[
  {
    "arxiv_id": "2505.13778v1",
    "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs",
    "authors": [
      "Guoheng Sun",
      "Ziyao Wang",
      "Bowei Tian",
      "Meng Liu",
      "Zheyu Shen",
      "Shwai He",
      "Yexiao He",
      "Wanghao Ye",
      "Yiting Wang",
      "Ang Li"
    ],
    "abstract": "As post-training techniques evolve, large language models (LLMs) are\nincreasingly augmented with structured multi-step reasoning abilities, often\noptimized through reinforcement learning. These reasoning-enhanced models\noutperform standard LLMs on complex tasks and now underpin many commercial LLM\nAPIs. However, to protect proprietary behavior and reduce verbosity, providers\ntypically conceal the reasoning traces while returning only the final answer.\nThis opacity introduces a critical transparency gap: users are billed for\ninvisible reasoning tokens, which often account for the majority of the cost,\nyet have no means to verify their authenticity. This opens the door to token\ncount inflation, where providers may overreport token usage or inject\nsynthetic, low-effort tokens to inflate charges. To address this issue, we\npropose CoIn, a verification framework that audits both the quantity and\nsemantic validity of hidden tokens. CoIn constructs a verifiable hash tree from\ntoken embedding fingerprints to check token counts, and uses embedding-based\nrelevance matching to detect fabricated reasoning content. Experiments\ndemonstrate that CoIn, when deployed as a trusted third-party auditor, can\neffectively detect token count inflation with a success rate reaching up to\n94.7%, showing the strong ability to restore billing transparency in opaque LLM\nservices. The dataset and code are available at\nhttps://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13778v1",
    "published_date": "2025-05-19 23:39:23 UTC",
    "updated_date": "2025-05-19 23:39:23 UTC"
  },
  {
    "arxiv_id": "2505.13777v1",
    "title": "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping",
    "authors": [
      "Subash Khanal",
      "Srikumar Sastry",
      "Aayush Dhakal",
      "Adeel Ahmad",
      "Nathan Jacobs"
    ],
    "abstract": "We present Sat2Sound, a multimodal representation learning framework for\nsoundscape mapping, designed to predict the distribution of sounds at any\nlocation on Earth. Existing methods for this task rely on satellite image and\npaired geotagged audio samples, which often fail to capture the diversity of\nsound sources at a given location. To address this limitation, we enhance\nexisting datasets by leveraging a Vision-Language Model (VLM) to generate\nsemantically rich soundscape descriptions for locations depicted in satellite\nimages. Our approach incorporates contrastive learning across audio, audio\ncaptions, satellite images, and satellite image captions. We hypothesize that\nthere is a fixed set of soundscape concepts shared across modalities. To this\nend, we learn a shared codebook of soundscape concepts and represent each\nsample as a weighted average of these concepts. Sat2Sound achieves\nstate-of-the-art performance in cross-modal retrieval between satellite image\nand audio on two datasets: GeoSound and SoundingEarth. Additionally, building\non Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a\nnovel application: location-based soundscape synthesis, which enables immersive\nacoustic experiences. Our code and models will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13777v1",
    "published_date": "2025-05-19 23:36:04 UTC",
    "updated_date": "2025-05-19 23:36:04 UTC"
  },
  {
    "arxiv_id": "2505.13775v1",
    "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
    "authors": [
      "Kaya Stechly",
      "Karthik Valmeekam",
      "Atharva Gundawar",
      "Vardhan Palod",
      "Subbarao Kambhampati"
    ],
    "abstract": "Recent impressive results from large reasoning models have been interpreted\nas a triumph of Chain of Thought (CoT), and especially of the process of\ntraining on CoTs sampled from base LLMs in order to help find new reasoning\npatterns. In this paper, we critically examine that interpretation by\ninvestigating how the semantics of intermediate tokens-often anthropomorphized\nas \"thoughts\" or reasoning traces and which are claimed to display behaviors\nlike backtracking, self-verification etc.-actually influence model performance.\nWe train transformer models on formally verifiable reasoning traces and\nsolutions, constraining both intermediate steps and final outputs to align with\nthose of a formal solver (in our case, A* search). By constructing a formal\ninterpreter of the semantics of our problems and intended algorithm, we\nsystematically evaluate not only solution accuracy but also the correctness of\nintermediate traces, thus allowing us to evaluate whether the latter causally\ninfluences the former. We notice that, despite significant improvements on the\nsolution-only baseline, models trained on entirely correct traces still produce\ninvalid reasoning traces when arriving at correct solutions. To further show\nthat trace accuracy is only loosely connected to solution accuracy, we then\ntrain models on noisy, corrupted traces which have no relation to the specific\nproblem each is paired with, and find that not only does performance remain\nlargely consistent with models trained on correct data, but in some cases can\nimprove upon it and generalize more robustly on out-of-distribution tasks.\nThese results challenge the assumption that intermediate tokens or \"Chains of\nThought\" induce predictable reasoning behaviors and caution against\nanthropomorphizing such outputs or over-interpreting them (despite their mostly\ncorrect forms) as evidence of human-like or algorithmic behaviors in language\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13775v1",
    "published_date": "2025-05-19 23:29:23 UTC",
    "updated_date": "2025-05-19 23:29:23 UTC"
  },
  {
    "arxiv_id": "2505.13774v1",
    "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models",
    "authors": [
      "Zidi Xiong",
      "Chen Shan",
      "Zhenting Qi",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13774v1",
    "published_date": "2025-05-19 23:20:24 UTC",
    "updated_date": "2025-05-19 23:20:24 UTC"
  },
  {
    "arxiv_id": "2505.13773v1",
    "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments",
    "authors": [
      "Ryan Bowers",
      "Richard Agbeyibor",
      "Jack Kolb",
      "Karen Feigh"
    ],
    "abstract": "We compare three methods of familiarizing a human with an artificial\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\na between-subjects user study (n=60), participants either read documentation\nabout the agent, trained alongside the agent prior to the mission, or were\ngiven no familiarization. Results showed that the most valuable information\nabout the agent included details of its decision-making algorithms and its\nrelative strengths and weaknesses compared to the human. This information\nallowed the familiarization groups to form sophisticated team strategies more\nquickly than the control group. Documentation-based familiarization led to the\nfastest adoption of these strategies, but also biased participants towards\nrisk-averse behavior that prevented high scores. Participants familiarized\nthrough direct interaction were able to infer much of the same information\nthrough observation, and were more willing to take risks and experiment with\ndifferent control modes, but reported weaker understanding of the agent's\ninternal processes. Significant differences were seen between individual\nparticipants' risk tolerance and methods of AI interaction, which should be\nconsidered when designing human-AI control interfaces. Based on our findings,\nwe recommend a human-AI team familiarization method that combines AI\ndocumentation, structured in-situ training, and exploratory interaction.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13773v1",
    "published_date": "2025-05-19 23:19:16 UTC",
    "updated_date": "2025-05-19 23:19:16 UTC"
  },
  {
    "arxiv_id": "2505.13770v1",
    "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference",
    "authors": [
      "Jin Du",
      "Li Chen",
      "Xun Xian",
      "An Luo",
      "Fangqiao Tian",
      "Ganghua Wang",
      "Charles Doss",
      "Xiaotong Shen",
      "Jie Ding"
    ],
    "abstract": "Reliable causal inference is essential for making decisions in high-stakes\nareas like medicine, economics, and public policy. However, it remains unclear\nwhether large language models (LLMs) can handle rigorous and trustworthy\nstatistical causal inference. Current benchmarks usually involve simplified\ntasks. For example, these tasks might only ask LLMs to identify semantic causal\nrelationships or draw conclusions directly from raw data. As a result, models\nmay overlook important statistical pitfalls, such as Simpson's paradox or\nselection bias. This oversight limits the applicability of LLMs in the real\nworld. To address these limitations, we propose CausalPitfalls, a comprehensive\nbenchmark designed to rigorously evaluate the capability of LLMs in overcoming\ncommon causal inference pitfalls. Our benchmark features structured challenges\nacross multiple difficulty levels, each paired with grading rubrics. This\napproach allows us to quantitatively measure both causal reasoning capabilities\nand the reliability of LLMs' responses. We evaluate models using two protocols:\n(1) direct prompting, which assesses intrinsic causal reasoning, and (2)\ncode-assisted prompting, where models generate executable code for explicit\nstatistical analysis. Additionally, we validate the effectiveness of this judge\nby comparing its scoring with assessments from human experts. Our results\nreveal significant limitations in current LLMs when performing statistical\ncausal inference. The CausalPitfalls benchmark provides essential guidance and\nquantitative metrics to advance the development of trustworthy causal reasoning\nsystems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ME",
      "stat.ML",
      "62-08, 68T50, 68T05, 68T01, 68T07, 62-07, 68U35, 62C99",
      "I.2.7; I.2.6; I.2.0; I.5.1; I.5.4; F.2.2; H.2.8; G.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13770v1",
    "published_date": "2025-05-19 23:06:00 UTC",
    "updated_date": "2025-05-19 23:06:00 UTC"
  },
  {
    "arxiv_id": "2505.13766v1",
    "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques",
    "authors": [
      "Avinash Patil"
    ],
    "abstract": "Software Quality Assurance (SQA) is critical for delivering reliable, secure,\nand efficient software products. The Software Quality Assurance Process aims to\nprovide assurance that work products and processes comply with predefined\nprovisions and plans. Recent advancements in Large Language Models (LLMs)\npresent new opportunities to enhance existing SQA processes by automating tasks\nlike requirement analysis, code review, test generation, and compliance checks.\nSimultaneously, established standards such as ISO/IEC 12207, ISO/IEC 25010,\nISO/IEC 5055, ISO 9001/ISO/IEC 90003, CMMI, and TMM provide structured\nframeworks for ensuring robust quality practices. This paper surveys the\nintersection of LLM-based SQA methods and these recognized standards,\nhighlighting how AI-driven solutions can augment traditional approaches while\nmaintaining compliance and process maturity. We first review the foundational\nsoftware quality standards and the technical fundamentals of LLMs in software\nengineering. Next, we explore various LLM-based SQA applications, including\nrequirement validation, defect detection, test generation, and documentation\nmaintenance. We then map these applications to key software quality frameworks,\nillustrating how LLMs can address specific requirements and metrics within each\nstandard. Empirical case studies and open-source initiatives demonstrate the\npractical viability of these methods. At the same time, discussions on\nchallenges (e.g., data privacy, model bias, explainability) underscore the need\nfor deliberate governance and auditing. Finally, we propose future directions\nencompassing adaptive learning, privacy-focused deployments, multimodal\nanalysis, and evolving standards for AI-driven software quality.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "16 pages, 1 Table, 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13766v1",
    "published_date": "2025-05-19 22:49:30 UTC",
    "updated_date": "2025-05-19 22:49:30 UTC"
  },
  {
    "arxiv_id": "2505.13763v1",
    "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations",
    "authors": [
      "Li Ji-An",
      "Hua-Dong Xiong",
      "Robert C. Wilson",
      "Marcelo G. Mattar",
      "Marcus K. Benna"
    ],
    "abstract": "Large language models (LLMs) can sometimes report the strategies they\nactually use to solve tasks, but they can also fail to do so. This suggests\nsome degree of metacognition -- the capacity to monitor one's own cognitive\nprocesses for subsequent reporting and self-control. Metacognitive abilities\nenhance AI capabilities but raise safety concerns, as models might obscure\ntheir internal processes to evade neural-activation-based oversight mechanisms\ndesigned to detect harmful behaviors. Given society's increased reliance on\nthese models, it is critical that we understand the limits of their\nmetacognitive abilities, particularly their ability to monitor their internal\nactivations. To address this, we introduce a neuroscience-inspired\nneurofeedback paradigm designed to quantify the ability of LLMs to explicitly\nreport and control their activation patterns. By presenting models with\nsentence-label pairs where labels correspond to sentence-elicited internal\nactivations along specific directions in the neural representation space, we\ndemonstrate that LLMs can learn to report and control these activations. The\nperformance varies with several factors: the number of example pairs provided,\nthe semantic interpretability of the target neural direction, and the variance\nexplained by that direction. These results reveal a \"metacognitive space\" with\ndimensionality much lower than the model's neural space, suggesting LLMs can\nmonitor only a subset of their neural mechanisms. Our findings provide\nempirical evidence quantifying metacognitive capabilities in LLMs, with\nsignificant implications for AI safety.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13763v1",
    "published_date": "2025-05-19 22:32:25 UTC",
    "updated_date": "2025-05-19 22:32:25 UTC"
  },
  {
    "arxiv_id": "2505.13742v1",
    "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation",
    "authors": [
      "Andrew Nam",
      "Declan Campbell",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "Neural networks are powerful tools for cognitive modeling due to their\nflexibility and emergent properties. However, interpreting their learned\nrepresentations remains challenging due to their sub-symbolic semantics. In\nthis work, we introduce a novel probabilistic framework for interpreting latent\ntask representations in neural networks. Inspired by Bayesian inference, our\napproach defines a distribution over representational units to infer their\ncausal contributions to task performance. Using ideas from information theory,\nwe propose a suite of tools and metrics to illuminate key model properties,\nincluding representational distributedness, manifold complexity, and\npolysemanticity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13742v1",
    "published_date": "2025-05-19 21:36:09 UTC",
    "updated_date": "2025-05-19 21:36:09 UTC"
  },
  {
    "arxiv_id": "2505.13740v1",
    "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
    "authors": [
      "Chenning Yu",
      "Sicun Gao"
    ],
    "abstract": "We introduce a novel resampling criterion using lift scores, for improving\ncompositional generation in diffusion models. By leveraging the lift scores, we\nevaluate whether generated samples align with each single condition and then\ncompose the results to determine whether the composed prompt is satisfied. Our\nkey insight is that lift scores can be efficiently approximated using only the\noriginal diffusion model, requiring no additional training or external modules.\nWe develop an optimized variant that achieves relatively lower computational\noverhead during inference while maintaining effectiveness. Through extensive\nexperiments, we demonstrate that lift scores significantly improved the\ncondition alignment for compositional generation across 2D synthetic data,\nCLEVR position tasks, and text-to-image synthesis. Our code is available at\nhttp://github.com/rainorangelemon/complift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13740v1",
    "published_date": "2025-05-19 21:34:42 UTC",
    "updated_date": "2025-05-19 21:34:42 UTC"
  },
  {
    "arxiv_id": "2505.13738v1",
    "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training",
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ],
    "abstract": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs),\nincluding learning rate {\\eta} and weight decay {\\lambda}. We study scaling\nlaws for HPs: formulas for how to scale HPs as we scale model size N, dataset\nsize D, and batch size B. Recent work suggests the AdamW timescale,\nB/({\\eta}{\\lambda}D), should remain constant across training settings, and we\nverify the implication that optimal {\\lambda} scales linearly with B, for a\nfixed N,D. However, as N,D scale, we show the optimal timescale obeys a precise\npower law in the tokens-per-parameter ratio, D/N. This law thus provides a\nmethod to accurately predict {\\lambda}opt in advance of large-scale training.\nWe also study scaling laws for optimal batch size Bopt (the B enabling lowest\nloss at a given N,D) and critical batch size Bcrit (the B beyond which further\ndata parallelism becomes ineffective). In contrast with prior work, we find\nboth Bopt and Bcrit scale as power laws in D, independent of model size, N.\nFinally, we analyze how these findings inform the real-world selection of\nPareto-optimal N and D under dual training time and compute objectives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13738v1",
    "published_date": "2025-05-19 21:27:33 UTC",
    "updated_date": "2025-05-19 21:27:33 UTC"
  },
  {
    "arxiv_id": "2505.13737v1",
    "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers",
    "authors": [
      "Andrew Nam",
      "Henry Conklin",
      "Yukang Yang",
      "Thomas Griffiths",
      "Jonathan Cohen",
      "Sarah-Jane Leslie"
    ],
    "abstract": "We present causal head gating (CHG), a scalable method for interpreting the\nfunctional roles of attention heads in transformer models. CHG learns soft\ngates over heads and assigns them a causal taxonomy - facilitating,\ninterfering, or irrelevant - based on their impact on task performance. Unlike\nprior approaches in mechanistic interpretability, which are hypothesis-driven\nand require prompt templates or target labels, CHG applies directly to any\ndataset using standard next-token prediction. We evaluate CHG across multiple\nlarge language models (LLMs) in the Llama 3 model family and diverse tasks,\nincluding syntax, commonsense, and mathematical reasoning, and show that CHG\nscores yield causal - not merely correlational - insight, validated via\nablation and causal mediation analyses. We also introduce contrastive CHG, a\nvariant that isolates sub-circuits for specific task components. Our findings\nreveal that LLMs contain multiple sparse, sufficient sub-circuits, that\nindividual head roles depend on interactions with others (low modularity), and\nthat instruction following and in-context learning rely on separable\nmechanisms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.13737v1",
    "published_date": "2025-05-19 21:24:13 UTC",
    "updated_date": "2025-05-19 21:24:13 UTC"
  },
  {
    "arxiv_id": "2505.13729v1",
    "title": "SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation",
    "authors": [
      "Abhinav Rajvanshi",
      "Pritish Sahu",
      "Tixiao Shan",
      "Karan Sikka",
      "Han-Pang Chiu"
    ],
    "abstract": "Adaptive collaboration is critical to a team of autonomous robots to perform\ncomplicated navigation tasks in large-scale unknown environments. An effective\ncollaboration strategy should be determined and adapted according to each\nrobot's skills and current status to successfully achieve the shared goal. We\npresent SayCoNav, a new approach that leverages large language models (LLMs)\nfor automatically generating this collaboration strategy among a team of\nrobots. Building on the collaboration strategy, each robot uses the LLM to\ngenerate its plans and actions in a decentralized way. By sharing information\nto each other during navigation, each robot also continuously updates its\nstep-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation\n(MultiON) tasks, that require the team of the robots to utilize their\ncomplementary strengths to efficiently search multiple different objects in\nunknown environments. By validating SayCoNav with varied team compositions and\nconditions against baseline methods, our experimental results show that\nSayCoNav can improve search efficiency by at most 44.28% through effective\ncollaboration among heterogeneous robots. It can also dynamically adapt to the\nchanging conditions during task execution.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13729v1",
    "published_date": "2025-05-19 20:58:06 UTC",
    "updated_date": "2025-05-19 20:58:06 UTC"
  },
  {
    "arxiv_id": "2505.13718v1",
    "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings",
    "authors": [
      "Safal Shrestha",
      "Minwu Kim",
      "Aadim Nepal",
      "Anubhav Shrestha",
      "Keith Ross"
    ],
    "abstract": "Designing effective reasoning-capable LLMs typically requires training using\nReinforcement Learning with Verifiable Rewards (RLVR) or distillation with\ncarefully curated Long Chain of Thoughts (CoT), both of which depend heavily on\nextensive training data. This creates a major challenge when the amount of\nquality training data is scarce. We propose a sample-efficient, two-stage\ntraining strategy to develop reasoning LLMs under limited supervision. In the\nfirst stage, we \"warm up\" the model by distilling Long CoTs from a toy domain,\nnamely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning\nskills. In the second stage, we apply RLVR to the warmed-up model using a\nlimited set of target-domain examples. Our experiments demonstrate that this\ntwo-phase approach offers several benefits: $(i)$ the warmup phase alone\nfacilitates generalized reasoning, leading to performance improvements across a\nrange of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro. $(ii)$ When both\nthe base model and the warmed-up model are RLVR trained on the same small\ndataset ($\\leq100$ examples), the warmed-up model consistently outperforms the\nbase model; $(iii)$ Warming up before RLVR training allows a model to maintain\ncross-domain generalizability even after training on a specific domain; $(iv)$\nIntroducing warmup in the pipeline improves not only accuracy but also overall\nsample efficiency during RLVR training. The results in this paper highlight the\npromise of warmup for building robust reasoning LLMs in data-scarce\nenvironments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13718v1",
    "published_date": "2025-05-19 20:29:15 UTC",
    "updated_date": "2025-05-19 20:29:15 UTC"
  },
  {
    "arxiv_id": "2505.15849v1",
    "title": "What Lives? A meta-analysis of diverse opinions on the definition of life",
    "authors": [
      "Reed Bender",
      "Karina Kofman",
      "Blaise Agüera y Arcas",
      "Michael Levin"
    ],
    "abstract": "The question of \"what is life?\" has challenged scientists and philosophers\nfor centuries, producing an array of definitions that reflect both the mystery\nof its emergence and the diversity of disciplinary perspectives brought to bear\non the question. Despite significant progress in our understanding of\nbiological systems, psychology, computation, and information theory, no single\ndefinition for life has yet achieved universal acceptance. This challenge\nbecomes increasingly urgent as advances in synthetic biology, artificial\nintelligence, and astrobiology challenge our traditional conceptions of what it\nmeans to be alive. We undertook a methodological approach that leverages large\nlanguage models (LLMs) to analyze a set of definitions of life provided by a\ncurated set of cross-disciplinary experts. We used a novel pairwise correlation\nanalysis to map the definitions into distinct feature vectors, followed by\nagglomerative clustering, intra-cluster semantic analysis, and t-SNE projection\nto reveal underlying conceptual archetypes. This methodology revealed a\ncontinuous landscape of the themes relating to the definition of life,\nsuggesting that what has historically been approached as a binary taxonomic\nproblem should be instead conceived as differentiated perspectives within a\nunified conceptual latent space. We offer a new methodological bridge between\nreductionist and holistic approaches to fundamental questions in science and\nphilosophy, demonstrating how computational semantic analysis can reveal\nconceptual patterns across disciplinary boundaries, and opening similar\npathways for addressing other contested definitional territories across the\nsciences.",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.CY",
      "q-bio.BM",
      "q-bio.CB",
      "q-bio.SC",
      "stat.AP"
    ],
    "primary_category": "q-bio.OT",
    "comment": "54 pages, 4 figures, 2 tables, 11 supplemental figures, 3\n  supplemental tables",
    "pdf_url": "http://arxiv.org/pdf/2505.15849v1",
    "published_date": "2025-05-19 20:17:37 UTC",
    "updated_date": "2025-05-19 20:17:37 UTC"
  },
  {
    "arxiv_id": "2505.13709v1",
    "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning",
    "authors": [
      "Jiayu Chen",
      "Aravind Venugopal",
      "Jeff Schneider"
    ],
    "abstract": "Offline reinforcement learning (RL) offers a powerful paradigm for\ndata-driven control. Compared to model-free approaches, offline model-based RL\n(MBRL) explicitly learns a world model from a static dataset and uses it as a\nsurrogate simulator, improving data efficiency and enabling potential\ngeneralization beyond the dataset support. However, most existing offline MBRL\nmethods follow a two-stage training procedure: first learning a world model by\nmaximizing the likelihood of the observed transitions, then optimizing a policy\nto maximize its expected return under the learned model. This objective\nmismatch results in a world model that is not necessarily optimized for\neffective policy learning. Moreover, we observe that policies learned via\noffline MBRL often lack robustness during deployment, and small adversarial\nnoise in the environment can lead to significant performance degradation. To\naddress these, we propose a framework that dynamically adapts the world model\nalongside the policy under a unified learning objective aimed at improving\nrobustness. At the core of our method is a maximin optimization problem, which\nwe solve by innovatively utilizing Stackelberg learning dynamics. We provide\ntheoretical analysis to support our design and introduce computationally\nefficient implementations. We benchmark our algorithm on twelve noisy D4RL\nMuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its\nstate-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13709v1",
    "published_date": "2025-05-19 20:14:33 UTC",
    "updated_date": "2025-05-19 20:14:33 UTC"
  },
  {
    "arxiv_id": "2505.13706v1",
    "title": "Are Large Language Models Good at Detecting Propaganda?",
    "authors": [
      "Julia Jose",
      "Rachel Greenstadt"
    ],
    "abstract": "Propagandists use rhetorical devices that rely on logical fallacies and\nemotional appeals to advance their agendas. Recognizing these techniques is key\nto making informed decisions. Recent advances in Natural Language Processing\n(NLP) have enabled the development of systems capable of detecting manipulative\ncontent. In this study, we look at several Large Language Models and their\nperformance in detecting propaganda techniques in news articles. We compare the\nperformance of these LLMs with transformer-based models. We find that, while\nGPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude\n3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally,\nwe find that all three LLMs outperform a MultiGranularity Network (MGN)\nbaseline in detecting instances of one out of six propaganda techniques\n(name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in\ndetecting instances of appeal to fear and flag-waving.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13706v1",
    "published_date": "2025-05-19 20:11:13 UTC",
    "updated_date": "2025-05-19 20:11:13 UTC"
  },
  {
    "arxiv_id": "2505.13697v1",
    "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs",
    "authors": [
      "Soumya Rani Samineni",
      "Durgesh Kalwar",
      "Karthik Valmeekam",
      "Kaya Stechly",
      "Subbarao Kambhampati"
    ],
    "abstract": "Reinforcement learning-based post-training of large language models (LLMs)\nhas recently gained attention, particularly following the release of DeepSeek\nR1, which applied GRPO for fine-tuning. Amid the growing hype around improved\nreasoning abilities attributed to RL post-training, we critically examine the\nformulation and assumptions underlying these methods. We start by highlighting\nthe popular structural assumptions made in modeling LLM training as a Markov\nDecision Process (MDP), and show how they lead to a degenerate MDP that doesn't\nquite need the RL/GRPO apparatus. The two critical structural assumptions\ninclude (1) making the MDP states be just a concatenation of the actions-with\nstates becoming the context window and the actions becoming the tokens in LLMs\nand (2) splitting the reward of a state-action trajectory uniformly across the\ntrajectory. Through a comprehensive analysis, we demonstrate that these\nsimplifying assumptions make the approach effectively equivalent to an\noutcome-driven supervised learning. Our experiments on benchmarks including\nGSM8K and Countdown using Qwen-2.5 base models show that iterative supervised\nfine-tuning, incorporating both positive and negative samples, achieves\nperformance comparable to GRPO-based training. We will also argue that the\nstructural assumptions indirectly incentivize the RL to generate longer\nsequences of intermediate tokens-which in turn feeds into the narrative of \"RL\ngenerating longer thinking traces.\" While RL may well be a very useful\ntechnique for improving the reasoning abilities of LLMs, our analysis shows\nthat the simplistic structural assumptions made in modeling the underlying MDP\nrender the popular LLM RL frameworks and their interpretations questionable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13697v1",
    "published_date": "2025-05-19 19:57:15 UTC",
    "updated_date": "2025-05-19 19:57:15 UTC"
  },
  {
    "arxiv_id": "2505.13696v1",
    "title": "Building spatial world models from sparse transitional episodic memories",
    "authors": [
      "Zizhan He",
      "Maxime Daigle",
      "Pouya Bashivan"
    ],
    "abstract": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13696v1",
    "published_date": "2025-05-19 19:56:24 UTC",
    "updated_date": "2025-05-19 19:56:24 UTC"
  },
  {
    "arxiv_id": "2505.13672v1",
    "title": "A*-Decoding: Token-Efficient Inference Scaling",
    "authors": [
      "Giannis Chatziveroglou"
    ],
    "abstract": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13672v1",
    "published_date": "2025-05-19 19:19:48 UTC",
    "updated_date": "2025-05-19 19:19:48 UTC"
  },
  {
    "arxiv_id": "2505.13668v1",
    "title": "MAFA: A multi-agent framework for annotation",
    "authors": [
      "Mahmood Hegazy",
      "Aaron Rodrigues",
      "Azzam Naeem"
    ],
    "abstract": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13668v1",
    "published_date": "2025-05-19 19:16:37 UTC",
    "updated_date": "2025-05-19 19:16:37 UTC"
  },
  {
    "arxiv_id": "2505.13650v1",
    "title": "Self-Reinforced Graph Contrastive Learning",
    "authors": [
      "Chou-Ying Hsieh",
      "Chun-Fu Jang",
      "Cheng-En Hsieh",
      "Qian-Hui Chen",
      "Sy-Yen Kuo"
    ],
    "abstract": "Graphs serve as versatile data structures in numerous real-world\ndomains-including social networks, molecular biology, and knowledge graphs-by\ncapturing intricate relational information among entities. Among graph-based\nlearning techniques, Graph Contrastive Learning (GCL) has gained significant\nattention for its ability to derive robust, self-supervised graph\nrepresentations through the contrasting of positive and negative sample pairs.\nHowever, a critical challenge lies in ensuring high-quality positive pairs so\nthat the intrinsic semantic and structural properties of the original graph are\npreserved rather than distorted. To address this issue, we propose SRGCL\n(Self-Reinforced Graph Contrastive Learning), a novel framework that leverages\nthe model's own encoder to dynamically evaluate and select high-quality\npositive pairs. We designed a unified positive pair generator employing\nmultiple augmentation strategies, and a selector guided by the manifold\nhypothesis to maintain the underlying geometry of the latent space. By adopting\na probabilistic mechanism for selecting positive pairs, SRGCL iteratively\nrefines its assessment of pair quality as the encoder's representational power\nimproves. Extensive experiments on diverse graph-level classification tasks\ndemonstrate that SRGCL, as a plug-in module, consistently outperforms\nstate-of-the-art GCL methods, underscoring its adaptability and efficacy across\nvarious domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13650v1",
    "published_date": "2025-05-19 18:45:54 UTC",
    "updated_date": "2025-05-19 18:45:54 UTC"
  },
  {
    "arxiv_id": "2505.13636v1",
    "title": "Incentivizing Truthful Language Models via Peer Elicitation Games",
    "authors": [
      "Baiting Chen",
      "Tong Zhu",
      "Jiale Han",
      "Lexin Li",
      "Gang Li",
      "Xiaowu Dai"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where rewards are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13636v1",
    "published_date": "2025-05-19 18:16:58 UTC",
    "updated_date": "2025-05-19 18:16:58 UTC"
  },
  {
    "arxiv_id": "2505.13631v1",
    "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization",
    "authors": [
      "Andrei Manolache",
      "Luiz F. O. Chamon",
      "Mathias Niepert"
    ],
    "abstract": "Equivariant neural networks are designed to respect symmetries through their\narchitecture, boosting generalization and sample efficiency when those\nsymmetries are present in the data distribution. Real-world data, however,\noften departs from perfect symmetry because of noise, structural variation,\nmeasurement bias, or other symmetry-breaking effects. Strictly equivariant\nmodels may struggle to fit the data, while unconstrained models lack a\nprincipled way to leverage partial symmetries. Even when the data is fully\nsymmetric, enforcing equivariance can hurt training by limiting the model to a\nrestricted region of the parameter space. Guided by homotopy principles, where\nan optimization problem is solved by gradually transforming a simpler problem\ninto a complex one, we introduce Adaptive Constrained Equivariance (ACE), a\nconstrained optimization approach that starts with a flexible, non-equivariant\nmodel and gradually reduces its deviation from equivariance. This gradual\ntightening smooths training early on and settles the model at a data-driven\nequilibrium, balancing between equivariance and non-equivariance. Across\nmultiple architectures and tasks, our method consistently improves performance\nmetrics, sample efficiency, and robustness to input perturbations compared with\nstrictly equivariant models and heuristic equivariance relaxations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13631v1",
    "published_date": "2025-05-19 18:08:09 UTC",
    "updated_date": "2025-05-19 18:08:09 UTC"
  },
  {
    "arxiv_id": "2505.13617v1",
    "title": "Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses",
    "authors": [
      "Christopher Ick",
      "Gordon Wichern",
      "Yoshiki Masuyama",
      "François Germain",
      "Jonathan Le Roux"
    ],
    "abstract": "The characteristics of a sound field are intrinsically linked to the\ngeometric and spatial properties of the environment surrounding a sound source\nand a listener. The physics of sound propagation is captured in a time-domain\nsignal known as a room impulse response (RIR). Prior work using neural fields\n(NFs) has allowed learning spatially-continuous representations of RIRs from\nfinite RIR measurements. However, previous NF-based methods have focused on\nmonaural omnidirectional or at most binaural listeners, which does not\nprecisely capture the directional characteristics of a real sound field at a\nsingle point. We propose a direction-aware neural field (DANF) that more\nexplicitly incorporates the directional information by Ambisonic-format RIRs.\nWhile DANF inherently captures spatial relations between sources and listeners,\nwe further propose a direction-aware loss. In addition, we investigate the\nability of DANF to adapt to new rooms in various ways including low-rank\nadaptation.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at Interspeech 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13617v1",
    "published_date": "2025-05-19 18:01:53 UTC",
    "updated_date": "2025-05-19 18:01:53 UTC"
  },
  {
    "arxiv_id": "2505.13448v1",
    "title": "CIE: Controlling Language Model Text Generations Using Continuous Signals",
    "authors": [
      "Vinay Samuel",
      "Harshita Diddee",
      "Yiming Zhang",
      "Daphne Ippolito"
    ],
    "abstract": "Aligning language models with user intent is becoming increasingly relevant\nto enhance user experience. This calls for designing methods that can allow\nusers to control the properties of the language that LMs generate. For example,\ncontrolling the length of the generation, the complexity of the language that\ngets chosen, the sentiment, tone, etc. Most existing work attempts to integrate\nusers' control by conditioning LM generations on natural language prompts or\ndiscrete control signals, which are often brittle and hard to scale. In this\nwork, we are interested in \\textit{continuous} control signals, ones that exist\nalong a spectrum that can't easily be captured in a natural language prompt or\nvia existing techniques in conditional generation. Through a case study in\ncontrolling the precise response-length of generations produced by LMs, we\ndemonstrate how after fine-tuning, behaviors of language models can be\ncontrolled via continuous signals -- as vectors that are interpolated between a\n\"low\" and a \"high\" token embedding. Our method more reliably exerts\nresponse-length control than in-context learning methods or fine-tuning methods\nthat represent the control signal as a discrete signal. Our full open-sourced\ncode and datasets are available at https://github.com/vsamuel2003/CIE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13448v1",
    "published_date": "2025-05-19 17:59:58 UTC",
    "updated_date": "2025-05-19 17:59:58 UTC"
  },
  {
    "arxiv_id": "2505.13445v1",
    "title": "Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards",
    "authors": [
      "Xiaoyuan Liu",
      "Tian Liang",
      "Zhiwei He",
      "Jiahao Xu",
      "Wenxuan Wang",
      "Pinjia He",
      "Zhaopeng Tu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Large Language Models (LLMs) show great promise in complex reasoning, with\nReinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement\nstrategy. However, a prevalent issue is ``superficial self-reflection'', where\nmodels fail to robustly verify their own outputs. We introduce RISE\n(Reinforcing Reasoning with Self-Verification), a novel online RL framework\ndesigned to tackle this. RISE explicitly and simultaneously trains an LLM to\nimprove both its problem-solving and self-verification abilities within a\nsingle, integrated RL process. The core mechanism involves leveraging\nverifiable rewards from an outcome verifier to provide on-the-fly feedback for\nboth solution generation and self-verification tasks. In each iteration, the\nmodel generates solutions, then critiques its own on-policy generated\nsolutions, with both trajectories contributing to the policy update. Extensive\nexperiments on diverse mathematical reasoning benchmarks show that RISE\nconsistently improves model's problem-solving accuracy while concurrently\nfostering strong self-verification skills. Our analyses highlight the\nadvantages of online verification and the benefits of increased verification\ncompute. Additionally, RISE models exhibit more frequent and accurate\nself-verification behaviors during reasoning. These advantages reinforce RISE\nas a flexible and effective path towards developing more robust and self-aware\nreasoners.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "code available at https://github.com/xyliu-cs/RISE",
    "pdf_url": "http://arxiv.org/pdf/2505.13445v1",
    "published_date": "2025-05-19 17:59:31 UTC",
    "updated_date": "2025-05-19 17:59:31 UTC"
  },
  {
    "arxiv_id": "2505.13439v1",
    "title": "VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation",
    "authors": [
      "Huawei Lin",
      "Tong Geng",
      "Zhaozhuo Xu",
      "Weijie Zhao"
    ],
    "abstract": "Autoregressive (AR) models have recently shown strong performance in image\ngeneration, where a critical component is the visual tokenizer (VT) that maps\ncontinuous pixel inputs to discrete token sequences. The quality of the VT\nlargely defines the upper bound of AR model performance. However, current\ndiscrete VTs fall significantly behind continuous variational autoencoders\n(VAEs), leading to degraded image reconstructions and poor preservation of\ndetails and text. Existing benchmarks focus on end-to-end generation quality,\nwithout isolating VT performance. To address this gap, we introduce VTBench, a\ncomprehensive benchmark that systematically evaluates VTs across three core\ntasks: Image Reconstruction, Detail Preservation, and Text Preservation, and\ncovers a diverse range of evaluation scenarios. We systematically assess\nstate-of-the-art VTs using a set of metrics to evaluate the quality of\nreconstructed images. Our findings reveal that continuous VAEs produce superior\nvisual representations compared to discrete VTs, particularly in retaining\nspatial structure and semantic detail. In contrast, the degraded\nrepresentations produced by discrete VTs often lead to distorted\nreconstructions, loss of fine-grained textures, and failures in preserving text\nand object integrity. Furthermore, we conduct experiments on GPT-4o image\ngeneration and discuss its potential AR nature, offering new insights into the\nrole of visual tokenization. We release our benchmark and codebase publicly to\nsupport further research and call on the community to develop strong,\ngeneral-purpose open-source VTs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 13 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.13439v1",
    "published_date": "2025-05-19 17:59:01 UTC",
    "updated_date": "2025-05-19 17:59:01 UTC"
  },
  {
    "arxiv_id": "2505.13438v1",
    "title": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization",
    "authors": [
      "Penghui Qi",
      "Zichen Liu",
      "Tianyu Pang",
      "Chao Du",
      "Wee Sun Lee",
      "Min Lin"
    ],
    "abstract": "Scaling test-time compute is crucial for enhancing the reasoning capabilities\nof large language models (LLMs). Existing approaches typically employ\nreinforcement learning (RL) to maximize a verifiable reward obtained at the end\nof reasoning traces. However, such methods optimize only the final performance\nunder a large and fixed token budget, which hinders efficiency in both training\nand deployment. In this work, we present a novel framework, AnytimeReasoner, to\noptimize anytime reasoning performance, which aims to improve token efficiency\nand the flexibility of reasoning under varying token budget constraints. To\nachieve this, we truncate the complete thinking process to fit within sampled\ntoken budgets from a prior distribution, compelling the model to summarize the\noptimal answer for each truncated thinking for verification. This introduces\nverifiable dense rewards into the reasoning process, facilitating more\neffective credit assignment in RL optimization. We then optimize the thinking\nand summary policies in a decoupled manner to maximize the cumulative reward.\nAdditionally, we introduce a novel variance reduction technique, Budget\nRelative Policy Optimization (BRPO), to enhance the robustness and efficiency\nof the learning process when reinforcing the thinking policy. Empirical results\nin mathematical reasoning tasks demonstrate that our method consistently\noutperforms GRPO across all thinking budgets under various prior distributions,\nenhancing both training and token efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13438v1",
    "published_date": "2025-05-19 17:58:44 UTC",
    "updated_date": "2025-05-19 17:58:44 UTC"
  },
  {
    "arxiv_id": "2505.13437v1",
    "title": "FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance",
    "authors": [
      "Dian Shao",
      "Mingfei Shi",
      "Shengda Xu",
      "Haodong Chen",
      "Yongle Huang",
      "Binglu Wang"
    ],
    "abstract": "Despite significant advances in video generation, synthesizing physically\nplausible human actions remains a persistent challenge, particularly in\nmodeling fine-grained semantics and complex temporal dynamics. For instance,\ngenerating gymnastics routines such as \"switch leap with 0.5 turn\" poses\nsubstantial difficulties for current methods, often yielding unsatisfactory\nresults. To bridge this gap, we propose FinePhys, a Fine-grained human action\ngeneration framework that incorporates Physics to obtain effective skeletal\nguidance. Specifically, FinePhys first estimates 2D poses in an online manner\nand then performs 2D-to-3D dimension lifting via in-context learning. To\nmitigate the instability and limited interpretability of purely data-driven 3D\nposes, we further introduce a physics-based motion re-estimation module\ngoverned by Euler-Lagrange equations, calculating joint accelerations via\nbidirectional temporal updating. The physically predicted 3D poses are then\nfused with data-driven ones, offering multi-scale 2D heatmap guidance for the\ndiffusion process. Evaluated on three fine-grained action subsets from FineGym\n(FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms\ncompetitive baselines. Comprehensive qualitative results further demonstrate\nFinePhys's ability to generate more natural and plausible fine-grained human\nactions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13437v1",
    "published_date": "2025-05-19 17:58:11 UTC",
    "updated_date": "2025-05-19 17:58:11 UTC"
  },
  {
    "arxiv_id": "2505.13427v1",
    "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision",
    "authors": [
      "Lingxiao Du",
      "Fanqing Meng",
      "Zongkai Liu",
      "Zhixiang Zhou",
      "Ping Luo",
      "Qiaosheng Zhang",
      "Wenqi Shao"
    ],
    "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive\nprogress in vision-language understanding, they still struggle with complex\nmulti-step reasoning, often producing logically inconsistent or partially\ncorrect solutions. A key limitation lies in the lack of fine-grained\nsupervision over intermediate reasoning steps. To address this, we propose\nMM-PRM, a process reward model trained within a fully automated, scalable\nframework. We first build MM-Policy, a strong multimodal model trained on\ndiverse mathematical reasoning data. Then, we construct MM-K12, a curated\ndataset of 10,000 multimodal math problems with verifiable answers, which\nserves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based\npipeline, we generate over 700k step-level annotations without human labeling.\nThe resulting PRM is used to score candidate reasoning paths in the Best-of-N\ninference setup and achieves significant improvements across both in-domain\n(MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.)\nbenchmarks. Further analysis confirms the effectiveness of soft labels, smaller\nlearning rates, and path diversity in optimizing PRM performance. MM-PRM\ndemonstrates that process supervision is a powerful tool for enhancing the\nlogical robustness of multimodal reasoning systems. We release all our codes\nand data at https://github.com/ModalMinds/MM-PRM.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13427v1",
    "published_date": "2025-05-19 17:55:08 UTC",
    "updated_date": "2025-05-19 17:55:08 UTC"
  },
  {
    "arxiv_id": "2505.13425v1",
    "title": "Learnware of Language Models: Specialized Small Language Models Can Do Big",
    "authors": [
      "Zhi-Hao Tan",
      "Zi-Chen Zhao",
      "Hao-Yu Shi",
      "Xin-Yu Zhang",
      "Peng Tan",
      "Yang Yu",
      "Zhi-Hua Zhou"
    ],
    "abstract": "The learnware paradigm offers a novel approach to machine learning by\nenabling users to reuse a set of well-trained models for tasks beyond the\nmodels' original purposes. It eliminates the need to build models from scratch,\ninstead relying on specifications (representations of a model's capabilities)\nto identify and leverage the most suitable models for new tasks. While\nlearnware has proven effective in many scenarios, its application to language\nmodels has remained largely unexplored. At the same time, large language models\n(LLMs) have demonstrated remarkable universal question-answering abilities, yet\nthey face challenges in specialized scenarios due to data scarcity, privacy\nconcerns, and high computational costs, thus more and more specialized small\nlanguage models (SLMs) are being trained for specific domains. To address these\nlimitations systematically, the learnware paradigm provides a promising\nsolution by enabling maximum utilization of specialized SLMs, and allowing\nusers to identify and reuse them in a collaborative and privacy-preserving\nmanner.\n  This paper presents a preliminary attempt to apply the learnware paradigm to\nlanguage models. We simulated a learnware system comprising approximately 100\nlearnwares of specialized SLMs with 8B parameters, fine-tuned across finance,\nhealthcare, and mathematics domains. Each learnware contains an SLM and a\nspecification, which enables users to identify the most relevant models without\nexposing their own data. Experimental results demonstrate promising\nperformance: by selecting one suitable learnware for each task-specific\ninference, the system outperforms the base SLMs on all benchmarks. Compared to\nLLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and\nLlama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses\nFlan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical\ndomain tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13425v1",
    "published_date": "2025-05-19 17:54:35 UTC",
    "updated_date": "2025-05-19 17:54:35 UTC"
  },
  {
    "arxiv_id": "2505.13417v1",
    "title": "AdaptThink: Reasoning Models Can Learn When to Think",
    "authors": [
      "Jiajie Zhang",
      "Nianyi Lin",
      "Lei Hou",
      "Ling Feng",
      "Juanzi Li"
    ],
    "abstract": "Recently, large reasoning models have achieved impressive performance on\nvarious tasks by employing human-like deep thinking. However, the lengthy\nthinking process substantially increases inference overhead, making efficiency\na critical bottleneck. In this work, we first demonstrate that NoThinking,\nwhich prompts the reasoning model to skip thinking and directly generate the\nfinal solution, is a better choice for relatively simple tasks in terms of both\nperformance and efficiency. Motivated by this, we propose AdaptThink, a novel\nRL algorithm to teach reasoning models to choose the optimal thinking mode\nadaptively based on problem difficulty. Specifically, AdaptThink features two\ncore components: (1) a constrained optimization objective that encourages the\nmodel to choose NoThinking while maintaining the overall performance; (2) an\nimportance sampling strategy that balances Thinking and NoThinking samples\nduring on-policy training, thereby enabling cold start and allowing the model\nto explore and exploit both thinking modes throughout the training process. Our\nexperiments indicate that AdaptThink significantly reduces the inference costs\nwhile further enhancing performance. Notably, on three math datasets,\nAdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B\nby 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive\nthinking-mode selection for optimizing the balance between reasoning quality\nand efficiency. Our codes and models are available at\nhttps://github.com/THU-KEG/AdaptThink.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13417v1",
    "published_date": "2025-05-19 17:50:52 UTC",
    "updated_date": "2025-05-19 17:50:52 UTC"
  },
  {
    "arxiv_id": "2505.13408v1",
    "title": "CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process",
    "authors": [
      "Jinhe Bi",
      "Danqi Yan",
      "Yifan Wang",
      "Wenke Huang",
      "Haokun Chen",
      "Guancheng Wan",
      "Mang Ye",
      "Xun Xiao",
      "Hinrich Schuetze",
      "Volker Tresp",
      "Yunpu Ma"
    ],
    "abstract": "Recent Large Reasoning Models significantly improve the reasoning ability of\nLarge Language Models by learning to reason, exhibiting the promising\nperformance in solving complex tasks. LRMs solve tasks that require complex\nreasoning by explicitly generating reasoning trajectories together with\nanswers. Nevertheless, judging the quality of such an output answer is not easy\nbecause only considering the correctness of the answer is not enough and the\nsoundness of the reasoning trajectory part matters as well. Logically, if the\nsoundness of the reasoning part is poor, even if the answer is correct, the\nconfidence of the derived answer should be low. Existing methods did consider\njointly assessing the overall output answer by taking into account the\nreasoning part, however, their capability is still not satisfactory as the\ncausal relationship of the reasoning to the concluded answer cannot properly\nreflected. In this paper, inspired by classical mechanics, we present a novel\napproach towards establishing a CoT-Kinetics energy equation. Specifically, our\nCoT-Kinetics energy equation formulates the token state transformation process,\nwhich is regulated by LRM internal transformer layers, as like a particle\nkinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy\nassigns a scalar score to evaluate specifically the soundness of the reasoning\nphase, telling how confident the derived answer could be given the evaluated\nreasoning. As such, the LRM's overall output quality can be accurately\nmeasured, rather than a coarse judgment (e.g., correct or incorrect) anymore.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13408v1",
    "published_date": "2025-05-19 17:44:26 UTC",
    "updated_date": "2025-05-19 17:44:26 UTC"
  },
  {
    "arxiv_id": "2505.13406v1",
    "title": "AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database",
    "authors": [
      "Rong Bian",
      "Yu Geng",
      "Zijian Yang",
      "Bing Cheng"
    ],
    "abstract": "A mathematical knowledge graph (KG) presents knowledge within the field of\nmathematics in a structured manner. Constructing a math KG using natural\nlanguage is an essential but challenging task. There are two major limitations\nof existing works: first, they are constrained by corpus completeness, often\ndiscarding or manually supplementing incomplete knowledge; second, they\ntypically fail to fully automate the integration of diverse knowledge sources.\nThis paper proposes AutoMathKG, a high-quality, wide-coverage, and\nmulti-dimensional math KG capable of automatic updates. AutoMathKG regards\nmathematics as a vast directed graph composed of Definition, Theorem, and\nProblem entities, with their reference relationships as edges. It integrates\nknowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing\nentities and relationships with large language models (LLMs) via in-context\nlearning for data augmentation. To search for similar entities, MathVD, a\nvector database, is built through two designed embedding strategies using\nSBERT. To automatically update, two mechanisms are proposed. For knowledge\ncompletion mechanism, Math LLM is developed to interact with AutoMathKG,\nproviding missing proofs or solutions. For knowledge fusion mechanism, MathVD\nis used to retrieve similar entities, and LLM is used to determine whether to\nmerge with a candidate or add as a new entity. A wide range of experiments\ndemonstrate the advanced performance and broad applicability of the AutoMathKG\nsystem, including superior reachability query results in MathVD compared to\nfive baselines and robust mathematical reasoning capability in Math LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13406v1",
    "published_date": "2025-05-19 17:41:29 UTC",
    "updated_date": "2025-05-19 17:41:29 UTC"
  },
  {
    "arxiv_id": "2505.13400v1",
    "title": "Robin: A multi-agent system for automating scientific discovery",
    "authors": [
      "Ali Essam Ghareeb",
      "Benjamin Chang",
      "Ludovico Mitchener",
      "Angela Yiu",
      "Caralyn J. Szostkiewicz",
      "Jon M. Laurent",
      "Muhammed T. Razzak",
      "Andrew D. White",
      "Michaela M. Hinks",
      "Samuel G. Rodriques"
    ],
    "abstract": "Scientific discovery is driven by the iterative process of background\nresearch, hypothesis generation, experimentation, and data analysis. Despite\nrecent advancements in applying artificial intelligence to scientific\ndiscovery, no system has yet automated all of these stages in a single\nworkflow. Here, we introduce Robin, the first multi-agent system capable of\nfully automating the key intellectual steps of the scientific process. By\nintegrating literature search agents with data analysis agents, Robin can\ngenerate hypotheses, propose experiments, interpret experimental results, and\ngenerate updated hypotheses, achieving a semi-autonomous approach to scientific\ndiscovery. By applying this system, we were able to identify a novel treatment\nfor dry age-related macular degeneration (dAMD), the major cause of blindness\nin the developed world. Robin proposed enhancing retinal pigment epithelium\nphagocytosis as a therapeutic strategy, and identified and validated a\npromising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho\nkinase (ROCK) inhibitor that has never previously been proposed for treating\ndAMD. To elucidate the mechanism of ripasudil-induced upregulation of\nphagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment,\nwhich revealed upregulation of ABCA1, a critical lipid efflux pump and possible\nnovel target. All hypotheses, experimental plans, data analyses, and data\nfigures in the main text of this report were produced by Robin. As the first AI\nsystem to autonomously discover and validate a novel therapeutic candidate\nwithin an iterative lab-in-the-loop framework, Robin establishes a new paradigm\nfor AI-driven scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13400v1",
    "published_date": "2025-05-19 17:36:17 UTC",
    "updated_date": "2025-05-19 17:36:17 UTC"
  },
  {
    "arxiv_id": "2505.13393v2",
    "title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar",
    "authors": [
      "Christopher K. Frantz"
    ],
    "abstract": "This article provides an overview of IG Parser, a software that facilitates\nqualitative content analysis of formal (e.g., legal) rules or informal (e.g.,\nsocial) norms, and strategies (such as conventions) -- referred to as\ninstitutions -- that govern social systems and operate configurally to describe\ninstitutional systems. To this end, the IG Parser employs a distinctive syntax\nthat ensures rigorous encoding of natural language, while automating the\ntransformation into various formats that support the downstream analysis using\ndiverse analytical techniques. The conceptual core of the IG Parser is an\nassociated syntax, IG Script, that operationalizes the conceptual foundations\nof the Institutional Grammar, and more specifically the Institutional Grammar\n2.0, an analytical paradigm for institutional analysis. This article presents\nthe IG Parser, including its conceptual foundations, the syntax specification\nof IG Script, and its architectural principles. This overview is augmented with\nselective illustrative examples that highlight its use and the associated\nbenefits.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "68T30, 68T50",
      "E.2; H.1.0; I.7.2; I.6.5; K.4.1"
    ],
    "primary_category": "cs.MA",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.13393v2",
    "published_date": "2025-05-19 17:33:15 UTC",
    "updated_date": "2025-05-20 09:52:05 UTC"
  },
  {
    "arxiv_id": "2505.13391v1",
    "title": "Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks",
    "authors": [
      "Mikołaj Małkiński",
      "Jacek Mańdziuk"
    ],
    "abstract": "The abstract visual reasoning (AVR) domain presents a diverse suite of\nanalogy-based tasks devoted to studying model generalization. Recent years have\nbrought dynamic progress in the field, particularly in i.i.d. scenarios, in\nwhich models are trained and evaluated on the same data distributions.\nNevertheless, o.o.d. setups that assess model generalization to new test\ndistributions remain challenging even for the most recent models. To advance\ngeneralization in AVR tasks, we present the Pathways of Normalized Group\nConvolution model (PoNG), a novel neural architecture that features group\nconvolution, normalization, and a parallel design. We consider a wide set of\nAVR benchmarks, including Raven's Progressive Matrices and visual analogy\nproblems with both synthetic and real-world images. The experiments demonstrate\nstrong generalization capabilities of the proposed model, which in several\nsettings outperforms the existing literature methods.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.13391v1",
    "published_date": "2025-05-19 17:32:07 UTC",
    "updated_date": "2025-05-19 17:32:07 UTC"
  },
  {
    "arxiv_id": "2505.13388v1",
    "title": "R3: Robust Rubric-Agnostic Reward Models",
    "authors": [
      "David Anugraha",
      "Zilu Tang",
      "Lester James V. Miranda",
      "Hanyang Zhao",
      "Mohammad Rifqi Farhansyah",
      "Garry Kuwanto",
      "Derry Wijaya",
      "Genta Indra Winata"
    ],
    "abstract": "Reward models are essential for aligning language model outputs with human\npreferences, yet existing approaches often lack both controllability and\ninterpretability. These models are typically optimized for narrow objectives,\nlimiting their generalizability to broader downstream tasks. Moreover, their\nscalar outputs are difficult to interpret without contextual reasoning. To\naddress these limitations, we introduce R3, a novel reward modeling framework\nthat is rubric-agnostic, generalizable across evaluation dimensions, and\nprovides interpretable, reasoned score assignments. R3 enables more transparent\nand flexible evaluation of language models, supporting robust alignment with\ndiverse human values and use cases. Our models, data, and code are available as\nopen source at https://github.com/rubricreward/r3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.13388v1",
    "published_date": "2025-05-19 17:29:03 UTC",
    "updated_date": "2025-05-19 17:29:03 UTC"
  },
  {
    "arxiv_id": "2505.13381v1",
    "title": "How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors",
    "authors": [
      "Mak Ahmad",
      "Prerna Ravi",
      "David Karger",
      "Marc Facciotti"
    ],
    "abstract": "Providing personalized, detailed feedback at scale in large undergraduate\nSTEM courses remains a persistent challenge. We present an empirically\nevaluated practice exam system that integrates AI generated feedback with\ntargeted textbook references, deployed in a large introductory biology course.\nOur system encourages metacognitive behavior by asking students to explain\ntheir answers and declare their confidence. It uses OpenAI's GPT-4o to generate\npersonalized feedback based on this information, while directing them to\nrelevant textbook sections. Through interaction logs from consenting\nparticipants across three midterms (541, 342, and 413 students respectively),\ntotaling 28,313 question-student interactions across 146 learning objectives,\nalong with 279 surveys and 23 interviews, we examined the system's impact on\nlearning outcomes and engagement. Across all midterms, feedback types showed no\nstatistically significant performance differences, though some trends suggested\npotential benefits. The most substantial impact came from the required\nconfidence ratings and explanations, which students reported transferring to\ntheir actual exam strategies. About 40 percent of students engaged with\ntextbook references when prompted by feedback -- far higher than traditional\nreading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5),\nwith 82.1 percent reporting increased confidence on practiced midterm topics,\nand 73.4 percent indicating they could recall and apply specific concepts. Our\nfindings suggest that embedding structured reflection requirements may be more\nimpactful than sophisticated feedback mechanisms.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "K.3.1; I.2.7; H.5.2"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 3 figures, to appear in Proceedings of the Twelfth ACM\n  Conference on Learning @ Scale (L@S 2025), July 2025, Palermo, Italy",
    "pdf_url": "http://arxiv.org/pdf/2505.13381v1",
    "published_date": "2025-05-19 17:25:07 UTC",
    "updated_date": "2025-05-19 17:25:07 UTC"
  },
  {
    "arxiv_id": "2505.13380v1",
    "title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition",
    "authors": [
      "Nam V. Nguyen",
      "Huy Nguyen",
      "Quang Pham",
      "Van Nguyen",
      "Savitha Ramasamy",
      "Nhat Ho"
    ],
    "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the\nmodel complexity beyond the mean of increasing the network's depth or width.\nHowever, we argue that effective SMoE training remains challenging because of\nthe suboptimal routing process where experts that perform computation do not\ndirectly contribute to the routing process. In this work, we propose\ncompetition, a novel mechanism to route tokens to experts with the highest\nneural response. Theoretically, we show that the competition mechanism enjoys a\nbetter sample efficiency than the traditional softmax routing. Furthermore, we\ndevelop CompeteSMoE, a simple yet effective algorithm to train large language\nmodels by deploying a router to learn the competition policy, thus enjoying\nstrong performances at a low training overhead. Our extensive empirical\nevaluations on both the visual instruction tuning and language pre-training\ntasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE\ncompared to state-of-the-art SMoE strategies. We have made the implementation\navailable at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an\nimproved version of the previous study at arXiv:2402.02526",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "52 pages. This work is an improved version of the previous study at\n  arXiv:2402.02526",
    "pdf_url": "http://arxiv.org/pdf/2505.13380v1",
    "published_date": "2025-05-19 17:24:26 UTC",
    "updated_date": "2025-05-19 17:24:26 UTC"
  },
  {
    "arxiv_id": "2505.13379v1",
    "title": "Thinkless: LLM Learns When to Think",
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning,\nhave demonstrated remarkable performance on tasks requiring complex logical\ninference. However, applying elaborate reasoning for all queries often results\nin substantial computational inefficiencies, particularly when many problems\nadmit straightforward solutions. This motivates an open question: Can LLMs\nlearn when to think? To answer this, we propose Thinkless, a learnable\nframework that empowers an LLM to adaptively select between short-form and\nlong-form reasoning, based on both task complexity and the model's ability.\nThinkless is trained under a reinforcement learning paradigm and employs two\ncontrol tokens, <short> for concise responses and <think> for detailed\nreasoning. At the core of our method is a Decoupled Group Relative Policy\nOptimization (DeGRPO) algorithm, which decomposes the learning objective of\nhybrid reasoning into two components: (1) a control token loss that governs the\nselection of the reasoning mode, and (2) a response loss that improves the\naccuracy of the generated answers. This decoupled formulation enables\nfine-grained control over the contributions of each objective, stabilizing\ntraining and effectively preventing collapse observed in vanilla GRPO.\nEmpirically, on several benchmarks such as Minerva Algebra, MATH-500, and\nGSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% -\n90%, significantly improving the efficiency of Reasoning Language Models. The\ncode is available at https://github.com/VainF/Thinkless",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13379v1",
    "published_date": "2025-05-19 17:24:16 UTC",
    "updated_date": "2025-05-19 17:24:16 UTC"
  },
  {
    "arxiv_id": "2505.13372v1",
    "title": "Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning",
    "authors": [
      "Irene Brugnara",
      "Alessandro Valentini",
      "Andrea Micheli"
    ],
    "abstract": "Recent work investigated the use of Reinforcement Learning (RL) for the\nsynthesis of heuristic guidance to improve the performance of temporal planners\nwhen a domain is fixed and a set of training problems (not plans) is given. The\nidea is to extract a heuristic from the value function of a particular\n(possibly infinite-state) MDP constructed over the training problems.\n  In this paper, we propose an evolution of this learning and planning\nframework that focuses on exploiting the information provided by symbolic\nheuristics during both the RL and planning phases. First, we formalize\ndifferent reward schemata for the synthesis and use symbolic heuristics to\nmitigate the problems caused by the truncation of episodes needed to deal with\nthe potentially infinite MDP. Second, we propose learning a residual of an\nexisting symbolic heuristic, which is a \"correction\" of the heuristic value,\ninstead of eagerly learning the whole heuristic from scratch. Finally, we use\nthe learned heuristic in combination with a symbolic heuristic using a\nmultiple-queue planning approach to balance systematic search with imperfect\nlearned information. We experimentally compare all the approaches, highlighting\ntheir strengths and weaknesses and significantly advancing the state of the art\nfor this planning and learning schema.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13372v1",
    "published_date": "2025-05-19 17:19:13 UTC",
    "updated_date": "2025-05-19 17:19:13 UTC"
  },
  {
    "arxiv_id": "2505.13358v2",
    "title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling",
    "authors": [
      "Nimrod Berman",
      "Ilan Naiman",
      "Moshe Eliasof",
      "Hedi Zisling",
      "Omri Azencot"
    ],
    "abstract": "Diffusion-based generative models have demonstrated exceptional performance,\nyet their iterative sampling procedures remain computationally expensive. A\nprominent strategy to mitigate this cost is distillation, with offline\ndistillation offering particular advantages in terms of efficiency, modularity,\nand flexibility. In this work, we identify two key observations that motivate a\nprincipled distillation framework: (1) while diffusion models have been viewed\nthrough the lens of dynamical systems theory, powerful and underexplored tools\ncan be further leveraged; and (2) diffusion models inherently impose\nstructured, semantically coherent trajectories in latent space. Building on\nthese observations, we introduce the Koopman Distillation Model KDM, a novel\noffline distillation approach grounded in Koopman theory-a classical framework\nfor representing nonlinear dynamics linearly in a transformed space. KDM\nencodes noisy inputs into an embedded space where a learned linear operator\npropagates them forward, followed by a decoder that reconstructs clean samples.\nThis enables single-step generation while preserving semantic fidelity. We\nprovide theoretical justification for our approach: (1) under mild assumptions,\nthe learned diffusion dynamics admit a finite-dimensional Koopman\nrepresentation; and (2) proximity in the Koopman latent space correlates with\nsemantic similarity in the generated outputs, allowing for effective trajectory\nalignment. Empirically, KDM achieves state-of-the-art performance across\nstandard offline distillation benchmarks, improving FID scores by up to 40% in\na single generation step. All implementation details and code for the\nexperimental setups are provided in our GitHub -\nhttps://github.com/azencot-group/KDM, or in our project page -\nhttps://sites.google.com/view/koopman-distillation-model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13358v2",
    "published_date": "2025-05-19 16:59:47 UTC",
    "updated_date": "2025-05-20 14:05:02 UTC"
  },
  {
    "arxiv_id": "2505.13355v1",
    "title": "Multi-Armed Bandits Meet Large Language Models",
    "authors": [
      "Djallel Bouneffouf",
      "Raphael Feraud"
    ],
    "abstract": "Bandit algorithms and Large Language Models (LLMs) have emerged as powerful\ntools in artificial intelligence, each addressing distinct yet complementary\nchallenges in decision-making and natural language processing. This survey\nexplores the synergistic potential between these two fields, highlighting how\nbandit algorithms can enhance the performance of LLMs and how LLMs, in turn,\ncan provide novel insights for improving bandit-based decision-making. We first\nexamine the role of bandit algorithms in optimizing LLM fine-tuning, prompt\nengineering, and adaptive response generation, focusing on their ability to\nbalance exploration and exploitation in large-scale learning tasks.\nSubsequently, we explore how LLMs can augment bandit algorithms through\nadvanced contextual understanding, dynamic adaptation, and improved policy\nselection using natural language reasoning. By providing a comprehensive review\nof existing research and identifying key challenges and opportunities, this\nsurvey aims to bridge the gap between bandit algorithms and LLMs, paving the\nway for innovative applications and interdisciplinary research in AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13355v1",
    "published_date": "2025-05-19 16:57:57 UTC",
    "updated_date": "2025-05-19 16:57:57 UTC"
  },
  {
    "arxiv_id": "2505.13346v2",
    "title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization",
    "authors": [
      "Austin Xu",
      "Yilun Zhou",
      "Xuan-Phi Nguyen",
      "Caiming Xiong",
      "Shafiq Joty"
    ],
    "abstract": "To keep pace with the increasing pace of large language models (LLM)\ndevelopment, model output evaluation has transitioned away from time-consuming\nhuman evaluation to automatic evaluation, where LLMs themselves are tasked with\nassessing and critiquing other model outputs. LLM-as-judge models are a class\nof generative evaluators that excel in evaluating relatively simple domains,\nlike chat quality, but struggle in reasoning intensive domains where model\nresponses contain more substantive and challenging content. To remedy existing\njudge shortcomings, we explore training judges with reinforcement learning\n(RL). We make three key contributions: (1) We propose the Equivalent Initial\nState Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us\nto train our judge to be robust to positional biases that arise in more complex\nevaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that\nevaluates judges in diverse reasoning settings not covered by prior work. (3)\nWe train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that\noutperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or\nexceeding the performance of larger GRPO-trained judges on both JudgeBench and\nReasoningJudgeBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 4 figures, 6 tables. To be updated with links for\n  code/benchmark",
    "pdf_url": "http://arxiv.org/pdf/2505.13346v2",
    "published_date": "2025-05-19 16:50:35 UTC",
    "updated_date": "2025-05-20 14:57:18 UTC"
  },
  {
    "arxiv_id": "2505.13344v1",
    "title": "RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers",
    "authors": [
      "Ahmet Berke Gokmen",
      "Yigit Ekin",
      "Bahri Batuhan Bilecen",
      "Aysegul Dundar"
    ],
    "abstract": "We propose RoPECraft, a training-free video motion transfer method for\ndiffusion transformers that operates solely by modifying their rotary\npositional embeddings (RoPE). We first extract dense optical flow from a\nreference video, and utilize the resulting motion offsets to warp the\ncomplex-exponential tensors of RoPE, effectively encoding motion into the\ngeneration process. These embeddings are then further optimized during\ndenoising time steps via trajectory alignment between the predicted and target\nvelocities using a flow-matching objective. To keep the output faithful to the\ntext prompt and prevent duplicate generations, we incorporate a regularization\nterm based on the phase components of the reference video's Fourier transform,\nprojecting the phase angles onto a smooth manifold to suppress high-frequency\nartifacts. Experiments on benchmarks reveal that RoPECraft outperforms all\nrecently published methods, both qualitatively and quantitatively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://berkegokmen1.github.io/RoPECraft/",
    "pdf_url": "http://arxiv.org/pdf/2505.13344v1",
    "published_date": "2025-05-19 16:50:26 UTC",
    "updated_date": "2025-05-19 16:50:26 UTC"
  },
  {
    "arxiv_id": "2505.13339v1",
    "title": "OPA-Pack: Object-Property-Aware Robotic Bin Packing",
    "authors": [
      "Jia-Hui Pan",
      "Yeok Tatt Cheah",
      "Zhengzhe Liu",
      "Ka-Hei Hui",
      "Xiaojie Gao",
      "Pheng-Ann Heng",
      "Yun-Hui Liu",
      "Chi-Wing Fu"
    ],
    "abstract": "Robotic bin packing aids in a wide range of real-world scenarios such as\ne-commerce and warehouses. Yet, existing works focus mainly on considering the\nshape of objects to optimize packing compactness and neglect object properties\nsuch as fragility, edibility, and chemistry that humans typically consider when\npacking objects. This paper presents OPA-Pack (Object-Property-Aware Packing\nframework), the first framework that equips the robot with object property\nconsiderations in planning the object packing. Technical-wise, we develop a\nnovel object property recognition scheme with retrieval-augmented generation\nand chain-of-thought reasoning, and build a dataset with object property\nannotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to\njointly separate incompatible object pairs and reduce pressure on fragile\nobjects, while compacting the packing. Further, OPA-Net consists of a property\nembedding layer to encode the property of candidate objects to be packed,\ntogether with a fragility heightmap and an avoidance heightmap to keep track of\nthe packed objects. Then, we design a reward function and adopt a deep\nQ-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack\ngreatly improves the accuracy of separating incompatible object pairs (from 52%\nto 95%) and largely reduces pressure on fragile objects (by 29.4%), while\nmaintaining good packing compactness. Besides, we demonstrate the effectiveness\nof OPA-Pack on a real packing platform, showcasing its practicality in\nreal-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IEEE Transactions on Robotics (TRO) on Feb. 10, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13339v1",
    "published_date": "2025-05-19 16:48:14 UTC",
    "updated_date": "2025-05-19 16:48:14 UTC"
  },
  {
    "arxiv_id": "2505.13338v1",
    "title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation",
    "authors": [
      "Qiongqiong Wang",
      "Hardik B. Sailor",
      "Tianchi Liu",
      "Ai Ti Aw"
    ],
    "abstract": "Current speech-LLMs exhibit limited capability in contextual reasoning\nalongside paralinguistic understanding, primarily due to the lack of\nQuestion-Answer (QA) datasets that cover both aspects. We propose a novel\nframework for dataset generation from in-the-wild speech data, that integrates\ncontextual reasoning with paralinguistic information. It consists of a pseudo\nparalinguistic label-based data condensation of in-the-wild speech and\nLLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is\nvalidated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct\nmodel on a dataset created by our framework and human-generated CPQA dataset.\nThe results also reveal the speech-LLM's limitations in handling empathetic\nreasoning tasks, highlighting the need for such datasets and more robust\nmodels. The proposed framework is first of its kind and has potential in\ntraining more robust speech-LLMs with paralinguistic reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Interspeech 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13338v1",
    "published_date": "2025-05-19 16:47:46 UTC",
    "updated_date": "2025-05-19 16:47:46 UTC"
  },
  {
    "arxiv_id": "2505.13329v1",
    "title": "Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications",
    "authors": [
      "Frédéric Berdoz",
      "Dustin Brunner",
      "Yann Vonlanthen",
      "Roger Wattenhofer"
    ],
    "abstract": "Voting advice applications (VAAs) help millions of voters understand which\npolitical parties or candidates best align with their views. This paper\nexplores the potential risks these applications pose to the democratic process\nwhen targeted by adversarial entities. In particular, we expose 11 manipulation\nstrategies and measure their impact using data from Switzerland's primary VAA,\nSmartvote, collected during the last two national elections. We find that\naltering application parameters, such as the matching method, can shift a\nparty's recommendation frequency by up to 105%. Cherry-picking questionnaire\nitems can increase party recommendation frequency by over 261%, while subtle\nchanges to parties' or candidates' responses can lead to a 248% increase. To\naddress these vulnerabilities, we propose adversarial robustness properties\nVAAs should satisfy, introduce empirical metrics for assessing the resilience\nof various matching methods, and suggest possible avenues for research toward\nmitigating the effect of manipulation. Our framework is key to ensuring secure\nand reliable AI-based VAAs poised to emerge in the near future.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "This is the extended version of the paper, accepted at IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13329v1",
    "published_date": "2025-05-19 16:38:06 UTC",
    "updated_date": "2025-05-19 16:38:06 UTC"
  },
  {
    "arxiv_id": "2505.13324v1",
    "title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI",
    "authors": [
      "Galit Shmueli",
      "David Martens",
      "Jaewon Yoo",
      "Travis Greene"
    ],
    "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields\nof causal inference (CI) and explainable artificial intelligence (XAI). While\nthe core idea behind counterfactuals remains the same in both fields--the\nexamination of what would have happened under different circumstances--there\nare key differences in how they are used and interpreted. We introduce a formal\ndefinition that encompasses the multi-faceted concept of the counterfactual in\nCI and XAI. We then discuss how counterfactuals are used, evaluated, generated,\nand operationalized in CI vs. XAI, highlighting conceptual and practical\ndifferences. By comparing and contrasting the two, we hope to identify\nopportunities for cross-fertilization across CI and XAI.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13324v1",
    "published_date": "2025-05-19 16:34:36 UTC",
    "updated_date": "2025-05-19 16:34:36 UTC"
  },
  {
    "arxiv_id": "2505.13316v1",
    "title": "Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates",
    "authors": [
      "Gabriele Spadaro",
      "Alberto Presta",
      "Jhony H. Giraldo",
      "Marco Grangetto",
      "Wei Hu",
      "Giuseppe Valenzise",
      "Attilio Fiandrotti",
      "Enzo Tartaglione"
    ],
    "abstract": "Efficient compression of low-bit-rate point clouds is critical for\nbandwidth-constrained applications. However, existing techniques mainly focus\non high-fidelity reconstruction, requiring many bits for compression. This\npaper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture\nfor point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder\nproduces the condition vector for the generation, which is then quantized via a\nlearnable vector quantizer. This configuration allows to achieve a low bitrates\nwhile preserving quality. Experiments on ShapeNet and ModelNet40 show improved\nrate-distortion at low rates compared to standardized and state-of-the-art\napproaches. We publicly released the code at\nhttps://github.com/EIDOSLAB/DDPM-PCC.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures, accepted at ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13316v1",
    "published_date": "2025-05-19 16:29:12 UTC",
    "updated_date": "2025-05-19 16:29:12 UTC"
  },
  {
    "arxiv_id": "2505.13315v1",
    "title": "KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation",
    "authors": [
      "Reza T. Batley",
      "Sourav Saha"
    ],
    "abstract": "Contemporary models of high dimensional physical systems are constrained by\nthe curse of dimensionality and a reliance on dense data. We introduce KHRONOS\n(Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an\nAI framework for model based, model free and model inversion tasks. KHRONOS\nconstructs continuously differentiable target fields with a hierarchical\ncomposition of per-dimension kernel expansions, which are tensorized into modes\nand then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation\nbenchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L2 square\nerrors of 5e-4 down to 6e-10. This represents a 100 time gain over Kolmogorov\nArnold Networks (which itself reports a 100 times improvement on MLPs/PINNs\nwith 100 times fewer parameters) when controlling for the number of parameters.\nThis also represents a 1e4 times improvement in L2 square error compared to\nstandard linear FEM at comparable DoFs. Inference complexity is dominated by\ninner products, yielding sub-millisecond full-field predictions that scale to\nan arbitrary resolution. For inverse problems, KHRONOS facilitates rapid,\niterative level set recovery in only a few forward evaluations, with\nsub-microsecond per sample latency. KHRONOS scalability, expressivity, and\ninterpretability open new avenues in constrained edge computing, online\ncontrol, computer vision, and beyond.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13315v1",
    "published_date": "2025-05-19 16:29:07 UTC",
    "updated_date": "2025-05-19 16:29:07 UTC"
  },
  {
    "arxiv_id": "2505.13308v1",
    "title": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space",
    "authors": [
      "Hengli Li",
      "Chenxi Li",
      "Tong Wu",
      "Xuekai Zhu",
      "Yuxuan Wang",
      "Zhaoxin Yu",
      "Eric Hanchen Jiang",
      "Song-Chun Zhu",
      "Zixia Jia",
      "Ying Nian Wu",
      "Zilong Zheng"
    ],
    "abstract": "Reasoning ability, a core component of human intelligence, continues to pose\na significant challenge for Large Language Models (LLMs) in the pursuit of AGI.\nAlthough model performance has improved under the training scaling law,\nsignificant challenges remain, particularly with respect to training\nalgorithms, such as catastrophic forgetting, and the limited availability of\nnovel training data. As an alternative, test-time scaling enhances reasoning\nperformance by increasing test-time computation without parameter updating.\nUnlike prior methods in this paradigm focused on token space, we propose\nleveraging latent space for more effective reasoning and better adherence to\nthe test-time scaling law. We introduce LatentSeek, a novel framework that\nenhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA)\nwithin the model's latent space. Specifically, LatentSeek leverages policy\ngradient to iteratively update latent representations, guided by self-generated\nreward signals. LatentSeek is evaluated on a range of reasoning benchmarks,\nincluding GSM8K, MATH-500, and AIME2024, across multiple LLM architectures.\nResults show that LatentSeek consistently outperforms strong baselines, such as\nChain-of-Thought prompting and fine-tuning-based methods. Furthermore, our\nanalysis demonstrates that LatentSeek is highly efficient, typically converging\nwithin a few iterations for problems of average complexity, while also\nbenefiting from additional iterations, thereby highlighting the potential of\ntest-time scaling in the latent space. These findings position LatentSeek as a\nlightweight, scalable, and effective solution for enhancing the reasoning\ncapabilities of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13308v1",
    "published_date": "2025-05-19 16:26:02 UTC",
    "updated_date": "2025-05-19 16:26:02 UTC"
  },
  {
    "arxiv_id": "2505.13307v1",
    "title": "RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning",
    "authors": [
      "Qiguang Chen",
      "Libo Qin",
      "Jinhao Liu",
      "Yue Liao",
      "Jiaqi Wang",
      "Jingxuan Zhou",
      "Wanxiang Che"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large\nlanguage models (LLMs) on complex tasks, spurring research into its underlying\nmechanisms. However, two primary challenges remain for real-world applications:\n(1) the lack of quantitative metrics and actionable guidelines for evaluating\nand optimizing measurable boundaries of CoT capability, and (2) the absence of\nmethods to assess boundaries of unmeasurable CoT capability, such as multimodal\nperception. To address these gaps, we introduce the Reasoning Boundary\nFramework++ (RBF++). To tackle the first challenge, we define the reasoning\nboundary (RB) as the maximum limit of CoT performance. We also propose a\ncombination law for RBs, enabling quantitative analysis and offering actionable\nguidance across various CoT tasks. For the second challenge, particularly in\nmultimodal scenarios, we introduce a constant assumption, which replaces\nunmeasurable RBs with scenario-specific constants. Additionally, we propose the\nreasoning boundary division mechanism, which divides unmeasurable RBs into two\nsub-boundaries, facilitating the quantification and optimization of both\nunmeasurable domain knowledge and multimodal perception capabilities. Extensive\nexperiments involving 38 models across 13 tasks validate the feasibility of our\nframework in cross-modal settings. Additionally, we evaluate 10 CoT strategies,\noffer insights into optimization and decay from two complementary perspectives,\nand expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope\nthis work advances the understanding of RBs and optimization strategies in\nLLMs. Code and data are available at\nhttps://github.com/LightChen233/reasoning-boundary.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript",
    "pdf_url": "http://arxiv.org/pdf/2505.13307v1",
    "published_date": "2025-05-19 16:25:55 UTC",
    "updated_date": "2025-05-19 16:25:55 UTC"
  },
  {
    "arxiv_id": "2505.13292v1",
    "title": "Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs",
    "authors": [
      "Huaiying Luo",
      "Cheng Ji"
    ],
    "abstract": "In the age of cloud computing, data privacy protection has become a major\nchallenge, especially when sharing sensitive data across cloud environments.\nHowever, how to optimize collaboration across cloud environments remains an\nunresolved problem. In this paper, we combine federated learning with\nlarge-scale language models to optimize the collaborative mechanism of AI\nsystems. Based on the existing federated learning framework, we introduce a\ncross-cloud architecture in which federated learning works by aggregating model\nupdates from decentralized nodes without exposing the original data. At the\nsame time, combined with large-scale language models, its powerful context and\nsemantic understanding capabilities are used to improve model training\nefficiency and decision-making ability. We've further innovated by introducing\na secure communication layer to ensure the privacy and integrity of model\nupdates and training data. The model enables continuous model adaptation and\nfine-tuning across different cloud environments while protecting sensitive\ndata. Experimental results show that the proposed method is significantly\nbetter than the traditional federated learning model in terms of accuracy,\nconvergence speed and data privacy protection.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by 2025 IEEE 7th International Conference on Communications,\n  Information System and Computer Engineering",
    "pdf_url": "http://arxiv.org/pdf/2505.13292v1",
    "published_date": "2025-05-19 16:14:27 UTC",
    "updated_date": "2025-05-19 16:14:27 UTC"
  },
  {
    "arxiv_id": "2505.13291v1",
    "title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents",
    "authors": [
      "Yifu Cai",
      "Xinyu Li",
      "Mononito Goswami",
      "Michał Wiliński",
      "Gus Welter",
      "Artur Dubrawski"
    ],
    "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating\nArtificial Intelligence (AI) agents on time series machine learning engineering\nchallenges. Existing benchmarks lack scalability, focus narrowly on model\nbuilding in well-defined settings, and evaluate only a limited set of research\nartifacts (e.g., CSV submission files). To make AI agent benchmarking more\nrelevant to the practice of machine learning engineering, our framework scales\nalong two critical dimensions. First, recognizing that effective ML engineering\nrequires a range of diverse skills, TimeSeriesGym incorporates challenges from\ndiverse sources spanning multiple domains and tasks. We design challenges to\nevaluate both isolated capabilities (including data handling, understanding\nresearch repositories, and code translation) and their combinations, and rather\nthan addressing each challenge independently, we develop tools that support\ndesigning multiple challenges at scale. Second, we implement evaluation\nmechanisms for multiple research artifacts, including submission files, code,\nand models, using both precise numeric measures and more flexible LLM-based\nevaluation approaches. This dual strategy balances objective assessment with\ncontextual judgment. Although our initial focus is on time series applications,\nour framework can be readily extended to other data modalities, broadly\nenhancing the comprehensiveness and practical utility of agentic AI evaluation.\nWe open-source our benchmarking framework to facilitate future research on the\nML engineering capabilities of AI agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Open source code available at\n  https://github.com/moment-timeseries-foundation-model/TimeSeriesGym. YC, XL,\n  MG and MW contributed equally, and should be considered joint first authors",
    "pdf_url": "http://arxiv.org/pdf/2505.13291v1",
    "published_date": "2025-05-19 16:11:23 UTC",
    "updated_date": "2025-05-19 16:11:23 UTC"
  },
  {
    "arxiv_id": "2505.14723v1",
    "title": "QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding",
    "authors": [
      "Subrata Biswas",
      "Mohammad Nur Hossain Khan",
      "Bashima Islam"
    ],
    "abstract": "Spoken Language Understanding (SLU) systems must balance performance and\nefficiency, particularly in resource-constrained environments. Existing methods\napply distillation and quantization separately, leading to suboptimal\ncompression as distillation ignores quantization constraints. We propose QUADS,\na unified framework that optimizes both through multi-stage training with a\npre-tuned model, enhancing adaptability to low-bit regimes while maintaining\naccuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with\nonly minor degradations of up to 5.56\\% compared to state-of-the-art models.\nAdditionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and\nmodel size by 83--700$\\times$, demonstrating strong robustness under extreme\nquantization. These results establish QUADS as a highly efficient solution for\nreal-world, resource-constrained SLU applications.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.14723v1",
    "published_date": "2025-05-19 16:09:51 UTC",
    "updated_date": "2025-05-19 16:09:51 UTC"
  },
  {
    "arxiv_id": "2505.13287v1",
    "title": "Level Generation with Quantum Reservoir Computing",
    "authors": [
      "João S. Ferreira",
      "Pierre Fromholz",
      "Hari Shaji",
      "James R. Wootton"
    ],
    "abstract": "Reservoir computing is a form of machine learning particularly suited for\ntime series analysis, including forecasting predictions. We take an\nimplementation of \\emph{quantum} reservoir computing that was initially\ndesigned to generate variants of musical scores and adapt it to create levels\nof Super Mario Bros. Motivated by our analysis of these levels, we develop a\nnew Roblox \\textit{obby} where the courses can be generated in real time on\nsuperconducting qubit hardware, and investigate some of the constraints placed\nby such real-time generation.",
    "categories": [
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13287v1",
    "published_date": "2025-05-19 16:09:30 UTC",
    "updated_date": "2025-05-19 16:09:30 UTC"
  },
  {
    "arxiv_id": "2505.13280v1",
    "title": "FlowPure: Continuous Normalizing Flows for Adversarial Purification",
    "authors": [
      "Elias Collaert",
      "Abel Rodríguez",
      "Sander Joos",
      "Lieven Desmet",
      "Vera Rimmer"
    ],
    "abstract": "Despite significant advancements in the area, adversarial robustness remains\na critical challenge in systems employing machine learning models. The removal\nof adversarial perturbations at inference time, known as adversarial\npurification, has emerged as a promising defense strategy. To achieve this,\nstate-of-the-art methods leverage diffusion models that inject Gaussian noise\nduring a forward process to dilute adversarial perturbations, followed by a\ndenoising step to restore clean samples before classification. In this work, we\npropose FlowPure, a novel purification method based on Continuous Normalizing\nFlows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings\nfrom adversarial examples to their clean counterparts. Unlike prior\ndiffusion-based approaches that rely on fixed noise processes, FlowPure can\nleverage specific attack knowledge to improve robustness under known threats,\nwhile also supporting a more general stochastic variant trained on Gaussian\nperturbations for settings where such knowledge is unavailable. Experiments on\nCIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art\npurification-based defenses in preprocessor-blind and white-box scenarios, and\ncan do so while fully preserving benign accuracy in the former. Moreover, our\nresults show that not only is FlowPure a highly effective purifier but it also\nholds a strong potential for adversarial detection, identifying\npreprocessor-blind PGD samples with near-perfect accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13280v1",
    "published_date": "2025-05-19 16:04:43 UTC",
    "updated_date": "2025-05-19 16:04:43 UTC"
  },
  {
    "arxiv_id": "2505.13273v1",
    "title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models",
    "authors": [
      "Lucas Berry",
      "Axel Brando",
      "Wei-Di Chang",
      "Juan Camilo Gamboa Higuera",
      "David Meger"
    ],
    "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging\nbecause of their large parameter counts (often exceeding 100 million) and\noperation in complex, high-dimensional spaces with virtually infinite input\npossibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a\nnovel framework for efficiently estimating epistemic uncertainty in diffusion\nmodels. EMoE leverages pre-trained networks without requiring additional\ntraining, enabling direct uncertainty estimation from a prompt. We leverage a\nlatent space within the diffusion process that captures epistemic uncertainty\nbetter than existing methods. Experimental results on the COCO dataset\ndemonstrate EMoE's effectiveness, showing a strong correlation between\nuncertainty and image quality. Additionally, EMoE identifies under-sampled\nlanguages and regions with higher uncertainty, revealing hidden biases in the\ntraining set. This capability demonstrates the relevance of EMoE as a tool for\naddressing fairness and accountability in AI-generated content.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13273v1",
    "published_date": "2025-05-19 15:53:32 UTC",
    "updated_date": "2025-05-19 15:53:32 UTC"
  },
  {
    "arxiv_id": "2505.13268v1",
    "title": "Representation of perceived prosodic similarity of conversational feedback",
    "authors": [
      "Livia Qian",
      "Carol Figueroa",
      "Gabriel Skantze"
    ],
    "abstract": "Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of\nspoken dialogue and is crucial to ensuring common ground in conversational\nsystems. The exact meaning of such feedback is conveyed through both lexical\nand prosodic form. In this work, we investigate the perceived prosodic\nsimilarity of vocal feedback with the same lexical form, and to what extent\nexisting speech representations reflect such similarities. A triadic comparison\ntask with recruited participants is used to measure perceived similarity of\nfeedback responses taken from two different datasets. We find that spectral and\nself-supervised speech representations encode prosody better than extracted\npitch features, especially in the case of feedback from the same speaker. We\nalso find that it is possible to further condense and align the representations\nto human perception through contrastive learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Interspeech 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13268v1",
    "published_date": "2025-05-19 15:47:51 UTC",
    "updated_date": "2025-05-19 15:47:51 UTC"
  },
  {
    "arxiv_id": "2505.13264v1",
    "title": "Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty",
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Louis Daumas",
      "Leonardo Chiani",
      "Massimo Tavoni"
    ],
    "abstract": "Climate-economic modeling under uncertainty presents significant\ncomputational challenges that may limit policymakers' ability to address\nclimate change effectively. This paper explores neural network-based approaches\nfor solving high-dimensional optimal control problems arising from models that\nincorporate ambiguity aversion in climate mitigation decisions. We develop a\ncontinuous-time endogenous-growth economic model that accounts for multiple\nmitigation pathways, including emission-free capital and carbon intensity\nreductions. Given the inherent complexity and high dimensionality of these\nmodels, traditional numerical methods become computationally intractable. We\nbenchmark several neural network architectures against finite-difference\ngenerated solutions, evaluating their ability to capture the dynamic\ninteractions between uncertainty, technology transitions, and optimal climate\npolicy. Our findings demonstrate that appropriate neural architecture selection\nsignificantly impacts both solution accuracy and computational efficiency when\nmodeling climate-economic systems under uncertainty. These methodological\nadvances enable more sophisticated modeling of climate policy decisions,\nallowing for better representation of technology transitions and\nuncertainty-critical elements for developing effective mitigation strategies in\nthe face of climate change.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.PF",
      "math.AP",
      "68T07 (Primary) 35Q91, 91B76 (Secondary)",
      "I.2.1; I.5.1; J.4"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2505.13264v1",
    "published_date": "2025-05-19 15:46:12 UTC",
    "updated_date": "2025-05-19 15:46:12 UTC"
  },
  {
    "arxiv_id": "2505.13257v1",
    "title": "WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?",
    "authors": [
      "Zilu Tang",
      "Afra Feyza Akyürek",
      "Ekin Akyürek",
      "Derry Wijaya"
    ],
    "abstract": "Preference alignment has become a standard pipeline in finetuning models to\nfollow \\emph{generic} human preferences. Majority of work seeks to optimize\nmodel to produce responses that would be preferable \\emph{on average},\nsimplifying the diverse and often \\emph{contradicting} space of human\npreferences. While research has increasingly focused on personalized alignment:\nadapting models to individual user preferences, there is a lack of personalized\npreference dataset which focus on nuanced individual-level preferences. To\naddress this, we introduce WikiPersona: the first fine-grained personalization\nusing well-documented, famous individuals. Our dataset challenges models to\nalign with these personas through an interpretable process: generating\nverifiable textual descriptions of a persona's background and preferences in\naddition to alignment. We systematically evaluate different personalization\napproaches and find that as few-shot prompting with preferences and fine-tuning\nfail to simultaneously ensure effectiveness and efficiency, using\n\\textit{inferred personal preferences} as prefixes enables effective\npersonalization, especially in topics where preferences clash while leading to\nmore equitable generalization across unseen personas.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.13257v1",
    "published_date": "2025-05-19 15:39:48 UTC",
    "updated_date": "2025-05-19 15:39:48 UTC"
  },
  {
    "arxiv_id": "2505.13253v1",
    "title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic",
    "authors": [
      "Lennart Röstel",
      "Dominik Winkelbauer",
      "Johannes Pitz",
      "Leon Sievers",
      "Berthold Bäuml"
    ],
    "abstract": "In-hand manipulation and grasping are fundamental yet often separately\naddressed tasks in robotics. For deriving in-hand manipulation policies,\nreinforcement learning has recently shown great success. However, the derived\ncontrollers are not yet useful in real-world scenarios because they often\nrequire a human operator to place the objects in suitable initial (grasping)\nstates. Finding stable grasps that also promote the desired in-hand\nmanipulation goal is an open problem. In this work, we propose a method for\nbridging this gap by leveraging the critic network of a reinforcement learning\nagent trained for in-hand manipulation to score and select initial grasps. Our\nexperiments show that this method significantly increases the success rate of\nin-hand manipulation without requiring additional training. We also present an\nimplementation of a full grasp manipulation pipeline on a real-world system,\nenabling autonomous grasping and reorientation even of unwieldy objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13253v1",
    "published_date": "2025-05-19 15:36:34 UTC",
    "updated_date": "2025-05-19 15:36:34 UTC"
  },
  {
    "arxiv_id": "2505.13580v1",
    "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making",
    "authors": [
      "Hanzhao Wang",
      "Guanting Chen",
      "Kalyan Talluri",
      "Xiaocheng Li"
    ],
    "abstract": "We build a Generative Pre-trained Transformer (GPT) model from scratch to\nsolve sequential decision making tasks arising in contexts of operations\nresearch and management science which we call OMGPT. We first propose a general\nsequence modeling framework to cover several operational decision making tasks\nas special cases, such as dynamic pricing, inventory management, resource\nallocation, and queueing control. Under the framework, all these tasks can be\nviewed as a sequential prediction problem where the goal is to predict the\noptimal future action given all the historical information. Then we train a\ntransformer-based neural network model (OMGPT) as a natural and powerful\narchitecture for sequential modeling. This marks a paradigm shift compared to\nthe existing methods for these OR/OM tasks in that (i) the OMGPT model can take\nadvantage of the huge amount of pre-trained data; (ii) when tackling these\nproblems, OMGPT does not assume any analytical model structure and enables a\ndirect and rich mapping from the history to the future actions. Either of these\ntwo aspects, to the best of our knowledge, is not achieved by any existing\nmethod. We establish a Bayesian perspective to theoretically understand the\nworking mechanism of the OMGPT on these tasks, which relates its performance\nwith the pre-training task diversity and the divergence between the testing\ntask and pre-training tasks. Numerically, we observe a surprising performance\nof the proposed model across all the above tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2405.14219",
    "pdf_url": "http://arxiv.org/pdf/2505.13580v1",
    "published_date": "2025-05-19 15:33:03 UTC",
    "updated_date": "2025-05-19 15:33:03 UTC"
  },
  {
    "arxiv_id": "2505.13579v1",
    "title": "Learning Wavelet-Sparse FDK for 3D Cone-Beam CT Reconstruction",
    "authors": [
      "Yipeng Sun",
      "Linda-Sophie Schneider",
      "Chengze Ye",
      "Mingxuan Gu",
      "Siyuan Mei",
      "Siming Bayer",
      "Andreas Maier"
    ],
    "abstract": "Cone-Beam Computed Tomography (CBCT) is essential in medical imaging, and the\nFeldkamp-Davis-Kress (FDK) algorithm is a popular choice for reconstruction due\nto its efficiency. However, FDK is susceptible to noise and artifacts. While\nrecent deep learning methods offer improved image quality, they often increase\ncomputational complexity and lack the interpretability of traditional methods.\nIn this paper, we introduce an enhanced FDK-based neural network that maintains\nthe classical algorithm's interpretability by selectively integrating trainable\nelements into the cosine weighting and filtering stages. Recognizing the\nchallenge of a large parameter space inherent in 3D CBCT data, we leverage\nwavelet transformations to create sparse representations of the cosine weights\nand filters. This strategic sparsification reduces the parameter count by\n$93.75\\%$ without compromising performance, accelerates convergence, and\nimportantly, maintains the inference computational cost equivalent to the\nclassical FDK algorithm. Our method not only ensures volumetric consistency and\nboosts robustness to noise, but is also designed for straightforward\nintegration into existing CT reconstruction pipelines. This presents a\npragmatic enhancement that can benefit clinical applications, particularly in\nenvironments with computational limitations.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by Fully3D 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13579v1",
    "published_date": "2025-05-19 15:31:40 UTC",
    "updated_date": "2025-05-19 15:31:40 UTC"
  },
  {
    "arxiv_id": "2505.13246v1",
    "title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems",
    "authors": [
      "Roberto Pugliese",
      "George Kourousias",
      "Francesco Venier",
      "Grazia Garlatti Costa"
    ],
    "abstract": "The exponential growth of scientific literature presents significant\nchallenges for researchers navigating the complex knowledge landscape. We\npropose \"Agentic Publications\", a novel LLM-driven framework complementing\ntraditional publishing by transforming papers into interactive knowledge\nsystems. Our architecture integrates structured data with unstructured content\nthrough retrieval-augmented generation and multi-agent verification. The\nframework offers interfaces for both humans and machines, combining narrative\nexplanations with machine-readable outputs while addressing ethical\nconsiderations through automated validation and transparent governance. Key\nfeatures include continuous knowledge updates, automatic integration of new\nfindings, and customizable detail levels. Our proof-of-concept demonstrates\nmultilingual interaction, API accessibility, and structured knowledge\nrepresentation through vector databases, knowledge graphs, and verification\nagents. This approach enhances scientific communication across disciplines,\nimproving efficiency and collaboration while preserving traditional publishing\npathways, particularly valuable for interdisciplinary fields where knowledge\nintegration remains challenging.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13246v1",
    "published_date": "2025-05-19 15:28:10 UTC",
    "updated_date": "2025-05-19 15:28:10 UTC"
  },
  {
    "arxiv_id": "2505.13232v2",
    "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
    "authors": [
      "Younghyun Kim",
      "Jongheon Jeong",
      "Sangkyung Kwak",
      "Kyungmin Lee",
      "Juho Lee",
      "Jinwoo Shin"
    ],
    "abstract": "Learning robust representations from data often requires scale, which has led\nto the success of recent zero-shot models such as CLIP. However, the obtained\nrobustness can easily be deteriorated when these models are fine-tuned on other\ndownstream tasks (e.g., of smaller scales). Previous works often interpret this\nphenomenon in the context of domain shift, developing fine-tuning methods that\naim to preserve the original domain as much as possible. However, in a\ndifferent context, fine-tuned models with limited data are also prone to\nlearning features that are spurious to humans, such as background or texture.\nIn this paper, we propose StarFT (Spurious Textual Alignment Regularization), a\nnovel framework for fine-tuning zero-shot models to enhance robustness by\npreventing them from learning spuriosity. We introduce a regularization that\naligns the output distribution for spuriosity-injected labels with the original\nzero-shot model, ensuring that the model is not induced to extract irrelevant\nfeatures further from these descriptions. We leverage recent language models to\nget such spuriosity-injected labels by generating alternative textual\ndescriptions that highlight potentially confounding features. Extensive\nexperiments validate the robust generalization of StarFT and its emerging\nproperties: zero-shot group robustness and improved zero-shot classification.\nNotably, StarFT boosts both worst-group and average accuracy by 14.30% and\n3.02%, respectively, in the Waterbirds group shift scenario, where other robust\nfine-tuning baselines show even degraded performance.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2025; Code is available at https://github.com/alinlab/StarFT",
    "pdf_url": "http://arxiv.org/pdf/2505.13232v2",
    "published_date": "2025-05-19 15:15:35 UTC",
    "updated_date": "2025-05-20 12:27:33 UTC"
  },
  {
    "arxiv_id": "2505.13227v1",
    "title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis",
    "authors": [
      "Tianbao Xie",
      "Jiaqi Deng",
      "Xiaochuan Li",
      "Junlin Yang",
      "Haoyuan Wu",
      "Jixuan Chen",
      "Wenjing Hu",
      "Xinyuan Wang",
      "Yuhui Xu",
      "Zekun Wang",
      "Yiheng Xu",
      "Junli Wang",
      "Doyen Sahoo",
      "Tao Yu",
      "Caiming Xiong"
    ],
    "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language\ninstructions to specific actions on graphical user interfaces, remains a\ncritical bottleneck in computer use agent development. Current benchmarks\noversimplify grounding tasks as short referring expressions, failing to capture\nthe complexity of real-world interactions that require software commonsense,\nlayout understanding, and fine-grained manipulation capabilities. To address\nthese limitations, we introduce OSWorld-G, a comprehensive benchmark comprising\n564 finely annotated samples across diverse task types including text matching,\nelement recognition, layout understanding, and precise manipulation.\nAdditionally, we synthesize and release the largest computer use grounding\ndataset Jedi, which contains 4 million examples through multi-perspective\ndecoupling of tasks. Our multi-scale models trained on Jedi demonstrate its\neffectiveness by outperforming existing approaches on ScreenSpot-v2,\nScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved\ngrounding with Jedi directly enhances agentic capabilities of general\nfoundation models on complex computer tasks, improving from 5% to 27% on\nOSWorld. Through detailed ablation studies, we identify key factors\ncontributing to grounding performance and verify that combining specialized\ndata for different interface elements enables compositional generalization to\nnovel interfaces. All benchmark, data, checkpoints, and code are open-sourced\nand available at https://osworld-grounding.github.io.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "49 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13227v1",
    "published_date": "2025-05-19 15:09:23 UTC",
    "updated_date": "2025-05-19 15:09:23 UTC"
  },
  {
    "arxiv_id": "2505.13211v1",
    "title": "MAGI-1: Autoregressive Video Generation at Scale",
    "authors": [
      "Sand. ai",
      "Hansi Teng",
      "Hongyu Jia",
      "Lei Sun",
      "Lingzhi Li",
      "Maolin Li",
      "Mingqiu Tang",
      "Shuai Han",
      "Tianning Zhang",
      "W. Q. Zhang",
      "Weifeng Luo",
      "Xiaoyang Kang",
      "Yuchen Sun",
      "Yue Cao",
      "Yunpeng Huang",
      "Yutong Lin",
      "Yuxin Fang",
      "Zewei Tao",
      "Zheng Zhang",
      "Zhongshu Wang",
      "Zixun Liu",
      "Dai Shi",
      "Guoli Su",
      "Hanwen Sun",
      "Hong Pan",
      "Jie Wang",
      "Jiexin Sheng",
      "Min Cui",
      "Min Hu",
      "Ming Yan",
      "Shucheng Yin",
      "Siran Zhang",
      "Tingting Liu",
      "Xianping Yin",
      "Xiaoyu Yang",
      "Xin Song",
      "Xuan Hu",
      "Yankai Zhang",
      "Yuqiao Li"
    ],
    "abstract": "We present MAGI-1, a world model that generates videos by autoregressively\npredicting a sequence of video chunks, defined as fixed-length segments of\nconsecutive frames. Trained to denoise per-chunk noise that increases\nmonotonically over time, MAGI-1 enables causal temporal modeling and naturally\nsupports streaming generation. It achieves strong performance on image-to-video\n(I2V) tasks conditioned on text instructions, providing high temporal\nconsistency and scalability, which are made possible by several algorithmic\ninnovations and a dedicated infrastructure stack. MAGI-1 facilitates\ncontrollable generation via chunk-wise prompting and supports real-time,\nmemory-efficient deployment by maintaining constant peak inference cost,\nregardless of video length. The largest variant of MAGI-1 comprises 24 billion\nparameters and supports context lengths of up to 4 million tokens,\ndemonstrating the scalability and robustness of our approach. The code and\nmodels are available at https://github.com/SandAI-org/MAGI-1 and\nhttps://github.com/SandAI-org/MagiAttention. The product can be accessed at\nhttps://sand.ai.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13211v1",
    "published_date": "2025-05-19 14:58:50 UTC",
    "updated_date": "2025-05-19 14:58:50 UTC"
  },
  {
    "arxiv_id": "2505.13210v1",
    "title": "Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry",
    "authors": [
      "Xiaocong Du",
      "Haoyu Pei",
      "Haipeng Zhang"
    ],
    "abstract": "Classical Chinese poetry is a vital and enduring part of Chinese literature,\nconveying profound emotional resonance. Existing studies analyze sentiment\nbased on textual meanings, overlooking the unique rhythmic and visual features\ninherent in poetry,especially since it is often recited and accompanied by\nChinese paintings. In this work, we propose a dialect-enhanced multimodal\nframework for classical Chinese poetry sentiment analysis. We extract\nsentence-level audio features from the poetry and incorporate audio from\nmultiple dialects,which may retain regional ancient Chinese phonetic features,\nenriching the phonetic representation. Additionally, we generate sentence-level\nvisual features, and the multimodal features are fused with textual features\nenhanced by LLM translation through multimodal contrastive representation\nlearning. Our framework outperforms state-of-the-art methods on two public\ndatasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro\nF1. We open-source the code to facilitate research in this area and provide\ninsights for general multimodal Chinese representation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13210v1",
    "published_date": "2025-05-19 14:58:44 UTC",
    "updated_date": "2025-05-19 14:58:44 UTC"
  },
  {
    "arxiv_id": "2505.13577v1",
    "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation",
    "authors": [
      "Yubin Kim",
      "Taehan Kim",
      "Wonjune Kang",
      "Eugene Park",
      "Joonsik Yoon",
      "Dongjae Lee",
      "Xin Liu",
      "Daniel McDuff",
      "Hyeonhoon Lee",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Vocal health plays a crucial role in peoples' lives, significantly impacting\ntheir communicative abilities and interactions. However, despite the global\nprevalence of voice disorders, many lack access to convenient diagnosis and\ntreatment. This paper introduces VocalAgent, an audio large language model\n(LLM) to address these challenges through vocal health diagnosis. We leverage\nQwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital\npatients, and present a multifaceted evaluation framework encompassing a safety\nassessment to mitigate diagnostic biases, cross-lingual performance analysis,\nand modality ablation studies. VocalAgent demonstrates superior accuracy on\nvoice disorder classification compared to state-of-the-art baselines. Its\nLLM-based method offers a scalable solution for broader adoption of health\ndiagnostics, while underscoring the importance of ethical and technical\nvalidation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13577v1",
    "published_date": "2025-05-19 14:58:42 UTC",
    "updated_date": "2025-05-19 14:58:42 UTC"
  },
  {
    "arxiv_id": "2505.13208v1",
    "title": "Efficient Generation of Parameterised Quantum Circuits from Large Texts",
    "authors": [
      "Colin Krawchuk",
      "Nikhil Khatri",
      "Neil John Ortega",
      "Dimitri Kartsaklis"
    ],
    "abstract": "Quantum approaches to natural language processing (NLP) are redefining how\nlinguistic information is represented and processed. While traditional hybrid\nquantum-classical models rely heavily on classical neural networks, recent\nadvancements propose a novel framework, DisCoCirc, capable of directly encoding\nentire documents as parameterised quantum circuits (PQCs), besides enjoying\nsome additional interpretability and compositionality benefits. Following these\nideas, this paper introduces an efficient methodology for converting\nlarge-scale texts into quantum circuits using tree-like representations of\npregroup diagrams. Exploiting the compositional parallels between language and\nquantum mechanics, grounded in symmetric monoidal categories, our approach\nenables faithful and efficient encoding of syntactic and discourse\nrelationships in long and complex texts (up to 6410 words in our experiments)\nto quantum circuits. The developed system is provided to the community as part\nof the augmented open-source quantum NLP package lambeq Gen II.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13208v1",
    "published_date": "2025-05-19 14:57:53 UTC",
    "updated_date": "2025-05-19 14:57:53 UTC"
  },
  {
    "arxiv_id": "2505.13201v1",
    "title": "MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects",
    "authors": [
      "Yuzhen Chen",
      "Hojun Son",
      "Arpan Kusari"
    ],
    "abstract": "Determining material properties from camera images can expand the ability to\nidentify complex objects in indoor environments, which is valuable for consumer\nrobotics applications. To support this, we introduce MatPredict, a dataset that\ncombines the high-quality synthetic objects from Replica dataset with MatSynth\ndataset's material properties classes - to create objects with diverse material\nproperties. We select 3D meshes of specific foreground objects and render them\nwith different material properties. In total, we generate \\textbf{18} commonly\noccurring objects with \\textbf{14} different materials. We showcase how we\nprovide variability in terms of lighting and camera placement for these\nobjects. Next, we provide a benchmark for inferring material properties from\nvisual images using these perturbed models in the scene, discussing the\nspecific neural network models involved and their performance based on\ndifferent image comparison metrics. By accurately simulating light interactions\nwith different materials, we can enhance realism, which is crucial for training\nmodels effectively through large-scale simulations. This research aims to\nrevolutionize perception in consumer robotics. The dataset is provided\n\\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is\nprovided \\href{https://github.com/arpan-kusari/MatPredict}{here}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13201v1",
    "published_date": "2025-05-19 14:54:04 UTC",
    "updated_date": "2025-05-19 14:54:04 UTC"
  },
  {
    "arxiv_id": "2505.13196v1",
    "title": "A Physics-Inspired Optimizer: Velocity Regularized Adam",
    "authors": [
      "Pranav Vaidhyanathan",
      "Lucas Schorling",
      "Natalia Ares",
      "Michael A. Osborne"
    ],
    "abstract": "We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer\nfor training deep neural networks that draws on ideas from quartic terms for\nkinetic energy with its stabilizing effects on various system dynamics.\nPrevious algorithms, including the ubiquitous Adam, operate at the so called\nadaptive edge of stability regime during training leading to rapid oscillations\nand slowed convergence of loss. However, VRAdam adds a higher order penalty on\nthe learning rate based on the velocity such that the algorithm automatically\nslows down whenever weight updates become large. In practice, we observe that\nthe effective dynamic learning rate shrinks in high-velocity regimes, damping\noscillations and allowing for a more aggressive base step size when necessary\nwithout divergence. By combining this velocity-based regularizer for global\ndamping with per-parameter scaling of Adam to create a hybrid optimizer, we\ndemonstrate that VRAdam consistently exceeds the performance against standard\noptimizers including AdamW. We benchmark various tasks such as image\nclassification, language modeling, image generation and generative modeling\nusing diverse architectures and training methodologies including Convolutional\nNeural Networks (CNNs), Transformers, and GFlowNets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "L. Schorling and P. Vaidhyanathan contributed equally to this work.\n  20 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13196v1",
    "published_date": "2025-05-19 14:51:40 UTC",
    "updated_date": "2025-05-19 14:51:40 UTC"
  },
  {
    "arxiv_id": "2505.13195v1",
    "title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities",
    "authors": [
      "Lili Zhang",
      "Haomiaomiao Wang",
      "Long Cheng",
      "Libao Deng",
      "Tomas Ward"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world decision-making systems, understanding their behavioural\nvulnerabilities remains a critical challenge for AI safety and alignment. While\nexisting evaluation metrics focus primarily on reasoning accuracy or factual\ncorrectness, they often overlook whether LLMs are robust to adversarial\nmanipulation or capable of using adaptive strategy in dynamic environments.\nThis paper introduces an adversarial evaluation framework designed to\nsystematically stress-test the decision-making processes of LLMs under\ninteractive and adversarial conditions. Drawing on methodologies from cognitive\npsychology and game theory, our framework probes how models respond in two\ncanonical tasks: the two-armed bandit task and the Multi-Round Trust Task.\nThese tasks capture key aspects of exploration-exploitation trade-offs, social\ncooperation, and strategic flexibility. We apply this framework to several\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3,\nrevealing model-specific susceptibilities to manipulation and rigidity in\nstrategy adaptation. Our findings highlight distinct behavioral patterns across\nmodels and emphasize the importance of adaptability and fairness recognition\nfor trustworthy AI deployment. Rather than offering a performance benchmark,\nthis work proposes a methodology for diagnosing decision-making weaknesses in\nLLM-based agents, providing actionable insights for alignment and safety\nresearch.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13195v1",
    "published_date": "2025-05-19 14:50:44 UTC",
    "updated_date": "2025-05-19 14:50:44 UTC"
  },
  {
    "arxiv_id": "2505.13192v1",
    "title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics",
    "authors": [
      "Christoph Jürgen Hemmer",
      "Daniel Durstewitz"
    ],
    "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are\ngoverned by dynamical systems (DS). DS reconstruction (DSR) seeks to infer\ngenerative surrogate models of these from observed data, reproducing their\nlong-term behavior. Existing DSR approaches require purpose-training for any\nnew system observed, lacking the zero-shot and in-context inference\ncapabilities known from LLMs. Here we introduce DynaMix, a novel multivariate\nALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR\nmodel able to generalize zero-shot to out-of-domain DS. Just from a provided\ncontext signal, without any re-training, DynaMix faithfully forecasts the\nlong-term evolution of novel DS where existing time series (TS) foundation\nmodels, like Chronos, fail -- at a fraction of the number of parameters and\norders of magnitude faster inference times. DynaMix outperforms TS foundation\nmodels in terms of long-term statistics, and often also short-term forecasts,\neven on real-world time series, like traffic or weather data, typically used\nfor training and evaluating TS models, but not at all part of DynaMix' training\ncorpus. We illustrate some of the failure modes of TS models for DSR problems,\nand conclude that models built on DS principles may bear a huge potential also\nfor advancing the TS prediction field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.CD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13192v1",
    "published_date": "2025-05-19 14:49:10 UTC",
    "updated_date": "2025-05-19 14:49:10 UTC"
  },
  {
    "arxiv_id": "2505.13191v1",
    "title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision",
    "authors": [
      "Pengcheng Pan",
      "Yonekura Shogo",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "Inspired by foveal vision, hard attention models promise interpretability and\nparameter economy. However, existing models like the Recurrent Model of Visual\nAttention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the\nhierarchy of human vision system, that compromise on the visual exploration\ndynamics. As a result, they tend to produce attention that are either overly\nfixational or excessively saccadic, diverging from human eye movement behavior.\nIn this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a\nnovel hard attention framework that explicitly models the neural hierarchy of\nhuman visual processing. By decoupling the function of glimpse location\ngeneration and task execution in two recurrent layers, MRAM emergent a balanced\nbehavior between fixation and saccadic movement. Our results show that MRAM not\nonly achieves more human-like attention dynamics, but also consistently\noutperforms CNN, RAM and DRAM baselines on standard image classification\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13191v1",
    "published_date": "2025-05-19 14:48:36 UTC",
    "updated_date": "2025-05-19 14:48:36 UTC"
  },
  {
    "arxiv_id": "2505.13188v1",
    "title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns",
    "authors": [
      "Juntian Zhu",
      "Miguel de Carvalho",
      "Zhouwang Yang",
      "Fengxiang He"
    ],
    "abstract": "An AI agent might surprisingly find she has reached an unknown state which\nshe has never been aware of -- an unknown unknown. We mathematically ground\nthis scenario in reinforcement learning: an agent, after taking an action\ncalculated from value functions $Q$ and $V$ defined on the {\\it {aware\ndomain}}, reaches a state out of the domain. To enable the agent to handle this\nscenario, we propose an {\\it episodic Markov decision {process} with growing\nawareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion}\n(NIVE) approach to expand value functions to newly aware areas: when an agent\narrives at an unknown unknown, value functions $Q$ and $V$ whereon are\ninitialised by noninformative beliefs -- the averaged values on the aware\ndomain. This design is out of respect for the complete absence of knowledge in\nthe newly discovered state. The upper confidence bound momentum Q-learning is\nthen adapted to the growing awareness for training the EMDP-GA model. We prove\nthat (1) the regret of our approach is asymptotically consistent with the state\nof the art (SOTA) without exposure to unknown unknowns in an extremely\nuncertain environment, and (2) our computational complexity and space\ncomplexity are comparable with the SOTA -- these collectively suggest that\nthough an unknown unknown is surprising, it will be asymptotically properly\ndiscovered with decent speed and an affordable cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13188v1",
    "published_date": "2025-05-19 14:45:58 UTC",
    "updated_date": "2025-05-19 14:45:58 UTC"
  },
  {
    "arxiv_id": "2505.13182v1",
    "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping",
    "authors": [
      "Jianfeng Xu"
    ],
    "abstract": "[Objective] This study focuses on addressing the current lack of a unified\nformal theoretical framework in machine learning, as well as the deficiencies\nin interpretability and ethical safety assurance. [Methods] A formal\ninformation model is first constructed, utilizing sets of well-formed formulas\nto explicitly define the ontological states and carrier mappings of typical\ncomponents in machine learning. Learnable and processable predicates, along\nwith learning and processing functions, are introduced to analyze the logical\ndeduction and constraint rules of the causal chains within models. [Results] A\nmeta-framework for machine learning theory (MLT-MF) is established. Based on\nthis framework, universal definitions for model interpretability and ethical\nsafety are proposed. Furthermore, three key theorems are proved: the\nequivalence of model interpretability and information recoverability, the\nassurance of ethical safety, and the estimation of generalization error.\n[Limitations] The current framework assumes ideal conditions with noiseless\ninformation-enabling mappings and primarily targets model learning and\nprocessing logic in static scenarios. It does not yet address information\nfusion and conflict resolution across ontological spaces in multimodal or\nmulti-agent systems. [Conclusions] This work overcomes the limitations of\nfragmented research and provides a unified theoretical foundation for\nsystematically addressing the critical challenges currently faced in machine\nlearning.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13182v1",
    "published_date": "2025-05-19 14:39:41 UTC",
    "updated_date": "2025-05-19 14:39:41 UTC"
  },
  {
    "arxiv_id": "2505.13180v1",
    "title": "ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models",
    "authors": [
      "Matteo Merler",
      "Nicola Dainese",
      "Minttu Alakuijala",
      "Giovanni Bonetta",
      "Pietro Ferrazzi",
      "Yu Tian",
      "Bernardo Magnini",
      "Pekka Marttinen"
    ],
    "abstract": "Integrating Large Language Models with symbolic planners is a promising\ndirection for obtaining verifiable and grounded plans compared to planning in\nnatural language, with recent works extending this idea to visual domains using\nVision-Language Models (VLMs). However, rigorous comparison between\nVLM-grounded symbolic approaches and methods that plan directly with a VLM has\nbeen hindered by a lack of common environments, evaluation protocols and model\ncoverage. We introduce ViPlan, the first open-source benchmark for Visual\nPlanning with symbolic predicates and VLMs. ViPlan features a series of\nincreasingly challenging tasks in two domains: a visual variant of the classic\nBlocksworld planning problem and a simulated household robotics environment. We\nbenchmark nine open-source VLM families across multiple sizes, along with\nselected closed models, evaluating both VLM-grounded symbolic planning and\nusing the models directly to propose actions. We find symbolic planning to\noutperform direct VLM planning in Blocksworld, where accurate image grounding\nis crucial, whereas the opposite is true in the household robotics tasks, where\ncommonsense knowledge and the ability to recover from errors are beneficial.\nFinally, we show that across most models and methods, there is no significant\nbenefit to using Chain-of-Thought prompting, suggesting that current VLMs still\nstruggle with visual reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures and 1 table in the main text; 43 pages, 9 figures\n  and 16 tables including supplementary material",
    "pdf_url": "http://arxiv.org/pdf/2505.13180v1",
    "published_date": "2025-05-19 14:38:15 UTC",
    "updated_date": "2025-05-19 14:38:15 UTC"
  },
  {
    "arxiv_id": "2505.13176v2",
    "title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models",
    "authors": [
      "Zihao Cheng",
      "Hongru Wang",
      "Zeming Liu",
      "Yuhang Guo",
      "Yuanfang Guo",
      "Yunhong Wang",
      "Haifeng Wang"
    ],
    "abstract": "While integrating external tools into large language models (LLMs) enhances\ntheir ability to access real-time information and domain-specific services,\nexisting approaches focus narrowly on functional tool selection following user\ninstructions, overlooking the context-aware personalization in tool selection.\nThis oversight leads to suboptimal user satisfaction and inefficient tool\nutilization, particularly when overlapping toolsets require nuanced selection\nbased on contextual factors. To bridge this gap, we introduce ToolSpectrum, a\nbenchmark designed to evaluate LLMs' capabilities in personalized tool\nutilization. Specifically, we formalize two key dimensions of personalization,\nuser profile and environmental factors, and analyze their individual and\nsynergistic impacts on tool utilization. Through extensive experiments on\nToolSpectrum, we demonstrate that personalized tool utilization significantly\nimproves user experience across diverse scenarios. However, even\nstate-of-the-art LLMs exhibit the limited ability to reason jointly about user\nprofiles and environmental factors, often prioritizing one dimension at the\nexpense of the other. Our findings underscore the necessity of context-aware\npersonalization in tool-augmented LLMs and reveal critical limitations for\ncurrent models. Our data and code are available at\nhttps://github.com/Chengziha0/ToolSpectrum.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2505.13176v2",
    "published_date": "2025-05-19 14:30:46 UTC",
    "updated_date": "2025-05-22 14:08:07 UTC"
  },
  {
    "arxiv_id": "2505.13175v1",
    "title": "Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment",
    "authors": [
      "Siming Sun",
      "Kai Zhang",
      "Xuejun Jiang",
      "Wenchao Meng",
      "Qinmin Yang"
    ],
    "abstract": "The emerging paradigm of leveraging pretrained large language models (LLMs)\nfor time series forecasting has predominantly employed linguistic-temporal\nmodality alignment strategies through token-level or layer-wise feature\nmapping. However, these approaches fundamentally neglect a critical insight:\nthe core competency of LLMs resides not merely in processing localized token\nfeatures but in their inherent capacity to model holistic sequence structures.\nThis paper posits that effective cross-modal alignment necessitates structural\nconsistency at the sequence level. We propose the Structure-Guided Cross-Modal\nAlignment (SGCMA), a framework that fully exploits and aligns the\nstate-transition graph structures shared by time-series and linguistic data as\nsequential modalities, thereby endowing time series with language-like\nproperties and delivering stronger generalization after modality alignment.\nSGCMA consists of two key components, namely Structure Alignment and Semantic\nAlignment. In Structure Alignment, a state transition matrix is learned from\ntext data through Hidden Markov Models (HMMs), and a shallow transformer-based\nMaximum Entropy Markov Model (MEMM) receives the hot-start transition matrix\nand annotates each temporal patch into state probability, ensuring that the\ntemporal representation sequence inherits language-like sequential dynamics. In\nSemantic Alignment, cross-attention is applied between temporal patches and the\ntop-k tokens within each state, and the ultimate temporal embeddings are\nderived by the expected value of these embeddings using a weighted average\nbased on state probabilities. Experiments on multiple benchmarks demonstrate\nthat SGCMA achieves state-of-the-art performance, offering a novel approach to\ncross-modal alignment in time series forecasting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13175v1",
    "published_date": "2025-05-19 14:30:41 UTC",
    "updated_date": "2025-05-19 14:30:41 UTC"
  },
  {
    "arxiv_id": "2505.13157v1",
    "title": "Role-Playing Evaluation for Large Language Models",
    "authors": [
      "Yassine El Boudouri",
      "Walter Nuninger",
      "Julian Alvarez",
      "Yvan Peter"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate a notable capacity for adopting\npersonas and engaging in role-playing. However, evaluating this ability\npresents significant challenges, as human assessments are resource-intensive\nand automated evaluations can be biased. To address this, we introduce\nRole-Playing Eval (RPEval), a novel benchmark designed to assess LLM\nrole-playing capabilities across four key dimensions: emotional understanding,\ndecision-making, moral alignment, and in-character consistency. This article\ndetails the construction of RPEval and presents baseline evaluations. Our code\nand dataset are available at https://github.com/yelboudouri/RPEval",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13157v1",
    "published_date": "2025-05-19 14:18:16 UTC",
    "updated_date": "2025-05-19 14:18:16 UTC"
  },
  {
    "arxiv_id": "2505.13156v1",
    "title": "Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice",
    "authors": [
      "Zhi Liu",
      "Tao Yang",
      "Jing Wang",
      "Yexin Chen",
      "Zhan Gao",
      "Jiaxi Yang",
      "Kui Chen",
      "Bingji Lu",
      "Xiaochen Li",
      "Changyong Luo",
      "Yan Li",
      "Xiaohong Gu",
      "Peng Cao"
    ],
    "abstract": "Natural medicines, particularly Traditional Chinese Medicine (TCM), are\ngaining global recognition for their therapeutic potential in addressing human\nsymptoms and diseases. TCM, with its systematic theories and extensive\npractical experience, provides abundant resources for healthcare. However, the\neffective application of TCM requires precise syndrome diagnosis, determination\nof treatment principles, and prescription formulation, which demand decades of\nclinical expertise. Despite advancements in TCM-based decision systems, machine\nlearning, and deep learning research, limitations in data and single-objective\nconstraints hinder their practical application. In recent years, large language\nmodels (LLMs) have demonstrated potential in complex tasks, but lack\nspecialization in TCM and face significant challenges, such as too big model\nscale to deploy and issues with hallucination. To address these challenges, we\nintroduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and\nspecifically designed for TCM, pre-trained and fine-tuned on diverse TCM\ncorpora, including classical texts, expert treatises, clinical records, and\nknowledge graphs. Tianyi is designed to assimilate interconnected and\nsystematic TCM knowledge through a progressive learning manner. Additionally,\nwe establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in\nTCM examinations, clinical tasks, domain-specific question-answering, and\nreal-world trials. The extensive evaluations demonstrate the significant\npotential of Tianyi as an AI assistant in TCM clinical practice and research,\nbridging the gap between TCM knowledge and practical application.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 4 figures, and 1 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.13156v1",
    "published_date": "2025-05-19 14:17:37 UTC",
    "updated_date": "2025-05-19 14:17:37 UTC"
  },
  {
    "arxiv_id": "2505.13144v1",
    "title": "Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning",
    "authors": [
      "Dongsu Lee",
      "Minhae Kwon"
    ],
    "abstract": "The goal of offline reinforcement learning (RL) is to extract a\nhigh-performance policy from the fixed datasets, minimizing performance\ndegradation due to out-of-distribution (OOD) samples. Offline model-based RL\n(MBRL) is a promising approach that ameliorates OOD issues by enriching\nstate-action transitions with augmentations synthesized via a learned dynamics\nmodel. Unfortunately, seminal offline MBRL methods often struggle in\nsparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL\nframework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA),\nthat generates augmented transitions in a temporally structured latent space\nrather than in raw state space. To model long-horizon behavior, TempDATA learns\na latent abstraction that captures a temporal distance from both trajectory and\ntransition levels of state space. Our experiments confirm that TempDATA\noutperforms previous offline MBRL methods and achieves matching or surpassing\nthe performance of diffusion-based trajectory augmentation and goal-conditioned\nRL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 ICML",
    "pdf_url": "http://arxiv.org/pdf/2505.13144v1",
    "published_date": "2025-05-19 14:11:14 UTC",
    "updated_date": "2025-05-19 14:11:14 UTC"
  },
  {
    "arxiv_id": "2505.13136v1",
    "title": "ModernGBERT: German-only 1B Encoder Model Trained from Scratch",
    "authors": [
      "Anton Ehrmanntraut",
      "Julia Wunderle",
      "Jan Pfister",
      "Fotis Jannidis",
      "Andreas Hotho"
    ],
    "abstract": "Despite the prominence of decoder-only language models, encoders remain\ncrucial for resource-constrained applications. We introduce ModernGBERT (134M,\n1B), a fully transparent family of German encoder models trained from scratch,\nincorporating architectural innovations from ModernBERT. To evaluate the\npractical trade-offs of training encoders from scratch, we also present\nLL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German\ndecoder-only models via LLM2Vec. We benchmark all models on natural language\nunderstanding, text embedding, and long-context reasoning tasks, enabling a\ncontrolled comparison between dedicated encoders and converted decoders. Our\nresults show that ModernGBERT 1B outperforms prior state-of-the-art German\nencoders as well as encoders adapted via LLM2Vec, with regard to performance\nand parameter-efficiency. All models, training data, checkpoints and code are\npublicly available, advancing the German NLP ecosystem with transparent,\nhigh-performance encoder models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "under review @ARR",
    "pdf_url": "http://arxiv.org/pdf/2505.13136v1",
    "published_date": "2025-05-19 14:07:20 UTC",
    "updated_date": "2025-05-19 14:07:20 UTC"
  },
  {
    "arxiv_id": "2505.14719v1",
    "title": "MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion",
    "authors": [
      "Wei Hua",
      "Chenlin Zhou",
      "Jibin Wu",
      "Yansong Chua",
      "Yangyang Shu"
    ],
    "abstract": "The combination of Spiking Neural Networks(SNNs) with Vision Transformer\narchitectures has attracted significant attention due to the great potential\nfor energy-efficient and high-performance computing paradigms. However, a\nsubstantial performance gap still exists between SNN-based and ANN-based\ntransformer architectures. While existing methods propose spiking\nself-attention mechanisms that are successfully combined with SNNs, the overall\narchitectures proposed by these methods suffer from a bottleneck in effectively\nextracting features from different image scales. In this paper, we address this\nissue and propose MSVIT, a novel spike-driven Transformer architecture, which\nfirstly uses multi-scale spiking attention (MSSA) to enrich the capability of\nspiking attention blocks. We validate our approach across various main data\nsets. The experimental results show that MSVIT outperforms existing SNN-based\nmodels, positioning itself as a state-of-the-art solution among SNN-transformer\narchitectures. The codes are available at\nhttps://github.com/Nanhu-AI-Lab/MSViT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.14719v1",
    "published_date": "2025-05-19 14:01:03 UTC",
    "updated_date": "2025-05-19 14:01:03 UTC"
  },
  {
    "arxiv_id": "2505.13130v1",
    "title": "Adaptive Image Restoration for Video Surveillance: A Real-Time Approach",
    "authors": [
      "Muhammad Awais Amin",
      "Adama Ilboudo",
      "Abdul Samad bin Shahid",
      "Amjad Ali",
      "Waqas Haider Khan Bangyal"
    ],
    "abstract": "One of the major challenges in the field of computer vision especially for\ndetection, segmentation, recognition, monitoring, and automated solutions, is\nthe quality of images. Image degradation, often caused by factors such as rain,\nfog, lighting, etc., has a negative impact on automated\ndecision-making.Furthermore, several image restoration solutions exist,\nincluding restoration models for single degradation and restoration models for\nmultiple degradations. However, these solutions are not suitable for real-time\nprocessing. In this study, the aim was to develop a real-time image restoration\nsolution for video surveillance. To achieve this, using transfer learning with\nResNet_50, we developed a model for automatically identifying the types of\ndegradation present in an image to reference the necessary treatment(s) for\nimage restoration. Our solution has the advantage of being flexible and\nscalable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13130v1",
    "published_date": "2025-05-19 14:00:10 UTC",
    "updated_date": "2025-05-19 14:00:10 UTC"
  },
  {
    "arxiv_id": "2505.13126v2",
    "title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments",
    "authors": [
      "Liancheng Gong",
      "Wang Zhu",
      "Jesse Thomason",
      "Li Zhang"
    ],
    "abstract": "Using LLMs not to predict plans but to formalize an environment into the\nPlanning Domain Definition Language (PDDL) has been shown to improve\nperformance and control. Existing work focuses on fully observable\nenvironments; we tackle the more realistic and challenging partially observable\nenvironments that lack of complete, reliable information. We propose PDDLego+,\na framework to iteratively formalize, plan, grow, and refine PDDL\nrepresentations in a zero-shot manner, without needing access to any existing\ntrajectories. On two textual simulated environments, we show that PDDLego+\nimproves goal reaching success and exhibits robustness against problem\ncomplexity. We also show that the domain knowledge captured after a successful\ntrial can benefit future tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13126v2",
    "published_date": "2025-05-19 13:58:15 UTC",
    "updated_date": "2025-05-20 13:53:50 UTC"
  },
  {
    "arxiv_id": "2505.13124v1",
    "title": "$μ$PC: Scaling Predictive Coding to 100+ Layer Networks",
    "authors": [
      "Francesco Innocenti",
      "El Mehdi Achour",
      "Christopher L. Buckley"
    ],
    "abstract": "The biological implausibility of backpropagation (BP) has motivated many\nalternative, brain-inspired algorithms that attempt to rely only on local\ninformation, such as predictive coding (PC) and equilibrium propagation.\nHowever, these algorithms have notoriously struggled to train very deep\nnetworks, preventing them from competing with BP in large-scale settings.\nIndeed, scaling PC networks (PCNs) has recently been posed as a challenge for\nthe community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can\nbe trained reliably using a Depth-$\\mu$P parameterisation (Yang et al., 2023;\nBordelon et al., 2023) which we call \"$\\mu$PC\". Through an extensive analysis\nof the scaling behaviour of PCNs, we reveal several pathologies that make\nstandard PCNs difficult to train at large depths. We then show that, despite\naddressing only some of these instabilities, $\\mu$PC allows stable training of\nvery deep (up to 128-layer) residual networks on simple classification tasks\nwith competitive performance and little tuning compared to current benchmarks.\nMoreover, $\\mu$PC enables zero-shot transfer of both weight and activity\nlearning rates across widths and depths. Our results have implications for\nother local algorithms and could be extended to convolutional and transformer\narchitectures. Code for $\\mu$PC is made available as part of a JAX library for\nPCNs at https://github.com/thebuckleylab/jpc (Innocenti et al., 2024).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages, 41 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13124v1",
    "published_date": "2025-05-19 13:54:29 UTC",
    "updated_date": "2025-05-19 13:54:29 UTC"
  },
  {
    "arxiv_id": "2505.13573v1",
    "title": "FreeMesh: Boosting Mesh Generation with Coordinates Merging",
    "authors": [
      "Jian Liu",
      "Haohan Weng",
      "Biwen Lei",
      "Xianghui Yang",
      "Zibo Zhao",
      "Zhuo Chen",
      "Song Guo",
      "Tao Han",
      "Chunchao Guo"
    ],
    "abstract": "The next-coordinate prediction paradigm has emerged as the de facto standard\nin current auto-regressive mesh generation methods. Despite their\neffectiveness, there is no efficient measurement for the various tokenizers\nthat serialize meshes into sequences. In this paper, we introduce a new metric\nPer-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers\ntheoretically without any training. Building upon PTME, we propose a\nplug-and-play tokenization technique called coordinate merging. It further\nimproves the compression ratios of existing tokenizers by rearranging and\nmerging the most frequent patterns of coordinates. Through experiments on\nvarious tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we\nfurther validate the performance of our method. We hope that the proposed PTME\nand coordinate merging can enhance the existing mesh tokenizers and guide the\nfurther development of native mesh generation.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "Accepted by ICML 2025, camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2505.13573v1",
    "published_date": "2025-05-19 13:52:57 UTC",
    "updated_date": "2025-05-19 13:52:57 UTC"
  },
  {
    "arxiv_id": "2505.13123v1",
    "title": "Just Dance with $π$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection",
    "authors": [
      "Snehashis Majhi",
      "Giacomo D'Amicantonio",
      "Antitza Dantcheva",
      "Quan Kong",
      "Lorenzo Garattoni",
      "Gianpiero Francesca",
      "Egor Bondarev",
      "Francois Bremond"
    ],
    "abstract": "Weakly-supervised methods for video anomaly detection (VAD) are\nconventionally based merely on RGB spatio-temporal features, which continues to\nlimit their reliability in real-world scenarios. This is due to the fact that\nRGB-features are not sufficiently distinctive in setting apart categories such\nas shoplifting from visually similar events. Therefore, towards robust complex\nreal-world VAD, it is essential to augment RGB spatio-temporal features by\nadditional modalities. Motivated by this, we introduce the Poly-modal Induced\nframework for VAD: \"PI-VAD\", a novel approach that augments RGB representations\nby five additional modalities. Specifically, the modalities include sensitivity\nto fine-grained motion (Pose), three dimensional scene and entity\nrepresentation (Depth), surrounding objects (Panoptic masks), global motion\n(optical flow), as well as language cues (VLM). Each modality represents an\naxis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two\nplug-in modules, namely Pseudo-modality Generation module and Cross Modal\nInduction module, which generate modality-specific prototypical representation\nand, thereby, induce multi-modal information into RGB cues. These modules\noperate by performing anomaly-aware auxiliary tasks and necessitate five\nmodality backbones -- only during training. Notably, PI-VAD achieves\nstate-of-the-art accuracy on three prominent VAD datasets encompassing\nreal-world scenarios, without requiring the computational overhead of five\nmodality backbones at inference.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13123v1",
    "published_date": "2025-05-19 13:51:57 UTC",
    "updated_date": "2025-05-19 13:51:57 UTC"
  },
  {
    "arxiv_id": "2505.13122v1",
    "title": "When majority rules, minority loses: bias amplification of gradient descent",
    "authors": [
      "François Bachoc",
      "Jérôme Bolte",
      "Ryan Boustany",
      "Jean-Michel Loubes"
    ],
    "abstract": "Despite growing empirical evidence of bias amplification in machine learning,\nits theoretical foundations remain poorly understood. We develop a formal\nframework for majority-minority learning tasks, showing how standard training\ncan favor majority groups and produce stereotypical predictors that neglect\nminority-specific features. Assuming population and variance imbalance, our\nanalysis reveals three key findings: (i) the close proximity between\n``full-data'' and stereotypical predictors, (ii) the dominance of a region\nwhere training the entire model tends to merely learn the majority traits, and\n(iii) a lower bound on the additional training required. Our results are\nillustrated through experiments in deep learning for tabular and image\nclassification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13122v1",
    "published_date": "2025-05-19 13:51:49 UTC",
    "updated_date": "2025-05-19 13:51:49 UTC"
  },
  {
    "arxiv_id": "2505.13118v1",
    "title": "Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals",
    "authors": [
      "Marouane Il Idrissi",
      "Agathe Fernandes Machado",
      "Ewen Gallic",
      "Arthur Charpentier"
    ],
    "abstract": "Cooperative game theory methods, notably Shapley values, have significantly\nenhanced machine learning (ML) interpretability. However, existing explainable\nAI (XAI) frameworks mainly attribute average model predictions, overlooking\npredictive uncertainty. This work addresses that gap by proposing a novel,\nmodel-agnostic uncertainty attribution (UA) method grounded in conformal\nprediction (CP). By defining cooperative games where CP interval\nproperties-such as width and bounds-serve as value functions, we systematically\nattribute predictive uncertainty to input features. Extending beyond the\ntraditional Shapley values, we use the richer class of Harsanyi allocations,\nand in particular the proportional Shapley values, which distribute attribution\nproportionally to feature importance. We propose a Monte Carlo approximation\nmethod with robust statistical guarantees to address computational feasibility,\nsignificantly improving runtime efficiency. Our comprehensive experiments on\nsynthetic benchmarks and real-world datasets demonstrate the practical utility\nand interpretative depth of our approach. By combining cooperative game theory\nand conformal prediction, we offer a rigorous, flexible toolkit for\nunderstanding and communicating predictive uncertainty in high-stakes ML\napplications.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13118v1",
    "published_date": "2025-05-19 13:49:05 UTC",
    "updated_date": "2025-05-19 13:49:05 UTC"
  },
  {
    "arxiv_id": "2505.13116v1",
    "title": "Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data",
    "authors": [
      "Kathrin Lammers",
      "Valerie Vaquet",
      "Barbara Hammer"
    ],
    "abstract": "As machine learning is increasingly applied in an online fashion to deal with\nevolving data streams, the fairness of these algorithms is a matter of growing\nethical and legal concern. In many use cases, class imbalance in the data also\nneeds to be dealt with to ensure predictive performance. Current fairness-aware\nstream learners typically attempt to solve these issues through in- or\npost-processing by focusing on optimizing one specific discrimination metric,\naddressing class imbalance in a separate processing step. While C-SMOTE is a\nhighly effective model-agnostic pre-processing approach to mitigate class\nimbalance, as a side effect of this method, algorithmic bias is often\nintroduced.\n  Therefore, we propose CFSMOTE - a fairness-aware, continuous SMOTE variant -\nas a pre-processing approach to simultaneously address the class imbalance and\nfairness concerns by employing situation testing and balancing\nfairness-relevant groups during oversampling. Unlike other fairness-aware\nstream learners, CFSMOTE is not optimizing for only one specific fairness\nmetric, therefore avoiding potentially problematic trade-offs. Our experiments\nshow significant improvement on several common group fairness metrics in\ncomparison to vanilla C-SMOTE while maintaining competitive performance, also\nin comparison to other fairness-aware algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13116v1",
    "published_date": "2025-05-19 13:46:47 UTC",
    "updated_date": "2025-05-19 13:46:47 UTC"
  },
  {
    "arxiv_id": "2505.13115v1",
    "title": "Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning",
    "authors": [
      "Debarpan Bhattacharya",
      "Apoorva Kulkarni",
      "Sriram Ganapathy"
    ],
    "abstract": "The popular success of text-based large language models (LLM) has streamlined\nthe attention of the multimodal community to combine other modalities like\nvision and audio along with text to achieve similar multimodal capabilities. In\nthis quest, large audio language models (LALMs) have to be evaluated on\nreasoning related tasks which are different from traditional classification or\ngeneration tasks. Towards this goal, we propose a novel dataset called temporal\nreasoning evaluation of audio (TREA).\n  We benchmark open-source LALMs and observe that they are consistently behind\nhuman capabilities on the tasks in the TREA dataset. While evaluating LALMs, we\nalso propose an uncertainty metric, which computes the invariance of the model\nto semantically identical perturbations of the input. Our analysis shows that\nthe accuracy and uncertainty metrics are not necessarily correlated and thus,\npoints to a need for wholesome evaluation of LALMs for high-stakes\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in INTERSPEECH, 2025, Rotterdam, The Netherlands",
    "pdf_url": "http://arxiv.org/pdf/2505.13115v1",
    "published_date": "2025-05-19 13:46:35 UTC",
    "updated_date": "2025-05-19 13:46:35 UTC"
  },
  {
    "arxiv_id": "2505.13109v1",
    "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
    "authors": [
      "Guangda Liu",
      "Chengwei Li",
      "Zhenyu Ning",
      "Jing Lin",
      "Yiwu Yao",
      "Danning Ke",
      "Minyi Guo",
      "Jieru Zhao"
    ],
    "abstract": "Large language models (LLMs) have been widely deployed with rapidly expanding\ncontext windows to support increasingly demanding applications. However, long\ncontexts pose significant deployment challenges, primarily due to the KV cache\nwhose size grows proportionally with context length. While KV cache compression\nmethods are proposed to address this issue, KV dropping methods incur\nconsiderable accuracy loss, and KV retrieval methods suffer from significant\nefficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization\nframework to enhance KV retrieval efficiency while preserving accuracy. On the\nalgorithm side, FreeKV introduces speculative retrieval to shift the KV\nselection and recall processes out of the critical path, combined with\nfine-grained correction to ensure accuracy. On the system side, FreeKV employs\nhybrid KV layouts across CPU and GPU memory to eliminate fragmented data\ntransfers, and leverages double-buffered streamed recall to further improve\nefficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy\nacross various scenarios and models, delivering up to 13$\\times$ speedup\ncompared to SOTA KV retrieval methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13109v1",
    "published_date": "2025-05-19 13:36:45 UTC",
    "updated_date": "2025-05-19 13:36:45 UTC"
  },
  {
    "arxiv_id": "2505.13102v1",
    "title": "Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast",
    "authors": [
      "Ji Qi",
      "Tam Thuc Do",
      "Mingxiao Liu",
      "Zhuoshi Pan",
      "Yuzhe Li",
      "Gene Cheung",
      "H. Vicky Zhao"
    ],
    "abstract": "To forecast traffic with both spatial and temporal dimensions, we unroll a\nmixed-graph-based optimization algorithm into a lightweight and interpretable\ntransformer-like neural net. Specifically, we construct two graphs: an\nundirected graph $\\mathcal{G}^u$ capturing spatial correlations across\ngeography, and a directed graph $\\mathcal{G}^d$ capturing sequential\nrelationships over time. We formulate a prediction problem for the future\nsamples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both\n$\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and\n$\\ell_1$-norm variational terms to quantify and promote signal smoothness\n(low-frequency reconstruction) on a directed graph. We construct an iterative\nalgorithm based on alternating direction method of multipliers (ADMM), and\nunroll it into a feed-forward network for data-driven parameter learning. We\ninsert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$, which\nare akin to the self-attention mechanism in classical transformers. Experiments\nshow that our unrolled networks achieve competitive traffic forecast\nperformance as state-of-the-art prediction schemes, while reducing parameter\ncounts drastically. Our code is available in\nhttps://github.com/SingularityUndefined/Unrolling-GSP-STForecast.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 5 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.13102v1",
    "published_date": "2025-05-19 13:32:34 UTC",
    "updated_date": "2025-05-19 13:32:34 UTC"
  },
  {
    "arxiv_id": "2505.13101v1",
    "title": "ARIW-Framework: Adaptive Robust Iterative Watermarking Framework",
    "authors": [
      "Shaowu Wu",
      "Liting Zeng",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "With the rapid rise of large models, copyright protection for generated image\ncontent has become a critical security challenge. Although deep learning\nwatermarking techniques offer an effective solution for digital image copyright\nprotection, they still face limitations in terms of visual quality, robustness\nand generalization. To address these issues, this paper proposes an adaptive\nrobust iterative watermarking framework (ARIW-Framework) that achieves\nhigh-quality watermarked images while maintaining exceptional robustness and\ngeneralization performance. Specifically, we introduce an iterative approach to\noptimize the encoder for generating robust residuals. The encoder incorporates\nnoise layers and a decoder to compute robustness weights for residuals under\nvarious noise attacks. By employing a parallel optimization strategy, the\nframework enhances robustness against multiple types of noise attacks.\nFurthermore, we leverage image gradients to determine the embedding strength at\neach pixel location, significantly improving the visual quality of the\nwatermarked images. Extensive experiments demonstrate that the proposed method\nachieves superior visual quality while exhibiting remarkable robustness and\ngeneralization against noise attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13101v1",
    "published_date": "2025-05-19 13:31:48 UTC",
    "updated_date": "2025-05-19 13:31:48 UTC"
  },
  {
    "arxiv_id": "2505.13098v1",
    "title": "LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs",
    "authors": [
      "Lars-Peter Meyer",
      "Johannes Frey",
      "Desiree Heim",
      "Felix Brei",
      "Claus Stadler",
      "Kurt Junghanns",
      "Michael Martin"
    ],
    "abstract": "Current Large Language Models (LLMs) can assist developing program code\nbeside many other things, but can they support working with Knowledge Graphs\n(KGs) as well? Which LLM is offering the best capabilities in the field of\nSemantic Web and Knowledge Graph Engineering (KGE)? Is this possible to\ndetermine without checking many answers manually? The LLM-KG-Bench framework in\nVersion 3.0 is designed to answer these questions. It consists of an extensible\nset of tasks for automated evaluation of LLM answers and covers different\naspects of working with semantic technologies. In this paper the LLM-KG-Bench\nframework is presented in Version 3 along with a dataset of prompts, answers\nand evaluations generated with it and several state-of-the-art LLMs.\nSignificant enhancements have been made to the framework since its initial\nrelease, including an updated task API that offers greater flexibility in\nhandling evaluation tasks, revised tasks, and extended support for various open\nmodels through the vllm library, among other improvements. A comprehensive\ndataset has been generated using more than 30 contemporary open and proprietary\nLLMs, enabling the creation of exemplary model cards that demonstrate the\nmodels' capabilities in working with RDF and SPARQL, as well as comparing their\nperformance on Turtle and JSON-LD RDF serialization tasks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Peer reviewed publication at ESWC 2025 Resources Track",
    "pdf_url": "http://arxiv.org/pdf/2505.13098v1",
    "published_date": "2025-05-19 13:29:27 UTC",
    "updated_date": "2025-05-19 13:29:27 UTC"
  },
  {
    "arxiv_id": "2505.13572v1",
    "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs",
    "authors": [
      "Yousouf Taghzouti",
      "Franck Michel",
      "Tao Jiang",
      "Louis-Félix Nothias",
      "Fabien Gandon"
    ],
    "abstract": "The SPARQL query language is the standard method to access knowledge graphs\n(KGs). However, formulating SPARQL queries is a significant challenge for\nnon-expert users, and remains time-consuming for the experienced ones. Best\npractices recommend to document KGs with competency questions and example\nqueries to contextualise the knowledge they contain and illustrate their\npotential applications. In practice, however, this is either not the case or\nthe examples are provided in limited numbers. Large Language Models (LLMs) are\nbeing used in conversational agents and are proving to be an attractive\nsolution with a wide range of applications, from simple question-answering\nabout common knowledge to generating code in a targeted programming language.\nHowever, training and testing these models to produce high quality SPARQL\nqueries from natural language questions requires substantial datasets of\nquestion-query pairs. In this paper, we present Q${}^2$Forge that addresses the\nchallenge of generating new competency questions for a KG and corresponding\nSPARQL queries. It iteratively validates those queries with human feedback and\nLLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular,\nmeaning that the different modules of the application (CQ generation, query\ngeneration and query refinement) can be used separately, as an integrated\npipeline, or replaced by alternative services. The result is a complete\npipeline from competency question formulation to query evaluation, supporting\nthe creation of reference query sets for any target KG.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13572v1",
    "published_date": "2025-05-19 13:26:51 UTC",
    "updated_date": "2025-05-19 13:26:51 UTC"
  },
  {
    "arxiv_id": "2505.13094v1",
    "title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation",
    "authors": [
      "Guo Chen",
      "Kai Li",
      "Runxuan Yang",
      "Xiaolin Hu"
    ],
    "abstract": "Existing causal speech separation models often underperform compared to\nnon-causal models due to difficulties in retaining historical information. To\naddress this, we propose the Time-Frequency Attention Cache Memory (TFACM)\nmodel, which effectively captures spatio-temporal relationships through an\nattention mechanism and cache memory (CM) for historical information storage.\nIn TFACM, an LSTM layer captures frequency-relative positions, while causal\nmodeling is applied to the time dimension using local and global\nrepresentations. The CM module stores past information, and the causal\nattention refinement (CAR) module further enhances time-based feature\nrepresentations for finer granularity. Experimental results showed that TFACM\nachieveed comparable performance to the SOTA TF-GridNet-Causal model, with\nsignificantly lower complexity and fewer trainable parameters. For more\ndetails, visit the project page: https://cslikai.cn/TFACM/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13094v1",
    "published_date": "2025-05-19 13:25:51 UTC",
    "updated_date": "2025-05-19 13:25:51 UTC"
  },
  {
    "arxiv_id": "2505.13087v1",
    "title": "Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings",
    "authors": [
      "Adrien Lagesse",
      "Marc Lelarge"
    ],
    "abstract": "We propose a novel benchmarking methodology for graph neural networks (GNNs)\nbased on the graph alignment problem, a combinatorial optimization task that\ngeneralizes graph isomorphism by aligning two unlabeled graphs to maximize\noverlapping edges. We frame this problem as a self-supervised learning task and\npresent several methods to generate graph alignment datasets using synthetic\nrandom graphs and real-world graph datasets from multiple domains. For a given\ngraph dataset, we generate a family of graph alignment datasets with increasing\ndifficulty, allowing us to rank the performance of various architectures. Our\nexperiments indicate that anisotropic graph neural networks outperform standard\nconvolutional architectures. To further demonstrate the utility of the graph\nalignment task, we show its effectiveness for unsupervised GNN pre-training,\nwhere the learned node embeddings outperform other positional encodings on\nthree molecular regression tasks and achieve state-of-the-art results on the\nPCQM4Mv2 dataset with significantly fewer parameters. To support\nreproducibility and further research, we provide an open-source Python package\nto generate graph alignment datasets and benchmark new GNN architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13087v1",
    "published_date": "2025-05-19 13:22:17 UTC",
    "updated_date": "2025-05-19 13:22:17 UTC"
  },
  {
    "arxiv_id": "2505.13082v1",
    "title": "MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers",
    "authors": [
      "Kyeongman Park",
      "Seongho Joo",
      "Kyomin Jung"
    ],
    "abstract": "We introduce MultiActor-Audiobook, a zero-shot approach for generating\naudiobooks that automatically produces consistent, expressive, and\nspeaker-appropriate prosody, including intonation and emotion. Previous\naudiobook systems have several limitations: they require users to manually\nconfigure the speaker's prosody, read each sentence with a monotonic tone\ncompared to voice actors, or rely on costly training. However, our\nMultiActor-Audiobook addresses these issues by introducing two novel processes:\n(1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based\nScript Instruction Generation**). With these two processes,\nMultiActor-Audiobook can generate more emotionally expressive audiobooks with a\nconsistent speaker prosody without additional training. We compare our system\nwith commercial products, through human and MLLM evaluations, achieving\ncompetitive results. Furthermore, we demonstrate the effectiveness of MSP and\nLSI through ablation studies.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13082v1",
    "published_date": "2025-05-19 13:13:46 UTC",
    "updated_date": "2025-05-19 13:13:46 UTC"
  },
  {
    "arxiv_id": "2505.13079v1",
    "title": "Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR",
    "authors": [
      "Xugang Lu",
      "Peng Shen",
      "Yu Tsao",
      "Hisashi Kawai"
    ],
    "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nacoustic feature learning has proven effective in enhancing end-to-end\nautomatic speech recognition (E2E-ASR). However, aligning representations\nbetween linguistic and acoustic modalities remains a challenge due to inherent\nmodality gaps. Optimal transport (OT) has shown promise in mitigating these\ngaps by minimizing the Wasserstein distance (WD) between linguistic and\nacoustic feature distributions. However, previous OT-based methods overlook\nstructural relationships, treating feature vectors as unordered sets. To\naddress this, we propose Graph Matching Optimal Transport (GM-OT), which models\nlinguistic and acoustic sequences as structured graphs. Nodes represent feature\nembeddings, while edges capture temporal and sequential relationships. GM-OT\nminimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD)\n(between edges), leading to a fused Gromov-Wasserstein distance (FGWD)\nformulation. This enables structured alignment and more efficient knowledge\ntransfer compared to existing OT-based approaches. Theoretical analysis further\nshows that prior OT-based methods in linguistic knowledge transfer can be\nviewed as a special case within our GM-OT framework. We evaluate GM-OT on\nMandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge\ntransfer. Experimental results demonstrate significant performance gains over\nstate-of-the-art models, validating the effectiveness of our approach.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "To appear in Interspeech 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13079v1",
    "published_date": "2025-05-19 13:13:18 UTC",
    "updated_date": "2025-05-19 13:13:18 UTC"
  },
  {
    "arxiv_id": "2505.13077v1",
    "title": "Advancing Sequential Numerical Prediction in Autoregressive Models",
    "authors": [
      "Xiang Fei",
      "Jinghui Lu",
      "Qi Sun",
      "Hao Feng",
      "Yanjie Wang",
      "Wei Shi",
      "An-Lan Wang",
      "Jingqun Tang",
      "Can Huang"
    ],
    "abstract": "Autoregressive models have become the de facto choice for sequence generation\ntasks, but standard approaches treat digits as independent tokens and apply\ncross-entropy loss, overlooking the coherent structure of numerical sequences.\nThis paper introduces Numerical Token Integrity Loss (NTIL) to address this\ngap. NTIL operates at two levels: (1) token-level, where it extends the Earth\nMover's Distance (EMD) to preserve ordinal relationships between numerical\nvalues, and (2) sequence-level, where it penalizes the overall discrepancy\nbetween the predicted and actual sequences. This dual approach improves\nnumerical prediction and integrates effectively with LLMs/MLLMs. Extensive\nexperiments show significant performance improvements with NTIL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2505.13077v1",
    "published_date": "2025-05-19 13:11:28 UTC",
    "updated_date": "2025-05-19 13:11:28 UTC"
  },
  {
    "arxiv_id": "2505.13076v1",
    "title": "The Hidden Dangers of Browsing AI Agents",
    "authors": [
      "Mykyta Mudryi",
      "Markiyan Chaklosh",
      "Grzegorz Wójcik"
    ],
    "abstract": "Autonomous browsing agents powered by large language models (LLMs) are\nincreasingly used to automate web-based tasks. However, their reliance on\ndynamic content, tool execution, and user-provided data exposes them to a broad\nattack surface. This paper presents a comprehensive security evaluation of such\nagents, focusing on systemic vulnerabilities across multiple architectural\nlayers. Our work outlines the first end-to-end threat model for browsing agents\nand provides actionable guidance for securing their deployment in real-world\nenvironments. To address discovered threats, we propose a defense in depth\nstrategy incorporating input sanitization, planner executor isolation, formal\nanalyzers, and session safeguards. These measures protect against both initial\naccess and post exploitation attack vectors. Through a white box analysis of a\npopular open source project, Browser Use, we demonstrate how untrusted web\ncontent can hijack agent behavior and lead to critical security breaches. Our\nfindings include prompt injection, domain validation bypass, and credential\nexfiltration, evidenced by a disclosed CVE and a working proof of concept\nexploit.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13076v1",
    "published_date": "2025-05-19 13:10:29 UTC",
    "updated_date": "2025-05-19 13:10:29 UTC"
  },
  {
    "arxiv_id": "2505.13073v1",
    "title": "Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion",
    "authors": [
      "Dengfeng Liu",
      "Jucai Zhai",
      "Xiaoguang Jiang",
      "Ziqun Li",
      "Qianjin Yu",
      "Feng Liu",
      "Rui Ye",
      "Huang Liu",
      "Zhiguo Yang",
      "Yongsheng Du",
      "Fang Tan"
    ],
    "abstract": "Code completion technology based on large language model has significantly\nimproved the development efficiency of programmers. However, in practical\napplications, there remains a gap between current commonly used code completion\nevaluation metrics and users' actual perception. To address this issue, we\npropose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP,\nfrom the perspective of probabilistic modeling. Furthermore, to tackle the lack\nof effective structural semantic modeling and cross-module dependency\ninformation in LLMs for repository-level code completion scenarios, we propose\na data processing method based on a Structure-Preserving and\nSemantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis\nand experimental validation, we demonstrate the superiority of the proposed\nevaluation metrics in terms of user perception consistency, as well as the\neffectiveness of the data processing method in enhancing model performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "14 pages,8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13073v1",
    "published_date": "2025-05-19 13:09:32 UTC",
    "updated_date": "2025-05-19 13:09:32 UTC"
  },
  {
    "arxiv_id": "2505.13053v1",
    "title": "SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation",
    "authors": [
      "Amelie S. Robrecht",
      "Christoph R. Kowalski",
      "Stefan Kopp"
    ],
    "abstract": "Adapting to the addressee is crucial for successful explanations, yet poses\nsignificant challenges for dialogsystems. We adopt the approach of treating\nexplanation generation as a non-stationary decision process, where the optimal\nstrategy varies according to changing beliefs about the explainee and the\ninteraction context. In this paper we address the questions of (1) how to track\nthe interaction context and the relevant listener features in a formally\ndefined computational partner model, and (2) how to utilize this model in the\ndynamically adjusted, rational decision process that determines the currently\nbest explanation strategy. We propose a Bayesian inference-based approach to\ncontinuously update the partner model based on user feedback, and a\nnon-stationary Markov Decision Process to adjust decision-making based on the\npartner model values. We evaluate an implementation of this framework with five\nsimulated interlocutors, demonstrating its effectiveness in adapting to\ndifferent partners with constant and even changing feedback behavior. The\nresults show high adaptivity with distinct explanation strategies emerging for\ndifferent partners, highlighting the potential of our approach to improve\nexplainable AI systems and dialogsystems in general.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "currently under review at Frontiers in Communication",
    "pdf_url": "http://arxiv.org/pdf/2505.13053v1",
    "published_date": "2025-05-19 12:42:23 UTC",
    "updated_date": "2025-05-19 12:42:23 UTC"
  },
  {
    "arxiv_id": "2505.13043v1",
    "title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation",
    "authors": [
      "Hao-Ran Yang",
      "Xiaohui Chen",
      "Chuan-Xian Ren"
    ],
    "abstract": "Aiming to generalize the well-trained gaze estimation model to new target\ndomains, Cross-domain Gaze Estimation (CDGE) is developed for real-world\napplication scenarios. Existing CDGE methods typically extract the\ndomain-invariant features to mitigate domain shift in feature space, which is\nproved insufficient by Generalized Label Shift (GLS) theory. In this paper, we\nintroduce a novel GLS perspective to CDGE and modelize the cross-domain problem\nby label and conditional shift problem. A GLS correction framework is presented\nand a feasible realization is proposed, in which a importance reweighting\nstrategy based on truncated Gaussian distribution is introduced to overcome the\ncontinuity challenges in label shift correction. To embed the reweighted source\ndistribution to conditional invariant learning, we further derive a\nprobability-aware estimation of conditional operator discrepancy. Extensive\nexperiments on standard CDGE tasks with different backbone models validate the\nsuperior generalization capability across domain and applicability on various\nmodels of proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13043v1",
    "published_date": "2025-05-19 12:33:52 UTC",
    "updated_date": "2025-05-19 12:33:52 UTC"
  },
  {
    "arxiv_id": "2505.13044v1",
    "title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents",
    "authors": [
      "Rebecca Westhäußer",
      "Frederik Berenz",
      "Wolfgang Minker",
      "Sebastian Zepf"
    ],
    "abstract": "Large language models (LLMs) have advanced the field of artificial\nintelligence (AI) and are a powerful enabler for interactive systems. However,\nthey still face challenges in long-term interactions that require adaptation\ntowards the user as well as contextual knowledge and understanding of the\never-changing environment. To overcome these challenges, holistic memory\nmodeling is required to efficiently retrieve and store relevant information\nacross interaction sessions for suitable responses. Cognitive AI, which aims to\nsimulate the human thought process in a computerized model, highlights\ninteresting aspects, such as thoughts, memory mechanisms, and decision-making,\nthat can contribute towards improved memory modeling for LLMs. Inspired by\nthese cognitive AI principles, we propose our memory framework CAIM. CAIM\nconsists of three modules: 1.) The Memory Controller as the central decision\nunit; 2.) the Memory Retrieval, which filters relevant data for interaction\nupon request; and 3.) the Post-Thinking, which maintains the memory storage. We\ncompare CAIM against existing approaches, focusing on metrics such as retrieval\naccuracy, response correctness, contextual coherence, and memory storage. The\nresults demonstrate that CAIM outperforms baseline frameworks across different\nmetrics, highlighting its context-awareness and potential to improve long-term\nhuman-AI interactions.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13044v1",
    "published_date": "2025-05-19 12:33:52 UTC",
    "updated_date": "2025-05-19 12:33:52 UTC"
  },
  {
    "arxiv_id": "2505.13036v1",
    "title": "KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025",
    "authors": [
      "Sai Koneru",
      "Maike Züfle",
      "Thai-Binh Nguyen",
      "Seymanur Akti",
      "Jan Niehues",
      "Alexander Waibel"
    ],
    "abstract": "The scope of the International Workshop on Spoken Language Translation\n(IWSLT) has recently broadened beyond traditional Speech Translation (ST) to\nencompass a wider array of tasks, including Speech Question Answering and\nSummarization. This shift is partly driven by the growing capabilities of\nmodern systems, particularly with the success of Large Language Models (LLMs).\nIn this paper, we present the Karlsruhe Institute of Technology's submissions\nfor the Offline ST and Instruction Following (IF) tracks, where we leverage\nLLMs to enhance performance across all tasks. For the Offline ST track, we\npropose a pipeline that employs multiple automatic speech recognition systems,\nwhose outputs are fused using an LLM with document-level context. This is\nfollowed by a two-step translation process, incorporating additional refinement\nstep to improve translation quality. For the IF track, we develop an end-to-end\nmodel that integrates a speech encoder with an LLM to perform a wide range of\ninstruction-following tasks. We complement it with a final document-level\nrefinement stage to further enhance output quality by using contextual\ninformation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13036v1",
    "published_date": "2025-05-19 12:21:29 UTC",
    "updated_date": "2025-05-19 12:21:29 UTC"
  },
  {
    "arxiv_id": "2505.13033v1",
    "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis",
    "authors": [
      "Vijay Ekambaram",
      "Subodh Kumar",
      "Arindam Jati",
      "Sumanta Mukherjee",
      "Tomoya Sakai",
      "Pankaj Dayama",
      "Wesley M. Gifford",
      "Jayant Kalagnanam"
    ],
    "abstract": "The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters,\nmaking TSPulse 10-100X smaller than existing pre-trained models. Its efficiency\nenables GPU-free inference and rapid pre-training, setting a new standard for\nefficient time-series pre-trained models. Models will be open-sourced soon.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13033v1",
    "published_date": "2025-05-19 12:18:53 UTC",
    "updated_date": "2025-05-19 12:18:53 UTC"
  },
  {
    "arxiv_id": "2505.13031v1",
    "title": "MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO",
    "authors": [
      "Yicheng Xiao",
      "Lin Song",
      "Yukang Chen",
      "Yingmin Luo",
      "Yuxin Chen",
      "Yukang Gan",
      "Wei Huang",
      "Xiu Li",
      "Xiaojuan Qi",
      "Ying Shan"
    ],
    "abstract": "Recent text-to-image systems face limitations in handling multimodal inputs\nand complex reasoning tasks. We introduce MindOmni, a unified multimodal large\nlanguage model that addresses these challenges by incorporating reasoning\ngeneration through reinforcement learning. MindOmni leverages a three-phase\ntraining strategy: i) design of a unified vision language model with a\ndecoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought\n(CoT) instruction data, and iii) our proposed Reasoning Generation Policy\nOptimization (RGPO) algorithm, utilizing multimodal feedback to effectively\nguide policy updates. Experimental results demonstrate that MindOmni\noutperforms existing models, achieving impressive performance on both\nunderstanding and generation benchmarks, meanwhile showcasing advanced\nfine-grained reasoning generation capabilities, especially with mathematical\nreasoning instruction. All codes will be made public at\n\\href{https://github.com/EasonXiao-888/MindOmni}{https://github.com/EasonXiao-888/MindOmni}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code: https://github.com/EasonXiao-888/MindOmni",
    "pdf_url": "http://arxiv.org/pdf/2505.13031v1",
    "published_date": "2025-05-19 12:17:04 UTC",
    "updated_date": "2025-05-19 12:17:04 UTC"
  },
  {
    "arxiv_id": "2505.13028v2",
    "title": "Evaluating the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset",
    "authors": [
      "Sayon Palit",
      "Daniel Woods"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\nsystems in industries like healthcare and finance. Users can often submit\nqueries to LLM-enabled chatbots, some of which can enrich responses with\ninformation retrieved from internal databases storing sensitive data. This\ngives rise to a range of attacks in which a user submits a malicious query and\nthe LLM-system outputs a response that creates harm to the owner, such as\nleaking internal data or creating legal liability by harming a third-party.\nWhile security tools are being developed to counter these threats, there is\nlittle formal evaluation of their effectiveness and usability. This study\naddresses this gap by conducting a thorough comparative analysis of LLM\nsecurity tools. We identified 13 solutions (9 closed-source, 4 open-source),\nbut only 7 were evaluated due to a lack of participation by proprietary model\nowners.To evaluate, we built a benchmark dataset of malicious prompts, and\nevaluate these tools performance against a baseline LLM model\n(ChatGPT-3.5-Turbo). Our results show that the baseline model has too many\nfalse positives to be used for this task. Lakera Guard and ProtectAI LLM Guard\nemerged as the best overall tools showcasing the tradeoff between usability and\nperformance. The study concluded with recommendations for greater transparency\namong closed source providers, improved context-aware detections, enhanced\nopen-source engagement, increased user awareness, and the adoption of more\nrepresentative performance metrics.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "F.2.2; I.2.7; F.2.2; I.2.7; F.2.2; I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13028v2",
    "published_date": "2025-05-19 12:12:00 UTC",
    "updated_date": "2025-05-20 07:34:53 UTC"
  },
  {
    "arxiv_id": "2505.13026v1",
    "title": "Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs",
    "authors": [
      "Jack Chen",
      "Fazhong Liu",
      "Naruto Liu",
      "Yuhan Luo",
      "Erqu Qin",
      "Harry Zheng",
      "Tian Dong",
      "Haojin Zhu",
      "Yan Meng",
      "Xiao Wang"
    ],
    "abstract": "Large language models (LLMs) excel at mathematical reasoning and logical\nproblem-solving. The current popular training paradigms primarily use\nsupervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the\nmodels' reasoning abilities. However, when using SFT or RL alone, there are\nrespective challenges: SFT may suffer from overfitting, while RL is prone to\nmode collapse. The state-of-the-art methods have proposed hybrid training\nschemes. However, static switching faces challenges such as poor generalization\nacross different tasks and high dependence on data quality. In response to\nthese challenges, inspired by the curriculum learning-quiz mechanism in human\nreasoning cultivation, We propose SASR, a step-wise adaptive hybrid training\nframework that theoretically unifies SFT and RL and dynamically balances the\ntwo throughout optimization. SASR uses SFT for initial warm-up to establish\nbasic reasoning skills, and then uses an adaptive dynamic adjustment algorithm\nbased on gradient norm and divergence relative to the original distribution to\nseamlessly integrate SFT with the online RL method GRPO. By monitoring the\ntraining status of LLMs and adjusting the training process in sequence, SASR\nensures a smooth transition between training schemes, maintaining core\nreasoning abilities while exploring different paths. Experimental results\ndemonstrate that SASR outperforms SFT, RL, and static hybrid training methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13026v1",
    "published_date": "2025-05-19 12:10:17 UTC",
    "updated_date": "2025-05-19 12:10:17 UTC"
  },
  {
    "arxiv_id": "2505.13025v1",
    "title": "LiBOG: Lifelong Learning for Black-Box Optimizer Generation",
    "authors": [
      "Jiyuan Pei",
      "Yi Mei",
      "Jialin Liu",
      "Mengjie Zhang"
    ],
    "abstract": "Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in\nautomating the configuration and generation of black-box optimizers,\nsignificantly reducing the human effort required for optimizer design and\ndiscovering optimizers with higher performance than classic human-designed\noptimizers. However, existing MetaBBO methods conduct one-off training under\nthe assumption that a stationary problem distribution with extensive and\nrepresentative training problem samples is pre-available. This assumption is\noften impractical in real-world scenarios, where diverse problems following\nshifting distribution continually arise. Consequently, there is a pressing need\nfor methods that can continuously learn from new problems encountered\non-the-fly and progressively enhance their capabilities. In this work, we\nexplore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a\nnovel approach designed to learn from sequentially encountered problems and\ngenerate high-performance optimizers for Black-Box Optimization (BBO). LiBOG\nconsolidates knowledge both across tasks and within tasks to mitigate\ncatastrophic forgetting. Extensive experiments demonstrate LiBOG's\neffectiveness in learning to generate high-performance optimizers in a lifelong\nlearning manner, addressing catastrophic forgetting while maintaining\nplasticity to learn new tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IJCAI 2025. To appear",
    "pdf_url": "http://arxiv.org/pdf/2505.13025v1",
    "published_date": "2025-05-19 12:09:25 UTC",
    "updated_date": "2025-05-19 12:09:25 UTC"
  },
  {
    "arxiv_id": "2505.13023v1",
    "title": "Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions",
    "authors": [
      "Yimao Guo",
      "Zuomin Qu",
      "Wei Lu",
      "Xiangyang Luo"
    ],
    "abstract": "As diffusion-based malicious image manipulation becomes increasingly\nprevalent, multiple proactive defense methods are developed to safeguard images\nagainst unauthorized tampering. However, most proactive defense methods only\ncan safeguard images against manipulation under known conditions, and fail to\nprotect images from manipulations guided by tampering conditions crafted by\nmalicious users. To tackle this issue, we propose Anti-Inpainting, a proactive\ndefense method that achieves adequate protection under unknown conditions\nthrough a triple mechanism to address this challenge. Specifically, a\nmulti-level deep feature extractor is presented to obtain intricate features\nduring the diffusion denoising process to improve protective effectiveness. We\ndesign multi-scale semantic-preserving data augmentation to enhance the\ntransferability of adversarial perturbations across unknown conditions by\nmulti-scale transformations while preserving semantic integrity. In addition,\nwe propose a selection-based distribution deviation optimization strategy to\nimprove the protection of adversarial perturbation against manipulation under\ndiverse random seeds. Extensive experiments indicate the proactive defensive\nperformance of Anti-Inpainting against diffusion-based inpainters guided by\nunknown conditions in InpaintGuardBench and CelebA-HQ. At the same time, we\nalso demonstrate the proposed approach's robustness under various image\npurification methods and its transferability across different versions of\ndiffusion models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13023v1",
    "published_date": "2025-05-19 12:07:29 UTC",
    "updated_date": "2025-05-19 12:07:29 UTC"
  },
  {
    "arxiv_id": "2505.13011v1",
    "title": "Unveiling and Steering Connectome Organization with Interpretable Latent Variables",
    "authors": [
      "Yubin Li",
      "Xingyu Liu",
      "Guozhang Chen"
    ],
    "abstract": "The brain's intricate connectome, a blueprint for its function, presents\nimmense complexity, yet it arises from a compact genetic code, hinting at\nunderlying low-dimensional organizational principles. This work bridges\nconnectomics and representation learning to uncover these principles. We\npropose a framework that combines subgraph extraction from the Drosophila\nconnectome, FlyWire, with a generative model to derive interpretable\nlow-dimensional representations of neural circuitry. Crucially, an\nexplainability module links these latent dimensions to specific structural\nfeatures, offering insights into their functional relevance. We validate our\napproach by demonstrating effective graph reconstruction and, significantly,\nthe ability to manipulate these latent codes to controllably generate\nconnectome subgraphs with predefined properties. This research offers a novel\ntool for understanding brain architecture and a potential avenue for designing\nbio-inspired artificial neural networks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13011v1",
    "published_date": "2025-05-19 11:54:40 UTC",
    "updated_date": "2025-05-19 11:54:40 UTC"
  },
  {
    "arxiv_id": "2505.13010v1",
    "title": "To Bias or Not to Bias: Detecting bias in News with bias-detector",
    "authors": [
      "Himel Ghosh",
      "Ahmed Mosharafa",
      "Georg Groh"
    ],
    "abstract": "Media bias detection is a critical task in ensuring fair and balanced\ninformation dissemination, yet it remains challenging due to the subjectivity\nof bias and the scarcity of high-quality annotated data. In this work, we\nperform sentence-level bias classification by fine-tuning a RoBERTa-based model\non the expert-annotated BABE dataset. Using McNemar's test and the 5x2\ncross-validation paired t-test, we show statistically significant improvements\nin performance when comparing our model to a domain-adaptively pre-trained\nDA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model\navoids common pitfalls like oversensitivity to politically charged terms and\ninstead attends more meaningfully to contextually relevant tokens. For a\ncomprehensive examination of media bias, we present a pipeline that combines\nour model with an already-existing bias-type classifier. Our method exhibits\ngood generalization and interpretability, despite being constrained by\nsentence-level analysis and dataset size because of a lack of larger and more\nadvanced bias corpora. We talk about context-aware modeling, bias\nneutralization, and advanced bias type classification as potential future\ndirections. Our findings contribute to building more robust, explainable, and\nsocially responsible NLP systems for media bias detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.13010v1",
    "published_date": "2025-05-19 11:54:39 UTC",
    "updated_date": "2025-05-19 11:54:39 UTC"
  },
  {
    "arxiv_id": "2505.12996v1",
    "title": "ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "abstract": "In recent years, the emergence of large reasoning models (LRMs), such as\nOpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex\nproblems, e.g., mathematics and coding. Some pioneering studies attempt to\nbring the success of LRMs in neural machine translation (MT). They try to build\nLRMs with deep reasoning MT ability via reinforcement learning (RL). Despite\nsome progress that has been made, these attempts generally focus on several\nhigh-resource languages, e.g., English and Chinese, leaving the performance on\nother languages unclear. Besides, the reward modeling methods in previous work\ndo not fully unleash the potential of reinforcement learning in MT. In this\nwork, we first design a new reward modeling method that compares the\ntranslation results of the policy MT model with a strong LRM (i.e.,\nDeepSeek-R1-671B), and quantifies the comparisons to provide rewards.\nExperimental results demonstrate the superiority of the reward modeling method.\nUsing Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new\nstate-of-the-art performance in literary translation, and outperforms strong\nLRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to\nthe multilingual settings with 11 languages. With a carefully designed\nlightweight reward modeling in RL, we can simply transfer the strong MT ability\nfrom a single direction into multiple (i.e., 90) translation directions and\nachieve impressive multilingual MT performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12996v1",
    "published_date": "2025-05-19 11:34:47 UTC",
    "updated_date": "2025-05-19 11:34:47 UTC"
  },
  {
    "arxiv_id": "2505.12992v1",
    "title": "Fractured Chain-of-Thought Reasoning",
    "authors": [
      "Baohao Liao",
      "Hanze Dong",
      "Yuhui Xu",
      "Doyen Sahoo",
      "Christof Monz",
      "Junnan Li",
      "Caiming Xiong"
    ],
    "abstract": "Inference-time scaling techniques have significantly bolstered the reasoning\ncapabilities of large language models (LLMs) by harnessing additional\ncomputational effort at inference without retraining. Similarly,\nChain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy\nby generating rich intermediate reasoning trajectories, but these approaches\nincur substantial token costs that impede their deployment in latency-sensitive\nsettings. In this work, we first show that truncated CoT, which stops reasoning\nbefore completion and directly generates the final answer, often matches full\nCoT sampling while using dramatically fewer tokens. Building on this insight,\nwe introduce Fractured Sampling, a unified inference-time strategy that\ninterpolates between full CoT and solution-only sampling along three orthogonal\naxes: (1) the number of reasoning trajectories, (2) the number of final\nsolutions per trajectory, and (3) the depth at which reasoning traces are\ntruncated. Through extensive experiments on five diverse reasoning benchmarks\nand several model scales, we demonstrate that Fractured Sampling consistently\nachieves superior accuracy-cost trade-offs, yielding steep log-linear scaling\ngains in Pass@k versus token budget. Our analysis reveals how to allocate\ncomputation across these dimensions to maximize performance, paving the way for\nmore efficient and scalable LLM reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12992v1",
    "published_date": "2025-05-19 11:30:41 UTC",
    "updated_date": "2025-05-19 11:30:41 UTC"
  },
  {
    "arxiv_id": "2505.12983v1",
    "title": "An Empirical Study of Many-to-Many Summarization with Large Language Models",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Zengkui Sun",
      "Yunlong Liang",
      "Yuxuan Cao",
      "Jiarong Xu",
      "Haoxiang Shi",
      "Jie Zhou"
    ],
    "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language\nand generate the corresponding summaries also in any language. Recently, large\nlanguage models (LLMs) have shown strong multi-lingual abilities, giving them\nthe potential to perform M2MS in real applications. This work presents a\nsystematic empirical study on LLMs' M2MS ability. Specifically, we first\nreorganize M2MS data based on eight previous domain-specific datasets. The\nreorganized data contains 47.8K samples spanning five domains and six\nlanguages, which could be used to train and evaluate LLMs. Then, we benchmark\n18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned\ntraditional models (e.g., mBART) are also conducted for comparisons. Our\nexperiments reveal that, zero-shot LLMs achieve competitive results with\nfine-tuned traditional models. After instruct-tuning, open-source LLMs can\nsignificantly improve their M2MS ability, and outperform zero-shot LLMs\n(including GPT-4) in terms of automatic evaluations. In addition, we\ndemonstrate that this task-specific improvement does not sacrifice the LLMs'\ngeneral task-solving abilities. However, as revealed by our human evaluation,\nLLMs still face the factuality issue, and the instruction tuning might\nintensify the issue. Thus, how to control factual errors becomes the key when\nbuilding LLM summarizers in real applications, and is worth noting in future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2505.12983v1",
    "published_date": "2025-05-19 11:18:54 UTC",
    "updated_date": "2025-05-19 11:18:54 UTC"
  },
  {
    "arxiv_id": "2505.12981v2",
    "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents",
    "authors": [
      "Liangxuan Wu",
      "Chao Wang",
      "Tianming Liu",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "The growing adoption of large language models (LLMs) has led to a new\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\ndecomposing and automating complex tasks directly on smartphones. However, the\nsecurity implications of these agents remain largely unexplored. In this paper,\nwe present the first comprehensive security analysis of mobile LLM agents,\nencompassing three representative categories: System-level AI Agents developed\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\nagents and identifying security threats across three core capability\ndimensions: language-based reasoning, GUI-based interaction, and system-level\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\ntheir entire operational lifecycle. To investigate these threats in practice,\nwe introduce AgentScan, a semi-automated security analysis framework that\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\nagents exhibit vulnerabilities across eight distinct attack vectors. These\nattacks can cause behavioral deviations, privacy leakage, or even full\nexecution hijacking. Based on these findings, we propose a set of defensive\ndesign principles and practical recommendations for building secure mobile LLM\nagents. Our disclosures have received positive feedback from two major device\nvendors. Overall, this work highlights the urgent need for standardized\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\nautomation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12981v2",
    "published_date": "2025-05-19 11:17:46 UTC",
    "updated_date": "2025-05-20 07:02:05 UTC"
  },
  {
    "arxiv_id": "2505.12966v1",
    "title": "Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection",
    "authors": [
      "Zihan Xiong",
      "Xiaohua Wu",
      "Lei Chen",
      "Fangqi Lou"
    ],
    "abstract": "Advances in computer vision and deep learning have blurred the line between\ndeepfakes and authentic media, undermining multimedia credibility through\naudio-visual forgery. Current multimodal detection methods remain limited by\nunbalanced learning between modalities. To tackle this issue, we propose an\nAudio-Visual Joint Learning Method (MACB-DF) to better mitigate modality\nconflicts and neglect by leveraging contrastive learning to assist in\nmulti-level and cross-modal fusion, thereby fully balancing and exploiting\ninformation from each modality. Additionally, we designed an\northogonalization-multimodal pareto module that preserves unimodal information\nwhile addressing gradient conflicts in audio-video encoders caused by differing\noptimization targets of the loss functions. Extensive experiments and ablation\nstudies conducted on mainstream deepfake datasets demonstrate consistent\nperformance gains of our model across key evaluation metrics, achieving an\naverage accuracy of 95.5% across multiple datasets. Notably, our method\nexhibits superior cross-dataset generalization capabilities, with absolute\nimprovements of 8.0% and 7.7% in ACC scores over the previous best-performing\napproach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages,ICMR accepted",
    "pdf_url": "http://arxiv.org/pdf/2505.12966v1",
    "published_date": "2025-05-19 11:01:49 UTC",
    "updated_date": "2025-05-19 11:01:49 UTC"
  },
  {
    "arxiv_id": "2505.13567v1",
    "title": "Learning Dynamics of RNNs in Closed-Loop Environments",
    "authors": [
      "Yoav Ger",
      "Omri Barak"
    ],
    "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer\npowerful models of brain computation. However, typical training paradigms rely\non open-loop, supervised settings, whereas real-world learning unfolds in\nclosed-loop environments. Here, we develop a mathematical theory describing the\nlearning dynamics of linear RNNs trained in closed-loop contexts. We first\ndemonstrate that two otherwise identical RNNs, trained in either closed- or\nopen-loop modes, follow markedly different learning trajectories. To probe this\ndivergence, we analytically characterize the closed-loop case, revealing\ndistinct stages aligned with the evolution of the training loss. Specifically,\nwe show that the learning dynamics of closed-loop RNNs, in contrast to\nopen-loop ones, are governed by an interplay between two competing objectives:\nshort-term policy improvement and long-term stability of the agent-environment\ninteraction. Finally, we apply our framework to a realistic motor control task,\nhighlighting its broader applicability. Taken together, our results underscore\nthe importance of modeling closed-loop dynamics in a biologically plausible\nsetting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages with 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13567v1",
    "published_date": "2025-05-19 11:00:23 UTC",
    "updated_date": "2025-05-19 11:00:23 UTC"
  },
  {
    "arxiv_id": "2505.12963v1",
    "title": "Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies",
    "authors": [
      "Maksim I. Ivanov",
      "Olga E. Mendybaeva",
      "Yuri E. Karyakin",
      "Igor N. Glukhikh",
      "Aleksey V. Lebedev"
    ],
    "abstract": "This article explores the use of artificial intelligence for the diagnosis of\npathologies of the temporomandibular joint (TMJ), in particular, for the\nsegmentation of the articular disc on MRI images. The relevance of the work is\ndue to the high prevalence of TMJ pathologies, as well as the need to improve\nthe accuracy and speed of diagnosis in medical institutions. During the study,\nthe existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result,\nare not suitable for studying the articular disc due to the orientation towards\nbone structures. To solve the problem, an original dataset was collected from\n94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the\namount of data, augmentation methods were used. After that, the models of\nU-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and\ncompared. The evaluation was carried out according to the Dice Score,\nPrecision, Sensitivity, Specificity, and Mean Average Precision metrics. The\nresults confirm the potential of using the Roboflow model for segmentation of\nthe temporomandibular joint. In the future, it is planned to develop an\nalgorithm for measuring the distance between the jaws and determining the\nposition of the articular disc, which will improve the diagnosis of TMJ\npathologies.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12963v1",
    "published_date": "2025-05-19 10:58:02 UTC",
    "updated_date": "2025-05-19 10:58:02 UTC"
  },
  {
    "arxiv_id": "2505.12960v1",
    "title": "Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory",
    "authors": [
      "Chengping He",
      "Mingrui Jiang",
      "Keyi Shan",
      "Szu-Hao Yang",
      "Zefan Li",
      "Shengbo Wang",
      "Giacomo Pedretti",
      "Jim Ignowski",
      "Can Li"
    ],
    "abstract": "Brain-inspired computing aims to mimic cognitive functions like associative\nmemory, the ability to recall complete patterns from partial cues. Memristor\ntechnology offers promising hardware for such neuromorphic systems due to its\npotential for efficient in-memory analog computing. Hopfield Neural Networks\n(HNNs) are a classic model for associative memory, but implementations on\nconventional hardware suffer from efficiency bottlenecks, while prior\nmemristor-based HNNs faced challenges with vulnerability to hardware defects\ndue to offline training, limited storage capacity, and difficulty processing\nanalog patterns. Here we introduce and experimentally demonstrate on integrated\nmemristor hardware a new hardware-adaptive learning algorithm for associative\nmemories that significantly improves defect tolerance and capacity, and\nnaturally extends to scalable multilayer architectures capable of handling both\nbinary and continuous patterns. Our approach achieves 3x effective capacity\nunder 50% device faults compared to state-of-the-art methods. Furthermore, its\nextension to multilayer architectures enables superlinear capacity scaling\n(\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous\npatterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling\nfor previous HNNs. It also provides flexibility to adjust capacity by tuning\nhidden neurons for the same-sized patterns. By leveraging the massive\nparallelism of the hardware enabled by synchronous updates, it reduces energy\nby 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous\nschemes, with greater improvements at scale. This promises the development of\nmore reliable memristor-based associative memory systems and enables new\napplications research due to the significantly improved capacity, efficiency,\nand flexibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12960v1",
    "published_date": "2025-05-19 10:55:09 UTC",
    "updated_date": "2025-05-19 10:55:09 UTC"
  },
  {
    "arxiv_id": "2505.13565v1",
    "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks",
    "authors": [
      "Oier Mentxaka",
      "Natalia Díaz-Rodríguez",
      "Mark Coeckelbergh",
      "Marcos López de Prado",
      "Emilia Gómez",
      "David Fernández Llorca",
      "Enrique Herrera-Viedma",
      "Francisco Herrera"
    ],
    "abstract": "Artificial Intelligence (AI) poses both significant risks and valuable\nopportunities for democratic governance. This paper introduces a dual taxonomy\nto evaluate AI's complex relationship with democracy: the AI Risks to Democracy\n(AIRD) taxonomy, which identifies how AI can undermine core democratic\nprinciples such as autonomy, fairness, and trust; and the AI's Positive\nContributions to Democracy (AIPD) taxonomy, which highlights AI's potential to\nenhance transparency, participation, efficiency, and evidence-based\npolicymaking.\n  Grounded in the European Union's approach to ethical AI governance, and\nparticularly the seven Trustworthy AI requirements proposed by the European\nCommission's High-Level Expert Group on AI, each identified risk is aligned\nwith mitigation strategies based on EU regulatory and normative frameworks. Our\nanalysis underscores the transversal importance of transparency and societal\nwell-being across all risk categories and offers a structured lens for aligning\nAI systems with democratic values.\n  By integrating democratic theory with practical governance tools, this paper\noffers a normative and actionable framework to guide research, regulation, and\ninstitutional design to support trustworthy, democratic AI. It provides\nscholars with a conceptual foundation to evaluate the democratic implications\nof AI, equips policymakers with structured criteria for ethical oversight, and\nhelps technologists align system design with democratic principles. In doing\nso, it bridges the gap between ethical aspirations and operational realities,\nlaying the groundwork for more inclusive, accountable, and resilient democratic\nsystems in the algorithmic age.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "26 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13565v1",
    "published_date": "2025-05-19 10:51:08 UTC",
    "updated_date": "2025-05-19 10:51:08 UTC"
  },
  {
    "arxiv_id": "2505.12951v1",
    "title": "DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management",
    "authors": [
      "Xuerui Su",
      "Liya Guo",
      "Yue Wang",
      "Yi Zhu",
      "Zhiming Ma",
      "Zun Wang",
      "Yuting Liu"
    ],
    "abstract": "Inference scaling further accelerates Large Language Models (LLMs) toward\nArtificial General Intelligence (AGI), with large-scale Reinforcement Learning\n(RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning\napproaches usually rely on handcrafted rule-based reward functions. However,\nthe tarde-offs of exploration and exploitation in RL algorithms involves\nmultiple complex considerations, and the theoretical and empirical impacts of\nmanually designed reward functions remain insufficiently explored. In this\npaper, we propose Decoupled Group Reward Optimization (DGRO), a general RL\nalgorithm for LLM reasoning. On the one hand, DGRO decouples the traditional\nregularization coefficient into two independent hyperparameters: one scales the\npolicy gradient term, and the other regulates the distance from the sampling\npolicy. This decoupling not only enables precise control over balancing\nexploration and exploitation, but also can be seamlessly extended to Online\nPolicy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward\nOptimization. On the other hand, we observe that reward variance significantly\naffects both convergence speed and final model performance. We conduct both\ntheoretical analysis and extensive empirical validation to assess DGRO,\nincluding a detailed ablation study that investigates its performance and\noptimization dynamics. Experimental results show that DGRO achieves\nstate-of-the-art performance on the Logic dataset with an average accuracy of\n96.9\\%, and demonstrates strong generalization across mathematical benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12951v1",
    "published_date": "2025-05-19 10:44:49 UTC",
    "updated_date": "2025-05-19 10:44:49 UTC"
  },
  {
    "arxiv_id": "2505.13563v1",
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "authors": [
      "Xiaohui Wang",
      "Peng Ye",
      "Chenyu Huang",
      "Shenghe Zheng",
      "Bo Zhang",
      "Wanli Ouyang",
      "Tao Chen"
    ],
    "abstract": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13563v1",
    "published_date": "2025-05-19 10:37:22 UTC",
    "updated_date": "2025-05-19 10:37:22 UTC"
  },
  {
    "arxiv_id": "2505.12944v1",
    "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs",
    "authors": [
      "Jan Hagnberger",
      "Daniel Musekamp",
      "Mathias Niepert"
    ],
    "abstract": "Solving time-dependent Partial Differential Equations (PDEs) using a densely\ndiscretized spatial domain is a fundamental problem in various scientific and\nengineering disciplines, including modeling climate phenomena and fluid\ndynamics. However, performing these computations directly in the physical space\noften incurs significant computational costs. To address this issue, several\nneural surrogate models have been developed that operate in a compressed latent\nspace to solve the PDE. While these approaches reduce computational complexity,\nthey often use Transformer-based attention mechanisms to handle irregularly\nsampled domains, resulting in increased memory consumption. In contrast,\nconvolutional neural networks allow memory-efficient encoding and decoding but\nare limited to regular discretizations. Motivated by these considerations, we\npropose CALM-PDE, a model class that efficiently solves arbitrarily discretized\nPDEs in a compressed latent space. We introduce a novel continuous\nconvolution-based encoder-decoder architecture that uses an\nepsilon-neighborhood-constrained kernel and learns to apply the convolution\noperator to adaptive and optimized query points. We demonstrate the\neffectiveness of CALM-PDE on a diverse set of PDEs with both regularly and\nirregularly sampled spatial domains. CALM-PDE is competitive with or\noutperforms existing baseline methods while offering significant improvements\nin memory and inference time efficiency compared to Transformer-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12944v1",
    "published_date": "2025-05-19 10:31:30 UTC",
    "updated_date": "2025-05-19 10:31:30 UTC"
  },
  {
    "arxiv_id": "2505.12942v1",
    "title": "A3 : an Analytical Low-Rank Approximation Framework for Attention",
    "authors": [
      "Jeffrey T. H. Wong",
      "Cheng Zhang",
      "Xinye Cao",
      "Pedro Gimenes",
      "George A. Constantinides",
      "Wayne Luk",
      "Yiren Zhao"
    ],
    "abstract": "Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12942v1",
    "published_date": "2025-05-19 10:29:32 UTC",
    "updated_date": "2025-05-19 10:29:32 UTC"
  },
  {
    "arxiv_id": "2505.12938v2",
    "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance",
    "authors": [
      "Uri Dalal",
      "Meirav Segal",
      "Zvika Ben-Haim",
      "Dan Lahav",
      "Omer Nevo"
    ],
    "abstract": "Large language models (LLMs) achieve impressive abilities in numerous\ndomains, but exhibit inconsistent performance in response to minor input\nchanges. Rather than view this as a drawback, in this paper we introduce a\nnovel method for leveraging models' inconsistency to boost Pass@k performance.\nSpecifically, we present a \"Variator\" agent that generates k variants of a\ngiven task and submits one candidate solution for each one. Our variant\ngeneration approach is applicable to a wide range of domains as it is task\nagnostic and compatible with free-form inputs. We demonstrate the efficacy of\nour agent theoretically using a probabilistic model of the inconsistency\neffect, and show empirically that it outperforms the baseline on the APPS\ndataset. Furthermore, we establish that inconsistency persists even in frontier\nreasoning models across coding and cybersecurity domains, suggesting our method\nis likely to remain relevant for future model generations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12938v2",
    "published_date": "2025-05-19 10:22:04 UTC",
    "updated_date": "2025-05-20 14:22:15 UTC"
  },
  {
    "arxiv_id": "2505.12929v1",
    "title": "Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs",
    "authors": [
      "Zhihe Yang",
      "Xufang Luo",
      "Zilong Wang",
      "Dongqi Han",
      "Zhiyuan He",
      "Dongsheng Li",
      "Yunjian Xu"
    ],
    "abstract": "Reinforcement learning (RL) has become a cornerstone for enhancing the\nreasoning capabilities of large language models (LLMs), with recent innovations\nsuch as Group Relative Policy Optimization (GRPO) demonstrating exceptional\neffectiveness. In this study, we identify a critical yet underexplored issue in\nRL training: low-probability tokens disproportionately influence model updates\ndue to their large gradient magnitudes. This dominance hinders the effective\nlearning of high-probability tokens, whose gradients are essential for LLMs'\nperformance but are substantially suppressed. To mitigate this interference, we\npropose two novel methods: Advantage Reweighting and Low-Probability Token\nIsolation (Lopti), both of which effectively attenuate gradients from\nlow-probability tokens while emphasizing parameter updates driven by\nhigh-probability tokens. Our approaches promote balanced updates across tokens\nwith varying probabilities, thereby enhancing the efficiency of RL training.\nExperimental results demonstrate that they substantially improve the\nperformance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&K\nLogic Puzzle reasoning tasks. Our implementation is available at\nhttps://github.com/zhyang2226/AR-Lopti.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12929v1",
    "published_date": "2025-05-19 10:14:08 UTC",
    "updated_date": "2025-05-19 10:14:08 UTC"
  },
  {
    "arxiv_id": "2505.12925v1",
    "title": "CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming",
    "authors": [
      "Han Deng",
      "Yuan Meng",
      "Shixiang Tang",
      "Wanli Ouyang",
      "Xinzhu Ma"
    ],
    "abstract": "Competitive programming benchmarks are widely used in scenarios such as\nprogramming contests and large language model assessments. However, the growing\npresence of duplicate or highly similar problems raises concerns not only about\ncompetition fairness, but also about the validity of competitive programming as\na benchmark for model evaluation. In this paper, we propose a new problem --\nsimilar question retrieval -- to address this issue. Due to the lack of both\ndata and models, solving this problem is challenging. To this end, we introduce\nCPRet, a retrieval-oriented benchmark suite for competitive programming,\ncovering four retrieval tasks: two code-centric (i.e., Text-to-Code and\nCode-to-Code) and two newly proposed problem-centric tasks (i.e.,\nProblem-to-Duplicate and Simplified-to-Full), built from a combination of\nautomatically crawled problem-solution data and manually curated annotations.\nOur contribution includes both high-quality training data and temporally\nseparated test sets for reliable evaluation. In addition, we develop two\ntask-specialized retrievers based on this dataset: CPRetriever-Code, trained\nwith a novel Group-InfoNCE loss for problem-code alignment, and\nCPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both\nmodels achieve strong results and are open-sourced for local use. Finally, we\nanalyze LiveCodeBench and find that high-similarity problems inflate model pass\nrates and reduce differentiation, underscoring the need for similarity-aware\nevaluation in future benchmarks.\n  Code and data are available at: https://github.com/coldchair/CPRet",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR",
      "H.3.3"
    ],
    "primary_category": "cs.SE",
    "comment": "main 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12925v1",
    "published_date": "2025-05-19 10:07:51 UTC",
    "updated_date": "2025-05-19 10:07:51 UTC"
  },
  {
    "arxiv_id": "2505.13562v1",
    "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback",
    "authors": [
      "Shishen Lin"
    ],
    "abstract": "Learning in games is a fundamental problem in machine learning and artificial\nintelligence, with numerous\napplications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work\ninvestigates two-player zero-sum matrix games with an unknown payoff matrix and\nbandit feedback, where each player observes their actions and the corresponding\nnoisy payoff. Prior studies have proposed algorithms for this\nsetting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with\n\\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism\n(e.g., \\ucb) in achieving sublinear regret. However, the potential of\nrandomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel\nalgorithm that integrates evolutionary algorithms (EAs) into the bandit\nframework to implement randomised optimism through EA variation operators. We\nprove that \\coebl achieves sublinear regret, matching the performance of\ndeterministic optimism-based methods. To the best of our knowledge, this is the\nfirst theoretical regret analysis of an evolutionary bandit learning algorithm\nin matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that\n\\coebl not only achieves sublinear regret but also consistently outperforms\nclassical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic},\nthe variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}.\nThese results highlight the potential of evolutionary bandit learning,\nparticularly the efficacy of randomised optimism via evolutionary algorithms in\ngame-theoretic settings.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "stat.ML",
    "comment": "21 pages, 10 figures, accepted at IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13562v1",
    "published_date": "2025-05-19 10:05:55 UTC",
    "updated_date": "2025-05-19 10:05:55 UTC"
  },
  {
    "arxiv_id": "2505.12923v1",
    "title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations",
    "authors": [
      "Pedro M. P. Curvo"
    ],
    "abstract": "As AI systems increasingly assume roles where trust and alignment with human\nvalues are essential, understanding when and why they engage in deception has\nbecome a critical research priority. We introduce The Traitors, a multi-agent\nsimulation framework inspired by social deduction games, designed to probe\ndeception, trust formation, and strategic communication among large language\nmodel (LLM) agents under asymmetric information. A minority of agents the\ntraitors seek to mislead the majority, while the faithful must infer hidden\nidentities through dialogue and reasoning. Our contributions are: (1) we ground\nthe environment in formal frameworks from game theory, behavioral economics,\nand social cognition; (2) we develop a suite of evaluation metrics capturing\ndeception success, trust dynamics, and collective inference quality; (3) we\nimplement a fully autonomous simulation platform where LLMs reason over\npersistent memory and evolving social dynamics, with support for heterogeneous\nagent populations, specialized traits, and adaptive behaviors. Our initial\nexperiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model)\nreveal a notable asymmetry: advanced models like GPT-4o demonstrate superior\ndeceptive capabilities yet exhibit disproportionate vulnerability to others'\nfalsehoods. This suggests deception skills may scale faster than detection\nabilities. Overall, The Traitors provides a focused, configurable testbed for\ninvestigating LLM behavior in socially nuanced interactions. We position this\nwork as a contribution toward more rigorous research on deception mechanisms,\nalignment challenges, and the broader social reliability of AI systems.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "9 main pages, 31 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12923v1",
    "published_date": "2025-05-19 10:01:35 UTC",
    "updated_date": "2025-05-19 10:01:35 UTC"
  },
  {
    "arxiv_id": "2505.12920v1",
    "title": "PyFCG: Fluid Construction Grammar in Python",
    "authors": [
      "Paul Van Eecke",
      "Katrien Beuls"
    ],
    "abstract": "We present PyFCG, an open source software library that ports Fluid\nConstruction Grammar (FCG) to the Python programming language. PyFCG enables\nits users to seamlessly integrate FCG functionality into Python programs, and\nto use FCG in combination with other libraries within Python's rich ecosystem.\nApart from a general description of the library, this paper provides three\nwalkthrough tutorials that demonstrate example usage of PyFCG in typical use\ncases of FCG: (i) formalising and testing construction grammar analyses, (ii)\nlearning usage-based construction grammars from corpora, and (iii) implementing\nagent-based experiments on emergent communication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12920v1",
    "published_date": "2025-05-19 10:00:01 UTC",
    "updated_date": "2025-05-19 10:00:01 UTC"
  },
  {
    "arxiv_id": "2505.14718v1",
    "title": "Enhancing Shape Perception and Segmentation Consistency for Industrial Image Inspection",
    "authors": [
      "Guoxuan Mao",
      "Ting Cao",
      "Ziyang Li",
      "Yuan Dong"
    ],
    "abstract": "Semantic segmentation stands as a pivotal research focus in computer vision.\nIn the context of industrial image inspection, conventional semantic\nsegmentation models fail to maintain the segmentation consistency of fixed\ncomponents across varying contextual environments due to a lack of perception\nof object contours. Given the real-time constraints and limited computing\ncapability of industrial image detection machines, it is also necessary to\ncreate efficient models to reduce computational complexity. In this work, a\nShape-Aware Efficient Network (SPENet) is proposed, which focuses on the shapes\nof objects to achieve excellent segmentation consistency by separately\nsupervising the extraction of boundary and body information from images. In\nSPENet, a novel method is introduced for describing fuzzy boundaries to better\nadapt to real-world scenarios named Variable Boundary Domain (VBD).\nAdditionally, a new metric, Consistency Mean Square Error(CMSE), is proposed to\nmeasure segmentation consistency for fixed components. Our approach attains the\nbest segmentation accuracy and competitive speed on our dataset, showcasing\nsignificant advantages in CMSE among numerous state-of-the-art real-time\nsegmentation networks, achieving a reduction of over 50% compared to the\npreviously top-performing models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.14718v1",
    "published_date": "2025-05-19 09:57:00 UTC",
    "updated_date": "2025-05-19 09:57:00 UTC"
  },
  {
    "arxiv_id": "2505.12910v1",
    "title": "SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Chao Gao",
      "Zhen Wang",
      "Keke Tang"
    ],
    "abstract": "Source detection on graphs has demonstrated high efficacy in identifying\nrumor origins. Despite advances in machine learning-based methods, many fail to\ncapture intrinsic dynamics of rumor propagation. In this work, we present\nSourceDetMamba: A Graph-aware State Space Model for Source Detection in\nSequential Hypergraphs, which harnesses the recent success of the state space\nmodel Mamba, known for its superior global modeling capabilities and\ncomputational efficiency, to address this challenge. Specifically, we first\nemploy hypergraphs to model high-order interactions within social networks.\nSubsequently, temporal network snapshots generated during the propagation\nprocess are sequentially fed in reverse order into Mamba to infer underlying\npropagation dynamics. Finally, to empower the sequential model to effectively\ncapture propagation patterns while integrating structural information, we\npropose a novel graph-aware state update mechanism, wherein the state of each\nnode is propagated and refined by both temporal dependencies and topological\ncontext. Extensive evaluations on eight datasets demonstrate that\nSourceDetMamba consistently outperforms state-of-the-art approaches.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by IJCAI25",
    "pdf_url": "http://arxiv.org/pdf/2505.12910v1",
    "published_date": "2025-05-19 09:45:27 UTC",
    "updated_date": "2025-05-19 09:45:27 UTC"
  },
  {
    "arxiv_id": "2505.12909v2",
    "title": "Sinusoidal Initialization, Time for a New Start",
    "authors": [
      "Alberto Fernández-Hernández",
      "Jose I. Mestre",
      "Manuel F. Dolz",
      "Jose Duato",
      "Enrique S. Quintana-Ortí"
    ],
    "abstract": "Initialization plays a critical role in Deep Neural Network training,\ndirectly influencing convergence, stability, and generalization. Common\napproaches such as Glorot and He initializations rely on randomness, which can\nproduce uneven weight distributions across layer connections. In this paper, we\nintroduce the Sinusoidal initialization, a novel deterministic method that\nemploys sinusoidal functions to construct structured weight matrices expressly\nto improve the spread and balance of weights throughout the network while\nsimultaneously fostering a more uniform, well-conditioned distribution of\nneuron activation states from the very first forward pass. Because Sinusoidal\ninitialization begins with weights and activations that are already evenly and\nefficiently utilized, it delivers consistently faster convergence, greater\ntraining stability, and higher final accuracy across a wide range of models,\nincluding convolutional neural networks, vision transformers, and large\nlanguage models. On average, our experiments show an increase of 4.9% in final\nvalidation accuracy and 20.9% in convergence speed. By replacing randomness\nwith structure, this initialization provides a stronger and more reliable\nfoundation for Deep Learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2; G.3; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12909v2",
    "published_date": "2025-05-19 09:45:18 UTC",
    "updated_date": "2025-05-20 15:54:36 UTC"
  },
  {
    "arxiv_id": "2505.12908v1",
    "title": "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection",
    "authors": [
      "Xiao Wang",
      "Yu Jin",
      "Lan Chen",
      "Bo Jiang",
      "Lin Zhu",
      "Yonghong Tian",
      "Jin Tang",
      "Bin Luo"
    ],
    "abstract": "Event-based Vision Sensors (EVS) have demonstrated significant advantages\nover traditional RGB frame-based cameras in low-light conditions, high-speed\nmotion capture, and low latency. Consequently, object detection based on EVS\nhas attracted increasing attention from researchers. Current event stream\nobject detection algorithms are typically built upon Convolutional Neural\nNetworks (CNNs) or Transformers, which either capture limited local features\nusing convolutional filters or incur high computational costs due to the\nutilization of self-attention. Recently proposed vision heat conduction\nbackbone networks have shown a good balance between efficiency and accuracy;\nhowever, these models are not specifically designed for event stream data. They\nexhibit weak capability in modeling object contour information and fail to\nexploit the benefits of multi-scale features. To address these issues, this\npaper proposes a novel dynamic graph induced contour-aware heat conduction\nnetwork for event stream based object detection, termed CvHeat-DET. The\nproposed model effectively leverages the clear contour information inherent in\nevent streams to predict the thermal diffusivity coefficients within the heat\nconduction model, and integrates hierarchical structural graph features to\nenhance feature learning across multiple scales. Extensive experiments on three\nbenchmark datasets for event stream-based object detection fully validated the\neffectiveness of the proposed model. The source code of this paper will be\nreleased on https://github.com/Event-AHU/OpenEvDET.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12908v1",
    "published_date": "2025-05-19 09:44:01 UTC",
    "updated_date": "2025-05-19 09:44:01 UTC"
  },
  {
    "arxiv_id": "2505.12904v1",
    "title": "The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning",
    "authors": [
      "Hilde I. Hummel",
      "Arwin Gansekoele",
      "Sandjai Bhulai",
      "Rob van der Mei"
    ],
    "abstract": "The increasing level of sound pollution in marine environments poses an\nincreased threat to ocean health, making it crucial to monitor underwater\nnoise. By monitoring this noise, the sources responsible for this pollution can\nbe mapped. Monitoring is performed by passively listening to these sounds. This\ngenerates a large amount of data records, capturing a mix of sound sources such\nas ship activities and marine mammal vocalizations. Although machine learning\noffers a promising solution for automatic sound classification, current\nstate-of-the-art methods implement supervised learning. This requires a large\namount of high-quality labeled data that is not publicly available. In\ncontrast, a massive amount of lower-quality unlabeled data is publicly\navailable, offering the opportunity to explore unsupervised learning\ntechniques. This research explores this possibility by implementing an\nunsupervised Contrastive Learning approach. Here, a Conformer-based encoder is\noptimized by the so-called Variance-Invariance-Covariance Regularization loss\nfunction on these lower-quality unlabeled data and the translation to the\nlabeled data is made. Through classification tasks involving recognizing ship\ntypes and marine mammal vocalizations, our method demonstrates to produce\nrobust and generalized embeddings. This shows to potential of unsupervised\nmethods for various automatic underwater acoustic analysis tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12904v1",
    "published_date": "2025-05-19 09:37:46 UTC",
    "updated_date": "2025-05-19 09:37:46 UTC"
  },
  {
    "arxiv_id": "2505.12903v1",
    "title": "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach",
    "authors": [
      "Shiao Wang",
      "Xiao Wang",
      "Liye Jin",
      "Bo Jiang",
      "Lin Zhu",
      "Lan Chen",
      "Yonghong Tian",
      "Bin Luo"
    ],
    "abstract": "Existing tracking algorithms typically rely on low-frame-rate RGB cameras\ncoupled with computationally intensive deep neural network architectures to\nachieve effective tracking. However, such frame-based methods inherently face\nchallenges in achieving low-latency performance and often fail in\nresource-constrained environments. Visual object tracking using bio-inspired\nevent cameras has emerged as a promising research direction in recent years,\noffering distinct advantages for low-latency applications. In this paper, we\npropose a novel Slow-Fast Tracking paradigm that flexibly adapts to different\noperational requirements, termed SFTrack. The proposed framework supports two\ncomplementary modes, i.e., a high-precision slow tracker for scenarios with\nsufficient computational resources, and an efficient fast tracker tailored for\nlatency-aware, resource-constrained environments. Specifically, our framework\nfirst performs graph-based representation learning from\nhigh-temporal-resolution event streams, and then integrates the learned\ngraph-structured information into two FlashAttention-based vision backbones,\nyielding the slow and fast trackers, respectively. The fast tracker achieves\nlow latency through a lightweight network design and by producing multiple\nbounding box outputs in a single forward pass. Finally, we seamlessly combine\nboth trackers via supervised fine-tuning and further enhance the fast tracker's\nperformance through a knowledge distillation strategy. Extensive experiments on\npublic benchmarks, including FE240, COESOT, and EventVOT, demonstrate the\neffectiveness and efficiency of our proposed method across different real-world\nscenarios. The source code has been released on\nhttps://github.com/Event-AHU/SlowFast_Event_Track.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12903v1",
    "published_date": "2025-05-19 09:37:23 UTC",
    "updated_date": "2025-05-19 09:37:23 UTC"
  },
  {
    "arxiv_id": "2505.12900v1",
    "title": "AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models",
    "authors": [
      "Shuyang Hou",
      "Zhangxiao Shen",
      "Huayi Wu",
      "Jianyuan Liang",
      "Haoyue Jiao",
      "Yaxian Qing",
      "Xiaopu Zhang",
      "Xu Li",
      "Zhipeng Gui",
      "Xuefeng Guan",
      "Longgang Xiang"
    ],
    "abstract": "Geospatial code generation is emerging as a key direction in the integration\nof artificial intelligence and geoscientific analysis. However, there remains a\nlack of standardized tools for automatic evaluation in this domain. To address\nthis gap, we propose AutoGEEval, the first multimodal, unit-level automated\nevaluation framework for geospatial code generation tasks on the Google Earth\nEngine (GEE) platform powered by large language models (LLMs). Built upon the\nGEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench)\ncomprising 1325 test cases that span 26 GEE data types. The framework\nintegrates both question generation and answer verification components to\nenable an end-to-end automated evaluation pipeline-from function invocation to\nexecution validation. AutoGEEval supports multidimensional quantitative\nanalysis of model outputs in terms of accuracy, resource consumption, execution\nefficiency, and error types. We evaluate 18 state-of-the-art LLMs-including\ngeneral-purpose, reasoning-augmented, code-centric, and geoscience-specialized\nmodels-revealing their performance characteristics and potential optimization\npathways in GEE code generation. This work provides a unified protocol and\nfoundational resource for the development and assessment of geospatial code\ngeneration models, advancing the frontier of automated natural language to\ndomain-specific code translation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CG",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12900v1",
    "published_date": "2025-05-19 09:35:58 UTC",
    "updated_date": "2025-05-19 09:35:58 UTC"
  },
  {
    "arxiv_id": "2505.14717v1",
    "title": "Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
    "authors": [
      "Xigui Li",
      "Yuanye Zhou",
      "Feiyang Xiao",
      "Xin Guo",
      "Chen Jiang",
      "Tan Pan",
      "Xingmeng Zhang",
      "Cenyu Liu",
      "Zeyun Miao",
      "Jianchao Ge",
      "Xiansheng Wang",
      "Qimeng Wang",
      "Yichi Zhang",
      "Wenbo Zhang",
      "Fengping Zhu",
      "Limei Han",
      "Yuan Qi",
      "Chensen Lin",
      "Yuan Cheng"
    ],
    "abstract": "Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in\napproximately 5\\% of the general population. Their rupture may lead to high\nmortality. Current methods for assessing IA risk focus on morphological and\npatient-specific factors, but the hemodynamic influences on IA development and\nrupture remain unclear. While accurate for hemodynamic studies, conventional\ncomputational fluid dynamics (CFD) methods are computationally intensive,\nhindering their deployment in large-scale or real-time clinical applications.\nTo address this challenge, we curated a large-scale, high-fidelity aneurysm CFD\ndataset to facilitate the development of efficient machine learning algorithms\nfor such applications. Based on 427 real aneurysm geometries, we synthesized\n10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The\nauthenticity of these synthetic shapes was confirmed by neurosurgeons. CFD\ncomputations were performed on each shape under eight steady-state mass flow\nconditions, generating a total of 85,280 blood flow dynamics data covering key\nparameters. Furthermore, the dataset includes segmentation masks, which can\nsupport tasks that use images, point clouds or other multimodal data as input.\nAdditionally, we introduced a benchmark for estimating flow parameters to\nassess current modeling methods. This dataset aims to advance aneurysm research\nand promote data-driven approaches in biofluids, biomedical engineering, and\nclinical risk assessment. The code and dataset are available at:\nhttps://github.com/Xigui-Li/Aneumo.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.14717v1",
    "published_date": "2025-05-19 09:32:09 UTC",
    "updated_date": "2025-05-19 09:32:09 UTC"
  },
  {
    "arxiv_id": "2505.13561v1",
    "title": "Language and Thought: The View from LLMs",
    "authors": [
      "Daniel Rothschild"
    ],
    "abstract": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "37 Pages",
    "pdf_url": "http://arxiv.org/pdf/2505.13561v1",
    "published_date": "2025-05-19 09:29:32 UTC",
    "updated_date": "2025-05-19 09:29:32 UTC"
  },
  {
    "arxiv_id": "2505.12894v1",
    "title": "HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Yangming Guo",
      "Keke Tang",
      "Chao Gao",
      "Zhen Wang"
    ],
    "abstract": "Hypergraphs offer superior modeling capabilities for social networks,\nparticularly in capturing group phenomena that extend beyond pairwise\ninteractions in rumor propagation. Existing approaches in rumor source\ndetection predominantly focus on dyadic interactions, which inadequately\naddress the complexity of more intricate relational structures. In this study,\nwe present a novel approach for Source Detection in Hypergraphs (HyperDet) via\nInteractive Relationship Construction and Feature-rich Attention Fusion.\nSpecifically, our methodology employs an Interactive Relationship Construction\nmodule to accurately model both the static topology and dynamic interactions\namong users, followed by the Feature-rich Attention Fusion module, which\nautonomously learns node features and discriminates between nodes using a\nself-attention mechanism, thereby effectively learning node representations\nunder the framework of accurately modeled higher-order relationships. Extensive\nexperimental validation confirms the efficacy of our HyperDet approach,\nshowcasing its superiority relative to current state-of-the-art methods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by IJCAI25",
    "pdf_url": "http://arxiv.org/pdf/2505.12894v1",
    "published_date": "2025-05-19 09:27:46 UTC",
    "updated_date": "2025-05-19 09:27:46 UTC"
  },
  {
    "arxiv_id": "2505.12891v1",
    "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios",
    "authors": [
      "Shaohang Wei",
      "Wei Li",
      "Feifan Song",
      "Wen Luo",
      "Tianyi Zhuang",
      "Haochen Tan",
      "Zhijiang Guo",
      "Houfeng Wang"
    ],
    "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , and the dataset is available\nat https://huggingface.co/datasets/SylvainWei/TIME .",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "First version. There are still some examples to be added into the\n  appendix",
    "pdf_url": "http://arxiv.org/pdf/2505.12891v1",
    "published_date": "2025-05-19 09:22:02 UTC",
    "updated_date": "2025-05-19 09:22:02 UTC"
  },
  {
    "arxiv_id": "2505.12886v1",
    "title": "Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective",
    "authors": [
      "Zhongxiang Sun",
      "Qipeng Wang",
      "Haoyu Wang",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Large Reasoning Models (LRMs) have shown impressive capabilities in\nmulti-step reasoning tasks. However, alongside these successes, a more\ndeceptive form of model error has emerged--Reasoning Hallucination--where\nlogically coherent but factually incorrect reasoning traces lead to persuasive\nyet faulty conclusions. Unlike traditional hallucinations, these errors are\nembedded within structured reasoning, making them more difficult to detect and\npotentially more harmful. In this work, we investigate reasoning hallucinations\nfrom a mechanistic perspective. We propose the Reasoning Score, which\nquantifies the depth of reasoning by measuring the divergence between logits\nobtained from projecting late layers of LRMs to the vocabulary space,\neffectively distinguishing shallow pattern-matching from genuine deep\nreasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA\ndataset and identify two key reasoning hallucination patterns: early-stage\nfluctuation in reasoning depth and incorrect backtracking to flawed prior\nsteps. These insights motivate our Reasoning Hallucination Detection (RHD)\nframework, which achieves state-of-the-art performance across multiple domains.\nTo mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced\nreinforcement learning algorithm that incorporates step-level deep reasoning\nrewards via potential-based shaping. Our theoretical analysis establishes\nstronger generalization guarantees, and experiments demonstrate improved\nreasoning quality and reduced hallucination rates.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12886v1",
    "published_date": "2025-05-19 09:16:40 UTC",
    "updated_date": "2025-05-19 09:16:40 UTC"
  },
  {
    "arxiv_id": "2505.12884v1",
    "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
    "authors": [
      "Yuanze Hu",
      "Zhaoxin Fan",
      "Xinyu Wang",
      "Gen Li",
      "Ye Qiu",
      "Zhichao Yang",
      "Wenjun Wu",
      "Kejian Wu",
      "Yifan Sun",
      "Xiaotie Deng",
      "Jin Dong"
    ],
    "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for\nresource-constrained applications. The prevailing approach to aligning vision\nand language models involves freezing both the vision encoder and the language\nmodel while training small connector modules. However, this strategy heavily\ndepends on the intrinsic capabilities of the language model, which can be\nsuboptimal for lightweight models with limited representational capacity. In\nthis work, we investigate this alignment bottleneck through the lens of mutual\ninformation, demonstrating that the constrained capacity of the language model\ninherently limits the Effective Mutual Information (EMI) between multimodal\ninputs and outputs, thereby compromising alignment quality. To address this\nchallenge, we propose TinyAlign, a novel framework inspired by\nRetrieval-Augmented Generation, which strategically retrieves relevant context\nfrom a memory bank to enrich multimodal inputs and enhance their alignment.\nExtensive empirical evaluations reveal that TinyAlign significantly reduces\ntraining loss, accelerates convergence, and enhances task performance.\nRemarkably, it allows models to achieve baseline-level performance with only\n40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our\nwork thus offers a practical pathway for developing more capable lightweight\nVLMs while introducing a fresh theoretical lens to better understand and\naddress alignment bottlenecks in constrained multimodal systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12884v1",
    "published_date": "2025-05-19 09:11:54 UTC",
    "updated_date": "2025-05-19 09:11:54 UTC"
  },
  {
    "arxiv_id": "2505.12882v1",
    "title": "PhyDA: Physics-Guided Diffusion Models for Data Assimilation in Atmospheric Systems",
    "authors": [
      "Hao Wang",
      "Jindong Han",
      "Wei Fan",
      "Weijia Zhang",
      "Hao Liu"
    ],
    "abstract": "Data Assimilation (DA) plays a critical role in atmospheric science by\nreconstructing spatially continous estimates of the system state, which serves\nas initial conditions for scientific analysis. While recent advances in\ndiffusion models have shown great potential for DA tasks, most existing\napproaches remain purely data-driven and often overlook the physical laws that\ngovern complex atmospheric dynamics. As a result, they may yield physically\ninconsistent reconstructions that impair downstream applications. To overcome\nthis limitation, we propose PhyDA, a physics-guided diffusion framework\ndesigned to ensure physical coherence in atmospheric data assimilation. PhyDA\nintroduces two key components: (1) a Physically Regularized Diffusion Objective\nthat integrates physical constraints into the training process by penalizing\ndeviations from known physical laws expressed as partial differential\nequations, and (2) a Virtual Reconstruction Encoder that bridges observational\nsparsity for structured latent representations, further enhancing the model's\nability to infer complete and physically coherent states. Experiments on the\nERA5 reanalysis dataset demonstrate that PhyDA achieves superior accuracy and\nbetter physical plausibility compared to state-of-the-art baselines. Our\nresults emphasize the importance of combining generative modeling with\ndomain-specific physical knowledge and show that PhyDA offers a promising\ndirection for improving real-world data assimilation systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12882v1",
    "published_date": "2025-05-19 09:10:55 UTC",
    "updated_date": "2025-05-19 09:10:55 UTC"
  },
  {
    "arxiv_id": "2505.12880v1",
    "title": "AdS-GNN -- a Conformally Equivariant Graph Neural Network",
    "authors": [
      "Maksim Zhdanov",
      "Nabil Iqbal",
      "Erik Bekkers",
      "Patrick Forré"
    ],
    "abstract": "Conformal symmetries, i.e.\\ coordinate transformations that preserve angles,\nplay a key role in many fields, including physics, mathematics, computer vision\nand (geometric) machine learning. Here we build a neural network that is\nequivariant under general conformal transformations. To achieve this, we lift\ndata from flat Euclidean space to Anti de Sitter (AdS) space. This allows us to\nexploit a known correspondence between conformal transformations of flat space\nand isometric transformations on the AdS space. We then build upon the fact\nthat such isometric transformations have been extensively studied on general\ngeometries in the geometric deep learning literature. We employ message-passing\nlayers conditioned on the proper distance, yielding a computationally efficient\nframework. We validate our model on tasks from computer vision and statistical\nphysics, demonstrating strong performance, improved generalization capacities,\nand the ability to extract conformal data such as scaling dimensions from the\ntrained network.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12880v1",
    "published_date": "2025-05-19 09:08:52 UTC",
    "updated_date": "2025-05-19 09:08:52 UTC"
  },
  {
    "arxiv_id": "2505.13557v1",
    "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems",
    "authors": [
      "Davide Bruni",
      "Marco Avvenuti",
      "Nicola Tonellotto",
      "Maurizio Tesconi"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems are widely used in\nquestion-answering (QA) tasks, but current benchmarks lack metadata\nintegration, hindering evaluation in scenarios requiring both textual data and\nexternal information. To address this, we present AMAQA, a new open-access QA\ndataset designed to evaluate tasks combining text and metadata. The integration\nof metadata is especially important in fields that require rapid analysis of\nlarge volumes of data, such as cybersecurity and intelligence, where timely\naccess to relevant information is critical. AMAQA includes about 1.1 million\nEnglish messages collected from 26 public Telegram groups, enriched with\nmetadata such as timestamps, topics, emotional tones, and toxicity indicators,\nwhich enable precise and contextualized queries by filtering documents based on\nspecific criteria. It also includes 450 high-quality QA pairs, making it a\nvaluable resource for advancing research on metadata-driven QA and RAG systems.\nTo the best of our knowledge, AMAQA is the first single-hop QA benchmark to\nincorporate metadata and labels such as topics covered in the messages. We\nconduct extensive tests on the benchmark, establishing a new standard for\nfuture research. We show that leveraging metadata boosts accuracy from 0.12 to\n0.61, highlighting the value of structured context. Building on this, we\nexplore several strategies to refine the LLM input by iterating over provided\ncontext and enriching it with noisy documents, achieving a further 3-point gain\nover the best baseline and a 14-point improvement over simple metadata\nfiltering. The dataset is available at\nhttps://anonymous.4open.science/r/AMAQA-5D0D/",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13557v1",
    "published_date": "2025-05-19 08:59:08 UTC",
    "updated_date": "2025-05-19 08:59:08 UTC"
  },
  {
    "arxiv_id": "2505.12872v1",
    "title": "From Grunts to Grammar: Emergent Language from Cooperative Foraging",
    "authors": [
      "Maytus Piriyajitakonkij",
      "Rujikorn Charakorn",
      "Weicheng Tao",
      "Wei Pan",
      "Mingfei Sun",
      "Cheston Tan",
      "Mengmi Zhang"
    ],
    "abstract": "Early cavemen relied on gestures, vocalizations, and simple signals to\ncoordinate, plan, avoid predators, and share resources. Today, humans\ncollaborate using complex languages to achieve remarkable results. What drives\nthis evolution in communication? How does language emerge, adapt, and become\nvital for teamwork? Understanding the origins of language remains a challenge.\nA leading hypothesis in linguistics and anthropology posits that language\nevolved to meet the ecological and social demands of early human cooperation.\nLanguage did not arise in isolation, but through shared survival goals.\nInspired by this view, we investigate the emergence of language in multi-agent\nForaging Games. These environments are designed to reflect the cognitive and\necological constraints believed to have influenced the evolution of\ncommunication. Agents operate in a shared grid world with only partial\nknowledge about other agents and the environment, and must coordinate to\ncomplete games like picking up high-value targets or executing temporally\nordered actions. Using end-to-end deep reinforcement learning, agents learn\nboth actions and communication strategies from scratch. We find that agents\ndevelop communication protocols with hallmark features of natural language:\narbitrariness, interchangeability, displacement, cultural transmission, and\ncompositionality. We quantify each property and analyze how different factors,\nsuch as population size and temporal dependencies, shape specific aspects of\nthe emergent language. Our framework serves as a platform for studying how\nlanguage can evolve from partial observability, temporal reasoning, and\ncooperative goals in embodied multi-agent settings. We will release all data,\ncode, and models publicly.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12872v1",
    "published_date": "2025-05-19 08:57:30 UTC",
    "updated_date": "2025-05-19 08:57:30 UTC"
  },
  {
    "arxiv_id": "2505.12871v1",
    "title": "Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?",
    "authors": [
      "Zi Liang",
      "Haibo Hu",
      "Qingqing Ye",
      "Yaxin Xiao",
      "Ronghua Li"
    ],
    "abstract": "Low rank adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large language models (LLMs) thanks to its superb efficiency gains\nover previous methods. While extensive studies have examined the performance\nand structural properties of LoRA, its behavior upon training-time attacks\nremain underexplored, posing significant security risks. In this paper, we\ntheoretically investigate the security implications of LoRA's low-rank\nstructure during fine-tuning, in the context of its robustness against data\npoisoning and backdoor attacks. We propose an analytical framework that models\nLoRA's training dynamics, employs the neural tangent kernel to simplify the\nanalysis of the training process, and applies information theory to establish\nconnections between LoRA's low rank structure and its vulnerability against\ntraining-time attacks. Our analysis indicates that LoRA exhibits better\nrobustness to backdoor attacks than full fine-tuning, while becomes more\nvulnerable to untargeted data poisoning due to its over-simplified information\ngeometry. Extensive experimental evaluations have corroborated our theoretical\nfindings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at ICML 25",
    "pdf_url": "http://arxiv.org/pdf/2505.12871v1",
    "published_date": "2025-05-19 08:57:08 UTC",
    "updated_date": "2025-05-19 08:57:08 UTC"
  },
  {
    "arxiv_id": "2505.12869v1",
    "title": "Outsourced Privacy-Preserving Feature Selection Based on Fully Homomorphic Encryption",
    "authors": [
      "Koki Wakiyama",
      "Tomohiro I",
      "Hiroshi Sakamoto"
    ],
    "abstract": "Feature selection is a technique that extracts a meaningful subset from a set\nof features in training data. When the training data is large-scale,\nappropriate feature selection enables the removal of redundant features, which\ncan improve generalization performance, accelerate the training process, and\nenhance the interpretability of the model. This study proposes a\nprivacy-preserving computation model for feature selection. Generally, when the\ndata owner and analyst are the same, there is no need to conceal the private\ninformation. However, when they are different parties or when multiple owners\nexist, an appropriate privacy-preserving framework is required. Although\nvarious private feature selection algorithms, they all require two or more\ncomputing parties and do not guarantee security in environments where no\nexternal party can be fully trusted. To address this issue, we propose the\nfirst outsourcing algorithm for feature selection using fully homomorphic\nencryption. Compared to a prior two-party algorithm, our result improves the\ntime and space complexity O(kn^2) to O(kn log^3 n) and O(kn), where k and n\ndenote the number of features and data samples, respectively. We also\nimplemented the proposed algorithm and conducted comparative experiments with\nthe naive one. The experimental result shows the efficiency of our method even\nwith small datasets.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12869v1",
    "published_date": "2025-05-19 08:55:56 UTC",
    "updated_date": "2025-05-19 08:55:56 UTC"
  },
  {
    "arxiv_id": "2505.12864v1",
    "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams",
    "authors": [
      "Yu Fan",
      "Jingwei Ni",
      "Jakob Merane",
      "Etienne Salimbeni",
      "Yang Tian",
      "Yoan Hermstrüwer",
      "Yinya Huang",
      "Mubashara Akhtar",
      "Florian Geering",
      "Oliver Dreyer",
      "Daniel Brunner",
      "Markus Leippold",
      "Mrinmaya Sachan",
      "Alexander Stremitzer",
      "Christoph Engel",
      "Elliott Ash",
      "Joel Niklaus"
    ],
    "abstract": "Long-form legal reasoning remains a key challenge for large language models\n(LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a\nnovel benchmark derived from 340 law exams spanning 116 law school courses\nacross a range of subjects and degree levels. The dataset comprises 4,886 law\nexam questions in English and German, including 2,841 long-form, open-ended\nquestions and 2,045 multiple-choice questions. Besides reference answers, the\nopen questions are also accompanied by explicit guidance outlining the expected\nlegal reasoning approach such as issue spotting, rule recall, or rule\napplication. Our evaluation on both open-ended and multiple-choice questions\npresent significant challenges for current LLMs; in particular, they notably\nstruggle with open questions that require structured, multi-step legal\nreasoning. Moreover, our results underscore the effectiveness of the dataset in\ndifferentiating between models with varying capabilities. Adopting an\nLLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate\nhow model-generated reasoning steps can be evaluated consistently and\naccurately. Our evaluation setup provides a scalable method to assess legal\nreasoning quality beyond simple accuracy metrics. Project page:\nhttps://lexam-benchmark.github.io/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12864v1",
    "published_date": "2025-05-19 08:48:12 UTC",
    "updated_date": "2025-05-19 08:48:12 UTC"
  },
  {
    "arxiv_id": "2505.12863v1",
    "title": "Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio",
    "authors": [
      "Jongmin Jung",
      "Dongmin Kim",
      "Sihun Lee",
      "Seola Cho",
      "Hyungjoon Soh",
      "Irmak Bukey",
      "Chris Donahue",
      "Dasaem Jeong"
    ],
    "abstract": "Music exists in various modalities, such as score images, symbolic scores,\nMIDI, and audio. Translations between each modality are established as core\ntasks of music information retrieval, such as automatic music transcription\n(audio-to-MIDI) and optical music recognition (score image to symbolic score).\nHowever, most past work on multimodal translation trains specialized models on\nindividual translation tasks. In this paper, we propose a unified approach,\nwhere we train a general-purpose model on many translation tasks\nsimultaneously. Two key factors make this unified approach viable: a new\nlarge-scale dataset and the tokenization of each modality. Firstly, we propose\na new dataset that consists of more than 1,300 hours of paired audio-score\nimage data collected from YouTube videos, which is an order of magnitude larger\nthan any existing music modal translation datasets. Secondly, our unified\ntokenization framework discretizes score images, audio, MIDI, and MusicXML into\na sequence of tokens, enabling a single encoder-decoder Transformer to tackle\nmultiple cross-modal translation as one coherent sequence-to-sequence task.\nExperimental results confirm that our unified multitask model improves upon\nsingle-task baselines in several key areas, notably reducing the symbol error\nrate for optical music recognition from 24.58% to a state-of-the-art 13.67%,\nwhile similarly substantial improvements are observed across the other\ntranslation tasks. Notably, our approach achieves the first successful\nscore-image-conditioned audio generation, marking a significant breakthrough in\ncross-modal music generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to IEEE Transactions on Audio, Speech and Language\n  Processing (TASLPRO)",
    "pdf_url": "http://arxiv.org/pdf/2505.12863v1",
    "published_date": "2025-05-19 08:46:45 UTC",
    "updated_date": "2025-05-19 08:46:45 UTC"
  },
  {
    "arxiv_id": "2505.12851v1",
    "title": "FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting",
    "authors": [
      "Yanhua Wen",
      "Lu Ai",
      "Gang Liu",
      "Chuang Li",
      "Jianhao Wei"
    ],
    "abstract": "Byzantine attacks during model aggregation in Federated Learning (FL)\nthreaten training integrity by manipulating malicious clients' updates.\nExisting methods struggle with limited robustness under high malicious client\nratios and sensitivity to non-i.i.d. data, leading to degraded accuracy. To\naddress this, we propose FLTG, a novel aggregation algorithm integrating\nangle-based defense and dynamic reference selection. FLTG first filters clients\nvia ReLU-clipped cosine similarity, leveraging a server-side clean dataset to\nexclude misaligned updates. It then dynamically selects a reference client\nbased on the prior global model to mitigate non-i.i.d. bias, assigns\naggregation weights inversely proportional to angular deviations, and\nnormalizes update magnitudes to suppress malicious scaling. Evaluations across\ndatasets of varying complexity under five classic attacks demonstrate FLTG's\nsuperiority over state-of-the-art methods under extreme bias scenarios and\nsustains robustness with a higher proportion(over 50%) of malicious clients.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 5 figures, BlockSys2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12851v1",
    "published_date": "2025-05-19 08:39:07 UTC",
    "updated_date": "2025-05-19 08:39:07 UTC"
  },
  {
    "arxiv_id": "2505.12845v1",
    "title": "Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks",
    "authors": [
      "Ruopei Sun",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Kangwen Zhao",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "RLHF has emerged as a predominant approach for aligning artificial\nintelligence systems with human preferences, demonstrating exceptional and\nmeasurable efficacy in instruction following tasks; however, it exhibits\ninsufficient compliance capabilities when confronted with complex\nmulti-instruction tasks. Conventional approaches rely heavily on human\nannotation or more sophisticated large language models, thereby introducing\nsubstantial resource expenditure or potential bias concerns. Meanwhile,\nalternative synthetic methods that augment standard preference datasets often\ncompromise the model's semantic quality. Our research identifies a critical\noversight in existing techniques, which predominantly focus on comparing\nresponses while neglecting valuable latent signals embedded within prompt\ninputs, and which only focus on preference disparities at the intra-sample\nlevel, while neglecting to account for the inter-sample level preference\ndifferentials that exist among preference data. To leverage these previously\nneglected indicators, we propose a novel Multi-level Aware Preference Learning\n(MAPL) framework, capable of enhancing multi-instruction capabilities.\nSpecifically, for any given response in original preference data pairs, we\nconstruct varied prompts with a preference relation under different conditions,\nin order to learn intra-sample level preference disparities. Furthermore, for\nany given original preference pair, we synthesize multi-instruction preference\npairs to capture preference discrepancies at the inter-sample level. Building\non the two datasets constructed above, we consequently devise two sophisticated\ntraining objective functions. Subsequently, our framework integrates seamlessly\ninto both Reward Modeling and Direct Preference Optimization paradigms. Through\nrigorous evaluation across multiple benchmarks, we empirically validate the\nefficacy of our framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12845v1",
    "published_date": "2025-05-19 08:33:11 UTC",
    "updated_date": "2025-05-19 08:33:11 UTC"
  },
  {
    "arxiv_id": "2505.12844v1",
    "title": "AGI-Elo: How Far Are We From Mastering A Task?",
    "authors": [
      "Shuo Sun",
      "Yimin Zhao",
      "Christina Dao Wen Lee",
      "Jiawei Sun",
      "Chengran Yuan",
      "Zefan Huang",
      "Dongen Li",
      "Justin KW Yeoh",
      "Alok Prakash",
      "Thomas W. Malone",
      "Marcelo H. Ang Jr"
    ],
    "abstract": "As the field progresses toward Artificial General Intelligence (AGI), there\nis a pressing need for more comprehensive and insightful evaluation frameworks\nthat go beyond aggregate performance metrics. This paper introduces a unified\nrating system that jointly models the difficulty of individual test cases and\nthe competency of AI models (or humans) across vision, language, and action\ndomains. Unlike existing metrics that focus solely on models, our approach\nallows for fine-grained, difficulty-aware evaluations through competitive\ninteractions between models and tasks, capturing both the long-tail\ndistribution of real-world challenges and the competency gap between current\nmodels and full task mastery. We validate the generalizability and robustness\nof our system through extensive experiments on multiple established datasets\nand models across distinct AGI domains. The resulting rating distributions\noffer novel perspectives and interpretable insights into task difficulty, model\nprogression, and the outstanding challenges that remain on the path to\nachieving full AGI task mastery.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12844v1",
    "published_date": "2025-05-19 08:30:13 UTC",
    "updated_date": "2025-05-19 08:30:13 UTC"
  },
  {
    "arxiv_id": "2505.12843v1",
    "title": "Bias Fitting to Mitigate Length Bias of Reward Model in RLHF",
    "authors": [
      "Kangwen Zhao",
      "Jianfeng Cai",
      "Jinhua Zhu",
      "Ruopei Sun",
      "Dongyun Xue",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ],
    "abstract": "Reinforcement Learning from Human Feedback relies on reward models to align\nlarge language models with human preferences. However, RLHF often suffers from\nreward hacking, wherein policy learning exploits flaws in the trained reward\nmodel to maximize reward scores without genuinely aligning with human\npreferences. A significant example of such reward hacking is length bias, where\nreward models usually favor longer responses irrespective of actual response\nquality. Previous works on length bias have notable limitations, these\napproaches either mitigate bias without characterizing the bias form, or simply\nassume a linear length-reward relation. To accurately model the intricate\nnature of length bias and facilitate more effective bias mitigation, we propose\nFiMi-RM (Bias Fitting to Mitigate Length Bias of Reward Model in RLHF), a\nframework that autonomously learns and corrects underlying bias patterns. Our\napproach consists of three stages: First, we train a standard reward model\nwhich inherently contains length bias. Next, we deploy a lightweight fitting\nmodel to explicitly capture the non-linear relation between length and reward.\nFinally, we incorporate this learned relation into the reward model to debias.\nExperimental results demonstrate that FiMi-RM achieves a more balanced\nlength-reward distribution. Furthermore, when applied to alignment algorithms,\nour debiased reward model improves length-controlled win rate and reduces\nverbosity without compromising its performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Due to the word limit for arXiv abstract, the abstract here has been\n  abridged compared to the one in the PDF",
    "pdf_url": "http://arxiv.org/pdf/2505.12843v1",
    "published_date": "2025-05-19 08:29:28 UTC",
    "updated_date": "2025-05-19 08:29:28 UTC"
  },
  {
    "arxiv_id": "2505.12837v1",
    "title": "The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting",
    "authors": [
      "Christian Braun",
      "Alexander Lilienbeck",
      "Daniel Mentjukov"
    ],
    "abstract": "Legal contracts possess an inherent, semantically vital structure (e.g.,\nsections, clauses) that is crucial for human comprehension but whose impact on\nLLM processing remains under-explored. This paper investigates the effects of\nexplicit input text structure and prompt engineering on the performance of\nGPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the\nCUAD. We compare model exact-match accuracy across various input formats:\nwell-structured plain-text (human-generated from CUAD), plain-text cleaned of\nline breaks, extracted plain-text from Azure OCR, plain-text extracted by\nGPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o\nVision. To give an indication of the impact of possible prompt engineering, we\nassess the impact of shifting task instructions to the system prompt and\nexplicitly informing the model about the structured nature of the input. Our\nfindings reveal that GPT-4o demonstrates considerable robustness to variations\nin input structure, but lacks in overall performance. Conversely, GPT-4.1's\nperformance is markedly sensitive; poorly structured inputs yield suboptimal\nresults (but identical with GPT-4o), while well-structured formats (original\nCUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by\n~20 percentage points. Optimizing the system prompt to include task details and\nan advisory about structured input further elevates GPT-4.1's accuracy by an\nadditional ~10-13 percentage points, with Markdown ultimately achieving the\nhighest performance under these conditions (79 percentage points overall\nexact-match accuracy). This research empirically demonstrates that while newer\nmodels exhibit greater resilience, careful input structuring and strategic\nprompt design remain critical for optimizing the performance of LLMs, and can\nsignificantly affect outcomes in high-stakes legal applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12837v1",
    "published_date": "2025-05-19 08:25:21 UTC",
    "updated_date": "2025-05-19 08:25:21 UTC"
  },
  {
    "arxiv_id": "2505.12833v1",
    "title": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs",
    "authors": [
      "Zhuo Yang",
      "Lingli Ge",
      "Dong Han",
      "Tianfan Fu",
      "Yuqiang Li"
    ],
    "abstract": "Many real-world scientific and industrial applications require the\noptimization of expensive black-box functions. Bayesian Optimization (BO)\nprovides an effective framework for such problems. However, traditional BO\nmethods are prone to get trapped in local optima and often lack interpretable\ninsights. To address this issue, this paper designs Reasoning BO, a novel\nframework that leverages reasoning models to guide the sampling process in BO\nwhile incorporating multi-agent systems and knowledge graphs for online\nknowledge accumulation. By integrating the reasoning and contextual\nunderstanding capabilities of Large Language Models (LLMs), we can provide\nstrong guidance to enhance the BO process. As the optimization progresses,\nReasoning BO provides real-time sampling recommendations along with critical\ninsights grounded in plausible scientific theories, aiding in the discovery of\nsuperior solutions within the search space. We systematically evaluate our\napproach across 10 diverse tasks encompassing synthetic mathematical functions\nand complex real-world applications. The framework demonstrates its capability\nto progressively refine sampling strategies through real-time insights and\nhypothesis evolution, effectively identifying higher-performing regions of the\nsearch space for focused exploration. This process highlights the powerful\nreasoning and context-learning abilities of LLMs in optimization scenarios. For\nexample, in the Direct Arylation task, our method increased the yield to 60.7%,\nwhereas traditional BO achieved only a 25.2% yield. Furthermore, our\ninvestigation reveals that smaller LLMs, when fine-tuned through reinforcement\nlearning, can attain comparable performance to their larger counterparts. This\nenhanced reasoning capability paves the way for more efficient automated\nscientific experimentation while maintaining computational feasibility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12833v1",
    "published_date": "2025-05-19 08:20:40 UTC",
    "updated_date": "2025-05-19 08:20:40 UTC"
  },
  {
    "arxiv_id": "2505.12822v2",
    "title": "Emergent Specialization: Rare Token Neurons in Language Models",
    "authors": [
      "Jing Liu",
      "Haozheng Wang",
      "Yueheng Li"
    ],
    "abstract": "Large language models struggle with representing and generating rare tokens\ndespite their importance in specialized domains. In this study, we identify\nneuron structures with exceptionally strong influence on language model's\nprediction of rare tokens, termed as rare token neurons, and investigate the\nmechanism for their emergence and behavior. These neurons exhibit a\ncharacteristic three-phase organization (plateau, power-law, and rapid decay)\nthat emerges dynamically during training, evolving from a homogeneous initial\nstate to a functionally differentiated architecture. In the activation space,\nrare token neurons form a coordinated subnetwork that selectively co-activates\nwhile avoiding co-activation with other neurons. This functional specialization\npotentially correlates with the development of heavy-tailed weight\ndistributions, suggesting a statistical mechanical basis for emergent\nspecialization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12822v2",
    "published_date": "2025-05-19 08:05:13 UTC",
    "updated_date": "2025-05-22 16:03:57 UTC"
  },
  {
    "arxiv_id": "2505.12821v1",
    "title": "SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models",
    "authors": [
      "Han Sun",
      "Zhen Sun",
      "Zongmin Zhang",
      "Linzhao Jia",
      "Wei Shao",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as dominant forces for textual\nstyle transfer. However, for arbitrary style transfer, LLMs face two key\nchallenges: (1) considerable reliance on manually-constructed prompts and (2)\nrigid stylistic biases inherent in LLMs. In this paper, we propose a novel\nSynthesize-then-Decode (SynDec) approach, which automatically synthesizes\nhigh-quality prompts and amplifies their roles during decoding process.\nSpecifically, our approach synthesizes prompts by selecting representative\nfew-shot samples, conducting a four-dimensional style analysis, and reranking\nthe candidates. At LLM decoding stage, the TST effect is amplified by\nmaximizing the contrast in output probabilities between scenarios with and\nwithout the synthesized prompt, as well as between prompts and negative\nsamples. We conduct extensive experiments and the results show that SynDec\noutperforms existing state-of-the-art LLM-based methods on five out of six\nbenchmarks (e.g., achieving up to a 9\\% increase in accuracy for\nmodern-to-Elizabethan English transfer). Detailed ablation studies further\nvalidate the effectiveness of SynDec.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12821v1",
    "published_date": "2025-05-19 08:03:38 UTC",
    "updated_date": "2025-05-19 08:03:38 UTC"
  },
  {
    "arxiv_id": "2505.12815v1",
    "title": "Learning in Chaos: Efficient Autoscaling and Self-healing for Distributed Training at the Edge",
    "authors": [
      "Wenjiao Feng",
      "Rongxing Xiao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun",
      "Long Luo",
      "Mohsen Guizani",
      "Qirong Ho"
    ],
    "abstract": "Frequent node and link changes in edge AI clusters disrupt distributed\ntraining, while traditional checkpoint-based recovery and cloud-centric\nautoscaling are too slow for scale-out and ill-suited to chaotic and\nself-governed edge. This paper proposes Chaos, a resilient and scalable edge\ndistributed training system with built-in self-healing and autoscaling. It\nspeeds up scale-out by using multi-neighbor replication with fast shard\nscheduling, allowing a new node to pull the latest training state from nearby\nneighbors in parallel while balancing the traffic load between them. It also\nuses a cluster monitor to track resource and topology changes to assist\nscheduler decisions, and handles scaling events through peer negotiation\nprotocols, enabling fully self-governed autoscaling without a central admin.\nExtensive experiments show that Chaos consistently achieves much lower\nscale-out delays than Pollux, EDL, and Autoscaling, and handles scale-in,\nconnect-link, and disconnect-link events within 1 millisecond, making it\nsmoother to handle node joins, exits, and failures. It also delivers the lowest\nidle time, showing superior resource use and scalability as the cluster grows.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "68T99",
      "I.2.11"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12815v1",
    "published_date": "2025-05-19 07:52:17 UTC",
    "updated_date": "2025-05-19 07:52:17 UTC"
  },
  {
    "arxiv_id": "2505.12814v1",
    "title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs",
    "authors": [
      "Xilong Cheng",
      "Yunxiao Qin",
      "Yuting Tan",
      "Zhengnan Li",
      "Ye Wang",
      "Hongjiang Xiao",
      "Yuan Zhang"
    ],
    "abstract": "Existing LLM-based role-playing methods often rely on superficial textual\ndescriptions or simplistic metrics, inadequately modeling both intrinsic and\nextrinsic character dimensions. Additionally, they typically simulate character\nmemory with implicit model knowledge or basic retrieval augment generation\nwithout explicit memory alignment, compromising memory consistency. The two\nissues weaken reliability of role-playing LLMs in several applications, such as\ntrustworthy social simulation. To address these limitations, we propose PsyMem,\na novel framework integrating fine-grained psychological attributes and\nexplicit memory control for role-playing. PsyMem supplements textual\ndescriptions with 26 psychological indicators to detailed model character.\nAdditionally, PsyMem implements memory alignment training, explicitly trains\nthe model to align character's response with memory, thereby enabling dynamic\nmemory-controlled responding during inference. By training Qwen2.5-7B-Instruct\non our specially designed dataset (including 5,414 characters and 38,962\ndialogues extracted from novels), the resulting model, termed as PsyMem-Qwen,\noutperforms baseline models in role-playing, achieving the best performance in\nhuman-likeness and character fidelity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12814v1",
    "published_date": "2025-05-19 07:45:09 UTC",
    "updated_date": "2025-05-19 07:45:09 UTC"
  },
  {
    "arxiv_id": "2505.12811v1",
    "title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning",
    "authors": [
      "Wei-Chen Liao",
      "Ti-Rong Wu",
      "I-Chen Wu"
    ],
    "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight\nrange dilemma, where agents either receive insufficient or excessive\ninformation from their environment. In this paper, we propose a novel method,\ncalled Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes\nan Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight\nrange during training. Experiment results show several advantages of using DSR.\nFirst, we demonstrate using DSR achieves better performance in three common\nMARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse\n(RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show\nthat DSR consistently improves performance across multiple MARL algorithms,\nincluding QMIX and MAPPO. Third, DSR offers suitable sight ranges for different\ntraining steps, thereby accelerating the training process. Finally, DSR\nprovides additional interpretability by indicating the optimal sight range used\nduring training. Unlike existing methods that rely on global information or\ncommunication mechanisms, our approach operates solely based on the individual\nsight ranges of agents. This approach offers a practical and efficient solution\nto the sight range dilemma, making it broadly applicable to real-world complex\nenvironments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted at AAMAS 2025. The compiled PDF includes the appendix",
    "pdf_url": "http://arxiv.org/pdf/2505.12811v1",
    "published_date": "2025-05-19 07:40:42 UTC",
    "updated_date": "2025-05-19 07:40:42 UTC"
  },
  {
    "arxiv_id": "2505.12805v1",
    "title": "FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA",
    "authors": [
      "Seanie Lee",
      "Sangwoo Park",
      "Dong Bok Lee",
      "Dominik Wagner",
      "Haebin Seong",
      "Tobias Bocklet",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "abstract": "Low-Rank Adaptation (LoRA), which introduces a product of two trainable\nlow-rank matrices into frozen pre-trained weights, is widely used for efficient\nfine-tuning of language models in federated learning (FL). However, when\ncombined with differentially private stochastic gradient descent (DP-SGD), LoRA\nfaces substantial noise amplification: DP-SGD perturbs per-sample gradients,\nand the matrix multiplication of the LoRA update ($BA$) intensifies this\neffect. Freezing one matrix (e.g., $A$) reduces the noise but restricts model\nexpressiveness, often resulting in suboptimal adaptation. To address this, we\npropose FedSVD, a simple yet effective method that introduces a global\nreparameterization based on singular value decomposition (SVD). In our\napproach, each client optimizes only the $B$ matrix and transmits it to the\nserver. The server aggregates the $B$ matrices, computes the product $BA$ using\nthe previous $A$, and refactorizes the result via SVD. This yields a new\nadaptive $A$ composed of the orthonormal right singular vectors of $BA$, and an\nupdated $B$ containing the remaining SVD components. This reparameterization\navoids quadratic noise amplification, while allowing $A$ to better capture the\nprincipal directions of the aggregate updates. Moreover, the orthonormal\nstructure of $A$ bounds the gradient norms of $B$ and preserves more signal\nunder DP-SGD, as confirmed by our theoretical analysis. As a result, FedSVD\nconsistently improves stability and performance across a variety of privacy\nsettings and benchmarks, outperforming relevant baselines under both private\nand non-private regimes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2505.12805v1",
    "published_date": "2025-05-19 07:32:56 UTC",
    "updated_date": "2025-05-19 07:32:56 UTC"
  },
  {
    "arxiv_id": "2505.12800v1",
    "title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching",
    "authors": [
      "Hieu-Nghia Huynh-Nguyen",
      "Ngoc Son Nguyen",
      "Huynh Nguyen Dang",
      "Thieu Vo",
      "Truong-Son Hy",
      "Van Nguyen"
    ],
    "abstract": "Text-to-speech (TTS) systems have seen significant advancements in recent\nyears, driven by improvements in deep learning and neural network\narchitectures. Viewing the output speech as a data distribution, previous\napproaches often employ traditional speech representations, such as waveforms\nor spectrograms, within the Flow Matching framework. However, these methods\nhave limitations, including overlooking various speech attributes and incurring\nhigh computational costs due to additional constraints introduced during\ntraining. To address these challenges, we introduce OZSpeech, the first TTS\nmethod to explore optimal transport conditional flow matching with one-step\nsampling and a learned prior as the condition, effectively disregarding\npreceding states and reducing the number of sampling steps. Our approach\noperates on disentangled, factorized components of speech in token format,\nenabling accurate modeling of each speech attribute, which enhances the TTS\nsystem's ability to precisely clone the prompt speech. Experimental results\nshow that our method achieves promising performance over existing methods in\ncontent accuracy, naturalness, prosody generation, and speaker style\npreservation. Audio samples are available at our demo page\nhttps://ozspeech.github.io/OZSpeech_Web/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12800v1",
    "published_date": "2025-05-19 07:31:55 UTC",
    "updated_date": "2025-05-19 07:31:55 UTC"
  },
  {
    "arxiv_id": "2505.12795v1",
    "title": "FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities",
    "authors": [
      "Shibo Hong",
      "Jiahao Ying",
      "Haiyuan Liang",
      "Mengdi Zhang",
      "Jun Kuang",
      "Jiazheng Zhang",
      "Yixin Cao"
    ],
    "abstract": "Evaluating the open-ended outputs of large language models (LLMs) has become\na bottleneck as model capabilities, task diversity, and modality coverage\nrapidly expand. Existing \"LLM-as-a-Judge\" evaluators are typically narrow in a\nfew tasks, aspects, or modalities, and easily suffer from low consistency. In\nthis paper, we argue that explicit, fine-grained aspect specification is the\nkey to both generalizability and objectivity in automated evaluation. To do so,\nwe introduce a hierarchical aspect taxonomy spanning 112 aspects that unifies\nevaluation across four representative settings - Natural Language Generation,\nImage Understanding, Image Generation, and Interleaved Text-and-Image\nGeneration. Building on this taxonomy, we create FRAbench, a benchmark\ncomprising 60.4k pairwise samples with 325k aspect-level labels obtained from a\ncombination of human and LLM annotations. FRAbench provides the first\nlarge-scale, multi-modal resource for training and meta-evaluating fine-grained\nLMM judges. Leveraging FRAbench, we develop GenEval, a fine-grained evaluator\ngeneralizable across tasks and modalities. Experiments show that GenEval (i)\nattains high agreement with GPT-4o and expert annotators, (ii) transfers\nrobustly to unseen tasks and modalities, and (iii) reveals systematic\nweaknesses of current LMMs on evaluation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12795v1",
    "published_date": "2025-05-19 07:29:26 UTC",
    "updated_date": "2025-05-19 07:29:26 UTC"
  },
  {
    "arxiv_id": "2505.12788v1",
    "title": "Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs",
    "authors": [
      "Zhongni Hou",
      "Miao Su",
      "Xiaolong Jin",
      "Zixuan Li",
      "Long Bai",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of\n(subject, predicate, object, timestamp) to describe temporal facts, have\nattracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional\nTKGs by utilizing n-tuples to incorporate auxiliary elements alongside core\nelements (i.e., subject, predicate, and object) of facts, so as to represent\nthem in a more fine-grained manner. Reasoning over N-TKGs aims to predict\npotential future facts based on historical ones. However, existing N-TKG\nreasoning methods often lack explainability due to their black-box nature.\nTherefore, we introduce a new Reinforcement Learning-based method, named\nMT-Path, which leverages the temporal information to traverse historical\nn-tuples and construct a temporal reasoning path. Specifically, in order to\nintegrate the information encapsulated within n-tuples, i.e., the\nentity-irrelevant information within the predicate, the information about core\nelements, and the complete information about the entire n-tuples, MT-Path\nutilizes a mixture policy-driven action selector, which bases on three\nlow-level policies, namely, the predicate-focused policy, the\ncore-element-focused policy and the whole-fact-focused policy. Further, MT-Path\nutilizes an auxiliary element-aware GCN to capture the rich semantic\ndependencies among facts, thereby enabling the agent to gain a deep\nunderstanding of each n-tuple. Experimental results demonstrate the\neffectiveness and the explainability of MT-Path.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12788v1",
    "published_date": "2025-05-19 07:20:33 UTC",
    "updated_date": "2025-05-19 07:20:33 UTC"
  },
  {
    "arxiv_id": "2505.12781v1",
    "title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone",
    "authors": [
      "Jitai Hao",
      "Qiang Huang",
      "Hao Liu",
      "Xinyan Xiao",
      "Zhaochun Ren",
      "Jun Yu"
    ],
    "abstract": "Training high-performing Small Language Models (SLMs) remains costly, even\nwith knowledge distillation and pruning from larger teacher models. Existing\nwork often faces three key challenges: (1) information loss from hard pruning,\n(2) inefficient alignment of representations, and (3) underutilization of\ninformative activations, particularly from Feed-Forward Networks (FFNs). To\naddress these challenges, we introduce Low-Rank Clone (LRC), an efficient\npre-training method that constructs SLMs aspiring to behavioral equivalence\nwith strong teacher models. LRC trains a set of low-rank projection matrices\nthat jointly enable soft pruning by compressing teacher weights, and activation\nclone by aligning student activations, including FFN signals, with those of the\nteacher. This unified design maximizes knowledge transfer while removing the\nneed for explicit alignment modules. Extensive experiments with open-source\nteachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC\nmatches or surpasses state-of-the-art models trained on trillions of\ntokens--while using only 20B tokens, achieving over 1,000x training efficiency.\nOur codes and model checkpoints are available at\nhttps://github.com/CURRENTF/LowRankClone and\nhttps://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12781v1",
    "published_date": "2025-05-19 07:10:42 UTC",
    "updated_date": "2025-05-19 07:10:42 UTC"
  },
  {
    "arxiv_id": "2505.12774v1",
    "title": "UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes",
    "authors": [
      "Zichen Geng",
      "Zeeshan Hayder",
      "Wei Liu",
      "Ajmal Mian"
    ],
    "abstract": "Human motion synthesis in complex scenes presents a fundamental challenge,\nextending beyond conventional Text-to-Motion tasks by requiring the integration\nof diverse modalities such as static environments, movable objects, natural\nlanguage prompts, and spatial waypoints. Existing language-conditioned motion\nmodels often struggle with scene-aware motion generation due to limitations in\nmotion tokenization, which leads to information loss and fails to capture the\ncontinuous, context-dependent nature of 3D human movement. To address these\nissues, we propose UniHM, a unified motion language model that leverages\ndiffusion-based generation for synthesizing scene-aware human motion. UniHM is\nthe first framework to support both Text-to-Motion and Text-to-Human-Object\nInteraction (HOI) in complex 3D scenes. Our approach introduces three key\ncontributions: (1) a mixed-motion representation that fuses continuous 6DoF\nmotion with discrete local motion tokens to improve motion realism; (2) a novel\nLook-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in\nboth reconstruction accuracy and generative performance; and (3) an enriched\nversion of the Lingo dataset augmented with HumanML3D annotations, providing\nstronger supervision for scene-specific motion learning. Experimental results\ndemonstrate that UniHM achieves comparative performance on the OMOMO benchmark\nfor text-to-HOI synthesis and yields competitive results on HumanML3D for\ngeneral text-conditioned motion generation.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12774v1",
    "published_date": "2025-05-19 07:02:12 UTC",
    "updated_date": "2025-05-19 07:02:12 UTC"
  },
  {
    "arxiv_id": "2505.13554v1",
    "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation",
    "authors": [
      "Zhanglin Wu",
      "Daimeng Wei",
      "Xiaoyu Chen",
      "Hengchao Shang",
      "Jiaxin Guo",
      "Zongyao Li",
      "Yuanchang Luo",
      "Jinlong Yang",
      "Zhiqiang Rao",
      "Hao Yang"
    ],
    "abstract": "Large language model (LLM) shows promising performances in a variety of\ndownstream tasks, such as machine translation (MT). However, using LLMs for\ntranslation suffers from high computational costs and significant latency.\nBased on our evaluation, in most cases, translations using LLMs are comparable\nto that generated by neural machine translation (NMT) systems. Only in\nparticular scenarios, LLM and NMT models show respective advantages. As a\nresult, integrating NMT and LLM for translation and using LLM only when\nnecessary seems to be a sound solution. A scheduling policy that optimizes\ntranslation result while ensuring fast speed and as little LLM usage as\npossible is thereby required. We compare several scheduling policies and\npropose a novel and straightforward decider that leverages source sentence\nfeatures. We conduct extensive experiments on multilingual test sets and the\nresult shows that we can achieve optimal translation performance with minimal\nLLM usage, demonstrating effectiveness of our decider.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures, 9 tables, ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.13554v1",
    "published_date": "2025-05-19 06:50:52 UTC",
    "updated_date": "2025-05-19 06:50:52 UTC"
  },
  {
    "arxiv_id": "2505.12767v1",
    "title": "Language Models That Walk the Talk: A Framework for Formal Fairness Certificates",
    "authors": [
      "Danqing Chen",
      "Tobias Ladner",
      "Ahmed Rayen Mhadhbi",
      "Matthias Althoff"
    ],
    "abstract": "As large language models become integral to high-stakes applications,\nensuring their robustness and fairness is critical. Despite their success,\nlarge language models remain vulnerable to adversarial attacks, where small\nperturbations, such as synonym substitutions, can alter model predictions,\nposing risks in fairness-critical areas, such as gender bias mitigation, and\nsafety-critical areas, such as toxicity detection. While formal verification\nhas been explored for neural networks, its application to large language models\nremains limited. This work presents a holistic verification framework to\ncertify the robustness of transformer-based language models, with a focus on\nensuring gender fairness and consistent outputs across different gender-related\nterms. Furthermore, we extend this methodology to toxicity detection, offering\nformal guarantees that adversarially manipulated toxic inputs are consistently\ndetected and appropriately censored, thereby ensuring the reliability of\nmoderation systems. By formalizing robustness within the embedding space, this\nwork strengthens the reliability of language models in ethical AI deployment\nand content moderation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12767v1",
    "published_date": "2025-05-19 06:46:17 UTC",
    "updated_date": "2025-05-19 06:46:17 UTC"
  },
  {
    "arxiv_id": "2505.12763v1",
    "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
    "authors": [
      "Sunghwan Kim",
      "Dongjin Kang",
      "Taeyoon Kwon",
      "Hyungjoo Chae",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human\nfeedback (RLHF), aligning model behavior with human preferences. However,\nexisting benchmarks for reward models show a weak correlation with the\nperformance of optimized policies, suggesting that they fail to accurately\nassess the true capabilities of RMs. To bridge this gap, we explore several\nevaluation designs through the lens of reward overoptimization\\textemdash a\nphenomenon that captures both how well the reward model aligns with human\npreferences and the dynamics of the learning signal it provides to the policy.\nThe results highlight three key findings on how to construct a reliable\nbenchmark: (i) it is important to minimize differences between chosen and\nrejected responses beyond correctness, (ii) evaluating reward models requires\nmultiple comparisons across a wide range of chosen and rejected responses, and\n(iii) given that reward models encounter responses with diverse\nrepresentations, responses should be sourced from a variety of models. However,\nwe also observe that a extremely high correlation with degree of\noveroptimization leads to comparatively lower correlation with certain\ndownstream performance. Thus, when designing a benchmark, it is desirable to\nuse the degree of overoptimization as a useful tool, rather than the end goal.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12763v1",
    "published_date": "2025-05-19 06:43:08 UTC",
    "updated_date": "2025-05-19 06:43:08 UTC"
  },
  {
    "arxiv_id": "2505.12762v1",
    "title": "IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment",
    "authors": [
      "Chenlin Ming",
      "Chendi Qu",
      "Mengzhang Cai",
      "Qizhi Pei",
      "Zhuoshi Pan",
      "Yu Li",
      "Xiaoming Duan",
      "Lijun Wu",
      "Conghui He"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive performance through\nSupervised Fine-tuning (SFT) on diverse instructional datasets. When training\non multiple capabilities simultaneously, the mixture training dataset, governed\nby volumes of data from different domains, is a critical factor that directly\nimpacts the final model's performance. Unlike many studies that focus on\nenhancing the quality of training datasets through data selection methods, few\nworks explore the intricate relationship between the compositional quantity of\nmixture training datasets and the emergent capabilities of LLMs. Given the\navailability of a high-quality multi-domain training dataset, understanding the\nimpact of data from each domain on the model's overall capabilities is crucial\nfor preparing SFT data and training a well-balanced model that performs\neffectively across diverse domains. In this work, we introduce IDEAL, an\ninnovative data equilibrium adaptation framework designed to effectively\noptimize volumes of data from different domains within mixture SFT datasets,\nthereby enhancing the model's alignment and performance across multiple\ncapabilities. IDEAL employs a gradient-based approach to iteratively refine the\ntraining data distribution, dynamically adjusting the volumes of\ndomain-specific data based on their impact on downstream task performance. By\nleveraging this adaptive mechanism, IDEAL ensures a balanced dataset\ncomposition, enabling the model to achieve robust generalization and consistent\nproficiency across diverse tasks. Experiments across different capabilities\ndemonstrate that IDEAL outperforms conventional uniform data allocation\nstrategies, achieving a comprehensive improvement of approximately 7% in\nmulti-task evaluation scores.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12762v1",
    "published_date": "2025-05-19 06:42:44 UTC",
    "updated_date": "2025-05-19 06:42:44 UTC"
  },
  {
    "arxiv_id": "2505.12761v2",
    "title": "Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding",
    "authors": [
      "Donghwa Shin",
      "Edwin Zhang"
    ],
    "abstract": "Transformers have recently gained popularity in time series forecasting due\nto their ability to capture long-term dependencies. However, many existing\nmodels focus only on capturing temporal dependencies while omitting intricate\nrelationships between variables. Recent models have tried tackling this by\nexplicitly modeling both cross-time and cross-variate dependencies through a\nsequential or unified attention mechanism, but they are entirely channel\ndependent (CD) across all layers, making them potentially susceptible to\noverfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE),\na lightweight CD module that injects cross-variate context into\nchannel-independent (CI) models by simply modifying the patch embedding\nprocess. We achieve this by adding a learnable positional encoding and a\nlightweight router-attention block to the vanilla patch embedding layer. We\nthen integrate CVPE into Time-LLM, a multimodal CI forecasting model, to\ndemonstrate its effectiveness in capturing cross-variate dependencies and\nenhance the CI model's performance. Extensive experimental results on seven\nreal-world datasets show that our enhanced Time-LLM outperforms the original\nbaseline model simply by incorporating the CVPE module, with no other changes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12761v2",
    "published_date": "2025-05-19 06:41:14 UTC",
    "updated_date": "2025-05-20 03:01:46 UTC"
  },
  {
    "arxiv_id": "2505.12751v1",
    "title": "Structure-based Anomaly Detection and Clustering",
    "authors": [
      "Filippo Leveni"
    ],
    "abstract": "Anomaly detection is a fundamental problem in domains such as healthcare,\nmanufacturing, and cybersecurity. This thesis proposes new unsupervised methods\nfor anomaly detection in both structured and streaming data settings. In the\nfirst part, we focus on structure-based anomaly detection, where normal data\nfollows low-dimensional manifolds while anomalies deviate from them. We\nintroduce Preference Isolation Forest (PIF), which embeds data into a\nhigh-dimensional preference space via manifold fitting, and isolates outliers\nusing two variants: Voronoi-iForest, based on geometric distances, and\nRuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also\npropose Sliding-PIF, which captures local manifold information for streaming\nscenarios. Our methods outperform existing techniques on synthetic and real\ndatasets. We extend this to structure-based clustering with MultiLink, a novel\nmethod for recovering multiple geometric model families in noisy data.\nMultiLink merges clusters via a model-aware linkage strategy, enabling robust\nmulti-class structure recovery. It offers key advantages over existing\napproaches, such as speed, reduced sensitivity to thresholds, and improved\nrobustness to poor initial sampling. The second part of the thesis addresses\nonline anomaly detection in evolving data streams. We propose Online Isolation\nForest (Online-iForest), which uses adaptive, multi-resolution histograms and\ndynamically updates tree structures to track changes over time. It avoids\nretraining while achieving accuracy comparable to offline models, with superior\nefficiency for real-time applications. Finally, we tackle anomaly detection in\ncybersecurity via open-set recognition for malware classification. We enhance a\nGradient Boosting classifier with MaxLogit to detect unseen malware families, a\nmethod now integrated into Cleafy's production system.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Doctoral dissertation at Politecnico di Milano",
    "pdf_url": "http://arxiv.org/pdf/2505.12751v1",
    "published_date": "2025-05-19 06:20:00 UTC",
    "updated_date": "2025-05-19 06:20:00 UTC"
  },
  {
    "arxiv_id": "2505.12750v1",
    "title": "Malware families discovery via Open-Set Recognition on Android manifest permissions",
    "authors": [
      "Filippo Leveni",
      "Matteo Mistura",
      "Francesco Iubatti",
      "Carmine Giangregorio",
      "Nicolò Pastore",
      "Cesare Alippi",
      "Giacomo Boracchi"
    ],
    "abstract": "Malware are malicious programs that are grouped into families based on their\npenetration technique, source code, and other characteristics. Classifying\nmalware programs into their respective families is essential for building\neffective defenses against cyber threats. Machine learning models have a huge\npotential in malware detection on mobile devices, as malware families can be\nrecognized by classifying permission data extracted from Android manifest\nfiles. Still, the malware classification task is challenging due to the\nhigh-dimensional nature of permission data and the limited availability of\ntraining samples. In particular, the steady emergence of new malware families\nmakes it impossible to acquire a comprehensive training set covering all the\nmalware classes. In this work, we present a malware classification system that,\non top of classifying known malware, detects new ones. In particular, we\ncombine an open-set recognition technique developed within the computer vision\ncommunity, namely MaxLogit, with a tree-based Gradient Boosting classifier,\nwhich is particularly effective in classifying high-dimensional data. Our\nsolution turns out to be very practical, as it can be seamlessly employed in a\nstandard classification workflow, and efficient, as it adds minimal\ncomputational overhead. Experiments on public and proprietary datasets\ndemonstrate the potential of our solution, which has been deployed in a\nbusiness environment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to European Conference on Artificial Intelligence (ECAI\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.12750v1",
    "published_date": "2025-05-19 06:19:54 UTC",
    "updated_date": "2025-05-19 06:19:54 UTC"
  },
  {
    "arxiv_id": "2505.12748v1",
    "title": "TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation",
    "authors": [
      "Hangyu Li",
      "Qin Zhao",
      "Haoran Xu",
      "Xinyu Jiang",
      "Qingwei Ben",
      "Feiyu Jia",
      "Haoyu Zhao",
      "Liang Xu",
      "Jia Zeng",
      "Hanqing Wang",
      "Bo Dai",
      "Junting Dong",
      "Jiangmiao Pang"
    ],
    "abstract": "Teleoperation is a cornerstone of embodied-robot learning, and bimanual\ndexterous teleoperation in particular provides rich demonstrations that are\ndifficult to obtain with fully autonomous systems. While recent studies have\nproposed diverse hardware pipelines-ranging from inertial motion-capture gloves\nto exoskeletons and vision-based interfaces-there is still no unified benchmark\nthat enables fair, reproducible comparison of these systems. In this paper, we\nintroduce TeleOpBench, a simulator-centric benchmark tailored to bimanual\ndexterous teleoperation. TeleOpBench contains 30 high-fidelity task\nenvironments that span pick-and-place, tool use, and collaborative\nmanipulation, covering a broad spectrum of kinematic and force-interaction\ndifficulty. Within this benchmark we implement four representative\nteleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand\nexoskeletons, and (iv) monocular vision tracking-and evaluate them with a\ncommon protocol and metric suite. To validate that performance in simulation is\npredictive of real-world behavior, we conduct mirrored experiments on a\nphysical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10\nheld-out tasks we observe a strong correlation between simulator and hardware\nperformance, confirming the external validity of TeleOpBench. TeleOpBench\nestablishes a common yardstick for teleoperation research and provides an\nextensible platform for future algorithmic and hardware innovation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12748v1",
    "published_date": "2025-05-19 06:08:53 UTC",
    "updated_date": "2025-05-19 06:08:53 UTC"
  },
  {
    "arxiv_id": "2505.12746v1",
    "title": "Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs",
    "authors": [
      "Haruka Asanuma",
      "Naoko Koide-Majima",
      "Ken Nakamura",
      "Takato Horii",
      "Shinji Nishimoto",
      "Masafumi Oizumi"
    ],
    "abstract": "Recent studies have revealed that human emotions exhibit a high-dimensional,\ncomplex structure. A full capturing of this complexity requires new approaches,\nas conventional models that disregard high dimensionality risk overlooking key\nnuances of human emotions. Here, we examined the extent to which the latest\ngeneration of rapidly evolving Multimodal Large Language Models (MLLMs) capture\nthese high-dimensional, intricate emotion structures, including capabilities\nand limitations. Specifically, we compared self-reported emotion ratings from\nparticipants watching videos with model-generated estimates (e.g., Gemini or\nGPT). We evaluated performance not only at the individual video level but also\nfrom emotion structures that account for inter-video relationships. At the\nlevel of simple correlation between emotion structures, our results\ndemonstrated strong similarity between human and model-inferred emotion\nstructures. To further explore whether the similarity between humans and models\nis at the signle item level or the coarse-categorical level, we applied Gromov\nWasserstein Optimal Transport. We found that although performance was not\nnecessarily high at the strict, single-item level, performance across video\ncategories that elicit similar emotions was substantial, indicating that the\nmodel could infer human emotional experiences at the category level. Our\nresults suggest that current state-of-the-art MLLMs broadly capture the complex\nhigh-dimensional emotion structures at the category level, as well as their\napparent limitations in accurately capturing entire structures at the\nsingle-item level.",
    "categories": [
      "cs.AI",
      "I.2.7; I.2.10; I.5.1"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12746v1",
    "published_date": "2025-05-19 06:03:22 UTC",
    "updated_date": "2025-05-19 06:03:22 UTC"
  },
  {
    "arxiv_id": "2505.12745v1",
    "title": "PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization",
    "authors": [
      "Dong Kyu Cho",
      "Inwoo Hwang",
      "Sanghack Lee"
    ],
    "abstract": "Data augmentation is a popular tool for single source domain generalization,\nwhich expands the source domain by generating simulated ones, improving\ngeneralization on unseen target domains. In this work, we show that the\nperformance of such augmentation-based methods in the target domains\nuniversally fluctuates during training, posing challenges in model selection\nunder realistic scenarios. We argue that the fluctuation stems from the\ninability of the model to accumulate the knowledge learned from diverse\naugmentations, exacerbating feature distortion during training. Based on this\nobservation, we propose a novel generalization method, coined Parameter-Space\nEnsemble with Entropy Regularization (PEER), that uses a proxy model to learn\nthe augmented data on behalf of the main model. The main model is updated by\naveraging its parameters with the proxy model, progressively accumulating\nknowledge over the training steps. Maximizing the mutual information between\nthe output representations of the two models guides the learning process of the\nproxy model, mitigating feature distortion during training. Experimental\nresults demonstrate the effectiveness of PEER in reducing the OOD performance\nfluctuation and enhancing generalization across various datasets, including\nPACS, Digits, Office-Home, and VLCS. Notably, our method with simple random\naugmentation achieves state-of-the-art performance, surpassing prior approaches\non sDG that utilize complex data augmentation strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures, Accepted at CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12745v1",
    "published_date": "2025-05-19 06:01:11 UTC",
    "updated_date": "2025-05-19 06:01:11 UTC"
  },
  {
    "arxiv_id": "2505.12744v1",
    "title": "Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation",
    "authors": [
      "Weiliang Tang",
      "Dong Jing",
      "Jia-Hui Pan",
      "Zhiwu Lu",
      "Yun-Hui Liu",
      "Li Erran Li",
      "Mingyu Ding",
      "Chi-Wing Fu"
    ],
    "abstract": "Recent Large Multimodal Models have demonstrated remarkable reasoning\ncapabilities, especially in solving complex mathematical problems and realizing\naccurate spatial perception. Our key insight is that these emerging abilities\ncan naturally extend to robotic manipulation by enabling LMMs to directly infer\nthe next goal in language via reasoning, rather than relying on a separate\naction head. However, this paradigm meets two main challenges: i) How to make\nLMMs understand the spatial action space, and ii) How to fully exploit the\nreasoning capacity of LMMs in solving these tasks. To tackle the former\nchallenge, we propose a novel task formulation, which inputs the current states\nof object parts and the gripper, and reformulates rotation by a new axis\nrepresentation instead of traditional Euler angles. This representation is more\ncompatible with spatial reasoning and easier to interpret within a unified\nlanguage space. For the latter challenge, we design a pipeline to utilize\ncutting-edge LMMs to generate a small but high-quality reasoning dataset of\nmulti-round dialogues that successfully solve manipulation tasks for supervised\nfine-tuning. Then, we perform reinforcement learning by trial-and-error\ninteractions in simulation to further enhance the model's reasoning abilities\nfor robotic manipulation. Our resulting reasoning model built upon a 7B\nbackbone, named ReasonManip, demonstrates three notable advantages driven by\nits system-2 level reasoning capabilities: i) exceptional generalizability to\nout-of-distribution environments, objects, and tasks; ii) inherent sim-to-real\ntransfer ability enabled by the unified language representation shared across\ndomains; iii) transparent interpretability connecting high-level reasoning and\nlow-level control. Extensive experiments demonstrate the effectiveness of the\nproposed paradigm and its potential to advance LMM-driven robotic manipulation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12744v1",
    "published_date": "2025-05-19 06:00:14 UTC",
    "updated_date": "2025-05-19 06:00:14 UTC"
  },
  {
    "arxiv_id": "2505.12741v1",
    "title": "Dense Communication between Language Models",
    "authors": [
      "Shiguang Wu",
      "Yaqing Wang",
      "Quanming Yao"
    ],
    "abstract": "As higher-level intelligence emerges from the combination of modular\ncomponents with lower-level intelligence, many works combines Large Language\nModels (LLMs) for collective intelligence. Such combination is achieved by\nbuilding communications among LLMs. While current systems primarily facilitate\nsuch communication through natural language, this paper proposes a novel\nparadigm of direct dense vector communication between LLMs. Our approach\neliminates the unnecessary embedding and de-embedding steps when LLM interact\nwith another, enabling more efficient information transfer, fully\ndifferentiable optimization pathways, and exploration of capabilities beyond\nhuman heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq\nmodules as edges to construct LMNet, with similar structure as MLPs. By\nutilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves\ncomparable performance with LLMs in similar size with only less than 0.1%\ntraining cost. This offers a new perspective on scaling for general\nintelligence rather than training a monolithic LLM from scratch. Besides, the\nproposed method can be used for other applications, like customizing LLM with\nlimited data, showing its versatility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12741v1",
    "published_date": "2025-05-19 05:56:06 UTC",
    "updated_date": "2025-05-19 05:56:06 UTC"
  },
  {
    "arxiv_id": "2505.12738v1",
    "title": "EpiLLM: Unlocking the Potential of Large Language Models in Epidemic Forecasting",
    "authors": [
      "Chenghua Gong",
      "Rui Sun",
      "Yuhao Zheng",
      "Juyuan Zhang",
      "Tianjun Gu",
      "Liming Pan",
      "Linyuan Lv"
    ],
    "abstract": "Advanced epidemic forecasting is critical for enabling precision containment\nstrategies, highlighting its strategic importance for public health security.\nWhile recent advances in Large Language Models (LLMs) have demonstrated\neffectiveness as foundation models for domain-specific tasks, their potential\nfor epidemic forecasting remains largely unexplored. In this paper, we\nintroduce EpiLLM, a novel LLM-based framework tailored for spatio-temporal\nepidemic forecasting. Considering the key factors in real-world epidemic\ntransmission: infection cases and human mobility, we introduce a dual-branch\narchitecture to achieve fine-grained token-level alignment between such complex\nepidemic patterns and language tokens for LLM adaptation. To unleash the\nmulti-step forecasting and generalization potential of LLM architectures, we\npropose an autoregressive modeling paradigm that reformulates the epidemic\nforecasting task into next-token prediction. To further enhance LLM perception\nof epidemics, we introduce spatio-temporal prompt learning techniques, which\nstrengthen forecasting capabilities from a data-driven perspective. Extensive\nexperiments show that EpiLLM significantly outperforms existing baselines on\nreal-world COVID-19 datasets and exhibits scaling behavior characteristic of\nLLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12738v1",
    "published_date": "2025-05-19 05:53:25 UTC",
    "updated_date": "2025-05-19 05:53:25 UTC"
  },
  {
    "arxiv_id": "2505.12737v1",
    "title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Hongjoon Ahn",
      "Heewoong Choi",
      "Jisu Han",
      "Taesup Moon"
    ],
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) offers a practical\nlearning paradigm where goal-reaching policies are trained from abundant\nunlabeled (reward-free) datasets without additional environment interaction.\nHowever, offline GCRL still struggles with long-horizon tasks, even with recent\nadvances that employ hierarchical policy structures, such as HIQL. By\nidentifying the root cause of this challenge, we observe the following\ninsights: First, performance bottlenecks mainly stem from the high-level\npolicy's inability to generate appropriate subgoals. Second, when learning the\nhigh-level policy in the long-horizon regime, the sign of the advantage signal\nfrequently becomes incorrect. Thus, we argue that improving the value function\nto produce a clear advantage signal for learning the high-level policy is\nessential. In this paper, we propose a simple yet effective solution:\nOption-aware Temporally Abstracted value learning, dubbed OTA, which\nincorporates temporal abstraction into the temporal-difference learning\nprocess. By modifying the value update to be option-aware, the proposed\nlearning scheme contracts the effective horizon length, enabling better\nadvantage estimates even in long-horizon regimes. We experimentally show that\nthe high-level policy extracted using the OTA value function achieves strong\nperformance on complex tasks from OGBench, a recently proposed offline GCRL\nbenchmark, including maze navigation and visual robotic manipulation\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12737v1",
    "published_date": "2025-05-19 05:51:11 UTC",
    "updated_date": "2025-05-19 05:51:11 UTC"
  },
  {
    "arxiv_id": "2505.12734v1",
    "title": "SounDiT: Geo-Contextual Soundscape-to-Landscape Generation",
    "authors": [
      "Junbo Wang",
      "Haofeng Tan",
      "Bowen Liao",
      "Albert Jiang",
      "Teng Fei",
      "Qixing Huang",
      "Zhengzhong Tu",
      "Shan Ye",
      "Yuhao Kang"
    ],
    "abstract": "We present a novel and practically significant problem-Geo-Contextual\nSoundscape-to-Landscape (GeoS2L) generation-which aims to synthesize\ngeographically realistic landscape images from environmental soundscapes. Prior\naudio-to-image generation methods typically rely on general-purpose datasets\nand overlook geographic and environmental contexts, resulting in unrealistic\nimages that are misaligned with real-world environmental settings. To address\nthis limitation, we introduce a novel geo-contextual computational framework\nthat explicitly integrates geographic knowledge into multimodal generative\nmodeling. We construct two large-scale geo-contextual multimodal datasets,\nSoundingSVI and SonicUrban, pairing diverse soundscapes with real-world\nlandscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based\nmodel that incorporates geo-contextual scene conditioning to synthesize\ngeographically coherent landscape images. Furthermore, we propose a\npractically-informed geo-contextual evaluation framework, the Place Similarity\nScore (PSS), across element-, scene-, and human perception-levels to measure\nconsistency between input soundscapes and generated landscape images. Extensive\nexperiments demonstrate that SounDiT outperforms existing baselines in both\nvisual fidelity and geographic settings. Our work not only establishes\nfoundational benchmarks for GeoS2L generation but also highlights the\nimportance of incorporating geographic domain knowledge in advancing multimodal\ngenerative models, opening new directions at the intersection of generative AI,\ngeography, urban planning, and environmental sciences.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12734v1",
    "published_date": "2025-05-19 05:47:13 UTC",
    "updated_date": "2025-05-19 05:47:13 UTC"
  },
  {
    "arxiv_id": "2505.12731v1",
    "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps",
    "authors": [
      "Jie Ou",
      "Jinyu Guo",
      "Shuaihong Jiang",
      "Zhaokun Wang",
      "Libo Qin",
      "Shunyu Yao",
      "Wenhong Tian"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal method for\nexpanding the knowledge of large language models. To handle complex queries\nmore effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the\ngenerated quality through multiple interactions with external knowledge bases.\nDespite its effectiveness, A-RAG exacerbates the pre-existing efficiency\nchallenges inherent in RAG, which are attributable to its reliance on multiple\niterations of generation. Existing A-RAG approaches process all retrieved\ncontents from scratch. However, they ignore the situation where there is a\nsignificant overlap in the content of the retrieval results across rounds. The\noverlapping content is redundantly represented, which leads to a large\nproportion of repeated computations, thus affecting the overall efficiency. To\naddress this issue, this paper introduces a model-agnostic approach that can be\ngenerally applied to A-RAG methods, which is dedicated to reducing the\nredundant representation process caused by the overlapping of retrieval\nresults. Specifically, we use cache access and parallel generation to speed up\nthe prefilling and decoding stages respectively. Additionally, we also propose\nan instruction-driven module to further guide the model to more effectively\nattend to each part of the content in a more suitable way for LLMs. Experiments\nshow that our approach achieves 2.79 and 2.33 times significant acceleration on\naverage for prefilling and decoding respectively while maintaining equal\ngeneration quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12731v1",
    "published_date": "2025-05-19 05:39:38 UTC",
    "updated_date": "2025-05-19 05:39:38 UTC"
  },
  {
    "arxiv_id": "2505.12716v1",
    "title": "Shadow-FT: Tuning Instruct via Base",
    "authors": [
      "Taiqiang Wu",
      "Runming Yang",
      "Jiayi Li",
      "Pengfei Hu",
      "Ngai Wong",
      "Yujiu Yang"
    ],
    "abstract": "Large language models (LLMs) consistently benefit from further fine-tuning on\nvarious tasks. However, we observe that directly tuning the INSTRUCT (i.e.,\ninstruction tuned) models often leads to marginal improvements and even\nperformance degeneration. Notably, paired BASE models, the foundation for these\nINSTRUCT variants, contain highly similar weight values (i.e., less than 2% on\naverage for Llama 3.1 8B). Therefore, we propose a novel Shadow-FT framework to\ntune the INSTRUCT models by leveraging the corresponding BASE models. The key\ninsight is to fine-tune the BASE model, and then directly graft the learned\nweight updates to the INSTRUCT model. Our proposed Shadow-FT introduces no\nadditional parameters, is easy to implement, and significantly improves\nperformance. We conduct extensive experiments on tuning mainstream LLMs, such\nas Qwen 3 and Llama 3 series, and evaluate them across 19 benchmarks covering\ncoding, reasoning, and mathematical tasks. Experimental results demonstrate\nthat Shadow-FT consistently outperforms conventional full-parameter and\nparameter-efficient tuning approaches. Further analyses indicate that Shadow-FT\ncan be applied to multimodal large language models (MLLMs) and combined with\ndirect preference optimization (DPO). Codes and weights are available at\n\\href{https://github.com/wutaiqiang/Shadow-FT}{Github}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2505.12716v1",
    "published_date": "2025-05-19 05:16:21 UTC",
    "updated_date": "2025-05-19 05:16:21 UTC"
  },
  {
    "arxiv_id": "2505.12711v2",
    "title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining",
    "authors": [
      "Qichen Sun",
      "Zhengrui Guo",
      "Rui Peng",
      "Hao Chen",
      "Jinzhuo Wang"
    ],
    "abstract": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12711v2",
    "published_date": "2025-05-19 05:07:34 UTC",
    "updated_date": "2025-05-20 12:57:58 UTC"
  },
  {
    "arxiv_id": "2505.13551v1",
    "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems",
    "authors": [
      "Serge Dolgikh"
    ],
    "abstract": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.SI",
      "68T27, 94A15",
      "F.2.2; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13551v1",
    "published_date": "2025-05-19 05:04:07 UTC",
    "updated_date": "2025-05-19 05:04:07 UTC"
  },
  {
    "arxiv_id": "2505.12707v1",
    "title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI",
    "authors": [
      "Yingchen He",
      "Christian D. Weilbach",
      "Martyna E. Wojciechowska",
      "Yuxuan Zhang",
      "Frank Wood"
    ],
    "abstract": "Advances in deep generative modelling have made it increasingly plausible to\ntrain human-level embodied agents. Yet progress has been limited by the absence\nof large-scale, real-time, multi-modal, and socially interactive datasets that\nreflect the sensory-motor complexity of natural environments. To address this,\nwe present PLAICraft, a novel data collection platform and dataset capturing\nmultiplayer Minecraft interactions across five time-aligned modalities: video,\ngame output audio, microphone input audio, mouse, and keyboard actions. Each\nmodality is logged with millisecond time precision, enabling the study of\nsynchronous, embodied behaviour in a rich, open-ended world. The dataset\ncomprises over 10,000 hours of gameplay from more than 10,000 global\nparticipants.\\footnote{We have done a privacy review for the public release of\nan initial 200-hour subset of the dataset, with plans to release most of the\ndataset over time.} Alongside the dataset, we provide an evaluation suite for\nbenchmarking model capabilities in object recognition, spatial awareness,\nlanguage grounding, and long-term memory. PLAICraft opens a path toward\ntraining and evaluating agents that act fluently and purposefully in real time,\npaving the way for truly embodied artificial intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12707v1",
    "published_date": "2025-05-19 05:00:47 UTC",
    "updated_date": "2025-05-19 05:00:47 UTC"
  },
  {
    "arxiv_id": "2505.12705v1",
    "title": "DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Zongyu Lin",
      "Jiannan Xiang",
      "Johan Bjorck",
      "Yu Fang",
      "Fengyuan Hu",
      "Spencer Huang",
      "Kaushil Kundalia",
      "Yen-Chen Lin",
      "Loic Magne",
      "Ajay Mandlekar",
      "Avnish Narayan",
      "You Liang Tan",
      "Guanzhi Wang",
      "Jing Wang",
      "Qi Wang",
      "Yinzhen Xu",
      "Xiaohui Zeng",
      "Kaiyuan Zheng",
      "Ruijie Zheng",
      "Ming-Yu Liu",
      "Luke Zettlemoyer",
      "Dieter Fox",
      "Jan Kautz",
      "Scott Reed",
      "Yuke Zhu",
      "Linxi Fan"
    ],
    "abstract": "We introduce DreamGen, a simple yet highly effective 4-stage pipeline for\ntraining robot policies that generalize across behaviors and environments\nthrough neural trajectories - synthetic robot data generated from video world\nmodels. DreamGen leverages state-of-the-art image-to-video generative models,\nadapting them to the target robot embodiment to produce photorealistic\nsynthetic videos of familiar or novel tasks in diverse environments. Since\nthese models generate only videos, we recover pseudo-action sequences using\neither a latent action model or an inverse-dynamics model (IDM). Despite its\nsimplicity, DreamGen unlocks strong behavior and environment generalization: a\nhumanoid robot can perform 22 new behaviors in both seen and unseen\nenvironments, while requiring teleoperation data from only a single\npick-and-place task in one environment. To evaluate the pipeline\nsystematically, we introduce DreamGen Bench, a video generation benchmark that\nshows a strong correlation between benchmark performance and downstream policy\nsuccess. Our work establishes a promising new axis for scaling robot learning\nwell beyond manual data collection.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "See website for videos:\n  https://research.nvidia.com/labs/gear/dreamgen",
    "pdf_url": "http://arxiv.org/pdf/2505.12705v1",
    "published_date": "2025-05-19 04:55:39 UTC",
    "updated_date": "2025-05-19 04:55:39 UTC"
  },
  {
    "arxiv_id": "2505.13550v1",
    "title": "JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation",
    "authors": [
      "Ke Yang",
      "Kevin Ros",
      "Shankar Kumar Senthil Kumar",
      "ChengXiang Zhai"
    ],
    "abstract": "Just-in-time Information Recommendation (JIR) is a service designed to\ndeliver the most relevant information precisely when users need it, ,\naddressing their knowledge gaps with minimal effort and boosting\ndecision-making and efficiency in daily life. Advances in device-efficient\ndeployment of foundation models and the growing use of intelligent wearable\ndevices have made always-on JIR assistants feasible. However, there has been no\nsystematic effort to formally define JIR tasks or establish evaluation\nframeworks. To bridge this gap, we present the first mathematical definition of\nJIR tasks and associated evaluation metrics. Additionally, we introduce\nJIR-Arena, a multimodal benchmark dataset featuring diverse,\ninformation-request-intensive scenarios to evaluate JIR systems across critical\ndimensions: i) accurately inferring user information needs, ii) delivering\ntimely and relevant recommendations, and iii) avoiding irrelevant content that\nmay distract users.\n  Developing a JIR benchmark dataset poses challenges due to subjectivity in\nestimating user information needs and uncontrollable system variables affecting\nreproducibility. To address these, JIR-Arena: i) combines input from multiple\nhumans and large AI models to approximate information need distributions; ii)\nassesses JIR quality through information retrieval outcomes using static\nknowledge base snapshots; and iii) employs a multi-turn, multi-entity\nvalidation framework to improve objectivity and generality. Furthermore, we\nimplement a baseline JIR system capable of processing real-time information\nstreams aligned with user inputs. Our evaluation of this baseline system on\nJIR-Arena indicates that while foundation model-based JIR systems simulate user\nneeds with reasonable precision, they face challenges in recall and effective\ncontent retrieval. To support future research in this new area, we fully\nrelease our code and data.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13550v1",
    "published_date": "2025-05-19 04:49:47 UTC",
    "updated_date": "2025-05-19 04:49:47 UTC"
  },
  {
    "arxiv_id": "2505.12701v1",
    "title": "Counterfactual Explanations for Continuous Action Reinforcement Learning",
    "authors": [
      "Shuyang Dong",
      "Shangtong Zhang",
      "Lu Feng"
    ],
    "abstract": "Reinforcement Learning (RL) has shown great promise in domains like\nhealthcare and robotics but often struggles with adoption due to its lack of\ninterpretability. Counterfactual explanations, which address \"what if\"\nscenarios, provide a promising avenue for understanding RL decisions but remain\nunderexplored for continuous action spaces. We propose a novel approach for\ngenerating counterfactual explanations in continuous action RL by computing\nalternative action sequences that improve outcomes while minimizing deviations\nfrom the original sequence. Our approach leverages a distance metric for\ncontinuous actions and accounts for constraints such as adhering to predefined\npolicies in specific states. Evaluations in two RL domains, Diabetes Control\nand Lunar Lander, demonstrate the effectiveness, efficiency, and generalization\nof our approach, enabling more interpretable and trustworthy RL applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12701v1",
    "published_date": "2025-05-19 04:41:54 UTC",
    "updated_date": "2025-05-19 04:41:54 UTC"
  },
  {
    "arxiv_id": "2505.12692v1",
    "title": "Bullying the Machine: How Personas Increase LLM Vulnerability",
    "authors": [
      "Ziwei Xu",
      "Udit Sanghi",
      "Mohan Kankanhalli"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed in interactions where\nthey are prompted to adopt personas. This paper investigates whether such\npersona conditioning affects model safety under bullying, an adversarial\nmanipulation that applies psychological pressures in order to force the victim\nto comply to the attacker. We introduce a simulation framework in which an\nattacker LLM engages a victim LLM using psychologically grounded bullying\ntactics, while the victim adopts personas aligned with the Big Five personality\ntraits. Experiments using multiple open-source LLMs and a wide range of\nadversarial goals reveal that certain persona configurations -- such as\nweakened agreeableness or conscientiousness -- significantly increase victim's\nsusceptibility to unsafe outputs. Bullying tactics involving emotional or\nsarcastic manipulation, such as gaslighting and ridicule, are particularly\neffective. These findings suggest that persona-driven interaction introduces a\nnovel vector for safety risks in LLMs and highlight the need for persona-aware\nsafety evaluation and alignment strategies.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12692v1",
    "published_date": "2025-05-19 04:32:02 UTC",
    "updated_date": "2025-05-19 04:32:02 UTC"
  },
  {
    "arxiv_id": "2505.12684v1",
    "title": "Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement",
    "authors": [
      "Yinlin Zhu",
      "Xunkai Li",
      "Jishuo Jia",
      "Miao Hu",
      "Di Wu",
      "Meikang Qiu"
    ],
    "abstract": "Recent advances in graph machine learning have shifted to data-centric\nparadigms, driven by two emerging fields: (1) Federated graph learning (FGL)\nenables multi-client collaboration but faces challenges from data and task\nheterogeneity, limiting its practicality; (2) Graph foundation models (GFM)\noffer strong domain generalization but are usually trained on single machines,\nmissing out on cross-silo data and resources.\n  These paradigms are complementary, and their integration brings notable\nbenefits. Motivated by this, we propose FedGFM, a novel decentralized GFM\ntraining paradigm. However, a key challenge is knowledge entanglement, where\nmulti-domain knowledge merges into indistinguishable representations, hindering\ndownstream adaptation.\n  To address this, we present FedGFM+, an enhanced framework with two core\nmodules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based\ndomain-aware initialization strategy. Before pre-training, each client encodes\nits local graph into domain-specific prototypes that serve as semantic anchors.\nSynthetic embeddings around these anchors initialize the global model. We\ntheoretically prove these prototypes are distinguishable across domains,\nproviding a strong inductive bias to disentangle domain-specific knowledge. (2)\nAdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a\nlightweight graph prompt capturing domain semantics during pre-training. During\nfine-tuning, prompts from all clients form a pool from which the GFM selects\nrelevant prompts to augment target graph attributes, improving downstream\nadaptation.\n  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and\ntasks, outperforming 20 baselines from supervised learning, FGL, and federated\nGFM variants.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2505.12684v1",
    "published_date": "2025-05-19 04:06:32 UTC",
    "updated_date": "2025-05-19 04:06:32 UTC"
  },
  {
    "arxiv_id": "2505.12680v1",
    "title": "Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in Automated Theorem Proving on Inequalities",
    "authors": [
      "Haoyu Zhao",
      "Yihan Geng",
      "Shange Tang",
      "Yong Lin",
      "Bohan Lyu",
      "Hongzhou Lin",
      "Chi Jin",
      "Sanjeev Arora"
    ],
    "abstract": "LLM-based formal proof assistants (e.g., in Lean) hold great promise for\nautomating mathematical discovery. But beyond syntactic correctness, do these\nsystems truly understand mathematical structure as humans do? We investigate\nthis question through the lens of mathematical inequalities -- a fundamental\ntool across many domains. While modern provers can solve basic inequalities, we\nprobe their ability to handle human-intuitive compositionality. We introduce\nIneq-Comp, a benchmark built from elementary inequalities through systematic\ntransformations, including variable duplication, algebraic rewriting, and\nmulti-step composition. Although these problems remain easy for humans, we find\nthat most provers -- including Goedel, STP, and Kimina-7B -- struggle\nsignificantly. DeepSeek-Prover-V2-7B shows relative robustness -- possibly\nbecause it is trained to decompose the problems into sub-problems -- but still\nsuffers a 20\\% performance drop (pass@32). Strikingly, performance remains poor\nfor all models even when formal proofs of the constituent parts are provided in\ncontext, revealing that the source of weakness is indeed in compositional\nreasoning. Our results expose a persisting gap between the generalization\nbehavior of current AI provers and human mathematical intuition.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12680v1",
    "published_date": "2025-05-19 03:56:05 UTC",
    "updated_date": "2025-05-19 03:56:05 UTC"
  },
  {
    "arxiv_id": "2505.13547v1",
    "title": "Exploring Federated Pruning for Large Language Models",
    "authors": [
      "Pengxin Guo",
      "Yinong Wang",
      "Wei Li",
      "Mengting Liu",
      "Ming Li",
      "Jinkai Zheng",
      "Liangqiong Qu"
    ],
    "abstract": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13547v1",
    "published_date": "2025-05-19 03:41:54 UTC",
    "updated_date": "2025-05-19 03:41:54 UTC"
  },
  {
    "arxiv_id": "2505.12669v1",
    "title": "Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment",
    "authors": [
      "Abhinaba Roy",
      "Geeta Puri",
      "Dorien Herremans"
    ],
    "abstract": "We present Text2midi-InferAlign, a novel technique for improving symbolic\nmusic generation at inference time. Our method leverages text-to-audio\nalignment and music structural alignment rewards during inference to encourage\nthe generated music to be consistent with the input caption. Specifically, we\nintroduce two objectives scores: a text-audio consistency score that measures\nrhythmic alignment between the generated music and the original text caption,\nand a harmonic consistency score that penalizes generated music containing\nnotes inconsistent with the key. By optimizing these alignment-based objectives\nduring the generation process, our model produces symbolic music that is more\nclosely tied to the input captions, thereby improving the overall quality and\ncoherence of the generated compositions. Our approach can extend any existing\nautoregressive model without requiring further training or fine-tuning. We\nevaluate our work on top of Text2midi - an existing text-to-midi generation\nmodel, demonstrating significant improvements in both objective and subjective\nevaluation metrics.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS",
      "68T07",
      "I.2.1"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.12669v1",
    "published_date": "2025-05-19 03:36:06 UTC",
    "updated_date": "2025-05-19 03:36:06 UTC"
  },
  {
    "arxiv_id": "2505.13546v1",
    "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems",
    "authors": [
      "Ke Chen",
      "Yufei Zhou",
      "Xitong Zhang",
      "Haohan Wang"
    ],
    "abstract": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13546v1",
    "published_date": "2025-05-19 03:28:33 UTC",
    "updated_date": "2025-05-19 03:28:33 UTC"
  },
  {
    "arxiv_id": "2505.12664v1",
    "title": "Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design",
    "authors": [
      "Ziqing Xing",
      "Zhaoyang Zhang",
      "Zirui Chen",
      "Hongning Ruan",
      "Zhaohui Yang"
    ],
    "abstract": "In this paper, we incorporate physical knowledge into learning-based\nhigh-precision target sensing using the multi-view channel state information\n(CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind\nof multi-view sensing problem can be naturally cast into a conditional\ngeneration framework. To this end, we design a bipartite neural network\narchitecture, the first part of which uses an elaborately designed encoder to\nfuse the latent target features embedded in the multi-view CSI, and then the\nsecond uses them as conditioning inputs of a powerful generative model to guide\nthe target's reconstruction. Specifically, the encoder is designed to capture\nthe physical correlation between the CSI and the target, and also be adaptive\nto the numbers and positions of BS-UE pairs. Therein the view-specific nature\nof CSI is assimilated by introducing a spatial positional embedding scheme,\nwhich exploits the structure of electromagnetic(EM)-wave propagation channels.\nFinally, a conditional diffusion model with a weighted loss is employed to\ngenerate the target's point cloud from the fused features. Extensive numerical\nresults demonstrate that the proposed generative multi-view (Gen-MV) sensing\nframework exhibits excellent flexibility and significant performance\nimprovement on the reconstruction quality of target's shape and EM properties.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "submitted to IEEE Transactions on Wireless Communications",
    "pdf_url": "http://arxiv.org/pdf/2505.12664v1",
    "published_date": "2025-05-19 03:27:24 UTC",
    "updated_date": "2025-05-19 03:27:24 UTC"
  },
  {
    "arxiv_id": "2505.12662v1",
    "title": "Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering",
    "authors": [
      "Xukai Liu",
      "Ye Liu",
      "Shiwen Wu",
      "Yanghai Zhang",
      "Yihao Yuan",
      "Kai Zhang",
      "Qi Liu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have led to impressive\nprogress in natural language generation, yet their tendency to produce\nhallucinated or unsubstantiated content remains a critical concern. To improve\nfactual reliability, Retrieval-Augmented Generation (RAG) integrates external\nknowledge during inference. However, existing RAG systems face two major\nlimitations: (1) unreliable adaptive control due to limited external knowledge\nsupervision, and (2) hallucinations caused by inaccurate or irrelevant\nreferences. To address these issues, we propose Know3-RAG, a knowledge-aware\nRAG framework that leverages structured knowledge from knowledge graphs (KGs)\nto guide three core stages of the RAG process, including retrieval, generation,\nand filtering. Specifically, we introduce a knowledge-aware adaptive retrieval\nmodule that employs KG embedding to assess the confidence of the generated\nanswer and determine retrieval necessity, a knowledge-enhanced reference\ngeneration strategy that enriches queries with KG-derived entities to improve\ngenerated reference relevance, and a knowledge-driven reference filtering\nmechanism that ensures semantic alignment and factual accuracy of references.\nExperiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG\nconsistently outperforms strong baselines, significantly reducing\nhallucinations and enhancing answer reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12662v1",
    "published_date": "2025-05-19 03:25:18 UTC",
    "updated_date": "2025-05-19 03:25:18 UTC"
  },
  {
    "arxiv_id": "2505.13545v1",
    "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness",
    "authors": [
      "Jessica Foo",
      "Pradyumna Shyama Prasad",
      "Shaun Khoo"
    ],
    "abstract": "While the capabilities of large language models (LLMs) have progressed\nsignificantly, their use in high-stakes applications have been limited due to\nrisks of hallucination. One key approach in reducing hallucination is\nretrieval-augmented generation (RAG), but even in such setups, LLMs may still\nhallucinate when presented with questions outside of the knowledge base. Such\nbehavior is unacceptable in high-stake applications where LLMs are expected to\nabstain from answering queries it does not have sufficient context on. In this\nwork, we present a novel methodology for systematically evaluating\nout-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not\nknow) in the RAG setting, without the need for manual annotation of gold\nstandard answers. We implement our methodology in knowornot, an open-source\nlibrary that enables users to develop their own customized evaluation data and\npipelines for OOKB robustness. knowornot comprises four main features. Firstly,\nit provides a unified, high-level API that streamlines the process of setting\nup and running robustness benchmarks. Secondly, its modular architecture\nemphasizes extensibility and flexibility, allowing users to easily integrate\ntheir own LLM clients and RAG settings. Thirdly, its rigorous data modeling\ndesign ensures experiment reproducibility, reliability and traceability.\nLastly, it implements a comprehensive suite of tools for users to customize\ntheir pipelines. We demonstrate the utility of knowornot by developing a\nchallenging benchmark, PolicyBench, which spans four Question-Answer (QA)\nchatbots on government policies, and analyze its OOKB robustness. The source\ncode of knowornot is available\nhttps://github.com/govtech-responsibleai/KnowOrNot.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13545v1",
    "published_date": "2025-05-19 03:17:41 UTC",
    "updated_date": "2025-05-19 03:17:41 UTC"
  },
  {
    "arxiv_id": "2505.12655v1",
    "title": "Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models",
    "authors": [
      "Yisheng Zhong",
      "Yizhu Wen",
      "Junfeng Guo",
      "Mehran Kafai",
      "Heng Huang",
      "Hanqing Guo",
      "Zhuangdi Zhu"
    ],
    "abstract": "Protecting cyber Intellectual Property (IP) such as web content is an\nincreasingly critical concern. The rise of large language models (LLMs) with\nonline retrieval capabilities presents a double-edged sword that enables\nconvenient access to information but often undermines the rights of original\ncontent creators. As users increasingly rely on LLM-generated responses, they\ngradually diminish direct engagement with original information sources,\nsignificantly reducing the incentives for IP creators to contribute, and\nleading to a saturating cyberspace with more AI-generated content. In response,\nwe propose a novel defense framework that empowers web content creators to\nsafeguard their web-based IP from unauthorized LLM real-time extraction by\nleveraging the semantic understanding capability of LLMs themselves. Our method\nfollows principled motivations and effectively addresses an intractable\nblack-box optimization problem. Real-world experiments demonstrated that our\nmethods improve defense success rates from 2.5% to 88.6% on different LLMs,\noutperforming traditional defenses such as configuration-based restrictions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 13 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.12655v1",
    "published_date": "2025-05-19 03:14:08 UTC",
    "updated_date": "2025-05-19 03:14:08 UTC"
  },
  {
    "arxiv_id": "2505.12654v2",
    "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals",
    "authors": [
      "Yuxin Lin",
      "Yinglin Zheng",
      "Ming Zeng",
      "Wangzheng Shi"
    ],
    "abstract": "This paper addresses the gap in predicting turn-taking and backchannel\nactions in human-machine conversations using multi-modal signals (linguistic,\nacoustic, and visual). To overcome the limitation of existing datasets, we\npropose an automatic data collection pipeline that allows us to collect and\nannotate over 210 hours of human conversation videos. From this, we construct a\nMulti-Modal Face-to-Face (MM-F2F) human conversation dataset, including over\n1.5M words and corresponding turn-taking and backchannel annotations from\napproximately 20M frames. Additionally, we present an end-to-end framework that\npredicts the probability of turn-taking and backchannel actions from\nmulti-modal signals. The proposed model emphasizes the interrelation between\nmodalities and supports any combination of text, audio, and video inputs,\nmaking it adaptable to a variety of realistic scenarios. Our experiments show\nthat our approach achieves state-of-the-art performance on turn-taking and\nbackchannel prediction tasks, achieving a 10% increase in F1-score on\nturn-taking and a 33% increase on backchannel prediction. Our dataset and code\nare publicly available online to ease of subsequent research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepected by ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12654v2",
    "published_date": "2025-05-19 03:08:30 UTC",
    "updated_date": "2025-05-20 06:59:31 UTC"
  },
  {
    "arxiv_id": "2505.12651v1",
    "title": "$\\texttt{DIAMONDs}$: A Dataset for $\\mathbb{D}$ynamic $\\mathbb{I}$nformation $\\mathbb{A}$nd $\\mathbb{M}$ental modeling $\\mathbb{O}$f $\\mathbb{N}$umeric $\\mathbb{D}$iscussions",
    "authors": [
      "Sayontan Ghosh",
      "Mahnaz Koupaee",
      "Yash Kumar Lal",
      "Pegah Alipoormolabashi",
      "Mohammad Saqib Hasan",
      "Jun Seok Kang",
      "Niranjan Balasubramanian"
    ],
    "abstract": "Understanding multiparty conversations demands robust Theory of Mind (ToM)\ncapabilities, including the ability to track dynamic information, manage\nknowledge asymmetries, and distinguish relevant information across extended\nexchanges. To advance ToM evaluation in such settings, we present a carefully\ndesigned scalable methodology for generating high-quality benchmark\nconversation-question pairs with these characteristics. Using this methodology,\nwe create $\\texttt{DIAMONDs}$, a new conversational QA dataset covering common\nbusiness, financial or other group interactions. In these goal-oriented\nconversations, participants often have to track certain numerical quantities\n(say $\\textit{expected profit}$) of interest that can be derived from other\nvariable quantities (like $\\textit{marketing expenses, expected sales,\nsalary}$, etc.), whose values also change over the course of the conversation.\n$\\texttt{DIAMONDs}$ questions pose simple numerical reasoning problems over\nsuch quantities of interest (e.g., $\\textit{funds required for charity events,\nexpected company profit next quarter}$, etc.) in the context of the information\nexchanged in conversations. This allows for precisely evaluating ToM\ncapabilities for carefully tracking and reasoning over participants' knowledge\nstates.\n  Our evaluation of state-of-the-art language models reveals significant\nchallenges in handling participant-centric reasoning, specifically in\nsituations where participants have false beliefs. Models also struggle with\nconversations containing distractors and show limited ability to identify\nscenarios with insufficient information. These findings highlight current\nmodels' ToM limitations in handling real-world multi-party conversations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12651v1",
    "published_date": "2025-05-19 03:05:13 UTC",
    "updated_date": "2025-05-19 03:05:13 UTC"
  },
  {
    "arxiv_id": "2505.12650v1",
    "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use",
    "authors": [
      "Yaotian Yang",
      "Yiwen Tang",
      "Yizhe Chen",
      "Xiao Chen",
      "Jiangjie Qiu",
      "Hao Xiong",
      "Haoyu Yin",
      "Zhiyao Luo",
      "Yifei Zhang",
      "Sijia Tao",
      "Wentao Li",
      "Qinghua Zhang",
      "Yuqiang Li",
      "Wanli Ouyang",
      "Bin Zhao",
      "Xiaonan Wang",
      "Fei Wei"
    ],
    "abstract": "Machine learning-based interatomic potentials and force fields depend\ncritically on accurate atomic structures, yet such data are scarce due to the\nlimited availability of experimentally resolved crystals. Although\natomic-resolution electron microscopy offers a potential source of structural\ndata, converting these images into simulation-ready formats remains\nlabor-intensive and error-prone, creating a bottleneck for model training and\nvalidation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that\nautomatically transforms scanning transmission electron microscopy (STEM)\nimages into atomic crystal structures and predicts their physical properties.\nAutoMat combines pattern-adaptive denoising, physics-guided template retrieval,\nsymmetry-aware atomic reconstruction, fast relaxation and property prediction\nvia MatterSim, and coordinated orchestration across all stages. We propose the\nfirst dedicated STEM2Mat-Bench for this task and evaluate performance using\nlattice RMSD, formation energy MAE, and structure-matching success rate. By\norchestrating external tool calls, AutoMat enables a text-only LLM to\noutperform vision-language models in this domain, achieving closed-loop\nreasoning throughout the pipeline. In large-scale experiments over 450\nstructure samples, AutoMat substantially outperforms existing multimodal large\nlanguage models and tools. These results validate both AutoMat and\nSTEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic\nsimulation in materials science.The code and dataset are publicly available at\nhttps://github.com/yyt-2378/AutoMat and\nhttps://huggingface.co/datasets/yaotianvector/STEM2Mat.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The code and dataset are publicly available at\n  https://github.com/yyt-2378/AutoMat and\n  https://huggingface.co/datasets/yaotianvector/STEM2Mat",
    "pdf_url": "http://arxiv.org/pdf/2505.12650v1",
    "published_date": "2025-05-19 03:04:50 UTC",
    "updated_date": "2025-05-19 03:04:50 UTC"
  },
  {
    "arxiv_id": "2505.12641v1",
    "title": "Single Image Reflection Removal via inter-layer Complementarity",
    "authors": [
      "Yue Huang",
      "Zi'ang Li",
      "Tianle Hu",
      "Jie Wen",
      "Guanbin Li",
      "Jinglin Zhang",
      "Guoxu Zhou",
      "Xiaozhao Fang"
    ],
    "abstract": "Although dual-stream architectures have achieved remarkable success in single\nimage reflection removal, they fail to fully exploit inter-layer\ncomplementarity in their physical modeling and network design, which limits the\nquality of image separation. To address this fundamental limitation, we propose\ntwo targeted improvements to enhance dual-stream architectures: First, we\nintroduce a novel inter-layer complementarity model where low-frequency\ncomponents extracted from the residual layer interact with the transmission\nlayer through dual-stream architecture to enhance inter-layer complementarity.\nMeanwhile, high-frequency components from the residual layer provide inverse\nmodulation to both streams, improving the detail quality of the transmission\nlayer. Second, we propose an efficient inter-layer complementarity attention\nmechanism which first cross-reorganizes dual streams at the channel level to\nobtain reorganized streams with inter-layer complementary structures, then\nperforms attention computation on the reorganized streams to achieve better\ninter-layer separation, and finally restores the original stream structure for\noutput. Experimental results demonstrate that our method achieves\nstate-of-the-art separation quality on multiple public datasets while\nsignificantly reducing both computational cost and model complexity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12641v1",
    "published_date": "2025-05-19 02:50:15 UTC",
    "updated_date": "2025-05-19 02:50:15 UTC"
  },
  {
    "arxiv_id": "2505.12638v2",
    "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data",
    "authors": [
      "Yifeng Jiao",
      "Yuchen Liu",
      "Yu Zhang",
      "Xin Guo",
      "Yushuai Wu",
      "Chen Jiang",
      "Jiyang Li",
      "Hongwei Zhang",
      "Limei Han",
      "Xin Gao",
      "Yuan Qi",
      "Yuan Cheng"
    ],
    "abstract": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achieved significant success\nin single-cell transcriptomics, there is currently no foundation model for\nscATAC-seq that supports zero-shot high-quality cell identification and\ncomprehensive multi-omics analysis simultaneously. Key challenges lie in the\nhigh dimensionality and sparsity of scATAC-seq data, as well as the lack of a\nstandardized schema for representing open chromatin regions (OCRs). Here, we\npresent ChromFound, a foundation model tailored for scATAC-seq. ChromFound\nutilizes a hybrid architecture and genome-aware tokenization to effectively\ncapture genome-wide long contexts and regulatory signals from dynamic chromatin\nlandscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease\nconditions, ChromFound demonstrates broad applicability across 6 diverse tasks.\nNotably, it achieves robust zero-shot performance in generating universal cell\nrepresentations and exhibits excellent transferability in cell type annotation\nand cross-omics prediction. By uncovering enhancer-gene links undetected by\nexisting computational methods, ChromFound offers a promising framework for\nunderstanding disease risk variants in the noncoding genome.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12638v2",
    "published_date": "2025-05-19 02:45:42 UTC",
    "updated_date": "2025-05-20 02:40:30 UTC"
  },
  {
    "arxiv_id": "2505.12632v1",
    "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents",
    "authors": [
      "Yunseok Jang",
      "Yeda Song",
      "Sungryull Sohn",
      "Lajanugen Logeswaran",
      "Tiange Luo",
      "Dong-Ki Kim",
      "Kyunghoon Bae",
      "Honglak Lee"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have sparked significant interest in developing GUI visual\nagents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from\nYouTube), a large-scale dataset of 313K annotated frames from 20K instructional\nvideos capturing diverse real-world mobile OS navigation across multiple\nplatforms. Models that include MONDAY in their pre-training phases demonstrate\nrobust cross-platform generalization capabilities, consistently outperforming\nmodels trained on existing single OS datasets while achieving an average\nperformance gain of 18.11%p on an unseen mobile OS platform. To enable\ncontinuous dataset expansion as mobile platforms evolve, we present an\nautomated framework that leverages publicly available video content to create\ncomprehensive task datasets without manual annotation. Our framework comprises\nrobust OCR-based scene detection (95.04% F1score), near-perfect UI element\ndetection (99.87% hit ratio), and novel multi-step action identification to\nextract reliable action sequences across diverse interface configurations. We\ncontribute both the MONDAY dataset and our automated collection framework to\nfacilitate future research in mobile OS navigation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12632v1",
    "published_date": "2025-05-19 02:39:03 UTC",
    "updated_date": "2025-05-19 02:39:03 UTC"
  },
  {
    "arxiv_id": "2505.12630v1",
    "title": "Degradation-Aware Feature Perturbation for All-in-One Image Restoration",
    "authors": [
      "Xiangpeng Tian",
      "Xiangyu Liao",
      "Xiao Liu",
      "Meng Li",
      "Chao Ren"
    ],
    "abstract": "All-in-one image restoration aims to recover clear images from various\ndegradation types and levels with a unified model. Nonetheless, the significant\nvariations among degradation types present challenges for training a universal\nmodel, often resulting in task interference, where the gradient update\ndirections of different tasks may diverge due to shared parameters. To address\nthis issue, motivated by the routing strategy, we propose DFPIR, a novel\nall-in-one image restorer that introduces Degradation-aware Feature\nPerturbations(DFP) to adjust the feature space to align with the unified\nparameter space. In this paper, the feature perturbations primarily include\nchannel-wise perturbations and attention-wise perturbations. Specifically,\nchannel-wise perturbations are implemented by shuffling the channels in\nhigh-dimensional space guided by degradation types, while attention-wise\nperturbations are achieved through selective masking in the attention space. To\nachieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB)\nto implement these two functions, positioned between the encoding and decoding\nstages of the encoder-decoder architecture. Extensive experimental results\ndemonstrate that DFPIR achieves state-of-the-art performance on several\nall-in-one image restoration tasks including image denoising, image dehazing,\nimage deraining, motion deblurring, and low-light image enhancement. Our codes\nare available at https://github.com/TxpHome/DFPIR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025. 8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12630v1",
    "published_date": "2025-05-19 02:37:11 UTC",
    "updated_date": "2025-05-19 02:37:11 UTC"
  },
  {
    "arxiv_id": "2505.12626v1",
    "title": "scSiameseClu: A Siamese Clustering Framework for Interpreting single-cell RNA Sequencing Data",
    "authors": [
      "Ping Xu",
      "Zhiyuan Ning",
      "Pengjiang Li",
      "Wenhao Liu",
      "Pengyang Wang",
      "Jiaxu Cui",
      "Yuanchun Zhou",
      "Pengfei Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) reveals cell heterogeneity, with cell\nclustering playing a key role in identifying cell types and marker genes.\nRecent advances, especially graph neural networks (GNNs)-based methods, have\nsignificantly improved clustering performance. However, the analysis of\nscRNA-seq data remains challenging due to noise, sparsity, and high\ndimensionality. Compounding these challenges, GNNs often suffer from\nover-smoothing, limiting their ability to capture complex biological\ninformation. In response, we propose scSiameseClu, a novel Siamese Clustering\nframework for interpreting single-cell RNA-seq data, comprising of 3 key steps:\n(1) Dual Augmentation Module, which applies biologically informed perturbations\nto the gene expression matrix and cell graph relationships to enhance\nrepresentation robustness; (2) Siamese Fusion Module, which combines\ncross-correlation refinement and adaptive information fusion to capture complex\ncellular relationships while mitigating over-smoothing; and (3) Optimal\nTransport Clustering, which utilizes Sinkhorn distance to efficiently align\ncluster assignments with predefined proportions while maintaining balance.\nComprehensive evaluations on seven real-world datasets demonstrate\nthat~\\methodname~outperforms state-of-the-art methods in single-cell\nclustering, cell type annotation, and cell type classification, providing a\npowerful tool for scRNA-seq data interpretation.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12626v1",
    "published_date": "2025-05-19 02:17:09 UTC",
    "updated_date": "2025-05-19 02:17:09 UTC"
  },
  {
    "arxiv_id": "2505.12623v1",
    "title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding",
    "authors": [
      "Keisuke Okumura",
      "Hiroki Nagai"
    ],
    "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a\nvariety of multi-agent pathfinding (MAPF) problems, generating the next\ncollision-free locations of agents given another. Because of its simplicity and\nscalability, it is becoming a popular underlying scheme for recent large-scale\nMAPF methods involving several hundreds or thousands of agents. Vanilla PIBT\nmakes agents behave greedily towards their assigned goals, while agents\ntypically have multiple best actions, since the graph shortest path is not\nalways unique. Consequently, tiebreaking about how to choose between these\nactions significantly affects resulting solutions. This paper studies two\nsimple yet effective techniques for tiebreaking in PIBT, without compromising\nits computational advantage. The first technique allows an agent to\nintelligently dodge another, taking into account whether each action will\nhinder the progress of the next timestep. The second technique is to learn,\nthrough multiple PIBT runs, how an action causes regret in others and to use\nthis information to minimise regret collectively. Our empirical results\ndemonstrate that these techniques can reduce the solution cost of one-shot MAPF\nand improve the throughput of lifelong MAPF. For instance, in densely populated\none-shot cases, the combined use of these tiebreaks achieves improvements of\naround 10-20% in sum-of-costs, without significantly compromising the speed of\na PIBT-based planner.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "To be presented at SoCS-25",
    "pdf_url": "http://arxiv.org/pdf/2505.12623v1",
    "published_date": "2025-05-19 02:12:29 UTC",
    "updated_date": "2025-05-19 02:12:29 UTC"
  },
  {
    "arxiv_id": "2505.13544v2",
    "title": "Multi-head Temporal Latent Attention",
    "authors": [
      "Keqi Deng",
      "Philip C. Woodland"
    ],
    "abstract": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13544v2",
    "published_date": "2025-05-19 02:09:41 UTC",
    "updated_date": "2025-05-21 01:34:19 UTC"
  },
  {
    "arxiv_id": "2505.12594v1",
    "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection",
    "authors": [
      "Tiankai Yang",
      "Junjun Liu",
      "Wingchun Siu",
      "Jiahang Wang",
      "Zhuangzhuang Qian",
      "Chanjuan Song",
      "Cheng Cheng",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network\nmonitoring, and scientific research. However, the diversity of data modalities\nand the increasing number of specialized AD libraries pose challenges for\nnon-expert users who lack in-depth library-specific knowledge and advanced\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\nmulti-agent framework that turns natural-language instructions into fully\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\nparsing, data preparation, library and model selection, documentation mining,\nand iterative code generation and debugging. Using a shared short-term\nworkspace and a long-term cache, the agents integrate popular AD libraries like\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\nAD-AGENT produces reliable scripts and recommends competitive models across\nlibraries. The system is open-sourced to support further research and practical\napplications in AD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12594v1",
    "published_date": "2025-05-19 01:14:57 UTC",
    "updated_date": "2025-05-19 01:14:57 UTC"
  },
  {
    "arxiv_id": "2505.12585v1",
    "title": "Learning Robust Spectral Dynamics for Temporal Domain Generalization",
    "authors": [
      "En Yu",
      "Jie Lu",
      "Xiaoyu Yang",
      "Guangquan Zhang",
      "Zhen Fang"
    ],
    "abstract": "Modern machine learning models struggle to maintain performance in dynamic\nenvironments where temporal distribution shifts, \\emph{i.e., concept drift},\nare prevalent. Temporal Domain Generalization (TDG) seeks to enable model\ngeneralization across evolving domains, yet existing approaches typically\nassume smooth incremental changes, struggling with complex real-world drifts\ninvolving long-term structure (incremental evolution/periodicity) and local\nuncertainties. To overcome these limitations, we introduce FreKoo, which\ntackles these challenges via a novel frequency-domain analysis of parameter\ntrajectories. It leverages the Fourier transform to disentangle parameter\nevolution into distinct spectral bands. Specifically, low-frequency component\nwith dominant dynamics are learned and extrapolated using the Koopman operator,\nrobustly capturing diverse drift patterns including both incremental and\nperiodicity. Simultaneously, potentially disruptive high-frequency variations\nare smoothed via targeted temporal regularization, preventing overfitting to\ntransient noise and domain uncertainties. In addition, this dual spectral\nstrategy is rigorously grounded through theoretical analysis, providing\nstability guarantees for the Koopman prediction, a principled Bayesian\njustification for the high-frequency regularization, and culminating in a\nmultiscale generalization bound connecting spectral dynamics to improved\ngeneralization. Extensive experiments demonstrate FreKoo's significant\nsuperiority over SOTA TDG approaches, particularly excelling in real-world\nstreaming scenarios with complex drifts and uncertainties.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12585v1",
    "published_date": "2025-05-19 00:38:18 UTC",
    "updated_date": "2025-05-19 00:38:18 UTC"
  },
  {
    "arxiv_id": "2505.12583v1",
    "title": "A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics",
    "authors": [
      "Takeshi Kojima",
      "Yaonan Zhu",
      "Yusuke Iwasawa",
      "Toshinori Kitamura",
      "Gang Yan",
      "Shu Morikuni",
      "Ryosuke Takanami",
      "Alfredo Solano",
      "Tatsuya Matsushima",
      "Akiko Murakami",
      "Yutaka Matsuo"
    ],
    "abstract": "Recent Foundation Model-enabled robotics (FMRs) display greatly improved\ngeneral-purpose skills, enabling more adaptable automation than conventional\nrobotics. Their ability to handle diverse tasks thus creates new opportunities\nto replace human labor. However, unlike general foundation models, FMRs\ninteract with the physical world, where their actions directly affect the\nsafety of humans and surrounding objects, requiring careful deployment and\ncontrol. Based on this proposition, our survey comprehensively summarizes robot\ncontrol approaches to mitigate physical risks by covering all the lifespan of\nFMRs ranging from pre-deployment to post-accident stage. Specifically, we\nbroadly divide the timeline into the following three phases: (1) pre-deployment\nphase, (2) pre-incident phase, and (3) post-incident phase. Throughout this\nsurvey, we find that there is much room to study (i) pre-incident risk\nmitigation strategies, (ii) research that assumes physical interaction with\nhumans, and (iii) essential issues of foundation models themselves. We hope\nthat this survey will be a milestone in providing a high-resolution analysis of\nthe physical risks of FMRs and their control, contributing to the realization\nof a good human-robot relationship.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IJCAI 2025 Survey Track",
    "pdf_url": "http://arxiv.org/pdf/2505.12583v1",
    "published_date": "2025-05-19 00:11:42 UTC",
    "updated_date": "2025-05-19 00:11:42 UTC"
  },
  {
    "arxiv_id": "2505.12581v1",
    "title": "An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification",
    "authors": [
      "Lucas M. Dorneles",
      "Luan Fonseca Garcia",
      "Joel Luís Carbonera"
    ],
    "abstract": "Neural networks have become increasingly popular in the last few years as an\neffective tool for the task of image classification due to the impressive\nperformance they have achieved on this task. In image classification tasks, it\nis common to use data augmentation strategies to increase the robustness of\ntrained networks to changes in the input images and to avoid overfitting.\nAlthough data augmentation is a widely adopted technique, the literature lacks\na body of research analyzing the effects data augmentation methods have on the\npatterns learned by neural network models working on complex datasets. The\nprimary objective of this work is to propose a methodology and set of metrics\nthat may allow a quantitative approach to analyzing the effects of data\naugmentation in convolutional networks applied to image classification. An\nimportant tool used in the proposed approach lies in the concept of class\nactivation maps for said models, which allow us to identify and measure the\nimportance these models assign to each individual pixel in an image when\nexecuting the classification task. From these maps, we may then extract metrics\nover the similarities and differences between maps generated by these models\ntrained on a given dataset with different data augmentation strategies.\nExperiments made using this methodology suggest that the effects of these data\naugmentation techniques not only can be analyzed in this way but also allow us\nto identify different impact profiles over the trained models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12581v1",
    "published_date": "2025-05-19 00:03:57 UTC",
    "updated_date": "2025-05-19 00:03:57 UTC"
  }
]