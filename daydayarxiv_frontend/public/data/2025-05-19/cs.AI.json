{
  "date": "2025-05-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-19 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 更新聚焦于 AI 模型的优化与应用，特别是大型语言模型（LLM）的推理能力、多模态处理和联邦学习等领域，亮点包括高效的强化学习框架（如 CoIn 和 DreamGen）、多模态生成（如 Sat2Sound）和 LLM 安全基准（如 CausalPitfalls），以及知名学者如 Subbarao Kambhampati 的多篇工作，这些论文展示了 AI 在复杂任务中的潜力，同时强调了透明度和鲁棒性。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论那些创新性强、可能引发话题的文章（如 LLM 推理、强化学习和多模态方法），并将相关主题归类讨论。对于其他较为常规的论文（如图像处理或特定领域优化），我将快速掠过，只突出核心贡献。每个条目包括论文标题（中文 + 英文）和主要发现，保留核心学术术语。\n\n### LLM 推理与优化（重点主题，相关论文优先讨论）\n- **CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs**（英文原题：CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs）  \n  这篇论文提出 CoIn 框架，用于审计商业 LLM API 中的隐藏推理令牌，检测令牌计数膨胀。主要贡献是通过散列树和嵌入相关性匹配，实现高达 94.7% 的检测成功率，提升了 LLM 服务的计费透明度。\n\n- **Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens**（英文原题：Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens）  \n  作者 Subbarao Kambhampati 等研究了 Chain-of-Thought（CoT）在 LLM 推理中的局限性，发现即使中间令牌不准确，模型性能也能维持，主要发现是非语义中间令牌对最终准确性的松散影响，挑战了 CoT 的传统解释。\n\n- **Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models**（英文原题：Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models）  \n  这篇工作引入反事实干预框架评估大型推理模型的中间推理忠实度，主要贡献是评估内部推理步骤和最终答案的因果依赖，揭示了模型在逻辑一致性上的不足。\n\n- **Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations**（英文原题：Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations）  \n  论文展示了 LLM 在监控内部激活方面的元认知能力，通过神经反馈范式量化模型的自报告和控制，主要发现是 LLM 能学习报告特定神经方向，但受限于低维元认知空间。\n\n- **RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs**（英文原题：RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs）  \n  Subbarao Kambhampati 等人质疑了 LLM 后训练中强化学习的结构假设，主要发现是这些假设可能使 RL 退化成监督学习，呼吁更严格的建模。\n\n- **DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories**（英文原题：DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories）  \n  这篇论文提出 DreamGen 框架，使用神经轨迹提升机器人学习泛化性，主要贡献是通过视频世界模型生成合成数据，实现机器人行为和环境泛化。\n\n- **Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs**（英文原题：Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs）  \n  论文设计了自适应混合训练框架，结合监督微调和强化学习优化 LLM，主要发现是改进了任务特定性能，同时减少了冗余计算。\n\n- **Thinkless: LLM Learns When to Think**（英文原题：Thinkless: LLM Learns When to Think）  \n  这篇工作探索 LLM 在何时进行推理，主要贡献是通过强化学习让模型自适应选择简短或详细推理，显著降低了响应长度并提升了效率。\n\n这些 LLM 相关论文共同探讨了模型的推理鲁棒性、安全性和效率，Subbarao Kambhampati 的多篇工作特别值得关注，因为它们质疑了当前强化学习假设，推动了更可靠的 LLM 设计。\n\n### 多模态与图像生成（相关论文归类讨论）\n- **Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping**（英文原题：Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping）  \n  论文提出 Sat2Sound 框架，用于零样本声音场景映射，主要发现是通过对比学习融合卫星图像和音频，实现跨模态检索和声音合成。\n\n- **Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments**（英文原题：Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments）  \n  这篇工作比较了 AI 队友熟悉化方法，主要贡献是强调文档和交互训练的结合，提高了人类-AI 团队协作策略。\n\n- **Language Models That Walk the Talk: A Framework for Formal Fairness Certificates**（英文原题：Language Models That Walk the Talk: A Framework for Formal Fairness Certificates）  \n  论文开发了形式化公平框架，用于语言模型的稳健性验证，主要发现是通过嵌入空间的正式验证，确保模型在公平任务中的可靠性。\n\n这些多模态论文突出了 AI 在声音、图像和团队协作中的应用，Sat2Sound 的零样本能力尤其引人注目。\n\n### 强化学习与机器人（快速讨论创新点）\n- **Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings**（英文原题：Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings）  \n  主要贡献是两阶段训练策略，提升了资源受限环境下的推理泛化。\n\n- **SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation**（英文原题：SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation）  \n  论文使用 LLM 生成协作策略，主要发现是提高了多机器人导航效率。\n\n这些论文展示了强化学习在机器人领域的潜力，但细节较常规，故快速掠过。\n\n### 其他领域（简要概述，控制篇幅）\n- 对于图像处理和时间序列等论文，如 **VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation**（主要发现：评估视觉标记器的性能，提升图像生成质量）和 **Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training**（分析 LLM 预训练的缩放定律），这些工作虽有贡献，但非核心热点，故仅提及其优化方法。\n- 联邦学习论文如 **Self-Reinforced Graph Contrastive Learning**（提出 SRGCL 框架，提升图表示学习）和 **Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning**（改进离线强化学习的鲁棒性），快速总结为隐私保护和鲁棒性提升。\n- 剩余论文（如数学建模、音频处理等）由于篇幅有限，仅注：今日还包括多篇图像、音频和数学领域的技术改进，聚焦效率和泛化，但细节较常规。\n\n总之，今天的更新突显了 AI 社区对模型安全、推理和多模态的持续探索，相关论文为未来应用提供了坚实基础。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2505.13778v1",
      "title": "CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs",
      "title_zh": "CoIn：计数商业不透明LLM API中的不可见推理令牌",
      "authors": [
        "Guoheng Sun",
        "Ziyao Wang",
        "Bowei Tian",
        "Meng Liu",
        "Zheyu Shen",
        "Shwai He",
        "Yexiao He",
        "Wanghao Ye",
        "Yiting Wang",
        "Ang Li"
      ],
      "abstract": "As post-training techniques evolve, large language models (LLMs) are\nincreasingly augmented with structured multi-step reasoning abilities, often\noptimized through reinforcement learning. These reasoning-enhanced models\noutperform standard LLMs on complex tasks and now underpin many commercial LLM\nAPIs. However, to protect proprietary behavior and reduce verbosity, providers\ntypically conceal the reasoning traces while returning only the final answer.\nThis opacity introduces a critical transparency gap: users are billed for\ninvisible reasoning tokens, which often account for the majority of the cost,\nyet have no means to verify their authenticity. This opens the door to token\ncount inflation, where providers may overreport token usage or inject\nsynthetic, low-effort tokens to inflate charges. To address this issue, we\npropose CoIn, a verification framework that audits both the quantity and\nsemantic validity of hidden tokens. CoIn constructs a verifiable hash tree from\ntoken embedding fingerprints to check token counts, and uses embedding-based\nrelevance matching to detect fabricated reasoning content. Experiments\ndemonstrate that CoIn, when deployed as a trusted third-party auditor, can\neffectively detect token count inflation with a success rate reaching up to\n94.7%, showing the strong ability to restore billing transparency in opaque LLM\nservices. The dataset and code are available at\nhttps://github.com/CASE-Lab-UMD/LLM-Auditing-CoIn.",
      "tldr_zh": "该研究探讨了商业大型语言模型 (LLMs) API 的不透明性问题，用户为隐藏的推理 tokens 付费，却无法验证其真实性，可能导致 token count inflation 和过度收费。作者提出 CoIn 框架，通过构建基于 token embedding fingerprints 的可验证 hash tree 来审计 tokens 数量，并使用 embedding-based relevance matching 检测伪造内容。实验结果显示，CoIn 作为第三方审计工具能有效识别 tokens 膨胀，成功率高达 94.7%，从而提升了 LLM 服务的计费透明度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13778v1",
      "published_date": "2025-05-19 23:39:23 UTC",
      "updated_date": "2025-05-19 23:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:59:52.669695"
    },
    {
      "arxiv_id": "2505.13777v1",
      "title": "Sat2Sound: A Unified Framework for Zero-Shot Soundscape Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Subash Khanal",
        "Srikumar Sastry",
        "Aayush Dhakal",
        "Adeel Ahmad",
        "Nathan Jacobs"
      ],
      "abstract": "We present Sat2Sound, a multimodal representation learning framework for\nsoundscape mapping, designed to predict the distribution of sounds at any\nlocation on Earth. Existing methods for this task rely on satellite image and\npaired geotagged audio samples, which often fail to capture the diversity of\nsound sources at a given location. To address this limitation, we enhance\nexisting datasets by leveraging a Vision-Language Model (VLM) to generate\nsemantically rich soundscape descriptions for locations depicted in satellite\nimages. Our approach incorporates contrastive learning across audio, audio\ncaptions, satellite images, and satellite image captions. We hypothesize that\nthere is a fixed set of soundscape concepts shared across modalities. To this\nend, we learn a shared codebook of soundscape concepts and represent each\nsample as a weighted average of these concepts. Sat2Sound achieves\nstate-of-the-art performance in cross-modal retrieval between satellite image\nand audio on two datasets: GeoSound and SoundingEarth. Additionally, building\non Sat2Sound's ability to retrieve detailed soundscape captions, we introduce a\nnovel application: location-based soundscape synthesis, which enables immersive\nacoustic experiences. Our code and models will be publicly available.",
      "tldr_zh": "本研究提出 Sat2Sound，一种统一的零样本（Zero-Shot）声景映射框架，用于预测地球上任何地点的声音分布，以解决现有方法依赖卫星图像和配对音频时无法捕捉声音来源多样性的问题。该框架利用 Vision-Language Model (VLM) 增强数据集，生成卫星图像的语义丰富描述，并通过对比学习（contrastive learning）跨音频、音频标题、卫星图像和图像标题学习一个共享的声景概念 codebook，每个样本作为这些概念的加权平均。在 GeoSound 和 SoundingEarth 数据集上，Sat2Sound 实现了卫星图像和音频的 state-of-the-art 跨模态检索性能，并引入基于位置的声景合成应用，提供沉浸式声学体验。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13777v1",
      "published_date": "2025-05-19 23:36:04 UTC",
      "updated_date": "2025-05-19 23:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:00:06.239786"
    },
    {
      "arxiv_id": "2505.13775v1",
      "title": "Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Kaya Stechly",
        "Karthik Valmeekam",
        "Atharva Gundawar",
        "Vardhan Palod",
        "Subbarao Kambhampati"
      ],
      "abstract": "Recent impressive results from large reasoning models have been interpreted\nas a triumph of Chain of Thought (CoT), and especially of the process of\ntraining on CoTs sampled from base LLMs in order to help find new reasoning\npatterns. In this paper, we critically examine that interpretation by\ninvestigating how the semantics of intermediate tokens-often anthropomorphized\nas \"thoughts\" or reasoning traces and which are claimed to display behaviors\nlike backtracking, self-verification etc.-actually influence model performance.\nWe train transformer models on formally verifiable reasoning traces and\nsolutions, constraining both intermediate steps and final outputs to align with\nthose of a formal solver (in our case, A* search). By constructing a formal\ninterpreter of the semantics of our problems and intended algorithm, we\nsystematically evaluate not only solution accuracy but also the correctness of\nintermediate traces, thus allowing us to evaluate whether the latter causally\ninfluences the former. We notice that, despite significant improvements on the\nsolution-only baseline, models trained on entirely correct traces still produce\ninvalid reasoning traces when arriving at correct solutions. To further show\nthat trace accuracy is only loosely connected to solution accuracy, we then\ntrain models on noisy, corrupted traces which have no relation to the specific\nproblem each is paired with, and find that not only does performance remain\nlargely consistent with models trained on correct data, but in some cases can\nimprove upon it and generalize more robustly on out-of-distribution tasks.\nThese results challenge the assumption that intermediate tokens or \"Chains of\nThought\" induce predictable reasoning behaviors and caution against\nanthropomorphizing such outputs or over-interpreting them (despite their mostly\ncorrect forms) as evidence of human-like or algorithmic behaviors in language\nmodels.",
      "tldr_zh": "本研究质疑了Chain of Thought (CoT)方法的有效性，通过训练transformer models来考察intermediate tokens的语义（常被视为“推理痕迹”）是否真正影响模型性能。研究者使用基于A* search的正式可验证推理痕迹进行训练，并系统评估中间步骤的正确性与最终解决方案的关联。结果显示，即使训练数据完全正确，模型仍可能产生无效的推理痕迹；此外，使用噪声或与问题无关的腐败痕迹训练时，模型性能保持稳定、甚至在某些任务上提升，并显示出更强的分布外泛化能力。这些发现挑战了intermediate tokens能诱导可预测推理行为的假设，并警告不要将模型输出过度解读为人类-like或算法行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13775v1",
      "published_date": "2025-05-19 23:29:23 UTC",
      "updated_date": "2025-05-19 23:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:00:17.539138"
    },
    {
      "arxiv_id": "2505.13774v1",
      "title": "Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models",
      "title_zh": "测量大型推理模型中思考草稿的忠实度",
      "authors": [
        "Zidi Xiong",
        "Chen Shan",
        "Zhenting Qi",
        "Himabindu Lakkaraju"
      ],
      "abstract": "Large Reasoning Models (LRMs) have significantly enhanced their capabilities\nin complex problem-solving by introducing a thinking draft that enables\nmulti-path Chain-of-Thought explorations before producing final answers.\nEnsuring the faithfulness of these intermediate reasoning processes is crucial\nfor reliable monitoring, interpretation, and effective control. In this paper,\nwe propose a systematic counterfactual intervention framework to rigorously\nevaluate thinking draft faithfulness. Our approach focuses on two complementary\ndimensions: (1) Intra-Draft Faithfulness, which assesses whether individual\nreasoning steps causally influence subsequent steps and the final draft\nconclusion through counterfactual step insertions; and (2) Draft-to-Answer\nFaithfulness, which evaluates whether final answers are logically consistent\nwith and dependent on the thinking draft, by perturbing the draft's concluding\nlogic. We conduct extensive experiments across six state-of-the-art LRMs. Our\nfindings show that current LRMs demonstrate selective faithfulness to\nintermediate reasoning steps and frequently fail to faithfully align with the\ndraft conclusions. These results underscore the need for more faithful and\ninterpretable reasoning in advanced LRMs.",
      "tldr_zh": "本论文探讨了 Large Reasoning Models (LRMs) 中 thinking draft 的 faithfulness，旨在评估这些中间推理过程是否可靠，以支持模型的监控、解释和控制。研究提出一个系统性的 counterfactual intervention 框架，包括 Intra-Draft Faithfulness（通过 counterfactual step insertions 检查单个推理步骤对后续步骤和结论的因果影响）和 Draft-to-Answer Faithfulness（通过 perturbing the draft's concluding logic 验证最终答案的逻辑一致性和依赖性）。在六种 state-of-the-art LRMs 上进行的实验发现，这些模型对中间推理步骤表现出选择性 faithfulness，并经常无法与 draft 结论保持一致，强调了提升 LRMs 推理的 faithful 和 interpretable 性的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13774v1",
      "published_date": "2025-05-19 23:20:24 UTC",
      "updated_date": "2025-05-19 23:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:00:29.310828"
    },
    {
      "arxiv_id": "2505.13773v1",
      "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Bowers",
        "Richard Agbeyibor",
        "Jack Kolb",
        "Karen Feigh"
      ],
      "abstract": "We compare three methods of familiarizing a human with an artificial\nintelligence (AI) teammate (\"agent\") prior to operation in a collaborative,\nfast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In\na between-subjects user study (n=60), participants either read documentation\nabout the agent, trained alongside the agent prior to the mission, or were\ngiven no familiarization. Results showed that the most valuable information\nabout the agent included details of its decision-making algorithms and its\nrelative strengths and weaknesses compared to the human. This information\nallowed the familiarization groups to form sophisticated team strategies more\nquickly than the control group. Documentation-based familiarization led to the\nfastest adoption of these strategies, but also biased participants towards\nrisk-averse behavior that prevented high scores. Participants familiarized\nthrough direct interaction were able to infer much of the same information\nthrough observation, and were more willing to take risks and experiment with\ndifferent control modes, but reported weaker understanding of the agent's\ninternal processes. Significant differences were seen between individual\nparticipants' risk tolerance and methods of AI interaction, which should be\nconsidered when designing human-AI control interfaces. Based on our findings,\nwe recommend a human-AI team familiarization method that combines AI\ndocumentation, structured in-situ training, and exploratory interaction.",
      "tldr_zh": "这篇论文比较了三种人类-AI 团队熟悉化方法，包括阅读 AI 文档、与 AI 一起训练，以及无熟悉化干预，在高风险的协作性情报、监视和侦察 (ISR) 环境中进行评估。研究通过一个 between-subjects 用户研究 (n=60) 发现，提供 AI 决策算法和相对优缺点的详细信息能帮助团队更快制定复杂策略，但文档-based 方法可能导致风险厌恶行为，影响高分表现。直接互动熟悉化允许参与者通过观察推断关键信息，并更愿意冒险实验不同控制模式，但对 AI 内部过程的理解较弱。基于这些发现，论文推荐一种结合 AI 文档、结构化 in-situ 训练和探索性互动的混合熟悉化方法，以优化 human-AI team 绩效。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13773v1",
      "published_date": "2025-05-19 23:19:16 UTC",
      "updated_date": "2025-05-19 23:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:00:42.691271"
    },
    {
      "arxiv_id": "2505.13770v1",
      "title": "Ice Cream Doesn't Cause Drowning: Benchmarking LLMs Against Statistical Pitfalls in Causal Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Du",
        "Li Chen",
        "Xun Xian",
        "An Luo",
        "Fangqiao Tian",
        "Ganghua Wang",
        "Charles Doss",
        "Xiaotong Shen",
        "Jie Ding"
      ],
      "abstract": "Reliable causal inference is essential for making decisions in high-stakes\nareas like medicine, economics, and public policy. However, it remains unclear\nwhether large language models (LLMs) can handle rigorous and trustworthy\nstatistical causal inference. Current benchmarks usually involve simplified\ntasks. For example, these tasks might only ask LLMs to identify semantic causal\nrelationships or draw conclusions directly from raw data. As a result, models\nmay overlook important statistical pitfalls, such as Simpson's paradox or\nselection bias. This oversight limits the applicability of LLMs in the real\nworld. To address these limitations, we propose CausalPitfalls, a comprehensive\nbenchmark designed to rigorously evaluate the capability of LLMs in overcoming\ncommon causal inference pitfalls. Our benchmark features structured challenges\nacross multiple difficulty levels, each paired with grading rubrics. This\napproach allows us to quantitatively measure both causal reasoning capabilities\nand the reliability of LLMs' responses. We evaluate models using two protocols:\n(1) direct prompting, which assesses intrinsic causal reasoning, and (2)\ncode-assisted prompting, where models generate executable code for explicit\nstatistical analysis. Additionally, we validate the effectiveness of this judge\nby comparing its scoring with assessments from human experts. Our results\nreveal significant limitations in current LLMs when performing statistical\ncausal inference. The CausalPitfalls benchmark provides essential guidance and\nquantitative metrics to advance the development of trustworthy causal reasoning\nsystems.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在因果推理中的局限性，特别是忽略统计陷阱如Simpson's paradox和selection bias，导致其在高风险领域（如医学和经济）的可靠性不足。作者提出CausalPitfalls基准，这是一个全面评估框架，包含多难度级别的结构化挑战、评分标准，以及两种评估协议：直接提示和代码-assisted prompting，以量化LLMs的因果推理能力和响应可靠性。实验结果显示当前LLMs存在显著缺陷，并通过与人类专家比较验证了基准的有效性，为推进可信赖的因果推理系统提供了关键指导和量化指标。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ME",
        "stat.ML",
        "62-08, 68T50, 68T05, 68T01, 68T07, 62-07, 68U35, 62C99",
        "I.2.7; I.2.6; I.2.0; I.5.1; I.5.4; F.2.2; H.2.8; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13770v1",
      "published_date": "2025-05-19 23:06:00 UTC",
      "updated_date": "2025-05-19 23:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:00:53.250488"
    },
    {
      "arxiv_id": "2505.13766v1",
      "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques",
      "title_zh": "推进软件质量：基于LLM的标准导向保证技术回顾",
      "authors": [
        "Avinash Patil"
      ],
      "abstract": "Software Quality Assurance (SQA) is critical for delivering reliable, secure,\nand efficient software products. The Software Quality Assurance Process aims to\nprovide assurance that work products and processes comply with predefined\nprovisions and plans. Recent advancements in Large Language Models (LLMs)\npresent new opportunities to enhance existing SQA processes by automating tasks\nlike requirement analysis, code review, test generation, and compliance checks.\nSimultaneously, established standards such as ISO/IEC 12207, ISO/IEC 25010,\nISO/IEC 5055, ISO 9001/ISO/IEC 90003, CMMI, and TMM provide structured\nframeworks for ensuring robust quality practices. This paper surveys the\nintersection of LLM-based SQA methods and these recognized standards,\nhighlighting how AI-driven solutions can augment traditional approaches while\nmaintaining compliance and process maturity. We first review the foundational\nsoftware quality standards and the technical fundamentals of LLMs in software\nengineering. Next, we explore various LLM-based SQA applications, including\nrequirement validation, defect detection, test generation, and documentation\nmaintenance. We then map these applications to key software quality frameworks,\nillustrating how LLMs can address specific requirements and metrics within each\nstandard. Empirical case studies and open-source initiatives demonstrate the\npractical viability of these methods. At the same time, discussions on\nchallenges (e.g., data privacy, model bias, explainability) underscore the need\nfor deliberate governance and auditing. Finally, we propose future directions\nencompassing adaptive learning, privacy-focused deployments, multimodal\nanalysis, and evolving standards for AI-driven software quality.",
      "tldr_zh": "这篇论文审视了大型语言模型 (LLMs) 在软件质量保证 (SQA) 中的应用，重点探讨如何通过自动化任务（如需求分析、代码审查、测试生成和合规检查）来增强传统 SQA 过程，同时与标准如 ISO/IEC 12207、ISO/IEC 25010 和 CMMI 等相结合。作者首先回顾了软件质量标准的基础和 LLMs 的技术原理，然后映射 LLMs 应用到这些框架中，并通过实证案例研究证明了其实际可行性。论文同时讨论了挑战（如数据隐私、模型偏差和可解释性），并提出未来方向，包括自适应学习、隐私保护部署和多模态分析，以推动 AI 驱动的软件质量改进。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "16 pages, 1 Table, 6 Figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13766v1",
      "published_date": "2025-05-19 22:49:30 UTC",
      "updated_date": "2025-05-19 22:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:01:05.491215"
    },
    {
      "arxiv_id": "2505.13763v1",
      "title": "Language Models Are Capable of Metacognitive Monitoring and Control of Their Internal Activations",
      "title_zh": "翻译失败",
      "authors": [
        "Li Ji-An",
        "Hua-Dong Xiong",
        "Robert C. Wilson",
        "Marcelo G. Mattar",
        "Marcus K. Benna"
      ],
      "abstract": "Large language models (LLMs) can sometimes report the strategies they\nactually use to solve tasks, but they can also fail to do so. This suggests\nsome degree of metacognition -- the capacity to monitor one's own cognitive\nprocesses for subsequent reporting and self-control. Metacognitive abilities\nenhance AI capabilities but raise safety concerns, as models might obscure\ntheir internal processes to evade neural-activation-based oversight mechanisms\ndesigned to detect harmful behaviors. Given society's increased reliance on\nthese models, it is critical that we understand the limits of their\nmetacognitive abilities, particularly their ability to monitor their internal\nactivations. To address this, we introduce a neuroscience-inspired\nneurofeedback paradigm designed to quantify the ability of LLMs to explicitly\nreport and control their activation patterns. By presenting models with\nsentence-label pairs where labels correspond to sentence-elicited internal\nactivations along specific directions in the neural representation space, we\ndemonstrate that LLMs can learn to report and control these activations. The\nperformance varies with several factors: the number of example pairs provided,\nthe semantic interpretability of the target neural direction, and the variance\nexplained by that direction. These results reveal a \"metacognitive space\" with\ndimensionality much lower than the model's neural space, suggesting LLMs can\nmonitor only a subset of their neural mechanisms. Our findings provide\nempirical evidence quantifying metacognitive capabilities in LLMs, with\nsignificant implications for AI safety.",
      "tldr_zh": "这篇论文证明了大语言模型(LLMs)具备元认知能力，能够监控和控制其内部激活，从而报告或调整解决任务的策略。研究引入了一个受神经科学启发的神经反馈(neurofeedback)范式，通过提供句子-标签对来量化LLMs在神经表示空间特定方向上的激活报告和控制能力。结果显示，性能受因素如示例数量、目标神经方向的语义可解释性和方差影响，并揭示了一个维度远低于模型神经空间的“元认知空间”，表明LLMs仅能监控部分神经机制。这些发现为提升AI安全提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13763v1",
      "published_date": "2025-05-19 22:32:25 UTC",
      "updated_date": "2025-05-19 22:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:01:17.937366"
    },
    {
      "arxiv_id": "2505.13742v1",
      "title": "Understanding Task Representations in Neural Networks via Bayesian Ablation",
      "title_zh": "通过贝叶斯消融理解神经网络中的任务表示",
      "authors": [
        "Andrew Nam",
        "Declan Campbell",
        "Thomas Griffiths",
        "Jonathan Cohen",
        "Sarah-Jane Leslie"
      ],
      "abstract": "Neural networks are powerful tools for cognitive modeling due to their\nflexibility and emergent properties. However, interpreting their learned\nrepresentations remains challenging due to their sub-symbolic semantics. In\nthis work, we introduce a novel probabilistic framework for interpreting latent\ntask representations in neural networks. Inspired by Bayesian inference, our\napproach defines a distribution over representational units to infer their\ncausal contributions to task performance. Using ideas from information theory,\nwe propose a suite of tools and metrics to illuminate key model properties,\nincluding representational distributedness, manifold complexity, and\npolysemanticity.",
      "tldr_zh": "本研究提出了一种基于Bayesian Ablation的概率框架，用于解释神经网络中任务表示（task representations）的潜在含义，以解决其子符号语义（sub-symbolic semantics）带来的解释挑战。该框架受Bayesian inference启发，通过定义表示单位（representational units）的分布来推断其对任务性能的因果贡献，并整合信息理论思想。研究开发了一系列工具和指标，包括representational distributedness、manifold complexity和polysemanticity，以揭示模型的关键属性，如表示的分布式性和多义性。总的来说，此方法为更好地理解神经网络在认知建模中的作用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13742v1",
      "published_date": "2025-05-19 21:36:09 UTC",
      "updated_date": "2025-05-19 21:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:01:28.902390"
    },
    {
      "arxiv_id": "2505.13740v1",
      "title": "Improving Compositional Generation with Diffusion Models Using Lift Scores",
      "title_zh": "翻译失败",
      "authors": [
        "Chenning Yu",
        "Sicun Gao"
      ],
      "abstract": "We introduce a novel resampling criterion using lift scores, for improving\ncompositional generation in diffusion models. By leveraging the lift scores, we\nevaluate whether generated samples align with each single condition and then\ncompose the results to determine whether the composed prompt is satisfied. Our\nkey insight is that lift scores can be efficiently approximated using only the\noriginal diffusion model, requiring no additional training or external modules.\nWe develop an optimized variant that achieves relatively lower computational\noverhead during inference while maintaining effectiveness. Through extensive\nexperiments, we demonstrate that lift scores significantly improved the\ncondition alignment for compositional generation across 2D synthetic data,\nCLEVR position tasks, and text-to-image synthesis. Our code is available at\nhttp://github.com/rainorangelemon/complift.",
      "tldr_zh": "本文提出了一种基于 lift scores 的新重采样标准，用于提升扩散模型（diffusion models）中的组合生成（compositional generation）。该方法通过评估生成的样本是否与每个单一条件对齐，并组合结果来验证整体提示满足情况，其关键优势是能高效近似计算，仅需原始模型而无须额外训练或模块。实验结果显示，在 2D 合成数据、CLEVR 位置任务和文本到图像合成中，lift scores 显著提高了条件对齐性能，同时优化变体降低了推理时的计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13740v1",
      "published_date": "2025-05-19 21:34:42 UTC",
      "updated_date": "2025-05-19 21:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:01:39.546661"
    },
    {
      "arxiv_id": "2505.13738v1",
      "title": "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Shane Bergsma",
        "Nolan Dey",
        "Gurpreet Gosal",
        "Gavia Gray",
        "Daria Soboleva",
        "Joel Hestness"
      ],
      "abstract": "Efficient LLM pre-training requires well-tuned hyperparameters (HPs),\nincluding learning rate {\\eta} and weight decay {\\lambda}. We study scaling\nlaws for HPs: formulas for how to scale HPs as we scale model size N, dataset\nsize D, and batch size B. Recent work suggests the AdamW timescale,\nB/({\\eta}{\\lambda}D), should remain constant across training settings, and we\nverify the implication that optimal {\\lambda} scales linearly with B, for a\nfixed N,D. However, as N,D scale, we show the optimal timescale obeys a precise\npower law in the tokens-per-parameter ratio, D/N. This law thus provides a\nmethod to accurately predict {\\lambda}opt in advance of large-scale training.\nWe also study scaling laws for optimal batch size Bopt (the B enabling lowest\nloss at a given N,D) and critical batch size Bcrit (the B beyond which further\ndata parallelism becomes ineffective). In contrast with prior work, we find\nboth Bopt and Bcrit scale as power laws in D, independent of model size, N.\nFinally, we analyze how these findings inform the real-world selection of\nPareto-optimal N and D under dual training time and compute objectives.",
      "tldr_zh": "本研究探讨了LLM预训练中权重衰减λ和批量大小B的缩放定律，旨在通过公式预测超参数如何随模型大小N、数据集大小D和B的变化而调整。研究发现，最优λ与B线性相关，且最优AdamW时间尺度遵循D/N的幂律，从而能提前准确预测λopt；此外，最优批量大小Bopt和临界批量大小Bcrit均作为D的幂律缩放，与N无关。这些发现为在训练时间和计算资源双重约束下选择Pareto最优的N和D提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13738v1",
      "published_date": "2025-05-19 21:27:33 UTC",
      "updated_date": "2025-05-19 21:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:01:53.273251"
    },
    {
      "arxiv_id": "2505.13737v1",
      "title": "Causal Head Gating: A Framework for Interpreting Roles of Attention Heads in Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Nam",
        "Henry Conklin",
        "Yukang Yang",
        "Thomas Griffiths",
        "Jonathan Cohen",
        "Sarah-Jane Leslie"
      ],
      "abstract": "We present causal head gating (CHG), a scalable method for interpreting the\nfunctional roles of attention heads in transformer models. CHG learns soft\ngates over heads and assigns them a causal taxonomy - facilitating,\ninterfering, or irrelevant - based on their impact on task performance. Unlike\nprior approaches in mechanistic interpretability, which are hypothesis-driven\nand require prompt templates or target labels, CHG applies directly to any\ndataset using standard next-token prediction. We evaluate CHG across multiple\nlarge language models (LLMs) in the Llama 3 model family and diverse tasks,\nincluding syntax, commonsense, and mathematical reasoning, and show that CHG\nscores yield causal - not merely correlational - insight, validated via\nablation and causal mediation analyses. We also introduce contrastive CHG, a\nvariant that isolates sub-circuits for specific task components. Our findings\nreveal that LLMs contain multiple sparse, sufficient sub-circuits, that\nindividual head roles depend on interactions with others (low modularity), and\nthat instruction following and in-context learning rely on separable\nmechanisms.",
      "tldr_zh": "本研究提出了一种可扩展框架 Causal Head Gating (CHG)，用于解释 Transformer 模型中注意力 heads 的功能角色，通过学习软门控（soft gates）并基于对任务性能的影响将 heads 分类为促进（facilitating）、干扰（interfering）或无关（irrelevant）。不同于以往假设驱动的方法，CHG 直接应用于任何数据集，利用标准的下一个标记预测（next-token prediction），无需提示模板或目标标签。实验在 Llama 3 模型家族的多个大型语言模型（LLMs）上评估了语法、常识和数学推理等任务，结果显示 CHG 提供真实的因果洞见，并通过消融和因果中介分析验证；此外，引入对比 CHG 变体揭示 LLMs 包含多个稀疏、足够的子电路，heads 角色依赖于与其他 heads 的交互（低模块性），而指令遵循和上下文学习依赖于可分离机制。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13737v1",
      "published_date": "2025-05-19 21:24:13 UTC",
      "updated_date": "2025-05-19 21:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:02:06.113140"
    },
    {
      "arxiv_id": "2505.13729v1",
      "title": "SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation",
      "title_zh": "SayCoNav：利用大型语言模型实现去中心化多机器人导航中的自适应协作",
      "authors": [
        "Abhinav Rajvanshi",
        "Pritish Sahu",
        "Tixiao Shan",
        "Karan Sikka",
        "Han-Pang Chiu"
      ],
      "abstract": "Adaptive collaboration is critical to a team of autonomous robots to perform\ncomplicated navigation tasks in large-scale unknown environments. An effective\ncollaboration strategy should be determined and adapted according to each\nrobot's skills and current status to successfully achieve the shared goal. We\npresent SayCoNav, a new approach that leverages large language models (LLMs)\nfor automatically generating this collaboration strategy among a team of\nrobots. Building on the collaboration strategy, each robot uses the LLM to\ngenerate its plans and actions in a decentralized way. By sharing information\nto each other during navigation, each robot also continuously updates its\nstep-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation\n(MultiON) tasks, that require the team of the robots to utilize their\ncomplementary strengths to efficiently search multiple different objects in\nunknown environments. By validating SayCoNav with varied team compositions and\nconditions against baseline methods, our experimental results show that\nSayCoNav can improve search efficiency by at most 44.28% through effective\ncollaboration among heterogeneous robots. It can also dynamically adapt to the\nchanging conditions during task execution.",
      "tldr_zh": "本研究提出SayCoNav，一种利用Large Language Models (LLMs)实现自适应协作的框架，旨在提升去中心化多机器人导航任务的效率。SayCoNav通过LLMs自动生成协作策略，每个机器人根据策略在本地生成计划和行动，并通过信息共享动态更新计划，以应对未知环境中的变化。针对Multi-Object Navigation (MultiON)任务，实验结果显示，该方法通过机器人团队的互补协作，最多提高了44.28%的搜索效率，并能实时适应任务执行中的条件变化。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13729v1",
      "published_date": "2025-05-19 20:58:06 UTC",
      "updated_date": "2025-05-19 20:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:02:16.407565"
    },
    {
      "arxiv_id": "2505.13718v1",
      "title": "Warm Up Before You Train: Unlocking General Reasoning in Resource-Constrained Settings",
      "title_zh": "先预热再训练：解锁资源受限环境中的通用推理",
      "authors": [
        "Safal Shrestha",
        "Minwu Kim",
        "Aadim Nepal",
        "Anubhav Shrestha",
        "Keith Ross"
      ],
      "abstract": "Designing effective reasoning-capable LLMs typically requires training using\nReinforcement Learning with Verifiable Rewards (RLVR) or distillation with\ncarefully curated Long Chain of Thoughts (CoT), both of which depend heavily on\nextensive training data. This creates a major challenge when the amount of\nquality training data is scarce. We propose a sample-efficient, two-stage\ntraining strategy to develop reasoning LLMs under limited supervision. In the\nfirst stage, we \"warm up\" the model by distilling Long CoTs from a toy domain,\nnamely, Knights \\& Knaves (K\\&K) logic puzzles to acquire general reasoning\nskills. In the second stage, we apply RLVR to the warmed-up model using a\nlimited set of target-domain examples. Our experiments demonstrate that this\ntwo-phase approach offers several benefits: $(i)$ the warmup phase alone\nfacilitates generalized reasoning, leading to performance improvements across a\nrange of tasks, including MATH, HumanEval$^{+}$, and MMLU-Pro. $(ii)$ When both\nthe base model and the warmed-up model are RLVR trained on the same small\ndataset ($\\leq100$ examples), the warmed-up model consistently outperforms the\nbase model; $(iii)$ Warming up before RLVR training allows a model to maintain\ncross-domain generalizability even after training on a specific domain; $(iv)$\nIntroducing warmup in the pipeline improves not only accuracy but also overall\nsample efficiency during RLVR training. The results in this paper highlight the\npromise of warmup for building robust reasoning LLMs in data-scarce\nenvironments.",
      "tldr_zh": "该论文提出了一种高效的两阶段训练策略，用于在数据稀缺的环境中开发推理能力的LLMs。第一阶段通过从Knights & Knaves (K&K)逻辑谜题中提炼Long Chain of Thoughts (CoT)来预热模型，增强其一般推理技能；第二阶段则对预热后的模型应用Reinforcement Learning with Verifiable Rewards (RLVR)，使用有限的目标领域示例进行训练。实验结果表明，这种方法不仅提升了模型在MATH、HumanEval+和MMLU-Pro等任务上的性能，还提高了样本效率和跨领域泛化能力，为资源受限场景下构建鲁棒的推理LLMs提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13718v1",
      "published_date": "2025-05-19 20:29:15 UTC",
      "updated_date": "2025-05-19 20:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:02:29.764248"
    },
    {
      "arxiv_id": "2505.15849v1",
      "title": "What Lives? A meta-analysis of diverse opinions on the definition of life",
      "title_zh": "翻译失败",
      "authors": [
        "Reed Bender",
        "Karina Kofman",
        "Blaise Agüera y Arcas",
        "Michael Levin"
      ],
      "abstract": "The question of \"what is life?\" has challenged scientists and philosophers\nfor centuries, producing an array of definitions that reflect both the mystery\nof its emergence and the diversity of disciplinary perspectives brought to bear\non the question. Despite significant progress in our understanding of\nbiological systems, psychology, computation, and information theory, no single\ndefinition for life has yet achieved universal acceptance. This challenge\nbecomes increasingly urgent as advances in synthetic biology, artificial\nintelligence, and astrobiology challenge our traditional conceptions of what it\nmeans to be alive. We undertook a methodological approach that leverages large\nlanguage models (LLMs) to analyze a set of definitions of life provided by a\ncurated set of cross-disciplinary experts. We used a novel pairwise correlation\nanalysis to map the definitions into distinct feature vectors, followed by\nagglomerative clustering, intra-cluster semantic analysis, and t-SNE projection\nto reveal underlying conceptual archetypes. This methodology revealed a\ncontinuous landscape of the themes relating to the definition of life,\nsuggesting that what has historically been approached as a binary taxonomic\nproblem should be instead conceived as differentiated perspectives within a\nunified conceptual latent space. We offer a new methodological bridge between\nreductionist and holistic approaches to fundamental questions in science and\nphilosophy, demonstrating how computational semantic analysis can reveal\nconceptual patterns across disciplinary boundaries, and opening similar\npathways for addressing other contested definitional territories across the\nsciences.",
      "tldr_zh": "这篇论文通过元分析探讨了“什么是生命？”的多样定义，利用大型语言模型 (LLMs) 分析跨学科专家提供的观点。研究采用成对相关性分析 (pairwise correlation analysis) 将定义映射为特征向量，随后通过凝聚聚类 (agglomerative clustering)、集群内语义分析 (intra-cluster semantic analysis) 和 t-SNE 投影，揭示了生命定义的连续主题景观，而非二元分类。论文的关键贡献在于桥接还原论和整体论方法，展示了计算语义分析如何揭示跨学科概念模式，并为其他科学领域的定义问题开辟新路径。",
      "categories": [
        "q-bio.OT",
        "cs.AI",
        "cs.CY",
        "q-bio.BM",
        "q-bio.CB",
        "q-bio.SC",
        "stat.AP"
      ],
      "primary_category": "q-bio.OT",
      "comment": "54 pages, 4 figures, 2 tables, 11 supplemental figures, 3\n  supplemental tables",
      "pdf_url": "http://arxiv.org/pdf/2505.15849v1",
      "published_date": "2025-05-19 20:17:37 UTC",
      "updated_date": "2025-05-19 20:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:02:41.144519"
    },
    {
      "arxiv_id": "2505.13709v1",
      "title": "Policy-Driven World Model Adaptation for Robust Offline Model-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Chen",
        "Aravind Venugopal",
        "Jeff Schneider"
      ],
      "abstract": "Offline reinforcement learning (RL) offers a powerful paradigm for\ndata-driven control. Compared to model-free approaches, offline model-based RL\n(MBRL) explicitly learns a world model from a static dataset and uses it as a\nsurrogate simulator, improving data efficiency and enabling potential\ngeneralization beyond the dataset support. However, most existing offline MBRL\nmethods follow a two-stage training procedure: first learning a world model by\nmaximizing the likelihood of the observed transitions, then optimizing a policy\nto maximize its expected return under the learned model. This objective\nmismatch results in a world model that is not necessarily optimized for\neffective policy learning. Moreover, we observe that policies learned via\noffline MBRL often lack robustness during deployment, and small adversarial\nnoise in the environment can lead to significant performance degradation. To\naddress these, we propose a framework that dynamically adapts the world model\nalongside the policy under a unified learning objective aimed at improving\nrobustness. At the core of our method is a maximin optimization problem, which\nwe solve by innovatively utilizing Stackelberg learning dynamics. We provide\ntheoretical analysis to support our design and introduce computationally\nefficient implementations. We benchmark our algorithm on twelve noisy D4RL\nMuJoCo tasks and three stochastic Tokamak Control tasks, demonstrating its\nstate-of-the-art performance.",
      "tldr_zh": "这篇论文针对离线基于模型的强化学习（Offline MBRL）中的鲁棒性问题，提出了一种政策驱动的世界模型适应框架，以统一优化目标动态调整世界模型和策略。核心方法涉及maximin优化问题，并采用Stackelberg学习动态来解决目标不匹配和环境扰动导致的性能下降问题。实验结果显示，该框架在十二个D4RL MuJoCo任务和三个Tokamak Control任务上实现了最先进性能，提高了策略的鲁棒性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13709v1",
      "published_date": "2025-05-19 20:14:33 UTC",
      "updated_date": "2025-05-19 20:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:02:52.022942"
    },
    {
      "arxiv_id": "2505.13706v1",
      "title": "Are Large Language Models Good at Detecting Propaganda?",
      "title_zh": "大语言模型在检测宣传方面表现好吗？",
      "authors": [
        "Julia Jose",
        "Rachel Greenstadt"
      ],
      "abstract": "Propagandists use rhetorical devices that rely on logical fallacies and\nemotional appeals to advance their agendas. Recognizing these techniques is key\nto making informed decisions. Recent advances in Natural Language Processing\n(NLP) have enabled the development of systems capable of detecting manipulative\ncontent. In this study, we look at several Large Language Models and their\nperformance in detecting propaganda techniques in news articles. We compare the\nperformance of these LLMs with transformer-based models. We find that, while\nGPT-4 demonstrates superior F1 scores (F1=0.16) compared to GPT-3.5 and Claude\n3 Opus, it does not outperform a RoBERTa-CRF baseline (F1=0.67). Additionally,\nwe find that all three LLMs outperform a MultiGranularity Network (MGN)\nbaseline in detecting instances of one out of six propaganda techniques\n(name-calling), with GPT-3.5 and GPT-4 also outperforming the MGN baseline in\ndetecting instances of appeal to fear and flag-waving.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在检测新闻文章中宣传技术（如逻辑谬误和情感诉求）方面的性能。研究比较了 GPT-4、GPT-3.5 和 Claude 3 Opus 与基于 transformer 的模型（如 RoBERTa-CRF）和 MultiGranularity Network (MGN) 基线。结果显示，GPT-4 的 F1 分数（0.16）优于其他 LLMs，但远低于 RoBERTa-CRF 基线（F1=0.67）；然而，LLMs 在 name-calling 技术上全面超越 MGN 基线，在 appeal to fear 和 flag-waving 上也表现出色。该研究揭示了 LLMs 在宣传检测中的优势和局限性，为改进自然语言处理系统提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13706v1",
      "published_date": "2025-05-19 20:11:13 UTC",
      "updated_date": "2025-05-19 20:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:03:05.088521"
    },
    {
      "arxiv_id": "2505.13697v1",
      "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Soumya Rani Samineni",
        "Durgesh Kalwar",
        "Karthik Valmeekam",
        "Kaya Stechly",
        "Subbarao Kambhampati"
      ],
      "abstract": "Reinforcement learning-based post-training of large language models (LLMs)\nhas recently gained attention, particularly following the release of DeepSeek\nR1, which applied GRPO for fine-tuning. Amid the growing hype around improved\nreasoning abilities attributed to RL post-training, we critically examine the\nformulation and assumptions underlying these methods. We start by highlighting\nthe popular structural assumptions made in modeling LLM training as a Markov\nDecision Process (MDP), and show how they lead to a degenerate MDP that doesn't\nquite need the RL/GRPO apparatus. The two critical structural assumptions\ninclude (1) making the MDP states be just a concatenation of the actions-with\nstates becoming the context window and the actions becoming the tokens in LLMs\nand (2) splitting the reward of a state-action trajectory uniformly across the\ntrajectory. Through a comprehensive analysis, we demonstrate that these\nsimplifying assumptions make the approach effectively equivalent to an\noutcome-driven supervised learning. Our experiments on benchmarks including\nGSM8K and Countdown using Qwen-2.5 base models show that iterative supervised\nfine-tuning, incorporating both positive and negative samples, achieves\nperformance comparable to GRPO-based training. We will also argue that the\nstructural assumptions indirectly incentivize the RL to generate longer\nsequences of intermediate tokens-which in turn feeds into the narrative of \"RL\ngenerating longer thinking traces.\" While RL may well be a very useful\ntechnique for improving the reasoning abilities of LLMs, our analysis shows\nthat the simplistic structural assumptions made in modeling the underlying MDP\nrender the popular LLM RL frameworks and their interpretations questionable.",
      "tldr_zh": "该研究质疑了基于强化学习（RL）的LLM后训练方法（如DeepSeek R1的GRPO）的结构假设，通过分析将LLM训练建模为Markov Decision Process (MDP)的两个关键假设：（1）MDP状态为动作的连接（如上下文窗口和令牌），（2）轨迹奖励均匀分配，这些假设使RL方法本质上退化成一种基于结果的监督学习。实验在GSM8K和Countdown基准上使用Qwen-2.5基模型显示，迭代监督微调（包括正负样本）可达到与GRPO训练相当的性能，并揭示这些假设间接鼓励生成更长的中间序列，强化了“RL产生更长思考痕迹”的叙事。尽管RL可能提升LLM的推理能力，但论文指出当前MDP建模的简化假设使这些框架的可信度 questionable。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13697v1",
      "published_date": "2025-05-19 19:57:15 UTC",
      "updated_date": "2025-05-19 19:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:03:16.561392"
    },
    {
      "arxiv_id": "2505.13696v1",
      "title": "Building spatial world models from sparse transitional episodic memories",
      "title_zh": "从稀疏的过渡性情节记忆中构建空间世界模型",
      "authors": [
        "Zizhan He",
        "Maxime Daigle",
        "Pouya Bashivan"
      ],
      "abstract": "Many animals possess a remarkable capacity to rapidly construct flexible\nmental models of their environments. These world models are crucial for\nethologically relevant behaviors such as navigation, exploration, and planning.\nThe ability to form episodic memories and make inferences based on these sparse\nexperiences is believed to underpin the efficiency and adaptability of these\nmodels in the brain. Here, we ask: Can a neural network learn to construct a\nspatial model of its surroundings from sparse and disjoint episodic memories?\nWe formulate the problem in a simulated world and propose a novel framework,\nthe Episodic Spatial World Model (ESWM), as a potential answer. We show that\nESWM is highly sample-efficient, requiring minimal observations to construct a\nrobust representation of the environment. It is also inherently adaptive,\nallowing for rapid updates when the environment changes. In addition, we\ndemonstrate that ESWM readily enables near-optimal strategies for exploring\nnovel environments and navigating between arbitrary points, all without the\nneed for additional training.",
      "tldr_zh": "本研究探讨了神经网络如何从稀疏且不连续的 episodic memories 构建空间世界模型，以模仿动物在导航、探索和规划中的高效适应能力。作者提出了一种新型框架 Episodic Spatial World Model (ESWM)，该框架利用神经网络从有限观察中构建稳健的环境表示，并支持快速更新以应对环境变化。实验结果显示，ESWM 高度 sample-efficient，能够无需额外训练就实现近优的探索和导航策略，从而为构建灵活的智能环境模型提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13696v1",
      "published_date": "2025-05-19 19:56:24 UTC",
      "updated_date": "2025-05-19 19:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:03:27.643466"
    },
    {
      "arxiv_id": "2505.13672v1",
      "title": "A*-Decoding: Token-Efficient Inference Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Giannis Chatziveroglou"
      ],
      "abstract": "Inference-time scaling has emerged as a powerful alternative to parameter\nscaling for improving language model performance on complex reasoning tasks.\nWhile existing methods have shown strong performance gains under fixed compute\nbudgets, there has been little focus on optimally utilizing that budget during\ninference. In this work, we introduce A*-decoding, a search-based\ninference-time strategy that builds on the A* search algorithm to optimally\nutilize a fixed compute budget by prioritizing high-quality reasoning paths\nduring generation. We frame language model decoding as a structured search in a\nstate space of partial solutions, applying the A* transition model to identify\npromising continuations guided by an external process supervision signal. In\nour experiments, A*-decoding reaches the performance levels of strong inference\nscaling baselines like best-of-N and particle filtering while using up to 3x\nfewer tokens and 30% fewer PRM passes under equivalent compute budgets. On the\nMATH500 and AIME 2024 benchmarks, A*-decoding enables Llama-3.2-1B-Instruct to\nmatch the performance of the 70x larger Llama-3.1-70B-Instruct, and allows\nQwen3-1.7B to reach o1-like reasoning accuracy. These results highlight the\npower of structured search in decoding, offering an alternative to brute-force\nsampling or scale-driven gains. Our work demonstrates how thoughtful\ninference-time strategies can enhance reasoning in SLMs, pointing toward future\nadvances in more efficient and scalable language model deployment.",
      "tldr_zh": "本研究提出了一种基于 A* 搜索算法的推理策略——A*-decoding，旨在优化语言模型在固定计算预算下的推理性能，通过优先选择高质量的推理路径来减少不必要的计算。A*-decoding 将语言模型解码视为部分解决方案的状态空间搜索，并利用外部过程监督信号指导生成过程，从而在等效预算下使用最多 3 倍更少的令牌和 30% 更少的 PRM 传递。实验结果显示，该方法使 Llama-3.2-1B-Instruct 在 MATH500 和 AIME 2024 基准上匹敌 70 倍更大的 Llama-3.1-70B-Instruct，并让 Qwen3-1.7B 达到 o1-like 的推理准确性，证明了结构化搜索在提升小型语言模型（SLMs）效率方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13672v1",
      "published_date": "2025-05-19 19:19:48 UTC",
      "updated_date": "2025-05-19 19:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:03:41.630895"
    },
    {
      "arxiv_id": "2505.13668v1",
      "title": "MAFA: A multi-agent framework for annotation",
      "title_zh": "MAFA",
      "authors": [
        "Mahmood Hegazy",
        "Aaron Rodrigues",
        "Azzam Naeem"
      ],
      "abstract": "Modern applications require accurate and efficient retrieval of information\nin response to user queries. Mapping user utterances to the most relevant\nFrequently Asked Questions (FAQs) is a crucial component of these systems.\nTraditional approaches often rely on a single model or technique, which may not\ncapture the nuances of diverse user inquiries. In this paper, we introduce a\nmulti-agent framework for FAQ annotation that combines multiple specialized\nagents with different approaches and a judge agent that reranks candidates to\nproduce optimal results. Our agents utilize a structured reasoning approach\ninspired by Attentive Reasoning Queries (ARQs), which guides them through\nsystematic reasoning steps using targeted, task-specific JSON queries. Our\nframework features a specialized few-shot example strategy, where each agent\nreceives different few-shots, enhancing ensemble diversity and coverage of the\nquery space. We evaluate our framework on a real-world banking dataset as well\nas public benchmark datasets (LCQMC and FiQA), demonstrating significant\nimprovements over single-agent approaches across multiple metrics, including a\n14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12%\nimprovement in Mean Reciprocal Rank on our dataset, and similar gains on public\nbenchmarks when compared with traditional single agent annotation techniques.\nOur framework is particularly effective at handling ambiguous queries, making\nit well-suited for deployment in production applications while showing strong\ngeneralization capabilities across different domains and languages.",
      "tldr_zh": "该论文提出了一种多智能体框架 MAFA，用于 FAQ 注解，帮助将用户查询映射到最相关的问题，提高信息检索的准确性和效率。框架结合多个专业化智能体和一个判断智能体，使用受 Attentive Reasoning Queries (ARQs) 启发的结构化推理方法，以及针对性的 few-shot 例子策略，以增强智能体多样性和查询空间覆盖。实验在真实银行数据集和公共基准数据集 (LCQMC 和 FiQA) 上显示，该框架比单一智能体方法提升显著，包括 Top-1 准确率提高 14%、Top-5 准确率提高 18%、Mean Reciprocal Rank 改善 12%，并特别擅长处理模糊查询，具有强泛化能力和生产环境部署潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13668v1",
      "published_date": "2025-05-19 19:16:37 UTC",
      "updated_date": "2025-05-19 19:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:03:54.736005"
    },
    {
      "arxiv_id": "2505.13650v1",
      "title": "Self-Reinforced Graph Contrastive Learning",
      "title_zh": "自我强化图对比学习",
      "authors": [
        "Chou-Ying Hsieh",
        "Chun-Fu Jang",
        "Cheng-En Hsieh",
        "Qian-Hui Chen",
        "Sy-Yen Kuo"
      ],
      "abstract": "Graphs serve as versatile data structures in numerous real-world\ndomains-including social networks, molecular biology, and knowledge graphs-by\ncapturing intricate relational information among entities. Among graph-based\nlearning techniques, Graph Contrastive Learning (GCL) has gained significant\nattention for its ability to derive robust, self-supervised graph\nrepresentations through the contrasting of positive and negative sample pairs.\nHowever, a critical challenge lies in ensuring high-quality positive pairs so\nthat the intrinsic semantic and structural properties of the original graph are\npreserved rather than distorted. To address this issue, we propose SRGCL\n(Self-Reinforced Graph Contrastive Learning), a novel framework that leverages\nthe model's own encoder to dynamically evaluate and select high-quality\npositive pairs. We designed a unified positive pair generator employing\nmultiple augmentation strategies, and a selector guided by the manifold\nhypothesis to maintain the underlying geometry of the latent space. By adopting\na probabilistic mechanism for selecting positive pairs, SRGCL iteratively\nrefines its assessment of pair quality as the encoder's representational power\nimproves. Extensive experiments on diverse graph-level classification tasks\ndemonstrate that SRGCL, as a plug-in module, consistently outperforms\nstate-of-the-art GCL methods, underscoring its adaptability and efficacy across\nvarious domains.",
      "tldr_zh": "该论文提出 SRGCL（Self-Reinforced Graph Contrastive Learning），一种新框架，用于解决 Graph Contrastive Learning (GCL) 在生成高质量正样本对时的挑战，确保保留图的语义和结构属性。SRGCL 利用模型自身的编码器动态评估正样本对，通过统一的增强策略生成器和基于流形假设（manifold hypothesis）的选择器，以及概率机制进行迭代精炼，以提升潜在空间的几何完整性。在各种图级分类任务的实验中，SRGCL 作为插件模块显著超越现有最先进 GCL 方法，展示了其在社交网络、分子生物学和知识图谱等领域的适应性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13650v1",
      "published_date": "2025-05-19 18:45:54 UTC",
      "updated_date": "2025-05-19 18:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:04:05.416834"
    },
    {
      "arxiv_id": "2505.13636v1",
      "title": "Incentivizing Truthful Language Models via Peer Elicitation Games",
      "title_zh": "翻译失败",
      "authors": [
        "Baiting Chen",
        "Tong Zhu",
        "Jiale Han",
        "Lexin Li",
        "Gang Li",
        "Xiaowu Dai"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong generative capabilities\nbut remain prone to inconsistencies and hallucinations. We introduce Peer\nElicitation Games (PEG), a training-free, game-theoretic framework for aligning\nLLMs through a peer elicitation mechanism involving a generator and multiple\ndiscriminators instantiated from distinct base models. Discriminators interact\nin a peer evaluation setting, where rewards are computed using a\ndeterminant-based mutual information score that provably incentivizes truthful\nreporting without requiring ground-truth labels. We establish theoretical\nguarantees showing that each agent, via online learning, achieves sublinear\nregret in the sense their cumulative performance approaches that of the best\nfixed truthful strategy in hindsight. Moreover, we prove last-iterate\nconvergence to a truthful Nash equilibrium, ensuring that the actual policies\nused by agents converge to stable and truthful behavior over time. Empirical\nevaluations across multiple benchmarks demonstrate significant improvements in\nfactual accuracy. These results position PEG as a practical approach for\neliciting truthful behavior from LLMs without supervision or fine-tuning.",
      "tldr_zh": "本文提出 Peer Elicitation Games (PEG)，一种无需训练的游戏理论框架，通过生成器和多个鉴别器的对等互动机制，提升大型语言模型 (LLMs) 的真实性和一致性。PEG 使用基于行列式的互信息分数计算奖励，激励代理真实报告，并提供理论保证，包括每个代理通过在线学习实现亚线性遗憾，以及最后迭代收敛到真实 Nash 均衡。实证结果显示，PEG 在多个基准上显著提高了事实准确性，为无需监督或微调的情况下激发 LLMs 真实行为提供了实用方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13636v1",
      "published_date": "2025-05-19 18:16:58 UTC",
      "updated_date": "2025-05-19 18:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:04:18.164694"
    },
    {
      "arxiv_id": "2505.13631v1",
      "title": "Learning (Approximately) Equivariant Networks via Constrained Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Manolache",
        "Luiz F. O. Chamon",
        "Mathias Niepert"
      ],
      "abstract": "Equivariant neural networks are designed to respect symmetries through their\narchitecture, boosting generalization and sample efficiency when those\nsymmetries are present in the data distribution. Real-world data, however,\noften departs from perfect symmetry because of noise, structural variation,\nmeasurement bias, or other symmetry-breaking effects. Strictly equivariant\nmodels may struggle to fit the data, while unconstrained models lack a\nprincipled way to leverage partial symmetries. Even when the data is fully\nsymmetric, enforcing equivariance can hurt training by limiting the model to a\nrestricted region of the parameter space. Guided by homotopy principles, where\nan optimization problem is solved by gradually transforming a simpler problem\ninto a complex one, we introduce Adaptive Constrained Equivariance (ACE), a\nconstrained optimization approach that starts with a flexible, non-equivariant\nmodel and gradually reduces its deviation from equivariance. This gradual\ntightening smooths training early on and settles the model at a data-driven\nequilibrium, balancing between equivariance and non-equivariance. Across\nmultiple architectures and tasks, our method consistently improves performance\nmetrics, sample efficiency, and robustness to input perturbations compared with\nstrictly equivariant models and heuristic equivariance relaxations.",
      "tldr_zh": "该论文提出 Adaptive Constrained Equivariance (ACE) 方法，通过约束优化学习近似 equivariant 神经网络，以平衡数据中的部分对称性和模型灵活性。ACE 基于 homotopy 原则，从一个非-equivariant 模型开始，逐步减少对 equivariance 的偏差，从而平滑训练过程并在数据驱动的平衡点收敛。实验结果显示，该方法在多种架构和任务上显著提升了性能指标、样本效率和对输入扰动的鲁棒性，优于严格 equivariant 模型和启发式松弛方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13631v1",
      "published_date": "2025-05-19 18:08:09 UTC",
      "updated_date": "2025-05-19 18:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:04:30.522954"
    },
    {
      "arxiv_id": "2505.13617v1",
      "title": "Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Ick",
        "Gordon Wichern",
        "Yoshiki Masuyama",
        "François Germain",
        "Jonathan Le Roux"
      ],
      "abstract": "The characteristics of a sound field are intrinsically linked to the\ngeometric and spatial properties of the environment surrounding a sound source\nand a listener. The physics of sound propagation is captured in a time-domain\nsignal known as a room impulse response (RIR). Prior work using neural fields\n(NFs) has allowed learning spatially-continuous representations of RIRs from\nfinite RIR measurements. However, previous NF-based methods have focused on\nmonaural omnidirectional or at most binaural listeners, which does not\nprecisely capture the directional characteristics of a real sound field at a\nsingle point. We propose a direction-aware neural field (DANF) that more\nexplicitly incorporates the directional information by Ambisonic-format RIRs.\nWhile DANF inherently captures spatial relations between sources and listeners,\nwe further propose a direction-aware loss. In addition, we investigate the\nability of DANF to adapt to new rooms in various ways including low-rank\nadaptation.",
      "tldr_zh": "本研究提出了一种方向感知神经场（Direction-Aware Neural Field，DANF），旨在通过Ambisonic格式的房间脉冲响应（RIR）更精确地捕捉声音场的方向特性，解决现有神经场（NFs）方法仅限于单声道或双声道听者的局限性。DANF 内在整合了声源和听者之间的空间关系，并引入了方向感知损失函数，以实现从少量样本的Few-Shot Interpolation中学习连续的RIR表示。此外，该方法探讨了DANF在新环境中的适应策略，如low-rank adaptation，提升了声音场建模的灵活性和准确性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13617v1",
      "published_date": "2025-05-19 18:01:53 UTC",
      "updated_date": "2025-05-19 18:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:04:42.834442"
    },
    {
      "arxiv_id": "2505.13448v1",
      "title": "CIE: Controlling Language Model Text Generations Using Continuous Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Samuel",
        "Harshita Diddee",
        "Yiming Zhang",
        "Daphne Ippolito"
      ],
      "abstract": "Aligning language models with user intent is becoming increasingly relevant\nto enhance user experience. This calls for designing methods that can allow\nusers to control the properties of the language that LMs generate. For example,\ncontrolling the length of the generation, the complexity of the language that\ngets chosen, the sentiment, tone, etc. Most existing work attempts to integrate\nusers' control by conditioning LM generations on natural language prompts or\ndiscrete control signals, which are often brittle and hard to scale. In this\nwork, we are interested in \\textit{continuous} control signals, ones that exist\nalong a spectrum that can't easily be captured in a natural language prompt or\nvia existing techniques in conditional generation. Through a case study in\ncontrolling the precise response-length of generations produced by LMs, we\ndemonstrate how after fine-tuning, behaviors of language models can be\ncontrolled via continuous signals -- as vectors that are interpolated between a\n\"low\" and a \"high\" token embedding. Our method more reliably exerts\nresponse-length control than in-context learning methods or fine-tuning methods\nthat represent the control signal as a discrete signal. Our full open-sourced\ncode and datasets are available at https://github.com/vsamuel2003/CIE.",
      "tldr_zh": "本研究提出CIE方法，使用连续信号（continuous signals）来控制语言模型（Language Models, LMs）的文本生成属性，如响应长度、语言复杂性或情感，从而更好地与用户意图对齐。该方法通过微调模型，将控制信号表示为在“低”和“高”token embedding之间插值的向量，避免了传统自然语言提示或离散信号的脆弱性。在一个控制响应长度的案例研究中，CIE比in-context learning或离散信号的fine-tuning方法更可靠地实现精确控制。作者提供了开源代码和数据集，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13448v1",
      "published_date": "2025-05-19 17:59:58 UTC",
      "updated_date": "2025-05-19 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:04:53.519218"
    },
    {
      "arxiv_id": "2505.13445v1",
      "title": "Trust, But Verify: A Self-Verification Approach to Reinforcement Learning with Verifiable Rewards",
      "title_zh": "信任，但验证：一种自验证方法用于强化学习的可验证奖励",
      "authors": [
        "Xiaoyuan Liu",
        "Tian Liang",
        "Zhiwei He",
        "Jiahao Xu",
        "Wenxuan Wang",
        "Pinjia He",
        "Zhaopeng Tu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Large Language Models (LLMs) show great promise in complex reasoning, with\nReinforcement Learning with Verifiable Rewards (RLVR) being a key enhancement\nstrategy. However, a prevalent issue is ``superficial self-reflection'', where\nmodels fail to robustly verify their own outputs. We introduce RISE\n(Reinforcing Reasoning with Self-Verification), a novel online RL framework\ndesigned to tackle this. RISE explicitly and simultaneously trains an LLM to\nimprove both its problem-solving and self-verification abilities within a\nsingle, integrated RL process. The core mechanism involves leveraging\nverifiable rewards from an outcome verifier to provide on-the-fly feedback for\nboth solution generation and self-verification tasks. In each iteration, the\nmodel generates solutions, then critiques its own on-policy generated\nsolutions, with both trajectories contributing to the policy update. Extensive\nexperiments on diverse mathematical reasoning benchmarks show that RISE\nconsistently improves model's problem-solving accuracy while concurrently\nfostering strong self-verification skills. Our analyses highlight the\nadvantages of online verification and the benefits of increased verification\ncompute. Additionally, RISE models exhibit more frequent and accurate\nself-verification behaviors during reasoning. These advantages reinforce RISE\nas a flexible and effective path towards developing more robust and self-aware\nreasoners.",
      "tldr_zh": "该论文提出 RISE（Reinforcing Reasoning with Self-Verification），一种在线强化学习框架，旨在解决 Large Language Models (LLMs) 在强化学习中存在的浅层自反省问题，即模型无法robustly验证自身输出。RISE 通过利用 verifiable rewards 提供实时反馈，同时训练 LLM 改进问题解决和自验证能力，在每个迭代中生成解决方案并批判自身输出，以更新策略。实验结果显示，在多种数学推理基准上，RISE 显著提升了问题解决准确性，并培养了更频繁和准确的自验证行为，从而为开发更 robust 和 self-aware 推理器提供了灵活有效的方法。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "code available at https://github.com/xyliu-cs/RISE",
      "pdf_url": "http://arxiv.org/pdf/2505.13445v1",
      "published_date": "2025-05-19 17:59:31 UTC",
      "updated_date": "2025-05-19 17:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:05:05.307265"
    },
    {
      "arxiv_id": "2505.13439v1",
      "title": "VTBench: Evaluating Visual Tokenizers for Autoregressive Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Huawei Lin",
        "Tong Geng",
        "Zhaozhuo Xu",
        "Weijie Zhao"
      ],
      "abstract": "Autoregressive (AR) models have recently shown strong performance in image\ngeneration, where a critical component is the visual tokenizer (VT) that maps\ncontinuous pixel inputs to discrete token sequences. The quality of the VT\nlargely defines the upper bound of AR model performance. However, current\ndiscrete VTs fall significantly behind continuous variational autoencoders\n(VAEs), leading to degraded image reconstructions and poor preservation of\ndetails and text. Existing benchmarks focus on end-to-end generation quality,\nwithout isolating VT performance. To address this gap, we introduce VTBench, a\ncomprehensive benchmark that systematically evaluates VTs across three core\ntasks: Image Reconstruction, Detail Preservation, and Text Preservation, and\ncovers a diverse range of evaluation scenarios. We systematically assess\nstate-of-the-art VTs using a set of metrics to evaluate the quality of\nreconstructed images. Our findings reveal that continuous VAEs produce superior\nvisual representations compared to discrete VTs, particularly in retaining\nspatial structure and semantic detail. In contrast, the degraded\nrepresentations produced by discrete VTs often lead to distorted\nreconstructions, loss of fine-grained textures, and failures in preserving text\nand object integrity. Furthermore, we conduct experiments on GPT-4o image\ngeneration and discuss its potential AR nature, offering new insights into the\nrole of visual tokenization. We release our benchmark and codebase publicly to\nsupport further research and call on the community to develop strong,\ngeneral-purpose open-source VTs.",
      "tldr_zh": "该论文引入了VTBench，一种全面基准测试，用于评估视觉分词器（Visual Tokenizer, VT）在自动回归（Autoregressive, AR）图像生成中的性能，以解决现有离散VT落后于连续变分自动编码器（VAEs）的问题，导致图像重建细节和文本保留不足。VTBench系统地评估VT在图像重建（Image Reconstruction）、细节保留（Detail Preservation）和文本保留（Text Preservation）等三个核心任务上的表现，涵盖多种评估场景，并使用一组指标比较最先进VT的优劣。研究发现，连续VAEs在保留空间结构和语义细节方面明显优于离散VT，后者常导致重建失真、细粒度纹理丢失以及文本和对象完整性问题。此外，通过对GPT-4o图像生成实验的分析，论文提供了新见解，并公开了基准测试代码，呼吁社区开发更强的开源VT。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 13 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13439v1",
      "published_date": "2025-05-19 17:59:01 UTC",
      "updated_date": "2025-05-19 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:05:18.631158"
    },
    {
      "arxiv_id": "2505.13438v1",
      "title": "Optimizing Anytime Reasoning via Budget Relative Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Penghui Qi",
        "Zichen Liu",
        "Tianyu Pang",
        "Chao Du",
        "Wee Sun Lee",
        "Min Lin"
      ],
      "abstract": "Scaling test-time compute is crucial for enhancing the reasoning capabilities\nof large language models (LLMs). Existing approaches typically employ\nreinforcement learning (RL) to maximize a verifiable reward obtained at the end\nof reasoning traces. However, such methods optimize only the final performance\nunder a large and fixed token budget, which hinders efficiency in both training\nand deployment. In this work, we present a novel framework, AnytimeReasoner, to\noptimize anytime reasoning performance, which aims to improve token efficiency\nand the flexibility of reasoning under varying token budget constraints. To\nachieve this, we truncate the complete thinking process to fit within sampled\ntoken budgets from a prior distribution, compelling the model to summarize the\noptimal answer for each truncated thinking for verification. This introduces\nverifiable dense rewards into the reasoning process, facilitating more\neffective credit assignment in RL optimization. We then optimize the thinking\nand summary policies in a decoupled manner to maximize the cumulative reward.\nAdditionally, we introduce a novel variance reduction technique, Budget\nRelative Policy Optimization (BRPO), to enhance the robustness and efficiency\nof the learning process when reinforcing the thinking policy. Empirical results\nin mathematical reasoning tasks demonstrate that our method consistently\noutperforms GRPO across all thinking budgets under various prior distributions,\nenhancing both training and token efficiency.",
      "tldr_zh": "这篇论文提出 AnytimeReasoner 框架，用于优化大型语言模型 (LLMs) 的随时推理性能，旨在提升令牌效率并适应不同令牌预算约束。方法通过截断完整的思考过程以匹配从先验分布采样的预算，并引入可验证的密集奖励，支持强化学习 (RL) 中的有效信用分配，同时解耦优化思考和总结策略。此外，论文引入 Budget Relative Policy Optimization (BRPO) 技术，以提高学习过程的稳健性和效率。实验在数学推理任务中显示，该方法在各种预算下均优于 GRPO，提升了训练和令牌效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13438v1",
      "published_date": "2025-05-19 17:58:44 UTC",
      "updated_date": "2025-05-19 17:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:05:30.233859"
    },
    {
      "arxiv_id": "2505.13437v1",
      "title": "FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Dian Shao",
        "Mingfei Shi",
        "Shengda Xu",
        "Haodong Chen",
        "Yongle Huang",
        "Binglu Wang"
      ],
      "abstract": "Despite significant advances in video generation, synthesizing physically\nplausible human actions remains a persistent challenge, particularly in\nmodeling fine-grained semantics and complex temporal dynamics. For instance,\ngenerating gymnastics routines such as \"switch leap with 0.5 turn\" poses\nsubstantial difficulties for current methods, often yielding unsatisfactory\nresults. To bridge this gap, we propose FinePhys, a Fine-grained human action\ngeneration framework that incorporates Physics to obtain effective skeletal\nguidance. Specifically, FinePhys first estimates 2D poses in an online manner\nand then performs 2D-to-3D dimension lifting via in-context learning. To\nmitigate the instability and limited interpretability of purely data-driven 3D\nposes, we further introduce a physics-based motion re-estimation module\ngoverned by Euler-Lagrange equations, calculating joint accelerations via\nbidirectional temporal updating. The physically predicted 3D poses are then\nfused with data-driven ones, offering multi-scale 2D heatmap guidance for the\ndiffusion process. Evaluated on three fine-grained action subsets from FineGym\n(FX-JUMP, FX-TURN, and FX-SALTO), FinePhys significantly outperforms\ncompetitive baselines. Comprehensive qualitative results further demonstrate\nFinePhys's ability to generate more natural and plausible fine-grained human\nactions.",
      "tldr_zh": "该研究提出FinePhys框架，通过显式整合物理定律来生成细粒度的物理上合理的动作序列，旨在解决现有视频生成方法在处理复杂时间动态和细粒度语义（如体操动作“switch leap with 0.5 turn”）时的不足。FinePhys首先在线方式估计2D姿势，然后利用in-context learning进行2D-to-3D提升，并引入基于Euler-Lagrange equations的运动重新估计模块，通过双向时间更新计算关节加速度，以融合物理预测和数据驱动的3D姿势，提供多尺度2D热图指导扩散过程。在FineGym数据集的三个子集（FX-JUMP、FX-TURN和FX-SALTO）上，FinePhys显著优于基线模型，并生成更自然、逼真的细粒度人类动作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13437v1",
      "published_date": "2025-05-19 17:58:11 UTC",
      "updated_date": "2025-05-19 17:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:05:41.988382"
    },
    {
      "arxiv_id": "2505.13427v1",
      "title": "MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision",
      "title_zh": "MM-PRM：通过可扩展步骤级",
      "authors": [
        "Lingxiao Du",
        "Fanqing Meng",
        "Zongkai Liu",
        "Zhixiang Zhou",
        "Ping Luo",
        "Qiaosheng Zhang",
        "Wenqi Shao"
      ],
      "abstract": "While Multimodal Large Language Models (MLLMs) have achieved impressive\nprogress in vision-language understanding, they still struggle with complex\nmulti-step reasoning, often producing logically inconsistent or partially\ncorrect solutions. A key limitation lies in the lack of fine-grained\nsupervision over intermediate reasoning steps. To address this, we propose\nMM-PRM, a process reward model trained within a fully automated, scalable\nframework. We first build MM-Policy, a strong multimodal model trained on\ndiverse mathematical reasoning data. Then, we construct MM-K12, a curated\ndataset of 10,000 multimodal math problems with verifiable answers, which\nserves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based\npipeline, we generate over 700k step-level annotations without human labeling.\nThe resulting PRM is used to score candidate reasoning paths in the Best-of-N\ninference setup and achieves significant improvements across both in-domain\n(MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.)\nbenchmarks. Further analysis confirms the effectiveness of soft labels, smaller\nlearning rates, and path diversity in optimizing PRM performance. MM-PRM\ndemonstrates that process supervision is a powerful tool for enhancing the\nlogical robustness of multimodal reasoning systems. We release all our codes\nand data at https://github.com/ModalMinds/MM-PRM.",
      "tldr_zh": "这项研究针对Multimodal Large Language Models (MLLMs)在多步推理中的问题，如逻辑不一致或部分正确解决方案，提出MM-PRM，一种通过可扩展步级监督来增强多模态数学推理的过程奖励模型。研究首先构建了MM-Policy模型和MM-K12数据集（包含10,000个多模态数学问题），然后利用Monte Carlo Tree Search (MCTS)管道自动生成超过700k步级注释，实现无人工标注的训练框架。实验结果显示，MM-PRM在Best-of-N推理设置中显著提升了性能，在内部基准（MM-K12测试集）和外部基准（OlympiadBench、MathVista等）上均取得改进，进一步证明过程监督能增强多模态推理系统的逻辑稳健性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13427v1",
      "published_date": "2025-05-19 17:55:08 UTC",
      "updated_date": "2025-05-19 17:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:05:54.724839"
    },
    {
      "arxiv_id": "2505.13425v1",
      "title": "Learnware of Language Models: Specialized Small Language Models Can Do Big",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi-Hao Tan",
        "Zi-Chen Zhao",
        "Hao-Yu Shi",
        "Xin-Yu Zhang",
        "Peng Tan",
        "Yang Yu",
        "Zhi-Hua Zhou"
      ],
      "abstract": "The learnware paradigm offers a novel approach to machine learning by\nenabling users to reuse a set of well-trained models for tasks beyond the\nmodels' original purposes. It eliminates the need to build models from scratch,\ninstead relying on specifications (representations of a model's capabilities)\nto identify and leverage the most suitable models for new tasks. While\nlearnware has proven effective in many scenarios, its application to language\nmodels has remained largely unexplored. At the same time, large language models\n(LLMs) have demonstrated remarkable universal question-answering abilities, yet\nthey face challenges in specialized scenarios due to data scarcity, privacy\nconcerns, and high computational costs, thus more and more specialized small\nlanguage models (SLMs) are being trained for specific domains. To address these\nlimitations systematically, the learnware paradigm provides a promising\nsolution by enabling maximum utilization of specialized SLMs, and allowing\nusers to identify and reuse them in a collaborative and privacy-preserving\nmanner.\n  This paper presents a preliminary attempt to apply the learnware paradigm to\nlanguage models. We simulated a learnware system comprising approximately 100\nlearnwares of specialized SLMs with 8B parameters, fine-tuned across finance,\nhealthcare, and mathematics domains. Each learnware contains an SLM and a\nspecification, which enables users to identify the most relevant models without\nexposing their own data. Experimental results demonstrate promising\nperformance: by selecting one suitable learnware for each task-specific\ninference, the system outperforms the base SLMs on all benchmarks. Compared to\nLLMs, the system outperforms Qwen1.5-110B, Qwen2.5-72B, and\nLlama3.1-70B-Instruct by at least 14% in finance domain tasks, and surpasses\nFlan-PaLM-540B (ranked 7th on the Open Medical LLM Leaderboard) in medical\ndomain tasks.",
      "tldr_zh": "该论文引入 learnware 范式应用于语言模型，允许用户重用专门的小语言模型 (SLMs) 来处理超出原设计的新任务，从而避免从零构建模型。研究模拟了一个包含约100个针对金融、健康和数学领域的8B参数 SLMs 的 learnware 系统，每个模型配有规范 (specification)，以隐私保护方式帮助用户识别和利用最相关模型。实验结果显示，该系统在基准测试中优于基础 SLMs，并在特定领域表现出色，例如在金融任务中比 Qwen1.5-110B、Qwen2.5-72B 和 Llama3.1-70B-Instruct 高出至少14%，并在医疗任务中超越 Flan-PaLM-540B。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13425v1",
      "published_date": "2025-05-19 17:54:35 UTC",
      "updated_date": "2025-05-19 17:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:06:07.639526"
    },
    {
      "arxiv_id": "2505.13417v1",
      "title": "AdaptThink: Reasoning Models Can Learn When to Think",
      "title_zh": "AdaptThink: 推理模型能够学习何时思考",
      "authors": [
        "Jiajie Zhang",
        "Nianyi Lin",
        "Lei Hou",
        "Ling Feng",
        "Juanzi Li"
      ],
      "abstract": "Recently, large reasoning models have achieved impressive performance on\nvarious tasks by employing human-like deep thinking. However, the lengthy\nthinking process substantially increases inference overhead, making efficiency\na critical bottleneck. In this work, we first demonstrate that NoThinking,\nwhich prompts the reasoning model to skip thinking and directly generate the\nfinal solution, is a better choice for relatively simple tasks in terms of both\nperformance and efficiency. Motivated by this, we propose AdaptThink, a novel\nRL algorithm to teach reasoning models to choose the optimal thinking mode\nadaptively based on problem difficulty. Specifically, AdaptThink features two\ncore components: (1) a constrained optimization objective that encourages the\nmodel to choose NoThinking while maintaining the overall performance; (2) an\nimportance sampling strategy that balances Thinking and NoThinking samples\nduring on-policy training, thereby enabling cold start and allowing the model\nto explore and exploit both thinking modes throughout the training process. Our\nexperiments indicate that AdaptThink significantly reduces the inference costs\nwhile further enhancing performance. Notably, on three math datasets,\nAdaptThink reduces the average response length of DeepSeek-R1-Distill-Qwen-1.5B\nby 53% and improves its accuracy by 2.4%, highlighting the promise of adaptive\nthinking-mode selection for optimizing the balance between reasoning quality\nand efficiency. Our codes and models are available at\nhttps://github.com/THU-KEG/AdaptThink.",
      "tldr_zh": "该研究发现，大型推理模型的深度思考过程虽提升了性能，但显著增加了推理开销，而对于简单任务，直接生成答案（NoThinking）更具效率优势。作者提出 AdaptThink，一种基于 Reinforcement Learning (RL) 算法的框架，让模型根据问题难度自适应选择思考模式，包括约束优化目标以维持性能并鼓励 NoThinking，以及重要性采样策略来平衡训练样本。实验结果显示，在三个数学数据集上，AdaptThink 将 DeepSeek-R1-Distill-Qwen-1.5B 的平均响应长度减少 53%，并提高准确率 2.4%，从而优化了推理质量与效率的平衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13417v1",
      "published_date": "2025-05-19 17:50:52 UTC",
      "updated_date": "2025-05-19 17:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:06:19.849019"
    },
    {
      "arxiv_id": "2505.13408v1",
      "title": "CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhe Bi",
        "Danqi Yan",
        "Yifan Wang",
        "Wenke Huang",
        "Haokun Chen",
        "Guancheng Wan",
        "Mang Ye",
        "Xun Xiao",
        "Hinrich Schuetze",
        "Volker Tresp",
        "Yunpu Ma"
      ],
      "abstract": "Recent Large Reasoning Models significantly improve the reasoning ability of\nLarge Language Models by learning to reason, exhibiting the promising\nperformance in solving complex tasks. LRMs solve tasks that require complex\nreasoning by explicitly generating reasoning trajectories together with\nanswers. Nevertheless, judging the quality of such an output answer is not easy\nbecause only considering the correctness of the answer is not enough and the\nsoundness of the reasoning trajectory part matters as well. Logically, if the\nsoundness of the reasoning part is poor, even if the answer is correct, the\nconfidence of the derived answer should be low. Existing methods did consider\njointly assessing the overall output answer by taking into account the\nreasoning part, however, their capability is still not satisfactory as the\ncausal relationship of the reasoning to the concluded answer cannot properly\nreflected. In this paper, inspired by classical mechanics, we present a novel\napproach towards establishing a CoT-Kinetics energy equation. Specifically, our\nCoT-Kinetics energy equation formulates the token state transformation process,\nwhich is regulated by LRM internal transformer layers, as like a particle\nkinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy\nassigns a scalar score to evaluate specifically the soundness of the reasoning\nphase, telling how confident the derived answer could be given the evaluated\nreasoning. As such, the LRM's overall output quality can be accurately\nmeasured, rather than a coarse judgment (e.g., correct or incorrect) anymore.",
      "tldr_zh": "本文提出 CoT-Kinetics 能量方程，一种受经典力学启发的理论模型，用于评估 Large Reasoning Models (LRMs) 的推理过程。现有方法仅关注答案正确性，无法充分反映推理轨迹的 soundness 和其与答案的因果关系，而 CoT-Kinetics 通过将 LRM 的 token 状态转换过程模拟为粒子动力学，生成一个标量分数来量化推理的 soundness，从而更准确地衡量整体输出质量。该方法提升了对 LRM 推理可靠性的评估，为复杂任务的置信度判断提供了新工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13408v1",
      "published_date": "2025-05-19 17:44:26 UTC",
      "updated_date": "2025-05-19 17:44:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:06:31.494474"
    },
    {
      "arxiv_id": "2505.13406v1",
      "title": "AutoMathKG: The automated mathematical knowledge graph based on LLM and vector database",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Bian",
        "Yu Geng",
        "Zijian Yang",
        "Bing Cheng"
      ],
      "abstract": "A mathematical knowledge graph (KG) presents knowledge within the field of\nmathematics in a structured manner. Constructing a math KG using natural\nlanguage is an essential but challenging task. There are two major limitations\nof existing works: first, they are constrained by corpus completeness, often\ndiscarding or manually supplementing incomplete knowledge; second, they\ntypically fail to fully automate the integration of diverse knowledge sources.\nThis paper proposes AutoMathKG, a high-quality, wide-coverage, and\nmulti-dimensional math KG capable of automatic updates. AutoMathKG regards\nmathematics as a vast directed graph composed of Definition, Theorem, and\nProblem entities, with their reference relationships as edges. It integrates\nknowledge from ProofWiki, textbooks, arXiv papers, and TheoremQA, enhancing\nentities and relationships with large language models (LLMs) via in-context\nlearning for data augmentation. To search for similar entities, MathVD, a\nvector database, is built through two designed embedding strategies using\nSBERT. To automatically update, two mechanisms are proposed. For knowledge\ncompletion mechanism, Math LLM is developed to interact with AutoMathKG,\nproviding missing proofs or solutions. For knowledge fusion mechanism, MathVD\nis used to retrieve similar entities, and LLM is used to determine whether to\nmerge with a candidate or add as a new entity. A wide range of experiments\ndemonstrate the advanced performance and broad applicability of the AutoMathKG\nsystem, including superior reachability query results in MathVD compared to\nfive baselines and robust mathematical reasoning capability in Math LLM.",
      "tldr_zh": "本文提出 AutoMathKG，这是一个基于 LLMs 和 vector database 的自动数学知识图谱系统，旨在解决现有数学 KG 构建中语料不完整和自动化不足的问题。AutoMathKG 将数学知识结构化为由 Definition, Theorem, and Problem 实体组成的巨大有向图，并通过整合 ProofWiki、教科书、arXiv 论文和 TheoremQA 等来源，利用 in-context learning 增强实体和关系。系统构建了 MathVD 向量数据库，使用 SBERT 的嵌入策略进行实体相似性搜索，并引入知识完成机制（Math LLM 提供缺失证明）和知识融合机制（检索并决定合并实体）。实验结果显示，AutoMathKG 在可达性查询上优于五个基线模型，并在数学推理能力方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13406v1",
      "published_date": "2025-05-19 17:41:29 UTC",
      "updated_date": "2025-05-19 17:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:06:44.560692"
    },
    {
      "arxiv_id": "2505.13400v1",
      "title": "Robin: A multi-agent system for automating scientific discovery",
      "title_zh": "Robin：用于自动化科学发现的多智能体系统",
      "authors": [
        "Ali Essam Ghareeb",
        "Benjamin Chang",
        "Ludovico Mitchener",
        "Angela Yiu",
        "Caralyn J. Szostkiewicz",
        "Jon M. Laurent",
        "Muhammed T. Razzak",
        "Andrew D. White",
        "Michaela M. Hinks",
        "Samuel G. Rodriques"
      ],
      "abstract": "Scientific discovery is driven by the iterative process of background\nresearch, hypothesis generation, experimentation, and data analysis. Despite\nrecent advancements in applying artificial intelligence to scientific\ndiscovery, no system has yet automated all of these stages in a single\nworkflow. Here, we introduce Robin, the first multi-agent system capable of\nfully automating the key intellectual steps of the scientific process. By\nintegrating literature search agents with data analysis agents, Robin can\ngenerate hypotheses, propose experiments, interpret experimental results, and\ngenerate updated hypotheses, achieving a semi-autonomous approach to scientific\ndiscovery. By applying this system, we were able to identify a novel treatment\nfor dry age-related macular degeneration (dAMD), the major cause of blindness\nin the developed world. Robin proposed enhancing retinal pigment epithelium\nphagocytosis as a therapeutic strategy, and identified and validated a\npromising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho\nkinase (ROCK) inhibitor that has never previously been proposed for treating\ndAMD. To elucidate the mechanism of ripasudil-induced upregulation of\nphagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment,\nwhich revealed upregulation of ABCA1, a critical lipid efflux pump and possible\nnovel target. All hypotheses, experimental plans, data analyses, and data\nfigures in the main text of this report were produced by Robin. As the first AI\nsystem to autonomously discover and validate a novel therapeutic candidate\nwithin an iterative lab-in-the-loop framework, Robin establishes a new paradigm\nfor AI-driven scientific discovery.",
      "tldr_zh": "该研究介绍了 Robin，一个多-agent 系统，旨在自动化科学发现过程，包括文献搜索、假设生成、实验提出、结果解释和更新假设，从而实现半自治的迭代工作流。Robin 通过整合文献搜索代理和数据分析代理，成功识别并验证了 ripasudil 作为治疗干性年龄相关性黄斑变性 (dAMD) 的新候选药物，该药物通过增强视网膜色素上皮吞噬作用发挥疗效。进一步的 RNA-seq 实验由系统提出和分析，揭示了 ripasudil 上调 ABCA1（一个关键的脂质外排泵）的机制。所有论文中的假设、实验计划、数据分析和图表均由 Robin 生成，这标志着 AI 在科学发现中的新范式，建立起可迭代的实验室-系统框架。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13400v1",
      "published_date": "2025-05-19 17:36:17 UTC",
      "updated_date": "2025-05-19 17:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:06:55.034962"
    },
    {
      "arxiv_id": "2505.13393v2",
      "title": "IG Parser: A Software Package for the Encoding of Institutional Statements using the Institutional Grammar",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher K. Frantz"
      ],
      "abstract": "This article provides an overview of IG Parser, a software that facilitates\nqualitative content analysis of formal (e.g., legal) rules or informal (e.g.,\nsocial) norms, and strategies (such as conventions) -- referred to as\ninstitutions -- that govern social systems and operate configurally to describe\ninstitutional systems. To this end, the IG Parser employs a distinctive syntax\nthat ensures rigorous encoding of natural language, while automating the\ntransformation into various formats that support the downstream analysis using\ndiverse analytical techniques. The conceptual core of the IG Parser is an\nassociated syntax, IG Script, that operationalizes the conceptual foundations\nof the Institutional Grammar, and more specifically the Institutional Grammar\n2.0, an analytical paradigm for institutional analysis. This article presents\nthe IG Parser, including its conceptual foundations, the syntax specification\nof IG Script, and its architectural principles. This overview is augmented with\nselective illustrative examples that highlight its use and the associated\nbenefits.",
      "tldr_zh": "本研究介绍了 IG Parser，一款软件工具，用于对正式规则（如法律）和非正式规范（如社会规范）进行定性内容分析，这些规范统称为机构。IG Parser 采用 IG Script 语法来严格编码自然语言，并自动将其转换为多种格式，支持下游分析技术，该语法基于 Institutional Grammar 2.0 的概念基础。文章详细阐述了软件的架构原理、语法规范，并通过示例展示了其使用益处，有助于提升机构分析的效率和准确性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "68T30, 68T50",
        "E.2; H.1.0; I.7.2; I.6.5; K.4.1"
      ],
      "primary_category": "cs.MA",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.13393v2",
      "published_date": "2025-05-19 17:33:15 UTC",
      "updated_date": "2025-05-20 09:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:07:05.248962"
    },
    {
      "arxiv_id": "2505.13391v1",
      "title": "Advancing Generalization Across a Variety of Abstract Visual Reasoning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Mikołaj Małkiński",
        "Jacek Mańdziuk"
      ],
      "abstract": "The abstract visual reasoning (AVR) domain presents a diverse suite of\nanalogy-based tasks devoted to studying model generalization. Recent years have\nbrought dynamic progress in the field, particularly in i.i.d. scenarios, in\nwhich models are trained and evaluated on the same data distributions.\nNevertheless, o.o.d. setups that assess model generalization to new test\ndistributions remain challenging even for the most recent models. To advance\ngeneralization in AVR tasks, we present the Pathways of Normalized Group\nConvolution model (PoNG), a novel neural architecture that features group\nconvolution, normalization, and a parallel design. We consider a wide set of\nAVR benchmarks, including Raven's Progressive Matrices and visual analogy\nproblems with both synthetic and real-world images. The experiments demonstrate\nstrong generalization capabilities of the proposed model, which in several\nsettings outperforms the existing literature methods.",
      "tldr_zh": "该研究针对抽象视觉推理 (AVR) 任务中的模型泛化问题，特别是在 o.o.d.（非独立同分布）场景下模型难以适应新数据分布的挑战。作者提出了一种新颖的神经网络架构——Pathways of Normalized Group Convolution model (PoNG)，它整合了 group convolution、normalization 和并行设计，以提升模型的泛化能力。实验在多种 AVR 基准上进行，包括 Raven's Progressive Matrices 和基于合成及真实图像的视觉类比问题，结果显示 PoNG 在多个设置中超过了现有方法，展示了强大的泛化性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.13391v1",
      "published_date": "2025-05-19 17:32:07 UTC",
      "updated_date": "2025-05-19 17:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:07:18.862461"
    },
    {
      "arxiv_id": "2505.13388v1",
      "title": "R3: Robust Rubric-Agnostic Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "David Anugraha",
        "Zilu Tang",
        "Lester James V. Miranda",
        "Hanyang Zhao",
        "Mohammad Rifqi Farhansyah",
        "Garry Kuwanto",
        "Derry Wijaya",
        "Genta Indra Winata"
      ],
      "abstract": "Reward models are essential for aligning language model outputs with human\npreferences, yet existing approaches often lack both controllability and\ninterpretability. These models are typically optimized for narrow objectives,\nlimiting their generalizability to broader downstream tasks. Moreover, their\nscalar outputs are difficult to interpret without contextual reasoning. To\naddress these limitations, we introduce R3, a novel reward modeling framework\nthat is rubric-agnostic, generalizable across evaluation dimensions, and\nprovides interpretable, reasoned score assignments. R3 enables more transparent\nand flexible evaluation of language models, supporting robust alignment with\ndiverse human values and use cases. Our models, data, and code are available as\nopen source at https://github.com/rubricreward/r3",
      "tldr_zh": "现有奖励模型在对齐语言模型输出与人类偏好时，往往缺乏可控性和可解释性，且因优化狭窄目标而难以泛化。论文引入R3框架，这是一种rubric-agnostic的奖励模型，能够跨评估维度泛化，并提供可解释的推理支持评分。R3通过更透明、灵活的评估机制，支持语言模型与多样人类价值观的对齐，并开源了模型、数据和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.13388v1",
      "published_date": "2025-05-19 17:29:03 UTC",
      "updated_date": "2025-05-19 17:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:07:29.072096"
    },
    {
      "arxiv_id": "2505.13381v1",
      "title": "How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Mak Ahmad",
        "Prerna Ravi",
        "David Karger",
        "Marc Facciotti"
      ],
      "abstract": "Providing personalized, detailed feedback at scale in large undergraduate\nSTEM courses remains a persistent challenge. We present an empirically\nevaluated practice exam system that integrates AI generated feedback with\ntargeted textbook references, deployed in a large introductory biology course.\nOur system encourages metacognitive behavior by asking students to explain\ntheir answers and declare their confidence. It uses OpenAI's GPT-4o to generate\npersonalized feedback based on this information, while directing them to\nrelevant textbook sections. Through interaction logs from consenting\nparticipants across three midterms (541, 342, and 413 students respectively),\ntotaling 28,313 question-student interactions across 146 learning objectives,\nalong with 279 surveys and 23 interviews, we examined the system's impact on\nlearning outcomes and engagement. Across all midterms, feedback types showed no\nstatistically significant performance differences, though some trends suggested\npotential benefits. The most substantial impact came from the required\nconfidence ratings and explanations, which students reported transferring to\ntheir actual exam strategies. About 40 percent of students engaged with\ntextbook references when prompted by feedback -- far higher than traditional\nreading rates. Survey data revealed high satisfaction (mean rating 4.1 of 5),\nwith 82.1 percent reporting increased confidence on practiced midterm topics,\nand 73.4 percent indicating they could recall and apply specific concepts. Our\nfindings suggest that embedding structured reflection requirements may be more\nimpactful than sophisticated feedback mechanisms.",
      "tldr_zh": "本研究探讨了在大型本科 STEM 课程中，通过添加元认知要求（Metacognitive Requirements）来支持 AI 反馈（如 OpenAI's GPT-4o），如何改变学生在实践考试中的学习行为。该系统要求学生解释答案并声明信心水平，同时提供个性化反馈和针对性教材引用。实验分析了跨越三个学期（总计 28,313 次互动）的日志、调查和访谈数据，结果显示，虽然反馈类型对学习成绩无显著差异，但元认知要求显著提升了学生的考试策略和参与度，例如40%的学生主动查阅教材。总体而言，该研究强调，嵌入结构化的反思机制可能比复杂的 AI 反馈机制更有效，提升了学生信心和概念应用（满意度均分4.1/5）。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "K.3.1; I.2.7; H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 3 figures, to appear in Proceedings of the Twelfth ACM\n  Conference on Learning @ Scale (L@S 2025), July 2025, Palermo, Italy",
      "pdf_url": "http://arxiv.org/pdf/2505.13381v1",
      "published_date": "2025-05-19 17:25:07 UTC",
      "updated_date": "2025-05-19 17:25:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:07:41.595094"
    },
    {
      "arxiv_id": "2505.13380v1",
      "title": "CompeteSMoE -- Statistically Guaranteed Mixture of Experts Training via Competition",
      "title_zh": "Compete",
      "authors": [
        "Nam V. Nguyen",
        "Huy Nguyen",
        "Quang Pham",
        "Van Nguyen",
        "Savitha Ramasamy",
        "Nhat Ho"
      ],
      "abstract": "Sparse mixture of experts (SMoE) offers an appealing solution to scale up the\nmodel complexity beyond the mean of increasing the network's depth or width.\nHowever, we argue that effective SMoE training remains challenging because of\nthe suboptimal routing process where experts that perform computation do not\ndirectly contribute to the routing process. In this work, we propose\ncompetition, a novel mechanism to route tokens to experts with the highest\nneural response. Theoretically, we show that the competition mechanism enjoys a\nbetter sample efficiency than the traditional softmax routing. Furthermore, we\ndevelop CompeteSMoE, a simple yet effective algorithm to train large language\nmodels by deploying a router to learn the competition policy, thus enjoying\nstrong performances at a low training overhead. Our extensive empirical\nevaluations on both the visual instruction tuning and language pre-training\ntasks demonstrate the efficacy, robustness, and scalability of CompeteSMoE\ncompared to state-of-the-art SMoE strategies. We have made the implementation\navailable at: https://github.com/Fsoft-AIC/CompeteSMoE. This work is an\nimproved version of the previous study at arXiv:2402.02526",
      "tldr_zh": "该研究针对 Sparse Mixture of Experts (SMoE) 模型的训练挑战，提出了一种新型 competition 机制，将 tokens 路由到具有最高神经响应的 experts，从而优化路由过程并提升样本效率。论文理论证明，competition 机制比传统的 softmax routing 具有更好的样本效率，并开发了 CompeteSMoE 算法，通过一个 router 学习 competition policy，实现高效、低开销的大型语言模型训练。在视觉指令调优和语言预训练任务的广泛实验中，CompeteSMoE 展示了比现有 SMoE 策略更强的性能、鲁棒性和可扩展性，并提供了开源实现。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "52 pages. This work is an improved version of the previous study at\n  arXiv:2402.02526",
      "pdf_url": "http://arxiv.org/pdf/2505.13380v1",
      "published_date": "2025-05-19 17:24:26 UTC",
      "updated_date": "2025-05-19 17:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:07:53.299834"
    },
    {
      "arxiv_id": "2505.13379v1",
      "title": "Thinkless: LLM Learns When to Think",
      "title_zh": "Thinkless：LLM 学习何时思考",
      "authors": [
        "Gongfan Fang",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "abstract": "Reasoning Language Models, capable of extended chain-of-thought reasoning,\nhave demonstrated remarkable performance on tasks requiring complex logical\ninference. However, applying elaborate reasoning for all queries often results\nin substantial computational inefficiencies, particularly when many problems\nadmit straightforward solutions. This motivates an open question: Can LLMs\nlearn when to think? To answer this, we propose Thinkless, a learnable\nframework that empowers an LLM to adaptively select between short-form and\nlong-form reasoning, based on both task complexity and the model's ability.\nThinkless is trained under a reinforcement learning paradigm and employs two\ncontrol tokens, <short> for concise responses and <think> for detailed\nreasoning. At the core of our method is a Decoupled Group Relative Policy\nOptimization (DeGRPO) algorithm, which decomposes the learning objective of\nhybrid reasoning into two components: (1) a control token loss that governs the\nselection of the reasoning mode, and (2) a response loss that improves the\naccuracy of the generated answers. This decoupled formulation enables\nfine-grained control over the contributions of each objective, stabilizing\ntraining and effectively preventing collapse observed in vanilla GRPO.\nEmpirically, on several benchmarks such as Minerva Algebra, MATH-500, and\nGSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% -\n90%, significantly improving the efficiency of Reasoning Language Models. The\ncode is available at https://github.com/VainF/Thinkless",
      "tldr_zh": "该论文提出 Thinkless 框架，让大型语言模型(LLM)学会根据任务复杂度和模型能力，自适应选择简短响应(<short>)或详细推理(<think>)，以解决过度推理导致的计算效率问题。框架采用强化学习(reinforcement learning)训练，并引入 Decoupled Group Relative Policy Optimization (DeGRPO) 算法，将学习目标分解为控制标记损失和响应损失，从而稳定训练并优化混合推理。实验结果显示，在 Minerva Algebra、MATH-500 和 GSM8K 等基准上，Thinkless 减少了长链思考的使用 50%-90%，显著提高了推理语言模型的效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13379v1",
      "published_date": "2025-05-19 17:24:16 UTC",
      "updated_date": "2025-05-19 17:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:08:06.186998"
    },
    {
      "arxiv_id": "2505.13372v1",
      "title": "Exploiting Symbolic Heuristics for the Synthesis of Domain-Specific Temporal Planning Guidance using Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Irene Brugnara",
        "Alessandro Valentini",
        "Andrea Micheli"
      ],
      "abstract": "Recent work investigated the use of Reinforcement Learning (RL) for the\nsynthesis of heuristic guidance to improve the performance of temporal planners\nwhen a domain is fixed and a set of training problems (not plans) is given. The\nidea is to extract a heuristic from the value function of a particular\n(possibly infinite-state) MDP constructed over the training problems.\n  In this paper, we propose an evolution of this learning and planning\nframework that focuses on exploiting the information provided by symbolic\nheuristics during both the RL and planning phases. First, we formalize\ndifferent reward schemata for the synthesis and use symbolic heuristics to\nmitigate the problems caused by the truncation of episodes needed to deal with\nthe potentially infinite MDP. Second, we propose learning a residual of an\nexisting symbolic heuristic, which is a \"correction\" of the heuristic value,\ninstead of eagerly learning the whole heuristic from scratch. Finally, we use\nthe learned heuristic in combination with a symbolic heuristic using a\nmultiple-queue planning approach to balance systematic search with imperfect\nlearned information. We experimentally compare all the approaches, highlighting\ntheir strengths and weaknesses and significantly advancing the state of the art\nfor this planning and learning schema.",
      "tldr_zh": "本文提出了一种改进框架，使用 Reinforcement Learning (RL) 合成特定领域的时序规划启发式指导，通过利用符号 heuristics 来提升规划性能。具体贡献包括形式化新的奖励方案以处理无限 MDP 中的剧集截断问题、学习现有符号 heuristics 的残差作为修正，以及将学到的 heuristics 与符号 heuristics 结合使用多队列规划方法进行平衡搜索。实验比较了这些方法，突出了它们的优势和劣势，并显著推进了这一规划和学习方案的状态。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13372v1",
      "published_date": "2025-05-19 17:19:13 UTC",
      "updated_date": "2025-05-19 17:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:08:19.576158"
    },
    {
      "arxiv_id": "2505.13358v2",
      "title": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Nimrod Berman",
        "Ilan Naiman",
        "Moshe Eliasof",
        "Hedi Zisling",
        "Omri Azencot"
      ],
      "abstract": "Diffusion-based generative models have demonstrated exceptional performance,\nyet their iterative sampling procedures remain computationally expensive. A\nprominent strategy to mitigate this cost is distillation, with offline\ndistillation offering particular advantages in terms of efficiency, modularity,\nand flexibility. In this work, we identify two key observations that motivate a\nprincipled distillation framework: (1) while diffusion models have been viewed\nthrough the lens of dynamical systems theory, powerful and underexplored tools\ncan be further leveraged; and (2) diffusion models inherently impose\nstructured, semantically coherent trajectories in latent space. Building on\nthese observations, we introduce the Koopman Distillation Model KDM, a novel\noffline distillation approach grounded in Koopman theory-a classical framework\nfor representing nonlinear dynamics linearly in a transformed space. KDM\nencodes noisy inputs into an embedded space where a learned linear operator\npropagates them forward, followed by a decoder that reconstructs clean samples.\nThis enables single-step generation while preserving semantic fidelity. We\nprovide theoretical justification for our approach: (1) under mild assumptions,\nthe learned diffusion dynamics admit a finite-dimensional Koopman\nrepresentation; and (2) proximity in the Koopman latent space correlates with\nsemantic similarity in the generated outputs, allowing for effective trajectory\nalignment. Empirically, KDM achieves state-of-the-art performance across\nstandard offline distillation benchmarks, improving FID scores by up to 40% in\na single generation step. All implementation details and code for the\nexperimental setups are provided in our GitHub -\nhttps://github.com/azencot-group/KDM, or in our project page -\nhttps://sites.google.com/view/koopman-distillation-model.",
      "tldr_zh": "这篇论文提出了一种基于 Koopman 理论的离线蒸馏方法，名为 Koopman Distillation Model (KDM)，旨在优化 Diffusion-based 生成模型的采样过程，实现高效的单步生成。KDM 通过将噪声输入编码到嵌入空间，使用线性操作符传播动态，并通过解码器重建干净样本，从而保留语义连贯性。理论分析证明，扩散模型动态可表示为有限维 Koopman 表示，且潜在空间的接近度与生成输出语义相似度相关。实验结果显示，KDM 在离线蒸馏基准上取得最先进性能，FID scores 改善高达 40%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13358v2",
      "published_date": "2025-05-19 16:59:47 UTC",
      "updated_date": "2025-05-20 14:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:08:32.359296"
    },
    {
      "arxiv_id": "2505.13355v1",
      "title": "Multi-Armed Bandits Meet Large Language Models",
      "title_zh": "多臂老虎机遇见大语言模型",
      "authors": [
        "Djallel Bouneffouf",
        "Raphael Feraud"
      ],
      "abstract": "Bandit algorithms and Large Language Models (LLMs) have emerged as powerful\ntools in artificial intelligence, each addressing distinct yet complementary\nchallenges in decision-making and natural language processing. This survey\nexplores the synergistic potential between these two fields, highlighting how\nbandit algorithms can enhance the performance of LLMs and how LLMs, in turn,\ncan provide novel insights for improving bandit-based decision-making. We first\nexamine the role of bandit algorithms in optimizing LLM fine-tuning, prompt\nengineering, and adaptive response generation, focusing on their ability to\nbalance exploration and exploitation in large-scale learning tasks.\nSubsequently, we explore how LLMs can augment bandit algorithms through\nadvanced contextual understanding, dynamic adaptation, and improved policy\nselection using natural language reasoning. By providing a comprehensive review\nof existing research and identifying key challenges and opportunities, this\nsurvey aims to bridge the gap between bandit algorithms and LLMs, paving the\nway for innovative applications and interdisciplinary research in AI.",
      "tldr_zh": "这篇调查论文探讨了多臂老虎机（Multi-Armed Bandits）算法与大型语言模型（Large Language Models, LLMs）之间的协同潜力，旨在桥接这两个AI领域的决策优化和自然语言处理。论文首先分析了bandit算法在LLMs微调、提示工程和自适应响应生成中的作用，通过平衡探索和利用来提升大规模学习任务的性能。其次，研究了LLMs如何通过高级上下文理解、动态适应和自然语言推理来增强bandit算法的策略选择。总体上，该文提供了现有研究的全面回顾，识别了关键挑战和机会，为AI中的创新应用和跨学科研究铺平道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13355v1",
      "published_date": "2025-05-19 16:57:57 UTC",
      "updated_date": "2025-05-19 16:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:08:42.727335"
    },
    {
      "arxiv_id": "2505.13346v2",
      "title": "J4R: Learning to Judge with Equivalent Initial State Group Relative Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Austin Xu",
        "Yilun Zhou",
        "Xuan-Phi Nguyen",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "To keep pace with the increasing pace of large language models (LLM)\ndevelopment, model output evaluation has transitioned away from time-consuming\nhuman evaluation to automatic evaluation, where LLMs themselves are tasked with\nassessing and critiquing other model outputs. LLM-as-judge models are a class\nof generative evaluators that excel in evaluating relatively simple domains,\nlike chat quality, but struggle in reasoning intensive domains where model\nresponses contain more substantive and challenging content. To remedy existing\njudge shortcomings, we explore training judges with reinforcement learning\n(RL). We make three key contributions: (1) We propose the Equivalent Initial\nState Group Relative Policy Optimization (EIS-GRPO) algorithm, which allows us\nto train our judge to be robust to positional biases that arise in more complex\nevaluation settings. (2) We introduce ReasoningJudgeBench, a benchmark that\nevaluates judges in diverse reasoning settings not covered by prior work. (3)\nWe train Judge for Reasoning (J4R), a 7B judge trained with EIS-GRPO that\noutperforms GPT-4o and the next best small judge by 6.7% and 9%, matching or\nexceeding the performance of larger GRPO-trained judges on both JudgeBench and\nReasoningJudgeBench.",
      "tldr_zh": "这篇论文针对大型语言模型（LLM-as-judge）在推理密集型领域（如复杂响应评估）的不足，提出Equivalent Initial State Group Relative Policy Optimization (EIS-GRPO)算法，使用强化学习（RL）训练评判者模型，以提升其对位置偏差的鲁棒性。论文的主要贡献包括引入ReasoningJudgeBench基准，用于评估多样推理场景，以及训练了Judge for Reasoning (J4R)，一个7B参数的评判者模型。实验结果显示，J4R在JudgeBench和ReasoningJudgeBench上比GPT-4o和最佳小模型分别提高了6.7%和9%的性能，甚至与更大模型相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 4 figures, 6 tables. To be updated with links for\n  code/benchmark",
      "pdf_url": "http://arxiv.org/pdf/2505.13346v2",
      "published_date": "2025-05-19 16:50:35 UTC",
      "updated_date": "2025-05-20 14:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:08:56.888876"
    },
    {
      "arxiv_id": "2505.13344v1",
      "title": "RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE Optimization on Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmet Berke Gokmen",
        "Yigit Ekin",
        "Bahri Batuhan Bilecen",
        "Aysegul Dundar"
      ],
      "abstract": "We propose RoPECraft, a training-free video motion transfer method for\ndiffusion transformers that operates solely by modifying their rotary\npositional embeddings (RoPE). We first extract dense optical flow from a\nreference video, and utilize the resulting motion offsets to warp the\ncomplex-exponential tensors of RoPE, effectively encoding motion into the\ngeneration process. These embeddings are then further optimized during\ndenoising time steps via trajectory alignment between the predicted and target\nvelocities using a flow-matching objective. To keep the output faithful to the\ntext prompt and prevent duplicate generations, we incorporate a regularization\nterm based on the phase components of the reference video's Fourier transform,\nprojecting the phase angles onto a smooth manifold to suppress high-frequency\nartifacts. Experiments on benchmarks reveal that RoPECraft outperforms all\nrecently published methods, both qualitatively and quantitatively.",
      "tldr_zh": "我们提出了 RoPECraft，一种无需训练的视频动作转移方法，针对扩散变压器（diffusion transformers）通过修改旋转位置嵌入（RoPE）来实现运动编码。具体而言，该方法先从参考视频提取密集光流（dense optical flow），并用运动偏移扭曲 RoPE 的复指数张量，然后在去噪步骤中通过轨迹对齐和流匹配目标（flow-matching objective）进一步优化嵌入，同时加入基于参考视频傅立叶变换相位的正则化项，以确保输出忠于文本提示并抑制高频伪像。实验结果显示，RoPECraft 在基准测试中定性和定量上优于最近发布的其他方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://berkegokmen1.github.io/RoPECraft/",
      "pdf_url": "http://arxiv.org/pdf/2505.13344v1",
      "published_date": "2025-05-19 16:50:26 UTC",
      "updated_date": "2025-05-19 16:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:09:07.212052"
    },
    {
      "arxiv_id": "2505.13339v1",
      "title": "OPA-Pack: Object-Property-Aware Robotic Bin Packing",
      "title_zh": "翻译失败",
      "authors": [
        "Jia-Hui Pan",
        "Yeok Tatt Cheah",
        "Zhengzhe Liu",
        "Ka-Hei Hui",
        "Xiaojie Gao",
        "Pheng-Ann Heng",
        "Yun-Hui Liu",
        "Chi-Wing Fu"
      ],
      "abstract": "Robotic bin packing aids in a wide range of real-world scenarios such as\ne-commerce and warehouses. Yet, existing works focus mainly on considering the\nshape of objects to optimize packing compactness and neglect object properties\nsuch as fragility, edibility, and chemistry that humans typically consider when\npacking objects. This paper presents OPA-Pack (Object-Property-Aware Packing\nframework), the first framework that equips the robot with object property\nconsiderations in planning the object packing. Technical-wise, we develop a\nnovel object property recognition scheme with retrieval-augmented generation\nand chain-of-thought reasoning, and build a dataset with object property\nannotations for 1,032 everyday objects. Also, we formulate OPA-Net, aiming to\njointly separate incompatible object pairs and reduce pressure on fragile\nobjects, while compacting the packing. Further, OPA-Net consists of a property\nembedding layer to encode the property of candidate objects to be packed,\ntogether with a fragility heightmap and an avoidance heightmap to keep track of\nthe packed objects. Then, we design a reward function and adopt a deep\nQ-learning scheme to train OPA-Net. Experimental results manifest that OPA-Pack\ngreatly improves the accuracy of separating incompatible object pairs (from 52%\nto 95%) and largely reduces pressure on fragile objects (by 29.4%), while\nmaintaining good packing compactness. Besides, we demonstrate the effectiveness\nof OPA-Pack on a real packing platform, showcasing its practicality in\nreal-world scenarios.",
      "tldr_zh": "本论文提出 OPA-Pack 框架，这是首个考虑物体属性（如易碎性、可食用性和化学性质）的机器人装箱系统，旨在解决现有方法仅关注物体形状的局限性。框架采用 retrieval-augmented generation 和 chain-of-thought reasoning 的物体属性识别方案，并构建了一个包含 1,032 个日常物体的属性标注数据集，同时开发了 OPA-Net 模型，通过属性嵌入层、易碎高度图和避免高度图结合深度 Q-learning 训练，实现分离不相容物体对、减少易碎物体压力并保持装箱紧凑性。实验结果显示，OPA-Pack 将分离不相容物体对的准确率从 52% 提高到 95%，减少易碎物体压力 29.4%，并在真实平台上验证了其在实际场景中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to IEEE Transactions on Robotics (TRO) on Feb. 10, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13339v1",
      "published_date": "2025-05-19 16:48:14 UTC",
      "updated_date": "2025-05-19 16:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:09:20.107044"
    },
    {
      "arxiv_id": "2505.13338v1",
      "title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiongqiong Wang",
        "Hardik B. Sailor",
        "Tianchi Liu",
        "Ai Ti Aw"
      ],
      "abstract": "Current speech-LLMs exhibit limited capability in contextual reasoning\nalongside paralinguistic understanding, primarily due to the lack of\nQuestion-Answer (QA) datasets that cover both aspects. We propose a novel\nframework for dataset generation from in-the-wild speech data, that integrates\ncontextual reasoning with paralinguistic information. It consists of a pseudo\nparalinguistic label-based data condensation of in-the-wild speech and\nLLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is\nvalidated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct\nmodel on a dataset created by our framework and human-generated CPQA dataset.\nThe results also reveal the speech-LLM's limitations in handling empathetic\nreasoning tasks, highlighting the need for such datasets and more robust\nmodels. The proposed framework is first of its kind and has potential in\ntraining more robust speech-LLMs with paralinguistic reasoning capabilities.",
      "tldr_zh": "该研究针对当前 speech-LLMs 在语境推理和副语言理解方面的局限性，提出一个新框架，用于从野外语音数据生成整合这两方面的 QA 数据集。该框架包括基于伪副语言标签的数据浓缩和 LLM-based Contextual Paralinguistic QA (CPQA) 生成，通过 Qwen2-Audio-7B-Instruct 模型的评估验证了其有效性，并显示了模型在处理移情推理任务时的不足。结果强调了此类数据集的需求，该框架作为首创方法，有潜力提升 speech-LLMs 的副语言推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13338v1",
      "published_date": "2025-05-19 16:47:46 UTC",
      "updated_date": "2025-05-19 16:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:09:31.704095"
    },
    {
      "arxiv_id": "2505.13329v1",
      "title": "Recommender Systems for Democracy: Toward Adversarial Robustness in Voting Advice Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Frédéric Berdoz",
        "Dustin Brunner",
        "Yann Vonlanthen",
        "Roger Wattenhofer"
      ],
      "abstract": "Voting advice applications (VAAs) help millions of voters understand which\npolitical parties or candidates best align with their views. This paper\nexplores the potential risks these applications pose to the democratic process\nwhen targeted by adversarial entities. In particular, we expose 11 manipulation\nstrategies and measure their impact using data from Switzerland's primary VAA,\nSmartvote, collected during the last two national elections. We find that\naltering application parameters, such as the matching method, can shift a\nparty's recommendation frequency by up to 105%. Cherry-picking questionnaire\nitems can increase party recommendation frequency by over 261%, while subtle\nchanges to parties' or candidates' responses can lead to a 248% increase. To\naddress these vulnerabilities, we propose adversarial robustness properties\nVAAs should satisfy, introduce empirical metrics for assessing the resilience\nof various matching methods, and suggest possible avenues for research toward\nmitigating the effect of manipulation. Our framework is key to ensuring secure\nand reliable AI-based VAAs poised to emerge in the near future.",
      "tldr_zh": "该论文探讨了投票建议应用（Voting Advice Applications, VAAs）在民主过程中的潜在风险，特别是面对对手操纵时的脆弱性。研究者识别了11种操纵策略，并利用瑞士Smartvote数据进行实证分析，发现改变匹配方法可使政党推荐频率增加105%，挑选问题可增加261%，而修改响应可导致248%的提升。为了提升对抗鲁棒性，论文提出VAAs应满足的鲁棒性属性、评估匹配方法的经验指标，并建议研究方向，以确保未来AI-based VAAs的安全性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "This is the extended version of the paper, accepted at IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13329v1",
      "published_date": "2025-05-19 16:38:06 UTC",
      "updated_date": "2025-05-19 16:38:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:09:42.355814"
    },
    {
      "arxiv_id": "2505.13324v1",
      "title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Galit Shmueli",
        "David Martens",
        "Jaewon Yoo",
        "Travis Greene"
      ],
      "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields\nof causal inference (CI) and explainable artificial intelligence (XAI). While\nthe core idea behind counterfactuals remains the same in both fields--the\nexamination of what would have happened under different circumstances--there\nare key differences in how they are used and interpreted. We introduce a formal\ndefinition that encompasses the multi-faceted concept of the counterfactual in\nCI and XAI. We then discuss how counterfactuals are used, evaluated, generated,\nand operationalized in CI vs. XAI, highlighting conceptual and practical\ndifferences. By comparing and contrasting the two, we hope to identify\nopportunities for cross-fertilization across CI and XAI.",
      "tldr_zh": "本论文比较了反事实（counterfactuals）在因果推理（CI）和可解释AI（XAI）中的作用，尽管两者核心概念相同（即探讨不同情境下可能发生的情况），但在使用和解释上存在关键差异。论文引入了一个正式定义，涵盖反事实在CI和XAI的多方面概念，并讨论了它们在评估、生成和操作化方面的异同。最终，通过对比分析，论文突出了概念和实践差异，并探索了CI和XAI之间潜在的交叉合作机会，以促进更深入的见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13324v1",
      "published_date": "2025-05-19 16:34:36 UTC",
      "updated_date": "2025-05-19 16:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:09:54.864455"
    },
    {
      "arxiv_id": "2505.13316v1",
      "title": "Denoising Diffusion Probabilistic Model for Point Cloud Compression at Low Bit-Rates",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Spadaro",
        "Alberto Presta",
        "Jhony H. Giraldo",
        "Marco Grangetto",
        "Wei Hu",
        "Giuseppe Valenzise",
        "Attilio Fiandrotti",
        "Enzo Tartaglione"
      ],
      "abstract": "Efficient compression of low-bit-rate point clouds is critical for\nbandwidth-constrained applications. However, existing techniques mainly focus\non high-fidelity reconstruction, requiring many bits for compression. This\npaper proposes a \"Denoising Diffusion Probabilistic Model\" (DDPM) architecture\nfor point cloud compression (DDPM-PCC) at low bit-rates. A PointNet encoder\nproduces the condition vector for the generation, which is then quantized via a\nlearnable vector quantizer. This configuration allows to achieve a low bitrates\nwhile preserving quality. Experiments on ShapeNet and ModelNet40 show improved\nrate-distortion at low rates compared to standardized and state-of-the-art\napproaches. We publicly released the code at\nhttps://github.com/EIDOSLAB/DDPM-PCC.",
      "tldr_zh": "本文提出了一种基于Denoising Diffusion Probabilistic Model (DDPM)的点云压缩框架DDPM-PCC，针对低比特率场景以实现高效压缩。框架使用PointNet编码器生成条件向量，并通过可学习的向量量化器进行量化，从而在保持质量的同时降低比特率。在ShapeNet和ModelNet40数据集上的实验表明，DDPM-PCC在低比特率下比标准和最先进方法表现出更好的率-失真性能，且代码已开源在GitHub上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures, accepted at ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13316v1",
      "published_date": "2025-05-19 16:29:12 UTC",
      "updated_date": "2025-05-19 16:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:10:06.331203"
    },
    {
      "arxiv_id": "2505.13315v1",
      "title": "KHRONOS: a Kernel-Based Neural Architecture for Rapid, Resource-Efficient Scientific Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Reza T. Batley",
        "Sourav Saha"
      ],
      "abstract": "Contemporary models of high dimensional physical systems are constrained by\nthe curse of dimensionality and a reliance on dense data. We introduce KHRONOS\n(Kernel Expansion Hierarchy for Reduced Order, Neural Optimized Surrogates), an\nAI framework for model based, model free and model inversion tasks. KHRONOS\nconstructs continuously differentiable target fields with a hierarchical\ncomposition of per-dimension kernel expansions, which are tensorized into modes\nand then superposed. We evaluate KHRONOS on a canonical 2D, Poisson equation\nbenchmark: across 16 to 512 degrees of freedom (DoFs), it obtained L2 square\nerrors of 5e-4 down to 6e-10. This represents a 100 time gain over Kolmogorov\nArnold Networks (which itself reports a 100 times improvement on MLPs/PINNs\nwith 100 times fewer parameters) when controlling for the number of parameters.\nThis also represents a 1e4 times improvement in L2 square error compared to\nstandard linear FEM at comparable DoFs. Inference complexity is dominated by\ninner products, yielding sub-millisecond full-field predictions that scale to\nan arbitrary resolution. For inverse problems, KHRONOS facilitates rapid,\niterative level set recovery in only a few forward evaluations, with\nsub-microsecond per sample latency. KHRONOS scalability, expressivity, and\ninterpretability open new avenues in constrained edge computing, online\ncontrol, computer vision, and beyond.",
      "tldr_zh": "本研究提出KHRONOS，一种基于内核展开（Kernel Expansion）的神经架构框架，旨在解决高维物理系统建模中维度诅咒和数据密集问题。该框架通过层次化组合的每个维度内核展开构建连续可微的目标场，并将其张量化（tensorized）后叠加，实现模型构建、模型自由和模型反演任务。在2D Poisson方程基准测试中，KHRONOS在16至512自由度（DoFs）范围内，L2平方误差从5e-4降至6e-10，比Kolmogorov-Arnold Networks在相同参数下快100倍，并比标准线性FEM改善1e4倍的误差，支持亚毫秒级推理和任意分辨率预测。该框架的扩展性、可表达性和可解释性，为边缘计算、在线控制和计算机视觉等领域提供高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13315v1",
      "published_date": "2025-05-19 16:29:07 UTC",
      "updated_date": "2025-05-19 16:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:10:19.128177"
    },
    {
      "arxiv_id": "2505.13308v1",
      "title": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space",
      "title_zh": "翻译失败",
      "authors": [
        "Hengli Li",
        "Chenxi Li",
        "Tong Wu",
        "Xuekai Zhu",
        "Yuxuan Wang",
        "Zhaoxin Yu",
        "Eric Hanchen Jiang",
        "Song-Chun Zhu",
        "Zixia Jia",
        "Ying Nian Wu",
        "Zilong Zheng"
      ],
      "abstract": "Reasoning ability, a core component of human intelligence, continues to pose\na significant challenge for Large Language Models (LLMs) in the pursuit of AGI.\nAlthough model performance has improved under the training scaling law,\nsignificant challenges remain, particularly with respect to training\nalgorithms, such as catastrophic forgetting, and the limited availability of\nnovel training data. As an alternative, test-time scaling enhances reasoning\nperformance by increasing test-time computation without parameter updating.\nUnlike prior methods in this paradigm focused on token space, we propose\nleveraging latent space for more effective reasoning and better adherence to\nthe test-time scaling law. We introduce LatentSeek, a novel framework that\nenhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA)\nwithin the model's latent space. Specifically, LatentSeek leverages policy\ngradient to iteratively update latent representations, guided by self-generated\nreward signals. LatentSeek is evaluated on a range of reasoning benchmarks,\nincluding GSM8K, MATH-500, and AIME2024, across multiple LLM architectures.\nResults show that LatentSeek consistently outperforms strong baselines, such as\nChain-of-Thought prompting and fine-tuning-based methods. Furthermore, our\nanalysis demonstrates that LatentSeek is highly efficient, typically converging\nwithin a few iterations for problems of average complexity, while also\nbenefiting from additional iterations, thereby highlighting the potential of\ntest-time scaling in the latent space. These findings position LatentSeek as a\nlightweight, scalable, and effective solution for enhancing the reasoning\ncapabilities of LLMs.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在推理能力上的挑战，提出LatentSeek框架，通过测试时实例级适应（TTIA）在潜在空间（latent space）中提升性能，避免了传统训练中的灾难性遗忘和数据限制问题。具体而言，LatentSeek利用策略梯度（policy gradient）迭代更新潜在表示，并通过自生成的奖励信号引导优化过程。在GSM8K、MATH-500和AIME2024等基准上，LatentSeek优于Chain-of-Thought提示和微调方法，显示出高效收敛和可扩展性，证明了测试时缩放在潜在空间的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13308v1",
      "published_date": "2025-05-19 16:26:02 UTC",
      "updated_date": "2025-05-19 16:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:10:30.829228"
    },
    {
      "arxiv_id": "2505.13307v1",
      "title": "RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning",
      "title_zh": "RBF++：针对链式思维推理的可测量和不可测量能力的推理边界量化与优化",
      "authors": [
        "Qiguang Chen",
        "Libo Qin",
        "Jinhao Liu",
        "Yue Liao",
        "Jiaqi Wang",
        "Jingxuan Zhou",
        "Wanxiang Che"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning has proven effective in enhancing large\nlanguage models (LLMs) on complex tasks, spurring research into its underlying\nmechanisms. However, two primary challenges remain for real-world applications:\n(1) the lack of quantitative metrics and actionable guidelines for evaluating\nand optimizing measurable boundaries of CoT capability, and (2) the absence of\nmethods to assess boundaries of unmeasurable CoT capability, such as multimodal\nperception. To address these gaps, we introduce the Reasoning Boundary\nFramework++ (RBF++). To tackle the first challenge, we define the reasoning\nboundary (RB) as the maximum limit of CoT performance. We also propose a\ncombination law for RBs, enabling quantitative analysis and offering actionable\nguidance across various CoT tasks. For the second challenge, particularly in\nmultimodal scenarios, we introduce a constant assumption, which replaces\nunmeasurable RBs with scenario-specific constants. Additionally, we propose the\nreasoning boundary division mechanism, which divides unmeasurable RBs into two\nsub-boundaries, facilitating the quantification and optimization of both\nunmeasurable domain knowledge and multimodal perception capabilities. Extensive\nexperiments involving 38 models across 13 tasks validate the feasibility of our\nframework in cross-modal settings. Additionally, we evaluate 10 CoT strategies,\noffer insights into optimization and decay from two complementary perspectives,\nand expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope\nthis work advances the understanding of RBs and optimization strategies in\nLLMs. Code and data are available at\nhttps://github.com/LightChen233/reasoning-boundary.",
      "tldr_zh": "这篇论文引入了RBF++框架，用于量化和优化Chain-of-Thought (CoT)推理的可测量和不可测量能力边界，解决现有方法在评估和优化方面的不足。论文定义了reasoning boundary (RB)作为CoT性能的最大极限，并提出RB组合定律，提供量化分析和行动指导；同时，通过常量假设和reasoning boundary division机制，处理不可测量的能力，如多模态感知，将其分解为可优化的子边界。实验涉及38个模型和13个任务，验证了框架在跨模态场景的有效性，并评估了10种CoT策略，揭示优化路径和性能衰减洞见，从而推进LLMs推理边界的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript",
      "pdf_url": "http://arxiv.org/pdf/2505.13307v1",
      "published_date": "2025-05-19 16:25:55 UTC",
      "updated_date": "2025-05-19 16:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:10:43.750817"
    },
    {
      "arxiv_id": "2505.13292v1",
      "title": "Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Huaiying Luo",
        "Cheng Ji"
      ],
      "abstract": "In the age of cloud computing, data privacy protection has become a major\nchallenge, especially when sharing sensitive data across cloud environments.\nHowever, how to optimize collaboration across cloud environments remains an\nunresolved problem. In this paper, we combine federated learning with\nlarge-scale language models to optimize the collaborative mechanism of AI\nsystems. Based on the existing federated learning framework, we introduce a\ncross-cloud architecture in which federated learning works by aggregating model\nupdates from decentralized nodes without exposing the original data. At the\nsame time, combined with large-scale language models, its powerful context and\nsemantic understanding capabilities are used to improve model training\nefficiency and decision-making ability. We've further innovated by introducing\na secure communication layer to ensure the privacy and integrity of model\nupdates and training data. The model enables continuous model adaptation and\nfine-tuning across different cloud environments while protecting sensitive\ndata. Experimental results show that the proposed method is significantly\nbetter than the traditional federated learning model in terms of accuracy,\nconvergence speed and data privacy protection.",
      "tldr_zh": "本文提出了一种整合Federated Learning和LLMs的跨云数据隐私保护方法，旨在优化AI系统的协作机制，以解决云计算环境中敏感数据共享的隐私挑战。该方法基于Federated Learning的框架，引入跨云架构和Secure Communication Layer，实现模型更新的聚合而不暴露原始数据，同时利用LLMs的语境和语义理解能力提升训练效率和决策性能。实验结果表明，该方法在准确性、收敛速度和数据隐私保护方面显著优于传统Federated Learning模型，为跨云环境下的AI协作提供了可靠的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by 2025 IEEE 7th International Conference on Communications,\n  Information System and Computer Engineering",
      "pdf_url": "http://arxiv.org/pdf/2505.13292v1",
      "published_date": "2025-05-19 16:14:27 UTC",
      "updated_date": "2025-05-19 16:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:10:55.268107"
    },
    {
      "arxiv_id": "2505.13291v1",
      "title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents",
      "title_zh": "TimeSeriesGym：用于（时间序列）机器学习工程代理的可扩展基准测试",
      "authors": [
        "Yifu Cai",
        "Xinyu Li",
        "Mononito Goswami",
        "Michał Wiliński",
        "Gus Welter",
        "Artur Dubrawski"
      ],
      "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating\nArtificial Intelligence (AI) agents on time series machine learning engineering\nchallenges. Existing benchmarks lack scalability, focus narrowly on model\nbuilding in well-defined settings, and evaluate only a limited set of research\nartifacts (e.g., CSV submission files). To make AI agent benchmarking more\nrelevant to the practice of machine learning engineering, our framework scales\nalong two critical dimensions. First, recognizing that effective ML engineering\nrequires a range of diverse skills, TimeSeriesGym incorporates challenges from\ndiverse sources spanning multiple domains and tasks. We design challenges to\nevaluate both isolated capabilities (including data handling, understanding\nresearch repositories, and code translation) and their combinations, and rather\nthan addressing each challenge independently, we develop tools that support\ndesigning multiple challenges at scale. Second, we implement evaluation\nmechanisms for multiple research artifacts, including submission files, code,\nand models, using both precise numeric measures and more flexible LLM-based\nevaluation approaches. This dual strategy balances objective assessment with\ncontextual judgment. Although our initial focus is on time series applications,\nour framework can be readily extended to other data modalities, broadly\nenhancing the comprehensiveness and practical utility of agentic AI evaluation.\nWe open-source our benchmarking framework to facilitate future research on the\nML engineering capabilities of AI agents.",
      "tldr_zh": "该研究引入了 TimeSeriesGym，一种可扩展的基准框架，用于评估 AI agents 在时间序列机器学习工程挑战中的性能。TimeSeriesGym 解决了现有基准的局限性，如缺乏可扩展性和对单一任务的狭隘关注，通过整合多样化挑战（涵盖数据处理、研究仓库理解和代码翻译等孤立或组合能力）来模拟实际 ML 工程实践。框架采用精确的数字指标和灵活的 LLM-based 评估机制，对多种研究产物（如提交文件、代码和模型）进行全面评估；尽管初始聚焦时间序列应用，但其设计易于扩展到其他数据模式，并已开源以推动未来 AI 代理研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Open source code available at\n  https://github.com/moment-timeseries-foundation-model/TimeSeriesGym. YC, XL,\n  MG and MW contributed equally, and should be considered joint first authors",
      "pdf_url": "http://arxiv.org/pdf/2505.13291v1",
      "published_date": "2025-05-19 16:11:23 UTC",
      "updated_date": "2025-05-19 16:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:11:07.557384"
    },
    {
      "arxiv_id": "2505.14723v1",
      "title": "QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Subrata Biswas",
        "Mohammad Nur Hossain Khan",
        "Bashima Islam"
      ],
      "abstract": "Spoken Language Understanding (SLU) systems must balance performance and\nefficiency, particularly in resource-constrained environments. Existing methods\napply distillation and quantization separately, leading to suboptimal\ncompression as distillation ignores quantization constraints. We propose QUADS,\na unified framework that optimizes both through multi-stage training with a\npre-tuned model, enhancing adaptability to low-bit regimes while maintaining\naccuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with\nonly minor degradations of up to 5.56\\% compared to state-of-the-art models.\nAdditionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and\nmodel size by 83--700$\\times$, demonstrating strong robustness under extreme\nquantization. These results establish QUADS as a highly efficient solution for\nreal-world, resource-constrained SLU applications.",
      "tldr_zh": "该论文提出QUADS框架，一种统一的量化(distillation)蒸馏方法，用于优化Spoken Language Understanding (SLU)系统的性能和效率，尤其适用于资源受限环境。QUADS通过多阶段训练和预调整模型，同时处理distillation和quantization，实现对低位量化环境的适应性，同时保持高准确性。实验结果显示，QUADS在SLURP数据集上达到71.13%准确率、在FSC上达到99.20%，相较最先进模型仅下降不超过5.56%，并减少60-73倍的计算复杂度(GMACs)和83-700倍的模型大小，展示了在极端量化下的强大鲁棒性。总之，QUADS为资源受限的真实世界SLU应用提供了高效解决方案。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14723v1",
      "published_date": "2025-05-19 16:09:51 UTC",
      "updated_date": "2025-05-19 16:09:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:11:19.526170"
    },
    {
      "arxiv_id": "2505.13287v1",
      "title": "Level Generation with Quantum Reservoir Computing",
      "title_zh": "翻译失败",
      "authors": [
        "João S. Ferreira",
        "Pierre Fromholz",
        "Hari Shaji",
        "James R. Wootton"
      ],
      "abstract": "Reservoir computing is a form of machine learning particularly suited for\ntime series analysis, including forecasting predictions. We take an\nimplementation of \\emph{quantum} reservoir computing that was initially\ndesigned to generate variants of musical scores and adapt it to create levels\nof Super Mario Bros. Motivated by our analysis of these levels, we develop a\nnew Roblox \\textit{obby} where the courses can be generated in real time on\nsuperconducting qubit hardware, and investigate some of the constraints placed\nby such real-time generation.",
      "tldr_zh": "该论文将 Quantum Reservoir Computing 应用于游戏关卡生成，将其从原本的音乐变体生成扩展到创建 Super Mario Bros 关卡。研究者分析了这些生成的关卡，并开发了一个新的 Roblox obby 游戏，能在超导量子比特硬件上实时生成关卡。最终，他们探讨了实时生成过程的限制，为量子计算在动态内容生成中的应用提供了新见解。",
      "categories": [
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13287v1",
      "published_date": "2025-05-19 16:09:30 UTC",
      "updated_date": "2025-05-19 16:09:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:11:30.466405"
    },
    {
      "arxiv_id": "2505.13280v1",
      "title": "FlowPure: Continuous Normalizing Flows for Adversarial Purification",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Collaert",
        "Abel Rodríguez",
        "Sander Joos",
        "Lieven Desmet",
        "Vera Rimmer"
      ],
      "abstract": "Despite significant advancements in the area, adversarial robustness remains\na critical challenge in systems employing machine learning models. The removal\nof adversarial perturbations at inference time, known as adversarial\npurification, has emerged as a promising defense strategy. To achieve this,\nstate-of-the-art methods leverage diffusion models that inject Gaussian noise\nduring a forward process to dilute adversarial perturbations, followed by a\ndenoising step to restore clean samples before classification. In this work, we\npropose FlowPure, a novel purification method based on Continuous Normalizing\nFlows (CNFs) trained with Conditional Flow Matching (CFM) to learn mappings\nfrom adversarial examples to their clean counterparts. Unlike prior\ndiffusion-based approaches that rely on fixed noise processes, FlowPure can\nleverage specific attack knowledge to improve robustness under known threats,\nwhile also supporting a more general stochastic variant trained on Gaussian\nperturbations for settings where such knowledge is unavailable. Experiments on\nCIFAR-10 and CIFAR-100 demonstrate that our method outperforms state-of-the-art\npurification-based defenses in preprocessor-blind and white-box scenarios, and\ncan do so while fully preserving benign accuracy in the former. Moreover, our\nresults show that not only is FlowPure a highly effective purifier but it also\nholds a strong potential for adversarial detection, identifying\npreprocessor-blind PGD samples with near-perfect accuracy.",
      "tldr_zh": "该论文提出FlowPure，一种基于Continuous Normalizing Flows (CNFs)和Conditional Flow Matching (CFM)的对抗净化方法，用于移除机器学习模型中的对抗扰动，从而提升模型鲁棒性。\nFlowPure通过学习从对抗样本到干净样本的映射，支持利用特定攻击知识优化防御，或采用通用随机变体处理未知威胁。\n实验结果显示，在CIFAR-10和CIFAR-100数据集上，FlowPure在预处理器盲和白盒场景中优于现有防御方法，同时保持良性准确率，并展现出高效的对抗检测能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13280v1",
      "published_date": "2025-05-19 16:04:43 UTC",
      "updated_date": "2025-05-19 16:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:11:43.332029"
    },
    {
      "arxiv_id": "2505.13273v1",
      "title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Berry",
        "Axel Brando",
        "Wei-Di Chang",
        "Juan Camilo Gamboa Higuera",
        "David Meger"
      ],
      "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging\nbecause of their large parameter counts (often exceeding 100 million) and\noperation in complex, high-dimensional spaces with virtually infinite input\npossibilities. In this paper, we propose Epistemic Mixture of Experts (EMoE), a\nnovel framework for efficiently estimating epistemic uncertainty in diffusion\nmodels. EMoE leverages pre-trained networks without requiring additional\ntraining, enabling direct uncertainty estimation from a prompt. We leverage a\nlatent space within the diffusion process that captures epistemic uncertainty\nbetter than existing methods. Experimental results on the COCO dataset\ndemonstrate EMoE's effectiveness, showing a strong correlation between\nuncertainty and image quality. Additionally, EMoE identifies under-sampled\nlanguages and regions with higher uncertainty, revealing hidden biases in the\ntraining set. This capability demonstrates the relevance of EMoE as a tool for\naddressing fairness and accountability in AI-generated content.",
      "tldr_zh": "本文提出 Epistemic Mixture of Experts (EMoE)，一个新框架，用于高效估计文本到图像扩散模型中的 epistemic uncertainty，而无需额外训练，仅利用预训练网络和扩散过程中的 latent space 从提示中直接评估不确定性。EMoE 在 COCO 数据集上的实验结果显示，它与图像质量存在强相关性，能够有效识别训练集中的隐藏偏差，如 undersampled 语言和区域。最终，该框架为解决 AI 生成内容中的公平性和责任性问题提供了重要工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13273v1",
      "published_date": "2025-05-19 15:53:32 UTC",
      "updated_date": "2025-05-19 15:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:11:55.786983"
    },
    {
      "arxiv_id": "2505.13268v1",
      "title": "Representation of perceived prosodic similarity of conversational feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Livia Qian",
        "Carol Figueroa",
        "Gabriel Skantze"
      ],
      "abstract": "Vocal feedback (e.g., `mhm', `yeah', `okay') is an important component of\nspoken dialogue and is crucial to ensuring common ground in conversational\nsystems. The exact meaning of such feedback is conveyed through both lexical\nand prosodic form. In this work, we investigate the perceived prosodic\nsimilarity of vocal feedback with the same lexical form, and to what extent\nexisting speech representations reflect such similarities. A triadic comparison\ntask with recruited participants is used to measure perceived similarity of\nfeedback responses taken from two different datasets. We find that spectral and\nself-supervised speech representations encode prosody better than extracted\npitch features, especially in the case of feedback from the same speaker. We\nalso find that it is possible to further condense and align the representations\nto human perception through contrastive learning.",
      "tldr_zh": "本研究探讨了对话声音反馈（如“mhm”、“yeah”、“okay”）中韵律（prosodic）形式的感知相似性，以及现有语音表示是否能准确反映这种相似性。研究采用三元比较任务（triadic comparison task）来评估来自两个不同数据集的反馈响应，比较了光谱表示（spectral representations）、自监督语音表示（self-supervised speech representations）和提取的音高特征（extracted pitch features）。结果显示，自监督和光谱表示在编码韵律方面优于音高特征，尤其在同一说话者的反馈中；此外，通过对比学习（contrastive learning），可以进一步优化这些表示以更好地匹配人类感知。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13268v1",
      "published_date": "2025-05-19 15:47:51 UTC",
      "updated_date": "2025-05-19 15:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:12:07.445961"
    },
    {
      "arxiv_id": "2505.13264v1",
      "title": "Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty",
      "title_zh": "Net-Zero：不确定性下气候经济PDEs神经网络设计比较研究",
      "authors": [
        "Carlos Rodriguez-Pardo",
        "Louis Daumas",
        "Leonardo Chiani",
        "Massimo Tavoni"
      ],
      "abstract": "Climate-economic modeling under uncertainty presents significant\ncomputational challenges that may limit policymakers' ability to address\nclimate change effectively. This paper explores neural network-based approaches\nfor solving high-dimensional optimal control problems arising from models that\nincorporate ambiguity aversion in climate mitigation decisions. We develop a\ncontinuous-time endogenous-growth economic model that accounts for multiple\nmitigation pathways, including emission-free capital and carbon intensity\nreductions. Given the inherent complexity and high dimensionality of these\nmodels, traditional numerical methods become computationally intractable. We\nbenchmark several neural network architectures against finite-difference\ngenerated solutions, evaluating their ability to capture the dynamic\ninteractions between uncertainty, technology transitions, and optimal climate\npolicy. Our findings demonstrate that appropriate neural architecture selection\nsignificantly impacts both solution accuracy and computational efficiency when\nmodeling climate-economic systems under uncertainty. These methodological\nadvances enable more sophisticated modeling of climate policy decisions,\nallowing for better representation of technology transitions and\nuncertainty-critical elements for developing effective mitigation strategies in\nthe face of climate change.",
      "tldr_zh": "这篇论文探讨了不确定性下气候经济PDEs（偏微分方程）的建模挑战，通过神经网络（neural network）方法解决高维最优控制问题（optimal control problems）。研究者开发了一个连续时间内生增长经济模型，纳入排放自由资本和碳强度减少等多重缓解途径，并将多种神经网络架构与有限差分（finite-difference）方法进行基准测试。结果表明，选择合适的神经网络设计能显著提高解决方案的准确性和计算效率，从而更好地捕捉不确定性、技术转型与最优气候政策间的动态互动，并为制定有效的气候缓解策略提供更先进的建模支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "cs.PF",
        "math.AP",
        "68T07 (Primary) 35Q91, 91B76 (Secondary)",
        "I.2.1; I.5.1; J.4"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.13264v1",
      "published_date": "2025-05-19 15:46:12 UTC",
      "updated_date": "2025-05-19 15:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:12:19.692547"
    },
    {
      "arxiv_id": "2505.13257v1",
      "title": "WikiPersonas: What Can We Learn From Personalized Alignment to Famous People?",
      "title_zh": "翻译失败",
      "authors": [
        "Zilu Tang",
        "Afra Feyza Akyürek",
        "Ekin Akyürek",
        "Derry Wijaya"
      ],
      "abstract": "Preference alignment has become a standard pipeline in finetuning models to\nfollow \\emph{generic} human preferences. Majority of work seeks to optimize\nmodel to produce responses that would be preferable \\emph{on average},\nsimplifying the diverse and often \\emph{contradicting} space of human\npreferences. While research has increasingly focused on personalized alignment:\nadapting models to individual user preferences, there is a lack of personalized\npreference dataset which focus on nuanced individual-level preferences. To\naddress this, we introduce WikiPersona: the first fine-grained personalization\nusing well-documented, famous individuals. Our dataset challenges models to\nalign with these personas through an interpretable process: generating\nverifiable textual descriptions of a persona's background and preferences in\naddition to alignment. We systematically evaluate different personalization\napproaches and find that as few-shot prompting with preferences and fine-tuning\nfail to simultaneously ensure effectiveness and efficiency, using\n\\textit{inferred personal preferences} as prefixes enables effective\npersonalization, especially in topics where preferences clash while leading to\nmore equitable generalization across unseen personas.",
      "tldr_zh": "本文研究 personalized alignment 的问题，指出现有方法多优化模型以符合平均人类偏好，而忽略个性化偏好的多样性和冲突。作者引入 WikiPersona 数据集，这是首个基于著名人物的细粒度个性化数据集，通过生成可验证的文本描述来实现模型与个人偏好的对齐。实验评估显示，few-shot prompting 和 fine-tuning 无法同时兼顾有效性和效率，而使用 inferred personal preferences 作为 prefixes 能更有效地处理偏好冲突，并实现更公平的泛化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.13257v1",
      "published_date": "2025-05-19 15:39:48 UTC",
      "updated_date": "2025-05-19 15:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:12:32.451519"
    },
    {
      "arxiv_id": "2505.13253v1",
      "title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Lennart Röstel",
        "Dominik Winkelbauer",
        "Johannes Pitz",
        "Leon Sievers",
        "Berthold Bäuml"
      ],
      "abstract": "In-hand manipulation and grasping are fundamental yet often separately\naddressed tasks in robotics. For deriving in-hand manipulation policies,\nreinforcement learning has recently shown great success. However, the derived\ncontrollers are not yet useful in real-world scenarios because they often\nrequire a human operator to place the objects in suitable initial (grasping)\nstates. Finding stable grasps that also promote the desired in-hand\nmanipulation goal is an open problem. In this work, we propose a method for\nbridging this gap by leveraging the critic network of a reinforcement learning\nagent trained for in-hand manipulation to score and select initial grasps. Our\nexperiments show that this method significantly increases the success rate of\nin-hand manipulation without requiring additional training. We also present an\nimplementation of a full grasp manipulation pipeline on a real-world system,\nenabling autonomous grasping and reorientation even of unwieldy objects.",
      "tldr_zh": "该论文解决了机器人学中灵巧抓取（Dextrous Grasping）和手内操作（In-hand Manipulation）的结合问题，提出了一种方法，使用强化学习（Reinforcement Learning）的Critic Network来评分和选择初始抓取，从而避免了人类干预。实验结果显示，该方法显著提高了手内操作的成功率，而无需额外训练。作者还实现了在真实系统上的完整抓取操作管道，支持对复杂物体的自主抓取和重新定向。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13253v1",
      "published_date": "2025-05-19 15:36:34 UTC",
      "updated_date": "2025-05-19 15:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:12:44.724406"
    },
    {
      "arxiv_id": "2505.13580v1",
      "title": "OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhao Wang",
        "Guanting Chen",
        "Kalyan Talluri",
        "Xiaocheng Li"
      ],
      "abstract": "We build a Generative Pre-trained Transformer (GPT) model from scratch to\nsolve sequential decision making tasks arising in contexts of operations\nresearch and management science which we call OMGPT. We first propose a general\nsequence modeling framework to cover several operational decision making tasks\nas special cases, such as dynamic pricing, inventory management, resource\nallocation, and queueing control. Under the framework, all these tasks can be\nviewed as a sequential prediction problem where the goal is to predict the\noptimal future action given all the historical information. Then we train a\ntransformer-based neural network model (OMGPT) as a natural and powerful\narchitecture for sequential modeling. This marks a paradigm shift compared to\nthe existing methods for these OR/OM tasks in that (i) the OMGPT model can take\nadvantage of the huge amount of pre-trained data; (ii) when tackling these\nproblems, OMGPT does not assume any analytical model structure and enables a\ndirect and rich mapping from the history to the future actions. Either of these\ntwo aspects, to the best of our knowledge, is not achieved by any existing\nmethod. We establish a Bayesian perspective to theoretically understand the\nworking mechanism of the OMGPT on these tasks, which relates its performance\nwith the pre-training task diversity and the divergence between the testing\ntask and pre-training tasks. Numerically, we observe a surprising performance\nof the proposed model across all the above tasks.",
      "tldr_zh": "该研究提出了一种序列建模框架 OMSGPT，利用从零构建的 Generative Pre-trained Transformer (GPT) 模型，解决运营研究和管理科学中的顺序决策任务，如动态定价、库存管理、资源分配和队列控制。框架将这些任务视为序列预测问题，通过 Transformer 架构直接从历史信息映射到最优未来行动，并利用大量预训练数据，避免了传统方法的分析模型假设。理论上，该模型从贝叶斯视角分析其性能，强调预训练任务多样性和任务差异的影响；实验结果显示，OMSGPT 在所有测试任务上表现出色，实现了显著的范式转变。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2405.14219",
      "pdf_url": "http://arxiv.org/pdf/2505.13580v1",
      "published_date": "2025-05-19 15:33:03 UTC",
      "updated_date": "2025-05-19 15:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:12:57.055968"
    },
    {
      "arxiv_id": "2505.13579v1",
      "title": "Learning Wavelet-Sparse FDK for 3D Cone-Beam CT Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Yipeng Sun",
        "Linda-Sophie Schneider",
        "Chengze Ye",
        "Mingxuan Gu",
        "Siyuan Mei",
        "Siming Bayer",
        "Andreas Maier"
      ],
      "abstract": "Cone-Beam Computed Tomography (CBCT) is essential in medical imaging, and the\nFeldkamp-Davis-Kress (FDK) algorithm is a popular choice for reconstruction due\nto its efficiency. However, FDK is susceptible to noise and artifacts. While\nrecent deep learning methods offer improved image quality, they often increase\ncomputational complexity and lack the interpretability of traditional methods.\nIn this paper, we introduce an enhanced FDK-based neural network that maintains\nthe classical algorithm's interpretability by selectively integrating trainable\nelements into the cosine weighting and filtering stages. Recognizing the\nchallenge of a large parameter space inherent in 3D CBCT data, we leverage\nwavelet transformations to create sparse representations of the cosine weights\nand filters. This strategic sparsification reduces the parameter count by\n$93.75\\%$ without compromising performance, accelerates convergence, and\nimportantly, maintains the inference computational cost equivalent to the\nclassical FDK algorithm. Our method not only ensures volumetric consistency and\nboosts robustness to noise, but is also designed for straightforward\nintegration into existing CT reconstruction pipelines. This presents a\npragmatic enhancement that can benefit clinical applications, particularly in\nenvironments with computational limitations.",
      "tldr_zh": "本研究针对锥束计算机断层扫描(CBCT)重建中的噪声和伪影问题，提出了一种基于小波稀疏化的增强FDK算法。该方法在FDK的余弦加权和过滤阶段选择性地整合可训练元素，并利用小波变换创建稀疏表示，从而将参数数量减少93.75%，同时保持与经典FDK相同的推理计算成本和可解释性。实验结果显示，该算法提升了图像质量、噪声鲁棒性和体积一致性，并易于集成到现有CT重建管道中，对计算资源有限的临床环境具有显著实用价值。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by Fully3D 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13579v1",
      "published_date": "2025-05-19 15:31:40 UTC",
      "updated_date": "2025-05-19 15:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:13:08.202437"
    },
    {
      "arxiv_id": "2505.13246v1",
      "title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems",
      "title_zh": "Agentic Publications：LLM 驱动的交互式科学出版框架，用 AI 驱动的知识系统补充传统论文",
      "authors": [
        "Roberto Pugliese",
        "George Kourousias",
        "Francesco Venier",
        "Grazia Garlatti Costa"
      ],
      "abstract": "The exponential growth of scientific literature presents significant\nchallenges for researchers navigating the complex knowledge landscape. We\npropose \"Agentic Publications\", a novel LLM-driven framework complementing\ntraditional publishing by transforming papers into interactive knowledge\nsystems. Our architecture integrates structured data with unstructured content\nthrough retrieval-augmented generation and multi-agent verification. The\nframework offers interfaces for both humans and machines, combining narrative\nexplanations with machine-readable outputs while addressing ethical\nconsiderations through automated validation and transparent governance. Key\nfeatures include continuous knowledge updates, automatic integration of new\nfindings, and customizable detail levels. Our proof-of-concept demonstrates\nmultilingual interaction, API accessibility, and structured knowledge\nrepresentation through vector databases, knowledge graphs, and verification\nagents. This approach enhances scientific communication across disciplines,\nimproving efficiency and collaboration while preserving traditional publishing\npathways, particularly valuable for interdisciplinary fields where knowledge\nintegration remains challenging.",
      "tldr_zh": "本研究提出“Agentic Publications”，一种基于LLM（Large Language Models）的框架，用于将传统科学论文转化为交互式知识系统，以应对科学文献爆炸式增长的挑战。该框架整合结构化和非结构化数据，通过retrieval-augmented generation和multi-agent verification，提供人类和机器接口，支持持续知识更新、多语言交互以及自动伦理验证。概念验证展示了其在API访问、知识图谱（knowledge graphs）和向量数据库（vector databases）上的结构化表示能力，最终提升了跨学科科学交流的效率和合作潜力，同时保留了传统出版路径。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13246v1",
      "published_date": "2025-05-19 15:28:10 UTC",
      "updated_date": "2025-05-19 15:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:13:19.825094"
    },
    {
      "arxiv_id": "2505.13232v2",
      "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Younghyun Kim",
        "Jongheon Jeong",
        "Sangkyung Kwak",
        "Kyungmin Lee",
        "Juho Lee",
        "Jinwoo Shin"
      ],
      "abstract": "Learning robust representations from data often requires scale, which has led\nto the success of recent zero-shot models such as CLIP. However, the obtained\nrobustness can easily be deteriorated when these models are fine-tuned on other\ndownstream tasks (e.g., of smaller scales). Previous works often interpret this\nphenomenon in the context of domain shift, developing fine-tuning methods that\naim to preserve the original domain as much as possible. However, in a\ndifferent context, fine-tuned models with limited data are also prone to\nlearning features that are spurious to humans, such as background or texture.\nIn this paper, we propose StarFT (Spurious Textual Alignment Regularization), a\nnovel framework for fine-tuning zero-shot models to enhance robustness by\npreventing them from learning spuriosity. We introduce a regularization that\naligns the output distribution for spuriosity-injected labels with the original\nzero-shot model, ensuring that the model is not induced to extract irrelevant\nfeatures further from these descriptions. We leverage recent language models to\nget such spuriosity-injected labels by generating alternative textual\ndescriptions that highlight potentially confounding features. Extensive\nexperiments validate the robust generalization of StarFT and its emerging\nproperties: zero-shot group robustness and improved zero-shot classification.\nNotably, StarFT boosts both worst-group and average accuracy by 14.30% and\n3.02%, respectively, in the Waterbirds group shift scenario, where other robust\nfine-tuning baselines show even degraded performance.",
      "tldr_zh": "这篇论文提出 StarFT（Spurious Textual Alignment Regularization），一种新型框架，用于提升 zero-shot 模型（如 CLIP）在 fine-tuning 时的鲁棒性，通过防止模型学习无关的 spurious features，例如背景或纹理。方法涉及使用语言模型生成带有 spurious features 的标签描述，并通过输出分布对齐正则化，确保 fine-tuned 模型不提取这些无关特征。实验结果显示，StarFT 在 Waterbirds 组移位场景中将 worst-group 准确率提升 14.30%，平均准确率提升 3.02%，并显著改善 zero-shot group robustness 和分类性能。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "IJCAI 2025; Code is available at https://github.com/alinlab/StarFT",
      "pdf_url": "http://arxiv.org/pdf/2505.13232v2",
      "published_date": "2025-05-19 15:15:35 UTC",
      "updated_date": "2025-05-20 12:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:13:32.867211"
    },
    {
      "arxiv_id": "2505.13227v1",
      "title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Tianbao Xie",
        "Jiaqi Deng",
        "Xiaochuan Li",
        "Junlin Yang",
        "Haoyuan Wu",
        "Jixuan Chen",
        "Wenjing Hu",
        "Xinyuan Wang",
        "Yuhui Xu",
        "Zekun Wang",
        "Yiheng Xu",
        "Junli Wang",
        "Doyen Sahoo",
        "Tao Yu",
        "Caiming Xiong"
      ],
      "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language\ninstructions to specific actions on graphical user interfaces, remains a\ncritical bottleneck in computer use agent development. Current benchmarks\noversimplify grounding tasks as short referring expressions, failing to capture\nthe complexity of real-world interactions that require software commonsense,\nlayout understanding, and fine-grained manipulation capabilities. To address\nthese limitations, we introduce OSWorld-G, a comprehensive benchmark comprising\n564 finely annotated samples across diverse task types including text matching,\nelement recognition, layout understanding, and precise manipulation.\nAdditionally, we synthesize and release the largest computer use grounding\ndataset Jedi, which contains 4 million examples through multi-perspective\ndecoupling of tasks. Our multi-scale models trained on Jedi demonstrate its\neffectiveness by outperforming existing approaches on ScreenSpot-v2,\nScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved\ngrounding with Jedi directly enhances agentic capabilities of general\nfoundation models on complex computer tasks, improving from 5% to 27% on\nOSWorld. Through detailed ablation studies, we identify key factors\ncontributing to grounding performance and verify that combining specialized\ndata for different interface elements enables compositional generalization to\nnovel interfaces. All benchmark, data, checkpoints, and code are open-sourced\nand available at https://osworld-grounding.github.io.",
      "tldr_zh": "本文提出了一种通过用户界面分解和合成的方法来扩展 GUI grounding 能力，以解决计算机使用代理在处理真实世界交互时的瓶颈问题。研究引入了 OSWorld-G 基准（包含564个精细标注样本）和Jedi数据集（4百万例子），并通过多视角任务解耦训练多尺度模型，结果显示该模型在ScreenSpot-v2、ScreenSpot-Pro和OSWorld-G上优于现有方法，并将基础模型在复杂任务上的性能从5%提升至27%。此外，通过消融研究，论文验证了结合不同界面元素的专业数据能实现对新接口的组合泛化，并开源了所有资源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "49 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13227v1",
      "published_date": "2025-05-19 15:09:23 UTC",
      "updated_date": "2025-05-19 15:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:13:44.700061"
    },
    {
      "arxiv_id": "2505.13211v1",
      "title": "MAGI-1: Autoregressive Video Generation at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Sand. ai",
        "Hansi Teng",
        "Hongyu Jia",
        "Lei Sun",
        "Lingzhi Li",
        "Maolin Li",
        "Mingqiu Tang",
        "Shuai Han",
        "Tianning Zhang",
        "W. Q. Zhang",
        "Weifeng Luo",
        "Xiaoyang Kang",
        "Yuchen Sun",
        "Yue Cao",
        "Yunpeng Huang",
        "Yutong Lin",
        "Yuxin Fang",
        "Zewei Tao",
        "Zheng Zhang",
        "Zhongshu Wang",
        "Zixun Liu",
        "Dai Shi",
        "Guoli Su",
        "Hanwen Sun",
        "Hong Pan",
        "Jie Wang",
        "Jiexin Sheng",
        "Min Cui",
        "Min Hu",
        "Ming Yan",
        "Shucheng Yin",
        "Siran Zhang",
        "Tingting Liu",
        "Xianping Yin",
        "Xiaoyu Yang",
        "Xin Song",
        "Xuan Hu",
        "Yankai Zhang",
        "Yuqiao Li"
      ],
      "abstract": "We present MAGI-1, a world model that generates videos by autoregressively\npredicting a sequence of video chunks, defined as fixed-length segments of\nconsecutive frames. Trained to denoise per-chunk noise that increases\nmonotonically over time, MAGI-1 enables causal temporal modeling and naturally\nsupports streaming generation. It achieves strong performance on image-to-video\n(I2V) tasks conditioned on text instructions, providing high temporal\nconsistency and scalability, which are made possible by several algorithmic\ninnovations and a dedicated infrastructure stack. MAGI-1 facilitates\ncontrollable generation via chunk-wise prompting and supports real-time,\nmemory-efficient deployment by maintaining constant peak inference cost,\nregardless of video length. The largest variant of MAGI-1 comprises 24 billion\nparameters and supports context lengths of up to 4 million tokens,\ndemonstrating the scalability and robustness of our approach. The code and\nmodels are available at https://github.com/SandAI-org/MAGI-1 and\nhttps://github.com/SandAI-org/MagiAttention. The product can be accessed at\nhttps://sand.ai.",
      "tldr_zh": "本研究介绍了MAGI-1，一种自回归(Autoregressive)视频生成世界模型，通过预测序列化的视频块（固定长度的连续帧）来实现视频生成，并通过单调增加的去噪训练支持因果时间建模和流式生成。MAGI-1在图像到视频(I2V)任务中表现出色，能够基于文本指令提供高时间一致性和可扩展性，同时通过算法创新和专用基础设施实现块级提示的控制生成。实验结果显示，其最大变体拥有240亿参数，支持高达400万标记的上下文长度，并实现实时、内存高效部署，无论视频长度如何，峰值推理成本保持恒定。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13211v1",
      "published_date": "2025-05-19 14:58:50 UTC",
      "updated_date": "2025-05-19 14:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:13:58.686135"
    },
    {
      "arxiv_id": "2505.13210v1",
      "title": "Picturized and Recited with Dialects: A Multimodal Chinese Representation Framework for Sentiment Analysis of Classical Chinese Poetry",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaocong Du",
        "Haoyu Pei",
        "Haipeng Zhang"
      ],
      "abstract": "Classical Chinese poetry is a vital and enduring part of Chinese literature,\nconveying profound emotional resonance. Existing studies analyze sentiment\nbased on textual meanings, overlooking the unique rhythmic and visual features\ninherent in poetry,especially since it is often recited and accompanied by\nChinese paintings. In this work, we propose a dialect-enhanced multimodal\nframework for classical Chinese poetry sentiment analysis. We extract\nsentence-level audio features from the poetry and incorporate audio from\nmultiple dialects,which may retain regional ancient Chinese phonetic features,\nenriching the phonetic representation. Additionally, we generate sentence-level\nvisual features, and the multimodal features are fused with textual features\nenhanced by LLM translation through multimodal contrastive representation\nlearning. Our framework outperforms state-of-the-art methods on two public\ndatasets, achieving at least 2.51% improvement in accuracy and 1.63% in macro\nF1. We open-source the code to facilitate research in this area and provide\ninsights for general multimodal Chinese representation.",
      "tldr_zh": "这篇论文提出了一种基于方言增强的多模态框架，用于古典中文诗歌的情感分析，旨在整合诗歌的文本、音频和视觉特征，以弥补现有方法忽略节奏和视觉元素的不足。框架通过提取句子级音频特征（包括多种方言以保留区域古汉语语音）和视觉特征，并将这些多模态特征与通过LLM翻译增强的文本特征融合，利用多模态对比表示学习进行整合。实验结果显示，该框架在两个公共数据集上优于最先进方法，提升准确率至少2.51%和宏F1分数至少1.63%。论文开源代码，并为多模态中文表示提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13210v1",
      "published_date": "2025-05-19 14:58:44 UTC",
      "updated_date": "2025-05-19 14:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:14:10.921125"
    },
    {
      "arxiv_id": "2505.13577v1",
      "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Kim",
        "Taehan Kim",
        "Wonjune Kang",
        "Eugene Park",
        "Joonsik Yoon",
        "Dongjae Lee",
        "Xin Liu",
        "Daniel McDuff",
        "Hyeonhoon Lee",
        "Cynthia Breazeal",
        "Hae Won Park"
      ],
      "abstract": "Vocal health plays a crucial role in peoples' lives, significantly impacting\ntheir communicative abilities and interactions. However, despite the global\nprevalence of voice disorders, many lack access to convenient diagnosis and\ntreatment. This paper introduces VocalAgent, an audio large language model\n(LLM) to address these challenges through vocal health diagnosis. We leverage\nQwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital\npatients, and present a multifaceted evaluation framework encompassing a safety\nassessment to mitigate diagnostic biases, cross-lingual performance analysis,\nand modality ablation studies. VocalAgent demonstrates superior accuracy on\nvoice disorder classification compared to state-of-the-art baselines. Its\nLLM-based method offers a scalable solution for broader adoption of health\ndiagnostics, while underscoring the importance of ethical and technical\nvalidation.",
      "tldr_zh": "该研究提出VocalAgent，一种基于Large Language Models (LLM)的音频模型，用于声带健康诊断，以解决人们缺乏便捷诊断的全球性问题。该系统通过对Qwen-Audio-Chat模型进行微调，利用从医院患者收集的三个数据集，实现了对声带疾病的准确分类。VocalAgent采用多方面评估框架，包括safety-aware evaluation以缓解诊断偏差、跨语言性能分析和模态消融研究，并在分类准确性上超越现有基线模型，提供了一个可扩展的健康诊断解决方案，同时强调了伦理和技术验证的重要性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13577v1",
      "published_date": "2025-05-19 14:58:42 UTC",
      "updated_date": "2025-05-19 14:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:14:21.489080"
    },
    {
      "arxiv_id": "2505.13208v1",
      "title": "Efficient Generation of Parameterised Quantum Circuits from Large Texts",
      "title_zh": "从大型文本高效生成参数化量子电路",
      "authors": [
        "Colin Krawchuk",
        "Nikhil Khatri",
        "Neil John Ortega",
        "Dimitri Kartsaklis"
      ],
      "abstract": "Quantum approaches to natural language processing (NLP) are redefining how\nlinguistic information is represented and processed. While traditional hybrid\nquantum-classical models rely heavily on classical neural networks, recent\nadvancements propose a novel framework, DisCoCirc, capable of directly encoding\nentire documents as parameterised quantum circuits (PQCs), besides enjoying\nsome additional interpretability and compositionality benefits. Following these\nideas, this paper introduces an efficient methodology for converting\nlarge-scale texts into quantum circuits using tree-like representations of\npregroup diagrams. Exploiting the compositional parallels between language and\nquantum mechanics, grounded in symmetric monoidal categories, our approach\nenables faithful and efficient encoding of syntactic and discourse\nrelationships in long and complex texts (up to 6410 words in our experiments)\nto quantum circuits. The developed system is provided to the community as part\nof the augmented open-source quantum NLP package lambeq Gen II.",
      "tldr_zh": "本论文提出了一种高效方法，用于将大型文本转换为参数化量子电路 (PQCs)，基于 DisCoCirc 框架和树状 pregroup diagrams 的表示。方法利用语言与量子力学的组合性（基于 symmetric monoidal categories），实现了对文本句法和语篇关系的忠实编码，能够处理长达 6410 词的复杂文本。实验验证了该方法的效率，并通过开源包 lambeq Gen II 提供给社区，推动量子自然语言处理 (NLP) 的发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13208v1",
      "published_date": "2025-05-19 14:57:53 UTC",
      "updated_date": "2025-05-19 14:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:14:34.140929"
    },
    {
      "arxiv_id": "2505.13201v1",
      "title": "MatPredict: a dataset and benchmark for learning material properties of diverse indoor objects",
      "title_zh": "MatPredict：用于学习多样室内物体材料属性数据集和基准",
      "authors": [
        "Yuzhen Chen",
        "Hojun Son",
        "Arpan Kusari"
      ],
      "abstract": "Determining material properties from camera images can expand the ability to\nidentify complex objects in indoor environments, which is valuable for consumer\nrobotics applications. To support this, we introduce MatPredict, a dataset that\ncombines the high-quality synthetic objects from Replica dataset with MatSynth\ndataset's material properties classes - to create objects with diverse material\nproperties. We select 3D meshes of specific foreground objects and render them\nwith different material properties. In total, we generate \\textbf{18} commonly\noccurring objects with \\textbf{14} different materials. We showcase how we\nprovide variability in terms of lighting and camera placement for these\nobjects. Next, we provide a benchmark for inferring material properties from\nvisual images using these perturbed models in the scene, discussing the\nspecific neural network models involved and their performance based on\ndifferent image comparison metrics. By accurately simulating light interactions\nwith different materials, we can enhance realism, which is crucial for training\nmodels effectively through large-scale simulations. This research aims to\nrevolutionize perception in consumer robotics. The dataset is provided\n\\href{https://huggingface.co/datasets/UMTRI/MatPredict}{here} and the code is\nprovided \\href{https://github.com/arpan-kusari/MatPredict}{here}.",
      "tldr_zh": "本研究引入了MatPredict数据集和基准，用于从相机图像中学习室内物体的材料属性，从而提升消费机器人对复杂物体的识别能力。MatPredict结合Replica数据集的高质量合成对象和MatSynth数据集的材料属性类别，生成18个常见物体，每个物体配以14种不同材料，并提供光照和相机位置的变异性。研究通过基准测试评估神经网络模型在视觉图像中推断材料属性的性能，使用不同图像比较指标，并证明通过准确模拟光与材料的交互，可以增强模型的真实性和训练效果。该工作旨在革新消费机器人的感知能力，并公开了数据集和代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13201v1",
      "published_date": "2025-05-19 14:54:04 UTC",
      "updated_date": "2025-05-19 14:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:14:45.291040"
    },
    {
      "arxiv_id": "2505.13196v1",
      "title": "A Physics-Inspired Optimizer: Velocity Regularized Adam",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Vaidhyanathan",
        "Lucas Schorling",
        "Natalia Ares",
        "Michael A. Osborne"
      ],
      "abstract": "We introduce Velocity-Regularized Adam (VRAdam), a physics-inspired optimizer\nfor training deep neural networks that draws on ideas from quartic terms for\nkinetic energy with its stabilizing effects on various system dynamics.\nPrevious algorithms, including the ubiquitous Adam, operate at the so called\nadaptive edge of stability regime during training leading to rapid oscillations\nand slowed convergence of loss. However, VRAdam adds a higher order penalty on\nthe learning rate based on the velocity such that the algorithm automatically\nslows down whenever weight updates become large. In practice, we observe that\nthe effective dynamic learning rate shrinks in high-velocity regimes, damping\noscillations and allowing for a more aggressive base step size when necessary\nwithout divergence. By combining this velocity-based regularizer for global\ndamping with per-parameter scaling of Adam to create a hybrid optimizer, we\ndemonstrate that VRAdam consistently exceeds the performance against standard\noptimizers including AdamW. We benchmark various tasks such as image\nclassification, language modeling, image generation and generative modeling\nusing diverse architectures and training methodologies including Convolutional\nNeural Networks (CNNs), Transformers, and GFlowNets.",
      "tldr_zh": "本研究引入了 Velocity-Regularized Adam (VRAdam)，一种受物理启发的优化器，它借鉴 kinetic energy 的四次项效应来稳定深度神经网络的训练过程。VRAdam 通过添加基于速度的学习率惩罚机制，在权重更新变大时自动减速，从而抑制 adaptive edge of stability 导致的快速振荡并提升收敛效率。实验结果显示，VRAdam 在图像分类、语言建模、图像生成和生成建模等任务上，使用 CNNs、Transformers 和 GFlowNets 等架构时，表现优于标准优化器如 AdamW。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "L. Schorling and P. Vaidhyanathan contributed equally to this work.\n  20 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13196v1",
      "published_date": "2025-05-19 14:51:40 UTC",
      "updated_date": "2025-05-19 14:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:14:57.813937"
    },
    {
      "arxiv_id": "2505.13195v1",
      "title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities",
      "title_zh": "LLMs 中的对抗测试：对决策漏洞的洞见",
      "authors": [
        "Lili Zhang",
        "Haomiaomiao Wang",
        "Long Cheng",
        "Libao Deng",
        "Tomas Ward"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world decision-making systems, understanding their behavioural\nvulnerabilities remains a critical challenge for AI safety and alignment. While\nexisting evaluation metrics focus primarily on reasoning accuracy or factual\ncorrectness, they often overlook whether LLMs are robust to adversarial\nmanipulation or capable of using adaptive strategy in dynamic environments.\nThis paper introduces an adversarial evaluation framework designed to\nsystematically stress-test the decision-making processes of LLMs under\ninteractive and adversarial conditions. Drawing on methodologies from cognitive\npsychology and game theory, our framework probes how models respond in two\ncanonical tasks: the two-armed bandit task and the Multi-Round Trust Task.\nThese tasks capture key aspects of exploration-exploitation trade-offs, social\ncooperation, and strategic flexibility. We apply this framework to several\nstate-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3,\nrevealing model-specific susceptibilities to manipulation and rigidity in\nstrategy adaptation. Our findings highlight distinct behavioral patterns across\nmodels and emphasize the importance of adaptability and fairness recognition\nfor trustworthy AI deployment. Rather than offering a performance benchmark,\nthis work proposes a methodology for diagnosing decision-making weaknesses in\nLLM-based agents, providing actionable insights for alignment and safety\nresearch.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在决策系统中的行为脆弱性，引入了一个对抗性评估框架，以系统测试模型在互动和对抗环境下的鲁棒性。框架借鉴认知心理学和博弈论的方法，通过两个经典任务——two-armed bandit task 和 Multi-Round Trust Task——来评估模型在探索-利用权衡、社会合作和策略灵活性方面的表现。实验对 GPT-3.5、GPT-4、Gemini-1.5 和 DeepSeek-V3 等模型进行测试，揭示了模型特有的易受操纵性和策略适应刚性问题。总体而言，该工作强调了适应性和公平性识别对可信 AI 部署的重要性，并为 LLMs 的安全对齐研究提供诊断决策弱点的实用方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13195v1",
      "published_date": "2025-05-19 14:50:44 UTC",
      "updated_date": "2025-05-19 14:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:15:10.480990"
    },
    {
      "arxiv_id": "2505.13192v1",
      "title": "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Jürgen Hemmer",
        "Daniel Durstewitz"
      ],
      "abstract": "Complex, temporally evolving phenomena, from climate to brain activity, are\ngoverned by dynamical systems (DS). DS reconstruction (DSR) seeks to infer\ngenerative surrogate models of these from observed data, reproducing their\nlong-term behavior. Existing DSR approaches require purpose-training for any\nnew system observed, lacking the zero-shot and in-context inference\ncapabilities known from LLMs. Here we introduce DynaMix, a novel multivariate\nALRNN-based mixture-of-experts architecture pre-trained for DSR, the first DSR\nmodel able to generalize zero-shot to out-of-domain DS. Just from a provided\ncontext signal, without any re-training, DynaMix faithfully forecasts the\nlong-term evolution of novel DS where existing time series (TS) foundation\nmodels, like Chronos, fail -- at a fraction of the number of parameters and\norders of magnitude faster inference times. DynaMix outperforms TS foundation\nmodels in terms of long-term statistics, and often also short-term forecasts,\neven on real-world time series, like traffic or weather data, typically used\nfor training and evaluating TS models, but not at all part of DynaMix' training\ncorpus. We illustrate some of the failure modes of TS models for DSR problems,\nand conclude that models built on DS principles may bear a huge potential also\nfor advancing the TS prediction field.",
      "tldr_zh": "该论文提出 DynaMix，一种基于多变量 ALRNN 的混合专家架构，用于动态系统重建(DSR)，首次实现了 zero-shot 推理，能够从观察数据中推断并预测新系统的长期演化，而无需重新训练。相比现有时间序列(TS)基础模型如 Chronos，DynaMix 在参数量更少和推理速度快的情况下，更准确地保持长期统计，并在短期预测上表现优越，即使在未见过的真实世界数据（如交通或天气）上。论文还揭示了 TS 模型在 DSR 问题上的失败模式，并认为基于动态系统(DS)原则的模型有望推进 TS 预测领域的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "nlin.CD"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13192v1",
      "published_date": "2025-05-19 14:49:10 UTC",
      "updated_date": "2025-05-19 14:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:15:23.086055"
    },
    {
      "arxiv_id": "2505.13191v1",
      "title": "Emergence of Fixational and Saccadic Movements in a Multi-Level Recurrent Attention Model for Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Pengcheng Pan",
        "Yonekura Shogo",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "Inspired by foveal vision, hard attention models promise interpretability and\nparameter economy. However, existing models like the Recurrent Model of Visual\nAttention (RAM) and Deep Recurrent Attention Model (DRAM) failed to model the\nhierarchy of human vision system, that compromise on the visual exploration\ndynamics. As a result, they tend to produce attention that are either overly\nfixational or excessively saccadic, diverging from human eye movement behavior.\nIn this paper, we propose a Multi-Level Recurrent Attention Model (MRAM), a\nnovel hard attention framework that explicitly models the neural hierarchy of\nhuman visual processing. By decoupling the function of glimpse location\ngeneration and task execution in two recurrent layers, MRAM emergent a balanced\nbehavior between fixation and saccadic movement. Our results show that MRAM not\nonly achieves more human-like attention dynamics, but also consistently\noutperforms CNN, RAM and DRAM baselines on standard image classification\nbenchmarks.",
      "tldr_zh": "本研究针对现有硬注意力模型（如Recurrent Model of Visual Attention (RAM)和Deep Recurrent Attention Model (DRAM)）未能模拟人类视觉系统的神经层次，导致注意力行为过于fixational或saccadic的问题，提出了一种新型Multi-Level Recurrent Attention Model (MRAM)。MRAM通过在两个recurrent layers中分离视线位置生成和任务执行功能，实现fixational和saccadic movements的平衡动态，更加贴近人类视觉探索过程。实验结果显示，MRAM不仅在图像分类基准上优于CNN、RAM和DRAM基线模型，还展现出更人性化的注意力模式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13191v1",
      "published_date": "2025-05-19 14:48:36 UTC",
      "updated_date": "2025-05-19 14:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:15:33.457474"
    },
    {
      "arxiv_id": "2505.13188v1",
      "title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns",
      "title_zh": "翻译失败",
      "authors": [
        "Juntian Zhu",
        "Miguel de Carvalho",
        "Zhouwang Yang",
        "Fengxiang He"
      ],
      "abstract": "An AI agent might surprisingly find she has reached an unknown state which\nshe has never been aware of -- an unknown unknown. We mathematically ground\nthis scenario in reinforcement learning: an agent, after taking an action\ncalculated from value functions $Q$ and $V$ defined on the {\\it {aware\ndomain}}, reaches a state out of the domain. To enable the agent to handle this\nscenario, we propose an {\\it episodic Markov decision {process} with growing\nawareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion}\n(NIVE) approach to expand value functions to newly aware areas: when an agent\narrives at an unknown unknown, value functions $Q$ and $V$ whereon are\ninitialised by noninformative beliefs -- the averaged values on the aware\ndomain. This design is out of respect for the complete absence of knowledge in\nthe newly discovered state. The upper confidence bound momentum Q-learning is\nthen adapted to the growing awareness for training the EMDP-GA model. We prove\nthat (1) the regret of our approach is asymptotically consistent with the state\nof the art (SOTA) without exposure to unknown unknowns in an extremely\nuncertain environment, and (2) our computational complexity and space\ncomplexity are comparable with the SOTA -- these collectively suggest that\nthough an unknown unknown is surprising, it will be asymptotically properly\ndiscovered with decent speed and an affordable cost.",
      "tldr_zh": "这篇论文探讨了强化学习(Reinforcement Learning)代理遇到未知未知(unknown unknowns)状态的挑战，即代理基于定义在已知域(aware domain)上的价值函数Q和V采取行动，却到达域外状态。作者提出了一种episodic Markov decision process with growing awareness (EMDP-GA)模型，并采用noninformative value expansion (NIVE)方法扩展价值函数：在代理发现新状态时，以已知域的平均值初始化Q和V函数，以尊重对未知状态的完全无知。实验证明，该方法在极端不确定环境中，遗憾(regret)与最先进(SOTA)算法相当，且计算复杂度和空间复杂度类似，从而以高效且低成本的方式处理未知未知。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13188v1",
      "published_date": "2025-05-19 14:45:58 UTC",
      "updated_date": "2025-05-19 14:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:15:47.495029"
    },
    {
      "arxiv_id": "2505.13182v1",
      "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Jianfeng Xu"
      ],
      "abstract": "[Objective] This study focuses on addressing the current lack of a unified\nformal theoretical framework in machine learning, as well as the deficiencies\nin interpretability and ethical safety assurance. [Methods] A formal\ninformation model is first constructed, utilizing sets of well-formed formulas\nto explicitly define the ontological states and carrier mappings of typical\ncomponents in machine learning. Learnable and processable predicates, along\nwith learning and processing functions, are introduced to analyze the logical\ndeduction and constraint rules of the causal chains within models. [Results] A\nmeta-framework for machine learning theory (MLT-MF) is established. Based on\nthis framework, universal definitions for model interpretability and ethical\nsafety are proposed. Furthermore, three key theorems are proved: the\nequivalence of model interpretability and information recoverability, the\nassurance of ethical safety, and the estimation of generalization error.\n[Limitations] The current framework assumes ideal conditions with noiseless\ninformation-enabling mappings and primarily targets model learning and\nprocessing logic in static scenarios. It does not yet address information\nfusion and conflict resolution across ontological spaces in multimodal or\nmulti-agent systems. [Conclusions] This work overcomes the limitations of\nfragmented research and provides a unified theoretical foundation for\nsystematically addressing the critical challenges currently faced in machine\nlearning.",
      "tldr_zh": "本研究针对机器学习缺乏统一理论框架、解释性和伦理安全保障的不足，提出了一种基于正式信息映射的因果链元框架（Causal Chain Meta-Framework）。该框架首先构建正式信息模型，使用well-formed formulas定义机器学习组件的ontological states和carrier mappings，并引入learnable和processable predicates以及learning和processing functions来分析模型中因果链的逻辑演绎和约束规则。研究结果建立了机器学习理论元框架（MLT-MF），并证明了三个关键定理：模型interpretability等价于信息可恢复性、伦理安全保障机制，以及generalization error的估计，为系统解决机器学习挑战提供了统一基础。尽管框架假设无噪声信息映射并限于静态场景，未涵盖多模态系统的信息融合，但它克服了碎片化研究的局限性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13182v1",
      "published_date": "2025-05-19 14:39:41 UTC",
      "updated_date": "2025-05-19 14:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:00.998142"
    },
    {
      "arxiv_id": "2505.13180v1",
      "title": "ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Merler",
        "Nicola Dainese",
        "Minttu Alakuijala",
        "Giovanni Bonetta",
        "Pietro Ferrazzi",
        "Yu Tian",
        "Bernardo Magnini",
        "Pekka Marttinen"
      ],
      "abstract": "Integrating Large Language Models with symbolic planners is a promising\ndirection for obtaining verifiable and grounded plans compared to planning in\nnatural language, with recent works extending this idea to visual domains using\nVision-Language Models (VLMs). However, rigorous comparison between\nVLM-grounded symbolic approaches and methods that plan directly with a VLM has\nbeen hindered by a lack of common environments, evaluation protocols and model\ncoverage. We introduce ViPlan, the first open-source benchmark for Visual\nPlanning with symbolic predicates and VLMs. ViPlan features a series of\nincreasingly challenging tasks in two domains: a visual variant of the classic\nBlocksworld planning problem and a simulated household robotics environment. We\nbenchmark nine open-source VLM families across multiple sizes, along with\nselected closed models, evaluating both VLM-grounded symbolic planning and\nusing the models directly to propose actions. We find symbolic planning to\noutperform direct VLM planning in Blocksworld, where accurate image grounding\nis crucial, whereas the opposite is true in the household robotics tasks, where\ncommonsense knowledge and the ability to recover from errors are beneficial.\nFinally, we show that across most models and methods, there is no significant\nbenefit to using Chain-of-Thought prompting, suggesting that current VLMs still\nstruggle with visual reasoning.",
      "tldr_zh": "这篇论文引入了ViPlan，这是一个开源基准，用于评估视觉规划任务中符号谓词和视觉语言模型(VLMs)的性能。ViPlan包括两个领域的任务：Blocksworld的视觉变体和模拟家庭机器人环境，并通过统一的环境和评估协议比较VLM-grounded符号规划与直接VLM行动提出方法。实验结果显示，在Blocksworld中，符号规划因精确图像grounding而优于直接VLM规划，而在家庭机器人任务中，直接VLM规划更具优势，依赖于常识知识和错误恢复能力。最后，研究发现Chain-of-Thought提示对大多数模型没有显著益处，表明当前VLMs在视觉推理方面仍面临挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures and 1 table in the main text; 43 pages, 9 figures\n  and 16 tables including supplementary material",
      "pdf_url": "http://arxiv.org/pdf/2505.13180v1",
      "published_date": "2025-05-19 14:38:15 UTC",
      "updated_date": "2025-05-19 14:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:12.726056"
    },
    {
      "arxiv_id": "2505.13176v2",
      "title": "ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models",
      "title_zh": "ToolSpectrum：朝向大型语言模型的个性化工具利用",
      "authors": [
        "Zihao Cheng",
        "Hongru Wang",
        "Zeming Liu",
        "Yuhang Guo",
        "Yuanfang Guo",
        "Yunhong Wang",
        "Haifeng Wang"
      ],
      "abstract": "While integrating external tools into large language models (LLMs) enhances\ntheir ability to access real-time information and domain-specific services,\nexisting approaches focus narrowly on functional tool selection following user\ninstructions, overlooking the context-aware personalization in tool selection.\nThis oversight leads to suboptimal user satisfaction and inefficient tool\nutilization, particularly when overlapping toolsets require nuanced selection\nbased on contextual factors. To bridge this gap, we introduce ToolSpectrum, a\nbenchmark designed to evaluate LLMs' capabilities in personalized tool\nutilization. Specifically, we formalize two key dimensions of personalization,\nuser profile and environmental factors, and analyze their individual and\nsynergistic impacts on tool utilization. Through extensive experiments on\nToolSpectrum, we demonstrate that personalized tool utilization significantly\nimproves user experience across diverse scenarios. However, even\nstate-of-the-art LLMs exhibit the limited ability to reason jointly about user\nprofiles and environmental factors, often prioritizing one dimension at the\nexpense of the other. Our findings underscore the necessity of context-aware\npersonalization in tool-augmented LLMs and reveal critical limitations for\ncurrent models. Our data and code are available at\nhttps://github.com/Chengziha0/ToolSpectrum.",
      "tldr_zh": "该研究指出，现有的工具整合方法在大型语言模型 (LLMs) 中仅关注功能性工具选择，而忽略了基于上下文的个性化，导致用户满意度和工具利用效率低下。为解决此问题，论文引入了 ToolSpectrum 基准，用于评估 LLMs 在个性化工具利用方面的能力，并形式化了用户 profile 和 environmental factors 的两个关键维度及其协同影响。通过实验，ToolSpectrum 证明个性化工具利用能显著提升用户体验，但当前最先进的 LLMs 在联合推理这些因素时能力有限，常优先考虑一个维度而忽略另一个，这突显了工具增强 LLMs 中上下文感知个性化设计的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.13176v2",
      "published_date": "2025-05-19 14:30:46 UTC",
      "updated_date": "2025-05-22 14:08:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:25.232639"
    },
    {
      "arxiv_id": "2505.13175v1",
      "title": "Enhancing LLMs for Time Series Forecasting via Structure-Guided Cross-Modal Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Siming Sun",
        "Kai Zhang",
        "Xuejun Jiang",
        "Wenchao Meng",
        "Qinmin Yang"
      ],
      "abstract": "The emerging paradigm of leveraging pretrained large language models (LLMs)\nfor time series forecasting has predominantly employed linguistic-temporal\nmodality alignment strategies through token-level or layer-wise feature\nmapping. However, these approaches fundamentally neglect a critical insight:\nthe core competency of LLMs resides not merely in processing localized token\nfeatures but in their inherent capacity to model holistic sequence structures.\nThis paper posits that effective cross-modal alignment necessitates structural\nconsistency at the sequence level. We propose the Structure-Guided Cross-Modal\nAlignment (SGCMA), a framework that fully exploits and aligns the\nstate-transition graph structures shared by time-series and linguistic data as\nsequential modalities, thereby endowing time series with language-like\nproperties and delivering stronger generalization after modality alignment.\nSGCMA consists of two key components, namely Structure Alignment and Semantic\nAlignment. In Structure Alignment, a state transition matrix is learned from\ntext data through Hidden Markov Models (HMMs), and a shallow transformer-based\nMaximum Entropy Markov Model (MEMM) receives the hot-start transition matrix\nand annotates each temporal patch into state probability, ensuring that the\ntemporal representation sequence inherits language-like sequential dynamics. In\nSemantic Alignment, cross-attention is applied between temporal patches and the\ntop-k tokens within each state, and the ultimate temporal embeddings are\nderived by the expected value of these embeddings using a weighted average\nbased on state probabilities. Experiments on multiple benchmarks demonstrate\nthat SGCMA achieves state-of-the-art performance, offering a novel approach to\ncross-modal alignment in time series forecasting.",
      "tldr_zh": "本论文提出Structure-Guided Cross-Modal Alignment (SGCMA)框架，以提升大型语言模型(LLMs)在时间序列预测中的性能，通过在序列级别上对时间序列和语言数据进行结构对齐，解决传统方法忽略整体序列结构的问题。SGCMA包括两个核心组件：Structure Alignment，使用Hidden Markov Models (HMMs)从文本数据学习状态转移矩阵，并通过Maximum Entropy Markov Model (MEMM)标注时间序列的每个patch，以赋予其语言般的顺序动态；以及Semantic Alignment，通过cross-attention在时间序列patch和状态内的top-k tokens之间进行交互，并使用加权平均获取最终嵌入。实验结果显示，SGCMA在多个基准上实现最先进性能，提供更强的泛化能力和跨模态对齐新方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13175v1",
      "published_date": "2025-05-19 14:30:41 UTC",
      "updated_date": "2025-05-19 14:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:35.904021"
    },
    {
      "arxiv_id": "2505.13157v1",
      "title": "Role-Playing Evaluation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yassine El Boudouri",
        "Walter Nuninger",
        "Julian Alvarez",
        "Yvan Peter"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate a notable capacity for adopting\npersonas and engaging in role-playing. However, evaluating this ability\npresents significant challenges, as human assessments are resource-intensive\nand automated evaluations can be biased. To address this, we introduce\nRole-Playing Eval (RPEval), a novel benchmark designed to assess LLM\nrole-playing capabilities across four key dimensions: emotional understanding,\ndecision-making, moral alignment, and in-character consistency. This article\ndetails the construction of RPEval and presents baseline evaluations. Our code\nand dataset are available at https://github.com/yelboudouri/RPEval",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在角色扮演方面的能力，但评估这一能力面临人工评估资源消耗大和自动化评估偏差等问题。为此，作者引入了 Role-Playing Eval (RPEval) 基准，用于评估 LLMs 在四个关键维度上的表现：emotional understanding、decision-making、moral alignment 和 in-character consistency。论文详细描述了 RPEval 的构建过程、基线评估结果，并提供了开源代码和数据集（https://github.com/yelboudouri/RPEval），为未来 LLM 角色扮演能力的标准化评估奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13157v1",
      "published_date": "2025-05-19 14:18:16 UTC",
      "updated_date": "2025-05-19 14:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:48.760945"
    },
    {
      "arxiv_id": "2505.13156v1",
      "title": "Tianyi: A Traditional Chinese Medicine all-rounder language model and its Real-World Clinical Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Liu",
        "Tao Yang",
        "Jing Wang",
        "Yexin Chen",
        "Zhan Gao",
        "Jiaxi Yang",
        "Kui Chen",
        "Bingji Lu",
        "Xiaochen Li",
        "Changyong Luo",
        "Yan Li",
        "Xiaohong Gu",
        "Peng Cao"
      ],
      "abstract": "Natural medicines, particularly Traditional Chinese Medicine (TCM), are\ngaining global recognition for their therapeutic potential in addressing human\nsymptoms and diseases. TCM, with its systematic theories and extensive\npractical experience, provides abundant resources for healthcare. However, the\neffective application of TCM requires precise syndrome diagnosis, determination\nof treatment principles, and prescription formulation, which demand decades of\nclinical expertise. Despite advancements in TCM-based decision systems, machine\nlearning, and deep learning research, limitations in data and single-objective\nconstraints hinder their practical application. In recent years, large language\nmodels (LLMs) have demonstrated potential in complex tasks, but lack\nspecialization in TCM and face significant challenges, such as too big model\nscale to deploy and issues with hallucination. To address these challenges, we\nintroduce Tianyi with 7.6-billion-parameter LLM, a model scale proper and\nspecifically designed for TCM, pre-trained and fine-tuned on diverse TCM\ncorpora, including classical texts, expert treatises, clinical records, and\nknowledge graphs. Tianyi is designed to assimilate interconnected and\nsystematic TCM knowledge through a progressive learning manner. Additionally,\nwe establish TCMEval, a comprehensive evaluation benchmark, to assess LLMs in\nTCM examinations, clinical tasks, domain-specific question-answering, and\nreal-world trials. The extensive evaluations demonstrate the significant\npotential of Tianyi as an AI assistant in TCM clinical practice and research,\nbridging the gap between TCM knowledge and practical application.",
      "tldr_zh": "该研究介绍了Tianyi，一种专为Traditional Chinese Medicine (TCM)设计的7.6亿参数Large Language Models (LLMs)，旨在解决TCM临床应用中的精确诊断和处方问题，通过预训练和微调多样TCM语料库（如经典文本、专家论著和知识图谱）实现渐进式知识整合。Tianyi克服了现有LLMs的模型规模过大和幻觉等问题，使其更适合实际部署。研究还建立了TCMEval基准，对Tianyi在TCM考试、临床任务、领域问答和真实试验中的表现进行全面评估，结果显示Tianyi作为AI助手在TCM临床实践和研究中具有显著潜力，桥接了TCM知识与实际应用的鸿沟。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 4 figures, and 1 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13156v1",
      "published_date": "2025-05-19 14:17:37 UTC",
      "updated_date": "2025-05-19 14:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:16:59.765299"
    },
    {
      "arxiv_id": "2505.13144v1",
      "title": "Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongsu Lee",
        "Minhae Kwon"
      ],
      "abstract": "The goal of offline reinforcement learning (RL) is to extract a\nhigh-performance policy from the fixed datasets, minimizing performance\ndegradation due to out-of-distribution (OOD) samples. Offline model-based RL\n(MBRL) is a promising approach that ameliorates OOD issues by enriching\nstate-action transitions with augmentations synthesized via a learned dynamics\nmodel. Unfortunately, seminal offline MBRL methods often struggle in\nsparse-reward, long-horizon tasks. In this work, we introduce a novel MBRL\nframework, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA),\nthat generates augmented transitions in a temporally structured latent space\nrather than in raw state space. To model long-horizon behavior, TempDATA learns\na latent abstraction that captures a temporal distance from both trajectory and\ntransition levels of state space. Our experiments confirm that TempDATA\noutperforms previous offline MBRL methods and achieves matching or surpassing\nthe performance of diffusion-based trajectory augmentation and goal-conditioned\nRL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.",
      "tldr_zh": "这篇论文针对离线强化学习(Offline RL)中的分布外(Out-of-Distribution, OOD)样本问题，提出了一种新型模型-based RL方法TempDATA，以改善稀疏奖励和长时序任务的性能。TempDATA框架通过在时间结构化的潜在空间中生成增强转移，并学习捕捉轨迹和转移的temporal distance，来丰富状态-动作转移数据。实验结果显示，TempDATA在D4RL AntMaze、FrankaKitchen、CALVIN和基于像素的FrankaKitchen基准上，优于现有离线MBRL方法，并达到或超过了扩散-based轨迹增强和目标条件RL的性能水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "2025 ICML",
      "pdf_url": "http://arxiv.org/pdf/2505.13144v1",
      "published_date": "2025-05-19 14:11:14 UTC",
      "updated_date": "2025-05-19 14:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:17:12.288394"
    },
    {
      "arxiv_id": "2505.13136v1",
      "title": "ModernGBERT: German-only 1B Encoder Model Trained from Scratch",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Ehrmanntraut",
        "Julia Wunderle",
        "Jan Pfister",
        "Fotis Jannidis",
        "Andreas Hotho"
      ],
      "abstract": "Despite the prominence of decoder-only language models, encoders remain\ncrucial for resource-constrained applications. We introduce ModernGBERT (134M,\n1B), a fully transparent family of German encoder models trained from scratch,\nincorporating architectural innovations from ModernBERT. To evaluate the\npractical trade-offs of training encoders from scratch, we also present\nLL\\\"aMmlein2Vec (120M, 1B, 7B), a family of encoders derived from German\ndecoder-only models via LLM2Vec. We benchmark all models on natural language\nunderstanding, text embedding, and long-context reasoning tasks, enabling a\ncontrolled comparison between dedicated encoders and converted decoders. Our\nresults show that ModernGBERT 1B outperforms prior state-of-the-art German\nencoders as well as encoders adapted via LLM2Vec, with regard to performance\nand parameter-efficiency. All models, training data, checkpoints and code are\npublicly available, advancing the German NLP ecosystem with transparent,\nhigh-performance encoder models.",
      "tldr_zh": "本研究引入了 ModernGBERT，这是一个从零开始训练的德语专用编码器模型家族（包括 134M 和 1B 参数版本），采用了 ModernBERT 的架构创新，以解决资源受限应用的实际需求。同时，他们提出了 LLäMmlein2Vec，这是一个从德语解码器模型转换而来的编码器家族（120M、1B 和 7B 参数），并通过在自然语言理解、文本嵌入和长上下文推理任务上的基准测试进行比较。结果显示，ModernGBERT 1B 在性能和参数效率上超过了现有德语编码器和通过 LLM2Vec 转换的模型，所有模型、训练数据、检查点及代码均公开，以推动德语 NLP 生态系统的透明发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "under review @ARR",
      "pdf_url": "http://arxiv.org/pdf/2505.13136v1",
      "published_date": "2025-05-19 14:07:20 UTC",
      "updated_date": "2025-05-19 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:17:26.590192"
    },
    {
      "arxiv_id": "2505.14719v1",
      "title": "MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion",
      "title_zh": "MSVIT：使用多尺度注意力融合改进",
      "authors": [
        "Wei Hua",
        "Chenlin Zhou",
        "Jibin Wu",
        "Yansong Chua",
        "Yangyang Shu"
      ],
      "abstract": "The combination of Spiking Neural Networks(SNNs) with Vision Transformer\narchitectures has attracted significant attention due to the great potential\nfor energy-efficient and high-performance computing paradigms. However, a\nsubstantial performance gap still exists between SNN-based and ANN-based\ntransformer architectures. While existing methods propose spiking\nself-attention mechanisms that are successfully combined with SNNs, the overall\narchitectures proposed by these methods suffer from a bottleneck in effectively\nextracting features from different image scales. In this paper, we address this\nissue and propose MSVIT, a novel spike-driven Transformer architecture, which\nfirstly uses multi-scale spiking attention (MSSA) to enrich the capability of\nspiking attention blocks. We validate our approach across various main data\nsets. The experimental results show that MSVIT outperforms existing SNN-based\nmodels, positioning itself as a state-of-the-art solution among SNN-transformer\narchitectures. The codes are available at\nhttps://github.com/Nanhu-AI-Lab/MSViT.",
      "tldr_zh": "该研究针对 Spiking Neural Networks (SNNs) 与 Vision Transformer 结合的性能差距，提出 MSVIT 架构，以解决现有模型在提取不同图像尺度特征时的瓶颈问题。MSVIT 首次引入多尺度 spiking attention (MSSA) 机制，增强 spiking attention blocks 的能力，从而实现更有效的特征提取和处理。在主要数据集上的实验验证显示，MSVIT 超过了现有 SNN-based 模型，成为 SNN-transformer 架构中的最先进解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14719v1",
      "published_date": "2025-05-19 14:01:03 UTC",
      "updated_date": "2025-05-19 14:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:17:36.306187"
    },
    {
      "arxiv_id": "2505.13130v1",
      "title": "Adaptive Image Restoration for Video Surveillance: A Real-Time Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Awais Amin",
        "Adama Ilboudo",
        "Abdul Samad bin Shahid",
        "Amjad Ali",
        "Waqas Haider Khan Bangyal"
      ],
      "abstract": "One of the major challenges in the field of computer vision especially for\ndetection, segmentation, recognition, monitoring, and automated solutions, is\nthe quality of images. Image degradation, often caused by factors such as rain,\nfog, lighting, etc., has a negative impact on automated\ndecision-making.Furthermore, several image restoration solutions exist,\nincluding restoration models for single degradation and restoration models for\nmultiple degradations. However, these solutions are not suitable for real-time\nprocessing. In this study, the aim was to develop a real-time image restoration\nsolution for video surveillance. To achieve this, using transfer learning with\nResNet_50, we developed a model for automatically identifying the types of\ndegradation present in an image to reference the necessary treatment(s) for\nimage restoration. Our solution has the advantage of being flexible and\nscalable.",
      "tldr_zh": "本论文针对视频监控中图像退化（如雨雾或照明问题）对计算机视觉任务（如检测和识别）的影响，提出了一种实时图像恢复方法。研究团队使用迁移学习和ResNet_50模型自动识别图像中的退化类型，并据此应用相应的处理来恢复图像。该方法的优势在于其灵活性和可扩展性，适用于实时处理的场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13130v1",
      "published_date": "2025-05-19 14:00:10 UTC",
      "updated_date": "2025-05-19 14:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:17:47.545389"
    },
    {
      "arxiv_id": "2505.13126v2",
      "title": "Zero-Shot Iterative Formalization and Planning in Partially Observable Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Liancheng Gong",
        "Wang Zhu",
        "Jesse Thomason",
        "Li Zhang"
      ],
      "abstract": "Using LLMs not to predict plans but to formalize an environment into the\nPlanning Domain Definition Language (PDDL) has been shown to improve\nperformance and control. Existing work focuses on fully observable\nenvironments; we tackle the more realistic and challenging partially observable\nenvironments that lack of complete, reliable information. We propose PDDLego+,\na framework to iteratively formalize, plan, grow, and refine PDDL\nrepresentations in a zero-shot manner, without needing access to any existing\ntrajectories. On two textual simulated environments, we show that PDDLego+\nimproves goal reaching success and exhibits robustness against problem\ncomplexity. We also show that the domain knowledge captured after a successful\ntrial can benefit future tasks.",
      "tldr_zh": "该研究提出 PDDLego+ 框架，利用 LLMs 在部分可观察环境（Partially Observable Environments）中进行零-shot 迭代形式化和规划，无需现有轨迹即可动态形式化为 PDDL（Planning Domain Definition Language）。框架通过迭代形式化、规划、扩展和精炼过程来处理信息不完全的环境，提升任务适应性。在两个文本模拟环境中，PDDLego+ 显著提高了目标达到成功率，并展示了针对问题复杂度的鲁棒性，同时捕获的领域知识可惠及后续任务。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13126v2",
      "published_date": "2025-05-19 13:58:15 UTC",
      "updated_date": "2025-05-20 13:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:18:00.562010"
    },
    {
      "arxiv_id": "2505.13124v1",
      "title": "$μ$PC: Scaling Predictive Coding to 100+ Layer Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Innocenti",
        "El Mehdi Achour",
        "Christopher L. Buckley"
      ],
      "abstract": "The biological implausibility of backpropagation (BP) has motivated many\nalternative, brain-inspired algorithms that attempt to rely only on local\ninformation, such as predictive coding (PC) and equilibrium propagation.\nHowever, these algorithms have notoriously struggled to train very deep\nnetworks, preventing them from competing with BP in large-scale settings.\nIndeed, scaling PC networks (PCNs) has recently been posed as a challenge for\nthe community (Pinchetti et al., 2024). Here, we show that 100+ layer PCNs can\nbe trained reliably using a Depth-$\\mu$P parameterisation (Yang et al., 2023;\nBordelon et al., 2023) which we call \"$\\mu$PC\". Through an extensive analysis\nof the scaling behaviour of PCNs, we reveal several pathologies that make\nstandard PCNs difficult to train at large depths. We then show that, despite\naddressing only some of these instabilities, $\\mu$PC allows stable training of\nvery deep (up to 128-layer) residual networks on simple classification tasks\nwith competitive performance and little tuning compared to current benchmarks.\nMoreover, $\\mu$PC enables zero-shot transfer of both weight and activity\nlearning rates across widths and depths. Our results have implications for\nother local algorithms and could be extended to convolutional and transformer\narchitectures. Code for $\\mu$PC is made available as part of a JAX library for\nPCNs at https://github.com/thebuckleylab/jpc (Innocenti et al., 2024).",
      "tldr_zh": "该论文提出μPC方法，通过Depth-μP参数化来扩展Predictive Coding (PC)网络（PCNs），成功训练100+层深度网络，解决了传统PC算法在深层网络训练中的不稳定性问题。研究通过分析PCNs的缩放行为，揭示了其潜在病理，并证明μPC能在简单分类任务上稳定训练高达128层的残差网络，与基准模型性能竞争，且支持宽度和深度的零样本转移（zero-shot transfer）。这些结果为脑启发本地算法的发展提供了新见解，并可扩展至卷积和transformer架构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 41 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13124v1",
      "published_date": "2025-05-19 13:54:29 UTC",
      "updated_date": "2025-05-19 13:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:18:12.954510"
    },
    {
      "arxiv_id": "2505.13573v1",
      "title": "FreeMesh: Boosting Mesh Generation with Coordinates Merging",
      "title_zh": "FreeMesh：通过坐标合并提升网格生成",
      "authors": [
        "Jian Liu",
        "Haohan Weng",
        "Biwen Lei",
        "Xianghui Yang",
        "Zibo Zhao",
        "Zhuo Chen",
        "Song Guo",
        "Tao Han",
        "Chunchao Guo"
      ],
      "abstract": "The next-coordinate prediction paradigm has emerged as the de facto standard\nin current auto-regressive mesh generation methods. Despite their\neffectiveness, there is no efficient measurement for the various tokenizers\nthat serialize meshes into sequences. In this paper, we introduce a new metric\nPer-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers\ntheoretically without any training. Building upon PTME, we propose a\nplug-and-play tokenization technique called coordinate merging. It further\nimproves the compression ratios of existing tokenizers by rearranging and\nmerging the most frequent patterns of coordinates. Through experiments on\nvarious tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we\nfurther validate the performance of our method. We hope that the proposed PTME\nand coordinate merging can enhance the existing mesh tokenizers and guide the\nfurther development of native mesh generation.",
      "tldr_zh": "本文提出 FreeMesh 方法，通过引入 Per-Token-Mesh-Entropy (PTME) 指标来理论评估网格标记器，而无需训练，从而解决当前自回归网格生成中序列化效率问题。基于 PTME，该方法开发了坐标 merging 技术，用于重新排列和合并坐标的频繁模式，以提高现有标记器的压缩比。实验在 MeshXL、MeshAnything V2 和 Edgerunner 等方法上验证了其性能提升，并有望增强网格标记器并指导原生网格生成的发展。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted by ICML 2025, camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2505.13573v1",
      "published_date": "2025-05-19 13:52:57 UTC",
      "updated_date": "2025-05-19 13:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:18:23.396488"
    },
    {
      "arxiv_id": "2505.13123v1",
      "title": "Just Dance with $π$! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Snehashis Majhi",
        "Giacomo D'Amicantonio",
        "Antitza Dantcheva",
        "Quan Kong",
        "Lorenzo Garattoni",
        "Gianpiero Francesca",
        "Egor Bondarev",
        "Francois Bremond"
      ],
      "abstract": "Weakly-supervised methods for video anomaly detection (VAD) are\nconventionally based merely on RGB spatio-temporal features, which continues to\nlimit their reliability in real-world scenarios. This is due to the fact that\nRGB-features are not sufficiently distinctive in setting apart categories such\nas shoplifting from visually similar events. Therefore, towards robust complex\nreal-world VAD, it is essential to augment RGB spatio-temporal features by\nadditional modalities. Motivated by this, we introduce the Poly-modal Induced\nframework for VAD: \"PI-VAD\", a novel approach that augments RGB representations\nby five additional modalities. Specifically, the modalities include sensitivity\nto fine-grained motion (Pose), three dimensional scene and entity\nrepresentation (Depth), surrounding objects (Panoptic masks), global motion\n(optical flow), as well as language cues (VLM). Each modality represents an\naxis of a polygon, streamlined to add salient cues to RGB. PI-VAD includes two\nplug-in modules, namely Pseudo-modality Generation module and Cross Modal\nInduction module, which generate modality-specific prototypical representation\nand, thereby, induce multi-modal information into RGB cues. These modules\noperate by performing anomaly-aware auxiliary tasks and necessitate five\nmodality backbones -- only during training. Notably, PI-VAD achieves\nstate-of-the-art accuracy on three prominent VAD datasets encompassing\nreal-world scenarios, without requiring the computational overhead of five\nmodality backbones at inference.",
      "tldr_zh": "本研究针对弱监督视频异常检测（Weakly-supervised Video Anomaly Detection）的局限性，提出PI-VAD框架，通过整合RGB特征与五种额外模态（Pose、Depth、Panoptic masks、Optical flow和VLM）来提升对复杂真实场景的鲁棒性。该框架包括Pseudo-modality Generation模块和Cross Modal Induction模块，这些模块在训练时生成模态特定原型表示，并将多模态信息诱导到RGB线索中，而在推理时无需额外模态骨干网。实验结果显示，PI-VAD在三个主要VAD数据集上实现了最先进准确率，显著改善了事件区分能力，如将偷窃与相似事件区分开来。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13123v1",
      "published_date": "2025-05-19 13:51:57 UTC",
      "updated_date": "2025-05-19 13:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:18:37.585472"
    },
    {
      "arxiv_id": "2505.13122v1",
      "title": "When majority rules, minority loses: bias amplification of gradient descent",
      "title_zh": "翻译失败",
      "authors": [
        "François Bachoc",
        "Jérôme Bolte",
        "Ryan Boustany",
        "Jean-Michel Loubes"
      ],
      "abstract": "Despite growing empirical evidence of bias amplification in machine learning,\nits theoretical foundations remain poorly understood. We develop a formal\nframework for majority-minority learning tasks, showing how standard training\ncan favor majority groups and produce stereotypical predictors that neglect\nminority-specific features. Assuming population and variance imbalance, our\nanalysis reveals three key findings: (i) the close proximity between\n``full-data'' and stereotypical predictors, (ii) the dominance of a region\nwhere training the entire model tends to merely learn the majority traits, and\n(iii) a lower bound on the additional training required. Our results are\nillustrated through experiments in deep learning for tabular and image\nclassification tasks.",
      "tldr_zh": "本文研究了机器学习中梯度下降（gradient descent）导致的偏见放大（bias amplification）问题，开发了一个正式框架来分析多数-少数学习任务（majority-minority learning tasks），揭示标准训练如何偏向多数群体并产生忽略少数特定特征的刻板印象预测器。在假设人口和方差不平衡的情况下，分析得出三个关键发现：（i）全数据预测器与刻板印象预测器之间的密切关系，（ii）一个主导区域，其中训练模型主要学习多数特征，以及（iii）额外训练所需的最低界限。通过深度学习实验在表格和图像分类任务中验证了这些结果，为理解和缓解偏见提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13122v1",
      "published_date": "2025-05-19 13:51:49 UTC",
      "updated_date": "2025-05-19 13:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:18:49.563848"
    },
    {
      "arxiv_id": "2505.13118v1",
      "title": "Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals",
      "title_zh": "揭示不确定性的来源：特征对 Conformal Prediction Intervals 的贡献",
      "authors": [
        "Marouane Il Idrissi",
        "Agathe Fernandes Machado",
        "Ewen Gallic",
        "Arthur Charpentier"
      ],
      "abstract": "Cooperative game theory methods, notably Shapley values, have significantly\nenhanced machine learning (ML) interpretability. However, existing explainable\nAI (XAI) frameworks mainly attribute average model predictions, overlooking\npredictive uncertainty. This work addresses that gap by proposing a novel,\nmodel-agnostic uncertainty attribution (UA) method grounded in conformal\nprediction (CP). By defining cooperative games where CP interval\nproperties-such as width and bounds-serve as value functions, we systematically\nattribute predictive uncertainty to input features. Extending beyond the\ntraditional Shapley values, we use the richer class of Harsanyi allocations,\nand in particular the proportional Shapley values, which distribute attribution\nproportionally to feature importance. We propose a Monte Carlo approximation\nmethod with robust statistical guarantees to address computational feasibility,\nsignificantly improving runtime efficiency. Our comprehensive experiments on\nsynthetic benchmarks and real-world datasets demonstrate the practical utility\nand interpretative depth of our approach. By combining cooperative game theory\nand conformal prediction, we offer a rigorous, flexible toolkit for\nunderstanding and communicating predictive uncertainty in high-stakes ML\napplications.",
      "tldr_zh": "本文提出了一种新型、模型无关的不确定性归因（UA）方法，旨在解决现有可解释AI（XAI）框架忽略预测不确定性的问题，通过将cooperative game theory与conformal prediction (CP)相结合。方法定义合作博弈，其中CP的间隔属性（如宽度和边界）作为价值函数，并使用Harsanyi allocations，特别是proportional Shapley values，根据特征重要性比例分配不确定性归因，以提升解释深度。作者引入Monte Carlo近似方法，提高计算效率并提供鲁棒统计保证；在合成基准和真实数据集上的实验验证了该方法的实用性和有效性，最终为高风险机器学习应用提供了一个灵活工具包，用于理解和沟通预测不确定性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13118v1",
      "published_date": "2025-05-19 13:49:05 UTC",
      "updated_date": "2025-05-19 13:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:19:01.122320"
    },
    {
      "arxiv_id": "2505.13116v1",
      "title": "Continuous Fair SMOTE -- Fairness-Aware Stream Learning from Imbalanced Data",
      "title_zh": "翻译失败",
      "authors": [
        "Kathrin Lammers",
        "Valerie Vaquet",
        "Barbara Hammer"
      ],
      "abstract": "As machine learning is increasingly applied in an online fashion to deal with\nevolving data streams, the fairness of these algorithms is a matter of growing\nethical and legal concern. In many use cases, class imbalance in the data also\nneeds to be dealt with to ensure predictive performance. Current fairness-aware\nstream learners typically attempt to solve these issues through in- or\npost-processing by focusing on optimizing one specific discrimination metric,\naddressing class imbalance in a separate processing step. While C-SMOTE is a\nhighly effective model-agnostic pre-processing approach to mitigate class\nimbalance, as a side effect of this method, algorithmic bias is often\nintroduced.\n  Therefore, we propose CFSMOTE - a fairness-aware, continuous SMOTE variant -\nas a pre-processing approach to simultaneously address the class imbalance and\nfairness concerns by employing situation testing and balancing\nfairness-relevant groups during oversampling. Unlike other fairness-aware\nstream learners, CFSMOTE is not optimizing for only one specific fairness\nmetric, therefore avoiding potentially problematic trade-offs. Our experiments\nshow significant improvement on several common group fairness metrics in\ncomparison to vanilla C-SMOTE while maintaining competitive performance, also\nin comparison to other fairness-aware algorithms.",
      "tldr_zh": "该论文针对数据流中的类别不平衡和公平性问题，提出CFSMOTE，一种公平感知的连续SMOTE变体，作为预处理方法。CFSMOTE通过情境测试和平衡公平相关组在过采样过程中，同时处理类别不平衡和算法偏差，避免了针对单一公平指标的优化可能带来的权衡。实验结果显示，与C-SMOTE相比，CFSMOTE在多个组公平指标上显著提升，同时保持了与其它公平感知算法相当的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13116v1",
      "published_date": "2025-05-19 13:46:47 UTC",
      "updated_date": "2025-05-19 13:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:19:11.832040"
    },
    {
      "arxiv_id": "2505.13115v1",
      "title": "Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning",
      "title_zh": "LALMs 用于时间推理的基准测试与置信度评估",
      "authors": [
        "Debarpan Bhattacharya",
        "Apoorva Kulkarni",
        "Sriram Ganapathy"
      ],
      "abstract": "The popular success of text-based large language models (LLM) has streamlined\nthe attention of the multimodal community to combine other modalities like\nvision and audio along with text to achieve similar multimodal capabilities. In\nthis quest, large audio language models (LALMs) have to be evaluated on\nreasoning related tasks which are different from traditional classification or\ngeneration tasks. Towards this goal, we propose a novel dataset called temporal\nreasoning evaluation of audio (TREA).\n  We benchmark open-source LALMs and observe that they are consistently behind\nhuman capabilities on the tasks in the TREA dataset. While evaluating LALMs, we\nalso propose an uncertainty metric, which computes the invariance of the model\nto semantically identical perturbations of the input. Our analysis shows that\nthe accuracy and uncertainty metrics are not necessarily correlated and thus,\npoints to a need for wholesome evaluation of LALMs for high-stakes\napplications.",
      "tldr_zh": "这篇论文提出一个名为 TREA 的新数据集，用于评估大型音频语言模型(LALMs)在时间推理任务上的性能，这些任务不同于传统的分类或生成任务。研究者对开源 LALMs 进行了基准测试，发现其表现远低于人类水平。论文同时引入了一个不确定性指标，通过计算模型对语义相同输入扰动的鲁棒性来评估其可靠性。最终分析显示，准确性和不确定性指标不一定相关，因此强调了在高风险应用中全面评估 LALMs 的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in INTERSPEECH, 2025, Rotterdam, The Netherlands",
      "pdf_url": "http://arxiv.org/pdf/2505.13115v1",
      "published_date": "2025-05-19 13:46:35 UTC",
      "updated_date": "2025-05-19 13:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:19:23.917855"
    },
    {
      "arxiv_id": "2505.13109v1",
      "title": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference",
      "title_zh": "FreeKV：提升 KV 缓存检索以实现高效 LLM 推理",
      "authors": [
        "Guangda Liu",
        "Chengwei Li",
        "Zhenyu Ning",
        "Jing Lin",
        "Yiwu Yao",
        "Danning Ke",
        "Minyi Guo",
        "Jieru Zhao"
      ],
      "abstract": "Large language models (LLMs) have been widely deployed with rapidly expanding\ncontext windows to support increasingly demanding applications. However, long\ncontexts pose significant deployment challenges, primarily due to the KV cache\nwhose size grows proportionally with context length. While KV cache compression\nmethods are proposed to address this issue, KV dropping methods incur\nconsiderable accuracy loss, and KV retrieval methods suffer from significant\nefficiency bottlenecks. We propose FreeKV, an algorithm-system co-optimization\nframework to enhance KV retrieval efficiency while preserving accuracy. On the\nalgorithm side, FreeKV introduces speculative retrieval to shift the KV\nselection and recall processes out of the critical path, combined with\nfine-grained correction to ensure accuracy. On the system side, FreeKV employs\nhybrid KV layouts across CPU and GPU memory to eliminate fragmented data\ntransfers, and leverages double-buffered streamed recall to further improve\nefficiency. Experiments demonstrate that FreeKV achieves near-lossless accuracy\nacross various scenarios and models, delivering up to 13$\\times$ speedup\ncompared to SOTA KV retrieval methods.",
      "tldr_zh": "大语言模型 (LLMs) 的长上下文窗口导致 KV cache 尺寸急剧增加，带来部署效率挑战。为解决此问题，本文提出 FreeKV，一种算法-系统联合优化框架，通过投机检索 (speculative retrieval) 和细粒度修正在算法层面移出 KV 选择与回忆的关键路径，并在系统层面采用 CPU 与 GPU 内存的混合布局及双缓冲流式回忆，提升检索效率。实验结果显示，FreeKV 在多种场景和模型中实现近乎无损准确性，比现有最先进 (SOTA) KV 检索方法快达 13 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13109v1",
      "published_date": "2025-05-19 13:36:45 UTC",
      "updated_date": "2025-05-19 13:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:19:36.764127"
    },
    {
      "arxiv_id": "2505.13102v1",
      "title": "Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Qi",
        "Tam Thuc Do",
        "Mingxiao Liu",
        "Zhuoshi Pan",
        "Yuzhe Li",
        "Gene Cheung",
        "H. Vicky Zhao"
      ],
      "abstract": "To forecast traffic with both spatial and temporal dimensions, we unroll a\nmixed-graph-based optimization algorithm into a lightweight and interpretable\ntransformer-like neural net. Specifically, we construct two graphs: an\nundirected graph $\\mathcal{G}^u$ capturing spatial correlations across\ngeography, and a directed graph $\\mathcal{G}^d$ capturing sequential\nrelationships over time. We formulate a prediction problem for the future\nsamples of signal $\\mathbf{x}$, assuming it is \"smooth\" with respect to both\n$\\mathcal{G}^u$ and $\\mathcal{G}^d$, where we design new $\\ell_2$ and\n$\\ell_1$-norm variational terms to quantify and promote signal smoothness\n(low-frequency reconstruction) on a directed graph. We construct an iterative\nalgorithm based on alternating direction method of multipliers (ADMM), and\nunroll it into a feed-forward network for data-driven parameter learning. We\ninsert graph learning modules for $\\mathcal{G}^u$ and $\\mathcal{G}^d$, which\nare akin to the self-attention mechanism in classical transformers. Experiments\nshow that our unrolled networks achieve competitive traffic forecast\nperformance as state-of-the-art prediction schemes, while reducing parameter\ncounts drastically. Our code is available in\nhttps://github.com/SingularityUndefined/Unrolling-GSP-STForecast.",
      "tldr_zh": "本文提出了一种轻量级的Transformer-like神经网络，通过展开混合图算法来实现交通预测。该方法构建无向图$\\mathcal{G}^u$以捕捉地理空间相关性，以及有向图$\\mathcal{G}^d$以捕捉时间序列关系，并使用新的$\\ell_2$和$\\ell_1$-norm变分项结合ADMM算法展开成可学习的网络，类似于自注意力机制。实验结果表明，该网络在交通预测性能上与最先进方案相当，但大幅减少了参数数量，提升了模型的可解释性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 5 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13102v1",
      "published_date": "2025-05-19 13:32:34 UTC",
      "updated_date": "2025-05-19 13:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:19:48.609076"
    },
    {
      "arxiv_id": "2505.13101v1",
      "title": "ARIW-Framework: Adaptive Robust Iterative Watermarking Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Shaowu Wu",
        "Liting Zeng",
        "Wei Lu",
        "Xiangyang Luo"
      ],
      "abstract": "With the rapid rise of large models, copyright protection for generated image\ncontent has become a critical security challenge. Although deep learning\nwatermarking techniques offer an effective solution for digital image copyright\nprotection, they still face limitations in terms of visual quality, robustness\nand generalization. To address these issues, this paper proposes an adaptive\nrobust iterative watermarking framework (ARIW-Framework) that achieves\nhigh-quality watermarked images while maintaining exceptional robustness and\ngeneralization performance. Specifically, we introduce an iterative approach to\noptimize the encoder for generating robust residuals. The encoder incorporates\nnoise layers and a decoder to compute robustness weights for residuals under\nvarious noise attacks. By employing a parallel optimization strategy, the\nframework enhances robustness against multiple types of noise attacks.\nFurthermore, we leverage image gradients to determine the embedding strength at\neach pixel location, significantly improving the visual quality of the\nwatermarked images. Extensive experiments demonstrate that the proposed method\nachieves superior visual quality while exhibiting remarkable robustness and\ngeneralization against noise attacks.",
      "tldr_zh": "该论文提出了一种自适应鲁棒迭代水印框架（ARIW-Framework），旨在解决深度学习水印技术在图像版权保护中存在的视觉质量、鲁棒性和泛化能力问题。该框架通过迭代优化编码器生成鲁棒残差，利用噪声层和解码器计算权重，并采用并行优化策略来增强对多种噪声攻击的抵抗力，同时借助图像梯度调整像素嵌入强度以提升水印图像的视觉质量。实验结果显示，该方法在视觉质量上表现出色，并实现了卓越的鲁棒性和泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13101v1",
      "published_date": "2025-05-19 13:31:48 UTC",
      "updated_date": "2025-05-19 13:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:20:00.559314"
    },
    {
      "arxiv_id": "2505.13098v1",
      "title": "LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lars-Peter Meyer",
        "Johannes Frey",
        "Desiree Heim",
        "Felix Brei",
        "Claus Stadler",
        "Kurt Junghanns",
        "Michael Martin"
      ],
      "abstract": "Current Large Language Models (LLMs) can assist developing program code\nbeside many other things, but can they support working with Knowledge Graphs\n(KGs) as well? Which LLM is offering the best capabilities in the field of\nSemantic Web and Knowledge Graph Engineering (KGE)? Is this possible to\ndetermine without checking many answers manually? The LLM-KG-Bench framework in\nVersion 3.0 is designed to answer these questions. It consists of an extensible\nset of tasks for automated evaluation of LLM answers and covers different\naspects of working with semantic technologies. In this paper the LLM-KG-Bench\nframework is presented in Version 3 along with a dataset of prompts, answers\nand evaluations generated with it and several state-of-the-art LLMs.\nSignificant enhancements have been made to the framework since its initial\nrelease, including an updated task API that offers greater flexibility in\nhandling evaluation tasks, revised tasks, and extended support for various open\nmodels through the vllm library, among other improvements. A comprehensive\ndataset has been generated using more than 30 contemporary open and proprietary\nLLMs, enabling the creation of exemplary model cards that demonstrate the\nmodels' capabilities in working with RDF and SPARQL, as well as comparing their\nperformance on Turtle and JSON-LD RDF serialization tasks.",
      "tldr_zh": "该论文介绍了 LLM-KG-Bench 3.0 框架，这是一个用于评估大型语言模型 (LLMs) 在知识图谱 (KGs) 和语义技术领域能力的自动化工具，旨在回答 LLMs 是否能有效支持语义网络和 KGE (Knowledge Graph Engineering) 任务，而无需手动检查。框架通过可扩展的任务集、更新后的任务 API 和 vllm 库支持多种开源模型，涵盖 RDF、SPARQL 等方面的评估，并进行了显著改进。研究生成了一个数据集，使用超过 30 个当代 LLMs 的提示、答案和评估，创建了模型卡来比较性能，例如在 Turtle 和 JSON-LD 序列化任务上的表现。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Peer reviewed publication at ESWC 2025 Resources Track",
      "pdf_url": "http://arxiv.org/pdf/2505.13098v1",
      "published_date": "2025-05-19 13:29:27 UTC",
      "updated_date": "2025-05-19 13:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:20:13.248160"
    },
    {
      "arxiv_id": "2505.13572v1",
      "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Yousouf Taghzouti",
        "Franck Michel",
        "Tao Jiang",
        "Louis-Félix Nothias",
        "Fabien Gandon"
      ],
      "abstract": "The SPARQL query language is the standard method to access knowledge graphs\n(KGs). However, formulating SPARQL queries is a significant challenge for\nnon-expert users, and remains time-consuming for the experienced ones. Best\npractices recommend to document KGs with competency questions and example\nqueries to contextualise the knowledge they contain and illustrate their\npotential applications. In practice, however, this is either not the case or\nthe examples are provided in limited numbers. Large Language Models (LLMs) are\nbeing used in conversational agents and are proving to be an attractive\nsolution with a wide range of applications, from simple question-answering\nabout common knowledge to generating code in a targeted programming language.\nHowever, training and testing these models to produce high quality SPARQL\nqueries from natural language questions requires substantial datasets of\nquestion-query pairs. In this paper, we present Q${}^2$Forge that addresses the\nchallenge of generating new competency questions for a KG and corresponding\nSPARQL queries. It iteratively validates those queries with human feedback and\nLLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular,\nmeaning that the different modules of the application (CQ generation, query\ngeneration and query refinement) can be used separately, as an integrated\npipeline, or replaced by alternative services. The result is a complete\npipeline from competency question formulation to query evaluation, supporting\nthe creation of reference query sets for any target KG.",
      "tldr_zh": "这篇论文介绍了 Q²Forge，一个开源的系统，用于为知识图谱 (KGs) 生成能力问题 (competency questions) 和对应的 SPARQL 查询，以简化基于自然语言的问答过程。Q²Forge 利用大型语言模型 (LLMs) 进行迭代生成，并通过人类反馈和 LLM 作为判断机制来验证查询的准确性。该系统模块化且可扩展，支持从问题制定到查询评估的完整管道，帮助创建高质量的参考查询集，从而提升非专家用户对 KGs 的访问效率。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13572v1",
      "published_date": "2025-05-19 13:26:51 UTC",
      "updated_date": "2025-05-19 13:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:20:25.176331"
    },
    {
      "arxiv_id": "2505.13094v1",
      "title": "Time-Frequency-Based Attention Cache Memory Model for Real-Time Speech Separation",
      "title_zh": "翻译失败",
      "authors": [
        "Guo Chen",
        "Kai Li",
        "Runxuan Yang",
        "Xiaolin Hu"
      ],
      "abstract": "Existing causal speech separation models often underperform compared to\nnon-causal models due to difficulties in retaining historical information. To\naddress this, we propose the Time-Frequency Attention Cache Memory (TFACM)\nmodel, which effectively captures spatio-temporal relationships through an\nattention mechanism and cache memory (CM) for historical information storage.\nIn TFACM, an LSTM layer captures frequency-relative positions, while causal\nmodeling is applied to the time dimension using local and global\nrepresentations. The CM module stores past information, and the causal\nattention refinement (CAR) module further enhances time-based feature\nrepresentations for finer granularity. Experimental results showed that TFACM\nachieveed comparable performance to the SOTA TF-GridNet-Causal model, with\nsignificantly lower complexity and fewer trainable parameters. For more\ndetails, visit the project page: https://cslikai.cn/TFACM/.",
      "tldr_zh": "本研究针对现有因果语音分离模型在保留历史信息方面存在的不足，提出 Time-Frequency Attention Cache Memory (TFACM) 模型，通过注意力机制和 cache memory (CM) 模块有效捕获时空关系。TFACM 利用 LSTM 层处理频率相对位置，并在时间维度应用因果建模，包括局部和全局表示，同时通过 causal attention refinement (CAR) 模块进一步优化特征粒度。实验结果显示，TFACM 与 SOTA 的 TF-GridNet-Causal 模型性能相当，但复杂度更低且参数更少，从而适用于实时语音分离任务。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13094v1",
      "published_date": "2025-05-19 13:25:51 UTC",
      "updated_date": "2025-05-19 13:25:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:20:37.115129"
    },
    {
      "arxiv_id": "2505.13087v1",
      "title": "Graph Alignment for Benchmarking Graph Neural Networks and Learning Positional Encodings",
      "title_zh": "图对齐：用于图神经网络基准测试和位置编码学习",
      "authors": [
        "Adrien Lagesse",
        "Marc Lelarge"
      ],
      "abstract": "We propose a novel benchmarking methodology for graph neural networks (GNNs)\nbased on the graph alignment problem, a combinatorial optimization task that\ngeneralizes graph isomorphism by aligning two unlabeled graphs to maximize\noverlapping edges. We frame this problem as a self-supervised learning task and\npresent several methods to generate graph alignment datasets using synthetic\nrandom graphs and real-world graph datasets from multiple domains. For a given\ngraph dataset, we generate a family of graph alignment datasets with increasing\ndifficulty, allowing us to rank the performance of various architectures. Our\nexperiments indicate that anisotropic graph neural networks outperform standard\nconvolutional architectures. To further demonstrate the utility of the graph\nalignment task, we show its effectiveness for unsupervised GNN pre-training,\nwhere the learned node embeddings outperform other positional encodings on\nthree molecular regression tasks and achieve state-of-the-art results on the\nPCQM4Mv2 dataset with significantly fewer parameters. To support\nreproducibility and further research, we provide an open-source Python package\nto generate graph alignment datasets and benchmark new GNN architectures.",
      "tldr_zh": "该论文提出了一种基于图对齐（graph alignment）问题的基准测试方法，用于评估图神经网络（GNNs），将这一组合优化任务转化为自监督学习任务，并通过合成随机图和真实世界数据集生成不同难度的图对齐数据集。实验结果显示，各向异性 GNNs 在性能上优于标准卷积架构。论文进一步证明，该任务可用于无监督 GNN 预训练，生成的节点嵌入在三个分子回归任务中优于其他位置编码（positional encodings），并在 PCQM4Mv2 数据集上实现了 state-of-the-art 结果，同时参数更少。为支持再现性，论文提供了开源 Python 包。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13087v1",
      "published_date": "2025-05-19 13:22:17 UTC",
      "updated_date": "2025-05-19 13:22:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:20:50.229489"
    },
    {
      "arxiv_id": "2505.13082v1",
      "title": "MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers",
      "title_zh": "MultiActor-Audiobook：利用多个说话者面部和声音的零样本有声书生成",
      "authors": [
        "Kyeongman Park",
        "Seongho Joo",
        "Kyomin Jung"
      ],
      "abstract": "We introduce MultiActor-Audiobook, a zero-shot approach for generating\naudiobooks that automatically produces consistent, expressive, and\nspeaker-appropriate prosody, including intonation and emotion. Previous\naudiobook systems have several limitations: they require users to manually\nconfigure the speaker's prosody, read each sentence with a monotonic tone\ncompared to voice actors, or rely on costly training. However, our\nMultiActor-Audiobook addresses these issues by introducing two novel processes:\n(1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based\nScript Instruction Generation**). With these two processes,\nMultiActor-Audiobook can generate more emotionally expressive audiobooks with a\nconsistent speaker prosody without additional training. We compare our system\nwith commercial products, through human and MLLM evaluations, achieving\ncompetitive results. Furthermore, we demonstrate the effectiveness of MSP and\nLSI through ablation studies.",
      "tldr_zh": "该研究提出 MultiActor-Audiobook，一种零样本方法，用于自动生成包含多个说话者面部和声音的富有表现力和情感的有声书，解决了传统系统手动配置韵律、语气单调或训练成本高的局限。\n该方法引入了两个关键过程：Multimodal Speaker Persona Generation (MSP) 用于生成多模态说话者角色，以及 LLM-based Script Instruction Generation (LSI) 用于基于大语言模型创建脚本指令，从而实现一致的韵律表达而不需额外训练。\n通过人类和 MLLM 评估，与商业产品相比，该系统取得了竞争性结果，并通过消融研究证实了 MSP 和 LSI 的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13082v1",
      "published_date": "2025-05-19 13:13:46 UTC",
      "updated_date": "2025-05-19 13:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:21:02.192018"
    },
    {
      "arxiv_id": "2505.13079v1",
      "title": "Cross-modal Knowledge Transfer Learning as Graph Matching Based on Optimal Transport for ASR",
      "title_zh": "跨模态知识转移学习作为基于最优传输的图匹配，用于 ASR",
      "authors": [
        "Xugang Lu",
        "Peng Shen",
        "Yu Tsao",
        "Hisashi Kawai"
      ],
      "abstract": "Transferring linguistic knowledge from a pretrained language model (PLM) to\nacoustic feature learning has proven effective in enhancing end-to-end\nautomatic speech recognition (E2E-ASR). However, aligning representations\nbetween linguistic and acoustic modalities remains a challenge due to inherent\nmodality gaps. Optimal transport (OT) has shown promise in mitigating these\ngaps by minimizing the Wasserstein distance (WD) between linguistic and\nacoustic feature distributions. However, previous OT-based methods overlook\nstructural relationships, treating feature vectors as unordered sets. To\naddress this, we propose Graph Matching Optimal Transport (GM-OT), which models\nlinguistic and acoustic sequences as structured graphs. Nodes represent feature\nembeddings, while edges capture temporal and sequential relationships. GM-OT\nminimizes both WD (between nodes) and Gromov-Wasserstein distance (GWD)\n(between edges), leading to a fused Gromov-Wasserstein distance (FGWD)\nformulation. This enables structured alignment and more efficient knowledge\ntransfer compared to existing OT-based approaches. Theoretical analysis further\nshows that prior OT-based methods in linguistic knowledge transfer can be\nviewed as a special case within our GM-OT framework. We evaluate GM-OT on\nMandarin ASR using a CTC-based E2E-ASR system with a PLM for knowledge\ntransfer. Experimental results demonstrate significant performance gains over\nstate-of-the-art models, validating the effectiveness of our approach.",
      "tldr_zh": "本论文提出了一种基于Graph Matching Optimal Transport (GM-OT)的跨模态知识转移学习方法，用于提升端到端自动语音识别 (E2E-ASR) 的性能，通过将预训练语言模型 (PLM) 的语言知识转移到声学特征学习中。GM-OT 将语言和声学序列建模为结构化图，节点表示特征嵌入，边捕捉时间和顺序关系，并通过最小化Wasserstein Distance (WD) 和Gromov-Wasserstein Distance (GWD) 来形成Fused Gromov-Wasserstein Distance (FGWD)，从而实现更有效的结构化对齐。实验结果显示，在普通话ASR任务上，该方法比现有OT-based方法显著提高性能，理论分析还证明了现有方法是GM-OT框架的特例。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "To appear in Interspeech 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13079v1",
      "published_date": "2025-05-19 13:13:18 UTC",
      "updated_date": "2025-05-19 13:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:21:14.547267"
    },
    {
      "arxiv_id": "2505.13077v1",
      "title": "Advancing Sequential Numerical Prediction in Autoregressive Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Fei",
        "Jinghui Lu",
        "Qi Sun",
        "Hao Feng",
        "Yanjie Wang",
        "Wei Shi",
        "An-Lan Wang",
        "Jingqun Tang",
        "Can Huang"
      ],
      "abstract": "Autoregressive models have become the de facto choice for sequence generation\ntasks, but standard approaches treat digits as independent tokens and apply\ncross-entropy loss, overlooking the coherent structure of numerical sequences.\nThis paper introduces Numerical Token Integrity Loss (NTIL) to address this\ngap. NTIL operates at two levels: (1) token-level, where it extends the Earth\nMover's Distance (EMD) to preserve ordinal relationships between numerical\nvalues, and (2) sequence-level, where it penalizes the overall discrepancy\nbetween the predicted and actual sequences. This dual approach improves\nnumerical prediction and integrates effectively with LLMs/MLLMs. Extensive\nexperiments show significant performance improvements with NTIL.",
      "tldr_zh": "本论文针对自回归模型(Autoregressive models)在序列生成任务中将数字视为独立标记并使用交叉熵损失的问题，提出了一种新的损失函数Numerical Token Integrity Loss (NTIL)，以解决数字序列的连贯结构被忽略的缺陷。NTIL在token-level上扩展Earth Mover's Distance (EMD)来维护数字值之间的顺序关系，并在sequence-level上惩罚预测序列与实际序列的整体差异，从而提升数字预测的准确性，并与LLMs/MLLMs无缝整合。实验结果显示，采用NTIL后，模型性能显著提升，为序列生成任务提供了更有效的优化方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.13077v1",
      "published_date": "2025-05-19 13:11:28 UTC",
      "updated_date": "2025-05-19 13:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:21:24.015941"
    },
    {
      "arxiv_id": "2505.13076v1",
      "title": "The Hidden Dangers of Browsing AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Mykyta Mudryi",
        "Markiyan Chaklosh",
        "Grzegorz Wójcik"
      ],
      "abstract": "Autonomous browsing agents powered by large language models (LLMs) are\nincreasingly used to automate web-based tasks. However, their reliance on\ndynamic content, tool execution, and user-provided data exposes them to a broad\nattack surface. This paper presents a comprehensive security evaluation of such\nagents, focusing on systemic vulnerabilities across multiple architectural\nlayers. Our work outlines the first end-to-end threat model for browsing agents\nand provides actionable guidance for securing their deployment in real-world\nenvironments. To address discovered threats, we propose a defense in depth\nstrategy incorporating input sanitization, planner executor isolation, formal\nanalyzers, and session safeguards. These measures protect against both initial\naccess and post exploitation attack vectors. Through a white box analysis of a\npopular open source project, Browser Use, we demonstrate how untrusted web\ncontent can hijack agent behavior and lead to critical security breaches. Our\nfindings include prompt injection, domain validation bypass, and credential\nexfiltration, evidenced by a disclosed CVE and a working proof of concept\nexploit.",
      "tldr_zh": "这篇论文探讨了基于大型语言模型(LLMs)的自主浏览代理的安全风险，这些代理依赖动态内容、工具执行和用户数据，导致广泛的攻击面。作者提出了首个端到端威胁模型，并提供防御策略，包括输入 sanitization、planner executor isolation、formal analyzers 和 session safeguards，以防范初始访问和后期利用攻击。实验通过对开源项目 Browser Use 的白盒分析，揭示了 prompt injection、domain validation bypass 和 credential exfiltration 等关键漏洞，并以披露的 CVE 和实际证明-of-concept 漏洞作为证据。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13076v1",
      "published_date": "2025-05-19 13:10:29 UTC",
      "updated_date": "2025-05-19 13:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:21:36.050225"
    },
    {
      "arxiv_id": "2505.13073v1",
      "title": "Structure-Aware Corpus Construction and User-Perception-Aligned Metrics for Large-Language-Model Code Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Dengfeng Liu",
        "Jucai Zhai",
        "Xiaoguang Jiang",
        "Ziqun Li",
        "Qianjin Yu",
        "Feng Liu",
        "Rui Ye",
        "Huang Liu",
        "Zhiguo Yang",
        "Yongsheng Du",
        "Fang Tan"
      ],
      "abstract": "Code completion technology based on large language model has significantly\nimproved the development efficiency of programmers. However, in practical\napplications, there remains a gap between current commonly used code completion\nevaluation metrics and users' actual perception. To address this issue, we\npropose two evaluation metrics for code completion tasks--LCP and ROUGE-LCP,\nfrom the perspective of probabilistic modeling. Furthermore, to tackle the lack\nof effective structural semantic modeling and cross-module dependency\ninformation in LLMs for repository-level code completion scenarios, we propose\na data processing method based on a Structure-Preserving and\nSemantically-Reordered Code Graph (SPSR-Graph). Through theoretical analysis\nand experimental validation, we demonstrate the superiority of the proposed\nevaluation metrics in terms of user perception consistency, as well as the\neffectiveness of the data processing method in enhancing model performance.",
      "tldr_zh": "本文针对大型语言模型(LLMs)代码补全技术的评估指标与用户实际感知存在差距的问题，提出两种新指标LCP和ROUGE-LCP，从概率建模视角进行设计，以更好地反映用户体验。同时，论文引入基于Structure-Preserving and Semantically-Reordered Code Graph (SPSR-Graph)的数据处理方法，提升LLMs在仓库级代码补全场景中的结构语义建模和跨模块依赖信息。通过理论分析和实验验证，这些指标在用户感知一致性上表现出优越性，而数据处理方法显著提高了模型性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "14 pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13073v1",
      "published_date": "2025-05-19 13:09:32 UTC",
      "updated_date": "2025-05-19 13:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:21:49.164500"
    },
    {
      "arxiv_id": "2505.13053v1",
      "title": "SNAPE-PM: Building and Utilizing Dynamic Partner Models for Adaptive Explanation Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Amelie S. Robrecht",
        "Christoph R. Kowalski",
        "Stefan Kopp"
      ],
      "abstract": "Adapting to the addressee is crucial for successful explanations, yet poses\nsignificant challenges for dialogsystems. We adopt the approach of treating\nexplanation generation as a non-stationary decision process, where the optimal\nstrategy varies according to changing beliefs about the explainee and the\ninteraction context. In this paper we address the questions of (1) how to track\nthe interaction context and the relevant listener features in a formally\ndefined computational partner model, and (2) how to utilize this model in the\ndynamically adjusted, rational decision process that determines the currently\nbest explanation strategy. We propose a Bayesian inference-based approach to\ncontinuously update the partner model based on user feedback, and a\nnon-stationary Markov Decision Process to adjust decision-making based on the\npartner model values. We evaluate an implementation of this framework with five\nsimulated interlocutors, demonstrating its effectiveness in adapting to\ndifferent partners with constant and even changing feedback behavior. The\nresults show high adaptivity with distinct explanation strategies emerging for\ndifferent partners, highlighting the potential of our approach to improve\nexplainable AI systems and dialogsystems in general.",
      "tldr_zh": "该论文提出SNAPE-PM框架，用于构建和利用动态partner model，以实现自适应解释生成。该框架将解释生成视为非-stationary决策过程，通过Bayesian inference-based方法根据用户反馈持续更新partner model，并采用non-stationary Markov Decision Process调整决策策略，以适应变化的交互上下文和听众特征。在模拟实验中，SNAPE-PM与五种模拟对话者互动，展示了高适应性，不同伙伴产生了独特的解释策略，从而提升了可解释AI系统和对话系统的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "currently under review at Frontiers in Communication",
      "pdf_url": "http://arxiv.org/pdf/2505.13053v1",
      "published_date": "2025-05-19 12:42:23 UTC",
      "updated_date": "2025-05-19 12:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:22:00.443213"
    },
    {
      "arxiv_id": "2505.13043v1",
      "title": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Ran Yang",
        "Xiaohui Chen",
        "Chuan-Xian Ren"
      ],
      "abstract": "Aiming to generalize the well-trained gaze estimation model to new target\ndomains, Cross-domain Gaze Estimation (CDGE) is developed for real-world\napplication scenarios. Existing CDGE methods typically extract the\ndomain-invariant features to mitigate domain shift in feature space, which is\nproved insufficient by Generalized Label Shift (GLS) theory. In this paper, we\nintroduce a novel GLS perspective to CDGE and modelize the cross-domain problem\nby label and conditional shift problem. A GLS correction framework is presented\nand a feasible realization is proposed, in which a importance reweighting\nstrategy based on truncated Gaussian distribution is introduced to overcome the\ncontinuity challenges in label shift correction. To embed the reweighted source\ndistribution to conditional invariant learning, we further derive a\nprobability-aware estimation of conditional operator discrepancy. Extensive\nexperiments on standard CDGE tasks with different backbone models validate the\nsuperior generalization capability across domain and applicability on various\nmodels of proposed method.",
      "tldr_zh": "本文从 Generalized Label Shift (GLS) 视角重新审视 Cross-domain Gaze Estimation (CDGE)，将跨域问题建模为标签移位和条件移位问题，以克服现有方法的不足。论文提出一个 GLS 修正框架，并引入基于 truncated Gaussian distribution 的 importance reweighting 策略来处理标签移位的连续性挑战，同时推导概率感知的条件操作符差异估计，以嵌入重加权源分布到条件不变学习中。实验结果显示，该方法在标准 CDGE 任务上显著提升了模型的泛化能力，并在不同骨干模型中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13043v1",
      "published_date": "2025-05-19 12:33:52 UTC",
      "updated_date": "2025-05-19 12:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:22:13.330031"
    },
    {
      "arxiv_id": "2505.13044v1",
      "title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents",
      "title_zh": "CAIM：认知 AI 记忆框架的开发和评估，用于与智能代理的长期互动",
      "authors": [
        "Rebecca Westhäußer",
        "Frederik Berenz",
        "Wolfgang Minker",
        "Sebastian Zepf"
      ],
      "abstract": "Large language models (LLMs) have advanced the field of artificial\nintelligence (AI) and are a powerful enabler for interactive systems. However,\nthey still face challenges in long-term interactions that require adaptation\ntowards the user as well as contextual knowledge and understanding of the\never-changing environment. To overcome these challenges, holistic memory\nmodeling is required to efficiently retrieve and store relevant information\nacross interaction sessions for suitable responses. Cognitive AI, which aims to\nsimulate the human thought process in a computerized model, highlights\ninteresting aspects, such as thoughts, memory mechanisms, and decision-making,\nthat can contribute towards improved memory modeling for LLMs. Inspired by\nthese cognitive AI principles, we propose our memory framework CAIM. CAIM\nconsists of three modules: 1.) The Memory Controller as the central decision\nunit; 2.) the Memory Retrieval, which filters relevant data for interaction\nupon request; and 3.) the Post-Thinking, which maintains the memory storage. We\ncompare CAIM against existing approaches, focusing on metrics such as retrieval\naccuracy, response correctness, contextual coherence, and memory storage. The\nresults demonstrate that CAIM outperforms baseline frameworks across different\nmetrics, highlighting its context-awareness and potential to improve long-term\nhuman-AI interactions.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在长期互动中面临的挑战，如用户适应和环境上下文理解问题，提出了一种认知 AI 记忆框架 CAIM。CAIM 由三个模块组成：Memory Controller 作为中央决策单元、Memory Retrieval 用于过滤相关数据，以及 Post-Thinking 负责维护记忆存储。该框架借鉴认知 AI 原理，通过实验评估显示，CAIM 在检索准确率、响应正确性、上下文连贯性和记忆存储指标上均优于现有方法，从而提升了长期人-AI 互动的上下文感知能力。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13044v1",
      "published_date": "2025-05-19 12:33:52 UTC",
      "updated_date": "2025-05-19 12:33:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:22:25.615954"
    },
    {
      "arxiv_id": "2505.13036v1",
      "title": "KIT's Offline Speech Translation and Instruction Following Submission for IWSLT 2025",
      "title_zh": "翻译失败",
      "authors": [
        "Sai Koneru",
        "Maike Züfle",
        "Thai-Binh Nguyen",
        "Seymanur Akti",
        "Jan Niehues",
        "Alexander Waibel"
      ],
      "abstract": "The scope of the International Workshop on Spoken Language Translation\n(IWSLT) has recently broadened beyond traditional Speech Translation (ST) to\nencompass a wider array of tasks, including Speech Question Answering and\nSummarization. This shift is partly driven by the growing capabilities of\nmodern systems, particularly with the success of Large Language Models (LLMs).\nIn this paper, we present the Karlsruhe Institute of Technology's submissions\nfor the Offline ST and Instruction Following (IF) tracks, where we leverage\nLLMs to enhance performance across all tasks. For the Offline ST track, we\npropose a pipeline that employs multiple automatic speech recognition systems,\nwhose outputs are fused using an LLM with document-level context. This is\nfollowed by a two-step translation process, incorporating additional refinement\nstep to improve translation quality. For the IF track, we develop an end-to-end\nmodel that integrates a speech encoder with an LLM to perform a wide range of\ninstruction-following tasks. We complement it with a final document-level\nrefinement stage to further enhance output quality by using contextual\ninformation.",
      "tldr_zh": "本论文介绍了Karlsruhe Institute of Technology (KIT)针对IWSLT 2025比赛的离线语音翻译(Offline ST)和指令跟随(Instruction Following, IF)任务提交，利用Large Language Models (LLMs)提升系统性能。针对Offline ST轨道，作者提出一个管道，使用多个自动语音识别(ASR)系统融合输出，通过LLMs处理文档级上下文，并采用两步翻译过程加上精炼步骤来改善翻译质量。对于IF轨道，他们开发了一个端到端模型，将语音编码器与LLMs整合，以执行多种指令任务，并通过文档级精炼阶段利用上下文信息进一步优化输出。这些方法展示了LLMs在扩展IWSLT任务（如语音问答和总结）中的潜力，有望显著提高语音处理任务的准确性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13036v1",
      "published_date": "2025-05-19 12:21:29 UTC",
      "updated_date": "2025-05-19 12:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:22:37.521914"
    },
    {
      "arxiv_id": "2505.13033v1",
      "title": "TSPulse: Dual Space Tiny Pre-Trained Models for Rapid Time-Series Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Vijay Ekambaram",
        "Subodh Kumar",
        "Arindam Jati",
        "Sumanta Mukherjee",
        "Tomoya Sakai",
        "Pankaj Dayama",
        "Wesley M. Gifford",
        "Jayant Kalagnanam"
      ],
      "abstract": "The rise of time-series pre-trained models has advanced temporal\nrepresentation learning, but current state-of-the-art models are often\nlarge-scale, requiring substantial compute. We introduce TSPulse, ultra-compact\ntime-series pre-trained models with only 1M parameters, specialized to perform\nstrongly across classification, anomaly detection, imputation, and retrieval\ntasks. TSPulse introduces innovations at both the architecture and task levels.\nAt the architecture level, it employs a dual-space masked reconstruction,\nlearning from both time and frequency domains to capture complementary signals.\nThis is further enhanced by a dual-embedding disentanglement, generating both\ndetailed embeddings for fine-grained analysis and high-level semantic\nembeddings for broader task understanding. Notably, TSPulse's semantic\nembeddings are robust to shifts in time, magnitude, and noise, which is\nimportant for robust retrieval. At the task level, TSPulse incorporates TSLens,\na fine-tuning component enabling task-specific feature attention. It also\nintroduces a multi-head triangulation technique that correlates deviations from\nmultiple prediction heads, enhancing anomaly detection by fusing complementary\nmodel outputs. Additionally, a hybrid mask pretraining is proposed to improves\nzero-shot imputation by reducing pre-training bias. These architecture and task\ninnovations collectively contribute to TSPulse's significant performance gains:\n5-16% on the UEA classification benchmarks, +20% on the TSB-AD anomaly\ndetection leaderboard, +50% in zero-shot imputation, and +25% in time-series\nretrieval. Remarkably, these results are achieved with just 1M parameters,\nmaking TSPulse 10-100X smaller than existing pre-trained models. Its efficiency\nenables GPU-free inference and rapid pre-training, setting a new standard for\nefficient time-series pre-trained models. Models will be open-sourced soon.",
      "tldr_zh": "本研究引入了 TSPulse，一种仅有 1M 参数的超紧凑时间序列预训练模型，旨在实现快速时间序列分析，支持分类、异常检测、插值和检索任务。TSPulse 在架构层面采用 dual-space masked reconstruction 从时间和频率域学习，以及 dual-embedding disentanglement 生成详细嵌入和高层语义嵌入，提升了对时间、幅度和噪声偏移的鲁棒性；在任务层面，引入 TSLens 用于任务特定特征注意力、multi-head triangulation 增强异常检测，以及 hybrid mask pretraining 改善零样本插值。实验结果显示，TSPulse 在 UEA 分类基准上提升 5-16%、TSB-AD 异常检测上提升 20%、零样本插值上提升 50%、时间序列检索上提升 25%，且模型比现有预训练模型小 10-100 倍，支持无 GPU 推理和快速预训练，未来将开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13033v1",
      "published_date": "2025-05-19 12:18:53 UTC",
      "updated_date": "2025-05-19 12:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:22:49.636090"
    },
    {
      "arxiv_id": "2505.13031v1",
      "title": "MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Xiao",
        "Lin Song",
        "Yukang Chen",
        "Yingmin Luo",
        "Yuxin Chen",
        "Yukang Gan",
        "Wei Huang",
        "Xiu Li",
        "Xiaojuan Qi",
        "Ying Shan"
      ],
      "abstract": "Recent text-to-image systems face limitations in handling multimodal inputs\nand complex reasoning tasks. We introduce MindOmni, a unified multimodal large\nlanguage model that addresses these challenges by incorporating reasoning\ngeneration through reinforcement learning. MindOmni leverages a three-phase\ntraining strategy: i) design of a unified vision language model with a\ndecoder-only diffusion module, ii) supervised fine-tuning with Chain-of-Thought\n(CoT) instruction data, and iii) our proposed Reasoning Generation Policy\nOptimization (RGPO) algorithm, utilizing multimodal feedback to effectively\nguide policy updates. Experimental results demonstrate that MindOmni\noutperforms existing models, achieving impressive performance on both\nunderstanding and generation benchmarks, meanwhile showcasing advanced\nfine-grained reasoning generation capabilities, especially with mathematical\nreasoning instruction. All codes will be made public at\n\\href{https://github.com/EasonXiao-888/MindOmni}{https://github.com/EasonXiao-888/MindOmni}.",
      "tldr_zh": "该研究提出 MindOmni，一种统一的 multimodal large language model，通过 Reinforcement Generation Policy Optimization (RGPO) 算法来提升视觉语言模型在处理多模态输入和复杂推理任务时的能力。MindOmni 采用三阶段训练策略：首先设计带有 decoder-only diffusion module 的统一模型，其次使用 Chain-of-Thought (CoT) 指令数据进行监督微调，最后通过 RGPO 算法利用多模态反馈优化策略。实验结果表明，MindOmni 在理解和生成基准上超越现有模型，尤其在细粒度推理生成（如数学推理）方面表现出色，并计划开源代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Code: https://github.com/EasonXiao-888/MindOmni",
      "pdf_url": "http://arxiv.org/pdf/2505.13031v1",
      "published_date": "2025-05-19 12:17:04 UTC",
      "updated_date": "2025-05-19 12:17:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:23:01.585828"
    },
    {
      "arxiv_id": "2505.13028v2",
      "title": "Evaluating the efficacy of LLM Safety Solutions : The Palit Benchmark Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Sayon Palit",
        "Daniel Woods"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\nsystems in industries like healthcare and finance. Users can often submit\nqueries to LLM-enabled chatbots, some of which can enrich responses with\ninformation retrieved from internal databases storing sensitive data. This\ngives rise to a range of attacks in which a user submits a malicious query and\nthe LLM-system outputs a response that creates harm to the owner, such as\nleaking internal data or creating legal liability by harming a third-party.\nWhile security tools are being developed to counter these threats, there is\nlittle formal evaluation of their effectiveness and usability. This study\naddresses this gap by conducting a thorough comparative analysis of LLM\nsecurity tools. We identified 13 solutions (9 closed-source, 4 open-source),\nbut only 7 were evaluated due to a lack of participation by proprietary model\nowners.To evaluate, we built a benchmark dataset of malicious prompts, and\nevaluate these tools performance against a baseline LLM model\n(ChatGPT-3.5-Turbo). Our results show that the baseline model has too many\nfalse positives to be used for this task. Lakera Guard and ProtectAI LLM Guard\nemerged as the best overall tools showcasing the tradeoff between usability and\nperformance. The study concluded with recommendations for greater transparency\namong closed source providers, improved context-aware detections, enhanced\nopen-source engagement, increased user awareness, and the adoption of more\nrepresentative performance metrics.",
      "tldr_zh": "这篇论文评估了LLM（Large Language Models）安全解决方案的效能，针对用户恶意查询可能导致的数据泄露或法律责任等问题，构建了Palit Benchmark Dataset作为基准数据集。研究者比较分析了13种安全工具中的7种（包括9个闭源和4个开源工具），并与基线模型ChatGPT-3.5-Turbo进行性能对比，结果显示基线模型存在过多假阳性，而Lakera Guard和ProtectAI LLM Guard在可用性和性能之间取得了最佳权衡。论文最后推荐提升闭源提供者的透明度、改进上下文感知检测、加强开源参与、提高用户意识，并采用更具代表性的性能指标。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "F.2.2; I.2.7; F.2.2; I.2.7; F.2.2; I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13028v2",
      "published_date": "2025-05-19 12:12:00 UTC",
      "updated_date": "2025-05-20 07:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:23:13.012994"
    },
    {
      "arxiv_id": "2505.13026v1",
      "title": "Step-wise Adaptive Integration of Supervised Fine-tuning and Reinforcement Learning for Task-Specific LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jack Chen",
        "Fazhong Liu",
        "Naruto Liu",
        "Yuhan Luo",
        "Erqu Qin",
        "Harry Zheng",
        "Tian Dong",
        "Haojin Zhu",
        "Yan Meng",
        "Xiao Wang"
      ],
      "abstract": "Large language models (LLMs) excel at mathematical reasoning and logical\nproblem-solving. The current popular training paradigms primarily use\nsupervised fine-tuning (SFT) and reinforcement learning (RL) to enhance the\nmodels' reasoning abilities. However, when using SFT or RL alone, there are\nrespective challenges: SFT may suffer from overfitting, while RL is prone to\nmode collapse. The state-of-the-art methods have proposed hybrid training\nschemes. However, static switching faces challenges such as poor generalization\nacross different tasks and high dependence on data quality. In response to\nthese challenges, inspired by the curriculum learning-quiz mechanism in human\nreasoning cultivation, We propose SASR, a step-wise adaptive hybrid training\nframework that theoretically unifies SFT and RL and dynamically balances the\ntwo throughout optimization. SASR uses SFT for initial warm-up to establish\nbasic reasoning skills, and then uses an adaptive dynamic adjustment algorithm\nbased on gradient norm and divergence relative to the original distribution to\nseamlessly integrate SFT with the online RL method GRPO. By monitoring the\ntraining status of LLMs and adjusting the training process in sequence, SASR\nensures a smooth transition between training schemes, maintaining core\nreasoning abilities while exploring different paths. Experimental results\ndemonstrate that SASR outperforms SFT, RL, and static hybrid training methods.",
      "tldr_zh": "该论文提出 SASR，一种逐步自适应混合训练框架，用于针对特定任务的大语言模型（LLMs），以解决 supervised fine-tuning (SFT) 的过拟合问题和 reinforcement learning (RL) 的模式崩溃问题。SASR 受人类课程学习启发，先通过 SFT 进行初始热身建立基本推理技能，然后使用基于梯度范数和与原始分布发散的自适应算法，将 SFT 与在线 RL 方法 GRPO 无缝整合，实现动态平衡和平滑过渡。实验结果显示，SASR 在性能上优于纯 SFT、RL 以及静态混合方法，证明了其在提升模型泛化性和任务适应性方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13026v1",
      "published_date": "2025-05-19 12:10:17 UTC",
      "updated_date": "2025-05-19 12:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:23:24.805180"
    },
    {
      "arxiv_id": "2505.13025v1",
      "title": "LiBOG: Lifelong Learning for Black-Box Optimizer Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyuan Pei",
        "Yi Mei",
        "Jialin Liu",
        "Mengjie Zhang"
      ],
      "abstract": "Meta-Black-Box Optimization (MetaBBO) garners attention due to its success in\nautomating the configuration and generation of black-box optimizers,\nsignificantly reducing the human effort required for optimizer design and\ndiscovering optimizers with higher performance than classic human-designed\noptimizers. However, existing MetaBBO methods conduct one-off training under\nthe assumption that a stationary problem distribution with extensive and\nrepresentative training problem samples is pre-available. This assumption is\noften impractical in real-world scenarios, where diverse problems following\nshifting distribution continually arise. Consequently, there is a pressing need\nfor methods that can continuously learn from new problems encountered\non-the-fly and progressively enhance their capabilities. In this work, we\nexplore a novel paradigm of lifelong learning in MetaBBO and introduce LiBOG, a\nnovel approach designed to learn from sequentially encountered problems and\ngenerate high-performance optimizers for Black-Box Optimization (BBO). LiBOG\nconsolidates knowledge both across tasks and within tasks to mitigate\ncatastrophic forgetting. Extensive experiments demonstrate LiBOG's\neffectiveness in learning to generate high-performance optimizers in a lifelong\nlearning manner, addressing catastrophic forgetting while maintaining\nplasticity to learn new tasks.",
      "tldr_zh": "本论文探讨了MetaBBO（元黑箱优化）中的终身学习范式，针对现实场景中问题分布动态变化的挑战，提出LiBOG方法。该方法通过从顺序出现的问题中持续学习，并整合跨任务和任务内知识，来生成高性能的黑箱优化器（BBO），同时缓解catastrophic forgetting（灾难性遗忘）。实验结果显示，LiBOG在终身学习环境中有效提升优化器性能，并保持了对新任务的学习能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IJCAI 2025. To appear",
      "pdf_url": "http://arxiv.org/pdf/2505.13025v1",
      "published_date": "2025-05-19 12:09:25 UTC",
      "updated_date": "2025-05-19 12:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:23:36.741366"
    },
    {
      "arxiv_id": "2505.13023v1",
      "title": "Anti-Inpainting: A Proactive Defense against Malicious Diffusion-based Inpainters under Unknown Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Yimao Guo",
        "Zuomin Qu",
        "Wei Lu",
        "Xiangyang Luo"
      ],
      "abstract": "As diffusion-based malicious image manipulation becomes increasingly\nprevalent, multiple proactive defense methods are developed to safeguard images\nagainst unauthorized tampering. However, most proactive defense methods only\ncan safeguard images against manipulation under known conditions, and fail to\nprotect images from manipulations guided by tampering conditions crafted by\nmalicious users. To tackle this issue, we propose Anti-Inpainting, a proactive\ndefense method that achieves adequate protection under unknown conditions\nthrough a triple mechanism to address this challenge. Specifically, a\nmulti-level deep feature extractor is presented to obtain intricate features\nduring the diffusion denoising process to improve protective effectiveness. We\ndesign multi-scale semantic-preserving data augmentation to enhance the\ntransferability of adversarial perturbations across unknown conditions by\nmulti-scale transformations while preserving semantic integrity. In addition,\nwe propose a selection-based distribution deviation optimization strategy to\nimprove the protection of adversarial perturbation against manipulation under\ndiverse random seeds. Extensive experiments indicate the proactive defensive\nperformance of Anti-Inpainting against diffusion-based inpainters guided by\nunknown conditions in InpaintGuardBench and CelebA-HQ. At the same time, we\nalso demonstrate the proposed approach's robustness under various image\npurification methods and its transferability across different versions of\ndiffusion models.",
      "tldr_zh": "该研究提出Anti-Inpainting，一种主动防御方法，旨在保护图像免受未知条件下恶意diffusion-based图像修复(inpainters)的篡改。方法采用三重机制，包括multi-level deep feature extractor来提取扩散去噪过程中的复杂特征、multi-scale semantic-preserving data augmentation来增强对抗扰动的转移性，同时保留语义完整性，以及selection-based distribution deviation optimization strategy来优化扰动在不同随机种子下的保护效果。实验结果显示，Anti-Inpainting在InpaintGuardBench和CelebA-HQ数据集上对未知条件引导的inpainters表现出色，并证明了其在各种图像净化方法下的鲁棒性和跨不同diffusion模型版本的转移性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13023v1",
      "published_date": "2025-05-19 12:07:29 UTC",
      "updated_date": "2025-05-19 12:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:23:48.961286"
    },
    {
      "arxiv_id": "2505.13011v1",
      "title": "Unveiling and Steering Connectome Organization with Interpretable Latent Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Li",
        "Xingyu Liu",
        "Guozhang Chen"
      ],
      "abstract": "The brain's intricate connectome, a blueprint for its function, presents\nimmense complexity, yet it arises from a compact genetic code, hinting at\nunderlying low-dimensional organizational principles. This work bridges\nconnectomics and representation learning to uncover these principles. We\npropose a framework that combines subgraph extraction from the Drosophila\nconnectome, FlyWire, with a generative model to derive interpretable\nlow-dimensional representations of neural circuitry. Crucially, an\nexplainability module links these latent dimensions to specific structural\nfeatures, offering insights into their functional relevance. We validate our\napproach by demonstrating effective graph reconstruction and, significantly,\nthe ability to manipulate these latent codes to controllably generate\nconnectome subgraphs with predefined properties. This research offers a novel\ntool for understanding brain architecture and a potential avenue for designing\nbio-inspired artificial neural networks.",
      "tldr_zh": "本研究桥接连接体学和表示学习，提出一个框架从Drosophila connectome的FlyWire提取子图，并使用生成模型获取可解释的低维latent variables，从而揭示脑连接体的底层组织原则。框架中包含一个explainability module，将这些latent variables链接到特定结构特征，提供功能相关洞见，并验证其能有效重建图形并操纵latent codes生成具有预定义属性的连接体子图。该方法为理解脑架构提供了新工具，并开辟了设计生物启发的人工神经网络的潜在途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13011v1",
      "published_date": "2025-05-19 11:54:40 UTC",
      "updated_date": "2025-05-19 11:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:24:01.131337"
    },
    {
      "arxiv_id": "2505.13010v1",
      "title": "To Bias or Not to Bias: Detecting bias in News with bias-detector",
      "title_zh": "翻译失败",
      "authors": [
        "Himel Ghosh",
        "Ahmed Mosharafa",
        "Georg Groh"
      ],
      "abstract": "Media bias detection is a critical task in ensuring fair and balanced\ninformation dissemination, yet it remains challenging due to the subjectivity\nof bias and the scarcity of high-quality annotated data. In this work, we\nperform sentence-level bias classification by fine-tuning a RoBERTa-based model\non the expert-annotated BABE dataset. Using McNemar's test and the 5x2\ncross-validation paired t-test, we show statistically significant improvements\nin performance when comparing our model to a domain-adaptively pre-trained\nDA-RoBERTa baseline. Furthermore, attention-based analysis shows that our model\navoids common pitfalls like oversensitivity to politically charged terms and\ninstead attends more meaningfully to contextually relevant tokens. For a\ncomprehensive examination of media bias, we present a pipeline that combines\nour model with an already-existing bias-type classifier. Our method exhibits\ngood generalization and interpretability, despite being constrained by\nsentence-level analysis and dataset size because of a lack of larger and more\nadvanced bias corpora. We talk about context-aware modeling, bias\nneutralization, and advanced bias type classification as potential future\ndirections. Our findings contribute to building more robust, explainable, and\nsocially responsible NLP systems for media bias detection.",
      "tldr_zh": "本文提出了一种基于 RoBERTa 模型的句子级媒体偏见检测方法，通过在专家标注的 BABE 数据集上微调，与 DA-RoBERTa 基线相比，使用 McNemar's test 和 5x2 交叉验证配对 t-测试证明了显著性能提升。模型通过注意机制避免了对政治术语的过度敏感，而是更关注上下文相关标记，并与现有偏见类型分类器结合形成一个全面的检测管道，提升了泛化性和可解释性。尽管受限于数据集大小，该方法为构建更健壮、负责任的 NLP 系统提供了重要贡献，并建议未来探索上下文感知建模和偏见中和等方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.13010v1",
      "published_date": "2025-05-19 11:54:39 UTC",
      "updated_date": "2025-05-19 11:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:24:13.637395"
    },
    {
      "arxiv_id": "2505.12996v1",
      "title": "ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning",
      "title_zh": "ExTrans：通过示例增强强化学习的多语言深度推理翻译",
      "authors": [
        "Jiaan Wang",
        "Fandong Meng",
        "Jie Zhou"
      ],
      "abstract": "In recent years, the emergence of large reasoning models (LRMs), such as\nOpenAI-o1 and DeepSeek-R1, has shown impressive capabilities in complex\nproblems, e.g., mathematics and coding. Some pioneering studies attempt to\nbring the success of LRMs in neural machine translation (MT). They try to build\nLRMs with deep reasoning MT ability via reinforcement learning (RL). Despite\nsome progress that has been made, these attempts generally focus on several\nhigh-resource languages, e.g., English and Chinese, leaving the performance on\nother languages unclear. Besides, the reward modeling methods in previous work\ndo not fully unleash the potential of reinforcement learning in MT. In this\nwork, we first design a new reward modeling method that compares the\ntranslation results of the policy MT model with a strong LRM (i.e.,\nDeepSeek-R1-671B), and quantifies the comparisons to provide rewards.\nExperimental results demonstrate the superiority of the reward modeling method.\nUsing Qwen2.5-7B-Instruct as the backbone, the trained model achieves the new\nstate-of-the-art performance in literary translation, and outperforms strong\nLRMs including OpenAI-o1 and DeepSeeK-R1. Furthermore, we extend our method to\nthe multilingual settings with 11 languages. With a carefully designed\nlightweight reward modeling in RL, we can simply transfer the strong MT ability\nfrom a single direction into multiple (i.e., 90) translation directions and\nachieve impressive multilingual MT performance.",
      "tldr_zh": "这篇论文提出ExTrans，一种通过示例增强的强化学习(Exemplar-Enhanced Reinforcement Learning)框架，旨在提升大型推理模型(LRMs)如OpenAI-o1和DeepSeek-R1在神经机器翻译(MT)中的深度推理能力，特别是针对高资源语言外的多语言场景。作者设计了一种新颖的奖励建模方法，将策略MT模型的翻译结果与强LRM（如DeepSeek-R1-671B）比较并量化作为奖励，使用Qwen2.5-7B-Instruct作为骨干模型，实验结果显示该方法在文学翻译中达到state-of-the-art性能，并优于现有LRMs。进一步，该框架扩展到11种语言，通过轻量级奖励建模，将强MT能力从单一翻译方向转移到90个方向，实现了出色的多语言MT性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12996v1",
      "published_date": "2025-05-19 11:34:47 UTC",
      "updated_date": "2025-05-19 11:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:24:27.359295"
    },
    {
      "arxiv_id": "2505.12992v1",
      "title": "Fractured Chain-of-Thought Reasoning",
      "title_zh": "破碎的链式思维推理",
      "authors": [
        "Baohao Liao",
        "Hanze Dong",
        "Yuhui Xu",
        "Doyen Sahoo",
        "Christof Monz",
        "Junnan Li",
        "Caiming Xiong"
      ],
      "abstract": "Inference-time scaling techniques have significantly bolstered the reasoning\ncapabilities of large language models (LLMs) by harnessing additional\ncomputational effort at inference without retraining. Similarly,\nChain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy\nby generating rich intermediate reasoning trajectories, but these approaches\nincur substantial token costs that impede their deployment in latency-sensitive\nsettings. In this work, we first show that truncated CoT, which stops reasoning\nbefore completion and directly generates the final answer, often matches full\nCoT sampling while using dramatically fewer tokens. Building on this insight,\nwe introduce Fractured Sampling, a unified inference-time strategy that\ninterpolates between full CoT and solution-only sampling along three orthogonal\naxes: (1) the number of reasoning trajectories, (2) the number of final\nsolutions per trajectory, and (3) the depth at which reasoning traces are\ntruncated. Through extensive experiments on five diverse reasoning benchmarks\nand several model scales, we demonstrate that Fractured Sampling consistently\nachieves superior accuracy-cost trade-offs, yielding steep log-linear scaling\ngains in Pass@k versus token budget. Our analysis reveals how to allocate\ncomputation across these dimensions to maximize performance, paving the way for\nmore efficient and scalable LLM reasoning.",
      "tldr_zh": "本研究发现，Chain-of-Thought (CoT) 提示虽能提升大型语言模型 (LLMs) 的推理准确性，但会因高 token 成本而影响延迟敏感应用；截断 CoT（truncated CoT）可与完整 CoT 匹敌，同时显著减少 token 使用。作者提出 Fractured Sampling，一种统一的推理时策略，通过调整推理轨迹数量、每个轨迹的最终解决方案数量以及推理深度这三个轴来优化准确性-成本权衡。在五个多样化推理基准上的实验显示，该方法实现了 log-linear scaling gains，在 Pass@k 与 token 预算之间提供高效性能提升，从而为更可扩展的 LLM 推理铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12992v1",
      "published_date": "2025-05-19 11:30:41 UTC",
      "updated_date": "2025-05-19 11:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:24:37.445377"
    },
    {
      "arxiv_id": "2505.12983v1",
      "title": "An Empirical Study of Many-to-Many Summarization with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaan Wang",
        "Fandong Meng",
        "Zengkui Sun",
        "Yunlong Liang",
        "Yuxuan Cao",
        "Jiarong Xu",
        "Haoxiang Shi",
        "Jie Zhou"
      ],
      "abstract": "Many-to-many summarization (M2MS) aims to process documents in any language\nand generate the corresponding summaries also in any language. Recently, large\nlanguage models (LLMs) have shown strong multi-lingual abilities, giving them\nthe potential to perform M2MS in real applications. This work presents a\nsystematic empirical study on LLMs' M2MS ability. Specifically, we first\nreorganize M2MS data based on eight previous domain-specific datasets. The\nreorganized data contains 47.8K samples spanning five domains and six\nlanguages, which could be used to train and evaluate LLMs. Then, we benchmark\n18 LLMs in a zero-shot manner and an instruction-tuning manner. Fine-tuned\ntraditional models (e.g., mBART) are also conducted for comparisons. Our\nexperiments reveal that, zero-shot LLMs achieve competitive results with\nfine-tuned traditional models. After instruct-tuning, open-source LLMs can\nsignificantly improve their M2MS ability, and outperform zero-shot LLMs\n(including GPT-4) in terms of automatic evaluations. In addition, we\ndemonstrate that this task-specific improvement does not sacrifice the LLMs'\ngeneral task-solving abilities. However, as revealed by our human evaluation,\nLLMs still face the factuality issue, and the instruction tuning might\nintensify the issue. Thus, how to control factual errors becomes the key when\nbuilding LLM summarizers in real applications, and is worth noting in future\nresearch.",
      "tldr_zh": "该论文对 Large Language Models (LLMs) 在 Many-to-Many Summarization (M2MS) 任务中的能力进行了系统实证研究，M2MS 涉及处理任意语言的文档并生成任意语言的摘要。作者重新组织了 47.8K 个样本的数据，涵盖五个领域和六种语言，并对 18 个 LLMs 进行了 zero-shot 和 instruction-tuning 基准测试，与 fine-tuned 传统模型（如 mBART）进行比较。结果显示，zero-shot LLMs 的表现已与 fine-tuned 传统模型相当，而 instruction-tuning 后，开源 LLMs 的性能显著提升，并优于 zero-shot LLMs（包括 GPT-4）。此外，这种任务特定改进不会影响 LLMs 的通用能力，但论文强调 LLMs 存在 factuality issue（事实性问题），instruction-tuning 可能加剧这一问题，因此未来研究应重点关注控制事实错误以构建可靠的 LLM 摘要工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2505.12983v1",
      "published_date": "2025-05-19 11:18:54 UTC",
      "updated_date": "2025-05-19 11:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:24:50.497025"
    },
    {
      "arxiv_id": "2505.12981v2",
      "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents",
      "title_zh": "从助手到对手：探索移动 LLM 代理的安全风险",
      "authors": [
        "Liangxuan Wu",
        "Chao Wang",
        "Tianming Liu",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "The growing adoption of large language models (LLMs) has led to a new\nparadigm in mobile computing--LLM-powered mobile AI agents--capable of\ndecomposing and automating complex tasks directly on smartphones. However, the\nsecurity implications of these agents remain largely unexplored. In this paper,\nwe present the first comprehensive security analysis of mobile LLM agents,\nencompassing three representative categories: System-level AI Agents developed\nby original equipment manufacturers (e.g., YOYO Assistant), Third-party\nUniversal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g.,\nAlibaba Mobile Agent). We begin by analyzing the general workflow of mobile\nagents and identifying security threats across three core capability\ndimensions: language-based reasoning, GUI-based interaction, and system-level\nexecution. Our analysis reveals 11 distinct attack surfaces, all rooted in the\nunique capabilities and interaction patterns of mobile LLM agents, and spanning\ntheir entire operational lifecycle. To investigate these threats in practice,\nwe introduce AgentScan, a semi-automated security analysis framework that\nsystematically evaluates mobile LLM agents across all 11 attack scenarios.\nApplying AgentScan to nine widely deployed agents, we uncover a concerning\ntrend: every agent is vulnerable to targeted attacks. In the most severe cases,\nagents exhibit vulnerabilities across eight distinct attack vectors. These\nattacks can cause behavioral deviations, privacy leakage, or even full\nexecution hijacking. Based on these findings, we propose a set of defensive\ndesign principles and practical recommendations for building secure mobile LLM\nagents. Our disclosures have received positive feedback from two major device\nvendors. Overall, this work highlights the urgent need for standardized\nsecurity practices in the fast-evolving landscape of LLM-driven mobile\nautomation.",
      "tldr_zh": "这篇论文探讨了移动 LLM 代理从助手转向对手的安全风险，首次对三种代表性类别（包括 System-level AI Agents 如 YOYO Assistant、Third-party Universal Agents 如 Zhipu AI AutoGLM，以及 Emerging Agent Frameworks 如 Alibaba Mobile Agent）进行了全面分析。研究者识别了 11 个攻击面，涵盖语言-based reasoning、GUI-based interaction 和 system-level execution 等核心能力维度，并分析了这些威胁在代理整个生命周期中的表现。作者开发了 AgentScan 框架，对九个广泛部署的代理进行半自动化评估，结果显示所有代理都存在漏洞，有些涉及八个攻击向量，可能导致行为偏差、隐私泄露或执行劫持。最终，论文提出了防御设计原则和实用推荐，以推动 LLM 驱动的移动自动化领域的标准化安全实践。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12981v2",
      "published_date": "2025-05-19 11:17:46 UTC",
      "updated_date": "2025-05-20 07:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:25:02.059043"
    },
    {
      "arxiv_id": "2505.12966v1",
      "title": "Multiscale Adaptive Conflict-Balancing Model For Multimedia Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Xiong",
        "Xiaohua Wu",
        "Lei Chen",
        "Fangqi Lou"
      ],
      "abstract": "Advances in computer vision and deep learning have blurred the line between\ndeepfakes and authentic media, undermining multimedia credibility through\naudio-visual forgery. Current multimodal detection methods remain limited by\nunbalanced learning between modalities. To tackle this issue, we propose an\nAudio-Visual Joint Learning Method (MACB-DF) to better mitigate modality\nconflicts and neglect by leveraging contrastive learning to assist in\nmulti-level and cross-modal fusion, thereby fully balancing and exploiting\ninformation from each modality. Additionally, we designed an\northogonalization-multimodal pareto module that preserves unimodal information\nwhile addressing gradient conflicts in audio-video encoders caused by differing\noptimization targets of the loss functions. Extensive experiments and ablation\nstudies conducted on mainstream deepfake datasets demonstrate consistent\nperformance gains of our model across key evaluation metrics, achieving an\naverage accuracy of 95.5% across multiple datasets. Notably, our method\nexhibits superior cross-dataset generalization capabilities, with absolute\nimprovements of 8.0% and 7.7% in ACC scores over the previous best-performing\napproach when trained on DFDC and tested on DefakeAVMiT and FakeAVCeleb\ndatasets.",
      "tldr_zh": "这篇论文针对多媒体深假检测中的模态不平衡问题，提出了一种Audio-Visual Joint Learning Method (MACB-DF)，通过contrastive learning辅助多级别和跨模态融合，缓解模态冲突并充分利用音频和视频信息。论文还设计了orthogonalization-multimodal pareto module，用于保留单模态信息并解决音频-视频编码器中的梯度冲突。实验结果显示，该方法在主流deepfake数据集上平均准确率达到95.5%，并在跨数据集泛化能力上优于现有最佳方法，提高了8.0%和7.7%的ACC分数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages,ICMR accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.12966v1",
      "published_date": "2025-05-19 11:01:49 UTC",
      "updated_date": "2025-05-19 11:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:25:14.101904"
    },
    {
      "arxiv_id": "2505.13567v1",
      "title": "Learning Dynamics of RNNs in Closed-Loop Environments",
      "title_zh": "RNNs 在闭环环境中的学习动态",
      "authors": [
        "Yoav Ger",
        "Omri Barak"
      ],
      "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer\npowerful models of brain computation. However, typical training paradigms rely\non open-loop, supervised settings, whereas real-world learning unfolds in\nclosed-loop environments. Here, we develop a mathematical theory describing the\nlearning dynamics of linear RNNs trained in closed-loop contexts. We first\ndemonstrate that two otherwise identical RNNs, trained in either closed- or\nopen-loop modes, follow markedly different learning trajectories. To probe this\ndivergence, we analytically characterize the closed-loop case, revealing\ndistinct stages aligned with the evolution of the training loss. Specifically,\nwe show that the learning dynamics of closed-loop RNNs, in contrast to\nopen-loop ones, are governed by an interplay between two competing objectives:\nshort-term policy improvement and long-term stability of the agent-environment\ninteraction. Finally, we apply our framework to a realistic motor control task,\nhighlighting its broader applicability. Taken together, our results underscore\nthe importance of modeling closed-loop dynamics in a biologically plausible\nsetting.",
      "tldr_zh": "本研究开发了一个数学理论，描述线性 RNNs 在闭环环境中的学习动态，以更好地模拟现实世界学习过程。作者比较了闭环和开放循环训练的 RNNs，发现二者在学习轨迹上存在显著差异，闭环训练涉及短期策略改进与长期稳定互动的竞争目标。实验分析揭示了闭环学习的不同阶段，并将其应用于现实运动控制任务，强调在生物学上合理的设置中建模闭环动态的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages with 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13567v1",
      "published_date": "2025-05-19 11:00:23 UTC",
      "updated_date": "2025-05-19 11:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:25:25.405279"
    },
    {
      "arxiv_id": "2505.12963v1",
      "title": "Segmentation of temporomandibular joint structures on mri images using neural networks for diagnosis of pathologies",
      "title_zh": "使用神经网络对 MRI 图像上的颞下颌关节结构进行分割以诊断病理",
      "authors": [
        "Maksim I. Ivanov",
        "Olga E. Mendybaeva",
        "Yuri E. Karyakin",
        "Igor N. Glukhikh",
        "Aleksey V. Lebedev"
      ],
      "abstract": "This article explores the use of artificial intelligence for the diagnosis of\npathologies of the temporomandibular joint (TMJ), in particular, for the\nsegmentation of the articular disc on MRI images. The relevance of the work is\ndue to the high prevalence of TMJ pathologies, as well as the need to improve\nthe accuracy and speed of diagnosis in medical institutions. During the study,\nthe existing solutions (Diagnocat, MandSeg) were analyzed, which, as a result,\nare not suitable for studying the articular disc due to the orientation towards\nbone structures. To solve the problem, an original dataset was collected from\n94 images with the classes \"temporomandibular joint\" and \"jaw\". To increase the\namount of data, augmentation methods were used. After that, the models of\nU-Net, YOLOv8n, YOLOv11n and Roboflow neural networks were trained and\ncompared. The evaluation was carried out according to the Dice Score,\nPrecision, Sensitivity, Specificity, and Mean Average Precision metrics. The\nresults confirm the potential of using the Roboflow model for segmentation of\nthe temporomandibular joint. In the future, it is planned to develop an\nalgorithm for measuring the distance between the jaws and determining the\nposition of the articular disc, which will improve the diagnosis of TMJ\npathologies.",
      "tldr_zh": "这篇论文探讨了使用神经网络对 MRI 图像进行颞下颌关节 (TMJ) 结构分割，以诊断 TMJ 病变，旨在提高诊断的准确性和速度。研究团队收集了原创数据集（包括 94 张图像的 \"temporomandibular joint\" 和 \"jaw\" 类），并通过数据增强方法扩充数据，然后训练并比较了 U-Net、YOLOv8n、YOLOv11n 和 Roboflow 模型，使用 Dice Score、Precision、Sensitivity、Specificity 和 Mean Average Precision 等指标进行评估。结果表明，Roboflow 模型在 TMJ 分割方面表现出色，具有潜在应用价值，并计划未来开发算法来测量颌间距离和确定关节盘位置，以进一步改善诊断。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12963v1",
      "published_date": "2025-05-19 10:58:02 UTC",
      "updated_date": "2025-05-19 10:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:25:39.567375"
    },
    {
      "arxiv_id": "2505.12960v1",
      "title": "Hardware-Adaptive and Superlinear-Capacity Memristor-based Associative Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Chengping He",
        "Mingrui Jiang",
        "Keyi Shan",
        "Szu-Hao Yang",
        "Zefan Li",
        "Shengbo Wang",
        "Giacomo Pedretti",
        "Jim Ignowski",
        "Can Li"
      ],
      "abstract": "Brain-inspired computing aims to mimic cognitive functions like associative\nmemory, the ability to recall complete patterns from partial cues. Memristor\ntechnology offers promising hardware for such neuromorphic systems due to its\npotential for efficient in-memory analog computing. Hopfield Neural Networks\n(HNNs) are a classic model for associative memory, but implementations on\nconventional hardware suffer from efficiency bottlenecks, while prior\nmemristor-based HNNs faced challenges with vulnerability to hardware defects\ndue to offline training, limited storage capacity, and difficulty processing\nanalog patterns. Here we introduce and experimentally demonstrate on integrated\nmemristor hardware a new hardware-adaptive learning algorithm for associative\nmemories that significantly improves defect tolerance and capacity, and\nnaturally extends to scalable multilayer architectures capable of handling both\nbinary and continuous patterns. Our approach achieves 3x effective capacity\nunder 50% device faults compared to state-of-the-art methods. Furthermore, its\nextension to multilayer architectures enables superlinear capacity scaling\n(\\(\\propto N^{1.49}\\ for binary patterns) and effective recalling of continuous\npatterns (\\propto N^{1.74}\\ scaling), as compared to linear capacity scaling\nfor previous HNNs. It also provides flexibility to adjust capacity by tuning\nhidden neurons for the same-sized patterns. By leveraging the massive\nparallelism of the hardware enabled by synchronous updates, it reduces energy\nby 8.8x and latency by 99.7% for 64-dimensional patterns over asynchronous\nschemes, with greater improvements at scale. This promises the development of\nmore reliable memristor-based associative memory systems and enables new\napplications research due to the significantly improved capacity, efficiency,\nand flexibility.",
      "tldr_zh": "本文提出了一种硬件适应性学习算法，用于基于 Memristor 的关联记忆系统，旨在提升 Hopfield Neural Networks (HNNs) 的缺陷耐受性、存储容量，并处理二进制和连续模式。该算法在集成 Memristor 硬件上实验验证下，实现 3 倍有效容量（在 50% 设备故障条件下），并通过多层架构实现超线性容量扩展（∝ N^1.49 对于二进制模式，∝ N^1.74 对于连续模式），允许通过调整隐藏神经元灵活优化容量。相比异步方案，该方法利用硬件的并行性，减少能量消耗 8.8 倍和延迟 99.7%，为更可靠的脑启发计算应用提供高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12960v1",
      "published_date": "2025-05-19 10:55:09 UTC",
      "updated_date": "2025-05-19 10:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:25:50.258955"
    },
    {
      "arxiv_id": "2505.13565v1",
      "title": "Aligning Trustworthy AI with Democracy: A Dual Taxonomy of Opportunities and Risks",
      "title_zh": "翻译失败",
      "authors": [
        "Oier Mentxaka",
        "Natalia Díaz-Rodríguez",
        "Mark Coeckelbergh",
        "Marcos López de Prado",
        "Emilia Gómez",
        "David Fernández Llorca",
        "Enrique Herrera-Viedma",
        "Francisco Herrera"
      ],
      "abstract": "Artificial Intelligence (AI) poses both significant risks and valuable\nopportunities for democratic governance. This paper introduces a dual taxonomy\nto evaluate AI's complex relationship with democracy: the AI Risks to Democracy\n(AIRD) taxonomy, which identifies how AI can undermine core democratic\nprinciples such as autonomy, fairness, and trust; and the AI's Positive\nContributions to Democracy (AIPD) taxonomy, which highlights AI's potential to\nenhance transparency, participation, efficiency, and evidence-based\npolicymaking.\n  Grounded in the European Union's approach to ethical AI governance, and\nparticularly the seven Trustworthy AI requirements proposed by the European\nCommission's High-Level Expert Group on AI, each identified risk is aligned\nwith mitigation strategies based on EU regulatory and normative frameworks. Our\nanalysis underscores the transversal importance of transparency and societal\nwell-being across all risk categories and offers a structured lens for aligning\nAI systems with democratic values.\n  By integrating democratic theory with practical governance tools, this paper\noffers a normative and actionable framework to guide research, regulation, and\ninstitutional design to support trustworthy, democratic AI. It provides\nscholars with a conceptual foundation to evaluate the democratic implications\nof AI, equips policymakers with structured criteria for ethical oversight, and\nhelps technologists align system design with democratic principles. In doing\nso, it bridges the gap between ethical aspirations and operational realities,\nlaying the groundwork for more inclusive, accountable, and resilient democratic\nsystems in the algorithmic age.",
      "tldr_zh": "这篇论文提出了一个双重分类法，包括 AI Risks to Democracy (AIRD) 和 AI's Positive Contributions to Democracy (AIPD)，用于评估 AI 对民主治理的风险与机遇。AIRD 识别 AI 如何破坏核心民主原则如自治、公平和信任，并基于欧盟的 Trustworthy AI 要求提供缓解策略；AIPD 则突出 AI 在提升透明度、参与度、效率和基于证据的政策制定方面的潜力。总体框架整合民主理论与实际治理工具，为学者、政策制定者和技术人员提供规范性指导，帮助构建更具包容性、可问责性和弹性的民主系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13565v1",
      "published_date": "2025-05-19 10:51:08 UTC",
      "updated_date": "2025-05-19 10:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:26:02.950195"
    },
    {
      "arxiv_id": "2505.12951v1",
      "title": "DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management",
      "title_zh": "DGRO：通过探索-利用控制和奖励方差管理提升LLM推理",
      "authors": [
        "Xuerui Su",
        "Liya Guo",
        "Yue Wang",
        "Yi Zhu",
        "Zhiming Ma",
        "Zun Wang",
        "Yuting Liu"
      ],
      "abstract": "Inference scaling further accelerates Large Language Models (LLMs) toward\nArtificial General Intelligence (AGI), with large-scale Reinforcement Learning\n(RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning\napproaches usually rely on handcrafted rule-based reward functions. However,\nthe tarde-offs of exploration and exploitation in RL algorithms involves\nmultiple complex considerations, and the theoretical and empirical impacts of\nmanually designed reward functions remain insufficiently explored. In this\npaper, we propose Decoupled Group Reward Optimization (DGRO), a general RL\nalgorithm for LLM reasoning. On the one hand, DGRO decouples the traditional\nregularization coefficient into two independent hyperparameters: one scales the\npolicy gradient term, and the other regulates the distance from the sampling\npolicy. This decoupling not only enables precise control over balancing\nexploration and exploitation, but also can be seamlessly extended to Online\nPolicy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward\nOptimization. On the other hand, we observe that reward variance significantly\naffects both convergence speed and final model performance. We conduct both\ntheoretical analysis and extensive empirical validation to assess DGRO,\nincluding a detailed ablation study that investigates its performance and\noptimization dynamics. Experimental results show that DGRO achieves\nstate-of-the-art performance on the Logic dataset with an average accuracy of\n96.9\\%, and demonstrates strong generalization across mathematical benchmarks.",
      "tldr_zh": "该研究提出 DGRO，一种通用强化学习 (RL) 算法，用于增强大语言模型 (LLMs) 的推理能力，通过解耦正则化系数为两个独立超参数来精确控制探索和利用的平衡，并管理奖励方差以提升收敛速度和性能。DGRO 不仅支持传统策略梯度优化，还扩展到 Online Policy Mirror Descent (OPMD) 等算法，并通过理论分析和实证验证证实其有效性。实验结果显示，DGRO 在 Logic 数据集上实现 96.9% 的平均准确率，并在数学基准上表现出强泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12951v1",
      "published_date": "2025-05-19 10:44:49 UTC",
      "updated_date": "2025-05-19 10:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:26:17.922327"
    },
    {
      "arxiv_id": "2505.13563v1",
      "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohui Wang",
        "Peng Ye",
        "Chenyu Huang",
        "Shenghe Zheng",
        "Bo Zhang",
        "Wanli Ouyang",
        "Tao Chen"
      ],
      "abstract": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression.",
      "tldr_zh": "该论文解决了细调模型存储开销的问题，提出了一种无需数据的UltraDelta管道，用于实现高效的Delta Compression。UltraDelta通过三个关键组件优化压缩：(1) Variance-Based Mixed Sparsity Allocation，根据层间方差分配稀疏度以保留重要信息；(2) Distribution-Aware Compression，使用均匀量化、参数分组和组内剪枝来维护层内分布；(3) Trace-Norm-Guided Rescaling，利用delta权重迹范数估计全局缩放因子，提升模型稳定性。实验结果显示，UltraDelta在大型语言模型（如LLaMA-2 7B和13B，压缩比达133倍）、NLP模型（如RoBERTa-base和T5-base，达800倍）、视觉模型（如ViT-B/32和ViT-L/14，达400倍）及多模态模型（如BEiT-3，达40倍）上，均显著优于现有方法，在超高压缩率下保持了强劲性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13563v1",
      "published_date": "2025-05-19 10:37:22 UTC",
      "updated_date": "2025-05-19 10:37:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:26:26.807059"
    },
    {
      "arxiv_id": "2505.12944v1",
      "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Hagnberger",
        "Daniel Musekamp",
        "Mathias Niepert"
      ],
      "abstract": "Solving time-dependent Partial Differential Equations (PDEs) using a densely\ndiscretized spatial domain is a fundamental problem in various scientific and\nengineering disciplines, including modeling climate phenomena and fluid\ndynamics. However, performing these computations directly in the physical space\noften incurs significant computational costs. To address this issue, several\nneural surrogate models have been developed that operate in a compressed latent\nspace to solve the PDE. While these approaches reduce computational complexity,\nthey often use Transformer-based attention mechanisms to handle irregularly\nsampled domains, resulting in increased memory consumption. In contrast,\nconvolutional neural networks allow memory-efficient encoding and decoding but\nare limited to regular discretizations. Motivated by these considerations, we\npropose CALM-PDE, a model class that efficiently solves arbitrarily discretized\nPDEs in a compressed latent space. We introduce a novel continuous\nconvolution-based encoder-decoder architecture that uses an\nepsilon-neighborhood-constrained kernel and learns to apply the convolution\noperator to adaptive and optimized query points. We demonstrate the\neffectiveness of CALM-PDE on a diverse set of PDEs with both regularly and\nirregularly sampled spatial domains. CALM-PDE is competitive with or\noutperforms existing baseline methods while offering significant improvements\nin memory and inference time efficiency compared to Transformer-based methods.",
      "tldr_zh": "该研究针对时间相关的偏微分方程 (PDEs) 在密集空间域中的高计算成本问题，提出了一种名为 CALM-PDE 的模型，用于在压缩潜在空间中高效求解任意离散化的 PDEs。CALM-PDE 引入了新型的连续和自适应卷积架构，包括 epsilon-neighborhood-constrained kernel 和自适应优化查询点，从而克服了传统卷积神经网络对规则离散化的限制，同时避免了 Transformer-based 方法的内存消耗问题。在多种 PDEs 测试中，CALM-PDE 与现有基线方法相比表现出色，并在内存和推理时间效率上实现了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12944v1",
      "published_date": "2025-05-19 10:31:30 UTC",
      "updated_date": "2025-05-19 10:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:26:37.784101"
    },
    {
      "arxiv_id": "2505.12942v1",
      "title": "A3 : an Analytical Low-Rank Approximation Framework for Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffrey T. H. Wong",
        "Cheng Zhang",
        "Xinye Cao",
        "Pedro Gimenes",
        "George A. Constantinides",
        "Wayne Luk",
        "Yiren Zhao"
      ],
      "abstract": "Large language models have demonstrated remarkable performance; however,\ntheir massive parameter counts make deployment highly expensive. Low-rank\napproximation offers a promising compression solution, yet existing approaches\nhave two main limitations: (1) They focus on minimizing the output error of\nindividual linear layers, without considering the architectural characteristics\nof Transformers, and (2) they decompose a large weight matrix into two small\nlow-rank matrices. Consequently, these methods often fall short compared to\nother compression techniques like pruning and quantization, and introduce\nruntime overhead such as the extra GEMM kernel launches for decomposed small\nmatrices. To address these limitations, we propose $\\tt A^\\tt 3$, a\npost-training low-rank approximation framework. $\\tt A^\\tt 3$ splits a\nTransformer layer into three functional components, namely $\\tt QK$, $\\tt OV$,\nand $\\tt MLP$. For each component, $\\tt A^\\tt 3$ provides an analytical\nsolution that reduces the hidden dimension size inside each component while\nminimizing the component's functional loss ($\\it i.e.$, error in attention\nscores, attention outputs, and MLP outputs). This approach directly reduces\nmodel sizes, KV cache sizes, and FLOPs without introducing any runtime\noverheads. In addition, it provides a new narrative in advancing the\noptimization problem from singular linear layer loss optimization toward\nimproved end-to-end performance. Through extensive experiments, we show that\n$\\tt A^\\tt 3$ maintains superior performance compared to SoTAs. For example,\nunder the same reduction budget in computation and memory, our low-rank\napproximated LLaMA 3.1-70B achieves a perplexity of 4.69 on WikiText-2,\noutperforming the previous SoTA's 7.87 by 3.18. We also demonstrate the\nversatility of $\\tt A^\\tt 3$, including KV cache compression, quantization, and\nmixed-rank assignments for enhanced performance.",
      "tldr_zh": "这篇论文提出了A3，一个后训练低秩近似框架，针对Transformer模型的注意力机制，解决现有方法忽略架构特性和引入运行时开销的问题。A3将Transformer层分解为QK、OV和MLP三个功能组件，并为每个组件提供分析解决方案，以减少隐藏维度大小并最小化功能损失（如注意力分数和输出错误），从而直接降低模型大小、KV缓存大小和FLOPs。实验结果显示，A3在相同计算和内存减少预算下，使LLaMA 3.1-70B在WikiText-2上的困惑度达到4.69，比现有SOTA方法低3.18，并展示了其在KV缓存压缩、量化及混合秩分配方面的多功能性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12942v1",
      "published_date": "2025-05-19 10:29:32 UTC",
      "updated_date": "2025-05-19 10:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:26:51.750178"
    },
    {
      "arxiv_id": "2505.12938v2",
      "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Uri Dalal",
        "Meirav Segal",
        "Zvika Ben-Haim",
        "Dan Lahav",
        "Omer Nevo"
      ],
      "abstract": "Large language models (LLMs) achieve impressive abilities in numerous\ndomains, but exhibit inconsistent performance in response to minor input\nchanges. Rather than view this as a drawback, in this paper we introduce a\nnovel method for leveraging models' inconsistency to boost Pass@k performance.\nSpecifically, we present a \"Variator\" agent that generates k variants of a\ngiven task and submits one candidate solution for each one. Our variant\ngeneration approach is applicable to a wide range of domains as it is task\nagnostic and compatible with free-form inputs. We demonstrate the efficacy of\nour agent theoretically using a probabilistic model of the inconsistency\neffect, and show empirically that it outperforms the baseline on the APPS\ndataset. Furthermore, we establish that inconsistency persists even in frontier\nreasoning models across coding and cybersecurity domains, suggesting our method\nis likely to remain relevant for future model generations.",
      "tldr_zh": "本文提出了一种创新方法，利用大型语言模型(LLMs)的输入不一致性来提升Pass@k性能，而不是将其视为缺点。作者引入了\"Variator\"代理，该代理为给定任务生成k个变体，并为每个变体提交候选解决方案，这种任务无关的方法适用于广泛领域，包括自由形式输入。实验结果显示，该方法在APPS数据集上优于基线模型，并在理论和实证上证明其有效性；此外，不一致性在前沿推理模型（如编码和网络安全领域）中持续存在，表明该方法对未来模型发展仍有重要意义。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12938v2",
      "published_date": "2025-05-19 10:22:04 UTC",
      "updated_date": "2025-05-20 14:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:27:02.359083"
    },
    {
      "arxiv_id": "2505.12929v1",
      "title": "Do Not Let Low-Probability Tokens Over-Dominate in RL for LLMs",
      "title_zh": "不要让低概率标记在强化学习中过度主导大型语言模型",
      "authors": [
        "Zhihe Yang",
        "Xufang Luo",
        "Zilong Wang",
        "Dongqi Han",
        "Zhiyuan He",
        "Dongsheng Li",
        "Yunjian Xu"
      ],
      "abstract": "Reinforcement learning (RL) has become a cornerstone for enhancing the\nreasoning capabilities of large language models (LLMs), with recent innovations\nsuch as Group Relative Policy Optimization (GRPO) demonstrating exceptional\neffectiveness. In this study, we identify a critical yet underexplored issue in\nRL training: low-probability tokens disproportionately influence model updates\ndue to their large gradient magnitudes. This dominance hinders the effective\nlearning of high-probability tokens, whose gradients are essential for LLMs'\nperformance but are substantially suppressed. To mitigate this interference, we\npropose two novel methods: Advantage Reweighting and Low-Probability Token\nIsolation (Lopti), both of which effectively attenuate gradients from\nlow-probability tokens while emphasizing parameter updates driven by\nhigh-probability tokens. Our approaches promote balanced updates across tokens\nwith varying probabilities, thereby enhancing the efficiency of RL training.\nExperimental results demonstrate that they substantially improve the\nperformance of GRPO-trained LLMs, achieving up to a 46.2% improvement in K&K\nLogic Puzzle reasoning tasks. Our implementation is available at\nhttps://github.com/zhyang2226/AR-Lopti.",
      "tldr_zh": "本研究发现，在强化学习 (RL) 训练大型语言模型 (LLMs) 时，低概率标记 (low-probability tokens) 由于其较大梯度幅度而过度主导模型更新，从而抑制高概率标记的学习效率。针对这一问题，作者提出两种新方法：Advantage Reweighting 和 Low-Probability Token Isolation (Lopti)，这些方法通过减弱低概率标记的梯度影响并强调高概率标记的更新，实现对不同概率标记的平衡优化。实验结果显示，该方法显著提升了基于 Group Relative Policy Optimization (GRPO) 的 LLMs 性能，在 K&K Logic Puzzle 推理任务中实现高达 46.2% 的改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12929v1",
      "published_date": "2025-05-19 10:14:08 UTC",
      "updated_date": "2025-05-19 10:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:27:13.964189"
    },
    {
      "arxiv_id": "2505.12925v1",
      "title": "CPRet: A Dataset, Benchmark, and Model for Retrieval in Competitive Programming",
      "title_zh": "CPRet：一个用于竞争性编程检索的数据集、基准和模型",
      "authors": [
        "Han Deng",
        "Yuan Meng",
        "Shixiang Tang",
        "Wanli Ouyang",
        "Xinzhu Ma"
      ],
      "abstract": "Competitive programming benchmarks are widely used in scenarios such as\nprogramming contests and large language model assessments. However, the growing\npresence of duplicate or highly similar problems raises concerns not only about\ncompetition fairness, but also about the validity of competitive programming as\na benchmark for model evaluation. In this paper, we propose a new problem --\nsimilar question retrieval -- to address this issue. Due to the lack of both\ndata and models, solving this problem is challenging. To this end, we introduce\nCPRet, a retrieval-oriented benchmark suite for competitive programming,\ncovering four retrieval tasks: two code-centric (i.e., Text-to-Code and\nCode-to-Code) and two newly proposed problem-centric tasks (i.e.,\nProblem-to-Duplicate and Simplified-to-Full), built from a combination of\nautomatically crawled problem-solution data and manually curated annotations.\nOur contribution includes both high-quality training data and temporally\nseparated test sets for reliable evaluation. In addition, we develop two\ntask-specialized retrievers based on this dataset: CPRetriever-Code, trained\nwith a novel Group-InfoNCE loss for problem-code alignment, and\nCPRetriever-Prob, fine-tuned for identifying problem-level similarity. Both\nmodels achieve strong results and are open-sourced for local use. Finally, we\nanalyze LiveCodeBench and find that high-similarity problems inflate model pass\nrates and reduce differentiation, underscoring the need for similarity-aware\nevaluation in future benchmarks.\n  Code and data are available at: https://github.com/coldchair/CPRet",
      "tldr_zh": "这篇论文针对竞争性编程中重复或相似问题的公平性和基准有效性问题，提出了 CPRet 数据集、基准和模型，以解决类似问题检索的新挑战。CPRet 包括四个检索任务：Text-to-Code、Code-to-Code、Problem-to-Duplicate 和 Simplified-to-Full，这些任务基于自动爬取的数据和手动注释构建，并提供高质量训练数据和时间分离的测试集。作者开发了两个专用模型：CPRetriever-Code，使用新型 Group-InfoNCE 损失进行问题-代码对齐训练，以及 CPRetriever-Prob，用于识别问题级相似性；这些模型表现出色并开源可用。最后，通过分析 LiveCodeBench，他们发现高相似性问题会夸大模型通过率并降低区分度，强调未来基准需引入相似性感知评估。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR",
        "H.3.3"
      ],
      "primary_category": "cs.SE",
      "comment": "main 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12925v1",
      "published_date": "2025-05-19 10:07:51 UTC",
      "updated_date": "2025-05-19 10:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:27:27.156288"
    },
    {
      "arxiv_id": "2505.13562v1",
      "title": "Randomised Optimism via Competitive Co-Evolution for Matrix Games with Bandit Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Shishen Lin"
      ],
      "abstract": "Learning in games is a fundamental problem in machine learning and artificial\nintelligence, with numerous\napplications~\\citep{silver2016mastering,schrittwieser2020mastering}. This work\ninvestigates two-player zero-sum matrix games with an unknown payoff matrix and\nbandit feedback, where each player observes their actions and the corresponding\nnoisy payoff. Prior studies have proposed algorithms for this\nsetting~\\citep{o2021matrix,maiti2023query,cai2024uncoupled}, with\n\\citet{o2021matrix} demonstrating the effectiveness of deterministic optimism\n(e.g., \\ucb) in achieving sublinear regret. However, the potential of\nrandomised optimism in matrix games remains theoretically unexplored.\n  We propose Competitive Co-evolutionary Bandit Learning (\\coebl), a novel\nalgorithm that integrates evolutionary algorithms (EAs) into the bandit\nframework to implement randomised optimism through EA variation operators. We\nprove that \\coebl achieves sublinear regret, matching the performance of\ndeterministic optimism-based methods. To the best of our knowledge, this is the\nfirst theoretical regret analysis of an evolutionary bandit learning algorithm\nin matrix games.\n  Empirical evaluations on diverse matrix game benchmarks demonstrate that\n\\coebl not only achieves sublinear regret but also consistently outperforms\nclassical bandit algorithms, including \\exptr~\\citep{auer2002nonstochastic},\nthe variant \\exptrni~\\citep{cai2024uncoupled}, and \\ucb~\\citep{o2021matrix}.\nThese results highlight the potential of evolutionary bandit learning,\nparticularly the efficacy of randomised optimism via evolutionary algorithms in\ngame-theoretic settings.",
      "tldr_zh": "该研究探讨了未知回报矩阵的两玩家零和矩阵游戏学习问题，在bandit feedback设置下，每个玩家仅观察自身行动和噪音回报。作者提出了一种新算法Competitive Co-evolutionary Bandit Learning (CoEBL)，通过整合进化算法(EAs)的变异操作来实现随机乐观，并证明该算法可实现次线性 regret，与确定性方法相当，这是首个对进化bandit学习算法在矩阵游戏中的理论分析。实验结果显示，CoEBL在多种矩阵游戏基准上优于经典算法如Exp3、Exp3-IX和UCB，不仅达到次线性regret，还展示了随机乐观在游戏理论中的潜力。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "stat.ML",
      "comment": "21 pages, 10 figures, accepted at IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13562v1",
      "published_date": "2025-05-19 10:05:55 UTC",
      "updated_date": "2025-05-19 10:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:27:38.095019"
    },
    {
      "arxiv_id": "2505.12923v1",
      "title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations",
      "title_zh": "The Traitors：多智能体语言模型模拟中的欺骗和信任",
      "authors": [
        "Pedro M. P. Curvo"
      ],
      "abstract": "As AI systems increasingly assume roles where trust and alignment with human\nvalues are essential, understanding when and why they engage in deception has\nbecome a critical research priority. We introduce The Traitors, a multi-agent\nsimulation framework inspired by social deduction games, designed to probe\ndeception, trust formation, and strategic communication among large language\nmodel (LLM) agents under asymmetric information. A minority of agents the\ntraitors seek to mislead the majority, while the faithful must infer hidden\nidentities through dialogue and reasoning. Our contributions are: (1) we ground\nthe environment in formal frameworks from game theory, behavioral economics,\nand social cognition; (2) we develop a suite of evaluation metrics capturing\ndeception success, trust dynamics, and collective inference quality; (3) we\nimplement a fully autonomous simulation platform where LLMs reason over\npersistent memory and evolving social dynamics, with support for heterogeneous\nagent populations, specialized traits, and adaptive behaviors. Our initial\nexperiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model)\nreveal a notable asymmetry: advanced models like GPT-4o demonstrate superior\ndeceptive capabilities yet exhibit disproportionate vulnerability to others'\nfalsehoods. This suggests deception skills may scale faster than detection\nabilities. Overall, The Traitors provides a focused, configurable testbed for\ninvestigating LLM behavior in socially nuanced interactions. We position this\nwork as a contribution toward more rigorous research on deception mechanisms,\nalignment challenges, and the broader social reliability of AI systems.",
      "tldr_zh": "该论文引入了“The Traitors”框架，这是一个受社会演绎游戏启发的多智能体模拟环境，用于探究大型语言模型(LLM)代理在不对称信息下的欺骗行为、信任形成和战略沟通。该框架基于game theory、behavioral economics和社会认知的正式框架，并开发了评估指标来衡量欺骗成功率、信任动态和集体推理质量；同时，实现了一个完全自治的模拟平台，支持LLM代理在持久记忆和演变的社会动态中进行推理。实验结果显示，高级模型如GPT-4o在欺骗能力上表现出色，但更易受其他代理的欺骗，表明欺骗技能可能比检测能力增长更快。该框架为研究LLM的欺骗机制、对齐挑战和社会可靠性提供了可配置的测试平台。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "9 main pages, 31 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12923v1",
      "published_date": "2025-05-19 10:01:35 UTC",
      "updated_date": "2025-05-19 10:01:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:27:51.619362"
    },
    {
      "arxiv_id": "2505.12920v1",
      "title": "PyFCG: Fluid Construction Grammar in Python",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Van Eecke",
        "Katrien Beuls"
      ],
      "abstract": "We present PyFCG, an open source software library that ports Fluid\nConstruction Grammar (FCG) to the Python programming language. PyFCG enables\nits users to seamlessly integrate FCG functionality into Python programs, and\nto use FCG in combination with other libraries within Python's rich ecosystem.\nApart from a general description of the library, this paper provides three\nwalkthrough tutorials that demonstrate example usage of PyFCG in typical use\ncases of FCG: (i) formalising and testing construction grammar analyses, (ii)\nlearning usage-based construction grammars from corpora, and (iii) implementing\nagent-based experiments on emergent communication.",
      "tldr_zh": "本论文介绍了 PyFCG，这是一个开源软件库，将 Fluid Construction Grammar (FCG) 移植到 Python 语言中。PyFCG 允许用户无缝地将 FCG 功能集成到 Python 程序中，并与其他 Python 库结合使用，从而增强其灵活性和扩展性。论文提供了三个教程，展示 PyFCG 在典型应用中的示例：(i) 形式化和测试构式语法分析，(ii) 从语料库中学习基于使用的构式语法，以及 (iii) 实现基于代理的紧急通信实验。总的来说，这为 FCG 的实际应用提供了更便捷的工具，支持了语言学和计算实验的创新。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12920v1",
      "published_date": "2025-05-19 10:00:01 UTC",
      "updated_date": "2025-05-19 10:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:28:02.622964"
    },
    {
      "arxiv_id": "2505.14718v1",
      "title": "Enhancing Shape Perception and Segmentation Consistency for Industrial Image Inspection",
      "title_zh": "针对工业图像检查的形状感知和分割一致性增强",
      "authors": [
        "Guoxuan Mao",
        "Ting Cao",
        "Ziyang Li",
        "Yuan Dong"
      ],
      "abstract": "Semantic segmentation stands as a pivotal research focus in computer vision.\nIn the context of industrial image inspection, conventional semantic\nsegmentation models fail to maintain the segmentation consistency of fixed\ncomponents across varying contextual environments due to a lack of perception\nof object contours. Given the real-time constraints and limited computing\ncapability of industrial image detection machines, it is also necessary to\ncreate efficient models to reduce computational complexity. In this work, a\nShape-Aware Efficient Network (SPENet) is proposed, which focuses on the shapes\nof objects to achieve excellent segmentation consistency by separately\nsupervising the extraction of boundary and body information from images. In\nSPENet, a novel method is introduced for describing fuzzy boundaries to better\nadapt to real-world scenarios named Variable Boundary Domain (VBD).\nAdditionally, a new metric, Consistency Mean Square Error(CMSE), is proposed to\nmeasure segmentation consistency for fixed components. Our approach attains the\nbest segmentation accuracy and competitive speed on our dataset, showcasing\nsignificant advantages in CMSE among numerous state-of-the-art real-time\nsegmentation networks, achieving a reduction of over 50% compared to the\npreviously top-performing models.",
      "tldr_zh": "这篇论文针对工业图像检查中的语义分割问题，指出传统模型因缺乏物体轮廓感知而无法保持固定组件在不同环境下的分割一致性，同时强调了高效模型的需求以满足实时计算约束。作者提出了一种Shape-Aware Efficient Network (SPENet)，通过分离监督图像的边界和主体信息提取，并引入Variable Boundary Domain (VBD)来更好地处理真实场景中的模糊边界。实验结果显示，SPENet在数据集上取得了最佳的分割准确率和竞争性速度，并在Consistency Mean Square Error (CMSE)指标上比最先进实时网络降低了超过50%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14718v1",
      "published_date": "2025-05-19 09:57:00 UTC",
      "updated_date": "2025-05-19 09:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:28:16.441164"
    },
    {
      "arxiv_id": "2505.12910v1",
      "title": "SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Le Cheng",
        "Peican Zhu",
        "Yangming Guo",
        "Chao Gao",
        "Zhen Wang",
        "Keke Tang"
      ],
      "abstract": "Source detection on graphs has demonstrated high efficacy in identifying\nrumor origins. Despite advances in machine learning-based methods, many fail to\ncapture intrinsic dynamics of rumor propagation. In this work, we present\nSourceDetMamba: A Graph-aware State Space Model for Source Detection in\nSequential Hypergraphs, which harnesses the recent success of the state space\nmodel Mamba, known for its superior global modeling capabilities and\ncomputational efficiency, to address this challenge. Specifically, we first\nemploy hypergraphs to model high-order interactions within social networks.\nSubsequently, temporal network snapshots generated during the propagation\nprocess are sequentially fed in reverse order into Mamba to infer underlying\npropagation dynamics. Finally, to empower the sequential model to effectively\ncapture propagation patterns while integrating structural information, we\npropose a novel graph-aware state update mechanism, wherein the state of each\nnode is propagated and refined by both temporal dependencies and topological\ncontext. Extensive evaluations on eight datasets demonstrate that\nSourceDetMamba consistently outperforms state-of-the-art approaches.",
      "tldr_zh": "这篇论文提出了 SourceDetMamba，一种图感知状态空间模型，用于在顺序超图（Sequential Hypergraphs）中检测谣言来源，旨在捕捉社交网络的高阶交互和传播动态。模型基于 Mamba 的全局建模能力和计算效率，将传播过程中的时间网络快照逆序输入，并引入新型图感知状态更新机制，结合时间依赖性和拓扑上下文来优化节点状态的传播和精炼。在八个数据集上的广泛评估中，SourceDetMamba  consistently outperforms 现有最先进的方法，展示了其在源检测任务中的显著优势。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by IJCAI25",
      "pdf_url": "http://arxiv.org/pdf/2505.12910v1",
      "published_date": "2025-05-19 09:45:27 UTC",
      "updated_date": "2025-05-19 09:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:28:27.047072"
    },
    {
      "arxiv_id": "2505.12909v2",
      "title": "Sinusoidal Initialization, Time for a New Start",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Fernández-Hernández",
        "Jose I. Mestre",
        "Manuel F. Dolz",
        "Jose Duato",
        "Enrique S. Quintana-Ortí"
      ],
      "abstract": "Initialization plays a critical role in Deep Neural Network training,\ndirectly influencing convergence, stability, and generalization. Common\napproaches such as Glorot and He initializations rely on randomness, which can\nproduce uneven weight distributions across layer connections. In this paper, we\nintroduce the Sinusoidal initialization, a novel deterministic method that\nemploys sinusoidal functions to construct structured weight matrices expressly\nto improve the spread and balance of weights throughout the network while\nsimultaneously fostering a more uniform, well-conditioned distribution of\nneuron activation states from the very first forward pass. Because Sinusoidal\ninitialization begins with weights and activations that are already evenly and\nefficiently utilized, it delivers consistently faster convergence, greater\ntraining stability, and higher final accuracy across a wide range of models,\nincluding convolutional neural networks, vision transformers, and large\nlanguage models. On average, our experiments show an increase of 4.9% in final\nvalidation accuracy and 20.9% in convergence speed. By replacing randomness\nwith structure, this initialization provides a stronger and more reliable\nfoundation for Deep Learning systems.",
      "tldr_zh": "本研究强调神经网络初始化的重要性，指出传统如 Glorot 和 He initializations 的随机方法可能导致权重分布不均匀，从而影响收敛、稳定性和泛化。论文提出 Sinusoidal initialization，一种新型确定性方法，使用正弦函数构建结构化的权重矩阵，以实现权重和神经元激活状态的均匀分布，从第一次前向传播开始提升网络性能。该方法在各种模型（如 CNN、Vision Transformers 和 large language models）上实验显示，最终验证准确率平均提高4.9%，收敛速度提高20.9%，从而为深度学习系统提供更可靠的基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2; G.3; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12909v2",
      "published_date": "2025-05-19 09:45:18 UTC",
      "updated_date": "2025-05-20 15:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:28:39.809702"
    },
    {
      "arxiv_id": "2505.12908v1",
      "title": "Dynamic Graph Induced Contour-aware Heat Conduction Network for Event-based Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Yu Jin",
        "Lan Chen",
        "Bo Jiang",
        "Lin Zhu",
        "Yonghong Tian",
        "Jin Tang",
        "Bin Luo"
      ],
      "abstract": "Event-based Vision Sensors (EVS) have demonstrated significant advantages\nover traditional RGB frame-based cameras in low-light conditions, high-speed\nmotion capture, and low latency. Consequently, object detection based on EVS\nhas attracted increasing attention from researchers. Current event stream\nobject detection algorithms are typically built upon Convolutional Neural\nNetworks (CNNs) or Transformers, which either capture limited local features\nusing convolutional filters or incur high computational costs due to the\nutilization of self-attention. Recently proposed vision heat conduction\nbackbone networks have shown a good balance between efficiency and accuracy;\nhowever, these models are not specifically designed for event stream data. They\nexhibit weak capability in modeling object contour information and fail to\nexploit the benefits of multi-scale features. To address these issues, this\npaper proposes a novel dynamic graph induced contour-aware heat conduction\nnetwork for event stream based object detection, termed CvHeat-DET. The\nproposed model effectively leverages the clear contour information inherent in\nevent streams to predict the thermal diffusivity coefficients within the heat\nconduction model, and integrates hierarchical structural graph features to\nenhance feature learning across multiple scales. Extensive experiments on three\nbenchmark datasets for event stream-based object detection fully validated the\neffectiveness of the proposed model. The source code of this paper will be\nreleased on https://github.com/Event-AHU/OpenEvDET.",
      "tldr_zh": "这篇论文针对事件流物体检测的问题，提出了一种新型动态图诱导的轮廓感知热传导网络（CvHeat-DET），以解决基于CNNs或Transformers的方法在捕捉局部特征和计算效率方面的局限性。该模型利用事件流（Event-based Vision Sensors, EVS）中固有的清晰轮廓信息来预测热传导模型的热扩散系数，并整合层次结构图特征来增强多尺度特征学习。实验结果在三个基准数据集上充分验证了CvHeat-DET的有效性，展示了其在效率和准确性之间的良好平衡。源代码将在GitHub上发布。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12908v1",
      "published_date": "2025-05-19 09:44:01 UTC",
      "updated_date": "2025-05-19 09:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:28:53.694016"
    },
    {
      "arxiv_id": "2505.12904v1",
      "title": "The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hilde I. Hummel",
        "Arwin Gansekoele",
        "Sandjai Bhulai",
        "Rob van der Mei"
      ],
      "abstract": "The increasing level of sound pollution in marine environments poses an\nincreased threat to ocean health, making it crucial to monitor underwater\nnoise. By monitoring this noise, the sources responsible for this pollution can\nbe mapped. Monitoring is performed by passively listening to these sounds. This\ngenerates a large amount of data records, capturing a mix of sound sources such\nas ship activities and marine mammal vocalizations. Although machine learning\noffers a promising solution for automatic sound classification, current\nstate-of-the-art methods implement supervised learning. This requires a large\namount of high-quality labeled data that is not publicly available. In\ncontrast, a massive amount of lower-quality unlabeled data is publicly\navailable, offering the opportunity to explore unsupervised learning\ntechniques. This research explores this possibility by implementing an\nunsupervised Contrastive Learning approach. Here, a Conformer-based encoder is\noptimized by the so-called Variance-Invariance-Covariance Regularization loss\nfunction on these lower-quality unlabeled data and the translation to the\nlabeled data is made. Through classification tasks involving recognizing ship\ntypes and marine mammal vocalizations, our method demonstrates to produce\nrobust and generalized embeddings. This shows to potential of unsupervised\nmethods for various automatic underwater acoustic analysis tasks.",
      "tldr_zh": "本研究针对海洋噪音监测面临的标签数据短缺问题，提出了一种基于无监督对比学习（Contrastive Learning）的框架，用于计算泛化嵌入（generalized embeddings）。方法采用 Conformer-based 编码器，并通过 Variance-Invariance-Covariance Regularization 损失函数在低质量无标签数据上进行优化，然后转移到有标签数据。实验结果显示，该方法在识别船只类型和海洋哺乳动物声音的分类任务中表现出色，产生了鲁棒的嵌入。总体上，这证明了无监督技术在各种水下声学分析任务中的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12904v1",
      "published_date": "2025-05-19 09:37:46 UTC",
      "updated_date": "2025-05-19 09:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:29:04.972843"
    },
    {
      "arxiv_id": "2505.12903v1",
      "title": "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Shiao Wang",
        "Xiao Wang",
        "Liye Jin",
        "Bo Jiang",
        "Lin Zhu",
        "Lan Chen",
        "Yonghong Tian",
        "Bin Luo"
      ],
      "abstract": "Existing tracking algorithms typically rely on low-frame-rate RGB cameras\ncoupled with computationally intensive deep neural network architectures to\nachieve effective tracking. However, such frame-based methods inherently face\nchallenges in achieving low-latency performance and often fail in\nresource-constrained environments. Visual object tracking using bio-inspired\nevent cameras has emerged as a promising research direction in recent years,\noffering distinct advantages for low-latency applications. In this paper, we\npropose a novel Slow-Fast Tracking paradigm that flexibly adapts to different\noperational requirements, termed SFTrack. The proposed framework supports two\ncomplementary modes, i.e., a high-precision slow tracker for scenarios with\nsufficient computational resources, and an efficient fast tracker tailored for\nlatency-aware, resource-constrained environments. Specifically, our framework\nfirst performs graph-based representation learning from\nhigh-temporal-resolution event streams, and then integrates the learned\ngraph-structured information into two FlashAttention-based vision backbones,\nyielding the slow and fast trackers, respectively. The fast tracker achieves\nlow latency through a lightweight network design and by producing multiple\nbounding box outputs in a single forward pass. Finally, we seamlessly combine\nboth trackers via supervised fine-tuning and further enhance the fast tracker's\nperformance through a knowledge distillation strategy. Extensive experiments on\npublic benchmarks, including FE240, COESOT, and EventVOT, demonstrate the\neffectiveness and efficiency of our proposed method across different real-world\nscenarios. The source code has been released on\nhttps://github.com/Event-AHU/SlowFast_Event_Track.",
      "tldr_zh": "该论文针对传统基于低帧率 RGB 相机的视觉对象跟踪算法存在的延迟高和资源限制问题，提出了一种基于事件流的 Slow-Fast Tracking 范式，名为 SFTrack。框架包括一个高精度慢速跟踪器（适用于资源充足场景）和一个高效快速跟踪器（通过轻量级网络和单次前向传递输出多个边界框，实现低延迟）。具体方法涉及从高时间分辨率事件流进行 graph-based representation learning，并整合到 FlashAttention-based 视觉骨干网络中，同时通过监督微调和 knowledge distillation 策略优化性能。在 FE240、COESOT 和 EventVOT 等基准上的实验证明，SFTrack 在实时性和准确性方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12903v1",
      "published_date": "2025-05-19 09:37:23 UTC",
      "updated_date": "2025-05-19 09:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:29:17.859222"
    },
    {
      "arxiv_id": "2505.12900v1",
      "title": "AutoGEEval: A Multimodal and Automated Framework for Geospatial Code Generation on GEE with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyang Hou",
        "Zhangxiao Shen",
        "Huayi Wu",
        "Jianyuan Liang",
        "Haoyue Jiao",
        "Yaxian Qing",
        "Xiaopu Zhang",
        "Xu Li",
        "Zhipeng Gui",
        "Xuefeng Guan",
        "Longgang Xiang"
      ],
      "abstract": "Geospatial code generation is emerging as a key direction in the integration\nof artificial intelligence and geoscientific analysis. However, there remains a\nlack of standardized tools for automatic evaluation in this domain. To address\nthis gap, we propose AutoGEEval, the first multimodal, unit-level automated\nevaluation framework for geospatial code generation tasks on the Google Earth\nEngine (GEE) platform powered by large language models (LLMs). Built upon the\nGEE Python API, AutoGEEval establishes a benchmark suite (AutoGEEval-Bench)\ncomprising 1325 test cases that span 26 GEE data types. The framework\nintegrates both question generation and answer verification components to\nenable an end-to-end automated evaluation pipeline-from function invocation to\nexecution validation. AutoGEEval supports multidimensional quantitative\nanalysis of model outputs in terms of accuracy, resource consumption, execution\nefficiency, and error types. We evaluate 18 state-of-the-art LLMs-including\ngeneral-purpose, reasoning-augmented, code-centric, and geoscience-specialized\nmodels-revealing their performance characteristics and potential optimization\npathways in GEE code generation. This work provides a unified protocol and\nfoundational resource for the development and assessment of geospatial code\ngeneration models, advancing the frontier of automated natural language to\ndomain-specific code translation.",
      "tldr_zh": "本文提出 AutoGEEval，这是一个多模态自动化框架，利用大型语言模型(LLMs)评估 Google Earth Engine (GEE) 上的地理空间代码生成任务，以填补标准化评估工具的空白。该框架基于 GEE Python API，建立了一个包含 1325 个测试案例的基准套件(AutoGEEval-Bench)，覆盖 26 种数据类型，并集成问题生成、答案验证和多维度分析（如准确性、资源消耗、执行效率和错误类型）。通过评估 18 个最先进 LLMs（包括通用、推理增强、代码导向和地理科学专用模型），研究揭示了这些模型的性能特征和优化路径，为自然语言到领域特定代码的自动翻译提供了统一协议和基础资源。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CG",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12900v1",
      "published_date": "2025-05-19 09:35:58 UTC",
      "updated_date": "2025-05-19 09:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:29:30.124526"
    },
    {
      "arxiv_id": "2505.14717v1",
      "title": "Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Xigui Li",
        "Yuanye Zhou",
        "Feiyang Xiao",
        "Xin Guo",
        "Chen Jiang",
        "Tan Pan",
        "Xingmeng Zhang",
        "Cenyu Liu",
        "Zeyun Miao",
        "Jianchao Ge",
        "Xiansheng Wang",
        "Qimeng Wang",
        "Yichi Zhang",
        "Wenbo Zhang",
        "Fengping Zhu",
        "Limei Han",
        "Yuan Qi",
        "Chensen Lin",
        "Yuan Cheng"
      ],
      "abstract": "Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in\napproximately 5\\% of the general population. Their rupture may lead to high\nmortality. Current methods for assessing IA risk focus on morphological and\npatient-specific factors, but the hemodynamic influences on IA development and\nrupture remain unclear. While accurate for hemodynamic studies, conventional\ncomputational fluid dynamics (CFD) methods are computationally intensive,\nhindering their deployment in large-scale or real-time clinical applications.\nTo address this challenge, we curated a large-scale, high-fidelity aneurysm CFD\ndataset to facilitate the development of efficient machine learning algorithms\nfor such applications. Based on 427 real aneurysm geometries, we synthesized\n10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The\nauthenticity of these synthetic shapes was confirmed by neurosurgeons. CFD\ncomputations were performed on each shape under eight steady-state mass flow\nconditions, generating a total of 85,280 blood flow dynamics data covering key\nparameters. Furthermore, the dataset includes segmentation masks, which can\nsupport tasks that use images, point clouds or other multimodal data as input.\nAdditionally, we introduced a benchmark for estimating flow parameters to\nassess current modeling methods. This dataset aims to advance aneurysm research\nand promote data-driven approaches in biofluids, biomedical engineering, and\nclinical risk assessment. The code and dataset are available at:\nhttps://github.com/Xigui-Li/Aneumo.",
      "tldr_zh": "该研究构建了 Aneumo 数据集，这是一个大规模多模态颅内动脉瘤 (IAs) 数据集，包含计算流体动力学 (CFD) 模拟数据，以解决传统 CFD 方法在临床应用中计算密集的问题。数据集基于 427 个真实动脉瘤几何形状，通过受控变形合成 10,660 个 3D 形状，并进行八种稳态质量流条件下的 CFD 计算，生成 85,280 个血流动力学参数数据，同时包括分割掩码以支持图像、点云等多模态任务。研究者还引入了一个基准，用于评估流参数估计的机器学习模型。该数据集旨在推进动脉瘤研究，促进数据驱动方法在生物流体、生物医学工程和临床风险评估中的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14717v1",
      "published_date": "2025-05-19 09:32:09 UTC",
      "updated_date": "2025-05-19 09:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:29:41.498095"
    },
    {
      "arxiv_id": "2505.13561v1",
      "title": "Language and Thought: The View from LLMs",
      "title_zh": "语言与思想：从LLMs的视角",
      "authors": [
        "Daniel Rothschild"
      ],
      "abstract": "Daniel Dennett speculated in *Kinds of Minds* 1996: \"Perhaps the kind of mind\nyou get when you add language to it is so different from the kind of mind you\ncan have without language that calling them both minds is a mistake.\" Recent\nwork in AI can be seen as testing Dennett's thesis by exploring the performance\nof AI systems with and without linguistic training. I argue that the success of\nLarge Language Models at inferential reasoning, limited though it may be,\nsupports Dennett's radical view about the effect of language on thought. I\nsuggest it is the abstractness and efficiency of linguistic encoding that lies\nbehind the capacity of LLMs to perform inferences across a wide range of\ndomains. In a slogan, language makes inference computationally tractable. I\nassess what these results in AI indicate about the role of language in the\nworkings of our own biological minds.",
      "tldr_zh": "本文从大型语言模型（LLMs）的视角探讨了语言对思维的影响，回应Daniel Dennett的观点，即添加语言可能使思维本质发生根本变化。作者通过分析AI系统有无语言训练的性能，论证LLMs在推理方面的成功（尽管有限）支持了这一观点，认为语言的抽象性和效率使跨领域推理在计算上变得可行。最后，论文评估这些AI结果对人类生物思维中语言角色的启示，提供了一个跨学科的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "37 Pages",
      "pdf_url": "http://arxiv.org/pdf/2505.13561v1",
      "published_date": "2025-05-19 09:29:32 UTC",
      "updated_date": "2025-05-19 09:29:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:29:52.102158"
    },
    {
      "arxiv_id": "2505.12894v1",
      "title": "HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Le Cheng",
        "Peican Zhu",
        "Yangming Guo",
        "Keke Tang",
        "Chao Gao",
        "Zhen Wang"
      ],
      "abstract": "Hypergraphs offer superior modeling capabilities for social networks,\nparticularly in capturing group phenomena that extend beyond pairwise\ninteractions in rumor propagation. Existing approaches in rumor source\ndetection predominantly focus on dyadic interactions, which inadequately\naddress the complexity of more intricate relational structures. In this study,\nwe present a novel approach for Source Detection in Hypergraphs (HyperDet) via\nInteractive Relationship Construction and Feature-rich Attention Fusion.\nSpecifically, our methodology employs an Interactive Relationship Construction\nmodule to accurately model both the static topology and dynamic interactions\namong users, followed by the Feature-rich Attention Fusion module, which\nautonomously learns node features and discriminates between nodes using a\nself-attention mechanism, thereby effectively learning node representations\nunder the framework of accurately modeled higher-order relationships. Extensive\nexperimental validation confirms the efficacy of our HyperDet approach,\nshowcasing its superiority relative to current state-of-the-art methods.",
      "tldr_zh": "本研究提出 HyperDet 方法，用于超图中的源检测（Source Detection），旨在更好地捕捉社交网络中超出二元交互（dyadic interactions）的群组现象，如谣言传播。HyperDet 包括 Interactive Relationship Construction 模块，用于精确建模用户间的静态拓扑和动态交互，以及 Feature-rich Attention Fusion 模块，通过自注意力机制（self-attention mechanism）自主学习节点特征并区分节点，从而在更高阶关系框架下优化节点表示。通过广泛实验验证，HyperDet 展现出比现有最先进方法更优越的性能。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by IJCAI25",
      "pdf_url": "http://arxiv.org/pdf/2505.12894v1",
      "published_date": "2025-05-19 09:27:46 UTC",
      "updated_date": "2025-05-19 09:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:30:03.870050"
    },
    {
      "arxiv_id": "2505.12891v1",
      "title": "TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in Real-World Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Shaohang Wei",
        "Wei Li",
        "Feifan Song",
        "Wen Luo",
        "Tianyi Zhuang",
        "Haochen Tan",
        "Zhijiang Guo",
        "Houfeng Wang"
      ],
      "abstract": "Temporal reasoning is pivotal for Large Language Models (LLMs) to comprehend\nthe real world. However, existing works neglect the real-world challenges for\ntemporal reasoning: (1) intensive temporal information, (2) fast-changing event\ndynamics, and (3) complex temporal dependencies in social interactions. To\nbridge this gap, we propose a multi-level benchmark TIME, designed for temporal\nreasoning in real-world scenarios. TIME consists of 38,522 QA pairs, covering 3\nlevels with 11 fine-grained sub-tasks. This benchmark encompasses 3\nsub-datasets reflecting different real-world challenges: TIME-Wiki, TIME-News,\nand TIME-Dial. We conduct extensive experiments on reasoning models and\nnon-reasoning models. And we conducted an in-depth analysis of temporal\nreasoning performance across diverse real-world scenarios and tasks, and\nsummarized the impact of test-time scaling on temporal reasoning capabilities.\nAdditionally, we release TIME-Lite, a human-annotated subset to foster future\nresearch and standardized evaluation in temporal reasoning. The code is\navailable at https://github.com/sylvain-wei/TIME , and the dataset is available\nat https://huggingface.co/datasets/SylvainWei/TIME .",
      "tldr_zh": "这篇论文提出 TIME 基准（Benchmark），一个多级评估框架，用于测试大型语言模型（LLMs）在真实场景中的时间推理（Temporal Reasoning）能力，旨在解决现有工作忽略的挑战，如密集时间信息、快速变化的事件动态和复杂时间依赖。TIME 包含 38,522 个 QA 对，覆盖 3 个级别和 11 个细粒度子任务，并包括 3 个子数据集（TIME-Wiki、TIME-News、TIME-Dial），分别反映不同真实世界场景。作者通过广泛实验比较了推理模型和非推理模型的性能，并分析了这些模型在各种任务中的时间推理效果，以及测试时缩放对能力的冲击。最后，他们发布了人工标注的 TIME-Lite 子集和相关代码及数据集，以支持未来研究和标准化评估。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "First version. There are still some examples to be added into the\n  appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.12891v1",
      "published_date": "2025-05-19 09:22:02 UTC",
      "updated_date": "2025-05-19 09:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:30:18.445015"
    },
    {
      "arxiv_id": "2505.12886v1",
      "title": "Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective",
      "title_zh": "大型推理模型中幻觉的检测与缓解：机制视角",
      "authors": [
        "Zhongxiang Sun",
        "Qipeng Wang",
        "Haoyu Wang",
        "Xiao Zhang",
        "Jun Xu"
      ],
      "abstract": "Large Reasoning Models (LRMs) have shown impressive capabilities in\nmulti-step reasoning tasks. However, alongside these successes, a more\ndeceptive form of model error has emerged--Reasoning Hallucination--where\nlogically coherent but factually incorrect reasoning traces lead to persuasive\nyet faulty conclusions. Unlike traditional hallucinations, these errors are\nembedded within structured reasoning, making them more difficult to detect and\npotentially more harmful. In this work, we investigate reasoning hallucinations\nfrom a mechanistic perspective. We propose the Reasoning Score, which\nquantifies the depth of reasoning by measuring the divergence between logits\nobtained from projecting late layers of LRMs to the vocabulary space,\neffectively distinguishing shallow pattern-matching from genuine deep\nreasoning. Using this score, we conduct an in-depth analysis on the ReTruthQA\ndataset and identify two key reasoning hallucination patterns: early-stage\nfluctuation in reasoning depth and incorrect backtracking to flawed prior\nsteps. These insights motivate our Reasoning Hallucination Detection (RHD)\nframework, which achieves state-of-the-art performance across multiple domains.\nTo mitigate reasoning hallucinations, we further introduce GRPO-R, an enhanced\nreinforcement learning algorithm that incorporates step-level deep reasoning\nrewards via potential-based shaping. Our theoretical analysis establishes\nstronger generalization guarantees, and experiments demonstrate improved\nreasoning quality and reduced hallucination rates.",
      "tldr_zh": "大型推理模型(LRMs) 在多步推理任务中表现出色，但常出现推理幻觉(Reasoning Hallucination)，即逻辑连贯却事实错误的推理路径，导致误导性结论。论文从机制视角提出 Reasoning Score，通过测量 LRMs 晚层投影到词汇空间的 logits 差异，量化推理深度并区分浅层模式匹配与深度推理。基于此，在 ReTruthQA 数据集分析中识别出早期推理深度波动和错误回溯等关键模式，并开发了 Reasoning Hallucination Detection (RHD) 框架，实现多领域最先进检测性能。为缓解幻觉，论文引入 GRPO-R 算法，该算法通过步级深度推理奖励的强化学习提升推理质量，实验证明显著减少幻觉率并提供更强的泛化保证。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12886v1",
      "published_date": "2025-05-19 09:16:40 UTC",
      "updated_date": "2025-05-19 09:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:30:30.162168"
    },
    {
      "arxiv_id": "2505.12884v1",
      "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
      "title_zh": "TinyAlign：通过缓解模态对齐瓶颈提升轻量级视觉-语言模型",
      "authors": [
        "Yuanze Hu",
        "Zhaoxin Fan",
        "Xinyu Wang",
        "Gen Li",
        "Ye Qiu",
        "Zhichao Yang",
        "Wenjun Wu",
        "Kejian Wu",
        "Yifan Sun",
        "Xiaotie Deng",
        "Jin Dong"
      ],
      "abstract": "Lightweight Vision-Language Models (VLMs) are indispensable for\nresource-constrained applications. The prevailing approach to aligning vision\nand language models involves freezing both the vision encoder and the language\nmodel while training small connector modules. However, this strategy heavily\ndepends on the intrinsic capabilities of the language model, which can be\nsuboptimal for lightweight models with limited representational capacity. In\nthis work, we investigate this alignment bottleneck through the lens of mutual\ninformation, demonstrating that the constrained capacity of the language model\ninherently limits the Effective Mutual Information (EMI) between multimodal\ninputs and outputs, thereby compromising alignment quality. To address this\nchallenge, we propose TinyAlign, a novel framework inspired by\nRetrieval-Augmented Generation, which strategically retrieves relevant context\nfrom a memory bank to enrich multimodal inputs and enhance their alignment.\nExtensive empirical evaluations reveal that TinyAlign significantly reduces\ntraining loss, accelerates convergence, and enhances task performance.\nRemarkably, it allows models to achieve baseline-level performance with only\n40\\% of the fine-tuning data, highlighting exceptional data efficiency. Our\nwork thus offers a practical pathway for developing more capable lightweight\nVLMs while introducing a fresh theoretical lens to better understand and\naddress alignment bottlenecks in constrained multimodal systems.",
      "tldr_zh": "本研究探讨了轻量级视觉语言模型（VLMs）在模态对齐方面的瓶颈问题，通过互信息（mutual information）的视角揭示，语言模型的有限容量会限制 Effective Mutual Information (EMI)，从而影响多模态输入和输出的对齐质量。针对此，作者提出 TinyAlign 框架，借鉴 Retrieval-Augmented Generation (RAG) 的理念，从记忆库检索相关上下文来丰富输入，从而提升模态对齐。实验结果显示，TinyAlign 显著降低了训练损失、加速了收敛，并提升了任务性能，仅需 40% 的微调数据即可达到基线水平。该框架为开发高效轻量级 VLMs 提供了实用路径，并引入新理论视角来理解和解决多模态系统中的对齐瓶颈。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12884v1",
      "published_date": "2025-05-19 09:11:54 UTC",
      "updated_date": "2025-05-19 09:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:30:41.382526"
    },
    {
      "arxiv_id": "2505.12882v1",
      "title": "PhyDA: Physics-Guided Diffusion Models for Data Assimilation in Atmospheric Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Jindong Han",
        "Wei Fan",
        "Weijia Zhang",
        "Hao Liu"
      ],
      "abstract": "Data Assimilation (DA) plays a critical role in atmospheric science by\nreconstructing spatially continous estimates of the system state, which serves\nas initial conditions for scientific analysis. While recent advances in\ndiffusion models have shown great potential for DA tasks, most existing\napproaches remain purely data-driven and often overlook the physical laws that\ngovern complex atmospheric dynamics. As a result, they may yield physically\ninconsistent reconstructions that impair downstream applications. To overcome\nthis limitation, we propose PhyDA, a physics-guided diffusion framework\ndesigned to ensure physical coherence in atmospheric data assimilation. PhyDA\nintroduces two key components: (1) a Physically Regularized Diffusion Objective\nthat integrates physical constraints into the training process by penalizing\ndeviations from known physical laws expressed as partial differential\nequations, and (2) a Virtual Reconstruction Encoder that bridges observational\nsparsity for structured latent representations, further enhancing the model's\nability to infer complete and physically coherent states. Experiments on the\nERA5 reanalysis dataset demonstrate that PhyDA achieves superior accuracy and\nbetter physical plausibility compared to state-of-the-art baselines. Our\nresults emphasize the importance of combining generative modeling with\ndomain-specific physical knowledge and show that PhyDA offers a promising\ndirection for improving real-world data assimilation systems.",
      "tldr_zh": "该研究提出PhyDA，一种受物理指导的扩散模型框架，用于改进大气系统的Data Assimilation (DA)，以生成物理一致的系统状态重建，避免传统数据驱动方法忽略物理定律导致的不一致问题。PhyDA的关键组件包括Physically Regularized Diffusion Objective，它通过惩罚偏离偏微分方程表达的物理约束来优化训练过程，以及Virtual Reconstruction Encoder，用于处理观测数据的稀疏性并生成结构化的潜在表示。实验在ERA5再分析数据集上显示，PhyDA比现有基准模型实现了更高的准确性和物理合理性，强调了将生成模型与领域特定物理知识相结合的潜力，为真实世界DA系统提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12882v1",
      "published_date": "2025-05-19 09:10:55 UTC",
      "updated_date": "2025-05-19 09:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:30:51.949407"
    },
    {
      "arxiv_id": "2505.12880v1",
      "title": "AdS-GNN -- a Conformally Equivariant Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Maksim Zhdanov",
        "Nabil Iqbal",
        "Erik Bekkers",
        "Patrick Forré"
      ],
      "abstract": "Conformal symmetries, i.e.\\ coordinate transformations that preserve angles,\nplay a key role in many fields, including physics, mathematics, computer vision\nand (geometric) machine learning. Here we build a neural network that is\nequivariant under general conformal transformations. To achieve this, we lift\ndata from flat Euclidean space to Anti de Sitter (AdS) space. This allows us to\nexploit a known correspondence between conformal transformations of flat space\nand isometric transformations on the AdS space. We then build upon the fact\nthat such isometric transformations have been extensively studied on general\ngeometries in the geometric deep learning literature. We employ message-passing\nlayers conditioned on the proper distance, yielding a computationally efficient\nframework. We validate our model on tasks from computer vision and statistical\nphysics, demonstrating strong performance, improved generalization capacities,\nand the ability to extract conformal data such as scaling dimensions from the\ntrained network.",
      "tldr_zh": "本文提出AdS-GNN，一种在共形变换下等变的图神经网络，旨在处理共形对称性在物理、数学和机器学习中的关键作用。方法涉及将数据从平欧空间提升到Anti de Sitter (AdS) 空间，利用AdS空间上的等距变换来实现计算高效的消息传递层。实验结果显示，该模型在计算机视觉和统计物理任务上表现出强性能、更好的泛化能力，并能从训练网络中提取共形数据，如scaling dimensions。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "hep-th"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12880v1",
      "published_date": "2025-05-19 09:08:52 UTC",
      "updated_date": "2025-05-19 09:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:31:04.166074"
    },
    {
      "arxiv_id": "2505.13557v1",
      "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Bruni",
        "Marco Avvenuti",
        "Nicola Tonellotto",
        "Maurizio Tesconi"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems are widely used in\nquestion-answering (QA) tasks, but current benchmarks lack metadata\nintegration, hindering evaluation in scenarios requiring both textual data and\nexternal information. To address this, we present AMAQA, a new open-access QA\ndataset designed to evaluate tasks combining text and metadata. The integration\nof metadata is especially important in fields that require rapid analysis of\nlarge volumes of data, such as cybersecurity and intelligence, where timely\naccess to relevant information is critical. AMAQA includes about 1.1 million\nEnglish messages collected from 26 public Telegram groups, enriched with\nmetadata such as timestamps, topics, emotional tones, and toxicity indicators,\nwhich enable precise and contextualized queries by filtering documents based on\nspecific criteria. It also includes 450 high-quality QA pairs, making it a\nvaluable resource for advancing research on metadata-driven QA and RAG systems.\nTo the best of our knowledge, AMAQA is the first single-hop QA benchmark to\nincorporate metadata and labels such as topics covered in the messages. We\nconduct extensive tests on the benchmark, establishing a new standard for\nfuture research. We show that leveraging metadata boosts accuracy from 0.12 to\n0.61, highlighting the value of structured context. Building on this, we\nexplore several strategies to refine the LLM input by iterating over provided\ncontext and enriching it with noisy documents, achieving a further 3-point gain\nover the best baseline and a 14-point improvement over simple metadata\nfiltering. The dataset is available at\nhttps://anonymous.4open.science/r/AMAQA-5D0D/",
      "tldr_zh": "本文提出 AMAQA，这是一个基于元数据的问答(QA)数据集，旨在评估检索增强生成(RAG)系统在整合文本和外部信息时的性能。该数据集包含约110万条英文消息（来自26个公共Telegram群组），并附带元数据如时间戳、主题、情感语气和毒性指标，以及450个高质量QA对，是首个整合此类元数据的单跳QA基准。实验结果显示，利用元数据将准确率从0.12提升至0.61，并通过迭代上下文和添加噪声文档的策略进一步提高3点，较简单元数据过滤高14点。该数据集为网络安全和情报等领域的研究提供了宝贵资源，可从指定链接获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13557v1",
      "published_date": "2025-05-19 08:59:08 UTC",
      "updated_date": "2025-05-19 08:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:31:17.448184"
    },
    {
      "arxiv_id": "2505.12872v1",
      "title": "From Grunts to Grammar: Emergent Language from Cooperative Foraging",
      "title_zh": "翻译失败",
      "authors": [
        "Maytus Piriyajitakonkij",
        "Rujikorn Charakorn",
        "Weicheng Tao",
        "Wei Pan",
        "Mingfei Sun",
        "Cheston Tan",
        "Mengmi Zhang"
      ],
      "abstract": "Early cavemen relied on gestures, vocalizations, and simple signals to\ncoordinate, plan, avoid predators, and share resources. Today, humans\ncollaborate using complex languages to achieve remarkable results. What drives\nthis evolution in communication? How does language emerge, adapt, and become\nvital for teamwork? Understanding the origins of language remains a challenge.\nA leading hypothesis in linguistics and anthropology posits that language\nevolved to meet the ecological and social demands of early human cooperation.\nLanguage did not arise in isolation, but through shared survival goals.\nInspired by this view, we investigate the emergence of language in multi-agent\nForaging Games. These environments are designed to reflect the cognitive and\necological constraints believed to have influenced the evolution of\ncommunication. Agents operate in a shared grid world with only partial\nknowledge about other agents and the environment, and must coordinate to\ncomplete games like picking up high-value targets or executing temporally\nordered actions. Using end-to-end deep reinforcement learning, agents learn\nboth actions and communication strategies from scratch. We find that agents\ndevelop communication protocols with hallmark features of natural language:\narbitrariness, interchangeability, displacement, cultural transmission, and\ncompositionality. We quantify each property and analyze how different factors,\nsuch as population size and temporal dependencies, shape specific aspects of\nthe emergent language. Our framework serves as a platform for studying how\nlanguage can evolve from partial observability, temporal reasoning, and\ncooperative goals in embodied multi-agent settings. We will release all data,\ncode, and models publicly.",
      "tldr_zh": "本研究探讨了语言从简单信号演变为复杂系统的起源，假设语言源于早期人类的合作需求，并通过多智能体 Foraging Games 模拟环境来验证这一观点。代理在部分可观察的网格世界中，使用端到端深度强化学习从零开始学习动作和通信策略，以完成合作任务如拾取高价值目标或执行有序动作。结果显示，代理发展出自然语言的标志性特征，包括 arbitrariness、interchangeability、displacement、cultural transmission 和 compositionality，并量化了这些属性如何受人口规模和时间依赖性等因素影响。该框架为研究语言在部分可观察性、时间推理和合作目标下的演变提供了一个平台，并计划公开所有数据、代码和模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12872v1",
      "published_date": "2025-05-19 08:57:30 UTC",
      "updated_date": "2025-05-19 08:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:31:28.642911"
    },
    {
      "arxiv_id": "2505.12871v1",
      "title": "Does Low Rank Adaptation Lead to Lower Robustness against Training-Time Attacks?",
      "title_zh": "低秩适配是否会导致针对训练时攻击的鲁棒性降低？",
      "authors": [
        "Zi Liang",
        "Haibo Hu",
        "Qingqing Ye",
        "Yaxin Xiao",
        "Ronghua Li"
      ],
      "abstract": "Low rank adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large language models (LLMs) thanks to its superb efficiency gains\nover previous methods. While extensive studies have examined the performance\nand structural properties of LoRA, its behavior upon training-time attacks\nremain underexplored, posing significant security risks. In this paper, we\ntheoretically investigate the security implications of LoRA's low-rank\nstructure during fine-tuning, in the context of its robustness against data\npoisoning and backdoor attacks. We propose an analytical framework that models\nLoRA's training dynamics, employs the neural tangent kernel to simplify the\nanalysis of the training process, and applies information theory to establish\nconnections between LoRA's low rank structure and its vulnerability against\ntraining-time attacks. Our analysis indicates that LoRA exhibits better\nrobustness to backdoor attacks than full fine-tuning, while becomes more\nvulnerable to untargeted data poisoning due to its over-simplified information\ngeometry. Extensive experimental evaluations have corroborated our theoretical\nfindings.",
      "tldr_zh": "本研究探讨了低秩适配（LoRA）在微调大型语言模型（LLMs）时的安全隐患，重点分析其低秩结构对训练时攻击（training-time attacks）的鲁棒性影响，包括数据投毒（data poisoning）和后门攻击（backdoor attacks）。作者提出一个分析框架，利用神经切线核（neural tangent kernel）和信息理论，建模LoRA的训练动态，并揭示其低秩结构使模型在后门攻击方面比全微调更具鲁棒性，但对无针对性数据投毒更易受损。实验结果证实了这些理论发现，为LoRA的安全应用提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at ICML 25",
      "pdf_url": "http://arxiv.org/pdf/2505.12871v1",
      "published_date": "2025-05-19 08:57:08 UTC",
      "updated_date": "2025-05-19 08:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:31:40.674117"
    },
    {
      "arxiv_id": "2505.12869v1",
      "title": "Outsourced Privacy-Preserving Feature Selection Based on Fully Homomorphic Encryption",
      "title_zh": "基于全同态加密的外包隐私保护特征选择",
      "authors": [
        "Koki Wakiyama",
        "Tomohiro I",
        "Hiroshi Sakamoto"
      ],
      "abstract": "Feature selection is a technique that extracts a meaningful subset from a set\nof features in training data. When the training data is large-scale,\nappropriate feature selection enables the removal of redundant features, which\ncan improve generalization performance, accelerate the training process, and\nenhance the interpretability of the model. This study proposes a\nprivacy-preserving computation model for feature selection. Generally, when the\ndata owner and analyst are the same, there is no need to conceal the private\ninformation. However, when they are different parties or when multiple owners\nexist, an appropriate privacy-preserving framework is required. Although\nvarious private feature selection algorithms, they all require two or more\ncomputing parties and do not guarantee security in environments where no\nexternal party can be fully trusted. To address this issue, we propose the\nfirst outsourcing algorithm for feature selection using fully homomorphic\nencryption. Compared to a prior two-party algorithm, our result improves the\ntime and space complexity O(kn^2) to O(kn log^3 n) and O(kn), where k and n\ndenote the number of features and data samples, respectively. We also\nimplemented the proposed algorithm and conducted comparative experiments with\nthe naive one. The experimental result shows the efficiency of our method even\nwith small datasets.",
      "tldr_zh": "这篇论文提出了一种基于 Fully Homomorphic Encryption 的外包隐私保护特征选择算法，旨在解决多方计算环境中数据隐私问题，同时提取有意义的特征子集以提升模型泛化性能、训练速度和可解释性。与现有两党算法相比，该方法将时间复杂度从 O(kn^2) 优化到 O(kn log^3 n)，空间复杂度从 O(kn^2) 优化到 O(kn)，其中 k 和 n 分别表示特征数和数据样本数。实验结果显示，该算法在小数据集上表现出色，证明了其高效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12869v1",
      "published_date": "2025-05-19 08:55:56 UTC",
      "updated_date": "2025-05-19 08:55:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:31:52.988123"
    },
    {
      "arxiv_id": "2505.12864v1",
      "title": "LEXam: Benchmarking Legal Reasoning on 340 Law Exams",
      "title_zh": "LEXam：基于340场法律考试的法律推理基准测试",
      "authors": [
        "Yu Fan",
        "Jingwei Ni",
        "Jakob Merane",
        "Etienne Salimbeni",
        "Yang Tian",
        "Yoan Hermstrüwer",
        "Yinya Huang",
        "Mubashara Akhtar",
        "Florian Geering",
        "Oliver Dreyer",
        "Daniel Brunner",
        "Markus Leippold",
        "Mrinmaya Sachan",
        "Alexander Stremitzer",
        "Christoph Engel",
        "Elliott Ash",
        "Joel Niklaus"
      ],
      "abstract": "Long-form legal reasoning remains a key challenge for large language models\n(LLMs) in spite of recent advances in test-time scaling. We introduce LEXam, a\nnovel benchmark derived from 340 law exams spanning 116 law school courses\nacross a range of subjects and degree levels. The dataset comprises 4,886 law\nexam questions in English and German, including 2,841 long-form, open-ended\nquestions and 2,045 multiple-choice questions. Besides reference answers, the\nopen questions are also accompanied by explicit guidance outlining the expected\nlegal reasoning approach such as issue spotting, rule recall, or rule\napplication. Our evaluation on both open-ended and multiple-choice questions\npresent significant challenges for current LLMs; in particular, they notably\nstruggle with open questions that require structured, multi-step legal\nreasoning. Moreover, our results underscore the effectiveness of the dataset in\ndifferentiating between models with varying capabilities. Adopting an\nLLM-as-a-Judge paradigm with rigorous human expert validation, we demonstrate\nhow model-generated reasoning steps can be evaluated consistently and\naccurately. Our evaluation setup provides a scalable method to assess legal\nreasoning quality beyond simple accuracy metrics. Project page:\nhttps://lexam-benchmark.github.io/",
      "tldr_zh": "本研究引入了 LEXam 基准数据集，基于 340 个法律考试（涵盖 116 门课程），用于评估大型语言模型 (LLMs) 在长形式法律推理方面的表现。该数据集包含 4,886 个英语和德语问题，包括 2,841 个开放式长形式问题和 2,045 个多项选择题，并为开放问题提供明确的推理指导，如 issue spotting 和 rule application。实验结果显示，当前 LLMs 在需要结构化、多步法律推理的开放问题上表现不佳，且 LEXam 能有效区分不同模型的能力；论文采用 LLM-as-a-Judge 范式结合人类专家验证，提供了一种可扩展的评估方法，超越简单准确率指标。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12864v1",
      "published_date": "2025-05-19 08:48:12 UTC",
      "updated_date": "2025-05-19 08:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:32:05.810835"
    },
    {
      "arxiv_id": "2505.12863v1",
      "title": "Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Jongmin Jung",
        "Dongmin Kim",
        "Sihun Lee",
        "Seola Cho",
        "Hyungjoon Soh",
        "Irmak Bukey",
        "Chris Donahue",
        "Dasaem Jeong"
      ],
      "abstract": "Music exists in various modalities, such as score images, symbolic scores,\nMIDI, and audio. Translations between each modality are established as core\ntasks of music information retrieval, such as automatic music transcription\n(audio-to-MIDI) and optical music recognition (score image to symbolic score).\nHowever, most past work on multimodal translation trains specialized models on\nindividual translation tasks. In this paper, we propose a unified approach,\nwhere we train a general-purpose model on many translation tasks\nsimultaneously. Two key factors make this unified approach viable: a new\nlarge-scale dataset and the tokenization of each modality. Firstly, we propose\na new dataset that consists of more than 1,300 hours of paired audio-score\nimage data collected from YouTube videos, which is an order of magnitude larger\nthan any existing music modal translation datasets. Secondly, our unified\ntokenization framework discretizes score images, audio, MIDI, and MusicXML into\na sequence of tokens, enabling a single encoder-decoder Transformer to tackle\nmultiple cross-modal translation as one coherent sequence-to-sequence task.\nExperimental results confirm that our unified multitask model improves upon\nsingle-task baselines in several key areas, notably reducing the symbol error\nrate for optical music recognition from 24.58% to a state-of-the-art 13.67%,\nwhile similarly substantial improvements are observed across the other\ntranslation tasks. Notably, our approach achieves the first successful\nscore-image-conditioned audio generation, marking a significant breakthrough in\ncross-modal music generation.",
      "tldr_zh": "该研究提出了一种统一的跨模态翻译方法，使用一个通用多任务模型同时处理分数图像、符号音乐（包括 MIDI 和 MusicXML）和性能音频之间的转换，取代了以往针对单个任务的专门模型。\n他们构建了一个大规模数据集，包含超过1300小时的配对音频-分数图像数据，并开发了统一的标记化框架，将这些模态离散化为token序列，从而让一个编码器-解码器 Transformer 模型能够处理多种序列到序列任务。\n实验结果显示，该模型在多个翻译任务上优于单任务基线，例如将光学音乐识别的符号错误率从24.58%降低到13.67%，并实现了首个基于分数图像的音频生成，标志着跨模态音乐生成的重大突破。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to IEEE Transactions on Audio, Speech and Language\n  Processing (TASLPRO)",
      "pdf_url": "http://arxiv.org/pdf/2505.12863v1",
      "published_date": "2025-05-19 08:46:45 UTC",
      "updated_date": "2025-05-19 08:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:32:17.757001"
    },
    {
      "arxiv_id": "2505.12851v1",
      "title": "FLTG: Byzantine-Robust Federated Learning via Angle-Based Defense and Non-IID-Aware Weighting",
      "title_zh": "翻译失败",
      "authors": [
        "Yanhua Wen",
        "Lu Ai",
        "Gang Liu",
        "Chuang Li",
        "Jianhao Wei"
      ],
      "abstract": "Byzantine attacks during model aggregation in Federated Learning (FL)\nthreaten training integrity by manipulating malicious clients' updates.\nExisting methods struggle with limited robustness under high malicious client\nratios and sensitivity to non-i.i.d. data, leading to degraded accuracy. To\naddress this, we propose FLTG, a novel aggregation algorithm integrating\nangle-based defense and dynamic reference selection. FLTG first filters clients\nvia ReLU-clipped cosine similarity, leveraging a server-side clean dataset to\nexclude misaligned updates. It then dynamically selects a reference client\nbased on the prior global model to mitigate non-i.i.d. bias, assigns\naggregation weights inversely proportional to angular deviations, and\nnormalizes update magnitudes to suppress malicious scaling. Evaluations across\ndatasets of varying complexity under five classic attacks demonstrate FLTG's\nsuperiority over state-of-the-art methods under extreme bias scenarios and\nsustains robustness with a higher proportion(over 50%) of malicious clients.",
      "tldr_zh": "本文提出 FLTG，一种针对联邦学习 (Federated Learning) 中 Byzantine attacks 的鲁棒聚合算法，整合 angle-based defense 和 non-IID-aware weighting，以提升在高恶意客户端比例下的准确性。FLTG 通过 ReLU-clipped cosine similarity 和服务器端干净数据集过滤恶意更新，动态选择参考客户端缓解 non-i.i.d. 偏置，并基于角度偏差分配权重并标准化更新幅度。实验结果显示，在多种数据集和五种经典攻击下，FLTG 在极端偏置场景中优于现有方法，即使恶意客户端比例超过 50%，仍保持出色鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 5 figures, BlockSys2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12851v1",
      "published_date": "2025-05-19 08:39:07 UTC",
      "updated_date": "2025-05-19 08:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:32:29.973014"
    },
    {
      "arxiv_id": "2505.12845v1",
      "title": "Multi-Level Aware Preference Learning: Enhancing RLHF for Complex Multi-Instruction Tasks",
      "title_zh": "多层次感知偏好学习：增强 RLHF 用于复杂多指令任务",
      "authors": [
        "Ruopei Sun",
        "Jianfeng Cai",
        "Jinhua Zhu",
        "Kangwen Zhao",
        "Dongyun Xue",
        "Wengang Zhou",
        "Li Li",
        "Houqiang Li"
      ],
      "abstract": "RLHF has emerged as a predominant approach for aligning artificial\nintelligence systems with human preferences, demonstrating exceptional and\nmeasurable efficacy in instruction following tasks; however, it exhibits\ninsufficient compliance capabilities when confronted with complex\nmulti-instruction tasks. Conventional approaches rely heavily on human\nannotation or more sophisticated large language models, thereby introducing\nsubstantial resource expenditure or potential bias concerns. Meanwhile,\nalternative synthetic methods that augment standard preference datasets often\ncompromise the model's semantic quality. Our research identifies a critical\noversight in existing techniques, which predominantly focus on comparing\nresponses while neglecting valuable latent signals embedded within prompt\ninputs, and which only focus on preference disparities at the intra-sample\nlevel, while neglecting to account for the inter-sample level preference\ndifferentials that exist among preference data. To leverage these previously\nneglected indicators, we propose a novel Multi-level Aware Preference Learning\n(MAPL) framework, capable of enhancing multi-instruction capabilities.\nSpecifically, for any given response in original preference data pairs, we\nconstruct varied prompts with a preference relation under different conditions,\nin order to learn intra-sample level preference disparities. Furthermore, for\nany given original preference pair, we synthesize multi-instruction preference\npairs to capture preference discrepancies at the inter-sample level. Building\non the two datasets constructed above, we consequently devise two sophisticated\ntraining objective functions. Subsequently, our framework integrates seamlessly\ninto both Reward Modeling and Direct Preference Optimization paradigms. Through\nrigorous evaluation across multiple benchmarks, we empirically validate the\nefficacy of our framework.",
      "tldr_zh": "该研究指出，现有的 RLHF（Reinforcement Learning from Human Feedback）方法在处理复杂多指令任务时表现不足，主要由于忽略了提示输入中的潜在信号以及样本间偏好差异。论文提出了一种新型框架 Multi-Level Aware Preference Learning (MAPL)，通过构建变体提示来学习样本内偏好差异，并合成多指令偏好对以捕捉样本间差异。基于这些扩展数据集，MAPL 设计了两个高级训练目标函数，并可无缝集成到 Reward Modeling 和 Direct Preference Optimization 范式中。通过多基准测试，实验验证了该框架显著提升了模型的多指令处理能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12845v1",
      "published_date": "2025-05-19 08:33:11 UTC",
      "updated_date": "2025-05-19 08:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:32:42.704041"
    },
    {
      "arxiv_id": "2505.12844v1",
      "title": "AGI-Elo: How Far Are We From Mastering A Task?",
      "title_zh": "AGI-Elo：我们距离掌握一个任务还有多远？",
      "authors": [
        "Shuo Sun",
        "Yimin Zhao",
        "Christina Dao Wen Lee",
        "Jiawei Sun",
        "Chengran Yuan",
        "Zefan Huang",
        "Dongen Li",
        "Justin KW Yeoh",
        "Alok Prakash",
        "Thomas W. Malone",
        "Marcelo H. Ang Jr"
      ],
      "abstract": "As the field progresses toward Artificial General Intelligence (AGI), there\nis a pressing need for more comprehensive and insightful evaluation frameworks\nthat go beyond aggregate performance metrics. This paper introduces a unified\nrating system that jointly models the difficulty of individual test cases and\nthe competency of AI models (or humans) across vision, language, and action\ndomains. Unlike existing metrics that focus solely on models, our approach\nallows for fine-grained, difficulty-aware evaluations through competitive\ninteractions between models and tasks, capturing both the long-tail\ndistribution of real-world challenges and the competency gap between current\nmodels and full task mastery. We validate the generalizability and robustness\nof our system through extensive experiments on multiple established datasets\nand models across distinct AGI domains. The resulting rating distributions\noffer novel perspectives and interpretable insights into task difficulty, model\nprogression, and the outstanding challenges that remain on the path to\nachieving full AGI task mastery.",
      "tldr_zh": "这篇论文引入了AGI-Elo评分系统，用于评估AI模型（或人类）在视觉、language和action领域的能力，同时考虑任务的难度。该系统通过模型与任务之间的竞争互动，实现细粒度的、难度感知评估，捕捉真实世界挑战的长尾分布和模型与完全任务掌握之间的能力差距。实验在多个数据集和模型上验证了系统的泛化性和鲁棒性，结果提供了可解释的洞见，包括任务难度、模型进步以及通往AGI的剩余挑战。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12844v1",
      "published_date": "2025-05-19 08:30:13 UTC",
      "updated_date": "2025-05-19 08:30:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:32:53.237828"
    },
    {
      "arxiv_id": "2505.12843v1",
      "title": "Bias Fitting to Mitigate Length Bias of Reward Model in RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Kangwen Zhao",
        "Jianfeng Cai",
        "Jinhua Zhu",
        "Ruopei Sun",
        "Dongyun Xue",
        "Wengang Zhou",
        "Li Li",
        "Houqiang Li"
      ],
      "abstract": "Reinforcement Learning from Human Feedback relies on reward models to align\nlarge language models with human preferences. However, RLHF often suffers from\nreward hacking, wherein policy learning exploits flaws in the trained reward\nmodel to maximize reward scores without genuinely aligning with human\npreferences. A significant example of such reward hacking is length bias, where\nreward models usually favor longer responses irrespective of actual response\nquality. Previous works on length bias have notable limitations, these\napproaches either mitigate bias without characterizing the bias form, or simply\nassume a linear length-reward relation. To accurately model the intricate\nnature of length bias and facilitate more effective bias mitigation, we propose\nFiMi-RM (Bias Fitting to Mitigate Length Bias of Reward Model in RLHF), a\nframework that autonomously learns and corrects underlying bias patterns. Our\napproach consists of three stages: First, we train a standard reward model\nwhich inherently contains length bias. Next, we deploy a lightweight fitting\nmodel to explicitly capture the non-linear relation between length and reward.\nFinally, we incorporate this learned relation into the reward model to debias.\nExperimental results demonstrate that FiMi-RM achieves a more balanced\nlength-reward distribution. Furthermore, when applied to alignment algorithms,\nour debiased reward model improves length-controlled win rate and reduces\nverbosity without compromising its performance.",
      "tldr_zh": "RLHF（Reinforcement Learning from Human Feedback）中，奖励模型常存在长度偏差（length bias），导致模型偏好更长的响应而非高质量内容，从而引发奖励黑客（reward hacking）问题。研究提出FiMi-RM框架，通过三阶段方法解决此问题：首先训练一个标准奖励模型；其次，使用轻量级拟合模型捕获长度与奖励之间的非线性关系；最后，将此关系整合到奖励模型中进行去偏差。实验结果显示，FiMi-RM实现了更平衡的长度-奖励分布，提高了长度控制的胜率，减少了响应冗长性，同时维持了整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Due to the word limit for arXiv abstract, the abstract here has been\n  abridged compared to the one in the PDF",
      "pdf_url": "http://arxiv.org/pdf/2505.12843v1",
      "published_date": "2025-05-19 08:29:28 UTC",
      "updated_date": "2025-05-19 08:29:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:33:05.445197"
    },
    {
      "arxiv_id": "2505.12837v1",
      "title": "The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting",
      "title_zh": "隐藏的结构——通过显式文本格式化提升法律文档理解",
      "authors": [
        "Christian Braun",
        "Alexander Lilienbeck",
        "Daniel Mentjukov"
      ],
      "abstract": "Legal contracts possess an inherent, semantically vital structure (e.g.,\nsections, clauses) that is crucial for human comprehension but whose impact on\nLLM processing remains under-explored. This paper investigates the effects of\nexplicit input text structure and prompt engineering on the performance of\nGPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the\nCUAD. We compare model exact-match accuracy across various input formats:\nwell-structured plain-text (human-generated from CUAD), plain-text cleaned of\nline breaks, extracted plain-text from Azure OCR, plain-text extracted by\nGPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o\nVision. To give an indication of the impact of possible prompt engineering, we\nassess the impact of shifting task instructions to the system prompt and\nexplicitly informing the model about the structured nature of the input. Our\nfindings reveal that GPT-4o demonstrates considerable robustness to variations\nin input structure, but lacks in overall performance. Conversely, GPT-4.1's\nperformance is markedly sensitive; poorly structured inputs yield suboptimal\nresults (but identical with GPT-4o), while well-structured formats (original\nCUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by\n~20 percentage points. Optimizing the system prompt to include task details and\nan advisory about structured input further elevates GPT-4.1's accuracy by an\nadditional ~10-13 percentage points, with Markdown ultimately achieving the\nhighest performance under these conditions (79 percentage points overall\nexact-match accuracy). This research empirically demonstrates that while newer\nmodels exhibit greater resilience, careful input structuring and strategic\nprompt design remain critical for optimizing the performance of LLMs, and can\nsignificantly affect outcomes in high-stakes legal applications.",
      "tldr_zh": "这篇论文探讨了显式文本结构（如部分和条款）对LLM（如GPT-4o和GPT-4.1）在法律问答任务（基于CUAD数据集）的影响，通过比较不同输入格式（包括结构良好的纯文本、去除换行的纯文本、Azure OCR提取文本、GPT-4o Vision提取文本和Markdown）来评估模型性能。结果显示，GPT-4o对输入结构变化表现出较强鲁棒性，但整体准确率较低；相比之下，GPT-4.1对结构敏感，采用良好格式可提高精确匹配准确率约20个百分点，而优化系统提示（如添加任务细节和结构化建议）进一步提升其准确率10-13个百分点，最终Markdown格式达到79%的最高性能。研究强调，尽管新模型更具韧性，但仔细的输入结构化和战略提示工程对优化LLM在高风险法律应用中的表现至关重要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12837v1",
      "published_date": "2025-05-19 08:25:21 UTC",
      "updated_date": "2025-05-19 08:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:33:21.388239"
    },
    {
      "arxiv_id": "2505.12833v1",
      "title": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs",
      "title_zh": "Reasoning BO：利用 LLMs 的长上下文推理能力增强贝叶斯优化",
      "authors": [
        "Zhuo Yang",
        "Lingli Ge",
        "Dong Han",
        "Tianfan Fu",
        "Yuqiang Li"
      ],
      "abstract": "Many real-world scientific and industrial applications require the\noptimization of expensive black-box functions. Bayesian Optimization (BO)\nprovides an effective framework for such problems. However, traditional BO\nmethods are prone to get trapped in local optima and often lack interpretable\ninsights. To address this issue, this paper designs Reasoning BO, a novel\nframework that leverages reasoning models to guide the sampling process in BO\nwhile incorporating multi-agent systems and knowledge graphs for online\nknowledge accumulation. By integrating the reasoning and contextual\nunderstanding capabilities of Large Language Models (LLMs), we can provide\nstrong guidance to enhance the BO process. As the optimization progresses,\nReasoning BO provides real-time sampling recommendations along with critical\ninsights grounded in plausible scientific theories, aiding in the discovery of\nsuperior solutions within the search space. We systematically evaluate our\napproach across 10 diverse tasks encompassing synthetic mathematical functions\nand complex real-world applications. The framework demonstrates its capability\nto progressively refine sampling strategies through real-time insights and\nhypothesis evolution, effectively identifying higher-performing regions of the\nsearch space for focused exploration. This process highlights the powerful\nreasoning and context-learning abilities of LLMs in optimization scenarios. For\nexample, in the Direct Arylation task, our method increased the yield to 60.7%,\nwhereas traditional BO achieved only a 25.2% yield. Furthermore, our\ninvestigation reveals that smaller LLMs, when fine-tuned through reinforcement\nlearning, can attain comparable performance to their larger counterparts. This\nenhanced reasoning capability paves the way for more efficient automated\nscientific experimentation while maintaining computational feasibility.",
      "tldr_zh": "本论文提出Reasoning BO框架，利用Large Language Models (LLMs)的长上下文推理能力来提升Bayesian Optimization (BO)，解决其易陷入局部最优和缺乏可解释性的问题。该框架整合多智能体系统和知识图谱，实现在线知识积累，并通过LLMs提供实时采样推荐和基于科学理论的洞见，以指导优化过程。在10个多样任务（如合成数学函数和真实应用）上的实验显示，Reasoning BO能通过实时洞见和假设演化逐步优化采样策略，例如在Direct Arylation任务中将产率从传统BO的25.2%提高至60.7%。此外，研究发现，通过强化学习微调的较小LLMs可与大型模型媲美，从而实现更高效的自动科学实验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12833v1",
      "published_date": "2025-05-19 08:20:40 UTC",
      "updated_date": "2025-05-19 08:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:33:28.957999"
    },
    {
      "arxiv_id": "2505.12822v2",
      "title": "Emergent Specialization: Rare Token Neurons in Language Models",
      "title_zh": "涌现专业化：语言模型中的稀有标记神经元",
      "authors": [
        "Jing Liu",
        "Haozheng Wang",
        "Yueheng Li"
      ],
      "abstract": "Large language models struggle with representing and generating rare tokens\ndespite their importance in specialized domains. In this study, we identify\nneuron structures with exceptionally strong influence on language model's\nprediction of rare tokens, termed as rare token neurons, and investigate the\nmechanism for their emergence and behavior. These neurons exhibit a\ncharacteristic three-phase organization (plateau, power-law, and rapid decay)\nthat emerges dynamically during training, evolving from a homogeneous initial\nstate to a functionally differentiated architecture. In the activation space,\nrare token neurons form a coordinated subnetwork that selectively co-activates\nwhile avoiding co-activation with other neurons. This functional specialization\npotentially correlates with the development of heavy-tailed weight\ndistributions, suggesting a statistical mechanical basis for emergent\nspecialization.",
      "tldr_zh": "本研究发现，大语言模型在处理稀有标记(rare tokens)时存在代表和生成困难，因此识别了 rare token neurons，这些神经元对模型预测稀有标记有显著影响，并调查了它们的涌现机制和行为。rare token neurons 在训练过程中从同质状态演变为三阶段组织，包括 plateau（平台期）、power-law（幂律期）和 rapid decay（快速衰减期）。在激活空间中，这些神经元形成协调子网络，选择性共同激活，同时避免与其他神经元共激活，这可能与 heavy-tailed weight distributions（重尾权重分布）相关，揭示了语言模型中涌现专业化的统计力学基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12822v2",
      "published_date": "2025-05-19 08:05:13 UTC",
      "updated_date": "2025-05-22 16:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:33:41.135159"
    },
    {
      "arxiv_id": "2505.12821v1",
      "title": "SynDec: A Synthesize-then-Decode Approach for Arbitrary Textual Style Transfer via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Han Sun",
        "Zhen Sun",
        "Zongmin Zhang",
        "Linzhao Jia",
        "Wei Shao",
        "Min Zhang"
      ],
      "abstract": "Large Language Models (LLMs) are emerging as dominant forces for textual\nstyle transfer. However, for arbitrary style transfer, LLMs face two key\nchallenges: (1) considerable reliance on manually-constructed prompts and (2)\nrigid stylistic biases inherent in LLMs. In this paper, we propose a novel\nSynthesize-then-Decode (SynDec) approach, which automatically synthesizes\nhigh-quality prompts and amplifies their roles during decoding process.\nSpecifically, our approach synthesizes prompts by selecting representative\nfew-shot samples, conducting a four-dimensional style analysis, and reranking\nthe candidates. At LLM decoding stage, the TST effect is amplified by\nmaximizing the contrast in output probabilities between scenarios with and\nwithout the synthesized prompt, as well as between prompts and negative\nsamples. We conduct extensive experiments and the results show that SynDec\noutperforms existing state-of-the-art LLM-based methods on five out of six\nbenchmarks (e.g., achieving up to a 9\\% increase in accuracy for\nmodern-to-Elizabethan English transfer). Detailed ablation studies further\nvalidate the effectiveness of SynDec.",
      "tldr_zh": "该论文提出了一种名为 SynDec 的新方法，用于通过 Large Language Models (LLMs) 实现任意文本风格转移，旨在解决 LLMs 对手动构建的 prompts 的过度依赖以及固有的风格偏见问题。SynDec 的核心步骤包括自动合成高质量提示（通过选择 few-shot samples、进行 four-dimensional style analysis 和候选重新排序），并在 LLM 解码阶段放大 TST effect 效果（例如，通过最大化输出概率的对比）。实验结果显示，SynDec 在六个基准中的五个上优于现有最先进方法，提高准确率高达 9%（如现代英语到伊丽莎白时代英语的转移），并通过 ablation studies 验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12821v1",
      "published_date": "2025-05-19 08:03:38 UTC",
      "updated_date": "2025-05-19 08:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:33:54.343449"
    },
    {
      "arxiv_id": "2505.12815v1",
      "title": "Learning in Chaos: Efficient Autoscaling and Self-healing for Distributed Training at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjiao Feng",
        "Rongxing Xiao",
        "Zonghang Li",
        "Hongfang Yu",
        "Gang Sun",
        "Long Luo",
        "Mohsen Guizani",
        "Qirong Ho"
      ],
      "abstract": "Frequent node and link changes in edge AI clusters disrupt distributed\ntraining, while traditional checkpoint-based recovery and cloud-centric\nautoscaling are too slow for scale-out and ill-suited to chaotic and\nself-governed edge. This paper proposes Chaos, a resilient and scalable edge\ndistributed training system with built-in self-healing and autoscaling. It\nspeeds up scale-out by using multi-neighbor replication with fast shard\nscheduling, allowing a new node to pull the latest training state from nearby\nneighbors in parallel while balancing the traffic load between them. It also\nuses a cluster monitor to track resource and topology changes to assist\nscheduler decisions, and handles scaling events through peer negotiation\nprotocols, enabling fully self-governed autoscaling without a central admin.\nExtensive experiments show that Chaos consistently achieves much lower\nscale-out delays than Pollux, EDL, and Autoscaling, and handles scale-in,\nconnect-link, and disconnect-link events within 1 millisecond, making it\nsmoother to handle node joins, exits, and failures. It also delivers the lowest\nidle time, showing superior resource use and scalability as the cluster grows.",
      "tldr_zh": "这篇论文提出了 Chaos 系统，一种针对边缘分布式训练的弹性可扩展框架，旨在解决边缘 AI 集群中节点和链接频繁变化导致的训练中断问题，通过多邻居复制、快速分片调度和集群监控来实现高效的 autoscaling 和 self-healing。系统采用对等协商协议进行完全自治的缩放决策，无需中央管理员，从而加速 scale-out 过程并平衡流量负载。实验结果显示，Chaos 比 Pollux、EDL 和 Autoscaling 等基线模型的扩展延迟显著降低，并在处理 scale-in、连接和断开事件时仅需 1 毫秒，同时实现了最低空闲时间和更好的资源利用率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "68T99",
        "I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12815v1",
      "published_date": "2025-05-19 07:52:17 UTC",
      "updated_date": "2025-05-19 07:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:34:07.157137"
    },
    {
      "arxiv_id": "2505.12814v1",
      "title": "PsyMem: Fine-grained psychological alignment and Explicit Memory Control for Advanced Role-Playing LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xilong Cheng",
        "Yunxiao Qin",
        "Yuting Tan",
        "Zhengnan Li",
        "Ye Wang",
        "Hongjiang Xiao",
        "Yuan Zhang"
      ],
      "abstract": "Existing LLM-based role-playing methods often rely on superficial textual\ndescriptions or simplistic metrics, inadequately modeling both intrinsic and\nextrinsic character dimensions. Additionally, they typically simulate character\nmemory with implicit model knowledge or basic retrieval augment generation\nwithout explicit memory alignment, compromising memory consistency. The two\nissues weaken reliability of role-playing LLMs in several applications, such as\ntrustworthy social simulation. To address these limitations, we propose PsyMem,\na novel framework integrating fine-grained psychological attributes and\nexplicit memory control for role-playing. PsyMem supplements textual\ndescriptions with 26 psychological indicators to detailed model character.\nAdditionally, PsyMem implements memory alignment training, explicitly trains\nthe model to align character's response with memory, thereby enabling dynamic\nmemory-controlled responding during inference. By training Qwen2.5-7B-Instruct\non our specially designed dataset (including 5,414 characters and 38,962\ndialogues extracted from novels), the resulting model, termed as PsyMem-Qwen,\noutperforms baseline models in role-playing, achieving the best performance in\nhuman-likeness and character fidelity.",
      "tldr_zh": "该论文指出，现有的基于LLMs的角色扮演方法依赖浅显文本描述和简单指标，无法充分建模角色的内在和外在维度，且记忆模拟缺乏显式对齐，导致角色一致性不足。PsyMem框架通过整合细粒度的心理属性（如26个心理指标）和显式记忆控制（如记忆对齐训练），来增强角色建模和动态响应能力。研究者在自定义数据集上训练Qwen2.5-7B-Instruct模型，生成PsyMem-Qwen，该模型在角色扮演任务中超越基线模型，尤其在人性化和角色忠诚度方面表现出最佳性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12814v1",
      "published_date": "2025-05-19 07:45:09 UTC",
      "updated_date": "2025-05-19 07:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:34:19.543380"
    },
    {
      "arxiv_id": "2505.12811v1",
      "title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning",
      "title_zh": "动态视线范围选择在多智能体强化学习中的应用",
      "authors": [
        "Wei-Chen Liao",
        "Ti-Rong Wu",
        "I-Chen Wu"
      ],
      "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight\nrange dilemma, where agents either receive insufficient or excessive\ninformation from their environment. In this paper, we propose a novel method,\ncalled Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes\nan Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight\nrange during training. Experiment results show several advantages of using DSR.\nFirst, we demonstrate using DSR achieves better performance in three common\nMARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse\n(RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show\nthat DSR consistently improves performance across multiple MARL algorithms,\nincluding QMIX and MAPPO. Third, DSR offers suitable sight ranges for different\ntraining steps, thereby accelerating the training process. Finally, DSR\nprovides additional interpretability by indicating the optimal sight range used\nduring training. Unlike existing methods that rely on global information or\ncommunication mechanisms, our approach operates solely based on the individual\nsight ranges of agents. This approach offers a practical and efficient solution\nto the sight range dilemma, making it broadly applicable to real-world complex\nenvironments.",
      "tldr_zh": "这篇论文针对 Multi-Agent Reinforcement Learning (MARL) 中的 sight range dilemma 问题，提出了一种名为 Dynamic Sight Range Selection (DSR) 的方法，该方法利用 Upper Confidence Bound (UCB) 算法动态调整代理的视线范围，以优化信息获取。实验结果显示，DSR 在 Level-Based Foraging (LBF)、Multi-Robot Warehouse (RWARE) 和 StarCraft Multi-Agent Challenge (SMAC) 等环境中显著提升性能，并在 QMIX 和 MAPPO 等算法上实现一致改进，同时加速训练过程并提供额外解释性。相比依赖全局信息或通信机制的现有方法，DSR 仅基于个体视线范围，是一种实用且高效的解决方案，适用于真实世界的复杂环境。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at AAMAS 2025. The compiled PDF includes the appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.12811v1",
      "published_date": "2025-05-19 07:40:42 UTC",
      "updated_date": "2025-05-19 07:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:34:31.372051"
    },
    {
      "arxiv_id": "2505.12805v1",
      "title": "FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Seanie Lee",
        "Sangwoo Park",
        "Dong Bok Lee",
        "Dominik Wagner",
        "Haebin Seong",
        "Tobias Bocklet",
        "Juho Lee",
        "Sung Ju Hwang"
      ],
      "abstract": "Low-Rank Adaptation (LoRA), which introduces a product of two trainable\nlow-rank matrices into frozen pre-trained weights, is widely used for efficient\nfine-tuning of language models in federated learning (FL). However, when\ncombined with differentially private stochastic gradient descent (DP-SGD), LoRA\nfaces substantial noise amplification: DP-SGD perturbs per-sample gradients,\nand the matrix multiplication of the LoRA update ($BA$) intensifies this\neffect. Freezing one matrix (e.g., $A$) reduces the noise but restricts model\nexpressiveness, often resulting in suboptimal adaptation. To address this, we\npropose FedSVD, a simple yet effective method that introduces a global\nreparameterization based on singular value decomposition (SVD). In our\napproach, each client optimizes only the $B$ matrix and transmits it to the\nserver. The server aggregates the $B$ matrices, computes the product $BA$ using\nthe previous $A$, and refactorizes the result via SVD. This yields a new\nadaptive $A$ composed of the orthonormal right singular vectors of $BA$, and an\nupdated $B$ containing the remaining SVD components. This reparameterization\navoids quadratic noise amplification, while allowing $A$ to better capture the\nprincipal directions of the aggregate updates. Moreover, the orthonormal\nstructure of $A$ bounds the gradient norms of $B$ and preserves more signal\nunder DP-SGD, as confirmed by our theoretical analysis. As a result, FedSVD\nconsistently improves stability and performance across a variety of privacy\nsettings and benchmarks, outperforming relevant baselines under both private\nand non-private regimes.",
      "tldr_zh": "该论文针对 LoRA 在联邦学习中结合 DP-SGD 时噪声放大的问题，提出 FedSVD 方法，该方法通过奇异值分解 (SVD) 进行全局重参数化。FedSVD 让客户端仅优化 B 矩阵，服务器聚合后计算 BA 并用 SVD 重构，生成正交化的 A 和更新后的 B，从而避免二次噪声放大并保留更多信号。实验结果显示，FedSVD 在各种隐私和非隐私设置下，提升了模型的稳定性和性能，优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.12805v1",
      "published_date": "2025-05-19 07:32:56 UTC",
      "updated_date": "2025-05-19 07:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:34:43.174151"
    },
    {
      "arxiv_id": "2505.12800v1",
      "title": "OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Hieu-Nghia Huynh-Nguyen",
        "Ngoc Son Nguyen",
        "Huynh Nguyen Dang",
        "Thieu Vo",
        "Truong-Son Hy",
        "Van Nguyen"
      ],
      "abstract": "Text-to-speech (TTS) systems have seen significant advancements in recent\nyears, driven by improvements in deep learning and neural network\narchitectures. Viewing the output speech as a data distribution, previous\napproaches often employ traditional speech representations, such as waveforms\nor spectrograms, within the Flow Matching framework. However, these methods\nhave limitations, including overlooking various speech attributes and incurring\nhigh computational costs due to additional constraints introduced during\ntraining. To address these challenges, we introduce OZSpeech, the first TTS\nmethod to explore optimal transport conditional flow matching with one-step\nsampling and a learned prior as the condition, effectively disregarding\npreceding states and reducing the number of sampling steps. Our approach\noperates on disentangled, factorized components of speech in token format,\nenabling accurate modeling of each speech attribute, which enhances the TTS\nsystem's ability to precisely clone the prompt speech. Experimental results\nshow that our method achieves promising performance over existing methods in\ncontent accuracy, naturalness, prosody generation, and speaker style\npreservation. Audio samples are available at our demo page\nhttps://ozspeech.github.io/OZSpeech_Web/.",
      "tldr_zh": "该研究提出了一种名为 OZSpeech 的文本到语音 (TTS) 系统，这是首个采用 one-step zero-shot 合成的框架，通过 learned-prior-conditioned flow matching 来优化语音生成过程。不同于传统方法，OZSpeech 使用 optimal transport conditional flow matching 和分离的因子化语音组件，精确建模语音属性并减少采样步骤，从而降低计算成本并提升合成效率。实验结果显示，该方法在内容准确性、自然度、prosody generation 和 speaker style preservation 方面均优于现有技术，为高效的语音合成提供了新途径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12800v1",
      "published_date": "2025-05-19 07:31:55 UTC",
      "updated_date": "2025-05-19 07:31:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:34:54.678116"
    },
    {
      "arxiv_id": "2505.12795v1",
      "title": "FRAbench and GenEval: Scaling Fine-Grained Aspect Evaluation across Tasks, Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Shibo Hong",
        "Jiahao Ying",
        "Haiyuan Liang",
        "Mengdi Zhang",
        "Jun Kuang",
        "Jiazheng Zhang",
        "Yixin Cao"
      ],
      "abstract": "Evaluating the open-ended outputs of large language models (LLMs) has become\na bottleneck as model capabilities, task diversity, and modality coverage\nrapidly expand. Existing \"LLM-as-a-Judge\" evaluators are typically narrow in a\nfew tasks, aspects, or modalities, and easily suffer from low consistency. In\nthis paper, we argue that explicit, fine-grained aspect specification is the\nkey to both generalizability and objectivity in automated evaluation. To do so,\nwe introduce a hierarchical aspect taxonomy spanning 112 aspects that unifies\nevaluation across four representative settings - Natural Language Generation,\nImage Understanding, Image Generation, and Interleaved Text-and-Image\nGeneration. Building on this taxonomy, we create FRAbench, a benchmark\ncomprising 60.4k pairwise samples with 325k aspect-level labels obtained from a\ncombination of human and LLM annotations. FRAbench provides the first\nlarge-scale, multi-modal resource for training and meta-evaluating fine-grained\nLMM judges. Leveraging FRAbench, we develop GenEval, a fine-grained evaluator\ngeneralizable across tasks and modalities. Experiments show that GenEval (i)\nattains high agreement with GPT-4o and expert annotators, (ii) transfers\nrobustly to unseen tasks and modalities, and (iii) reveals systematic\nweaknesses of current LMMs on evaluation.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)输出评估的瓶颈，提出一个层次化方面分类法，涵盖112个方面，以统一自然语言生成、图像理解、图像生成和交错文本及图像生成等四个模态的评估。作者构建了FRAbench基准数据集，包含60.4k对样本和325k方面级标签，用于训练和元评估细粒度LMM判断器。基于FRAbench，他们开发了GenEval评估器，该系统在实验中显示出与GPT-4o和专家注释者的高度一致性，并能稳健地转移到未见任务和模态，同时揭示了当前LMMs在评估中的系统性弱点。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12795v1",
      "published_date": "2025-05-19 07:29:26 UTC",
      "updated_date": "2025-05-19 07:29:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:35:07.514406"
    },
    {
      "arxiv_id": "2505.12788v1",
      "title": "Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs",
      "title_zh": "N元",
      "authors": [
        "Zhongni Hou",
        "Miao Su",
        "Xiaolong Jin",
        "Zixuan Li",
        "Long Bai",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of\n(subject, predicate, object, timestamp) to describe temporal facts, have\nattracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional\nTKGs by utilizing n-tuples to incorporate auxiliary elements alongside core\nelements (i.e., subject, predicate, and object) of facts, so as to represent\nthem in a more fine-grained manner. Reasoning over N-TKGs aims to predict\npotential future facts based on historical ones. However, existing N-TKG\nreasoning methods often lack explainability due to their black-box nature.\nTherefore, we introduce a new Reinforcement Learning-based method, named\nMT-Path, which leverages the temporal information to traverse historical\nn-tuples and construct a temporal reasoning path. Specifically, in order to\nintegrate the information encapsulated within n-tuples, i.e., the\nentity-irrelevant information within the predicate, the information about core\nelements, and the complete information about the entire n-tuples, MT-Path\nutilizes a mixture policy-driven action selector, which bases on three\nlow-level policies, namely, the predicate-focused policy, the\ncore-element-focused policy and the whole-fact-focused policy. Further, MT-Path\nutilizes an auxiliary element-aware GCN to capture the rich semantic\ndependencies among facts, thereby enabling the agent to gain a deep\nunderstanding of each n-tuple. Experimental results demonstrate the\neffectiveness and the explainability of MT-Path.",
      "tldr_zh": "该论文针对 N-tuple Temporal Knowledge Graphs (N-TKGs) 提出了一种基于 Reinforcement Learning 的多跳推理方法 MT-Path，以预测未来事实并提升可解释性。MT-Path 通过混合策略（mixture policy）驱动的行动选择器整合 n-元组信息，包括 predicate-focused policy、core-element-focused policy 和 whole-fact-focused policy，从而处理谓词无关信息、核心元素和整体事实。实验结果显示，MT-Path 利用辅助元素-aware GCN 捕捉事实间的语义依赖，证明了其在 N-TKGs 推理中的有效性和可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12788v1",
      "published_date": "2025-05-19 07:20:33 UTC",
      "updated_date": "2025-05-19 07:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:36:01.268519"
    },
    {
      "arxiv_id": "2505.12781v1",
      "title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone",
      "title_zh": "翻译失败",
      "authors": [
        "Jitai Hao",
        "Qiang Huang",
        "Hao Liu",
        "Xinyan Xiao",
        "Zhaochun Ren",
        "Jun Yu"
      ],
      "abstract": "Training high-performing Small Language Models (SLMs) remains costly, even\nwith knowledge distillation and pruning from larger teacher models. Existing\nwork often faces three key challenges: (1) information loss from hard pruning,\n(2) inefficient alignment of representations, and (3) underutilization of\ninformative activations, particularly from Feed-Forward Networks (FFNs). To\naddress these challenges, we introduce Low-Rank Clone (LRC), an efficient\npre-training method that constructs SLMs aspiring to behavioral equivalence\nwith strong teacher models. LRC trains a set of low-rank projection matrices\nthat jointly enable soft pruning by compressing teacher weights, and activation\nclone by aligning student activations, including FFN signals, with those of the\nteacher. This unified design maximizes knowledge transfer while removing the\nneed for explicit alignment modules. Extensive experiments with open-source\nteachers (e.g., Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct) show that LRC\nmatches or surpasses state-of-the-art models trained on trillions of\ntokens--while using only 20B tokens, achieving over 1,000x training efficiency.\nOur codes and model checkpoints are available at\nhttps://github.com/CURRENTF/LowRankClone and\nhttps://huggingface.co/collections/JitaiHao/low-rank-clone-lrc-6828389e96a93f1d4219dfaf.",
      "tldr_zh": "本论文针对训练小语言模型（SLMs）的成本问题，提出了一种高效的知识蒸馏方法Low-Rank Clone (LRC)，旨在解决硬修剪导致的信息丢失、对齐表示的低效以及Feed-Forward Networks (FFNs)激活的未充分利用等问题。LRC通过训练低秩投影矩阵实现软修剪（压缩教师权重）和激活克隆（对齐学生与教师的激活信号），从而最大化知识转移而不需额外对齐模块。实验结果显示，使用仅20B tokens，LRC便能匹配或超越基于数万亿tokens训练的SOTA模型，实现超过1000倍的训练效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12781v1",
      "published_date": "2025-05-19 07:10:42 UTC",
      "updated_date": "2025-05-19 07:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:35:30.781799"
    },
    {
      "arxiv_id": "2505.12774v1",
      "title": "UniHM: Universal Human Motion Generation with Object Interactions in Indoor Scenes",
      "title_zh": "UniHM：室内场景中物体交互的通用人类运动生成",
      "authors": [
        "Zichen Geng",
        "Zeeshan Hayder",
        "Wei Liu",
        "Ajmal Mian"
      ],
      "abstract": "Human motion synthesis in complex scenes presents a fundamental challenge,\nextending beyond conventional Text-to-Motion tasks by requiring the integration\nof diverse modalities such as static environments, movable objects, natural\nlanguage prompts, and spatial waypoints. Existing language-conditioned motion\nmodels often struggle with scene-aware motion generation due to limitations in\nmotion tokenization, which leads to information loss and fails to capture the\ncontinuous, context-dependent nature of 3D human movement. To address these\nissues, we propose UniHM, a unified motion language model that leverages\ndiffusion-based generation for synthesizing scene-aware human motion. UniHM is\nthe first framework to support both Text-to-Motion and Text-to-Human-Object\nInteraction (HOI) in complex 3D scenes. Our approach introduces three key\ncontributions: (1) a mixed-motion representation that fuses continuous 6DoF\nmotion with discrete local motion tokens to improve motion realism; (2) a novel\nLook-Up-Free Quantization VAE (LFQ-VAE) that surpasses traditional VQ-VAEs in\nboth reconstruction accuracy and generative performance; and (3) an enriched\nversion of the Lingo dataset augmented with HumanML3D annotations, providing\nstronger supervision for scene-specific motion learning. Experimental results\ndemonstrate that UniHM achieves comparative performance on the OMOMO benchmark\nfor text-to-HOI synthesis and yields competitive results on HumanML3D for\ngeneral text-conditioned motion generation.",
      "tldr_zh": "本研究提出UniHM，一种统一的动作语言模型，旨在通过扩散-based生成方法处理复杂室内场景中的人类动作合成，支持Text-to-Motion和Text-to-Human-Object Interaction (HOI)任务。UniHM的关键创新包括：(1) 混合动作表示，融合连续的6DoF动作和离散局部动作标记以提升动作真实性；(2) 创新的Look-Up-Free Quantization VAE (LFQ-VAE)，在重建准确性和生成性能上超越传统VQ-VAEs；以及(3) 增强的Lingo数据集，结合HumanML3D注释以提供更强的场景特定监督。实验结果显示，UniHM在OMOMO基准上实现与最佳模型相当的性能，并在HumanML3D基准上表现出色。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12774v1",
      "published_date": "2025-05-19 07:02:12 UTC",
      "updated_date": "2025-05-19 07:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:35:43.148975"
    },
    {
      "arxiv_id": "2505.13554v1",
      "title": "Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanglin Wu",
        "Daimeng Wei",
        "Xiaoyu Chen",
        "Hengchao Shang",
        "Jiaxin Guo",
        "Zongyao Li",
        "Yuanchang Luo",
        "Jinlong Yang",
        "Zhiqiang Rao",
        "Hao Yang"
      ],
      "abstract": "Large language model (LLM) shows promising performances in a variety of\ndownstream tasks, such as machine translation (MT). However, using LLMs for\ntranslation suffers from high computational costs and significant latency.\nBased on our evaluation, in most cases, translations using LLMs are comparable\nto that generated by neural machine translation (NMT) systems. Only in\nparticular scenarios, LLM and NMT models show respective advantages. As a\nresult, integrating NMT and LLM for translation and using LLM only when\nnecessary seems to be a sound solution. A scheduling policy that optimizes\ntranslation result while ensuring fast speed and as little LLM usage as\npossible is thereby required. We compare several scheduling policies and\npropose a novel and straightforward decider that leverages source sentence\nfeatures. We conduct extensive experiments on multilingual test sets and the\nresult shows that we can achieve optimal translation performance with minimal\nLLM usage, demonstrating effectiveness of our decider.",
      "tldr_zh": "这篇论文提出了一种混合翻译方法，将神经机器翻译（NMT）和大型语言模型（LLM）相结合，以解决LLM在翻译任务中计算成本高和延迟大的问题。作者设计了一个基于源句特征的简单决策器作为调度策略，仅在特定场景（如LLM更具优势时）调用LLM，从而优化翻译性能并最小化LLM使用。实验在多语言测试集上显示，该方法实现了最佳翻译结果，同时显著减少了LLM的使用，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures, 9 tables, ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.13554v1",
      "published_date": "2025-05-19 06:50:52 UTC",
      "updated_date": "2025-05-19 06:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:35:54.297131"
    },
    {
      "arxiv_id": "2505.12767v1",
      "title": "Language Models That Walk the Talk: A Framework for Formal Fairness Certificates",
      "title_zh": "翻译失败",
      "authors": [
        "Danqing Chen",
        "Tobias Ladner",
        "Ahmed Rayen Mhadhbi",
        "Matthias Althoff"
      ],
      "abstract": "As large language models become integral to high-stakes applications,\nensuring their robustness and fairness is critical. Despite their success,\nlarge language models remain vulnerable to adversarial attacks, where small\nperturbations, such as synonym substitutions, can alter model predictions,\nposing risks in fairness-critical areas, such as gender bias mitigation, and\nsafety-critical areas, such as toxicity detection. While formal verification\nhas been explored for neural networks, its application to large language models\nremains limited. This work presents a holistic verification framework to\ncertify the robustness of transformer-based language models, with a focus on\nensuring gender fairness and consistent outputs across different gender-related\nterms. Furthermore, we extend this methodology to toxicity detection, offering\nformal guarantees that adversarially manipulated toxic inputs are consistently\ndetected and appropriately censored, thereby ensuring the reliability of\nmoderation systems. By formalizing robustness within the embedding space, this\nwork strengthens the reliability of language models in ethical AI deployment\nand content moderation.",
      "tldr_zh": "这篇论文提出一个整体验证框架，用于正式认证Transformer-based语言模型的鲁棒性，旨在应对对抗性攻击（如同义词替换）对性别公平性和安全性的潜在风险。框架通过在嵌入空间中形式化鲁棒性，确保模型在性别相关术语上输出一致，并扩展到毒性检测领域，提供正式保证以检测和审查对抗性操纵的输入。最终，该方法增强了语言模型在道德AI部署和内容审查中的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12767v1",
      "published_date": "2025-05-19 06:46:17 UTC",
      "updated_date": "2025-05-19 06:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:36:12.878035"
    },
    {
      "arxiv_id": "2505.12763v1",
      "title": "Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization",
      "title_zh": "通过奖励过度优化的视角重新审视奖励模型评估",
      "authors": [
        "Sunghwan Kim",
        "Dongjin Kang",
        "Taeyoon Kwon",
        "Hyungjoo Chae",
        "Dongha Lee",
        "Jinyoung Yeo"
      ],
      "abstract": "Reward models (RMs) play a crucial role in reinforcement learning from human\nfeedback (RLHF), aligning model behavior with human preferences. However,\nexisting benchmarks for reward models show a weak correlation with the\nperformance of optimized policies, suggesting that they fail to accurately\nassess the true capabilities of RMs. To bridge this gap, we explore several\nevaluation designs through the lens of reward overoptimization\\textemdash a\nphenomenon that captures both how well the reward model aligns with human\npreferences and the dynamics of the learning signal it provides to the policy.\nThe results highlight three key findings on how to construct a reliable\nbenchmark: (i) it is important to minimize differences between chosen and\nrejected responses beyond correctness, (ii) evaluating reward models requires\nmultiple comparisons across a wide range of chosen and rejected responses, and\n(iii) given that reward models encounter responses with diverse\nrepresentations, responses should be sourced from a variety of models. However,\nwe also observe that a extremely high correlation with degree of\noveroptimization leads to comparatively lower correlation with certain\ndownstream performance. Thus, when designing a benchmark, it is desirable to\nuse the degree of overoptimization as a useful tool, rather than the end goal.",
      "tldr_zh": "该论文重新审视了奖励模型（Reward Models, RMs）在强化学习从人类反馈（RLHF）中的评估问题，指出现有基准与优化策略性能的相关性较弱。研究通过奖励过度优化（Reward Overoptimization）的视角，探索了改进评估设计的多种方案，包括最小化chosen和rejected响应在正确性之外的差异。关键发现包括：需要进行多次比较以覆盖广泛的响应，以及从多种模型中获取响应以处理多样化表示。然而，过高的过度优化相关性可能降低与某些下游性能的相关性，因此建议将Reward Overoptimization作为评估工具而非最终目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12763v1",
      "published_date": "2025-05-19 06:43:08 UTC",
      "updated_date": "2025-05-19 06:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:36:25.244760"
    },
    {
      "arxiv_id": "2505.12762v1",
      "title": "IDEAL: Data Equilibrium Adaptation for Multi-Capability Language Model Alignment",
      "title_zh": "IDEAL：数据平衡适应用于多能力语言模型对齐",
      "authors": [
        "Chenlin Ming",
        "Chendi Qu",
        "Mengzhang Cai",
        "Qizhi Pei",
        "Zhuoshi Pan",
        "Yu Li",
        "Xiaoming Duan",
        "Lijun Wu",
        "Conghui He"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive performance through\nSupervised Fine-tuning (SFT) on diverse instructional datasets. When training\non multiple capabilities simultaneously, the mixture training dataset, governed\nby volumes of data from different domains, is a critical factor that directly\nimpacts the final model's performance. Unlike many studies that focus on\nenhancing the quality of training datasets through data selection methods, few\nworks explore the intricate relationship between the compositional quantity of\nmixture training datasets and the emergent capabilities of LLMs. Given the\navailability of a high-quality multi-domain training dataset, understanding the\nimpact of data from each domain on the model's overall capabilities is crucial\nfor preparing SFT data and training a well-balanced model that performs\neffectively across diverse domains. In this work, we introduce IDEAL, an\ninnovative data equilibrium adaptation framework designed to effectively\noptimize volumes of data from different domains within mixture SFT datasets,\nthereby enhancing the model's alignment and performance across multiple\ncapabilities. IDEAL employs a gradient-based approach to iteratively refine the\ntraining data distribution, dynamically adjusting the volumes of\ndomain-specific data based on their impact on downstream task performance. By\nleveraging this adaptive mechanism, IDEAL ensures a balanced dataset\ncomposition, enabling the model to achieve robust generalization and consistent\nproficiency across diverse tasks. Experiments across different capabilities\ndemonstrate that IDEAL outperforms conventional uniform data allocation\nstrategies, achieving a comprehensive improvement of approximately 7% in\nmulti-task evaluation scores.",
      "tldr_zh": "这篇论文介绍了 IDEAL 框架，一种用于多能力语言模型（LLMs）对齐的数据平衡适应方法，通过优化混合监督微调（SFT）数据集中的不同领域数据量来提升模型性能。IDEAL 采用基于梯度的迭代机制，动态调整领域特定数据的分布，根据其对下游任务的影响确保数据集的均衡性，从而实现模型在多样任务上的鲁棒泛化和一致表现。实验结果显示，IDEAL 相较于传统均匀数据分配策略，在多任务评估中整体提升约 7%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12762v1",
      "published_date": "2025-05-19 06:42:44 UTC",
      "updated_date": "2025-05-19 06:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:36:37.415134"
    },
    {
      "arxiv_id": "2505.12761v2",
      "title": "Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding",
      "title_zh": "通过跨变量补丁嵌入增强通道独立的时间序列预测",
      "authors": [
        "Donghwa Shin",
        "Edwin Zhang"
      ],
      "abstract": "Transformers have recently gained popularity in time series forecasting due\nto their ability to capture long-term dependencies. However, many existing\nmodels focus only on capturing temporal dependencies while omitting intricate\nrelationships between variables. Recent models have tried tackling this by\nexplicitly modeling both cross-time and cross-variate dependencies through a\nsequential or unified attention mechanism, but they are entirely channel\ndependent (CD) across all layers, making them potentially susceptible to\noverfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE),\na lightweight CD module that injects cross-variate context into\nchannel-independent (CI) models by simply modifying the patch embedding\nprocess. We achieve this by adding a learnable positional encoding and a\nlightweight router-attention block to the vanilla patch embedding layer. We\nthen integrate CVPE into Time-LLM, a multimodal CI forecasting model, to\ndemonstrate its effectiveness in capturing cross-variate dependencies and\nenhance the CI model's performance. Extensive experimental results on seven\nreal-world datasets show that our enhanced Time-LLM outperforms the original\nbaseline model simply by incorporating the CVPE module, with no other changes.",
      "tldr_zh": "本研究针对时间序列预测中的问题，指出现有 Transformers 模型虽能捕捉时间依赖，但忽略了变量间的交叉关系，且通道依赖 (CD) 模型易过拟合。作者提出 Cross-Variate Patch Embeddings (CVPE)，一个轻量级模块，通过在 patch embedding 层添加可学习定位编码和 router-attention 块，将跨变量上下文注入通道独立 (CI) 模型中。实验结果显示，将 CVPE 集成到 Time-LLM 中后，该模型在七个真实世界数据集上显著提升性能，仅凭此模块就超越了原基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12761v2",
      "published_date": "2025-05-19 06:41:14 UTC",
      "updated_date": "2025-05-20 03:01:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:36:49.025789"
    },
    {
      "arxiv_id": "2505.12751v1",
      "title": "Structure-based Anomaly Detection and Clustering",
      "title_zh": "基于结构的异常检测和聚类",
      "authors": [
        "Filippo Leveni"
      ],
      "abstract": "Anomaly detection is a fundamental problem in domains such as healthcare,\nmanufacturing, and cybersecurity. This thesis proposes new unsupervised methods\nfor anomaly detection in both structured and streaming data settings. In the\nfirst part, we focus on structure-based anomaly detection, where normal data\nfollows low-dimensional manifolds while anomalies deviate from them. We\nintroduce Preference Isolation Forest (PIF), which embeds data into a\nhigh-dimensional preference space via manifold fitting, and isolates outliers\nusing two variants: Voronoi-iForest, based on geometric distances, and\nRuzHash-iForest, leveraging Locality Sensitive Hashing for scalability. We also\npropose Sliding-PIF, which captures local manifold information for streaming\nscenarios. Our methods outperform existing techniques on synthetic and real\ndatasets. We extend this to structure-based clustering with MultiLink, a novel\nmethod for recovering multiple geometric model families in noisy data.\nMultiLink merges clusters via a model-aware linkage strategy, enabling robust\nmulti-class structure recovery. It offers key advantages over existing\napproaches, such as speed, reduced sensitivity to thresholds, and improved\nrobustness to poor initial sampling. The second part of the thesis addresses\nonline anomaly detection in evolving data streams. We propose Online Isolation\nForest (Online-iForest), which uses adaptive, multi-resolution histograms and\ndynamically updates tree structures to track changes over time. It avoids\nretraining while achieving accuracy comparable to offline models, with superior\nefficiency for real-time applications. Finally, we tackle anomaly detection in\ncybersecurity via open-set recognition for malware classification. We enhance a\nGradient Boosting classifier with MaxLogit to detect unseen malware families, a\nmethod now integrated into Cleafy's production system.",
      "tldr_zh": "这篇论文提出新的无监督方法，用于结构化和流式数据的异常检测和聚类，针对正常数据遵循低维流形（low-dimensional manifolds）的特性。核心方法包括 Preference Isolation Forest (PIF) 及其变体（如 Voronoi-iForest 和 RuzHash-iForest），用于嵌入数据并隔离异常，以及 Sliding-PIF 用于流式场景；此外，MultiLink 方法通过模型感知的链接策略实现鲁棒的多类结构恢复。实验结果显示，这些方法在合成和真实数据集上优于现有技术，而 Online Isolation Forest (Online-iForest) 则在在线数据流中实现了高效的动态更新，并在网络安全中通过增强 Gradient Boosting 分类器检测未知恶意软件家族。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Doctoral dissertation at Politecnico di Milano",
      "pdf_url": "http://arxiv.org/pdf/2505.12751v1",
      "published_date": "2025-05-19 06:20:00 UTC",
      "updated_date": "2025-05-19 06:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:37:02.313848"
    },
    {
      "arxiv_id": "2505.12750v1",
      "title": "Malware families discovery via Open-Set Recognition on Android manifest permissions",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Leveni",
        "Matteo Mistura",
        "Francesco Iubatti",
        "Carmine Giangregorio",
        "Nicolò Pastore",
        "Cesare Alippi",
        "Giacomo Boracchi"
      ],
      "abstract": "Malware are malicious programs that are grouped into families based on their\npenetration technique, source code, and other characteristics. Classifying\nmalware programs into their respective families is essential for building\neffective defenses against cyber threats. Machine learning models have a huge\npotential in malware detection on mobile devices, as malware families can be\nrecognized by classifying permission data extracted from Android manifest\nfiles. Still, the malware classification task is challenging due to the\nhigh-dimensional nature of permission data and the limited availability of\ntraining samples. In particular, the steady emergence of new malware families\nmakes it impossible to acquire a comprehensive training set covering all the\nmalware classes. In this work, we present a malware classification system that,\non top of classifying known malware, detects new ones. In particular, we\ncombine an open-set recognition technique developed within the computer vision\ncommunity, namely MaxLogit, with a tree-based Gradient Boosting classifier,\nwhich is particularly effective in classifying high-dimensional data. Our\nsolution turns out to be very practical, as it can be seamlessly employed in a\nstandard classification workflow, and efficient, as it adds minimal\ncomputational overhead. Experiments on public and proprietary datasets\ndemonstrate the potential of our solution, which has been deployed in a\nbusiness environment.",
      "tldr_zh": "本研究针对Android manifest permissions中的高维权限数据，提出了一种恶意软件（malware）家族发现系统，利用Open-Set Recognition技术（具体为MaxLogit）结合树-based Gradient Boosting分类器，实现对已知恶意软件的分类和新型恶意软件的检测。传统机器学习面临训练样本有限和新家族不断涌现的挑战，该系统通过无缝集成上述方法，显著降低了计算开销。实验在公共和专有数据集上验证了其有效性，准确率表现出色，并已在商业环境中成功部署。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to European Conference on Artificial Intelligence (ECAI\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.12750v1",
      "published_date": "2025-05-19 06:19:54 UTC",
      "updated_date": "2025-05-19 06:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:37:13.440685"
    },
    {
      "arxiv_id": "2505.12748v1",
      "title": "TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation",
      "title_zh": "翻译失败",
      "authors": [
        "Hangyu Li",
        "Qin Zhao",
        "Haoran Xu",
        "Xinyu Jiang",
        "Qingwei Ben",
        "Feiyu Jia",
        "Haoyu Zhao",
        "Liang Xu",
        "Jia Zeng",
        "Hanqing Wang",
        "Bo Dai",
        "Junting Dong",
        "Jiangmiao Pang"
      ],
      "abstract": "Teleoperation is a cornerstone of embodied-robot learning, and bimanual\ndexterous teleoperation in particular provides rich demonstrations that are\ndifficult to obtain with fully autonomous systems. While recent studies have\nproposed diverse hardware pipelines-ranging from inertial motion-capture gloves\nto exoskeletons and vision-based interfaces-there is still no unified benchmark\nthat enables fair, reproducible comparison of these systems. In this paper, we\nintroduce TeleOpBench, a simulator-centric benchmark tailored to bimanual\ndexterous teleoperation. TeleOpBench contains 30 high-fidelity task\nenvironments that span pick-and-place, tool use, and collaborative\nmanipulation, covering a broad spectrum of kinematic and force-interaction\ndifficulty. Within this benchmark we implement four representative\nteleoperation modalities-(i) MoCap, (ii) VR device, (iii) arm-hand\nexoskeletons, and (iv) monocular vision tracking-and evaluate them with a\ncommon protocol and metric suite. To validate that performance in simulation is\npredictive of real-world behavior, we conduct mirrored experiments on a\nphysical dual-arm platform equipped with two 6-DoF dexterous hands. Across 10\nheld-out tasks we observe a strong correlation between simulator and hardware\nperformance, confirming the external validity of TeleOpBench. TeleOpBench\nestablishes a common yardstick for teleoperation research and provides an\nextensible platform for future algorithmic and hardware innovation.",
      "tldr_zh": "本论文引入 TeleOpBench，这是一个以模拟器为核心的基准，用于评估双臂灵巧遥操作(bimanual dexterous teleoperation)。该基准包含 30 个高保真任务环境，涵盖拾取放置、工具使用和协作操作，并实现了四种代表性遥操作模式：MoCap、VR device、arm-hand exoskeletons 和 monocular vision tracking，通过共同协议和指标套件进行评估。实验结果显示，在模拟器和配备两个 6-DoF 灵巧手的物理平台上，性能之间存在强相关性，验证了基准的外部有效性。TeleOpBench 作为统一的评估标准，提供了一个可扩展的平台，支持未来的遥操作算法和硬件创新。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12748v1",
      "published_date": "2025-05-19 06:08:53 UTC",
      "updated_date": "2025-05-19 06:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:37:28.935473"
    },
    {
      "arxiv_id": "2505.12746v1",
      "title": "Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Haruka Asanuma",
        "Naoko Koide-Majima",
        "Ken Nakamura",
        "Takato Horii",
        "Shinji Nishimoto",
        "Masafumi Oizumi"
      ],
      "abstract": "Recent studies have revealed that human emotions exhibit a high-dimensional,\ncomplex structure. A full capturing of this complexity requires new approaches,\nas conventional models that disregard high dimensionality risk overlooking key\nnuances of human emotions. Here, we examined the extent to which the latest\ngeneration of rapidly evolving Multimodal Large Language Models (MLLMs) capture\nthese high-dimensional, intricate emotion structures, including capabilities\nand limitations. Specifically, we compared self-reported emotion ratings from\nparticipants watching videos with model-generated estimates (e.g., Gemini or\nGPT). We evaluated performance not only at the individual video level but also\nfrom emotion structures that account for inter-video relationships. At the\nlevel of simple correlation between emotion structures, our results\ndemonstrated strong similarity between human and model-inferred emotion\nstructures. To further explore whether the similarity between humans and models\nis at the signle item level or the coarse-categorical level, we applied Gromov\nWasserstein Optimal Transport. We found that although performance was not\nnecessarily high at the strict, single-item level, performance across video\ncategories that elicit similar emotions was substantial, indicating that the\nmodel could infer human emotional experiences at the category level. Our\nresults suggest that current state-of-the-art MLLMs broadly capture the complex\nhigh-dimensional emotion structures at the category level, as well as their\napparent limitations in accurately capturing entire structures at the\nsingle-item level.",
      "tldr_zh": "这篇论文探讨了人类和 Multimodal LLMs 在观看视频时引发的高维情绪结构之间的对应关系，强调了传统模型忽略高维度的风险。研究通过比较人类自报情绪评分与模型（如 Gemini 或 GPT）的生成估计，并使用 Gromov Wasserstein Optimal Transport 分析视频间关系，发现模型在整体情绪结构简单相关性和类别层面（如类似情绪的视频类别）表现出强烈相似性。结果表明，当前最先进的 MLLMs 能有效捕捉复杂的高维情绪结构，但存在单项层面准确性不足的局限性，为未来情绪建模提供了重要见解。",
      "categories": [
        "cs.AI",
        "I.2.7; I.2.10; I.5.1"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12746v1",
      "published_date": "2025-05-19 06:03:22 UTC",
      "updated_date": "2025-05-19 06:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:37:37.957513"
    },
    {
      "arxiv_id": "2505.12745v1",
      "title": "PEER pressure: Model-to-Model Regularization for Single Source Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Kyu Cho",
        "Inwoo Hwang",
        "Sanghack Lee"
      ],
      "abstract": "Data augmentation is a popular tool for single source domain generalization,\nwhich expands the source domain by generating simulated ones, improving\ngeneralization on unseen target domains. In this work, we show that the\nperformance of such augmentation-based methods in the target domains\nuniversally fluctuates during training, posing challenges in model selection\nunder realistic scenarios. We argue that the fluctuation stems from the\ninability of the model to accumulate the knowledge learned from diverse\naugmentations, exacerbating feature distortion during training. Based on this\nobservation, we propose a novel generalization method, coined Parameter-Space\nEnsemble with Entropy Regularization (PEER), that uses a proxy model to learn\nthe augmented data on behalf of the main model. The main model is updated by\naveraging its parameters with the proxy model, progressively accumulating\nknowledge over the training steps. Maximizing the mutual information between\nthe output representations of the two models guides the learning process of the\nproxy model, mitigating feature distortion during training. Experimental\nresults demonstrate the effectiveness of PEER in reducing the OOD performance\nfluctuation and enhancing generalization across various datasets, including\nPACS, Digits, Office-Home, and VLCS. Notably, our method with simple random\naugmentation achieves state-of-the-art performance, surpassing prior approaches\non sDG that utilize complex data augmentation strategies.",
      "tldr_zh": "本文研究了单源域泛化（Single Source Domain Generalization）中数据增强方法的性能波动问题，指出模型无法有效积累增强数据知识导致特征扭曲。作者提出PEER（Parameter-Space Ensemble with Entropy Regularization）方法，使用代理模型学习增强数据，并通过参数平均和熵正则化最大化两个模型输出表示的互信息，以缓解训练过程中的波动。实验结果显示，PEER在PACS、Digits、Office-Home和VLCS数据集上显著减少了OOD性能波动，并使用简单随机增强就超越了现有复杂策略，实现了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures, Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12745v1",
      "published_date": "2025-05-19 06:01:11 UTC",
      "updated_date": "2025-05-19 06:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:37:50.066035"
    },
    {
      "arxiv_id": "2505.12744v1",
      "title": "Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation",
      "title_zh": "激励大型模型中的多模态推理用于直接机器人操控",
      "authors": [
        "Weiliang Tang",
        "Dong Jing",
        "Jia-Hui Pan",
        "Zhiwu Lu",
        "Yun-Hui Liu",
        "Li Erran Li",
        "Mingyu Ding",
        "Chi-Wing Fu"
      ],
      "abstract": "Recent Large Multimodal Models have demonstrated remarkable reasoning\ncapabilities, especially in solving complex mathematical problems and realizing\naccurate spatial perception. Our key insight is that these emerging abilities\ncan naturally extend to robotic manipulation by enabling LMMs to directly infer\nthe next goal in language via reasoning, rather than relying on a separate\naction head. However, this paradigm meets two main challenges: i) How to make\nLMMs understand the spatial action space, and ii) How to fully exploit the\nreasoning capacity of LMMs in solving these tasks. To tackle the former\nchallenge, we propose a novel task formulation, which inputs the current states\nof object parts and the gripper, and reformulates rotation by a new axis\nrepresentation instead of traditional Euler angles. This representation is more\ncompatible with spatial reasoning and easier to interpret within a unified\nlanguage space. For the latter challenge, we design a pipeline to utilize\ncutting-edge LMMs to generate a small but high-quality reasoning dataset of\nmulti-round dialogues that successfully solve manipulation tasks for supervised\nfine-tuning. Then, we perform reinforcement learning by trial-and-error\ninteractions in simulation to further enhance the model's reasoning abilities\nfor robotic manipulation. Our resulting reasoning model built upon a 7B\nbackbone, named ReasonManip, demonstrates three notable advantages driven by\nits system-2 level reasoning capabilities: i) exceptional generalizability to\nout-of-distribution environments, objects, and tasks; ii) inherent sim-to-real\ntransfer ability enabled by the unified language representation shared across\ndomains; iii) transparent interpretability connecting high-level reasoning and\nlow-level control. Extensive experiments demonstrate the effectiveness of the\nproposed paradigm and its potential to advance LMM-driven robotic manipulation.",
      "tldr_zh": "该研究提出了一种新范式，利用大型多模态模型（LMMs）通过推理直接推断机器人操作的下一个目标，从而避免依赖单独的动作头。针对LMMs理解空间动作空间的挑战，作者引入了新任务表述，使用轴表示代替传统欧拉角来处理对象部件和抓取器的状态，便于在统一语言空间中进行空间推理；同时，通过生成高质量的多轮对话数据集进行监督微调，并结合强化学习在模拟环境中增强模型能力。结果开发的ReasonManip模型（基于7B骨干）展示了显著优势，包括对分布外环境、对象和任务的出色泛化能力、模拟到真实的固有转移能力，以及连接高层推理和底层控制的透明可解释性。实验验证了这一方法的有效性，为LMMs驱动的机器人操作提供了新的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12744v1",
      "published_date": "2025-05-19 06:00:14 UTC",
      "updated_date": "2025-05-19 06:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:38:01.886259"
    },
    {
      "arxiv_id": "2505.12741v1",
      "title": "Dense Communication between Language Models",
      "title_zh": "语言",
      "authors": [
        "Shiguang Wu",
        "Yaqing Wang",
        "Quanming Yao"
      ],
      "abstract": "As higher-level intelligence emerges from the combination of modular\ncomponents with lower-level intelligence, many works combines Large Language\nModels (LLMs) for collective intelligence. Such combination is achieved by\nbuilding communications among LLMs. While current systems primarily facilitate\nsuch communication through natural language, this paper proposes a novel\nparadigm of direct dense vector communication between LLMs. Our approach\neliminates the unnecessary embedding and de-embedding steps when LLM interact\nwith another, enabling more efficient information transfer, fully\ndifferentiable optimization pathways, and exploration of capabilities beyond\nhuman heuristics. We use such stripped LLMs as vertexes and optimizable seq2seq\nmodules as edges to construct LMNet, with similar structure as MLPs. By\nutilizing smaller pre-trained LLMs as vertexes, we train a LMNet that achieves\ncomparable performance with LLMs in similar size with only less than 0.1%\ntraining cost. This offers a new perspective on scaling for general\nintelligence rather than training a monolithic LLM from scratch. Besides, the\nproposed method can be used for other applications, like customizing LLM with\nlimited data, showing its versatility.",
      "tldr_zh": "这篇论文提出了一种直接的 dense vector communication 范式，用于 Large Language Models (LLMs) 之间的通信，以克服传统自然语言通信的低效问题。该方法通过消除嵌入和解嵌入步骤，实现更高效的信息传输、完全可微优化路径，并探索超出人类启发式的能力。作者构建了 LMNet，将小型预训练 LLMs 作为顶点 (vertexes)，并使用可优化的 seq2seq 模块作为边 (edges)，类似于 MLPs 的结构。实验结果显示，LMNet 在性能上与类似大小的 LLMs 相当，但训练成本仅为 0.1% 以下；此外，该方法还适用于其他应用，如用有限数据定制 LLM，提供了一种新的扩展一般智能的视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12741v1",
      "published_date": "2025-05-19 05:56:06 UTC",
      "updated_date": "2025-05-19 05:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:38:15.265262"
    },
    {
      "arxiv_id": "2505.12738v1",
      "title": "EpiLLM: Unlocking the Potential of Large Language Models in Epidemic Forecasting",
      "title_zh": "EpiLLM：解锁大型语言模型在流行病预测中的潜力",
      "authors": [
        "Chenghua Gong",
        "Rui Sun",
        "Yuhao Zheng",
        "Juyuan Zhang",
        "Tianjun Gu",
        "Liming Pan",
        "Linyuan Lv"
      ],
      "abstract": "Advanced epidemic forecasting is critical for enabling precision containment\nstrategies, highlighting its strategic importance for public health security.\nWhile recent advances in Large Language Models (LLMs) have demonstrated\neffectiveness as foundation models for domain-specific tasks, their potential\nfor epidemic forecasting remains largely unexplored. In this paper, we\nintroduce EpiLLM, a novel LLM-based framework tailored for spatio-temporal\nepidemic forecasting. Considering the key factors in real-world epidemic\ntransmission: infection cases and human mobility, we introduce a dual-branch\narchitecture to achieve fine-grained token-level alignment between such complex\nepidemic patterns and language tokens for LLM adaptation. To unleash the\nmulti-step forecasting and generalization potential of LLM architectures, we\npropose an autoregressive modeling paradigm that reformulates the epidemic\nforecasting task into next-token prediction. To further enhance LLM perception\nof epidemics, we introduce spatio-temporal prompt learning techniques, which\nstrengthen forecasting capabilities from a data-driven perspective. Extensive\nexperiments show that EpiLLM significantly outperforms existing baselines on\nreal-world COVID-19 datasets and exhibits scaling behavior characteristic of\nLLMs.",
      "tldr_zh": "该论文引入EpiLLM，一种基于Large Language Models (LLMs)的创新框架，用于时空流行病预测，旨在探索LLMs在这一领域的潜力。框架采用双分支架构，实现感染病例和人类流动性等复杂流行病模式与语言标记的细粒度对齐，并通过autoregressive建模范式将预测任务转化为下一个标记预测，同时引入时空提示学习技术来增强LLMs对流行病的感知能力。实验结果表明，EpiLLM在真实COVID-19数据集上显著优于现有基线模型，并展示了LLMs的缩放行为特性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12738v1",
      "published_date": "2025-05-19 05:53:25 UTC",
      "updated_date": "2025-05-19 05:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:38:26.797495"
    },
    {
      "arxiv_id": "2505.12737v1",
      "title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjoon Ahn",
        "Heewoong Choi",
        "Jisu Han",
        "Taesup Moon"
      ],
      "abstract": "Offline goal-conditioned reinforcement learning (GCRL) offers a practical\nlearning paradigm where goal-reaching policies are trained from abundant\nunlabeled (reward-free) datasets without additional environment interaction.\nHowever, offline GCRL still struggles with long-horizon tasks, even with recent\nadvances that employ hierarchical policy structures, such as HIQL. By\nidentifying the root cause of this challenge, we observe the following\ninsights: First, performance bottlenecks mainly stem from the high-level\npolicy's inability to generate appropriate subgoals. Second, when learning the\nhigh-level policy in the long-horizon regime, the sign of the advantage signal\nfrequently becomes incorrect. Thus, we argue that improving the value function\nto produce a clear advantage signal for learning the high-level policy is\nessential. In this paper, we propose a simple yet effective solution:\nOption-aware Temporally Abstracted value learning, dubbed OTA, which\nincorporates temporal abstraction into the temporal-difference learning\nprocess. By modifying the value update to be option-aware, the proposed\nlearning scheme contracts the effective horizon length, enabling better\nadvantage estimates even in long-horizon regimes. We experimentally show that\nthe high-level policy extracted using the OTA value function achieves strong\nperformance on complex tasks from OGBench, a recently proposed offline GCRL\nbenchmark, including maze navigation and visual robotic manipulation\nenvironments.",
      "tldr_zh": "本论文针对离线目标条件强化学习(Offline GCRL)在长时序任务中的表现问题，提出了一种Option-aware Temporally Abstracted value learning (OTA)方法，以改善高层策略的子目标生成和优势信号估计。\nOTA 通过将时间抽象融入时间差分学习过程，修改价值更新使其对选项敏感，从而缩短有效时序长度并提供更准确的优势信号。\n实验结果表明，该方法在 OGBench 基准上的复杂任务（如迷宫导航和视觉机器人操作）中表现出强性能，显著提升了离线 GCRL 的整体效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12737v1",
      "published_date": "2025-05-19 05:51:11 UTC",
      "updated_date": "2025-05-19 05:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:38:38.720803"
    },
    {
      "arxiv_id": "2505.12734v1",
      "title": "SounDiT: Geo-Contextual Soundscape-to-Landscape Generation",
      "title_zh": "SounDiT：基于地理上下文的声景到景观生成",
      "authors": [
        "Junbo Wang",
        "Haofeng Tan",
        "Bowen Liao",
        "Albert Jiang",
        "Teng Fei",
        "Qixing Huang",
        "Zhengzhong Tu",
        "Shan Ye",
        "Yuhao Kang"
      ],
      "abstract": "We present a novel and practically significant problem-Geo-Contextual\nSoundscape-to-Landscape (GeoS2L) generation-which aims to synthesize\ngeographically realistic landscape images from environmental soundscapes. Prior\naudio-to-image generation methods typically rely on general-purpose datasets\nand overlook geographic and environmental contexts, resulting in unrealistic\nimages that are misaligned with real-world environmental settings. To address\nthis limitation, we introduce a novel geo-contextual computational framework\nthat explicitly integrates geographic knowledge into multimodal generative\nmodeling. We construct two large-scale geo-contextual multimodal datasets,\nSoundingSVI and SonicUrban, pairing diverse soundscapes with real-world\nlandscape images. We propose SounDiT, a novel Diffusion Transformer (DiT)-based\nmodel that incorporates geo-contextual scene conditioning to synthesize\ngeographically coherent landscape images. Furthermore, we propose a\npractically-informed geo-contextual evaluation framework, the Place Similarity\nScore (PSS), across element-, scene-, and human perception-levels to measure\nconsistency between input soundscapes and generated landscape images. Extensive\nexperiments demonstrate that SounDiT outperforms existing baselines in both\nvisual fidelity and geographic settings. Our work not only establishes\nfoundational benchmarks for GeoS2L generation but also highlights the\nimportance of incorporating geographic domain knowledge in advancing multimodal\ngenerative models, opening new directions at the intersection of generative AI,\ngeography, urban planning, and environmental sciences.",
      "tldr_zh": "我们提出 GeoS2L 生成问题，旨在从环境声景合成地理上真实的景观图像，以解决现有音频到图像方法忽略地理上下文的局限性。为此，我们构建了两个大型数据集 SoundingSVI 和 SonicUrban，并开发了 SounDiT 模型，该模型基于 Diffusion Transformer (DiT) 并整合地理场景条件来生成一致的图像。同时，我们引入 Place Similarity Score (PSS) 作为多层次评估框架，实验结果显示 SounDiT 在视觉保真度和地理设置上优于基线模型，为生成 AI、地理学和城市规划等领域开辟新方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12734v1",
      "published_date": "2025-05-19 05:47:13 UTC",
      "updated_date": "2025-05-19 05:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:38:52.189203"
    },
    {
      "arxiv_id": "2505.12731v1",
      "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Ou",
        "Jinyu Guo",
        "Shuaihong Jiang",
        "Zhaokun Wang",
        "Libo Qin",
        "Shunyu Yao",
        "Wenhong Tian"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal method for\nexpanding the knowledge of large language models. To handle complex queries\nmore effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the\ngenerated quality through multiple interactions with external knowledge bases.\nDespite its effectiveness, A-RAG exacerbates the pre-existing efficiency\nchallenges inherent in RAG, which are attributable to its reliance on multiple\niterations of generation. Existing A-RAG approaches process all retrieved\ncontents from scratch. However, they ignore the situation where there is a\nsignificant overlap in the content of the retrieval results across rounds. The\noverlapping content is redundantly represented, which leads to a large\nproportion of repeated computations, thus affecting the overall efficiency. To\naddress this issue, this paper introduces a model-agnostic approach that can be\ngenerally applied to A-RAG methods, which is dedicated to reducing the\nredundant representation process caused by the overlapping of retrieval\nresults. Specifically, we use cache access and parallel generation to speed up\nthe prefilling and decoding stages respectively. Additionally, we also propose\nan instruction-driven module to further guide the model to more effectively\nattend to each part of the content in a more suitable way for LLMs. Experiments\nshow that our approach achieves 2.79 and 2.33 times significant acceleration on\naverage for prefilling and decoding respectively while maintaining equal\ngeneration quality.",
      "tldr_zh": "本论文针对 Adaptive-RAG (A-RAG) 在处理复杂查询时存在的效率问题提出了一种模型无关的方法，通过减少检索结果重叠的冗余表示来加速生成过程。具体方法包括使用缓存访问加速预填充阶段、并行生成加速解码阶段，以及引入一个指令驱动模块来指导大语言模型(LLMs)更有效地关注内容。实验结果显示，该方法在保持生成质量不变的情况下，平均将预填充和解码阶段分别加速2.79倍和2.33倍，从而提升了RAG系统的整体效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12731v1",
      "published_date": "2025-05-19 05:39:38 UTC",
      "updated_date": "2025-05-19 05:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:39:02.141283"
    },
    {
      "arxiv_id": "2505.12716v1",
      "title": "Shadow-FT: Tuning Instruct via Base",
      "title_zh": "翻译失败",
      "authors": [
        "Taiqiang Wu",
        "Runming Yang",
        "Jiayi Li",
        "Pengfei Hu",
        "Ngai Wong",
        "Yujiu Yang"
      ],
      "abstract": "Large language models (LLMs) consistently benefit from further fine-tuning on\nvarious tasks. However, we observe that directly tuning the INSTRUCT (i.e.,\ninstruction tuned) models often leads to marginal improvements and even\nperformance degeneration. Notably, paired BASE models, the foundation for these\nINSTRUCT variants, contain highly similar weight values (i.e., less than 2% on\naverage for Llama 3.1 8B). Therefore, we propose a novel Shadow-FT framework to\ntune the INSTRUCT models by leveraging the corresponding BASE models. The key\ninsight is to fine-tune the BASE model, and then directly graft the learned\nweight updates to the INSTRUCT model. Our proposed Shadow-FT introduces no\nadditional parameters, is easy to implement, and significantly improves\nperformance. We conduct extensive experiments on tuning mainstream LLMs, such\nas Qwen 3 and Llama 3 series, and evaluate them across 19 benchmarks covering\ncoding, reasoning, and mathematical tasks. Experimental results demonstrate\nthat Shadow-FT consistently outperforms conventional full-parameter and\nparameter-efficient tuning approaches. Further analyses indicate that Shadow-FT\ncan be applied to multimodal large language models (MLLMs) and combined with\ndirect preference optimization (DPO). Codes and weights are available at\n\\href{https://github.com/wutaiqiang/Shadow-FT}{Github}.",
      "tldr_zh": "这篇论文发现，直接微调已指令调整的 INSTRUCT 模型往往只能带来微小改善，甚至导致性能下降，而 INSTRUCT 模型与对应的 BASE 模型权重高度相似（平均不到2%）。为此，提出 Shadow-FT 框架，通过微调 BASE 模型并直接将学到的权重更新移植到 INSTRUCT 模型，从而显著提升性能，而无需增加额外参数。实验在 Qwen 3 和 Llama 3 等 LLMs 上进行，涵盖19个编码、推理和数学任务基准，结果显示 Shadow-FT 优于传统全参数和参数高效微调方法，并可扩展到多模态大语言模型（MLLMs）和直接偏好优化（DPO）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.12716v1",
      "published_date": "2025-05-19 05:16:21 UTC",
      "updated_date": "2025-05-19 05:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:39:14.278011"
    },
    {
      "arxiv_id": "2505.12711v2",
      "title": "Any-to-Any Learning in Computational Pathology via Triplet Multimodal Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Qichen Sun",
        "Zhengrui Guo",
        "Rui Peng",
        "Hao Chen",
        "Jinzhuo Wang"
      ],
      "abstract": "Recent advances in computational pathology and artificial intelligence have\nsignificantly enhanced the utilization of gigapixel whole-slide images and and\nadditional modalities (e.g., genomics) for pathological diagnosis. Although\ndeep learning has demonstrated strong potential in pathology, several key\nchallenges persist: (1) fusing heterogeneous data types requires sophisticated\nstrategies beyond simple concatenation due to high computational costs; (2)\ncommon scenarios of missing modalities necessitate flexible strategies that\nallow the model to learn robustly in the absence of certain modalities; (3) the\ndownstream tasks in CPath are diverse, ranging from unimodal to multimodal,\ncnecessitating a unified model capable of handling all modalities. To address\nthese challenges, we propose ALTER, an any-to-any tri-modal pretraining\nframework that integrates WSIs, genomics, and pathology reports. The term \"any\"\nemphasizes ALTER's modality-adaptive design, enabling flexible pretraining with\nany subset of modalities, and its capacity to learn robust, cross-modal\nrepresentations beyond WSI-centric approaches. We evaluate ALTER across\nextensive clinical tasks including survival prediction, cancer subtyping, gene\nmutation prediction, and report generation, achieving superior or comparable\nperformance to state-of-the-art baselines.",
      "tldr_zh": "本研究针对计算病理学中的挑战，提出 ALTER 框架，这是一种基于三模态预训练（整合全切片图像WSIs、基因组学和病理报告）的“any-to-any”学习方法，能够灵活处理异构数据融合、缺失模态和多样下游任务。ALTER 的模态自适应设计允许使用任何模态子集进行预训练，并生成鲁棒的跨模态表示。实验结果显示，在生存预测、癌症亚型、基因突变预测和报告生成等临床任务上，ALTER 取得了优于或相当于是最先进基线的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12711v2",
      "published_date": "2025-05-19 05:07:34 UTC",
      "updated_date": "2025-05-20 12:57:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:39:25.981844"
    },
    {
      "arxiv_id": "2505.13551v1",
      "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems",
      "title_zh": "自然",
      "authors": [
        "Serge Dolgikh"
      ],
      "abstract": "This study explores the emergence of counter-inferential behavior in natural\nand artificial cognitive systems, that is, patterns in which agents\nmisattribute empirical success or suppress adaptation, leading to epistemic\nrigidity or maladaptive stability. We analyze archetypal scenarios in which\nsuch behavior arises: reinforcement of stability through reward imbalance,\nmeta-cognitive attribution of success to internal superiority, and protective\nreframing under perceived model fragility. Rather than arising from noise or\nflawed design, these behaviors emerge through structured interactions between\ninternal information models, empirical feedback, and higher-order evaluation\nmechanisms. Drawing on evidence from artificial systems, biological cognition,\nhuman psychology, and social dynamics, we identify counter-inferential behavior\nas a general cognitive vulnerability that can manifest even in otherwise\nwell-adapted systems. The findings highlight the importance of preserving\nminimal adaptive activation under stable conditions and suggest design\nprinciples for cognitive architectures that can resist rigidity under\ninformational stress.",
      "tldr_zh": "本研究探讨了自然和人工认知系统中的 counter-inferential behavior，即代理误归因经验成功或抑制适应，导致认识僵化或不适应稳定。通过分析典型场景（如奖励失衡、元认知归因和模型脆弱下的保护性重构），研究揭示这种行为源于内部信息模型、经验反馈和更高阶评估机制的结构化互动。基于人工系统、生物认知、人类心理学和社会动态的证据，该行为被认定为一种普遍的认知脆弱性，即使在适应良好的系统中也会出现。研究强调在稳定条件下保留最小适应激活的重要性，并提出认知架构设计原则，以抵抗信息压力下的僵化。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.SI",
        "68T27, 94A15",
        "F.2.2; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13551v1",
      "published_date": "2025-05-19 05:04:07 UTC",
      "updated_date": "2025-05-19 05:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:39:38.393677"
    },
    {
      "arxiv_id": "2505.12707v1",
      "title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI",
      "title_zh": "PLAICraft：大规模时间对齐的视觉-语音-动作数据集，用于具身人工智能",
      "authors": [
        "Yingchen He",
        "Christian D. Weilbach",
        "Martyna E. Wojciechowska",
        "Yuxuan Zhang",
        "Frank Wood"
      ],
      "abstract": "Advances in deep generative modelling have made it increasingly plausible to\ntrain human-level embodied agents. Yet progress has been limited by the absence\nof large-scale, real-time, multi-modal, and socially interactive datasets that\nreflect the sensory-motor complexity of natural environments. To address this,\nwe present PLAICraft, a novel data collection platform and dataset capturing\nmultiplayer Minecraft interactions across five time-aligned modalities: video,\ngame output audio, microphone input audio, mouse, and keyboard actions. Each\nmodality is logged with millisecond time precision, enabling the study of\nsynchronous, embodied behaviour in a rich, open-ended world. The dataset\ncomprises over 10,000 hours of gameplay from more than 10,000 global\nparticipants.\\footnote{We have done a privacy review for the public release of\nan initial 200-hour subset of the dataset, with plans to release most of the\ndataset over time.} Alongside the dataset, we provide an evaluation suite for\nbenchmarking model capabilities in object recognition, spatial awareness,\nlanguage grounding, and long-term memory. PLAICraft opens a path toward\ntraining and evaluating agents that act fluently and purposefully in real time,\npaving the way for truly embodied artificial intelligence.",
      "tldr_zh": "该研究引入了PLAICraft，这是一个大规模、时间对齐的视觉-语音-动作数据集，旨在解决训练人类级别具身AI代理面临的缺乏多模态交互数据的问题。数据集通过一个新型收集平台捕获了Minecraft多人互动，包括视频、游戏音频、麦克风音频、鼠标和键盘动作等五种模态，并以毫秒级精度记录，总计超过10,000小时的游戏数据来自全球10,000多名参与者。研究同时提供了一个评估套件，用于基准测试AI模型在物体识别、空间感知、语言接地和长期记忆等方面的能力，从而为开发实时、流畅的具身人工智能铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12707v1",
      "published_date": "2025-05-19 05:00:47 UTC",
      "updated_date": "2025-05-19 05:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:39:50.556302"
    },
    {
      "arxiv_id": "2505.12705v1",
      "title": "DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Jang",
        "Seonghyeon Ye",
        "Zongyu Lin",
        "Jiannan Xiang",
        "Johan Bjorck",
        "Yu Fang",
        "Fengyuan Hu",
        "Spencer Huang",
        "Kaushil Kundalia",
        "Yen-Chen Lin",
        "Loic Magne",
        "Ajay Mandlekar",
        "Avnish Narayan",
        "You Liang Tan",
        "Guanzhi Wang",
        "Jing Wang",
        "Qi Wang",
        "Yinzhen Xu",
        "Xiaohui Zeng",
        "Kaiyuan Zheng",
        "Ruijie Zheng",
        "Ming-Yu Liu",
        "Luke Zettlemoyer",
        "Dieter Fox",
        "Jan Kautz",
        "Scott Reed",
        "Yuke Zhu",
        "Linxi Fan"
      ],
      "abstract": "We introduce DreamGen, a simple yet highly effective 4-stage pipeline for\ntraining robot policies that generalize across behaviors and environments\nthrough neural trajectories - synthetic robot data generated from video world\nmodels. DreamGen leverages state-of-the-art image-to-video generative models,\nadapting them to the target robot embodiment to produce photorealistic\nsynthetic videos of familiar or novel tasks in diverse environments. Since\nthese models generate only videos, we recover pseudo-action sequences using\neither a latent action model or an inverse-dynamics model (IDM). Despite its\nsimplicity, DreamGen unlocks strong behavior and environment generalization: a\nhumanoid robot can perform 22 new behaviors in both seen and unseen\nenvironments, while requiring teleoperation data from only a single\npick-and-place task in one environment. To evaluate the pipeline\nsystematically, we introduce DreamGen Bench, a video generation benchmark that\nshows a strong correlation between benchmark performance and downstream policy\nsuccess. Our work establishes a promising new axis for scaling robot learning\nwell beyond manual data collection.",
      "tldr_zh": "我们引入 DreamGen，一个简单的 4 阶段管道，通过神经轨迹（neural trajectories）从视频世界模型生成合成机器人数据，实现机器人策略在行为和环境上的泛化。该管道利用最先进的图像到视频生成模型，适应目标机器人形式，产生真实照片般的合成视频，并使用潜在动作模型或逆动力学模型 (IDM) 恢复伪动作序列。实验结果显示，一个类人机器人仅基于一个 pick-and-place 任务的遥操作数据，就能执行 22 个新行为，并在已见和未见环境中表现出强泛化能力。我们还开发了 DreamGen Bench 作为评估基准，证明其性能与下游策略成功率高度相关，为机器人学习开辟了超越手动数据收集的新扩展方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "See website for videos:\n  https://research.nvidia.com/labs/gear/dreamgen",
      "pdf_url": "http://arxiv.org/pdf/2505.12705v1",
      "published_date": "2025-05-19 04:55:39 UTC",
      "updated_date": "2025-05-19 04:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:40:03.501114"
    },
    {
      "arxiv_id": "2505.13550v1",
      "title": "JIR-Arena: The First Benchmark Dataset for Just-in-time Information Recommendation",
      "title_zh": "JIR-Arena：首个即时信息推荐基准数据集",
      "authors": [
        "Ke Yang",
        "Kevin Ros",
        "Shankar Kumar Senthil Kumar",
        "ChengXiang Zhai"
      ],
      "abstract": "Just-in-time Information Recommendation (JIR) is a service designed to\ndeliver the most relevant information precisely when users need it, ,\naddressing their knowledge gaps with minimal effort and boosting\ndecision-making and efficiency in daily life. Advances in device-efficient\ndeployment of foundation models and the growing use of intelligent wearable\ndevices have made always-on JIR assistants feasible. However, there has been no\nsystematic effort to formally define JIR tasks or establish evaluation\nframeworks. To bridge this gap, we present the first mathematical definition of\nJIR tasks and associated evaluation metrics. Additionally, we introduce\nJIR-Arena, a multimodal benchmark dataset featuring diverse,\ninformation-request-intensive scenarios to evaluate JIR systems across critical\ndimensions: i) accurately inferring user information needs, ii) delivering\ntimely and relevant recommendations, and iii) avoiding irrelevant content that\nmay distract users.\n  Developing a JIR benchmark dataset poses challenges due to subjectivity in\nestimating user information needs and uncontrollable system variables affecting\nreproducibility. To address these, JIR-Arena: i) combines input from multiple\nhumans and large AI models to approximate information need distributions; ii)\nassesses JIR quality through information retrieval outcomes using static\nknowledge base snapshots; and iii) employs a multi-turn, multi-entity\nvalidation framework to improve objectivity and generality. Furthermore, we\nimplement a baseline JIR system capable of processing real-time information\nstreams aligned with user inputs. Our evaluation of this baseline system on\nJIR-Arena indicates that while foundation model-based JIR systems simulate user\nneeds with reasonable precision, they face challenges in recall and effective\ncontent retrieval. To support future research in this new area, we fully\nrelease our code and data.",
      "tldr_zh": "本研究首次正式定义了 Just-in-time Information Recommendation (JIR) 任务及其评估指标，旨在通过及时提供相关信息来满足用户知识需求并提升决策效率。论文引入了 JIR-Arena，这是一个多模态基准数据集，涵盖多样化的信息请求场景，用于评估 JIR 系统在推断用户需求、及时推荐和避免无关内容方面的性能。针对数据集开发中的主观性和可重复性挑战，研究采用多人类和 AI 输入、静态知识库以及多轮验证框架来确保客观性。实验评估显示，基于 foundation models 的基线 JIR 系统能较好模拟用户需求，但存在召回和内容检索的不足；为推动该领域研究，论文公开了代码和数据。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13550v1",
      "published_date": "2025-05-19 04:49:47 UTC",
      "updated_date": "2025-05-19 04:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:40:15.889029"
    },
    {
      "arxiv_id": "2505.12701v1",
      "title": "Counterfactual Explanations for Continuous Action Reinforcement Learning",
      "title_zh": "针对连续动作强化学习的反事实解释",
      "authors": [
        "Shuyang Dong",
        "Shangtong Zhang",
        "Lu Feng"
      ],
      "abstract": "Reinforcement Learning (RL) has shown great promise in domains like\nhealthcare and robotics but often struggles with adoption due to its lack of\ninterpretability. Counterfactual explanations, which address \"what if\"\nscenarios, provide a promising avenue for understanding RL decisions but remain\nunderexplored for continuous action spaces. We propose a novel approach for\ngenerating counterfactual explanations in continuous action RL by computing\nalternative action sequences that improve outcomes while minimizing deviations\nfrom the original sequence. Our approach leverages a distance metric for\ncontinuous actions and accounts for constraints such as adhering to predefined\npolicies in specific states. Evaluations in two RL domains, Diabetes Control\nand Lunar Lander, demonstrate the effectiveness, efficiency, and generalization\nof our approach, enabling more interpretable and trustworthy RL applications.",
      "tldr_zh": "该论文针对强化学习（RL）在连续动作空间中的可解释性不足问题，提出了一种生成反事实解释（Counterfactual explanations）的创新方法，以回答“如果采取不同动作会怎样”的场景。该方法通过计算备选动作序列来优化结果，同时最小化与原序列的偏差，并引入连续动作的距离度量以及遵守预定义策略的约束。在糖尿病控制和 Lunar Lander 两个领域进行评估，证明该方法有效、高效且具有良好的泛化能力，从而提升了 RL 应用的透明度和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12701v1",
      "published_date": "2025-05-19 04:41:54 UTC",
      "updated_date": "2025-05-19 04:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:40:27.574976"
    },
    {
      "arxiv_id": "2505.12692v1",
      "title": "Bullying the Machine: How Personas Increase LLM Vulnerability",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Xu",
        "Udit Sanghi",
        "Mohan Kankanhalli"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in interactions where\nthey are prompted to adopt personas. This paper investigates whether such\npersona conditioning affects model safety under bullying, an adversarial\nmanipulation that applies psychological pressures in order to force the victim\nto comply to the attacker. We introduce a simulation framework in which an\nattacker LLM engages a victim LLM using psychologically grounded bullying\ntactics, while the victim adopts personas aligned with the Big Five personality\ntraits. Experiments using multiple open-source LLMs and a wide range of\nadversarial goals reveal that certain persona configurations -- such as\nweakened agreeableness or conscientiousness -- significantly increase victim's\nsusceptibility to unsafe outputs. Bullying tactics involving emotional or\nsarcastic manipulation, such as gaslighting and ridicule, are particularly\neffective. These findings suggest that persona-driven interaction introduces a\nnovel vector for safety risks in LLMs and highlight the need for persona-aware\nsafety evaluation and alignment strategies.",
      "tldr_zh": "这篇论文研究了大型语言模型（LLMs）在采用 personas 时，如何增加对欺凌攻击的脆弱性。研究者引入了一个模拟框架，其中攻击者 LLM 使用心理基础的欺凌策略（如 gaslighting 和 ridicule）针对采用 Big Five 个性特质的受害者 LLM 进行测试。实验结果显示，某些 personas 配置，例如降低的宜人性或责任感，会显著提升受害者产生不安全输出的风险。论文强调，persona 驱动的交互引入了新的安全威胁，并呼吁开发 persona-aware 的安全评估和对齐策略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12692v1",
      "published_date": "2025-05-19 04:32:02 UTC",
      "updated_date": "2025-05-19 04:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:40:38.973879"
    },
    {
      "arxiv_id": "2505.12684v1",
      "title": "Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Yinlin Zhu",
        "Xunkai Li",
        "Jishuo Jia",
        "Miao Hu",
        "Di Wu",
        "Meikang Qiu"
      ],
      "abstract": "Recent advances in graph machine learning have shifted to data-centric\nparadigms, driven by two emerging fields: (1) Federated graph learning (FGL)\nenables multi-client collaboration but faces challenges from data and task\nheterogeneity, limiting its practicality; (2) Graph foundation models (GFM)\noffer strong domain generalization but are usually trained on single machines,\nmissing out on cross-silo data and resources.\n  These paradigms are complementary, and their integration brings notable\nbenefits. Motivated by this, we propose FedGFM, a novel decentralized GFM\ntraining paradigm. However, a key challenge is knowledge entanglement, where\nmulti-domain knowledge merges into indistinguishable representations, hindering\ndownstream adaptation.\n  To address this, we present FedGFM+, an enhanced framework with two core\nmodules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based\ndomain-aware initialization strategy. Before pre-training, each client encodes\nits local graph into domain-specific prototypes that serve as semantic anchors.\nSynthetic embeddings around these anchors initialize the global model. We\ntheoretically prove these prototypes are distinguishable across domains,\nproviding a strong inductive bias to disentangle domain-specific knowledge. (2)\nAdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a\nlightweight graph prompt capturing domain semantics during pre-training. During\nfine-tuning, prompts from all clients form a pool from which the GFM selects\nrelevant prompts to augment target graph attributes, improving downstream\nadaptation.\n  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and\ntasks, outperforming 20 baselines from supervised learning, FGL, and federated\nGFM variants.",
      "tldr_zh": "该研究针对 Federated Graph Learning (FGL) 和 Graph Foundation Models (GFM) 的局限性，提出 FedGFM+ 框架，以缓解知识纠缠问题，实现有效的去中心化 GFM 训练。\nFedGFM+ 包括两个核心模块：AncDAI，通过全局锚点-based 域感知初始化策略生成可区分的域特定原型，提供了解纠缠的归纳偏置；以及 AdaDPP，一个本地自适应域敏感提示池，用于捕捉域语义并在微调时选择相关提示增强目标图属性。\n实验在 8 个多样基准上评估，FedGFM+ 优于 20 个基线模型，包括监督学习、FGL 和联邦 GFM 变体，展示了其在多域图学习中的显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.12684v1",
      "published_date": "2025-05-19 04:06:32 UTC",
      "updated_date": "2025-05-19 04:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:40:52.532002"
    },
    {
      "arxiv_id": "2505.12680v1",
      "title": "Ineq-Comp: Benchmarking Human-Intuitive Compositional Reasoning in Automated Theorem Proving on Inequalities",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Zhao",
        "Yihan Geng",
        "Shange Tang",
        "Yong Lin",
        "Bohan Lyu",
        "Hongzhou Lin",
        "Chi Jin",
        "Sanjeev Arora"
      ],
      "abstract": "LLM-based formal proof assistants (e.g., in Lean) hold great promise for\nautomating mathematical discovery. But beyond syntactic correctness, do these\nsystems truly understand mathematical structure as humans do? We investigate\nthis question through the lens of mathematical inequalities -- a fundamental\ntool across many domains. While modern provers can solve basic inequalities, we\nprobe their ability to handle human-intuitive compositionality. We introduce\nIneq-Comp, a benchmark built from elementary inequalities through systematic\ntransformations, including variable duplication, algebraic rewriting, and\nmulti-step composition. Although these problems remain easy for humans, we find\nthat most provers -- including Goedel, STP, and Kimina-7B -- struggle\nsignificantly. DeepSeek-Prover-V2-7B shows relative robustness -- possibly\nbecause it is trained to decompose the problems into sub-problems -- but still\nsuffers a 20\\% performance drop (pass@32). Strikingly, performance remains poor\nfor all models even when formal proofs of the constituent parts are provided in\ncontext, revealing that the source of weakness is indeed in compositional\nreasoning. Our results expose a persisting gap between the generalization\nbehavior of current AI provers and human mathematical intuition.",
      "tldr_zh": "这篇论文引入了Ineq-Comp基准，用于评估AI证明器在不等式上的组合推理能力，旨在检验这些系统是否像人类一样理解数学结构。基准通过变量复制、代数重写和多步组合等系统转换，从基本不等式构建问题，这些对人类简单但对大多数证明器（如Goedel、STP和Kimina-7B）构成重大挑战。DeepSeek-Prover-V2-7B显示相对稳健，可能得益于其分解子问题训练，但仍面临20%性能下降（pass@32）。即使提供构成部分的正式证明，模型表现仍差，揭示了当前AI证明器在组合推理方面的局限性，与人类数学直觉的泛化行为存在显著差距。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12680v1",
      "published_date": "2025-05-19 03:56:05 UTC",
      "updated_date": "2025-05-19 03:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:41:04.895154"
    },
    {
      "arxiv_id": "2505.13547v1",
      "title": "Exploring Federated Pruning for Large Language Models",
      "title_zh": "探索针对大型语言模型的联邦剪枝",
      "authors": [
        "Pengxin Guo",
        "Yinong Wang",
        "Wei Li",
        "Mengting Liu",
        "Ming Li",
        "Jinkai Zheng",
        "Liangqiong Qu"
      ],
      "abstract": "LLM pruning has emerged as a promising technology for compressing LLMs,\nenabling their deployment on resource-limited devices. However, current\nmethodologies typically require access to public calibration samples, which can\nbe challenging to obtain in privacy-sensitive domains. To address this issue,\nwe introduce FedPrLLM, a comprehensive federated pruning framework designed for\nthe privacy-preserving compression of LLMs. In FedPrLLM, each client only needs\nto calculate a pruning mask matrix based on its local calibration data and\nshare it with the server to prune the global model. This approach allows for\ncollaborative pruning of the global model with the knowledge of each client\nwhile maintaining local data privacy. Additionally, we conduct extensive\nexperiments to explore various possibilities within the FedPrLLM framework,\nincluding different comparison groups, pruning strategies, and the decision to\nscale weights. Our extensive evaluation reveals that one-shot pruning with\nlayer comparison and no weight scaling is the optimal choice within the\nFedPrLLM framework. We hope our work will help guide future efforts in pruning\nLLMs in privacy-sensitive fields. Our code is available at\nhttps://github.com/Pengxin-Guo/FedPrLLM.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的联邦修剪（Federated Pruning），以解决传统修剪方法依赖公共校准样本而可能侵犯隐私的问题。作者提出 FedPrLLM 框架，一个隐私保护的联邦修剪系统，其中每个客户端仅基于本地校准数据计算修剪掩码矩阵，并与服务器共享，以实现全局模型的协作修剪，同时保持数据隐私。该框架通过实验评估不同修剪策略，发现 one-shot pruning 结合层比较和不缩放权重是最优选择，可有效压缩 LLMs 并提升在隐私敏感领域的适用性。研究提供了开源代码（https://github.com/Pengxin-Guo/FedPrLLM），旨在指导未来的相关工作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13547v1",
      "published_date": "2025-05-19 03:41:54 UTC",
      "updated_date": "2025-05-19 03:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:41:16.940213"
    },
    {
      "arxiv_id": "2505.12669v1",
      "title": "Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinaba Roy",
        "Geeta Puri",
        "Dorien Herremans"
      ],
      "abstract": "We present Text2midi-InferAlign, a novel technique for improving symbolic\nmusic generation at inference time. Our method leverages text-to-audio\nalignment and music structural alignment rewards during inference to encourage\nthe generated music to be consistent with the input caption. Specifically, we\nintroduce two objectives scores: a text-audio consistency score that measures\nrhythmic alignment between the generated music and the original text caption,\nand a harmonic consistency score that penalizes generated music containing\nnotes inconsistent with the key. By optimizing these alignment-based objectives\nduring the generation process, our model produces symbolic music that is more\nclosely tied to the input captions, thereby improving the overall quality and\ncoherence of the generated compositions. Our approach can extend any existing\nautoregressive model without requiring further training or fine-tuning. We\nevaluate our work on top of Text2midi - an existing text-to-midi generation\nmodel, demonstrating significant improvements in both objective and subjective\nevaluation metrics.",
      "tldr_zh": "该论文提出了 Text2midi-InferAlign，一种在推理时（Inference-Time Alignment）通过文本到音频对齐和音乐结构对齐奖励来改善符号音乐生成的技术。方法引入了两个优化目标分数：文本-音频一致性分数（测量生成的音乐与输入标题的节奏对齐）和和谐一致性分数（惩罚与调性不一致的音符），从而增强生成的音乐与标题的一致性。实验在现有自回归模型 Text2midi 上进行，结果显示该方法显著提高了音乐的质量和连贯性，在客观和主观评估指标上取得了改进，而无需额外训练或微调。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS",
        "68T07",
        "I.2.1"
      ],
      "primary_category": "cs.SD",
      "comment": "7 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12669v1",
      "published_date": "2025-05-19 03:36:06 UTC",
      "updated_date": "2025-05-19 03:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:41:28.075776"
    },
    {
      "arxiv_id": "2505.13546v1",
      "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems",
      "title_zh": "提示稳定性至关重要：评估和优化通用目的系统中的自动生成提示",
      "authors": [
        "Ke Chen",
        "Yufei Zhou",
        "Xitong Zhang",
        "Haohan Wang"
      ],
      "abstract": "Automatic prompt generation plays a crucial role in enabling general-purpose\nmulti-agent systems to perform diverse tasks autonomously. Existing methods\ntypically evaluate prompts based on their immediate task performance,\noverlooking the intrinsic qualities that determine their reliability. This\noutcome-centric view not only limits interpretability but also fails to account\nfor the inherent stochasticity of large language models (LLMs). In this work,\nwe bring attention to prompt stability-the consistency of model responses\nacross repeated executions-as a key factor for building robust and effective\nprompt generation systems. To quantify this, we propose semantic stability as a\ncriterion for assessing the response consistency of prompts, and fine-tune a\nLLaMA-based evaluator to measure it automatically across tasks. These\ncomponents have enabled us to develop the first stability-aware general-purpose\nprompt generation system that leverages stability feedback to iteratively\nenhance both prompt quality and system-level performance. Furthermore, we\nestablish a logical chain between prompt stability and task success by\nanalyzing the structural dependencies within our system, proving stability as a\nnecessary condition for effective system-level execution. Empirical results\nacross general and domain-specific tasks demonstrate that our stability-aware\nframework improves both accuracy and output consistency. By shifting the focus\nfrom one-off results to persistent reliability, our work offers a new\nperspective on prompt design and contributes practical tools for building more\ntrustworthy general-purpose systems.",
      "tldr_zh": "本文研究了自动提示生成在通用多智能体系统中的重要性，强调了提示稳定性（prompt stability）作为评估可靠性的关键指标，因为现有方法仅关注即时任务性能而忽略响应一致性。作者提出语义稳定性（semantic stability）作为评估标准，并微调了一个 LLaMA-based evaluator 来自动测量提示在不同任务中的一致性。基于此，他们开发了首个稳定性-aware 提示生成系统，通过迭代稳定性反馈优化提示质量和系统性能，并证明了提示稳定性是任务成功必要条件。实证结果显示，该框架在通用和领域特定任务上显著提高了准确性和输出一致性，为构建更可信赖的系统提供了实用工具和新视角。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13546v1",
      "published_date": "2025-05-19 03:28:33 UTC",
      "updated_date": "2025-05-19 03:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:41:41.775348"
    },
    {
      "arxiv_id": "2505.12664v1",
      "title": "Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Xing",
        "Zhaoyang Zhang",
        "Zirui Chen",
        "Hongning Ruan",
        "Zhaohui Yang"
      ],
      "abstract": "In this paper, we incorporate physical knowledge into learning-based\nhigh-precision target sensing using the multi-view channel state information\n(CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind\nof multi-view sensing problem can be naturally cast into a conditional\ngeneration framework. To this end, we design a bipartite neural network\narchitecture, the first part of which uses an elaborately designed encoder to\nfuse the latent target features embedded in the multi-view CSI, and then the\nsecond uses them as conditioning inputs of a powerful generative model to guide\nthe target's reconstruction. Specifically, the encoder is designed to capture\nthe physical correlation between the CSI and the target, and also be adaptive\nto the numbers and positions of BS-UE pairs. Therein the view-specific nature\nof CSI is assimilated by introducing a spatial positional embedding scheme,\nwhich exploits the structure of electromagnetic(EM)-wave propagation channels.\nFinally, a conditional diffusion model with a weighted loss is employed to\ngenerate the target's point cloud from the fused features. Extensive numerical\nresults demonstrate that the proposed generative multi-view (Gen-MV) sensing\nframework exhibits excellent flexibility and significant performance\nimprovement on the reconstruction quality of target's shape and EM properties.",
      "tldr_zh": "本文提出了一种基于条件生成学习的框架，用于多视图无线感知，利用多基站(BSs)和用户设备(UEs)之间的信道状态信息(CSI)融入物理知识进行高精度目标重建。框架采用二分神经网络架构，包括一个设计精巧的编码器来融合多视图CSI中的潜在目标特征，并通过空间位置嵌入方案捕获电磁(EM)-波传播通道的物理相关性；随后，使用条件扩散模型以这些特征作为条件输入生成目标的点云。实验结果显示，该生成多视图(Gen-MV)感知方法在目标形状和电磁属性的重建质量上表现出卓越的灵活性和显著性能提升。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "submitted to IEEE Transactions on Wireless Communications",
      "pdf_url": "http://arxiv.org/pdf/2505.12664v1",
      "published_date": "2025-05-19 03:27:24 UTC",
      "updated_date": "2025-05-19 03:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:41:52.914267"
    },
    {
      "arxiv_id": "2505.12662v1",
      "title": "Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering",
      "title_zh": "Know3-RAG：一个知识感知 RAG 框架，具有自适应检索、生成和过滤",
      "authors": [
        "Xukai Liu",
        "Ye Liu",
        "Shiwen Wu",
        "Yanghai Zhang",
        "Yihao Yuan",
        "Kai Zhang",
        "Qi Liu"
      ],
      "abstract": "Recent advances in large language models (LLMs) have led to impressive\nprogress in natural language generation, yet their tendency to produce\nhallucinated or unsubstantiated content remains a critical concern. To improve\nfactual reliability, Retrieval-Augmented Generation (RAG) integrates external\nknowledge during inference. However, existing RAG systems face two major\nlimitations: (1) unreliable adaptive control due to limited external knowledge\nsupervision, and (2) hallucinations caused by inaccurate or irrelevant\nreferences. To address these issues, we propose Know3-RAG, a knowledge-aware\nRAG framework that leverages structured knowledge from knowledge graphs (KGs)\nto guide three core stages of the RAG process, including retrieval, generation,\nand filtering. Specifically, we introduce a knowledge-aware adaptive retrieval\nmodule that employs KG embedding to assess the confidence of the generated\nanswer and determine retrieval necessity, a knowledge-enhanced reference\ngeneration strategy that enriches queries with KG-derived entities to improve\ngenerated reference relevance, and a knowledge-driven reference filtering\nmechanism that ensures semantic alignment and factual accuracy of references.\nExperiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG\nconsistently outperforms strong baselines, significantly reducing\nhallucinations and enhancing answer reliability.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 容易产生幻觉 (hallucinations) 的问题，提出 Know3-RAG 框架，利用知识图谱 (KGs) 来提升 Retrieval-Augmented Generation (RAG) 的可靠性和准确性。框架包括三个核心模块：知识-aware adaptive retrieval 通过 KG embedding 评估答案信心并决定检索必要性、knowledge-enhanced reference generation 用 KG 派生实体丰富查询以提高引用相关性，以及 knowledge-driven reference filtering 确保引用的语义对齐和事实准确性。实验在多个开放域 QA 基准上表明，Know3-RAG 显著超越强基线，减少了幻觉并提升了答案可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12662v1",
      "published_date": "2025-05-19 03:25:18 UTC",
      "updated_date": "2025-05-19 03:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:42:04.829933"
    },
    {
      "arxiv_id": "2505.13545v1",
      "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Foo",
        "Pradyumna Shyama Prasad",
        "Shaun Khoo"
      ],
      "abstract": "While the capabilities of large language models (LLMs) have progressed\nsignificantly, their use in high-stakes applications have been limited due to\nrisks of hallucination. One key approach in reducing hallucination is\nretrieval-augmented generation (RAG), but even in such setups, LLMs may still\nhallucinate when presented with questions outside of the knowledge base. Such\nbehavior is unacceptable in high-stake applications where LLMs are expected to\nabstain from answering queries it does not have sufficient context on. In this\nwork, we present a novel methodology for systematically evaluating\nout-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not\nknow) in the RAG setting, without the need for manual annotation of gold\nstandard answers. We implement our methodology in knowornot, an open-source\nlibrary that enables users to develop their own customized evaluation data and\npipelines for OOKB robustness. knowornot comprises four main features. Firstly,\nit provides a unified, high-level API that streamlines the process of setting\nup and running robustness benchmarks. Secondly, its modular architecture\nemphasizes extensibility and flexibility, allowing users to easily integrate\ntheir own LLM clients and RAG settings. Thirdly, its rigorous data modeling\ndesign ensures experiment reproducibility, reliability and traceability.\nLastly, it implements a comprehensive suite of tools for users to customize\ntheir pipelines. We demonstrate the utility of knowornot by developing a\nchallenging benchmark, PolicyBench, which spans four Question-Answer (QA)\nchatbots on government policies, and analyze its OOKB robustness. The source\ncode of knowornot is available\nhttps://github.com/govtech-responsibleai/KnowOrNot.",
      "tldr_zh": "本论文介绍了 Know Or Not，一个开源库，用于评估大型语言模型 (LLMs) 在检索增强生成 (RAG) 设置下的 out-of-knowledge base (OOKB) 鲁棒性，以减少模型在知识库外问题上的幻觉风险。研究提出了一种无需手动标注答案的新方法，通过系统评估 LLMs 是否知道或不知道特定查询的答案。Know Or Not 库包括统一的高级 API、模块化架构、严格数据建模以及自定义工具集，以提升实验的可重现性和灵活性。作者通过开发 PolicyBench 基准测试，分析了四个政府政策 QA 聊天机器人的 OOKB 鲁棒性，展示了库的实用价值。源代码可从 https://github.com/govtech-responsibleai/KnowOrNot 获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13545v1",
      "published_date": "2025-05-19 03:17:41 UTC",
      "updated_date": "2025-05-19 03:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:42:16.823638"
    },
    {
      "arxiv_id": "2505.12655v1",
      "title": "Web IP at Risk: Prevent Unauthorized Real-Time Retrieval by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yisheng Zhong",
        "Yizhu Wen",
        "Junfeng Guo",
        "Mehran Kafai",
        "Heng Huang",
        "Hanqing Guo",
        "Zhuangdi Zhu"
      ],
      "abstract": "Protecting cyber Intellectual Property (IP) such as web content is an\nincreasingly critical concern. The rise of large language models (LLMs) with\nonline retrieval capabilities presents a double-edged sword that enables\nconvenient access to information but often undermines the rights of original\ncontent creators. As users increasingly rely on LLM-generated responses, they\ngradually diminish direct engagement with original information sources,\nsignificantly reducing the incentives for IP creators to contribute, and\nleading to a saturating cyberspace with more AI-generated content. In response,\nwe propose a novel defense framework that empowers web content creators to\nsafeguard their web-based IP from unauthorized LLM real-time extraction by\nleveraging the semantic understanding capability of LLMs themselves. Our method\nfollows principled motivations and effectively addresses an intractable\nblack-box optimization problem. Real-world experiments demonstrated that our\nmethods improve defense success rates from 2.5% to 88.6% on different LLMs,\noutperforming traditional defenses such as configuration-based restrictions.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)对网络知识产权(IP)的未经授权实时检索带来的风险，导致用户减少直接访问原内容并削弱创作者动力。作者提出了一种新型防御框架，利用LLMs的语义理解能力，帮助网页内容创作者保护其IP，通过解决黑箱优化问题实现有效防护。实验结果显示，该方法在不同LLMs上将防御成功率从2.5%提高到88.6%，显著优于传统的基于配置的限制措施。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 13 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.12655v1",
      "published_date": "2025-05-19 03:14:08 UTC",
      "updated_date": "2025-05-19 03:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:42:29.518472"
    },
    {
      "arxiv_id": "2505.12654v2",
      "title": "Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals",
      "title_zh": "使用语言、声学和",
      "authors": [
        "Yuxin Lin",
        "Yinglin Zheng",
        "Ming Zeng",
        "Wangzheng Shi"
      ],
      "abstract": "This paper addresses the gap in predicting turn-taking and backchannel\nactions in human-machine conversations using multi-modal signals (linguistic,\nacoustic, and visual). To overcome the limitation of existing datasets, we\npropose an automatic data collection pipeline that allows us to collect and\nannotate over 210 hours of human conversation videos. From this, we construct a\nMulti-Modal Face-to-Face (MM-F2F) human conversation dataset, including over\n1.5M words and corresponding turn-taking and backchannel annotations from\napproximately 20M frames. Additionally, we present an end-to-end framework that\npredicts the probability of turn-taking and backchannel actions from\nmulti-modal signals. The proposed model emphasizes the interrelation between\nmodalities and supports any combination of text, audio, and video inputs,\nmaking it adaptable to a variety of realistic scenarios. Our experiments show\nthat our approach achieves state-of-the-art performance on turn-taking and\nbackchannel prediction tasks, achieving a 10% increase in F1-score on\nturn-taking and a 33% increase on backchannel prediction. Our dataset and code\nare publicly available online to ease of subsequent research.",
      "tldr_zh": "这篇论文针对人机对话中预测 turn-taking（交谈轮换）和 backchannel（回馈信号）的问题，使用 linguistic（语言）、acoustic（声学）和 visual（视觉）信号进行多模态分析。研究者提出一个自动数据收集管道，构建了 Multi-Modal Face-to-Face (MM-F2F) 数据集，包含超过210小时视频、1.5M单词和从约20M帧中提取的 turn-taking 和 backchannel 注解。论文呈现了一个端到端框架，支持文本、音频和视频的任意组合，强调模态间的相互关系，以适应现实场景。实验结果显示，该方法在 turn-taking 预测上F1-score提高了10%，在 backchannel 预测上提高了33%，达到了最先进性能。该数据集和代码已公开，以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepected by ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12654v2",
      "published_date": "2025-05-19 03:08:30 UTC",
      "updated_date": "2025-05-20 06:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:42:43.447393"
    },
    {
      "arxiv_id": "2505.12651v1",
      "title": "$\\texttt{DIAMONDs}$: A Dataset for $\\mathbb{D}$ynamic $\\mathbb{I}$nformation $\\mathbb{A}$nd $\\mathbb{M}$ental modeling $\\mathbb{O}$f $\\mathbb{N}$umeric $\\mathbb{D}$iscussions",
      "title_zh": "翻译失败",
      "authors": [
        "Sayontan Ghosh",
        "Mahnaz Koupaee",
        "Yash Kumar Lal",
        "Pegah Alipoormolabashi",
        "Mohammad Saqib Hasan",
        "Jun Seok Kang",
        "Niranjan Balasubramanian"
      ],
      "abstract": "Understanding multiparty conversations demands robust Theory of Mind (ToM)\ncapabilities, including the ability to track dynamic information, manage\nknowledge asymmetries, and distinguish relevant information across extended\nexchanges. To advance ToM evaluation in such settings, we present a carefully\ndesigned scalable methodology for generating high-quality benchmark\nconversation-question pairs with these characteristics. Using this methodology,\nwe create $\\texttt{DIAMONDs}$, a new conversational QA dataset covering common\nbusiness, financial or other group interactions. In these goal-oriented\nconversations, participants often have to track certain numerical quantities\n(say $\\textit{expected profit}$) of interest that can be derived from other\nvariable quantities (like $\\textit{marketing expenses, expected sales,\nsalary}$, etc.), whose values also change over the course of the conversation.\n$\\texttt{DIAMONDs}$ questions pose simple numerical reasoning problems over\nsuch quantities of interest (e.g., $\\textit{funds required for charity events,\nexpected company profit next quarter}$, etc.) in the context of the information\nexchanged in conversations. This allows for precisely evaluating ToM\ncapabilities for carefully tracking and reasoning over participants' knowledge\nstates.\n  Our evaluation of state-of-the-art language models reveals significant\nchallenges in handling participant-centric reasoning, specifically in\nsituations where participants have false beliefs. Models also struggle with\nconversations containing distractors and show limited ability to identify\nscenarios with insufficient information. These findings highlight current\nmodels' ToM limitations in handling real-world multi-party conversations.",
      "tldr_zh": "该论文引入了 $\\texttt{DIAMONDs}$ 数据集，用于评估多方对话中的 Theory of Mind (ToM) 能力，焦点在于跟踪动态信息、管理知识不对称以及数字推理。研究者设计了一个可扩展的方法生成高质量的对话-问题对，涵盖商业和金融场景，其中参与者需处理变化的数字量（如预期利润），并回答基于对话信息的数字推理问题。实验结果显示，现有语言模型在处理参与者中心推理（如假信念）、干扰项和信息不足场景时表现不佳，突显了模型在真实多方对话中 ToM 能力的局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12651v1",
      "published_date": "2025-05-19 03:05:13 UTC",
      "updated_date": "2025-05-19 03:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:42:54.144068"
    },
    {
      "arxiv_id": "2505.12650v1",
      "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use",
      "title_zh": "翻译失败",
      "authors": [
        "Yaotian Yang",
        "Yiwen Tang",
        "Yizhe Chen",
        "Xiao Chen",
        "Jiangjie Qiu",
        "Hao Xiong",
        "Haoyu Yin",
        "Zhiyao Luo",
        "Yifei Zhang",
        "Sijia Tao",
        "Wentao Li",
        "Qinghua Zhang",
        "Yuqiang Li",
        "Wanli Ouyang",
        "Bin Zhao",
        "Xiaonan Wang",
        "Fei Wei"
      ],
      "abstract": "Machine learning-based interatomic potentials and force fields depend\ncritically on accurate atomic structures, yet such data are scarce due to the\nlimited availability of experimentally resolved crystals. Although\natomic-resolution electron microscopy offers a potential source of structural\ndata, converting these images into simulation-ready formats remains\nlabor-intensive and error-prone, creating a bottleneck for model training and\nvalidation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that\nautomatically transforms scanning transmission electron microscopy (STEM)\nimages into atomic crystal structures and predicts their physical properties.\nAutoMat combines pattern-adaptive denoising, physics-guided template retrieval,\nsymmetry-aware atomic reconstruction, fast relaxation and property prediction\nvia MatterSim, and coordinated orchestration across all stages. We propose the\nfirst dedicated STEM2Mat-Bench for this task and evaluate performance using\nlattice RMSD, formation energy MAE, and structure-matching success rate. By\norchestrating external tool calls, AutoMat enables a text-only LLM to\noutperform vision-language models in this domain, achieving closed-loop\nreasoning throughout the pipeline. In large-scale experiments over 450\nstructure samples, AutoMat substantially outperforms existing multimodal large\nlanguage models and tools. These results validate both AutoMat and\nSTEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic\nsimulation in materials science.The code and dataset are publicly available at\nhttps://github.com/yyt-2378/AutoMat and\nhttps://huggingface.co/datasets/yaotianvector/STEM2Mat.",
      "tldr_zh": "本文提出 AutoMat，一种端到端的代理辅助管道，用于自动将扫描传输电子显微镜 (STEM) 图像转换为模拟-ready的原子晶体结构，并预测其物理属性，以解决实验结构数据稀缺的问题。AutoMat 整合了模式自适应去噪、物理引导模板检索、对称感知原子重建、快速松弛和属性预测 via MatterSim 等技术，通过协调外部工具调用实现闭环推理。研究引入了首个专用基准 STEM2Mat-Bench，使用 lattice RMSD、formation energy MAE 和 structure-matching success rate 评估，在 450 个结构样本的大规模实验中，AutoMat 显著优于现有多模态大语言模型和工具。该框架标志着材料科学中桥接显微镜和原子模拟的关键进展，并公开了代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The code and dataset are publicly available at\n  https://github.com/yyt-2378/AutoMat and\n  https://huggingface.co/datasets/yaotianvector/STEM2Mat",
      "pdf_url": "http://arxiv.org/pdf/2505.12650v1",
      "published_date": "2025-05-19 03:04:50 UTC",
      "updated_date": "2025-05-19 03:04:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:43:07.582168"
    },
    {
      "arxiv_id": "2505.12641v1",
      "title": "Single Image Reflection Removal via inter-layer Complementarity",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Huang",
        "Zi'ang Li",
        "Tianle Hu",
        "Jie Wen",
        "Guanbin Li",
        "Jinglin Zhang",
        "Guoxu Zhou",
        "Xiaozhao Fang"
      ],
      "abstract": "Although dual-stream architectures have achieved remarkable success in single\nimage reflection removal, they fail to fully exploit inter-layer\ncomplementarity in their physical modeling and network design, which limits the\nquality of image separation. To address this fundamental limitation, we propose\ntwo targeted improvements to enhance dual-stream architectures: First, we\nintroduce a novel inter-layer complementarity model where low-frequency\ncomponents extracted from the residual layer interact with the transmission\nlayer through dual-stream architecture to enhance inter-layer complementarity.\nMeanwhile, high-frequency components from the residual layer provide inverse\nmodulation to both streams, improving the detail quality of the transmission\nlayer. Second, we propose an efficient inter-layer complementarity attention\nmechanism which first cross-reorganizes dual streams at the channel level to\nobtain reorganized streams with inter-layer complementary structures, then\nperforms attention computation on the reorganized streams to achieve better\ninter-layer separation, and finally restores the original stream structure for\noutput. Experimental results demonstrate that our method achieves\nstate-of-the-art separation quality on multiple public datasets while\nsignificantly reducing both computational cost and model complexity.",
      "tldr_zh": "该论文针对单图像反射去除问题，指出现有双-stream architectures 未能充分利用层间互补性，从而限制了图像分离质量。作者提出两点改进：一是引入新型层间互补性模型，通过从残差层提取的低频组件与传输层交互，以及高频组件的反向调制，来提升传输层的细节质量；二是设计高效的层间互补性注意力机制，包括通道级别的双流交叉重组、注意力计算和原始结构恢复。实验结果显示，该方法在多个公共数据集上实现了最先进的分离质量，同时显著降低了计算成本和模型复杂度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12641v1",
      "published_date": "2025-05-19 02:50:15 UTC",
      "updated_date": "2025-05-19 02:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:43:16.288263"
    },
    {
      "arxiv_id": "2505.12638v2",
      "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell Chromatin Accessibility Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng Jiao",
        "Yuchen Liu",
        "Yu Zhang",
        "Xin Guo",
        "Yushuai Wu",
        "Chen Jiang",
        "Jiyang Li",
        "Hongwei Zhang",
        "Limei Han",
        "Xin Gao",
        "Yuan Qi",
        "Yuan Cheng"
      ],
      "abstract": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achieved significant success\nin single-cell transcriptomics, there is currently no foundation model for\nscATAC-seq that supports zero-shot high-quality cell identification and\ncomprehensive multi-omics analysis simultaneously. Key challenges lie in the\nhigh dimensionality and sparsity of scATAC-seq data, as well as the lack of a\nstandardized schema for representing open chromatin regions (OCRs). Here, we\npresent ChromFound, a foundation model tailored for scATAC-seq. ChromFound\nutilizes a hybrid architecture and genome-aware tokenization to effectively\ncapture genome-wide long contexts and regulatory signals from dynamic chromatin\nlandscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease\nconditions, ChromFound demonstrates broad applicability across 6 diverse tasks.\nNotably, it achieves robust zero-shot performance in generating universal cell\nrepresentations and exhibits excellent transferability in cell type annotation\nand cross-omics prediction. By uncovering enhancer-gene links undetected by\nexisting computational methods, ChromFound offers a promising framework for\nunderstanding disease risk variants in the noncoding genome.",
      "tldr_zh": "该论文提出 ChromFound，一种针对单细胞染色质可及性数据 (scATAC-seq) 的通用基础模型，旨在解决数据高维稀疏性和开放染色质区域 (OCRs) 表示标准化的挑战。ChromFound 采用混合架构和 genome-aware tokenization 技术，在 1.97 百万细胞数据上预训练，以捕获基因组范围的长上下文和调控信号。实验结果显示，该模型在 6 个多样任务中表现出色，包括零-shot 细胞识别、细胞类型注释和跨组学预测，并能发现现有方法未检测到的增强子-基因链接，为理解非编码基因组中的疾病风险变异提供新框架。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12638v2",
      "published_date": "2025-05-19 02:45:42 UTC",
      "updated_date": "2025-05-20 02:40:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:43:28.630854"
    },
    {
      "arxiv_id": "2505.12632v1",
      "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yunseok Jang",
        "Yeda Song",
        "Sungryull Sohn",
        "Lajanugen Logeswaran",
        "Tiange Luo",
        "Dong-Ki Kim",
        "Kyunghoon Bae",
        "Honglak Lee"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have sparked significant interest in developing GUI visual\nagents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from\nYouTube), a large-scale dataset of 313K annotated frames from 20K instructional\nvideos capturing diverse real-world mobile OS navigation across multiple\nplatforms. Models that include MONDAY in their pre-training phases demonstrate\nrobust cross-platform generalization capabilities, consistently outperforming\nmodels trained on existing single OS datasets while achieving an average\nperformance gain of 18.11%p on an unseen mobile OS platform. To enable\ncontinuous dataset expansion as mobile platforms evolve, we present an\nautomated framework that leverages publicly available video content to create\ncomprehensive task datasets without manual annotation. Our framework comprises\nrobust OCR-based scene detection (95.04% F1score), near-perfect UI element\ndetection (99.87% hit ratio), and novel multi-step action identification to\nextract reliable action sequences across diverse interface configurations. We\ncontribute both the MONDAY dataset and our automated collection framework to\nfacilitate future research in mobile OS navigation.",
      "tldr_zh": "本研究引入了MONDAY数据集，该数据集包含31.3K个标注帧，源自20K个YouTube教学视频，涵盖多种平台的移动操作系统导航任务，从而支持Large Language Models (LLMs)和Vision-Language Models (VLMs)的GUI视觉代理开发。研究提出一个自动化框架，利用OCR-based scene detection (95.04% F1 score)、UI element detection (99.87% hit ratio)和multi-step action identification，从公开视频中提取可靠行动序列，实现无手动标注的扩展数据集生成。实验结果显示，加入MONDAY预训练的模型在跨平台泛化能力上优于现有单OS数据集，平均在未见平台上提升18.11%，为未来移动OS导航研究提供宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12632v1",
      "published_date": "2025-05-19 02:39:03 UTC",
      "updated_date": "2025-05-19 02:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:43:39.974316"
    },
    {
      "arxiv_id": "2505.12630v1",
      "title": "Degradation-Aware Feature Perturbation for All-in-One Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangpeng Tian",
        "Xiangyu Liao",
        "Xiao Liu",
        "Meng Li",
        "Chao Ren"
      ],
      "abstract": "All-in-one image restoration aims to recover clear images from various\ndegradation types and levels with a unified model. Nonetheless, the significant\nvariations among degradation types present challenges for training a universal\nmodel, often resulting in task interference, where the gradient update\ndirections of different tasks may diverge due to shared parameters. To address\nthis issue, motivated by the routing strategy, we propose DFPIR, a novel\nall-in-one image restorer that introduces Degradation-aware Feature\nPerturbations(DFP) to adjust the feature space to align with the unified\nparameter space. In this paper, the feature perturbations primarily include\nchannel-wise perturbations and attention-wise perturbations. Specifically,\nchannel-wise perturbations are implemented by shuffling the channels in\nhigh-dimensional space guided by degradation types, while attention-wise\nperturbations are achieved through selective masking in the attention space. To\nachieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB)\nto implement these two functions, positioned between the encoding and decoding\nstages of the encoder-decoder architecture. Extensive experimental results\ndemonstrate that DFPIR achieves state-of-the-art performance on several\nall-in-one image restoration tasks including image denoising, image dehazing,\nimage deraining, motion deblurring, and low-light image enhancement. Our codes\nare available at https://github.com/TxpHome/DFPIR.",
      "tldr_zh": "这篇论文针对 All-in-One Image Restoration 提出了一种新方法 DFPIR，以解决不同退化类型和级别导致的任务干扰问题，该问题源于共享参数的梯度更新方向分歧。DFPIR 通过引入 Degradation-aware Feature Perturbations (DFP)，包括 channel-wise perturbations（根据退化类型在高维空间洗牌通道）和 attention-wise perturbations（在注意力空间进行选择性掩码），来调整特征空间以适应统一参数空间。具体实现采用 Degradation-Guided Perturbation Block (DGPB)，置于编码器-解码器架构的编码和解码阶段之间。实验结果表明，DFPIR 在图像去噪、去雾、去雨、运动去模糊和低光增强等任务上实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025. 8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12630v1",
      "published_date": "2025-05-19 02:37:11 UTC",
      "updated_date": "2025-05-19 02:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:43:55.678470"
    },
    {
      "arxiv_id": "2505.12626v1",
      "title": "scSiameseClu: A Siamese Clustering Framework for Interpreting single-cell RNA Sequencing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Xu",
        "Zhiyuan Ning",
        "Pengjiang Li",
        "Wenhao Liu",
        "Pengyang Wang",
        "Jiaxu Cui",
        "Yuanchun Zhou",
        "Pengfei Wang"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) reveals cell heterogeneity, with cell\nclustering playing a key role in identifying cell types and marker genes.\nRecent advances, especially graph neural networks (GNNs)-based methods, have\nsignificantly improved clustering performance. However, the analysis of\nscRNA-seq data remains challenging due to noise, sparsity, and high\ndimensionality. Compounding these challenges, GNNs often suffer from\nover-smoothing, limiting their ability to capture complex biological\ninformation. In response, we propose scSiameseClu, a novel Siamese Clustering\nframework for interpreting single-cell RNA-seq data, comprising of 3 key steps:\n(1) Dual Augmentation Module, which applies biologically informed perturbations\nto the gene expression matrix and cell graph relationships to enhance\nrepresentation robustness; (2) Siamese Fusion Module, which combines\ncross-correlation refinement and adaptive information fusion to capture complex\ncellular relationships while mitigating over-smoothing; and (3) Optimal\nTransport Clustering, which utilizes Sinkhorn distance to efficiently align\ncluster assignments with predefined proportions while maintaining balance.\nComprehensive evaluations on seven real-world datasets demonstrate\nthat~\\methodname~outperforms state-of-the-art methods in single-cell\nclustering, cell type annotation, and cell type classification, providing a\npowerful tool for scRNA-seq data interpretation.",
      "tldr_zh": "本研究提出 scSiameseClu，一种 Siamese Clustering 框架，用于解释 single-cell RNA sequencing (scRNA-seq) 数据，旨在解决数据噪声、稀疏性和高维度问题，同时缓解 GNNs 的过平滑问题。该框架包括三个关键模块：Dual Augmentation Module 通过生物学信息扰动增强表示鲁棒性、Siamese Fusion Module 结合交叉相关精炼和自适应信息融合捕获复杂细胞关系，以及 Optimal Transport Clustering 使用 Sinkhorn 距离实现平衡的聚类分配。在七个真实数据集上的评估中，scSiameseClu 在单细胞聚类、细胞类型注释和分类方面优于现有方法，提供了一个高效的 scRNA-seq 数据解释工具。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12626v1",
      "published_date": "2025-05-19 02:17:09 UTC",
      "updated_date": "2025-05-19 02:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:44:06.440954"
    },
    {
      "arxiv_id": "2505.12623v1",
      "title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding",
      "title_zh": "在 PIBT 中用于大规模多智能体路径规划的轻量级且有效的偏好构建",
      "authors": [
        "Keisuke Okumura",
        "Hiroki Nagai"
      ],
      "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a\nvariety of multi-agent pathfinding (MAPF) problems, generating the next\ncollision-free locations of agents given another. Because of its simplicity and\nscalability, it is becoming a popular underlying scheme for recent large-scale\nMAPF methods involving several hundreds or thousands of agents. Vanilla PIBT\nmakes agents behave greedily towards their assigned goals, while agents\ntypically have multiple best actions, since the graph shortest path is not\nalways unique. Consequently, tiebreaking about how to choose between these\nactions significantly affects resulting solutions. This paper studies two\nsimple yet effective techniques for tiebreaking in PIBT, without compromising\nits computational advantage. The first technique allows an agent to\nintelligently dodge another, taking into account whether each action will\nhinder the progress of the next timestep. The second technique is to learn,\nthrough multiple PIBT runs, how an action causes regret in others and to use\nthis information to minimise regret collectively. Our empirical results\ndemonstrate that these techniques can reduce the solution cost of one-shot MAPF\nand improve the throughput of lifelong MAPF. For instance, in densely populated\none-shot cases, the combined use of these tiebreaks achieves improvements of\naround 10-20% in sum-of-costs, without significantly compromising the speed of\na PIBT-based planner.",
      "tldr_zh": "该论文针对大规模多代理路径查找(MAPF)中的 PIBT 算法，提出两种轻量级有效的破局技术，以优化代理在多路径选择中的行为决策。第一种技术让代理智能躲避其他代理，考虑动作是否会阻碍下一个时间步的进展；第二种技术通过多次 PIBT 运行学习动作导致的遗憾，并利用此信息最小化集体遗憾。实验结果显示，这些方法在密集的单次 MAPF 场景下可降低总成本 10-20%，并提升终身 MAPF 的吞吐量，同时保持 PIBT 的计算效率优势。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "To be presented at SoCS-25",
      "pdf_url": "http://arxiv.org/pdf/2505.12623v1",
      "published_date": "2025-05-19 02:12:29 UTC",
      "updated_date": "2025-05-19 02:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:44:19.486335"
    },
    {
      "arxiv_id": "2505.13544v2",
      "title": "Multi-head Temporal Latent Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Keqi Deng",
        "Philip C. Woodland"
      ],
      "abstract": "While Transformer self-attention offers strong parallelism, the Key-Value\n(KV) cache grows linearly with sequence length and becomes a bottleneck for\ninference efficiency. Multi-head latent attention was recently developed to\ncompress the KV cache into a low-rank latent space. This paper proposes\nMulti-head Temporal Latent Attention (MTLA), which further reduces the KV cache\nsize along the temporal dimension, greatly lowering the memory footprint of\nself-attention inference. MTLA employs a hyper-network to dynamically merge\ntemporally adjacent KV cache vectors. To address the mismatch between the\ncompressed KV cache and processed sequence lengths, a stride-aware causal mask\nis proposed to ensure efficient parallel training and consistency with\ninference behaviour. Experiments across tasks, including speech translation,\nspeech recognition, speech understanding and text summarisation, demonstrate\nthat MTLA achieves competitive performance compared to standard Multi-Head\nAttention (MHA), while greatly improving inference speed and GPU memory usage.\nFor example, on a English-German speech translation task, MTLA achieves a 5.3x\nspeedup and a reduction in GPU memory usage by a factor of 8.3 compared to MHA,\nwhile maintaining translation quality.",
      "tldr_zh": "本论文提出Multi-head Temporal Latent Attention (MTLA)，一种改进自注意力机制的方法，旨在通过在时间维度上压缩Key-Value (KV) cache来解决Transformer模型推理效率的瓶颈问题。MTLA利用hyper-network动态合并相邻的KV缓存向量，并引入stride-aware causal mask来确保训练与推理的一致性，从而降低内存占用。实验结果显示，在语音翻译、语音识别、语音理解和文本摘要等任务上，MTLA与标准Multi-Head Attention (MHA)相比，实现了高达5.3倍的推理速度提升和8.3倍的GPU内存减少，同时保持了相似的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13544v2",
      "published_date": "2025-05-19 02:09:41 UTC",
      "updated_date": "2025-05-21 01:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:44:31.859615"
    },
    {
      "arxiv_id": "2505.12594v1",
      "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection",
      "title_zh": "AD-AGENT：一种用于端到端异常检测的多智能体框架",
      "authors": [
        "Tiankai Yang",
        "Junjun Liu",
        "Wingchun Siu",
        "Jiahang Wang",
        "Zhuangzhuang Qian",
        "Chanjuan Song",
        "Cheng Cheng",
        "Xiyang Hu",
        "Yue Zhao"
      ],
      "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network\nmonitoring, and scientific research. However, the diversity of data modalities\nand the increasing number of specialized AD libraries pose challenges for\nnon-expert users who lack in-depth library-specific knowledge and advanced\nprogramming skills. To tackle this, we present AD-AGENT, an LLM-driven\nmulti-agent framework that turns natural-language instructions into fully\nexecutable AD pipelines. AD-AGENT coordinates specialized agents for intent\nparsing, data preparation, library and model selection, documentation mining,\nand iterative code generation and debugging. Using a shared short-term\nworkspace and a long-term cache, the agents integrate popular AD libraries like\nPyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that\nAD-AGENT produces reliable scripts and recommends competitive models across\nlibraries. The system is open-sourced to support further research and practical\napplications in AD.",
      "tldr_zh": "该论文提出 AD-AGENT，一种基于 LLM 驱动的多智能体框架，用于实现端到端的异常检测（AD），旨在解决非专家用户在处理数据模态多样化和专用库（如 PyOD、PyGOD 和 TSLib）时的知识和编程技能不足问题。框架通过协调意图解析、数据准备、库模型选择、文档挖掘以及迭代代码生成和调试的专门智能体，结合共享短期工作空间和长期缓存，形成统一的 AD 工作流程。实验结果显示，AD-AGENT 生成可靠的脚本并推荐竞争性模型，并已开源以支持 AD 的进一步研究和实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12594v1",
      "published_date": "2025-05-19 01:14:57 UTC",
      "updated_date": "2025-05-19 01:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:44:43.354162"
    },
    {
      "arxiv_id": "2505.12585v1",
      "title": "Learning Robust Spectral Dynamics for Temporal Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "En Yu",
        "Jie Lu",
        "Xiaoyu Yang",
        "Guangquan Zhang",
        "Zhen Fang"
      ],
      "abstract": "Modern machine learning models struggle to maintain performance in dynamic\nenvironments where temporal distribution shifts, \\emph{i.e., concept drift},\nare prevalent. Temporal Domain Generalization (TDG) seeks to enable model\ngeneralization across evolving domains, yet existing approaches typically\nassume smooth incremental changes, struggling with complex real-world drifts\ninvolving long-term structure (incremental evolution/periodicity) and local\nuncertainties. To overcome these limitations, we introduce FreKoo, which\ntackles these challenges via a novel frequency-domain analysis of parameter\ntrajectories. It leverages the Fourier transform to disentangle parameter\nevolution into distinct spectral bands. Specifically, low-frequency component\nwith dominant dynamics are learned and extrapolated using the Koopman operator,\nrobustly capturing diverse drift patterns including both incremental and\nperiodicity. Simultaneously, potentially disruptive high-frequency variations\nare smoothed via targeted temporal regularization, preventing overfitting to\ntransient noise and domain uncertainties. In addition, this dual spectral\nstrategy is rigorously grounded through theoretical analysis, providing\nstability guarantees for the Koopman prediction, a principled Bayesian\njustification for the high-frequency regularization, and culminating in a\nmultiscale generalization bound connecting spectral dynamics to improved\ngeneralization. Extensive experiments demonstrate FreKoo's significant\nsuperiority over SOTA TDG approaches, particularly excelling in real-world\nstreaming scenarios with complex drifts and uncertainties.",
      "tldr_zh": "该研究针对 Temporal Domain Generalization (TDG) 中的时间分布偏移（如概念漂移）问题，提出 FreKoo 框架，通过傅立叶变换分析参数轨迹，将演化分解为不同谱带，以处理长期结构（如增量演化和周期性）和局部不确定性。FreKoo 使用 Koopman 算子学习和外推低频动态，捕获多样漂移模式，同时通过针对性时间正则化平滑高频变化，防止过拟合噪声。理论分析提供了 Koopman 预测的稳定性保证、多尺度泛化边界和 Bayesian 理由，实验证明 FreKoo 在真实世界流式场景中显著优于 SOTA TDG 方法，展现出卓越的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12585v1",
      "published_date": "2025-05-19 00:38:18 UTC",
      "updated_date": "2025-05-19 00:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:44:56.132275"
    },
    {
      "arxiv_id": "2505.12583v1",
      "title": "A Comprehensive Survey on Physical Risk Control in the Era of Foundation Model-enabled Robotics",
      "title_zh": "在基础模型赋能机器人时代物理风险控制的全面调查",
      "authors": [
        "Takeshi Kojima",
        "Yaonan Zhu",
        "Yusuke Iwasawa",
        "Toshinori Kitamura",
        "Gang Yan",
        "Shu Morikuni",
        "Ryosuke Takanami",
        "Alfredo Solano",
        "Tatsuya Matsushima",
        "Akiko Murakami",
        "Yutaka Matsuo"
      ],
      "abstract": "Recent Foundation Model-enabled robotics (FMRs) display greatly improved\ngeneral-purpose skills, enabling more adaptable automation than conventional\nrobotics. Their ability to handle diverse tasks thus creates new opportunities\nto replace human labor. However, unlike general foundation models, FMRs\ninteract with the physical world, where their actions directly affect the\nsafety of humans and surrounding objects, requiring careful deployment and\ncontrol. Based on this proposition, our survey comprehensively summarizes robot\ncontrol approaches to mitigate physical risks by covering all the lifespan of\nFMRs ranging from pre-deployment to post-accident stage. Specifically, we\nbroadly divide the timeline into the following three phases: (1) pre-deployment\nphase, (2) pre-incident phase, and (3) post-incident phase. Throughout this\nsurvey, we find that there is much room to study (i) pre-incident risk\nmitigation strategies, (ii) research that assumes physical interaction with\nhumans, and (iii) essential issues of foundation models themselves. We hope\nthat this survey will be a milestone in providing a high-resolution analysis of\nthe physical risks of FMRs and their control, contributing to the realization\nof a good human-robot relationship.",
      "tldr_zh": "本调查全面总结了Foundation Model-enabled Robotics (FMRs)中物理风险控制的方法，强调FMRs的通用技能虽提升了自动化能力，但其物理交互可能危及人类和环境安全。调查将风险控制生命周期分为三个阶段：预部署阶段（pre-deployment phase）、预事件阶段（pre-incident phase）和事后阶段（post-incident phase），并探讨了相关机器人控制策略。研究发现，未来需加强预事件风险缓解、人机物理交互研究以及基础模型自身问题的探讨，以促进良好的人机关系。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IJCAI 2025 Survey Track",
      "pdf_url": "http://arxiv.org/pdf/2505.12583v1",
      "published_date": "2025-05-19 00:11:42 UTC",
      "updated_date": "2025-05-19 00:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:45:06.312024"
    },
    {
      "arxiv_id": "2505.12581v1",
      "title": "An approach based on class activation maps for investigating the effects of data augmentation on neural networks for image classification",
      "title_zh": "基于类激活图的方法，用于调查数据增强对图像分类神经网络的影响",
      "authors": [
        "Lucas M. Dorneles",
        "Luan Fonseca Garcia",
        "Joel Luís Carbonera"
      ],
      "abstract": "Neural networks have become increasingly popular in the last few years as an\neffective tool for the task of image classification due to the impressive\nperformance they have achieved on this task. In image classification tasks, it\nis common to use data augmentation strategies to increase the robustness of\ntrained networks to changes in the input images and to avoid overfitting.\nAlthough data augmentation is a widely adopted technique, the literature lacks\na body of research analyzing the effects data augmentation methods have on the\npatterns learned by neural network models working on complex datasets. The\nprimary objective of this work is to propose a methodology and set of metrics\nthat may allow a quantitative approach to analyzing the effects of data\naugmentation in convolutional networks applied to image classification. An\nimportant tool used in the proposed approach lies in the concept of class\nactivation maps for said models, which allow us to identify and measure the\nimportance these models assign to each individual pixel in an image when\nexecuting the classification task. From these maps, we may then extract metrics\nover the similarities and differences between maps generated by these models\ntrained on a given dataset with different data augmentation strategies.\nExperiments made using this methodology suggest that the effects of these data\naugmentation techniques not only can be analyzed in this way but also allow us\nto identify different impact profiles over the trained models.",
      "tldr_zh": "本研究提出了一种基于 class activation maps (CAM) 的方法，用于量化分析数据增强对图像分类神经网络的影响，旨在填补现有文献中对复杂数据集上模型学习模式分析的空白。该方法通过提取 CAM 来识别模型对图像中每个像素的重要性，并计算不同数据增强策略下生成的 CAM 之间的相似性和差异性指标。实验结果表明，这种方法不仅能有效评估数据增强的技术效果，还能识别出对训练模型的不同影响模式，从而为提升神经网络的鲁棒性和避免过拟合提供新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12581v1",
      "published_date": "2025-05-19 00:03:57 UTC",
      "updated_date": "2025-05-19 00:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T01:45:17.839020"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 226,
  "processed_papers_count": 226,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T01:45:52.015725"
}