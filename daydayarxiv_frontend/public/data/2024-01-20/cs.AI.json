{
  "date": "2024-01-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-20 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 32 篇论文，主要聚焦 AI 模型优化（如 LLM 和视觉语言模型）、强化学习在扩散模型和多模态任务中的应用，以及医疗和自动驾驶领域的实际应用；令人印象深刻的包括 Prompting Large Vision-Language Models 这篇探索 LLM 组合推理的创新工作，以及 PRILoRA 的参数高效微调方法；知名学者如 Yann LeCun 的论文也值得关注。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI 和热门主题的相关文章，再快速掠过其他领域的内容。每个条目包括论文标题（中文 + 英文）和核心贡献，确保简洁明了。\n\n### AI 模型与强化学习领域（重点部分）\n1. **Prompting Large Vision-Language Models for Compositional Reasoning（提示大型视觉语言模型进行组合推理）**  \n   这篇论文提出了一种新方法，使用 GPT-4 等模型进行图像描述和组合推理，解决了传统嵌入模型在 Winoground 数据集上的匹配问题，通过逐步推理提升了多模态数据处理准确率高达 10%，为视觉语言任务提供更有效的生成框架。\n\n2. **PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation（PRILoRA: 修剪和秩增加的低秩适应）**  \n   作者 Nadav Benedek 和 Lior Wolf 开发了 PRILoRA 方法，在 GLUE 基准上实现了 SOTA 性能，通过层级秩分配和训练中修剪，提升了参数高效微调（PEFT）的效果，减少了模型参数并提高了大语言模型的适应性（EACL 2024）。\n\n3. **Large-scale Reinforcement Learning for Diffusion Models（大规模强化学习用于扩散模型）**  \n   这篇论文探索了强化学习优化文本到图像扩散模型，使用人类偏好奖励函数，使预训练 Stable Diffusion 模型在生成图像时更符合偏好，提升了 80.3% 的用户满意度，同时改善了图像的多样性和组成性。\n\n4. **CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant（CodeAid: 评估 LLM 基于编程助手的课堂部署）**  \n   论文评估了 CodeAid 系统（CHI 2024），它使用 LLM 提供编程反馈而不直接暴露代码，设计了四个原则（如简化查询和避免直接回答），通过 700 名学生的实验，证明了其在提升学生参与度和认知学习中的有效性。\n\n5. **Embedding Ontologies via Incorporating Extensional and Intensional Knowledge（通过整合外延和内涵知识嵌入本体）**  \n   作者提出 EIKE 框架，使用几何方法和预训练语言模型同时捕捉本体中的实例和概念知识，在三数据集上显著提升了三元组分类和链接预测性能，提供了一种全面的本体嵌入方法。\n\n6. **Density Adaptive Attention is All You Need: Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities（密度自适应注意力机制：跨多模态的鲁棒参数高效微调）**  \n   这篇论文引入 Density Adaptive Attention Mechanism（DAAM）和 Density Adaptive Transformer（DAT），在语音、文本和视觉任务中提升了模型鲁棒性，通过概率分布动态调整特征权重，实现了高达 20% 的准确率改进。\n\n7. **FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement（FedRKG: 通过知识图谱增强的隐私保护联邦推荐框架）**  \n   论文提出 FedRKG 系统，使用全局知识图谱和本地差分隐私，改善了联邦推荐的性能，在真实数据集上平均提高了 4% 的准确率，同时保护用户隐私。\n\n### 医疗和自动驾驶应用\n8. **Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions（自动化融合多模态电子健康记录以提升医疗预测）**  \n   作者开发了 AutoFM 框架，通过神经架构搜索自动优化多模态 EHR 数据编码，在真实医疗任务中超越了 SOTA 方法，提升了预测性能（SDM 2024）。\n\n9. **Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose（基于眼动数据和头部姿势评估条件自动驾驶车辆的驾驶员准备度）**  \n   这篇论文使用 LSTM 模型结合眼动和头部数据，实现了 0.363 的均绝对误差，改进了 SAE Level 3 车辆中驾驶员准备度的评估，提供更可靠的实时监控。\n\n10. **SleepNet: Attention-Enhanced Robust Sleep Prediction using Dynamic Social Networks（SleepNet: 使用动态社交网络的注意力增强鲁棒睡眠预测）**  \n    论文提出 SleepNet 系统，通过图网络和注意力机制整合生理数据和社会网络，预测睡眠行为，提升了预测准确性，并证明了社交传染对睡眠的影响（IMWUT 2024）。\n\n### 其他领域快速掠过\n其他论文涉及强化学习、多实例学习和知识图谱等，但部分主题较 niche，我仅简要提及几篇代表：\n\n11. **Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov（检测隐藏触发器: 将非Markov 奖励函数映射到 Markov）**  \n    通过学习 Reward Machines 处理非Markov 奖励，改进了强化学习在复杂环境中的性能。\n\n12. **TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision（TreeMIL: 带有不精确监督的时间序列异常检测的多实例学习框架）**  \n    提出树结构框架检测时间序列异常，提升了 F1 分数 32.3%，适用于工业监控。\n\n13. **Fast and Exact Enumeration of Deep Networks Partitions Regions（快速精确枚举深度网络分区区域）**  \n    作者 Yann LeCun 开发了并行算法，精确枚举深度网络分区，揭示了均匀采样在高维空间的局限性。\n\n14. **Pixel-Wise Recognition for Holistic Surgical Scene Understanding（像素级识别用于整体手术场景理解）**  \n    论文引入 GraSP 数据集和 TAPIS 模型，提升了手术阶段和工具识别的性能。\n\n剩余论文如电商聊天机器人、废水处理和车辆路径优化等，虽有实际应用价值，但相对不那么热门，我在此快速掠过，以控制篇幅。如果您对特定领域感兴趣，可以进一步查询。\n\n总之，今天的 arXiv 更新突出了 AI 模型的创新应用和实际落地潜力，建议关注 LLM 和强化学习相关工作，以把握前沿趋势！如果有反馈，欢迎随时交流。",
  "papers": [
    {
      "arxiv_id": "2401.11337v1",
      "title": "Prompting Large Vision-Language Models for Compositional Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Ossowski",
        "Ming Jiang",
        "Junjie Hu"
      ],
      "abstract": "Vision-language models such as CLIP have shown impressive capabilities in\nencoding texts and images into aligned embeddings, enabling the retrieval of\nmultimodal data in a shared embedding space. However, these embedding-based\nmodels still face challenges in effectively matching images and texts with\nsimilar visio-linguistic compositionality, as evidenced by their performance on\nthe recent Winoground dataset. In this paper, we argue that this limitation\nstems from two factors: the use of single vector representations for complex\nmultimodal data, and the absence of step-by-step reasoning in these\nembedding-based methods. To address this issue, we make an exploratory step\nusing a novel generative method that prompts large vision-language models\n(e.g., GPT-4) to depict images and perform compositional reasoning. Our method\noutperforms other embedding-based methods on the Winoground dataset, and\nobtains further improvement of up to 10% accuracy when enhanced with the\noptimal description.",
      "tldr_zh": "本论文探讨了视觉语言模型（如 CLIP）在处理具有组合性（compositional reasoning）的图像和文本匹配时面临的挑战，主要归因于单一向量表示和缺少逐步推理。研究者提出了一种新颖的生成式方法，通过提示大型视觉语言模型（如 GPT-4）来描述图像并执行组合推理，以提升匹配性能。该方法在 Winoground 数据集上优于其他嵌入式方法，并在优化描述后准确率提高了多达 10%。这为改进多模态数据处理提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11337v1",
      "published_date": "2024-01-20 22:04:28 UTC",
      "updated_date": "2024-01-20 22:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:01:41.104082"
    },
    {
      "arxiv_id": "2402.00043v1",
      "title": "Interactive and Intelligent Root Cause Analysis in Manufacturing with Causal Bayesian Networks and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Wehner",
        "Maximilian Kertel",
        "Judith Wewerka"
      ],
      "abstract": "Root Cause Analysis (RCA) in the manufacturing of electric vehicles is the\nprocess of identifying fault causes. Traditionally, the RCA is conducted\nmanually, relying on process expert knowledge. Meanwhile, sensor networks\ncollect significant amounts of data in the manufacturing process. Using this\ndata for RCA makes it more efficient. However, purely data-driven methods like\nCausal Bayesian Networks have problems scaling to large-scale, real-world\nmanufacturing processes due to the vast amount of potential cause-effect\nrelationships (CERs). Furthermore, purely data-driven methods have the\npotential to leave out already known CERs or to learn spurious CERs. The paper\ncontributes by proposing an interactive and intelligent RCA tool that combines\nexpert knowledge of an electric vehicle manufacturing process and a data-driven\nmachine learning method. It uses reasoning over a large-scale Knowledge Graph\nof the manufacturing process while learning a Causal Bayesian Network. In\naddition, an Interactive User Interface enables a process expert to give\nfeedback to the root cause graph by adding and removing information to the\nKnowledge Graph. The interactive and intelligent RCA tool reduces the learning\ntime of the Causal Bayesian Network while decreasing the number of spurious\nCERs. Thus, the interactive and intelligent RCA tool closes the feedback loop\nbetween expert and machine learning method.",
      "tldr_zh": "本研究针对电动汽车制造中的根因分析（RCA）问题，提出了一种交互式智能工具，以解决传统手动方法依赖专家知识以及纯数据驱动方法（如Causal Bayesian Networks）在扩展到大规模过程时可能遗漏已知因果关系（CERs）或学习虚假CERs的局限。工具结合专家知识和机器学习，通过Knowledge Graphs进行推理并学习Causal Bayesian Networks，同时提供交互式用户界面，让专家添加或移除信息反馈到Knowledge Graph中。该方法显著减少了Causal Bayesian Networks的学习时间，降低了虚假CERs的数量，并建立了专家与机器学习之间的反馈循环，从而提升了RCA的效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00043v1",
      "published_date": "2024-01-20 21:25:57 UTC",
      "updated_date": "2024-01-20 21:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:01:54.007695"
    },
    {
      "arxiv_id": "2401.11325v3",
      "title": "Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Hyde",
        "Eugene Santos Jr"
      ],
      "abstract": "Many Reinforcement Learning algorithms assume a Markov reward function to\nguarantee optimality. However, not all reward functions are Markov. This paper\nproposes a framework for mapping non-Markov reward functions into equivalent\nMarkov ones by learning specialized reward automata, Reward Machines. Unlike\nthe general practice of learning Reward Machines, we do not require a set of\nhigh-level propositional symbols from which to learn. Rather, we learn hidden\ntriggers, directly from data, that construct them. We demonstrate the\nimportance of learning Reward Machines over their Deterministic Finite-State\nAutomata counterparts given their ability to model reward dependencies. We\nformalize this distinction in our learning objective. Our mapping process is\nconstructed as an Integer Linear Programming problem. We prove that our\nmappings form a suitable proxy for maximizing reward expectations. We\nempirically validate our approach by learning black-box, non-Markov reward\nfunctions in the Officeworld domain. Additionally, we demonstrate the\neffectiveness of learning reward dependencies in a new domain, Breakfastworld.",
      "tldr_zh": "该论文解决强化学习中非Markov奖励函数的问题，提出一个框架，通过学习隐藏触发器（hidden triggers）来将非Markov奖励函数映射到等价的Markov奖励函数，使用奖励自动机（Reward Machines）。与传统方法不同，该框架直接从数据中构建这些触发器，而非依赖预定义的高级命题符号，并通过整数线性规划（Integer Linear Programming）问题形式化映射过程，以最大化奖励预期。实验在Officeworld和Breakfastworld域中验证了该方法的有效性，证明Reward Machines在建模奖励依赖性方面优于Deterministic Finite-State Automata。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11325v3",
      "published_date": "2024-01-20 21:09:27 UTC",
      "updated_date": "2024-08-16 16:18:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:02:04.844369"
    },
    {
      "arxiv_id": "2401.11316v1",
      "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Benedek",
        "Lior Wolf"
      ],
      "abstract": "With the proliferation of large pre-trained language models (PLMs),\nfine-tuning all model parameters becomes increasingly inefficient, particularly\nwhen dealing with numerous downstream tasks that entail substantial training\nand storage costs. Several approaches aimed at achieving parameter-efficient\nfine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA)\nstands out as an archetypal method, incorporating trainable rank decomposition\nmatrices into each target module. Nevertheless, LoRA does not consider the\nvarying importance of each layer. To address these challenges, we introduce\nPRILoRA, which linearly allocates a different rank for each layer, in an\nincreasing manner, and performs pruning throughout the training process,\nconsidering both the temporary magnitude of weights and the accumulated\nstatistics of the input to any given layer. We validate the effectiveness of\nPRILoRA through extensive experiments on eight GLUE benchmarks, setting a new\nstate of the art.",
      "tldr_zh": "针对大型预训练语言模型 (PLMs) 的微调问题，PRILoRA 提出了一种参数高效微调 (PEFT) 方法，通过线性分配递增秩 (rank) 为各层设置不同秩，并结合权重临时幅度和输入层累积统计进行剪枝 (pruning)，以优化 LoRA 的局限性。相比传统 LoRA，PRILoRA 考虑了各层的不同重要性，提升了微调效率和性能。在八个 GLUE 基准上的广泛实验中，PRILoRA 设定了新的最先进 (state of the art) 水平，证明了其在处理多个下游任务时的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11316v1",
      "published_date": "2024-01-20 20:25:17 UTC",
      "updated_date": "2024-01-20 20:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:02:17.044040"
    },
    {
      "arxiv_id": "2401.11314v2",
      "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
      "title_zh": "翻译失败",
      "authors": [
        "Majeed Kazemitabaar",
        "Runlong Ye",
        "Xiaoning Wang",
        "Austin Z. Henley",
        "Paul Denny",
        "Michelle Craig",
        "Tovi Grossman"
      ],
      "abstract": "Timely, personalized feedback is essential for students learning programming.\nLLM-powered tools like ChatGPT offer instant support, but reveal direct answers\nwith code, which may hinder deep conceptual engagement. We developed CodeAid,\nan LLM-powered programming assistant delivering helpful, technically correct\nresponses, without revealing code solutions. CodeAid answers conceptual\nquestions, generates pseudo-code with line-by-line explanations, and annotates\nstudent's incorrect code with fix suggestions. We deployed CodeAid in a\nprogramming class of 700 students for a 12-week semester. A thematic analysis\nof 8,000 usages of CodeAid was performed, further enriched by weekly surveys,\nand 22 student interviews. We then interviewed eight programming educators to\ngain further insights. Our findings reveal four design considerations for\nfuture educational AI assistants: D1) exploiting AI's unique benefits; D2)\nsimplifying query formulation while promoting cognitive engagement; D3)\navoiding direct responses while encouraging motivated learning; and D4)\nmaintaining transparency and control for students to asses and steer AI\nresponses.",
      "tldr_zh": "本研究开发了 CodeAid，一种基于 LLM（大型语言模型）的编程助手，旨在为编程学习提供及时的个性化反馈，同时避免直接给出代码答案，以促进学生的概念深度理解。CodeAid 的功能包括回答概念问题、生成伪代码并提供逐行解释，以及注解学生错误代码并建议修复，并在包含 700 名学生的编程课中部署了 12 周。通过对 8000 次使用记录的主题分析、每周调查和 22 次学生访谈，以及 8 次教育者访谈，研究得出了四个关键设计考虑：D1) 利用 AI 的独特优势；D2) 简化查询制定同时提升认知参与；D3) 避免直接响应并鼓励主动学习；以及 D4) 保持透明度和控制以帮助学生评估和引导 AI 响应。这些发现为未来教育 AI 助手的优化提供了指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2024 Paper - The paper includes 17 pages, 8 figures, 2 tables,\n  along with a 2-page appendix",
      "pdf_url": "http://arxiv.org/pdf/2401.11314v2",
      "published_date": "2024-01-20 20:14:42 UTC",
      "updated_date": "2024-02-25 22:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:02:30.130130"
    },
    {
      "arxiv_id": "2401.11284v1",
      "title": "Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose",
      "title_zh": "翻译失败",
      "authors": [
        "Mostafa Kazemi",
        "Mahdi Rezaei",
        "Mohsen Azarmi"
      ],
      "abstract": "As automated driving technology advances, the role of the driver to resume\ncontrol of the vehicle in conditionally automated vehicles becomes increasingly\ncritical. In the SAE Level 3 or partly automated vehicles, the driver needs to\nbe available and ready to intervene when necessary. This makes it essential to\nevaluate their readiness accurately. This article presents a comprehensive\nanalysis of driver readiness assessment by combining head pose features and\neye-tracking data. The study explores the effectiveness of predictive models in\nevaluating driver readiness, addressing the challenges of dataset limitations\nand limited ground truth labels. Machine learning techniques, including LSTM\narchitectures, are utilised to model driver readiness based on the\nSpatio-temporal status of the driver's head pose and eye gaze. The experiments\nin this article revealed that a Bidirectional LSTM architecture, combining both\nfeature sets, achieves a mean absolute error of 0.363 on the DMD dataset,\ndemonstrating superior performance in assessing driver readiness. The modular\narchitecture of the proposed model also allows the integration of additional\ndriver-specific features, such as steering wheel activity, enhancing its\nadaptability and real-world applicability.",
      "tldr_zh": "这篇论文探讨了在 SAE Level 3 自动车辆中，通过 eye-tracking 数据和 head pose 特征来评估驾驶员准备度的方法，以应对驾驶员需随时接管车辆的挑战。研究采用机器学习技术，包括 LSTM 架构，构建模型来分析驾驶员的时空状态，从而预测其注意力水平。实验结果显示，Bidirectional LSTM 结合两种特征在 DMD 数据集上达到了 0.363 的 mean absolute error，显著优于基线模型。该模型的模块化设计允许整合额外特征，如方向盘活动，提升了其在实际场景中的适应性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11284v1",
      "published_date": "2024-01-20 17:32:52 UTC",
      "updated_date": "2024-01-20 17:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:02:42.376602"
    },
    {
      "arxiv_id": "2401.14413v1",
      "title": "Aprendizado de máquina aplicado na eletroquímica",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Eduardo do Egito Araújo",
        "Lívia F. Sgobbi",
        "Iwens Gervasio Sene Jr",
        "Sergio Teixeira de Carvalho"
      ],
      "abstract": "This systematic review focuses on analyzing the use of machine learning\ntechniques for identifying and quantifying analytes in various electrochemical\napplications, presenting the available applications in the literature. Machine\nlearning is a tool that can facilitate the analysis and enhance the\nunderstanding of processes involving various analytes. In electrochemical\nbiosensors, it increases the precision of medical diagnostics, improving the\nidentification of biomarkers and pathogens with high reliability. It can be\neffectively used for the classification of complex chemical products; in\nenvironmental monitoring, using low-cost sensors; in portable devices and\nwearable systems; among others. Currently, the analysis of some analytes is\nstill performed manually, requiring the expertise of a specialist in the field\nand thus hindering the generalization of results. In light of the advancements\nin artificial intelligence today, this work proposes to carry out a systematic\nreview of the literature on the applications of artificial intelligence\ntechniques. A set of articles has been identified that address electrochemical\nproblems using machine learning techniques, more specifically, supervised\nlearning.",
      "tldr_zh": "这篇系统综述探讨了machine learning在电化学领域的应用，重点分析其在识别和量化分析物方面的作用，以提升过程理解和效率。研究回顾了文献中machine learning技术（如supervised learning）的实际应用，包括提高电化学生物传感器的诊断精度、分类复杂化学产品以及在低成本环境监测和便携设备中的使用。结果表明，这些技术能减少对专家的依赖，促进分析过程的自动化，并为人工智能在电化学中的进一步发展提供基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "in Portuguese language",
      "pdf_url": "http://arxiv.org/pdf/2401.14413v1",
      "published_date": "2024-01-20 16:41:25 UTC",
      "updated_date": "2024-01-20 16:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:02:53.219296"
    },
    {
      "arxiv_id": "2402.00881v1",
      "title": "On the Interplay of Artificial Intelligence and Space-Air-Ground Integrated Networks: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Adilya Bakambekova",
        "Nour Kouzayha",
        "Tareq Al-Naffouri"
      ],
      "abstract": "Space-Air-Ground Integrated Networks (SAGINs), which incorporate space and\naerial networks with terrestrial wireless systems, are vital enablers of the\nemerging sixth-generation (6G) wireless networks. Besides bringing significant\nbenefits to various applications and services, SAGINs are envisioned to extend\nhigh-speed broadband coverage to remote areas, such as small towns or mining\nsites, or areas where terrestrial infrastructure cannot reach, such as\nairplanes or maritime use cases. However, due to the limited power and storage\nresources, as well as other constraints introduced by the design of terrestrial\nnetworks, SAGINs must be intelligently configured and controlled to satisfy the\nenvisioned requirements. Meanwhile, Artificial Intelligence (AI) is another\ncritical enabler of 6G. Due to massive amounts of available data, AI has been\nleveraged to address pressing challenges of current and future wireless\nnetworks. By adding AI and facilitating the decision-making and prediction\nprocedures, SAGINs can effectively adapt to their surrounding environment, thus\nenhancing the performance of various metrics. In this work, we aim to\ninvestigate the interplay of AI and SAGINs by providing a holistic overview of\nstate-of-the-art research in AI-enabled SAGINs. Specifically, we present a\ncomprehensive overview of some potential applications of AI in SAGINs. We also\ncover open issues in employing AI and detail the contributions of SAGINs in the\ndevelopment of AI. Finally, we highlight some limitations of the existing\nresearch works and outline potential future research directions.",
      "tldr_zh": "本调查论文探讨了人工智能（AI）和空间-空中-地面集成网络（SAGINs）之间的相互作用，强调SAGINs作为第六代（6G）无线网络的关键组成部分，能够扩展高速宽带覆盖至偏远或难以触达的区域，如偏远城镇或海上场景。论文提供了AI在SAGINs中的潜在应用概述，包括如何通过AI提升网络的适应性和性能，同时讨论了开放问题、SAGINs对AI发展的贡献以及现有研究的局限性。最终，论文指出了未来研究方向，如进一步优化AI算法以应对SAGINs的资源限制和环境挑战。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00881v1",
      "published_date": "2024-01-20 16:10:31 UTC",
      "updated_date": "2024-01-20 16:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:03:05.561909"
    },
    {
      "arxiv_id": "2401.11257v2",
      "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning",
      "title_zh": "多智能体强化学习中的策略",
      "authors": [
        "Tianyi Hu",
        "Zhiqiang Pu",
        "Xiaolin Ai",
        "Tenghai Qiu",
        "Jianqiang Yi"
      ],
      "abstract": "Diversity plays a crucial role in improving the performance of multi-agent\nreinforcement learning (MARL). Currently, many diversity-based methods have\nbeen developed to overcome the drawbacks of excessive parameter sharing in\ntraditional MARL. However, there remains a lack of a general metric to quantify\npolicy differences among agents. Such a metric would not only facilitate the\nevaluation of the diversity evolution in multi-agent systems, but also provide\nguidance for the design of diversity-based MARL algorithms. In this paper, we\npropose the multi-agent policy distance (MAPD), a general tool for measuring\npolicy differences in MARL. By learning the conditional representations of\nagents' decisions, MAPD can computes the policy distance between any pair of\nagents. Furthermore, we extend MAPD to a customizable version, which can\nquantify differences among agent policies on specified aspects. Based on the\nonline deployment of MAPD, we design a multi-agent dynamic parameter sharing\n(MADPS) algorithm as an example of the MAPD's applications. Extensive\nexperiments demonstrate that our method is effective in measuring differences\nin agent policies and specific behavioral tendencies. Moreover, in comparison\nto other methods of parameter sharing, MADPS exhibits superior performance.",
      "tldr_zh": "本论文针对多智能体强化学习(MARL)中的策略多样性问题，提出了一种通用指标——多智能体策略距离(MAPD)，用于量化智能体之间策略差异，从而评估系统多样性演化和指导算法设计。MAPD 通过学习智能体决策的条件表示来计算任意两智能体间的策略距离，并扩展为可定制版本，以量化特定方面的行为差异。基于 MAPD，作者设计了多智能体动态参数共享(MADPS)算法作为应用示例，实验结果显示，该方法在测量策略差异和行为倾向方面有效，且 MADPS 比其他参数共享方法表现出色。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.11257v2",
      "published_date": "2024-01-20 15:34:51 UTC",
      "updated_date": "2024-01-28 15:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:03:16.798873"
    },
    {
      "arxiv_id": "2401.12247v1",
      "title": "Exploring consumers response to text-based chatbots in e-commerce: The moderating role of task complexity and chatbot disclosure",
      "title_zh": "翻译失败",
      "authors": [
        "Xusen Cheng",
        "Ying Bao",
        "Alex Zarifis",
        "Wankun Gong",
        "Jian Mou"
      ],
      "abstract": "Artificial intelligence based chatbots have brought unprecedented business\npotential. This study aims to explore consumers trust and response to a\ntext-based chatbot in ecommerce, involving the moderating effects of task\ncomplexity and chatbot identity disclosure. A survey method with 299 useable\nresponses was conducted in this research. This study adopted the ordinary least\nsquares regression to test the hypotheses. First, the consumers perception of\nboth the empathy and friendliness of the chatbot positively impacts their trust\nin it. Second, task complexity negatively moderates the relationship between\nfriendliness and consumers trust. Third, disclosure of the text based chatbot\nnegatively moderates the relationship between empathy and consumers trust,\nwhile it positively moderates the relationship between friendliness and\nconsumers trust. Fourth, consumers trust in the chatbot increases their\nreliance on the chatbot and decreases their resistance to the chatbot in future\ninteractions. Adopting the stimulus organism response framework, this study\nprovides important insights on consumers perception and response to the\ntext-based chatbot. The findings of this research also make suggestions that\ncan increase consumers positive responses to text based chatbots. Extant\nstudies have investigated the effects of automated bots attributes on consumers\nperceptions. However, the boundary conditions of these effects are largely\nignored. This research is one of the first attempts to provide a deep\nunderstanding of consumers responses to a chatbot.",
      "tldr_zh": "这篇论文探讨了消费者对电商中文本-based chatbots的信任和反应，特别考察了任务 complexity和chatbot disclosure的调节作用。研究通过调查299个有效样本并采用ordinary least squares regression分析，发现消费者对chatbots的移情和友好感知正向影响信任，而任务complexity负向调节友好与信任的关系。chatbot disclosure则负向调节移情与信任的关联，但正向调节友好与信任的关系；此外，消费者信任会增加对chatbots的依赖并减少未来抵抗。基于stimulus-organism-response框架，该研究为提升消费者对文本chatbots的正面响应提供了重要洞见，并填补了现有文献中忽略这些边界条件的空白。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Internet Research (2021)",
      "pdf_url": "http://arxiv.org/pdf/2401.12247v1",
      "published_date": "2024-01-20 15:17:50 UTC",
      "updated_date": "2024-01-20 15:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:03:30.168965"
    },
    {
      "arxiv_id": "2401.11252v1",
      "title": "Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions",
      "title_zh": "自动化多模态电子健康记录融合以实现更好的医疗预测",
      "authors": [
        "Suhan Cui",
        "Jiaqi Wang",
        "Yuan Zhong",
        "Han Liu",
        "Ting Wang",
        "Fenglong Ma"
      ],
      "abstract": "The widespread adoption of Electronic Health Record (EHR) systems in\nhealthcare institutes has generated vast amounts of medical data, offering\nsignificant opportunities for improving healthcare services through deep\nlearning techniques. However, the complex and diverse modalities and feature\nstructures in real-world EHR data pose great challenges for deep learning model\ndesign. To address the multi-modality challenge in EHR data, current approaches\nprimarily rely on hand-crafted model architectures based on intuition and\nempirical experiences, leading to sub-optimal model architectures and limited\nperformance. Therefore, to automate the process of model design for mining EHR\ndata, we propose a novel neural architecture search (NAS) framework named\nAutoFM, which can automatically search for the optimal model architectures for\nencoding diverse input modalities and fusion strategies. We conduct thorough\nexperiments on real-world multi-modal EHR data and prediction tasks, and the\nresults demonstrate that our framework not only achieves significant\nperformance improvement over existing state-of-the-art methods but also\ndiscovers meaningful network architectures effectively.",
      "tldr_zh": "这篇论文针对电子健康记录(EHR)数据的多模态复杂性问题，提出了一种新型神经架构搜索(NAS)框架AutoFM，以自动优化模型架构和融合策略，避免依赖手工设计。AutoFM能够有效编码多样化的输入模态并搜索最佳融合方法，从而提升医疗预测的性能。在真实多模态EHR数据和预测任务上的实验表明，该框架比现有最先进方法取得了显著的性能提升，并成功发现了有意义的网络架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11252v1",
      "published_date": "2024-01-20 15:14:14 UTC",
      "updated_date": "2024-01-20 15:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:03:42.686255"
    },
    {
      "arxiv_id": "2401.11249v1",
      "title": "Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI",
      "title_zh": "评估信任和个人信息隐私担忧是否是使用显式利用 AI 的健康保险的障碍",
      "authors": [
        "Alex Zarifis",
        "Peter Kawalek",
        "Aida Azadegan"
      ],
      "abstract": "Trust and privacy have emerged as significant concerns in online\ntransactions. Sharing information on health is especially sensitive but it is\nnecessary for purchasing and utilizing health insurance. Evidence shows that\nconsumers are increasingly comfortable with technology in place of humans, but\nthe expanding use of AI potentially changes this. This research explores\nwhether trust and privacy concern are barriers to the adoption of AI in health\ninsurance. Two scenarios are compared: The first scenario has limited AI that\nis not in the interface and its presence is not explicitly revealed to the\nconsumer. In the second scenario there is an AI interface and AI evaluation,\nand this is explicitly revealed to the consumer. The two scenarios were modeled\nand compared using SEM PLS-MGA. The findings show that trust is significantly\nlower in the second scenario where AI is visible. Privacy concerns are higher\nwith AI but the difference is not statistically significant within the model.",
      "tldr_zh": "这篇论文评估了信任和个人隐私担忧是否会阻碍消费者采用显式使用AI的健康保险。研究比较了两个场景：一个是AI存在但不显露于界面，另一个是AI显露并明确告知消费者，并使用SEM PLS-MGA模型进行分析。结果显示，在AI显露场景中，信任显著降低，而隐私担忧虽有所增加，但差异未达统计显著水平。整体发现突显了AI透明度对用户采用的潜在障碍。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "H.0; A.0; K.4; K.6"
      ],
      "primary_category": "cs.CY",
      "comment": "Journal of Internet Commerce (2021)",
      "pdf_url": "http://arxiv.org/pdf/2401.11249v1",
      "published_date": "2024-01-20 15:02:56 UTC",
      "updated_date": "2024-01-20 15:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:03:54.059281"
    },
    {
      "arxiv_id": "2401.11235v1",
      "title": "TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Liu",
        "Shibo He",
        "Haoyu Liu",
        "Shizhong Li"
      ],
      "abstract": "Time series anomaly detection (TSAD) plays a vital role in various domains\nsuch as healthcare, networks, and industry. Considering labels are crucial for\ndetection but difficult to obtain, we turn to TSAD with inexact supervision:\nonly series-level labels are provided during the training phase, while\npoint-level anomalies are predicted during the testing phase. Previous works\nfollow a traditional multi-instance learning (MIL) approach, which focuses on\nencouraging high anomaly scores at individual time steps. However, time series\nanomalies are not only limited to individual point anomalies, they can also be\ncollective anomalies, typically exhibiting abnormal patterns over subsequences.\nTo address the challenge of collective anomalies, in this paper, we propose a\ntree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to\ndivide the entire series into multiple nodes, where nodes at different levels\nrepresent subsequences with different lengths. Then, the subsequence features\nare extracted to determine the presence of collective anomalies. Finally, we\ncalculate point-level anomaly scores by aggregating features from nodes at\ndifferent levels. Experiments conducted on seven public datasets and eight\nbaselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-\nscore compared to previous state-of-the-art methods. The code is available at\nhttps://github.com/fly-orange/TreeMIL.",
      "tldr_zh": "这篇论文针对 Time Series Anomaly Detection (TSAD) 的不精确监督问题，提出了一种基于 Multi-instance Learning (MIL) 的框架 TreeMIL，以处理不仅限于单个点异常，还包括子序列集体异常的挑战。TreeMIL 采用 N-ary 树结构将时间序列划分为不同长度的子序列，提取特征来检测集体异常模式，并通过多层节点特征聚合计算点级异常分数。实验在七个公共数据集上与八个基线方法比较，结果显示 TreeMIL 的 F1-score 平均提高了 32.3%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by IEEE ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11235v1",
      "published_date": "2024-01-20 14:15:04 UTC",
      "updated_date": "2024-01-20 14:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:04:07.564626"
    },
    {
      "arxiv_id": "2402.01679v2",
      "title": "STICKERCONV: Generating Multimodal Empathetic Responses from Scratch",
      "title_zh": "STICKERCONV：从零开始生成多模态移情响应",
      "authors": [
        "Yiqun Zhang",
        "Fanheng Kong",
        "Peidong Wang",
        "Shuang Sun",
        "Lingshuai Wang",
        "Shi Feng",
        "Daling Wang",
        "Yifei Zhang",
        "Kaisong Song"
      ],
      "abstract": "Stickers, while widely recognized for enhancing empathetic communication in\nonline interactions, remain underexplored in current empathetic dialogue\nresearch, notably due to the challenge of a lack of comprehensive datasets. In\nthis paper, we introduce the Agent for STICKERCONV (Agent4SC), which uses\ncollaborative agent interactions to realistically simulate human behavior with\nsticker usage, thereby enhancing multimodal empathetic communication. Building\non this foundation, we develop a multimodal empathetic dialogue dataset,\nSTICKERCONV, comprising 12.9K dialogue sessions, 5.8K unique stickers, and 2K\ndiverse conversational scenarios. This dataset serves as a benchmark for\nmultimodal empathetic generation. To advance further, we propose PErceive and\nGenerate Stickers (PEGS), a multimodal empathetic response generation\nframework, complemented by a comprehensive set of empathy evaluation metrics\nbased on LLM. Our experiments demonstrate PEGS's effectiveness in generating\ncontextually relevant and emotionally resonant multimodal empathetic responses,\ncontributing to the advancement of more nuanced and engaging empathetic\ndialogue systems.",
      "tldr_zh": "该研究针对贴纸在在线互动中的移情沟通潜力，引入 Agent for STICKERCONV (Agent4SC)，通过协作代理模拟人类行为来生成多模态移情响应。研究团队构建了 STICKERCONV 数据集，包含 12.9K 对话会话、5.8K 独特贴纸和 2K 多样场景，作为多模态移情生成的基准。论文提出 PErceive and Generate Stickers (PEGS) 框架，并开发基于 LLM 的移情评估指标，以提升响应的上下文相关性和情感共鸣。实验结果证明，PEGS 框架显著提高了多模态移情对话系统的表现，推动了更细致入微的对话技术发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01679v2",
      "published_date": "2024-01-20 13:44:21 UTC",
      "updated_date": "2024-02-16 11:27:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:04:19.253737"
    },
    {
      "arxiv_id": "2402.00042v2",
      "title": "Optimized Task Assignment and Predictive Maintenance for Industrial Machines using Markov Decision Process",
      "title_zh": "基于马尔可夫决策过程的工业机器任务分配和预测性维护优化",
      "authors": [
        "Ali Nasir",
        "Samir Mekid",
        "Zaid Sawlan",
        "Omar Alsawafy"
      ],
      "abstract": "This paper considers a distributed decision-making approach for manufacturing\ntask assignment and condition-based machine health maintenance. Our approach\nconsiders information sharing between the task assignment and health management\ndecision-making agents. We propose the design of the decision-making agents\nbased on Markov decision processes. The key advantage of using a Markov\ndecision process-based approach is the incorporation of uncertainty involved in\nthe decision-making process. The paper provides detailed mathematical models\nalong with the associated practical execution strategy. In order to demonstrate\nthe effectiveness and practical applicability of our proposed approach, we have\nincluded a detailed numerical case study that is based on open source milling\nmachine tool degradation data. Our case study indicates that the proposed\napproach offers flexibility in terms of the selection of cost parameters and it\nallows for offline computation and analysis of the decision-making policy.\nThese features create and opportunity for the future work on learning of the\ncost parameters associated with our proposed model using artificial\nintelligence.",
      "tldr_zh": "本文提出了一种基于 Markov Decision Process (MDP) 的分布式决策方法，用于优化工业机器的任务分配和基于条件的预测维护。该方法通过任务分配和健康管理决策代理之间的信息共享，处理决策过程中的不确定性，并提供了详细的数学模型和实际执行策略。通过一个基于开源铣床工具退化数据的数值案例研究，证明了该方法的灵活性、离线计算能力，以及在成本参数选择上的优势，为未来使用人工智能学习成本参数提供了潜在机会。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 11 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.00042v2",
      "published_date": "2024-01-20 12:12:14 UTC",
      "updated_date": "2024-02-03 14:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:04:31.018539"
    },
    {
      "arxiv_id": "2401.11217v1",
      "title": "A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant",
      "title_zh": "迁移学习和基于",
      "authors": [
        "Ece S. Koksal",
        "Erdal Aydin"
      ],
      "abstract": "Constructing first principles models is a challenging task for nonlinear and\ncomplex systems such as a wastewater treatment unit. In recent years,\ndata-driven models are widely used to overcome the complexity. However, they\noften suffer from issues such as missing, low quality or noisy data. Transfer\nlearning is a solution for this issue where knowledge from another task is\ntransferred to target one to increase the prediction performance. In this work,\nthe objective is increasing the prediction performance of an industrial\nwastewater treatment plant by transferring the knowledge of (i) an open-source\nsimulation model that captures the underlying physics of the process, albeit\nwith dissimilarities to the target plant, (ii) another industrial plant\ncharacterized by noisy and limited data but located in the same refinery, and\n(iii) the model in (ii) and making the objective function of the training\nproblem physics informed where the physics information derived from the\nopen-source model in (ii). The results have shown that test and validation\nperformance are improved up to 27% and 59%, respectively.",
      "tldr_zh": "本研究提出了一种结合迁移学习（transfer learning）和物理信息建模（physics-informed modeling）的混合方法，以提高工业废水处理厂中溶解氧浓度（dissolved oxygen concentration）的预测性能，针对数据缺失、低质量或噪声等问题。方法通过转移知识自一个开源模拟模型（捕捉过程物理但与目标工厂有差异）、另一个位于同一炼油厂的工业工厂（数据噪声大且有限），并将训练问题目标函数基于该开源模型的物理信息。结果显示，测试性能提高了27%，验证性能提高了59%，为处理复杂非线性系统提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11217v1",
      "published_date": "2024-01-20 11:53:08 UTC",
      "updated_date": "2024-01-20 11:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:04:44.593705"
    },
    {
      "arxiv_id": "2401.11212v3",
      "title": "Programming Distributed Collective Processes in the eXchange Calculus",
      "title_zh": "eXchange Calculus 中的分布式集体进程编程",
      "authors": [
        "Giorgio Audrito",
        "Roberto Casadei",
        "Ferruccio Damiani",
        "Gianluca Torta",
        "Mirko Viroli"
      ],
      "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and\nmulti-scale deployments of computing devices in nearly all kinds of\nenvironments. A prominent engineering challenge revolves around programming the\ncollective adaptive behaviour of such computational ecosystems. This requires\nabstractions able to capture concepts like ensembles (dynamic groups of\ncooperating devices) and collective tasks (joint activities carried out by\nensembles). In this work, we consider collections of devices interacting with\nneighbours and that execute in nearly-synchronised sense-compute-interact\nrounds, where the computation is given by a single program mapping sensing\nvalues and incoming messages to output and outcoming messages. To support\nprogramming whole computational collectives, we propose the abstraction of a\ndistributed collective process, which can be used to define at once the\nensemble formation logic and its collective task. We formalise the abstraction\nin the eXchange Calculus (XC), a core functional language based on neighbouring\nvalues (maps from neighbours to values) where state and interaction is handled\nthrough a single primitive, exchange, and provide a corresponding\nimplementation in the FCPP language. Then, we exercise distributed collective\nprocesses using two case studies: multi-hop message propagation and distributed\nmonitoring of spatial properties. Finally, we discuss the features of the\nabstraction and its suitability for different kinds of distributed computing\napplications.",
      "tldr_zh": "本文提出了一种抽象框架，用于编程分布式集体过程（distributed collective processes），以应对物联网（IoT）环境中计算设备的集体适应行为，包括动态设备组（ensembles）和集体任务（collective tasks）。该框架在eXchange Calculus (XC)中形式化，使用exchange原始处理邻居值（neighbouring values）的状态和交互，并提供了FCPP语言的实现。作者通过多跳消息传播和分布式空间属性监控的案例研究，验证了该抽象的有效性，并讨论了其在各种分布式计算应用中的适用性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.MA",
        "cs.PL",
        "D.1.3; F.1.1; F.4.3; I.2.11; J.7"
      ],
      "primary_category": "cs.DC",
      "comment": "41 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.11212v3",
      "published_date": "2024-01-20 11:37:44 UTC",
      "updated_date": "2025-04-04 15:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:04:55.248263"
    },
    {
      "arxiv_id": "2401.11201v1",
      "title": "Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects",
      "title_zh": "穿越细微界线：考察搜索中的用户行为以检测参与度和反作用效应",
      "authors": [
        "F. M. Cau",
        "N. Tintarev"
      ],
      "abstract": "Opinionated users often seek information that aligns with their preexisting\nbeliefs while dismissing contradictory evidence due to confirmation bias. This\nconduct hinders their ability to consider alternative stances when searching\nthe web. Despite this, few studies have analyzed how the diversification of\nsearch results on disputed topics influences the search behavior of highly\nopinionated users. To this end, we present a preregistered user study (n = 257)\ninvestigating whether different levels (low and high) of bias metrics and\nsearch results presentation (with or without AI-predicted stances labels) can\naffect the stance diversity consumption and search behavior of opinionated\nusers on three debated topics (i.e., atheism, intellectual property rights, and\nschool uniforms). Our results show that exposing participants to\n(counter-attitudinally) biased search results increases their consumption of\nattitude-opposing content, but we also found that bias was associated with a\ntrend toward overall fewer interactions within the search page. We also found\nthat 19% of users interacted with queries and search pages but did not select\nany search results. When we removed these participants in a post-hoc analysis,\nwe found that stance labels increased the diversity of stances consumed by\nusers, particularly when the search results were biased. Our findings highlight\nthe need for future research to explore distinct search scenario settings to\ngain insight into opinionated users' behavior.",
      "tldr_zh": "这篇论文探讨了意见强烈用户在网络搜索中受confirmation bias影响的搜索行为，特别是在争议话题（如无神论、知识产权和校服）上如何偏向支持自身信念的信息。研究通过一项preregistered user study（n=257）测试了不同偏见水平（低和高）和搜索结果呈现方式（是否添加AI-predicted stances labels）对用户立场多样性消费和互动的影响。结果显示，有偏见搜索结果增加了用户消费反态度内容的比例，但整体互动减少，且19%的用户虽互动查询却未选择结果；在后验分析中，立场标签显著提升了偏见搜索下的立场多样性。论文强调，需要更多研究探索不同搜索场景，以深入理解opinionated users的行为。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 3 figures, ECIR2024 (46th European Conference on\n  Information Retrieval - IR4Good track)",
      "pdf_url": "http://arxiv.org/pdf/2401.11201v1",
      "published_date": "2024-01-20 10:28:25 UTC",
      "updated_date": "2024-01-20 10:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:05:08.442827"
    },
    {
      "arxiv_id": "2401.11188v1",
      "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions",
      "title_zh": "深度神经网络分区区域的快速且精确枚举",
      "authors": [
        "Randall Balestriero",
        "Yann LeCun"
      ],
      "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical\nstudy and providing practical guidelines to practitioners relies on Piecewise\nAffine Splines. In that realm, a DN's input-mapping is expressed as per-region\naffine mapping where those regions are implicitly determined by the model's\narchitecture and form a partition of their input space. That partition -- which\nis involved in all the results spanned from this line of research -- has so far\nonly been computed on $2/3$-dimensional slices of the DN's input space or\nestimated by random sampling. In this paper, we provide the first parallel\nalgorithm that does exact enumeration of the DN's partition regions. The\nproposed algorithm enables one to finally assess the closeness of the commonly\nemployed approximations methods, e.g. based on random sampling of the DN input\nspace. One of our key finding is that if one is only interested in regions with\n``large'' volume, then uniform sampling of the space is highly efficient, but\nthat if one is also interested in discovering the ``small'' regions of the\npartition, then uniform sampling is exponentially costly with the DN's input\nspace dimension. On the other hand, our proposed method has complexity scaling\nlinearly with input dimension and the number of regions.",
      "tldr_zh": "这篇论文提出了一种快速且精确的并行算法，用于对 Deep Networks (DNs) 的分区区域进行 exact enumeration，这些区域基于 Piecewise Affine Splines 定义，并由模型架构隐式形成输入空间的分区。以前的方法仅限于在2/3维切片上计算分区或通过随机采样估计，而新算法首次实现了对完整分区的精确枚举。研究发现，如果只关注“large”体积的区域，均匀采样是高效的，但对于“小”区域，采样成本会随输入空间维度指数级增加；相比之下，该算法的复杂度与输入维度和区域数量线性相关。这为评估常用近似方法提供了可靠工具，并为DNs的理论研究和实践应用带来更精确的指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11188v1",
      "published_date": "2024-01-20 09:51:52 UTC",
      "updated_date": "2024-01-20 09:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:05:20.097238"
    },
    {
      "arxiv_id": "2401.11174v3",
      "title": "Pixel-Wise Recognition for Holistic Surgical Scene Understanding",
      "title_zh": "针对整体手术场景理解的逐像素识别",
      "authors": [
        "Nicolás Ayobi",
        "Santiago Rodríguez",
        "Alejandra Pérez",
        "Isabela Hernández",
        "Nicolás Aparicio",
        "Eugénie Dessevres",
        "Sebastián Peña",
        "Jessica Santander",
        "Juan Ignacio Caicedo",
        "Nicolás Fernández",
        "Pablo Arbeláez"
      ],
      "abstract": "This paper presents the Holistic and Multi-Granular Surgical Scene\nUnderstanding of Prostatectomies (GraSP) dataset, a curated benchmark that\nmodels surgical scene understanding as a hierarchy of complementary tasks with\nvarying levels of granularity. Our approach encompasses long-term tasks, such\nas surgical phase and step recognition, and short-term tasks, including\nsurgical instrument segmentation and atomic visual actions detection. To\nexploit our proposed benchmark, we introduce the Transformers for Actions,\nPhases, Steps, and Instrument Segmentation (TAPIS) model, a general\narchitecture that combines a global video feature extractor with localized\nregion proposals from an instrument segmentation model to tackle the\nmulti-granularity of our benchmark. Through extensive experimentation in ours\nand alternative benchmarks, we demonstrate TAPIS's versatility and\nstate-of-the-art performance across different tasks. This work represents a\nfoundational step forward in Endoscopic Vision, offering a novel framework for\nfuture research towards holistic surgical scene understanding.",
      "tldr_zh": "本论文介绍了GraSP数据集，这是一个针对前列腺切除手术的基准，用于建模手术场景理解的层次结构，包括长期任务（如手术阶段和步骤识别）和短期任务（如手术器械分割和原子视觉动作检测）。为了利用该数据集，作者提出TAPIS模型，这是一个基于Transformers的通用架构，结合全局视频特征提取器和局部区域提案来处理多粒度任务。实验结果显示，TAPIS在GraSP和其他基准上表现出色，实现了state-of-the-art性能，为Endoscopic Vision领域的整体手术场景理解提供了创新框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint submitted to Medical Image Analysis. Official extension of\n  previous MICCAI 2022\n  (https://link.springer.com/chapter/10.1007/978-3-031-16449-1_42) and ISBI\n  2023 (https://ieeexplore.ieee.org/document/10230819) orals. Data and codes\n  are available at https://github.com/BCV-Uniandes/GraSP",
      "pdf_url": "http://arxiv.org/pdf/2401.11174v3",
      "published_date": "2024-01-20 09:09:52 UTC",
      "updated_date": "2024-12-27 01:39:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:05:30.424638"
    },
    {
      "arxiv_id": "2402.01677v5",
      "title": "Embedding Ontologies via Incorporating Extensional and Intensional Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Keyu Wang",
        "Guilin Qi",
        "Jiaoyan Chen",
        "Yi Huang",
        "Tianxing Wu"
      ],
      "abstract": "Ontologies contain rich knowledge within domain, which can be divided into\ntwo categories, namely extensional knowledge and intensional knowledge.\nExtensional knowledge provides information about the concrete instances that\nbelong to specific concepts in the ontology, while intensional knowledge\ndetails inherent properties, characteristics, and semantic associations among\nconcepts. However, existing ontology embedding approaches fail to take both\nextensional knowledge and intensional knowledge into fine consideration\nsimultaneously. In this paper, we propose a novel ontology embedding approach\nnamed EIKE (Extensional and Intensional Knowledge Embedding) by representing\nontologies in two spaces, called extensional space and intensional space. EIKE\npresents a unified framework for embedding instances, concepts and their\nrelations in an ontology, applying a geometry-based method to model extensional\nknowledge and a pretrained language model to model intensional knowledge, which\ncan capture both structure information and textual information. Experimental\nresults show that EIKE significantly outperforms state-of-the-art methods in\nthree datasets for both triple classification and link prediction, indicating\nthat EIKE provides a more comprehensive and representative perspective of the\ndomain.",
      "tldr_zh": "本研究提出了一种新的本体（Ontologies）嵌入方法 EIKE（Extensional and Intensional Knowledge Embedding），旨在同时整合扩展知识（Extensional Knowledge）和内涵知识（Intensional Knowledge），以解决现有方法忽略其中一种或两者的局限性。EIKE 通过在扩展空间使用几何-based 方法来建模实例和结构信息，以及在内涵空间使用预训练语言模型来捕捉概念的属性和语义关联，从而实现对本体中实例、概念及其关系的统一嵌入。实验结果表明，在三个数据集上，EIKE 在三元组分类（triple classification）和链接预测（link prediction）任务中显著优于最先进方法，提供了一个更全面和代表性的领域视角。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01677v5",
      "published_date": "2024-01-20 08:44:34 UTC",
      "updated_date": "2025-04-21 15:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:05:44.356915"
    },
    {
      "arxiv_id": "2401.12244v1",
      "title": "Large-scale Reinforcement Learning for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yinan Zhang",
        "Eric Tzeng",
        "Yilun Du",
        "Dmitry Kislyuk"
      ],
      "abstract": "Text-to-image diffusion models are a class of deep generative models that\nhave demonstrated an impressive capacity for high-quality image generation.\nHowever, these models are susceptible to implicit biases that arise from\nweb-scale text-image training pairs and may inaccurately model aspects of\nimages we care about. This can result in suboptimal samples, model bias, and\nimages that do not align with human ethics and preferences. In this paper, we\npresent an effective scalable algorithm to improve diffusion models using\nReinforcement Learning (RL) across a diverse set of reward functions, such as\nhuman preference, compositionality, and fairness over millions of images. We\nillustrate how our approach substantially outperforms existing methods for\naligning diffusion models with human preferences. We further illustrate how\nthis substantially improves pretrained Stable Diffusion (SD) models, generating\nsamples that are preferred by humans 80.3% of the time over those from the base\nSD model while simultaneously improving both the composition and diversity of\ngenerated samples.",
      "tldr_zh": "本研究针对文本到图像的 diffusion models 存在的隐式偏差问题（如模型偏差和不符合人类偏好），提出了一种大规模强化学习（RL）算法，用于优化这些模型。算法通过多种奖励函数（如人类偏好、compositionality 和 fairness）处理数百万图像，实现模型的改进和对齐。实验结果显示，该方法显著优于现有技术，并在预训练的 Stable Diffusion (SD) 模型上提升性能，使生成的样本在80.3%的时间内被人类偏好，同时提高了样本的组合性和多样性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12244v1",
      "published_date": "2024-01-20 08:10:43 UTC",
      "updated_date": "2024-01-20 08:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:05:54.937833"
    },
    {
      "arxiv_id": "2401.11156v2",
      "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding Space",
      "title_zh": "翻译失败",
      "authors": [
        "Xuechen Liu",
        "Md Sahidullah",
        "Kong Aik Lee",
        "Tomi Kinnunen"
      ],
      "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be\nspoofed using various types of adversaries. The usual approach to counteract\nASV systems against such attacks is to develop a separate spoofing\ncountermeasure (CM) module to classify speech input either as a bonafide, or a\nspoofed utterance. Nevertheless, such a design requires additional computation\nand utilization efforts at the authentication stage. An alternative strategy\ninvolves a single monolithic ASV system designed to handle both zero-effort\nimposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have\nthe potential to provide stronger protections and more economic computations.\nTo this end, we propose to generalize the standalone ASV (G-SASV) against\nspoofing attacks, where we leverage limited training data from CM to enhance a\nsimple backend in the embedding space, without the involvement of a separate CM\nmodule during the test (authentication) phase. We propose a novel yet simple\nbackend classifier based on deep neural networks and conduct the study via\ndomain adaptation and multi-task integration of spoof embeddings at the\ntraining stage. Experiments are conducted on the ASVspoof 2019 logical access\ndataset, where we improve the performance of statistical ASV backends on the\njoint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and\n49.8% in terms of equal error rates, respectively.",
      "tldr_zh": "本研究针对自动说话人验证 (ASV) 系统易受欺骗攻击的问题，提出了一种泛化独立 ASV (G-SASV) 方法，通过在 embedding space 中增强后端分类器来实现对欺骗攻击的感知，而无需单独的反欺骗模块 (CM)。该方法利用有限的 CM 训练数据，进行域适应和多任务整合，以处理欺骗嵌入。实验结果显示，在 ASVspoof 2019 逻辑访问数据集上，G-SASV 相比统计 ASV 后端，将联合（真实和伪造）条件下的错误率降低了最多 36.2%，伪造条件下的错误率降低了最多 49.8%。这为更高效且鲁棒的说话人验证系统提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CR",
      "comment": "Published in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (doi updated)",
      "pdf_url": "http://arxiv.org/pdf/2401.11156v2",
      "published_date": "2024-01-20 07:30:22 UTC",
      "updated_date": "2024-01-28 02:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:06:09.025545"
    },
    {
      "arxiv_id": "2401.11143v4",
      "title": "Density Adaptive Attention is All You Need: Robust Parameter-Efficient Fine-Tuning Across Multiple Modalities",
      "title_zh": "密度自适应注意力就是你所需要的：跨多个模态的鲁棒参数高效微调",
      "authors": [
        "Georgios Ioannides",
        "Aman Chadha",
        "Aaron Elkins"
      ],
      "abstract": "We propose the Multi-Head Density Adaptive Attention Mechanism (DAAM), a\nnovel probabilistic attention framework that can be used for\nParameter-Efficient Fine-tuning (PEFT), and the Density Adaptive Transformer\n(DAT), designed to enhance information aggregation across multiple modalities,\nincluding Speech, Text, and Vision. DAAM integrates learnable mean and variance\ninto its attention mechanism, implemented in a multi-head framework, enabling\nit to collectively model any probability distribution for dynamic recalibration\nof feature significance. This method demonstrates significant improvements,\nespecially with highly non-stationary data, surpassing the state-of-the-art\nattention techniques in model performance, up to approximately +20% (abs.) in\naccuracy. Empirically, DAAM exhibits superior adaptability and efficacy across\na diverse range of tasks, including emotion recognition in speech, image\nclassification, and text classification, thereby establishing its robustness\nand versatility in handling data across multiple modalities. Furthermore, we\nintroduce the Importance Factor, a new learning-based metric that enhances the\nexplainability of models trained with DAAM-based methods.",
      "tldr_zh": "本研究提出了一种新型的 Multi-Head Density Adaptive Attention Mechanism (DAAM)，作为一种概率注意力框架，用于 Parameter-Efficient Fine-tuning (PEFT)，并开发了 Density Adaptive Transformer (DAT) 来增强语音、文本和视觉等多模态信息聚合。DAAM 通过整合可学习的均值和方差，在多头框架中动态重新校准特征重要性，尤其适用于非平稳数据，从而显著提升模型性能，准确率最高提高约 20%。此外，该方法在情感识别、图像分类和文本分类等任务中表现出色，并引入了 Importance Factor 这一新学习指标，以提高模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SD",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11143v4",
      "published_date": "2024-01-20 06:42:32 UTC",
      "updated_date": "2024-09-29 00:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:06:20.747711"
    },
    {
      "arxiv_id": "2401.11140v1",
      "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection",
      "title_zh": "少样本端到端目标检测的稳定性-",
      "authors": [
        "Yuantao Yin",
        "Ping Yin"
      ],
      "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object\ndetectors efficiently with only few annotated samples. Fine-tuning has been\nshown to be an effective and practical approach. However, previous works often\ntake the classical base-novel two stage fine-tuning procedure but ignore the\nimplicit stability-plasticity contradiction among different modules.\nSpecifically, the random re-initialized classifiers need more plasticity to\nadapt to novel samples. The other modules inheriting pre-trained weights demand\nmore stability to reserve their class-agnostic knowledge. Regular fine-tuning\nwhich couples the optimization of these two parts hurts the model\ngeneralization in FSOD scenarios. In this paper, we find that this problem is\nprominent in the end-to-end object detector Sparse R-CNN for its\nmulti-classifier cascaded architecture. We propose to mitigate this\ncontradiction by a new three-stage fine-tuning procedure by introducing an\naddtional plasticity classifier fine-tuning(PCF) stage. We further design the\nmulti-source ensemble(ME) technique to enhance the generalization of the model\nin the final fine-tuning stage. Extensive experiments verify that our method is\neffective in regularizing Sparse R-CNN, outperforming previous methods in the\nFSOD benchmark.",
      "tldr_zh": "本论文针对 Few-shot object detection (FSOD) 的微调过程，揭示了不同模块间的稳定性-可塑性矛盾问题，即分类器需更多可塑性适应新样本，而其他预训练模块需保持稳定性以保留类无关知识。作者提出一种新的三阶段微调方法，包括额外的可塑性分类器微调 (PCF) 阶段，以及多源集成 (ME) 技术，以解耦优化并提升模型泛化能力。在端到端检测器 Sparse R-CNN 上进行广泛实验，该方法显著优于现有基准，在 FSOD 任务中提高了检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11140v1",
      "published_date": "2024-01-20 06:31:30 UTC",
      "updated_date": "2024-01-20 06:31:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:06:32.119773"
    },
    {
      "arxiv_id": "2402.04880v2",
      "title": "Combining Cloud and Mobile Computing for Machine Learning",
      "title_zh": "结合云计算和移动计算用于机器",
      "authors": [
        "Ruiqi Xu",
        "Tianchi Zhang"
      ],
      "abstract": "Although the computing power of mobile devices is increasing, machine\nlearning models are also growing in size. This trend creates problems for\nmobile devices due to limitations like their memory capacity and battery life.\nWhile many services, like ChatGPT and Midjourney, run all the inferences in the\ncloud, we believe a flexible and fine-grained task distribution is more\ndesirable. In this work, we consider model segmentation as a solution to\nimproving the user experience, dividing the computation between mobile devices\nand the cloud in a way that offloads the compute-heavy portion of the model\nwhile minimizing the data transfer required. We show that the division not only\nreduces the wait time for users but can also be fine-tuned to optimize the\nworkloads of the cloud. To achieve that, we design a scheduler that collects\ninformation about network quality, client device capability, and job\nrequirements, making decisions to achieve consistent performance across a range\nof devices while reducing the work the cloud needs to perform.",
      "tldr_zh": "该研究探讨了移动设备计算能力的限制（如内存和电池寿命）与机器学习模型规模增长之间的矛盾，提出通过模型分割（model segmentation）来优化计算任务分配。方法是将计算密集部分移至云端，同时最小化数据传输，从而减少用户等待时间并提升整体性能。为实现这一目标，研究设计了一个调度器（scheduler），它根据网络质量、客户端设备能力及任务需求进行决策，确保在不同设备上实现一致的性能，同时降低云端工作负载。总体而言，此方法为结合云端和移动计算的机器学习应用提供了灵活的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Ruiqi Xu and Tianchi Zhang contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2402.04880v2",
      "published_date": "2024-01-20 06:14:22 UTC",
      "updated_date": "2024-02-23 22:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:06:42.012904"
    },
    {
      "arxiv_id": "2402.00041v1",
      "title": "Spatial-temporal-demand clustering for solving large-scale vehicle routing problems with time windows",
      "title_zh": "空间-时间-需求聚类用于解决大规模带时间窗的车辆路径问题",
      "authors": [
        "Christoph Kerscher",
        "Stefan Minner"
      ],
      "abstract": "Several metaheuristics use decomposition and pruning strategies to solve\nlarge-scale instances of the vehicle routing problem (VRP). Those complexity\nreduction techniques often rely on simple, problem-specific rules. However, the\ngrowth in available data and advances in computer hardware enable data-based\napproaches that use machine learning (ML) to improve scalability of solution\nalgorithms. We propose a decompose-route-improve (DRI) framework that groups\ncustomers using clustering. Its similarity metric incorporates customers'\nspatial, temporal, and demand data and is formulated to reflect the problem's\nobjective function and constraints. The resulting sub-routing problems can\nindependently be solved using any suitable algorithm. We apply pruned local\nsearch (LS) between solved subproblems to improve the overall solution. Pruning\nis based on customers' similarity information obtained in the decomposition\nphase. In a computational study, we parameterize and compare existing\nclustering algorithms and benchmark the DRI against the Hybrid Genetic Search\n(HGS) of Vidal et al. (2013). Results show that our data-based approach\noutperforms classic cluster-first, route-second approaches solely based on\ncustomers' spatial information. The newly introduced similarity metric forms\nseparate sub-VRPs and improves the selection of LS moves in the improvement\nphase. Thus, the DRI scales existing metaheuristics to achieve high-quality\nsolutions faster for large-scale VRPs by efficiently reducing complexity.\nFurther, the DRI can be easily adapted to various solution methods and VRP\ncharacteristics, such as distribution of customer locations and demands, depot\nlocation, and different time window scenarios, making it a generalizable\napproach to solving routing problems.",
      "tldr_zh": "该论文提出了一种基于空间-时间-需求聚类的 decompose-route-improve (DRI) 框架，用于解决大规模带时间窗的 vehicle routing problems (VRP)。框架通过设计一个整合客户空间、时间和需求数据的相似性指标来分组客户，形成独立的子路由问题，并应用基于相似性的 pruned local search (LS) 来优化整体解决方案。与传统方法相比，实验结果显示 DRI 框架显著提升了求解效率，在基准测试中 outperform 了 Hybrid Genetic Search (HGS)，并能轻松适应不同 VRP 特性，如客户分布和时间窗场景。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00041v1",
      "published_date": "2024-01-20 06:06:01 UTC",
      "updated_date": "2024-01-20 06:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:06:56.298793"
    },
    {
      "arxiv_id": "2401.11120v2",
      "title": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines",
      "title_zh": "通过整合临床实践指南增强大语言模型用于临床决策支持",
      "authors": [
        "David Oniani",
        "Xizhi Wu",
        "Shyam Visweswaran",
        "Sumit Kapoor",
        "Shravan Kooragayalu",
        "Katelyn Polanska",
        "Yanshan Wang"
      ],
      "abstract": "Background Large Language Models (LLMs), enhanced with Clinical Practice\nGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).\nHowever, methods for incorporating CPGs into LLMs are not well studied. Methods\nWe develop three distinct methods for incorporating CPGs into LLMs: Binary\nDecision Tree (BDT), Program-Aided Graph Construction (PAGC), and\nChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of\nthe proposed methods, we create a set of synthetic patient descriptions and\nconduct both automatic and human evaluation of the responses generated by four\nLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was\nused as the baseline method. We focus on CDS for COVID-19 outpatient treatment\nas the case study. Results All four LLMs exhibit improved performance when\nenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP\nand PAGC in automatic evaluation. All of the proposed methods demonstrated high\nperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate\nsuperior performance, as compared to plain LLMs with ZSP, in providing accurate\nrecommendations for COVID-19 outpatient treatment, which also highlights the\npotential for broader applications beyond the case study.",
      "tldr_zh": "本研究探讨了通过整合 Clinical Practice Guidelines (CPGs) 来增强 Large Language Models (LLMs) 用于 Clinical Decision Support (CDS)，以改善医疗决策准确性。研究开发了三种方法：Binary Decision Tree (BDT)、Program-Aided Graph Construction (PAGC) 和 Chain-of-Thought-Few-Shot Prompting (CoT-FSP)，并以 Zero-Shot Prompting (ZSP) 作为基线，对 GPT-4、GPT-3.5 Turbo、LLaMA 和 PaLM 2 等模型进行评估，焦点为 COVID-19 门诊治疗。结果显示，所有方法均优于基线，BDT 在自动评估中表现最佳，而所有方法在人工评估中均显示高性能。总之，该方法不仅提升了 LLMs 在 COVID-19 推荐方面的表现，还展示了其在更广泛医疗应用中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11120v2",
      "published_date": "2024-01-20 05:10:46 UTC",
      "updated_date": "2024-01-23 19:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:07:11.100010"
    },
    {
      "arxiv_id": "2401.13697v1",
      "title": "Toward Robust Multimodal Learning using Multimodal Foundational Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xianbing Zhao",
        "Soujanya Poria",
        "Xuejiao Li",
        "Yixin Chen",
        "Buzhou Tang"
      ],
      "abstract": "Existing multimodal sentiment analysis tasks are highly rely on the\nassumption that the training and test sets are complete multimodal data, while\nthis assumption can be difficult to hold: the multimodal data are often\nincomplete in real-world scenarios. Therefore, a robust multimodal model in\nscenarios with randomly missing modalities is highly preferred. Recently,\nCLIP-based multimodal foundational models have demonstrated impressive\nperformance on numerous multimodal tasks by learning the aligned cross-modal\nsemantics of image and text pairs, but the multimodal foundational models are\nalso unable to directly address scenarios involving modality absence. To\nalleviate this issue, we propose a simple and effective framework, namely TRML,\nToward Robust Multimodal Learning using Multimodal Foundational Models. TRML\nemploys generated virtual modalities to replace missing modalities, and aligns\nthe semantic spaces between the generated and missing modalities. Concretely,\nwe design a missing modality inference module to generate virtual modaliites\nand replace missing modalities. We also design a semantic matching learning\nmodule to align semantic spaces generated and missing modalities. Under the\nprompt of complete modality, our model captures the semantics of missing\nmodalities by leveraging the aligned cross-modal semantic space. Experiments\ndemonstrate the superiority of our approach on three multimodal sentiment\nanalysis benchmark datasets, CMU-MOSI, CMU-MOSEI, and MELD.",
      "tldr_zh": "该研究针对多模态情感分析中训练和测试数据可能随机缺失模态的问题，提出了一种鲁棒框架TRML（Toward Robust Multimodal Learning using Multimodal Foundational Models）。TRML利用生成的虚拟模态替换缺失模态，并通过缺失模态推断模块和语义匹配学习模块来对齐虚拟模态与原始模态的语义空间，从而基于CLIP等多模态基础模型捕获完整的跨模态语义。实验在CMU-MOSI、CMU-MOSEI和MELD等基准数据集上证明了该方法的优越性，提升了模型在不完整数据场景下的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2401.13697v1",
      "published_date": "2024-01-20 04:46:43 UTC",
      "updated_date": "2024-01-20 04:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:07:19.895917"
    },
    {
      "arxiv_id": "2401.11113v2",
      "title": "SleepNet: Attention-Enhanced Robust Sleep Prediction using Dynamic Social Networks",
      "title_zh": "SleepNet：利用动态",
      "authors": [
        "Maryam Khalid",
        "Elizabeth B. Klerman",
        "Andrew W. Mchill",
        "Andrew J. K. Phillips",
        "Akane Sano"
      ],
      "abstract": "Sleep behavior significantly impacts health and acts as an indicator of\nphysical and mental well-being. Monitoring and predicting sleep behavior with\nubiquitous sensors may therefore assist in both sleep management and tracking\nof related health conditions. While sleep behavior depends on, and is reflected\nin the physiology of a person, it is also impacted by external factors such as\ndigital media usage, social network contagion, and the surrounding weather. In\nthis work, we propose SleepNet, a system that exploits social contagion in\nsleep behavior through graph networks and integrates it with physiological and\nphone data extracted from ubiquitous mobile and wearable devices for predicting\nnext-day sleep labels about sleep duration. Our architecture overcomes the\nlimitations of large-scale graphs containing connections irrelevant to sleep\nbehavior by devising an attention mechanism. The extensive experimental\nevaluation highlights the improvement provided by incorporating social networks\nin the model. Additionally, we conduct robustness analysis to demonstrate the\nsystem's performance in real-life conditions. The outcomes affirm the stability\nof SleepNet against perturbations in input data. Further analyses emphasize the\nsignificance of network topology in prediction performance revealing that users\nwith higher eigenvalue centrality are more vulnerable to data perturbations.",
      "tldr_zh": "本研究提出 SleepNet 系统，利用动态社会网络中的社会传染效应（social contagion），结合生理数据和手机数据，来预测次日睡眠时长（sleep duration）。SleepNet 采用注意力机制（attention mechanism）处理大规模图网络中与睡眠无关的连接，从而提升预测准确性。实验结果显示，融入社会网络显著提高了模型性能，并在鲁棒性分析中证明了系统在真实条件下稳定表现；此外，分析揭示网络拓扑（如 eigenvalue centrality）对预测影响重大，高中心度用户更易受数据扰动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in Proceedings of the ACM on Interactive,\n  Mobile, Wearable and Ubiquitous Technologies (IMWUT), 8 (March 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11113v2",
      "published_date": "2024-01-20 04:38:34 UTC",
      "updated_date": "2024-01-27 02:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:07:31.647186"
    },
    {
      "arxiv_id": "2401.12998v1",
      "title": "Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA",
      "title_zh": "评估和提升大型语言模型在特定领域医学中的性能：使用 DocOA 进行骨关节炎管理",
      "authors": [
        "Xi Chen",
        "MingKe You",
        "Li Wang",
        "WeiZhi Liu",
        "Yu Fu",
        "Jie Xu",
        "Shaoting Zhang",
        "Gang Chen",
        "Kang Li",
        "Jian Li"
      ],
      "abstract": "The efficacy of large language models (LLMs) in domain-specific medicine,\nparticularly for managing complex diseases such as osteoarthritis (OA), remains\nlargely unexplored. This study focused on evaluating and enhancing the clinical\ncapabilities of LLMs in specific domains, using osteoarthritis (OA) management\nas a case study. A domain specific benchmark framework was developed, which\nevaluate LLMs across a spectrum from domain-specific knowledge to clinical\napplications in real-world clinical scenarios. DocOA, a specialized LLM\ntailored for OA management that integrates retrieval-augmented generation (RAG)\nand instruction prompts, was developed. The study compared the performance of\nGPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human\nevaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less\neffective in the specialized domain of OA management, particularly in providing\npersonalized treatment recommendations. However, DocOA showed significant\nimprovements. This study introduces a novel benchmark framework which assesses\nthe domain-specific abilities of LLMs in multiple aspects, highlights the\nlimitations of generalized LLMs in clinical contexts, and demonstrates the\npotential of tailored approaches for developing domain-specific medical LLMs.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在特定医学领域（如骨关节炎 (OA) 管理）的效能，并通过一个新开发的基准框架，从领域知识到真实临床应用进行全面评估。研究团队创建了 DocOA，一个专为 OA 管理设计的 LLM，结合了检索增强生成 (RAG) 和指令提示，以提升其临床能力。实验结果显示，通用模型如 GPT-3.5 和 GPT-4 在个性化治疗推荐方面表现较差，而 DocOA 取得了显著改进。该研究不仅引入了评估 LLMs 领域特定能力的创新框架，还强调了定制方法的潜力，以克服通用模型在临床环境中的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12998v1",
      "published_date": "2024-01-20 03:41:23 UTC",
      "updated_date": "2024-01-20 03:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:07:46.697277"
    },
    {
      "arxiv_id": "2401.11094v1",
      "title": "TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shishi Xiao",
        "Liangwei Wang",
        "Xiaojuan Ma",
        "Wei Zeng"
      ],
      "abstract": "Semantic typographic logos harmoniously blend typeface and imagery to\nrepresent semantic concepts while maintaining legibility. Conventional methods\nusing spatial composition and shape substitution are hindered by the\nconflicting requirement for achieving seamless spatial fusion between\ngeometrically dissimilar typefaces and semantics. While recent advances made AI\ngeneration of semantic typography possible, the end-to-end approaches exclude\ndesigner involvement and disregard personalized design. This paper presents\nTypeDance, an AI-assisted tool incorporating design rationales with the\ngenerative model for personalized semantic typographic logo design. It\nleverages combinable design priors extracted from uploaded image exemplars and\nsupports type-imagery mapping at various structural granularity, achieving\ndiverse aesthetic designs with flexible control. Additionally, we instantiate a\ncomprehensive design workflow in TypeDance, including ideation, selection,\ngeneration, evaluation, and iteration. A two-task user evaluation, including\nimitation and creation, confirmed the usability of TypeDance in design across\ndifferent usage scenarios",
      "tldr_zh": "本研究针对语义排版标志（semantic typographic logos）的设计问题，指出传统方法难以实现字体和图像的无缝融合，而现有AI生成方法忽略了设计师参与和个性化需求。论文提出TypeDance，一种AI-assisted工具，通过从上传图像中提取可组合的设计先验，并支持不同结构粒度的类型-图像映射，实现多样化的美学设计和灵活控制。TypeDance整合了一个全面的设计工作流，包括构思、选择、生成、评估和迭代，用户评估显示该工具在模仿和创建任务中表现出色，证明了其在不同场景下的可用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.11094v1",
      "published_date": "2024-01-20 02:55:11 UTC",
      "updated_date": "2024-01-20 02:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:07:57.634917"
    },
    {
      "arxiv_id": "2401.11089v1",
      "title": "FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement",
      "title_zh": "FedRKG：一种通过知识图谱增强的隐私保护联邦推荐框架",
      "authors": [
        "Dezhong Yao",
        "Tongtong Liu",
        "Qi Cao",
        "Hai Jin"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising approach for preserving\ndata privacy in recommendation systems by training models locally. Recently,\nGraph Neural Networks (GNN) have gained popularity in recommendation tasks due\nto their ability to capture high-order interactions between users and items.\nHowever, privacy concerns prevent the global sharing of the entire user-item\ngraph. To address this limitation, some methods create pseudo-interacted items\nor users in the graph to compensate for missing information for each client.\nUnfortunately, these methods introduce random noise and raise privacy concerns.\nIn this paper, we propose FedRKG, a novel federated recommendation system,\nwhere a global knowledge graph (KG) is constructed and maintained on the server\nusing publicly available item information, enabling higher-order user-item\ninteractions. On the client side, a relation-aware GNN model leverages diverse\nKG relationships. To protect local interaction items and obscure gradients, we\nemploy pseudo-labeling and Local Differential Privacy (LDP). Extensive\nexperiments conducted on three real-world datasets demonstrate the competitive\nperformance of our approach compared to centralized algorithms while ensuring\nprivacy preservation. Moreover, FedRKG achieves an average accuracy improvement\nof 4% compared to existing federated learning baselines.",
      "tldr_zh": "本研究提出FedRKG，一种基于知识图谱(KG)增强的隐私保护联邦推荐框架，旨在解决联邦学习(FL)中用户-物品图共享的隐私问题。该框架在服务器上构建全局KG利用公开物品信息，并在客户端使用关系感知图神经网络(GNN)模型来捕捉高阶交互；同时，通过伪标签和局部差分隐私(LDP)技术保护本地交互数据和梯度。在三个真实数据集上的实验显示，FedRKG的性能与集中式算法相当，并比现有联邦学习基线平均准确率提升4%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11089v1",
      "published_date": "2024-01-20 02:38:21 UTC",
      "updated_date": "2024-01-20 02:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:08:07.567938"
    },
    {
      "arxiv_id": "2401.11085v1",
      "title": "Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuefang Gao",
        "Yuhao Xie",
        "Zeke Zexi Hu",
        "Tianshui Chen",
        "Liang Lin"
      ],
      "abstract": "Domain shift poses a significant challenge in Cross-Domain Facial Expression\nRecognition (CD-FER) due to the distribution variation across different\ndomains. Current works mainly focus on learning domain-invariant features\nthrough global feature adaptation, while neglecting the transferability of\nlocal features. Additionally, these methods lack discriminative supervision\nduring training on target datasets, resulting in deteriorated feature\nrepresentation in target domain. To address these limitations, we propose an\nAdaptive Global-Local Representation Learning and Selection (AGLRLS) framework.\nThe framework incorporates global-local adversarial adaptation and\nsemantic-aware pseudo label generation to enhance the learning of\ndomain-invariant and discriminative feature during training. Meanwhile, a\nglobal-local prediction consistency learning is introduced to improve\nclassification results during inference. Specifically, the framework consists\nof separate global-local adversarial learning modules that learn\ndomain-invariant global and local features independently. We also design a\nsemantic-aware pseudo label generation module, which computes semantic labels\nbased on global and local features. Moreover, a novel dynamic threshold\nstrategy is employed to learn the optimal thresholds by leveraging independent\nprediction of global and local features, ensuring filtering out the unreliable\npseudo labels while retaining reliable ones. These labels are utilized for\nmodel optimization through the adversarial learning process in an end-to-end\nmanner. During inference, a global-local prediction consistency module is\ndeveloped to automatically learn an optimal result from multiple predictions.\nWe conduct comprehensive experiments and analysis based on a fair evaluation\nbenchmark. The results demonstrate that the proposed framework outperforms the\ncurrent competing methods by a substantial margin.",
      "tldr_zh": "该研究针对跨域面部表情识别（Cross-Domain Facial Expression Recognition, CD-FER）中的领域偏移问题，提出了一种Adaptive Global-Local Representation Learning and Selection (AGLRLS)框架，通过全局-局部对抗适应和语义感知伪标签生成，增强领域不变性和判别特征的学习。框架包括独立的全局-局部对抗学习模块、动态阈值策略来过滤不可靠伪标签，以及全局-局部预测一致性模块，以优化训练和推理过程。实验结果显示，该框架在公平基准上显著优于现有方法，证明了其在改善CD-FER性能方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11085v1",
      "published_date": "2024-01-20 02:21:41 UTC",
      "updated_date": "2024-01-20 02:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:08:20.103924"
    },
    {
      "arxiv_id": "2401.11081v1",
      "title": "Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Adel Javanmard",
        "Lin Chen",
        "Vahab Mirrokni",
        "Ashwinkumar Badanidiyuru",
        "Gang Fu"
      ],
      "abstract": "Due to the rise of privacy concerns, in many practical applications the\ntraining data is aggregated before being shared with the learner, in order to\nprotect privacy of users' sensitive responses. In an aggregate learning\nframework, the dataset is grouped into bags of samples, where each bag is\navailable only with an aggregate response, providing a summary of individuals'\nresponses in that bag. In this paper, we study two natural loss functions for\nlearning from aggregate responses: bag-level loss and the instance-level loss.\nIn the former, the model is learnt by minimizing a loss between aggregate\nresponses and aggregate model predictions, while in the latter the model aims\nto fit individual predictions to the aggregate responses. In this work, we show\nthat the instance-level loss can be perceived as a regularized form of the\nbag-level loss. This observation lets us compare the two approaches with\nrespect to bias and variance of the resulting estimators, and introduce a novel\ninterpolating estimator which combines the two approaches. For linear\nregression tasks, we provide a precise characterization of the risk of the\ninterpolating estimator in an asymptotic regime where the size of the training\nset grows in proportion to the features dimension. Our analysis allows us to\ntheoretically understand the effect of different factors, such as bag size on\nthe model prediction risk. In addition, we propose a mechanism for\ndifferentially private learning from aggregate responses and derive the optimal\nbag size in terms of prediction risk-privacy trade-off. We also carry out\nthorough experiments to corroborate our theory and show the efficacy of the\ninterpolating estimator.",
      "tldr_zh": "本论文探讨了在隐私保护下从聚合响应中学习的两种损失函数：bag-level loss 和 instance-level loss，前者最小化聚合响应与模型预测之间的损失，而后者通过拟合个体预测来实现，并被证明是bag-level loss的正则化形式。研究比较了两种方法的偏差和方差，并引入了一个新的插值估计器，以结合二者优势。针对线性回归任务，论文在训练集大小与特征维度成比例增长的渐近环境中，精确表征了插值估计器的风险，并分析了因素如bag大小的影响。同时，提出了一种差分隐私学习机制，并推导了最佳bag大小以平衡预测风险和隐私，通过实验验证了这些理论发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in the Twelfth International Conference on Learning\n  Representations (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11081v1",
      "published_date": "2024-01-20 02:14:11 UTC",
      "updated_date": "2024-01-20 02:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:08:34.005598"
    },
    {
      "arxiv_id": "2402.04882v1",
      "title": "LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Liu",
        "Gourav Datta",
        "Anni Li",
        "Peter Anthony Beerel"
      ],
      "abstract": "Transformer models have demonstrated high accuracy in numerous applications\nbut have high complexity and lack sequential processing capability making them\nill-suited for many streaming applications at the edge where devices are\nheavily resource-constrained. Thus motivated, many researchers have proposed\nreformulating the transformer models as RNN modules which modify the\nself-attention computation with explicit states. However, these approaches\noften incur significant performance degradation. The ultimate goal is to\ndevelop a model that has the following properties: parallel training, streaming\nand low-cost inference, and SOTA performance. In this paper, we propose a new\ndirection to achieve this goal. We show how architectural modifications to a\nrecurrent model can help push its performance toward Transformer models while\nretaining its sequential processing capability. Specifically, inspired by the\nrecent success of Legendre Memory Units (LMU) in sequence learning tasks, we\npropose LMUFormer, which augments the LMU with convolutional patch embedding\nand convolutional channel mixer. Moreover, we present a spiking version of this\narchitecture, which introduces the benefit of states within the patch embedding\nand channel mixer modules while simultaneously reducing the computing\ncomplexity. We evaluated our architectures on multiple sequence datasets. In\ncomparison to SOTA transformer-based models within the ANN domain on the SCv2\ndataset, our LMUFormer demonstrates comparable performance while necessitating\na remarkable 53 times reduction in parameters and a substantial 65 times\ndecrement in FLOPs. Additionally, owing to our model's proficiency in real-time\ndata processing, we can achieve a 32.03% reduction in sequence length, all\nwhile incurring an inconsequential decline in performance. Our code is publicly\navailable at https://github.com/zeyuliu1037/LMUFormer.git.",
      "tldr_zh": "这篇论文针对Transformer模型的高复杂性和缺乏顺序处理能力的问题，提出了一种低复杂度且高效的序列模型LMUFormer，该模型基于Legendre Memory Units (LMU)，并结合卷积补丁嵌入和卷积通道混合器，以实现并行训练、流式推理和SOTA性能。论文进一步开发了spiking版本，通过在补丁嵌入和通道混合器中引入状态，显著降低计算复杂度。在多个序列数据集上的实验表明，LMUFormer在SCv2数据集上与SOTA Transformer模型性能相当，但参数减少53倍、FLOPs减少65倍，并能将序列长度减少32.03%而几乎不影响性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.NE",
      "comment": "The 12th International Conference on Learning Representations (ICLR\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.04882v1",
      "published_date": "2024-01-20 01:10:18 UTC",
      "updated_date": "2024-01-20 01:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:08:46.208962"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 36,
  "processed_papers_count": 36,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T23:09:10.575922"
}