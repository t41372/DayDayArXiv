[
  {
    "arxiv_id": "2408.13960v2",
    "title": "Time Series Analysis for Education: Methods, Applications, and Future Directions",
    "authors": [
      "Shengzhong Mao",
      "Chaoli Zhang",
      "Yichi Song",
      "Jindong Wang",
      "Xiao-Jun Zeng",
      "Zenglin Xu",
      "Qingsong Wen"
    ],
    "abstract": "Recent advancements in the collection and analysis of sequential educational\ndata have brought time series analysis to a pivotal position in educational\nresearch, highlighting its essential role in facilitating data-driven\ndecision-making. However, there is a lack of comprehensive summaries that\nconsolidate these advancements. To the best of our knowledge, this paper is the\nfirst to provide a comprehensive review of time series analysis techniques\nspecifically within the educational context. We begin by exploring the\nlandscape of educational data analytics, categorizing various data sources and\ntypes relevant to education. We then review four prominent time series\nmethods-forecasting, classification, clustering, and anomaly\ndetection-illustrating their specific application points in educational\nsettings. Subsequently, we present a range of educational scenarios and\napplications, focusing on how these methods are employed to address diverse\neducational tasks, which highlights the practical integration of multiple time\nseries methods to solve complex educational problems. Finally, we conclude with\na discussion on future directions, including personalized learning analytics,\nmultimodal data fusion, and the role of large language models (LLMs) in\neducational time series. The contributions of this paper include a detailed\ntaxonomy of educational data, a synthesis of time series techniques with\nspecific educational applications, and a forward-looking perspective on\nemerging trends and future research opportunities in educational analysis. The\nrelated papers and resources are available and regularly updated at the project\npage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 3 figures, 6 tables, project page: see\n  https://github.com/ai-for-edu/time-series-analysis-for-education",
    "pdf_url": "http://arxiv.org/pdf/2408.13960v2",
    "published_date": "2024-08-25 23:48:11 UTC",
    "updated_date": "2024-08-27 15:06:17 UTC"
  },
  {
    "arxiv_id": "2408.13950v1",
    "title": "Bridging the Gap between Real-world and Synthetic Images for Testing Autonomous Driving Systems",
    "authors": [
      "Mohammad Hossein Amini",
      "Shiva Nejati"
    ],
    "abstract": "Deep Neural Networks (DNNs) for Autonomous Driving Systems (ADS) are\ntypically trained on real-world images and tested using synthetic simulator\nimages. This approach results in training and test datasets with dissimilar\ndistributions, which can potentially lead to erroneously decreased test\naccuracy. To address this issue, the literature suggests applying\ndomain-to-domain translators to test datasets to bring them closer to the\ntraining datasets. However, translating images used for testing may\nunpredictably affect the reliability, effectiveness and efficiency of the\ntesting process. Hence, this paper investigates the following questions in the\ncontext of ADS: Could translators reduce the effectiveness of images used for\nADS-DNN testing and their ability to reveal faults in ADS-DNNs? Can translators\nresult in excessive time overhead during simulation-based testing? To address\nthese questions, we consider three domain-to-domain translators: CycleGAN and\nneural style transfer, from the literature, and SAEVAE, our proposed\ntranslator. Our results for two critical ADS tasks -- lane keeping and object\ndetection -- indicate that translators significantly narrow the gap in ADS test\naccuracy caused by distribution dissimilarities between training and test data,\nwith SAEVAE outperforming the other two translators. We show that, based on the\nrecent diversity, coverage, and fault-revealing ability metrics for testing\ndeep-learning systems, translators do not compromise the diversity and the\ncoverage of test data, nor do they lead to revealing fewer faults in ADS-DNNs.\nFurther, among the translators considered, SAEVAE incurs a negligible overhead\nin simulation time and can be efficiently integrated into simulation-based\ntesting. Finally, we show that translators increase the correlation between\noffline and simulation-based testing results, which can help reduce the cost of\nsimulation-based testing.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication by the International Conference on Automated\n  Software Engineering (ASE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.13950v1",
    "published_date": "2024-08-25 22:07:41 UTC",
    "updated_date": "2024-08-25 22:07:41 UTC"
  },
  {
    "arxiv_id": "2408.13934v1",
    "title": "Learning to Move Like Professional Counter-Strike Players",
    "authors": [
      "David Durst",
      "Feng Xie",
      "Vishnu Sarukkai",
      "Brennan Shacklett",
      "Iuri Frosio",
      "Chen Tessler",
      "Joohwan Kim",
      "Carly Taylor",
      "Gilbert Bernstein",
      "Sanjiban Choudhury",
      "Pat Hanrahan",
      "Kayvon Fatahalian"
    ],
    "abstract": "In multiplayer, first-person shooter games like Counter-Strike: Global\nOffensive (CS:GO), coordinated movement is a critical component of high-level\nstrategic play. However, the complexity of team coordination and the variety of\nconditions present in popular game maps make it impractical to author\nhand-crafted movement policies for every scenario. We show that it is possible\nto take a data-driven approach to creating human-like movement controllers for\nCS:GO. We curate a team movement dataset comprising 123 hours of professional\ngame play traces, and use this dataset to train a transformer-based movement\nmodel that generates human-like team movement for all players in a \"Retakes\"\nround of the game. Importantly, the movement prediction model is efficient.\nPerforming inference for all players takes less than 0.5 ms per game step\n(amortized cost) on a single CPU core, making it plausible for use in\ncommercial games today. Human evaluators assess that our model behaves more\nlike humans than both commercially-available bots and procedural movement\ncontrollers scripted by experts (16% to 59% higher by TrueSkill rating of\n\"human-like\"). Using experiments involving in-game bot vs. bot self-play, we\ndemonstrate that our model performs simple forms of teamwork, makes fewer\ncommon movement mistakes, and yields movement distributions, player lifetimes,\nand kill locations similar to those observed in professional CS:GO match play.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "The project website is at https://davidbdurst.com/mlmove/",
    "pdf_url": "http://arxiv.org/pdf/2408.13934v1",
    "published_date": "2024-08-25 20:43:34 UTC",
    "updated_date": "2024-08-25 20:43:34 UTC"
  },
  {
    "arxiv_id": "2408.13926v1",
    "title": "FedGlu: A personalized federated learning-based glucose forecasting algorithm for improved performance in glycemic excursion regions",
    "authors": [
      "Darpit Dave",
      "Kathan Vyas",
      "Jagadish Kumaran Jayagopal",
      "Alfredo Garcia",
      "Madhav Erraguntla",
      "Mark Lawley"
    ],
    "abstract": "Continuous glucose monitoring (CGM) devices provide real-time glucose\nmonitoring and timely alerts for glycemic excursions, improving glycemic\ncontrol among patients with diabetes. However, identifying rare events like\nhypoglycemia and hyperglycemia remain challenging due to their infrequency.\nMoreover, limited access to sensitive patient data hampers the development of\nrobust machine learning models. Our objective is to accurately predict glycemic\nexcursions while addressing data privacy concerns. To tackle excursion\nprediction, we propose a novel Hypo-Hyper (HH) loss function, which\nsignificantly improves performance in the glycemic excursion regions. The HH\nloss function demonstrates a 46% improvement over mean-squared error (MSE) loss\nacross 125 patients. To address privacy concerns, we propose FedGlu, a machine\nlearning model trained in a federated learning (FL) framework. FL allows\ncollaborative learning without sharing sensitive data by training models\nlocally and sharing only model parameters across other patients. FedGlu\nachieves a 35% superior glycemic excursion detection rate compared to local\nmodels. This improvement translates to enhanced performance in predicting both,\nhypoglycemia and hyperglycemia, for 105 out of 125 patients. These results\nunderscore the effectiveness of the proposed HH loss function in augmenting the\npredictive capabilities of glucose predictions. Moreover, implementing models\nwithin a federated learning framework not only ensures better predictive\ncapabilities but also safeguards sensitive data concurrently.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13926v1",
    "published_date": "2024-08-25 19:51:27 UTC",
    "updated_date": "2024-08-25 19:51:27 UTC"
  },
  {
    "arxiv_id": "2408.13918v4",
    "title": "Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with Spatiotemporal Constraints",
    "authors": [
      "Siyu Li",
      "Toan Tran",
      "Haowen Lin",
      "John Krumm",
      "Cyrus Shahabi",
      "Lingyi Zhao",
      "Khurram Shafique",
      "Li Xiong"
    ],
    "abstract": "Generating realistic human mobility data is essential for various application\ndomains, including transportation, urban planning, and epidemic control, as\nreal data is often inaccessible to researchers due to high costs and privacy\nconcerns. Existing deep generative models learn from real trajectories to\ngenerate synthetic ones. Despite the progress, most of them suffer from\ntraining stability issues and scale poorly with increasing data size. More\nimportantly, they often lack control mechanisms to guide the generated\ntrajectories under constraints such as enforcing specific visits. To address\nthese limitations, we formally define the controlled trajectory generation\nproblem for effectively handling multiple spatiotemporal constraints. We\nintroduce Geo-Llama, a novel LLM finetuning framework that can enforce multiple\nexplicit visit constraints while maintaining contextual coherence of the\ngenerated trajectories. In this approach, pre-trained LLMs are fine-tuned on\ntrajectory data with a visit-wise permutation strategy where each visit\ncorresponds to a specific time and location. This strategy enables the model to\ncapture spatiotemporal patterns regardless of visit orders while maintaining\nflexible and in-context constraint integration through prompts during\ngeneration. Extensive experiments on real-world and synthetic datasets validate\nthe effectiveness of Geo-Llama, demonstrating its versatility and robustness in\nhandling a broad range of constraints to generate more realistic trajectories\ncompared to existing methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13918v4",
    "published_date": "2024-08-25 19:03:46 UTC",
    "updated_date": "2025-04-28 09:22:21 UTC"
  },
  {
    "arxiv_id": "2408.13915v1",
    "title": "LLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie Detection with Self-Generated Feedback",
    "authors": [
      "Tanushree Banerjee",
      "Richard Zhu",
      "Runzhe Yang",
      "Karthik Narasimhan"
    ],
    "abstract": "Large Language Models (LLMs) excel at generating human-like dialogues and\ncomprehending text. However, understanding the subtleties of complex exchanges\nin language remains a challenge. We propose a bootstrapping framework that\nleverages self-generated feedback to enhance LLM reasoning capabilities for lie\ndetection. The framework consists of three stages: suggestion, feedback\ncollection, and modification. In the suggestion stage, a cost-effective\nlanguage model generates initial predictions based on game state and dialogue.\nThe feedback-collection stage involves a language model providing feedback on\nthese predictions. In the modification stage, a more advanced language model\nrefines the initial predictions using the auto-generated feedback. We\ninvestigate the application of the proposed framework for detecting betrayal\nand deception in Diplomacy games, and compare it with feedback from\nprofessional human players. The LLM-generated feedback exhibits superior\nquality and significantly enhances the performance of the model. Our approach\nachieves a 39% improvement over the zero-shot baseline in lying-F1 without the\nneed for any training data, rivaling state-of-the-art supervised learning\nresults.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13915v1",
    "published_date": "2024-08-25 18:47:55 UTC",
    "updated_date": "2024-08-25 18:47:55 UTC"
  },
  {
    "arxiv_id": "2408.13906v1",
    "title": "ConVis: Contrastive Decoding with Hallucination Visualization for Mitigating Hallucinations in Multimodal Large Language Models",
    "authors": [
      "Yeji Park",
      "Deokyeong Lee",
      "Junsuk Choe",
      "Buru Chang"
    ],
    "abstract": "Hallucinations in Multimodal Large Language Models (MLLMs) where generated\nresponses fail to accurately reflect the given image pose a significant\nchallenge to their reliability. To address this, we introduce ConVis, a novel\ntraining-free contrastive decoding method. ConVis leverages a text-to-image\n(T2I) generation model to semantically reconstruct the given image from\nhallucinated captions. By comparing the contrasting probability distributions\nproduced by the original and reconstructed images, ConVis enables MLLMs to\ncapture visual contrastive signals that penalize hallucination generation.\nNotably, this method operates purely within the decoding process, eliminating\nthe need for additional data or model updates. Our extensive experiments on\nfive popular benchmarks demonstrate that ConVis effectively reduces\nhallucinations across various MLLMs, highlighting its potential to enhance\nmodel reliability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "First two authors contributed equally. Source code is available at\n  https://github.com/yejipark-m/ConVis",
    "pdf_url": "http://arxiv.org/pdf/2408.13906v1",
    "published_date": "2024-08-25 18:02:36 UTC",
    "updated_date": "2024-08-25 18:02:36 UTC"
  },
  {
    "arxiv_id": "2408.16018v1",
    "title": "SPICED: Syntactical Bug and Trojan Pattern Identification in A/MS Circuits using LLM-Enhanced Detection",
    "authors": [
      "Jayeeta Chaudhuri",
      "Dhruv Thapar",
      "Arjun Chaudhuri",
      "Farshad Firouzi",
      "Krishnendu Chakrabarty"
    ],
    "abstract": "Analog and mixed-signal (A/MS) integrated circuits (ICs) are crucial in\nmodern electronics, playing key roles in signal processing, amplification,\nsensing, and power management. Many IC companies outsource manufacturing to\nthird-party foundries, creating security risks such as stealthy analog Trojans.\nTraditional detection methods, including embedding circuit watermarks or\nconducting hardware-based monitoring, often impose significant area and power\noverheads, and may not effectively identify all types of Trojans. To address\nthese shortcomings, we propose SPICED, a Large Language Model (LLM)-based\nframework that operates within the software domain, eliminating the need for\nhardware modifications for Trojan detection and localization. This is the first\nwork using LLM-aided techniques for detecting and localizing syntactical bugs\nand analog Trojans in circuit netlists, requiring no explicit training and\nincurring zero area overhead. Our framework employs chain-of-thought reasoning\nand few-shot examples to teach anomaly detection rules to LLMs. With the\nproposed method, we achieve an average Trojan coverage of 93.32% and an average\ntrue positive rate of 93.4% in identifying Trojan-impacted nodes for the\nevaluated analog benchmark circuits. These experimental results validate the\neffectiveness of LLMs in detecting and locating both syntactical bugs and\nTrojans within analog netlists.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at PAINE'24",
    "pdf_url": "http://arxiv.org/pdf/2408.16018v1",
    "published_date": "2024-08-25 17:07:08 UTC",
    "updated_date": "2024-08-25 17:07:08 UTC"
  },
  {
    "arxiv_id": "2408.13888v1",
    "title": "Enhancing SQL Query Generation with Neurosymbolic Reasoning",
    "authors": [
      "Henrijs Princis",
      "Cristina David",
      "Alan Mycroft"
    ],
    "abstract": "Neurosymbolic approaches blend the effectiveness of symbolic reasoning with\nthe flexibility of neural networks. In this work, we propose a neurosymbolic\narchitecture for generating SQL queries that builds and explores a solution\ntree using Best-First Search, with the possibility of backtracking. For this\npurpose, it integrates a Language Model (LM) with symbolic modules that help\ncatch and correct errors made by the LM on SQL queries, as well as guiding the\nexploration of the solution tree. We focus on improving the performance of\nsmaller open-source LMs, and we find that our tool, Xander, increases accuracy\nby an average of 10.9% and reduces runtime by an average of 28% compared to the\nLM without Xander, enabling a smaller LM (with Xander) to outperform its\nfour-times larger counterpart (without Xander).",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE",
      "I.2"
    ],
    "primary_category": "cs.DB",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13888v1",
    "published_date": "2024-08-25 16:37:26 UTC",
    "updated_date": "2024-08-25 16:37:26 UTC"
  },
  {
    "arxiv_id": "2408.13871v2",
    "title": "AlphaViT: A Flexible Game-Playing AI for Multiple Games and Variable Board Sizes",
    "authors": [
      "Kazuhisa Fujita"
    ],
    "abstract": "This paper presents novel game-playing AI agents based on the AlphaZero\nframework, enhanced with Vision Transformer (ViT): AlphaViT, AlphaViD, and\nAlphaVDA. These agents are designed to play multiple board games of various\nsizes using a single network with shared weights, thereby overcoming\nAlphaZero's limitation of fixed-board-size constraints. AlphaViT employs only a\ntransformer encoder, whereas AlphaViD and AlphaVDA incorporate both transformer\nencoders and decoders. In AlphaViD, the decoder processes outputs from the\nencoder, whereas AlphaVDA uses a learnable embeddings as the decoder input. The\nadditional decoder layers in AlphaViD and AlphaVDA provide flexibility to adapt\nto various action spaces and board sizes. Experimental results show that the\nproposed agents, trained on either individual games or multiple games\nsimultaneously, consistently outperform traditional algorithms such as Minimax\nand Monte Carlo Tree Search and approach the performance of AlphaZero, despite\nusing a single deep neural network (DNN) with shared weights. In particular,\nAlphaViT shows strong performance across all tested games. Furthermore,\nfine-tuning the DNN using pre-trained weights from small-board games\naccelerates convergence and improves performance, particularly in Gomoku.\nInterestingly, simultaneous training on multiple games yields performance\ncomparable to, or even surpassing, single-game training. These results indicate\nthe potential of transformer-based architectures to develop more flexible and\nrobust game-playing AI agents that excel in multiple games and dynamic\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13871v2",
    "published_date": "2024-08-25 15:40:21 UTC",
    "updated_date": "2024-11-29 07:00:39 UTC"
  },
  {
    "arxiv_id": "2408.13863v1",
    "title": "CodeGraph: Enhancing Graph Reasoning of LLMs with Code",
    "authors": [
      "Qiaolong Cai",
      "Zhaowei Wang",
      "Shizhe Diao",
      "James Kwok",
      "Yangqiu Song"
    ],
    "abstract": "With the increasing popularity of large language models (LLMs), reasoning on\nbasic graph algorithm problems is an essential intermediate step in assessing\ntheir abilities to process and infer complex graph reasoning tasks. Existing\nmethods usually convert graph-structured data to textual descriptions and then\nuse LLMs for reasoning and computation. However, LLMs often produce computation\nerrors on arithmetic parts in basic graph algorithm problems, such as counting\nnumber of edges. In addition, they struggle to control or understand the output\nof the reasoning process, raising concerns about whether LLMs are simply\nguessing. In this paper, we introduce CodeGraph, a method that encodes graph\nproblem solutions as code. The methods solve new graph problems by learning\nfrom exemplars, generating programs, and executing them via a program\ninterpreter. Using the few-shot setting, we evaluate CodeGraph with the base\nLLM being GPT-3.5 Turbo, Llama3-70B Instruct, Mixtral-8x22B Instruct, and\nMixtral-8x7B Instruct. Experimental results on six tasks with six graph\nencoding methods in the GraphQA dataset demonstrate that CodeGraph can boost\nperformance on graph reasoning tasks inside LLMs by 1.3% to 58.6%, depending on\nthe task. Compared to the existing methods, CodeGraph demonstrates strong\nperformance on arithmetic problems in graph tasks and offers a more\ncontrollable and interpretable approach to the reasoning process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "In Progress",
    "pdf_url": "http://arxiv.org/pdf/2408.13863v1",
    "published_date": "2024-08-25 15:27:21 UTC",
    "updated_date": "2024-08-25 15:27:21 UTC"
  },
  {
    "arxiv_id": "2409.00084v2",
    "title": "Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models",
    "authors": [
      "Seyed Amir Ahmad Safavi-Naini",
      "Shuhaib Ali",
      "Omer Shahab",
      "Zahra Shahhoseini",
      "Thomas Savage",
      "Sara Rafiee",
      "Jamil S Samaan",
      "Reem Al Shabeeb",
      "Farah Ladak",
      "Jamie O Yang",
      "Juan Echavarria",
      "Sumbal Babar",
      "Aasma Shaukat",
      "Samuel Margolis",
      "Nicholas P Tatonetti",
      "Girish Nadkarni",
      "Bara El Kurdi",
      "Ali Soroush"
    ],
    "abstract": "Background and Aims: This study evaluates the medical reasoning performance\nof large language models (LLMs) and vision language models (VLMs) in\ngastroenterology.\n  Methods: We used 300 gastroenterology board exam-style multiple-choice\nquestions, 138 of which contain images to systematically assess the impact of\nmodel configurations and parameters and prompt engineering strategies utilizing\nGPT-3.5. Next, we assessed the performance of proprietary and open-source LLMs\n(versions), including GPT (3.5, 4, 4o, 4omini), Claude (3, 3.5), Gemini (1.0),\nMistral, Llama (2, 3, 3.1), Mixtral, and Phi (3), across different interfaces\n(web and API), computing environments (cloud and local), and model precisions\n(with and without quantization). Finally, we assessed accuracy using a\nsemiautomated pipeline.\n  Results: Among the proprietary models, GPT-4o (73.7%) and Claude3.5-Sonnet\n(74.0%) achieved the highest accuracy, outperforming the top open-source\nmodels: Llama3.1-405b (64%), Llama3.1-70b (58.3%), and Mixtral-8x7b (54.3%).\nAmong the quantized open-source models, the 6-bit quantized Phi3-14b (48.7%)\nperformed best. The scores of the quantized models were comparable to those of\nthe full-precision models Llama2-7b, Llama2--13b, and Gemma2-9b. Notably, VLM\nperformance on image-containing questions did not improve when the images were\nprovided and worsened when LLM-generated captions were provided. In contrast, a\n10% increase in accuracy was observed when images were accompanied by\nhuman-crafted image descriptions.\n  Conclusion: In conclusion, while LLMs exhibit robust zero-shot performance in\nmedical reasoning, the integration of visual data remains a challenge for VLMs.\nEffective deployment involves carefully determining optimal model\nconfigurations, encouraging users to consider either the high performance of\nproprietary models or the flexible adaptability of open-source models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "92C50, 68T50",
      "J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript Pages: 34, Figures: 7, Tables: 2, Supplementary File\n  Pages: 35, Data Transparency Statement: Code is available at:\n  https://github.com/Sdamirsa/LLM-VLM-in-Gastroenterology . Study data from\n  American College of Gastroenterology (ACG) are restricted and available upon\n  request with ACG permission. Correction: updated abstract considering\n  Llama3.1 results",
    "pdf_url": "http://arxiv.org/pdf/2409.00084v2",
    "published_date": "2024-08-25 14:50:47 UTC",
    "updated_date": "2024-09-04 08:22:28 UTC"
  },
  {
    "arxiv_id": "2408.13854v2",
    "title": "Tangram: Benchmark for Evaluating Geometric Element Recognition in Large Multimodal Models",
    "authors": [
      "Chao Zhang",
      "Jiamin Tang",
      "Jing Xiao"
    ],
    "abstract": "Significant advancements in Large Multimodal Models (LMMs) have enabled them\nto tackle complex problems involving visual-mathematical reasoning. However,\ntheir ability to identify geometric elements remains underexplored. To address\nthis gap, we introduce Tangram, a novel benchmark designed to evaluate the\nperformance of LMMs on geometric element recognition. Tangram comprises 1,080\ndiverse geometric diagrams sourced from primary and secondary school exams,\ncompetitions, and textbooks, ranging from simple geometric shapes to complex\ncombinations. Each diagram is paired with four questions, resulting in 4,320\nvisual-question-answer pairs. Unlike existing benchmarks that emphasize\nhigher-level cognition and reasoning, Tangram focuses on understanding\ngeometric elements, requiring models to perform a ``simple yet challenging\"\ncounting task. Systematic evaluation of 13 prominent LMMs, such as GPT-4o and\nClaude 3.5 Sonnet, reveals that these models face significant challenges even\nin seemingly straightforward tasks. The top-performing model achieves an\naccuracy of only 53.0%, highlighting a substantial gap compared to human\nperformance. These findings underscore the limitations of current multimodal AI\nsystems in handling basic perception tasks and serve to inspire the development\nof the next generation of expert-level multimodal foundational models. The data\nand code will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13854v2",
    "published_date": "2024-08-25 14:47:25 UTC",
    "updated_date": "2024-12-17 08:12:25 UTC"
  },
  {
    "arxiv_id": "2408.13850v1",
    "title": "Condensed Sample-Guided Model Inversion for Knowledge Distillation",
    "authors": [
      "Kuluhan Binici",
      "Shivam Aggarwal",
      "Cihan Acar",
      "Nam Trung Pham",
      "Karianto Leman",
      "Gim Hee Lee",
      "Tulika Mitra"
    ],
    "abstract": "Knowledge distillation (KD) is a key element in neural network compression\nthat allows knowledge transfer from a pre-trained teacher model to a more\ncompact student model. KD relies on access to the training dataset, which may\nnot always be fully available due to privacy concerns or logistical issues\nrelated to the size of the data. To address this, \"data-free\" KD methods use\nsynthetic data, generated through model inversion, to mimic the target data\ndistribution. However, conventional model inversion methods are not designed to\nutilize supplementary information from the target dataset, and thus, cannot\nleverage it to improve performance, even when it is available. In this paper,\nwe consider condensed samples, as a form of supplementary information, and\nintroduce a method for using them to better approximate the target data\ndistribution, thereby enhancing the KD performance. Our approach is versatile,\nevidenced by improvements of up to 11.4% in KD accuracy across various datasets\nand model inversion-based methods. Importantly, it remains effective even when\nusing as few as one condensed sample per class, and can also enhance\nperformance in few-shot scenarios where only limited real data samples are\navailable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13850v1",
    "published_date": "2024-08-25 14:43:27 UTC",
    "updated_date": "2024-08-25 14:43:27 UTC"
  },
  {
    "arxiv_id": "2408.13836v2",
    "title": "PAM: A Propagation-Based Model for Segmenting Any 3D Objects across Multi-Modal Medical Images",
    "authors": [
      "Zifan Chen",
      "Xinyu Nan",
      "Jiazheng Li",
      "Jie Zhao",
      "Haifeng Li",
      "Ziling Lin",
      "Haoshen Li",
      "Heyun Chen",
      "Yiting Liu",
      "Lei Tang",
      "Li Zhang",
      "Bin Dong"
    ],
    "abstract": "Volumetric segmentation is important in medical imaging, but current methods\nface challenges like requiring lots of manual annotations and being tailored to\nspecific tasks, which limits their versatility. General segmentation models\nused for natural images don't perform well with the unique features of medical\nimages. There's a strong need for an adaptable approach that can effectively\nhandle different 3D medical structures and imaging modalities. In this study,\nwe present PAM (Propagating Anything Model), a segmentation approach that uses\na 2D prompt, like a bounding box or sketch, to create a complete 3D\nsegmentation of medical image volumes. PAM works by modeling relationships\nbetween slices, maintaining information flow across the 3D structure. It\ncombines a CNN-based UNet for processing within slices and a Transformer-based\nattention module for propagating information between slices, leading to better\ngeneralizability across various imaging modalities. PAM significantly\noutperformed existing models like MedSAM and SegVol, with an average\nimprovement of over 18.1% in dice similarity coefficient (DSC) across 44\nmedical datasets and various object types. It also showed stable performance\ndespite prompt deviations and different propagation setups, and faster\ninference speeds compared to other models. PAM's one-view prompt design made it\nmore efficient, reducing interaction time by about 63.6% compared to two-view\nprompts. Thanks to its focus on structural relationships, PAM handled unseen\nand complex objects well, showing a unique ability to generalize to new\nsituations. PAM represents an advancement in medical image segmentation,\neffectively reducing the need for extensive manual work and specialized\ntraining. Its adaptability makes it a promising tool for more automated and\nreliable analysis in clinical settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13836v2",
    "published_date": "2024-08-25 13:42:47 UTC",
    "updated_date": "2024-10-25 08:31:33 UTC"
  },
  {
    "arxiv_id": "2408.13831v1",
    "title": "Guardians of the Machine Translation Meta-Evaluation: Sentinel Metrics Fall In!",
    "authors": [
      "Stefano Perrella",
      "Lorenzo Proietti",
      "Alessandro Scirè",
      "Edoardo Barba",
      "Roberto Navigli"
    ],
    "abstract": "Annually, at the Conference of Machine Translation (WMT), the Metrics Shared\nTask organizers conduct the meta-evaluation of Machine Translation (MT)\nmetrics, ranking them according to their correlation with human judgments.\nTheir results guide researchers toward enhancing the next generation of metrics\nand MT systems. With the recent introduction of neural metrics, the field has\nwitnessed notable advancements. Nevertheless, the inherent opacity of these\nmetrics has posed substantial challenges to the meta-evaluation process. This\nwork highlights two issues with the meta-evaluation framework currently\nemployed in WMT, and assesses their impact on the metrics rankings. To do this,\nwe introduce the concept of sentinel metrics, which are designed explicitly to\nscrutinize the meta-evaluation process's accuracy, robustness, and fairness. By\nemploying sentinel metrics, we aim to validate our findings, and shed light on\nand monitor the potential biases or inconsistencies in the rankings. We\ndiscover that the present meta-evaluation framework favors two categories of\nmetrics: i) those explicitly trained to mimic human quality assessments, and\nii) continuous metrics. Finally, we raise concerns regarding the evaluation\ncapabilities of state-of-the-art metrics, emphasizing that they might be basing\ntheir assessments on spurious correlations found in their training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at ACL 2024 Main Conference. 29 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.13831v1",
    "published_date": "2024-08-25 13:29:34 UTC",
    "updated_date": "2024-08-25 13:29:34 UTC"
  },
  {
    "arxiv_id": "2408.13825v2",
    "title": "RoCP-GNN: Robust Conformal Prediction for Graph Neural Networks in Node-Classification",
    "authors": [
      "S. Akansha"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for predicting\noutcomes in graph-structured data. However, a notable limitation of GNNs is\ntheir inability to provide robust uncertainty estimates, which undermines their\nreliability in contexts where errors are costly. One way to address this issue\nis by providing prediction sets that contain the true label with a predefined\nprobability margin. Our approach builds upon conformal prediction (CP), a\nframework that promises to construct statistically robust prediction sets or\nintervals. There are two primary challenges: first, given dependent data like\ngraphs, it is unclear whether the critical assumption in CP - exchangeability -\nstill holds when applied to node classification. Second, even if the\nexchangeability assumption is valid for conformalized link prediction, we need\nto ensure high efficiency, i.e., the resulting prediction set or the interval\nlength is small enough to provide useful information. In this article, we\npropose a novel approach termed Robust Conformal Prediction for GNNs\n(RoCP-GNN), which integrates conformal prediction (CP) directly into the GNN\ntraining process. This method generates prediction sets, instead of just point\npredictions, that are valid at a user-defined confidence level, assuming only\nexchangeability. Our approach robustly predicts outcomes with any predictive\nGNN model while quantifying the uncertainty in predictions within the realm of\ngraph-based semi-supervised learning (SSL). Experimental results demonstrate\nthat GNN models with size loss provide a statistically significant increase in\nperformance. We validate our approach on standard graph benchmark datasets by\ncoupling it with various state-of-the-art GNNs in node classification. The code\nwill be made available after publication.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.13825v2",
    "published_date": "2024-08-25 12:51:19 UTC",
    "updated_date": "2024-10-09 06:54:58 UTC"
  },
  {
    "arxiv_id": "2408.14515v2",
    "title": "A Joint Learning Model with Variational Interaction for Multilingual Program Translation",
    "authors": [
      "Yali Du",
      "Hui Sun",
      "Ming Li"
    ],
    "abstract": "Programs implemented in various programming languages form the foundation of\nsoftware applications. To alleviate the burden of program migration and\nfacilitate the development of software systems, automated program translation\nacross languages has garnered significant attention. Previous approaches\nprimarily focus on pairwise translation paradigms, learning translation between\npairs of languages using bilingual parallel data. However, parallel data is\ndifficult to collect for some language pairs, and the distribution of program\nsemantics across languages can shift, posing challenges for pairwise program\ntranslation. In this paper, we argue that jointly learning a unified model to\ntranslate code across multiple programming languages is superior to separately\nlearning from bilingual parallel data. We propose Variational Interaction for\nMultilingual Program Translation~(VIM-PT), a disentanglement-based generative\napproach that jointly trains a unified model for multilingual program\ntranslation across multiple languages. VIM-PT disentangles code into\nlanguage-shared and language-specific features, using variational inference and\ninteraction information with a novel lower bound, then achieves program\ntranslation through conditional generation. VIM-PT demonstrates four\nadvantages: 1) captures language-shared information more accurately from\nvarious implementations and improves the quality of multilingual program\ntranslation, 2) mines and leverages the capability of non-parallel data, 3)\naddresses the distribution shift of program semantics across languages, 4) and\nserves as a unified model, reducing deployment complexity.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by the 39th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.14515v2",
    "published_date": "2024-08-25 11:33:52 UTC",
    "updated_date": "2024-09-13 04:25:37 UTC"
  },
  {
    "arxiv_id": "2408.13786v1",
    "title": "Localization of Synthetic Manipulations in Western Blot Images",
    "authors": [
      "Anmol Manjunath",
      "Viola Negroni",
      "Sara Mandelli",
      "Daniel Moreira",
      "Paolo Bestagini"
    ],
    "abstract": "Recent breakthroughs in deep learning and generative systems have\nsignificantly fostered the creation of synthetic media, as well as the local\nalteration of real content via the insertion of highly realistic synthetic\nmanipulations. Local image manipulation, in particular, poses serious\nchallenges to the integrity of digital content and societal trust. This problem\nis not only confined to multimedia data, but also extends to biological images\nincluded in scientific publications, like images depicting Western blots. In\nthis work, we address the task of localizing synthetic manipulations in Western\nblot images. To discriminate between pristine and synthetic pixels of an\nanalyzed image, we propose a synthetic detector that operates on small patches\nextracted from the image. We aggregate patch contributions to estimate a\ntampering heatmap, highlighting synthetic pixels out of pristine ones. Our\nmethodology proves effective when tested over two manipulated Western blot\nimage datasets, one altered automatically and the other manually by exploiting\nadvanced AI-based image manipulation tools that are unknown at our training\nstage. We also explore the robustness of our method over an external dataset of\nother scientific images depicting different semantics, manipulated through\nunseen generation techniques.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13786v1",
    "published_date": "2024-08-25 09:29:20 UTC",
    "updated_date": "2024-08-25 09:29:20 UTC"
  },
  {
    "arxiv_id": "2408.13784v1",
    "title": "Analyzing the Impact of Splicing Artifacts in Partially Fake Speech Signals",
    "authors": [
      "Viola Negroni",
      "Davide Salvi",
      "Paolo Bestagini",
      "Stefano Tubaro"
    ],
    "abstract": "Speech deepfake detection has recently gained significant attention within\nthe multimedia forensics community. Related issues have also been explored,\nsuch as the identification of partially fake signals, i.e., tracks that include\nboth real and fake speech segments. However, generating high-quality spliced\naudio is not as straightforward as it may appear. Spliced signals are typically\ncreated through basic signal concatenation. This process could introduce\nnoticeable artifacts that can make the generated data easier to detect. We\nanalyze spliced audio tracks resulting from signal concatenation, investigate\ntheir artifacts and assess whether such artifacts introduce any bias in\nexisting datasets. Our findings reveal that by analyzing splicing artifacts, we\ncan achieve a detection EER of 6.16% and 7.36% on PartialSpoof and HAD\ndatasets, respectively, without needing to train any detector. These results\nunderscore the complexities of generating reliable spliced audio data and lead\nto discussions that can help improve future research in this area.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ASVspoof 5 Workshop (Interspeech2024 Satellite)",
    "pdf_url": "http://arxiv.org/pdf/2408.13784v1",
    "published_date": "2024-08-25 09:28:04 UTC",
    "updated_date": "2024-08-25 09:28:04 UTC"
  },
  {
    "arxiv_id": "2408.14513v1",
    "title": "Variational autoencoder-based neural network model compression",
    "authors": [
      "Liang Cheng",
      "Peiyuan Guan",
      "Amir Taherkordi",
      "Lei Liu",
      "Dapeng Lan"
    ],
    "abstract": "Variational Autoencoders (VAEs), as a form of deep generative model, have\nbeen widely used in recent years, and shown great great peformance in a number\nof different domains, including image generation and anomaly detection, etc..\nThis paper aims to explore neural network model compression method based on\nVAE. The experiment uses different neural network models for MNIST recognition\nas compression targets, including Feedforward Neural Network (FNN),\nConvolutional Neural Network (CNN), Recurrent Neural Network (RNN) and Long\nShort-Term Memory (LSTM). These models are the most basic models in deep\nlearning, and other more complex and advanced models are based on them or\ninherit their features and evolve. In the experiment, the first step is to\ntrain the models mentioned above, each trained model will have different\naccuracy and number of total parameters. And then the variants of parameters\nfor each model are processed as training data in VAEs separately, and the\ntrained VAEs are tested by the true model parameters. The experimental results\nshow that using the latent space as a representation of the model compression\ncan improve the compression rate compared to some traditional methods such as\npruning and quantization, meanwhile the accuracy is not greatly affected using\nthe model parameters reconstructed based on the latent space. In the future, a\nvariety of different large-scale deep learning models will be used more widely,\nso exploring different ways to save time and space on saving or transferring\nmodels will become necessary, and the use of VAE in this paper can provide a\nbasis for these further explorations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.14513v1",
    "published_date": "2024-08-25 09:06:22 UTC",
    "updated_date": "2024-08-25 09:06:22 UTC"
  },
  {
    "arxiv_id": "2408.13773v1",
    "title": "SAB:A Stealing and Robust Backdoor Attack based on Steganographic Algorithm against Federated Learning",
    "authors": [
      "Weida Xu",
      "Yang Xu",
      "Sicong Zhang"
    ],
    "abstract": "Federated learning, an innovative network architecture designed to safeguard\nuser privacy, is gaining widespread adoption in the realm of technology.\nHowever, given the existence of backdoor attacks in federated learning,\nexploring the security of federated learning is significance. Nevertheless, the\nbackdoors investigated in current federated learning research can be readily\ndetected by human inspection or resisted by detection algorithms. Accordingly,\na new goal has been set to develop stealing and robust federated learning\nbackdoor attacks. In this paper, we introduce a novel approach, SAB, tailored\nspecifically for backdoor attacks in federated learning, presenting an\nalternative gradient updating mechanism. SAB attack based on steganographic\nalgorithm, using image steganographic algorithm to build a full-size trigger to\nimprove the accuracy of backdoors and use multiple loss joint computation to\nproduce triggers. SAB exhibits smaller distances to benign samples and greater\nimperceptibility to the human eye. As such, our triggers are capable of\nmitigating or evading specific backdoor defense methods. In SAB, the\nbottom-95\\% method is applied to extend the lifespan of backdoor attacks. It\nupdates the gradient on minor value points to reduce the probability of being\ncleaned. Finally, the generalization of backdoors is enhanced with\nSparse-update to improve the backdoor accuracy.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13773v1",
    "published_date": "2024-08-25 08:54:08 UTC",
    "updated_date": "2024-08-25 08:54:08 UTC"
  },
  {
    "arxiv_id": "2408.13767v2",
    "title": "Lecture Notes on Linear Neural Networks: A Tale of Optimization and Generalization in Deep Learning",
    "authors": [
      "Nadav Cohen",
      "Noam Razin"
    ],
    "abstract": "These notes are based on a lecture delivered by NC on March 2021, as part of\nan advanced course in Princeton University on the mathematical understanding of\ndeep learning. They present a theory (developed by NC, NR and collaborators) of\nlinear neural networks -- a fundamental model in the study of optimization and\ngeneralization in deep learning. Practical applications born from the presented\ntheory are also discussed. The theory is based on mathematical tools that are\ndynamical in nature. It showcases the potential of such tools to push the\nenvelope of our understanding of optimization and generalization in deep\nlearning. The text assumes familiarity with the basics of statistical learning\ntheory. Exercises (without solutions) are included.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Lecture notes",
    "pdf_url": "http://arxiv.org/pdf/2408.13767v2",
    "published_date": "2024-08-25 08:24:48 UTC",
    "updated_date": "2024-11-06 15:02:37 UTC"
  },
  {
    "arxiv_id": "2409.00083v1",
    "title": "On-device Learning of EEGNet-based Network For Wearable Motor Imagery Brain-Computer Interface",
    "authors": [
      "Sizhen Bian",
      "Pixi Kang",
      "Julian Moosmann",
      "Mengxi Liu",
      "Pietro Bonazzi",
      "Roman Rosipal",
      "Michele Magno"
    ],
    "abstract": "Electroencephalogram (EEG)-based Brain-Computer Interfaces (BCIs) have\ngarnered significant interest across various domains, including rehabilitation\nand robotics. Despite advancements in neural network-based EEG decoding,\nmaintaining performance across diverse user populations remains challenging due\nto feature distribution drift. This paper presents an effective approach to\naddress this challenge by implementing a lightweight and efficient on-device\nlearning engine for wearable motor imagery recognition. The proposed approach,\napplied to the well-established EEGNet architecture, enables real-time and\naccurate adaptation to EEG signals from unregistered users. Leveraging the\nnewly released low-power parallel RISC-V-based processor, GAP9 from\nGreeenwaves, and the Physionet EEG Motor Imagery dataset, we demonstrate a\nremarkable accuracy gain of up to 7.31\\% with respect to the baseline with a\nmemory footprint of 15.6 KByte. Furthermore, by optimizing the input stream, we\nachieve enhanced real-time performance without compromising inference accuracy.\nOur tailored approach exhibits inference time of 14.9 ms and 0.76 mJ per single\ninference and 20 us and 0.83 uJ per single update during online training. These\nfindings highlight the feasibility of our method for edge EEG devices as well\nas other battery-powered wearable AI systems suffering from subject-dependant\nfeature distribution drift.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00083v1",
    "published_date": "2024-08-25 08:23:51 UTC",
    "updated_date": "2024-08-25 08:23:51 UTC"
  },
  {
    "arxiv_id": "2408.13754v1",
    "title": "Multimodal Ensemble with Conditional Feature Fusion for Dysgraphia Diagnosis in Children from Handwriting Samples",
    "authors": [
      "Jayakanth Kunhoth",
      "Somaya Al-Maadeed",
      "Moutaz Saleh",
      "Younes Akbari"
    ],
    "abstract": "Developmental dysgraphia is a neurological disorder that hinders children's\nwriting skills. In recent years, researchers have increasingly explored machine\nlearning methods to support the diagnosis of dysgraphia based on offline and\nonline handwriting. In most previous studies, the two types of handwriting have\nbeen analysed separately, which does not necessarily lead to promising results.\nIn this way, the relationship between online and offline data cannot be\nexplored. To address this limitation, we propose a novel multimodal machine\nlearning approach utilizing both online and offline handwriting data. We\ncreated a new dataset by transforming an existing online handwritten dataset,\ngenerating corresponding offline handwriting images. We considered only\ndifferent types of word data (simple word, pseudoword & difficult word) in our\nmultimodal analysis. We trained SVM and XGBoost classifiers separately on\nonline and offline features as well as implemented multimodal feature fusion\nand soft-voted ensemble. Furthermore, we proposed a novel ensemble with\nconditional feature fusion method which intelligently combines predictions from\nonline and offline classifiers, selectively incorporating feature fusion when\nconfidence scores fall below a threshold. Our novel approach achieves an\naccuracy of 88.8%, outperforming SVMs for single modalities by 12-14%, existing\nmethods by 8-9%, and traditional multimodal approaches (soft-vote ensemble and\nfeature fusion) by 3% and 5%, respectively. Our methodology contributes to the\ndevelopment of accurate and efficient dysgraphia diagnosis tools, requiring\nonly a single instance of multimodal word/pseudoword data to determine the\nhandwriting impairment. This work highlights the potential of multimodal\nlearning in enhancing dysgraphia diagnosis, paving the way for accessible and\npractical diagnostic tools.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.6; I.2.10; I.4.9; I.5.1; I.5.4"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13754v1",
    "published_date": "2024-08-25 07:42:54 UTC",
    "updated_date": "2024-08-25 07:42:54 UTC"
  },
  {
    "arxiv_id": "2408.13750v3",
    "title": "Multi-Agent Target Assignment and Path Finding for Intelligent Warehouse: A Cooperative Multi-Agent Deep Reinforcement Learning Perspective",
    "authors": [
      "Qi Liu",
      "Jianqi Gao",
      "Dongjie Zhu",
      "Zhongjian Qiao",
      "Pengbin Chen",
      "Jingxiang Guo",
      "Yanjie Li"
    ],
    "abstract": "Multi-agent target assignment and path planning (TAPF) are two key problems\nin intelligent warehouse. However, most literature only addresses one of these\ntwo problems separately. In this study, we propose a method to simultaneously\nsolve target assignment and path planning from a perspective of cooperative\nmulti-agent deep reinforcement learning (RL). To the best of our knowledge,\nthis is the first work to model the TAPF problem for intelligent warehouse to\ncooperative multi-agent deep RL, and the first to simultaneously address TAPF\nbased on multi-agent deep RL. Furthermore, previous literature rarely considers\nthe physical dynamics of agents. In this study, the physical dynamics of the\nagents is considered. Experimental results show that our method performs well\nin various task settings, which means that the target assignment is solved\nreasonably well and the planned path is almost shortest. Moreover, our method\nis more time-efficient than baselines.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13750v3",
    "published_date": "2024-08-25 07:32:58 UTC",
    "updated_date": "2024-10-27 09:09:58 UTC"
  },
  {
    "arxiv_id": "2408.13745v4",
    "title": "DOCE: Finding the Sweet Spot for Execution-Based Code Generation",
    "authors": [
      "Haau-Sing Li",
      "Patrick Fernandes",
      "Iryna Gurevych",
      "André F. T. Martins"
    ],
    "abstract": "Recently, a diverse set of decoding and reranking procedures have been shown\neffective for LLM-based code generation. However, a comprehensive framework\nthat links and experimentally compares these methods is missing. We address\nthis by proposing Decoding Objectives for Code Execution, a comprehensive\nframework that includes candidate generation, $n$-best reranking, minimum Bayes\nrisk (MBR) decoding, and self-debugging as the core components. We then study\nthe contributions of these components through execution-based evaluation\nmetrics. Our findings highlight the importance of execution-based methods and\nthe difference gap between execution-based and execution-free methods.\nFurthermore, we assess the impact of filtering based on trial unit tests, a\nsimple and effective strategy that has been often overlooked in prior works. We\nalso propose self-debugging on multiple candidates, obtaining state-of-the-art\nperformance on reranking for code generation. We expect our framework to\nprovide a solid guideline for future research on code generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages (32 including appendix), 5 figures, 25 tables. Prompts are\n  provided in the GitHub repository to avoid potential text overlap with other\n  papers",
    "pdf_url": "http://arxiv.org/pdf/2408.13745v4",
    "published_date": "2024-08-25 07:10:36 UTC",
    "updated_date": "2024-10-16 15:07:41 UTC"
  },
  {
    "arxiv_id": "2408.13727v1",
    "title": "LogParser-LLM: Advancing Efficient Log Parsing with Large Language Models",
    "authors": [
      "Aoxiao Zhong",
      "Dengyao Mo",
      "Guiyang Liu",
      "Jinbu Liu",
      "Qingda Lu",
      "Qi Zhou",
      "Jiesheng Wu",
      "Quanzheng Li",
      "Qingsong Wen"
    ],
    "abstract": "Logs are ubiquitous digital footprints, playing an indispensable role in\nsystem diagnostics, security analysis, and performance optimization. The\nextraction of actionable insights from logs is critically dependent on the log\nparsing process, which converts raw logs into structured formats for downstream\nanalysis. Yet, the complexities of contemporary systems and the dynamic nature\nof logs pose significant challenges to existing automatic parsing techniques.\nThe emergence of Large Language Models (LLM) offers new horizons. With their\nexpansive knowledge and contextual prowess, LLMs have been transformative\nacross diverse applications. Building on this, we introduce LogParser-LLM, a\nnovel log parser integrated with LLM capabilities. This union seamlessly blends\nsemantic insights with statistical nuances, obviating the need for\nhyper-parameter tuning and labeled training data, while ensuring rapid\nadaptability through online parsing. Further deepening our exploration, we\naddress the intricate challenge of parsing granularity, proposing a new metric\nand integrating human interactions to allow users to calibrate granularity to\ntheir specific needs. Our method's efficacy is empirically demonstrated through\nevaluations on the Loghub-2k and the large-scale LogPub benchmark. In\nevaluations on the LogPub benchmark, involving an average of 3.6 million logs\nper dataset across 14 datasets, our LogParser-LLM requires only 272.5 LLM\ninvocations on average, achieving a 90.6% F1 score for grouping accuracy and an\n81.1% for parsing accuracy. These results demonstrate the method's high\nefficiency and accuracy, outperforming current state-of-the-art log parsers,\nincluding pattern-based, neural network-based, and existing LLM-enhanced\napproaches.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by ACM KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.13727v1",
    "published_date": "2024-08-25 05:34:24 UTC",
    "updated_date": "2024-08-25 05:34:24 UTC"
  },
  {
    "arxiv_id": "2409.06709v1",
    "title": "Unveiling Visual Biases in Audio-Visual Localization Benchmarks",
    "authors": [
      "Liangyu Chen",
      "Zihao Yue",
      "Boshen Xu",
      "Qin Jin"
    ],
    "abstract": "Audio-Visual Source Localization (AVSL) aims to localize the source of sound\nwithin a video. In this paper, we identify a significant issue in existing\nbenchmarks: the sounding objects are often easily recognized based solely on\nvisual cues, which we refer to as visual bias. Such biases hinder these\nbenchmarks from effectively evaluating AVSL models. To further validate our\nhypothesis regarding visual biases, we examine two representative AVSL\nbenchmarks, VGG-SS and EpicSounding-Object, where the vision-only models\noutperform all audiovisual baselines. Our findings suggest that existing AVSL\nbenchmarks need further refinement to facilitate audio-visual learning.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by ECCV24 AVGenL Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.06709v1",
    "published_date": "2024-08-25 04:56:08 UTC",
    "updated_date": "2024-08-25 04:56:08 UTC"
  },
  {
    "arxiv_id": "2408.14512v3",
    "title": "LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings",
    "authors": [
      "Duo Wang",
      "Yuan Zuo",
      "Fengzhi Li",
      "Junjie Wu"
    ],
    "abstract": "Zero-shot graph machine learning, especially with graph neural networks\n(GNNs), has garnered significant interest due to the challenge of scarce\nlabeled data. While methods like self-supervised learning and graph prompt\nlearning have been extensively explored, they often rely on fine-tuning with\ntask-specific labels, limiting their effectiveness in zero-shot scenarios.\nInspired by the zero-shot capabilities of instruction-fine-tuned large language\nmodels (LLMs), we introduce a novel framework named Token Embedding-Aligned\nGraph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and\ncross-task zero-shot learners for graph machine learning. Concretely, we\npretrain a GNN, aligning its representations with token embeddings of an LLM.\nWe then train a linear projector that transforms the GNN's representations into\na fixed number of graph token embeddings without tuning the LLM. A unified\ninstruction is designed for various graph tasks at different levels, such as\nnode classification (node-level) and link prediction (edge-level). These design\nchoices collectively enhance our method's effectiveness in zero-shot learning,\nsetting it apart from existing methods. Experiments show that our graph token\nembeddings help the LLM predictor achieve state-of-the-art performance on\nunseen datasets and tasks compared to other methods using LLMs as predictors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.14512v3",
    "published_date": "2024-08-25 04:32:45 UTC",
    "updated_date": "2024-12-19 16:37:00 UTC"
  },
  {
    "arxiv_id": "2408.13719v1",
    "title": "Count-based Novelty Exploration in Classical Planning",
    "authors": [
      "Giacomo Rosa",
      "Nir Lipovetzky"
    ],
    "abstract": "Count-based exploration methods are widely employed to improve the\nexploratory behavior of learning agents over sequential decision problems.\nMeanwhile, Novelty search has achieved success in Classical Planning through\nrecording of the first, but not successive, occurrences of tuples. In order to\nstructure the exploration, however, the number of tuples considered needs to\ngrow exponentially as the search progresses. We propose a new novelty\ntechnique, classical count-based novelty, which aims to explore the state space\nwith a constant number of tuples, by leveraging the frequency of each tuple's\nappearance in a search tree. We then justify the mechanisms through which lower\ntuple counts lead the search towards novel tuples. We also introduce\nalgorithmic contributions in the form of a trimmed open list that maintains a\nconstant size by pruning nodes with bad novelty values. These techniques are\nshown to complement existing novelty heuristics when integrated in a classical\nsolver, achieving competitive results in challenging benchmarks from recent\nInternational Planning Competitions. Moreover, adapting our solver as the\nfrontend planner in dual configurations that utilize both memory and time\nthresholds demonstrates a significant increase in instance coverage, surpassing\ncurrent state-of-the-art solvers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of paper accepted for publication at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.13719v1",
    "published_date": "2024-08-25 04:25:10 UTC",
    "updated_date": "2024-08-25 04:25:10 UTC"
  },
  {
    "arxiv_id": "2408.14511v2",
    "title": "Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods",
    "authors": [
      "Xinyang Hu",
      "Fengzhuo Zhang",
      "Siyu Chen",
      "Zhuoran Yang"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting and its variants have gained popularity as\neffective methods for solving multi-step reasoning problems using pretrained\nlarge language models (LLMs). In this work, we analyze CoT prompting from a\nstatistical estimation perspective, providing a comprehensive characterization\nof its sample complexity. To this end, we introduce a multi-step latent\nvariable model that encapsulates the reasoning process, where the latent\nvariable encodes the task information. Under this framework, we demonstrate\nthat when the pretraining dataset is sufficiently large, the estimator formed\nby CoT prompting is equivalent to a Bayesian estimator. This estimator\neffectively solves the multi-step reasoning problem by aggregating a posterior\ndistribution inferred from the demonstration examples in the prompt. Moreover,\nwe prove that the statistical error of the CoT estimator can be decomposed into\ntwo main components: (i) a prompting error, which arises from inferring the\ntrue task using CoT prompts, and (ii) the statistical error of the pretrained\nLLM. We establish that, under appropriate assumptions, the prompting error\ndecays exponentially to zero as the number of demonstrations increases.\nAdditionally, we explicitly characterize the approximation and generalization\nerrors of the pretrained LLM. Notably, we construct a transformer model that\napproximates the target distribution of the multi-step reasoning problem with\nan error that decreases exponentially in the number of transformer blocks. Our\nanalysis extends to other variants of CoT, including Self-Consistent CoT,\nTree-of-Thought, and Selection-Inference, offering a broad perspective on the\nefficacy of these methods. We also provide numerical experiments to validate\nthe theoretical findings.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "150 pages, 18 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.14511v2",
    "published_date": "2024-08-25 04:07:18 UTC",
    "updated_date": "2024-08-28 14:13:41 UTC"
  },
  {
    "arxiv_id": "2408.13704v2",
    "title": "DHP Benchmark: Are LLMs Good NLG Evaluators?",
    "authors": [
      "Yicheng Wang",
      "Jiayi Yuan",
      "Yu-Neng Chuang",
      "Zhuoer Wang",
      "Yingchi Liu",
      "Mark Cusick",
      "Param Kulkarni",
      "Zhengping Ji",
      "Yasser Ibrahim",
      "Xia Hu"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly serving as evaluators in\nNatural Language Generation (NLG) tasks; this is often referred to as\n``LLM-as-a-judge'' paradigm. However, the capabilities of LLMs in evaluating\nNLG quality remain underexplored. Current studies depend on human assessments\nand simple metrics that fail to capture the discernment of LLMs across diverse\nNLG tasks. To address this gap, we propose the Discernment of Hierarchical\nPerturbation (DHP) benchmarking framework, which provides quantitative\ndiscernment scores for LLMs. This framework leverages hierarchically perturbed\ntext data and statistical tests to systematically measure the NLG evaluation\ncapabilities of LLMs. We re-established six evaluation datasets for this\nbenchmark, covering four NLG tasks: Summarization, Story Completion, Question\nAnswering, and Translation. Our comprehensive benchmarking of five major LLM\nfamilies provides critical insight into their strengths and limitations as NLG\nevaluators. Our dataset is available at\nhttps://huggingface.co/datasets/YCWANGVINCE/DHP_Benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.13704v2",
    "published_date": "2024-08-25 02:01:38 UTC",
    "updated_date": "2025-02-25 01:51:06 UTC"
  },
  {
    "arxiv_id": "2409.01281v2",
    "title": "Path-Consistency: Prefix Enhancement for Efficient Inference in LLM",
    "authors": [
      "Jiace Zhu",
      "Yingtao Shen",
      "Jie Zhao",
      "An Zou"
    ],
    "abstract": "To enhance the reasoning capabilities of large language models (LLMs),\nself-consistency has gained significant popularity by combining multiple\nsampling with majority voting. However, the state-of-the-art self-consistency\napproaches consume substantial computational resources and lead to significant\nadditional time costs due to the multiple sampling. This prevents its full\npotential from being realized in scenarios where computational resources are\ncritical. To improve the inference efficiency, this paper introduces\n\\textit{path-consistency}, a method that leverages the confidence of answers\ngenerated in earlier branches to identify the prefix of the most promising\npath. By dynamically guiding the generation of subsequent branches based on\nthis prefix, the \\textit{path-consistency} mitigates both the errors and\nredundancies from random or less useful sampling in self-consistency. As a\nresult, it can significantly accelerate the inference process by reducing the\nnumber of tokens generated. Our extensive empirical evaluation shows that the\n\\textit{path-consistency} achieves significant acceleration in inference\nlatency ranging from $7.8\\%$ to $40.5\\%$, while maintaining or even improving\ntask accuracy across different datasets, including mathematical reasoning,\ncommon sense reasoning, symbolic reasoning, and code generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.01281v2",
    "published_date": "2024-08-25 01:45:53 UTC",
    "updated_date": "2025-03-02 09:13:56 UTC"
  },
  {
    "arxiv_id": "2409.08281v1",
    "title": "StockTime: A Time Series Specialized Large Language Model Architecture for Stock Price Prediction",
    "authors": [
      "Shengkun Wang",
      "Taoran Ji",
      "Linhan Wang",
      "Yanshen Sun",
      "Shang-Ching Liu",
      "Amit Kumar",
      "Chang-Tien Lu"
    ],
    "abstract": "The stock price prediction task holds a significant role in the financial\ndomain and has been studied for a long time. Recently, large language models\n(LLMs) have brought new ways to improve these predictions. While recent\nfinancial large language models (FinLLMs) have shown considerable progress in\nfinancial NLP tasks compared to smaller pre-trained language models (PLMs),\nchallenges persist in stock price forecasting. Firstly, effectively integrating\nthe modalities of time series data and natural language to fully leverage these\ncapabilities remains complex. Secondly, FinLLMs focus more on analysis and\ninterpretability, which can overlook the essential features of time series\ndata. Moreover, due to the abundance of false and redundant information in\nfinancial markets, models often produce less accurate predictions when faced\nwith such input data. In this paper, we introduce StockTime, a novel LLM-based\narchitecture designed specifically for stock price data. Unlike recent FinLLMs,\nStockTime is specifically designed for stock price time series data. It\nleverages the natural ability of LLMs to predict the next token by treating\nstock prices as consecutive tokens, extracting textual information such as\nstock correlations, statistical trends and timestamps directly from these stock\nprices. StockTime then integrates both textual and time series data into the\nembedding space. By fusing this multimodal data, StockTime effectively predicts\nstock prices across arbitrary look-back periods. Our experiments demonstrate\nthat StockTime outperforms recent LLMs, as it gives more accurate predictions\nwhile reducing memory usage and runtime costs.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08281v1",
    "published_date": "2024-08-25 00:50:33 UTC",
    "updated_date": "2024-08-25 00:50:33 UTC"
  }
]