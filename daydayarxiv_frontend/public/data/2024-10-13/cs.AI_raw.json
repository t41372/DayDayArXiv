[
  {
    "arxiv_id": "2410.10045v1",
    "title": "VQ-CNMP: Neuro-Symbolic Skill Learning for Bi-Level Planning",
    "authors": [
      "Hakan Aktas",
      "Emre Ugur"
    ],
    "abstract": "This paper proposes a novel neural network model capable of discovering\nhigh-level skill representations from unlabeled demonstration data. We also\npropose a bi-level planning pipeline that utilizes our model using a\ngradient-based planning approach. While extracting high-level representations,\nour model also preserves the low-level information, which can be used for\nlow-level action planning. In the experiments, we tested the skill discovery\nperformance of our model under different conditions, tested whether Multi-Modal\nLLMs can be utilized to label the learned high-level skill representations, and\nfinally tested the high-level and low-level planning performance of our\npipeline.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 6 figures, Submitted to Conference on Robot Learning LEAP\n  Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10045v1",
    "published_date": "2024-10-13 23:29:46 UTC",
    "updated_date": "2024-10-13 23:29:46 UTC"
  },
  {
    "arxiv_id": "2410.12868v1",
    "title": "IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery",
    "authors": [
      "Agasthya Gangavarapu",
      "Ananya Gangavarapu"
    ],
    "abstract": "Since the onset of COVID-19, rural communities worldwide have faced\nsignificant challenges in accessing healthcare due to the migration of\nexperienced medical professionals to urban centers. Semi-trained caregivers,\nsuch as Community Health Workers (CHWs) and Registered Medical Practitioners\n(RMPs), have stepped in to fill this gap, but often lack formal training. This\npaper proposes an advanced agentic medical assistant system designed to improve\nhealthcare delivery in rural areas by utilizing Large Language Models (LLMs)\nand agentic approaches. The system is composed of five crucial components:\ntranslation, medical complexity assessment, expert network integration, final\nmedical advice generation, and response simplification. Our innovative\nframework ensures context-sensitive, adaptive, and reliable medical assistance,\ncapable of clinical triaging, diagnostics, and identifying cases requiring\nspecialist intervention. The system is designed to handle cultural nuances and\nvarying literacy levels, providing clear and actionable medical advice in local\nlanguages. Evaluation results using the MedQA, PubMedQA, and JAMA datasets\ndemonstrate that this integrated approach significantly enhances the\neffectiveness of rural healthcare workers, making healthcare more accessible\nand understandable for underserved populations. All code and supplemental\nmaterials associated with the paper and IMAS are available at\nhttps://github.com/uheal/imas.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12868v1",
    "published_date": "2024-10-13 23:07:11 UTC",
    "updated_date": "2024-10-13 23:07:11 UTC"
  },
  {
    "arxiv_id": "2410.21293v1",
    "title": "Large-scale Multi-objective Feature Selection: A Multi-phase Search Space Shrinking Approach",
    "authors": [
      "Azam Asilian Bidgoli",
      "Shahryar Rahnamayan"
    ],
    "abstract": "Feature selection is a crucial step in machine learning, especially for\nhigh-dimensional datasets, where irrelevant and redundant features can degrade\nmodel performance and increase computational costs. This paper proposes a novel\nlarge-scale multi-objective evolutionary algorithm based on the search space\nshrinking, termed LMSSS, to tackle the challenges of feature selection\nparticularly as a sparse optimization problem. The method includes a shrinking\nscheme to reduce dimensionality of the search space by eliminating irrelevant\nfeatures before the main evolutionary process. This is achieved through a\nranking-based filtering method that evaluates features based on their\ncorrelation with class labels and frequency in an initial, cost-effective\nevolutionary process. Additionally, a smart crossover scheme based on voting\nbetween parent solutions is introduced, giving higher weight to the parent with\nbetter classification accuracy. An intelligent mutation process is also\ndesigned to target features prematurely excluded from the population, ensuring\nthey are evaluated in combination with other features. These integrated\ntechniques allow the evolutionary process to explore the search space more\nefficiently and effectively, addressing the sparse and high-dimensional nature\nof large-scale feature selection problems. The effectiveness of the proposed\nalgorithm is demonstrated through comprehensive experiments on 15 large-scale\ndatasets, showcasing its potential to identify more accurate feature subsets\ncompared to state-of-the-art large-scale feature selection algorithms. These\nresults highlight LMSSS's capability to improve model performance and\ncomputational efficiency, setting a new benchmark in the field.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21293v1",
    "published_date": "2024-10-13 23:06:10 UTC",
    "updated_date": "2024-10-13 23:06:10 UTC"
  },
  {
    "arxiv_id": "2410.10041v2",
    "title": "WormKAN: Are KAN Effective for Identifying and Tracking Concept Drift in Time Series?",
    "authors": [
      "Kunpeng Xu",
      "Lifei Chen",
      "Shengrui Wang"
    ],
    "abstract": "Dynamic concepts in time series are crucial for understanding complex systems\nsuch as financial markets, healthcare, and online activity logs. These concepts\nhelp reveal structures and behaviors in sequential data for better\ndecision-making and forecasting. However, existing models often struggle to\ndetect and track concept drift due to limitations in interpretability and\nadaptability. To address this challenge, inspired by the flexibility of the\nrecent Kolmogorov-Arnold Network (KAN), we propose WormKAN, a concept-aware\nKAN-based model to address concept drift in co-evolving time series. WormKAN\nconsists of three key components: Patch Normalization, Temporal Representation\nModule, and Concept Dynamics. Patch normalization processes co-evolving time\nseries into patches, treating them as fundamental modeling units to capture\nlocal dependencies while ensuring consistent scaling. The temporal\nrepresentation module learns robust latent representations by leveraging a\nKAN-based autoencoder, complemented by a smoothness constraint, to uncover\ninter-patch correlations. Concept dynamics identifies and tracks dynamic\ntransitions, revealing structural shifts in the time series through concept\nidentification and drift detection. These transitions, akin to passing through\na \\textit{wormhole}, are identified by abrupt changes in the latent space.\nExperiments show that KAN and KAN-based models (WormKAN) effectively segment\ntime series into meaningful concepts, enhancing the identification and tracking\nof concept drift.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10041v2",
    "published_date": "2024-10-13 23:05:37 UTC",
    "updated_date": "2024-12-13 00:23:09 UTC"
  },
  {
    "arxiv_id": "2410.10030v1",
    "title": "A Step Towards Mixture of Grader: Statistical Analysis of Existing Automatic Evaluation Metrics",
    "authors": [
      "Yun Joon Soh",
      "Jishen Zhao"
    ],
    "abstract": "The explosion of open-sourced models and Question-Answering (QA) datasets\nemphasizes the importance of automated QA evaluation. We studied the statistics\nof the existing evaluation metrics for a better understanding of their\nlimitations. By measuring the correlation coefficients of each evaluation\nmetric concerning human-like evaluation score, we observed the following: (1)\nexisting metrics have a high correlation among them concerning the question\ntype (e.g., single word, single phrase, etc.), (2) no single metric can\nadequately estimate the human-like evaluation. As a potential solution, we\ndiscuss how a Mixture Of Grader could potentially improve the auto QA evaluator\nquality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10030v1",
    "published_date": "2024-10-13 22:10:42 UTC",
    "updated_date": "2024-10-13 22:10:42 UTC"
  },
  {
    "arxiv_id": "2410.10021v1",
    "title": "Online Multi-modal Root Cause Analysis",
    "authors": [
      "Lecheng Zheng",
      "Zhengzhang Chen",
      "Haifeng Chen",
      "Jingrui He"
    ],
    "abstract": "Root Cause Analysis (RCA) is essential for pinpointing the root causes of\nfailures in microservice systems. Traditional data-driven RCA methods are\ntypically limited to offline applications due to high computational demands,\nand existing online RCA methods handle only single-modal data, overlooking\ncomplex interactions in multi-modal systems. In this paper, we introduce OCEAN,\na novel online multi-modal causal structure learning method for root cause\nlocalization. OCEAN employs a dilated convolutional neural network to capture\nlong-term temporal dependencies and graph neural networks to learn causal\nrelationships among system entities and key performance indicators. We further\ndesign a multi-factor attention mechanism to analyze and reassess the\nrelationships among different metrics and log indicators/attributes for\nenhanced online causal graph learning. Additionally, a contrastive mutual\ninformation maximization-based graph fusion module is developed to effectively\nmodel the relationships across various modalities. Extensive experiments on\nthree real-world datasets demonstrate the effectiveness and efficiency of our\nproposed method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10021v1",
    "published_date": "2024-10-13 21:47:36 UTC",
    "updated_date": "2024-10-13 21:47:36 UTC"
  },
  {
    "arxiv_id": "2410.10020v1",
    "title": "Adaptive Reasoning and Acting in Medical Language Agents",
    "authors": [
      "Abhishek Dutta",
      "Yen-Che Hsiao"
    ],
    "abstract": "This paper presents an innovative large language model (LLM) agent framework\nfor enhancing diagnostic accuracy in simulated clinical environments using the\nAgentClinic benchmark. The proposed automatic correction enables doctor agents\nto iteratively refine their reasoning and actions following incorrect\ndiagnoses, fostering improved decision-making over time. Experiments show that\nthe implementation of the adaptive LLM-based doctor agents achieve correct\ndiagnoses through dynamic interactions with simulated patients. The evaluations\nhighlight the capacity of autonomous agents to adapt and improve in complex\nmedical scenarios. Future enhancements will focus on refining the algorithm and\nexpanding its applicability across a wider range of tasks and different large\nlanguage models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10020v1",
    "published_date": "2024-10-13 21:45:16 UTC",
    "updated_date": "2024-10-13 21:45:16 UTC"
  },
  {
    "arxiv_id": "2410.10018v1",
    "title": "Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid",
    "authors": [
      "Vineet Jagadeesan Nair",
      "Lucas Pereira"
    ],
    "abstract": "This proposal aims to develop more accurate federated learning (FL) methods\nwith faster convergence properties and lower communication requirements,\nspecifically for forecasting distributed energy resources (DER) such as\nrenewables, energy storage, and loads in modern, low-carbon power grids. This\nwill be achieved by (i) leveraging recently developed extensions of FL such as\nhierarchical and iterative clustering to improve performance with non-IID data,\n(ii) experimenting with different types of FL global models well-suited to\ntime-series data, and (iii) incorporating domain-specific knowledge from power\nsystems to build more general FL frameworks and architectures that can be\napplied to diverse types of DERs beyond just load forecasting, and with\nheterogeneous clients.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the NeurIPS 2022 Tackling Climate Change with Machine\n  Learning workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.10018v1",
    "published_date": "2024-10-13 21:34:00 UTC",
    "updated_date": "2024-10-13 21:34:00 UTC"
  },
  {
    "arxiv_id": "2410.10014v1",
    "title": "Safety-Aware Fine-Tuning of Large Language Models",
    "authors": [
      "Hyeong Kyu Choi",
      "Xuefeng Du",
      "Yixuan Li"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) has emerged as a common practice for\ntailoring models to individual needs and preferences. The choice of datasets\nfor fine-tuning can be diverse, introducing safety concerns regarding the\npotential inclusion of harmful data samples. Manually filtering or avoiding\nsuch samples, however, can be labor-intensive and subjective. To address these\ndifficulties, we propose a novel Safety-Aware Fine-Tuning (SAFT) framework\ndesigned to automatically detect and remove potentially harmful data, by\nleveraging a scoring function that exploits the subspace information of harmful\nand benign samples. Experimental results demonstrate the efficacy of SAFT\nacross different LLMs and varying contamination rates, achieving reductions in\nharmfulness of up to 27.8%. Going beyond, we delve into the mechanism of our\napproach and validate its versatility in addressing practical challenges in\nreal-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Workshop on Safe Generative AI",
    "pdf_url": "http://arxiv.org/pdf/2410.10014v1",
    "published_date": "2024-10-13 21:24:25 UTC",
    "updated_date": "2024-10-13 21:24:25 UTC"
  },
  {
    "arxiv_id": "2410.10011v1",
    "title": "Learning Interpretable Classifiers for PDDL Planning",
    "authors": [
      "Arnaud Lequen"
    ],
    "abstract": "We consider the problem of synthesizing interpretable models that recognize\nthe behaviour of an agent compared to other agents, on a whole set of similar\nplanning tasks expressed in PDDL. Our approach consists in learning logical\nformulas, from a small set of examples that show how an agent solved small\nplanning instances. These formulas are expressed in a version of First-Order\nTemporal Logic (FTL) tailored to our planning formalism. Such formulas are\nhuman-readable, serve as (partial) descriptions of an agent's policy, and\ngeneralize to unseen instances. We show that learning such formulas is\ncomputationally intractable, as it is an NP-hard problem. As such, we propose\nto learn these behaviour classifiers through a topology-guided compilation to\nMaxSAT, which allows us to generate a wide range of different formulas.\nExperiments show that interesting and accurate formulas can be learned in\nreasonable time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10011v1",
    "published_date": "2024-10-13 21:12:45 UTC",
    "updated_date": "2024-10-13 21:12:45 UTC"
  },
  {
    "arxiv_id": "2410.10009v2",
    "title": "Enhancing Peer Review in Astronomy: A Machine Learning and Optimization Approach to Reviewer Assignments for ALMA",
    "authors": [
      "John M. Carpenter",
      "Andrea Corvillón",
      "Nihar B. Shah"
    ],
    "abstract": "The increasing volume of papers and proposals that undergo peer review\nemphasizes the pressing need for greater automation to effectively manage the\ngrowing scale. In this study, we present the deployment and evaluation of\nmachine learning and optimization techniques to assign proposals to reviewers\nthat were developed for the Atacama Large Millimeter/submillimeter Array (ALMA)\nduring the Cycle 10 Call for Proposals issued in 2023. Using topic modeling\nalgorithms, we identify the proposal topics and assess reviewers' expertise\nbased on their previous ALMA proposal submissions. We then apply an adapted\nversion of the assignment optimization algorithm from PeerReview4All (Stelmakh\net al. 2021) to maximize the alignment between proposal topics and reviewer\nexpertise. Our evaluation shows a significant improvement in matching reviewer\nexpertise: the median similarity score between the proposal topic and reviewer\nexpertise increased by 51 percentage points compared to the previous cycle, and\nthe percentage of reviewers reporting expertise in their assigned proposals\nrose by 20 percentage points. Furthermore, the assignment process proved highly\neffective in that no proposals required reassignment due to significant\nmismatches, resulting in a savings of 3 to 5 days of manual effort.",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "16 pages, 5 figures, revised version accepted by PASP",
    "pdf_url": "http://arxiv.org/pdf/2410.10009v2",
    "published_date": "2024-10-13 21:06:00 UTC",
    "updated_date": "2025-02-18 23:11:05 UTC"
  },
  {
    "arxiv_id": "2410.12867v1",
    "title": "Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis",
    "authors": [
      "Kaushal Attaluri",
      "Anirudh CHVS",
      "Sireesha Chittepu"
    ],
    "abstract": "Dysarthria is a motor speech disorder caused by neurological damage that\naffects the muscles used for speech production, leading to slurred, slow, or\ndifficult-to-understand speech. It affects millions of individuals worldwide,\nincluding those with conditions such as stroke, traumatic brain injury,\ncerebral palsy, Parkinsons disease, and multiple sclerosis. Dysarthria presents\na major communication barrier, impacting quality of life and social\ninteraction. This paper introduces a novel approach to recognizing and\ntranslating dysarthric speech, empowering individuals with this condition to\ncommunicate more effectively. We leverage advanced large language models for\naccurate speech correction and multimodal emotion analysis. Dysarthric speech\nis first converted to text using OpenAI Whisper model, followed by sentence\nprediction using fine-tuned open-source models and benchmark models like\nGPT-4.o, LLaMA 3.1 70B and Mistral 8x7B on Groq AI accelerators. The dataset\nused combines the TORGO dataset with Google speech data, manually labeled for\nemotional context. Our framework identifies emotions such as happiness,\nsadness, neutrality, surprise, anger, and fear, while reconstructing intended\nsentences from distorted speech with high accuracy. This approach demonstrates\nsignificant advancements in the recognition and interpretation of dysarthric\nspeech.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12867v1",
    "published_date": "2024-10-13 20:54:44 UTC",
    "updated_date": "2024-10-13 20:54:44 UTC"
  },
  {
    "arxiv_id": "2410.09999v1",
    "title": "Leveraging Customer Feedback for Multi-modal Insight Extraction",
    "authors": [
      "Sandeep Sricharan Mukku",
      "Abinesh Kanagarajan",
      "Pushpendu Ghosh",
      "Chetan Aggarwal"
    ],
    "abstract": "Businesses can benefit from customer feedback in different modalities, such\nas text and images, to enhance their products and services. However, it is\ndifficult to extract actionable and relevant pairs of text segments and images\nfrom customer feedback in a single pass. In this paper, we propose a novel\nmulti-modal method that fuses image and text information in a latent space and\ndecodes it to extract the relevant feedback segments using an image-text\ngrounded text decoder. We also introduce a weakly-supervised data generation\ntechnique that produces training data for this task. We evaluate our model on\nunseen data and demonstrate that it can effectively mine actionable insights\nfrom multi-modal customer feedback, outperforming the existing baselines by\n$14$ points in F1 score.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09999v1",
    "published_date": "2024-10-13 20:45:00 UTC",
    "updated_date": "2024-10-13 20:45:00 UTC"
  },
  {
    "arxiv_id": "2410.09998v1",
    "title": "SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network",
    "authors": [
      "Guorui Lu",
      "Jing Peng",
      "Bingyuan Huang",
      "Chang Gao",
      "Todor Stefanov",
      "Yong Hao",
      "Qinyu Chen"
    ],
    "abstract": "Epileptic seizures cause abnormal brain activity, and their unpredictability\ncan lead to accidents, underscoring the need for long-term seizure prediction.\nAlthough seizures can be predicted by analyzing electroencephalogram (EEG)\nsignals, existing methods often require too many electrode channels or larger\nmodels, limiting mobile usability. This paper introduces a SlimSeiz framework\nthat utilizes adaptive channel selection with a lightweight neural network\nmodel. SlimSeiz operates in two states: the first stage selects the optimal\nchannel set for seizure prediction using machine learning algorithms, and the\nsecond stage employs a lightweight neural network based on convolution and\nMamba for prediction. On the Children's Hospital Boston-MIT (CHB-MIT) EEG\ndataset, SlimSeiz can reduce channels from 22 to 8 while achieving a\nsatisfactory result of 94.8% accuracy, 95.5% sensitivity, and 94.0% specificity\nwith only 21.2K model parameters, matching or outperforming larger models'\nperformance. We also validate SlimSeiz on a new EEG dataset, SRH-LEI, collected\nfrom Shanghai Renji Hospital, demonstrating its effectiveness across different\npatients. The code and SRH-LEI dataset are available at\nhttps://github.com/guoruilu/SlimSeiz.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09998v1",
    "published_date": "2024-10-13 20:43:01 UTC",
    "updated_date": "2024-10-13 20:43:01 UTC"
  },
  {
    "arxiv_id": "2410.09997v1",
    "title": "Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code",
    "authors": [
      "Nan Jiang",
      "Qi Li",
      "Lin Tan",
      "Tianyi Zhang"
    ],
    "abstract": "Despite their success, large language models (LLMs) face the critical\nchallenge of hallucinations, generating plausible but incorrect content. While\nmuch research has focused on hallucinations in multiple modalities including\nimages and natural language text, less attention has been given to\nhallucinations in source code, which leads to incorrect and vulnerable code\nthat causes significant financial loss. To pave the way for research in LLMs'\nhallucinations in code, we introduce Collu-Bench, a benchmark for predicting\ncode hallucinations of LLMs across code generation (CG) and automated program\nrepair (APR) tasks. Collu-Bench includes 13,234 code hallucination instances\ncollected from five datasets and 11 diverse LLMs, ranging from open-source\nmodels to commercial ones. To better understand and predict code\nhallucinations, Collu-Bench provides detailed features such as the per-step log\nprobabilities of LLMs' output, token types, and the execution feedback of LLMs'\ngenerated code for in-depth analysis. In addition, we conduct experiments to\npredict hallucination on Collu-Bench, using both traditional machine learning\ntechniques and neural networks, which achieves 22.03 -- 33.15% accuracy. Our\nexperiments draw insightful findings of code hallucination patterns, reveal the\nchallenge of accurately localizing LLMs' hallucinations, and highlight the need\nfor more sophisticated techniques.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09997v1",
    "published_date": "2024-10-13 20:41:47 UTC",
    "updated_date": "2024-10-13 20:41:47 UTC"
  },
  {
    "arxiv_id": "2410.09988v2",
    "title": "HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics",
    "authors": [
      "Jingxuan Fan",
      "Sarah Martinson",
      "Erik Y. Wang",
      "Kaylie Hausknecht",
      "Jonah Brenner",
      "Danxian Liu",
      "Nianli Peng",
      "Corey Wang",
      "Michael P. Brenner"
    ],
    "abstract": "Advanced applied mathematics problems are underrepresented in existing Large\nLanguage Model (LLM) benchmark datasets. To address this, we introduce\nHARDMath, a dataset inspired by a graduate course on asymptotic methods,\nfeaturing challenging applied mathematics problems that require analytical\napproximation techniques. These problems demand a combination of mathematical\nreasoning, computational tools, and subjective judgment, making them difficult\nfor LLMs. Our framework auto-generates a large number of problems with\nsolutions validated against numerical ground truths. We evaluate both open- and\nclosed-source LLMs on HARDMath-mini, a sub-sampled test set of 366 problems, as\nwell as on 40 word problems formulated in applied science contexts. Even\nleading closed-source models like GPT-4 achieve only 43.8% overall accuracy\nwith few-shot Chain-of-Thought prompting, and all models demonstrate\nsignificantly lower performance compared to results on existing mathematics\nbenchmark datasets. We additionally conduct a detailed error analysis to gain\ninsights into the failure cases of LLMs. These results demonstrate limitations\nof current LLM performance on advanced graduate-level applied math problems and\nunderscore the importance of datasets like HARDMath to advance mathematical\nabilities of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code and the HARDMath dataset is available at\n  https://github.com/sarahmart/HARDMath",
    "pdf_url": "http://arxiv.org/pdf/2410.09988v2",
    "published_date": "2024-10-13 20:09:41 UTC",
    "updated_date": "2024-12-13 22:03:43 UTC"
  },
  {
    "arxiv_id": "2410.09979v1",
    "title": "Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies",
    "authors": [
      "Michal Kosinski"
    ],
    "abstract": "A growing number of studies have linked facial width-to-height ratio (fWHR)\nwith various antisocial or violent behavioral tendencies. However, those\nstudies have predominantly been laboratory based and low powered. This work\nreexamined the links between fWHR and behavioral tendencies in a large sample\nof 137,163 participants. Behavioral tendencies were measured using 55\nwell-established psychometric scales, including self-report scales measuring\nintelligence, domains and facets of the five-factor model of personality,\nimpulsiveness, sense of fairness, sensational interests, self-monitoring,\nimpression management, and satisfaction with life. The findings revealed that\nfWHR is not substantially linked with any of these self-reported measures of\nbehavioral tendencies, calling into question whether the links between fWHR and\nbehavior generalize beyond the small samples and specific experimental settings\nthat have been used in past fWHR research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "Psychological Science (2017)",
    "pdf_url": "http://arxiv.org/pdf/2410.09979v1",
    "published_date": "2024-10-13 19:48:53 UTC",
    "updated_date": "2024-10-13 19:48:53 UTC"
  },
  {
    "arxiv_id": "2410.09972v1",
    "title": "Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions",
    "authors": [
      "Kyungmin Kim",
      "JB Lanier",
      "Pierre Baldi",
      "Charless Fowlkes",
      "Roy Fox"
    ],
    "abstract": "Recent advancements in Model-Based Reinforcement Learning (MBRL) have made it\na powerful tool for visual control tasks. Despite improved data efficiency, it\nremains challenging to train MBRL agents with generalizable perception.\nTraining in the presence of visual distractions is particularly difficult due\nto the high variation they introduce to representation learning. Building on\nDREAMER, a popular MBRL method, we propose a simple yet effective auxiliary\ntask to facilitate representation learning in distracting environments. Under\nthe assumption that task-relevant components of image observations are\nstraightforward to identify with prior knowledge in a given task, we use a\nsegmentation mask on image observations to only reconstruct task-relevant\ncomponents. In doing so, we greatly reduce the complexity of representation\nlearning by removing the need to encode task-irrelevant objects in the latent\nrepresentation. Our method, Segmentation Dreamer (SD), can be used either with\nground-truth masks easily accessible in simulation or by leveraging potentially\nimperfect segmentation foundation models. The latter is further improved by\nselectively applying the reconstruction loss to avoid providing misleading\nlearning signals due to mask prediction errors. In modified DeepMind Control\nsuite (DMC) and Meta-World tasks with added visual distractions, SD achieves\nsignificantly better sample efficiency and greater final performance than prior\nwork. We find that SD is especially helpful in sparse reward tasks otherwise\nunsolvable by prior work, enabling the training of visually robust agents\nwithout the need for extensive reward engineering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09972v1",
    "published_date": "2024-10-13 19:24:07 UTC",
    "updated_date": "2024-10-13 19:24:07 UTC"
  },
  {
    "arxiv_id": "2410.09967v1",
    "title": "Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling",
    "authors": [
      "Mohammad Mozafari",
      "Hosein Hasani",
      "Reza Vahidimajd",
      "Mohamadreza Fereydooni",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "In recent years, few-shot segmentation (FSS) models have emerged as a\npromising approach in medical imaging analysis, offering remarkable\nadaptability to segment novel classes with limited annotated data. Existing\napproaches to few-shot segmentation have often overlooked the potential of the\nquery itself, failing to fully utilize the valuable information it contains.\nHowever, treating the query as unlabeled data provides an opportunity to\nenhance prediction accuracy. Specifically in the domain of medical imaging, the\nvolumetric structure of queries offers a considerable source of valuable\ninformation that can be used to improve the target slice segmentation. In this\nwork, we present a novel strategy to efficiently leverage the intrinsic\ninformation of the query sample for final segmentation during inference. First,\nwe use the support slices from a reference volume to generate an initial\nsegmentation score for the query slices through a prototypical approach.\nSubsequently, we apply a confidence-aware pseudo-labeling procedure to transfer\nthe most informative parts of query slices to the support set. The final\nprediction is performed based on the new expanded support set, enabling the\nprediction of a more accurate segmentation mask for the query volume. Extensive\nexperiments show that the proposed method can effectively boost performance\nacross diverse settings and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09967v1",
    "published_date": "2024-10-13 19:07:07 UTC",
    "updated_date": "2024-10-13 19:07:07 UTC"
  },
  {
    "arxiv_id": "2410.09964v1",
    "title": "Lower-dimensional projections of cellular expression improves cell type classification from single-cell RNA sequencing",
    "authors": [
      "Muhammad Umar",
      "Muhammad Asif",
      "Arif Mahmood"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) enables the study of cellular\ndiversity at single cell level. It provides a global view of cell-type\nspecification during the onset of biological mechanisms such as developmental\nprocesses and human organogenesis. Various statistical, machine and deep\nlearning-based methods have been proposed for cell-type classification. Most of\nthe methods utilizes unsupervised lower dimensional projections obtained from\nfor a large reference data. In this work, we proposed a reference-based method\nfor cell type classification, called EnProCell. The EnProCell, first, computes\nlower dimensional projections that capture both the high variance and class\nseparability through an ensemble of principle component analysis and multiple\ndiscriminant analysis. In the second phase, EnProCell trains a deep neural\nnetwork on the lower dimensional representation of data to classify cell types.\nThe proposed method outperformed the existing state-of-the-art methods when\ntested on four different data sets produced from different single-cell\nsequencing technologies. The EnProCell showed higher accuracy (98.91) and F1\nscore (98.64) than other methods for predicting reference from reference\ndatasets. Similarly, EnProCell also showed better performance than existing\nmethods in predicting cell types for data with unknown cell types (query) from\nreference datasets (accuracy:99.52; F1 score: 99.07). In addition to improved\nperformance, the proposed methodology is simple and does not require more\ncomputational resources and time. the EnProCell is available at\nhttps://github.com/umar1196/EnProCell.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09964v1",
    "published_date": "2024-10-13 19:01:38 UTC",
    "updated_date": "2024-10-13 19:01:38 UTC"
  },
  {
    "arxiv_id": "2410.09954v1",
    "title": "EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition",
    "authors": [
      "Jingyu Liu",
      "Xinyu Liu",
      "Mingzhe Qu",
      "Tianyi Lyu"
    ],
    "abstract": "Integrating IoT technology into basketball action recognition enhances sports\nanalytics, providing crucial insights into player performance and game\nstrategy. However, existing methods often fall short in terms of accuracy and\nefficiency, particularly in complex, real-time environments where player\nmovements are frequently occluded or involve intricate interactions. To\novercome these challenges, we propose the EITNet model, a deep learning\nframework that combines EfficientDet for object detection, I3D for\nspatiotemporal feature extraction, and TimeSformer for temporal analysis, all\nintegrated with IoT technology for seamless real-time data collection and\nprocessing. Our contributions include developing a robust architecture that\nimproves recognition accuracy to 92\\%, surpassing the baseline EfficientDet\nmodel's 87\\%, and reducing loss to below 5.0 compared to EfficientDet's 9.0\nover 50 epochs. Furthermore, the integration of IoT technology enhances\nreal-time data processing, providing adaptive insights into player performance\nand strategy. The paper details the design and implementation of EITNet,\nexperimental validation, and a comprehensive evaluation against existing\nmodels. The results demonstrate EITNet's potential to significantly advance\nautomated sports analysis and optimize data utilization for player performance\nand strategy improvement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09954v1",
    "published_date": "2024-10-13 18:21:15 UTC",
    "updated_date": "2024-10-13 18:21:15 UTC"
  },
  {
    "arxiv_id": "2410.19769v1",
    "title": "Real-time Monitoring of Lower Limb Movement Resistance Based on Deep Learning",
    "authors": [
      "Buren Batu",
      "Yuanmeng Liu",
      "Tianyi Lyu"
    ],
    "abstract": "Real-time lower limb movement resistance monitoring is critical for various\napplications in clinical and sports settings, such as rehabilitation and\nathletic training. Current methods often face limitations in accuracy,\ncomputational efficiency, and generalizability, which hinder their practical\nimplementation. To address these challenges, we propose a novel Mobile\nMulti-Task Learning Network (MMTL-Net) that integrates MobileNetV3 for\nefficient feature extraction and employs multi-task learning to simultaneously\npredict resistance levels and recognize activities. The advantages of MMTL-Net\ninclude enhanced accuracy, reduced latency, and improved computational\nefficiency, making it highly suitable for real-time applications. Experimental\nresults demonstrate that MMTL-Net significantly outperforms existing models on\nthe UCI Human Activity Recognition and Wireless Sensor Data Mining Activity\nPrediction datasets, achieving a lower Force Error Rate (FER) of 6.8% and a\nhigher Resistance Prediction Accuracy (RPA) of 91.2%. Additionally, the model\nshows a Real-time Responsiveness (RTR) of 12 milliseconds and a Throughput (TP)\nof 33 frames per second. These findings underscore the model's robustness and\neffectiveness in diverse real-world scenarios. The proposed framework not only\nadvances the state-of-the-art in resistance monitoring but also paves the way\nfor more efficient and accurate systems in clinical and sports applications. In\nreal-world settings, the practical implications of MMTL-Net include its\npotential to enhance patient outcomes in rehabilitation and improve athletic\nperformance through precise, real-time monitoring and feedback.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "17 pages paper",
    "pdf_url": "http://arxiv.org/pdf/2410.19769v1",
    "published_date": "2024-10-13 18:19:48 UTC",
    "updated_date": "2024-10-13 18:19:48 UTC"
  },
  {
    "arxiv_id": "2410.12866v2",
    "title": "Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Chen Feng",
      "Lu Cao",
      "Yue Zhang",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "abstract": "Recent advancements in brain-computer interfaces (BCIs) have enabled the\ndecoding of lexical tones from intracranial recordings, offering the potential\nto restore the communication abilities of speech-impaired tonal language\nspeakers. However, data heterogeneity induced by both physiological and\ninstrumental factors poses a significant challenge for unified invasive brain\ntone decoding. Traditional subject-specific models, which operate under a\nheterogeneous decoding paradigm, fail to capture generalized neural\nrepresentations and cannot effectively leverage data across subjects. To\naddress these limitations, we introduce Homogeneity-Heterogeneity Disentangled\nLearning for neural Representations (H2DiLR), a novel framework that\ndisentangles and learns both the homogeneity and heterogeneity from\nintracranial recordings across multiple subjects. To evaluate H2DiLR, we\ncollected stereoelectroencephalography (sEEG) data from multiple participants\nreading Mandarin materials comprising 407 syllables, representing nearly all\nMandarin characters. Extensive experiments demonstrate that H2DiLR, as a\nunified decoding paradigm, significantly outperforms the conventional\nheterogeneous decoding approach. Furthermore, we empirically confirm that\nH2DiLR effectively captures both homogeneity and heterogeneity during neural\nrepresentation learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR2025 Poster (Preprint V2)",
    "pdf_url": "http://arxiv.org/pdf/2410.12866v2",
    "published_date": "2024-10-13 18:09:12 UTC",
    "updated_date": "2025-02-18 12:28:03 UTC"
  },
  {
    "arxiv_id": "2410.09948v1",
    "title": "State of NLP in Kenya: A Survey",
    "authors": [
      "Cynthia Jayne Amol",
      "Everlyn Asiko Chimoto",
      "Rose Delilah Gesicho",
      "Antony M. Gitau",
      "Naome A. Etori",
      "Caringtone Kinyanjui",
      "Steven Ndung'u",
      "Lawrence Moruye",
      "Samson Otieno Ooko",
      "Kavengi Kitonga",
      "Brian Muhia",
      "Catherine Gitau",
      "Antony Ndolo",
      "Lilian D. A. Wanzare",
      "Albert Njoroge Kahira",
      "Ronald Tombe"
    ],
    "abstract": "Kenya, known for its linguistic diversity, faces unique challenges and\npromising opportunities in advancing Natural Language Processing (NLP)\ntechnologies, particularly for its underrepresented indigenous languages. This\nsurvey provides a detailed assessment of the current state of NLP in Kenya,\nemphasizing ongoing efforts in dataset creation, machine translation, sentiment\nanalysis, and speech recognition for local dialects such as Kiswahili, Dholuo,\nKikuyu, and Luhya. Despite these advancements, the development of NLP in Kenya\nremains constrained by limited resources and tools, resulting in the\nunderrepresentation of most indigenous languages in digital spaces. This paper\nuncovers significant gaps by critically evaluating the available datasets and\nexisting NLP models, most notably the need for large-scale language models and\nthe insufficient digital representation of Indigenous languages. We also\nanalyze key NLP applications: machine translation, information retrieval, and\nsentiment analysis-examining how they are tailored to address local linguistic\nneeds. Furthermore, the paper explores the governance, policies, and\nregulations shaping the future of AI and NLP in Kenya and proposes a strategic\nroadmap to guide future research and development efforts. Our goal is to\nprovide a foundation for accelerating the growth of NLP technologies that meet\nKenya's diverse linguistic demands.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09948v1",
    "published_date": "2024-10-13 18:08:24 UTC",
    "updated_date": "2024-10-13 18:08:24 UTC"
  },
  {
    "arxiv_id": "2410.09940v2",
    "title": "Generalized Group Data Attribution",
    "authors": [
      "Dan Ley",
      "Suraj Srinivas",
      "Shichang Zhang",
      "Gili Rusak",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Data Attribution (DA) methods quantify the influence of individual training\ndata points on model outputs and have broad applications such as\nexplainability, data selection, and noisy label identification. However,\nexisting DA methods are often computationally intensive, limiting their\napplicability to large-scale machine learning models. To address this\nchallenge, we introduce the Generalized Group Data Attribution (GGDA)\nframework, which computationally simplifies DA by attributing to groups of\ntraining points instead of individual ones. GGDA is a general framework that\nsubsumes existing attribution methods and can be applied to new DA techniques\nas they emerge. It allows users to optimize the trade-off between efficiency\nand fidelity based on their needs. Our empirical results demonstrate that GGDA\napplied to popular DA methods such as Influence Functions, TracIn, and TRAK\nresults in upto 10x-50x speedups over standard DA methods while gracefully\ntrading off attribution fidelity. For downstream applications such as dataset\npruning and noisy label identification, we demonstrate that GGDA significantly\nimproves computational efficiency and maintains effectiveness, enabling\npractical applications in large-scale machine learning scenarios that were\npreviously infeasible.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09940v2",
    "published_date": "2024-10-13 17:51:21 UTC",
    "updated_date": "2024-10-21 14:36:35 UTC"
  },
  {
    "arxiv_id": "2410.09928v1",
    "title": "M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models",
    "authors": [
      "Megha Sharma",
      "Muhammad Taimoor Haseeb",
      "Gus Xia",
      "Yoshimasa Tsuruoka"
    ],
    "abstract": "This paper introduces M2M Gen, a multi modal framework for generating\nbackground music tailored to Japanese manga. The key challenges in this task\nare the lack of an available dataset or a baseline. To address these\nchallenges, we propose an automated music generation pipeline that produces\nbackground music for an input manga book. Initially, we use the dialogues in a\nmanga to detect scene boundaries and perform emotion classification using the\ncharacters faces within a scene. Then, we use GPT4o to translate this low level\nscene information into a high level music directive. Conditioned on the scene\ninformation and the music directive, another instance of GPT 4o generates page\nlevel music captions to guide a text to music model. This produces music that\nis aligned with the mangas evolving narrative. The effectiveness of M2M Gen is\nconfirmed through extensive subjective evaluations, showcasing its capability\nto generate higher quality, more relevant and consistent music that complements\nspecific scenes when compared to our baselines.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09928v1",
    "published_date": "2024-10-13 17:15:59 UTC",
    "updated_date": "2024-10-13 17:15:59 UTC"
  },
  {
    "arxiv_id": "2410.09923v1",
    "title": "Analysis and Design of a Personalized Recommendation System Based on a Dynamic User Interest Model",
    "authors": [
      "Chunyan Mao",
      "Shuaishuai Huang",
      "Mingxiu Sui",
      "Haowei Yang",
      "Xueshe Wang"
    ],
    "abstract": "With the rapid development of the internet and the explosion of information,\nproviding users with accurate personalized recommendations has become an\nimportant research topic. This paper designs and analyzes a personalized\nrecommendation system based on a dynamic user interest model. The system\ncaptures user behavior data, constructs a dynamic user interest model, and\ncombines multiple recommendation algorithms to provide personalized content to\nusers. The research results show that this system significantly improves\nrecommendation accuracy and user satisfaction. This paper discusses the\nsystem's architecture design, algorithm implementation, and experimental\nresults in detail and explores future research directions.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09923v1",
    "published_date": "2024-10-13 17:08:16 UTC",
    "updated_date": "2024-10-13 17:08:16 UTC"
  },
  {
    "arxiv_id": "2410.09918v2",
    "title": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces",
    "authors": [
      "DiJia Su",
      "Sainbayar Sukhbaatar",
      "Michael Rabbat",
      "Yuandong Tian",
      "Qinqing Zheng"
    ],
    "abstract": "In human cognition theory, human thinking is governed by two systems: the\nfast and intuitive System 1 and the slower but more deliberative System 2.\nRecent studies have shown that incorporating System 2 process into Transformers\nincluding large language models (LLMs), significantly enhances their reasoning\ncapabilities. Nevertheless, models that purely resemble System 2 thinking\nrequire substantially higher computational costs and are much slower to\nrespond. To address this challenge, we present Dualformer, a single Transformer\nmodel that seamlessly integrates both the fast and slow reasoning modes.\nDualformer is obtained by training on data with randomized reasoning traces,\nwhere different parts of the traces are dropped during training. The dropping\nstrategies are specifically tailored according to the trace structure,\nanalogous to analyzing our thinking process and creating shortcuts with\npatterns. At inference time, our model can be configured to output only the\nsolutions (fast mode) or both the reasoning chain and the final solution (slow\nmode), or automatically decide which mode to engage (auto mode). In all cases,\nDualformer outperforms the corresponding baseline models in both performance\nand computational efficiency: (1) in slow mode, Dualformer optimally solves\nunseen 30 x 30 maze navigation tasks 97.6% of the time, surpassing the\nSearchformer (trained on data with complete reasoning traces) baseline\nperformance of 93.3%, while only using 45.5% fewer reasoning steps; (2) in fast\nmode, Dualformer completes those tasks with an 80% optimal rate, significantly\noutperforming the Solution-Only model (trained on solution-only data), which\nhas an optimal rate of only 30%. For math problems, our techniques have also\nachieved improved performance with LLM fine-tuning, showing its generalization\nbeyond task-specific models.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09918v2",
    "published_date": "2024-10-13 16:53:02 UTC",
    "updated_date": "2025-04-10 18:46:07 UTC"
  },
  {
    "arxiv_id": "2410.09908v1",
    "title": "Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning",
    "authors": [
      "Pengfei Jin",
      "Peng Shu",
      "Sekeun Kim",
      "Qing Xiao",
      "Sifan Song",
      "Cheng Chen",
      "Tianming Liu",
      "Xiang Li",
      "Quanzheng Li"
    ],
    "abstract": "Foundation models have become a cornerstone in deep learning, with techniques\nlike Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models.\nSimilarly, methods such as Retrieval-Augmented Generation (RAG), which leverage\nvectorized databases, have further improved model performance by grounding\noutputs in external information. While these approaches have demonstrated\nnotable success, they often require extensive training or labeled data, which\ncan limit their adaptability in resource-constrained environments. To address\nthese challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new\nmethod that creates a vectorized database of LoRAs, enabling efficient\nretrieval and application of model adaptations to new tasks. RPE minimizes the\nneed for extensive training and eliminates the requirement for labeled data,\nmaking it particularly effective for zero-shot learning. Additionally, RPE is\nwell-suited for privacy-sensitive domains like healthcare, as it modifies model\nparameters without accessing raw data. When applied to tasks such as medical\nreport generation and image segmentation, RPE not only proved effective but\nalso surpassed supervised fine-tuning methods in certain cases, highlighting\nits potential to enhance both computational efficiency and privacy in deep\nlearning applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09908v1",
    "published_date": "2024-10-13 16:28:38 UTC",
    "updated_date": "2024-10-13 16:28:38 UTC"
  },
  {
    "arxiv_id": "2410.09904v1",
    "title": "Equitable Access to Justice: Logical LLMs Show Promise",
    "authors": [
      "Manuj Kant",
      "Manav Kant",
      "Marzieh Nabi",
      "Preston Carlson",
      "Megan Ma"
    ],
    "abstract": "The costs and complexity of the American judicial system limit access to\nlegal solutions for many Americans. Large language models (LLMs) hold great\npotential to improve access to justice. However, a major challenge in applying\nAI and LLMs in legal contexts, where consistency and reliability are crucial,\nis the need for System 2 reasoning. In this paper, we explore the integration\nof LLMs with logic programming to enhance their ability to reason, bringing\ntheir strategic capabilities closer to that of a skilled lawyer. Our objective\nis to translate laws and contracts into logic programs that can be applied to\nspecific legal cases, with a focus on insurance contracts. We demonstrate that\nwhile GPT-4o fails to encode a simple health insurance contract into logical\ncode, the recently released OpenAI o1-preview model succeeds, exemplifying how\nLLMs with advanced System 2 reasoning capabilities can expand access to\njustice.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09904v1",
    "published_date": "2024-10-13 16:26:07 UTC",
    "updated_date": "2024-10-13 16:26:07 UTC"
  },
  {
    "arxiv_id": "2410.09890v1",
    "title": "Large-Scale 3D Medical Image Pre-training with Geometric Context Priors",
    "authors": [
      "Linshan Wu",
      "Jiaxin Zhuang",
      "Hao Chen"
    ],
    "abstract": "The scarcity of annotations poses a significant challenge in medical image\nanalysis. Large-scale pre-training has emerged as a promising label-efficient\nsolution, owing to the utilization of large-scale data, large models, and\nadvanced pre-training techniques. However, its development in medical images\nremains underexplored. The primary challenge lies in harnessing large-scale\nunlabeled data and learning high-level semantics without annotations. We\nobserve that 3D medical images exhibit consistent geometric context, i.e.,\nconsistent geometric relations between different organs, which leads to a\npromising way for learning consistent representations. Motivated by this, we\nintroduce a simple-yet-effective Volume Contrast (VoCo) framework to leverage\ngeometric context priors for self-supervision. Given an input volume, we\nextract base crops from different regions to construct positive and negative\npairs for contrastive learning. Then we predict the contextual position of a\nrandom crop by contrasting its similarity to the base crops. In this way, VoCo\nencodes the inherent geometric context into model representations, facilitating\nhigh-level semantic learning without annotations. Specifically, we (1)\nintroduce the largest medical pre-training dataset PreCT-160K; (2) investigate\nscaling laws and propose guidelines for tailoring different model sizes to\nvarious medical tasks; (3) build a benchmark encompassing 48 medical tasks.\nExtensive experiments highlight the superiority of VoCo. Codes at\nhttps://github.com/Luffy03/Large-Scale-Medical.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024 Extension",
    "pdf_url": "http://arxiv.org/pdf/2410.09890v1",
    "published_date": "2024-10-13 15:59:26 UTC",
    "updated_date": "2024-10-13 15:59:26 UTC"
  },
  {
    "arxiv_id": "2410.09870v3",
    "title": "ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains",
    "authors": [
      "Yein Park",
      "Chanwoong Yoon",
      "Jungwoo Park",
      "Donghyeon Lee",
      "Minbyul Jeong",
      "Jaewoo Kang"
    ],
    "abstract": "Large language models (LLMs) have brought significant changes to many aspects\nof our lives. However, assessing and ensuring their chronological knowledge\nremains challenging. Existing approaches fall short in addressing the temporal\nadaptability of knowledge, often relying on a fixed time-point view. To\novercome this, we introduce ChroKnowBench, a benchmark dataset designed to\nevaluate chronologically accumulated knowledge across three key aspects:\nmultiple domains, time dependency, temporal state. Our benchmark distinguishes\nbetween knowledge that evolves (e.g., personal history, scientific discoveries,\namended laws) and knowledge that remain constant (e.g., mathematical truths,\ncommonsense facts). Building on this benchmark, we present ChroKnowledge\n(Chronological Categorization of Knowledge), a novel sampling-based framework\nfor evaluating LLMs' non-parametric chronological knowledge. Our evaluation led\nto the following observations: (1) The ability of eliciting temporal knowledge\nvaries depending on the data format that model was trained on. (2) LLMs\npartially recall knowledge or show a cut-off at temporal boundaries rather than\nrecalling all aspects of knowledge correctly. Thus, we apply our\nChroKnowPrompt, an in-depth prompting to elicit chronological knowledge by\ntraversing step-by-step through the surrounding time spans. We observe that it\nsuccessfully recalls objects across both open-source and proprietary LLMs,\ndemonstrating versatility, though it faces challenges with dynamic datasets and\nunstructured formats.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025, 40 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09870v3",
    "published_date": "2024-10-13 15:08:49 UTC",
    "updated_date": "2025-02-28 08:02:31 UTC"
  },
  {
    "arxiv_id": "2410.09869v1",
    "title": "Prompt Tuning for Audio Deepfake Detection: Computationally Efficient Test-time Domain Adaptation with Limited Target Dataset",
    "authors": [
      "Hideyuki Oiso",
      "Yuto Matsunaga",
      "Kazuya Kakizaki",
      "Taiki Miyagawa"
    ],
    "abstract": "We study test-time domain adaptation for audio deepfake detection (ADD),\naddressing three challenges: (i) source-target domain gaps, (ii) limited target\ndataset size, and (iii) high computational costs. We propose an ADD method\nusing prompt tuning in a plug-in style. It bridges domain gaps by integrating\nit seamlessly with state-of-the-art transformer models and/or with other\nfine-tuning methods, boosting their performance on target data (challenge (i)).\nIn addition, our method can fit small target datasets because it does not\nrequire a large number of extra parameters (challenge (ii)). This feature also\ncontributes to computational efficiency, countering the high computational\ncosts typically associated with large-scale pre-trained models in ADD\n(challenge (iii)). We conclude that prompt tuning for ADD under domain gaps\npresents a promising avenue for enhancing accuracy with minimal target data and\nnegligible extra computational burden.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at Interspeech 2024. Hideyuki Oiso and Yuto Matsunaga\n  contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2410.09869v1",
    "published_date": "2024-10-13 15:07:35 UTC",
    "updated_date": "2024-10-13 15:07:35 UTC"
  },
  {
    "arxiv_id": "2410.12865v1",
    "title": "ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction",
    "authors": [
      "Yanlin Zhang",
      "Ning Li",
      "Quan Gan",
      "Weinan Zhang",
      "David Wipf",
      "Minjie Wang"
    ],
    "abstract": "Crafting effective features is a crucial yet labor-intensive and\ndomain-specific task within machine learning pipelines. Fortunately, recent\nadvancements in Large Language Models (LLMs) have shown promise in automating\nvarious data science tasks, including feature engineering. But despite this\npotential, evaluations thus far are primarily based on the end performance of a\ncomplete ML pipeline, providing limited insight into precisely how LLMs behave\nrelative to human experts in feature engineering. To address this gap, we\npropose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated\na new dataset from historical Kaggle competitions, including 251 \"golden\"\nfeatures used by top-performing teams. ELF-Gym then quantitatively evaluates\nLLM-generated features by measuring their impact on downstream model\nperformance as well as their alignment with expert-crafted features through\nsemantic and functional similarity assessments. This approach provides a more\ncomprehensive evaluation of disparities between LLMs and human experts, while\noffering valuable insights into specific areas where LLMs may have room for\nimprovement. For example, using ELF-Gym we empirically demonstrate that, in the\nbest-case scenario, LLMs can semantically capture approximately 56% of the\ngolden features, but at the more demanding implementation level this overlap\ndrops to 13%. Moreover, in other cases LLMs may fail completely, particularly\non datasets that require complex features, indicating broad potential pathways\nfor improvement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12865v1",
    "published_date": "2024-10-13 13:59:33 UTC",
    "updated_date": "2024-10-13 13:59:33 UTC"
  },
  {
    "arxiv_id": "2410.09838v2",
    "title": "Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense",
    "authors": [
      "Rui Min",
      "Zeyu Qin",
      "Nevin L. Zhang",
      "Li Shen",
      "Minhao Cheng"
    ],
    "abstract": "Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) as\nthey allow attackers to manipulate model predictions with backdoor triggers. To\naddress these security vulnerabilities, various backdoor purification methods\nhave been proposed to purify compromised models. Typically, these purified\nmodels exhibit low Attack Success Rates (ASR), rendering them resistant to\nbackdoored inputs. However, Does achieving a low ASR through current safety\npurification methods truly eliminate learned backdoor features from the\npretraining phase? In this paper, we provide an affirmative answer to this\nquestion by thoroughly investigating the Post-Purification Robustness of\ncurrent backdoor purification methods. We find that current safety purification\nmethods are vulnerable to the rapid re-learning of backdoor behavior, even when\nfurther fine-tuning of purified models is performed using a very small number\nof poisoned samples. Based on this, we further propose the practical\nQuery-based Reactivation Attack (QRA) which could effectively reactivate the\nbackdoor by merely querying purified models. We find the failure to achieve\nsatisfactory post-purification robustness stems from the insufficient deviation\nof purified models from the backdoored model along the backdoor-connected path.\nTo improve the post-purification robustness, we propose a straightforward\ntuning defense, Path-Aware Minimization (PAM), which promotes deviation along\nbackdoor-connected paths with extra model updates. Extensive experiments\ndemonstrate that PAM significantly improves post-purification robustness while\nmaintaining a good clean accuracy and low ASR. Our work provides a new\nperspective on understanding the effectiveness of backdoor safety tuning and\nhighlights the importance of faithfully assessing the model's safety.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Spotlight paper. The first two authors contributed\n  equally",
    "pdf_url": "http://arxiv.org/pdf/2410.09838v2",
    "published_date": "2024-10-13 13:37:36 UTC",
    "updated_date": "2024-10-16 15:59:19 UTC"
  },
  {
    "arxiv_id": "2410.09831v1",
    "title": "LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond",
    "authors": [
      "Md Tanvir Islam",
      "Inzamamul Alam",
      "Simon S. Woo",
      "Saeed Anwar",
      "IK Hyun Lee",
      "Khan Muhammad"
    ],
    "abstract": "Low-light image enhancement (LLIE) is essential for numerous computer vision\ntasks, including object detection, tracking, segmentation, and scene\nunderstanding. Despite substantial research on improving low-quality images\ncaptured in underexposed conditions, clear vision remains critical for\nautonomous vehicles, which often struggle with low-light scenarios, signifying\nthe need for continuous research. However, paired datasets for LLIE are scarce,\nparticularly for street scenes, limiting the development of robust LLIE\nmethods. Despite using advanced transformers and/or diffusion-based models,\ncurrent LLIE methods struggle in real-world low-light conditions and lack\ntraining on street-scene datasets, limiting their effectiveness for autonomous\nvehicles. To bridge these gaps, we introduce a new dataset LoLI-Street\n(Low-Light Images of Streets) with 33k paired low-light and well-exposed images\nfrom street scenes in developed cities, covering 19k object classes for object\ndetection. LoLI-Street dataset also features 1,000 real low-light test images\nfor testing LLIE models under real-life conditions. Furthermore, we propose a\ntransformer and diffusion-based LLIE model named \"TriFuse\". Leveraging the\nLoLI-Street dataset, we train and evaluate our TriFuse and SOTA models to\nbenchmark on our dataset. Comparing various models, our dataset's\ngeneralization feasibility is evident in testing across different mainstream\ndatasets by significantly enhancing images and object detection for practical\napplications in autonomous driving and surveillance systems. The complete code\nand dataset is available on https://github.com/tanvirnwu/TriFuse.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the Asian Conference on Computer Vision (ACCV 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.09831v1",
    "published_date": "2024-10-13 13:11:56 UTC",
    "updated_date": "2024-10-13 13:11:56 UTC"
  },
  {
    "arxiv_id": "2410.09807v2",
    "title": "Single Ground Truth Is Not Enough: Adding Flexibility to Aspect-Based Sentiment Analysis Evaluation",
    "authors": [
      "Soyoung Yang",
      "Hojun Cho",
      "Jiyoung Lee",
      "Sohee Yoon",
      "Edward Choi",
      "Jaegul Choo",
      "Won Ik Cho"
    ],
    "abstract": "Aspect-based sentiment analysis (ABSA) is a challenging task of extracting\nsentiments along with their corresponding aspects and opinion terms from the\ntext. The inherent subjectivity of span annotation makes variability in the\nsurface forms of extracted terms, complicating the evaluation process.\nTraditional evaluation methods often constrain ground truths (GT) to a single\nterm, potentially misrepresenting the accuracy of semantically valid\npredictions that differ in surface form. To address this limitation, we propose\na novel and fully automated pipeline that expands existing evaluation sets by\nadding alternative valid terms for aspect and opinion. Our approach facilitates\nan equitable assessment of language models by accommodating multiple-answer\ncandidates, resulting in enhanced human agreement compared to single-answer\ntest sets (achieving up to a 10\\%p improvement in Kendall's Tau score).\nExperimental results demonstrate that our expanded evaluation set helps uncover\nthe capabilities of large language models (LLMs) in ABSA tasks, which is\nconcealed by the single-answer GT sets. Consequently, our work contributes to\nthe development of a flexible evaluation framework for ABSA by embracing\ndiverse surface forms to span extraction tasks in a cost-effective and\nreproducible manner. Our code and dataset is open at\nhttps://github.com/dudrrm/zoom-in-n-out-absa.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2410.09807v2",
    "published_date": "2024-10-13 11:48:09 UTC",
    "updated_date": "2025-02-12 04:24:19 UTC"
  },
  {
    "arxiv_id": "2410.13891v2",
    "title": "S$^4$ST: A Strong, Self-transferable, faSt, and Simple Scale Transformation for Transferable Targeted Attack",
    "authors": [
      "Yongxiang Liu",
      "Bowen Peng",
      "Li Liu",
      "Xiang Li"
    ],
    "abstract": "Transferable Targeted Attacks (TTAs), which aim to deceive black-box models\ninto predicting specific erroneous labels, face significant challenges due to\nsevere overfitting to surrogate models. Although modifying image features to\ngenerate robust semantic patterns of the target class is a promising approach,\nexisting methods heavily rely on large-scale additional data. This dependence\nundermines the fair evaluation of TTA threats, potentially leading to a false\nsense of security or unnecessary overreactions. In this paper, we introduce two\nblind measures, surrogate self-alignment and self-transferability, to analyze\nthe effectiveness and correlations of basic transformations, to enhance\ndata-free attacks under strict black-box constraints. Our findings challenge\nconventional assumptions: (1) Attacking simple scaling transformations uniquely\nenhances targeted transferability, outperforming other basic transformations\nand rivaling leading complex methods; (2) Geometric and color transformations\nexhibit high internal redundancy despite weak inter-category correlations.\nThese insights drive the design and tuning of S4ST (Strong, Self-transferable,\nfaSt, Simple Scale Transformation), which integrates dimensionally consistent\nscaling, complementary low-redundancy transformations, and block-wise\noperations. Extensive experiments on the ImageNet-Compatible dataset\ndemonstrate that S4ST achieves a 77.7% average targeted success rate (tSuc),\nsurpassing existing transformations (+17.2% over H-Aug with only 26%\ncomputational time) and SOTA TTA solutions (+6.2% over SASD-WS with 1.2M\nsamples for post-training). Notably, it attains 69.6% and 55.3% average tSuc\nagainst three commercial APIs and vision-language models, respectively. This\nwork establishes a new SOTA for TTAs, highlights their potential threats, and\ncalls for a reevaluation of the data dependency in achieving targeted\ntransferability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "16 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13891v2",
    "published_date": "2024-10-13 11:39:13 UTC",
    "updated_date": "2025-02-25 10:11:28 UTC"
  },
  {
    "arxiv_id": "2410.09804v3",
    "title": "BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models",
    "authors": [
      "Xinyuan Wang",
      "Victor Shea-Jay Huang",
      "Renmiao Chen",
      "Hao Wang",
      "Chengwei Pan",
      "Lei Sha",
      "Minlie Huang"
    ],
    "abstract": "While large language models (LLMs) exhibit remarkable capabilities across\nvarious tasks, they encounter potential security risks such as jailbreak\nattacks, which exploit vulnerabilities to bypass security measures and generate\nharmful outputs. Existing jailbreak strategies mainly focus on maximizing\nattack success rate (ASR), frequently neglecting other critical factors,\nincluding the relevance of the jailbreak response to the query and the level of\nstealthiness. This narrow focus on single objectives can result in ineffective\nattacks that either lack contextual relevance or are easily recognizable. In\nthis work, we introduce BlackDAN, an innovative black-box attack framework with\nmulti-objective optimization, aiming to generate high-quality prompts that\neffectively facilitate jailbreaking while maintaining contextual relevance and\nminimizing detectability. BlackDAN leverages Multiobjective Evolutionary\nAlgorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks\nacross multiple objectives including ASR, stealthiness, and semantic relevance.\nBy integrating mechanisms like mutation, crossover, and Pareto-dominance,\nBlackDAN provides a transparent and interpretable process for generating\njailbreaks. Furthermore, the framework allows customization based on user\npreferences, enabling the selection of prompts that balance harmfulness,\nrelevance, and other factors. Experimental results demonstrate that BlackDAN\noutperforms traditional single-objective methods, yielding higher success rates\nand improved robustness across various LLMs and multimodal LLMs, while ensuring\njailbreak responses are both relevant and less detectable.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09804v3",
    "published_date": "2024-10-13 11:15:38 UTC",
    "updated_date": "2024-11-27 02:41:48 UTC"
  },
  {
    "arxiv_id": "2410.09802v1",
    "title": "EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models",
    "authors": [
      "Eungbean Lee",
      "Somi Jeong",
      "Kwanghoon Sohn"
    ],
    "abstract": "Exemplar-guided image translation, synthesizing photo-realistic images that\nconform to both structural control and style exemplars, is attracting attention\ndue to its ability to enhance user control over style manipulation. Previous\nmethodologies have predominantly depended on establishing dense correspondences\nacross cross-domain inputs. Despite these efforts, they incur quadratic memory\nand computational costs for establishing dense correspondence, resulting in\nlimited versatility and performance degradation. In this paper, we propose a\nnovel approach termed Exemplar-guided Image Translation with Brownian-Bridge\nDiffusion Models (EBDM). Our method formulates the task as a stochastic\nBrownian bridge process, a diffusion process with a fixed initial point as\nstructure control and translates into the corresponding photo-realistic image\nwhile being conditioned solely on the given exemplar image. To efficiently\nguide the diffusion process toward the style of exemplar, we delineate three\npivotal components: the Global Encoder, the Exemplar Network, and the Exemplar\nAttention Module to incorporate global and detailed texture information from\nexemplar images. Leveraging Bridge diffusion, the network can translate images\nfrom structure control while exclusively conditioned on the exemplar style,\nleading to more robust training and inference processes. We illustrate the\nsuperiority of our method over competing approaches through comprehensive\nbenchmark evaluations and visual results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09802v1",
    "published_date": "2024-10-13 11:10:34 UTC",
    "updated_date": "2024-10-13 11:10:34 UTC"
  },
  {
    "arxiv_id": "2410.09795v4",
    "title": "WGFormer: An SE(3)-Transformer Driven by Wasserstein Gradient Flows for Molecular Ground-State Conformation Prediction",
    "authors": [
      "Fanmeng Wang",
      "Minjie Cheng",
      "Hongteng Xu"
    ],
    "abstract": "Predicting molecular ground-state conformation (i.e., energy-minimized\nconformation) is crucial for many chemical applications such as molecular\ndocking and property prediction. Classic energy-based simulation is\ntime-consuming when solving this problem while existing learning-based methods\nhave advantages in computational efficiency but sacrifice accuracy and\ninterpretability. In this work, we propose a novel and effective method to\nbridge the energy-based simulation and the learning-based strategy, which\ndesigns and learns a Wasserstein gradient flow-driven SE(3)-Transformer, called\nWGFormer, for molecular ground-state conformation prediction. Specifically, our\nmethod tackles this task within an auto-encoding framework, which encodes\nlow-quality conformations by the proposed WGFormer and decodes corresponding\nground-state conformations by an MLP. The architecture of WGFormer corresponds\nto Wasserstein gradient flows -- it optimizes molecular conformations by\nminimizing an energy function defined on the latent mixture models of atoms,\nthereby significantly improving performance and interpretability. Extensive\nexperiments show that our method consistently outperforms state-of-the-art\ncompetitors, providing a new and insightful paradigm to predict molecular\nground-state conformation.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09795v4",
    "published_date": "2024-10-13 10:48:22 UTC",
    "updated_date": "2025-02-13 12:35:53 UTC"
  },
  {
    "arxiv_id": "2410.18123v1",
    "title": "Movement Control of Smart Mosque's Domes using CSRNet and Fuzzy Logic Techniques",
    "authors": [
      "Anas H. Blasi",
      "Mohammad Awis Al Lababede",
      "Mohammed A. Alsuwaiket"
    ],
    "abstract": "Mosques are worship places of Allah and must be preserved clean, immaculate,\nprovide all the comforts of the worshippers in them. The prophet's mosque in\nMedina/ Saudi Arabia is one of the most important mosques for Muslims. It\noccupies second place after the sacred mosque in Mecca/ Saudi Arabia, which is\nin constant overcrowding by all Muslims to visit the prophet Mohammad's tomb.\nThis paper aims to propose a smart dome model to preserve the fresh air and\nallow the sunlight to enter the mosque using artificial intelligence\ntechniques. The proposed model controls domes movements based on the weather\nconditions and the overcrowding rates in the mosque. The data have been\ncollected from two different resources, the first one from the database of\nSaudi Arabia weather's history, and the other from Shanghai Technology\nDatabase. Congested Scene Recognition Network (CSRNet) and Fuzzy techniques\nhave applied using Python programming language to control the domes to be\nopened and closed for a specific time to renew the air inside the mosque. Also,\nthis model consists of several parts that are connected for controlling the\nmechanism of opening/closing domes according to weather data and the situation\nof crowding in the mosque. Finally, the main goal of this paper has been\nachieved, and the proposed model has worked efficiently and specifies the exact\nduration time to keep the domes open automatically for a few minutes for each\nhour head.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18123v1",
    "published_date": "2024-10-13 09:39:44 UTC",
    "updated_date": "2024-10-13 09:39:44 UTC"
  },
  {
    "arxiv_id": "2410.09780v1",
    "title": "Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning",
    "authors": [
      "Gisang Lee",
      "Sangwoo Park",
      "Junyoung Park",
      "Andrew Chung",
      "Sieun Park",
      "Yoonah Park",
      "Byungju Kim",
      "Min-gyu Cho"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in many\ncomplex tasks including mathematical reasoning. However, traditional approaches\nheavily rely on ensuring self-consistency within single prompting method, which\nlimits the exploration of diverse problem-solving strategies. This study\naddresses these limitations by performing an experimental analysis of distinct\nprompting methods within the domain of mathematical reasoning. Our findings\ndemonstrate that each method explores a distinct search space, and this\ndifferentiation becomes more evident with increasing problem complexity. To\nleverage this phenomenon, we applied efficient sampling process that uniformly\ncombines samples from these diverse methods, which not only expands the maximum\nsearch space but achieves higher performance with fewer runs compared to single\nmethods. Especially, within the subset of difficult questions of MATH dataset\nnamed MATH-hard, The maximum search space was achieved while utilizing\napproximately 43% fewer runs than single methods on average. These findings\nhighlight the importance of integrating diverse problem-solving strategies to\nenhance the reasoning abilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09780v1",
    "published_date": "2024-10-13 08:49:22 UTC",
    "updated_date": "2024-10-13 08:49:22 UTC"
  },
  {
    "arxiv_id": "2410.09775v1",
    "title": "EasyJudge: an Easy-to-use Tool for Comprehensive Response Evaluation of LLMs",
    "authors": [
      "Yijie Li",
      "Yuan Sun"
    ],
    "abstract": "Recently, there has been a growing trend of employing large language models\n(LLMs) to judge the quality of other LLMs. Many studies have adopted\nclosed-source models, mainly using GPT-4 as the evaluator. However, due to the\nclosed-source nature of the GPT-4 model, employing it as an evaluator has\nresulted in issues including transparency, controllability, and\ncost-effectiveness. Some researchers have turned to using fine-tuned\nopen-source LLMs as evaluators. However, existing open-source evaluation LLMs\ngenerally lack a user-friendly visualization tool, and they have not been\noptimized for accelerated model inference, which causes inconvenience for\nresearchers with limited resources and those working across different fields.\nThis paper presents EasyJudge, a model developed to evaluate significant\nlanguage model responses. It is lightweight, precise, efficient, and\nuser-friendly, featuring an intuitive visualization interface for ease of\ndeployment and use. EasyJudge uses detailed datasets and refined prompts for\nmodel optimization, achieving strong consistency with human and proprietary\nmodel evaluations. The model optimized with quantitative methods enables\nEasyJudge to run efficiently on consumer-grade GPUs or even CPUs. We also\nprovide detailed analysis and case studies to further reveal the potential of\nour method.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09775v1",
    "published_date": "2024-10-13 08:24:12 UTC",
    "updated_date": "2024-10-13 08:24:12 UTC"
  },
  {
    "arxiv_id": "2410.09772v1",
    "title": "HypomimiaCoach: An AU-based Digital Therapy System for Hypomimia Detection & Rehabilitation with Parkinson's Disease",
    "authors": [
      "Yingjing Xu",
      "Xueyan Cai",
      "Zihong Zhou",
      "Mengru Xue",
      "Bo Wang",
      "Haotian Wang",
      "Zhengke Li",
      "Chentian Weng",
      "Wei Luo",
      "Cheng Yao",
      "Bo Lin",
      "Jianwei Yin"
    ],
    "abstract": "Hypomimia is a non-motor symptom of Parkinson's disease that manifests as\ndelayed facial movements and expressions, along with challenges in articulation\nand emotion. Currently, subjective evaluation by neurologists is the primary\nmethod for hypomimia detection, and conventional rehabilitation approaches\nheavily rely on verbal prompts from rehabilitation physicians. There remains a\ndeficiency in accessible, user-friendly and scientifically rigorous assistive\ntools for hypomimia treatments. To investigate this, we developed\nHypomimaCoach, an Action Unit (AU)-based digital therapy system for hypomimia\ndetection and rehabilitation in Parkinson's disease. The HypomimaCoach system\nwas designed to facilitate engagement through the incorporation of both relaxed\nand controlled rehabilitation exercises, while also stimulating initiative\nthrough the integration of digital therapies that incorporated traditional face\ntraining methods. We extract action unit(AU) features and their relationship\nfor hypomimia detection. In order to facilitate rehabilitation, a series of\ntraining programmes have been devised based on the Action Units (AUs) and\npatients are provided with real-time feedback through an additional AU\nrecognition model, which guides them through their training routines. A pilot\nstudy was conducted with seven participants in China, all of whom exhibited\nsymptoms of Parkinson's disease hypomimia. The results of the pilot study\ndemonstrated a positive impact on participants' self-efficacy, with favourable\nfeedback received. Furthermore, physician evaluations validated the system's\napplicability in a therapeutic setting for patients with Parkinson's disease,\nas well as its potential value in clinical applications.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09772v1",
    "published_date": "2024-10-13 08:09:42 UTC",
    "updated_date": "2024-10-13 08:09:42 UTC"
  },
  {
    "arxiv_id": "2410.09770v1",
    "title": "'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews",
    "authors": [
      "Sandeep Kumar",
      "Mohit Sahu",
      "Vardhan Gacche",
      "Tirthankar Ghosal",
      "Asif Ekbal"
    ],
    "abstract": "The integrity of the peer-review process is vital for maintaining scientific\nrigor and trust within the academic community. With the steady increase in the\nusage of large language models (LLMs) like ChatGPT in academic writing, there\nis a growing concern that AI-generated texts could compromise scientific\npublishing, including peer-reviews. Previous works have focused on generic\nAI-generated text detection or have presented an approach for estimating the\nfraction of peer-reviews that can be AI-generated. Our focus here is to solve a\nreal-world problem by assisting the editor or chair in determining whether a\nreview is written by ChatGPT or not. To address this, we introduce the Term\nFrequency (TF) model, which posits that AI often repeats tokens, and the Review\nRegeneration (RR) model, which is based on the idea that ChatGPT generates\nsimilar outputs upon re-prompting. We stress test these detectors against token\nattack and paraphrasing. Finally, we propose an effective defensive strategy to\nreduce the effect of paraphrasing on our models. Our findings suggest both our\nproposed methods perform better than the other AI text detectors. Our RR model\nis more robust, although our TF model performs better than the RR model without\nany attacks. We make our code, dataset, and model public.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Main, 17 pages, 5 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.09770v1",
    "published_date": "2024-10-13 08:06:08 UTC",
    "updated_date": "2024-10-13 08:06:08 UTC"
  },
  {
    "arxiv_id": "2410.09767v2",
    "title": "LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition",
    "authors": [
      "Huan Liu",
      "Shusen Yang",
      "Yuzhe Zhang",
      "Mengze Wang",
      "Fanyu Gong",
      "Chengxi Xie",
      "Guanjian Liu",
      "Zejun Liu",
      "Yong-Jin Liu",
      "Bao-Liang Lu",
      "Dalin Zhang"
    ],
    "abstract": "EEG-based emotion recognition (EER) has gained significant attention due to\nits potential for understanding and analyzing human emotions. While recent\nadvancements in deep learning techniques have substantially improved EER, the\nfield lacks a convincing benchmark and comprehensive open-source libraries.\nThis absence complicates fair comparisons between models and creates\nreproducibility challenges for practitioners, which collectively hinder\nprogress. To address these issues, we introduce LibEER, a comprehensive\nbenchmark and algorithm library designed to facilitate fair comparisons in EER.\nLibEER carefully selects popular and powerful baselines, harmonizes key\nimplementation details across methods, and provides a standardized codebase in\nPyTorch. By offering a consistent evaluation framework with standardized\nexperimental settings, LibEER enables unbiased assessments of over ten\nrepresentative deep learning models for EER across the four most widely used\ndatasets. Additionally, we conduct a thorough, reproducible comparison of model\nperformance and efficiency, providing valuable insights to guide researchers in\nthe selection and design of EER models. Moreover, we make observations and\nin-depth analysis on the experiment results and identify current challenges in\nthis community. We hope that our work will not only lower entry barriers for\nnewcomers to EEG-based emotion recognition but also contribute to the\nstandardization of research in this domain, fostering steady development. The\nlibrary and source code are publicly available at\nhttps://github.com/XJTU-EEG/LibEER.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09767v2",
    "published_date": "2024-10-13 07:51:39 UTC",
    "updated_date": "2024-11-12 12:09:20 UTC"
  },
  {
    "arxiv_id": "2410.09763v3",
    "title": "EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing Wheelchair System Using Deep Learning Approach",
    "authors": [
      "Biplov Paneru",
      "Bishwash Paneru",
      "Bipul Thapa",
      "Khem Narayan Poudyal"
    ],
    "abstract": "This study offers a revolutionary strategy to developing wheelchairs based on\nthe Brain-Computer Interface (BCI) that incorporates Artificial Intelligence\n(AI) using a The device uses electroencephalogram (EEG) data to mimic\nwheelchair navigation. Five different models were trained on a pre-filtered\ndataset that was divided into fixed-length windows using a sliding window\ntechnique. Each window contained statistical measurements, FFT coefficients for\ndifferent frequency bands, and a label identifying the activity carried out\nduring that window that was taken from an open-source Kaggle repository. The\nXGBoost model outperformed the other models, CatBoost, GRU, SVC, and XGBoost,\nwith an accuracy of 60%. The CatBoost model with a major difference between\ntraining and testing accuracy shows overfitting, and similarly, the\nbest-performing model, with SVC, was implemented in a tkinter GUI. The\nwheelchair movement could be simulated in various directions, and a Raspberry\nPi-powered wheelchair system for brain-computer interface is proposed here.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09763v3",
    "published_date": "2024-10-13 07:41:37 UTC",
    "updated_date": "2025-01-12 15:56:53 UTC"
  },
  {
    "arxiv_id": "2410.09761v1",
    "title": "ChartKG: A Knowledge-Graph-Based Representation for Chart Images",
    "authors": [
      "Zhiguang Zhou",
      "Haoxuan Wang",
      "Zhengqing Zhao",
      "Fengling Zheng",
      "Yongheng Wang",
      "Wei Chen",
      "Yong Wang"
    ],
    "abstract": "Chart images, such as bar charts, pie charts, and line charts, are\nexplosively produced due to the wide usage of data visualizations. Accordingly,\nknowledge mining from chart images is becoming increasingly important, which\ncan benefit downstream tasks like chart retrieval and knowledge graph\ncompletion. However, existing methods for chart knowledge mining mainly focus\non converting chart images into raw data and often ignore their visual\nencodings and semantic meanings, which can result in information loss for many\ndownstream tasks. In this paper, we propose ChartKG, a novel knowledge graph\n(KG) based representation for chart images, which can model the visual elements\nin a chart image and semantic relations among them including visual encodings\nand visual insights in a unified manner. Further, we develop a general\nframework to convert chart images to the proposed KG-based representation. It\nintegrates a series of image processing techniques to identify visual elements\nand relations, e.g., CNNs to classify charts, yolov5 and optical character\nrecognition to parse charts, and rule-based methods to construct graphs. We\npresent four cases to illustrate how our knowledge-graph-based representation\ncan model the detailed visual elements and semantic relations in charts, and\nfurther demonstrate how our approach can benefit downstream applications such\nas semantic-aware chart retrieval and chart question answering. We also conduct\nquantitative evaluations to assess the two fundamental building blocks of our\nchart-to-KG framework, i.e., object recognition and optical character\nrecognition. The results provide support for the usefulness and effectiveness\nof ChartKG.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09761v1",
    "published_date": "2024-10-13 07:38:44 UTC",
    "updated_date": "2024-10-13 07:38:44 UTC"
  },
  {
    "arxiv_id": "2410.09754v1",
    "title": "SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning",
    "authors": [
      "Hojoon Lee",
      "Dongyoon Hwang",
      "Donghu Kim",
      "Hyunseung Kim",
      "Jun Jet Tai",
      "Kaushik Subramanian",
      "Peter R. Wurman",
      "Jaegul Choo",
      "Peter Stone",
      "Takuma Seno"
    ],
    "abstract": "Recent advances in CV and NLP have been largely driven by scaling up the\nnumber of network parameters, despite traditional theories suggesting that\nlarger networks are prone to overfitting. These large networks avoid\noverfitting by integrating components that induce a simplicity bias, guiding\nmodels toward simple and generalizable solutions. However, in deep RL,\ndesigning and scaling up networks have been less explored. Motivated by this\nopportunity, we present SimBa, an architecture designed to scale up parameters\nin deep RL by injecting a simplicity bias. SimBa consists of three components:\n(i) an observation normalization layer that standardizes inputs with running\nstatistics, (ii) a residual feedforward block to provide a linear pathway from\nthe input to output, and (iii) a layer normalization to control feature\nmagnitudes. By scaling up parameters with SimBa, the sample efficiency of\nvarious deep RL algorithms-including off-policy, on-policy, and unsupervised\nmethods-is consistently improved. Moreover, solely by integrating SimBa\narchitecture into SAC, it matches or surpasses state-of-the-art deep RL methods\nwith high computational efficiency across DMC, MyoSuite, and HumanoidBench.\nThese results demonstrate SimBa's broad applicability and effectiveness across\ndiverse RL algorithms and environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.09754v1",
    "published_date": "2024-10-13 07:20:53 UTC",
    "updated_date": "2024-10-13 07:20:53 UTC"
  },
  {
    "arxiv_id": "2410.11578v1",
    "title": "STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation",
    "authors": [
      "Vamsi Krishna Vasa",
      "Wenhui Zhu",
      "Xiwen Chen",
      "Peijie Qiu",
      "Xuanzhao Dong",
      "Yalin Wang"
    ],
    "abstract": "In recent years, significant progress has been made in the medical image\nanalysis domain using convolutional neural networks (CNNs). In particular, deep\nneural networks based on a U-shaped architecture (UNet) with skip connections\nhave been adopted for several medical imaging tasks, including organ\nsegmentation. Despite their great success, CNNs are not good at learning global\nor semantic features. Especially ones that require human-like reasoning to\nunderstand the context. Many UNet architectures attempted to adjust with the\nintroduction of Transformer-based self-attention mechanisms, and notable gains\nin performance have been noted. However, the transformers are inherently flawed\nwith redundancy to learn at shallow layers, which often leads to an increase in\nthe computation of attention from the nearby pixels offering limited\ninformation. The recently introduced Super Token Attention (STA) mechanism\nadapts the concept of superpixels from pixel space to token space, using super\ntokens as compact visual representations. This approach tackles the redundancy\nby learning efficient global representations in vision transformers, especially\nfor the shallow layers. In this work, we introduce the STA module in the UNet\narchitecture (STA-UNet), to limit redundancy without losing rich information.\nExperimental results on four publicly available datasets demonstrate the\nsuperiority of STA-UNet over existing state-of-the-art architectures in terms\nof Dice score and IOU for organ segmentation tasks. The code is available at\n\\url{https://github.com/Retinal-Research/STA-UNet}.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11578v1",
    "published_date": "2024-10-13 07:19:46 UTC",
    "updated_date": "2024-10-13 07:19:46 UTC"
  },
  {
    "arxiv_id": "2410.09750v1",
    "title": "Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models",
    "authors": [
      "Juseong Jin",
      "Chang Wook Jeong"
    ],
    "abstract": "Conversation agents powered by large language models are revolutionizing the\nway we interact with visual data. Recently, large vision-language models\n(LVLMs) have been extensively studied for both images and videos. However,\nthese studies typically focus on common scenarios. In this work, we introduce\nan LVLM specifically designed for surgical scenarios. We integrate visual\nrepresentations of surgical images and videos into the language feature space.\nConsequently, we establish a LVLM model, Surgical-LLaVA, fine-tuned on\ninstruction following data of surgical scenarios. Our experiments demonstrate\nthat Surgical-LLaVA exhibits impressive multi-modal chat abilities in surgical\ncontexts, occasionally displaying multi-modal behaviors on unseen instructions.\nWe conduct a quantitative evaluation of visual question-answering datasets for\nsurgical scenarios. The results show superior performance compared to previous\nworks, indicating the potential of our model to tackle more complex surgery\nscenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 AIM-FM Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.09750v1",
    "published_date": "2024-10-13 07:12:35 UTC",
    "updated_date": "2024-10-13 07:12:35 UTC"
  },
  {
    "arxiv_id": "2410.09747v3",
    "title": "t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving",
    "authors": [
      "Pengfei Hu",
      "Yuhang Qian",
      "Tianyue Zheng",
      "Ang Li",
      "Zhe Chen",
      "Yue Gao",
      "Xiuzhen Cheng",
      "Jun Luo"
    ],
    "abstract": "Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by\nautonomous vehicles (AVs), deep analytics to fuse their outputs for a robust\nperception become imperative. However, existing fusion methods often make two\nassumptions rarely holding in practice: i) similar data distributions for all\ninputs and ii) constant availability for all sensors. Because, for example,\nlidars have various resolutions and failures of radars may occur, such\nvariability often results in significant performance degradation in fusion. To\nthis end, we present tREADi, an adaptive inference system that accommodates the\nvariability of multimodal sensory data and thus enables robust and efficient\nperception. t-READi identifies variation-sensitive yet structure-specific model\nparameters; it then adapts only these parameters while keeping the rest intact.\nt-READi also leverages a cross-modality contrastive learning method to\ncompensate for the loss from missing modalities. Both functions are implemented\nto maintain compatibility with existing multimodal deep fusion methods. The\nextensive experiments evidently demonstrate that compared with the status quo\napproaches, t-READi not only improves the average inference accuracy by more\nthan 6% but also reduces the inference latency by almost 15x with the cost of\nonly 5% extra memory overhead in the worst case under realistic data and modal\nvariations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09747v3",
    "published_date": "2024-10-13 06:53:58 UTC",
    "updated_date": "2024-11-21 06:46:57 UTC"
  },
  {
    "arxiv_id": "2410.09734v1",
    "title": "Gradient-Free Neural Network Training on the Edge",
    "authors": [
      "Dotan Di Castro",
      "Omkar Joglekar",
      "Shir Kozlovsky",
      "Vladimir Tchuiev",
      "Michal Moshkovitz"
    ],
    "abstract": "Training neural networks is computationally heavy and energy-intensive. Many\nmethodologies were developed to save computational requirements and energy by\nreducing the precision of network weights at inference time and introducing\ntechniques such as rounding, stochastic rounding, and quantization. However,\nmost of these techniques still require full gradient precision at training\ntime, which makes training such models prohibitive on edge devices. This work\npresents a novel technique for training neural networks without needing\ngradients. This enables a training process where all the weights are one or two\nbits, without any hidden full precision computations. We show that it is\npossible to train models without gradient-based optimization techniques by\nidentifying erroneous contributions of each neuron towards the expected\nclassification and flipping the relevant bits using logical operations. We\ntested our method on several standard datasets and achieved performance\ncomparable to corresponding gradient-based baselines with a fraction of the\ncompute power.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09734v1",
    "published_date": "2024-10-13 05:38:39 UTC",
    "updated_date": "2024-10-13 05:38:39 UTC"
  },
  {
    "arxiv_id": "2410.09729v2",
    "title": "MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions",
    "authors": [
      "Tavish Mankash",
      "V. S. Chaithanya Kota",
      "Anish De",
      "Praveen Prakash",
      "Kshitij Jadhav"
    ],
    "abstract": "Hospitals in India still rely on handwritten medical records despite the\navailability of Electronic Medical Records (EMR), complicating statistical\nanalysis and record retrieval. Handwritten records pose a unique challenge,\nrequiring specialized data for training models to recognize medications and\ntheir recommendation patterns. While traditional handwriting recognition\napproaches employ 2-D LSTMs, recent studies have explored using Multimodal\nLarge Language Models (MLLMs) for OCR tasks. Building on this approach, we\nfocus on extracting medication names and dosages from simulated medical\nrecords. Our methodology MIRAGE (Multimodal Identification and Recognition of\nAnnotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,\nLLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical\nrecord images-fully annotated from 1,133 doctors across India. Our approach\nachieves 82% accuracy in extracting medication names and dosages.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 9 figures, 3 tables, submitted to ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.09729v2",
    "published_date": "2024-10-13 05:19:09 UTC",
    "updated_date": "2024-11-12 04:19:32 UTC"
  },
  {
    "arxiv_id": "2410.09718v2",
    "title": "A Tidal Current Speed Forecasting Model based on Multi-Periodicity Learning",
    "authors": [
      "Tengfei Cheng",
      "Yangdi Huang",
      "Yunxuan Dong"
    ],
    "abstract": "Tidal energy is one of the key components in increasing the penetration rate\nof renewable energy. The penetration of tidal energy in the electrical grid\ndepends on the accuracy of tidal current speed forecasting. Modeling\ninaccuracies hinder forecast accuracy. Previous research has primarily used\nphysical models to forecast tidal current speed. However, tidal current\nvariations influenced by the orbital periods of celestial bodies make accurate\nphysical modeling challenging. Researching the multi-periodicity of tides is\ncrucial for accurately forecasting tidal current speed. In this article, we\npropose the Wavelet-Enhanced Convolutional Network (WCN) to learn\nmulti-periodicity. The framework embeds intra-period and inter-period\nvariations of one-dimensional tidal current data into the rows and columns of a\ntwo-dimensional tensor. Then, the two-dimensional variations of the sequence\ncan be processed by convolutional kernels. We integrate a time-frequency\nanalysis method into the framework to further address local periodic features.\nAdditionally, to enhance the framework's stability, we optimize the framework's\nhyperparameters with the Tree-structured Parzen Estimator algorithm. The\nproposed framework avoids the lack of learning multi-periodicity. Compared with\nbenchmarks, the proposed framework reduces the mean absolute error and mean\nsquare error in 10-step forecasting by, at most, 90.36% and 97.56%,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09718v2",
    "published_date": "2024-10-13 04:15:05 UTC",
    "updated_date": "2025-02-04 13:44:14 UTC"
  },
  {
    "arxiv_id": "2410.09713v4",
    "title": "Agentic Information Retrieval",
    "authors": [
      "Weinan Zhang",
      "Junwei Liao",
      "Ning Li",
      "Kounianhua Du",
      "Jianghao Lin"
    ],
    "abstract": "Since the 1970s, information retrieval (IR) has long been defined as the\nprocess of acquiring relevant information items from a pre-defined corpus to\nsatisfy user information needs. Traditional IR systems, while effective in\ndomains like web search, are constrained by their reliance on static,\npre-defined information items. To this end, this paper introduces agentic\ninformation retrieval (Agentic IR), a transformative next-generation paradigm\nfor IR driven by large language models (LLMs) and AI agents. The central shift\nin agentic IR is the evolving definition of ``information'' from static,\npre-defined information items to dynamic, context-dependent information states.\nInformation state refers to a particular information context that the user is\nright in within a dynamic environment, encompassing not only the acquired\ninformation items but also real-time user preferences, contextual factors, and\ndecision-making processes. In such a way, traditional information retrieval,\nfocused on acquiring relevant information items based on user queries, can be\nnaturally extended to achieving the target information state given the user\ninstruction, which thereby defines the agentic information retrieval. We\nsystematically discuss agentic IR from various aspects, i.e., task formulation,\narchitecture, evaluation, case studies, as well as challenges and future\nprospects. We believe that the concept of agentic IR introduced in this paper\nnot only broadens the scope of information retrieval research but also lays the\nfoundation for a more adaptive, interactive, and intelligent next-generation IR\nparadigm.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, perspective paper",
    "pdf_url": "http://arxiv.org/pdf/2410.09713v4",
    "published_date": "2024-10-13 03:45:24 UTC",
    "updated_date": "2025-02-23 03:23:46 UTC"
  },
  {
    "arxiv_id": "2410.12864v1",
    "title": "Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs",
    "authors": [
      "Divyanshu Kumar",
      "Umang Jain",
      "Sahil Agarwal",
      "Prashanth Harshangi"
    ],
    "abstract": "Large Language Models (LLMs) are being adopted across a wide range of tasks,\nincluding decision-making processes in industries where bias in AI systems is a\nsignificant concern. Recent research indicates that LLMs can harbor implicit\nbiases even when they pass explicit bias evaluations. Building upon the\nframeworks of the LLM Implicit Association Test (IAT) Bias and LLM Decision\nBias, this study highlights that newer or larger language models do not\nautomatically exhibit reduced bias; in some cases, they displayed higher bias\nscores than their predecessors, such as in Meta's Llama series and OpenAI's GPT\nmodels. This suggests that increasing model complexity without deliberate bias\nmitigation strategies can unintentionally amplify existing biases. The\nvariability in bias scores within and across providers underscores the need for\nstandardized evaluation metrics and benchmarks for bias assessment. The lack of\nconsistency indicates that bias mitigation is not yet a universally prioritized\ngoal in model development, which can lead to unfair or discriminatory outcomes.\nBy broadening the detection of implicit bias, this research provides a more\ncomprehensive understanding of the biases present in advanced models and\nunderscores the critical importance of addressing these issues to ensure the\ndevelopment of fair and responsible AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12864v1",
    "published_date": "2024-10-13 03:43:18 UTC",
    "updated_date": "2024-10-13 03:43:18 UTC"
  },
  {
    "arxiv_id": "2410.09703v1",
    "title": "Universal scaling laws in quantum-probabilistic machine learning by tensor network towards interpreting representation and generalization powers",
    "authors": [
      "Sheng-Chen Bai",
      "Shi-Ju Ran"
    ],
    "abstract": "Interpreting the representation and generalization powers has been a\nlong-standing issue in the field of machine learning (ML) and artificial\nintelligence. This work contributes to uncovering the emergence of universal\nscaling laws in quantum-probabilistic ML. We take the generative tensor network\n(GTN) in the form of a matrix product state as an example and show that with an\nuntrained GTN (such as a random TN state), the negative logarithmic likelihood\n(NLL) $L$ generally increases linearly with the number of features $M$, i.e.,\n$L \\simeq k M + const$. This is a consequence of the so-called ``catastrophe of\northogonality,'' which states that quantum many-body states tend to become\nexponentially orthogonal to each other as $M$ increases. We reveal that while\ngaining information through training, the linear scaling law is suppressed by a\nnegative quadratic correction, leading to $L \\simeq \\beta M - \\alpha M^2 +\nconst$. The scaling coefficients exhibit logarithmic relationships with the\nnumber of training samples and the number of quantum channels $\\chi$. The\nemergence of the quadratic correction term in NLL for the testing (training)\nset can be regarded as evidence of the generalization (representation) power of\nGTN. Over-parameterization can be identified by the deviation in the values of\n$\\alpha$ between training and testing sets while increasing $\\chi$. We further\ninvestigate how orthogonality in the quantum feature map relates to the\nsatisfaction of quantum probabilistic interpretation, as well as to the\nrepresentation and generalization powers of GTN. The unveiling of universal\nscaling laws in quantum-probabilistic ML would be a valuable step toward\nestablishing a white-box ML scheme interpreted within the quantum probabilistic\nframework.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "quant-ph",
    "comment": "5 pages (main text) + 3 pages (appendices), 5 figures (main text) + 4\n  figures (appendices)",
    "pdf_url": "http://arxiv.org/pdf/2410.09703v1",
    "published_date": "2024-10-13 02:48:08 UTC",
    "updated_date": "2024-10-13 02:48:08 UTC"
  },
  {
    "arxiv_id": "2410.09699v1",
    "title": "Honest AI: Fine-Tuning \"Small\" Language Models to Say \"I Don't Know\", and Reducing Hallucination in RAG",
    "authors": [
      "Xinxi Chen",
      "Li Wang",
      "Wei Wu",
      "Qi Tang",
      "Yiyao Liu"
    ],
    "abstract": "Hallucination is a key roadblock for applications of Large Language Models\n(LLMs), particularly for enterprise applications that are sensitive to\ninformation accuracy. To address this issue, two general approaches have been\nexplored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated\ninformation as context, and fine-tuning the LLMs with new information and\ndesired output styles. In this paper, we propose Honest AI: a novel strategy to\nfine-tune \"small\" language models to say \"I don't know\" to reduce\nhallucination, along with several alternative RAG approaches. The solution\nranked 1st in Task 2 for the false premise question. The alternative approaches\ninclude using RAG with search engine and knowledge graph results, fine-tuning\nbase LLMs with new information and combinations of both approaches. Although\nall approaches improve the performance of the LLMs, RAG alone does not\nsignificantly improve the performance and fine-tuning is needed for better\nresults. Finally, the hybrid approach achieved the highest score in the CRAG\nbenchmark. In addition, our approach emphasizes the use of relatively small\nmodels with fewer than 10 billion parameters, promoting resource efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09699v1",
    "published_date": "2024-10-13 02:34:47 UTC",
    "updated_date": "2024-10-13 02:34:47 UTC"
  },
  {
    "arxiv_id": "2410.10901v1",
    "title": "3DS: Decomposed Difficulty Data Selection's Case Study on LLM Medical Domain Adaptation",
    "authors": [
      "Hongxin Ding",
      "Yue Fang",
      "Runchuan Zhu",
      "Xinke Jiang",
      "Jinyang Zhang",
      "Yongxin Xu",
      "Xu Chu",
      "Junfeng Zhao",
      "Yasha Wang"
    ],
    "abstract": "Large Language Models(LLMs) excel in general tasks but struggle in\nspecialized domains like healthcare due to limited domain-specific\nknowledge.Supervised Fine-Tuning(SFT) data construction for domain adaptation\noften relies on heuristic methods, such as GPT-4 annotation or manual data\nselection, with a data-centric focus on presumed diverse, high-quality\ndatasets. However, these methods overlook the model's inherent knowledge\ndistribution, introducing noise, redundancy, and irrelevant data, leading to a\nmismatch between the selected data and the model's learning task, resulting in\nsuboptimal performance. To address this, we propose a two-stage model-centric\ndata selection framework, Decomposed Difficulty Data Selection (3DS), which\naligns data with the model's knowledge distribution for optimized adaptation.\nIn Stage1, we apply Prompt-Driven Data Selection via Explicit Alignment, where\nthe the model filters irrelevant or redundant data based on its internal\nknowledge. In Stage2, we perform Decomposed Difficulty Data Selection, where\ndata selection is guided by our defined difficulty decomposition, using three\nmetrics: Instruction Understanding, Response Confidence, and Response\nCorrectness. Additionally, an attention-based importance weighting mechanism\ncaptures token importance for more accurate difficulty calibration. This\ntwo-stage approach ensures the selected data is not only aligned with the\nmodel's knowledge and preferences but also appropriately challenging for the\nmodel to learn, leading to more effective and targeted domain adaptation. In\nthe case study of the medical domain, our extensive experiments on real-world\nhealthcare datasets demonstrate the superiority of 3DS over exisiting methods\nin accuracy by over 5.29%. Our dataset and code will be open-sourced at\nhttps://anonymous.4open.science/r/3DS-E67F.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10901v1",
    "published_date": "2024-10-13 02:29:00 UTC",
    "updated_date": "2024-10-13 02:29:00 UTC"
  },
  {
    "arxiv_id": "2410.09695v3",
    "title": "Can In-context Learning Really Generalize to Out-of-distribution Tasks?",
    "authors": [
      "Qixun Wang",
      "Yifei Wang",
      "Yisen Wang",
      "Xianghua Ying"
    ],
    "abstract": "In this work, we explore the mechanism of in-context learning (ICL) on\nout-of-distribution (OOD) tasks that were not encountered during training. To\nachieve this, we conduct synthetic experiments where the objective is to learn\nOOD mathematical functions through ICL using a GPT-2 model. We reveal that\nTransformers may struggle to learn OOD task functions through ICL.\nSpecifically, ICL performance resembles implementing a function within the\npretraining hypothesis space and optimizing it with gradient descent based on\nthe in-context examples. Additionally, we investigate ICL's well-documented\nability to learn unseen abstract labels in context. We demonstrate that such\nability only manifests in the scenarios without distributional shifts and,\ntherefore, may not serve as evidence of new-task-learning ability. Furthermore,\nwe assess ICL's performance on OOD tasks when the model is pretrained on\nmultiple tasks. Both empirical and theoretical analyses demonstrate the\nexistence of the \\textbf{low-test-error preference} of ICL, where it tends to\nimplement the pretraining function that yields low test error in the testing\ncontext. We validate this through numerical experiments. This new theoretical\nresult, combined with our empirical findings, elucidates the mechanism of ICL\nin addressing OOD tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, under review",
    "pdf_url": "http://arxiv.org/pdf/2410.09695v3",
    "published_date": "2024-10-13 02:10:26 UTC",
    "updated_date": "2024-12-04 15:35:48 UTC"
  },
  {
    "arxiv_id": "2410.09693v1",
    "title": "Neural Solver Selection for Combinatorial Optimization",
    "authors": [
      "Chengrui Gao",
      "Haopu Shang",
      "Ke Xue",
      "Chao Qian"
    ],
    "abstract": "Machine learning has increasingly been employed to solve NP-hard\ncombinatorial optimization problems, resulting in the emergence of neural\nsolvers that demonstrate remarkable performance, even with minimal\ndomain-specific knowledge. To date, the community has created numerous\nopen-source neural solvers with distinct motivations and inductive biases.\nWhile considerable efforts are devoted to designing powerful single solvers,\nour findings reveal that existing solvers typically demonstrate complementary\nperformance across different problem instances. This suggests that significant\nimprovements could be achieved through effective coordination of neural solvers\nat the instance level. In this work, we propose the first general framework to\ncoordinate the neural solvers, which involves feature extraction, selection\nmodel, and selection strategy, aiming to allocate each instance to the most\nsuitable solvers. To instantiate, we collect several typical neural solvers\nwith state-of-the-art performance as alternatives, and explore various methods\nfor each component of the framework. We evaluated our framework on two\nextensively studied combinatorial optimization problems, Traveling Salesman\nProblem (TSP) and Capacitated Vehicle Routing Problem (CVRP). Experimental\nresults show that the proposed framework can effectively distribute instances\nand the resulting composite solver can achieve significantly better performance\n(e.g., reduce the optimality gap by 0.88\\% on TSPLIB and 0.71\\% on CVRPLIB)\nthan the best individual neural solver with little extra time cost.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09693v1",
    "published_date": "2024-10-13 02:05:41 UTC",
    "updated_date": "2024-10-13 02:05:41 UTC"
  },
  {
    "arxiv_id": "2410.09692v1",
    "title": "ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws",
    "authors": [
      "Hai Huang",
      "Randall Balestriero"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is the bread and butter of Large Language Model\n(LLM) finetuning. LoRA learns an additive low-rank perturbation, $AB$, of a\npretrained matrix parameter $W$ to align the model to a new task or dataset\nwith $W+AB$. We identify three core limitations to LoRA for finetuning--a\nsetting that employs limited amount of data and training steps. First, LoRA\nemploys Dropout to prevent overfitting. We prove that Dropout is only suitable\nfor long training episodes but fails to converge to a reliable regularizer for\nshort training episodes. Second, LoRA's initialization of $B$ at $0$ creates a\nslow training dynamic between $A$ and $B$. That dynamic is also exacerbated by\nDropout that further slows the escape from $0$ for $B$ which is particularly\nharmful for short training episodes. Third, the scaling factor multiplying each\nLoRA additive perturbation creates ``short-sighted'' interactions between the\nLoRA modules of different layers. Motivated by principled analysis of those\nlimitations, we find an elegant solution: a Dropout-free, scaling-free, LoRA\nwith Adaptive Learning rate--coined ALLoRA. By scaling the per sample and per\nparameter gradients with a coefficient inversely proportional to parameters'\n$\\ell_2$ norm, ALLoRA alleviates those three limitations. As a by-product,\nALLoRA removes two hyper-parameters from LoRA: the scaling factor and the\ndropout rate. Empirical results show that ALLoRA admits better accuracy than\nLoRA on various settings, including against recent LoRA variants such as\nWeight-Decomposed Low-Rank Adaptation (DoRA). Ablation studies show our\nsolution is the optimal in a family of weight-dependent / output-dependent\napproaches on various LLMs including the latest Llama3.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09692v1",
    "published_date": "2024-10-13 01:57:38 UTC",
    "updated_date": "2024-10-13 01:57:38 UTC"
  },
  {
    "arxiv_id": "2410.09691v2",
    "title": "Robust 3D Point Clouds Classification based on Declarative Defenders",
    "authors": [
      "Kaidong Li",
      "Tianxiao Zhang",
      "Cuncong Zhong",
      "Ziming Zhang",
      "Guanghui Wang"
    ],
    "abstract": "3D point cloud classification requires distinct models from 2D image\nclassification due to the divergent characteristics of the respective input\ndata. While 3D point clouds are unstructured and sparse, 2D images are\nstructured and dense. Bridging the domain gap between these two data types is a\nnon-trivial challenge to enable model interchangeability. Recent research using\nLattice Point Classifier (LPC) highlights the feasibility of cross-domain\napplicability. However, the lattice projection operation in LPC generates 2D\nimages with disconnected projected pixels. In this paper, we explore three\ndistinct algorithms for mapping 3D point clouds into 2D images. Through\nextensive experiments, we thoroughly examine and analyze their performance and\ndefense mechanisms. Leveraging current large foundation models, we scrutinize\nthe feature disparities between regular 2D images and projected 2D images. The\nproposed approaches demonstrate superior accuracy and robustness against\nadversarial attacks. The generative model-based mapping algorithms yield\nregular 2D images, further minimizing the domain gap from regular 2D\nclassification tasks. The source code is available at\nhttps://github.com/KaidongLi/pytorch-LatticePointClassifier.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09691v2",
    "published_date": "2024-10-13 01:32:38 UTC",
    "updated_date": "2024-10-19 01:52:10 UTC"
  },
  {
    "arxiv_id": "2410.09687v1",
    "title": "MoIN: Mixture of Introvert Experts to Upcycle an LLM",
    "authors": [
      "Ajinkya Tejankar",
      "KL Navaneet",
      "Ujjawal Panchal",
      "Kossar Pourahmadi",
      "Hamed Pirsiavash"
    ],
    "abstract": "The goal of this paper is to improve (upcycle) an existing large language\nmodel without the prohibitive requirements of continued pre-training of the\nfull-model. The idea is to split the pre-training data into semantically\nrelevant groups and train an expert on each subset. An expert takes the form of\na lightweight adapter added on the top of a frozen base model. During\ninference, an incoming query is first routed to the most relevant expert which\nis then loaded onto the base model for the forward pass. Unlike typical Mixture\nof Experts (MoE) models, the experts in our method do not work with other\nexperts for a single query. Hence, we dub them \"introvert\" experts. Freezing\nthe base model and keeping the experts as lightweight adapters allows extreme\nparallelism during training and inference. Training of all experts can be done\nin parallel without any communication channels between them. Similarly, the\ninference can also be heavily parallelized by distributing experts on different\nGPUs and routing each request to the GPU containing its relevant expert. We\nimplement a proof-of-concept version of this method and show the validity of\nour approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09687v1",
    "published_date": "2024-10-13 01:11:04 UTC",
    "updated_date": "2024-10-13 01:11:04 UTC"
  },
  {
    "arxiv_id": "2410.09686v2",
    "title": "Generalization of Compositional Tasks with Logical Specification via Implicit Planning",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "abstract": "In this study, we address the challenge of learning generalizable policies\nfor compositional tasks defined by logical specifications. These tasks consist\nof multiple temporally extended sub-tasks. Due to the sub-task\ninter-dependencies and sparse reward issue in long-horizon tasks, existing\nreinforcement learning (RL) approaches, such as task-conditioned and\ngoal-conditioned policies, continue to struggle with slow convergence and\nsub-optimal performance in generalizing to compositional tasks. To overcome\nthese limitations, we introduce a new hierarchical RL framework that enhances\nthe efficiency and optimality of task generalization. At the high level, we\npresent an implicit planner specifically designed for generalizing\ncompositional tasks. This planner selects the next sub-task and estimates the\nmulti-step return for completing the remaining task to complete from the\ncurrent state. It learns a latent transition model and performs planning in the\nlatent space by using a graph neural network (GNN). Subsequently, the\nhigh-level planner's selected sub-task guides the low-level agent to\neffectively handle long-horizon tasks, while the multi-step return encourages\nthe low-level policy to account for future sub-task dependencies, enhancing its\noptimality. We conduct comprehensive experiments to demonstrate the framework's\nadvantages over previous methods in terms of both efficiency and optimality.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09686v2",
    "published_date": "2024-10-13 00:57:10 UTC",
    "updated_date": "2024-11-02 17:17:32 UTC"
  },
  {
    "arxiv_id": "2410.09681v3",
    "title": "LoRD: Adapting Differentiable Driving Policies to Distribution Shifts",
    "authors": [
      "Christopher Diehl",
      "Peter Karkus",
      "Sushant Veer",
      "Marco Pavone",
      "Torsten Bertram"
    ],
    "abstract": "Distribution shifts between operational domains can severely affect the\nperformance of learned models in self-driving vehicles (SDVs). While this is a\nwell-established problem, prior work has mostly explored naive solutions such\nas fine-tuning, focusing on the motion prediction task. In this work, we\nexplore novel adaptation strategies for differentiable autonomy stacks\nconsisting of prediction, planning, and control, perform evaluation in\nclosed-loop, and investigate the often-overlooked issue of catastrophic\nforgetting. Specifically, we introduce two simple yet effective techniques: a\nlow-rank residual decoder (LoRD) and multi-task fine-tuning. Through\nexperiments across three models conducted on two real-world autonomous driving\ndatasets (nuPlan, exiD), we demonstrate the effectiveness of our methods and\nhighlight a significant performance gap between open-loop and closed-loop\nevaluation in prior approaches. Our approach improves forgetting by up to\n23.33% and the closed-loop OOD driving score by 9.93% in comparison to standard\nfine-tuning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE International Conference on Robotics & Automation, ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.09681v3",
    "published_date": "2024-10-13 00:36:11 UTC",
    "updated_date": "2025-03-28 14:35:43 UTC"
  }
]