{
  "date": "2025-04-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-03 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的鲁棒性、解释性和应用创新，包括 LLM 在医疗、科学和强化学习领域的进展，其中 Multi-SWE-bench 和 VEGAS 等论文因其新颖框架和实际影响而令人印象深刻，同时强调了 AI 安全和知识删除等话题。\n\n### 重点论文讨论\n我们先聊聊今天最引人注目的论文，这些涉及 AI 解释性、基准构建和医疗应用，具有潜在话题度和实际价值。相关论文会放在一起讨论。\n\n1. **Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving（多语言问题解决基准）**  \n   这篇论文构建了一个多语言基准（包括 Java、TypeScript 等），包含 1632 个实例，用于评估 LLM 在代码问题解决中的性能。主要贡献是提供了一个全面数据集和评估框架，实验显示 LLM 在多语言场景下的性能提升显著，并启发了未来强化学习研究。\n\n2. **VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence（视觉可解释和基于的社交智能）**  \n   作为相关补充，这篇论文提出一个生成式框架，支持视觉引导的社交智能查询。主要发现是通过多模态提示和微调，提升了模型在社交任务中的解释性和准确性，实验在多个基准上表现出色。\n\n3. **AD-GPT: Large Language Models in Alzheimer's Disease（阿尔茨海默病中的大语言模型）**  \n   这篇论文引入 AD-GPT，一种针对阿尔茨海默病的领域特定 LLM，结合 Llama3 和 BERT 优化了基因和神经生物信息检索。主要贡献是提升了模型在医疗任务中的精度和可靠性，为生物标记物发现提供了新工具。\n\n4. **MegaMath: Pushing the Limits of Open Math Corpora（扩展开源数学语料库）**  \n   聚焦数学推理，这篇论文构建了 371B 标记的 MegaMath 数据集，整合网络数据和代码来源。主要发现是通过高效数据处理，提升了 LLM 在数学任务中的性能，为科学 AI 预训练设定了新标准。\n\n5. **JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model（基于自适应记忆的视觉语言模型越狱检测）**  \n   在 AI 安全主题下，这篇论文提出 JailDAM 框架，用于检测视觉语言模型的越狱攻击。主要贡献是利用记忆机制和策略驱动，提高了检测的鲁棒性和效率，实验在多个基准上超越了现有方法。\n\n其他相关论文，如 \"Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning\"（鲁棒强化学习从人类反馈的 LLM 微调），则通过 DPO 优化提升了模型安全性和性能，但细节较常规。\n\n### 快速掠过其他论文\n今天还有大量论文涉及强化学习、图像处理和量子计算等领域，以下快速总结重要性较低的几篇，保留核心术语：\n\n- **Context-Aware Self-Adaptation for Domain Generalization（基于上下文的自适应域泛化）**：提出 CASA 方法，提升模型在未见域的泛化性能，主要发现是通过自适应模块优化预测能力。\n- **FlowKV: A Disaggregated Inference Framework（解耦推理框架）**：设计了低延迟 KV 缓存传输框架，提高了 LLM 推理效率。\n- **ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation（提升多视图一致性的零样本文本到3D生成）**：通过优化 score distillation 缓解多视图偏差问题。\n- **Efficient Model Editing with Task-Localized Sparse Fine-tuning（任务本地化稀疏微调的模型编辑）**：使用稀疏微调减少计算开销，提升模型编辑效率。\n- **SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning（基于神经网络的强化学习中的符号知识推理）**：整合符号推理模块，提高强化学习代理的鲁棒性。\n\n剩余论文（如量子退火应用、图像分割等）多为技术细节优化，贡献较局部，例如 \"Steiner Traveling Salesman Problem with Quantum Annealing\"（Steiner 旅行 salesman 问题量子退火），主要探索量子方法在优化问题中的应用，但影响力有限，故从略。\n\n今天的快报到此结束，arXiv 持续更新，欢迎关注明日内容！",
  "papers": [
    {
      "arxiv_id": "2504.03085v2",
      "title": "From Questions to Insights: Exploring XAI Challenges Reported on Stack Overflow Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Saumendu Roy",
        "Saikat Mondal",
        "Banani Roy",
        "Chanchal Roy"
      ],
      "abstract": "The lack of interpretability is a major barrier that limits the practical\nusage of AI models. Several eXplainable AI (XAI) techniques (e.g., SHAP, LIME)\nhave been employed to interpret these models' performance. However, users often\nface challenges when leveraging these techniques in real-world scenarios and\nthus submit questions in technical Q&A forums like Stack Overflow (SO) to\nresolve these challenges. We conducted an exploratory study to expose these\nchallenges, their severity, and features that can make XAI techniques more\naccessible and easier to use. Our contributions to this study are fourfold.\nFirst, we manually analyzed 663 SO questions that discussed challenges related\nto XAI techniques. Our careful investigation produced a catalog of seven\nchallenges (e.g., disagreement issues). We then analyzed their prevalence and\nfound that model integration and disagreement issues emerged as the most\nprevalent challenges. Second, we attempt to estimate the severity of each XAI\nchallenge by determining the correlation between challenge types and answer\nmetadata (e.g., the presence of accepted answers). Our analysis suggests that\nmodel integration issues is the most severe challenge. Third, we attempt to\nperceive the severity of these challenges based on practitioners' ability to\nuse XAI techniques effectively in their work. Practitioners' responses suggest\nthat disagreement issues most severely affect the use of XAI techniques.\nFourth, we seek agreement from practitioners on improvements or features that\ncould make XAI techniques more accessible and user-friendly. The majority of\nthem suggest consistency in explanations and simplified integration. Our study\nfindings might (a) help to enhance the accessibility and usability of XAI and\n(b) act as the initial benchmark that can inspire future research.",
      "tldr_zh": "这篇论文通过分析 Stack Overflow 上 663 个用户问题，探索了 eXplainable AI (XAI) 技术的实际挑战，如 model integration 和 disagreement issues，并识别出七个主要挑战类别。研究评估了这些挑战的严重性，发现 model integration 通过回答元数据（如接受答案率）显示最严重，而从业者反馈则强调 disagreement issues 对 XAI 使用影响最大。最终，论文建议改进措施，包括 consistency in explanations 和 simplified integration，以提升 XAI 的可访问性和可用性，并为未来研究提供基准。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.03085v2",
      "published_date": "2025-04-03 23:33:46 UTC",
      "updated_date": "2025-04-17 23:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:04:18.680345"
    },
    {
      "arxiv_id": "2504.03077v1",
      "title": "Integrating Identity-Based Identification against Adaptive Adversaries in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Kacper Szelag",
        "Ji-Jian Chin",
        "Lauren Ansell",
        "Sook-Chin Yip"
      ],
      "abstract": "Federated Learning (FL) has recently emerged as a promising paradigm for\nprivacy-preserving, distributed machine learning. However, FL systems face\nsignificant security threats, particularly from adaptive adversaries capable of\nmodifying their attack strategies to evade detection. One such threat is the\npresence of Reconnecting Malicious Clients (RMCs), which exploit FLs open\nconnectivity by reconnecting to the system with modified attack strategies. To\naddress this vulnerability, we propose integration of Identity-Based\nIdentification (IBI) as a security measure within FL environments. By\nleveraging IBI, we enable FL systems to authenticate clients based on\ncryptographic identity schemes, effectively preventing previously disconnected\nmalicious clients from re-entering the system. Our approach is implemented\nusing the TNC-IBI (Tan-Ng-Chin) scheme over elliptic curves to ensure\ncomputational efficiency, particularly in resource-constrained environments\nlike Internet of Things (IoT). Experimental results demonstrate that\nintegrating IBI with secure aggregation algorithms, such as Krum and Trimmed\nMean, significantly improves FL robustness by mitigating the impact of RMCs. We\nfurther discuss the broader implications of IBI in FL security, highlighting\nresearch directions for adaptive adversary detection, reputation-based\nmechanisms, and the applicability of identity-based cryptographic frameworks in\ndecentralized FL architectures. Our findings advocate for a holistic approach\nto FL security, emphasizing the necessity of proactive defence strategies\nagainst evolving adaptive adversarial threats.",
      "tldr_zh": "本文针对 Federated Learning (FL) 中的安全威胁，特别是自适应攻击者和 Reconnecting Malicious Clients (RMCs)，提出整合 Identity-Based Identification (IBI) 作为防护措施，以基于加密身份方案认证客户端并防止恶意实体重新连接。方法采用 TNC-IBI 方案在椭圆曲线之上实现，确保在资源受限环境如 Internet of Things (IoT) 中的计算效率。实验结果表明，IBI 与安全聚合算法如 Krum 和 Trimmed Mean 结合后，能显著提升 FL 的鲁棒性，减轻 RMCs 的影响。论文进一步讨论了 IBI 在自适应攻击检测、基于声誉的机制以及去中心化 FL 架构中的潜在应用，强调了整体性防御策略对抗演变威胁的重要性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 5 figures, research article, IEEE possible publication (in\n  submission)",
      "pdf_url": "http://arxiv.org/pdf/2504.03077v1",
      "published_date": "2025-04-03 22:58:27 UTC",
      "updated_date": "2025-04-03 22:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:04:32.221918"
    },
    {
      "arxiv_id": "2504.03071v1",
      "title": "AD-GPT: Large Language Models in Alzheimer's Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Liu",
        "Lintao Tang",
        "Zeliang Sun",
        "Zhengliang Liu",
        "Yanjun Lyu",
        "Wei Ruan",
        "Yangshuang Xu",
        "Liang Shan",
        "Jiyoon Shin",
        "Xiaohe Chen",
        "Dajiang Zhu",
        "Tianming Liu",
        "Rongjie Liu",
        "Chao Huang"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools for medical\ninformation retrieval, yet their accuracy and depth remain limited in\nspecialized domains such as Alzheimer's disease (AD), a growing global health\nchallenge. To address this gap, we introduce AD-GPT, a domain-specific\ngenerative pre-trained transformer designed to enhance the retrieval and\nanalysis of AD-related genetic and neurobiological information. AD-GPT\nintegrates diverse biomedical data sources, including potential AD-associated\ngenes, molecular genetic information, and key gene variants linked to brain\nregions. We develop a stacked LLM architecture combining Llama3 and BERT,\noptimized for four critical tasks in AD research: (1) genetic information\nretrieval, (2) gene-brain region relationship assessment, (3) gene-AD\nrelationship analysis, and (4) brain region-AD relationship mapping.\nComparative evaluations against state-of-the-art LLMs demonstrate AD-GPT's\nsuperior precision and reliability across these tasks, underscoring its\npotential as a robust and specialized AI tool for advancing AD research and\nbiomarker discovery.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）在阿尔茨海默病（Alzheimer's Disease, AD）领域的准确性和深度不足问题，引入了AD-GPT，一种领域特定的生成预训练Transformer。AD-GPT整合了多样生物医学数据源，包括AD相关基因、分子遗传信息和基因变异，并采用堆叠LLM架构结合Llama3和BERT，优化了四个关键任务：遗传信息检索、基因-脑区关系评估、基因-AD关系分析以及脑区-AD关系映射。与最先进LLMs相比，AD-GPT展示了更高的精确性和可靠性，有望成为推进AD研究和生物标志物发现的强大AI工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03071v1",
      "published_date": "2025-04-03 22:49:10 UTC",
      "updated_date": "2025-04-03 22:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:04:41.968010"
    },
    {
      "arxiv_id": "2504.03069v1",
      "title": "Properties of Fixed Points of Generalised Extra Gradient Methods Applied to Min-Max Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Ali Farzin",
        "Yuen-Man Pun",
        "Philipp Braun",
        "Iman Shames"
      ],
      "abstract": "This paper studies properties of fixed points of generalised Extra-gradient\n(GEG) algorithms applied to min-max problems. We discuss connections between\nsaddle points of the objective function of the min-max problem and GEG fixed\npoints. We show that, under appropriate step-size selections, the set of saddle\npoints (Nash equilibria) is a subset of stable fixed points of GEG. Convergence\nproperties of the GEG algorithm are obtained through a stability analysis of a\ndiscrete-time dynamical system. The results and benefits when compared to\nexisting methods are illustrated through numerical examples.",
      "tldr_zh": "这篇论文探讨了广义额外梯度(Generalised Extra-gradient, GEG)算法应用于最小-最大(min-max)问题的固定点性质，并揭示了目标函数鞍点(saddle points)与GEG固定点之间的联系。研究证明，在适当步长选择下，鞍点集(Nash equilibria)是GEG稳定固定点的一个子集，并通过离散时间动力系统的稳定性分析确立了GEG算法的收敛属性。最终，通过数值例子展示了GEG相对于现有方法的优势，提高了对min-max问题的处理效率。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03069v1",
      "published_date": "2025-04-03 22:48:39 UTC",
      "updated_date": "2025-04-03 22:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:04:54.398357"
    },
    {
      "arxiv_id": "2504.03068v2",
      "title": "Design of AI-Powered Tool for Self-Regulation Support in Programming Education",
      "title_zh": "翻译失败",
      "authors": [
        "Huiyong Li",
        "Boxuan Ma"
      ],
      "abstract": "Large Language Model (LLM) tools have demonstrated their potential to deliver\nhigh-quality assistance by providing instant, personalized feedback that is\ncrucial for effective programming education. However, many of these tools\noperate independently from institutional Learning Management Systems, which\ncreates a significant disconnect. This isolation limits the ability to leverage\nlearning materials and exercise context for generating tailored, context-aware\nfeedback. Furthermore, previous research on self-regulated learning and LLM\nsupport mainly focused on knowledge acquisition, not the development of\nimportant self-regulation skills. To address these challenges, we developed\nCodeRunner Agent, an LLM-based programming assistant that integrates the\nCodeRunner, a student-submitted code executing and automated grading plugin in\nMoodle. CodeRunner Agent empowers educators to customize AI-generated feedback\nby incorporating detailed context from lecture materials, programming\nquestions, student answers, and execution results. Additionally, it enhances\nstudents' self-regulated learning by providing strategy-based AI responses.\nThis integrated, context-aware, and skill-focused approach offers promising\navenues for data-driven improvements in programming education.",
      "tldr_zh": "该论文设计了一个基于 Large Language Model (LLM) 的工具 CodeRunner Agent，用于支持编程教育中的自调节学习（self-regulated learning）。该工具集成到 Moodle 的 CodeRunner 插件中，能利用讲座材料、编程问题、学生答案和执行结果等上下文，提供个性化和策略-based AI 反馈，从而解决现有 LLM 工具与学习管理系统脱节的问题。相比以往重点于知识获取的研究，CodeRunner Agent 强调自调节技能的培养，并为编程教育带来数据驱动的改进潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03068v2",
      "published_date": "2025-04-03 22:47:33 UTC",
      "updated_date": "2025-04-07 01:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:05:06.567042"
    },
    {
      "arxiv_id": "2504.03064v1",
      "title": "Context-Aware Self-Adaptation for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yan",
        "Yuhong Guo"
      ],
      "abstract": "Domain generalization aims at developing suitable learning algorithms in\nsource training domains such that the model learned can generalize well on a\ndifferent unseen testing domain. We present a novel two-stage approach called\nContext-Aware Self-Adaptation (CASA) for domain generalization. CASA simulates\nan approximate meta-generalization scenario and incorporates a self-adaptation\nmodule to adjust pre-trained meta source models to the meta-target domains\nwhile maintaining their predictive capability on the meta-source domains. The\ncore concept of self-adaptation involves leveraging contextual information,\nsuch as the mean of mini-batch features, as domain knowledge to automatically\nadapt a model trained in the first stage to new contexts in the second stage.\nLastly, we utilize an ensemble of multiple meta-source models to perform\ninference on the testing domain. Experimental results demonstrate that our\nproposed method achieves state-of-the-art performance on standard benchmarks.",
      "tldr_zh": "本论文针对 Domain Generalization 提出了一种名为 Context-Aware Self-Adaptation (CASA) 的两阶段方法，旨在训练模型在源域上表现良好，同时在未见测试域上实现泛化。CASA 通过模拟 meta-generalization 场景，利用自适应模块（如基于 mini-batch 特征均值的上下文信息）自动调整预训练模型，以保持其在源域的预测能力。实验结果显示，该方法在标准基准上达到了 state-of-the-art 性能，并通过多个 meta-source 模型的集成进行测试域推理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2023 AdvML Frontiers workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.03064v1",
      "published_date": "2025-04-03 22:33:38 UTC",
      "updated_date": "2025-04-03 22:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:05:19.120180"
    },
    {
      "arxiv_id": "2504.03052v1",
      "title": "Cooperative Inference for Real-Time 3D Human Pose Estimation in Multi-Device Edge Networks",
      "title_zh": "多设备边缘网络中实时三维人体姿态估计的合作推理",
      "authors": [
        "Hyun-Ho Choi",
        "Kangsoo Kim",
        "Ki-Ho Lee",
        "Kisong Lee"
      ],
      "abstract": "Accurate and real-time three-dimensional (3D) pose estimation is challenging\nin resource-constrained and dynamic environments owing to its high\ncomputational complexity. To address this issue, this study proposes a novel\ncooperative inference method for real-time 3D human pose estimation in mobile\nedge computing (MEC) networks. In the proposed method, multiple end devices\nequipped with lightweight inference models employ dual confidence thresholds to\nfilter ambiguous images. Only the filtered images are offloaded to an edge\nserver with a more powerful inference model for re-evaluation, thereby\nimproving the estimation accuracy under computational and communication\nconstraints. We numerically analyze the performance of the proposed inference\nmethod in terms of the inference accuracy and end-to-end delay and formulate a\njoint optimization problem to derive the optimal confidence thresholds and\ntransmission time for each device, with the objective of minimizing the mean\nper-joint position error (MPJPE) while satisfying the required end-to-end delay\nconstraint. To solve this problem, we demonstrate that minimizing the MPJPE is\nequivalent to maximizing the sum of the inference accuracies for all devices,\ndecompose the problem into manageable subproblems, and present a low-complexity\noptimization algorithm to obtain a near-optimal solution. The experimental\nresults show that a trade-off exists between the MPJPE and end-to-end delay\ndepending on the confidence thresholds. Furthermore, the results confirm that\nthe proposed cooperative inference method achieves a significant reduction in\nthe MPJPE through the optimal selection of confidence thresholds and\ntransmission times, while consistently satisfying the end-to-end delay\nrequirement in various MEC environments.",
      "tldr_zh": "这篇论文提出了一种合作推理方法，用于在多设备边缘网络中实现实时 3D Human Pose Estimation，以应对资源受限环境下的高计算复杂度问题。该方法让多个端设备使用轻量级模型和双置信度阈值过滤模糊图像，仅将筛选后的图像卸载到边缘服务器进行重新评估，从而在计算和通信约束下提升估计准确性。论文通过数值分析和联合优化问题，优化了每个设备的置信度阈值和传输时间，以最小化 Mean Per-Joint Position Error (MPJPE) 并满足端到端延迟要求。实验结果表明，该方法显著降低了 MPJPE，同时在各种 Mobile Edge Computing (MEC) 环境中保持延迟约束的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.03052v1",
      "published_date": "2025-04-03 21:58:29 UTC",
      "updated_date": "2025-04-03 21:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:05:33.283189"
    },
    {
      "arxiv_id": "2504.03051v1",
      "title": "Task as Context Prompting for Accurate Medical Symptom Coding Using Large Language Models",
      "title_zh": "任务作为上下文提示，用于准确医疗症状编码，使用大型语言模型",
      "authors": [
        "Chengyang He",
        "Wenlong Zhang",
        "Violet Xinying Chen",
        "Yue Ning",
        "Ping Wang"
      ],
      "abstract": "Accurate medical symptom coding from unstructured clinical text, such as\nvaccine safety reports, is a critical task with applications in\npharmacovigilance and safety monitoring. Symptom coding, as tailored in this\nstudy, involves identifying and linking nuanced symptom mentions to\nstandardized vocabularies like MedDRA, differentiating it from broader medical\ncoding tasks. Traditional approaches to this task, which treat symptom\nextraction and linking as independent workflows, often fail to handle the\nvariability and complexity of clinical narratives, especially for rare cases.\nRecent advancements in Large Language Models (LLMs) offer new opportunities but\nface challenges in achieving consistent performance. To address these issues,\nwe propose Task as Context (TACO) Prompting, a novel framework that unifies\nextraction and linking tasks by embedding task-specific context into LLM\nprompts. Our study also introduces SYMPCODER, a human-annotated dataset derived\nfrom Vaccine Adverse Event Reporting System (VAERS) reports, and a two-stage\nevaluation framework to comprehensively assess both symptom linking and mention\nfidelity. Our comprehensive evaluation of multiple LLMs, including Llama2-chat,\nJackalope-7b, GPT-3.5 Turbo, GPT-4 Turbo, and GPT-4o, demonstrates TACO's\neffectiveness in improving flexibility and accuracy for tailored tasks like\nsymptom coding, paving the way for more specific coding tasks and advancing\nclinical text processing methodologies.",
      "tldr_zh": "本研究提出Task as Context (TACO) Prompting框架，利用Large Language Models (LLMs)来提升医疗症状编码的准确性，该框架通过在LLM提示中嵌入任务特定上下文，将症状提取和链接任务统一处理，从而应对临床文本（如疫苗安全报告）的变异性和复杂性。研究引入了SYMPCODER数据集，该数据集基于Vaccine Adverse Event Reporting System (VAERS)报告进行人工标注，并开发了一个两阶段评估框架来评估症状链接和提及保真度。实验结果显示，TACO在多种LLMs（如Llama2-chat、GPT-3.5 Turbo和GPT-4o）上显著提高了准确性和灵活性，为MedDRA等标准化词汇表的应用以及临床文本处理方法提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 5 figures, 5 Tables, ACM/IEEE International Conference on\n  Connected Health: Applications, Systems and Engineering Technologies (CHASE\n  '25), June 24--26, 2025, New York, NY, USA",
      "pdf_url": "http://arxiv.org/pdf/2504.03051v1",
      "published_date": "2025-04-03 21:57:17 UTC",
      "updated_date": "2025-04-03 21:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:05:42.847990"
    },
    {
      "arxiv_id": "2504.03040v1",
      "title": "Safety Modulation: Enhancing Safety in Reinforcement Learning through Cost-Modulated Rewards",
      "title_zh": "安全调制：通过成本调制奖励增强强化学习中的安全",
      "authors": [
        "Hanping Zhang",
        "Yuhong Guo"
      ],
      "abstract": "Safe Reinforcement Learning (Safe RL) aims to train an RL agent to maximize\nits performance in real-world environments while adhering to safety\nconstraints, as exceeding safety violation limits can result in severe\nconsequences. In this paper, we propose a novel safe RL approach called Safety\nModulated Policy Optimization (SMPO), which enables safe policy function\nlearning within the standard policy optimization framework through safety\nmodulated rewards. In particular, we consider safety violation costs as\nfeedback from the RL environments that are parallel to the standard awards, and\nintroduce a Q-cost function as safety critic to estimate expected future\ncumulative costs. Then we propose to modulate the rewards using a cost-aware\nweighting function, which is carefully designed to ensure the safety limits\nbased on the estimation of the safety critic, while maximizing the expected\nrewards. The policy function and the safety critic are simultaneously learned\nthrough gradient descent during online interactions with the environment. We\nconduct experiments using multiple RL environments and the experimental results\ndemonstrate that our method outperforms several classic and state-of-the-art\ncomparison methods in terms of overall safe RL performance.",
      "tldr_zh": "该论文提出了一种名为 Safety Modulated Policy Optimization (SMPO) 的新方法，用于 Safe Reinforcement Learning (Safe RL)，旨在通过成本调节奖励来提升代理在最大化性能的同时遵守安全约束。SMPO 引入 Q-cost function 作为 safety critic 来估计未来累积成本，并使用 cost-aware weighting function 调节奖励，确保安全限制不被违反，同时优化预期奖励。实验结果显示，该方法在多个 RL 环境上优于经典和最先进的方法，在整体 Safe RL 性能方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03040v1",
      "published_date": "2025-04-03 21:35:22 UTC",
      "updated_date": "2025-04-03 21:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:05:54.047806"
    },
    {
      "arxiv_id": "2504.08775v1",
      "title": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures",
      "title_zh": "在不同LLM架构中，相似深度的层生成相似的激活",
      "authors": [
        "Christopher Wolfram",
        "Aaron Schein"
      ],
      "abstract": "How do the latent spaces used by independently-trained LLMs relate to one\nanother? We study the nearest neighbor relationships induced by activations at\ndifferent layers of 24 open-weight LLMs, and find that they 1) tend to vary\nfrom layer to layer within a model, and 2) are approximately shared between\ncorresponding layers of different models. Claim 2 shows that these nearest\nneighbor relationships are not arbitrary, as they are shared across models, but\nClaim 1 shows that they are not \"obvious\" either, as there is no single set of\nnearest neighbor relationships that is universally shared. Together, these\nsuggest that LLMs generate a progression of activation geometries from layer to\nlayer, but that this entire progression is largely shared between models,\nstretched and squeezed to fit into different architectures.",
      "tldr_zh": "本研究探讨了独立训练的大型语言模型（LLMs）之间的潜在空间关系，通过分析24个开源LLMs的不同层级的激活（activations）最近邻关系（nearest neighbor relationships）。结果显示，同一模型内各层级的最近邻关系会随层级变化，而不同模型的对应层级则表现出相似性，这表明这些关系并非任意生成。总体而言，LLMs从一层到另一层生成激活几何的进展是跨模型共享的，但会根据不同架构进行调整，从而为理解LLM内部机制提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08775v1",
      "published_date": "2025-04-03 21:02:30 UTC",
      "updated_date": "2025-04-03 21:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:06:07.840209"
    },
    {
      "arxiv_id": "2504.03024v1",
      "title": "Deep Reinforcement Learning via Object-Centric Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jannis Blüml",
        "Cedric Derstroff",
        "Bjarne Gregori",
        "Elisabeth Dillies",
        "Quentin Delfosse",
        "Kristian Kersting"
      ],
      "abstract": "Deep reinforcement learning agents, trained on raw pixel inputs, often fail\nto generalize beyond their training environments, relying on spurious\ncorrelations and irrelevant background details. To address this issue,\nobject-centric agents have recently emerged. However, they require different\nrepresentations tailored to the task specifications. Contrary to deep agents,\nno single object-centric architecture can be applied to any environment.\nInspired by principles of cognitive science and Occam's Razor, we introduce\nObject-Centric Attention via Masking (OCCAM), which selectively preserves\ntask-relevant entities while filtering out irrelevant visual information.\nSpecifically, OCCAM takes advantage of the object-centric inductive bias.\nEmpirical evaluations on Atari benchmarks demonstrate that OCCAM significantly\nimproves robustness to novel perturbations and reduces sample complexity while\nshowing similar or improved performance compared to conventional pixel-based\nRL. These results suggest that structured abstraction can enhance\ngeneralization without requiring explicit symbolic representations or\ndomain-specific object extraction pipelines.",
      "tldr_zh": "该研究针对深度强化学习（Deep Reinforcement Learning）代理在原始像素输入上训练时，依赖虚假相关性和无关背景细节导致的泛化失败问题，提出了一种名为 OCCAM 的物体中心注意力（Object-Centric Attention via Masking）方法。OCCAM 受认知科学和奥卡姆剃刀原则启发，通过选择性保留任务相关实体并过滤无关视觉信息，利用物体中心归纳偏差来构建通用架构。实验在 Atari 基准测试中表明，OCCAM 显著提升了对新扰动的鲁棒性，降低了样本复杂度，并与传统像素-based RL 相比表现出类似或更好的性能。这些结果证明，结构化抽象能增强泛化能力，而无需显式符号表示或特定领域物体提取管道。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 11 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.03024v1",
      "published_date": "2025-04-03 20:48:27 UTC",
      "updated_date": "2025-04-03 20:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:06:19.928288"
    },
    {
      "arxiv_id": "2504.03022v1",
      "title": "The Dual-Route Model of Induction",
      "title_zh": "翻译失败",
      "authors": [
        "Sheridan Feucht",
        "Eric Todd",
        "Byron Wallace",
        "David Bau"
      ],
      "abstract": "Prior work on in-context copying has shown the existence of induction heads,\nwhich attend to and promote individual tokens during copying. In this work we\nintroduce a new type of induction head: concept-level induction heads, which\ncopy entire lexical units instead of individual tokens. Concept induction heads\nlearn to attend to the ends of multi-token words throughout training, working\nin parallel with token-level induction heads to copy meaningful text. We show\nthat these heads are responsible for semantic tasks like word-level\ntranslation, whereas token induction heads are vital for tasks that can only be\ndone verbatim, like copying nonsense tokens. These two \"routes\" operate\nindependently: in fact, we show that ablation of token induction heads causes\nmodels to paraphrase where they would otherwise copy verbatim. In light of\nthese findings, we argue that although token induction heads are vital for\nspecific tasks, concept induction heads may be more broadly relevant for\nin-context learning.",
      "tldr_zh": "本研究提出了一种双路线归纳模型（The Dual-Route Model of Induction），引入概念级别归纳头（concept-level induction heads），这些头能复制整个词汇单位而非单个 token，与 token-level induction heads 并行工作。实验显示，概念级别归纳头主要负责语义任务，如单词级翻译，而 token-level induction heads 则关键于逐字复制任务，如处理无意义 token；二者独立运作，消融 token-level heads 会使模型转向改述。总体而言，该模型强调概念级别归纳头在 in-context learning 中的更广泛适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "36 pages, 39 figures. Code and data at https://dualroute.baulab.info",
      "pdf_url": "http://arxiv.org/pdf/2504.03022v1",
      "published_date": "2025-04-03 20:40:31 UTC",
      "updated_date": "2025-04-03 20:40:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:06:31.094473"
    },
    {
      "arxiv_id": "2504.02984v1",
      "title": "Language Models Guidance with Multi-Aspect-Cueing: A Case Study for Competitor Analysis",
      "title_zh": "多方面提示下的语言模型指导：竞争者分析的案例研究",
      "authors": [
        "Amir Hadifar",
        "Christopher Ochs",
        "Arjan Van Ewijk"
      ],
      "abstract": "Competitor analysis is essential in modern business due to the influence of\nindustry rivals on strategic planning. It involves assessing multiple aspects\nand balancing trade-offs to make informed decisions. Recent Large Language\nModels (LLMs) have demonstrated impressive capabilities to reason about such\ntrade-offs but grapple with inherent limitations such as a lack of knowledge\nabout contemporary or future realities and an incomplete understanding of a\nmarket's competitive landscape. In this paper, we address this gap by\nincorporating business aspects into LLMs to enhance their understanding of a\ncompetitive market. Through quantitative and qualitative experiments, we\nillustrate how integrating such aspects consistently improves model\nperformance, thereby enhancing analytical efficacy in competitor analysis.",
      "tldr_zh": "本文研究了如何通过Multi-Aspect-Cueing提升Large Language Models (LLMs)在竞争对手分析中的指导能力，以解决LLMs在当代市场知识和竞争格局理解方面的局限性。研究方法涉及将商业方面整合到LLMs中，帮助模型更好地评估多个因素并权衡决策。定量和定性实验结果显示，这种整合显著提高了模型的分析效能，为商业战略规划提供了更可靠的支持。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02984v1",
      "published_date": "2025-04-03 19:18:11 UTC",
      "updated_date": "2025-04-03 19:18:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:06:42.604251"
    },
    {
      "arxiv_id": "2504.02976v1",
      "title": "Localized Definitions and Distributed Reasoning: A Proof-of-Concept Mechanistic Interpretability Study via Activation Patching",
      "title_zh": "局部化定义和分布式推理：通过激活修补的概念验证机制解释性研究",
      "authors": [
        "Nooshin Bahador"
      ],
      "abstract": "This study investigates the localization of knowledge representation in\nfine-tuned GPT-2 models using Causal Layer Attribution via Activation Patching\n(CLAP), a method that identifies critical neural layers responsible for correct\nanswer generation. The model was fine-tuned on 9,958 PubMed abstracts\n(epilepsy: 20,595 mentions, EEG: 11,674 mentions, seizure: 13,921 mentions)\nusing two configurations with validation loss monitoring for early stopping.\nCLAP involved (1) caching clean (correct answer) and corrupted (incorrect\nanswer) activations, (2) computing logit difference to quantify model\npreference, and (3) patching corrupted activations with clean ones to assess\nrecovery. Results revealed three findings: First, patching the first\nfeedforward layer recovered 56% of correct preference, demonstrating that\nassociative knowledge is distributed across multiple layers. Second, patching\nthe final output layer completely restored accuracy (100% recovery), indicating\nthat definitional knowledge is localised. The stronger clean logit difference\nfor definitional questions further supports this localized representation.\nThird, minimal recovery from convolutional layer patching (13.6%) suggests\nlow-level features contribute marginally to high-level reasoning. Statistical\nanalysis confirmed significant layer-specific effects (p<0.01). These findings\ndemonstrate that factual knowledge is more localized and associative knowledge\ndepends on distributed representations. We also showed that editing efficacy\ndepends on task type. Our findings not only reconcile conflicting observations\nabout localization in model editing but also emphasize on using task-adaptive\ntechniques for reliable, interpretable updates.",
      "tldr_zh": "这篇论文使用 Causal Layer Attribution via Activation Patching (CLAP) 方法，调查 fine-tuned GPT-2 模型中知识表示的本地化问题，模型在9,958个PubMed摘要上进行训练，焦点包括epilepsy、EEG和seizure等主题。研究发现，定义知识高度本地化于最终输出层（100%恢复），而关联知识分布在多个层（如第一个feedforward层恢复56%），卷积层对高级推理贡献较小（仅13.6%恢复）。这些结果证明事实知识更倾向于本地化，关联知识依赖分布表示，并强调任务类型对模型编辑效果的影响，为更可靠的模型解释和更新提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02976v1",
      "published_date": "2025-04-03 18:54:50 UTC",
      "updated_date": "2025-04-03 18:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:06:56.437406"
    },
    {
      "arxiv_id": "2504.02972v1",
      "title": "Improved Compact Genetic Algorithms with Efficient Caching",
      "title_zh": "改进的紧凑遗传算法，带有高效缓存",
      "authors": [
        "Prasanta Dutta",
        "Anirban Mukhopadhyay"
      ],
      "abstract": "Compact Genetic Algorithms (cGAs) are condensed variants of classical Genetic\nAlgorithms (GAs) that use a probability vector representation of the population\ninstead of the complete population. cGAs have been shown to significantly\nreduce the number of function evaluations required while producing outcomes\nsimilar to those of classical GAs. However, cGAs have a tendency to repeatedly\ngenerate the same chromosomes as they approach convergence, resulting in\nunnecessary evaluations of identical chromosomes. This article introduces the\nconcept of caching in cGAs as a means of avoiding redundant evaluations of the\nsame chromosomes. Our proposed approach operates equivalently to cGAs, but\nenhances the algorithm's time efficiency by reducing the number of function\nevaluations. We also present a data structure for efficient cache maintenance\nto ensure low overhead. The proposed caching approach has an asymptotically\nconstant time complexity on average. The proposed method further generalizes\nthe caching mechanism with higher selection pressure for elitism-based cGAs. We\nconduct a rigorous analysis based on experiments on benchmark optimization\nproblems using two well-known cache replacement strategies. The results\ndemonstrate that caching significantly reduces the number of function\nevaluations required while maintaining the same level of performance accuracy.",
      "tldr_zh": "这篇论文针对 Compact Genetic Algorithms (cGAs) 中重复评估相同染色体的低效问题，提出了一种引入高效缓存机制的改进方法，以减少不必要的函数评估，同时保持算法性能。方法包括设计一个低开销的数据结构来维护缓存，确保平均时间复杂度为常数，并扩展缓存机制以支持基于精英主义的 cGAs。实验结果显示，在基准优化问题上，使用两种常见缓存替换策略后，函数评估次数显著减少，而性能准确性保持不变。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.02972v1",
      "published_date": "2025-04-03 18:47:26 UTC",
      "updated_date": "2025-04-03 18:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:07:09.807235"
    },
    {
      "arxiv_id": "2505.13453v1",
      "title": "Pel, A Programming Language for Orchestrating AI Agents",
      "title_zh": "Pel：一种用于编排 AI 代理的编程语言",
      "authors": [
        "Behnam Mohammadi"
      ],
      "abstract": "The proliferation of Large Language Models (LLMs) has opened new frontiers in\ncomputing, yet controlling and orchestrating their capabilities beyond simple\ntext generation remains a challenge. Current methods, such as function/tool\ncalling and direct code generation, suffer from limitations in expressiveness,\nscalability, cost, security, and the ability to enforce fine-grained control.\nThis paper introduces Pel, a novel programming language specifically designed\nto bridge this gap. Inspired by the strengths of Lisp, Elixir, Gleam, and\nHaskell, Pel provides a syntactically simple, homoiconic, and semantically rich\nplatform for LLMs to express complex actions, control flow, and inter-agent\ncommunication safely and efficiently. Pel's design emphasizes a minimal, easily\nmodifiable grammar suitable for constrained LLM generation, eliminating the\nneed for complex sandboxing by enabling capability control at the syntax level.\nKey features include a powerful piping mechanism for linear composition,\nfirst-class closures enabling easy partial application and functional patterns,\nbuilt-in support for natural language conditions evaluated by LLMs, and an\nadvanced Read-Eval-Print-Loop (REPeL) with Common Lisp-style restarts and\nLLM-powered helper agents for automated error correction. Furthermore, Pel\nincorporates automatic parallelization of independent operations via static\ndependency analysis, crucial for performant agentic systems. We argue that Pel\noffers a more robust, secure, and expressive paradigm for LLM orchestration,\npaving the way for more sophisticated and reliable AI agentic frameworks.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）在控制和编排复杂动作时的局限性（如表达性不足、可扩展性差及安全问题），提出了一种新型编程语言Pel。Pel受Lisp、Elixir、Gleam和Haskell启发，提供简单同构语法、管道机制、一级闭包、自然语言条件支持以及高级REPeL（包括LLM驱动的错误修正），并通过静态依赖分析实现自动并行化。总体而言，Pel为LLMs编排提供更安全、高效和富有表现力的框架，推动可靠AI代理系统的发展。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.PL",
      "comment": "Added relevant figures and the section 4.5",
      "pdf_url": "http://arxiv.org/pdf/2505.13453v1",
      "published_date": "2025-04-03 18:46:53 UTC",
      "updated_date": "2025-04-03 18:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:07:19.323906"
    },
    {
      "arxiv_id": "2504.02968v1",
      "title": "Global-Order GFlowNets",
      "title_zh": "翻译失败",
      "authors": [
        "Lluís Pastor-Pérez",
        "Javier Alonso-Garcia",
        "Lukas Mauch"
      ],
      "abstract": "Order-Preserving (OP) GFlowNets have demonstrated remarkable success in\ntackling complex multi-objective (MOO) black-box optimization problems using\nstochastic optimization techniques. Specifically, they can be trained online to\nefficiently sample diverse candidates near the Pareto front. A key advantage of\nOP GFlowNets is their ability to impose a local order on training samples based\non Pareto dominance, eliminating the need for scalarization - a common\nrequirement in other approaches like Preference-Conditional GFlowNets. However,\nwe identify an important limitation of OP GFlowNets: imposing a local order on\ntraining samples can lead to conflicting optimization objectives. To address\nthis issue, we introduce Global-Order GFlowNets, which transform the local\norder into a global one, thereby resolving these conflicts. Our experimental\nevaluations on various benchmarks demonstrate the efficacy and promise of our\nproposed method.",
      "tldr_zh": "该论文分析了 Order-Preserving (OP) GFlowNets 在多目标优化 (MOO) 黑箱问题中的优势，即通过基于 Pareto dominance 的局部顺序训练，能高效采样接近 Pareto front 的多样候选，而无需标量化。然而，OP GFlowNets 的局部顺序可能导致优化目标冲突。为解决此问题，研究引入 Global-Order GFlowNets，通过将局部顺序转化为全局顺序来消除冲突。在各种基准实验中，该方法展示了显著的效能和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, ICLR 2025 Workshop format",
      "pdf_url": "http://arxiv.org/pdf/2504.02968v1",
      "published_date": "2025-04-03 18:43:52 UTC",
      "updated_date": "2025-04-03 18:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:07:30.404354"
    },
    {
      "arxiv_id": "2504.02965v2",
      "title": "CoLa -- Learning to Interactively Collaborate with Large LMs",
      "title_zh": "CoLa：学习与大型语言模型进行交互式协作",
      "authors": [
        "Abhishek Sharma",
        "Dan Goldwasser"
      ],
      "abstract": "LLMs' remarkable ability to tackle a wide range of language tasks opened new\nopportunities for collaborative human-AI problem solving. LLMs can amplify\nhuman capabilities by applying their intuitions and reasoning strategies at\nscale. We explore whether human guides can be simulated, by generalizing from\nhuman demonstrations of guiding an AI system to solve complex language\nproblems. We introduce CoLa, a novel self-guided learning paradigm for training\nautomated $\\textit{guides}$ and evaluate it on two QA datasets, a\npuzzle-solving task, and a constrained text generation task. Our empirical\nresults show that CoLa consistently outperforms competitive approaches across\nall domains. Moreover, a small-sized trained guide outperforms a strong model\nlike GPT-4 when acting as a guide. We compare the strategies employed by humans\nand automated guides by conducting a human study on a QA dataset. We show that\nautomated guides outperform humans by adapting their strategies to reasoners'\ncapabilities and conduct qualitative analyses highlighting distinct differences\nin guiding strategies.",
      "tldr_zh": "本文提出 CoLa，一种新型自引导学习范式，用于训练自动化的“guides”系统，以模拟人类指导大型语言模型 (LLMs) 协作解决复杂语言问题。CoLa 通过从人类演示中泛化训练，并在两个 QA datasets、谜题解决任务和受限文本生成任务上进行评估，结果显示其在所有领域均优于竞争对手。值得注意的是，一个小型训练后的 guide 甚至超过了 GPT-4 的表现，且自动 guides 能根据推理器的能力调整策略，在人类研究中表现出色，并揭示了指导策略的显著差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02965v2",
      "published_date": "2025-04-03 18:34:36 UTC",
      "updated_date": "2025-04-07 01:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:07:43.104849"
    },
    {
      "arxiv_id": "2504.02963v1",
      "title": "Digital Forensics in the Age of Large Language Models",
      "title_zh": "数字取证在大语言模型时代",
      "authors": [
        "Zhipeng Yin",
        "Zichong Wang",
        "Weifeng Xu",
        "Jun Zhuang",
        "Pallab Mozumder",
        "Antoinette Smith",
        "Wenbin Zhang"
      ],
      "abstract": "Digital forensics plays a pivotal role in modern investigative processes,\nutilizing specialized methods to systematically collect, analyze, and interpret\ndigital evidence for judicial proceedings. However, traditional digital\nforensic techniques are primarily based on manual labor-intensive processes,\nwhich become increasingly insufficient with the rapid growth and complexity of\ndigital data. To this end, Large Language Models (LLMs) have emerged as\npowerful tools capable of automating and enhancing various digital forensic\ntasks, significantly transforming the field. Despite the strides made, general\npractitioners and forensic experts often lack a comprehensive understanding of\nthe capabilities, principles, and limitations of LLM, which limits the full\npotential of LLM in forensic applications. To fill this gap, this paper aims to\nprovide an accessible and systematic overview of how LLM has revolutionized the\ndigital forensics approach. Specifically, it takes a look at the basic concepts\nof digital forensics, as well as the evolution of LLM, and emphasizes the\nsuperior capabilities of LLM. To connect theory and practice, relevant examples\nand real-world scenarios are discussed. We also critically analyze the current\nlimitations of applying LLMs to digital forensics, including issues related to\nillusion, interpretability, bias, and ethical considerations. In addition, this\npaper outlines the prospects for future research, highlighting the need for\neffective use of LLMs for transparency, accountability, and robust\nstandardization in the forensic process.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 如何革新数字取证领域，解决传统手动密集型方法的局限性，如数据复杂性和效率问题。论文提供了一个系统概述，包括数字取证的基本概念、LLMs 的演变及其在自动化证据收集、分析和解释方面的优势，并通过真实案例连接理论与实践。同时，它批判性地分析了 LLMs 的限制，例如幻觉、解释性不足、偏见和伦理挑战，并强调未来研究应聚焦于透明性、问责性和标准化，以提升数字取证的可信度。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02963v1",
      "published_date": "2025-04-03 18:32:15 UTC",
      "updated_date": "2025-04-03 18:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:07:55.386563"
    },
    {
      "arxiv_id": "2504.02962v1",
      "title": "Level Up Peer Review in Education: Investigating genAI-driven Gamification system and its influence on Peer Feedback Effectiveness",
      "title_zh": "翻译失败",
      "authors": [
        "Rafal Wlodarski",
        "Leonardo da Silva Sousa",
        "Allison Connell Pensky"
      ],
      "abstract": "In software engineering (SE), the ability to review code and critique designs\nis essential for professional practice. However, these skills are rarely\nemphasized in formal education, and peer feedback quality and engagement can\nvary significantly among students. This paper introduces Socratique, a gamified\npeer-assessment platform integrated with Generative AI (GenAI) assistance,\ndesigned to develop students' peer-review skills in a functional programming\ncourse. By incorporating game elements, Socratique aims to motivate students to\nprovide more feedback, while the GenAI assistant offers real-time support in\ncrafting high quality, constructive comments. To evaluate the impact of this\napproach, we conducted a randomized controlled experiment with master's\nstudents comparing a treatment group with a gamified, GenAI-driven setup\nagainst a control group with minimal gamification. Results show that students\nin the treatment group provided significantly more voluntary feedback, with\nhigher scores on clarity, relevance, and specificity - all key aspects of\neffective code and design reviews. This study provides evidence for the\neffectiveness of combining gamification and AI to improve peer review\nprocesses, with implications for fostering review-related competencies in\nsoftware engineering curricula.",
      "tldr_zh": "本研究探讨了在软件工程教育中，如何通过整合Generative AI (GenAI)与gamification来提升同行评审(peer review)技能，提出Socratique平台，该平台在功能性编程课程中利用游戏元素激励学生提供更多反馈，并借助GenAI助手实时优化评论的质量。研究采用随机对照实验，将配备游戏化和GenAI的治疗组与最小游戏化的对照组进行比较，结果显示治疗组学生提供了显著更多的自愿反馈，并在清晰度、相关性和具体性方面得分更高。整体而言，此研究证明了gamification和AI结合的有效性，为软件工程课程中培养代码和设计审查能力提供了重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02962v1",
      "published_date": "2025-04-03 18:30:25 UTC",
      "updated_date": "2025-04-03 18:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:08:07.202431"
    },
    {
      "arxiv_id": "2504.02949v1",
      "title": "VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via Iterative Instruction Tuning and Reinforcement Learning",
      "title_zh": "VARGPT",
      "authors": [
        "Xianwei Zhuang",
        "Yuxin Xie",
        "Yufan Deng",
        "Dongchao Yang",
        "Liming Liang",
        "Jinghan Ru",
        "Yuguo Yin",
        "Yuexian Zou"
      ],
      "abstract": "In this work, we present VARGPT-v1.1, an advanced unified visual\nautoregressive model that builds upon our previous framework VARGPT. The model\npreserves the dual paradigm of next-token prediction for visual understanding\nand next-scale generation for image synthesis. Specifically, VARGPT-v1.1\nintegrates: (1) a novel training strategy combining iterative visual\ninstruction tuning with reinforcement learning through Direct Preference\nOptimization (DPO), (2) an expanded training corpus containing 8.3M\nvisual-generative instruction pairs, (3) an upgraded language model backbone\nusing Qwen2, (4) enhanced image generation resolution, and (5) emergent image\nediting capabilities without architectural modifications. These advancements\nenable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal\nunderstanding and text-to-image instruction-following tasks, demonstrating\nsignificant improvements in both comprehension and generation metrics. Notably,\nthrough visual instruction tuning, the model acquires image editing\nfunctionality while maintaining architectural consistency with its predecessor,\nrevealing the potential for unified visual understanding, generation, and\nediting. Our findings suggest that well-designed unified visual autoregressive\nmodels can effectively adopt flexible training strategies from large language\nmodels (LLMs), exhibiting promising scalability. The codebase and model weights\nare publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.",
      "tldr_zh": "本文介绍了 VARGPT-v1.1，一种先进的统一视觉自回归模型，基于先前框架通过迭代 visual instruction tuning 和 Reinforcement Learning via Direct Preference Optimization (DPO) 等策略进行优化，提升了视觉理解和图像生成性能。该模型整合了8.3M视觉生成指令对的扩展训练语料库、升级的 Qwen2 语言模型主干、增强的图像生成分辨率，以及无需架构修改的涌现图像编辑能力。实验结果显示，VARGPT-v1.1 在多模态理解和文本到图像指令遵循任务中达到最先进水平，证明了统一模型的可扩展性和从大型语言模型（LLMs）借鉴训练策略的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/VARGPT-family/VARGPT-v1.1.\n  arXiv admin note: text overlap with arXiv:2501.12327",
      "pdf_url": "http://arxiv.org/pdf/2504.02949v1",
      "published_date": "2025-04-03 18:06:28 UTC",
      "updated_date": "2025-04-03 18:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:08:21.045698"
    },
    {
      "arxiv_id": "2504.02938v1",
      "title": "Graph Attention for Heterogeneous Graphs with Positional Encoding",
      "title_zh": "异质图的图注意力机制与位置编码",
      "authors": [
        "Nikhil Shivakumar Nayak"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as the de facto standard for\nmodeling graph data, with attention mechanisms and transformers significantly\nenhancing their performance on graph-based tasks. Despite these advancements,\nthe performance of GNNs on heterogeneous graphs often remains complex, with\nnetworks generally underperforming compared to their homogeneous counterparts.\nThis work benchmarks various GNN architectures to identify the most effective\nmethods for heterogeneous graphs, with a particular focus on node\nclassification and link prediction. Our findings reveal that graph attention\nnetworks excel in these tasks. As a main contribution, we explore enhancements\nto these attention networks by integrating positional encodings for node\nembeddings. This involves utilizing the full Laplacian spectrum to accurately\ncapture both the relative and absolute positions of each node within the graph,\nfurther enhancing performance on downstream tasks such as node classification\nand link prediction.",
      "tldr_zh": "这篇论文探讨了 Graph Neural Networks (GNNs) 在异构图上的性能问题，通过基准测试各种 GNN 架构，发现 graph attention networks 在节点分类和链接预测任务中表现出色。作者的主要贡献是整合 positional encodings 到这些注意力网络中，利用全 Laplacian spectrum 捕捉节点的相对和绝对位置，从而提升节点嵌入的准确性。实验结果显示，这种增强方法显著提高了下游任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "math.DG",
        "stat.ML",
        "53-02",
        "G.2.2; I.2.0; I.2.4; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02938v1",
      "published_date": "2025-04-03 18:00:02 UTC",
      "updated_date": "2025-04-03 18:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:08:31.100444"
    },
    {
      "arxiv_id": "2504.02828v1",
      "title": "Concept Lancet: Image Editing with Compositional Representation Transplant",
      "title_zh": "Concept Lancet: 基于组合表示移植的图像编辑",
      "authors": [
        "Jinqi Luo",
        "Tianjiao Ding",
        "Kwan Ho Ryan Chan",
        "Hancheng Min",
        "Chris Callison-Burch",
        "René Vidal"
      ],
      "abstract": "Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.",
      "tldr_zh": "本文提出 Concept Lancet (CoLan)，一个零样本即插即用框架，用于提升扩散模型（Diffusion models）在图像编辑中的表示操作，通过将源输入在潜在空间（文本嵌入或扩散分数）分解为视觉概念的稀疏线性组合，从而准确估计概念存在并指导编辑。CoLan 根据编辑任务（如替换、添加或移除）执行自定义的概念移植过程，避免了传统方法在编辑强度上的过度或不足问题，并构建了 CoLan-150K 数据集作为概念表示库。实验结果显示，配备 CoLan 的基线方法在编辑效果和视觉一致性保留方面达到了最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in CVPR 2025. Project page at\n  https://peterljq.github.io/project/colan",
      "pdf_url": "http://arxiv.org/pdf/2504.02828v1",
      "published_date": "2025-04-03 17:59:58 UTC",
      "updated_date": "2025-04-03 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:08:43.842301"
    },
    {
      "arxiv_id": "2504.02827v1",
      "title": "On Vanishing Variance in Transformer Length Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Ruining Li",
        "Gabrijel Boduljak",
        "Jensen",
        "Zhou"
      ],
      "abstract": "It is a widely known issue that Transformers, when trained on shorter\nsequences, fail to generalize robustly to longer ones at test time. This raises\nthe question of whether Transformer models are real reasoning engines, despite\ntheir impressive abilities in mathematical problem solving and code synthesis.\nIn this paper, we offer a vanishing variance perspective on this issue. To the\nbest of our knowledge, we are the first to demonstrate that even for today's\nfrontier models, a longer sequence length results in a decrease in variance in\nthe output of the multi-head attention modules. On the argmax retrieval and\ndictionary lookup tasks, our experiments show that applying layer normalization\nafter the attention outputs leads to significantly better length\ngeneralization. Our analyses attribute this improvement to a reduction-though\nnot a complete elimination-of the distribution shift caused by vanishing\nvariance.",
      "tldr_zh": "本论文探讨了 Transformers 模型在训练短序列后，无法良好泛化到长序列的问题，并从 vanishing variance 的角度提供新见解。作者首次证明，即使是前沿模型，更长的序列长度会导致 multi-head attention 模块输出方差减少，从而引发分布偏移。实验在 argmax retrieval 和 dictionary lookup 任务上显示，通过在注意力输出后应用 layer normalization，可以显著改善长度泛化能力。这些发现归因于 vanishing variance 引起的分布偏移得到部分减少，为提升 Transformers 的推理能力提供了潜在路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Project page: https://ruiningli.com/vanishing-variance. The first two\n  authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2504.02827v1",
      "published_date": "2025-04-03 17:59:56 UTC",
      "updated_date": "2025-04-03 17:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:08:55.641968"
    },
    {
      "arxiv_id": "2504.02822v1",
      "title": "Do Two AI Scientists Agree?",
      "title_zh": "两个 AI 科学家是否同意？",
      "authors": [
        "Xinghong Fu",
        "Ziming Liu",
        "Max Tegmark"
      ],
      "abstract": "When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.",
      "tldr_zh": "本研究探讨了多个 AI 模型在同一科学任务上训练时，是否会学习相同的理论（theory），类似于科学史中实验数据驱动理论的兴衰。作者提出 MASS（Hamiltonian-Lagrangian neural networks as AI Scientists）框架，通过训练于物理标准问题并聚合多个 seeds 的结果，量化 AI 科学家的理论一致性。结果显示，AI 模型在简单系统中倾向于学习 Hamiltonian theory，而在复杂系统中转向 Lagrangian formulation，且训练动态高度依赖 seeds，导致理论的收敛或分化；此外，该框架不仅提升了模型的可解释性，还可应用于更高维问题。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02822v1",
      "published_date": "2025-04-03 17:58:44 UTC",
      "updated_date": "2025-04-03 17:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:09:07.886229"
    },
    {
      "arxiv_id": "2504.02821v1",
      "title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models",
      "title_zh": "稀疏自编码器在视觉语言模型中学习单义特征",
      "authors": [
        "Mateusz Pach",
        "Shyamgopal Karthik",
        "Quentin Bouniot",
        "Serge Belongie",
        "Zeynep Akata"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.",
      "tldr_zh": "本文研究将 Sparse Autoencoders (SAEs) 应用到 Vision-Language Models (VLMs) 如 CLIP 上，以提升模型的可解释性和操控性，并引入一个全面框架来评估视觉表示的单义性(monosemanticity)。实验结果显示，SAEs 显著增强了单个神经元的单义性，并展示了与专家定义的层次化结构（如 iNaturalist taxonomy）对齐的表示。关键发现是，通过 SAEs 干预 CLIP 视觉编码器，可以直接操控多模态 LLMs（如 LLaVA）的输出，而无需修改底层模型。这些成果突显了 SAEs 作为无监督方法在提升 VLMs 实用性和可信度方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. The code is available at\n  https://github.com/ExplainableML/sae-for-vlm",
      "pdf_url": "http://arxiv.org/pdf/2504.02821v1",
      "published_date": "2025-04-03 17:58:35 UTC",
      "updated_date": "2025-04-03 17:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:09:20.145855"
    },
    {
      "arxiv_id": "2504.02819v1",
      "title": "GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings",
      "title_zh": "翻译失败",
      "authors": [
        "Yuexi Du",
        "Jiazhen Zhang",
        "Nicha C. Dvornek",
        "John A. Onofrey"
      ],
      "abstract": "Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.",
      "tldr_zh": "该研究提出了一种高效的卷积核 GMR-Conv，利用 Gaussian Mixture Rings 来实现旋转和反射等变性，解决了传统 CNN 在扩展等变性时面临的效率和信息损失问题。通过混合高斯加权的环状设计，GMR-Conv 减少了圆形内核的离散化错误，同时保持计算开销不变，并通过新颖的参数化和计算策略优化了空间和速度效率。实验在八个分类数据集和一个分割数据集上显示，GMR-Conv 的性能与传统 CNN 相当，并在无方向数据应用中表现出色，比最先进等变学习方法更稳健高效。该方法为等变网络架构提供了重要进展，证明了径向对称性的应用能有效缓解信息损失。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02819v1",
      "published_date": "2025-04-03 17:58:18 UTC",
      "updated_date": "2025-04-03 17:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:09:31.772148"
    },
    {
      "arxiv_id": "2504.02810v2",
      "title": "Generative Evaluation of Complex Reasoning in Large Language Models",
      "title_zh": "大语言模型中复杂推理的生成式评估",
      "authors": [
        "Haowei Lin",
        "Xiangyu Wang",
        "Ruilin Yan",
        "Baizhou Huang",
        "Haotian Ye",
        "Jianhua Zhu",
        "Zihao Wang",
        "James Zou",
        "Jianzhu Ma",
        "Yitao Liang"
      ],
      "abstract": "With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.",
      "tldr_zh": "本文质疑大型语言模型(LLMs)是否真正进行推理，还是仅依赖训练数据回忆，提出KUMO框架作为生成式评估工具来解决基准测试的污染问题。KUMO结合LLMs和符号引擎，动态生成多样化的多轮推理任务，这些任务部分可观察且难度可调，覆盖100个领域以测试模型的泛化能力。实验评估了23个最先进LLMs在5000个任务上的表现，发现这些模型在简单推理任务上已超过大学水平，而扩展推理的LLMs在复杂任务上达到大学水平。KUMO的结果与真实世界推理基准高度相关，证明其是评估LLMs真实推理能力的可靠工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02810v2",
      "published_date": "2025-04-03 17:54:18 UTC",
      "updated_date": "2025-04-25 12:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:09:43.926401"
    },
    {
      "arxiv_id": "2504.02807v1",
      "title": "MegaMath: Pushing the Limits of Open Math Corpora",
      "title_zh": "MegaMath：推动",
      "authors": [
        "Fan Zhou",
        "Zengzhi Wang",
        "Nikhil Ranjan",
        "Zhoujun Cheng",
        "Liping Tang",
        "Guowei He",
        "Zhengzhong Liu",
        "Eric P. Xing"
      ],
      "abstract": "Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.",
      "tldr_zh": "该论文介绍了 MegaMath，一个开放、大规模、高质量的数学语料库，旨在解决当前缺乏适合数学相关 LLMs 预训练数据集的问题。研究团队通过三种策略构建数据集：（1）从 Common Crawl 重新提取数学文档，使用数学导向的 HTML 优化、fasttext-based 过滤和去重；（2）从 Stack-V2 中识别高质量的数学相关代码，以提升数据多样性；（3）生成合成数据，包括 QA-style 文本、数学代码以及交错的文本-代码块。最终，MegaMath 提供了 371B tokens，是现有开放数学预训练数据集中最丰富且高质量的，并通过广泛的消融实验验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 15 figures, 22 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.02807v1",
      "published_date": "2025-04-03 17:52:07 UTC",
      "updated_date": "2025-04-03 17:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:09:56.474359"
    },
    {
      "arxiv_id": "2504.02922v1",
      "title": "Robustly identifying concepts introduced during chat fine-tuning using crosscoders",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Minder",
        "Clement Dumas",
        "Caden Juang",
        "Bilal Chugtai",
        "Neel Nanda"
      ],
      "abstract": "Model diffing is the study of how fine-tuning changes a model's\nrepresentations and internal algorithms. Many behaviours of interest are\nintroduced during fine-tuning, and model diffing offers a promising lens to\ninterpret such behaviors. Crosscoders are a recent model diffing method that\nlearns a shared dictionary of interpretable concepts represented as latent\ndirections in both the base and fine-tuned models, allowing us to track how\nconcepts shift or emerge during fine-tuning. Notably, prior work has observed\nconcepts with no direction in the base model, and it was hypothesized that\nthese model-specific latents were concepts introduced during fine-tuning.\nHowever, we identify two issues which stem from the crosscoders L1 training\nloss that can misattribute concepts as unique to the fine-tuned model, when\nthey really exist in both models. We develop Latent Scaling to flag these\nissues by more accurately measuring each latent's presence across models. In\nexperiments comparing Gemma 2 2B base and chat models, we observe that the\nstandard crosscoder suffers heavily from these issues. Building on these\ninsights, we train a crosscoder with BatchTopK loss and show that it\nsubstantially mitigates these issues, finding more genuinely chat-specific and\nhighly interpretable concepts. We recommend practitioners adopt similar\ntechniques. Using the BatchTopK crosscoder, we successfully identify a set of\ngenuinely chat-specific latents that are both interpretable and causally\neffective, representing concepts such as $\\textit{false information}$ and\n$\\textit{personal question}$, along with multiple refusal-related latents that\nshow nuanced preferences for different refusal triggers. Overall, our work\nadvances best practices for the crosscoder-based methodology for model diffing\nand demonstrates that it can provide concrete insights into how chat tuning\nmodifies language model behavior.",
      "tldr_zh": "该论文探讨了使用 crosscoders 方法来稳健地识别聊天微调过程中引入的概念，从而推进 model diffing 领域的分析。研究发现，标准 crosscoders 的 L1 训练损失可能导致误判概念为微调模型独有，因此开发了 Latent Scaling 技术来更准确测量概念的存在，并在实验中采用 BatchTopK 损失改进 crosscoders。结果显示，在 Gemma 2 2B 基模型和聊天模型的比较中，改进后的方法成功识别出真正的聊天特定概念，如 $\\textit{false information}$ 和 $\\textit{personal question}$，并揭示了拒绝相关概念的细微差异，提供了对语言模型行为修改的宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02922v1",
      "published_date": "2025-04-03 17:50:24 UTC",
      "updated_date": "2025-04-03 17:50:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:10:08.211927"
    },
    {
      "arxiv_id": "2504.02799v1",
      "title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence",
      "title_zh": "系统性评估大型视觉-语言模型在手术人工智能中的应用",
      "authors": [
        "Anita Rau",
        "Mark Endo",
        "Josiah Aklilu",
        "Jaewoo Heo",
        "Khaled Saab",
        "Alberto Paderno",
        "Jeffrey Jopling",
        "F. Christopher Holsinger",
        "Serena Yeung-Levy"
      ],
      "abstract": "Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.",
      "tldr_zh": "本研究系统评估了11个最先进的视觉语言模型(VLMs)在手术人工智能中的表现，涵盖17个关键视觉理解任务（如解剖识别和技能评估），并使用13个数据集，包括腹腔镜、机器人和开放手术程序。结果显示，VLMs展现出良好的泛化能力，有时在非训练场景下超越监督模型，而in-context learning（在测试时加入示例）可将性能提升多达三倍，突显其适应性优势。尽管如此，涉及空间或时间推理的任务仍面临挑战。该研究为VLMs在手术及更广泛的复杂临床应用中提供宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02799v1",
      "published_date": "2025-04-03 17:42:56 UTC",
      "updated_date": "2025-04-03 17:42:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:10:18.866189"
    },
    {
      "arxiv_id": "2504.02793v1",
      "title": "A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Verma",
        "Jiawei Zhou",
        "Mohit Chandra",
        "Srijan Kumar",
        "Munmun De Choudhury"
      ],
      "abstract": "Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).",
      "tldr_zh": "该研究讨论了大型 AI 模型（Large AI Models）在高风险垂直领域（如医疗、教育和法律）中的局限性，包括对输入数据变化的敏感性、缺乏上下文决策以及产生不准确信息的问题。论文提出一个框架，通过层级抽象创新来满足用户需求，并通过案例研究展示其操作化过程，以模块化地将模型转化为垂直系统（Vertical Systems）。该框架不仅强调各层的动态性，还指导研究者定位创新（如利用垂直特定见解驱动通用创新）、发现跨领域机会（如开发实用基础模型）和促进跨学科沟通（如建立共享词汇）。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "pre-print; 7 pages of main content, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.02793v1",
      "published_date": "2025-04-03 17:40:11 UTC",
      "updated_date": "2025-04-03 17:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:10:31.948526"
    },
    {
      "arxiv_id": "2504.02792v2",
      "title": "Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Chuning Zhu",
        "Raymond Yu",
        "Siyuan Feng",
        "Benjamin Burchfiel",
        "Paarth Shah",
        "Abhishek Gupta"
      ],
      "abstract": "Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. By simply controlling\neach diffusion timestep, UWM can flexibly represent a policy, a forward\ndynamics, an inverse dynamics, and a video generator. Through simulated and\nreal-world experiments, we show that: (1) UWM enables effective pretraining on\nlarge-scale multitask robot datasets with both dynamics and action predictions,\nresulting in more generalizable and robust policies than imitation learning,\n(2) UWM naturally facilitates learning from action-free video data through\nindependent control of modality-specific diffusion timesteps, further improving\nthe performance of finetuned policies. Our results suggest that UWM offers a\npromising step toward harnessing large, heterogeneous datasets for scalable\nrobot learning, and provides a simple unification between the often disparate\nparadigms of imitation learning and world modeling. Videos and code are\navailable at https://weirdlabuw.github.io/uwm/.",
      "tldr_zh": "该论文提出 Unified World Models (UWM)，一个统一框架，将视频扩散和动作扩散过程整合到 Transformer 架构中，用于在大型机器人数据集上进行预训练，从而解决模仿学习对高质量动作标注的依赖问题。UWM 通过独立控制每个模态的扩散时间步，能灵活表示策略、前向动态、逆向动态和视频生成器，实现对视频和动作数据的有效利用。实验结果显示，UWM 在模拟和真实环境中进行预训练后，比传统模仿学习产生更具泛化性和鲁棒性的策略，并能从无动作视频数据中学习，进一步提升微调策略的性能。该框架为利用异构数据集的机器人学习提供了一个简化的统一范式。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02792v2",
      "published_date": "2025-04-03 17:38:59 UTC",
      "updated_date": "2025-04-16 20:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:10:44.278403"
    },
    {
      "arxiv_id": "2504.02781v1",
      "title": "Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations",
      "title_zh": "翻译失败",
      "authors": [
        "Selim Ickin",
        "Shruti Bothe",
        "Aman Raparia",
        "Nitin Khanna",
        "Erik Sanders"
      ],
      "abstract": "Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.",
      "tldr_zh": "该研究评估了稀疏结构 Neural Circuit Policies (NCPs) 在估算基站能源消耗的应用，以推动 Green AI-Native Networks 的发展。相比传统模型如 Long Short Term Memory (LSTM)，NCPs 通过减少内存、计算和能源需求，提供了一个低成本且可扩展的解决方案。实验结果显示，NCPs 显著降低了计算开销和能源消耗，同时对模型超参数 (HPs) 如 epoch 数和神经元数量的变动表现出更高的鲁棒性。总体而言，这为简化 Machine Learning Operations (MLOps) 并在电信领域实现能源节约提供了可行路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02781v1",
      "published_date": "2025-04-03 17:22:39 UTC",
      "updated_date": "2025-04-03 17:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:10:55.630319"
    },
    {
      "arxiv_id": "2504.02780v1",
      "title": "From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Holstein",
        "Moritz Diener",
        "Philipp Spitzer"
      ],
      "abstract": "The rise of Generative AI, and Large Language Models (LLMs) in particular, is\nfundamentally changing cognitive processes in knowledge work, raising critical\nquestions about their impact on human reasoning and problem-solving\ncapabilities. As these AI systems become increasingly integrated into\nworkflows, they offer unprecedented opportunities for augmenting human thinking\nwhile simultaneously risking cognitive erosion through passive consumption of\ngenerated answers. This tension is particularly pronounced in open-ended tasks,\nwhere effective solutions require deep contextualization and integration of\ndomain knowledge. Unlike structured tasks with established metrics, measuring\nthe quality of human-LLM interaction in such open-ended tasks poses significant\nchallenges due to the absence of ground truth and the iterative nature of\nsolution development. To address this, we present a framework that analyzes\ninteraction patterns along two dimensions: cognitive activity mode (exploration\nvs. exploitation) and cognitive engagement mode (constructive vs. detrimental).\nThis framework provides systematic measurements to evaluate when LLMs are\neffective tools for thought rather than substitutes for human cognition,\nadvancing theoretical understanding and practical guidance for developing AI\nsystems that protect and augment human cognitive capabilities.",
      "tldr_zh": "这篇论文探讨了 Generative AI 和 LLMs 在知识工作中的应用如何改变人类认知过程，强调了这些工具在增强人类思考的同时，可能因被动消费答案而导致认知退化，尤其在开放式任务中。论文提出一个框架，通过分析交互模式（包括 cognitive activity mode：exploration vs. exploitation，以及 cognitive engagement mode：constructive vs. detrimental）来评估人类-LLM 协作质量。最终，该框架提供系统性测量方法，帮助确定 LLMs 何时作为有效的思考工具而非认知替代品，从而为开发保护和增强人类认知能力的 AI 系统提供理论指导和实践建议。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at Tools for Thought Workshop (CHI'25)",
      "pdf_url": "http://arxiv.org/pdf/2504.02780v1",
      "published_date": "2025-04-03 17:20:36 UTC",
      "updated_date": "2025-04-03 17:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:11:07.191093"
    },
    {
      "arxiv_id": "2504.02778v1",
      "title": "Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition",
      "title_zh": "多头自适应图卷积网络",
      "authors": [
        "Vincent Gbouna Zakka",
        "Luis J. Manso",
        "Zhuangzhuang Dai"
      ],
      "abstract": "Human activity recognition is increasingly vital for supporting independent\nliving, particularly for the elderly and those in need of assistance. Domestic\nservice robots with monitoring capabilities can enhance safety and provide\nessential support. Although image-based methods have advanced considerably in\nthe past decade, their adoption remains limited by concerns over privacy and\nsensitivity to low-light or dark conditions. As an alternative, millimetre-wave\n(mmWave) radar can produce point cloud data which is privacy-preserving.\nHowever, processing the sparse and noisy point clouds remains a long-standing\nchallenge. While graph-based methods and attention mechanisms show promise,\nthey predominantly rely on \"fixed\" kernels; kernels that are applied uniformly\nacross all neighbourhoods, highlighting the need for adaptive approaches that\ncan dynamically adjust their kernels to the specific geometry of each local\nneighbourhood in point cloud data. To overcome this limitation, we introduce an\nadaptive approach within the graph convolutional framework. Instead of a single\nshared weight function, our Multi-Head Adaptive Kernel (MAK) module generates\nmultiple dynamic kernels, each capturing different aspects of the local feature\nspace. By progressively refining local features while maintaining global\nspatial context, our method enables convolution kernels to adapt to varying\nlocal features. Experimental results on benchmark datasets confirm the\neffectiveness of our approach, achieving state-of-the-art performance in human\nactivity recognition. Our source code is made publicly available at:\nhttps://github.com/Gbouna/MAK-GCN",
      "tldr_zh": "该研究针对人类活动识别（Human Activity Recognition）提出了一种基于稀疏点云（Sparse Point Cloud）的多头自适应图卷积网络（Multi-Head Adaptive Graph Convolution Network），以解决传统图像方法的隐私和光线问题，同时处理 mmWave 雷达生成的点云数据噪声和稀疏性。论文引入 Multi-Head Adaptive Kernel (MAK) 模块，该模块生成多个动态内核，能根据局部邻域的几何形状自适应调整，逐步细化局部特征并保留全局空间上下文。与现有依赖固定内核的图-based 方法相比，这种自适应方法显著提升了模型的灵活性。实验在基准数据集上实现了 state-of-the-art 性能，证明了该框架在支持独立生活和监控应用中的有效性。开源代码已发布在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02778v1",
      "published_date": "2025-04-03 17:19:20 UTC",
      "updated_date": "2025-04-03 17:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:11:19.626882"
    },
    {
      "arxiv_id": "2504.02767v1",
      "title": "How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?",
      "title_zh": "翻译失败",
      "authors": [
        "Andres Algaba",
        "Vincent Holst",
        "Floriano Tori",
        "Melika Mobini",
        "Brecht Verbeken",
        "Sylvia Wenmackers",
        "Vincent Ginis"
      ],
      "abstract": "The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 如何内部化科学文献和引用实践，发现 LLMs 在生成引用时系统性地强化马太效应 (Matthew effect)，即偏好高引用论文，这一趋势在不同科学领域中保持一致。分析 GPT-4o 生成的 274,951 个引用（针对 10,000 篇论文）显示，这些引用与传统模式不同，更倾向于最近的、标题更短且作者更少的论文，同时在内容相关性、网络效应和减少作者自引方面与真实引用相当。这些发现表明，LLMs 可能重塑科学引用动态，并放大既有趋势，从而影响科学发现的轨迹。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.DL",
      "comment": "32 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02767v1",
      "published_date": "2025-04-03 17:04:56 UTC",
      "updated_date": "2025-04-03 17:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:11:32.260974"
    },
    {
      "arxiv_id": "2504.02764v1",
      "title": "Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shengjun Zhang",
        "Jinzhao Li",
        "Xin Fei",
        "Hao Liu",
        "Yueqi Duan"
      ],
      "abstract": "In this paper, we propose Scene Splatter, a momentum-based paradigm for video\ndiffusion to generate generic scenes from single image. Existing methods, which\nemploy video generation models to synthesize novel views, suffer from limited\nvideo length and scene inconsistency, leading to artifacts and distortions\nduring further reconstruction. To address this issue, we construct noisy\nsamples from original features as momentum to enhance video details and\nmaintain scene consistency. However, for latent features with the perception\nfield that spans both known and unknown regions, such latent-level momentum\nrestricts the generative ability of video diffusion in unknown regions.\nTherefore, we further introduce the aforementioned consistent video as a\npixel-level momentum to a directly generated video without momentum for better\nrecovery of unseen regions. Our cascaded momentum enables video diffusion\nmodels to generate both high-fidelity and consistent novel views. We further\nfinetune the global Gaussian representations with enhanced frames and render\nnew frames for momentum update in the next step. In this manner, we can\niteratively recover a 3D scene, avoiding the limitation of video length.\nExtensive experiments demonstrate the generalization capability and superior\nperformance of our method in high-fidelity and consistent scene generation.",
      "tldr_zh": "本研究提出了一种名为Scene Splatter的动量(momentum)基于方法，利用Video Diffusion Model从单张图像生成高质量的3D场景，以解决现有方法在视频长度限制和场景一致性上的问题。方法通过构建噪声样本作为潜在级动量来增强视频细节，并引入像素级动量以更好地恢复未知区域，从而实现高保真度和一致的新视图生成。作者进一步采用迭代微调全局高斯表示和帧渲染的方式，逐步恢复完整3D场景，避免了视频长度的制约。实验结果显示，该方法在泛化能力和场景生成性能上均优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02764v1",
      "published_date": "2025-04-03 17:00:44 UTC",
      "updated_date": "2025-04-03 17:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:11:43.800086"
    },
    {
      "arxiv_id": "2504.02737v2",
      "title": "RBT4DNN: Requirements-based Testing of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nusrat Jahan Mozumder",
        "Felipe Toledo",
        "Swaroopa Dola",
        "Matthew B. Dwyer"
      ],
      "abstract": "Deep neural network (DNN) testing is crucial for the reliability and safety\nof critical systems, where failures can have severe consequences. Although\nvarious techniques have been developed to create robustness test suites,\nrequirements-based testing for DNNs remains largely unexplored - yet such tests\nare recognized as an essential component of software validation of critical\nsystems. In this work, we propose a requirements-based test suite generation\nmethod that uses structured natural language requirements formulated in a\nsemantic feature space to create test suites by prompting text-conditional\nlatent diffusion models with the requirement precondition and then using the\nassociated postcondition to define a test oracle to judge outputs of the DNN\nunder test. We investigate the approach using fine-tuned variants of\npre-trained generative models. Our experiments on the MNIST, CelebA-HQ,\nImageNet, and autonomous car driving datasets demonstrate that the generated\ntest suites are realistic, diverse, consistent with preconditions, and capable\nof revealing faults.",
      "tldr_zh": "本文提出 RBT4DNN，一种基于 requirements-based testing 的神经网络（DNN）测试方法，旨在提升关键系统的可靠性和安全性。该方法使用结构化自然语言需求在语义特征空间中生成测试套件，通过文本-conditional latent diffusion models 提示模型创建测试输入，并以关联的后置条件作为 test oracle 来评估 DNN 输出。实验在 MNIST、CelebA-HQ、ImageNet 和自动驾驶数据集上表明，生成的测试套件真实、多样、符合前置条件，并能有效揭示故障。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02737v2",
      "published_date": "2025-04-03 16:24:49 UTC",
      "updated_date": "2025-04-04 01:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:11:56.585827"
    },
    {
      "arxiv_id": "2504.03784v3",
      "title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Ye",
        "Hongyi Zhou",
        "Jin Zhu",
        "Francesco Quinzan",
        "Chengchung Shi"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a key\ntechnique for aligning the output of large language models (LLMs) with human\npreferences. To learn the reward function, most existing RLHF algorithms use\nthe Bradley-Terry model, which relies on assumptions about human preferences\nthat may not reflect the complexity and variability of real-world judgments. In\nthis paper, we propose a robust algorithm to enhance the performance of\nexisting approaches under such reward model misspecifications. Theoretically,\nour algorithm reduces the variance of reward and policy estimators, leading to\nimproved regret bounds. Empirical evaluations on LLM benchmark datasets\ndemonstrate that the proposed algorithm consistently outperforms existing\nmethods, with 77-81% of responses being favored over baselines on the Anthropic\nHelpful and Harmless dataset.",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）在微调大型语言模型（LLMs）中的应用，提出了一种鲁棒算法，以解决现有方法依赖 Bradley-Terry 模型的假设可能不适配真实世界判断的局限性。该算法通过降低奖励和策略估计器的方差，理论上实现了更好的遗憾界（regret bounds）。在实证评估中，该方法在 LLM 基准数据集上表现突出，在 Anthropic Helpful and Harmless 数据集上，77-81%的响应被用户偏好于基线方法，从而提升了 LLMs 与人类偏好对齐的性能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03784v3",
      "published_date": "2025-04-03 16:16:35 UTC",
      "updated_date": "2025-04-15 09:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:12:08.004354"
    },
    {
      "arxiv_id": "2504.03783v4",
      "title": "FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training",
      "title_zh": "FAST：基于基础模型的联邦主动学习，用于通信高效的采样和训练",
      "authors": [
        "Haoyuan Li",
        "Mathias Funk",
        "Jindong Wang",
        "Aaqib Saeed"
      ],
      "abstract": "Federated Active Learning (FAL) has emerged as a promising framework to\nleverage large quantities of unlabeled data across distributed clients while\npreserving data privacy. However, real-world deployments remain limited by high\nannotation costs and communication-intensive sampling processes, particularly\nin a cross-silo setting, when clients possess substantial local datasets. This\npaper addresses the crucial question: What is the best practice to reduce\ncommunication costs in human-in-the-loop learning with minimal annotator\neffort? Existing FAL methods typically rely on iterative annotation processes\nthat separate active sampling from federated updates, leading to multiple\nrounds of expensive communication and annotation. In response, we introduce\nFAST, a two-pass FAL framework that harnesses foundation models for weak\nlabeling in a preliminary pass, followed by a refinement pass focused\nexclusively on the most uncertain samples. By leveraging representation\nknowledge from foundation models and integrating refinement steps into a\nstreamlined workflow, FAST substantially reduces the overhead incurred by\niterative active sampling. Extensive experiments on diverse medical and natural\nimage benchmarks demonstrate that FAST outperforms existing FAL methods by an\naverage of 4.36% while reducing communication rounds eightfold under a limited\n5% labeling budget.",
      "tldr_zh": "这篇论文提出了 FAST，一种基于 foundation models 的 Federated Active Learning (FAL) 框架，旨在通过两阶段流程减少通信成本和标注努力：首先利用 foundation models 进行弱标注，然后针对最不确定样本进行精炼。相比传统 FAL 方法，FAST 整合了表示知识和简化工作流，避免了多次迭代采样。实验结果显示，在医疗和自然图像基准上，FAST 在 5% 标注预算下平均比现有方法提高 4.36%，并将通信轮次减少八倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2504.03783v4",
      "published_date": "2025-04-03 16:12:03 UTC",
      "updated_date": "2025-05-19 09:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:12:20.516540"
    },
    {
      "arxiv_id": "2504.02724v1",
      "title": "Autonomous Human-Robot Interaction via Operator Imitation",
      "title_zh": "基于操作员模仿的自主人机交互",
      "authors": [
        "Sammy Christen",
        "David Müller",
        "Agon Serifi",
        "Ruben Grandia",
        "Georg Wiedebach",
        "Michael A. Hopkins",
        "Espen Knoop",
        "Moritz Bächer"
      ],
      "abstract": "Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.",
      "tldr_zh": "本论文提出了一种通过模仿操作员数据实现自主人机互动的方法，旨在让机器人无需实时控制即可进行表达性互动。模型使用扩散过程预测连续命令，通过分类器处理离散命令，并将两者统一到一个Transformer架构中进行训练。实验结果显示，该方法在模拟和真实系统中的用户研究中表现与专家操作员相当，用户能够识别机器人不同的心情；此外，还实现了零样本转移到其他机器人平台。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02724v1",
      "published_date": "2025-04-03 16:06:44 UTC",
      "updated_date": "2025-04-03 16:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:12:30.948531"
    },
    {
      "arxiv_id": "2504.02701v2",
      "title": "Responsible Development of Offensive AI",
      "title_zh": "进攻性 AI 的负责任发展",
      "authors": [
        "Ryan Marinelli"
      ],
      "abstract": "As AI advances, broader consensus is needed to determine research priorities.\nThis endeavor discusses offensive AI and provides guidance by leveraging\nSustainable Development Goals (SDGs) and interpretability techniques. The\nobjective is to more effectively establish priorities that balance societal\nbenefits against risks. The two forms of offensive AI evaluated in this study\nare vulnerability detection agents, which solve Capture- The-Flag challenges,\nand AI-powered malware.",
      "tldr_zh": "这篇论文讨论了 Offensive AI 的负责任发展，利用 Sustainable Development Goals (SDGs) 和可解释性技术来指导研究优先级，旨在平衡社会益处与风险。论文评估了两种 Offensive AI 形式：漏洞检测代理（用于解决 Capture-The-Flag 挑战）和 AI-powered malware，以更有效地建立研究优先级。随着 AI 进步，该方法有助于推动更广泛的共识，确保研究方向符合可持续发展目标。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02701v2",
      "published_date": "2025-04-03 15:37:38 UTC",
      "updated_date": "2025-04-05 15:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:12:43.570983"
    },
    {
      "arxiv_id": "2504.02698v3",
      "title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Shengrui XU",
        "Tianchi Lu",
        "Zikun Wang",
        "Jixiu Zhai"
      ],
      "abstract": "Protein-protein interaction (PPI) prediction plays a pivotal role in\ndeciphering cellular functions and disease mechanisms. To address the\nlimitations of traditional experimental methods and existing computational\napproaches in cross-modal feature fusion and false-negative suppression, we\npropose SCMPPI-a novel supervised contrastive multimodal framework. By\neffectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with\nnetwork topology (Node2Vec embeddings) and incorporating an enhanced\ncontrastive learning strategy with negative sample filtering, SCMPPI achieves\nsuperior prediction performance. Extensive experiments on eight benchmark\ndatasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%),\nalong with excellent cross-species generalization (AUC>99%). Successful\napplications in CD9 networks, Wnt pathway analysis, and cancer-specific\nnetworks further highlight its potential for disease target discovery,\nestablishing SCMPPI as a powerful tool for multimodal biological data analysis.",
      "tldr_zh": "该研究提出SCMPPI，一种监督对比多模态框架，用于提升蛋白质-蛋白质相互作用(PPI)预测的准确性，通过整合序列-based features（如AAC、DPC、ESMC-CKSAAP）和网络拓扑（Node2Vec embeddings），并采用增强的对比学习策略来抑制假阴性。实验在八个基准数据集上实现了最先进的准确率（98.13%）和AUC（99.69%），并展示了优秀的跨物种泛化能力（AUC>99%）。此外，SCMPPI已在CD9网络、Wnt通路分析和癌症特定网络中成功应用，有助于疾病靶点发现和生物数据分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM",
        "92C40, 68T07",
        "I.2.6; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages,9 figures,conference",
      "pdf_url": "http://arxiv.org/pdf/2504.02698v3",
      "published_date": "2025-04-03 15:34:02 UTC",
      "updated_date": "2025-04-27 12:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:12:56.924075"
    },
    {
      "arxiv_id": "2504.02685v1",
      "title": "STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Iván Sevillano-García",
        "Julián Luengo",
        "Francisco Herrera"
      ],
      "abstract": "Out-of-Distribution (OOD) detection is a critical task in machine learning,\nparticularly in safety-sensitive applications where model failures can have\nserious consequences. However, current OOD detection methods often suffer from\nrestrictive distributional assumptions, limited scalability, and a lack of\ninterpretability. To address these challenges, we propose STOOD-X, a two-stage\nmethodology that combines a Statistical nonparametric Test for OOD Detection\nwith eXplainability enhancements. In the first stage, STOOD-X uses\nfeature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD\nsamples without assuming a specific feature distribution. In the second stage,\nit generates user-friendly, concept-based visual explanations that reveal the\nfeatures driving each decision, aligning with the BLUE XAI paradigm. Through\nextensive experiments on benchmark datasets and multiple architectures, STOOD-X\nachieves competitive performance against state-of-the-art post hoc OOD\ndetectors, particularly in high-dimensional and complex settings. In addition,\nits explainability framework enables human oversight, bias detection, and model\ndebugging, fostering trust and collaboration between humans and AI systems. The\nSTOOD-X methodology therefore offers a robust, explainable, and scalable\nsolution for real-world OOD detection tasks.",
      "tldr_zh": "该研究提出 STOOD-X 方法，一种两阶段框架，用于 Out-of-Distribution (OOD) 检测，旨在解决现有方法在分布假设、可扩展性和可解释性方面的局限。STOOD-X 的第一阶段利用特征空间距离和 Wilcoxon-Mann-Whitney 测试来识别 OOD 样本，而不依赖特定分布假设；第二阶段则生成基于概念的可视化解释，支持 BLUE XAI 范式，以揭示决策驱动因素。在基准数据集和多种架构的实验中，STOOD-X 展现出与最先进后验 OOD 检测器相当的性能，尤其在高维复杂场景中，并通过增强可解释性促进人类监督、偏差检测和模型调试。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02685v1",
      "published_date": "2025-04-03 15:26:03 UTC",
      "updated_date": "2025-04-03 15:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:13:08.172178"
    },
    {
      "arxiv_id": "2504.02670v2",
      "title": "Affordable AI Assistants with Knowledge Graph of Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Besta",
        "Lorenzo Paleari",
        "Jia Hao Andrea Jiang",
        "Robert Gerstenberger",
        "You Wu",
        "Patrick Iff",
        "Ales Kubicek",
        "Piotr Nyczyk",
        "Diana Khimey",
        "Jón Gunnar Hannesson",
        "Grzegorz Kwaśniewski",
        "Marcin Copik",
        "Hubert Niewiadomski",
        "Torsten Hoefler"
      ],
      "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.",
      "tldr_zh": "该研究提出Knowledge Graph of Thoughts (KGoT)，一种创新AI助手架构，将LLM推理与动态知识图(KGs)整合，以解决当前LLM驱动代理的高成本和在GAIA等复杂基准上的低成功率问题。KGoT通过从任务中提取相关知识构建动态KG，并利用外部工具如数学求解器、网络爬虫和Python脚本进行迭代增强，从而使低成本模型也能有效处理复杂任务。在GAIA基准测试中，KGoT相较Hugging Face Agents with GPT-4o mini提高了29%的任务成功率，同时将成本降低了超过36倍；对于其他模型如Qwen2.5-32B和Deepseek-R1-70B，成功率提升分别为36%和37.5%。总之，KGoT提供了一个可扩展、负担得起且高性能的AI助手解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02670v2",
      "published_date": "2025-04-03 15:11:55 UTC",
      "updated_date": "2025-04-10 14:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:13:19.670946"
    },
    {
      "arxiv_id": "2504.02654v1",
      "title": "SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning",
      "title_zh": "SymDQN：神经网络强化学习中的符号知识与推理",
      "authors": [
        "Ivo Amador",
        "Nina Gierasimczuk"
      ],
      "abstract": "We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.",
      "tldr_zh": "本研究提出SymDQN，一种模块化架构，将符号知识和推理融入基于Dueling Deep Q-Networks (DuelDQN)的神经网络强化学习中，允许代理在环境中进行更一致的推理和行为指导。SymDQN通过Logic Tensor Networks (LTNs)模块增强行动策略学习，支持形状识别和奖励预测。实验在5x5网格环境中进行消融研究，结果显示SymDQN显著提高了代理的学习性能和精确性。该设计还便于反思神经与符号方法在强化学习中的复杂性结合。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.NE",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02654v1",
      "published_date": "2025-04-03 14:51:11 UTC",
      "updated_date": "2025-04-03 14:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:13:32.471352"
    },
    {
      "arxiv_id": "2504.02646v1",
      "title": "Prompt Optimization with Logged Bandit Data",
      "title_zh": "翻译失败",
      "authors": [
        "Haruka Kiyohara",
        "Daniel Yiming Cao",
        "Yuta Saito",
        "Thorsten Joachims"
      ],
      "abstract": "We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.",
      "tldr_zh": "这篇论文探讨了如何利用用户反馈（如点击）来优化大语言模型（LLM）的提示，以生成个性化的句子。传统方法在提示空间估计policy gradient时，面临因庞大动作空间导致的方差和不准确奖励预测导致的偏差问题。为此，论文提出了一种新型kernel-based off-policy gradient method，通过利用生成句子的相似性来估计策略梯度，从而显著降低方差并抑制偏差。在新建立的基准测试套件上，实验证明该方法在生成电影推荐的个性化描述方面特别有效，尤其适用于候选提示数量庞大的场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.02646v1",
      "published_date": "2025-04-03 14:40:40 UTC",
      "updated_date": "2025-04-03 14:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:13:43.736984"
    },
    {
      "arxiv_id": "2504.02623v3",
      "title": "Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions",
      "title_zh": "多任务工具基准：通过相关和动态任务评估基于 LLM 的代理的鲁棒性",
      "authors": [
        "Peijie Yu",
        "Yifan Yang",
        "Jinjian Li",
        "Zelong Zhang",
        "Haorui Wang",
        "Xiao Feng",
        "Feng Zhang"
      ],
      "abstract": "Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.",
      "tldr_zh": "本研究提出 Multi-Mission Tool Bench 基准，用于评估 LLM-based agents 在相关和动态任务场景中的鲁棒性，因为现有基准主要局限于单一任务，无法反映真实世界的复杂性。该基准设计每个测试案例包含多个相互关联的任务，并探索固定任务数下的所有任务切换模式，同时采用多代理数据生成框架进行构建，并引入动态决策树方法来评估代理的准确性和效率。实验在多种开源和闭源 LLMs 上进行，揭示了影响代理鲁棒性的关键因素，并为工具调用社区提供可操作的见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02623v3",
      "published_date": "2025-04-03 14:21:33 UTC",
      "updated_date": "2025-04-16 06:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:13:57.512273"
    },
    {
      "arxiv_id": "2504.02620v1",
      "title": "Efficient Model Editing with Task-Localized Sparse Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Iurada",
        "Marco Ciccone",
        "Tatiana Tommasi"
      ],
      "abstract": "Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.",
      "tldr_zh": "该研究针对模型编辑中的效率问题，提出TaLoS方法，通过Task-Localized Sparse Fine-tuning构建稀疏任务向量，避免了传统Task Arithmetic依赖的网络线性化，从而减少计算瓶颈并促进权重解耦。TaLoS识别预训练模型中梯度敏感度低的参数子集，仅对这些参数进行稀疏更新，并在任务间共享信息，以实现无冲突的任务向量组合。实验结果显示，TaLoS在任务添加和否定上优于现有方法，提高了训练和推理效率，并支持模块化参数编辑，推动基础模型在实际应用的部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted ICLR 2025 - https://github.com/iurada/talos-task-arithmetic",
      "pdf_url": "http://arxiv.org/pdf/2504.02620v1",
      "published_date": "2025-04-03 14:20:06 UTC",
      "updated_date": "2025-04-03 14:20:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:14:06.888147"
    },
    {
      "arxiv_id": "2504.02607v1",
      "title": "Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Tesfazgi",
        "Leonhard Sprandl",
        "Sandra Hirche"
      ],
      "abstract": "The practical deployment of learning-based autonomous systems would greatly\nbenefit from tools that flexibly obtain safety guarantees in the form of\ncertificate functions from data. While the geometrical properties of such\ncertificate functions are well understood, synthesizing them using machine\nlearning techniques still remains a challenge. To mitigate this issue, we\npropose a diffeomorphic function learning framework where prior structural\nknowledge of the desired output is encoded in the geometry of a simple\nsurrogate function, which is subsequently augmented through an expressive,\ntopology-preserving state-space transformation. Thereby, we achieve an indirect\nfunction approximation framework that is guaranteed to remain in the desired\nhypothesis space. To this end, we introduce a novel approach to construct\ndiffeomorphic maps based on RBF networks, which facilitate precise, local\ntransformations around data. Finally, we demonstrate our approach by learning\ndiffeomorphic Lyapunov functions from real-world data and apply our method to\ndifferent attractor systems.",
      "tldr_zh": "该研究提出了一种基于深层微分同胚（diffeomorphic）RBF网络的框架，用于从数据中学习几何信息丰富的Lyapunov functions，从而为基于学习的自主系统提供安全保证。框架通过将期望输出的结构知识编码到一个简单代理函数中，并应用表现力强的拓扑保持状态空间变换，实现对函数的间接逼近，确保输出始终处于预定义的假设空间中。作者引入了一种新方法，利用RBF networks构建精确的局部微分同胚映射，并在真实世界数据上学习diffeomorphic Lyapunov functions，并应用于不同吸引子（attractor）系统，展示了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02607v1",
      "published_date": "2025-04-03 14:09:17 UTC",
      "updated_date": "2025-04-03 14:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:14:19.319998"
    },
    {
      "arxiv_id": "2504.02606v1",
      "title": "Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification",
      "title_zh": "通过不确定性量化改善分子属性预测的反事实真实性",
      "authors": [
        "Jonas Teufel",
        "Annika Leinweber",
        "Pascal Friederich"
      ],
      "abstract": "Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.",
      "tldr_zh": "这篇论文针对分子属性预测，提出通过不确定性量化(uncertainty quantification)来提升反事实真实性(counterfactual truthfulness)，以确保反事实解释(counterfactual explanations)更准确地反映真实属性分布。作者的方法包括整合不确定性估计技术，如集成模型(ensembles)和均值-方差估计(mean-variance estimation)，用于过滤高不确定性的反事实候选。实验在合成和真实数据集上证明，这些技术显著降低了平均预测错误，并在分布外(out-of-distribution)场景中提高了真实性。结果突出了在Explainable AI (xAI)中加入不确定性估计的潜在影响，特别是通过低成本干预如模型集成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 5 figures, 4 tabels, accepted at the 3rd xAI World\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.02606v1",
      "published_date": "2025-04-03 14:07:30 UTC",
      "updated_date": "2025-04-03 14:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:14:33.323190"
    },
    {
      "arxiv_id": "2504.02605v1",
      "title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving",
      "title_zh": "翻译失败",
      "authors": [
        "Daoguang Zan",
        "Zhirong Huang",
        "Wei Liu",
        "Hanwu Chen",
        "Linhao Zhang",
        "Shulin Xin",
        "Lu Chen",
        "Qi Liu",
        "Xiaojian Zhong",
        "Aoyan Li",
        "Siyao Liu",
        "Yongsheng Xiao",
        "Liangqiang Chen",
        "Yuyu Zhang",
        "Jing Su",
        "Tianyu Liu",
        "Rui Long",
        "Kai Shen",
        "Liang Xiang"
      ],
      "abstract": "The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.",
      "tldr_zh": "本研究引入了 Multi-SWE-bench，这是一个多语言基准，用于评估 Large Language Models (LLMs) 在 issue-resolving 任务中的性能，涵盖 Java、TypeScript、JavaScript、Go、Rust、C 和 C++ 等七种编程语言，总计 1,632 个高质量实例，由 68 名专家从 2,456 个候选中精心标注。相比现有基准如 SWE-bench，该框架解决了 LLMs 在多样软件生态评估的不足，并通过 Agentless、SWE-agent 和 OpenHands 等三种方法评估了一系列 state-of-the-art 模型，提供全面的经验分析。研究者还启动了 Multi-SWE-RL 开源社区，发布 4,723 个结构化的 RL 训练数据集实例，并开源整个数据生产管道，以鼓励社区持续贡献。总体而言，这一工作为推进 reinforcement learning (RL) 在 issue-resolving 领域的应用奠定基础，并推动 AGI 的发展。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02605v1",
      "published_date": "2025-04-03 14:06:17 UTC",
      "updated_date": "2025-04-03 14:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:14:44.943949"
    },
    {
      "arxiv_id": "2504.02589v1",
      "title": "Knowledge Graph Completion with Mixed Geometry Tensor Factorization",
      "title_zh": "翻译失败",
      "authors": [
        "Viacheslav Yusupov",
        "Maxim Rakhuba",
        "Evgeny Frolov"
      ],
      "abstract": "In this paper, we propose a new geometric approach for knowledge graph\ncompletion via low rank tensor approximation. We augment a pretrained and\nwell-established Euclidean model based on a Tucker tensor decomposition with a\nnovel hyperbolic interaction term. This correction enables more nuanced\ncapturing of distributional properties in data better aligned with real-world\nknowledge graphs. By combining two geometries together, our approach improves\nexpressivity of the resulting model achieving new state-of-the-art link\nprediction accuracy with a significantly lower number of parameters compared to\nthe previous Euclidean and hyperbolic models.",
      "tldr_zh": "本文提出了一种混合几何张量因子分解方法，用于Knowledge Graph Completion，通过低秩张量逼近来提升模型性能。具体而言，该方法在预训练的Euclidean模型（基于Tucker tensor decomposition）上添加了新的Hyperbolic interaction term，以更精确地捕捉真实世界知识图谱中的数据分布特性。相比之前的Euclidean和Hyperbolic模型，该方法显著提高了Link Prediction准确率，同时参数数量更少，实现了新的state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02589v1",
      "published_date": "2025-04-03 13:54:43 UTC",
      "updated_date": "2025-04-03 13:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:14:55.109045"
    },
    {
      "arxiv_id": "2504.02586v1",
      "title": "Deep learning for music generation. Four approaches and their comparative evaluation",
      "title_zh": "深度学习用于音乐生成：四种方法及其比较评估",
      "authors": [
        "Razvan Paroiu",
        "Stefan Trausan-Matu"
      ],
      "abstract": "This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.",
      "tldr_zh": "本论文介绍了四种深度学习算法用于音乐生成，包括修改的visual transformer神经网络作为语言模型、结合chat sonification的经典transformer神经网络、结合Schillinger rhythm theory的transformer神经网络，以及OpenAI的GPT3 transformer，并评估它们在审美质量和特定应用上的表现。研究通过生成和比较多组旋律，分析了这些方法的差异。结果显示，GPT3生成的音乐在审美价值上最出色，而Schillinger rhythm theory方法比之前的sonification方法更具优势。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02586v1",
      "published_date": "2025-04-03 13:51:07 UTC",
      "updated_date": "2025-04-03 13:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:15:07.899545"
    },
    {
      "arxiv_id": "2504.16937v1",
      "title": "A Framework for the Assurance of AI-Enabled Systems",
      "title_zh": "AI 启用系统的保证框架",
      "authors": [
        "Ariel S. Kapusta",
        "David Jin",
        "Peter M. Teague",
        "Robert A. Houston",
        "Jonathan B. Elliott",
        "Grace Y. Park",
        "Shelby S. Holdren"
      ],
      "abstract": "The United States Department of Defense (DOD) looks to accelerate the\ndevelopment and deployment of AI capabilities across a wide spectrum of defense\napplications to maintain strategic advantages. However, many common features of\nAI algorithms that make them powerful, such as capacity for learning,\nlarge-scale data ingestion, and problem-solving, raise new technical, security,\nand ethical challenges. These challenges may hinder adoption due to uncertainty\nin development, testing, assurance, processes, and requirements.\nTrustworthiness through assurance is essential to achieve the expected value\nfrom AI.\n  This paper proposes a claims-based framework for risk management and\nassurance of AI systems that addresses the competing needs for faster\ndeployment, successful adoption, and rigorous evaluation. This framework\nsupports programs across all acquisition pathways provide grounds for\nsufficient confidence that an AI-enabled system (AIES) meets its intended\nmission goals without introducing unacceptable risks throughout its lifecycle.\nThe paper's contributions are a framework process for AI assurance, a set of\nrelevant definitions to enable constructive conversations on the topic of AI\nassurance, and a discussion of important considerations in AI assurance. The\nframework aims to provide the DOD a robust yet efficient mechanism for swiftly\nfielding effective AI capabilities without overlooking critical risks or\nundermining stakeholder trust.",
      "tldr_zh": "这篇论文针对美国国防部（DOD）加速AI能力开发面临的挑战，提出一个基于claims的框架，用于AI启用系统（AI-Enabled Systems, AIES）的风险管理和assurance。该框架平衡快速部署、成功采用和严格评估的需求，通过定义框架过程、相关术语以及关键考虑，帮助确保AIES在整个生命周期内实现预期使命目标而不引入不可接受的风险。论文的贡献包括提供一个稳健机制，支持DOD在维护战略优势的同时，提升AI系统的可信度和利益相关者信任。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 2 figures, published in conference proceedings of SPIE\n  Defense and Commercial Sensing conference on Assurance and Security for\n  AI-enabled Systems 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16937v1",
      "published_date": "2025-04-03 13:44:01 UTC",
      "updated_date": "2025-04-03 13:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:15:19.659882"
    },
    {
      "arxiv_id": "2504.02577v1",
      "title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning",
      "title_zh": "深度学习中的推理不一致性以及如何缓解它们",
      "authors": [
        "Erik Arakelyan"
      ],
      "abstract": "The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.",
      "tldr_zh": "这篇论文探讨了深度学习模型中的推理不一致问题，如矛盾输出、泛化失败和逻辑错误，这些问题源于模型内部不透明、训练数据偏差或任务复杂性。论文贡献了两种技术，用于检测和量化自然语言和图像处理模型中的预测不一致；同时提出了一种数据高效采样方法来改善公平性和性能，以及一种合成数据集生成方法适用于资源有限的场景。最终，论文提供了优化复杂推理任务的两种技巧，构建了一个全面框架，提升深度学习模型的鲁棒性、公平性和可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2504.02577v1",
      "published_date": "2025-04-03 13:40:55 UTC",
      "updated_date": "2025-04-03 13:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:15:33.240096"
    },
    {
      "arxiv_id": "2504.02917v1",
      "title": "Bias in Large Language Models Across Clinical Applications: A Systematic Review",
      "title_zh": "大语言模型在临床应用中的偏见：系统综述",
      "authors": [
        "Thanathip Suenghataiphorn",
        "Narisara Tribuddharat",
        "Pojsakorn Danpanichkul",
        "Narathorn Kulthamrongsri"
      ],
      "abstract": "Background: Large language models (LLMs) are rapidly being integrated into\nhealthcare, promising to enhance various clinical tasks. However, concerns\nexist regarding their potential for bias, which could compromise patient care\nand exacerbate health inequities. This systematic review investigates the\nprevalence, sources, manifestations, and clinical implications of bias in LLMs.\nMethods: We conducted a systematic search of PubMed, OVID, and EMBASE from\ndatabase inception through 2025, for studies evaluating bias in LLMs applied to\nclinical tasks. We extracted data on LLM type, bias source, bias manifestation,\naffected attributes, clinical task, evaluation methods, and outcomes. Risk of\nbias was assessed using a modified ROBINS-I tool. Results: Thirty-eight studies\nmet inclusion criteria, revealing pervasive bias across various LLMs and\nclinical applications. Both data-related bias (from biased training data) and\nmodel-related bias (from model training) were significant contributors. Biases\nmanifested as: allocative harm (e.g., differential treatment recommendations);\nrepresentational harm (e.g., stereotypical associations, biased image\ngeneration); and performance disparities (e.g., variable output quality). These\nbiases affected multiple attributes, most frequently race/ethnicity and gender,\nbut also age, disability, and language. Conclusions: Bias in clinical LLMs is a\npervasive and systemic issue, with a potential to lead to misdiagnosis and\ninappropriate treatment, particularly for marginalized patient populations.\nRigorous evaluation of the model is crucial. Furthermore, the development and\nimplementation of effective mitigation strategies, coupled with continuous\nmonitoring in real-world clinical settings, are essential to ensure the safe,\nequitable, and trustworthy deployment of LLMs in healthcare.",
      "tldr_zh": "这篇系统综述审查了大型语言模型 (LLMs) 在临床应用中的偏见问题，包括其流行性、来源、表现形式及临床影响。研究通过搜索 PubMed、OVID 和 EMBASE 数据库，并使用修改后的 ROBINS-I 工具评估 38 篇相关研究，发现偏见主要源于训练数据和模型训练，表现为分配性伤害（如差异化治疗推荐）、代表性伤害（如刻板印象）以及性能差异，常影响种族/民族、性别、年龄等属性。结论指出，LLMs 的偏见可能导致误诊和不当治疗，特别是对边缘化群体，因此需要严格评估、实施缓解策略并进行持续监控，以确保其在医疗领域的公平和可信部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02917v1",
      "published_date": "2025-04-03 13:32:08 UTC",
      "updated_date": "2025-04-03 13:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:15:44.981975"
    },
    {
      "arxiv_id": "2504.02558v1",
      "title": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Dumitriu",
        "Florin Tatui",
        "Florin Miron",
        "Radu Tudor Ionescu",
        "Radu Timofte"
      ],
      "abstract": "Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.",
      "tldr_zh": "本论文针对 rip current 导致的海滩事故，提出 rip current 实例分割的新任务，并发布了一个包含 2,466 张图像（用于训练和验证）和 17 个无人机视频（约 24K 帧，用于测试）的标注数据集。研究团队训练了 YOLOv8 的各种版本进行实例分割，其中 YOLOv8-nano 模型表现出色，在验证集上达到 88.94% mAP50，在测试集上为 81.21% 宏平均。论文提供了这些基线结果，并公开了代码、训练细节和数据集，以支持未来 rip current 检测研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2023 NTIRE Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.02558v1",
      "published_date": "2025-04-03 13:14:16 UTC",
      "updated_date": "2025-04-03 13:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:15:56.577533"
    },
    {
      "arxiv_id": "2504.02546v3",
      "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning",
      "title_zh": "GPG：一个简单且强大的强化学习基线，用于模型推理",
      "authors": [
        "Xiangxiang Chu",
        "Hailang Huang",
        "Xiao Zhang",
        "Fei Wei",
        "Yong Wang"
      ],
      "abstract": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. By eliminating the critic and\nreference models, avoiding KL divergence constraints, and addressing the\nadvantage and gradient estimation bias, our approach significantly simplifies\nthe training process compared to Group Relative Policy Optimization (GRPO). Our\napproach achieves superior performance without relying on auxiliary techniques\nor adjustments. As illustrated in Figure 1, extensive experiments demonstrate\nthat our method not only reduces computational costs but also consistently\noutperforms GRPO across various unimodal and multimodal tasks. Our code is\navailable at https://github.com/AMAP-ML/GPG.",
      "tldr_zh": "该研究提出了一种名为 Group Policy Gradient (GPG) 的简单强化学习 (RL) 方法，作为提升大型语言模型推理能力的基线，避免了对 Supervised Fine-Tuning (SFT) 的过度依赖。GPG 通过直接优化原始 RL 目标，移除 critic 和参考模型、避免 KL divergence 约束，并解决优势和梯度估计偏差，从而简化了训练过程，与 Group Relative Policy Optimization (GRPO) 相比更高效。实验结果表明，GPG 在各种单模态和多模态任务上表现出色，计算成本更低，并实现了稳定的性能提升。代码已开源，可供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02546v3",
      "published_date": "2025-04-03 12:53:41 UTC",
      "updated_date": "2025-05-01 15:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:16:08.024855"
    },
    {
      "arxiv_id": "2504.02544v2",
      "title": "Fourier Sliced-Wasserstein Embedding for Multisets and Measures",
      "title_zh": "翻译失败",
      "authors": [
        "Tal Amir",
        "Nadav Dym"
      ],
      "abstract": "We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.",
      "tldr_zh": "本研究提出了一种新的嵌入方法，Fourier Sliced-Wasserstein (FSW) 嵌入，用于将多集（multisets）和测度（measures）嵌入到欧氏空间中，从而近似保留切片 Wasserstein 距离，并提供更能捕捉输入结构的几何表示。FSW 嵌入在测度上具有注入性（injective），在多集上具有双 Lipschitz（bi-Lipschitz）属性，这比基于 sum- 或 max-pooling 的传统方法更优，后者往往缺乏这些度量保证，且所需的输出维度近似最优，为约 2 N d，其中 N 是最大输入多集大小。研究还证明，将分布嵌入欧氏空间中以 bi-Lipschitz 方式是不可能的，因此 FSW 的属性达到了最佳可能水平。通过数值实验，FSW 嵌入显著提升了实际学习任务的性能，例如与 MLP 结合实现了学习 (non-sliced) Wasserstein 距离的 state-of-the-art 效果，且在 PointNet 中替换 max-pooling 后，使模型对参数减少更鲁棒，即使减少 40 倍，性能仅轻微下降。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an erroneous submission that duplicates arXiv:2405.16519. It\n  has been withdrawn; please see arXiv:2405.16519 for the intended version and\n  all future updates",
      "pdf_url": "http://arxiv.org/pdf/2504.02544v2",
      "published_date": "2025-04-03 12:51:40 UTC",
      "updated_date": "2025-04-14 13:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:16:21.527611"
    },
    {
      "arxiv_id": "2504.02526v1",
      "title": "Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity",
      "title_zh": "翻译失败",
      "authors": [
        "Jeba Rezwana",
        "Corey Ford"
      ],
      "abstract": "How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.",
      "tldr_zh": "这篇论文介绍了 FAICO 框架，旨在通过优化 AI 沟通来提升人类-AI 协同创造（Human-AI Co-Creativity）中的用户体验。基于对 107 篇论文的系统回顾，FAICO 强调了 AI 沟通的关键方面及其对用户体验的影响，并提供了设计卡片和配置工具作为实用应用。设计卡片帮助设计师制定适应不同用户的 AI 沟通策略，而配置工具让用户根据自身需求自定义 AI 交互。该框架为 Human-Computer Interaction 领域贡献了新见解，促进更有效的 AI 协作设计。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02526v1",
      "published_date": "2025-04-03 12:29:53 UTC",
      "updated_date": "2025-04-03 12:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:16:32.157147"
    },
    {
      "arxiv_id": "2504.02512v1",
      "title": "Towards Generalizing Temporal Action Segmentation to Unseen Views",
      "title_zh": "翻译失败",
      "authors": [
        "Emad Bahrami",
        "Olga Zatsarynna",
        "Gianpiero Francesca",
        "Juergen Gall"
      ],
      "abstract": "While there has been substantial progress in temporal action segmentation,\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\ndefine a protocol for unseen view action segmentation where camera views for\nevaluating the model are unavailable during training. This includes changing\nfrom top-frontal views to a side view or even more challenging from exocentric\nto egocentric views. Furthermore, we present an approach for temporal action\nsegmentation that tackles this challenge. Our approach leverages a shared\nrepresentation at both the sequence and segment levels to reduce the impact of\nview differences during training. We achieve this by introducing a sequence\nloss and an action loss, which together facilitate consistent video and action\nrepresentations across different views. The evaluation on the Assembly101,\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\nimprovement for unseen egocentric views.",
      "tldr_zh": "这篇论文针对 temporal action segmentation 在泛化到 unseen views 的挑战，定义了一个新的评估协议，包括从 top-frontal 视图切换到 side view，或从 exocentric 到 egocentric 视图。作者提出了一种方法，通过在序列和段级使用共享表示、sequence loss 和 action loss，来减少视图差异对模型的影响，从而保持视频和动作表示的一致性。在 Assembly101、IkeaASM 和 EgoExoLearn 数据集上的实验显示，该方法显著提升了性能，在 unseen exocentric views 的 F1@50 提高了 12.8%，而在 unseen egocentric views 上取得了 54% 的实质性改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02512v1",
      "published_date": "2025-04-03 11:53:59 UTC",
      "updated_date": "2025-04-03 11:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:16:44.076381"
    },
    {
      "arxiv_id": "2504.02509v1",
      "title": "A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders",
      "title_zh": "一种记忆增强的LLM驱动方法，用于3D打印工作订单的自主合并",
      "authors": [
        "Yuhao Liu",
        "Maolin Yang",
        "Pingyu Jiang"
      ],
      "abstract": "With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Model (LLM) 的方法，用于自动合并 3D 打印工作订单，并整合 memory-augmented learning 策略，以提升工业生产效率。方法包括将设备和订单特征建模为 LLM 可读的自然语言提示模板，并开发订单-设备匹配工具和合并干扰检查模块。借助自记忆学习策略构建智能代理，该方法显著提高了订单分配的准确性和精确性，同时减少了 hallucination，在工业应用中充分发挥了 LLM 的优势。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02509v1",
      "published_date": "2025-04-03 11:50:29 UTC",
      "updated_date": "2025-04-03 11:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:16:56.186950"
    },
    {
      "arxiv_id": "2504.03777v1",
      "title": "Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay",
      "title_zh": "翻译失败",
      "authors": [
        "Hussain Jagirdar",
        "Rukma Talwadker",
        "Aditya Pareek",
        "Pulkit Agrawal",
        "Tridib Mukherjee"
      ],
      "abstract": "Multi-variate Time Series (MTS) forecasting has made large strides (with very\nnegligible errors) through recent advancements in neural networks, e.g.,\nTransformers. However, in critical situations like predicting gaming\noverindulgence that affects one's mental well-being; an accurate forecast\nwithout a contributing evidence (explanation) is irrelevant. Hence, it becomes\nimportant that the forecasts are Interpretable - intermediate representation of\nthe forecasted trajectory is comprehensible; as well as Explainable - attentive\ninput features and events are accessible for a personalized and timely\nintervention of players at risk. While the contributing state of the art\nresearch on interpretability primarily focuses on temporally-smooth\nsingle-process driven time series data, our online multi-player gameplay data\ndemonstrates intractable temporal randomness due to intrinsic orthogonality\nbetween player's game outcome and their intent to engage further. We introduce\na novel deep Actionable Forecasting Network (AFN), which addresses the\ninter-dependent challenges associated with three exclusive objectives - 1)\nforecasting accuracy; 2) smooth comprehensible trajectory and 3) explanations\nvia multi-dimensional input features while tackling the challenges introduced\nby our non-smooth temporal data, together in one single solution. AFN\nestablishes a \\it{new benchmark} via: (i) achieving 25% improvement on the MSE\nof the forecasts on player data in comparison to the SOM-VAE based SOTA\nnetworks; (ii) attributing unfavourable progression of a player's time series\nto a specific future time step(s), with the premise of eliminating near-future\noverindulgent player volume by over 18% with player specific actionable inputs\nfeature(s) and (iii) proactively detecting over 23% (100% jump from SOTA) of\nthe to-be overindulgent, players on an average, 4 weeks in advance.",
      "tldr_zh": "这篇论文针对非平滑的多变量时间序列 (Multivariate Time Series, MTS) 预测，提出了一种可解释和可解释的 Actionable Forecasting Network (AFN)，旨在为负责任的游戏玩法提供准确预测，同时提供可理解的轨迹和解释性特征，以及针对玩家的个性化干预。AFN 同时处理预测准确性、轨迹平滑性和多维输入特征解释的挑战，适用于游戏数据中的临时随机性问题。实验结果显示，AFN 在 MSE 上比现有最先进网络（如 SOM-VAE）改善 25%，并能将玩家的不利进展归因于特定未来时间步，从而减少 18% 的近未来过度沉迷玩家，并提前 4 周检测 23% 的潜在过度沉迷玩家。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03777v1",
      "published_date": "2025-04-03 11:49:24 UTC",
      "updated_date": "2025-04-03 11:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:17:08.119717"
    },
    {
      "arxiv_id": "2504.02495v2",
      "title": "Inference-Time Scaling for Generalist Reward Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Zijun Liu",
        "Peiyi Wang",
        "Runxin Xu",
        "Shirong Ma",
        "Chong Ruan",
        "Peng Li",
        "Yang Liu",
        "Yu Wu"
      ],
      "abstract": "Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.",
      "tldr_zh": "该研究探讨了强化学习（RL）在训练大型语言模型（LLMs）中的应用，特别关注如何通过推理时间可扩展性提升通用奖励建模（RM）的性能，以为各种领域提供准确奖励信号。作者提出Self-Principled Critique Tuning (SPCT)方法，结合点式生成奖励建模（GRM）和在线RL，开发出DeepSeek-GRM模型，该模型通过并行采样和元RM引导投票过程，适应性地生成原则并提升批判准确性。实验结果显示，SPCT显著提高了GRM的质量和可扩展性，在多个RM基准测试中优于现有方法，且推理时间扩展的效果优于训练时间扩展，尽管在某些任务中仍存在挑战。模型将开源，以推动通用奖励系统的未来发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, under review. 42 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.02495v2",
      "published_date": "2025-04-03 11:19:49 UTC",
      "updated_date": "2025-04-05 17:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:17:20.875039"
    },
    {
      "arxiv_id": "2504.02492v1",
      "title": "Industrial Internet Robot Collaboration System and Edge Computing Optimization",
      "title_zh": "工业互联网机器人协作系统和边缘计算优化",
      "authors": [
        "Qian Zuo",
        "Dajun Tao",
        "Tian Qi",
        "Jieyi Xie",
        "Zijie Zhou",
        "Zhen Tian",
        "Yu Mingyu"
      ],
      "abstract": "In a complex environment, for a mobile robot to safely and collision - free\navoid all obstacles, it poses high requirements for its intelligence level.\nGiven that the information such as the position and geometric characteristics\nof obstacles is random, the control parameters of the robot, such as velocity\nand angular velocity, are also prone to random deviations. To address this\nissue in the framework of the Industrial Internet Robot Collaboration System,\nthis paper proposes a global path control scheme for mobile robots based on\ndeep learning. First of all, the dynamic equation of the mobile robot is\nestablished. According to the linear velocity and angular velocity of the\nmobile robot, its motion behaviors are divided into obstacle - avoidance\nbehavior, target - turning behavior, and target approaching behavior.\nSubsequently, the neural network method in deep learning is used to build a\nglobal path planning model for the robot. On this basis, a fuzzy controller is\ndesigned with the help of a fuzzy control algorithm to correct the deviations\nthat occur during path planning, thereby achieving optimized control of the\nrobot's global path. In addition, considering edge computing optimization, the\nproposed model can process local data at the edge device, reducing the\ncommunication burden between the robot and the central server, and improving\nthe real time performance of path planning. The experimental results show that\nfor the mobile robot controlled by the research method in this paper, the\ndeviation distance of the path angle is within 5 cm, the deviation convergence\ncan be completed within 10 ms, and the planned path is shorter. This indicates\nthat the proposed scheme can effectively improve the global path planning\nability of mobile robots in the industrial Internet environment and promote the\ncollaborative operation of robots through edge computing optimization.",
      "tldr_zh": "本文提出了一种基于 deep learning 的全局路径控制方案，旨在解决工业互联网机器人协作系统（Industrial Internet Robot Collaboration System）中移动机器人在复杂环境下的避障问题，包括随机障碍物信息导致的控制参数偏差。该方案首先建立移动机器人的动态方程，将其运动行为分为避障、目标转向和目标接近，并利用神经网络构建全局路径规划模型，同时设计 fuzzy controller 修正路径偏差以优化控制。结合 edge computing 优化，该方法在边缘设备处理本地数据，减少通信负担并提升实时性能。实验结果表明，路径角度偏差控制在 5 cm 以内，偏差收敛时间小于 10 ms，且规划路径更短，有效提高了机器人在工业环境中的协作能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02492v1",
      "published_date": "2025-04-03 11:15:10 UTC",
      "updated_date": "2025-04-03 11:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:17:32.286457"
    },
    {
      "arxiv_id": "2504.02912v1",
      "title": "Haphazard Inputs as Images in Online Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Agarwal",
        "Aryan Dessai",
        "Arif Ahmed Sekh",
        "Krishna Agarwal",
        "Alexander Horsch",
        "Dilip K. Prasad"
      ],
      "abstract": "The field of varying feature space in online learning settings, also known as\nhaphazard inputs, is very prominent nowadays due to its applicability in\nvarious fields. However, the current solutions to haphazard inputs are\nmodel-dependent and cannot benefit from the existing advanced deep-learning\nmethods, which necessitate inputs of fixed dimensions. Therefore, we propose to\ntransform the varying feature space in an online learning setting to a\nfixed-dimension image representation on the fly. This simple yet novel approach\nis model-agnostic, allowing any vision-based models to be applicable for\nhaphazard inputs, as demonstrated using ResNet and ViT. The image\nrepresentation handles the inconsistent input data seamlessly, making our\nproposed approach scalable and robust. We show the efficacy of our method on\nfour publicly available datasets. The code is available at\nhttps://github.com/Rohit102497/HaphazardInputsAsImages.",
      "tldr_zh": "本文提出了一种处理在线学习中haphazard inputs（变化特征空间）的方法，通过实时转换为固定维度的图像表示，以克服现有解决方案的模型依赖性问题。该方法是model-agnostic的，允许直接应用先进的视觉模型如ResNet和ViT，从而无缝处理不一致输入数据，并提升系统的可扩展性和鲁棒性。在四个公开数据集上进行的实验证明了该方法的有效性，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02912v1",
      "published_date": "2025-04-03 11:14:05 UTC",
      "updated_date": "2025-04-03 11:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:17:43.502499"
    },
    {
      "arxiv_id": "2504.02489v1",
      "title": "The Self-Learning Agent with a Progressive Neural Network Integrated Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Ajay Sivakumar",
        "Shalini",
        "Vasantha Raj",
        "Sebastian Sylvester"
      ],
      "abstract": "This paper introduces a self-learning agent that integrates LLaMA 3.2 with a\nProgressive Neural Network (PNN) for continual learning in conversational AI\nand code generation. The framework dynamically collects data, fine-tunes tasks\nwith minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA\noptimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances\nknowledge retention. Experimental results demonstrate improved adaptability and\nmemory stability, positioning this approach as a scalable step toward\nArtificial General Intelligence (AGI).",
      "tldr_zh": "本论文提出了一种自学习代理，将 LLaMA 3.2 与 Progressive Neural Network (PNN) 整合，用于对话 AI 和代码生成的持续学习。框架通过动态数据收集、最小样本微调和 Meta-Learning 实现快速适应，同时利用 LoRA 优化微调过程，并通过 Elastic Weight Consolidation (EWC) 增强知识保留。实验结果显示，该方法显著提高了适应性和记忆稳定性，并将其定位为通向 Artificial General Intelligence (AGI) 的可扩展途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures, focuses on continual learning with PNN and LLaMA.\n  Experiments demonstrate scalability and lifelong learning capabilities",
      "pdf_url": "http://arxiv.org/pdf/2504.02489v1",
      "published_date": "2025-04-03 11:13:31 UTC",
      "updated_date": "2025-04-03 11:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:17:55.079129"
    },
    {
      "arxiv_id": "2504.02486v1",
      "title": "We Need Improved Data Curation and Attribution in AI for Scientific Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Mara Graziani",
        "Antonio Foncubierta",
        "Dimitrios Christofidellis",
        "Irina Espejo-Morales",
        "Malina Molnar",
        "Marvin Alberts",
        "Matteo Manica",
        "Jannis Born"
      ],
      "abstract": "As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.",
      "tldr_zh": "这篇论文探讨了AI在科学发现中数据完整性和模型稳定性的挑战，强调合成数据与真实实验数据的区别日益模糊，且约四分之三的开放平台实验数据集采用率较低。作者通过分析提出解决方案，包括加强合成数据检测并增加对真实实验数据的watermarking，以提升数据可追溯性和可用性。研究估计，即使watermarking不到一半的年度真实世界数据，也能维持模型稳健性，并促进合成数据与人类生成内容的平衡整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02486v1",
      "published_date": "2025-04-03 11:07:52 UTC",
      "updated_date": "2025-04-03 11:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:18:07.682950"
    },
    {
      "arxiv_id": "2504.02911v1",
      "title": "Noiser: Bounded Input Perturbations for Attributing Large Language Models",
      "title_zh": "Noiser：用于归因大型语言模型的受限输入扰动",
      "authors": [
        "Mohammad Reza Ghasemi Madani",
        "Aryo Pradipta Gema",
        "Gabriele Sarti",
        "Yu Zhao",
        "Pasquale Minervini",
        "Andrea Passerini"
      ],
      "abstract": "Feature attribution (FA) methods are common post-hoc approaches that explain\nhow Large Language Models (LLMs) make predictions. Accordingly, generating\nfaithful attributions that reflect the actual inner behavior of the model is\ncrucial. In this paper, we introduce Noiser, a perturbation-based FA method\nthat imposes bounded noise on each input embedding and measures the robustness\nof the model against partially noised input to obtain the input attributions.\nAdditionally, we propose an answerability metric that employs an instructed\njudge model to assess the extent to which highly scored tokens suffice to\nrecover the predicted output. Through a comprehensive evaluation across six\nLLMs and three tasks, we demonstrate that Noiser consistently outperforms\nexisting gradient-based, attention-based, and perturbation-based FA methods in\nterms of both faithfulness and answerability, making it a robust and effective\napproach for explaining language model predictions.",
      "tldr_zh": "本文提出 Noiser，一种基于有界输入扰动的特征归因 (Feature Attribution, FA) 方法，用于解释大型语言模型 (Large Language Models, LLMs) 的预测行为。具体而言，Noiser 通过在输入嵌入上施加边界噪声并测量模型对部分噪声输入的鲁棒性，来生成输入归因。论文还引入 answerability 指标，利用指令型判断模型评估高分标记是否足以恢复预测输出。在跨六个 LLMs 和三个任务的全面评估中，Noiser 在 faithfulness 和 answerability 方面均优于现有的基于梯度、注意力或扰动的方法，提供了一个稳健有效的解释框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02911v1",
      "published_date": "2025-04-03 10:59:37 UTC",
      "updated_date": "2025-04-03 10:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:18:20.292843"
    },
    {
      "arxiv_id": "2504.02480v1",
      "title": "Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungmin Choi",
        "JaKeoung Koo",
        "Stephen McLaughlin",
        "Abderrahim Halimi"
      ],
      "abstract": "Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.",
      "tldr_zh": "本研究针对单光子 Lidar 成像在噪声环境和每个像素多目标场景中的挑战，提出了一种 Graph Attention-Driven Bayesian Deep Unrolling 算法，以提升准确性和鲁棒性。方法采用分层 Bayesian 模型处理多个目标，并通过双深度图（dual depth maps）表示结合几何深度学习从点云中提取特征，从而融合统计方法的解释性和深度学习的高性能。实验结果显示，该算法在合成和真实数据上优于现有方法，同时提供不确定性量化信息。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02480v1",
      "published_date": "2025-04-03 10:57:26 UTC",
      "updated_date": "2025-04-03 10:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:18:31.189456"
    },
    {
      "arxiv_id": "2504.02479v1",
      "title": "Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Covone",
        "Italo Napolitano",
        "Francesco De Lellis",
        "Mario di Bernardo"
      ],
      "abstract": "We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.",
      "tldr_zh": "本研究提出了一种分层策略梯度强化学习方法，用于多智能体牧羊控制（shepherding）非凝聚目标的去中心化解决方案。该方法通过Proximal Policy Optimization（PPO）整合目标选择和目标驱动，克服了先前Deep Q-Network方法的离散动作约束，实现更平滑的代理轨迹。作为一个无模型框架，该方法无需先验动态知识即可有效解决牧羊问题。实验结果证明了该方法的有效性和可扩展性，即使在目标数量增加或感知能力有限的情况下表现良好。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02479v1",
      "published_date": "2025-04-03 10:56:57 UTC",
      "updated_date": "2025-04-03 10:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:18:42.871654"
    },
    {
      "arxiv_id": "2504.03776v1",
      "title": "Advancing Air Quality Monitoring: TinyML-Based Real-Time Ozone Prediction with Cost-Effective Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Huam Ming Ken",
        "Mehran Behjati"
      ],
      "abstract": "The escalation of urban air pollution necessitates innovative solutions for\nreal-time air quality monitoring and prediction. This paper introduces a novel\nTinyML-based system designed to predict ozone concentration in real-time. The\nsystem employs an Arduino Nano 33 BLE Sense microcontroller equipped with an\nMQ7 sensor for carbon monoxide (CO) detection and built-in sensors for\ntemperature and pressure measurements. The data, sourced from a Kaggle dataset\non air quality parameters from India, underwent thorough cleaning and\npreprocessing. Model training and evaluation were performed using Edge Impulse,\nconsidering various combinations of input parameters (CO, temperature, and\npressure). The optimal model, incorporating all three variables, achieved a\nmean squared error (MSE) of 0.03 and an R-squared value of 0.95, indicating\nhigh predictive accuracy. The regression model was deployed on the\nmicrocontroller via the Arduino IDE, showcasing robust real-time performance.\nSensitivity analysis identified CO levels as the most critical predictor of\nozone concentration, followed by pressure and temperature. The system's\nlow-cost and low-power design makes it suitable for widespread implementation,\nparticularly in resource-constrained settings. This TinyML approach provides\nprecise real-time predictions of ozone levels, enabling prompt responses to\npollution events and enhancing public health protection.",
      "tldr_zh": "本论文提出了一种基于 TinyML 的实时臭氧预测系统，利用低成本的 Arduino Nano 33 BLE Sense 微控制器和 MQ7 传感器，结合一氧化碳 (CO)、温度和压力数据进行监测和预测。系统使用 Kaggle 数据集进行数据清洗和预处理，并在 Edge Impulse 平台上训练模型，最终的最佳回归模型实现了 MSE 0.03 和 R-squared 0.95 的高准确性。敏感性分析表明 CO 是臭氧浓度预测的最关键因素，该系统的低功耗设计使其适合资源有限的环境，帮助及时响应污染事件并提升公共健康保护。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "This is a preprint version of a paper accepted and published in\n  Springer Lecture Notes in Networks and Systems. The final version is\n  available at https://doi.org/10.1007/978-981-96-3949-6_42",
      "pdf_url": "http://arxiv.org/pdf/2504.03776v1",
      "published_date": "2025-04-03 10:48:24 UTC",
      "updated_date": "2025-04-03 10:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:18:57.618358"
    },
    {
      "arxiv_id": "2504.02910v1",
      "title": "Systematic Literature Review: Explainable AI Definitions and Challenges in Education",
      "title_zh": "系统文献综述：可解释 AI 定义和在教育中的挑战",
      "authors": [
        "Zaid M. Altukhi",
        "Sojen Pradhan"
      ],
      "abstract": "Explainable AI (XAI) seeks to transform black-box algorithmic processes into\ntransparent ones, enhancing trust in AI applications across various sectors\nsuch as education. This review aims to examine the various definitions of XAI\nwithin the literature and explore the challenges of XAI in education. Our goal\nis to shed light on how XAI can contribute to enhancing the educational field.\nThis systematic review, utilising the PRISMA method for rigorous and\ntransparent research, identified 19 relevant studies. Our findings reveal 15\ndefinitions and 62 challenges. These challenges are categorised using thematic\nanalysis into seven groups: explainability, ethical, technical, human-computer\ninteraction (HCI), trustworthiness, policy and guideline, and others, thereby\ndeepening our understanding of the implications of XAI in education. Our\nanalysis highlights the absence of standardised definitions for XAI, leading to\nconfusion, especially because definitions concerning ethics, trustworthiness,\ntechnicalities, and explainability tend to overlap and vary.",
      "tldr_zh": "这篇文献综述探讨了Explainable AI (XAI)的定义及其在教育领域的挑战，旨在通过透明化AI算法增强教育领域的信任。研究采用PRISMA方法进行系统审查，识别了19个相关研究，并总结出15个XAI定义和62个挑战，这些挑战被主题分析分为七类：explainability、ethical、technical、human-computer interaction (HCI)、trustworthiness、policy and guideline，以及others。结果强调，XAI定义缺乏标准化，导致定义之间重叠和混淆，影响了其在教育中的实际应用和理解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02910v1",
      "published_date": "2025-04-03 10:43:35 UTC",
      "updated_date": "2025-04-03 10:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:19:09.358274"
    },
    {
      "arxiv_id": "2504.02467v1",
      "title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Qisheng Hu",
        "Quanyu Long",
        "Wenya Wang"
      ],
      "abstract": "Program-guided reasoning has shown promise in complex claim fact-checking by\ndecomposing claims into function calls and executing reasoning programs.\nHowever, prior work primarily relies on few-shot in-context learning (ICL) with\nad-hoc demonstrations, which limit program diversity and require manual design\nwith substantial domain knowledge. Fundamentally, the underlying principles of\neffective reasoning program generation still remain underexplored, making it\nchallenging to construct effective demonstrations. To address this, we propose\nBOOST, a bootstrapping-based framework for few-shot reasoning program\ngeneration. BOOST explicitly integrates claim decomposition and\ninformation-gathering strategies as structural guidance for program generation,\niteratively refining bootstrapped demonstrations in a strategy-driven and\ndata-centric manner without human intervention. This enables a seamless\ntransition from zero-shot to few-shot strategic program-guided learning,\nenhancing interpretability and effectiveness. Experimental results show that\nBOOST outperforms prior few-shot baselines in both zero-shot and few-shot\nsettings for complex claim verification.",
      "tldr_zh": "该论文提出BOOST框架，一种基于bootstrapping的自助式方法，用于生成程序引导的事实检查推理程序，以解决现有few-shot in-context learning（ICL）方法的程序多样性不足和手动设计依赖问题。BOOST通过整合声明分解和信息收集策略作为结构指导，进行迭代精炼的策略驱动演示，从而实现从zero-shot到few-shot的无缝过渡，并提升推理的可解释性和有效性。实验结果显示，BOOST在复杂声明验证的zero-shot和few-shot设置中，优于现有基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02467v1",
      "published_date": "2025-04-03 10:38:45 UTC",
      "updated_date": "2025-04-03 10:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:19:19.953112"
    },
    {
      "arxiv_id": "2504.02463v1",
      "title": "Evaluating AI Recruitment Sourcing Tools by Human Preference",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Slaykovskiy",
        "Maksim Zvegintsev",
        "Yury Sakhonchyk",
        "Hrachik Ajamian"
      ],
      "abstract": "This study introduces a benchmarking methodology designed to evaluate the\nperformance of AI-driven recruitment sourcing tools. We created and utilized a\ndataset to perform a comparative analysis of search results generated by\nleading AI-based solutions, LinkedIn Recruiter, and our proprietary system,\nPearch.ai. Human experts assessed the relevance of the returned candidates, and\nan Elo rating system was applied to quantitatively measure each tool's\ncomparative performance. Our findings indicate that AI-driven recruitment\nsourcing tools consistently outperform LinkedIn Recruiter in candidate\nrelevance, with Pearch.ai achieving the highest performance scores.\nFurthermore, we found a strong alignment between AI-based evaluations and human\njudgments, highlighting the potential for advanced AI technologies to\nsubstantially enhance talent acquisition effectiveness. Code and supporting\ndata are publicly available at\nhttps://github.com/vslaykovsky/ai-sourcing-benchmark",
      "tldr_zh": "这篇论文提出了一种基准方法，通过人类偏好评估 AI-driven recruitment sourcing tools 的性能，使用一个数据集比较了领先 AI 解决方案、LinkedIn Recruiter 和自有的 Pearch.ai 系统。人类专家评估候选人的相关性，并采用 Elo rating system 进行量化比较。结果显示，AI 驱动工具在候选人相关性上 consistently outperform LinkedIn Recruiter，且 Pearch.ai 取得最高分数；此外，AI 评估与人类判断高度一致，证明了 AI 技术在提升人才获取有效性的潜力。代码和数据已在 GitHub 上公开可用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02463v1",
      "published_date": "2025-04-03 10:33:43 UTC",
      "updated_date": "2025-04-03 10:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:19:31.658843"
    },
    {
      "arxiv_id": "2504.02464v1",
      "title": "CornerPoint3D: Look at the Nearest Corner Instead of the Center",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixiao Zhang",
        "Runwei Guan",
        "Xiangyu Chen",
        "Adam Prugel-Bennett",
        "Xiaohao Cai"
      ],
      "abstract": "3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.",
      "tldr_zh": "该论文针对 3D 对象检测中的问题，指出传统中心-based 检测器在 LiDAR 点云跨域任务中因仅捕捉物体近侧而导致定位不准确，并质疑是否需在整个 3D 边界框上维持性能。作者提出两个新评估指标，用于评估模型对物体近侧表面的检测能力，并引入 EdgeHead 精炼头来引导模型关注可学习的近侧表面，提升跨域性能。最终，他们开发了 CornerPoint3D 检测器，基于 CenterPoint 并使用热图监督最近角落的学习和检测，在多个跨域任务中优于传统方法，提供更实用和鲁棒的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2407.04061",
      "pdf_url": "http://arxiv.org/pdf/2504.02464v1",
      "published_date": "2025-04-03 10:33:43 UTC",
      "updated_date": "2025-04-03 10:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:19:44.788647"
    },
    {
      "arxiv_id": "2504.02461v1",
      "title": "Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness",
      "title_zh": "翻译失败",
      "authors": [
        "Juliett Suárez Ferreira",
        "Marija Slavkovik",
        "Jorge Casillas"
      ],
      "abstract": "Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.",
      "tldr_zh": "该论文提出一个概念框架，旨在帮助个体评估自动决策系统 (ADM) 是否公平，强调个体有权获取决策信息、质疑不公并寻求补救。框架整合算法公平性、explainable artificial intelligence、accountability 和 contestability 等领域的关键概念，提供工具赋予 ADM 系统的最终用户理解和挑战决策的能力。这种用户中心方法桥接了技术解决方案与实际问责机制，为组织和政策制定者提供蓝图，促进更具包容性的决策环境。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA",
        "I.2; J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02461v1",
      "published_date": "2025-04-03 10:28:19 UTC",
      "updated_date": "2025-04-03 10:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:19:55.599194"
    },
    {
      "arxiv_id": "2504.02458v1",
      "title": "Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Liangbo Ning",
        "Wenqi Fan",
        "Qing Li"
      ],
      "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.",
      "tldr_zh": "该论文针对大型语言模型 (LLM) 驱动的推荐系统 (RecSys) 易受微小扰动影响的问题，提出了一种名为 RETURN 的新型框架，利用检索增强生成 (RAG) 技术从外部协作知识中净化被攻击者篡改的用户历史数据。框架包括检索增强扰动定位模块，用于识别用户序列中的潜在扰动，以及后续的删除或替换策略来清除这些扰动，并采用鲁棒的集成推荐策略生成最终预测。实验在三个真实数据集上验证了 RETURN 的有效性，显著提升了 LLM-empowered RecSys 的鲁棒性，并以即插即用方式实现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02458v1",
      "published_date": "2025-04-03 10:22:30 UTC",
      "updated_date": "2025-04-03 10:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:20:07.879634"
    },
    {
      "arxiv_id": "2504.02450v3",
      "title": "CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion Stylization in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Wang",
        "Duanfeng Chu",
        "Zejian Deng",
        "Liping Lu",
        "Jinxiang Wang",
        "Chen Sun"
      ],
      "abstract": "To address the challenge of insufficient interactivity and behavioral\ndiversity in autonomous driving decision-making, this paper proposes a\nCognitive Hierarchical Agent for Reasoning and Motion Stylization (CHARMS). By\nleveraging Level-k game theory, CHARMS captures human-like reasoning patterns\nthrough a two-stage training pipeline comprising reinforcement learning\npretraining and supervised fine-tuning. This enables the resulting models to\nexhibit diverse and human-like behaviors, enhancing their decision-making\ncapacity and interaction fidelity in complex traffic environments. Building\nupon this capability, we further develop a scenario generation framework that\nutilizes the Poisson cognitive hierarchy theory to control the distribution of\nvehicles with different driving styles through Poisson and binomial sampling.\nExperimental results demonstrate that CHARMS is capable of both making\nintelligent driving decisions as an ego vehicle and generating diverse,\nrealistic driving scenarios as environment vehicles. The code for CHARMS is\nreleased at https://github.com/chuduanfeng/CHARMS.",
      "tldr_zh": "本研究提出 CHARMS，一种认知层次代理，用于提升自动驾驶决策中的互动性和行为多样性。CHARMS 通过 Level-k game theory 捕捉类似人类的推理模式，并采用两阶段训练管道，包括 reinforcement learning 预训练和 supervised fine-tuning，从而使模型在复杂交通环境中展现多样化的人类化行为。基于此，该框架进一步开发了场景生成机制，利用 Poisson cognitive hierarchy theory 通过 Poisson 和二项式采样控制不同驾驶风格的车辆分布。实验结果表明，CHARMS 能作为自车做出智能决策，并生成真实多样的驾驶场景，代码已开源于 https://github.com/chuduanfeng/CHARMS。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02450v3",
      "published_date": "2025-04-03 10:15:19 UTC",
      "updated_date": "2025-04-28 15:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:20:20.002344"
    },
    {
      "arxiv_id": "2504.02441v2",
      "title": "Cognitive Memory in Large Language Models",
      "title_zh": "大语言模型中的认知记忆",
      "authors": [
        "Lianlei Shan",
        "Shixian Luo",
        "Zezhou Zhu",
        "Yu Yuan",
        "Yong Wu"
      ],
      "abstract": "This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中的记忆机制及其对生成上下文丰富响应、减少幻觉和提升效率的重要性。论文将记忆分为感官记忆（对应输入提示）、短期记忆（处理即时上下文）和长期记忆（通过外部数据库实现），并详细分析基于文本的记忆方法，包括获取（selection and summarization）、管理（updating, accessing, storing, and resolving conflicts）以及利用（full-text search, SQL queries, semantic search）。此外，它考察了KV cache-based memory的技术，如选择方法（regularity-based summarization, score-based approaches, special token embeddings）和压缩策略（low-rank compression, KV merging），以及参数-based memory（如LoRA, TTT, MoE）和隐藏状态-based memory（如chunk mechanisms, recurrent transformers, Mamba model），这些方法有助于改善长文本处理。总体上，论文提供了LLMs记忆机制的全面分析，并指出了未来研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02441v2",
      "published_date": "2025-04-03 09:58:19 UTC",
      "updated_date": "2025-04-24 01:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:20:32.669703"
    },
    {
      "arxiv_id": "2504.02438v4",
      "title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanqi Cheng",
        "Jian Guan",
        "Wei Wu",
        "Rui Yan"
      ],
      "abstract": "Long-form video processing fundamentally challenges vision-language models\n(VLMs) due to the high computational costs of handling extended temporal\nsequences. Existing token pruning and feature merging methods often sacrifice\ncritical temporal dependencies or dilute semantic information. We introduce\ndifferential distillation, a principled approach that systematically preserves\ntask-relevant information while suppressing redundancy. Based on this\nprinciple, we develop ViLAMP, a hierarchical video-language model that\nprocesses hour-long videos at \"mixed precision\" through two key mechanisms: (1)\ndifferential keyframe selection that maximizes query relevance while\nmaintaining temporal distinctiveness at the frame level and (2) differential\nfeature merging that preserves query-salient features in non-keyframes at the\npatch level. Hence, ViLAMP retains full information in keyframes while reducing\nnon-keyframes to their most salient features, resembling mixed-precision\ntraining. Extensive experiments demonstrate ViLAMP's superior performance\nacross five video understanding benchmarks, particularly on long-form content.\nNotably, ViLAMP can process ultra-long videos (up to 10K frames) on a single\nNVIDIA A100 GPU, achieving substantial computational efficiency while\nmaintaining state-of-the-art performance. Code and model are available at\nhttps://github.com/steven-ccq/ViLAMP.",
      "tldr_zh": "该论文提出了一种分层差分蒸馏(hierarchical differential distillation)方法，以解决视觉语言模型(VLMs)在处理长视频时的计算成本问题，通过系统保留任务相关信息并抑制冗余。作者开发了ViLAMP模型，利用差分关键帧选择（在帧级别最大化查询相关性并保持时间独特性）和差分特征合并（在补丁级别保留查询显著特征），实现类似混合精度训练的效果，使关键帧保留完整信息而非关键帧仅保留核心特征。实验结果显示，ViLAMP在五个视频理解基准上表现出色，尤其在长视频内容上，并在单个NVIDIA A100 GPU上高效处理高达10K帧的视频，同时维持最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02438v4",
      "published_date": "2025-04-03 09:55:09 UTC",
      "updated_date": "2025-05-20 09:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:20:44.205349"
    },
    {
      "arxiv_id": "2504.02430v1",
      "title": "How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Guus Eelink",
        "Kilian Rückschloß",
        "Felix Weitkämper"
      ],
      "abstract": "Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.",
      "tldr_zh": "这篇论文探讨了人工智能如何通过Bayesian networks 和 causal models 处理外部干预和反事实查询，从而超越单纯概率分布的局限。作者引入了causal systems 的理论框架，借鉴亚里士多德的《Posterior Analytics》，以区分knowledge that 和 knowledge why 的知识类型。论文论证，将现有AI技术解释为causal systems 后，只有通过knowledge why 才能准确预测外部干预的效果，从而为AI 的因果知识提供更精确的理论基础。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02430v1",
      "published_date": "2025-04-03 09:37:05 UTC",
      "updated_date": "2025-04-03 09:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:20:55.638947"
    },
    {
      "arxiv_id": "2504.02426v1",
      "title": "Narrative Studio: Visual narrative exploration using LLMs and Monte Carlo Tree Search",
      "title_zh": "Narrative Studio: 利用 LLMs 和 Monte Carlo Tree Search 进行视觉叙事探索",
      "authors": [
        "Parsa Ghaffari",
        "Chris Hokamp"
      ],
      "abstract": "Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.",
      "tldr_zh": "该研究提出Narrative Studio，一种新型浏览器内叙事探索环境，使用树状界面允许用户从故事特定点进行分支探索，从而超越传统LLMs聊天界面的线性限制。系统通过迭代的LLM推理扩展每个分支，并结合Monte Carlo Tree Search (MCTS)自动扩展有前景的叙事路径，根据用户指定标准提升故事多样性和稳健性。此外，用户可利用实体图来增强生成的文本连贯性，确保故事中的角色和环境逻辑一致。整体框架促进交互式叙事故事的创新规划和“如果”场景探索。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02426v1",
      "published_date": "2025-04-03 09:31:07 UTC",
      "updated_date": "2025-04-03 09:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:21:07.555223"
    },
    {
      "arxiv_id": "2504.02417v1",
      "title": "Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing in Video Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Lili Liang",
        "Guanglu Sun"
      ],
      "abstract": "Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.",
      "tldr_zh": "本研究针对视频问答（Video Question Answering, VideoQA）中的静态关系推理问题，提出了一种基于intra-type和inter-type消息传递（message passing）的创新方法，以提升关系识别和利用的准确性。该方法构建dual graph进行intra-type消息传递推理，捕捉问题相关目标和关系的邻居信息，从而获取intra-type线索；同时构建heterogeneous graph进行inter-type消息传递推理，捕捉不同类别目标和关系的邻居信息，以获得inter-type线索。最终，通过结合这些线索基于静态关系进行答案推理。在ANetQA和Next-QA数据集上的实验结果证明了该方法的有效性，显著提高了VideoQA的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02417v1",
      "published_date": "2025-04-03 09:14:41 UTC",
      "updated_date": "2025-04-03 09:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:21:19.918421"
    },
    {
      "arxiv_id": "2504.02408v1",
      "title": "Translation of Fetal Brain Ultrasound Images into Pseudo-MRI Images using Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Naomi Silverstein",
        "Efrat Leibowitz",
        "Ron Beloosesky",
        "Haim Azhari"
      ],
      "abstract": "Ultrasound is a widely accessible and cost-effective medical imaging tool\ncommonly used for prenatal evaluation of the fetal brain. However, it has\nlimitations, particularly in the third trimester, where the complexity of the\nfetal brain requires high image quality for extracting quantitative data. In\ncontrast, magnetic resonance imaging (MRI) offers superior image quality and\ntissue differentiation but is less available, expensive, and requires\ntime-consuming acquisition. Thus, transforming ultrasonic images into an\nMRI-mimicking display may be advantageous and allow better tissue anatomy\npresentation. To address this goal, we have examined the use of artificial\nintelligence, implementing a diffusion model renowned for generating\nhigh-quality images. The proposed method, termed \"Dual Diffusion Imposed\nCorrelation\" (DDIC), leverages a diffusion-based translation methodology,\nassuming a shared latent space between ultrasound and MRI domains. Model\ntraining was obtained utilizing the \"HC18\" dataset for ultrasound and the \"CRL\nfetal brain atlas\" along with the \"FeTA \" datasets for MRI. The generated\npseudo-MRI images provide notable improvements in visual discrimination of\nbrain tissue, especially in the lateral ventricles and the Sylvian fissure,\ncharacterized by enhanced contrast clarity. Improvement was demonstrated in\nMutual information, Peak signal-to-noise ratio, Fr\\'echet Inception Distance,\nand Contrast-to-noise ratio. Findings from these evaluations indicate\nstatistically significant superior performance of the DDIC compared to other\ntranslation methodologies. In addition, a Medical Opinion Test was obtained\nfrom 5 gynecologists. The results demonstrated display improvement in 81% of\nthe tested images. In conclusion, the presented pseudo-MRI images hold the\npotential for streamlining diagnosis and enhancing clinical outcomes through\nimproved representation.",
      "tldr_zh": "本研究针对超声（Ultrasound）成像在胎儿脑部评估中的图像质量限制，特别是第三孕期的问题，提出了一种人工智能方法，将超声图像转化为伪 MRI 图像，以提升组织解剖的可视化。方法名为“Dual Diffusion Imposed Correlation”（DDIC），基于扩散模型（diffusion model），假设超声和 MRI 共享潜在空间，并利用 HC18 数据集训练超声模型，以及 CRL fetal brain atlas 和 FeTA 数据集训练 MRI 模型。结果显示，生成的伪 MRI 图像显著改善了脑组织对比度，尤其在侧脑室和 Sylvian fissure 区域，并在 Mutual information、Peak signal-to-noise ratio、Fréchet Inception Distance 和 Contrast-to-noise ratio 等指标上优于其他方法；此外，5 名妇科医生的评估显示，81% 的图像显示改善。该方法有望简化诊断流程并提升临床结果。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02408v1",
      "published_date": "2025-04-03 08:59:33 UTC",
      "updated_date": "2025-04-03 08:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:21:33.251389"
    },
    {
      "arxiv_id": "2504.03775v1",
      "title": "FlowKV: A Disaggregated Inference Framework with Low-Latency KV Cache Transfer and Load-Aware Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqing Li",
        "Guochao Jiang",
        "Xiangyong Ding",
        "Zhangcheng Tao",
        "Chuzhan Hao",
        "Chenfeng Xu",
        "Yuewei Zhang",
        "Hao Wang"
      ],
      "abstract": "Disaggregated inference has become an essential framework that separates the\nprefill (P) and decode (D) stages in large language model inference to improve\nthroughput. However, the KV cache transfer faces significant delays between\nprefill and decode nodes. The block-wise calling method and discontinuous KV\ncache memory allocation increase the number of calls to the transmission\nkernel. Additionally, existing frameworks often fix the roles of P and D nodes,\nleading to computational imbalances. In this paper, we propose FlowKV, a novel\ndisaggregated inference framework, which reduces the average transmission\nlatency of KV cache by 96%, from 0.944s to 0.053s, almost eliminating the\ntransfer time relative to the total request latency by optimizing the KV cache\ntransfer. FlowKV introduces the Load-Aware Scheduler for balanced request\nscheduling and flexible PD node allocation. This design maximizes hardware\nresource utilization, achieving peak system throughput across various\nscenarios, including normal, computational imbalance, and extreme overload\nconditions. Experimental results demonstrate that FlowKV significantly\naccelerates inference by 15.2%-48.9% on LongBench dataset compared to the\nbaseline and supports applications with heterogeneous GPUs.",
      "tldr_zh": "该论文提出FlowKV，一种新型的Disaggregated Inference框架，针对大型语言模型推理中预填充(Prefill)和解码(Decode)阶段的KV Cache传输延迟问题，通过优化传输机制将平均延迟减少96%（从0.944s到0.053s），并引入Load-Aware Scheduler实现平衡请求调度和灵活的PD节点分配。FlowKV最大化硬件资源利用，支持异构GPU应用，并在各种场景下提升系统吞吐量。实验结果显示，在LongBench数据集上，FlowKV比基线框架加速15.2%-48.9%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03775v1",
      "published_date": "2025-04-03 08:58:05 UTC",
      "updated_date": "2025-04-03 08:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:21:43.402150"
    },
    {
      "arxiv_id": "2504.02402v1",
      "title": "EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling",
      "title_zh": "EvMic: 基于事件的非接触式声音恢复，通过有效的时空建模",
      "authors": [
        "Hao Yin",
        "Shi Guo",
        "Xu Jia",
        "Xudong XU",
        "Lu Zhang",
        "Si Liu",
        "Dong Wang",
        "Huchuan Lu",
        "Tianfan Xue"
      ],
      "abstract": "When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.",
      "tldr_zh": "这篇论文提出了 EvMic，一种基于事件的非接触声音恢复方法，通过有效的 spatial-temporal 建模来利用事件流的时空信息，解决传统方法在采样率、带宽和视野等方面的权衡问题。方法包括生成一个大型训练集、使用网络捕捉事件的稀疏性以获取空间信息、采用 Mamba 建模长期时间信息，以及训练空间聚合块来整合不同位置的信息以提高信号质量。作者还设计了使用激光矩阵的成像系统来增强事件信号，并通过合成和真实世界数据的实验验证了方法的有效性，展示了其在声音恢复方面的优越性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Our project page: https://yyzq1.github.io/EvMic/",
      "pdf_url": "http://arxiv.org/pdf/2504.02402v1",
      "published_date": "2025-04-03 08:51:17 UTC",
      "updated_date": "2025-04-03 08:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:21:56.295343"
    },
    {
      "arxiv_id": "2504.02388v3",
      "title": "Steiner Traveling Salesman Problem with Quantum Annealing",
      "title_zh": "翻译失败",
      "authors": [
        "Alessia Ciacco",
        "Francesca Guerriero",
        "Eneko Osaba"
      ],
      "abstract": "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.",
      "tldr_zh": "本文研究了 Steiner Traveling Salesman Problem (STSP)，一种经典 Traveling Salesman Problem 的变体，通过添加 Steiner nodes 来最小化总旅行成本。作者提出使用 Quantum Annealing 技术，特别是 D-Wave 硬件，并开发了一种预处理方法来减少网络大小，从而提升 Quadratic Unconstrained Binary Optimization (QUBO) 公式的计算可行性。实验结果表明，该预处理方法显著降低了问题复杂度，并在 STSP 求解中展示了 Quantum Annealing 的创新潜力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "quant-ph",
      "comment": "7 pages, 1 figure, 6 tables. Paper accepted in The Genetic and\n  Evolutionary Computation Conference (GECCO 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.02388v3",
      "published_date": "2025-04-03 08:29:57 UTC",
      "updated_date": "2025-05-13 16:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:22:07.794219"
    },
    {
      "arxiv_id": "2504.03774v1",
      "title": "Exploring energy consumption of AI frameworks on a 64-core RV64 Server CPU",
      "title_zh": "翻译失败",
      "authors": [
        "Giulio Malenza",
        "Francesco Targa",
        "Adriano Marques Garcia",
        "Marco Aldinucci",
        "Robert Birke"
      ],
      "abstract": "In today's era of rapid technological advancement, artificial intelligence\n(AI) applications require large-scale, high-performance, and data-intensive\ncomputations, leading to significant energy demands. Addressing this challenge\nnecessitates a combined approach involving both hardware and software\ninnovations. Hardware manufacturers are developing new, efficient, and\nspecialized solutions, with the RISC-V architecture emerging as a prominent\nplayer due to its open, extensible, and energy-efficient instruction set\narchitecture (ISA). Simultaneously, software developers are creating new\nalgorithms and frameworks, yet their energy efficiency often remains unclear.\nIn this study, we conduct a comprehensive benchmark analysis of machine\nlearning (ML) applications on the 64-core SOPHON SG2042 RISC-V architecture. We\nspecifically analyze the energy consumption of deep learning inference models\nacross three leading AI frameworks: PyTorch, ONNX Runtime, and TensorFlow. Our\nfindings show that frameworks using the XNNPACK back-end, such as ONNX Runtime\nand TensorFlow, consume less energy compared to PyTorch, which is compiled with\nthe native OpenBLAS back-end.",
      "tldr_zh": "本研究探讨了AI框架在64-core RV64服务器CPU上的能源消耗，针对AI应用的高性能计算需求进行全面基准分析。研究在SOPHON SG2042 RISC-V架构上测试了PyTorch、ONNX Runtime和TensorFlow等框架在深度学习推理模型中的能耗表现。结果表明，使用XNNPACK后端的ONNX Runtime和TensorFlow比采用OpenBLAS后端的PyTorch能耗更低，为优化AI软件和硬件的能源效率提供了重要参考。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03774v1",
      "published_date": "2025-04-03 08:27:10 UTC",
      "updated_date": "2025-04-03 08:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:22:19.760100"
    },
    {
      "arxiv_id": "2504.02382v1",
      "title": "Benchmark of Segmentation Techniques for Pelvic Fracture in CT and X-ray: Summary of the PENGWIN 2024 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Yudi Sang",
        "Yanzhen Liu",
        "Sutuke Yibulayimu",
        "Yunning Wang",
        "Benjamin D. Killeen",
        "Mingxu Liu",
        "Ping-Cheng Ku",
        "Ole Johannsen",
        "Karol Gotkowski",
        "Maximilian Zenk",
        "Klaus Maier-Hein",
        "Fabian Isensee",
        "Peiyan Yue",
        "Yi Wang",
        "Haidong Yu",
        "Zhaohong Pan",
        "Yutong He",
        "Xiaokun Liang",
        "Daiqi Liu",
        "Fuxin Fan",
        "Artur Jurgas",
        "Andrzej Skalski",
        "Yuxi Ma",
        "Jing Yang",
        "Szymon Płotka",
        "Rafał Litka",
        "Gang Zhu",
        "Yingchun Song",
        "Mathias Unberath",
        "Mehran Armand",
        "Dan Ruan",
        "S. Kevin Zhou",
        "Qiyong Cao",
        "Chunpeng Zhao",
        "Xinbao Wu",
        "Yu Wang"
      ],
      "abstract": "The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.",
      "tldr_zh": "PENGWIN 2024 挑战赛作为 MICCAI 2024 的卫星活动，旨在基准测试盆骨骨折在 CT 和 X-ray 图像中的分割技术，以改进创伤诊断、手术规划和术中指导。挑战使用了包含 150 个临床 CT 扫描和模拟 X-ray 数据集，评估了 16 个团队的算法，显示最佳 CT 算法的 fragment-wise IoU 达到 0.930，而 X-ray 任务的最佳 IoU 为 0.774，突显了重叠解剖结构的挑战。研究还揭示了算法设计多样性，如实例表示的差异，并建议整合交互式分割方法以应对骨折定义的不确定性，从而提升模型的可靠性和临床适用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "PENGWIN 2024 Challenge Report",
      "pdf_url": "http://arxiv.org/pdf/2504.02382v1",
      "published_date": "2025-04-03 08:19:36 UTC",
      "updated_date": "2025-04-03 08:19:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:22:32.300068"
    },
    {
      "arxiv_id": "2504.03773v1",
      "title": "SHapley Estimated Explanation (SHEP): A Fast Post-Hoc Attribution Method for Interpreting Intelligent Fault Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Chen",
        "Xingjian Dong",
        "Zhike Peng",
        "Guang Meng"
      ],
      "abstract": "Despite significant progress in intelligent fault diagnosis (IFD), the lack\nof interpretability remains a critical barrier to practical industrial\napplications, driving the growth of interpretability research in IFD. Post-hoc\ninterpretability has gained popularity due to its ability to preserve network\nflexibility and scalability without modifying model structures. However, these\nmethods often yield suboptimal time-domain explanations. Recently, combining\ndomain transform with SHAP has improved interpretability by extending\nexplanations to more informative domains. Nonetheless, the computational\nexpense of SHAP, exacerbated by increased dimensions from domain transforms,\nremains a major challenge. To address this, we propose patch-wise attribution\nand SHapley Estimated Explanation (SHEP). Patch-wise attribution reduces\nfeature dimensions at the cost of explanation granularity, while SHEP\nsimplifies subset enumeration to approximate SHAP, reducing complexity from\nexponential to linear. Together, these methods significantly enhance SHAP's\ncomputational efficiency, providing feasibility for real-time interpretation in\nmonitoring tasks. Extensive experiments confirm SHEP's efficiency,\ninterpretability, and reliability in approximating SHAP. Additionally, with\nopen-source code, SHEP has the potential to serve as a benchmark for post-hoc\ninterpretability in IFD. The code is available on\nhttps://github.com/ChenQian0618/SHEP.",
      "tldr_zh": "尽管智能故障诊断 (IFD) 取得了显著进展，但其可解释性不足仍是实际应用中的主要障碍，现有的 post-hoc interpretability 方法虽能保留模型灵活性，却面临计算效率低和解释不佳的问题。论文提出 patch-wise attribution 和 SHapley Estimated Explanation (SHEP)，其中 patch-wise attribution 减少特征维度以降低计算开销，而 SHEP 通过简化 SHAP 的子集枚举，将复杂度从指数级降至线性级，从而实现实时解释。实验结果证实，SHEP 显著提高了计算效率，同时保持了高可解释性和可靠性。作者开源了代码（https://github.com/ChenQian0618/SHEP），有望成为 IFD 中 post-hoc interpretability 的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.03773v1",
      "published_date": "2025-04-03 07:56:07 UTC",
      "updated_date": "2025-04-03 07:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:22:44.142233"
    },
    {
      "arxiv_id": "2504.02906v1",
      "title": "Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihan Zhang",
        "Yixin Cao",
        "Lizi Liao"
      ],
      "abstract": "Chart-to-code generation, the process of converting chart images into\nexecutable plotting scripts, provides a lossless representation of chart\ninformation, requiring models to accurately capture and summarize all visual\nand structural elements. However, this remains a significant challenge for\nmultimodal large language models (MLLMs), which are not inherently well-aligned\nwith code generation tasks. To bridge this gap, we introduce Chart2Code, a\nnovel iterative dual preference learning framework designed to enhance MLLMs'\nchart-to-code generation capabilities through structured code variant\ngeneration and fine-grained dual reward signals. We validate Chart2Code across\nthree MLLMs and find that iterative preference learning consistently improves\nout-of-distribution chart-to-code generation quality. Throughout this process,\nour dual scoring method, which evaluates both the textual code structure and\nits visual representation, leads to greater performance improvements, even with\na reduced preference dataset size. Further analysis explores the key components\nof our framework and highlights the interplay between chart-to-code generation\nand broader chart reasoning, paving the way for future advancements in chart\ncomprehension.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)在图表到代码生成方面的挑战，提出了一种名为Chart2Code的迭代双偏好学习框架，以提升模型将图表图像转换为可执行绘图脚本的能力。该框架通过结构化的代码变体生成和细粒度的双奖励信号（评估代码文本结构和视觉表示）进行优化，即使在减少的偏好数据集上也能显著提高性能。实验在三个MLLMs上验证了框架的有效性，迭代学习过程改善了分布外生成质量，并探讨了关键组件及其与更广泛图表推理的互动，为未来图表理解领域的发展奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.02906v1",
      "published_date": "2025-04-03 07:51:20 UTC",
      "updated_date": "2025-04-03 07:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:22:56.064088"
    },
    {
      "arxiv_id": "2504.02351v1",
      "title": "Agglomerating Large Vision Encoders via Distillation for VFSS Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Chengxi Zeng",
        "Yuxuan Jiang",
        "Fan Zhang",
        "Alberto Gambaruto",
        "Tilo Burghardt"
      ],
      "abstract": "The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.",
      "tldr_zh": "该论文提出了一种新框架，通过知识蒸馏（knowledge distillation）从多个大型医疗基础模型（如 MedSAM, RAD-DINO, MedCLIP）中聚合知识，以提升低复杂度模型在 VFSS Segmentation 任务上的性能，从而实现复杂度与性能的更好权衡。框架避免了针对每个任务的显式训练，使聚合模型在 12 个医疗图像分割任务上表现出色，并展示了优越的泛化能力。与简单蒸馏方法相比，该方法平均提高了 2% 的 Dice coefficient 性能指标。总的来说，这为高效的医疗图像处理提供了可行的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02351v1",
      "published_date": "2025-04-03 07:38:09 UTC",
      "updated_date": "2025-04-03 07:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:23:08.529273"
    },
    {
      "arxiv_id": "2504.08772v1",
      "title": "Reward Generation via Large Vision-Language Model in Offline Reinforcement Learning",
      "title_zh": "利用大型视觉语言模型在离线强化学习中的奖励生成",
      "authors": [
        "Younghwan Lee",
        "Tung M. Luu",
        "Donghoon Lee",
        "Chang D. Yoo"
      ],
      "abstract": "In offline reinforcement learning (RL), learning from fixed datasets presents\na promising solution for domains where real-time interaction with the\nenvironment is expensive or risky. However, designing dense reward signals for\noffline dataset requires significant human effort and domain expertise.\nReinforcement learning with human feedback (RLHF) has emerged as an\nalternative, but it remains costly due to the human-in-the-loop process,\nprompting interest in automated reward generation models. To address this, we\npropose Reward Generation via Large Vision-Language Models (RG-VLM), which\nleverages the reasoning capabilities of LVLMs to generate rewards from offline\ndata without human involvement. RG-VLM improves generalization in long-horizon\ntasks and can be seamlessly integrated with the sparse reward signals to\nenhance task performance, demonstrating its potential as an auxiliary reward\nsignal.",
      "tldr_zh": "这篇论文针对 offline reinforcement learning 中的挑战，提出了一种名为 RG-VLM 的方法，利用 Large Vision-Language Models 的推理能力，从固定数据集自动生成奖励信号，从而避免了传统 RLHF 的高人力成本。RG-VLM 能够提升长horizon 任务的泛化性能，并与稀疏奖励信号无缝整合，以增强整体任务表现。该方法展示了作为辅助奖励信号的潜力，为自动化奖励设计提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, ICASSP 2025. First two authors are equally contributed",
      "pdf_url": "http://arxiv.org/pdf/2504.08772v1",
      "published_date": "2025-04-03 07:11:18 UTC",
      "updated_date": "2025-04-03 07:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:23:20.094114"
    },
    {
      "arxiv_id": "2504.02317v1",
      "title": "Temporal Gaussian Copula For Clinical Multivariate Time Series Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Su",
        "Hezhe Qiao",
        "Di Wu",
        "Yuwen Chen",
        "Lin Chen"
      ],
      "abstract": "The imputation of the Multivariate time series (MTS) is particularly\nchallenging since the MTS typically contains irregular patterns of missing\nvalues due to various factors such as instrument failures, interference from\nirrelevant data, and privacy regulations. Existing statistical methods and deep\nlearning methods have shown promising results in time series imputation. In\nthis paper, we propose a Temporal Gaussian Copula Model (TGC) for three-order\nMTS imputation. The key idea is to leverage the Gaussian Copula to explore the\ncross-variable and temporal relationships based on the latent Gaussian\nrepresentation. Subsequently, we employ an Expectation-Maximization (EM)\nalgorithm to improve robustness in managing data with varying missing rates.\nComprehensive experiments were conducted on three real-world MTS datasets. The\nresults demonstrate that our TGC substantially outperforms the state-of-the-art\nimputation methods. Additionally, the TGC model exhibits stronger robustness to\nthe varying missing ratios in the test dataset. Our code is available at\nhttps://github.com/MVL-Lab/TGC-MTS.",
      "tldr_zh": "这篇论文针对临床多变量时间序列 (MTS) 数据中不规则缺失值的挑战，提出了一种 Temporal Gaussian Copula Model (TGC)。TGC 通过利用 Gaussian Copula 探索变量间和时间关系，并基于潜在 Gaussian 表示，结合 Expectation-Maximization (EM) 算法来提高对不同缺失率数据的鲁棒性。在三个真实数据集上的实验结果显示，TGC 显著优于现有最先进的方法，并在不同缺失比例下表现出更强的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in BIBM2024",
      "pdf_url": "http://arxiv.org/pdf/2504.02317v1",
      "published_date": "2025-04-03 06:44:05 UTC",
      "updated_date": "2025-04-03 06:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:23:31.951022"
    },
    {
      "arxiv_id": "2504.02316v1",
      "title": "ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Zhou",
        "Shilong Jin",
        "Litao Hua",
        "Wanjun Lv",
        "Haoran Duan",
        "Jungong Han"
      ],
      "abstract": "Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.",
      "tldr_zh": "该研究针对零-shot Text-to-3D Generation中的多视图不一致问题，特别是多-face Janus问题，提出了一种名为ConsDreamer的创新框架，以提升3D生成的可视质量和几何一致性。ConsDreamer通过改进score distillation过程，包括View Disentanglement Module (VDM)，该模块解耦条件提示中的视图偏差并注入精确相机参数，以及基于相似性的partial order loss，以在无条件项中强制几何一致性。实验结果显示，ConsDreamer在多视图渲染上显著优于现有方法，有效缓解了多-face Janus问题，并提高了整体生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 11 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.02316v1",
      "published_date": "2025-04-03 06:43:23 UTC",
      "updated_date": "2025-04-03 06:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:23:43.571363"
    },
    {
      "arxiv_id": "2504.02312v1",
      "title": "OmniCam: Unified Multimodal Video Generation via Camera Control",
      "title_zh": "OmniCam：通过相机控制实现的统一",
      "authors": [
        "Xiaoda Yang",
        "Jiayang Xu",
        "Kaixuan Luan",
        "Xinyu Zhan",
        "Hongshun Qiu",
        "Shijun Shi",
        "Hao Li",
        "Shuai Yang",
        "Li Zhang",
        "Checheng Yu",
        "Cewu Lu",
        "Lixin Yang"
      ],
      "abstract": "Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.",
      "tldr_zh": "该研究提出 OmniCam，一种统一的 multimodal 相机控制框架，利用 large language models 和 video diffusion models 生成时空一致的视频，以解决现有方法的复杂交互和控制能力有限问题。OmniCam 支持多种输入模式组合，包括文本或视频作为相机路径指导，以及图像或视频作为内容参考，从而实现对相机运动的精确控制。为训练该框架，研究者引入 OmniTr 数据集，该数据集包含大量高质量的长序列轨迹、视频和描述。实验结果显示，OmniCam 在各种指标上实现了最先进的性能，显著提升了相机控制视频生成的质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02312v1",
      "published_date": "2025-04-03 06:38:30 UTC",
      "updated_date": "2025-04-03 06:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:23:54.609969"
    },
    {
      "arxiv_id": "2504.02904v1",
      "title": "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhe Du",
        "Weikai Li",
        "Min Cai",
        "Karim Saraipour",
        "Zimin Zhang",
        "Himabindu Lakkaraju",
        "Yizhou Sun",
        "Shichang Zhang"
      ],
      "abstract": "Post-training is essential for the success of large language models (LLMs),\ntransforming pre-trained base models into more useful and aligned post-trained\nmodels. While plenty of works have studied post-training algorithms and\nevaluated post-training models by their outputs, it remains understudied how\npost-training reshapes LLMs internally. In this paper, we compare base and\npost-trained LLMs mechanistically from four perspectives to better understand\npost-training effects. Our findings across model families and datasets reveal\nthat: (1) Post-training does not change the factual knowledge storage\nlocations, and it adapts knowledge representations from the base model while\ndeveloping new knowledge representations; (2) Both truthfulness and refusal can\nbe represented by linear vectors in the hidden representation space. The\ntruthfulness direction is highly similar between the base and post-trained\nmodel, and it is effectively transferable for interventions; (3) The refusal\ndirection is different between the base and post-trained models, and it shows\nlimited forward transferability; (4) Differences in confidence between the base\nand post-trained models cannot be attributed to entropy neurons. Our study\nprovides insights into the fundamental mechanisms preserved and altered during\npost-training, facilitates downstream tasks like model steering, and could\npotentially benefit future research in interpretability and LLM post-training.",
      "tldr_zh": "本文从机械主义视角探讨后训练（post-training）如何重塑大型语言模型（LLMs），通过比较基础模型和后训练模型，从知识存储、真实性（truthfulness）、拒绝（refusal）和置信度（confidence）四个方面进行分析。研究发现，后训练不改变事实知识的存储位置，而是适应原有知识表示并开发新表示。真实性可以用隐藏表示空间中的线性向量表示，且其方向在基础和后训练模型间高度相似，便于转移干预；相反，拒绝方向在两类模型间不同，且转移性有限。置信度的差异不能归因于熵神经元。该研究为模型导向（model steering）和未来LLMs后训练研究提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02904v1",
      "published_date": "2025-04-03 06:30:55 UTC",
      "updated_date": "2025-04-03 06:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:24:08.824000"
    },
    {
      "arxiv_id": "2504.02293v1",
      "title": "State-of-the-Art Translation of Text-to-Gloss using mBART : A case study of Bangla",
      "title_zh": "翻译失败",
      "authors": [
        "Sharif Md. Abdullah",
        "Abhijit Paul",
        "Shebuti Rayana",
        "Ahmedul Kabir",
        "Zarif Masud"
      ],
      "abstract": "Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language\n(BdSL) remains a understudied domain. Specifically, there are no works on\nBangla text-to-gloss translation task. To address this gap, we begin by\naddressing the dataset problem. We take inspiration from grammatical rule based\ngloss generation used in Germany and American sign langauage (ASL) and adapt it\nfor BdSL. We also leverage LLM to generate synthetic data and use\nback-translation, text generation for data augmentation. With dataset prepared,\nwe started experimentation. We fine-tuned pretrained mBART-50 and\nmBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a\nnovel seq-to-seq model with multi-head attention. We observe significant high\nperformance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual\nmodel from Facebook. We then explored why we observe such high performance with\nmBART. We soon notice an interesting property of mBART -- it was trained on\nshuffled and masked text data. And as we know, gloss form has shuffling\nproperty. So we hypothesize that mBART is inherently good at text-to-gloss\ntasks. To find support against this hypothesis, we trained mBART-50 on\nPHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50\nfinetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,\nfar outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =\n55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on\nthe results, this study proposes a new paradigm for text-to-gloss task using\nmBART models. Additionally, our results show that BdSL text-to-gloss task can\ngreatly benefit from rule-based synthetic dataset.",
      "tldr_zh": "这项研究针对孟加拉语手语（BdSL）的文本到手语词汇（text-to-gloss）翻译任务，解决了数据集不足的问题，通过语法规则生成数据并利用 LLM 进行合成数据增强和回译。\n作者微调了预训练模型如 mBART-50 和 mBERT，并训练了 GRU、RNN 以及一个新的 seq-to-seq 多头注意力模型，结果显示 mBART-50 在 BdSL 数据集上取得了高性能（SacreBLEU=79.53）。\n分析表明，mBART 的乱序和掩码训练特性使其特别适合手语词汇任务，并在 PHOENIX-14T 基准上超越现有模型，实现了 State-of-the-Art 性能（例如 SacreBLEU=63.89）。\n该研究提出使用 mBART 模型的新范式，并证明规则-based 合成数据集能显著提升 BdSL 翻译任务的效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Initial Version",
      "pdf_url": "http://arxiv.org/pdf/2504.02293v1",
      "published_date": "2025-04-03 05:47:51 UTC",
      "updated_date": "2025-04-03 05:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:24:22.331292"
    },
    {
      "arxiv_id": "2504.03771v1",
      "title": "Flow State: Humans Enabling AI Systems to Program Themselves",
      "title_zh": "翻译失败",
      "authors": [
        "Helena Zhang",
        "Jakobi Haskell",
        "Yosef Frost"
      ],
      "abstract": "Compound AI systems, orchestrating multiple AI components and external APIs,\nare increasingly vital but face challenges in managing complexity, handling\nambiguity, and enabling effective development workflows. Existing frameworks\noften introduce significant overhead, implicit complexity, or restrictive\nabstractions, hindering maintainability and iterative refinement, especially in\nHuman-AI collaborative settings. We argue that overcoming these hurdles\nrequires a foundational architecture prioritizing structural clarity and\nexplicit control. To this end, we introduce Pocketflow, a platform centered on\nHuman-AI co-design, enabled by Pocketflow. Pocketflow is a Python framework\nbuilt upon a deliberately minimal yet synergistic set of core abstractions:\nmodular Nodes with a strict lifecycle, declarative Flow orchestration, native\nhierarchical nesting (Flow-as-Node), and explicit action-based conditional\nlogic. This unique combination provides a robust, vendor-agnostic foundation\nwith very little code that demonstrably reduces overhead while offering the\nexpressiveness needed for complex patterns like agentic workflows and RAG.\nComplemented by Pocket AI, an assistant leveraging this structure for system\ndesign, Pocketflow provides an effective environment for iteratively\nprototyping, refining, and deploying the adaptable, scalable AI systems\ndemanded by modern enterprises.",
      "tldr_zh": "该论文探讨了复合 AI 系统在管理复杂性、处理模糊性和开发工作流方面的挑战，现有的框架往往导致额外开销和限制性抽象，影响人-AI 协作中的可维护性和迭代改进。为解决这些问题，研究团队引入了 Pocketflow，一个以人-AI 共同设计为核心的 Python 框架，利用模块化 Nodes（具有严格生命周期）、声明式 Flow 编排、本地层次化嵌套 (Flow-as-Node) 和显性基于动作的条件逻辑等最小协同抽象，提供稳健的、供应商无关的基础，以少量代码实现复杂模式如 agentic 工作流和 RAG。Pocketflow 结合 Pocket AI 助手，创建了一个高效的环境，支持迭代原型设计、完善和部署适应性、可扩展的 AI 系统，满足现代企业的需求。",
      "categories": [
        "cs.AI",
        "68T99, 68N19, 68U35",
        "I.2.1; D.2.11; H.5.2"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 4 figures, 5 tables. Describes a minimalist framework for\n  human-AI co-design of compound AI systems",
      "pdf_url": "http://arxiv.org/pdf/2504.03771v1",
      "published_date": "2025-04-03 05:25:46 UTC",
      "updated_date": "2025-04-03 05:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:24:32.552360"
    },
    {
      "arxiv_id": "2504.02285v1",
      "title": "Tree-based Models for Vertical Federated Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Bingchen Qian",
        "Yuexiang Xie",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "abstract": "Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.",
      "tldr_zh": "这篇调查论文综述了tree-based models在vertical federated learning (VFL)中的应用，重点从通信和计算协议角度分析其有效性、鲁棒性和可解释性。论文将tree-based models在VFL中分为feature-gathering models和label-scattering models两类，并详细讨论了它们的特性、优势、隐私保护机制以及实际应用。作者还总结了实现这些模型的设计原则，以适应学术研究和工业部署的需求，并通过实验提供了不同模型类型间的差异和进展的经验观察。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACM Computing Surveys (CSUR)",
      "pdf_url": "http://arxiv.org/pdf/2504.02285v1",
      "published_date": "2025-04-03 05:16:09 UTC",
      "updated_date": "2025-04-03 05:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:24:43.012320"
    },
    {
      "arxiv_id": "2504.03770v2",
      "title": "JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model",
      "title_zh": "JailDAM：针对视觉语言模型的自适应记忆越狱检测",
      "authors": [
        "Yi Nian",
        "Shenzhe Zhu",
        "Yuehan Qin",
        "Li Li",
        "Ziyi Wang",
        "Chaowei Xiao",
        "Yue Zhao"
      ],
      "abstract": "Multimodal large language models (MLLMs) excel in vision-language tasks but\nalso pose significant risks of generating harmful content, particularly through\njailbreak attacks. Jailbreak attacks refer to intentional manipulations that\nbypass safety mechanisms in models, leading to the generation of inappropriate\nor unsafe content. Detecting such attacks is critical to ensuring the\nresponsible deployment of MLLMs. Existing jailbreak detection methods face\nthree primary challenges: (1) Many rely on model hidden states or gradients,\nlimiting their applicability to white-box models, where the internal workings\nof the model are accessible; (2) They involve high computational overhead from\nuncertainty-based analysis, which limits real-time detection, and (3) They\nrequire fully labeled harmful datasets, which are often scarce in real-world\nsettings. To address these issues, we introduce a test-time adaptive framework\ncalled JAILDAM. Our method leverages a memory-based approach guided by\npolicy-driven unsafe knowledge representations, eliminating the need for\nexplicit exposure to harmful data. By dynamically updating unsafe knowledge\nduring test-time, our framework improves generalization to unseen jailbreak\nstrategies while maintaining efficiency. Experiments on multiple VLM jailbreak\nbenchmarks demonstrate that JAILDAM delivers state-of-the-art performance in\nharmful content detection, improving both accuracy and speed.",
      "tldr_zh": "该研究针对多模态大语言模型(MLLMs)面临的越狱攻击(jailbreak attacks)风险，提出了一种名为JAILDAM的测试时自适应框架，用于检测视觉语言模型(VLM)中的有害内容生成。JAILDAM采用基于记忆的方法，通过策略驱动的不安全知识表示动态更新记忆，从而避免了依赖模型隐藏状态或有害数据集的局限，同时提高了对未知攻击策略的泛化能力和检测效率。实验结果显示，该框架在多个VLM越狱基准上实现了最先进的性能，提升了有害内容检测的准确性和速度。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03770v2",
      "published_date": "2025-04-03 05:00:28 UTC",
      "updated_date": "2025-04-08 20:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:24:55.984398"
    },
    {
      "arxiv_id": "2504.02277v2",
      "title": "Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Rand",
        "Hadi Ibrahim"
      ],
      "abstract": "Medical imaging, particularly X-ray analysis, often involves detecting\nmultiple conditions simultaneously within a single scan, making multi-label\nclassification crucial for real-world clinical applications. We present the\nMedical X-ray Attention (MXA) block, a novel attention mechanism tailored\nspecifically to address the unique challenges of X-ray abnormality detection.\nThe MXA block enhances traditional Multi-Head Self Attention (MHSA) by\nintegrating a specialized module that efficiently captures both detailed local\ninformation and broader global context. To the best of our knowledge, this is\nthe first work to propose a task-specific attention mechanism for diagnosing\nchest X-rays, as well as to attempt multi-label classification using an\nEfficient Vision Transformer (EfficientViT). By embedding the MXA block within\nthe EfficientViT architecture and employing knowledge distillation, our\nproposed model significantly improves performance on the CheXpert dataset, a\nwidely used benchmark for multi-label chest X-ray abnormality detection. Our\napproach achieves an area under the curve (AUC) of 0.85, an absolute\nimprovement of 0.19 compared to our baseline model's AUC of 0.66, corresponding\nto a substantial approximate 233% relative improvement over random guessing\n(AUC = 0.5).",
      "tldr_zh": "本研究提出Medical X-ray Attention (MXA) block，一种针对X射线异常检测的创新注意力机制，用于提升多标签分类性能。MXA block通过增强传统的Multi-Head Self Attention (MHSA)，高效捕获局部细节和全局上下文，并将其嵌入Efficient Vision Transformer (EfficientViT)架构中，同时结合knowledge distillation技术。实验在CheXpert数据集上显示，该模型的AUC达到0.85，比基线模型的0.66提高了0.19，实现了约233%的相对改善，为临床X射线诊断提供了更准确的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 9 figures, 6 tables. For supplementary material and code,\n  see https://github.com/Hadi-M-Ibrahim/Beyond-Conventional-Transformers/",
      "pdf_url": "http://arxiv.org/pdf/2504.02277v2",
      "published_date": "2025-04-03 04:55:42 UTC",
      "updated_date": "2025-05-18 05:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:25:08.676943"
    },
    {
      "arxiv_id": "2504.02902v1",
      "title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models",
      "title_zh": "超越准确性：校准在自我改进大语言模型中的作用",
      "authors": [
        "Liangjie Huang",
        "Dawei Li",
        "Huan Liu",
        "Lu Cheng"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement\ncapabilities, whereby models iteratively revise their outputs through\nself-generated feedback. While this reflective mechanism has shown promise in\nenhancing task performance, recent studies suggest that it may also introduce\nundesirable biases-most notably, self-bias, or the tendency of LLMs to favor\ntheir own prior outputs. In this work, we extend this line of inquiry by\ninvestigating the impact on confidence estimation. We evaluate three\nrepresentative self-improvement paradigms-basic prompting, Chain-of-Thought\n(CoT) prompting, and tuning-based methods and find that iterative\nself-improvement can lead to systematic overconfidence, as evidenced by a\nsteadily increasing Expected Calibration Error (ECE) and lower accuracy with\nhigh confidence. We then further explore the integration of confidence\ncalibration techniques with self-improvement. Specifically, we compare three\nstrategies: (1) applying calibration after multiple rounds of self-improvement,\n(2) calibrating before self-improvement, and (3) applying calibration\niteratively at each self-improvement step. Our results show that iterative\ncalibration is most effective in reducing ECE, yielding improved calibration.\nOur work pioneers the study of self-improving LLMs from a calibration\nperspective, offering valuable insights into balancing model performance and\nreliability.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的自我改进机制（如基本提示、Chain-of-Thought (CoT) 提示和基于调优的方法）如何导致系统性过度自信，表现为 Expected Calibration Error (ECE) 增加和高置信度下的准确率下降，同时引入 self-bias 等偏差。通过比较三种校准策略——在自我改进后、之前或每个步骤中迭代应用校准——发现迭代校准最有效，能显著降低 ECE 并提升模型可靠性。该工作从校准角度开拓了自我改进 LLMs 的研究，提供平衡性能与可靠性的宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02902v1",
      "published_date": "2025-04-03 04:39:54 UTC",
      "updated_date": "2025-04-03 04:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:25:20.344390"
    },
    {
      "arxiv_id": "2504.02901v1",
      "title": "Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLM-Powered Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Yuan",
        "Yulin Chen",
        "Yin Zhang",
        "Wei Jiang"
      ],
      "abstract": "Learning from noisy labels (LNL) is a challenge that arises in many\nreal-world scenarios where collected training data can contain incorrect or\ncorrupted labels. Most existing solutions identify noisy labels and adopt\nactive learning to query human experts on them for denoising. In the era of\nlarge language models (LLMs), although we can reduce the human effort to\nimprove these methods, their performances are still subject to accurately\nseparating the clean and noisy samples from noisy data. In this paper, we\npropose an innovative collaborative learning framework NoiseAL based on active\nlearning to combine LLMs and small models (SMs) for learning from noisy labels.\nDuring collaborative training, we first adopt two SMs to form a co-prediction\nnetwork and propose a dynamic-enhanced threshold strategy to divide the noisy\ndata into different subsets, then select the clean and noisy samples from these\nsubsets to feed the active annotator LLMs to rectify noisy samples. Finally, we\nemploy different optimization objectives to conquer subsets with different\ndegrees of label noises. Extensive experiments on synthetic and real-world\nnoise datasets further demonstrate the superiority of our framework over\nstate-of-the-art baselines.",
      "tldr_zh": "该论文探讨了从噪声标签中学习（LNL）的挑战，提出了一种名为 NoiseAL 的噪声鲁棒协作主动学习框架，利用大型语言模型（LLMs）和小模型（SMs）来减少人类干预并提升性能。该框架通过两个 SMs 形成的共预测网络（co-prediction network）和动态增强阈值策略，将噪声数据划分为不同子集，并选择样本喂给 LLMs 进行噪声标签修正，同时采用不同的优化目标处理各子集的噪声程度。实验结果显示，NoiseAL 在合成和真实噪声数据集上优于现有基线方法，证明了其在主动学习（active learning）中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02901v1",
      "published_date": "2025-04-03 04:36:39 UTC",
      "updated_date": "2025-04-03 04:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:25:32.126378"
    },
    {
      "arxiv_id": "2504.02269v3",
      "title": "Engineering Artificial Intelligence: Framework, Challenges, and Future Direction",
      "title_zh": "工程人工智能：框架、挑战和未来方向",
      "authors": [
        "Jay Lee",
        "Hanqi Su",
        "Dai-Yan Ji",
        "Takanobu Minami"
      ],
      "abstract": "Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and eight future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）和机器学习（ML）在工程领域的应用，强调了开发领域特定AI方法面临的系统方法、可扩展性和鲁棒性挑战。论文引入了“ABCDE”作为Engineering AI的关键元素，并提出一个统一的生态框架，包括八个必要层、属性、目标和应用，以指导AI解决方案的开发和部署。同时，它分析了关键挑战并指出了八个未来研究方向。该框架旨在提供全面视角，促进AI的战略实施，推动下一代工程AI解决方案的发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper submitted to the Journal Machine Learning: Engineering has\n  been accepted",
      "pdf_url": "http://arxiv.org/pdf/2504.02269v3",
      "published_date": "2025-04-03 04:30:10 UTC",
      "updated_date": "2025-04-23 18:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:25:43.858512"
    },
    {
      "arxiv_id": "2504.02260v1",
      "title": "Implicit Neural Differential Model for Spatiotemporal Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Deepak Akhare",
        "Pan Du",
        "Tengfei Luo",
        "Jian-Xun Wang"
      ],
      "abstract": "Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.",
      "tldr_zh": "本研究提出Im-PiNDiff，一种新型隐式物理整合神经可微求解器，用于稳定准确地建模时空动态问题，解决传统显式循环框架的数值不稳定和错误积累问题。该框架受深度平衡模型启发，通过隐式固定点层实现稳健的长期模拟，同时保持端到端可微性。为提升训练可扩展性，引入混合梯度传播策略，结合adjoint-state methods和反向模式自动微分，减少中间状态存储并降低内存开销，并辅以检查点技术管理长时域模拟。实验在多种时空PDE系统（如advection-diffusion过程、Burgers' dynamics和化学气相沉积过程）上表明，Im-PiNDiff相较显式和朴素隐式基线，实现了更高的预测性能、更强的数值稳定性和显著的内存及运行时成本降低，为混合神经物理建模提供了一个高效可扩展的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02260v1",
      "published_date": "2025-04-03 04:07:18 UTC",
      "updated_date": "2025-04-03 04:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:25:56.418003"
    },
    {
      "arxiv_id": "2504.02254v1",
      "title": "LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks",
      "title_zh": "大语言模型作为欺骗性",
      "authors": [
        "Seunghyun Yoo"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.",
      "tldr_zh": "本文研究大型语言模型(LLMs)作为欺骗性代理时，如何通过基于角色的提示(role-based prompting)诱导语义模糊性(semantic ambiguity)，从而生成误导人类的谜题。研究者比较了零样本提示(zero-shot prompting)、注入角色的对抗提示和人类创建的谜题，使用HateBERT等计算分析结合人类评估，揭示对抗性代理行为显著增加了语义模糊性，导致谜题解决的认知负荷升高和公平性降低。这些发现为LLMs的代理特性提供了关键洞见，并强调了在教育技术和娱乐应用中评估和安全部署的伦理考虑。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68T05, 68U35"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.02254v1",
      "published_date": "2025-04-03 03:45:58 UTC",
      "updated_date": "2025-04-03 03:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:26:08.834424"
    },
    {
      "arxiv_id": "2504.02252v1",
      "title": "Adapting World Models with Latent-State Dynamics Residuals",
      "title_zh": "翻译失败",
      "authors": [
        "JB Lanier",
        "Kyungmin Kim",
        "Armin Karamzade",
        "Yifei Liu",
        "Ankita Sinha",
        "Kat He",
        "Davide Corsi",
        "Roy Fox"
      ],
      "abstract": "Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.",
      "tldr_zh": "该研究针对模拟到现实的强化学习（RL）中模拟与真实动态差异导致的性能下降问题，提出了一种名为 ReDRAW 的框架。该框架通过在模拟环境中预训练潜在状态自回归世界模型，并使用潜在状态动态的残差修正来校准目标环境，从而避免了直接修正高维状态（如图像）的不 practicality。ReDRAW 允许 RL 代理在修正后的动态下进行想象 rollout 优化，然后部署到真实世界。在多个基于视觉的 MuJoCo 领域和物理机器人视觉跟随任务中，该方法有效建模动态变化，并在低数据情况下避免过拟合，优于传统转移方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 11 figures. Project website at https://redraw.jblanier.net/",
      "pdf_url": "http://arxiv.org/pdf/2504.02252v1",
      "published_date": "2025-04-03 03:41:30 UTC",
      "updated_date": "2025-04-03 03:41:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:26:20.644976"
    },
    {
      "arxiv_id": "2504.02234v1",
      "title": "LLM Social Simulations Are a Promising Research Method",
      "title_zh": "LLM 社交模拟是一种有前景的研究方法",
      "authors": [
        "Jacy Reese Anthis",
        "Ryan Liu",
        "Sean M. Richardson",
        "Austin C. Kozlowski",
        "Bernard Koch",
        "James Evans",
        "Erik Brynjolfsson",
        "Michael Bernstein"
      ],
      "abstract": "Accurate and verifiable large language model (LLM) simulations of human\nresearch subjects promise an accessible data source for understanding human\nbehavior and training new AI systems. However, results to date have been\nlimited, and few social scientists have adopted these methods. In this position\npaper, we argue that the promise of LLM social simulations can be achieved by\naddressing five tractable challenges. We ground our argument in a literature\nsurvey of empirical comparisons between LLMs and human research subjects,\ncommentaries on the topic, and related work. We identify promising directions\nwith prompting, fine-tuning, and complementary methods. We believe that LLM\nsocial simulations can already be used for exploratory research, such as pilot\nexperiments for psychology, economics, sociology, and marketing. More\nwidespread use may soon be possible with rapidly advancing LLM capabilities,\nand researchers should prioritize developing conceptual models and evaluations\nthat can be iteratively deployed and refined at pace with ongoing AI advances.",
      "tldr_zh": "这篇论文主张，大型语言模型 (LLM) 社会模拟是一种有前景的研究方法，可作为理解人类行为和训练新 AI 系统的数据来源，尽管当前应用有限。作者通过文献调查，识别了五个可处理的挑战，并提出利用 prompting、fine-tuning 和补充方法等策略来提升模拟的准确性和可验证性。论文建议 LLM 社会模拟已可用于探索性研究，如心理学、经济、社会学和营销的试点实验，并呼吁研究者优先开发可迭代的概念模型和评估，以适应快速推进的 AI 技术。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02234v1",
      "published_date": "2025-04-03 03:01:26 UTC",
      "updated_date": "2025-04-03 03:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:26:32.081076"
    },
    {
      "arxiv_id": "2504.02231v1",
      "title": "AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image Generation",
      "title_zh": "AC-LoRA：用于个性化艺术风格图像生成的自动组件 LoRA",
      "authors": [
        "Zhipu Cui",
        "Andong Tian",
        "Zhi Ying",
        "Jialiang Lu"
      ],
      "abstract": "Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.",
      "tldr_zh": "该论文提出了一种名为 AC-LoRA 的方法，用于个性化艺术风格图像生成，旨在解决传统 Low Rank Adaptation (LoRA) 方法中 rank 参数调整的难题。AC-LoRA 通过 Singular Value Decomposition (SVD) 和动态启发式技术，自动分离 LoRA 矩阵中的信号组件和噪声组件，从而实现更高效的训练，避免模型 underfitting 或 overfitting。实验结果显示，AC-LoRA 在 FID、CLIP、DINO 和 ImageReward 等指标上平均提高了 9%，显著提升了个性化图像生成的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T05, 68U10",
        "I.2.6; I.4.0"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures, ICCGV 2025, SPIE",
      "pdf_url": "http://arxiv.org/pdf/2504.02231v1",
      "published_date": "2025-04-03 02:56:01 UTC",
      "updated_date": "2025-04-03 02:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:26:42.869548"
    },
    {
      "arxiv_id": "2504.02227v1",
      "title": "VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Hao Fei",
        "Zechao Hu",
        "Zhengwei Yang",
        "Zheng Wang"
      ],
      "abstract": "Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.",
      "tldr_zh": "本研究针对 Social Intelligence Queries (Social-IQ) 基准中的问题，指出现有模型过度依赖语言模态而忽略视觉上下文，且封闭式多选题无法评估推理路径的准确性。研究提出 VEGAS 模型，这是一个生成式多模态模型，通过开放式回答提供可解释的响应，并采用新颖的采样策略获取相关视觉帧。进一步，通过 Generalist Instruction Fine-Tuning (GIFT) 训练，VEGAS 学习多模态语言转换和联合推理能力，以提升对情感社会特质的理解。实验结果显示，VEGAS 在模态消融、开放式评估和监督多选题测试中，显著提升了视觉信息的利用率，提供正确且可信的答案，并为开发更像人类的社交 AI 带来新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures, AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02227v1",
      "published_date": "2025-04-03 02:48:21 UTC",
      "updated_date": "2025-04-03 02:48:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:26:56.223073"
    },
    {
      "arxiv_id": "2504.02221v1",
      "title": "Learning and Improving Backgammon Strategy",
      "title_zh": "学习和改进 Backgammon 策略",
      "authors": [
        "Gregory R. Galperin"
      ],
      "abstract": "A novel approach to learning is presented, combining features of on-line and\noff-line methods to achieve considerable performance in the task of learning a\nbackgammon value function in a process that exploits the processing power of\nparallel supercomputers. The off-line methods comprise a set of techniques for\nparallelizing neural network training and $TD(\\lambda)$ reinforcement learning;\nhere Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line\npolicy improvement technique which applies resources to the decision points\nencountered during the search of the game tree to further augment the learned\nvalue function estimate. A level of play roughly as good as, or possibly better\nthan, the current champion human and computer backgammon players has been\nachieved in a short period of learning.",
      "tldr_zh": "这篇论文提出了一种结合在线和离线学习的新方法，用于学习Backgammon的价值函数，充分利用并行超级计算机的处理能力。方法包括并行化neural network训练、TD(λ)强化学习，以及引入Monte-Carlo Rollouts作为大规模并行在线策略改进技术，以增强游戏树搜索中的决策。实验结果显示，该方法在短时间内达到了与当前顶级人类和计算机玩家相当或更高的水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accompanied by oral presentation by Gregory Galperin at the CBCL\n  Learning Day 1994",
      "pdf_url": "http://arxiv.org/pdf/2504.02221v1",
      "published_date": "2025-04-03 02:27:22 UTC",
      "updated_date": "2025-04-03 02:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:27:09.087416"
    },
    {
      "arxiv_id": "2504.02211v1",
      "title": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Huangliang Dai",
        "Shixun Wu",
        "Hairui Zhao",
        "Jiajun Huang",
        "Zizhe Jian",
        "Yue Zhu",
        "Haiyang Hu",
        "Zizhong Chen"
      ],
      "abstract": "Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.",
      "tldr_zh": "这篇论文提出 FT-Transformer 框架，通过集成端到端故障容忍注意力 (EFTA)，提升 Transformer 模型在软错误下的推理可靠性，避免了传统方法的分离内核保护带来的高计算和内存开销。框架引入混合故障容忍方案，包括架构感知算法-based fault tolerance (ABFT) 使用张量校验和减少通信开销、选择性神经元值限制平衡错误覆盖和开销，以及统一验证重用校验和简化计算步骤。实验结果显示，EFTA 相较传统方法实现高达 7.56 倍的加速，同时平均故障容忍开销仅 13.9%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02211v1",
      "published_date": "2025-04-03 02:05:08 UTC",
      "updated_date": "2025-04-03 02:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:27:21.214889"
    },
    {
      "arxiv_id": "2504.02199v1",
      "title": "ESC: Erasing Space Concept for Knowledge Deletion",
      "title_zh": "ESC：用于知识删除的擦除空间概念",
      "authors": [
        "Tae-Young Lee",
        "Sundong Park",
        "Minwoo Jeon",
        "Hyoseok Hwang",
        "Gyeong-Moon Park"
      ],
      "abstract": "As concerns regarding privacy in deep learning continue to grow, individuals\nare increasingly apprehensive about the potential exploitation of their\npersonal knowledge in trained models. Despite several research efforts to\naddress this, they often fail to consider the real-world demand from users for\ncomplete knowledge erasure. Furthermore, our investigation reveals that\nexisting methods have a risk of leaking personal knowledge through embedding\nfeatures. To address these issues, we introduce a novel concept of Knowledge\nDeletion (KD), an advanced task that considers both concerns, and provides an\nappropriate metric, named Knowledge Retention score (KR), for assessing\nknowledge retention in feature space. To achieve this, we propose a novel\ntraining-free erasing approach named Erasing Space Concept (ESC), which\nrestricts the important subspace for the forgetting knowledge by eliminating\nthe relevant activations in the feature. In addition, we suggest ESC with\nTraining (ESC-T), which uses a learnable mask to better balance the trade-off\nbetween forgetting and preserving knowledge in KD. Our extensive experiments on\nvarious datasets and models demonstrate that our proposed methods achieve the\nfastest and state-of-the-art performance. Notably, our methods are applicable\nto diverse forgetting scenarios, such as facial domain setting, demonstrating\nthe generalizability of our methods. The code is available at\nhttp://github.com/KU-VGI/ESC .",
      "tldr_zh": "该论文针对深度学习模型中隐私问题，引入Knowledge Deletion (KD) 概念，并提出Knowledge Retention score (KR) 作为评估知识保留的指标，以确保彻底删除个人知识并防止通过嵌入特征泄露。研究提出Erasing Space Concept (ESC)，一种无需训练的擦除方法，通过消除相关激活来限制遗忘知识的重要子空间；同时，开发ESC with Training (ESC-T)，使用可学习掩码平衡遗忘与保留知识的权衡。实验结果显示，ESC 和 ESC-T 在多种数据集和模型上实现最快且最先进的性能，并适用于多样遗忘场景，如面部领域，证明了其通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 14 figures, 18 tables, CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.02199v1",
      "published_date": "2025-04-03 00:53:09 UTC",
      "updated_date": "2025-04-03 00:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:27:31.894392"
    },
    {
      "arxiv_id": "2504.02193v1",
      "title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Wang",
        "Runjin Chen",
        "Bolian Li",
        "David Cho",
        "Yihe Deng",
        "Ruqi Zhang",
        "Tianlong Chen",
        "Zhangyang Wang",
        "Ananth Grama",
        "Junyuan Hong"
      ],
      "abstract": "Aligning large language models (LLMs) with human values is an increasingly\ncritical step in post-training. Direct Preference Optimization (DPO) has\nemerged as a simple, yet effective alternative to reinforcement learning from\nhuman feedback (RLHF). Synthetic preference data with its low cost and high\nquality enable effective alignment through single- or multi-model generated\npreference data. Our study reveals a striking, safety-specific phenomenon\nassociated with DPO alignment: Although multi-model generated data enhances\nperformance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by\nproviding diverse responses, it also tends to facilitate reward hacking during\ntraining. This can lead to a high attack success rate (ASR) when models\nencounter jailbreaking prompts. The issue is particularly pronounced when\nemploying stronger models like GPT-4o or larger models in the same family to\ngenerate chosen responses paired with target model self-generated rejected\nresponses, resulting in dramatically poorer safety outcomes. Furthermore, with\nrespect to safety, using solely self-generated responses (single-model\ngeneration) for both chosen and rejected pairs significantly outperforms\nconfigurations that incorporate responses from stronger models, whether used\ndirectly as chosen data or as part of a multi-model response pool. We\ndemonstrate that multi-model preference data exhibits high linear separability\nbetween chosen and rejected responses, which allows models to exploit\nsuperficial cues rather than internalizing robust safety constraints. Our\nexperiments, conducted on models from the Llama, Mistral, and Qwen families,\nconsistently validate these findings.",
      "tldr_zh": "该研究揭示了在Direct Preference Optimization (DPO)安全对齐中使用多模型合成偏好数据的潜在陷阱：尽管这种数据能提升模型在一般任务（如ARC、Hellaswag和MMLU）上的性能，但它会促进奖励黑客(reward hacking)，导致模型面对越狱提示时攻击成功率(ASR)显著升高。实验对比了Llama、Mistral和Qwen模型家族，证明单模型生成的偏好数据（仅用自身生成chosen和rejected响应）在安全方面远优于多模型配置，后者因高线性可分性使模型依赖浅层线索而非内部化安全约束。该发现强调了在LLM对齐过程中，选择适当的合成数据策略以避免安全风险的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02193v1",
      "published_date": "2025-04-03 00:36:40 UTC",
      "updated_date": "2025-04-03 00:36:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:27:46.221187"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 118,
  "processed_papers_count": 118,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T09:28:03.680929"
}