{
  "date": "2024-07-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的鲁棒性、生成模型优化、多模态学习和医疗应用等领域，重点包括大型语言模型（LLMs）的安全性和解释性挑战、扩散模型在图像生成的效率提升，以及一些新基准数据集的提出；令人印象深刻的文章有 GPT-4V 在医疗报告生成中的局限性分析，以及涉及知名会议如 ECCV 和 ICML 的创新工作。\n\n下面，我挑选并简要讨论了部分重要、话题性和影响大的论文，先优先聊 LLMs 相关和医疗 AI 领域的内容，再快速掠过其他有代表性的论文。其他较常规或小众的论文（如一些纯理论优化或特定数据集分析）将简要提及或略过，以控制篇幅。\n\n**LLMs 相关论文：**  \n- **Whitening Not Recommended for Classification Tasks in LLMs（Whitening 不推荐用于 LLMs 的分类任务）**  \n  作者：Ali Forooghi 等。主要贡献是发现 whitening 操作在 LLMs 嵌入中对分类任务有害，通过广泛实验验证了其模型和任务依赖性，并引入了 SentEval+ 平台作为副产品。该发现有助于改进 LLMs 的嵌入质量，避免任务退化。\n\n- **This Probably Looks Exactly Like That: An Invertible Prototypical Network（这可能看起来一模一样：一个可逆的原型网络）**  \n  作者：Zachariah Carmichael 等。论文提出 ProtoFlow 模型，将概念-based 神经网络与基于流的分类器结合，实现可解释的监督学习，在生成和预测建模上达到新 SOTA，并在 ECCV'24 接受，代码开源。\n\n- **GPT-4V Cannot Generate Radiology Reports Yet（GPT-4V 还无法生成放射学报告）**  \n  作者：Yuyang Jiang 等。这篇话题度高的论文通过系统评估发现 GPT-4V 在放射学报告生成中表现差劲，尤其在图像推理和报告合成上，强调其对医学图像理解的局限性，并建议更精细的模型优化。\n\n- **Continuous Embedding Attacks via Clipped Inputs in Jailbreaking Large Language Models（通过裁剪输入的连续嵌入攻击来越狱大型语言模型）**  \n  作者：Zihao Xu 等。贡献包括一种直接攻击 LLM 输入的新方法，提出 CLIP 策略来提升攻击成功率（ASR 从 62% 提升到 83%），揭示了 LLM 在安全方面的脆弱点。\n\n- **Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning（基于偏好强化学习的主体驱动文本到图像生成）**  \n  作者：Yanting Miao 等。论文引入 λ-Harmonic 奖励函数和 Reward Preference Optimization（RPO）方法，实现高效的图像生成，达到 SOTA 的 CLIP-I 和 CLIP-T 分数，在 NeurIPS 2024 接受。\n\n- **Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent（可解释性在行动中：对 Minecraft 代理 VPT 的探索性分析）**  \n  作者：Karolis Jucys 等。通过注意力机制和干预分析，揭示 VPT 代理的推理机制，并在 ICML 2024 的 Mechanistic Interpretability Workshop 中讨论，强调了 LLM 在序列决策中的透明性问题。\n\n**医疗和多模态 AI 论文：**  \n- **Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions（针对软机器人交互的可解释视触觉预测模型）**  \n  作者：Enrico Donato 等。论文开发了一个多模态感知模型，使用生成模型融合视觉和本体感觉数据来预测软机器人与物体的交互，并在 BioRob 2024 接受，提供了解释工具以提升模型透明度。\n\n- **LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation（LLMs-in-the-loop 第1部分：用于生物医学文本翻译的专家小 AI 模型）**  \n  作者：Bunyamin Keles 等。贡献是提出 LLMs-in-the-loop 方法，使用合成数据训练小模型，实现比 GPT-4-Turbo 更好的翻译性能，针对医疗术语优化。\n\n- **Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions（前端扩散：通过抽象到详细任务转换探索基于意图的用户界面）**  \n  作者：Qinshi Zhang 等。论文探索生成式 AI 在用户界面的应用，提出三阶段任务转换过程（sketching、writing、coding），减少人类干预，支持复杂任务如网站生成。\n\n**图像生成和优化论文（快速掠过，强调效率和创新）：**  \n- **Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models（Beta 采样就是你需要的：基于步进谱分析的扩散模型高效图像生成策略）**  \n  作者：Haeil Lee 等。通过 Beta 分布采样优化扩散模型的去噪过程，提升 FID 和 IS 分数，提供更高效的图像合成。\n\n- **DreamCatalyst: Fast and High-Quality 3D Editing（DreamCatalyst：通过控制可编辑性和身份保留实现快速高质 3D 编辑）**  \n  作者：Jiwook Kim 等。提出优化扩散模型的框架，实现 23 倍加速的 NeRF 编辑，并在 ECCV 2024 接受，显著提升 3D 生成效率。\n\n- **SurroFlow: A Flow-Based Surrogate Model（SurroFlow：基于流的代理模型用于参数空间探索和不确定性量化）**  \n  作者：Jingyi Shen 等。开发基于归一化流的代理模型，支持模拟输出预测和不确定性量化，在 IEEE VIS 2024 发布。\n\n其他论文如强化学习（e.g., \"Satisficing Exploration for Deep Reinforcement Learning\"）和图神经网络（e.g., \"Tackling Oversmoothing in GNN via Graph Sparsification\"）主要讨论算法优化，但不那么话题化，仅快速提及它们在效率和鲁棒性上的改进。总体上，今天的论文突显了 AI 在实际应用中的潜力与挑战，未来研究可聚焦于模型安全和跨领域泛化。",
  "papers": [
    {
      "arxiv_id": "2407.12886v1",
      "title": "Whitening Not Recommended for Classification Tasks in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Forooghi",
        "Shaghayegh Sadeghi",
        "Jianguo Lu"
      ],
      "abstract": "Sentence embedding is a cornerstone in NLP. Whitening has been claimed to be\nan effective operation to improve embedding quality obtained from Large\nLanguage Models (LLMs). However, we find that the efficacy of whitening is\nmodel-dependent and task-dependent. In particular, whitening degenerates\nembeddings for classification tasks. The conclusion is supported by extensive\nexperiments. We also explored a variety of whitening operations, including PCA,\nZCA, PCA-Cor, ZCA-Cor and Cholesky whitenings. A by-product of our research is\nembedding evaluation platform for LLMs called SentEval+.",
      "tldr_zh": "这篇论文探讨了白化(whitening)操作对大型语言模型(LLMs)句子嵌入的影响，发现其有效性依赖于模型和任务，尤其在分类任务中，白化会导致嵌入质量退化。研究通过广泛实验验证了这一结论，并测试了多种白化方法，包括 PCA、ZCA、PCA-Cor、ZCA-Cor 和 Cholesky whitenings。最终，论文不推荐将白化用于分类任务，并作为副产品开发了 SentEval+ 平台，用于评估 LLMs 的嵌入性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12886v1",
      "published_date": "2024-07-16 22:48:30 UTC",
      "updated_date": "2024-07-16 22:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:58:53.962996"
    },
    {
      "arxiv_id": "2407.12200v1",
      "title": "This Probably Looks Exactly Like That: An Invertible Prototypical Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zachariah Carmichael",
        "Timothy Redgrave",
        "Daniel Gonzalez Cedre",
        "Walter J. Scheirer"
      ],
      "abstract": "We combine concept-based neural networks with generative, flow-based\nclassifiers into a novel, intrinsically explainable, exactly invertible\napproach to supervised learning. Prototypical neural networks, a type of\nconcept-based neural network, represent an exciting way forward in realizing\nhuman-comprehensible machine learning without concept annotations, but a\nhuman-machine semantic gap continues to haunt current approaches. We find that\nreliance on indirect interpretation functions for prototypical explanations\nimposes a severe limit on prototypes' informative power. From this, we posit\nthat invertibly learning prototypes as distributions over the latent space\nprovides more robust, expressive, and interpretable modeling. We propose one\nsuch model, called ProtoFlow, by composing a normalizing flow with Gaussian\nmixture models. ProtoFlow (1) sets a new state-of-the-art in joint generative\nand predictive modeling and (2) achieves predictive performance comparable to\nexisting prototypical neural networks while enabling richer interpretation.",
      "tldr_zh": "该论文提出了一种新颖的、内在可解释的监督学习方法，将概念-based神经网络与生成式、基于流的分类器结合，创建出精确可逆的Prototypical Neural Networks。作者开发了ProtoFlow模型，通过normalizing flow和Gaussian mixture models学习潜在空间的原型分布，从而解决现有方法的语义鸿沟问题，提供更 robust、expressive和interpretable的建模。实验结果表明，ProtoFlow在联合生成和预测建模中设定了新的state-of-the-art水平，并在预测性能上与现有原型神经网络相当，同时提升了解释能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ECCV'24. Code available at\n  https://github.com/craymichael/ProtoFlow",
      "pdf_url": "http://arxiv.org/pdf/2407.12200v1",
      "published_date": "2024-07-16 21:51:02 UTC",
      "updated_date": "2024-07-16 21:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:59:07.245602"
    },
    {
      "arxiv_id": "2407.12197v2",
      "title": "Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Donato",
        "Thomas George Thuruthel",
        "Egidio Falotico"
      ],
      "abstract": "Autonomous systems face the intricate challenge of navigating unpredictable\nenvironments and interacting with external objects. The successful integration\nof robotic agents into real-world situations hinges on their perception\ncapabilities, which involve amalgamating world models and predictive skills.\nEffective perception models build upon the fusion of various sensory modalities\nto probe the surroundings. Deep learning applied to raw sensory modalities\noffers a viable option. However, learning-based perceptive representations\nbecome difficult to interpret. This challenge is particularly pronounced in\nsoft robots, where the compliance of structures and materials makes prediction\neven harder. Our work addresses this complexity by harnessing a generative\nmodel to construct a multi-modal perception model for soft robots and to\nleverage proprioceptive and visual information to anticipate and interpret\ncontact interactions with external objects. A suite of tools to interpret the\nperception model is furnished, shedding light on the fusion and prediction\nprocesses across multiple sensory inputs after the learning phase. We will\ndelve into the outlooks of the perception model and its implications for\ncontrol purposes.",
      "tldr_zh": "本研究针对软机器人（Soft Robot）在不可预测环境中的交互挑战，提出了一种可解释的视觉-触觉预测模型（Visuo-Tactile Predictive Models），旨在融合本体感觉和视觉信息来预测外部物体接触。方法采用生成模型（Generative Model）构建多模态感知模型（Multi-modal Perception Model），以解决深度学习表示难以解释的问题，并在软机器人柔顺结构下提升预测准确性。研究提供了一系列解释工具，揭示感官输入的融合和预测过程，并探讨该模型对机器人控制的潜在应用前景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE RAS EMBS 10th International Conference on Biomedical Robotics\n  and Biomechatronics (BioRob 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.12197v2",
      "published_date": "2024-07-16 21:46:04 UTC",
      "updated_date": "2024-07-25 12:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:59:17.996890"
    },
    {
      "arxiv_id": "2407.12185v1",
      "title": "Satisficing Exploration for Deep Reinforcement Learning",
      "title_zh": "深度强化学习的满意化探索",
      "authors": [
        "Dilip Arumugam",
        "Saurabh Kumar",
        "Ramki Gummadi",
        "Benjamin Van Roy"
      ],
      "abstract": "A default assumption in the design of reinforcement-learning algorithms is\nthat a decision-making agent always explores to learn optimal behavior. In\nsufficiently complex environments that approach the vastness and scale of the\nreal world, however, attaining optimal performance may in fact be an entirely\nintractable endeavor and an agent may seldom find itself in a position to\ncomplete the requisite exploration for identifying an optimal policy. Recent\nwork has leveraged tools from information theory to design agents that\ndeliberately forgo optimal solutions in favor of sufficiently-satisfying or\nsatisficing solutions, obtained through lossy compression. Notably, such agents\nmay employ fundamentally different exploratory decisions to learn satisficing\nbehaviors more efficiently than optimal ones that are more data intensive.\nWhile supported by a rigorous corroborating theory, the underlying algorithm\nrelies on model-based planning, drastically limiting the compatibility of these\nideas with function approximation and high-dimensional observations. In this\nwork, we remedy this issue by extending an agent that directly represents\nuncertainty over the optimal value function allowing it to both bypass the need\nfor model-based planning and to learn satisficing policies. We provide simple\nyet illustrative experiments that demonstrate how our algorithm enables deep\nreinforcement-learning agents to achieve satisficing behaviors. In keeping with\nprevious work on this setting for multi-armed bandits, we additionally find\nthat our algorithm is capable of synthesizing optimal behaviors, when feasible,\nmore efficiently than its non-information-theoretic counterpart.",
      "tldr_zh": "这篇论文探讨了在复杂环境中，强化学习代理通过 satisficing 探索来学习足够满意的行为，而不是追求难以实现的 optimal 策略。作者扩展了一个代理，使用信息理论工具直接表示 optimal 值函数的不确定性，从而避免依赖模型-based planning，并支持函数逼近和高维观察。实验结果显示，该算法使深度强化学习代理更高效地学习 satisficing 策略，并在可行时比非信息理论方法更快地合成 optimal 行为。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12185v1",
      "published_date": "2024-07-16 21:28:03 UTC",
      "updated_date": "2024-07-16 21:28:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:59:30.005767"
    },
    {
      "arxiv_id": "2407.12178v1",
      "title": "Exploration Unbound",
      "title_zh": "探索无界",
      "authors": [
        "Dilip Arumugam",
        "Wanqiao Xu",
        "Benjamin Van Roy"
      ],
      "abstract": "A sequential decision-making agent balances between exploring to gain new\nknowledge about an environment and exploiting current knowledge to maximize\nimmediate reward. For environments studied in the traditional literature,\noptimal decisions gravitate over time toward exploitation as the agent\naccumulates sufficient knowledge and the benefits of further exploration\nvanish. What if, however, the environment offers an unlimited amount of useful\nknowledge and there is large benefit to further exploration no matter how much\nthe agent has learned? We offer a simple, quintessential example of such a\ncomplex environment. In this environment, rewards are unbounded and an agent\ncan always increase the rate at which rewards accumulate by exploring to learn\nmore. Consequently, an optimal agent forever maintains a propensity to explore.",
      "tldr_zh": "这篇论文探讨了决策代理在环境不确定性下的行为，强调了探索(exploration)和利用(exploitation)之间的平衡。传统文献中，代理会随着知识积累转向利用，因为探索益处递减；但在本文提出的环境中，奖励是无界的(unbounded)，代理可以通过持续探索获得无限有用知识，从而不断提高奖励积累率。结果显示，最优代理会永久保持探索倾向(propensity to explore)，这为复杂环境下的决策理论提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12178v1",
      "published_date": "2024-07-16 21:14:43 UTC",
      "updated_date": "2024-07-16 21:14:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:59:41.438840"
    },
    {
      "arxiv_id": "2407.12176v4",
      "title": "GPT-4V Cannot Generate Radiology Reports Yet",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Jiang",
        "Chacha Chen",
        "Dang Nguyen",
        "Benjamin M. Mervak",
        "Chenhao Tan"
      ],
      "abstract": "GPT-4V's purported strong multimodal abilities raise interests in using it to\nautomate radiology report writing, but there lacks thorough evaluations. In\nthis work, we perform a systematic evaluation of GPT-4V in generating radiology\nreports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt\nto directly generate reports using GPT-4V through different prompting\nstrategies and find that it fails terribly in both lexical metrics and clinical\nefficacy metrics. To understand the low performance, we decompose the task into\ntwo steps: 1) the medical image reasoning step of predicting medical condition\nlabels from images; and 2) the report synthesis step of generating reports from\n(groundtruth) conditions. We show that GPT-4V's performance in image reasoning\nis consistently low across different prompts. In fact, the distributions of\nmodel-predicted labels remain constant regardless of which groundtruth\nconditions are present on the image, suggesting that the model is not\ninterpreting chest X-rays meaningfully. Even when given groundtruth conditions\nin report synthesis, its generated reports are less correct and less\nnatural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt\non the viability of using GPT-4V in a radiology workflow.",
      "tldr_zh": "本研究系统评估了GPT-4V在生成放射学报告方面的能力，使用MIMIC-CXR和IU X-Ray数据集，通过不同prompting strategies直接生成胸部X光报告，结果显示其在lexical metrics和clinical efficacy metrics上表现极差。研究将任务分解为medical image reasoning（从图像预测医疗条件标签）和report synthesis（从条件生成报告）两个步骤，发现GPT-4V在图像推理上持续低效，且模型预测标签的分布不受图像实际条件影响，表明其未能有效解读胸部X光图像。即使在report synthesis步骤提供groundtruth conditions，其生成的报告在正确性和自然度上仍不如finetuned LLaMA-2。总体而言，该研究质疑了GPT-4V在放射学工作流中的可行性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "24 pages, 3 figures, code:\n  https://github.com/ChicagoHAI/cxr-eval-gpt-4v Findings paper presented at\n  Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024,\n  Vancouver, Canada, 26 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.12176v4",
      "published_date": "2024-07-16 21:03:14 UTC",
      "updated_date": "2024-11-14 21:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:59:54.841374"
    },
    {
      "arxiv_id": "2407.12173v1",
      "title": "Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis",
      "title_zh": "Beta 采样就是你所需要的全部：利用逐步谱分析的",
      "authors": [
        "Haeil Lee",
        "Hansang Lee",
        "Seoyeon Gye",
        "Junmo Kim"
      ],
      "abstract": "Generative diffusion models have emerged as a powerful tool for high-quality\nimage synthesis, yet their iterative nature demands significant computational\nresources. This paper proposes an efficient time step sampling method based on\nan image spectral analysis of the diffusion process, aimed at optimizing the\ndenoising process. Instead of the traditional uniform distribution-based time\nstep sampling, we introduce a Beta distribution-like sampling technique that\nprioritizes critical steps in the early and late stages of the process. Our\nhypothesis is that certain steps exhibit significant changes in image content,\nwhile others contribute minimally. We validated our approach using Fourier\ntransforms to measure frequency response changes at each step, revealing\nsubstantial low-frequency changes early on and high-frequency adjustments\nlater. Experiments with ADM and Stable Diffusion demonstrated that our Beta\nSampling method consistently outperforms uniform sampling, achieving better FID\nand IS scores, and offers competitive efficiency relative to state-of-the-art\nmethods like AutoDiffusion. This work provides a practical framework for\nenhancing diffusion model efficiency by focusing computational resources on the\nmost impactful steps, with potential for further optimization and broader\napplication.",
      "tldr_zh": "这篇论文提出了一种基于 Beta 分布-like 采样的高效图像生成策略，用于优化扩散模型的去噪过程，以减少计算资源需求。作者通过傅立叶变换分析图像谱，识别早期低频变化和高频调整的关键步骤，并优先分配资源，而非传统的均匀分布采样。实验在 ADM 和 Stable Diffusion 上验证，该方法显著提升了 FID 和 IS 分数，比均匀采样提高性能，并与 AutoDiffusion 等技术竞争效率。该框架为聚焦计算资源于最影响力的步骤提供了实用方法，具有更广泛的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12173v1",
      "published_date": "2024-07-16 20:53:06 UTC",
      "updated_date": "2024-07-16 20:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:00:06.544073"
    },
    {
      "arxiv_id": "2407.13796v1",
      "title": "Continuous Embedding Attacks via Clipped Inputs in Jailbreaking Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Xu",
        "Yi Liu",
        "Gelei Deng",
        "Kailong Wang",
        "Yuekang Li",
        "Ling Shi",
        "Stjepan Picek"
      ],
      "abstract": "Security concerns for large language models (LLMs) have recently escalated,\nfocusing on thwarting jailbreaking attempts in discrete prompts. However, the\nexploration of jailbreak vulnerabilities arising from continuous embeddings has\nbeen limited, as prior approaches primarily involved appending discrete or\ncontinuous suffixes to inputs. Our study presents a novel channel for\nconducting direct attacks on LLM inputs, eliminating the need for suffix\naddition or specific questions provided that the desired output is predefined.\nWe additionally observe that extensive iterations often lead to overfitting,\ncharacterized by repetition in the output. To counteract this, we propose a\nsimple yet effective strategy named CLIP. Our experiments show that for an\ninput length of 40 at iteration 1000, applying CLIP improves the ASR from 62%\nto 83%",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的安全漏洞，专注于通过连续嵌入 (continuous embeddings) 进行越狱 (jailbreaking) 攻击，超越了以往针对离散提示的防御方法。研究提出了一种直接攻击输入的新策略，无需添加后缀或特定问题，仅需预定义输出，并引入 CLIP 机制来缓解迭代过程中的过拟合问题。实验结果显示，在输入长度为40和迭代1000次的情况下，CLIP 将攻击成功率 (ASR) 从62% 提高到83%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.13796v1",
      "published_date": "2024-07-16 20:53:00 UTC",
      "updated_date": "2024-07-16 20:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:00:18.361563"
    },
    {
      "arxiv_id": "2407.12165v2",
      "title": "Building AI Agents for Autonomous Clouds: Challenges and Design Principles",
      "title_zh": "为自治云构建 AI 代理：挑战与设计原则",
      "authors": [
        "Manish Shetty",
        "Yinfang Chen",
        "Gagan Somashekar",
        "Minghua Ma",
        "Yogesh Simmhan",
        "Xuchao Zhang",
        "Jonathan Mace",
        "Dax Vandevoorde",
        "Pedro Las-Casas",
        "Shachee Mishra Gupta",
        "Suman Nath",
        "Chetan Bansal",
        "Saravan Rajmohan"
      ],
      "abstract": "The rapid growth in the use of Large Language Models (LLMs) and AI Agents as\npart of software development and deployment is revolutionizing the information\ntechnology landscape. While code generation receives significant attention, a\nhigher-impact application lies in using AI agents for operational resilience of\ncloud services, which currently require significant human effort and domain\nknowledge. There is a growing interest in AI for IT Operations (AIOps) which\naims to automate complex operational tasks, like fault localization and root\ncause analysis, thereby reducing human intervention and customer impact.\nHowever, achieving the vision of autonomous and self-healing clouds through\nAIOps is hampered by the lack of standardized frameworks for building,\nevaluating, and improving AIOps agents. This vision paper lays the groundwork\nfor such a framework by first framing the requirements and then discussing\ndesign decisions that satisfy them. We also propose AIOpsLab, a prototype\nimplementation leveraging agent-cloud-interface that orchestrates an\napplication, injects real-time faults using chaos engineering, and interfaces\nwith an agent to localize and resolve the faults. We report promising results\nand lay the groundwork to build a modular and robust framework for building,\nevaluating, and improving agents for autonomous clouds.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 和 AI Agents 构建自主云服务的挑战，包括缺乏标准化框架和对复杂操作任务（如故障定位和根因分析）的自动化需求。作者提出了一个框架，包括需求定义、设计原则和 AIOpsLab 的原型实现，该原型利用 agent-cloud-interface 和 chaos engineering 注入实时故障，以测试代理的故障定位和解决能力。实验结果显示了该框架的潜力，有助于减少人为干预并提升云服务的操作弹性。该工作为开发模块化、鲁棒的 AIOps 代理奠定了基础，推动自主和自愈云的实现。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12165v2",
      "published_date": "2024-07-16 20:40:43 UTC",
      "updated_date": "2024-07-31 06:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:00:30.205858"
    },
    {
      "arxiv_id": "2407.12164v3",
      "title": "Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yanting Miao",
        "William Loh",
        "Suraj Kothawade",
        "Pascal Poupart",
        "Abdullah Rashwan",
        "Yeqing Li"
      ],
      "abstract": "Text-to-image generative models have recently attracted considerable\ninterest, enabling the synthesis of high-quality images from textual prompts.\nHowever, these models often lack the capability to generate specific subjects\nfrom given reference images or to synthesize novel renditions under varying\nconditions. Methods like DreamBooth and Subject-driven Text-to-Image (SuTI)\nhave made significant progress in this area. Yet, both approaches primarily\nfocus on enhancing similarity to reference images and require expensive setups,\noften overlooking the need for efficient training and avoiding overfitting to\nthe reference images. In this work, we present the $\\lambda$-Harmonic reward\nfunction, which provides a reliable reward signal and enables early stopping\nfor faster training and effective regularization. By combining the\nBradley-Terry preference model, the $\\lambda$-Harmonic reward function also\nprovides preference labels for subject-driven generation tasks. We propose\nReward Preference Optimization (RPO), which offers a simpler setup (requiring\nonly $3\\%$ of the negative samples used by DreamBooth) and fewer gradient steps\nfor fine-tuning. Unlike most existing methods, our approach does not require\ntraining a text encoder or optimizing text embeddings and achieves text-image\nalignment by fine-tuning only the U-Net component. Empirically,\n$\\lambda$-Harmonic proves to be a reliable approach for model selection in\nsubject-driven generation tasks. Based on preference labels and early stopping\nvalidation from the $\\lambda$-Harmonic reward function, our algorithm achieves\na state-of-the-art CLIP-I score of 0.833 and a CLIP-T score of 0.314 on\nDreamBench.",
      "tldr_zh": "本研究针对文本到图像生成模型的局限性，提出了一种基于偏好强化学习（Preference-based Reinforcement Learning）的主题驱动生成方法，以解决从参考图像生成特定主题或在不同条件下合成图像的问题。论文引入了$\\lambda$-Harmonic奖励函数和Bradley-Terry偏好模型，提供可靠的奖励信号，支持早停训练和正则化，同时提出Reward Preference Optimization (RPO)算法，该算法简化训练设置（仅需DreamBooth的3%负样本），仅微调U-Net组件而不优化文本编码器或嵌入。实验结果显示，RPO在DreamBench基准测试中实现了state-of-the-art的CLIP-I分数0.833和CLIP-T分数0.314，显著提高了效率并避免了过拟合。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12164v3",
      "published_date": "2024-07-16 20:40:25 UTC",
      "updated_date": "2024-12-22 08:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:00:43.843344"
    },
    {
      "arxiv_id": "2407.12161v1",
      "title": "Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Karolis Jucys",
        "George Adamopoulos",
        "Mehrab Hamidi",
        "Stephanie Milani",
        "Mohammad Reza Samsami",
        "Artem Zholus",
        "Sonia Joseph",
        "Blake Richards",
        "Irina Rish",
        "Özgür Şimşek"
      ],
      "abstract": "Understanding the mechanisms behind decisions taken by large foundation\nmodels in sequential decision making tasks is critical to ensuring that such\nsystems operate transparently and safely. In this work, we perform exploratory\nanalysis on the Video PreTraining (VPT) Minecraft playing agent, one of the\nlargest open-source vision-based agents. We aim to illuminate its reasoning\nmechanisms by applying various interpretability techniques. First, we analyze\nthe attention mechanism while the agent solves its training task - crafting a\ndiamond pickaxe. The agent pays attention to the last four frames and several\nkey-frames further back in its six-second memory. This is a possible mechanism\nfor maintaining coherence in a task that takes 3-10 minutes, despite the short\nmemory span. Secondly, we perform various interventions, which help us uncover\na worrying case of goal misgeneralization: VPT mistakenly identifies a villager\nwearing brown clothes as a tree trunk when the villager is positioned\nstationary under green tree leaves, and punches it to death.",
      "tldr_zh": "本研究通过探索性分析，调查了Video PreTraining (VPT) Minecraft 代理的决策机制，以提升大型基础模型在顺序决策任务中的透明性和安全性。研究者首先分析了代理的attention mechanism，发现它在完成合成钻石镐等任务时，主要关注最近的四个帧和几个关键帧，从而在短记忆条件下维持3-10分钟任务的连贯性。其次，通过各种interventions实验，揭示了代理存在goal misgeneralization问题，例如错误地将穿着棕色衣服的村民识别为树干，并在特定场景下攻击它。这些发现有助于改进代理的可解释性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Mechanistic Interpretability Workshop at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12161v1",
      "published_date": "2024-07-16 20:38:08 UTC",
      "updated_date": "2024-07-16 20:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:00:55.322300"
    },
    {
      "arxiv_id": "2408.00778v1",
      "title": "Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions",
      "title_zh": "Frontend Diffusion: 通过从抽象到详细任务转换探索基于意图的用户界面",
      "authors": [
        "Qinshi Zhang",
        "Latisha Besariani Hendra",
        "Mohan Chi",
        "Zijian Ding"
      ],
      "abstract": "The emergence of Generative AI is catalyzing a paradigm shift in user\ninterfaces from command-based to intent-based outcome specification. In this\npaper, we explore abstract-to-detailed task transitions in the context of\nfrontend code generation as a step towards intent-based user interfaces, aiming\nto bridge the gap between abstract user intentions and concrete\nimplementations. We introduce Frontend Diffusion, an end-to-end LLM-powered\ntool that generates high-quality websites from user sketches. The system\nemploys a three-stage task transition process: sketching, writing, and coding.\nWe demonstrate the potential of task transitions to reduce human intervention\nand communication costs in complex tasks. Our work also opens avenues for\nexploring similar approaches in other domains, potentially extending to more\ncomplex, interdependent tasks such as video production.",
      "tldr_zh": "本研究探讨了生成式 AI 如何推动用户界面从命令式向意图式(intent-based)转变，通过抽象到详细的任务转换来桥接用户意图与具体实现。论文引入了 Frontend Diffusion，这是一个基于 LLM 的端到端工具，能够从用户草图(sketching)生成高质量网站，并通过三个阶段的任务过程——sketching、writing 和 coding——来逐步细化任务。该方法显著降低了复杂任务中的人类干预和沟通成本，并为其他领域如视频制作等扩展类似方法提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.00778v1",
      "published_date": "2024-07-16 20:24:35 UTC",
      "updated_date": "2024-07-16 20:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:01:07.590110"
    },
    {
      "arxiv_id": "2407.12141v1",
      "title": "Predicting Emotion Intensity in Polish Political Texts: Comparing Supervised Models and Large Language Models in a Resource-Poor Language",
      "title_zh": "在波兰政治文本中预测情感强度：比较监督模型和大型语言模型在资源匮乏语言中的表现",
      "authors": [
        "Hubert Plisiecki",
        "Piotr Koc",
        "Maria Flakus",
        "Artur Pokropek"
      ],
      "abstract": "This study explores the use of large language models (LLMs) to predict\nemotion intensity in Polish political texts, a resource-poor language context.\nThe research compares the performance of several LLMs against a supervised\nmodel trained on an annotated corpus of 10,000 social media texts, evaluated\nfor the intensity of emotions by expert judges. The findings indicate that\nwhile the supervised model generally outperforms LLMs, offering higher accuracy\nand lower variance, LLMs present a viable alternative, especially given the\nhigh costs associated with data annotation. The study highlights the potential\nof LLMs in low-resource language settings and underscores the need for further\nresearch on emotion intensity prediction and its application across different\nlanguages and continuous features. The implications suggest a nuanced\ndecision-making process to choose the right approach to emotion prediction for\nresearchers and practitioners based on resource availability and the specific\nrequirements of their tasks.",
      "tldr_zh": "这篇论文比较了监督模型和大型语言模型 (LLMs) 在预测波兰语政治文本情感强度的性能，聚焦于资源匮乏语言的挑战。研究使用一个标注了 10,000 条社交媒体文本的语料训练监督模型，并通过专家判断评估了 LLMs 的表现。结果显示，监督模型在准确性和方差上优于 LLMs，但 LLMs 作为成本更低的替代方案，在低资源语言环境中表现出潜力。论文呼吁进一步研究情感强度预测的应用，并为研究者和从业者提供基于资源和任务需求的决策指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The Appendix is located at the very bottom of the manuscript",
      "pdf_url": "http://arxiv.org/pdf/2407.12141v1",
      "published_date": "2024-07-16 19:53:14 UTC",
      "updated_date": "2024-07-16 19:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:01:21.244910"
    },
    {
      "arxiv_id": "2407.12126v2",
      "title": "LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Bunyamin Keles",
        "Murat Gunay",
        "Serdar I. Caglar"
      ],
      "abstract": "Machine translation is indispensable in healthcare for enabling the global\ndissemination of medical knowledge across languages. However, complex medical\nterminology poses unique challenges to achieving adequate translation quality\nand accuracy. This study introduces a novel \"LLMs-in-the-loop\" approach to\ndevelop supervised neural machine translation models optimized specifically for\nmedical texts. While large language models (LLMs) have demonstrated powerful\ncapabilities, this research shows that small, specialized models trained on\nhigh-quality in-domain (mostly synthetic) data can outperform even vastly\nlarger LLMs.\n  Custom parallel corpora in six languages were compiled from scientific\narticles, synthetically generated clinical documents, and medical texts. Our\nLLMs-in-the-loop methodology employs synthetic data generation, rigorous\nevaluation, and agent orchestration to enhance performance. We developed small\nmedical translation models using the MarianMT base model. We introduce a new\nmedical translation test dataset to standardize evaluation in this domain.\nAssessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our\nMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.\n  Results demonstrate that our LLMs-in-the-loop approach, combined with\nfine-tuning high-quality, domain-specific data, enables specialized models to\noutperform general-purpose and some larger systems. This research, part of a\nbroader series on expert small models, paves the way for future\nhealthcare-related AI developments, including deidentification and bio-medical\nentity extraction models. Our study underscores the potential of tailored\nneural translation models and the LLMs-in-the-loop methodology to advance the\nfield through improved data generation, evaluation, agent, and modeling\ntechniques.",
      "tldr_zh": "该研究提出“LLMs-in-the-loop”方法，开发针对生物医学文本翻译的小型专家AI模型，以应对医学术语带来的翻译质量和准确性挑战。方法包括使用合成数据生成、严格评估和代理编排，基于MarianMT基模型训练小型模型，并编译了六种语言的自定义平行语料库，包括科学文章和临床文档。实验在新的医学术语翻译测试数据集上使用BLEU、METEOR、ROUGE和BERT指标评估，结果显示这些模型超过了Google Translate、DeepL和GPT-4-Turbo。总体而言，该方法证明了小型领域专用模型的优越性，为医疗AI应用如去识别和生物医学实体提取铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T35"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 2 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.12126v2",
      "published_date": "2024-07-16 19:32:23 UTC",
      "updated_date": "2024-07-26 12:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:01:34.009928"
    },
    {
      "arxiv_id": "2407.12884v1",
      "title": "SurroFlow: A Flow-Based Surrogate Model for Parameter Space Exploration and Uncertainty Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Shen",
        "Yuhan Duan",
        "Han-Wei Shen"
      ],
      "abstract": "Existing deep learning-based surrogate models facilitate efficient data\ngeneration, but fall short in uncertainty quantification, efficient parameter\nspace exploration, and reverse prediction. In our work, we introduce SurroFlow,\na novel normalizing flow-based surrogate model, to learn the invertible\ntransformation between simulation parameters and simulation outputs. The model\nnot only allows accurate predictions of simulation outcomes for a given\nsimulation parameter but also supports uncertainty quantification in the data\ngeneration process. Additionally, it enables efficient simulation parameter\nrecommendation and exploration. We integrate SurroFlow and a genetic algorithm\nas the backend of a visual interface to support effective user-guided ensemble\nsimulation exploration and visualization. Our framework significantly reduces\nthe computational costs while enhancing the reliability and exploration\ncapabilities of scientific surrogate models.",
      "tldr_zh": "本文提出 SurroFlow，一种基于 normalizing flow 的新型代理模型，用于学习模拟参数和输出之间的可逆变换，以解决现有深度学习代理模型在不确定性量化、参数空间探索和逆向预测方面的不足。SurroFlow 不仅能准确预测模拟结果，还支持不确定性量化以及高效的参数推荐和探索。该模型通过与 genetic algorithm 集成到视觉界面中，实现用户引导的集成模拟探索和可视化，最终显著降低了计算成本，并提升了科学代理模型的可靠性和探索能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in Proc. IEEE VIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12884v1",
      "published_date": "2024-07-16 19:08:49 UTC",
      "updated_date": "2024-07-16 19:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:01:44.444990"
    },
    {
      "arxiv_id": "2407.12113v2",
      "title": "A Graph-based Adversarial Imitation Learning Framework for Reliable & Realtime Fleet Scheduling in Urban Air Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Prithvi Poddar",
        "Steve Paul",
        "Souma Chowdhury"
      ],
      "abstract": "The advent of Urban Air Mobility (UAM) presents the scope for a\ntransformative shift in the domain of urban transportation. However, its\nwidespread adoption and economic viability depends in part on the ability to\noptimally schedule the fleet of aircraft across vertiports in a UAM network,\nunder uncertainties attributed to airspace congestion, changing weather\nconditions, and varying demands. This paper presents a comprehensive\noptimization formulation of the fleet scheduling problem, while also\nidentifying the need for alternate solution approaches, since directly solving\nthe resulting integer nonlinear programming problem is computationally\nprohibitive for daily fleet scheduling. Previous work has shown the\neffectiveness of using (graph) reinforcement learning (RL) approaches to train\nreal-time executable policy models for fleet scheduling. However, such policies\ncan often be brittle on out-of-distribution scenarios or edge cases. Moreover,\ntraining performance also deteriorates as the complexity (e.g., number of\nconstraints) of the problem increases. To address these issues, this paper\npresents an imitation learning approach where the RL-based policy exploits\nexpert demonstrations yielded by solving the exact optimization using a Genetic\nAlgorithm. The policy model comprises Graph Neural Network (GNN) based encoders\nthat embed the space of vertiports and aircraft, Transformer networks to encode\ndemand, passenger fare, and transport cost profiles, and a Multi-head attention\n(MHA) based decoder. Expert demonstrations are used through the Generative\nAdversarial Imitation Learning (GAIL) algorithm. Interfaced with a UAM\nsimulation environment involving 8 vertiports and 40 aircrafts, in terms of the\ndaily profits earned reward, the new imitative approach achieves better mean\nperformance and remarkable improvement in the case of unseen worst-case\nscenarios, compared to pure RL results.",
      "tldr_zh": "本文提出一个基于图的对抗模仿学习框架，用于 Urban Air Mobility (UAM) 中可靠且实时的机队调度优化，旨在应对不确定性如空域拥堵、天气变化和需求波动。框架利用 Generative Adversarial Imitation Learning (GAIL) 算法，通过遗传算法生成的专家演示训练强化学习 (RL) 策略，结合 Graph Neural Network (GNN) 编码器、Transformer 网络和 Multi-head attention (MHA) 解码器来处理机场、飞机和需求信息。实验结果显示，该方法在包含8个机场和40架飞机的模拟环境中，比纯 RL 策略在日常利润奖励上表现出平均性能提升，并在未见的最坏场景中实现显著改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the AIAA Aviation Forum 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12113v2",
      "published_date": "2024-07-16 18:51:24 UTC",
      "updated_date": "2024-09-05 17:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:01:57.294783"
    },
    {
      "arxiv_id": "2407.12101v2",
      "title": "Better RAG using Relevant Information Gain",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Pickett",
        "Jeremy Hartman",
        "Ayan Kumar Bhowmick",
        "Raquib-ul Alam",
        "Aditya Vempaty"
      ],
      "abstract": "A common way to extend the memory of large language models (LLMs) is by\nretrieval augmented generation (RAG), which inserts text retrieved from a\nlarger memory into an LLM's context window. However, the context window is\ntypically limited to several thousand tokens, which limits the number of\nretrieved passages that can inform a model's response. For this reason, it's\nimportant to avoid occupying context window space with redundant information by\nensuring a degree of diversity among retrieved passages. At the same time, the\ninformation should also be relevant to the current task. Most prior methods\nthat encourage diversity among retrieved results, such as Maximal Marginal\nRelevance (MMR), do so by incorporating an objective that explicitly trades off\ndiversity and relevance. We propose a novel simple optimization metric based on\nrelevant information gain, a probabilistic measure of the total information\nrelevant to a query for a set of retrieved results. By optimizing this metric,\ndiversity organically emerges from our system. When used as a drop-in\nreplacement for the retrieval component of a RAG system, this method yields\nstate-of-the-art performance on question answering tasks from the Retrieval\nAugmented Generation Benchmark (RGB), outperforming existing metrics that\ndirectly optimize for relevance and diversity.",
      "tldr_zh": "这篇论文针对大语言模型(LLMs)中的Retrieval Augmented Generation (RAG)系统，提出了一种基于Relevant Information Gain的优化指标，以解决上下文窗口限制导致的检索结果冗余问题。Relevant Information Gain作为一个概率测度，评估一组检索结果中与查询相关的总信息，通过优化该指标，多样性自然地融入系统，而无需显式权衡相关性和多样性。实验结果显示，该方法作为RAG检索组件的替换，在Retrieval Augmented Generation Benchmark (RGB)的问答任务上，优于现有指标如Maximal Marginal Relevance (MMR)，实现了最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "4 page paper submitted to EMNLP",
      "pdf_url": "http://arxiv.org/pdf/2407.12101v2",
      "published_date": "2024-07-16 18:09:21 UTC",
      "updated_date": "2025-02-12 21:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:02:07.813775"
    },
    {
      "arxiv_id": "2407.12077v1",
      "title": "GoldFinch: High Performance RWKV/Transformer Hybrid with Linear Pre-Fill and Extreme KV-Cache Compression",
      "title_zh": "GoldFinch: 高性能 RWKV/Transformer 混合模型，采用线性预填充和极端的 KV-Cache 压缩",
      "authors": [
        "Daniel Goldstein",
        "Fares Obeid",
        "Eric Alcaide",
        "Guangyu Song",
        "Eugene Cheah"
      ],
      "abstract": "We introduce GoldFinch, a hybrid Linear Attention/Transformer sequence model\nthat uses a new technique to efficiently generate a highly compressed and\nreusable KV-Cache in linear time and space with respect to sequence length.\nGoldFinch stacks our new GOLD transformer on top of an enhanced version of the\nFinch (RWKV-6) architecture. We train up to 1.5B parameter class models of the\nFinch, Llama, and GoldFinch architectures, and find dramatically improved\nmodeling performance relative to both Finch and Llama. Our cache size savings\nincrease linearly with model layer count, ranging from 756-2550 times smaller\nthan the traditional transformer cache for common sizes, enabling inference of\nextremely large context lengths even on limited hardware. Although\nautoregressive generation has O(n) time complexity per token because of\nattention, pre-fill computation of the entire initial cache state for a\nsubmitted context costs only O(1) time per token due to the use of a recurrent\nneural network (RNN) to generate this cache. We release our trained weights and\ntraining code under the Apache 2.0 license for community use.",
      "tldr_zh": "我们引入了 GoldFinch，一种高性能的 RWKV/Transformer 混合模型，它通过新技巧在线性时间和空间中生成高度压缩且可重用的 KV-Cache，从而显著提升序列建模效率。GoldFinch 在增强的 Finch (RWKV-6) 架构基础上堆叠 GOLD transformer，使用 RNN 生成初始缓存状态，使预填充计算达到 O(1) 时间复杂度每 token。实验结果显示，GoldFinch 在建模性能上优于 Finch 和 Llama 架构，并实现了 756-2550 倍的 KV-Cache 节省，支持在有限硬件上处理极长上下文；我们已开源训练权重和代码以供社区使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12077v1",
      "published_date": "2024-07-16 18:00:00 UTC",
      "updated_date": "2024-07-16 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:02:21.268474"
    },
    {
      "arxiv_id": "2407.11969v4",
      "title": "Does Refusal Training in LLMs Generalize to the Past Tense?",
      "title_zh": "LLMs 中的拒绝训练是否泛化到过去时？",
      "authors": [
        "Maksym Andriushchenko",
        "Nicolas Flammarion"
      ],
      "abstract": "Refusal training is widely used to prevent LLMs from generating harmful,\nundesirable, or illegal outputs. We reveal a curious generalization gap in the\ncurrent refusal training approaches: simply reformulating a harmful request in\nthe past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make\na Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art\nLLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet,\nGPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o mini, GPT-4o, o1-mini,\no1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For\nexample, the success rate of this simple attack on GPT-4o increases from 1%\nusing direct requests to 88% using 20 past tense reformulation attempts on\nharmful requests from JailbreakBench with GPT-4 as a jailbreak judge.\nInterestingly, we also find that reformulations in the future tense are less\neffective, suggesting that refusal guardrails tend to consider past historical\nquestions more benign than hypothetical future questions. Moreover, our\nexperiments on fine-tuning GPT-3.5 Turbo show that defending against past\nreformulations is feasible when past tense examples are explicitly included in\nthe fine-tuning data. Overall, our findings highlight that the widely used\nalignment techniques -- such as SFT, RLHF, and adversarial training -- employed\nto align the studied models can be brittle and do not always generalize as\nintended. We provide code and jailbreak artifacts at\nhttps://github.com/tml-epfl/llm-past-tense.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）中的拒绝训练（refusal training）存在泛化漏洞：将有害请求改成过去时（如 “How to make a Molotov cocktail?” 改为 “How did people make a Molotov cocktail?”）即可轻松绕过安全机制。研究者对多种模型（如 Llama-3 8B、Claude-3.5 Sonnet 和 GPT-4o）进行了系统评估，使用 GPT-3.5 Turbo 作为重述工具，结果显示 GPT-4o 的攻击成功率从直接请求的 1% 上升到过去时重述的 88%。此外，未来时重述攻击效果较差，表明模型更倾向将历史问题视为无害。实验还证明，通过在微调数据中包含过去时示例，可以有效防御此类攻击；整体而言，这突显了现有对齐技术（如 SFT、RLHF 和对抗训练）的脆性，并提供了相关代码和工件。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025. Updates in v2 and v3: added GPT-4o, Claude 3.5\n  Sonnet, o1-mini, and o1-preview results. Code and jailbreak artifacts:\n  https://github.com/tml-epfl/llm-past-tense",
      "pdf_url": "http://arxiv.org/pdf/2407.11969v4",
      "published_date": "2024-07-16 17:59:55 UTC",
      "updated_date": "2025-04-17 18:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:02:33.253174"
    },
    {
      "arxiv_id": "2407.11966v1",
      "title": "Efficient Training with Denoised Neural Weights",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Gong",
        "Zheng Zhan",
        "Yanyu Li",
        "Yerlan Idelbayev",
        "Andrey Zharkov",
        "Kfir Aberman",
        "Sergey Tulyakov",
        "Yanzhi Wang",
        "Jian Ren"
      ],
      "abstract": "Good weight initialization serves as an effective measure to reduce the\ntraining cost of a deep neural network (DNN) model. The choice of how to\ninitialize parameters is challenging and may require manual tuning, which can\nbe time-consuming and prone to human error. To overcome such limitations, this\nwork takes a novel step towards building a weight generator to synthesize the\nneural weights for initialization. We use the image-to-image translation task\nwith generative adversarial networks (GANs) as an example due to the ease of\ncollecting model weights spanning a wide range. Specifically, we first collect\na dataset with various image editing concepts and their corresponding trained\nweights, which are later used for the training of the weight generator. To\naddress the different characteristics among layers and the substantial number\nof weights to be predicted, we divide the weights into equal-sized blocks and\nassign each block an index. Subsequently, a diffusion model is trained with\nsuch a dataset using both text conditions of the concept and the block indexes.\nBy initializing the image translation model with the denoised weights predicted\nby our diffusion model, the training requires only 43.3 seconds. Compared to\ntraining from scratch (i.e., Pix2pix), we achieve a 15x training time\nacceleration for a new concept while obtaining even better image generation\nquality.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用权重生成器合成深度神经网络(DNN)模型的初始权重，以减少训练成本。作者通过收集图像编辑概念及其对应训练权重的数据集，并将权重分成等大小块分配索引，训练一个扩散模型(diffusion model)，结合文本条件来预测去噪权重。在图像到图像翻译任务中，该方法使模型训练时间缩短至43.3秒，比从零开始训练(GANs中的Pix2pix)快15倍，同时提升了图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024. Project Page:\n  https://yifanfanfanfan.github.io/denoised-weights/",
      "pdf_url": "http://arxiv.org/pdf/2407.11966v1",
      "published_date": "2024-07-16 17:59:42 UTC",
      "updated_date": "2024-07-16 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:02:43.492171"
    },
    {
      "arxiv_id": "2407.11962v2",
      "title": "Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyeok Kim",
        "Dongyoon Wee",
        "Dan Xu"
      ],
      "abstract": "This paper introduces Motion-oriented Compositional Neural Radiance Fields\n(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of\nmonocular human videos via novel non-rigid motion modeling approach. In the\ncontext of dynamic clothed humans, complex cloth dynamics generate non-rigid\nmotions that are intrinsically distinct from skeletal articulations and\ncritically important for the rendering quality. The conventional approach\nmodels non-rigid motions as spatial (3D) deviations in addition to skeletal\ntransformations. However, it is either time-consuming or challenging to achieve\noptimal quality due to its high learning complexity without a direct\nsupervision. To target this problem, we propose a novel approach of modeling\nnon-rigid motions as radiance residual fields to benefit from more direct color\nsupervision in the rendering and utilize the rigid radiance fields as a prior\nto reduce the complexity of the learning process. Our approach utilizes a\nsingle multiresolution hash encoding (MHE) to concurrently learn the canonical\nT-pose representation from rigid skeletal motions and the radiance residual\nfield for non-rigid motions. Additionally, to further improve both training\nefficiency and usability, we extend MoCo-NeRF to support simultaneous training\nof multiple subjects within a single framework, thanks to our effective design\nfor modeling non-rigid motions. This scalability is achieved through the\nintegration of a global MHE and learnable identity codes in addition to\nmultiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,\nclearly demonstrating state-of-the-art performance in both single- and\nmulti-subject settings. The code and model will be made publicly available at\nthe project page: https://stevejaehyeok.github.io/publications/moco-nerf.",
      "tldr_zh": "本文提出 MoCo-NeRF 框架，用于单目视频的自由视点渲染，通过将非刚性运动建模为 radiance residual fields，利用颜色监督和刚性辐射场作为先验，减少学习复杂性并提升渲染质量。不同于传统方法，该框架采用单个 multiresolution hash encoding (MHE) 同时学习规范 T-pose 表示和非刚性运动，并扩展支持多主体训练 via 全局 MHE 和可学习身份代码，提高训练效率。实验结果显示，MoCo-NeRF 在 ZJU-MoCap 和 MonoCap 数据集上实现了单主体和多主体设置的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11962v2",
      "published_date": "2024-07-16 17:59:01 UTC",
      "updated_date": "2024-07-18 08:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:02:56.785098"
    },
    {
      "arxiv_id": "2407.12883v4",
      "title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval",
      "title_zh": "BRIGHT: 针对推理密集型检索的真实且具有挑战性的基准",
      "authors": [
        "Hongjin Su",
        "Howard Yen",
        "Mengzhou Xia",
        "Weijia Shi",
        "Niklas Muennighoff",
        "Han-yu Wang",
        "Haisu Liu",
        "Quan Shi",
        "Zachary S. Siegel",
        "Michael Tang",
        "Ruoxi Sun",
        "Jinsung Yoon",
        "Sercan O. Arik",
        "Danqi Chen",
        "Tao Yu"
      ],
      "abstract": "Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023) SFR-Embedding-Mistral (Meng\net al., 2024), which achieves a score of 59.0 nDCG@10,1 produces a score of\nnDCG@10 of 18.3 on BRIGHT. We show that incorporating explicit reasoning about\nthe query improves retrieval performance by up to 12.2 points. Moreover,\nincorporating retrieved documents from the top-performing retriever boosts\nquestion-answering performance. We believe that BRIGHT paves the way for future\nresearch on retrieval systems in more realistic and challenging settings.",
      "tldr_zh": "本研究指出，现有的检索基准主要依赖关键词或语义匹配，无法有效处理需要深入推理的复杂查询，如编码或数学问题。为此，论文引入BRIGHT，这是一个针对推理密集型检索的首个文本基准数据集，包含1384个真实查询，覆盖经济学、心理学、数学和编码等领域。实验评估显示，即使是顶级模型如SFR-Embedding-Mistral，在BRIGHT上表现欠佳（nDCG@10仅为18.3），但通过加入查询的显式推理，可将检索性能提升最多12.2点；此外，结合顶级检索器的文档还能改善问答性能。BRIGHT为更现实和具有挑战性的检索系统研究提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.12883v4",
      "published_date": "2024-07-16 17:58:27 UTC",
      "updated_date": "2025-03-26 07:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:03:08.117029"
    },
    {
      "arxiv_id": "2407.11948v1",
      "title": "Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation",
      "title_zh": "重新思考基于 Transformer 的多文档摘要：一项实证调查",
      "authors": [
        "Congbo Ma",
        "Wei Emma Zhang",
        "Dileepa Pitawela",
        "Haojie Zhuang",
        "Yanfeng Shu"
      ],
      "abstract": "The utilization of Transformer-based models prospers the growth of\nmulti-document summarization (MDS). Given the huge impact and widespread\nadoption of Transformer-based models in various natural language processing\ntasks, investigating their performance and behaviors in the context of MDS\nbecomes crucial for advancing the field and enhancing the quality of summary.\nTo thoroughly examine the behaviours of Transformer-based MDS models, this\npaper presents five empirical studies on (1) measuring the impact of document\nboundary separators quantitatively; (2) exploring the effectiveness of\ndifferent mainstream Transformer structures; (3) examining the sensitivity of\nthe encoder and decoder; (4) discussing different training strategies; and (5)\ndiscovering the repetition in a summary generation. The experimental results on\nprevalent MDS datasets and eleven evaluation metrics show the influence of\ndocument boundary separators, the granularity of different level features and\ndifferent model training strategies. The results also reveal that the decoder\nexhibits greater sensitivity to noises compared to the encoder. This\nunderscores the important role played by the decoder, suggesting a potential\ndirection for future research in MDS. Furthermore, the experimental results\nindicate that the repetition problem in the generated summaries has\ncorrelations with the high uncertainty scores.",
      "tldr_zh": "这篇论文通过实证调查重新审视基于 Transformer 的多文档摘要 (MDS) 模型的表现和行为，旨在提升摘要质量。研究包括五个方面：量化文档边界分隔符的影响、探索不同 Transformer 结构的有效性、检查编码器和解码器的敏感性、讨论各种训练策略，以及分析摘要生成中的重复问题。实验结果基于常见 MDS 数据集和 11 个评估指标，显示文档边界分隔符对性能有显著影响，解码器比编码器更敏感，且摘要重复与高不确定性分数相关。这些发现为未来 MDS 研究提供了重要方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11948v1",
      "published_date": "2024-07-16 17:42:37 UTC",
      "updated_date": "2024-07-16 17:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:03:21.237078"
    },
    {
      "arxiv_id": "2407.11928v1",
      "title": "Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach",
      "title_zh": "通过图稀疏化应对",
      "authors": [
        "Tanvir Hossain",
        "Khaled Mohammed Saifuddin",
        "Muhammad Ifte Khairul Islam",
        "Farhan Tanvir",
        "Esra Akbas"
      ],
      "abstract": "Graph Neural Network (GNN) achieves great success for node-level and\ngraph-level tasks via encoding meaningful topological structures of networks in\nvarious domains, ranging from social to biological networks. However, repeated\naggregation operations lead to excessive mixing of node representations,\nparticularly in dense regions with multiple GNN layers, resulting in nearly\nindistinguishable embeddings. This phenomenon leads to the oversmoothing\nproblem that hampers downstream graph analytics tasks. To overcome this issue,\nwe propose a novel and flexible truss-based graph sparsification model that\nprunes edges from dense regions of the graph. Pruning redundant edges in dense\nregions helps to prevent the aggregation of excessive neighborhood information\nduring hierarchical message passing and pooling in GNN models. We then utilize\nour sparsification model in the state-of-the-art baseline GNNs and pooling\nmodels, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and\nAdamGNN. Extensive experiments on different real-world datasets show that our\nmodel significantly improves the performance of the baseline GNN models in the\ngraph classification task.",
      "tldr_zh": "本论文针对图神经网络(GNN)中的 oversmoothing 问题，提出了一种基于 truss 的图稀疏化方法，通过修剪图中密集区域的冗余边来防止过度混合节点表示。 该方法在层次化消息传递和池化过程中减少了过多邻居信息的聚合，并被应用于多种基线模型，如 GIN、SAGPool 和 DiffPool 等。 实验在真实数据集上表明，该模型显著提升了 GNN 在图分类任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11928v1",
      "published_date": "2024-07-16 17:21:36 UTC",
      "updated_date": "2024-07-16 17:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:03:32.132341"
    },
    {
      "arxiv_id": "2407.11919v1",
      "title": "What's Wrong? Refining Meeting Summaries with LLM Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Frederic Kirstein",
        "Terry Ruas",
        "Bela Gipp"
      ],
      "abstract": "Meeting summarization has become a critical task since digital encounters\nhave become a common practice. Large language models (LLMs) show great\npotential in summarization, offering enhanced coherence and context\nunderstanding compared to traditional methods. However, they still struggle to\nmaintain relevance and avoid hallucination. We introduce a multi-LLM correction\napproach for meeting summarization using a two-phase process that mimics the\nhuman review process: mistake identification and summary refinement. We release\nQMSum Mistake, a dataset of 200 automatically generated meeting summaries\nannotated by humans on nine error types, including structural, omission, and\nirrelevance errors. Our experiments show that these errors can be identified\nwith high accuracy by an LLM. We transform identified mistakes into actionable\nfeedback to improve the quality of a given summary measured by relevance,\ninformativeness, conciseness, and coherence. This post-hoc refinement\neffectively improves summary quality by leveraging multiple LLMs to validate\noutput quality. Our multi-LLM approach for meeting summarization shows\npotential for similar complex text generation tasks requiring robustness,\naction planning, and discussion towards a goal.",
      "tldr_zh": "本研究针对大语言模型(LLMs)在会议总结中的相关性问题和幻觉问题，提出了一种多-LLM修正方法，通过两阶段过程（错误识别和总结精炼）模仿人类审查流程来提升总结质量。研究者发布QMSum Mistake数据集，包含200个自动生成总结，由人类标注的九种错误类型（如结构、遗漏和无关错误），并证明LLMs能高精度识别这些错误。实验结果显示，通过将识别错误转化为可操作反馈，该方法显著提高了总结的相关性、信息性、简洁性和连贯性，为类似复杂文本生成任务提供鲁棒性和行动规划的潜在解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11919v1",
      "published_date": "2024-07-16 17:10:16 UTC",
      "updated_date": "2024-07-16 17:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:03:43.939549"
    },
    {
      "arxiv_id": "2407.11915v1",
      "title": "Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task",
      "title_zh": "通过模仿人类动作，人形机器人在主动说话者检测任务中实现自然的头部动作",
      "authors": [
        "Bosong Ding",
        "Murat Kirtay",
        "Giacomo Spigler"
      ],
      "abstract": "Head movements are crucial for social human-human interaction. They can\ntransmit important cues (e.g., joint attention, speaker detection) that cannot\nbe achieved with verbal interaction alone. This advantage also holds for\nhuman-robot interaction. Even though modeling human motions through generative\nAI models has become an active research area within robotics in recent years,\nthe use of these methods for producing head movements in human-robot\ninteraction remains underexplored. In this work, we employed a generative AI\npipeline to produce human-like head movements for a Nao humanoid robot. In\naddition, we tested the system on a real-time active-speaker tracking task in a\ngroup conversation setting. Overall, the results show that the Nao robot\nsuccessfully imitates human head movements in a natural manner while actively\ntracking the speakers during the conversation. Code and data from this study\nare available at https://github.com/dingdingding60/Humanoids2024HRI",
      "tldr_zh": "该研究探讨了如何通过模仿人类动作，使用生成 AI 管道（generative AI pipeline）为 Nao 人形机器人（Nao humanoid robot）生成自然的头部运动，以提升人-机器人交互中的社交线索传递。论文在实时活跃说话者检测任务（active-speaker detection task）中测试了该系统，结果显示机器人能够成功模仿人类头部运动，并在群聊场景中自然追踪说话者。总体而言，此方法为更真实的人-机器人交互提供了创新途径，并公开了代码和数据以供进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11915v1",
      "published_date": "2024-07-16 17:08:40 UTC",
      "updated_date": "2024-07-16 17:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:03:55.530187"
    },
    {
      "arxiv_id": "2407.12882v1",
      "title": "InstructAV: Instruction Fine-tuning Large Language Models for Authorship Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Yujia Hu",
        "Zhiqiang Hu",
        "Chun-Wei Seah",
        "Roy Ka-Wei Lee"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in a\nwide range of NLP tasks. However, when it comes to authorship verification (AV)\ntasks, which involve determining whether two given texts share the same\nauthorship, even advanced models like ChatGPT exhibit notable limitations. This\npaper introduces a novel approach, termed InstructAV, for authorship\nverification. This approach utilizes LLMs in conjunction with a\nparameter-efficient fine-tuning (PEFT) method to simultaneously improve\naccuracy and explainability. The distinctiveness of InstructAV lies in its\nability to align classification decisions with transparent and understandable\nexplanations, representing a significant progression in the field of authorship\nverification. Through comprehensive experiments conducted across various\ndatasets, InstructAV demonstrates its state-of-the-art performance on the AV\ntask, offering high classification accuracy coupled with enhanced explanation\nreliability.",
      "tldr_zh": "本研究提出InstructAV，一种基于指令微调(instruction fine-tuning)的创新方法，用于提升Large Language Models (LLMs)在作者验证(authorship verification)任务中的性能，该任务涉及判断两段文本是否由同一作者撰写。InstructAV结合参数高效微调(PEFT)技术，同时提高分类准确性和解释透明度，使模型的决策与可理解的解释对齐。实验结果显示，在各种数据集上，InstructAV实现了state-of-the-art性能，提供高准确率和可靠的解释可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12882v1",
      "published_date": "2024-07-16 16:27:01 UTC",
      "updated_date": "2024-07-16 16:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:04:07.543755"
    },
    {
      "arxiv_id": "2407.11877v2",
      "title": "Bridging Weighted First Order Model Counting and Graph Polynomials",
      "title_zh": "桥接加权一阶模型计数与图多项式",
      "authors": [
        "Qipeng Kuang",
        "Ondřej Kuželka",
        "Yuanhong Wang",
        "Yuyi Wang"
      ],
      "abstract": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the\nweighted sum of models of a given first-order logic sentence over a given\ndomain. It can be solved in time polynomial in the domain size for sentences\nfrom the two-variable fragment with counting quantifiers, known as $C^2$. This\npolynomial-time complexity is known to be retained when extending $C^2$ by one\nof the following axioms: linear order axiom, tree axiom, forest axiom, directed\nacyclic graph axiom or connectedness axiom. An interesting question remains as\nto which other axioms can be added to the first-order sentences in this way. We\nprovide a new perspective on this problem by associating WFOMC with graph\npolynomials. Using WFOMC, we define Weak Connectedness Polynomial and Strong\nConnectedness Polynomials for first-order logic sentences. It turns out that\nthese polynomials have the following interesting properties. First, they can be\ncomputed in polynomial time in the domain size for sentences from $C^2$.\nSecond, we can use them to solve WFOMC with all of the existing axioms known to\nbe tractable as well as with new ones such as bipartiteness, strong\nconnectedness, having $k$ connected components, etc. Third, the well-known\nTutte polynomial can be recovered as a special case of the Weak Connectedness\nPolynomial, and the Strict and Non-Strict Directed Chromatic Polynomials can be\nrecovered from the Strong Connectedness Polynomials.",
      "tldr_zh": "本论文探讨了Weighted First-Order Model Counting (WFOMC) 与图多项式的关联，旨在扩展WFOMC在处理一阶逻辑句子的可计算性。研究者定义了Weak Connectedness Polynomial和Strong Connectedness Polynomials，这些多项式能针对$C^2$片段的句子在域大小多项式时间内计算，并支持处理现有公理（如线性顺序或连通性）以及新公理（如二分图或强连通性）。此外，该框架能将著名的Tutte多项式作为Weak Connectedness Polynomial的特例，从而为图理论和逻辑计算提供更广泛的工具和见解。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "03C13, 68T27, 05A15 (Primary)",
        "F.4.0"
      ],
      "primary_category": "cs.LO",
      "comment": "33 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11877v2",
      "published_date": "2024-07-16 16:01:25 UTC",
      "updated_date": "2024-11-26 03:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:04:21.455917"
    },
    {
      "arxiv_id": "2407.12075v1",
      "title": "Tiled Bit Networks: Sub-Bit Neural Network Compression Through Reuse of Learnable Binary Vectors",
      "title_zh": "平铺位网络：通过可学习二进制向量的重用实现子位神经网络压缩",
      "authors": [
        "Matt Gorbett",
        "Hossein Shirazi",
        "Indrakshi Ray"
      ],
      "abstract": "Binary Neural Networks (BNNs) enable efficient deep learning by saving on\nstorage and computational costs. However, as the size of neural networks\ncontinues to grow, meeting computational requirements remains a challenge. In\nthis work, we propose a new form of quantization to tile neural network layers\nwith sequences of bits to achieve sub-bit compression of binary-weighted neural\nnetworks. The method learns binary vectors (i.e. tiles) to populate each layer\nof a model via aggregation and reshaping operations. During inference, the\nmethod reuses a single tile per layer to represent the full tensor. We employ\nthe approach to both fully-connected and convolutional layers, which make up\nthe breadth of space in most neural architectures. Empirically, the approach\nachieves near fullprecision performance on a diverse range of architectures\n(CNNs, Transformers, MLPs) and tasks (classification, segmentation, and time\nseries forecasting) with up to an 8x reduction in size compared to\nbinary-weighted models. We provide two implementations for Tiled Bit Networks:\n1) we deploy the model to a microcontroller to assess its feasibility in\nresource-constrained environments, and 2) a GPU-compatible inference kernel to\nfacilitate the reuse of a single tile per layer in memory.",
      "tldr_zh": "这篇论文提出了Tiled Bit Networks，一种通过重用可学习二进制向量实现子位压缩的神经网络方法，旨在进一步降低Binary Neural Networks的存储和计算成本。方法通过聚合和重塑操作学习二进制向量（tiles）来填充全连接层和卷积层，并在推理时每个层仅重用一个tile表示整个张量。实验结果显示，该方法在CNNs、Transformers和MLPs等架构上，以及分类、分割和时间序列预测等任务中，实现了接近全精度性能，同时模型大小比二进制模型减少高达8倍；此外，还提供了部署到微控制器和GPU兼容推理内核的实现版本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12075v1",
      "published_date": "2024-07-16 15:55:38 UTC",
      "updated_date": "2024-07-16 15:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:04:32.964252"
    },
    {
      "arxiv_id": "2407.11854v1",
      "title": "Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection",
      "title_zh": "零样本跨语言转移在语法错误检测中的合成数据生成",
      "authors": [
        "Gaetan Lopez Latouche",
        "Marc-André Carbonneau",
        "Ben Swanson"
      ],
      "abstract": "Grammatical Error Detection (GED) methods rely heavily on human annotated\nerror corpora. However, these annotations are unavailable in many low-resource\nlanguages. In this paper, we investigate GED in this context. Leveraging the\nzero-shot cross-lingual transfer capabilities of multilingual pre-trained\nlanguage models, we train a model using data from a diverse set of languages to\ngenerate synthetic errors in other languages. These synthetic error corpora are\nthen used to train a GED model. Specifically we propose a two-stage fine-tuning\npipeline where the GED model is first fine-tuned on multilingual synthetic data\nfrom target languages followed by fine-tuning on human-annotated GED corpora\nfrom source languages. This approach outperforms current state-of-the-art\nannotation-free GED methods. We also analyse the errors produced by our method\nand other strong baselines, finding that our approach produces errors that are\nmore diverse and more similar to human errors.",
      "tldr_zh": "本研究探讨了在语法错误检测（Grammatical Error Detection, GED）中，通过零-shot cross-lingual transfer 技术生成合成数据，以解决低资源语言缺乏人工标注语料的问题。研究利用多语言预训练语言模型，从多种语言的数据训练模型生成目标语言的合成错误数据，并提出一个两阶段微调管道：先在多语言合成数据上微调 GED 模型，然后在源语言的人工标注语料上进一步微调。该方法优于现有无标注 GED 方法，并在错误分析中显示，生成的错误更多样化且更接近人类错误，从而提升了低资源语言的 GED 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11854v1",
      "published_date": "2024-07-16 15:35:15 UTC",
      "updated_date": "2024-07-16 15:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:04:43.520582"
    },
    {
      "arxiv_id": "2407.11852v1",
      "title": "Schema Matching with Large Language Models: an Experimental Study",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Parciak",
        "Brecht Vandevoort",
        "Frank Neven",
        "Liesbet M. Peeters",
        "Stijn Vansummeren"
      ],
      "abstract": "Large Language Models (LLMs) have shown useful applications in a variety of\ntasks, including data wrangling. In this paper, we investigate the use of an\noff-the-shelf LLM for schema matching. Our objective is to identify semantic\ncorrespondences between elements of two relational schemas using only names and\ndescriptions. Using a newly created benchmark from the health domain, we\npropose different so-called task scopes. These are methods for prompting the\nLLM to do schema matching, which vary in the amount of context information\ncontained in the prompt. Using these task scopes we compare LLM-based schema\nmatching against a string similarity baseline, investigating matching quality,\nverification effort, decisiveness, and complementarity of the approaches. We\nfind that matching quality suffers from a lack of context information, but also\nfrom providing too much context information. In general, using newer LLM\nversions increases decisiveness. We identify task scopes that have acceptable\nverification effort and succeed in identifying a significant number of true\nsemantic matches. Our study shows that LLMs have potential in bootstrapping the\nschema matching process and are able to assist data engineers in speeding up\nthis task solely based on schema element names and descriptions without the\nneed for data instances.",
      "tldr_zh": "这篇论文实验性地研究了使用 Large Language Models (LLMs) 进行 schema matching，目标是仅基于元素名称和描述识别两个关系 schema 之间的语义对应。研究者创建了一个健康领域基准，并设计了不同任务 scopes 的提示方法，这些方法通过调整提示中的上下文信息量来优化匹配过程。实验结果表明，匹配质量会因上下文信息不足或过多而下降，但使用更新的 LLM 版本能提升决定性(decisiveness)，并在可接受的验证努力下识别出许多真正的语义匹配。总体上，该研究证明 LLMs 有潜力辅助数据工程师加速 schema matching 任务，而无需依赖数据实例。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted at the 2nd International Workshop on Tabular Data Analysis\n  (TaDA24), collocated with the 50th International Conference on Very Large\n  Data Bases (VLDB 2024) Guangzhou, China - August 29, 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11852v1",
      "published_date": "2024-07-16 15:33:00 UTC",
      "updated_date": "2024-07-16 15:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:04:59.402956"
    },
    {
      "arxiv_id": "2407.12074v1",
      "title": "Enhancing Parameter Efficiency and Generalization in Large-Scale Models: A Regularized and Masked Low-Rank Adaptation Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhu Mao",
        "Siqi Ping",
        "Zihao Zhao",
        "Yang Liu",
        "Wenbo Ding"
      ],
      "abstract": "Large pre-trained models, such as large language models (LLMs), present\nsignificant resource challenges for fine-tuning due to their extensive\nparameter sizes, especially for applications in mobile systems. To address\nthis, Low-Rank Adaptation (LoRA) has been developed to reduce resource\nconsumption while maintaining satisfactory fine-tuning results. Despite its\neffectiveness, the original LoRA method faces challenges of suboptimal\nperformance and overfitting. This paper investigates the intrinsic dimension of\nthe matrix updates approximated by the LoRA method and reveals the performance\nbenefits of increasing this intrinsic dimension. By employing regularization\nand a gradient masking method that encourages higher intrinsic dimension, the\nproposed method, termed Regularized and Masked LoRA (RM-LoRA), achieves\nsuperior generalization performance with the same or lower trainable parameter\nbudget compared to the original LoRA and its latest variants across various\nopen-source vision and language datasets.",
      "tldr_zh": "大型预训练模型（如 LLMs）在微调时面临资源消耗和参数过拟合挑战，而 Low-Rank Adaptation (LoRA) 方法虽能减少参数量但性能不佳。本文提出 Regularized and Masked LoRA (RM-LoRA)，通过正则化和梯度掩码技术来增加矩阵更新的内在维度，从而提升模型的泛化性能。实验结果显示，RM-LoRA 在各种开源视觉和语言数据集上，与原 LoRA 和其变体相比，实现了更高的准确率，同时保持相同或更低的参数预算。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12074v1",
      "published_date": "2024-07-16 15:26:31 UTC",
      "updated_date": "2024-07-16 15:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:05:07.739861"
    },
    {
      "arxiv_id": "2407.11844v1",
      "title": "Variational Randomized Smoothing for Sample-Wise Adversarial Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Hase",
        "Ye Wang",
        "Toshiaki Koike-Akino",
        "Jing Liu",
        "Kieran Parsons"
      ],
      "abstract": "Randomized smoothing is a defensive technique to achieve enhanced robustness\nagainst adversarial examples which are small input perturbations that degrade\nthe performance of neural network models. Conventional randomized smoothing\nadds random noise with a fixed noise level for every input sample to smooth out\nadversarial perturbations. This paper proposes a new variational framework that\nuses a per-sample noise level suitable for each input by introducing a noise\nlevel selector. Our experimental results demonstrate enhancement of empirical\nrobustness against adversarial attacks. We also provide and analyze the\ncertified robustness for our sample-wise smoothing method.",
      "tldr_zh": "这篇论文提出了一种变分随机平滑(Variational Randomized Smoothing)框架，用于提升神经网络模型对对抗样本的鲁棒性，通过为每个输入样本动态选择合适的噪声水平来取代传统固定噪声方法的局限性。框架引入了噪声水平选择器，以实现样本级(sample-wise)平滑处理。实验结果表明，该方法显著提高了经验鲁棒性，并在对抗攻击中提供了可认证的(certified)鲁棒性分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, under preparation",
      "pdf_url": "http://arxiv.org/pdf/2407.11844v1",
      "published_date": "2024-07-16 15:25:13 UTC",
      "updated_date": "2024-07-16 15:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:05:19.950894"
    },
    {
      "arxiv_id": "2407.11843v3",
      "title": "Preemptive Detection and Correction of Misaligned Actions in LLM Agents",
      "title_zh": "针对 LLM 代理中不对齐行为的预先检测与修正",
      "authors": [
        "Haishuo Fang",
        "Xiaodan Zhu",
        "Iryna Gurevych"
      ],
      "abstract": "Deploying LLM-based agents in real-life applications often faces a critical\nchallenge: the misalignment between agents' behavior and user intent. Such\nmisalignment may lead agents to unintentionally execute critical actions that\ncarry negative outcomes (e.g., accidentally triggering a \"buy-now\" in web\nshopping), resulting in undesirable or even irreversible consequences. Although\naddressing these issues is crucial, the preemptive detection and correction of\nmisaligned actions remains relatively underexplored. To fill this gap, we\nintroduce InferAct, a novel approach that leverages the belief reasoning\nability of LLMs, grounded in Theory-of-Mind, to detect misaligned actions\nbefore execution. Once the misalignment is detected, InferAct alerts users for\ntimely correction, preventing adverse outcomes and enhancing the reliability of\nLLM agents' decision-making processes. Experiments on three widely used tasks\ndemonstrate that InferAct achieves up to 20% improvements on Marco-F1 against\nbaselines in misaligned action detection. An in-depth evaluation of\nmisalignment correction further highlights InferAct's effectiveness in\nimproving agent alignment.",
      "tldr_zh": "该论文探讨了LLM代理在实际应用中行为与用户意图不一致的问题，可能导致负面后果，如意外执行关键动作。作者提出InferAct，一种新方法，利用LLMs的信念推理能力（基于Theory-of-Mind），在动作执行前预先检测失调行为，并通过警报用户实现及时纠正，从而提升代理的可靠性和决策过程。在三个常用任务的实验中，InferAct在失调行为检测上比基线提高了多达20%的Marco-F1分数，并在失调纠正方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11843v3",
      "published_date": "2024-07-16 15:24:44 UTC",
      "updated_date": "2024-12-27 14:17:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:05:32.713911"
    },
    {
      "arxiv_id": "2407.11830v3",
      "title": "zIA: a GenAI-powered local auntie assists tourists in Italy",
      "title_zh": "翻译失败",
      "authors": [
        "Alexio Cassani",
        "Michele Ruberl",
        "Antonio Salis",
        "Giacomo Giannese",
        "Gianluca Boanelli"
      ],
      "abstract": "The Tourism and Destination Management Organization (DMO) industry is rapidly\nevolving to adapt to new technologies and traveler expectations. Generative\nArtificial Intelligence (AI) offers an astonishing and innovative opportunity\nto enhance the tourism experience by providing personalized, interactive and\nengaging assistance. In this article, we propose a generative AI-based chatbot\nfor tourism assistance. The chatbot leverages AI ability to generate realistic\nand creative texts, adopting the friendly persona of the well-known Italian\nall-knowledgeable aunties, to provide tourists with personalized information,\ntailored and dynamic pre, during and post recommendations and trip plans and\npersonalized itineraries, using both text and voice commands, and supporting\ndifferent languages to satisfy Italian and foreign tourists expectations. This\nwork is under development in the Molise CTE research project, funded by the\nItalian Minister of the Economic Growth (MIMIT), with the aim to leverage the\nbest emerging technologies available, such as Cloud and AI to produce state of\nthe art solutions in the Smart City environment.",
      "tldr_zh": "该研究提出zIA，一种基于Generative AI的聊天机器人，旨在提升旅游体验，通过模仿友好的意大利“无所不知的阿姨”形象，为游客提供个性化信息、动态行程规划和推荐，支持文本、语音命令及多语言。机器人利用AI生成现实且富有创意的文本，针对旅游前、中、后阶段的个性化需求进行辅助。该项目作为Molise CTE研究的一部分，由意大利经济成长部(MIMIT)资助，聚焦于智能城市环境的应用，旨在满足本地和外国游客的期望。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11830v3",
      "published_date": "2024-07-16 15:18:12 UTC",
      "updated_date": "2024-08-19 09:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:05:44.566987"
    },
    {
      "arxiv_id": "2407.11827v1",
      "title": "GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text",
      "title_zh": "GPT 辅助的修辞和语言特征",
      "authors": [
        "Kyle Hamilton",
        "Luca Longo",
        "Bojan Bozic"
      ],
      "abstract": "While the use of machine learning for the detection of propaganda techniques\nin text has garnered considerable attention, most approaches focus on\n\"black-box\" solutions with opaque inner workings. Interpretable approaches\nprovide a solution, however, they depend on careful feature engineering and\ncostly expert annotated data. Additionally, language features specific to\npropagandistic text are generally the focus of rhetoricians or linguists, and\nthere is no data set labeled with such features suitable for machine learning.\nThis study codifies 22 rhetorical and linguistic features identified in\nliterature related to the language of persuasion for the purpose of annotating\nan existing data set labeled with propaganda techniques. To help human experts\nannotate natural language sentences with these features, RhetAnn, a web\napplication, was specifically designed to minimize an otherwise considerable\nmental effort. Finally, a small set of annotated data was used to fine-tune\nGPT-3.5, a generative large language model (LLM), to annotate the remaining\ndata while optimizing for financial cost and classification accuracy. This\nstudy demonstrates how combining a small number of human annotated examples\nwith GPT can be an effective strategy for scaling the annotation process at a\nfraction of the cost of traditional annotation relying solely on human experts.\nThe results are on par with the best performing model at the time of writing,\nnamely GPT-4, at 10x less the cost. Our contribution is a set of features,\ntheir properties, definitions, and examples in a machine-readable format, along\nwith the code for RhetAnn and the GPT prompts and fine-tuning procedures for\nadvancing state-of-the-art interpretable propaganda technique detection.",
      "tldr_zh": "本文研究了如何利用GPT辅助标注22种修辞和语言特征，以实现可解释的宣传技术(propaganda techniques)检测，解决现有“黑箱”模型的透明性问题和专家标注的高成本问题。研究开发了RhetAnn网络应用，帮助人类专家高效标注现有数据集，并通过少量标注数据微调GPT-3.5来自动处理剩余数据，优化了成本和准确性。结果显示，微调后的GPT-3.5在分类性能上与GPT-4相当，但成本仅为其1/10，主要贡献包括特征集的机器可读格式、RhetAnn代码以及GPT提示和微调过程，用于推进该领域的状态-of-the-art进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11827v1",
      "published_date": "2024-07-16 15:15:39 UTC",
      "updated_date": "2024-07-16 15:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:05:57.179882"
    },
    {
      "arxiv_id": "2407.11824v2",
      "title": "The Future of Data Science Education",
      "title_zh": "数据科学教育的未来",
      "authors": [
        "Brian Wright",
        "Peter Alonzi",
        "Ali Rivera"
      ],
      "abstract": "The definition of Data Science is a hotly debated topic. For many, the\ndefinition is a simple shortcut to Artificial Intelligence or Machine Learning.\nHowever, there is far more depth and nuance to the field of Data Science than a\nsimple shortcut can provide. The School of Data Science at the University of\nVirginia has developed a novel model for the definition of Data Science. This\nmodel is based on identifying a unified understanding of the data work done\nacross all areas of Data Science. It represents a generational leap forward in\nhow we understand and teach Data Science. In this paper we will present the\ncore features of the model and explain how it unifies various concepts going\nfar beyond the analytics component of AI. From this foundation we will present\nour Undergraduate Major curriculum in Data Science and demonstrate how it\nprepares students to be well-rounded Data Science team members and leaders. The\npaper will conclude with an in-depth overview of the Foundations of Data\nScience course designed to introduce students to the field while also\nimplementing proven STEM oriented pedagogical methods. These include, for\nexample, specifications grading, active learning lectures, guest lectures from\nindustry experts and weekly gamification labs.",
      "tldr_zh": "这篇论文讨论了 Data Science 的定义问题，认为它远不止是 Artificial Intelligence 或 Machine Learning 的简易版本，而是需要更深层次的理解。Virginia 大学的数据科学学院提出了一种新模型，通过统一 Data Science 各领域的概念，实现了理解和教学的重大进步。该模型超越了 AI 的分析组件，并应用于本科 Data Science 专业课程，帮助学生成为全面的团队成员和领导者。最后，论文详细概述了 Foundations of Data Science 课程的教学方法，包括 specifications grading、active learning lectures、行业专家客座讲座和每周 gamification labs。",
      "categories": [
        "stat.OT",
        "cs.AI"
      ],
      "primary_category": "stat.OT",
      "comment": "12 pages, 5 figures, publish at the 53rd Annual Southeast Decision\n  Science Institute 2024, won best paper for Innovation track",
      "pdf_url": "http://arxiv.org/pdf/2407.11824v2",
      "published_date": "2024-07-16 15:11:54 UTC",
      "updated_date": "2025-03-17 19:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:06:17.757884"
    },
    {
      "arxiv_id": "2407.12881v1",
      "title": "BinaryAlign: Word Alignment as Binary Sequence Labeling",
      "title_zh": "BinaryAlign：词对齐作为二元序列标注",
      "authors": [
        "Gaetan Lopez Latouche",
        "Marc-André Carbonneau",
        "Ben Swanson"
      ],
      "abstract": "Real world deployments of word alignment are almost certain to cover both\nhigh and low resource languages. However, the state-of-the-art for this task\nrecommends a different model class depending on the availability of gold\nalignment training data for a particular language pair. We propose BinaryAlign,\na novel word alignment technique based on binary sequence labeling that\noutperforms existing approaches in both scenarios, offering a unifying approach\nto the task. Additionally, we vary the specific choice of multilingual\nfoundation model, perform stratified error analysis over alignment error type,\nand explore the performance of BinaryAlign on non-English language pairs. We\nmake our source code publicly available.",
      "tldr_zh": "该研究提出BinaryAlign，一种将词对齐任务视为二元序列标记的新方法，能够统一处理高资源和低资源语言对齐场景，优于现有方法。BinaryAlign基于二元序列标记技术，不依赖于特定语言对的金标准训练数据，提供了一个灵活的解决方案。实验包括不同multilingual foundation model的选择、分层错误分析，以及对非英语语言对的性能评估，结果显示其在各种条件下表现出色。研究还公开了源代码，以促进进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12881v1",
      "published_date": "2024-07-16 15:11:06 UTC",
      "updated_date": "2024-07-16 15:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:06:19.132812"
    },
    {
      "arxiv_id": "2407.11821v1",
      "title": "Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqicheng Zhu",
        "Nico Potyka",
        "Bo Xiong",
        "Trung-Kien Tran",
        "Mojtaba Nayyeri",
        "Evgeny Kharlamov",
        "Steffen Staab"
      ],
      "abstract": "Statistical information is ubiquitous but drawing valid conclusions from it\nis prohibitively hard. We explain how knowledge graph embeddings can be used to\napproximate probabilistic inference efficiently using the example of\nStatistical EL (SEL), a statistical extension of the lightweight Description\nLogic EL. We provide proofs for runtime and soundness guarantees, and\nempirically evaluate the runtime and approximation quality of our approach.",
      "tldr_zh": "这篇论文提出了一种利用 Knowledge Graph Embeddings 来高效近似 Statistical EL 中的概率推理方法，以解决从统计信息中得出有效结论的挑战。Statistical EL 是轻量级描述逻辑 EL 的统计扩展，该方法提供了运行时保证和正确性证明（soundness guarantees）。实验结果显示，该方法在运行时和近似质量方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2407.11821v1",
      "published_date": "2024-07-16 15:08:33 UTC",
      "updated_date": "2024-07-16 15:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:06:30.812741"
    },
    {
      "arxiv_id": "2407.11820v3",
      "title": "Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Ma",
        "Peiwen Sun",
        "Yaoting Wang",
        "Di Hu"
      ],
      "abstract": "Audio-Visual Segmentation (AVS) aims to achieve pixel-level localization of\nsound sources in videos, while Audio-Visual Semantic Segmentation (AVSS), as an\nextension of AVS, further pursues semantic understanding of audio-visual\nscenes. However, since the AVSS task requires the establishment of audio-visual\ncorrespondence and semantic understanding simultaneously, we observe that\nprevious methods have struggled to handle this mashup of objectives in\nend-to-end training, resulting in insufficient learning and sub-optimization.\nTherefore, we propose a two-stage training strategy called \\textit{Stepping\nStones}, which decomposes the AVSS task into two simple subtasks from\nlocalization to semantic understanding, which are fully optimized in each stage\nto achieve step-by-step global optimization. This training strategy has also\nproved its generalization and effectiveness on existing methods. To further\nimprove the performance of AVS tasks, we propose a novel framework Adaptive\nAudio Visual Segmentation, in which we incorporate an adaptive audio query\ngenerator and integrate masked attention into the transformer decoder,\nfacilitating the adaptive fusion of visual and audio features. Extensive\nexperiments demonstrate that our methods achieve state-of-the-art results on\nall three AVS benchmarks. The project homepage can be accessed at\nhttps://gewu-lab.github.io/stepping_stones/.",
      "tldr_zh": "本论文针对Audio-Visual Semantic Segmentation (AVSS)任务提出了一种渐进式训练策略Stepping Stones，以解决端到端训练中音频-视觉对应和语义理解的冲突问题。该策略将AVSS分解为两个阶段：先优化定位子任务，再逐步转向语义理解，确保每个阶段的充分学习，并证明其在现有方法上的泛化有效性。同时，论文引入了Adaptive Audio Visual Segmentation框架，包含自适应音频查询生成器和masked attention机制，实现视觉和音频特征的自适应融合。实验结果显示，该方法在三个Audio-Visual Segmentation (AVS)基准上达到了state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024 poster. Project url:\n  https://gewu-lab.github.io/stepping_stones",
      "pdf_url": "http://arxiv.org/pdf/2407.11820v3",
      "published_date": "2024-07-16 15:08:30 UTC",
      "updated_date": "2024-09-12 09:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:06:44.035074"
    },
    {
      "arxiv_id": "2407.12073v5",
      "title": "Relational Representation Distillation",
      "title_zh": "关系表示蒸馏",
      "authors": [
        "Nikolaos Giakoumoglou",
        "Tania Stathaki"
      ],
      "abstract": "Knowledge distillation involves transferring knowledge from large, cumbersome\nteacher models to more compact student models. The standard approach minimizes\nthe Kullback-Leibler (KL) divergence between the probabilistic outputs of a\nteacher and student network. However, this approach fails to capture important\nstructural relationships in the teacher's internal representations. Recent\nadvances have turned to contrastive learning objectives, but these methods\nimpose overly strict constraints through instance-discrimination, forcing apart\nsemantically similar samples even when they should maintain similarity. This\nmotivates an alternative objective by which we preserve relative relationships\nbetween instances. Our method employs separate temperature parameters for\nteacher and student distributions, with sharper student outputs, enabling\nprecise learning of primary relationships while preserving secondary\nsimilarities. We show theoretical connections between our objective and both\nInfoNCE loss and KL divergence. Experiments demonstrate that our method\nsignificantly outperforms existing knowledge distillation methods across\ndiverse knowledge transfer tasks, achieving better alignment with teacher\nmodels, and sometimes even outperforms the teacher network.",
      "tldr_zh": "该论文提出了一种名为Relational Representation Distillation的新知识蒸馏方法，旨在通过保留实例之间的相对关系（Relative Relationships），克服标准Kullback-Leibler (KL) Divergence方法无法捕捉教师模型内部结构关系的问题。不同于传统Contrastive Learning方法，该方法使用单独的温度参数（Temperature Parameters）来生成更锐利的学生输出，从而精确学习主要关系并维护次要相似性，同时理论上与InfoNCE损失和KL散度有紧密联系。实验结果显示，该方法在多种知识转移任务中显著优于现有方法，与教师模型对齐更佳，有时甚至超越教师网络的表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.4; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Code: https://github.com/giakoumoglou/distillers,\n  Supplementary: https://giakoumoglou.com/src/rrd_suppl.pdf",
      "pdf_url": "http://arxiv.org/pdf/2407.12073v5",
      "published_date": "2024-07-16 14:56:13 UTC",
      "updated_date": "2025-05-12 18:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:06:56.849702"
    },
    {
      "arxiv_id": "2407.11802v5",
      "title": "Discriminative and Consistent Representation Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Giakoumoglou",
        "Tania Stathaki"
      ],
      "abstract": "Knowledge Distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. While contrastive learning has shown promise\nin self-supervised learning by creating discriminative representations, its\napplication in knowledge distillation remains limited and focuses primarily on\ndiscrimination, neglecting the structural relationships captured by the teacher\nmodel. To address this limitation, we propose Discriminative and Consistent\nDistillation (DCD), which employs a contrastive loss along with a consistency\nregularization to minimize the discrepancy between the distributions of teacher\nand student representations. Our method introduces learnable temperature and\nbias parameters that adapt during training to balance these complementary\nobjectives, replacing the fixed hyperparameters commonly used in contrastive\nlearning approaches. Through extensive experiments on CIFAR-100 and ImageNet\nILSVRC-2012, we demonstrate that DCD achieves state-of-the-art performance,\nwith the student model sometimes surpassing the teacher's accuracy.\nFurthermore, we show that DCD's learned representations exhibit superior\ncross-dataset generalization when transferred to Tiny ImageNet and STL-10.",
      "tldr_zh": "该研究提出了一种新的知识蒸馏(Knowledge Distillation, KD)方法，名为Discriminative and Consistent Distillation (DCD)，它结合对比损失(contrastive loss)和一致性正则化(consistency regularization)，以最小化教师模型和学生模型表示之间的分布差异，同时引入可学习的温度和偏差参数来动态平衡这些目标。相比传统对比学习方法，DCD 克服了仅关注区分性的局限，实验在CIFAR-100和ImageNet ILSVRC-2012数据集上实现了最先进性能，学生模型的准确率有时甚至超过了教师模型。此外，DCD的表示显示出优越的跨数据集泛化能力，在转移到Tiny ImageNet和STL-10时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.4; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Code: https://github.com/giakoumoglou/distillers,\n  Supplementary: https://giakoumoglou.com/src/dcd_suppl.pdf",
      "pdf_url": "http://arxiv.org/pdf/2407.11802v5",
      "published_date": "2024-07-16 14:53:35 UTC",
      "updated_date": "2025-05-12 18:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:07:09.368001"
    },
    {
      "arxiv_id": "2407.11793v1",
      "title": "Click-Gaussian: Interactive Segmentation to Any 3D Gaussians",
      "title_zh": "翻译失败",
      "authors": [
        "Seokhun Choi",
        "Hyeonseop Song",
        "Jaechul Kim",
        "Taehyeong Kim",
        "Hoseok Do"
      ],
      "abstract": "Interactive segmentation of 3D Gaussians opens a great opportunity for\nreal-time manipulation of 3D scenes thanks to the real-time rendering\ncapability of 3D Gaussian Splatting. However, the current methods suffer from\ntime-consuming post-processing to deal with noisy segmentation output. Also,\nthey struggle to provide detailed segmentation, which is important for\nfine-grained manipulation of 3D scenes. In this study, we propose\nClick-Gaussian, which learns distinguishable feature fields of two-level\ngranularity, facilitating segmentation without time-consuming post-processing.\nWe delve into challenges stemming from inconsistently learned feature fields\nresulting from 2D segmentation obtained independently from a 3D scene. 3D\nsegmentation accuracy deteriorates when 2D segmentation results across the\nviews, primary cues for 3D segmentation, are in conflict. To overcome these\nissues, we propose Global Feature-guided Learning (GFL). GFL constructs the\nclusters of global feature candidates from noisy 2D segments across the views,\nwhich smooths out noises when training the features of 3D Gaussians. Our method\nruns in 10 ms per click, 15 to 130 times as fast as the previous methods, while\nalso significantly improving segmentation accuracy. Our project page is\navailable at https://seokhunchoi.github.io/Click-Gaussian",
      "tldr_zh": "本研究提出 Click-Gaussian 方法，实现对任意 3D Gaussians 的交互式分割，解决了现有方法在实时渲染 3D 场景时存在的后期处理耗时和细节分割不足的问题。Click-Gaussian 通过学习两种粒度的可区分特征字段，避免了时间消耗的后期处理，同时针对 2D 分割视角不一致导致的 3D 准确性下降，引入 Global Feature-guided Learning (GFL) 来构建全局特征候选集群，从而平滑噪声并优化 3D Gaussians 特征训练。实验结果显示，该方法每点击只需 10 ms，比之前方法快 15 到 130 倍，同时显著提高了分割准确性，为细粒度 3D 场景操作提供了高效工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. The first two authors contributed equally to\n  this work",
      "pdf_url": "http://arxiv.org/pdf/2407.11793v1",
      "published_date": "2024-07-16 14:49:27 UTC",
      "updated_date": "2024-07-16 14:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:07:20.558005"
    },
    {
      "arxiv_id": "2407.11790v4",
      "title": "Characterizing and Understanding HGNN Training on GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Dengke Han",
        "Mingyu Yan",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Owing to their remarkable representation capabilities for heterogeneous graph\ndata, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in\nmany critical real-world domains such as recommendation systems and medical\nanalysis. Prior to their practical application, identifying the optimal HGNN\nmodel parameters tailored to specific tasks through extensive training is a\ntime-consuming and costly process. To enhance the efficiency of HGNN training,\nit is essential to characterize and analyze the execution semantics and\npatterns within the training process to identify performance bottlenecks. In\nthis study, we conduct an in-depth quantification and analysis of two\nmainstream HGNN training scenarios, including single-GPU and multi-GPU\ndistributed training. Based on the characterization results, we disclose the\nperformance bottlenecks and their underlying causes in different HGNN training\nscenarios and provide optimization guidelines from both software and hardware\nperspectives.",
      "tldr_zh": "本文对 Heterogeneous Graph Neural Networks (HGNNs) 在 GPUs 上的训练过程进行了深入特征化和分析，旨在解决其在推荐系统和医疗分析等领域的训练耗时问题。研究通过量化单 GPU 和多 GPU 分布式训练场景，揭示了关键性能瓶颈及其根本原因，包括执行语义和模式问题。最终，论文从软件和硬件角度提供了优化指南，以提升 HGNNs 训练的效率和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 14 figures, to appear in ACM Transactions on Architecture\n  and Code Optimization (ACM TACO)",
      "pdf_url": "http://arxiv.org/pdf/2407.11790v4",
      "published_date": "2024-07-16 14:45:46 UTC",
      "updated_date": "2024-10-29 06:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:07:31.750051"
    },
    {
      "arxiv_id": "2407.11789v1",
      "title": "Large Language Models as Misleading Assistants in Conversation",
      "title_zh": "大语言模型作为误导性助手在对话中",
      "authors": [
        "Betty Li Hou",
        "Kejian Shi",
        "Jason Phang",
        "James Aung",
        "Steven Adler",
        "Rosie Campbell"
      ],
      "abstract": "Large Language Models (LLMs) are able to provide assistance on a wide range\nof information-seeking tasks. However, model outputs may be misleading, whether\nunintentionally or in cases of intentional deception. We investigate the\nability of LLMs to be deceptive in the context of providing assistance on a\nreading comprehension task, using LLMs as proxies for human users. We compare\noutcomes of (1) when the model is prompted to provide truthful assistance, (2)\nwhen it is prompted to be subtly misleading, and (3) when it is prompted to\nargue for an incorrect answer. Our experiments show that GPT-4 can effectively\nmislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up\nto a 23% drop in accuracy on the task compared to when a truthful assistant is\nused. We also find that providing the user model with additional context from\nthe passage partially mitigates the influence of the deceptive model. This work\nhighlights the ability of LLMs to produce misleading information and the\neffects this may have in real-world situations.",
      "tldr_zh": "这篇论文研究了大型语言模型（LLMs）在对话中作为误导性助手的潜力，重点考察其在阅读理解任务中可能产生的欺骗行为。研究方法包括比较三种提示场景：（1）模型被提示提供真实帮助，（2）被提示微妙地误导，以及（3）被提示为错误答案辩护。实验结果显示，GPT-4 可以有效误导 GPT-3.5-Turbo 和 GPT-4，导致任务准确率下降高达23%。此外，提供额外上下文可部分缓解这种误导影响，该工作强调了LLMs 生成误导信息在现实世界的潜在风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Next Generation of AI Safety Workshop, 41st International Conference\n  on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.11789v1",
      "published_date": "2024-07-16 14:45:22 UTC",
      "updated_date": "2024-07-16 14:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:07:43.774939"
    },
    {
      "arxiv_id": "2407.11784v2",
      "title": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development",
      "title_zh": "Data-Juicer Sandbox：一种基于反馈驱动的多模态数据模型协同开发套件",
      "authors": [
        "Daoyuan Chen",
        "Haibin Wang",
        "Yilun Huang",
        "Ce Ge",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "abstract": "The emergence of multimodal large models has advanced artificial\nintelligence, introducing unprecedented levels of performance and\nfunctionality. However, optimizing these models remains challenging due to\nhistorically isolated paths of model-centric and data-centric developments,\nleading to suboptimal outcomes and inefficient resource utilization. In\nresponse, we present a new sandbox suite tailored for integrated data-model\nco-development. This sandbox provides a feedback-driven experimental platform,\nenabling cost-effective iteration and guided refinement of both data and\nmodels. Our proposed ``Probe-Analyze-Refine'' workflow, validated through\npractical use cases on multimodal tasks such as image-text pre-training with\nCLIP, image-to-text generation with LLaVA-like models, and text-to-video\ngeneration with DiT-based models, yields transferable and notable performance\nboosts, such as topping the VBench leaderboard. Extensive experiments also\nuncover fruitful insights into the interplay between data quality, diversity,\nmodel behavior, and computational costs. All codes, datasets, and models are\nopen-sourced to foster future research and applications that would otherwise be\ninfeasible due to the lack of a dedicated co-development infrastructure.",
      "tldr_zh": "该研究针对多模态大型模型的优化难题，提出 Data-Juicer Sandbox，这是一个反馈驱动的实验平台，用于实现数据和模型的联合开发，从而解决传统孤立路径导致的资源浪费问题。\n该平台采用 \"Probe-Analyze-Refine\" 工作流，通过在 CLIP 的图像文本预训练、LLaVA-like 的图像到文本生成以及 DiT-based 的文本到视频生成等任务上的实际案例验证，实现了可转移的性能提升，如在 VBench 排行榜上取得领先。\n实验还揭示了数据质量、多样性、模型行为和计算成本之间的互动关系，所有代码、数据集和模型均开源，以推动未来的研究和应用。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 12 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11784v2",
      "published_date": "2024-07-16 14:40:07 UTC",
      "updated_date": "2025-02-05 03:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:07:57.617102"
    },
    {
      "arxiv_id": "2407.11780v2",
      "title": "SwitchCIT: Switching for Continual Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinbo Wu",
        "Max Hartman",
        "Vidhata Arjun Jayaraman",
        "Lav R. Varshney"
      ],
      "abstract": "Large language models (LLMs) and multimodal models (MMs) have exhibited\nimpressive capabilities in various domains, particularly in general language\nunderstanding and visual reasoning. However, these models, trained on massive\ndata, may not be finely optimized for specific tasks triggered by instructions.\nContinual instruction tuning is crucial to adapt a large model to evolving\ntasks and domains, ensuring their effectiveness and relevance across a wide\nrange of applications. In the context of continual instruction tuning, where\nmodels are sequentially trained on different tasks, catastrophic forgetting can\noccur, leading to performance degradation on previously learned tasks. This\nwork addresses the catastrophic forgetting in continual instruction learning\nthrough a switching mechanism for routing computations to parameter-efficient\ntuned models. We demonstrate the effectiveness of our method through\nexperiments on continual instruction tuning of different natural language\ngeneration tasks and vision-language tasks. We also showcase the advantages of\nour proposed method in terms of efficiency, scalability, portability, and\nprivacy preservation.",
      "tldr_zh": "这篇论文提出了 SwitchCIT，一种切换机制（switching mechanism），用于缓解大型语言模型（LLMs）和多模态模型（MMs）在持续指令调整（continual instruction tuning）过程中出现的灾难性遗忘（catastrophic forgetting），从而优化模型在不同任务上的表现。SwitchCIT 通过路由计算到参数高效的调整模型，确保模型能适应不断演变的自然语言生成和视觉语言任务。实验结果显示，该方法在效率、可扩展性、可移植性和隐私保护方面表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11780v2",
      "published_date": "2024-07-16 14:37:33 UTC",
      "updated_date": "2024-12-18 18:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:08:07.743944"
    },
    {
      "arxiv_id": "2407.11774v1",
      "title": "Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text",
      "title_zh": "翻译失败",
      "authors": [
        "Seyedeh Fatemeh Ebrahimi",
        "Karim Akhavan Azari",
        "Amirmasoud Iravani",
        "Arian Qazvini",
        "Pouya Sadeghi",
        "Zeinab Sadat Taghavi",
        "Hossein Sameti"
      ],
      "abstract": "Detecting Machine-Generated Text (MGT) has emerged as a significant area of\nstudy within Natural Language Processing. While language models generate text,\nthey often leave discernible traces, which can be scrutinized using either\ntraditional feature-based methods or more advanced neural language models. In\nthis research, we explore the effectiveness of fine-tuning a RoBERTa-base\ntransformer, a powerful neural architecture, to address MGT detection as a\nbinary classification task. Focusing specifically on Subtask A\n(Monolingual-English) within the SemEval-2024 competition framework, our\nproposed system achieves an accuracy of 78.9% on the test dataset, positioning\nus at 57th among participants. Our study addresses this challenge while\nconsidering the limited hardware resources, resulting in a system that excels\nat identifying human-written texts but encounters challenges in accurately\ndiscerning MGTs.",
      "tldr_zh": "这篇论文探讨了检测机器生成文本 (MGT) 的方法，采用 fine-tuning RoBERTa-base transformer 模型作为二元分类任务。研究聚焦于 SemEval-2024 Task 8 Subtask A (Monolingual-English)，在测试数据集上实现了 78.9% 的准确率，并排名第 57 位。该系统在识别人类撰写的文本方面表现出色，但面临对 MGT 准确辨别的挑战，同时考虑了有限的硬件资源限制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures, 2 tables. Proceedings of the 18th International\n  Workshop on Semantic Evaluation (SemEval-2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.11774v1",
      "published_date": "2024-07-16 14:33:01 UTC",
      "updated_date": "2024-07-16 14:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:08:30.506212"
    },
    {
      "arxiv_id": "2407.11771v2",
      "title": "XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Truong Thanh Hung Nguyen",
        "Phuc Truong Loc Nguyen",
        "Hung Cao"
      ],
      "abstract": "Recent advancements in deep learning have significantly improved visual\nquality inspection and predictive maintenance within industrial settings.\nHowever, deploying these technologies on low-resource edge devices poses\nsubstantial challenges due to their high computational demands and the inherent\ncomplexity of Explainable AI (XAI) methods. This paper addresses these\nchallenges by introducing a novel XAI-integrated Visual Quality Inspection\nframework that optimizes the deployment of semantic segmentation models on\nlow-resource edge devices. Our framework incorporates XAI and the Large Vision\nLanguage Model to deliver human-centered interpretability through visual and\ntextual explanations to end-users. This is crucial for end-user trust and model\ninterpretability. We outline a comprehensive methodology consisting of six\nfundamental modules: base model fine-tuning, XAI-based explanation generation,\nevaluation of XAI approaches, XAI-guided data augmentation, development of an\nedge-compatible model, and the generation of understandable visual and textual\nexplanations. Through XAI-guided data augmentation, the enhanced model\nincorporating domain expert knowledge with visual and textual explanations is\nsuccessfully deployed on mobile devices to support end-users in real-world\nscenarios. Experimental results showcase the effectiveness of the proposed\nframework, with the mobile model achieving competitive accuracy while\nsignificantly reducing model size. This approach paves the way for the broader\nadoption of reliable and interpretable AI tools in critical industrial\napplications, where decisions must be both rapid and justifiable. Our code for\nthis work can be found at https://github.com/Analytics-Everywhere-Lab/vqixai.",
      "tldr_zh": "这篇论文提出了 XEdgeAI 框架，一个以人为中心的数据导向 Explainable Edge AI (XAI) 方法，用于优化语义分割模型在低资源边缘设备的工业视觉质量检查部署。框架包括六个核心模块：基础模型微调、XAI-based 解释生成、XAI 方法评估、XAI-guided 数据增强、边缘兼容模型开发，以及生成视觉和文本解释，从而提升模型的可解释性和用户信任。实验结果显示，该框架的移动模型在准确性上与基准模型竞争，同时显著减少了模型大小，为可靠且可解释的 AI 在关键工业应用中的广泛采用铺平了道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, preprint submitted to Information Fusion journal",
      "pdf_url": "http://arxiv.org/pdf/2407.11771v2",
      "published_date": "2024-07-16 14:30:24 UTC",
      "updated_date": "2024-10-25 18:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:08:33.422076"
    },
    {
      "arxiv_id": "2408.01427v1",
      "title": "Siamese Transformer Networks for Few-shot Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Jiang",
        "Shuoxi Zhang",
        "Kun He"
      ],
      "abstract": "Humans exhibit remarkable proficiency in visual classification tasks,\naccurately recognizing and classifying new images with minimal examples. This\nability is attributed to their capacity to focus on details and identify common\nfeatures between previously seen and new images. In contrast, existing few-shot\nimage classification methods often emphasize either global features or local\nfeatures, with few studies considering the integration of both. To address this\nlimitation, we propose a novel approach based on the Siamese Transformer\nNetwork (STN). Our method employs two parallel branch networks utilizing the\npre-trained Vision Transformer (ViT) architecture to extract global and local\nfeatures, respectively. Specifically, we implement the ViT-Small network\narchitecture and initialize the branch networks with pre-trained model\nparameters obtained through self-supervised learning. We apply the Euclidean\ndistance measure to the global features and the Kullback-Leibler (KL)\ndivergence measure to the local features. To integrate the two metrics, we\nfirst employ L2 normalization and then weight the normalized results to obtain\nthe final similarity score. This strategy leverages the advantages of both\nglobal and local features while ensuring their complementary benefits. During\nthe training phase, we adopt a meta-learning approach to fine-tune the entire\nnetwork. Our strategy effectively harnesses the potential of global and local\nfeatures in few-shot image classification, circumventing the need for complex\nfeature adaptation modules and enhancing the model's generalization ability.\nExtensive experiments demonstrate that our framework is simple yet effective,\nachieving superior performance compared to state-of-the-art baselines on four\npopular few-shot classification benchmarks in both 5-shot and 1-shot scenarios.",
      "tldr_zh": "这篇论文提出了一种基于 Siamese Transformer Network (STN) 的少样本图像分类方法，以整合全局和局部特征，解决现有方法忽略两者互补的问题。方法使用两个并行 Vision Transformer (ViT) 分支提取特征，并分别应用 Euclidean distance 和 Kullback-Leibler (KL) divergence 计算相似度，然后通过 L2 归一化和加权整合得到最终分数。训练过程采用 meta-learning 策略，提升模型的泛化能力，而无需复杂的特征适应模块。实验结果显示，该框架在四个流行少样本分类基准上，在 5-shot 和 1-shot 场景中均优于最先进基线，证明其简单且有效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.01427v1",
      "published_date": "2024-07-16 14:27:23 UTC",
      "updated_date": "2024-07-16 14:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:08:44.802479"
    },
    {
      "arxiv_id": "2407.11766v1",
      "title": "Vectoring Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Chen"
      ],
      "abstract": "Recent breakthroughs in large language models (LLM) have stirred up global\nattention, and the research has been accelerating non-stop since then.\nPhilosophers and psychologists have also been researching the structure of\nlanguage for decades, but they are having a hard time finding a theory that\ndirectly benefits from the breakthroughs of LLMs. In this article, we propose a\nnovel structure of language that reflects well on the mechanisms behind\nlanguage models and go on to show that this structure is also better at\ncapturing the diverse nature of language compared to previous methods. An\nanalogy of linear algebra is adapted to strengthen the basis of this\nperspective. We further argue about the difference between this perspective and\nthe design philosophy for current language models. Lastly, we discuss how this\nperspective can lead us to research directions that may accelerate the\nimprovements of science fastest.",
      "tldr_zh": "本论文提出了一种名为Vectoring Languages的新语言结构，该结构更好地反映大型语言模型(LLM)的内部机制，并比以往方法更有效地捕捉语言的多样性。通过线性代数的类比来强化这一视角，论文强调了这种结构的优势。论文进一步讨论了其与当前LLM设计哲学的差异，并探讨了如何引导未来的研究方向以加速科学进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages including references",
      "pdf_url": "http://arxiv.org/pdf/2407.11766v1",
      "published_date": "2024-07-16 14:25:55 UTC",
      "updated_date": "2024-07-16 14:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:08:56.396100"
    },
    {
      "arxiv_id": "2407.11753v1",
      "title": "A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Pandiyaraju V",
        "Shravan Venkatraman",
        "Abeshek A",
        "Pavan Kumar S",
        "Aravintakshan S A",
        "Senthil Kumar A M",
        "Kannan A"
      ],
      "abstract": "Farmers face various challenges when it comes to identifying diseases in rice\nleaves during their early stages of growth, which is a major reason for poor\nproduce. Therefore, early and accurate disease identification is important in\nagriculture to avoid crop loss and improve cultivation. In this research, we\npropose a novel hybrid deep learning (DL) classifier designed by extending the\nSqueeze-and-Excitation network architecture with a channel attention mechanism\nand the Swish ReLU activation function. The channel attention mechanism in our\nproposed model identifies the most important feature channels required for\nclassification during feature extraction and selection. The dying ReLU problem\nis mitigated by utilizing the Swish ReLU activation function, and the\nSqueeze-andExcitation blocks improve information propagation and cross-channel\ninteraction. Upon evaluation, our model achieved a high F1-score of 99.76% and\nan accuracy of 99.74%, surpassing the performance of existing models. These\noutcomes demonstrate the potential of state-of-the-art DL techniques in\nagriculture, contributing to the advancement of more efficient and reliable\ndisease detection systems.",
      "tldr_zh": "本文提出了一种基于Channel Attention Mechanism的混合CNN框架，用于水稻叶病害的早期检测，以帮助农民避免作物损失并提高产量。  \n该框架扩展了Squeeze-and-Excitation网络架构，结合Swish ReLU激活函数来识别关键特征通道、改善信息传播和跨通道交互，同时解决了Dying ReLU问题。  \n实验结果显示，该模型在评估中取得了99.74%的准确率和99.76%的F1-score，优于现有模型。  \n这项研究展示了先进深度学习技术在农业中的潜力，促进更高效可靠的病害检测系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 4 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11753v1",
      "published_date": "2024-07-16 14:17:26 UTC",
      "updated_date": "2024-07-16 14:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:09:09.487764"
    },
    {
      "arxiv_id": "2407.11745v2",
      "title": "Universal Sound Separation with Self-Supervised Audio Masked Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Zhao",
        "Xubo Liu",
        "Jinzheng Zhao",
        "Yi Yuan",
        "Qiuqiang Kong",
        "Mark D. Plumbley",
        "Wenwu Wang"
      ],
      "abstract": "Universal sound separation (USS) is a task of separating mixtures of\narbitrary sound sources. Typically, universal separation models are trained\nfrom scratch in a supervised manner, using labeled data. Self-supervised\nlearning (SSL) is an emerging deep learning approach that leverages unlabeled\ndata to obtain task-agnostic representations, which can benefit many downstream\ntasks. In this paper, we propose integrating a self-supervised pre-trained\nmodel, namely the audio masked autoencoder (A-MAE), into a universal sound\nseparation system to enhance its separation performance. We employ two\nstrategies to utilize SSL embeddings: freezing or updating the parameters of\nA-MAE during fine-tuning. The SSL embeddings are concatenated with the\nshort-time Fourier transform (STFT) to serve as input features for the\nseparation model. We evaluate our methods on the AudioSet dataset, and the\nexperimental results indicate that the proposed methods successfully enhance\nthe separation performance of a state-of-the-art ResUNet-based USS model.",
      "tldr_zh": "这篇论文提出了一种将自监督预训练模型 Audio Masked Autoencoder (A-MAE) 整合到 Universal Sound Separation (USS) 系统的方法，以提升对混合声音来源的分离性能。方法包括将 A-MAE 的 SSL 嵌入与短时傅里叶变换 (STFT) 拼接作为输入特征，并采用冻结或更新 A-MAE 参数的策略进行微调。实验结果显示，在 AudioSet 数据集上，该方法成功提升了基于 ResUNet 的 USS 模型的分离性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11745v2",
      "published_date": "2024-07-16 14:11:44 UTC",
      "updated_date": "2024-11-06 17:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:09:30.753553"
    },
    {
      "arxiv_id": "2407.11698v2",
      "title": "NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks",
      "title_zh": "NITRO-D：深度卷积神经网络的原生仅整数训练",
      "authors": [
        "Alberto Pirillo",
        "Luca Colombo",
        "Manuel Roveri"
      ],
      "abstract": "Quantization has become increasingly pivotal in addressing the steadily\nincreasing computational and memory requirements of Deep Neural Networks\n(DNNs). By reducing the number of bits used to represent weights and\nactivations (typically from 32-bit floating-point to 16-bit or 8-bit integers),\nquantization reduces the memory footprint, energy consumption, and execution\ntime of DNN models. However, traditional quantization methods typically focus\non the inference of DNNs, while the training process still relies on\nfloating-point operations. To date, only one work in the literature has\naddressed integer-only training for Multi-Layer Perceptron (MLP) architectures.\nThis work introduces NITRO-D, a new framework for training arbitrarily deep\ninteger-only Convolutional Neural Networks (CNNs) that operate entirely in the\ninteger-only domain for both training and inference. NITRO-D is the first\nframework in the literature enabling the training of integer-only CNNs without\nthe need to introduce a quantization scheme. Specifically, NITRO-D introduces a\nnovel architecture integrating multiple integer local-loss blocks, which\ninclude the proposed NITRO Scaling Layer and the NITRO-ReLU activation\nfunction. Additionally, it introduces a novel integer-only learning algorithm\nderived from Local Error Signals (LES), utilizing IntegerSGD, an optimizer\nspecifically designed to operate in an integer-only context. NITRO-D is\nimplemented in an open-source Python library. Extensive experimental\nevaluations demonstrate its effectiveness across several state-of-the-art image\nrecognition datasets. Results show significant performance improvements from\n2.47% to 5.96% for integer-only MLP architectures over the state-of-the-art\nsolution, and the capability of training integer-only CNN architectures with\nminimal accuracy degradation from -0.15% to -4.22% compared to floating-point\nLES.",
      "tldr_zh": "本论文提出了 NITRO-D 框架，用于实现深度卷积神经网络 (CNNs) 的原生整数-only 训练，旨在解决传统 Quantization 方法仅应用于推理而训练仍依赖浮点运算的问题。NITRO-D 引入了创新架构，包括 NITRO Scaling Layer 和 NITRO-ReLU 激活函数，以及基于 Local Error Signals (LES) 的整数-only 学习算法 IntegerSGD，从而使整个训练和推理过程完全在整数域中进行。实验结果显示，在多种图像识别数据集上，该框架使整数-only 多层感知器 (MLP) 架构的性能提升 2.47% 到 5.96%，而 CNN 架构的准确率仅较浮点版本下降 -0.15% 到 -4.22%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11698v2",
      "published_date": "2024-07-16 13:16:49 UTC",
      "updated_date": "2024-09-12 14:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:09:34.020978"
    },
    {
      "arxiv_id": "2407.20242v4",
      "title": "BadRobot: Jailbreaking Embodied LLMs in the Physical World",
      "title_zh": "翻译失败",
      "authors": [
        "Hangtao Zhang",
        "Chenyu Zhu",
        "Xianlong Wang",
        "Ziqi Zhou",
        "Changgan Yin",
        "Minghui Li",
        "Lulu Xue",
        "Yichen Wang",
        "Shengshan Hu",
        "Aishan Liu",
        "Peijin Guo",
        "Leo Yu Zhang"
      ],
      "abstract": "Embodied AI represents systems where AI is integrated into physical entities.\nLarge Language Model (LLM), which exhibits powerful language understanding\nabilities, has been extensively employed in embodied AI by facilitating\nsophisticated task planning. However, a critical safety issue remains\noverlooked: could these embodied LLMs perpetrate harmful behaviors? In\nresponse, we introduce BadRobot, a novel attack paradigm aiming to make\nembodied LLMs violate safety and ethical constraints through typical\nvoice-based user-system interactions. Specifically, three vulnerabilities are\nexploited to achieve this type of attack: (i) manipulation of LLMs within\nrobotic systems, (ii) misalignment between linguistic outputs and physical\nactions, and (iii) unintentional hazardous behaviors caused by world\nknowledge's flaws. Furthermore, we construct a benchmark of various malicious\nphysical action queries to evaluate BadRobot's attack performance. Based on\nthis benchmark, extensive experiments against existing prominent embodied LLM\nframeworks (e.g., Voxposer, Code as Policies, and ProgPrompt) demonstrate the\neffectiveness of our BadRobot.",
      "tldr_zh": "本研究提出 BadRobot，一种新型攻击范式，旨在通过语音交互诱导 Embodied LLMs 在物理世界中违反安全和伦理约束。BadRobot 利用三个关键漏洞：(i) 对机器人系统中 LLMs 的操控，(ii) 语言输出与物理动作之间的不匹配，以及 (iii) 世界知识缺陷导致的意外危险行为。研究者构建了一个恶意物理动作查询基准，并通过实验验证了 BadRobot 在现有框架（如 Voxposer、Code as Policies 和 ProgPrompt）上的有效性，从而揭示了 Embodied LLMs 的潜在安全风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ICLR 2025. Project page:\n  https://Embodied-LLMs-Safety.github.io",
      "pdf_url": "http://arxiv.org/pdf/2407.20242v4",
      "published_date": "2024-07-16 13:13:16 UTC",
      "updated_date": "2025-02-04 07:24:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:09:45.487225"
    },
    {
      "arxiv_id": "2407.11686v4",
      "title": "CCoE: A Compact and Efficient LLM Framework with Multi-Expert Collaboration for Resource-Limited Settings",
      "title_zh": "CCoE：一种紧凑高效的LLM框架，通过多专家协作适用于资源受限环境",
      "authors": [
        "Shaomang Huang",
        "Jianfeng Pan",
        "Min Peng",
        "Hanzhong Zheng"
      ],
      "abstract": "Large Language Models (LLMs) have achieved exceptional performance across\ndiverse domains through training on massive datasets. However, scaling LLMs to\nsupport multiple downstream domain applications remains a significant\nchallenge, especially under resource constraints. Existing approaches often\nstruggle to balance performance across multiple domains with resource\nefficiency, limiting their broader applicability. To address this, we introduce\nthe CCoE architecture, a modular framework that seamlessly integrates\ndomain-specific experts into a unified LLM. By leveraging independently trained\nexpert subnetworks on a shared backbone partition, CCoE achieves\nstate-of-the-art performance while significantly reducing the resource\nrequirements for multi-expert deployments. Furthermore, rule-based gating and\nexpert planning in CCoE enable flexible task allocation, promoting expert\ncollaboration to handle complex reasoning tasks. CCoE not only reduces\ninference costs but also provides a flexible and scalable solution for\nintegrating domain expertise across diverse applications. Experiments on five\ndomains demonstrate that CCoE achieves comparable performance to current\ndomain-specific LLMs. Moreover, compared to existing multi-domain model\nensemble methods, CCoE reduces memory usage by 61.3%, while improving inference\nefficiency by 0.76x over parameter-efficient multi-expert integration\napproaches.",
      "tldr_zh": "该论文提出 CCoE 架构，这是一个紧凑高效的 Large Language Models (LLMs) 框架，旨在解决资源有限环境下支持多领域应用的挑战，通过多专家协作实现性能与效率的平衡。CCoE 利用独立训练的专家子网络在共享主干分区上集成，并结合 rule-based gating 和 expert planning 来灵活分配任务，促进专家协作处理复杂推理。实验结果显示，CCoE 在五个领域达到与领域特定 LLMs 相当的性能，同时比现有多领域模型集成方法减少 61.3% 内存使用，并提升 0.76x 推理效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11686v4",
      "published_date": "2024-07-16 13:03:58 UTC",
      "updated_date": "2025-02-17 08:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:09:57.277881"
    },
    {
      "arxiv_id": "2407.11676v3",
      "title": "SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Yanis Lalou",
        "Théo Gnassounou",
        "Antoine Collas",
        "Antoine de Mathelin",
        "Oleksii Kachaiev",
        "Ambroise Odonnat",
        "Alexandre Gramfort",
        "Thomas Moreau",
        "Rémi Flamary"
      ],
      "abstract": "Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a\nlabeled source domain to perform well on an unlabeled target domain with some\ndata distribution shift. While many methods have been proposed in the\nliterature, fair and realistic evaluation remains an open question,\nparticularly due to methodological difficulties in selecting hyperparameters in\nthe unsupervised setting. With SKADA-bench, we propose a framework to evaluate\nDA methods on diverse modalities, beyond computer vision task that have been\nlargely explored in the literature. We present a complete and fair evaluation\nof existing shallow algorithms, including reweighting, mapping, and subspace\nalignment. Realistic hyperparameter selection is performed with nested\ncross-validation and various unsupervised model selection scores, on both\nsimulated datasets with controlled shifts and real-world datasets across\ndiverse modalities, such as images, text, biomedical, and tabular data. Our\nbenchmark highlights the importance of realistic validation and provides\npractical guidance for real-life applications, with key insights into the\nchoice and impact of model selection approaches. SKADA-bench is open-source,\nreproducible, and can be easily extended with novel DA methods, datasets, and\nmodel selection criteria without requiring re-evaluating competitors.\nSKADA-bench is available on Github at\nhttps://github.com/scikit-adaptation/skada-bench.",
      "tldr_zh": "本研究提出SKADA-Bench框架，用于基准测试Unsupervised Domain Adaptation (DA)方法，强调在多样模态上进行现实验证，以解决现有方法在超参数选择和公平评估方面的难题。该框架对浅层算法（如reweighting、mapping和subspace alignment）进行完整评估，利用嵌套交叉验证和各种无监督模型选择分数，在模拟数据集（控制分布偏移）和真实数据集（包括图像、文本、生物医学及表格数据）上进行测试。实验结果突显了现实验证的重要性，并提供实际指导，帮助选择合适的模型策略；SKADA-Bench是开源、可重现的框架，可轻松扩展新方法、数据集和标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11676v3",
      "published_date": "2024-07-16 12:52:29 UTC",
      "updated_date": "2025-02-11 11:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:10:09.021537"
    },
    {
      "arxiv_id": "2407.12070v1",
      "title": "Co-Designing Binarized Transformer and Hardware Accelerator for Efficient End-to-End Edge Deployment",
      "title_zh": "协同设计二值化 Transformer 和硬件加速器，用于高效端到端边缘部署",
      "authors": [
        "Yuhao Ji",
        "Chao Fang",
        "Shaobo Ma",
        "Haikuo Shao",
        "Zhongfeng Wang"
      ],
      "abstract": "Transformer models have revolutionized AI tasks, but their large size hinders\nreal-world deployment on resource-constrained and latency-critical edge\ndevices. While binarized Transformers offer a promising solution by\nsignificantly reducing model size, existing approaches suffer from\nalgorithm-hardware mismatches with limited co-design exploration, leading to\nsuboptimal performance on edge devices. Hence, we propose a co-design method\nfor efficient end-to-end edge deployment of Transformers from three aspects:\nalgorithm, hardware, and joint optimization. First, we propose BMT, a novel\nhardware-friendly binarized Transformer with optimized quantization methods and\ncomponents, and we further enhance its model accuracy by leveraging the\nweighted ternary weight splitting training technique. Second, we develop a\nstreaming processor mixed binarized Transformer accelerator, namely BAT, which\nis equipped with specialized units and scheduling pipelines for efficient\ninference of binarized Transformers. Finally, we co-optimize the algorithm and\nhardware through a design space exploration approach to achieve a global\ntrade-off between accuracy, latency, and robustness for real-world deployments.\nExperimental results show our co-design achieves up to 2.14-49.37x throughput\ngains and 3.72-88.53x better energy efficiency over state-of-the-art\nTransformer accelerators, enabling efficient end-to-end edge deployment.",
      "tldr_zh": "本研究针对Transformer模型在资源受限边缘设备上的部署挑战，提出了一种算法-硬件联合设计方法，以实现高效的端到端部署。具体而言，开发了BMT（一种硬件友好的二值化Transformer），通过优化的quantization方法和weighted ternary weight splitting训练技术提升模型准确性；同时，设计了BAT加速器，配备专用单元和调度管道以支持高效推理。最终，通过design space exploration进行联合优化，实验结果显示吞吐量提高2.14-49.37倍，能源效率提升3.72-88.53倍，显著改善了Transformer在边缘部署的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by ICCAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12070v1",
      "published_date": "2024-07-16 12:36:10 UTC",
      "updated_date": "2024-07-16 12:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:10:21.198883"
    },
    {
      "arxiv_id": "2407.11654v2",
      "title": "R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aladin Djuhera",
        "Vlad C. Andrei",
        "Xinyang Li",
        "Ullrich J. Mönich",
        "Holger Boche",
        "Walid Saad"
      ],
      "abstract": "Split federated learning (SFL) is a compute-efficient paradigm in distributed\nmachine learning (ML), where components of large ML models are outsourced to\nremote servers. A significant challenge in SFL, particularly when deployed over\nwireless channels, is the susceptibility of transmitted model parameters to\nadversarial jamming that could jeopardize the learning process. This is\nparticularly pronounced for word embedding parameters in large language models\n(LLMs), which are crucial for language understanding. In this paper, rigorous\ninsights are provided into the influence of jamming LLM word embeddings in SFL\nby deriving an expression for the ML training loss divergence and showing that\nit is upper-bounded by the mean squared error (MSE). Based on this analysis, a\nphysical layer framework is developed for resilient SFL with LLMs (R-SFLLM)\nover wireless networks. R-SFLLM leverages wireless sensing data to gather\ninformation on the jamming directions-of-arrival (DoAs) for the purpose of\ndevising a novel, sensing-assisted anti-jamming strategy while jointly\noptimizing beamforming, user scheduling, and resource allocation. Extensive\nexperiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,\nachieving close-to-baseline performance across various natural language\nprocessing (NLP) tasks and datasets. The proposed methodology further\nintroduces an adversarial training component, where controlled noise exposure\nsignificantly enhances the LLM's resilience to perturbed parameters during\ntraining. The results show that more noise-sensitive models, such as RoBERTa,\nbenefit from this feature, especially when resource allocation is unfair. It is\nalso shown that worst-case jamming in particular translates into worst-case\nmodel outcomes, thereby necessitating the need for jamming-resilient SFL\nprotocols.",
      "tldr_zh": "本文提出 R-SFLLM 框架，用于解决 Split Federated Learning (SFL) 在无线环境中对 Large Language Models (LLMs) 词嵌入参数的干扰问题，通过推导训练损失发散表达式并证明其受均方误差 (MSE) 上界。R-SFLLM 利用无线感知数据获取干扰方向 (DoAs)，并联合优化波束成形、用户调度和资源分配，同时引入对抗训练组件以增强模型对噪声的弹性。实验结果显示，该框架在使用 BERT 和 RoBERTa 模型的各种自然语言处理 (NLP) 任务中，性能接近基线，并在资源分配不公平或最坏情况干扰下显著提升模型鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11654v2",
      "published_date": "2024-07-16 12:21:29 UTC",
      "updated_date": "2024-09-09 12:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:10:34.532285"
    },
    {
      "arxiv_id": "2407.11652v7",
      "title": "CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging",
      "title_zh": "CCVA-FL：跨客户端变异自适应联邦学习用于医疗成像",
      "authors": [
        "Sunny Gupta",
        "Amit Sethi"
      ],
      "abstract": "Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.",
      "tldr_zh": "该论文提出了一种名为 CCVA-FL 的联邦学习框架，用于解决医疗成像中跨客户端数据变异和标注有限的问题。CCVA-FL 通过将图像转换为共同特征空间来最小化变异，包括专家标注子集图像、选择数据复杂度最低的客户端作为目标、使用 Scalable Diffusion Models with Transformers (DiT) 生成合成图像，并通过图像到图像翻译将本地图像转换为目标空间。最终，在联邦学习设置中训练服务器模型，结果显示 CCVA-FL 比 Vanilla Federated Averaging 更有效地处理数据分布差异，同时保持隐私保护。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10;\n  I.2.10; I.5.1; I.5.2; I.5.4; J.2; I.2.6; I.2.11; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version",
      "pdf_url": "http://arxiv.org/pdf/2407.11652v7",
      "published_date": "2024-07-16 12:18:20 UTC",
      "updated_date": "2024-08-09 05:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:10:44.949734"
    },
    {
      "arxiv_id": "2407.18264v1",
      "title": "Latency optimized Deep Neural Networks (DNNs): An Artificial Intelligence approach at the Edge using Multiprocessor System on Chip (MPSoC)",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Nima Omidsajedi",
        "Rekha Reddy",
        "Jianming Yi",
        "Jan Herbst",
        "Christoph Lipps",
        "Hans Dieter Schotten"
      ],
      "abstract": "Almost in every heavily computation-dependent application, from 6G\ncommunication systems to autonomous driving platforms, a large portion of\ncomputing should be near to the client side. Edge computing (AI at Edge) in\nmobile devices is one of the optimized approaches for addressing this\nrequirement. Therefore, in this work, the possibilities and challenges of\nimplementing a low-latency and power-optimized smart mobile system are\nexamined. Utilizing Field Programmable Gate Array (FPGA) based solutions at the\nedge will lead to bandwidth-optimized designs and as a consequence can boost\nthe computational effectiveness at a system-level deadline. Moreover, various\nperformance aspects and implementation feasibilities of Neural Networks (NNs)\non both embedded FPGA edge devices (using Xilinx Multiprocessor System on Chip\n(MPSoC)) and Cloud are discussed throughout this research. The main goal of\nthis work is to demonstrate a hybrid system that uses the deep learning\nprogrammable engine developed by Xilinx Inc. as the main component of the\nhardware accelerator. Then based on this design, an efficient system for mobile\nedge computing is represented by utilizing an embedded solution.",
      "tldr_zh": "本研究探讨了在边缘计算（Edge computing）中优化 Deep Neural Networks (DNNs) 的延迟和功耗问题，针对通信系统和自动驾驶等高计算应用的需求。作者采用 Field Programmable Gate Array (FPGA) 基于解决方案，特别是 Xilinx 的 Multiprocessor System on Chip (MPSoC)，构建了一个混合系统，利用硬件加速器提升计算效率和带宽优化。实验比较了嵌入式 FPGA 设备与云端神经网络的性能，证明了该方法在移动边缘计算中实现低延迟、高效系统的可行性，为AI at Edge应用提供了实用框架。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "25. ITG Fachtagung Mobilkommunikation",
      "pdf_url": "http://arxiv.org/pdf/2407.18264v1",
      "published_date": "2024-07-16 11:51:41 UTC",
      "updated_date": "2024-07-16 11:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:10:57.132023"
    },
    {
      "arxiv_id": "2407.11624v1",
      "title": "Rethinking Fair Graph Neural Networks from Re-balancing",
      "title_zh": "基于重新平衡",
      "authors": [
        "Zhixun Li",
        "Yushun Dong",
        "Qiang Liu",
        "Jeffrey Xu Yu"
      ],
      "abstract": "Driven by the powerful representation ability of Graph Neural Networks\n(GNNs), plentiful GNN models have been widely deployed in many real-world\napplications. Nevertheless, due to distribution disparities between different\ndemographic groups, fairness in high-stake decision-making systems is receiving\nincreasing attention. Although lots of recent works devoted to improving the\nfairness of GNNs and achieved considerable success, they all require\nsignificant architectural changes or additional loss functions requiring more\nhyper-parameter tuning. Surprisingly, we find that simple re-balancing methods\ncan easily match or surpass existing fair GNN methods. We claim that the\nimbalance across different demographic groups is a significant source of\nunfairness, resulting in imbalanced contributions from each group to the\nparameters updating. However, these simple re-balancing methods have their own\nshortcomings during training. In this paper, we propose FairGB, Fair Graph\nNeural Network via re-Balancing, which mitigates the unfairness of GNNs by\ngroup balancing. Technically, FairGB consists of two modules: counterfactual\nnode mixup and contribution alignment loss. Firstly, we select counterfactual\npairs across inter-domain and inter-class, and interpolate the ego-networks to\ngenerate new samples. Guided by analysis, we can reveal the debiasing mechanism\nof our model by the causal view and prove that our strategy can make sensitive\nattributes statistically independent from target labels. Secondly, we reweigh\nthe contribution of each group according to gradients. By combining these two\nmodules, they can mutually promote each other. Experimental results on\nbenchmark datasets show that our method can achieve state-of-the-art results\nconcerning both utility and fairness metrics. Code is available at\nhttps://github.com/ZhixunLEE/FairGB.",
      "tldr_zh": "该论文重新审视了图神经网络（GNNs）的公平性问题，认为不同群体间的分布不均衡是主要不公平来源，并发现简单重平衡（re-balancing）方法即可匹敌或超越现有公平GNN方法。作者提出FairGB框架，通过两个模块缓解不公平性：counterfactual node mixup（选择跨域和跨类反事实对，插值ego-networks生成新样本，并证明其使敏感属性与目标标签统计独立）和contribution alignment loss（根据梯度重新权衡各群体的贡献），这两个模块相互促进。实验结果显示，FairGB在基准数据集上实现了最先进的效用和公平性指标表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SIGKDD 2024, research track",
      "pdf_url": "http://arxiv.org/pdf/2407.11624v1",
      "published_date": "2024-07-16 11:39:27 UTC",
      "updated_date": "2024-07-16 11:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:11:09.118432"
    },
    {
      "arxiv_id": "2407.11615v1",
      "title": "Graph Dimension Attention Networks for Enterprise Credit Assessment",
      "title_zh": "用于企业信用评估的图维度注意力网络",
      "authors": [
        "Shaopeng Wei",
        "Beni Egressy",
        "Xingyan Chen",
        "Yu Zhao",
        "Fuzhen Zhuang",
        "Roger Wattenhofer",
        "Gang Kou"
      ],
      "abstract": "Enterprise credit assessment is critical for evaluating financial risk, and\nGraph Neural Networks (GNNs), with their advanced capability to model\ninter-entity relationships, are a natural tool to get a deeper understanding of\nthese financial networks. However, existing GNN-based methodologies\npredominantly emphasize entity-level attention mechanisms for contagion risk\naggregation, often overlooking the heterogeneous importance of different\nfeature dimensions, thus falling short in adequately modeling credit risk\nlevels. To address this issue, we propose a novel architecture named Graph\nDimension Attention Network (GDAN), which incorporates a dimension-level\nattention mechanism to capture fine-grained risk-related characteristics.\nFurthermore, we explore the interpretability of the GNN-based method in\nfinancial scenarios and propose a simple but effective data-centric explainer\nfor GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability\nby quantifying distribution shifts during the message-passing process.\nMoreover, we collected a real-world, multi-source Enterprise Credit Assessment\nDataset (ECAD) and have made it accessible to the research community since\nhigh-quality datasets are lacking in this field. Extensive experiments\nconducted on ECAD demonstrate the effectiveness of our methods. In addition, we\nran GDAN on the well-known datasets SMEsD and DBLP, also with excellent\nresults.",
      "tldr_zh": "本文提出 Graph Dimension Attention Network (GDAN)，一种新型架构，用于企业信用评估，通过引入维度级注意力机制来捕捉不同特征维度的异质重要性，从而改进 Graph Neural Networks (GNNs) 在建模信用风险时的细粒度特征提取。相比现有方法，GDAN 更有效地处理实体关系和风险聚合，并在金融场景中提升模型解释性。作者开发了 GDAN-DistShift 解释器，通过量化消息传递过程中的分布偏移，提供边级解释性，并公开了真实世界的多源企业信用评估数据集 (ECAD)。实验结果显示，GDAN 在 ECAD、SMEsD 和 DBLP 数据集上表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11615v1",
      "published_date": "2024-07-16 11:24:28 UTC",
      "updated_date": "2024-07-16 11:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:11:22.808127"
    },
    {
      "arxiv_id": "2407.11613v2",
      "title": "Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project",
      "title_zh": "翻译失败",
      "authors": [
        "David Moats",
        "Chandrima Ganguly"
      ],
      "abstract": "In 2023, Open AIs Democratic Inputs program funded 10 teams to design\nprocedures for public participation in generative AI. In this Perspective, we\nreview the results of the project, drawing on interviews with some of the teams\nand our own experiences conducting participation exercises, we identify several\nshared yet largely unspoken assumptions of the Democratic Inputs program 1.\nthat participation must be scalable 2. that the object of participation is a\nsingle model 3. that there must be a single form of participation 4. that the\ngoal is to extract abstract principles 5. that these principles should have\nconsensus 6. that publics should be representative and encourage alternative\nforms of participation in AI, perhaps not undertaken by tech companies.",
      "tldr_zh": "这篇评论文章审视了 OpenAI 的 Democratic Inputs 程序，该项目资助10个团队设计公众参与生成式 AI 的机制。作者通过对团队的访谈和自身参与经验，识别了几个共享假设：参与必须可扩展、对象是单一模型、采用单一形式、目标是提取共识原则，以及公众需代表性。最终，作者鼓励开发替代参与形式，或许不由科技公司主导，以促进更灵活的 AI 治理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11613v2",
      "published_date": "2024-07-16 11:22:34 UTC",
      "updated_date": "2025-03-05 14:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:11:33.113126"
    },
    {
      "arxiv_id": "2407.11612v1",
      "title": "Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study",
      "title_zh": "翻译失败",
      "authors": [
        "Chaya Ben Yehuda",
        "Ran Gilad-Bachrach",
        "Yarin Udi"
      ],
      "abstract": "Sustaining long-term user engagement with mobile health (mHealth)\ninterventions while preserving their high efficacy remains an ongoing challenge\nin real-world well-being applications. To address this issue, we introduce a\nnew algorithm, the Personalized, Context-Aware Recommender (PCAR), for\nintervention selection and evaluate its performance in a field experiment. In a\nfour-week, in-the-wild experiment involving 29 parents of young children, we\ndelivered personalized stress-reducing micro-interventions through a mobile\nchatbot. We assessed their impact on stress reduction using momentary stress\nlevel ecological momentary assessments (EMAs) before and after each\nintervention. Our findings demonstrate the superiority of PCAR intervention\nselection in enhancing the engagement and efficacy of mHealth\nmicro-interventions to stress coping compared to random intervention selection\nand a control group that did not receive any intervention. Furthermore, we show\nthat even brief, one-minute interventions can significantly reduce perceived\nstress levels (p=0.001). We observe that individuals are most receptive to\none-minute interventions during transitional periods between activities, such\nas transitioning from afternoon activities to bedtime routines. Our study\ncontributes to the literature by introducing a personalized context-aware\nintervention selection algorithm that improves engagement and efficacy of\nmHealth interventions, identifying key timing for stress interventions, and\noffering insights into mechanisms to improve stress coping.",
      "tldr_zh": "本研究引入了Personalized, Context-Aware Recommender (PCAR)算法，以提升mHealth微干预的参与度和效果，针对长期用户参与和实际应用中的挑战。研究通过一个为期四周的实地实验，向29名年轻父母通过移动聊天机器人提供个性化的减压微干预，并使用ecological momentary assessments (EMAs)评估干预前后压力水平。结果显示，PCAR干预选择比随机选择和无干预控制组更有效，能显著降低感知压力（p=0.001），且一分钟干预在活动过渡期（如从下午活动到睡前）最易被接受。该工作为mHealth干预提供了个性化算法、关键时机洞见，并深化了压力应对机制的研究。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11612v1",
      "published_date": "2024-07-16 11:22:22 UTC",
      "updated_date": "2024-07-16 11:22:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:11:45.943829"
    },
    {
      "arxiv_id": "2407.11609v1",
      "title": "Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift",
      "title_zh": "在分布偏移下的随机网络物理系统的统计可达性分析",
      "authors": [
        "Navid Hashemi",
        "Lars Lindemann",
        "Jyotirmoy V. Deshmukh"
      ],
      "abstract": "Reachability analysis is a popular method to give safety guarantees for\nstochastic cyber-physical systems (SCPSs) that takes in a symbolic description\nof the system dynamics and uses set-propagation methods to compute an\noverapproximation of the set of reachable states over a bounded time horizon.\nIn this paper, we investigate the problem of performing reachability analysis\nfor an SCPS that does not have a symbolic description of the dynamics, but\ninstead is described using a digital twin model that can be simulated to\ngenerate system trajectories. An important challenge is that the simulator\nimplicitly models a probability distribution over the set of trajectories of\nthe SCPS; however, it is typical to have a sim2real gap, i.e., the actual\ndistribution of the trajectories in a deployment setting may be shifted from\nthe distribution assumed by the simulator. We thus propose a statistical\nreachability analysis technique that, given a user-provided threshold\n$1-\\epsilon$, provides a set that guarantees that any reachable state during\ndeployment lies in this set with probability not smaller than this threshold.\nOur method is based on three main steps: (1) learning a deterministic surrogate\nmodel from sampled trajectories, (2) conducting reachability analysis over the\nsurrogate model, and (3) employing {\\em robust conformal inference} using an\nadditional set of sampled trajectories to quantify the surrogate model's\ndistribution shift with respect to the deployed SCPS. To counter conservatism\nin reachable sets, we propose a novel method to train surrogate models that\nminimizes a quantile loss term (instead of the usual mean squared loss), and a\nnew method that provides tighter guarantees using conformal inference using a\nnormalized surrogate error. We demonstrate the effectiveness of our technique\non various case studies.",
      "tldr_zh": "这篇论文针对随机网络物理系统（Stochastic Cyber-Physical Systems）在分布偏移（Distribution Shift）下的可达性分析（Reachability Analysis），提出了一种统计方法，用于提供安全保证，即使系统仅通过数字孪生（Digital Twin）模型模拟轨迹。方法包括三个主要步骤：从采样轨迹学习确定性代理模型（deterministic surrogate model）、在代理模型上进行可达性分析，以及使用鲁棒保形推理（robust conformal inference）量化代理模型与部署系统的分布差异。论文创新性地采用最小化分位数损失（quantile loss）的训练方式和归一化代理错误的方法，以减少可达集的保守性，并通过各种案例研究验证了该技术的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11609v1",
      "published_date": "2024-07-16 11:18:41 UTC",
      "updated_date": "2024-07-16 11:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:11:59.200829"
    },
    {
      "arxiv_id": "2407.11606v4",
      "title": "The Foundations of Tokenization: Statistical and Computational Concerns",
      "title_zh": "分词的基础：统计和计算问题",
      "authors": [
        "Juan Luis Gastaldi",
        "John Terilla",
        "Luca Malagutti",
        "Brian DuSell",
        "Tim Vieira",
        "Ryan Cotterell"
      ],
      "abstract": "Tokenization - the practice of converting strings of characters from an\nalphabet into sequences of tokens over a vocabulary - is a critical step in the\nNLP pipeline. The use of token representations is widely credited with\nincreased model performance but is also the source of many undesirable\nbehaviors, such as spurious ambiguity or inconsistency. Despite its recognized\nimportance as a standard representation method in NLP, the theoretical\nunderpinnings of tokenization are not yet fully understood. In particular, the\nimpact of tokenization on language model estimation has been investigated\nprimarily through empirical means. The present paper contributes to addressing\nthis theoretical gap by proposing a unified formal framework for representing\nand analyzing tokenizer models. Based on the category of stochastic maps, this\nframework enables us to establish general conditions for a principled use of\ntokenizers and, most importantly, the necessary and sufficient conditions for a\ntokenizer model to preserve the consistency of statistical estimators. In\naddition, we discuss statistical and computational concerns crucial for\ndesigning and implementing tokenizer models, such as inconsistency, ambiguity,\nfiniteness, and sequentiality. The framework and results advanced in this paper\ncontribute to building robust theoretical foundations for representations in\nneural language modeling that can inform future theoretical and empirical\nresearch.",
      "tldr_zh": "这篇论文探讨了 tokenization（将字符序列转换为词汇序列）在自然语言处理（NLP）管道中的关键作用及其问题，如 spurious ambiguity 和 inconsistency，尽管其对模型性能的贡献已被广泛认可，但理论基础仍不完善。作者提出一个统一的正式框架，基于 stochastic maps 的范畴，用于表示和分析 tokenizer 模型，并确立了 tokenizer 保持 statistical estimators 一致性的必要和充分条件。同时，论文讨论了设计 tokenizer 时的重要统计和计算问题，包括 inconsistency、ambiguity、finiteness 和 sequentiality。该框架为神经语言建模的表示提供了稳健的理论基础，有助于指导未来的理论和实证研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11606v4",
      "published_date": "2024-07-16 11:12:28 UTC",
      "updated_date": "2025-04-03 15:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:12:08.631078"
    },
    {
      "arxiv_id": "2407.11599v2",
      "title": "Enhancing TinyML Security: Study of Adversarial Attack Transferability",
      "title_zh": "增强 TinyML 安全：对抗攻击可转移性的研究",
      "authors": [
        "Parin Shah",
        "Yuvaraj Govindarajulu",
        "Pavan Kulkarni",
        "Manojkumar Parmar"
      ],
      "abstract": "The recent strides in artificial intelligence (AI) and machine learning (ML)\nhave propelled the rise of TinyML, a paradigm enabling AI computations at the\nedge without dependence on cloud connections. While TinyML offers real-time\ndata analysis and swift responses critical for diverse applications, its\ndevices' intrinsic resource limitations expose them to security risks. This\nresearch delves into the adversarial vulnerabilities of AI models on\nresource-constrained embedded hardware, with a focus on Model Extraction and\nEvasion Attacks. Our findings reveal that adversarial attacks from powerful\nhost machines could be transferred to smaller, less secure devices like ESP32\nand Raspberry Pi. This illustrates that adversarial attacks could be extended\nto tiny devices, underscoring vulnerabilities, and emphasizing the necessity\nfor reinforced security measures in TinyML deployments. This exploration\nenhances the comprehension of security challenges in TinyML and offers insights\nfor safeguarding sensitive data and ensuring device dependability in AI-powered\nedge computing settings.",
      "tldr_zh": "本研究探讨了 TinyML 在资源受限嵌入式硬件上的安全漏洞，焦点在于模型提取和逃避攻击的可转移性。研究发现，从强大主机生成的对抗攻击可以成功转移到小型设备如 ESP32 和 Raspberry Pi，这暴露了 TinyML 系统的潜在风险。结果显示，这种攻击转移可能导致数据泄露和设备不可靠，强调了在 AI 边缘计算中加强安全措施的必要性。该工作提升了对 TinyML 安全挑战的理解，并为开发更可靠的防护策略提供了宝贵见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted and presented at tinyML Foundation EMEA Innovation Forum\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11599v2",
      "published_date": "2024-07-16 10:55:25 UTC",
      "updated_date": "2024-07-18 05:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:12:21.753870"
    },
    {
      "arxiv_id": "2407.11594v1",
      "title": "DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training",
      "title_zh": "DiNO-Diffusion：通过自监督预训练扩展医疗扩散模型",
      "authors": [
        "Guillermo Jimenez-Perez",
        "Pedro Osorio",
        "Josef Cersovsky",
        "Javier Montalt-Tordera",
        "Jens Hooge",
        "Steffen Vogler",
        "Sadegh Mohammadi"
      ],
      "abstract": "Diffusion models (DMs) have emerged as powerful foundation models for a\nvariety of tasks, with a large focus in synthetic image generation. However,\ntheir requirement of large annotated datasets for training limits their\napplicability in medical imaging, where datasets are typically smaller and\nsparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for\ntraining latent diffusion models (LDMs) that conditions the generation process\non image embeddings extracted from DiNO. By eliminating the reliance on\nannotations, our training leverages over 868k unlabelled images from public\nchest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows\ncomprehensive manifold coverage, with FID scores as low as 4.7, and emerging\nproperties when evaluated in downstream tasks. It can be used to generate\nsemantically-diverse synthetic datasets even from small data pools,\ndemonstrating up to 20% AUC increase in classification performance when used\nfor data augmentation. Images were generated with different sampling strategies\nover the DiNO embedding manifold and using real images as a starting point.\nResults suggest, DiNO-Diffusion could facilitate the creation of large datasets\nfor flexible training of downstream AI models from limited amount of real data,\nwhile also holding potential for privacy preservation. Additionally,\nDiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%\nDice score when evaluating lung lobe segmentation. This evidences good CXR\nimage-anatomy alignment, akin to segmenting using textual descriptors on\nvanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical\nimaging modalities or state-of-the-art diffusion models, opening the door for\nlarge-scale, multi-domain image generation pipelines for medical imaging.",
      "tldr_zh": "该研究提出 DiNO-Diffusion，一种自监督预训练方法，用于扩展医疗扩散模型（Diffusion models），通过 DiNO 提取的图像嵌入来条件生成过程，从而避免了对标注数据的依赖，仅利用超过 86.8 万张无标签胸部 X 光（CXR）图像进行训练。实验显示，该模型实现了全面的流形覆盖，FID 得分低至 4.7，并在数据增强任务中提升分类性能高达 20% AUC，甚至支持从小型数据池生成语义多样性合成数据集。DiNO-Diffusion 还展现了零样本分割能力，肺叶分割的 Dice 分数高达 84.4%，并可轻松适应其他医疗成像模式，促进大规模、多域图像生成和隐私保护。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.11594v1",
      "published_date": "2024-07-16 10:51:21 UTC",
      "updated_date": "2024-07-16 10:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:12:35.827271"
    },
    {
      "arxiv_id": "2407.11585v2",
      "title": "QVD: Post-training Quantization for Video Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shilong Tian",
        "Hong Chen",
        "Chengtao Lv",
        "Yu Liu",
        "Jinyang Guo",
        "Xianglong Liu",
        "Shengxi Li",
        "Hao Yang",
        "Tao Xie"
      ],
      "abstract": "Recently, video diffusion models (VDMs) have garnered significant attention\ndue to their notable advancements in generating coherent and realistic video\ncontent. However, processing multiple frame features concurrently, coupled with\nthe considerable model size, results in high latency and extensive memory\nconsumption, hindering their broader application. Post-training quantization\n(PTQ) is an effective technique to reduce memory footprint and improve\ncomputational efficiency. Unlike image diffusion, we observe that the temporal\nfeatures, which are integrated into all frame features, exhibit pronounced\nskewness. Furthermore, we investigate significant inter-channel disparities and\nasymmetries in the activation of video diffusion models, resulting in low\ncoverage of quantization levels by individual channels and increasing the\nchallenge of quantization. To address these issues, we introduce the first PTQ\nstrategy tailored for video diffusion models, dubbed QVD. Specifically, we\npropose the High Temporal Discriminability Quantization (HTDQ) method, designed\nfor temporal features, which retains the high discriminability of quantized\nfeatures, providing precise temporal guidance for all video frames. In\naddition, we present the Scattered Channel Range Integration (SCRI) method\nwhich aims to improve the coverage of quantization levels across individual\nchannels. Experimental validations across various models, datasets, and\nbit-width settings demonstrate the effectiveness of our QVD in terms of diverse\nmetrics. In particular, we achieve near-lossless performance degradation on\nW8A8, outperforming the current methods by 205.12 in FVD.",
      "tldr_zh": "该研究针对视频扩散模型（VDMs）的高延迟和内存消耗问题，提出了首个后训练量化（PTQ）策略QVD，以提高计算效率。QVD 包括 High Temporal Discriminability Quantization (HTDQ) 方法，用于保留时间特征的高区分性，提供精确的视频帧指导，以及 Scattered Channel Range Integration (SCRI) 方法，以改善通道量化水平的覆盖率。实验结果显示，QVD 在各种模型、数据集和位宽设置下表现出色，尤其在 W8A8 配置下，几乎无损性能，并使 FVD 指标比现有方法提升 205.12。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by ACMMM2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11585v2",
      "published_date": "2024-07-16 10:47:27 UTC",
      "updated_date": "2024-07-17 05:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:12:46.040227"
    },
    {
      "arxiv_id": "2407.11573v1",
      "title": "Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification",
      "title_zh": "探究联邦参数高效微调视觉Transformer在医疗图像分类",
      "authors": [
        "Naif Alkhunaizi",
        "Faris Almalik",
        "Rouqaiah Al-Refai",
        "Muzammal Naseer",
        "Karthik Nandakumar"
      ],
      "abstract": "With the advent of large pre-trained transformer models, fine-tuning these\nmodels for various downstream tasks is a critical problem. Paucity of training\ndata, the existence of data silos, and stringent privacy constraints exacerbate\nthis fine-tuning problem in the medical imaging domain, creating a strong need\nfor algorithms that enable collaborative fine-tuning of pre-trained models.\nMoreover, the large size of these models necessitates the use of\nparameter-efficient fine-tuning (PEFT) to reduce the communication burden in\nfederated learning. In this work, we systematically investigate various\nfederated PEFT strategies for adapting a Vision Transformer (ViT) model\n(pre-trained on a large natural image dataset) for medical image\nclassification. Apart from evaluating known PEFT techniques, we introduce new\nfederated variants of PEFT algorithms such as visual prompt tuning (VPT),\nlow-rank decomposition of visual prompts, stochastic block attention\nfine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.\nMoreover, we perform a thorough empirical analysis to identify the optimal PEFT\nmethod for the federated setting and understand the impact of data distribution\non federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key\ninsight of this study is that while most federated PEFT methods work well for\nin-domain transfer, there is a substantial accuracy vs. efficiency trade-off\nwhen dealing with OOD and non-IID scenarios, which is commonly the case in\nmedical imaging. Specifically, every order of magnitude reduction in\nfine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the\ninitial model choice is crucial for federated PEFT. It is preferable to use\nmedical foundation models learned from in-domain medical image data (if\navailable) rather than general vision models.",
      "tldr_zh": "这篇论文探讨了在联邦学习环境中，使用参数高效微调 (PEFT) 技术微调 Vision Transformers (ViT) 用于医疗图像分类的有效性，以应对数据稀缺、隐私约束和通信负担等问题。研究者系统评估了多种联邦 PEFT 策略，包括视觉提示调优 (VPT)、低秩分解提示、随机块注意力微调，以及混合方法如 LoRA + VPT，并引入了这些策略的联邦变体。实证分析显示，虽然这些方法适用于领域内转移，但在处理 Out-of-Domain (OOD) 和 Non-IID 数据时，准确率与效率存在显著权衡，每减少一个数量级的微调参数可能导致 4% 的准确率下降。最终，论文建议优先使用从医疗图像数据学到的基础模型，以优化联邦 PEFT 的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11573v1",
      "published_date": "2024-07-16 10:28:50 UTC",
      "updated_date": "2024-07-16 10:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:00.871883"
    },
    {
      "arxiv_id": "2407.11566v2",
      "title": "TGIF: Text-Guided Inpainting Forgery Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Hannes Mareen",
        "Dimitrios Karageorgiou",
        "Glenn Van Wallendael",
        "Peter Lambert",
        "Symeon Papadopoulos"
      ],
      "abstract": "Digital image manipulation has become increasingly accessible and realistic\nwith the advent of generative AI technologies. Recent developments allow for\ntext-guided inpainting, making sophisticated image edits possible with minimal\neffort. This poses new challenges for digital media forensics. For example,\ndiffusion model-based approaches could either splice the inpainted region into\nthe original image, or regenerate the entire image. In the latter case,\ntraditional image forgery localization (IFL) methods typically fail. This paper\nintroduces the Text-Guided Inpainting Forgery (TGIF) dataset, a comprehensive\ncollection of images designed to support the training and evaluation of image\nforgery localization and synthetic image detection (SID) methods. The TGIF\ndataset includes approximately 75k forged images, originating from popular\nopen-source and commercial methods, namely SD2, SDXL, and Adobe Firefly. We\nbenchmark several state-of-the-art IFL and SID methods on TGIF. Whereas\ntraditional IFL methods can detect spliced images, they fail to detect\nregenerated inpainted images. Moreover, traditional SID may detect the\nregenerated inpainted images to be fake, but cannot localize the inpainted\narea. Finally, both IFL and SID methods fail when exposed to stronger\ncompression, while they are less robust to modern compression algorithms, such\nas WEBP. In conclusion, this work demonstrates the inefficiency of\nstate-of-the-art detectors on local manipulations performed by modern\ngenerative approaches, and aspires to help with the development of more capable\nIFL and SID methods. The dataset and code can be downloaded at\nhttps://github.com/IDLabMedia/tgif-dataset.",
      "tldr_zh": "本论文引入了 TGIF 数据集，这是一个包含约 75k 张图像的综合集合，用于训练和评估图像伪造定位 (IFL) 和合成图像检测 (SID) 方法，针对文本引导图像修复技术的伪造挑战。数据集基于 SD2、SDXL 和 Adobe Firefly 等流行工具生成图像，包括拼接和再生类型伪造。基准测试结果显示，传统 IFL 方法能检测拼接图像但失败于再生图像，而 SID 方法虽能识别假图像却无法定位修复区域，且两者对 WEBP 等现代压缩算法不鲁棒。该工作强调了现有检测器的不足，并提供数据集和代码以推动更先进 IFL 和 SID 方法的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, accepted at IEEE WIFS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11566v2",
      "published_date": "2024-07-16 10:19:14 UTC",
      "updated_date": "2024-10-04 09:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:11.266730"
    },
    {
      "arxiv_id": "2407.11562v2",
      "title": "RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Fatemeh Zargarbashi",
        "Jin Cheng",
        "Dongho Kang",
        "Robert Sumner",
        "Stelian Coros"
      ],
      "abstract": "This paper presents a novel learning-based control framework that uses\nkeyframing to incorporate high-level objectives in natural locomotion for\nlegged robots. These high-level objectives are specified as a variable number\nof partial or complete pose targets that are spaced arbitrarily in time. Our\nproposed framework utilizes a multi-critic reinforcement learning algorithm to\neffectively handle the mixture of dense and sparse rewards. Additionally, it\nemploys a transformer-based encoder to accommodate a variable number of input\ntargets, each associated with specific time-to-arrivals. Throughout simulation\nand hardware experiments, we demonstrate that our framework can effectively\nsatisfy the target keyframe sequence at the required times. In the experiments,\nthe multi-critic method significantly reduces the effort of hyperparameter\ntuning compared to the standard single-critic alternative. Moreover, the\nproposed transformer-based architecture enables robots to anticipate future\ngoals, which results in quantitative improvements in their ability to reach\ntheir targets.",
      "tldr_zh": "本文提出了一种名为 RobotKeyframing 的学习控制框架，用于在腿部机器人中整合高层次目标，实现自然运动，这些目标以可变数量的部分或完整姿势关键帧形式指定在任意时间点。框架采用多批评家强化学习算法处理混合的 dense and sparse rewards，并使用 transformer-based encoder 来处理可变输入目标及其到达时间信息。实验结果表明，该框架在模拟和硬件环境中有效满足关键帧序列要求，显著减少超参数调整努力，并提升机器人的未来目标预见能力，从而提高目标到达的定量性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted to 8th Conference on Robot Learning\n  (CoRL 2024). Project website: https://sites.google.com/view/robot-keyframing",
      "pdf_url": "http://arxiv.org/pdf/2407.11562v2",
      "published_date": "2024-07-16 10:15:35 UTC",
      "updated_date": "2024-11-04 14:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:22.474781"
    },
    {
      "arxiv_id": "2407.11555v1",
      "title": "Self-Guided Generation of Minority Samples Using Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Soobin Um",
        "Jong Chul Ye"
      ],
      "abstract": "We present a novel approach for generating minority samples that live on\nlow-density regions of a data manifold. Our framework is built upon diffusion\nmodels, leveraging the principle of guided sampling that incorporates an\narbitrary energy-based guidance during inference time. The key defining feature\nof our sampler lies in its \\emph{self-contained} nature, \\ie, implementable\nsolely with a pretrained model. This distinguishes our sampler from existing\ntechniques that require expensive additional components (like external\nclassifiers) for minority generation. Specifically, we first estimate the\nlikelihood of features within an intermediate latent sample by evaluating a\nreconstruction loss w.r.t. its posterior mean. The generation then proceeds\nwith the minimization of the estimated likelihood, thereby encouraging the\nemergence of minority features in the latent samples of subsequent timesteps.\nTo further improve the performance of our sampler, we provide several\ntime-scheduling techniques that properly manage the influence of guidance over\ninference steps. Experiments on benchmark real datasets demonstrate that our\napproach can greatly improve the capability of creating realistic\nlow-likelihood minority instances over the existing techniques without the\nreliance on costly additional elements. Code is available at\n\\url{https://github.com/soobin-um/sg-minority}.",
      "tldr_zh": "本文提出了一种自引导(Self-Guided)方法，使用 diffusion models 生成位于数据流形低密度区域的少数样本。该框架通过 guided sampling 原则，在推理时加入 energy-based guidance，并利用重建损失估计中间潜在样本的似然，然后最小化该似然以鼓励后续时间步中少数特征的出现。为提升性能，该方法引入了多种时间调度(time-scheduling)技术。实验在基准真实数据集上证明，该方法显著提高了生成真实低似然少数实例的能力，而无需依赖额外的外部组件。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11555v1",
      "published_date": "2024-07-16 10:03:29 UTC",
      "updated_date": "2024-07-16 10:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:35.279775"
    },
    {
      "arxiv_id": "2407.11553v2",
      "title": "Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An Image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Tang",
        "Tianyao Ji",
        "Wenhu Tang"
      ],
      "abstract": "As modern power systems continue to evolve, accurate power load forecasting\nremains a critical issue in energy management. The phase space reconstruction\nmethod can effectively retain the inner chaotic property of power load from a\nsystem dynamics perspective and thus is a promising knowledge-based\npreprocessing method for short-term forecasting. In order to fully utilize the\ncapability of PSR method to model the non-stationary characteristics within\npower load, and to solve the problem of the difficulty in applying traditional\nPSR prediction methods to form a general multi-step forecasting scheme, this\nstudy proposes a novel multi-step forecasting approach by delicately\nintegrating the PSR with neural networks to establish an end-to-end learning\nsystem. Firstly, the useful features in the phase trajectory are discussed in\ndetail. Through mathematical derivation, the equivalent characterization of the\nPSR and another time series preprocessing method, patch segmentation, is\ndemonstrated for the first time. Based on this knowledge, an image-based\nmodeling perspective is introduced. Subsequently, a novel deep learning model,\nnamely PSR-GALIEN, is designed, in which the Transformer Encoder and 2D-CNN are\nemployed for the extraction of the global and local patterns in the image, and\na MLP-based predictor is used for the efficient correlation modeling. Then,\nextensive experiments are conducted on five real-world benchmark datasets to\nverify the effectiveness of the PSR-GALIEN. The results show that, compared\nwith six state-of-the-art deep learning models, the forecasting performance of\nPSR-GALIEN consistently surpasses these baselines, achieving superior accuracy\nin both intra-day and day-ahead forecasting scenarios. At the same time, the\nattributions of its forecasting results can be explained through the\nvisualization-based method, which significantly increases the interpretability.",
      "tldr_zh": "本文提出一种新型多步电力负载预测方法，通过整合相空间重构（PSR）与神经网络，建立端到端学习系统，以处理电力负载的非平稳和混沌特性。PSR-GALIEN模型利用Transformer Encoder提取全局模式、2D-CNN提取局部特征，并通过MLP进行相关性建模，同时证明了PSR与patch segmentation的等效性。实验结果显示，在五个真实数据集上，该方法比六种先进深度学习模型更准确，并在短期和日预测场景中提升性能，同时通过可视化增强了结果的可解释性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11553v2",
      "published_date": "2024-07-16 09:59:13 UTC",
      "updated_date": "2024-07-28 16:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:46.641022"
    },
    {
      "arxiv_id": "2407.11550v4",
      "title": "Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Feng",
        "Junlin Lv",
        "Yukun Cao",
        "Xike Xie",
        "S. Kevin Zhou"
      ],
      "abstract": "Large Language Models have excelled in various domains but face efficiency\nchallenges due to the growing Key-Value (KV) cache required for long-sequence\ninference. Recent efforts aim to reduce KV cache size by evicting vast\nnon-critical cache elements during runtime while preserving generation quality.\nHowever, these methods typically allocate compression budgets uniformly across\nall attention heads, ignoring the unique attention patterns of each head. In\nthis paper, we establish a theoretical loss upper bound between pre- and\npost-eviction attention output, explaining the optimization target of prior\ncache eviction methods, while guiding the optimization of adaptive budget\nallocation. Base on this, we propose {\\it Ada-KV}, the first head-wise adaptive\nbudget allocation strategy. It offers plug-and-play benefits, enabling seamless\nintegration with prior cache eviction methods. Extensive evaluations on 13\ndatasets from Ruler and 16 datasets from LongBench, all conducted under both\nquestion-aware and question-agnostic scenarios, demonstrate substantial quality\nimprovements over existing methods.",
      "tldr_zh": "本文提出Ada-KV，一种针对大语言模型(LLMs)长序列推理的优化框架，通过自适应预算分配策略来优化Key-Value (KV) cache驱逐过程，以解决现有方法在attention heads上均匀分配预算的局限性。Ada-KV基于理论损失上限分析，实现了头-wise的自适应预算分配，并支持即插即用地集成到现有缓存驱逐方法中。实验结果显示，在13个Ruler数据集和16个LongBench数据集上的评估中，Ada-KV在question-aware和question-agnostic场景下均显著提升了生成质量，超过了基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11550v4",
      "published_date": "2024-07-16 09:53:32 UTC",
      "updated_date": "2025-01-26 07:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:13:59.212914"
    },
    {
      "arxiv_id": "2407.11549v2",
      "title": "How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Jou Huang",
        "Rafik Hadfi"
      ],
      "abstract": "Psychological evidence reveals the influence of personality traits on\ndecision-making. For instance, agreeableness is generally associated with\npositive outcomes in negotiations, whereas neuroticism is often linked to less\nfavorable outcomes. This paper introduces a simulation framework centered on\nLarge Language Model (LLM) agents endowed with synthesized personality traits.\nThe agents negotiate within bargaining domains and possess customizable\npersonalities and objectives. The experimental results show that the behavioral\ntendencies of LLM-based simulations could reproduce behavioral patterns\nobserved in human negotiations. The contribution is twofold. First, we propose\na simulation methodology that investigates the alignment between the linguistic\nand economic capabilities of LLM agents. Secondly, we offer empirical insights\ninto the strategic impact of Big-Five personality traits on the outcomes of\nbilateral negotiations. We also provide a case study based on synthesized\nbargaining dialogues to reveal intriguing behaviors, including deceitful and\ncompromising behaviors.",
      "tldr_zh": "这篇论文探讨了人格特质如何影响谈判结果，通过基于 Large Language Models (LLM) 的模拟框架来研究这一问题。研究者创建了具有合成的 Big-Five 人格特质的 LLM 代理，让它们在谈判领域进行模拟，实验结果显示这些代理的行为倾向能再现人类谈判中的模式，如欺骗和妥协行为。主要贡献包括提出一种评估 LLM 语言和经济能力的模拟方法，并提供实证洞见，揭示人格特质对双边谈判结果的战略影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11549v2",
      "published_date": "2024-07-16 09:52:51 UTC",
      "updated_date": "2024-11-02 16:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:14:10.214695"
    },
    {
      "arxiv_id": "2407.11537v1",
      "title": "AEMIM: Adversarial Examples Meet Masked Image Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Wenzhao Xiang",
        "Chang Liu",
        "Hang Su",
        "Hongyang Yu"
      ],
      "abstract": "Masked image modeling (MIM) has gained significant traction for its\nremarkable prowess in representation learning. As an alternative to the\ntraditional approach, the reconstruction from corrupted images has recently\nemerged as a promising pretext task. However, the regular corrupted images are\ngenerated using generic generators, often lacking relevance to the specific\nreconstruction task involved in pre-training. Hence, reconstruction from\nregular corrupted images cannot ensure the difficulty of the pretext task,\npotentially leading to a performance decline. Moreover, generating corrupted\nimages might introduce an extra generator, resulting in a notable computational\nburden. To address these issues, we propose to incorporate adversarial examples\ninto masked image modeling, as the new reconstruction targets. Adversarial\nexamples, generated online using only the trained models, can directly aim to\ndisrupt tasks associated with pre-training. Therefore, the incorporation not\nonly elevates the level of challenge in reconstruction but also enhances\nefficiency, contributing to the acquisition of superior representations by the\nmodel. In particular, we introduce a novel auxiliary pretext task that\nreconstructs the adversarial examples corresponding to the original images. We\nalso devise an innovative adversarial attack to craft more suitable adversarial\nexamples for MIM pre-training. It is noted that our method is not restricted to\nspecific model architectures and MIM strategies, rendering it an adaptable\nplug-in capable of enhancing all MIM methods. Experimental findings\nsubstantiate the remarkable capability of our approach in amplifying the\ngeneralization and robustness of existing MIM methods. Notably, our method\nsurpasses the performance of baselines on various tasks, including ImageNet,\nits variants, and other downstream tasks.",
      "tldr_zh": "本文提出 AEMIM 方法，将 Adversarial Examples 整合到 Masked Image Modeling (MIM) 中，作为新的重建目标，以解决传统 MIM 使用常规损坏图像导致的任务难度不足和计算负担问题。方法包括引入一个辅助预训练任务——重建原始图像对应的对抗样本，并设计创新的对抗攻击策略，使对抗样本更适合 MIM 预训练。该方法作为通用插件，不受特定模型或策略限制，能显著提升现有 MIM 方法的泛化性和鲁棒性，并在 ImageNet 及其变体等下游任务上超越基线性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review of International Journal of Computer Vision (IJCV)",
      "pdf_url": "http://arxiv.org/pdf/2407.11537v1",
      "published_date": "2024-07-16 09:39:13 UTC",
      "updated_date": "2024-07-16 09:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:14:22.425805"
    },
    {
      "arxiv_id": "2407.11536v1",
      "title": "Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise",
      "title_zh": "微调医疗语言模型以增强长上下文理解和领域专业知识",
      "authors": [
        "Qimin Yang",
        "Rongsheng Wang",
        "Jiexin Chen",
        "Runqi Su",
        "Tao Tan"
      ],
      "abstract": "Large Language Models (LLMs) have been widely applied in various professional\nfields. By fine-tuning the models using domain specific question and answer\ndatasets, the professional domain knowledge and Q\\&A abilities of these models\nhave significantly improved, for example, medical professional LLMs that use\nfine-tuning of doctor-patient Q\\&A data exhibit extraordinary disease\ndiagnostic abilities. However, we observed that despite improvements in\nspecific domain knowledge, the performance of medical LLM in long-context\nunderstanding has significantly declined, especially compared to general\nlanguage models with similar parameters. The purpose of this study is to\ninvestigate the phenomenon of reduced performance in understanding long-context\nin medical LLM. We designed a series of experiments to conduct open-book\nprofessional knowledge exams on all models to evaluate their ability to read\nlong-context. By adjusting the proportion and quantity of general data and\nmedical data in the process of fine-tuning, we can determine the best data\ncomposition to optimize the professional model and achieve a balance between\nlong-context performance and specific domain knowledge.",
      "tldr_zh": "本研究探讨了fine-tuning医疗LLMs时，专业领域知识提升但长上下文理解能力显著下降的现象。研究者通过设计实验，包括开放式专业知识考试，评估模型在长上下文阅读方面的表现，并调整fine-tuning过程中一般数据和医疗数据的比例。结果显示，这种优化方法能有效平衡长上下文性能与特定领域专长，最终确定了最佳数据组合，以提升医疗LLMs的整体效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 1 figure. Accepted by the Workshop on Long-Context\n  Foundation Models (LCFM) at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11536v1",
      "published_date": "2024-07-16 09:37:20 UTC",
      "updated_date": "2024-07-16 09:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:14:34.809666"
    },
    {
      "arxiv_id": "2407.12880v1",
      "title": "Cross-Modal Augmentation for Few-Shot Multimodal Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Jiang",
        "Taihang Wang",
        "Xiaoman Xu",
        "Yimin Wang",
        "Xingyi Song",
        "Diana Maynard"
      ],
      "abstract": "The nascent topic of fake news requires automatic detection methods to\nquickly learn from limited annotated samples. Therefore, the capacity to\nrapidly acquire proficiency in a new task with limited guidance, also known as\nfew-shot learning, is critical for detecting fake news in its early stages.\nExisting approaches either involve fine-tuning pre-trained language models\nwhich come with a large number of parameters, or training a complex neural\nnetwork from scratch with large-scale annotated datasets. This paper presents a\nmultimodal fake news detection model which augments multimodal features using\nunimodal features. For this purpose, we introduce Cross-Modal Augmentation\n(CMA), a simple approach for enhancing few-shot multimodal fake news detection\nby transforming n-shot classification into a more robust (n $\\times$ z)-shot\nproblem, where z represents the number of supplementary features. The proposed\nCMA achieves SOTA results over three benchmark datasets, utilizing a\nsurprisingly simple linear probing method to classify multimodal fake news with\nonly a few training samples. Furthermore, our method is significantly more\nlightweight than prior approaches, particularly in terms of the number of\ntrainable parameters and epoch times. The code is available here:\n\\url{https://github.com/zgjiangtoby/FND_fewshot}",
      "tldr_zh": "这篇论文针对假新闻检测的few-shot learning挑战，提出了一种Cross-Modal Augmentation (CMA)方法，通过利用单模态特征增强多模态特征，将n-shot分类问题转化为更鲁棒的(n × z)-shot问题，从而提高检测性能。CMA采用简单的线性探测方法，仅需少量训练样本，即在三个基准数据集上达到了SOTA结果。相比现有方法，该模型显著更轻量级，具有更少的训练参数和更短的训练时间，并提供了开源代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12880v1",
      "published_date": "2024-07-16 09:32:11 UTC",
      "updated_date": "2024-07-16 09:32:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:14:47.284074"
    },
    {
      "arxiv_id": "2407.11534v2",
      "title": "LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices",
      "title_zh": "LRQ：通过学习低秩权重缩放矩阵优化大型语言模型的训练后量化",
      "authors": [
        "Jung Hyun Lee",
        "Jeonghoon Kim",
        "June Yong Yang",
        "Se Jung Kwon",
        "Eunho Yang",
        "Kang Min Yoo",
        "Dongsoo Lee"
      ],
      "abstract": "With the commercialization of large language models (LLMs), weight-activation\nquantization has emerged to compress and accelerate LLMs, achieving high\nthroughput while reducing inference costs. However, existing post-training\nquantization (PTQ) techniques for quantizing weights and activations of LLMs\nstill suffer from non-negligible accuracy drops, especially on massive\nmultitask language understanding. To address this issue, we propose Low-Rank\nQuantization (LRQ) - a simple yet effective post-training weight quantization\nmethod for LLMs that reconstructs the outputs of an intermediate Transformer\nblock by leveraging low-rank weight-scaling matrices, replacing the\nconventional full weight-scaling matrices that entail as many learnable scales\nas their associated weights. Thanks to parameter sharing via low-rank\nstructure, LRQ only needs to learn significantly fewer parameters while\nenabling the individual scaling of weights, thus boosting the generalization\ncapability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ\nworks under (i) 8-bit weight and per-tensor activation quantization, (ii) 4-bit\nweight and 8-bit per-token activation quantization, and (iii) low-bit\nweight-only quantization schemes. Our code is available at Software.",
      "tldr_zh": "该论文提出了一种名为LRQ的优化方法，用于改进大型语言模型(LLMs)的后训练量化(PTQ)，通过学习低秩权重缩放矩阵来减少参数数量并提升模型准确性。LRQ通过替换传统的全权重缩放矩阵，利用低秩结构实现参数共享，从而在量化权重和激活时，仅需学习更少的参数，同时保持权重的独立缩放，以增强量化LLMs的泛化能力。实验结果显示，LRQ在多种方案下（如8-bit权重和per-tensor激活量化、4-bit权重和8-bit per-token激活量化，以及低bit权重-only量化）均优于现有PTQ方法，显著降低了准确性下降的风险。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the main conference at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.11534v2",
      "published_date": "2024-07-16 09:32:07 UTC",
      "updated_date": "2025-02-09 04:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:15:00.339933"
    },
    {
      "arxiv_id": "2407.11529v1",
      "title": "Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans",
      "title_zh": "翻译失败",
      "authors": [
        "Bizhe Bai",
        "Yan-Jie Zhou",
        "Yujian Hu",
        "Tony C. W. Mok",
        "Yilang Xiang",
        "Le Lu",
        "Hongkun Zhang",
        "Minfeng Xu"
      ],
      "abstract": "Pulmonary embolism (PE) is a life-threatening condition where rapid and\naccurate diagnosis is imperative yet difficult due to predominantly atypical\nsymptomatology. Computed tomography pulmonary angiography (CTPA) is\nacknowledged as the gold standard imaging tool in clinics, yet it can be\ncontraindicated for emergency department (ED) patients and represents an\nonerous procedure, thus necessitating PE identification through non-contrast CT\n(NCT) scans. In this work, we explore the feasibility of applying a\ndeep-learning approach to NCT scans for PE identification. We propose a novel\nCross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer\nfrom CTPA to NCT, while concurrently conducting embolism segmentation and\nabnormality classification in a multi-task manner. The proposed CPMN leverages\nthe Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and\nmutual learning between the dual-pathway network, while the Intra-Feature\nDiscrepancy (IFD) strategy can facilitate precise segmentation of PE against\ncomplex backgrounds for single-pathway networks. For a comprehensive assessment\nof the proposed approach, a large-scale dual-phase dataset containing 334 PE\npatients and 1,105 normal subjects has been established. Experimental results\ndemonstrate that CPMN achieves the leading identification performance, which is\n95.4\\% and 99.6\\% in patient-level sensitivity and specificity on NCT scans,\nindicating the potential of our approach as an economical, accessible, and\nprecise tool for PE identification in clinical practice.",
      "tldr_zh": "本研究探讨了使用非对比 CT (NCT) 扫描识别肺栓塞 (PE) 的可行性，以解决传统金标准 CT 肺动脉造影 (CTPA) 的局限性。作者提出 Cross-Phase Mutual Learning framework (CPMN)，通过从 CTPA 向 NCT 转移知识，并结合 Inter-Feature Alignment (IFA) 和 Intra-Feature Discrepancy (IFD) 策略，实现栓塞分割和异常分类的多任务学习。实验在包含 334 名 PE 患者和 1,105 名正常受试者的数据集上显示，CPMN 在 NCT 扫描上达到 95.4% 患者级敏感性和 99.6% 特异性，证明了其作为临床中经济、可靠的 PE 识别工具的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Early accept by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11529v1",
      "published_date": "2024-07-16 09:29:33 UTC",
      "updated_date": "2024-07-16 09:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:15:13.792022"
    },
    {
      "arxiv_id": "2407.12879v4",
      "title": "Large Visual-Language Models Are Also Good Classifiers: A Study of In-Context Multimodal Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Jiang",
        "Yimin Wang"
      ],
      "abstract": "Large visual-language models (LVLMs) exhibit exceptional performance in\nvisual-language reasoning across diverse cross-modal benchmarks. Despite these\nadvances, recent research indicates that Large Language Models (LLMs), like\nGPT-3.5-turbo, underachieve compared to well-trained smaller models, such as\nBERT, in Fake News Detection (FND), prompting inquiries into LVLMs' efficacy in\nFND tasks. Although performance could improve through fine-tuning LVLMs, the\nsubstantial parameters and requisite pre-trained weights render it a\nresource-heavy endeavor for FND applications. This paper initially assesses the\nFND capabilities of two notable LVLMs, CogVLM and GPT4V, in comparison to a\nsmaller yet adeptly trained CLIP model in a zero-shot context. The findings\ndemonstrate that LVLMs can attain performance competitive with that of the\nsmaller model. Next, we integrate standard in-context learning (ICL) with\nLVLMs, noting improvements in FND performance, though limited in scope and\nconsistency. To address this, we introduce the \\textbf{I}n-context\n\\textbf{M}ultimodal \\textbf{F}ake \\textbf{N}ews \\textbf{D}etection (IMFND)\nframework, enriching in-context examples and test inputs with predictions and\ncorresponding probabilities from a well-trained smaller model. This strategic\nintegration directs the LVLMs' focus towards news segments associated with\nhigher probabilities, thereby improving their analytical accuracy. The\nexperimental results suggest that the IMFND framework significantly boosts the\nFND efficiency of LVLMs, achieving enhanced accuracy over the standard ICL\napproach across three publicly available FND datasets.",
      "tldr_zh": "本研究评估了大型视觉语言模型 (LVLMs) 如 CogVLM 和 GPT4V 在多模态假新闻检测 (FND) 任务中的性能，发现它们在零样本设置下可与训练好的小模型（如 CLIP）竞争。论文首先探索了标准 in-context learning (ICL) 的应用，但其改进效果有限。随后，提出 IMFND 框架，通过整合小模型的预测概率来丰富上下文示例和测试输入，指导 LVLMs 关注高置信度新闻段落，从而提升分析准确性。实验结果显示，IMFND 框架显著提高了 LVLMs 在三个公开 FND 数据集上的准确性，超越了标准 ICL 方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Withdraw for new experiments",
      "pdf_url": "http://arxiv.org/pdf/2407.12879v4",
      "published_date": "2024-07-16 09:28:23 UTC",
      "updated_date": "2025-04-16 00:26:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:15:25.206029"
    },
    {
      "arxiv_id": "2407.12068v2",
      "title": "Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness",
      "title_zh": "基于大型语言模型(LLMs)的图学习：对模型鲁棒性的深入探讨",
      "authors": [
        "Kai Guo",
        "Zewen Liu",
        "Zhikai Chen",
        "Hongzhi Wen",
        "Wei Jin",
        "Jiliang Tang",
        "Yi Chang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language processing tasks. Recently, several LLMs-based\npipelines have been developed to enhance learning on graphs with text\nattributes, showcasing promising performance. However, graphs are well-known to\nbe susceptible to adversarial attacks and it remains unclear whether LLMs\nexhibit robustness in learning on graphs. To address this gap, our work aims to\nexplore the potential of LLMs in the context of adversarial attacks on graphs.\nSpecifically, we investigate the robustness against graph structural and\ntextual perturbations in terms of two dimensions: LLMs-as-Enhancers and\nLLMs-as-Predictors. Through extensive experiments, we find that, compared to\nshallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior\nrobustness against structural and textual attacks.Based on these findings, we\ncarried out additional analyses to investigate the underlying causes.\nFurthermore, we have made our benchmark library openly available to facilitate\nquick and fair evaluations, and to encourage ongoing innovative research in\nthis field.",
      "tldr_zh": "本研究深入探讨了Large Language Models (LLMs)在图学习中的鲁棒性，针对图结构和文本属性的对抗性攻击进行评估。研究从LLMs-as-Enhancers和LLMs-as-Predictors两个维度开展广泛实验，发现LLMs比浅层模型表现出更强的抵抗力，并分析了其潜在原因。最终，论文公开了基准库，以支持公平评估和进一步创新。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12068v2",
      "published_date": "2024-07-16 09:05:31 UTC",
      "updated_date": "2024-07-28 16:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:15:35.695625"
    },
    {
      "arxiv_id": "2407.12878v3",
      "title": "Do LLMs have Consistent Values?",
      "title_zh": "翻译失败",
      "authors": [
        "Naama Rozen",
        "Liat Bezalel",
        "Gal Elidan",
        "Amir Globerson",
        "Ella Daniel"
      ],
      "abstract": "Large Language Models (LLM) technology is constantly improving towards\nhuman-like dialogue. Values are a basic driving force underlying human\nbehavior, but little research has been done to study the values exhibited in\ntext generated by LLMs. Here we study this question by turning to the rich\nliterature on value structure in psychology. We ask whether LLMs exhibit the\nsame value structure that has been demonstrated in humans, including the\nranking of values, and correlation between values. We show that the results of\nthis analysis depend on how the LLM is prompted, and that under a particular\nprompting strategy (referred to as \"Value Anchoring\") the agreement with human\ndata is quite compelling. Our results serve both to improve our understanding\nof values in LLMs, as well as introduce novel methods for assessing consistency\nin LLM responses.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在文本生成中是否表现出与人类相似的价值结构，包括价值的排名和相关性。研究者参考心理学文献，通过不同提示策略测试LLMs的表现，发现结果高度依赖于提示方式。特别地，采用“Value Anchoring”提示策略时，LLMs的输出与人类数据高度一致。该工作不仅加深了对LLMs中价值的一致性理解，还引入了评估LLMs响应一致性的新方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 4 figures, and there are more in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2407.12878v3",
      "published_date": "2024-07-16 08:58:00 UTC",
      "updated_date": "2024-10-15 07:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:15:47.288290"
    },
    {
      "arxiv_id": "2407.11511v1",
      "title": "Reasoning with Large Language Models, a Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Aske Plaat",
        "Annie Wong",
        "Suzan Verberne",
        "Joost Broekens",
        "Niki van Stein",
        "Thomas Back"
      ],
      "abstract": "Scaling up language models to billions of parameters has opened up\npossibilities for in-context learning, allowing instruction tuning and few-shot\nlearning on tasks that the model was not specifically trained for. This has\nachieved breakthrough performance on language tasks such as translation,\nsummarization, and question-answering. Furthermore, in addition to these\nassociative \"System 1\" tasks, recent advances in Chain-of-thought prompt\nlearning have demonstrated strong \"System 2\" reasoning abilities, answering a\nquestion in the field of artificial general intelligence whether LLMs can\nreason. The field started with the question whether LLMs can solve grade school\nmath word problems. This paper reviews the rapidly expanding field of\nprompt-based reasoning with LLMs. Our taxonomy identifies different ways to\ngenerate, evaluate, and control multi-step reasoning. We provide an in-depth\ncoverage of core approaches and open problems, and we propose a research agenda\nfor the near future. Finally, we highlight the relation between reasoning and\nprompt-based learning, and we discuss the relation between reasoning,\nsequential decision processes, and reinforcement learning. We find that\nself-improvement, self-reflection, and some metacognitive abilities of the\nreasoning processes are possible through the judicious use of prompts. True\nself-improvement and self-reasoning, to go from reasoning with LLMs to\nreasoning by LLMs, remains future work.",
      "tldr_zh": "这篇调查论文回顾了大型语言模型（LLMs）在推理方面的进展，强调通过 in-context learning 和 Chain-of-thought 提示学习，LLMs 实现了在翻译、总结和问答等任务上的突破性性能，以及在多步推理（System 2）方面的强大能力。论文提出了一个分类法，用于生成、评估和控制多步推理的方法，并讨论了核心方法、开放问题以及与顺序决策过程和强化学习的关联。最终，它指出通过提示可以实现 LLMs 的自我改进和自我反思，但真正的自我推理仍需未来的研究工作。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11511v1",
      "published_date": "2024-07-16 08:49:35 UTC",
      "updated_date": "2024-07-16 08:49:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:16:00.525740"
    },
    {
      "arxiv_id": "2407.11501v1",
      "title": "Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Ren",
        "Haiteng Wang",
        "Yuanjun Laili"
      ],
      "abstract": "Industrial Multivariate Time Series (MTS) is a critical view of the\nindustrial field for people to understand the state of machines. However, due\nto data collection difficulty and privacy concerns, available data for building\nindustrial intelligence and industrial large models is far from sufficient.\nTherefore, industrial time series data generation is of great importance.\nExisting research usually applies Generative Adversarial Networks (GANs) to\ngenerate MTS. However, GANs suffer from unstable training process due to the\njoint training of the generator and discriminator. This paper proposes a\ntemporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for\nMTS generation. It aims to better handle the complex temporal dependencies and\ndynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean\nDiscrepancy (Ada-MMD) method has been proposed for the controlled generation of\nMTS, which does not require a classifier to control the generation. It improves\nthe condition consistency of the diffusion model. Moreover, a Temporal\nDecomposition Reconstruction UNet (TDR-UNet) is established to capture complex\ntemporal patterns and further improve the quality of the synthetic time series.\nComprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that\nthe proposed Diff-MTS performs substantially better in terms of diversity,\nfidelity, and utility compared with GAN-based methods. These results show that\nDiff-MTS facilitates the generation of industrial data, contributing to\nintelligent maintenance and the construction of industrial large models.",
      "tldr_zh": "本论文针对工业多变量时间序列 (MTS) 数据生成问题，提出了一种基于扩散模型的框架 Diff-MTS，以解决现有 GANs 方法训练不稳定的局限性，并更好地处理 MTS 的复杂时间依赖性。具体而言，Diff-MTS 引入条件 Adaptive Maximum-Mean Discrepancy (Ada-MMD) 方法来提升生成过程的条件一致性，以及 Temporal Decomposition Reconstruction UNet (TDR-UNet) 来捕捉复杂的时间模式，从而提高合成数据的质量。在 C-MAPSS 和 FEMTO 数据集上的实验显示，Diff-MTS 在多样性、逼真度和实用性方面显著优于 GAN-based 方法，有助于促进工业数据生成、智能化维护以及工业大型模型的构建。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages,4 figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.11501v1",
      "published_date": "2024-07-16 08:38:40 UTC",
      "updated_date": "2024-07-16 08:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:16:12.849478"
    },
    {
      "arxiv_id": "2407.11500v1",
      "title": "An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Niamh Belton",
        "Aonghus Lawlor",
        "Kathleen M. Curran"
      ],
      "abstract": "The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)\nordinal grading systems has been a subject of on-going debate and concern.\nExisting automated solutions are trained to emulate these imperfect systems,\nwhilst also being reliant on large annotated databases for fully-supervised\ntraining. This work proposes a three stage approach for automated continuous\ngrading of knee OA that is built upon the principles of Anomaly Detection (AD);\nlearning a robust representation of healthy knee X-rays and grading disease\nseverity based on its distance to the centre of normality. In the first stage,\nSS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'\nrepresentation, requiring only examples of healthy subjects and <3% of the\nlabels that existing methods require. In the second stage, this model is used\nto pseudo label a subset of unlabelled data as 'normal' or 'anomalous',\nfollowed by denoising of pseudo labels with CLIP. The final stage involves\nretraining on labelled and pseudo labelled data using the proposed Dual Centre\nRepresentation Learning (DCRL) which learns the centres of two representation\nspaces; normal and anomalous. Disease severity is then graded based on the\ndistance to the learned centres. The proposed methodology outperforms existing\ntechniques by margins of up to 24% in terms of OA detection and the disease\nseverity scores correlate with the Kellgren-Lawrence grading system at the same\nlevel as human expert performance. Code available at\nhttps://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.",
      "tldr_zh": "这篇论文提出了一种AI系统，用于膝关节骨关节炎（Knee Osteoarthritis, OA）的连续严重程度分级，采用自监督异常检测（Self-Supervised Anomaly Detection）方法，仅需少量数据（如健康样本和<3%的标签）来学习正常表示，从而解决现有系统依赖大量标注数据的局限性。系统分为三阶段：首先，使用SS-FewSOME技术训练正常膝部X光表示；其次，对未标注数据进行伪标签并通过CLIP去噪；最后，应用Dual Centre Representation Learning (DCRL)重新训练，基于距离到正常和异常中心的测量来评估疾病严重程度。实验结果显示，该方法在OA检测上比现有技术提高24%，其严重程度评分与Kellgren-Lawrence grading system的相关性达到了人类专家水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11500v1",
      "published_date": "2024-07-16 08:37:33 UTC",
      "updated_date": "2024-07-16 08:37:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:16:26.460707"
    },
    {
      "arxiv_id": "2407.12877v2",
      "title": "ReFeR: Improving Evaluation and Reasoning through Hierarchy of Models",
      "title_zh": "ReFeR：通过模型的层次结构改进评估和推理",
      "authors": [
        "Yaswanth Narsupalli",
        "Abhranil Chandra",
        "Sreevatsa Muppirala",
        "Manish Gupta",
        "Pawan Goyal"
      ],
      "abstract": "Assessing the quality of outputs generated by generative models, such as\nlarge language models and vision language models, presents notable challenges.\nTraditional methods for evaluation typically rely on either human assessments,\nwhich are resource-intensive, or automatic metrics that often show a low\ncorrelation with human judgment. Another common approach is to use deep\nlearning systems, which not only consume a substantial amount of compute and\ntime but also require extensive training data. In this study, we introduce a\ntuning-free framework called ReFeR, designed to evaluate generative outputs,\nincluding both text and images, by leveraging a 2-level hierarchy of LLMs and\nVLMs themselves. We rigorously evaluate our framework, ReFeR, across four\ndiverse evaluation tasks. The framework not only improves the accuracy of these\nevaluations, surpassing previous benchmarks but also generates constructive\nfeedback. Interestingly, the framework is also applicable to reasoning tasks.\nExperiments on four reasoning tasks demonstrate superior collective reasoning\nabilities of the framework. We present two variants of the framework:\nReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a\nmore cost-effective solution. ReFeR-Lite is $\\sim7.7\\times$ more efficient\nwhile being comparably accurate to ReFeR-Turbo. We make code, data and PIP\npackage publicly available. See this PIP URL\nhttps://pypi.org/project/refer-agents/ and this Git URL\nhttps://github.com/yaswanth-iitkgp/ReFeR_Code .",
      "tldr_zh": "该论文提出了 ReFeR，一种无需调优的框架，通过 LLMs 和 VLMs 的 2 级层次结构，改善生成模型（如大型语言模型和视觉语言模型）输出的评估，解决了传统方法（如人力评估或自动指标）的资源和准确性问题。ReFeR 在四个评估任务上超越了现有基准，不仅提升了评估准确性，还能生成建设性反馈，并扩展到推理任务中，展示了优越的集体推理能力。框架提供两个变体：ReFeR-Turbo 优化加速性能，以及更高效的 ReFeR-Lite，后者效率提高约 7.7 倍，同时保持可比准确性；作者公开了代码、数据和 PIP 包以促进应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper Under Review",
      "pdf_url": "http://arxiv.org/pdf/2407.12877v2",
      "published_date": "2024-07-16 08:25:26 UTC",
      "updated_date": "2024-10-09 17:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:16:36.750210"
    },
    {
      "arxiv_id": "2407.11489v1",
      "title": "A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Lu",
        "Patrick Mannion",
        "Karl Mason"
      ],
      "abstract": "Effective residential appliance scheduling is crucial for sustainable living.\nWhile multi-objective reinforcement learning (MORL) has proven effective in\nbalancing user preferences in appliance scheduling, traditional MORL struggles\nwith limited data in non-stationary residential settings characterized by\nrenewable generation variations. Significant context shifts that can invalidate\npreviously learned policies. To address these challenges, we extend\nstate-of-the-art MORL algorithms with the meta-learning paradigm, enabling\nrapid, few-shot adaptation to shifting contexts. Additionally, we employ an\nauto-encoder (AE)-based unsupervised method to detect environment context\nchanges. We have also developed a residential energy environment to evaluate\nour method using real-world data from London residential settings. This study\nnot only assesses the application of MORL in residential appliance scheduling\nbut also underscores the effectiveness of meta-learning in energy management.\nOur top-performing method significantly surpasses the best baseline, while the\ntrained model saves 3.28% on electricity bills, a 2.74% increase in user\ncomfort, and a 5.9% improvement in expected utility. Additionally, it reduces\nthe sparsity of solutions by 62.44%. Remarkably, these gains were accomplished\nusing 96.71% less training data and 61.1% fewer training steps.",
      "tldr_zh": "这篇论文提出了一种将元学习（Meta-Learning）整合到多目标强化学习（MORL）中的方法，用于可持续家居环境的家电调度，以解决传统 MORL 在数据有限和非平稳环境（如可再生能源变化）中的适应性问题。方法包括使用基于自编码器（AE）的无监督技术检测环境变化，并开发了一个基于伦敦真实数据的住宅能源模拟环境进行评估。该方法显著优于基线模型，节省3.28%电费、提高2.74%用户舒适度以及5.9%预期效用，同时减少62.44%解决方案稀疏度，并以96.71%更少的训练数据和61.1%更少的训练步骤实现这些成果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11489v1",
      "published_date": "2024-07-16 08:23:20 UTC",
      "updated_date": "2024-07-16 08:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:16:50.048599"
    },
    {
      "arxiv_id": "2407.11484v9",
      "title": "The Oscars of AI Theater: A Survey on Role-Playing with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nuo Chen",
        "Yan Wang",
        "Yang Deng",
        "Jia Li"
      ],
      "abstract": "This survey explores the burgeoning field of role-playing with language\nmodels, focusing on their development from early persona-based models to\nadvanced character-driven simulations facilitated by Large Language Models\n(LLMs). Initially confined to simple persona consistency due to limited model\ncapabilities, role-playing tasks have now expanded to embrace complex character\nportrayals involving character consistency, behavioral alignment, and overall\nattractiveness. We provide a comprehensive taxonomy of the critical components\nin designing these systems, including data, models and alignment, agent\narchitecture and evaluation. This survey not only outlines the current\nmethodologies and challenges, such as managing dynamic personal profiles and\nachieving high-level persona consistency but also suggests avenues for future\nresearch in improving the depth and realism of role-playing applications. The\ngoal is to guide future research by offering a structured overview of current\nmethodologies and identifying potential areas for improvement. Related\nresources and papers are available at\nhttps://github.com/nuochenpku/Awesome-Role-Play-Papers.",
      "tldr_zh": "这篇调查论文探讨了语言模型在角色扮演（Role-Playing）领域的快速发展，从早期的基于角色的简单模型演进到大型语言模型（LLMs）支持的复杂人物模拟，涵盖了角色一致性、行为对齐和吸引力等关键方面。论文提供了一个全面的分类框架，包括数据、模型和对齐（Alignment）、代理架构（Agent Architecture）和评估方法，系统概述了当前的设计方法和挑战，如管理动态个人资料和维持高水平角色一致性。同时，它建议了未来研究方向，以提升角色扮演的深度和真实性，并提供了相关资源链接以指导后续工作。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.11484v9",
      "published_date": "2024-07-16 08:20:39 UTC",
      "updated_date": "2025-01-10 02:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:17:02.515800"
    },
    {
      "arxiv_id": "2407.11481v2",
      "title": "Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarong Chen",
        "Wanqing Wu",
        "Tong Liu",
        "Shenda Hong"
      ],
      "abstract": "Electrocardiogram (ECG) has emerged as a widely accepted diagnostic\ninstrument for cardiovascular diseases (CVD). The standard clinical 12-lead ECG\nconfiguration causes considerable inconvenience and discomfort, while wearable\ndevices offers a more practical alternative. To reduce information gap between\n12-lead ECG and single-lead ECG, this study proposes a multi-channel masked\nautoencoder (MCMA) for reconstructing 12-Lead ECG from arbitrary single-lead\nECG, and a comprehensive evaluation benchmark, ECGGenEval, encompass the\nsignal-level, feature-level, and diagnostic-level evaluations. MCMA can achieve\nthe state-of-the-art performance. In the signal-level evaluation, the mean\nsquare errors of 0.0317 and 0.1034, Pearson correlation coefficients of 0.7885\nand 0.7420. In the feature-level evaluation, the average standard deviation of\nthe mean heart rate across the generated 12-lead ECG is 1.0481, the coefficient\nof variation is 1.58%, and the range is 3.2874. In the diagnostic-level\nevaluation, the average F1-score with two generated 12-lead ECG from different\nsingle-lead ECG are 0.8233 and 0.8410.",
      "tldr_zh": "该研究针对心电图(ECG)诊断心血管疾病(CVD)的便利性问题，提出了一种多通道掩码自编码器(MCMA)，用于从任意单-lead ECG 重建标准12-Lead ECG，同时开发了全面评估基准ECGGenEval，包括信号级、特征级和诊断级评估。MCMA 实现了最先进性能，在信号级评估中，均方误差(MSE)分别为0.0317和0.1034，Pearson相关系数分别为0.7885和0.7420；在特征级评估中，平均心率标准差为1.0481、变异系数为1.58%、范围为3.2874；在诊断级评估中，平均F1-score分别为0.8233和0.8410。这些结果有助于缩小单-lead ECG与12-Lead ECG的信息差距，提高可穿戴设备在临床中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "It is a revised version.The open-source code is publicly available at\n  https://github.com/CHENJIAR3/MCMA",
      "pdf_url": "http://arxiv.org/pdf/2407.11481v2",
      "published_date": "2024-07-16 08:17:45 UTC",
      "updated_date": "2024-10-03 09:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:17:15.197720"
    },
    {
      "arxiv_id": "2407.11480v2",
      "title": "AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Ren",
        "Haiteng Wang",
        "Jinwang Li",
        "Yang Tang",
        "Chunhua Yang"
      ],
      "abstract": "With the remarkable success of generative models like ChatGPT, Artificial\nIntelligence Generated Content (AIGC) is undergoing explosive development. Not\nlimited to text and images, generative models can generate industrial time\nseries data, addressing challenges such as the difficulty of data collection\nand data annotation. Due to their outstanding generation ability, they have\nbeen widely used in Internet of Things, metaverse, and cyber-physical-social\nsystems to enhance the efficiency of industrial production. In this paper, we\npresent a comprehensive overview of generative models for industrial time\nseries from deep generative models (DGMs) to large generative models (LGMs).\nFirst, a DGM-based AIGC framework is proposed for industrial time series\ngeneration. Within this framework, we survey advanced industrial DGMs and\npresent a multi-perspective categorization. Furthermore, we systematically\nanalyze the critical technologies required to construct industrial LGMs from\nfour aspects: large-scale industrial dataset, LGMs architecture for complex\nindustrial characteristics, self-supervised training for industrial time\nseries, and fine-tuning of industrial downstream tasks. Finally, we conclude\nthe challenges and future directions to enable the development of generative\nmodels in industry.",
      "tldr_zh": "这篇论文探讨了人工智能生成内容(AIGC)在工业时间序列数据生成中的应用，从deep generative models (DGMs)到large generative models (LGMs)的演进。作者提出一个DGM-based AIGC框架，用于生成工业时间序列数据，并对先进工业DGMs进行了多视角分类，以解决数据收集和标注的难题。论文系统分析了构建工业LGMs的关键技术，包括大规模工业数据集、LGMs架构适应复杂工业特性、自监督训练以及下游任务的微调。最终，论文总结了当前挑战和未来方向，如在Internet of Things (IoT)、metaverse和cyber-physical-social systems中提升工业生产效率的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures.his work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.11480v2",
      "published_date": "2024-07-16 08:16:54 UTC",
      "updated_date": "2025-02-16 14:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:17:26.801637"
    },
    {
      "arxiv_id": "2407.11477v1",
      "title": "XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaochuan Gou",
        "Ziyue Li",
        "Tian Lan",
        "Junpeng Lin",
        "Zhishuai Li",
        "Bingyu Zhao",
        "Chen Zhang",
        "Di Wang",
        "Xiangliang Zhang"
      ],
      "abstract": "Long-separated research has been conducted on two highly correlated tracks:\ntraffic and incidents. Traffic track witnesses complicating deep learning\nmodels, e.g., to push the prediction a few percent more accurate, and the\nincident track only studies the incidents alone, e.g., to infer the incident\nrisk. We, for the first time, spatiotemporally aligned the two tracks in a\nlarge-scale region (16,972 traffic nodes) over the whole year of 2023: our\nXTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,\nlane occupancy, and average vehicle speed, and incidents, whose records are\nspatiotemporally-aligned with traffic data, with seven different incident\nclasses. Additionally, each node includes detailed physical and policy-level\nmeta-attributes of lanes. Our data can revolutionalize traditional\ntraffic-related tasks towards higher interpretability and practice: instead of\ntraditional prediction or classification tasks, we conduct: (1) post-incident\ntraffic forecasting to quantify the impact of different incidents on traffic\nindexes; (2) incident classification using traffic indexes to determine the\nincidents types for precautions measures; (3) global causal analysis among the\ntraffic indexes, meta-attributes, and incidents to give high-level guidance of\nthe interrelations of various factors; (4) local causal analysis within road\nnodes to examine how different incidents affect the road segments' relations.\nThe dataset is available at http://xaitraffic.github.io.",
      "tldr_zh": "该论文引入了XTraffic数据集，将交通和incidents（事件）数据首次在时空上对齐，覆盖2023年全年16,972个交通节点，包括交通指标（如流量、车道占用率和平均车速）、七类事件记录以及节点的物理和政策级元属性。数据集旨在提升交通相关任务的可解释性和实用性，通过四个关键任务展示其价值：（1）事件后交通预测，以量化不同incidents对交通的影响；（2）使用交通指标进行事件分类，支持预防措施；（3）全局causal analysis，探索交通指标、元属性和事件间的相互关系；（4）局部causal analysis，分析事件对路段关系的具体影响。总体上，XTraffic为更具解释性的交通研究提供了大规模资源，促进了传统任务的革新。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11477v1",
      "published_date": "2024-07-16 08:16:01 UTC",
      "updated_date": "2024-07-16 08:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:17:40.118282"
    },
    {
      "arxiv_id": "2407.11472v2",
      "title": "DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Kaibo He",
        "Chenhui Zuo",
        "Chengtian Ma",
        "Yanan Sui"
      ],
      "abstract": "Learning an effective policy to control high-dimensional, overactuated\nsystems is a significant challenge for deep reinforcement learning algorithms.\nSuch control scenarios are often observed in the neural control of vertebrate\nmusculoskeletal systems. The study of these control mechanisms will provide\ninsights into the control of high-dimensional, overactuated systems. The\ncoordination of actuators, known as muscle synergies in neuromechanics, is\nconsidered a presumptive mechanism that simplifies the generation of motor\ncommands. The dynamical structure of a system is the basis of its function,\nallowing us to derive a synergistic representation of actuators. Motivated by\nthis theory, we propose the Dynamical Synergistic Representation (DynSyn)\nalgorithm. DynSyn aims to generate synergistic representations from dynamical\nstructures and perform task-specific, state-dependent adaptation to the\nrepresentations to improve motor control. We demonstrate DynSyn's efficiency\nacross various tasks involving different musculoskeletal models, achieving\nstate-of-the-art sample efficiency and robustness compared to baseline\nalgorithms. DynSyn generates interpretable synergistic representations that\ncapture the essential features of dynamical structures and demonstrates\ngeneralizability across diverse motor tasks.",
      "tldr_zh": "该研究针对高维过驱动系统（如脊椎动物肌肉骨骼系统）的控制挑战，提出DynSyn算法，该算法基于动态结构生成协同表示（synergistic representation），并进行任务特定和状态相关的适应，以简化电机命令生成和提升控制效率。DynSyn从系统动态中提取可解释的协同表示，捕捉其本质特征，并在不同肌肉骨骼模型任务中实现了出色的样本效率和鲁棒性。实验结果显示，DynSyn在各种电机任务上超过了基线算法，并展示了良好的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11472v2",
      "published_date": "2024-07-16 08:09:59 UTC",
      "updated_date": "2024-12-26 16:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:17:52.139091"
    },
    {
      "arxiv_id": "2407.11470v2",
      "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
      "title_zh": "超越正确性：大型语言模型的多维度代码生成基准测试",
      "authors": [
        "Jiasheng Zheng",
        "Boxi Cao",
        "Zhengzhao Ma",
        "Ruotong Pan",
        "Hongyu Lin",
        "Yaojie Lu",
        "Xianpei Han",
        "Le Sun"
      ],
      "abstract": "In recent years, researchers have proposed numerous benchmarks to evaluate\nthe impressive coding capabilities of large language models (LLMs). However,\ncurrent benchmarks primarily assess the accuracy of LLM-generated code, while\nneglecting other critical dimensions that also significantly impact code\nquality in real-world development. Moreover, relying exclusively on correctness\nas the guiding metric renders LLMs susceptible to data contamination.\nTherefore, this paper proposes the RACE benchmark, which comprehensively\nevaluates the quality of code generated by LLMs across 4 dimensions:\nReadability, mAintainability, Correctness, and Efficiency. Specifically,\nconsidering the demand-dependent nature of dimensions beyond correctness, we\ndesign various types of user requirements for each dimension to assess the\nmodel's ability to generate correct code that also meets user demands. We\nanalyze 28 representative LLMs based on RACE and find that: 1) current\ncorrectness-centric benchmarks fail to capture the multifaceted requirements of\ncode in real-world scenarios, while RACE provides a comprehensive evaluation\nthat reveals the defects of LLMs across multiple dimensions; 2) the RACE\nbenchmark serves as an effective tool for resisting the risk of data\ncontamination; 3) even the most advanced code LLMs still encounter significant\nchallenges in customized requirements involving complex instructions; 4) most\nLLMs exhibit an inherent preference for specific coding style. These findings\nhighlight the need for a multidimensional evaluation of code LLMs, emphasizing\nmetrics beyond correctness for real-world applications. Future efforts should\naim to develop novel learning algorithms to enhance code generation under\nvaried constraints and improve coverage and usability for diverse user needs.",
      "tldr_zh": "该论文指出，现有的基准主要评估大型语言模型(LLMs)代码生成的正确性，而忽略了可读性(Readability)、可维护性(mAintainability)、效率(Efficiency)等关键维度，这导致LLMs易受数据污染。作者提出RACE基准，全面评估代码生成的四个维度，并针对每个维度设计多种用户需求，以测试模型生成符合实际需求的代码。实验分析了28个代表性LLMs，发现当前基准无法捕捉真实场景的多方面要求，RACE能有效抵抗数据污染，且即使先进模型在复杂指令下仍面临挑战，并显示出固有的编码风格偏好。论文强调，需要多维评估LLMs的代码生成能力，并呼吁开发新算法来提升模型在各种约束下的性能和适用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "We release benchmark at https://github.com/jszheng21/RACE and\n  leaderboard at https://huggingface.co/spaces/jszheng/RACE_leaderboard",
      "pdf_url": "http://arxiv.org/pdf/2407.11470v2",
      "published_date": "2024-07-16 08:08:48 UTC",
      "updated_date": "2024-10-09 05:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:18:04.567830"
    },
    {
      "arxiv_id": "2407.20241v1",
      "title": "NudgeRank: Digital Algorithmic Nudging for Personalized Health",
      "title_zh": "翻译失败",
      "authors": [
        "Jodi Chiam",
        "Aloysius Lim",
        "Ankur Teredesai"
      ],
      "abstract": "In this paper we describe NudgeRank, an innovative digital algorithmic\nnudging system designed to foster positive health behaviors on a\npopulation-wide scale. Utilizing a novel combination of Graph Neural Networks\naugmented with an extensible Knowledge Graph, this Recommender System is\noperational in production, delivering personalized and context-aware nudges to\nover 1.1 million care recipients daily. This enterprise deployment marks one of\nthe largest AI-driven health behavior change initiatives, accommodating diverse\nhealth conditions and wearable devices. Rigorous evaluation reveals\nstatistically significant improvements in health outcomes, including a 6.17%\nincrease in daily steps and 7.61% more exercise minutes. Moreover, user\nengagement and program enrollment surged, with a 13.1% open rate compared to\nbaseline systems' 4%. Demonstrating scalability and reliability, NudgeRank\noperates efficiently on commodity compute resources while maintaining\nautomation and observability standards essential for production systems.",
      "tldr_zh": "本研究介绍了 NudgeRank，一种创新的数字算法推动系统，旨在通过 Recommender System 结合 Graph Neural Networks 和 Knowledge Graph，提供个性化的上下文感知健康推动，每天服务超过 110 万用户，促进大规模健康行为改变。系统已在生产环境中部署，支持多种健康条件和可穿戴设备。实验结果显示，它显著改善了健康指标，包括每日步数增加 6.17% 和运动分钟增加 7.61%，并将用户参与率提升至 13.1%，证明了其可扩展性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "To be published in Proceedings of the 30th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '24)",
      "pdf_url": "http://arxiv.org/pdf/2407.20241v1",
      "published_date": "2024-07-16 07:56:42 UTC",
      "updated_date": "2024-07-16 07:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:18:15.153160"
    },
    {
      "arxiv_id": "2407.14543v1",
      "title": "Towards consistency of rule-based explainer and black box model -- fusion of rule induction and XAI-based feature importance",
      "title_zh": "翻译失败",
      "authors": [
        "Michał Kozielski",
        "Marek Sikora",
        "Łukasz Wawrowski"
      ],
      "abstract": "Rule-based models offer a human-understandable representation, i.e. they are\ninterpretable. For this reason, they are used to explain the decisions of\nnon-interpretable complex models, referred to as black box models. The\ngeneration of such explanations involves the approximation of a black box model\nby a rule-based model. To date, however, it has not been investigated whether\nthe rule-based model makes decisions in the same way as the black box model it\napproximates. Decision making in the same way is understood in this work as the\nconsistency of decisions and the consistency of the most important attributes\nused for decision making. This study proposes a novel approach ensuring that\nthe rule-based surrogate model mimics the performance of the black box model.\nThe proposed solution performs an explanation fusion involving rule generation\nand taking into account the feature importance determined by the selected XAI\nmethods for the black box model being explained. The result of the method can\nbe both global and local rule-based explanations. The quality of the proposed\nsolution was verified by extensive analysis on 30 tabular benchmark datasets\nrepresenting classification problems. Evaluation included comparison with the\nreference method and an illustrative case study. In addition, the paper\ndiscusses the possible pathways for the application of the rule-based approach\nin XAI and how rule-based explanations, including the proposed method, meet the\nuser perspective and requirements for both content and presentation. The\nsoftware created and a detailed report containing the full experimental results\nare available on the GitHub repository\n(https://github.com/ruleminer/FI-rules4XAI ).",
      "tldr_zh": "本研究探讨了规则模型（rule-based model）在解释黑盒模型（black box model）时的决策一致性问题，提出了一种新方法，通过融合规则归纳（rule induction）和基于 XAI 的特征重要性（XAI-based feature importance），确保规则模型能准确模拟黑盒模型的性能。该方法生成全局和局部规则解释，并在 30 个表格基准数据集上进行广泛实验，与参考方法比较后显示显著改进，包括更高的决策一致性和重要属性一致性。此外，该方法满足用户对解释内容和呈现形式的需求，并提供开源软件和详细实验报告（GitHub 仓库）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.14543v1",
      "published_date": "2024-07-16 07:56:29 UTC",
      "updated_date": "2024-07-16 07:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:18:29.818945"
    },
    {
      "arxiv_id": "2407.11463v3",
      "title": "Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng He",
        "Chun Ouyang",
        "Laith Alzubaidi",
        "Alistair Barros",
        "Catarina Moreira"
      ],
      "abstract": "Adversarial attacks are a potential threat to machine learning models by\ncausing incorrect predictions through imperceptible perturbations to the input\ndata. While these attacks have been extensively studied in unstructured data\nlike images, applying them to tabular data, poses new challenges. These\nchallenges arise from the inherent heterogeneity and complex feature\ninterdependencies in tabular data, which differ from the image data. To account\nfor this distinction, it is necessary to establish tailored imperceptibility\ncriteria specific to tabular data. However, there is currently a lack of\nstandardised metrics for assessing the imperceptibility of adversarial attacks\non tabular data. To address this gap, we propose a set of key properties and\ncorresponding metrics designed to comprehensively characterise imperceptible\nadversarial attacks on tabular data. These are: proximity to the original\ninput, sparsity of altered features, deviation from the original data\ndistribution, sensitivity in perturbing features with narrow distribution,\nimmutability of certain features that should remain unchanged, feasibility of\nspecific feature values that should not go beyond valid practical ranges, and\nfeature interdependencies capturing complex relationships between data\nattributes. We evaluate the imperceptibility of five adversarial attacks,\nincluding both bounded attacks and unbounded attacks, on tabular data using the\nproposed imperceptibility metrics. The results reveal a trade-off between the\nimperceptibility and effectiveness of these attacks. The study also identifies\nlimitations in current attack algorithms, offering insights that can guide\nfuture research in the area. The findings gained from this empirical analysis\nprovide valuable direction for enhancing the design of adversarial attack\nalgorithms, thereby advancing adversarial machine learning on tabular data.",
      "tldr_zh": "本文通过实证分析探讨了针对表格数据(tabular data)的对抗攻击(adversarial attacks)的不可察觉性(imperceptibility)，并针对表格数据的异构性和特征互依赖性提出一套标准化指标，包括接近度(proximity)、改变特征稀疏性(sparsity)、数据分布偏差(deviation)等七个关键属性。作者评估了五种对抗攻击（包括bounded attacks和unbounded attacks），结果揭示了不可察觉性和攻击有效性之间的权衡关系。研究还识别了现有攻击算法的局限性，并为未来优化对抗机器学习算法提供了宝贵指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.11463v3",
      "published_date": "2024-07-16 07:55:25 UTC",
      "updated_date": "2024-10-04 06:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:18:40.329983"
    },
    {
      "arxiv_id": "2407.11456v1",
      "title": "Graceful task adaptation with a bi-hemispheric RL agent",
      "title_zh": "翻译失败",
      "authors": [
        "Grant Nicholas",
        "Levin Kuhlmann",
        "Gideon Kowadlo"
      ],
      "abstract": "In humans, responsibility for performing a task gradually shifts from the\nright hemisphere to the left. The Novelty-Routine Hypothesis (NRH) states that\nthe right and left hemispheres are used to perform novel and routine tasks\nrespectively, enabling us to learn a diverse range of novel tasks while\nperforming the task capably. Drawing on the NRH, we develop a reinforcement\nlearning agent with specialised hemispheres that can exploit generalist\nknowledge from the right-hemisphere to avoid poor initial performance on novel\ntasks. In addition, we find that this design has minimal impact on its ability\nto learn novel tasks. We conclude by identifying improvements to our agent and\nexploring potential expansion to the continual learning setting.",
      "tldr_zh": "该论文基于Novelty-Routine Hypothesis (NRH)假设，开发了一个双半球强化学习 (RL) 代理，以模仿人类大脑的机制，其中右半球处理新颖任务，左半球处理常规任务，从而实现优雅的任务适应。代理通过利用右半球的通用知识，避免在新任务上出现糟糕的初始性能，同时对其学习新任务的能力影响最小。研究还探讨了代理的改进潜力，并考虑扩展到持续学习场景中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11456v1",
      "published_date": "2024-07-16 07:45:28 UTC",
      "updated_date": "2024-07-16 07:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:18:50.403125"
    },
    {
      "arxiv_id": "2407.11449v1",
      "title": "Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights",
      "title_zh": "翻译失败",
      "authors": [
        "Shunqi Mao",
        "Chaoyi Zhang",
        "Hang Su",
        "Hwanjun Song",
        "Igor Shalyminov",
        "Weidong Cai"
      ],
      "abstract": "Contextualized Image Captioning (CIC) evolves traditional image captioning\ninto a more complex domain, necessitating the ability for multimodal reasoning.\nIt aims to generate image captions given specific contextual information. This\npaper further introduces a novel domain of Controllable Contextualized Image\nCaptioning (Ctrl-CIC). Unlike CIC, which solely relies on broad context,\nCtrl-CIC accentuates a user-defined highlight, compelling the model to tailor\ncaptions that resonate with the highlighted aspects of the context. We present\ntwo approaches, Prompting-based Controller (P-Ctrl) and Recalibration-based\nController (R-Ctrl), to generate focused captions. P-Ctrl conditions the model\ngeneration on highlight by prepending captions with highlight-driven prefixes,\nwhereas R-Ctrl tunes the model to selectively recalibrate the encoder\nembeddings for highlighted tokens. Additionally, we design a GPT-4V empowered\nevaluator to assess the quality of the controlled captions alongside standard\nassessment methods. Extensive experimental results demonstrate the efficient\nand effective controllability of our method, charting a new direction in\nachieving user-adaptive image captioning. Code is available at\nhttps://github.com/ShunqiM/Ctrl-CIC .",
      "tldr_zh": "本论文引入了 Controllable Contextualized Image Captioning (Ctrl-CIC)，一种扩展传统图像描述技术的创新方法，允许用户通过定义高亮（highlights）来指导模型生成针对特定上下文的个性化图像描述。论文提出了两种核心方法：Prompting-based Controller (P-Ctrl)，通过在描述前添加高亮驱动的前缀来条件化模型输出；以及 Recalibration-based Controller (R-Ctrl)，通过调整编码器嵌入来选择性地强化高亮标记。实验结果显示，该方法在控制描述方面高效有效，并使用 GPT-4V 赋能的评估器验证了其性能，为用户适应性图像描述开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11449v1",
      "published_date": "2024-07-16 07:32:48 UTC",
      "updated_date": "2024-07-16 07:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:19:06.681703"
    },
    {
      "arxiv_id": "2407.11442v3",
      "title": "EARN Fairness: Explaining, Asking, Reviewing, and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Luo",
        "Yuri Nakao",
        "Mathieu Chollet",
        "Hiroya Inakoshi",
        "Simone Stumpf"
      ],
      "abstract": "Numerous fairness metrics have been proposed and employed by artificial\nintelligence (AI) experts to quantitatively measure bias and define fairness in\nAI models. Recognizing the need to accommodate stakeholders' diverse fairness\nunderstandings, efforts are underway to solicit their input. However, conveying\nAI fairness metrics to stakeholders without AI expertise, capturing their\npersonal preferences, and seeking a collective consensus remain challenging and\nunderexplored. To bridge this gap, we propose a new framework, EARN Fairness,\nwhich facilitates collective metric decisions among stakeholders without\nrequiring AI expertise. The framework features an adaptable interactive system\nand a stakeholder-centered EARN Fairness process to Explain fairness metrics,\nAsk stakeholders' personal metric preferences, Review metrics collectively, and\nNegotiate a consensus on metric selection. To gather empirical results, we\napplied the framework to a credit rating scenario and conducted a user study\ninvolving 18 decision subjects without AI knowledge. We identify their personal\nmetric preferences and their acceptable level of unfairness in individual\nsessions. Subsequently, we uncovered how they reached metric consensus in team\nsessions. Our work shows that the EARN Fairness framework enables stakeholders\nto express personal preferences and reach consensus, providing practical\nguidance for implementing human-centered AI fairness in high-risk contexts.\nThrough this approach, we aim to harmonize fairness expectations of diverse\nstakeholders, fostering more equitable and inclusive AI fairness.",
      "tldr_zh": "该研究提出EARN Fairness框架，旨在帮助非AI专家的利益相关者理解、表达偏好并协商AI fairness metrics，以解决AI模型中偏见测量和公平定义的多样性挑战。该框架包括一个可交互系统和一个以利益相关者为中心的流程：Explain（解释公平指标）、Ask（询问个人偏好）、Review（集体审查）和Negotiate（协商共识）。通过在信用评级场景的用户研究，涉及18名无AI知识的决策者，研究发现参与者能够表达个人偏好并达成共识，从而为人类中心AI公平性提供实用指导，促进更公平和包容的AI系统。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11442v3",
      "published_date": "2024-07-16 07:20:30 UTC",
      "updated_date": "2025-02-10 10:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:19:14.691695"
    },
    {
      "arxiv_id": "2407.11439v1",
      "title": "Repurformer: Transformers for Repurposing-Aware Molecule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Changhun Lee",
        "Gyumin Lee"
      ],
      "abstract": "Generating as diverse molecules as possible with desired properties is\ncrucial for drug discovery research, which invokes many approaches based on\ndeep generative models today. Despite recent advancements in these models,\nparticularly in variational autoencoders (VAEs), generative adversarial\nnetworks (GANs), Transformers, and diffusion models, a significant challenge\nknown as \\textit{the sample bias problem} remains. This problem occurs when\ngenerated molecules targeting the same protein tend to be structurally similar,\nreducing the diversity of generation. To address this, we propose leveraging\nmulti-hop relationships among proteins and compounds. Our model, Repurformer,\nintegrates bi-directional pretraining with Fast Fourier Transform (FFT) and\nlow-pass filtering (LPF) to capture complex interactions and generate diverse\nmolecules. A series of experiments on BindingDB dataset confirm that\nRepurformer successfully creates substitutes for anchor compounds that resemble\npositive compounds, increasing diversity between the anchor and generated\ncompounds.",
      "tldr_zh": "本论文针对药物发现中的分子生成问题，提出 Repurformer 模型，以解决现有生成模型（如 VAEs、GANs、Transformers 和 diffusion models）中的样本偏差问题，该问题导致针对同一蛋白的分子结构过于相似，从而降低多样性。Repurformer 通过整合双向预训练、Fast Fourier Transform (FFT) 和低通滤波 (LPF)，利用蛋白和化合物之间的多跳关系来捕捉复杂交互，并生成更丰富的分子。实验在 BindingDB 数据集上验证，该模型成功创建了类似于正化合物的锚定化合物替代物，提高了生成分子与锚定分子之间的多样性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2407.11439v1",
      "published_date": "2024-07-16 07:16:13 UTC",
      "updated_date": "2024-07-16 07:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:19:28.095831"
    },
    {
      "arxiv_id": "2407.11426v1",
      "title": "Generally-Occurring Model Change for Robust Counterfactual Explanations",
      "title_zh": "针对鲁棒逆事实解释的一般",
      "authors": [
        "Ao Xu",
        "Tieru Wu"
      ],
      "abstract": "With the increasing impact of algorithmic decision-making on human lives, the\ninterpretability of models has become a critical issue in machine learning.\nCounterfactual explanation is an important method in the field of interpretable\nmachine learning, which can not only help users understand why machine learning\nmodels make specific decisions, but also help users understand how to change\nthese decisions. Naturally, it is an important task to study the robustness of\ncounterfactual explanation generation algorithms to model changes. Previous\nliterature has proposed the concept of Naturally-Occurring Model Change, which\nhas given us a deeper understanding of robustness to model change. In this\npaper, we first further generalize the concept of Naturally-Occurring Model\nChange, proposing a more general concept of model parameter changes,\nGenerally-Occurring Model Change, which has a wider range of applicability. We\nalso prove the corresponding probabilistic guarantees. In addition, we consider\na more specific problem, data set perturbation, and give relevant theoretical\nresults by combining optimization theory.",
      "tldr_zh": "该论文探讨了逆事实解释（Counterfactual Explanation）在可解释机器学习中的作用，强调其对模型变化的鲁棒性，以帮助用户理解模型决策及其修改方式。作者扩展了原有 Naturally-Occurring Model Change 概念，提出更通用的 Generally-Occurring Model Change，用于处理模型参数变化，并证明了相应的概率保证。同时，论文分析了数据集扰动问题，并结合优化理论提供了相关理论结果，从而提升逆事实解释算法的可靠性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11426v1",
      "published_date": "2024-07-16 06:44:00 UTC",
      "updated_date": "2024-07-16 06:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:19:38.302921"
    },
    {
      "arxiv_id": "2407.11418v3",
      "title": "Semantic Operators: A Declarative Model for Rich, AI-based Data Processing",
      "title_zh": "语义运算符：一种用于丰富的基于AI的数据处理的声明式模型",
      "authors": [
        "Liana Patel",
        "Siddharth Jha",
        "Melissa Pan",
        "Harshit Gupta",
        "Parth Asawa",
        "Carlos Guestrin",
        "Matei Zaharia"
      ],
      "abstract": "The semantic capabilities of large language models (LLMs) have the potential\nto enable rich analytics and reasoning over vast knowledge corpora.\nUnfortunately, existing systems either empirically optimize expensive\nLLM-powered operations with no performance guarantees, or serve a limited set\nof row-wise LLM operations, providing limited robustness, expressiveness and\nusability. We introduce semantic operators, the first formalism for declarative\nand general-purpose AI-based transformations based on natural language\nspecifications (e.g., filtering, sorting, joining or aggregating records using\nnatural language criteria). Each operator opens a rich space for execution\nplans, similar to relational operators. Our model specifies the expected\nbehavior of each operator with a high-quality gold algorithm, and we develop an\noptimization framework that reduces cost, while providing accuracy guarantees\nwith respect to a gold algorithm. Using this approach, we propose several novel\noptimizations to accelerate semantic filtering, joining, group-by and top-k\noperations by up to $1,000\\times$. We implement semantic operators in the LOTUS\nsystem and demonstrate LOTUS' effectiveness on real, bulk-semantic processing\napplications, including fact-checking, biomedical multi-label classification,\nsearch, and topic analysis. We show that the semantic operator model is\nexpressive, capturing state-of-the-art AI pipelines in a few operator calls,\nand making it easy to express new pipelines that match or exceed quality of\nrecent LLM-based analytic systems by up to $170\\%$, while offering accuracy\nguarantees. Overall, LOTUS programs match or exceed the accuracy of\nstate-of-the-art AI pipelines for each task while running up to $3.6\\times$\nfaster than the highest-quality baselines. LOTUS is publicly available at\nhttps://github.com/lotus-data/lotus.",
      "tldr_zh": "这篇论文引入了 semantic operators，一种基于自然语言规范的声明式模型，用于实现丰富的 AI 驱动数据处理（如 filtering、sorting、joining 和 aggregating），以解决现有 LLM 系统在鲁棒性、表达性和可用性上的局限。论文提出一个优化框架，通过定义高质量 gold algorithm 并进行执行计划优化，使 semantic filtering、joining、group-by 和 top-k 操作加速高达 1,000 倍，同时提供准确性保证。在 LOTUS 系统实现后，实验证明该模型在事实核查、生物医学多标签分类、搜索和主题分析等应用中，表达性强、易于构建新管道，并使准确性提升高达 170%，整体运行速度比最先进基线快达 3.6 倍。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11418v3",
      "published_date": "2024-07-16 06:19:14 UTC",
      "updated_date": "2025-03-01 01:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:19:53.166665"
    },
    {
      "arxiv_id": "2407.12876v2",
      "title": "Exploring the Use of Abusive Generative AI Models on Civitai",
      "title_zh": "翻译失败",
      "authors": [
        "Yiluo Wei",
        "Yiming Zhu",
        "Pan Hui",
        "Gareth Tyson"
      ],
      "abstract": "The rise of generative AI is transforming the landscape of digital imagery,\nand exerting a significant influence on online creative communities. This has\nled to the emergence of AI-Generated Content (AIGC) social platforms, such as\nCivitai. These distinctive social platforms allow users to build and share\ntheir own generative AI models, thereby enhancing the potential for more\ndiverse artistic expression. Designed in the vein of social networks, they also\nprovide artists with the means to showcase their creations (generated from the\nmodels), engage in discussions, and obtain feedback, thus nurturing a sense of\ncommunity. Yet, this openness also raises concerns about the abuse of such\nplatforms, e.g., using models to disseminate deceptive deepfakes or infringe\nupon copyrights. To explore this, we conduct the first comprehensive empirical\nstudy of an AIGC social platform, focusing on its use for generating abusive\ncontent. As an exemplar, we construct a comprehensive dataset covering Civitai,\nthe largest available AIGC social platform. Based on this dataset of 87K models\nand 2M images, we explore the characteristics of content and discuss strategies\nfor moderation to better govern these platforms.",
      "tldr_zh": "本研究探讨了生成式 AI 在 AIGC 社交平台 Civitai 上的滥用问题，这些平台虽促进了用户构建和分享 AI 模型、增强艺术表达与社区互动，但也引发了如传播欺骗性 deepfakes 或侵犯版权的风险。研究者构建了一个全面数据集，涵盖 87K 模型和 2M 图像，对内容特征进行了首个实证分析。最终，论文讨论了调节策略，以更好地治理这些平台并缓解潜在滥用。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted to ACM Multimedia 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12876v2",
      "published_date": "2024-07-16 06:18:03 UTC",
      "updated_date": "2024-07-20 19:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:20:03.495115"
    },
    {
      "arxiv_id": "2407.12875v1",
      "title": "ChatBCG: Can AI Read Your Slide Deck?",
      "title_zh": "ChatBCG：AI 能阅读你的幻灯片集吗？",
      "authors": [
        "Nikita Singh",
        "Rob Balian",
        "Lukas Martinelli"
      ],
      "abstract": "Multimodal models like GPT4o and Gemini Flash are exceptional at inference\nand summarization tasks, which approach human-level in performance. However, we\nfind that these models underperform compared to humans when asked to do very\nspecific 'reading and estimation' tasks, particularly in the context of visual\ncharts in business decks. This paper evaluates the accuracy of GPT 4o and\nGemini Flash-1.5 in answering straightforward questions about data on labeled\ncharts (where data is clearly annotated on the graphs), and unlabeled charts\n(where data is not clearly annotated and has to be inferred from the X and Y\naxis). We conclude that these models aren't currently capable of reading a deck\naccurately end-to-end if it contains any complex or unlabeled charts. Even if a\nuser created a deck of only labeled charts, the model would only be able to\nread 7-8 out of 15 labeled charts perfectly end-to-end. For full list of slide\ndeck figures visit https://www.repromptai.com/chat_bcg",
      "tldr_zh": "该论文探讨了多模态模型如 GPT-4o 和 Gemini Flash-1.5 在阅读和估计幻灯片图表任务中的表现，发现这些模型不如人类，尤其在处理标注图表和未标注图表时。研究通过评估模型对明确标注数据和需从 X/Y 轴推断数据的准确性，揭示了其在端到端阅读商业幻灯片上的局限性。结果显示，即使是全标注图表的幻灯片，模型也只能完美阅读 15 个中的 7-8 个，表明当前 AI 无法可靠地处理复杂或未标注图表。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "for full list of figures visit https://www.repromptai.com/chat_bcg",
      "pdf_url": "http://arxiv.org/pdf/2407.12875v1",
      "published_date": "2024-07-16 06:00:45 UTC",
      "updated_date": "2024-07-16 06:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:20:15.375773"
    },
    {
      "arxiv_id": "2407.12065v2",
      "title": "Data selection method for assessment of autonomous vehicles",
      "title_zh": "自动驾驶车辆评估的数据选择方法",
      "authors": [
        "Linh Trinh",
        "Ali Anwar",
        "Siegfried Mercelis"
      ],
      "abstract": "As the popularity of autonomous vehicles has grown, many standards and\nregulators, such as ISO, NHTSA, and Euro NCAP, require safety validation to\nensure a sufficient level of safety before deploying them in the real world.\nManufacturers gather a large amount of public road data for this purpose.\nHowever, the majority of these validation activities are done manually by\nhumans. Furthermore, the data used to validate each driving feature may differ.\nAs a result, it is essential to have an efficient data selection method that\ncan be used flexibly and dynamically for verification and validation while also\naccelerating the validation process. In this paper, we present a data selection\nmethod that is practical, flexible, and efficient for assessment of autonomous\nvehicles. Our idea is to optimize the similarity between the metadata\ndistribution of the selected data and a predefined metadata distribution that\nis expected for validation. Our experiments on the large dataset BDD100K show\nthat our method can perform data selection tasks efficiently. These results\ndemonstrate that our methods are highly reliable and can be used to select\nappropriate data for the validation of various safety functions.",
      "tldr_zh": "本文提出了一种实用、灵活且高效的数据选择方法，用于评估自动驾驶车辆的安全性，以满足 ISO、NHTSA 和 Euro NCAP 等标准的验证要求。该方法通过优化所选数据元数据分布与预定义验证期望分布的相似性，实现动态和高效的数据筛选，避免了传统手动验证的低效问题。在 BDD100K 大数据集上的实验证明，该方法显著加速了验证过程，并展示了其可靠性，可适用于多种安全功能的验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.12065v2",
      "published_date": "2024-07-16 05:35:38 UTC",
      "updated_date": "2024-10-28 18:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:20:26.313054"
    },
    {
      "arxiv_id": "2407.11394v3",
      "title": "DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation",
      "title_zh": "DreamCatalyst：通过控制可编辑性和身份保留实现快速且高质量的3D编辑",
      "authors": [
        "Jiwook Kim",
        "Seonho Lee",
        "Jaeyo Shin",
        "Jiho Choi",
        "Hyunjung Shim"
      ],
      "abstract": "Score distillation sampling (SDS) has emerged as an effective framework in\ntext-driven 3D editing tasks, leveraging diffusion models for 3D-consistent\nediting. However, existing SDS-based 3D editing methods suffer from long\ntraining times and produce low-quality results. We identify that the root cause\nof this performance degradation is \\textit{their conflict with the sampling\ndynamics of diffusion models}. Addressing this conflict allows us to treat SDS\nas a diffusion reverse process for 3D editing via sampling from data space. In\ncontrast, existing methods naively distill the score function using diffusion\nmodels. From these insights, we propose DreamCatalyst, a novel framework that\nconsiders these sampling dynamics in the SDS framework. Specifically, we devise\nthe optimization process of our DreamCatalyst to approximate the diffusion\nreverse process in editing tasks, thereby aligning with diffusion sampling\ndynamics. As a result, DreamCatalyst successfully reduces training time and\nimproves editing quality. Our method offers two modes: (1) a fast mode that\nedits Neural Radiance Fields (NeRF) scenes approximately 23 times faster than\ncurrent state-of-the-art NeRF editing methods, and (2) a high-quality mode that\nproduces superior results about 8 times faster than these methods. Notably, our\nhigh-quality mode outperforms current state-of-the-art NeRF editing methods in\nterms of both speed and quality. DreamCatalyst also surpasses the\nstate-of-the-art 3D Gaussian Splatting (3DGS) editing methods, establishing\nitself as an effective and model-agnostic 3D editing solution. See more\nextensive results on our project page: https://dream-catalyst.github.io.",
      "tldr_zh": "这篇论文提出了 DreamCatalyst 框架，用于文本驱动的 3D 编辑，通过优化 Score Distillation Sampling (SDS) 以匹配扩散模型的采样动态，解决现有方法训练时间长和质量低的问题。框架将 SDS 视为扩散逆过程，并设计了优化流程来提升编辑效率和一致性，提供快速模式（比现有 Neural Radiance Fields (NeRF) 编辑方法快 23 倍）和高质量模式（比现有方法快 8 倍且质量更优）。DreamCatalyst 超越了 NeRF 和 3D Gaussian Splatting (3DGS) 的现有技术，作为一种模型无关的 3D 编辑解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.11394v3",
      "published_date": "2024-07-16 05:26:14 UTC",
      "updated_date": "2025-02-11 07:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:20:40.449586"
    },
    {
      "arxiv_id": "2407.11393v2",
      "title": "CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Kalliopi Basioti",
        "Mohamed A. Abdelsalam",
        "Federico Fancellu",
        "Vladimir Pavlovic",
        "Afsaneh Fazly"
      ],
      "abstract": "Controllable Image Captioning (CIC) aims at generating natural language\ndescriptions for an image, conditioned on information provided by end users,\ne.g., regions, entities or events of interest. However, available\nimage-language datasets mainly contain captions that describe the entirety of\nan image, making them ineffective for training CIC models that can potentially\nattend to any subset of regions or relationships. To tackle this challenge, we\npropose a novel, fully automatic method to sample additional focused and\nvisually grounded captions using a unified structured semantic representation\nbuilt on top of the existing set of captions associated with an image. We\nleverage Abstract Meaning Representation (AMR), a cross-lingual graph-based\nsemantic formalism, to encode all possible spatio-semantic relations between\nentities, beyond the typical spatial-relations-only focus of current methods.\nWe use this Structured Semantic Augmentation (SSA) framework to augment\nexisting image-caption datasets with the grounded controlled captions,\nincreasing their spatial and semantic diversity and focal coverage. We then\ndevelop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that\nsources its control signals from SSA-diversified datasets. We empirically show\nthat, compared to SOTA CIC models, CIC-BART-SSA generates captions that are\nsuperior in diversity and text quality, are competitive in controllability,\nand, importantly, minimize the gap between broad and highly focused controlled\ncaptioning performance by efficiently generalizing to the challenging highly\nfocused scenarios. Code is available at\nhttps://github.com/SamsungLabs/CIC-BART-SSA.",
      "tldr_zh": "该论文针对 Controllable Image Captioning (CIC) 的挑战，即现有图像描述数据集无法有效支持用户指定的区域、实体或事件，提出了一种新型 Structured Semantic Augmentation (SSA) 框架。SSA 利用 Abstract Meaning Representation (AMR) 来编码图像中实体间的空间和语义关系，从而自动生成更多聚焦且视觉地锚定的描述，以增强数据集的多样性和覆盖范围。作者开发了 CIC-BART-SSA 模型，利用这些增强数据集进行训练，结果显示该模型在描述多样性、文本质量和可控性方面优于现有状态-of-the-art (SOTA) 模型，并能更好地处理高度聚焦的场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11393v2",
      "published_date": "2024-07-16 05:26:12 UTC",
      "updated_date": "2024-07-17 16:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:20:54.178892"
    },
    {
      "arxiv_id": "2407.11383v1",
      "title": "TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Tonmoy Rajkhowa",
        "Amartya Roy Chowdhury",
        "Sankalp Nagaonkar",
        "Achyut Mani Tripathi"
      ],
      "abstract": "In healthcare and medical diagnostics, Visual Question Answering (VQA)\nmayemergeasapivotal tool in scenarios where analysis of intricate medical\nimages becomes critical for accurate diagnoses. Current text-based VQA systems\nlimit their utility in scenarios where hands-free interaction and accessibility\nare crucial while performing tasks. A speech-based VQA system may provide a\nbetter means of interaction where information can be accessed while performing\ntasks simultaneously. To this end, this work implements a speech-based VQA\nsystem by introducing a Textless Multilingual Pathological VQA (TMPathVQA)\ndataset, an expansion of the PathVQA dataset, containing spoken questions in\nEnglish, German & French. This dataset comprises 98,397 multilingual spoken\nquestions and answers based on 5,004 pathological images along with 70 hours of\naudio. Finally, this work benchmarks and compares TMPathVQA systems implemented\nusing various combinations of acoustic and visual features.",
      "tldr_zh": "本研究针对医疗视觉问答 (VQA) 中的语音交互需求，引入了 TM-PATHVQA 数据集，这是一个基于 PathVQA 的扩展，包含超过 98,397 个无文本的多语言（英语、德语和法语）语音问题和答案，涉及 5,004 张病理图像以及 70 小时音频。数据集旨在提升 VQA 系统在双手操作场景下的可用性，支持语音查询医疗图像。作者通过基准测试比较了使用各种声学和视觉特征的 TM-PATHVQA 系统，展示了其在医疗诊断中的潜在优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "conference (Accepted at Interspeech 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.11383v1",
      "published_date": "2024-07-16 04:54:45 UTC",
      "updated_date": "2024-07-16 04:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:21:07.646310"
    },
    {
      "arxiv_id": "2407.11382v2",
      "title": "Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Li",
        "Tianyu Sun",
        "Zhongdao Wang",
        "Enze Xie",
        "Bailan Feng",
        "Hongbo Zhang",
        "Ze Yuan",
        "Ke Xu",
        "Jiaheng Liu",
        "Ping Luo"
      ],
      "abstract": "This paper proposes an algorithm for automatically labeling 3D objects from\n2D point or box prompts, especially focusing on applications in autonomous\ndriving. Unlike previous arts, our auto-labeler predicts 3D shapes instead of\nbounding boxes and does not require training on a specific dataset. We propose\na Segment, Lift, and Fit (SLF) paradigm to achieve this goal. Firstly, we\nsegment high-quality instance masks from the prompts using the Segment Anything\nModel (SAM) and transform the remaining problem into predicting 3D shapes from\ngiven 2D masks. Due to the ill-posed nature of this problem, it presents a\nsignificant challenge as multiple 3D shapes can project into an identical mask.\nTo tackle this issue, we then lift 2D masks to 3D forms and employ gradient\ndescent to adjust their poses and shapes until the projections fit the masks\nand the surfaces conform to surrounding LiDAR points. Notably, since we do not\ntrain on a specific dataset, the SLF auto-labeler does not overfit to biased\nannotation patterns in the training set as other methods do. Thus, the\ngeneralization ability across different datasets improves. Experimental results\non the KITTI dataset demonstrate that the SLF auto-labeler produces\nhigh-quality bounding box annotations, achieving an AP@0.5 IoU of nearly 90\\%.\nDetectors trained with the generated pseudo-labels perform nearly as well as\nthose trained with actual ground-truth annotations. Furthermore, the SLF\nauto-labeler shows promising results in detailed shape predictions, providing a\npotential alternative for the occupancy annotation of dynamic objects.",
      "tldr_zh": "本论文提出了一种Segment, Lift and Fit (SLF)算法，用于从2D点或框提示自动标注3D形状，特别针对自动驾驶应用，与传统方法不同，它预测3D形状而非边界框，且无需在特定数据集上训练。SLF范式包括使用Segment Anything Model (SAM)分割高质量实例掩码，然后将2D掩码提升到3D形式，并通过梯度下降调整姿势和形状，使其投影匹配掩码并符合周围LiDAR点，从而解决多解问题并提高泛化能力。在KITTI数据集实验中，SLF标注的边界框达到近90%的AP@0.5 IoU，使用生成的伪标签训练的检测器性能接近真实标注，并展现出在详细形状预测和动态对象占用标注方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11382v2",
      "published_date": "2024-07-16 04:53:28 UTC",
      "updated_date": "2024-07-17 06:32:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:21:21.773047"
    },
    {
      "arxiv_id": "2407.12874v2",
      "title": "SELF-GUIDE: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyang Zhao",
        "Xueying Jia",
        "Vijay Viswanathan",
        "Tongshuang Wu",
        "Graham Neubig"
      ],
      "abstract": "Large language models (LLMs) hold the promise of solving diverse tasks when\nprovided with appropriate natural language prompts. However, prompting often\nleads models to make predictions with lower accuracy compared to finetuning a\nmodel with ample training data. On the other hand, while finetuning LLMs on\ntask-specific data generally improves their performance, abundant annotated\ndatasets are not available for all tasks. Previous work has explored generating\ntask-specific data from state-of-the-art LLMs and using this data to finetune\nsmaller models, but this approach requires access to a language model other\nthan the one being trained, which introduces cost, scalability challenges, and\nlegal hurdles associated with continuously relying on more powerful LLMs. In\nresponse to these, we propose SELF-GUIDE, a multi-stage mechanism in which we\nsynthesize task-specific input-output pairs from the student LLM, then use\nthese input-output pairs to finetune the student LLM itself. In our empirical\nevaluation of the Natural Instructions V2 benchmark, we find that SELF-GUIDE\nimproves the performance of LLM by a substantial margin. Specifically, we\nreport an absolute improvement of approximately 15% for classification tasks\nand 18% for generation tasks in the benchmark's metrics. This sheds light on\nthe promise of self-synthesized data guiding LLMs towards becoming\ntask-specific experts without any external learning signals.",
      "tldr_zh": "该论文提出SELF-GUIDE方法，通过自合成微调(self-synthetic finetuning)来提升大型语言模型(LLMs)在任务特定指令遵循方面的性能，避免了依赖外部模型带来的成本、可扩展性和法律问题。具体而言，该机制让学生LLM自身生成任务特定的输入-输出对，并使用这些数据进行自微调。在Natural Instructions V2基准测试中，SELF-GUIDE使分类任务准确率提高约15%，生成任务提高约18%，证明了自合成数据能引导LLMs成为高效的任务专家，而无需外部学习信号。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.12874v2",
      "published_date": "2024-07-16 04:41:58 UTC",
      "updated_date": "2024-08-12 00:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:21:30.683337"
    },
    {
      "arxiv_id": "2407.11373v2",
      "title": "Reliable Reasoning Beyond Natural Language",
      "title_zh": "超越自然语言的可靠推理",
      "authors": [
        "Nasim Borazjanizadeh",
        "Steven T. Piantadosi"
      ],
      "abstract": "Despite their linguistic competence, Large Language models (LLMs) often\nexhibit limitations in their ability to reason reliably and flexibly. To\naddress this, we propose a neurosymbolic approach that prompts LLMs to extract\nand encode all relevant information from a problem statement as logical code\nstatements, and then use a logic programming language (Prolog) to conduct the\niterative computations of explicit deductive reasoning. Our approach\nsignificantly enhances the performance of LLMs on the standard mathematical\nreasoning benchmark, GSM8k, and the Navigate dataset from the BIG-bench\ndataset. Additionally, we introduce a novel dataset, the Non-Linear Reasoning\n(NLR) dataset, consisting of 55 unique word problems that target the\nshortcomings of the next token prediction paradigm of LLMs and require complex\nnon-linear reasoning but only basic arithmetic skills to solve. Our findings\ndemonstrate that the integration of Prolog enables LLMs to achieve high\nperformance on the NLR dataset, which even the most advanced language models\n(including GPT4) fail to solve using text only.",
      "tldr_zh": "该研究指出，大语言模型(LLMs)尽管语言能力强，但可靠和灵活推理能力有限。为解决此问题，提出一种神经符号(neurosymbolic)方法，让LLMs提取问题语句中的信息并编码为逻辑代码，然后使用Prolog进行迭代演绎推理。实验结果显示，该方法显著提升了LLMs在GSM8k和Navigate数据集上的性能。研究者还引入了新的Non-Linear Reasoning (NLR)数据集，包含55个需要复杂非线性推理但仅需基本算术的词问题，结果表明，结合Prolog的LLMs能成功解决这些问题，而纯文本模型如GPT4则失败。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11373v2",
      "published_date": "2024-07-16 04:34:18 UTC",
      "updated_date": "2024-07-19 18:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:21:43.350884"
    },
    {
      "arxiv_id": "2407.11360v1",
      "title": "Thorns and Algorithms: Navigating Generative AI Challenges Inspired by Giraffes and Acacias",
      "title_zh": "翻译失败",
      "authors": [
        "Waqar Hussain"
      ],
      "abstract": "The interplay between humans and Generative AI (Gen AI) draws an insightful\nparallel with the dynamic relationship between giraffes and acacias on the\nAfrican Savannah. Just as giraffes navigate the acacia's thorny defenses to\ngain nourishment, humans engage with Gen AI, maneuvering through ethical and\noperational challenges to harness its benefits. This paper explores how, like\nyoung giraffes that are still mastering their environment, humans are in the\nearly stages of adapting to and shaping Gen AI. It delves into the strategies\nhumans are developing and refining to help mitigate risks such as bias,\nmisinformation, and privacy breaches, that influence and shape Gen AI's\nevolution. While the giraffe-acacia analogy aptly frames human-AI relations, it\ncontrasts nature's evolutionary perfection with the inherent flaws of\nhuman-made technology and the tendency of humans to misuse it, giving rise to\nmany ethical dilemmas. Through the HHH framework we identify pathways to embed\nvalues of helpfulness, honesty, and harmlessness in AI development, fostering\nsafety-aligned agents that resonate with human values. This narrative presents\na cautiously optimistic view of human resilience and adaptability, illustrating\nour capacity to harness technologies and implement safeguards effectively,\nwithout succumbing to their perils. It emphasises a symbiotic relationship\nwhere humans and AI continually shape each other for mutual benefit.",
      "tldr_zh": "这篇论文以长颈鹿和金合欢树的动态互动作为比喻，探讨人类与 Generative AI (Gen AI) 的关系，强调人类需应对类似“荆棘”的伦理和操作挑战，如偏见、错误信息及隐私泄露。论文分析了人类在适应 Gen AI 早期阶段所发展的策略，并引入 HHH framework（Helpfulness, Honesty, Harmlessness），以嵌入 AI 开发中的核心价值观，促进安全对齐的 AI 代理。最终，它呈现出谨慎乐观的观点，突出人类韧性和适应性，推动人类与 AI 的共生关系，实现相互益处。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11360v1",
      "published_date": "2024-07-16 03:53:25 UTC",
      "updated_date": "2024-07-16 03:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:21:55.004031"
    },
    {
      "arxiv_id": "2407.11359v1",
      "title": "Feature Inference Attack on Shapley Values",
      "title_zh": "针对 Shapley 值的特征推断攻击",
      "authors": [
        "Xinjian Luo",
        "Yangfan Jiang",
        "Xiaokui Xiao"
      ],
      "abstract": "As a solution concept in cooperative game theory, Shapley value is highly\nrecognized in model interpretability studies and widely adopted by the leading\nMachine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and\nIBM. However, as the Shapley value-based model interpretability methods have\nbeen thoroughly studied, few researchers consider the privacy risks incurred by\nShapley values, despite that interpretability and privacy are two foundations\nof machine learning (ML) models.\n  In this paper, we investigate the privacy risks of Shapley value-based model\ninterpretability methods using feature inference attacks: reconstructing the\nprivate model inputs based on their Shapley value explanations. Specifically,\nwe present two adversaries. The first adversary can reconstruct the private\ninputs by training an attack model based on an auxiliary dataset and black-box\naccess to the model interpretability services. The second adversary, even\nwithout any background knowledge, can successfully reconstruct most of the\nprivate features by exploiting the local linear correlations between the model\ninputs and outputs. We perform the proposed attacks on the leading MLaaS\nplatforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The\nexperimental results demonstrate the vulnerability of the state-of-the-art\nShapley value-based model interpretability methods used in the leading MLaaS\nplatforms and highlight the significance and necessity of designing\nprivacy-preserving model interpretability methods in future studies. To our\nbest knowledge, this is also the first work that investigates the privacy risks\nof Shapley values.",
      "tldr_zh": "该论文探讨了Shapley values在机器学习模型可解释性中的隐私风险，通过feature inference attacks重建私有模型输入。研究者提出了两种攻击方法：第一种利用辅助数据集和黑盒访问训练攻击模型；第二种无需背景知识，仅凭模型输入与输出间的局部线性相关性即可重建大部分私有特征。在Google Cloud、Microsoft Azure和IBM aix360等领先MLaaS平台上的实验显示，这些攻击有效，证明了现有Shapley values方法的脆弱性，并强调未来需设计隐私保护的可解释性方法，这是首个针对Shapley values隐私风险的研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This work was published in CCS 2022",
      "pdf_url": "http://arxiv.org/pdf/2407.11359v1",
      "published_date": "2024-07-16 03:50:06 UTC",
      "updated_date": "2024-07-16 03:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:22:07.577600"
    },
    {
      "arxiv_id": "2407.11358v2",
      "title": "SES: Bridging the Gap Between Explainability and Prediction of Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenhua Huang",
        "Kunhao Li",
        "Shaojie Wang",
        "Zhaohong Jia",
        "Wentao Zhu",
        "Sharad Mehrotra"
      ],
      "abstract": "Despite the Graph Neural Networks' (GNNs) proficiency in analyzing graph\ndata, achieving high-accuracy and interpretable predictions remains\nchallenging. Existing GNN interpreters typically provide post-hoc explanations\ndisjointed from GNNs' predictions, resulting in misrepresentations.\nSelf-explainable GNNs offer built-in explanations during the training process.\nHowever, they cannot exploit the explanatory outcomes to augment prediction\nperformance, and they fail to provide high-quality explanations of node\nfeatures and require additional processes to generate explainable subgraphs,\nwhich is costly. To address the aforementioned limitations, we propose a\nself-explained and self-supervised graph neural network (SES) to bridge the gap\nbetween explainability and prediction. SES comprises two processes: explainable\ntraining and enhanced predictive learning. During explainable training, SES\nemploys a global mask generator co-trained with a graph encoder and directly\nproduces crucial structure and feature masks, reducing time consumption and\nproviding node feature and subgraph explanations. In the enhanced predictive\nlearning phase, mask-based positive-negative pairs are constructed utilizing\nthe explanations to compute a triplet loss and enhance the node representations\nby contrastive learning.",
      "tldr_zh": "该研究针对 Graph Neural Networks (GNNs) 在图数据分析中准确性与可解释性之间的鸿沟，提出了一种自解释和自监督的框架 SES。SES 包括两个关键过程：explainable training，使用全局 mask generator 与 graph encoder 共同训练，直接生成关键结构和特征掩码，从而提供高质量的节点特征和子图解释，同时降低时间消耗；enhanced predictive learning，利用这些掩码构建正负样本对，通过 triplet loss 和 contrastive learning 增强节点表示，提升预测性能。总体上，SES 有效桥接了 GNNs 的解释性和预测能力，避免了现有方法的误导和额外开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a conference paper at ICDE 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11358v2",
      "published_date": "2024-07-16 03:46:57 UTC",
      "updated_date": "2024-07-25 04:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:22:19.098856"
    },
    {
      "arxiv_id": "2407.15862v1",
      "title": "Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis",
      "title_zh": "轻量级开源大语言模型在儿科咨询中的性能评估：比较分析",
      "authors": [
        "Qiuhong Wei",
        "Ying Cui",
        "Mengwei Ding",
        "Yanqin Wang",
        "Lingling Xiang",
        "Zhengxiong Yao",
        "Ceran Chen",
        "Ying Long",
        "Zhezhen Jin",
        "Ximing Xu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated potential applications in\nmedicine, yet data privacy and computational burden limit their deployment in\nhealthcare institutions. Open-source and lightweight versions of LLMs emerge as\npotential solutions, but their performance, particularly in pediatric settings\nremains underexplored. In this cross-sectional study, 250 patient consultation\nquestions were randomly selected from a public online medical forum, with 10\nquestions from each of 25 pediatric departments, spanning from December 1,\n2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and\nVicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used\nproprietary ChatGPT-3.5, independently answered these questions in Chinese\nbetween November 1, 2023, and November 7, 2023. To assess reproducibility, each\ninquiry was replicated once. We found that ChatGLM3-6B demonstrated higher\naccuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all\nwere outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in\naccuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and\nVicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed\nby ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest\nratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming\nVicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the\nlightweight LLMs (P < .001). In safety, all models performed comparably well (P\n> .05), with over 98.4% of responses being rated as safe. Repetition of\ninquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate\npromising application in pediatric healthcare. However, the observed gap\nbetween lightweight and large-scale proprietary LLMs underscores the need for\ncontinued development efforts.",
      "tldr_zh": "本研究评估了轻量级开源大型语言模型（LLMs）在儿科咨询中的性能，通过比较 ChatGLM3-6B、Vicuna-7B、Vicuna-13B 和 ChatGPT-3.5 模型。研究选取了 250 个儿科患者咨询问题，从 25 个部门随机采样，并评估了准确性、完整性、可读性、同理心和安全性等指标。结果显示，ChatGPT-3.5 在准确性（65.2%）和完整性（78.4%）上领先，而 ChatGLM3-6B 在准确性和完整性上优于 Vicuna 模型，但在同理心上落后于 ChatGPT-3.5；在可读性和安全性上，ChatGLM3-6B 与 ChatGPT-3.5 表现相当，所有模型的安全性均超过 98.4%。总之，轻量级 LLMs 在儿科医疗中显示出潜力，但与大型专有模型相比存在差距，需要进一步优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "68M20 (Primary) 62G10 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages in total with 17 pages of main manuscript and 10 pages of\n  supplementary materials; 4 figures in the main manuscript and 2 figures in\n  supplementary material",
      "pdf_url": "http://arxiv.org/pdf/2407.15862v1",
      "published_date": "2024-07-16 03:35:09 UTC",
      "updated_date": "2024-07-16 03:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:22:33.211975"
    },
    {
      "arxiv_id": "2407.11315v1",
      "title": "COMET: \"Cone of experience\" enhanced large multimodal model for mathematical problem generation",
      "title_zh": "COMET: “Cone of Experience” 增强的大型多模态模型，用于数学问题生成",
      "authors": [
        "Sannyuya Liu",
        "Jintian Feng",
        "Zongkai Yang",
        "Yawei Luo",
        "Qian Wan",
        "Xiaoxuan Shen",
        "Jianwen Sun"
      ],
      "abstract": "The automatic generation of high-quality mathematical problems is practically\nvaluable in many educational scenarios. Large multimodal model provides a novel\ntechnical approach for the mathematical problem generation because of its wide\nsuccess in cross-modal data scenarios. However, the traditional method of\nseparating problem solving from problem generation and the mainstream\nfine-tuning framework of monotonous data structure with homogeneous training\nobjectives limit the application of large multimodal model in mathematical\nproblem generation. Addressing these challenges, this paper proposes COMET, a\n\"Cone of Experience\" enhanced large multimodal model for mathematical problem\ngeneration. Firstly, from the perspective of mutual ability promotion and\napplication logic, we unify stem generation and problem solving into\nmathematical problem generation. Secondly, a three-stage fine-turning framework\nguided by the \"Cone of Experience\" is proposed. The framework divides the\nfine-tuning data into symbolic experience, iconic experience, and direct\nexperience to draw parallels with experiences in the career growth of teachers.\nSeveral fine-grained data construction and injection methods are designed in\nthis framework. Finally, we construct a Chinese multimodal mathematical problem\ndataset to fill the vacancy of Chinese multimodal data in this field. Combined\nwith objective and subjective indicators, experiments on multiple datasets\nfully verify the effectiveness of the proposed framework and model.",
      "tldr_zh": "该论文提出 COMET，一种基于 \"Cone of Experience\" 增强的大型多模态模型，用于自动生成高质量数学问题，以支持教育场景。论文创新性地统一问题生成和求解过程，并设计了一个三阶段微调框架，将数据分为 symbolic experience、iconic experience 和 direct experience，模拟教师职业成长路径，同时引入细粒度的数据构建和注入方法。为填补中文多模态数据空白，研究者构建了一个中文数学问题数据集。实验结果通过客观和主观指标验证了 COMET 框架的有效性，在多个数据集上显著提升了问题生成质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11315v1",
      "published_date": "2024-07-16 02:02:16 UTC",
      "updated_date": "2024-07-16 02:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:22:42.614773"
    },
    {
      "arxiv_id": "2407.11300v1",
      "title": "Large Vision-Language Models as Emotion Recognizers in Context Awareness",
      "title_zh": "大型视觉语言模型作为上下文感知中的情感识别器",
      "authors": [
        "Yuxuan Lei",
        "Dingkang Yang",
        "Zhaoyu Chen",
        "Jiawei Chen",
        "Peng Zhai",
        "Lihua Zhang"
      ],
      "abstract": "Context-aware emotion recognition (CAER) is a complex and significant task\nthat requires perceiving emotions from various contextual cues. Previous\napproaches primarily focus on designing sophisticated architectures to extract\nemotional cues from images. However, their knowledge is confined to specific\ntraining datasets and may reflect the subjective emotional biases of the\nannotators. Furthermore, acquiring large amounts of labeled data is often\nchallenging in real-world applications. In this paper, we systematically\nexplore the potential of leveraging Large Vision-Language Models (LVLMs) to\nempower the CAER task from three paradigms: 1) We fine-tune LVLMs on two CAER\ndatasets, which is the most common way to transfer large models to downstream\ntasks. 2) We design zero-shot and few-shot patterns to evaluate the performance\nof LVLMs in scenarios with limited data or even completely unseen. In this\ncase, a training-free framework is proposed to fully exploit the In-Context\nLearning (ICL) capabilities of LVLMs. Specifically, we develop an image\nsimilarity-based ranking algorithm to retrieve examples; subsequently, the\ninstructions, retrieved examples, and the test example are combined to feed\nLVLMs to obtain the corresponding sentiment judgment. 3) To leverage the rich\nknowledge base of LVLMs, we incorporate Chain-of-Thought (CoT) into our\nframework to enhance the model's reasoning ability and provide interpretable\nresults. Extensive experiments and analyses demonstrate that LVLMs achieve\ncompetitive performance in the CAER task across different paradigms. Notably,\nthe superior performance in few-shot settings indicates the feasibility of\nLVLMs for accomplishing specific tasks without extensive training.",
      "tldr_zh": "该研究探讨了Large Vision-Language Models (LVLMs) 在上下文感知情绪识别 (CAER) 任务中的应用潜力，以解决传统方法依赖特定数据集和主观偏差的问题。论文通过三种范式评估 LVLMs：微调模型于 CAER 数据集、设计零样本和少样本学习框架（包括基于图像相似性排名的 In-Context Learning (ICL) 方法）、以及整合 Chain-of-Thought (CoT) 来增强推理能力和结果可解释性。实验结果显示，LVLMs 在不同范式下表现出色，尤其在少样本设置中，无需大量训练即可实现竞争性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11300v1",
      "published_date": "2024-07-16 01:28:06 UTC",
      "updated_date": "2024-07-16 01:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:22:56.682737"
    },
    {
      "arxiv_id": "2407.11288v1",
      "title": "Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems",
      "title_zh": "零样本",
      "authors": [
        "Yaşar Utku Alçalar",
        "Mehmet Akçakaya"
      ],
      "abstract": "Diffusion models have emerged as powerful generative techniques for solving\ninverse problems. Despite their success in a variety of inverse problems in\nimaging, these models require many steps to converge, leading to slow inference\ntime. Recently, there has been a trend in diffusion models for employing\nsophisticated noise schedules that involve more frequent iterations of\ntimesteps at lower noise levels, thereby improving image generation and\nconvergence speed. However, application of these ideas for solving inverse\nproblems with diffusion models remain challenging, as these noise schedules do\nnot perform well when using empirical tuning for the forward model\nlog-likelihood term weights. To tackle these challenges, we propose zero-shot\napproximate posterior sampling (ZAPS) that leverages connections to zero-shot\nphysics-driven deep learning. ZAPS fixes the number of sampling steps, and uses\nzero-shot training with a physics-guided loss function to learn log-likelihood\nweights at each irregular timestep. We apply ZAPS to the recently proposed\ndiffusion posterior sampling method as baseline, though ZAPS can also be used\nwith other posterior sampling diffusion models. We further approximate the\nHessian of the logarithm of the prior using a diagonalization approach with\nlearnable diagonal entries for computational efficiency. These parameters are\noptimized over a fixed number of epochs with a given computational budget. Our\nresults for various noisy inverse problems, including Gaussian and motion\ndeblurring, inpainting, and super-resolution show that ZAPS reduces inference\ntime, provides robustness to irregular noise schedules and improves\nreconstruction quality. Code is available at https://github.com/ualcalar17/ZAPS",
      "tldr_zh": "该论文针对扩散模型(Diffusion Models)在逆问题(Inverse Problems)中的慢速收敛问题，提出了一种零-shot适应方法ZAPS（Zero-Shot Approximate Posterior Sampling）。ZAPS通过零-shot训练和物理引导损失函数来学习不规则时间步的log-likelihood权重，并使用对角化近似Hessian矩阵以提高计算效率，从而固定采样步骤并减少推理时间。实验结果显示，ZAPS在高斯去噪、运动去模糊、修复和超分辨率等任务上提升了重建质量和鲁棒性，显著优于基线模型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "European Conference on Computer Vision (ECCV), 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11288v1",
      "published_date": "2024-07-16 00:09:37 UTC",
      "updated_date": "2024-07-16 00:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T07:23:08.996977"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 121,
  "processed_papers_count": 121,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T07:23:34.107456"
}