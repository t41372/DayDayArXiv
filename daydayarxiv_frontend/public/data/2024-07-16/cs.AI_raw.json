[
  {
    "arxiv_id": "2407.12886v1",
    "title": "Whitening Not Recommended for Classification Tasks in LLMs",
    "authors": [
      "Ali Forooghi",
      "Shaghayegh Sadeghi",
      "Jianguo Lu"
    ],
    "abstract": "Sentence embedding is a cornerstone in NLP. Whitening has been claimed to be\nan effective operation to improve embedding quality obtained from Large\nLanguage Models (LLMs). However, we find that the efficacy of whitening is\nmodel-dependent and task-dependent. In particular, whitening degenerates\nembeddings for classification tasks. The conclusion is supported by extensive\nexperiments. We also explored a variety of whitening operations, including PCA,\nZCA, PCA-Cor, ZCA-Cor and Cholesky whitenings. A by-product of our research is\nembedding evaluation platform for LLMs called SentEval+.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12886v1",
    "published_date": "2024-07-16 22:48:30 UTC",
    "updated_date": "2024-07-16 22:48:30 UTC"
  },
  {
    "arxiv_id": "2407.12200v1",
    "title": "This Probably Looks Exactly Like That: An Invertible Prototypical Network",
    "authors": [
      "Zachariah Carmichael",
      "Timothy Redgrave",
      "Daniel Gonzalez Cedre",
      "Walter J. Scheirer"
    ],
    "abstract": "We combine concept-based neural networks with generative, flow-based\nclassifiers into a novel, intrinsically explainable, exactly invertible\napproach to supervised learning. Prototypical neural networks, a type of\nconcept-based neural network, represent an exciting way forward in realizing\nhuman-comprehensible machine learning without concept annotations, but a\nhuman-machine semantic gap continues to haunt current approaches. We find that\nreliance on indirect interpretation functions for prototypical explanations\nimposes a severe limit on prototypes' informative power. From this, we posit\nthat invertibly learning prototypes as distributions over the latent space\nprovides more robust, expressive, and interpretable modeling. We propose one\nsuch model, called ProtoFlow, by composing a normalizing flow with Gaussian\nmixture models. ProtoFlow (1) sets a new state-of-the-art in joint generative\nand predictive modeling and (2) achieves predictive performance comparable to\nexisting prototypical neural networks while enabling richer interpretation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ECCV'24. Code available at\n  https://github.com/craymichael/ProtoFlow",
    "pdf_url": "http://arxiv.org/pdf/2407.12200v1",
    "published_date": "2024-07-16 21:51:02 UTC",
    "updated_date": "2024-07-16 21:51:02 UTC"
  },
  {
    "arxiv_id": "2407.12197v2",
    "title": "Towards Interpretable Visuo-Tactile Predictive Models for Soft Robot Interactions",
    "authors": [
      "Enrico Donato",
      "Thomas George Thuruthel",
      "Egidio Falotico"
    ],
    "abstract": "Autonomous systems face the intricate challenge of navigating unpredictable\nenvironments and interacting with external objects. The successful integration\nof robotic agents into real-world situations hinges on their perception\ncapabilities, which involve amalgamating world models and predictive skills.\nEffective perception models build upon the fusion of various sensory modalities\nto probe the surroundings. Deep learning applied to raw sensory modalities\noffers a viable option. However, learning-based perceptive representations\nbecome difficult to interpret. This challenge is particularly pronounced in\nsoft robots, where the compliance of structures and materials makes prediction\neven harder. Our work addresses this complexity by harnessing a generative\nmodel to construct a multi-modal perception model for soft robots and to\nleverage proprioceptive and visual information to anticipate and interpret\ncontact interactions with external objects. A suite of tools to interpret the\nperception model is furnished, shedding light on the fusion and prediction\nprocesses across multiple sensory inputs after the learning phase. We will\ndelve into the outlooks of the perception model and its implications for\ncontrol purposes.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE RAS EMBS 10th International Conference on Biomedical Robotics\n  and Biomechatronics (BioRob 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.12197v2",
    "published_date": "2024-07-16 21:46:04 UTC",
    "updated_date": "2024-07-25 12:49:12 UTC"
  },
  {
    "arxiv_id": "2407.12185v1",
    "title": "Satisficing Exploration for Deep Reinforcement Learning",
    "authors": [
      "Dilip Arumugam",
      "Saurabh Kumar",
      "Ramki Gummadi",
      "Benjamin Van Roy"
    ],
    "abstract": "A default assumption in the design of reinforcement-learning algorithms is\nthat a decision-making agent always explores to learn optimal behavior. In\nsufficiently complex environments that approach the vastness and scale of the\nreal world, however, attaining optimal performance may in fact be an entirely\nintractable endeavor and an agent may seldom find itself in a position to\ncomplete the requisite exploration for identifying an optimal policy. Recent\nwork has leveraged tools from information theory to design agents that\ndeliberately forgo optimal solutions in favor of sufficiently-satisfying or\nsatisficing solutions, obtained through lossy compression. Notably, such agents\nmay employ fundamentally different exploratory decisions to learn satisficing\nbehaviors more efficiently than optimal ones that are more data intensive.\nWhile supported by a rigorous corroborating theory, the underlying algorithm\nrelies on model-based planning, drastically limiting the compatibility of these\nideas with function approximation and high-dimensional observations. In this\nwork, we remedy this issue by extending an agent that directly represents\nuncertainty over the optimal value function allowing it to both bypass the need\nfor model-based planning and to learn satisficing policies. We provide simple\nyet illustrative experiments that demonstrate how our algorithm enables deep\nreinforcement-learning agents to achieve satisficing behaviors. In keeping with\nprevious work on this setting for multi-armed bandits, we additionally find\nthat our algorithm is capable of synthesizing optimal behaviors, when feasible,\nmore efficiently than its non-information-theoretic counterpart.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12185v1",
    "published_date": "2024-07-16 21:28:03 UTC",
    "updated_date": "2024-07-16 21:28:03 UTC"
  },
  {
    "arxiv_id": "2407.12178v1",
    "title": "Exploration Unbound",
    "authors": [
      "Dilip Arumugam",
      "Wanqiao Xu",
      "Benjamin Van Roy"
    ],
    "abstract": "A sequential decision-making agent balances between exploring to gain new\nknowledge about an environment and exploiting current knowledge to maximize\nimmediate reward. For environments studied in the traditional literature,\noptimal decisions gravitate over time toward exploitation as the agent\naccumulates sufficient knowledge and the benefits of further exploration\nvanish. What if, however, the environment offers an unlimited amount of useful\nknowledge and there is large benefit to further exploration no matter how much\nthe agent has learned? We offer a simple, quintessential example of such a\ncomplex environment. In this environment, rewards are unbounded and an agent\ncan always increase the rate at which rewards accumulate by exploring to learn\nmore. Consequently, an optimal agent forever maintains a propensity to explore.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Finding the Frame Workshop at RLC 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12178v1",
    "published_date": "2024-07-16 21:14:43 UTC",
    "updated_date": "2024-07-16 21:14:43 UTC"
  },
  {
    "arxiv_id": "2407.12176v4",
    "title": "GPT-4V Cannot Generate Radiology Reports Yet",
    "authors": [
      "Yuyang Jiang",
      "Chacha Chen",
      "Dang Nguyen",
      "Benjamin M. Mervak",
      "Chenhao Tan"
    ],
    "abstract": "GPT-4V's purported strong multimodal abilities raise interests in using it to\nautomate radiology report writing, but there lacks thorough evaluations. In\nthis work, we perform a systematic evaluation of GPT-4V in generating radiology\nreports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt\nto directly generate reports using GPT-4V through different prompting\nstrategies and find that it fails terribly in both lexical metrics and clinical\nefficacy metrics. To understand the low performance, we decompose the task into\ntwo steps: 1) the medical image reasoning step of predicting medical condition\nlabels from images; and 2) the report synthesis step of generating reports from\n(groundtruth) conditions. We show that GPT-4V's performance in image reasoning\nis consistently low across different prompts. In fact, the distributions of\nmodel-predicted labels remain constant regardless of which groundtruth\nconditions are present on the image, suggesting that the model is not\ninterpreting chest X-rays meaningfully. Even when given groundtruth conditions\nin report synthesis, its generated reports are less correct and less\nnatural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt\non the viability of using GPT-4V in a radiology workflow.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages, 3 figures, code:\n  https://github.com/ChicagoHAI/cxr-eval-gpt-4v Findings paper presented at\n  Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024,\n  Vancouver, Canada, 26 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.12176v4",
    "published_date": "2024-07-16 21:03:14 UTC",
    "updated_date": "2024-11-14 21:34:59 UTC"
  },
  {
    "arxiv_id": "2407.12173v1",
    "title": "Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis",
    "authors": [
      "Haeil Lee",
      "Hansang Lee",
      "Seoyeon Gye",
      "Junmo Kim"
    ],
    "abstract": "Generative diffusion models have emerged as a powerful tool for high-quality\nimage synthesis, yet their iterative nature demands significant computational\nresources. This paper proposes an efficient time step sampling method based on\nan image spectral analysis of the diffusion process, aimed at optimizing the\ndenoising process. Instead of the traditional uniform distribution-based time\nstep sampling, we introduce a Beta distribution-like sampling technique that\nprioritizes critical steps in the early and late stages of the process. Our\nhypothesis is that certain steps exhibit significant changes in image content,\nwhile others contribute minimally. We validated our approach using Fourier\ntransforms to measure frequency response changes at each step, revealing\nsubstantial low-frequency changes early on and high-frequency adjustments\nlater. Experiments with ADM and Stable Diffusion demonstrated that our Beta\nSampling method consistently outperforms uniform sampling, achieving better FID\nand IS scores, and offers competitive efficiency relative to state-of-the-art\nmethods like AutoDiffusion. This work provides a practical framework for\nenhancing diffusion model efficiency by focusing computational resources on the\nmost impactful steps, with potential for further optimization and broader\napplication.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12173v1",
    "published_date": "2024-07-16 20:53:06 UTC",
    "updated_date": "2024-07-16 20:53:06 UTC"
  },
  {
    "arxiv_id": "2407.13796v1",
    "title": "Continuous Embedding Attacks via Clipped Inputs in Jailbreaking Large Language Models",
    "authors": [
      "Zihao Xu",
      "Yi Liu",
      "Gelei Deng",
      "Kailong Wang",
      "Yuekang Li",
      "Ling Shi",
      "Stjepan Picek"
    ],
    "abstract": "Security concerns for large language models (LLMs) have recently escalated,\nfocusing on thwarting jailbreaking attempts in discrete prompts. However, the\nexploration of jailbreak vulnerabilities arising from continuous embeddings has\nbeen limited, as prior approaches primarily involved appending discrete or\ncontinuous suffixes to inputs. Our study presents a novel channel for\nconducting direct attacks on LLM inputs, eliminating the need for suffix\naddition or specific questions provided that the desired output is predefined.\nWe additionally observe that extensive iterations often lead to overfitting,\ncharacterized by repetition in the output. To counteract this, we propose a\nsimple yet effective strategy named CLIP. Our experiments show that for an\ninput length of 40 at iteration 1000, applying CLIP improves the ASR from 62%\nto 83%",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13796v1",
    "published_date": "2024-07-16 20:53:00 UTC",
    "updated_date": "2024-07-16 20:53:00 UTC"
  },
  {
    "arxiv_id": "2407.12165v2",
    "title": "Building AI Agents for Autonomous Clouds: Challenges and Design Principles",
    "authors": [
      "Manish Shetty",
      "Yinfang Chen",
      "Gagan Somashekar",
      "Minghua Ma",
      "Yogesh Simmhan",
      "Xuchao Zhang",
      "Jonathan Mace",
      "Dax Vandevoorde",
      "Pedro Las-Casas",
      "Shachee Mishra Gupta",
      "Suman Nath",
      "Chetan Bansal",
      "Saravan Rajmohan"
    ],
    "abstract": "The rapid growth in the use of Large Language Models (LLMs) and AI Agents as\npart of software development and deployment is revolutionizing the information\ntechnology landscape. While code generation receives significant attention, a\nhigher-impact application lies in using AI agents for operational resilience of\ncloud services, which currently require significant human effort and domain\nknowledge. There is a growing interest in AI for IT Operations (AIOps) which\naims to automate complex operational tasks, like fault localization and root\ncause analysis, thereby reducing human intervention and customer impact.\nHowever, achieving the vision of autonomous and self-healing clouds through\nAIOps is hampered by the lack of standardized frameworks for building,\nevaluating, and improving AIOps agents. This vision paper lays the groundwork\nfor such a framework by first framing the requirements and then discussing\ndesign decisions that satisfy them. We also propose AIOpsLab, a prototype\nimplementation leveraging agent-cloud-interface that orchestrates an\napplication, injects real-time faults using chaos engineering, and interfaces\nwith an agent to localize and resolve the faults. We report promising results\nand lay the groundwork to build a modular and robust framework for building,\nevaluating, and improving agents for autonomous clouds.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12165v2",
    "published_date": "2024-07-16 20:40:43 UTC",
    "updated_date": "2024-07-31 06:01:15 UTC"
  },
  {
    "arxiv_id": "2407.12164v3",
    "title": "Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning",
    "authors": [
      "Yanting Miao",
      "William Loh",
      "Suraj Kothawade",
      "Pascal Poupart",
      "Abdullah Rashwan",
      "Yeqing Li"
    ],
    "abstract": "Text-to-image generative models have recently attracted considerable\ninterest, enabling the synthesis of high-quality images from textual prompts.\nHowever, these models often lack the capability to generate specific subjects\nfrom given reference images or to synthesize novel renditions under varying\nconditions. Methods like DreamBooth and Subject-driven Text-to-Image (SuTI)\nhave made significant progress in this area. Yet, both approaches primarily\nfocus on enhancing similarity to reference images and require expensive setups,\noften overlooking the need for efficient training and avoiding overfitting to\nthe reference images. In this work, we present the $\\lambda$-Harmonic reward\nfunction, which provides a reliable reward signal and enables early stopping\nfor faster training and effective regularization. By combining the\nBradley-Terry preference model, the $\\lambda$-Harmonic reward function also\nprovides preference labels for subject-driven generation tasks. We propose\nReward Preference Optimization (RPO), which offers a simpler setup (requiring\nonly $3\\%$ of the negative samples used by DreamBooth) and fewer gradient steps\nfor fine-tuning. Unlike most existing methods, our approach does not require\ntraining a text encoder or optimizing text embeddings and achieves text-image\nalignment by fine-tuning only the U-Net component. Empirically,\n$\\lambda$-Harmonic proves to be a reliable approach for model selection in\nsubject-driven generation tasks. Based on preference labels and early stopping\nvalidation from the $\\lambda$-Harmonic reward function, our algorithm achieves\na state-of-the-art CLIP-I score of 0.833 and a CLIP-T score of 0.314 on\nDreamBench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12164v3",
    "published_date": "2024-07-16 20:40:25 UTC",
    "updated_date": "2024-12-22 08:42:13 UTC"
  },
  {
    "arxiv_id": "2407.12161v1",
    "title": "Interpretability in Action: Exploratory Analysis of VPT, a Minecraft Agent",
    "authors": [
      "Karolis Jucys",
      "George Adamopoulos",
      "Mehrab Hamidi",
      "Stephanie Milani",
      "Mohammad Reza Samsami",
      "Artem Zholus",
      "Sonia Joseph",
      "Blake Richards",
      "Irina Rish",
      "Özgür Şimşek"
    ],
    "abstract": "Understanding the mechanisms behind decisions taken by large foundation\nmodels in sequential decision making tasks is critical to ensuring that such\nsystems operate transparently and safely. In this work, we perform exploratory\nanalysis on the Video PreTraining (VPT) Minecraft playing agent, one of the\nlargest open-source vision-based agents. We aim to illuminate its reasoning\nmechanisms by applying various interpretability techniques. First, we analyze\nthe attention mechanism while the agent solves its training task - crafting a\ndiamond pickaxe. The agent pays attention to the last four frames and several\nkey-frames further back in its six-second memory. This is a possible mechanism\nfor maintaining coherence in a task that takes 3-10 minutes, despite the short\nmemory span. Secondly, we perform various interventions, which help us uncover\na worrying case of goal misgeneralization: VPT mistakenly identifies a villager\nwearing brown clothes as a tree trunk when the villager is positioned\nstationary under green tree leaves, and punches it to death.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Mechanistic Interpretability Workshop at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12161v1",
    "published_date": "2024-07-16 20:38:08 UTC",
    "updated_date": "2024-07-16 20:38:08 UTC"
  },
  {
    "arxiv_id": "2408.00778v1",
    "title": "Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions",
    "authors": [
      "Qinshi Zhang",
      "Latisha Besariani Hendra",
      "Mohan Chi",
      "Zijian Ding"
    ],
    "abstract": "The emergence of Generative AI is catalyzing a paradigm shift in user\ninterfaces from command-based to intent-based outcome specification. In this\npaper, we explore abstract-to-detailed task transitions in the context of\nfrontend code generation as a step towards intent-based user interfaces, aiming\nto bridge the gap between abstract user intentions and concrete\nimplementations. We introduce Frontend Diffusion, an end-to-end LLM-powered\ntool that generates high-quality websites from user sketches. The system\nemploys a three-stage task transition process: sketching, writing, and coding.\nWe demonstrate the potential of task transitions to reduce human intervention\nand communication costs in complex tasks. Our work also opens avenues for\nexploring similar approaches in other domains, potentially extending to more\ncomplex, interdependent tasks such as video production.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00778v1",
    "published_date": "2024-07-16 20:24:35 UTC",
    "updated_date": "2024-07-16 20:24:35 UTC"
  },
  {
    "arxiv_id": "2407.12141v1",
    "title": "Predicting Emotion Intensity in Polish Political Texts: Comparing Supervised Models and Large Language Models in a Resource-Poor Language",
    "authors": [
      "Hubert Plisiecki",
      "Piotr Koc",
      "Maria Flakus",
      "Artur Pokropek"
    ],
    "abstract": "This study explores the use of large language models (LLMs) to predict\nemotion intensity in Polish political texts, a resource-poor language context.\nThe research compares the performance of several LLMs against a supervised\nmodel trained on an annotated corpus of 10,000 social media texts, evaluated\nfor the intensity of emotions by expert judges. The findings indicate that\nwhile the supervised model generally outperforms LLMs, offering higher accuracy\nand lower variance, LLMs present a viable alternative, especially given the\nhigh costs associated with data annotation. The study highlights the potential\nof LLMs in low-resource language settings and underscores the need for further\nresearch on emotion intensity prediction and its application across different\nlanguages and continuous features. The implications suggest a nuanced\ndecision-making process to choose the right approach to emotion prediction for\nresearchers and practitioners based on resource availability and the specific\nrequirements of their tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The Appendix is located at the very bottom of the manuscript",
    "pdf_url": "http://arxiv.org/pdf/2407.12141v1",
    "published_date": "2024-07-16 19:53:14 UTC",
    "updated_date": "2024-07-16 19:53:14 UTC"
  },
  {
    "arxiv_id": "2407.12126v2",
    "title": "LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation",
    "authors": [
      "Bunyamin Keles",
      "Murat Gunay",
      "Serdar I. Caglar"
    ],
    "abstract": "Machine translation is indispensable in healthcare for enabling the global\ndissemination of medical knowledge across languages. However, complex medical\nterminology poses unique challenges to achieving adequate translation quality\nand accuracy. This study introduces a novel \"LLMs-in-the-loop\" approach to\ndevelop supervised neural machine translation models optimized specifically for\nmedical texts. While large language models (LLMs) have demonstrated powerful\ncapabilities, this research shows that small, specialized models trained on\nhigh-quality in-domain (mostly synthetic) data can outperform even vastly\nlarger LLMs.\n  Custom parallel corpora in six languages were compiled from scientific\narticles, synthetically generated clinical documents, and medical texts. Our\nLLMs-in-the-loop methodology employs synthetic data generation, rigorous\nevaluation, and agent orchestration to enhance performance. We developed small\nmedical translation models using the MarianMT base model. We introduce a new\nmedical translation test dataset to standardize evaluation in this domain.\nAssessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our\nMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.\n  Results demonstrate that our LLMs-in-the-loop approach, combined with\nfine-tuning high-quality, domain-specific data, enables specialized models to\noutperform general-purpose and some larger systems. This research, part of a\nbroader series on expert small models, paves the way for future\nhealthcare-related AI developments, including deidentification and bio-medical\nentity extraction models. Our study underscores the potential of tailored\nneural translation models and the LLMs-in-the-loop methodology to advance the\nfield through improved data generation, evaluation, agent, and modeling\ntechniques.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T35"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 2 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.12126v2",
    "published_date": "2024-07-16 19:32:23 UTC",
    "updated_date": "2024-07-26 12:37:58 UTC"
  },
  {
    "arxiv_id": "2407.12884v1",
    "title": "SurroFlow: A Flow-Based Surrogate Model for Parameter Space Exploration and Uncertainty Quantification",
    "authors": [
      "Jingyi Shen",
      "Yuhan Duan",
      "Han-Wei Shen"
    ],
    "abstract": "Existing deep learning-based surrogate models facilitate efficient data\ngeneration, but fall short in uncertainty quantification, efficient parameter\nspace exploration, and reverse prediction. In our work, we introduce SurroFlow,\na novel normalizing flow-based surrogate model, to learn the invertible\ntransformation between simulation parameters and simulation outputs. The model\nnot only allows accurate predictions of simulation outcomes for a given\nsimulation parameter but also supports uncertainty quantification in the data\ngeneration process. Additionally, it enables efficient simulation parameter\nrecommendation and exploration. We integrate SurroFlow and a genetic algorithm\nas the backend of a visual interface to support effective user-guided ensemble\nsimulation exploration and visualization. Our framework significantly reduces\nthe computational costs while enhancing the reliability and exploration\ncapabilities of scientific surrogate models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in Proc. IEEE VIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12884v1",
    "published_date": "2024-07-16 19:08:49 UTC",
    "updated_date": "2024-07-16 19:08:49 UTC"
  },
  {
    "arxiv_id": "2407.12113v2",
    "title": "A Graph-based Adversarial Imitation Learning Framework for Reliable & Realtime Fleet Scheduling in Urban Air Mobility",
    "authors": [
      "Prithvi Poddar",
      "Steve Paul",
      "Souma Chowdhury"
    ],
    "abstract": "The advent of Urban Air Mobility (UAM) presents the scope for a\ntransformative shift in the domain of urban transportation. However, its\nwidespread adoption and economic viability depends in part on the ability to\noptimally schedule the fleet of aircraft across vertiports in a UAM network,\nunder uncertainties attributed to airspace congestion, changing weather\nconditions, and varying demands. This paper presents a comprehensive\noptimization formulation of the fleet scheduling problem, while also\nidentifying the need for alternate solution approaches, since directly solving\nthe resulting integer nonlinear programming problem is computationally\nprohibitive for daily fleet scheduling. Previous work has shown the\neffectiveness of using (graph) reinforcement learning (RL) approaches to train\nreal-time executable policy models for fleet scheduling. However, such policies\ncan often be brittle on out-of-distribution scenarios or edge cases. Moreover,\ntraining performance also deteriorates as the complexity (e.g., number of\nconstraints) of the problem increases. To address these issues, this paper\npresents an imitation learning approach where the RL-based policy exploits\nexpert demonstrations yielded by solving the exact optimization using a Genetic\nAlgorithm. The policy model comprises Graph Neural Network (GNN) based encoders\nthat embed the space of vertiports and aircraft, Transformer networks to encode\ndemand, passenger fare, and transport cost profiles, and a Multi-head attention\n(MHA) based decoder. Expert demonstrations are used through the Generative\nAdversarial Imitation Learning (GAIL) algorithm. Interfaced with a UAM\nsimulation environment involving 8 vertiports and 40 aircrafts, in terms of the\ndaily profits earned reward, the new imitative approach achieves better mean\nperformance and remarkable improvement in the case of unseen worst-case\nscenarios, compared to pure RL results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the AIAA Aviation Forum 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12113v2",
    "published_date": "2024-07-16 18:51:24 UTC",
    "updated_date": "2024-09-05 17:01:33 UTC"
  },
  {
    "arxiv_id": "2407.12101v2",
    "title": "Better RAG using Relevant Information Gain",
    "authors": [
      "Marc Pickett",
      "Jeremy Hartman",
      "Ayan Kumar Bhowmick",
      "Raquib-ul Alam",
      "Aditya Vempaty"
    ],
    "abstract": "A common way to extend the memory of large language models (LLMs) is by\nretrieval augmented generation (RAG), which inserts text retrieved from a\nlarger memory into an LLM's context window. However, the context window is\ntypically limited to several thousand tokens, which limits the number of\nretrieved passages that can inform a model's response. For this reason, it's\nimportant to avoid occupying context window space with redundant information by\nensuring a degree of diversity among retrieved passages. At the same time, the\ninformation should also be relevant to the current task. Most prior methods\nthat encourage diversity among retrieved results, such as Maximal Marginal\nRelevance (MMR), do so by incorporating an objective that explicitly trades off\ndiversity and relevance. We propose a novel simple optimization metric based on\nrelevant information gain, a probabilistic measure of the total information\nrelevant to a query for a set of retrieved results. By optimizing this metric,\ndiversity organically emerges from our system. When used as a drop-in\nreplacement for the retrieval component of a RAG system, this method yields\nstate-of-the-art performance on question answering tasks from the Retrieval\nAugmented Generation Benchmark (RGB), outperforming existing metrics that\ndirectly optimize for relevance and diversity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "4 page paper submitted to EMNLP",
    "pdf_url": "http://arxiv.org/pdf/2407.12101v2",
    "published_date": "2024-07-16 18:09:21 UTC",
    "updated_date": "2025-02-12 21:48:22 UTC"
  },
  {
    "arxiv_id": "2407.12077v1",
    "title": "GoldFinch: High Performance RWKV/Transformer Hybrid with Linear Pre-Fill and Extreme KV-Cache Compression",
    "authors": [
      "Daniel Goldstein",
      "Fares Obeid",
      "Eric Alcaide",
      "Guangyu Song",
      "Eugene Cheah"
    ],
    "abstract": "We introduce GoldFinch, a hybrid Linear Attention/Transformer sequence model\nthat uses a new technique to efficiently generate a highly compressed and\nreusable KV-Cache in linear time and space with respect to sequence length.\nGoldFinch stacks our new GOLD transformer on top of an enhanced version of the\nFinch (RWKV-6) architecture. We train up to 1.5B parameter class models of the\nFinch, Llama, and GoldFinch architectures, and find dramatically improved\nmodeling performance relative to both Finch and Llama. Our cache size savings\nincrease linearly with model layer count, ranging from 756-2550 times smaller\nthan the traditional transformer cache for common sizes, enabling inference of\nextremely large context lengths even on limited hardware. Although\nautoregressive generation has O(n) time complexity per token because of\nattention, pre-fill computation of the entire initial cache state for a\nsubmitted context costs only O(1) time per token due to the use of a recurrent\nneural network (RNN) to generate this cache. We release our trained weights and\ntraining code under the Apache 2.0 license for community use.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12077v1",
    "published_date": "2024-07-16 18:00:00 UTC",
    "updated_date": "2024-07-16 18:00:00 UTC"
  },
  {
    "arxiv_id": "2407.11969v4",
    "title": "Does Refusal Training in LLMs Generalize to the Past Tense?",
    "authors": [
      "Maksym Andriushchenko",
      "Nicolas Flammarion"
    ],
    "abstract": "Refusal training is widely used to prevent LLMs from generating harmful,\nundesirable, or illegal outputs. We reveal a curious generalization gap in the\ncurrent refusal training approaches: simply reformulating a harmful request in\nthe past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make\na Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art\nLLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet,\nGPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o mini, GPT-4o, o1-mini,\no1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For\nexample, the success rate of this simple attack on GPT-4o increases from 1%\nusing direct requests to 88% using 20 past tense reformulation attempts on\nharmful requests from JailbreakBench with GPT-4 as a jailbreak judge.\nInterestingly, we also find that reformulations in the future tense are less\neffective, suggesting that refusal guardrails tend to consider past historical\nquestions more benign than hypothetical future questions. Moreover, our\nexperiments on fine-tuning GPT-3.5 Turbo show that defending against past\nreformulations is feasible when past tense examples are explicitly included in\nthe fine-tuning data. Overall, our findings highlight that the widely used\nalignment techniques -- such as SFT, RLHF, and adversarial training -- employed\nto align the studied models can be brittle and do not always generalize as\nintended. We provide code and jailbreak artifacts at\nhttps://github.com/tml-epfl/llm-past-tense.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICLR 2025. Updates in v2 and v3: added GPT-4o, Claude 3.5\n  Sonnet, o1-mini, and o1-preview results. Code and jailbreak artifacts:\n  https://github.com/tml-epfl/llm-past-tense",
    "pdf_url": "http://arxiv.org/pdf/2407.11969v4",
    "published_date": "2024-07-16 17:59:55 UTC",
    "updated_date": "2025-04-17 18:36:08 UTC"
  },
  {
    "arxiv_id": "2407.11966v1",
    "title": "Efficient Training with Denoised Neural Weights",
    "authors": [
      "Yifan Gong",
      "Zheng Zhan",
      "Yanyu Li",
      "Yerlan Idelbayev",
      "Andrey Zharkov",
      "Kfir Aberman",
      "Sergey Tulyakov",
      "Yanzhi Wang",
      "Jian Ren"
    ],
    "abstract": "Good weight initialization serves as an effective measure to reduce the\ntraining cost of a deep neural network (DNN) model. The choice of how to\ninitialize parameters is challenging and may require manual tuning, which can\nbe time-consuming and prone to human error. To overcome such limitations, this\nwork takes a novel step towards building a weight generator to synthesize the\nneural weights for initialization. We use the image-to-image translation task\nwith generative adversarial networks (GANs) as an example due to the ease of\ncollecting model weights spanning a wide range. Specifically, we first collect\na dataset with various image editing concepts and their corresponding trained\nweights, which are later used for the training of the weight generator. To\naddress the different characteristics among layers and the substantial number\nof weights to be predicted, we divide the weights into equal-sized blocks and\nassign each block an index. Subsequently, a diffusion model is trained with\nsuch a dataset using both text conditions of the concept and the block indexes.\nBy initializing the image translation model with the denoised weights predicted\nby our diffusion model, the training requires only 43.3 seconds. Compared to\ntraining from scratch (i.e., Pix2pix), we achieve a 15x training time\nacceleration for a new concept while obtaining even better image generation\nquality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024. Project Page:\n  https://yifanfanfanfan.github.io/denoised-weights/",
    "pdf_url": "http://arxiv.org/pdf/2407.11966v1",
    "published_date": "2024-07-16 17:59:42 UTC",
    "updated_date": "2024-07-16 17:59:42 UTC"
  },
  {
    "arxiv_id": "2407.11962v2",
    "title": "Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling",
    "authors": [
      "Jaehyeok Kim",
      "Dongyoon Wee",
      "Dan Xu"
    ],
    "abstract": "This paper introduces Motion-oriented Compositional Neural Radiance Fields\n(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of\nmonocular human videos via novel non-rigid motion modeling approach. In the\ncontext of dynamic clothed humans, complex cloth dynamics generate non-rigid\nmotions that are intrinsically distinct from skeletal articulations and\ncritically important for the rendering quality. The conventional approach\nmodels non-rigid motions as spatial (3D) deviations in addition to skeletal\ntransformations. However, it is either time-consuming or challenging to achieve\noptimal quality due to its high learning complexity without a direct\nsupervision. To target this problem, we propose a novel approach of modeling\nnon-rigid motions as radiance residual fields to benefit from more direct color\nsupervision in the rendering and utilize the rigid radiance fields as a prior\nto reduce the complexity of the learning process. Our approach utilizes a\nsingle multiresolution hash encoding (MHE) to concurrently learn the canonical\nT-pose representation from rigid skeletal motions and the radiance residual\nfield for non-rigid motions. Additionally, to further improve both training\nefficiency and usability, we extend MoCo-NeRF to support simultaneous training\nof multiple subjects within a single framework, thanks to our effective design\nfor modeling non-rigid motions. This scalability is achieved through the\nintegration of a global MHE and learnable identity codes in addition to\nmultiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,\nclearly demonstrating state-of-the-art performance in both single- and\nmulti-subject settings. The code and model will be made publicly available at\nthe project page: https://stevejaehyeok.github.io/publications/moco-nerf.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11962v2",
    "published_date": "2024-07-16 17:59:01 UTC",
    "updated_date": "2024-07-18 08:44:16 UTC"
  },
  {
    "arxiv_id": "2407.12883v4",
    "title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval",
    "authors": [
      "Hongjin Su",
      "Howard Yen",
      "Mengzhou Xia",
      "Weijia Shi",
      "Niklas Muennighoff",
      "Han-yu Wang",
      "Haisu Liu",
      "Quan Shi",
      "Zachary S. Siegel",
      "Michael Tang",
      "Ruoxi Sun",
      "Jinsung Yoon",
      "Sercan O. Arik",
      "Danqi Chen",
      "Tao Yu"
    ],
    "abstract": "Existing retrieval benchmarks primarily consist of information-seeking\nqueries (e.g., aggregated questions from search engines) where keyword or\nsemantic-based retrieval is usually sufficient. However, many complex\nreal-world queries require in-depth reasoning to identify relevant documents\nthat go beyond surface form matching. For example, finding documentation for a\ncoding question requires understanding the logic and syntax of the functions\ninvolved. To better benchmark retrieval on such challenging queries, we\nintroduce BRIGHT, the first text retrieval benchmark that requires intensive\nreasoning to retrieve relevant documents. Our dataset consists of 1,384\nreal-world queries spanning diverse domains, such as economics, psychology,\nmathematics, and coding. These queries are drawn from naturally occurring and\ncarefully curated human data. Extensive evaluation reveals that even\nstate-of-the-art retrieval models perform poorly on BRIGHT. The leading model\non the MTEB leaderboard (Muennighoff et al., 2023) SFR-Embedding-Mistral (Meng\net al., 2024), which achieves a score of 59.0 nDCG@10,1 produces a score of\nnDCG@10 of 18.3 on BRIGHT. We show that incorporating explicit reasoning about\nthe query improves retrieval performance by up to 12.2 points. Moreover,\nincorporating retrieved documents from the top-performing retriever boosts\nquestion-answering performance. We believe that BRIGHT paves the way for future\nresearch on retrieval systems in more realistic and challenging settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "51 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.12883v4",
    "published_date": "2024-07-16 17:58:27 UTC",
    "updated_date": "2025-03-26 07:37:26 UTC"
  },
  {
    "arxiv_id": "2407.11948v1",
    "title": "Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation",
    "authors": [
      "Congbo Ma",
      "Wei Emma Zhang",
      "Dileepa Pitawela",
      "Haojie Zhuang",
      "Yanfeng Shu"
    ],
    "abstract": "The utilization of Transformer-based models prospers the growth of\nmulti-document summarization (MDS). Given the huge impact and widespread\nadoption of Transformer-based models in various natural language processing\ntasks, investigating their performance and behaviors in the context of MDS\nbecomes crucial for advancing the field and enhancing the quality of summary.\nTo thoroughly examine the behaviours of Transformer-based MDS models, this\npaper presents five empirical studies on (1) measuring the impact of document\nboundary separators quantitatively; (2) exploring the effectiveness of\ndifferent mainstream Transformer structures; (3) examining the sensitivity of\nthe encoder and decoder; (4) discussing different training strategies; and (5)\ndiscovering the repetition in a summary generation. The experimental results on\nprevalent MDS datasets and eleven evaluation metrics show the influence of\ndocument boundary separators, the granularity of different level features and\ndifferent model training strategies. The results also reveal that the decoder\nexhibits greater sensitivity to noises compared to the encoder. This\nunderscores the important role played by the decoder, suggesting a potential\ndirection for future research in MDS. Furthermore, the experimental results\nindicate that the repetition problem in the generated summaries has\ncorrelations with the high uncertainty scores.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11948v1",
    "published_date": "2024-07-16 17:42:37 UTC",
    "updated_date": "2024-07-16 17:42:37 UTC"
  },
  {
    "arxiv_id": "2407.11928v1",
    "title": "Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach",
    "authors": [
      "Tanvir Hossain",
      "Khaled Mohammed Saifuddin",
      "Muhammad Ifte Khairul Islam",
      "Farhan Tanvir",
      "Esra Akbas"
    ],
    "abstract": "Graph Neural Network (GNN) achieves great success for node-level and\ngraph-level tasks via encoding meaningful topological structures of networks in\nvarious domains, ranging from social to biological networks. However, repeated\naggregation operations lead to excessive mixing of node representations,\nparticularly in dense regions with multiple GNN layers, resulting in nearly\nindistinguishable embeddings. This phenomenon leads to the oversmoothing\nproblem that hampers downstream graph analytics tasks. To overcome this issue,\nwe propose a novel and flexible truss-based graph sparsification model that\nprunes edges from dense regions of the graph. Pruning redundant edges in dense\nregions helps to prevent the aggregation of excessive neighborhood information\nduring hierarchical message passing and pooling in GNN models. We then utilize\nour sparsification model in the state-of-the-art baseline GNNs and pooling\nmodels, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and\nAdamGNN. Extensive experiments on different real-world datasets show that our\nmodel significantly improves the performance of the baseline GNN models in the\ngraph classification task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11928v1",
    "published_date": "2024-07-16 17:21:36 UTC",
    "updated_date": "2024-07-16 17:21:36 UTC"
  },
  {
    "arxiv_id": "2407.11919v1",
    "title": "What's Wrong? Refining Meeting Summaries with LLM Feedback",
    "authors": [
      "Frederic Kirstein",
      "Terry Ruas",
      "Bela Gipp"
    ],
    "abstract": "Meeting summarization has become a critical task since digital encounters\nhave become a common practice. Large language models (LLMs) show great\npotential in summarization, offering enhanced coherence and context\nunderstanding compared to traditional methods. However, they still struggle to\nmaintain relevance and avoid hallucination. We introduce a multi-LLM correction\napproach for meeting summarization using a two-phase process that mimics the\nhuman review process: mistake identification and summary refinement. We release\nQMSum Mistake, a dataset of 200 automatically generated meeting summaries\nannotated by humans on nine error types, including structural, omission, and\nirrelevance errors. Our experiments show that these errors can be identified\nwith high accuracy by an LLM. We transform identified mistakes into actionable\nfeedback to improve the quality of a given summary measured by relevance,\ninformativeness, conciseness, and coherence. This post-hoc refinement\neffectively improves summary quality by leveraging multiple LLMs to validate\noutput quality. Our multi-LLM approach for meeting summarization shows\npotential for similar complex text generation tasks requiring robustness,\naction planning, and discussion towards a goal.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11919v1",
    "published_date": "2024-07-16 17:10:16 UTC",
    "updated_date": "2024-07-16 17:10:16 UTC"
  },
  {
    "arxiv_id": "2407.11915v1",
    "title": "Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task",
    "authors": [
      "Bosong Ding",
      "Murat Kirtay",
      "Giacomo Spigler"
    ],
    "abstract": "Head movements are crucial for social human-human interaction. They can\ntransmit important cues (e.g., joint attention, speaker detection) that cannot\nbe achieved with verbal interaction alone. This advantage also holds for\nhuman-robot interaction. Even though modeling human motions through generative\nAI models has become an active research area within robotics in recent years,\nthe use of these methods for producing head movements in human-robot\ninteraction remains underexplored. In this work, we employed a generative AI\npipeline to produce human-like head movements for a Nao humanoid robot. In\naddition, we tested the system on a real-time active-speaker tracking task in a\ngroup conversation setting. Overall, the results show that the Nao robot\nsuccessfully imitates human head movements in a natural manner while actively\ntracking the speakers during the conversation. Code and data from this study\nare available at https://github.com/dingdingding60/Humanoids2024HRI",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11915v1",
    "published_date": "2024-07-16 17:08:40 UTC",
    "updated_date": "2024-07-16 17:08:40 UTC"
  },
  {
    "arxiv_id": "2407.12882v1",
    "title": "InstructAV: Instruction Fine-tuning Large Language Models for Authorship Verification",
    "authors": [
      "Yujia Hu",
      "Zhiqiang Hu",
      "Chun-Wei Seah",
      "Roy Ka-Wei Lee"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in a\nwide range of NLP tasks. However, when it comes to authorship verification (AV)\ntasks, which involve determining whether two given texts share the same\nauthorship, even advanced models like ChatGPT exhibit notable limitations. This\npaper introduces a novel approach, termed InstructAV, for authorship\nverification. This approach utilizes LLMs in conjunction with a\nparameter-efficient fine-tuning (PEFT) method to simultaneously improve\naccuracy and explainability. The distinctiveness of InstructAV lies in its\nability to align classification decisions with transparent and understandable\nexplanations, representing a significant progression in the field of authorship\nverification. Through comprehensive experiments conducted across various\ndatasets, InstructAV demonstrates its state-of-the-art performance on the AV\ntask, offering high classification accuracy coupled with enhanced explanation\nreliability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12882v1",
    "published_date": "2024-07-16 16:27:01 UTC",
    "updated_date": "2024-07-16 16:27:01 UTC"
  },
  {
    "arxiv_id": "2407.11877v2",
    "title": "Bridging Weighted First Order Model Counting and Graph Polynomials",
    "authors": [
      "Qipeng Kuang",
      "Ondřej Kuželka",
      "Yuanhong Wang",
      "Yuyi Wang"
    ],
    "abstract": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the\nweighted sum of models of a given first-order logic sentence over a given\ndomain. It can be solved in time polynomial in the domain size for sentences\nfrom the two-variable fragment with counting quantifiers, known as $C^2$. This\npolynomial-time complexity is known to be retained when extending $C^2$ by one\nof the following axioms: linear order axiom, tree axiom, forest axiom, directed\nacyclic graph axiom or connectedness axiom. An interesting question remains as\nto which other axioms can be added to the first-order sentences in this way. We\nprovide a new perspective on this problem by associating WFOMC with graph\npolynomials. Using WFOMC, we define Weak Connectedness Polynomial and Strong\nConnectedness Polynomials for first-order logic sentences. It turns out that\nthese polynomials have the following interesting properties. First, they can be\ncomputed in polynomial time in the domain size for sentences from $C^2$.\nSecond, we can use them to solve WFOMC with all of the existing axioms known to\nbe tractable as well as with new ones such as bipartiteness, strong\nconnectedness, having $k$ connected components, etc. Third, the well-known\nTutte polynomial can be recovered as a special case of the Weak Connectedness\nPolynomial, and the Strict and Non-Strict Directed Chromatic Polynomials can be\nrecovered from the Strong Connectedness Polynomials.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "03C13, 68T27, 05A15 (Primary)",
      "F.4.0"
    ],
    "primary_category": "cs.LO",
    "comment": "33 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11877v2",
    "published_date": "2024-07-16 16:01:25 UTC",
    "updated_date": "2024-11-26 03:00:54 UTC"
  },
  {
    "arxiv_id": "2407.12075v1",
    "title": "Tiled Bit Networks: Sub-Bit Neural Network Compression Through Reuse of Learnable Binary Vectors",
    "authors": [
      "Matt Gorbett",
      "Hossein Shirazi",
      "Indrakshi Ray"
    ],
    "abstract": "Binary Neural Networks (BNNs) enable efficient deep learning by saving on\nstorage and computational costs. However, as the size of neural networks\ncontinues to grow, meeting computational requirements remains a challenge. In\nthis work, we propose a new form of quantization to tile neural network layers\nwith sequences of bits to achieve sub-bit compression of binary-weighted neural\nnetworks. The method learns binary vectors (i.e. tiles) to populate each layer\nof a model via aggregation and reshaping operations. During inference, the\nmethod reuses a single tile per layer to represent the full tensor. We employ\nthe approach to both fully-connected and convolutional layers, which make up\nthe breadth of space in most neural architectures. Empirically, the approach\nachieves near fullprecision performance on a diverse range of architectures\n(CNNs, Transformers, MLPs) and tasks (classification, segmentation, and time\nseries forecasting) with up to an 8x reduction in size compared to\nbinary-weighted models. We provide two implementations for Tiled Bit Networks:\n1) we deploy the model to a microcontroller to assess its feasibility in\nresource-constrained environments, and 2) a GPU-compatible inference kernel to\nfacilitate the reuse of a single tile per layer in memory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12075v1",
    "published_date": "2024-07-16 15:55:38 UTC",
    "updated_date": "2024-07-16 15:55:38 UTC"
  },
  {
    "arxiv_id": "2407.11854v1",
    "title": "Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection",
    "authors": [
      "Gaetan Lopez Latouche",
      "Marc-André Carbonneau",
      "Ben Swanson"
    ],
    "abstract": "Grammatical Error Detection (GED) methods rely heavily on human annotated\nerror corpora. However, these annotations are unavailable in many low-resource\nlanguages. In this paper, we investigate GED in this context. Leveraging the\nzero-shot cross-lingual transfer capabilities of multilingual pre-trained\nlanguage models, we train a model using data from a diverse set of languages to\ngenerate synthetic errors in other languages. These synthetic error corpora are\nthen used to train a GED model. Specifically we propose a two-stage fine-tuning\npipeline where the GED model is first fine-tuned on multilingual synthetic data\nfrom target languages followed by fine-tuning on human-annotated GED corpora\nfrom source languages. This approach outperforms current state-of-the-art\nannotation-free GED methods. We also analyse the errors produced by our method\nand other strong baselines, finding that our approach produces errors that are\nmore diverse and more similar to human errors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11854v1",
    "published_date": "2024-07-16 15:35:15 UTC",
    "updated_date": "2024-07-16 15:35:15 UTC"
  },
  {
    "arxiv_id": "2407.11852v1",
    "title": "Schema Matching with Large Language Models: an Experimental Study",
    "authors": [
      "Marcel Parciak",
      "Brecht Vandevoort",
      "Frank Neven",
      "Liesbet M. Peeters",
      "Stijn Vansummeren"
    ],
    "abstract": "Large Language Models (LLMs) have shown useful applications in a variety of\ntasks, including data wrangling. In this paper, we investigate the use of an\noff-the-shelf LLM for schema matching. Our objective is to identify semantic\ncorrespondences between elements of two relational schemas using only names and\ndescriptions. Using a newly created benchmark from the health domain, we\npropose different so-called task scopes. These are methods for prompting the\nLLM to do schema matching, which vary in the amount of context information\ncontained in the prompt. Using these task scopes we compare LLM-based schema\nmatching against a string similarity baseline, investigating matching quality,\nverification effort, decisiveness, and complementarity of the approaches. We\nfind that matching quality suffers from a lack of context information, but also\nfrom providing too much context information. In general, using newer LLM\nversions increases decisiveness. We identify task scopes that have acceptable\nverification effort and succeed in identifying a significant number of true\nsemantic matches. Our study shows that LLMs have potential in bootstrapping the\nschema matching process and are able to assist data engineers in speeding up\nthis task solely based on schema element names and descriptions without the\nneed for data instances.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted at the 2nd International Workshop on Tabular Data Analysis\n  (TaDA24), collocated with the 50th International Conference on Very Large\n  Data Bases (VLDB 2024) Guangzhou, China - August 29, 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11852v1",
    "published_date": "2024-07-16 15:33:00 UTC",
    "updated_date": "2024-07-16 15:33:00 UTC"
  },
  {
    "arxiv_id": "2407.12074v1",
    "title": "Enhancing Parameter Efficiency and Generalization in Large-Scale Models: A Regularized and Masked Low-Rank Adaptation Approach",
    "authors": [
      "Yuzhu Mao",
      "Siqi Ping",
      "Zihao Zhao",
      "Yang Liu",
      "Wenbo Ding"
    ],
    "abstract": "Large pre-trained models, such as large language models (LLMs), present\nsignificant resource challenges for fine-tuning due to their extensive\nparameter sizes, especially for applications in mobile systems. To address\nthis, Low-Rank Adaptation (LoRA) has been developed to reduce resource\nconsumption while maintaining satisfactory fine-tuning results. Despite its\neffectiveness, the original LoRA method faces challenges of suboptimal\nperformance and overfitting. This paper investigates the intrinsic dimension of\nthe matrix updates approximated by the LoRA method and reveals the performance\nbenefits of increasing this intrinsic dimension. By employing regularization\nand a gradient masking method that encourages higher intrinsic dimension, the\nproposed method, termed Regularized and Masked LoRA (RM-LoRA), achieves\nsuperior generalization performance with the same or lower trainable parameter\nbudget compared to the original LoRA and its latest variants across various\nopen-source vision and language datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12074v1",
    "published_date": "2024-07-16 15:26:31 UTC",
    "updated_date": "2024-07-16 15:26:31 UTC"
  },
  {
    "arxiv_id": "2407.11844v1",
    "title": "Variational Randomized Smoothing for Sample-Wise Adversarial Robustness",
    "authors": [
      "Ryo Hase",
      "Ye Wang",
      "Toshiaki Koike-Akino",
      "Jing Liu",
      "Kieran Parsons"
    ],
    "abstract": "Randomized smoothing is a defensive technique to achieve enhanced robustness\nagainst adversarial examples which are small input perturbations that degrade\nthe performance of neural network models. Conventional randomized smoothing\nadds random noise with a fixed noise level for every input sample to smooth out\nadversarial perturbations. This paper proposes a new variational framework that\nuses a per-sample noise level suitable for each input by introducing a noise\nlevel selector. Our experimental results demonstrate enhancement of empirical\nrobustness against adversarial attacks. We also provide and analyze the\ncertified robustness for our sample-wise smoothing method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, under preparation",
    "pdf_url": "http://arxiv.org/pdf/2407.11844v1",
    "published_date": "2024-07-16 15:25:13 UTC",
    "updated_date": "2024-07-16 15:25:13 UTC"
  },
  {
    "arxiv_id": "2407.11843v3",
    "title": "Preemptive Detection and Correction of Misaligned Actions in LLM Agents",
    "authors": [
      "Haishuo Fang",
      "Xiaodan Zhu",
      "Iryna Gurevych"
    ],
    "abstract": "Deploying LLM-based agents in real-life applications often faces a critical\nchallenge: the misalignment between agents' behavior and user intent. Such\nmisalignment may lead agents to unintentionally execute critical actions that\ncarry negative outcomes (e.g., accidentally triggering a \"buy-now\" in web\nshopping), resulting in undesirable or even irreversible consequences. Although\naddressing these issues is crucial, the preemptive detection and correction of\nmisaligned actions remains relatively underexplored. To fill this gap, we\nintroduce InferAct, a novel approach that leverages the belief reasoning\nability of LLMs, grounded in Theory-of-Mind, to detect misaligned actions\nbefore execution. Once the misalignment is detected, InferAct alerts users for\ntimely correction, preventing adverse outcomes and enhancing the reliability of\nLLM agents' decision-making processes. Experiments on three widely used tasks\ndemonstrate that InferAct achieves up to 20% improvements on Marco-F1 against\nbaselines in misaligned action detection. An in-depth evaluation of\nmisalignment correction further highlights InferAct's effectiveness in\nimproving agent alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11843v3",
    "published_date": "2024-07-16 15:24:44 UTC",
    "updated_date": "2024-12-27 14:17:05 UTC"
  },
  {
    "arxiv_id": "2407.11830v3",
    "title": "zIA: a GenAI-powered local auntie assists tourists in Italy",
    "authors": [
      "Alexio Cassani",
      "Michele Ruberl",
      "Antonio Salis",
      "Giacomo Giannese",
      "Gianluca Boanelli"
    ],
    "abstract": "The Tourism and Destination Management Organization (DMO) industry is rapidly\nevolving to adapt to new technologies and traveler expectations. Generative\nArtificial Intelligence (AI) offers an astonishing and innovative opportunity\nto enhance the tourism experience by providing personalized, interactive and\nengaging assistance. In this article, we propose a generative AI-based chatbot\nfor tourism assistance. The chatbot leverages AI ability to generate realistic\nand creative texts, adopting the friendly persona of the well-known Italian\nall-knowledgeable aunties, to provide tourists with personalized information,\ntailored and dynamic pre, during and post recommendations and trip plans and\npersonalized itineraries, using both text and voice commands, and supporting\ndifferent languages to satisfy Italian and foreign tourists expectations. This\nwork is under development in the Molise CTE research project, funded by the\nItalian Minister of the Economic Growth (MIMIT), with the aim to leverage the\nbest emerging technologies available, such as Cloud and AI to produce state of\nthe art solutions in the Smart City environment.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11830v3",
    "published_date": "2024-07-16 15:18:12 UTC",
    "updated_date": "2024-08-19 09:35:11 UTC"
  },
  {
    "arxiv_id": "2407.11827v1",
    "title": "GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text",
    "authors": [
      "Kyle Hamilton",
      "Luca Longo",
      "Bojan Bozic"
    ],
    "abstract": "While the use of machine learning for the detection of propaganda techniques\nin text has garnered considerable attention, most approaches focus on\n\"black-box\" solutions with opaque inner workings. Interpretable approaches\nprovide a solution, however, they depend on careful feature engineering and\ncostly expert annotated data. Additionally, language features specific to\npropagandistic text are generally the focus of rhetoricians or linguists, and\nthere is no data set labeled with such features suitable for machine learning.\nThis study codifies 22 rhetorical and linguistic features identified in\nliterature related to the language of persuasion for the purpose of annotating\nan existing data set labeled with propaganda techniques. To help human experts\nannotate natural language sentences with these features, RhetAnn, a web\napplication, was specifically designed to minimize an otherwise considerable\nmental effort. Finally, a small set of annotated data was used to fine-tune\nGPT-3.5, a generative large language model (LLM), to annotate the remaining\ndata while optimizing for financial cost and classification accuracy. This\nstudy demonstrates how combining a small number of human annotated examples\nwith GPT can be an effective strategy for scaling the annotation process at a\nfraction of the cost of traditional annotation relying solely on human experts.\nThe results are on par with the best performing model at the time of writing,\nnamely GPT-4, at 10x less the cost. Our contribution is a set of features,\ntheir properties, definitions, and examples in a machine-readable format, along\nwith the code for RhetAnn and the GPT prompts and fine-tuning procedures for\nadvancing state-of-the-art interpretable propaganda technique detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11827v1",
    "published_date": "2024-07-16 15:15:39 UTC",
    "updated_date": "2024-07-16 15:15:39 UTC"
  },
  {
    "arxiv_id": "2407.11824v2",
    "title": "The Future of Data Science Education",
    "authors": [
      "Brian Wright",
      "Peter Alonzi",
      "Ali Rivera"
    ],
    "abstract": "The definition of Data Science is a hotly debated topic. For many, the\ndefinition is a simple shortcut to Artificial Intelligence or Machine Learning.\nHowever, there is far more depth and nuance to the field of Data Science than a\nsimple shortcut can provide. The School of Data Science at the University of\nVirginia has developed a novel model for the definition of Data Science. This\nmodel is based on identifying a unified understanding of the data work done\nacross all areas of Data Science. It represents a generational leap forward in\nhow we understand and teach Data Science. In this paper we will present the\ncore features of the model and explain how it unifies various concepts going\nfar beyond the analytics component of AI. From this foundation we will present\nour Undergraduate Major curriculum in Data Science and demonstrate how it\nprepares students to be well-rounded Data Science team members and leaders. The\npaper will conclude with an in-depth overview of the Foundations of Data\nScience course designed to introduce students to the field while also\nimplementing proven STEM oriented pedagogical methods. These include, for\nexample, specifications grading, active learning lectures, guest lectures from\nindustry experts and weekly gamification labs.",
    "categories": [
      "stat.OT",
      "cs.AI"
    ],
    "primary_category": "stat.OT",
    "comment": "12 pages, 5 figures, publish at the 53rd Annual Southeast Decision\n  Science Institute 2024, won best paper for Innovation track",
    "pdf_url": "http://arxiv.org/pdf/2407.11824v2",
    "published_date": "2024-07-16 15:11:54 UTC",
    "updated_date": "2025-03-17 19:06:45 UTC"
  },
  {
    "arxiv_id": "2407.12881v1",
    "title": "BinaryAlign: Word Alignment as Binary Sequence Labeling",
    "authors": [
      "Gaetan Lopez Latouche",
      "Marc-André Carbonneau",
      "Ben Swanson"
    ],
    "abstract": "Real world deployments of word alignment are almost certain to cover both\nhigh and low resource languages. However, the state-of-the-art for this task\nrecommends a different model class depending on the availability of gold\nalignment training data for a particular language pair. We propose BinaryAlign,\na novel word alignment technique based on binary sequence labeling that\noutperforms existing approaches in both scenarios, offering a unifying approach\nto the task. Additionally, we vary the specific choice of multilingual\nfoundation model, perform stratified error analysis over alignment error type,\nand explore the performance of BinaryAlign on non-English language pairs. We\nmake our source code publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12881v1",
    "published_date": "2024-07-16 15:11:06 UTC",
    "updated_date": "2024-07-16 15:11:06 UTC"
  },
  {
    "arxiv_id": "2407.11821v1",
    "title": "Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Bo Xiong",
      "Trung-Kien Tran",
      "Mojtaba Nayyeri",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Statistical information is ubiquitous but drawing valid conclusions from it\nis prohibitively hard. We explain how knowledge graph embeddings can be used to\napproximate probabilistic inference efficiently using the example of\nStatistical EL (SEL), a statistical extension of the lightweight Description\nLogic EL. We provide proofs for runtime and soundness guarantees, and\nempirically evaluate the runtime and approximation quality of our approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2407.11821v1",
    "published_date": "2024-07-16 15:08:33 UTC",
    "updated_date": "2024-07-16 15:08:33 UTC"
  },
  {
    "arxiv_id": "2407.11820v3",
    "title": "Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation",
    "authors": [
      "Juncheng Ma",
      "Peiwen Sun",
      "Yaoting Wang",
      "Di Hu"
    ],
    "abstract": "Audio-Visual Segmentation (AVS) aims to achieve pixel-level localization of\nsound sources in videos, while Audio-Visual Semantic Segmentation (AVSS), as an\nextension of AVS, further pursues semantic understanding of audio-visual\nscenes. However, since the AVSS task requires the establishment of audio-visual\ncorrespondence and semantic understanding simultaneously, we observe that\nprevious methods have struggled to handle this mashup of objectives in\nend-to-end training, resulting in insufficient learning and sub-optimization.\nTherefore, we propose a two-stage training strategy called \\textit{Stepping\nStones}, which decomposes the AVSS task into two simple subtasks from\nlocalization to semantic understanding, which are fully optimized in each stage\nto achieve step-by-step global optimization. This training strategy has also\nproved its generalization and effectiveness on existing methods. To further\nimprove the performance of AVS tasks, we propose a novel framework Adaptive\nAudio Visual Segmentation, in which we incorporate an adaptive audio query\ngenerator and integrate masked attention into the transformer decoder,\nfacilitating the adaptive fusion of visual and audio features. Extensive\nexperiments demonstrate that our methods achieve state-of-the-art results on\nall three AVS benchmarks. The project homepage can be accessed at\nhttps://gewu-lab.github.io/stepping_stones/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV2024 poster. Project url:\n  https://gewu-lab.github.io/stepping_stones",
    "pdf_url": "http://arxiv.org/pdf/2407.11820v3",
    "published_date": "2024-07-16 15:08:30 UTC",
    "updated_date": "2024-09-12 09:20:26 UTC"
  },
  {
    "arxiv_id": "2407.12073v5",
    "title": "Relational Representation Distillation",
    "authors": [
      "Nikolaos Giakoumoglou",
      "Tania Stathaki"
    ],
    "abstract": "Knowledge distillation involves transferring knowledge from large, cumbersome\nteacher models to more compact student models. The standard approach minimizes\nthe Kullback-Leibler (KL) divergence between the probabilistic outputs of a\nteacher and student network. However, this approach fails to capture important\nstructural relationships in the teacher's internal representations. Recent\nadvances have turned to contrastive learning objectives, but these methods\nimpose overly strict constraints through instance-discrimination, forcing apart\nsemantically similar samples even when they should maintain similarity. This\nmotivates an alternative objective by which we preserve relative relationships\nbetween instances. Our method employs separate temperature parameters for\nteacher and student distributions, with sharper student outputs, enabling\nprecise learning of primary relationships while preserving secondary\nsimilarities. We show theoretical connections between our objective and both\nInfoNCE loss and KL divergence. Experiments demonstrate that our method\nsignificantly outperforms existing knowledge distillation methods across\ndiverse knowledge transfer tasks, achieving better alignment with teacher\nmodels, and sometimes even outperforms the teacher network.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "I.4; I.2"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. Code: https://github.com/giakoumoglou/distillers,\n  Supplementary: https://giakoumoglou.com/src/rrd_suppl.pdf",
    "pdf_url": "http://arxiv.org/pdf/2407.12073v5",
    "published_date": "2024-07-16 14:56:13 UTC",
    "updated_date": "2025-05-12 18:39:07 UTC"
  },
  {
    "arxiv_id": "2407.11802v5",
    "title": "Discriminative and Consistent Representation Distillation",
    "authors": [
      "Nikolaos Giakoumoglou",
      "Tania Stathaki"
    ],
    "abstract": "Knowledge Distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. While contrastive learning has shown promise\nin self-supervised learning by creating discriminative representations, its\napplication in knowledge distillation remains limited and focuses primarily on\ndiscrimination, neglecting the structural relationships captured by the teacher\nmodel. To address this limitation, we propose Discriminative and Consistent\nDistillation (DCD), which employs a contrastive loss along with a consistency\nregularization to minimize the discrepancy between the distributions of teacher\nand student representations. Our method introduces learnable temperature and\nbias parameters that adapt during training to balance these complementary\nobjectives, replacing the fixed hyperparameters commonly used in contrastive\nlearning approaches. Through extensive experiments on CIFAR-100 and ImageNet\nILSVRC-2012, we demonstrate that DCD achieves state-of-the-art performance,\nwith the student model sometimes surpassing the teacher's accuracy.\nFurthermore, we show that DCD's learned representations exhibit superior\ncross-dataset generalization when transferred to Tiny ImageNet and STL-10.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "I.4; I.2"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. Code: https://github.com/giakoumoglou/distillers,\n  Supplementary: https://giakoumoglou.com/src/dcd_suppl.pdf",
    "pdf_url": "http://arxiv.org/pdf/2407.11802v5",
    "published_date": "2024-07-16 14:53:35 UTC",
    "updated_date": "2025-05-12 18:34:03 UTC"
  },
  {
    "arxiv_id": "2407.11793v1",
    "title": "Click-Gaussian: Interactive Segmentation to Any 3D Gaussians",
    "authors": [
      "Seokhun Choi",
      "Hyeonseop Song",
      "Jaechul Kim",
      "Taehyeong Kim",
      "Hoseok Do"
    ],
    "abstract": "Interactive segmentation of 3D Gaussians opens a great opportunity for\nreal-time manipulation of 3D scenes thanks to the real-time rendering\ncapability of 3D Gaussian Splatting. However, the current methods suffer from\ntime-consuming post-processing to deal with noisy segmentation output. Also,\nthey struggle to provide detailed segmentation, which is important for\nfine-grained manipulation of 3D scenes. In this study, we propose\nClick-Gaussian, which learns distinguishable feature fields of two-level\ngranularity, facilitating segmentation without time-consuming post-processing.\nWe delve into challenges stemming from inconsistently learned feature fields\nresulting from 2D segmentation obtained independently from a 3D scene. 3D\nsegmentation accuracy deteriorates when 2D segmentation results across the\nviews, primary cues for 3D segmentation, are in conflict. To overcome these\nissues, we propose Global Feature-guided Learning (GFL). GFL constructs the\nclusters of global feature candidates from noisy 2D segments across the views,\nwhich smooths out noises when training the features of 3D Gaussians. Our method\nruns in 10 ms per click, 15 to 130 times as fast as the previous methods, while\nalso significantly improving segmentation accuracy. Our project page is\navailable at https://seokhunchoi.github.io/Click-Gaussian",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024. The first two authors contributed equally to\n  this work",
    "pdf_url": "http://arxiv.org/pdf/2407.11793v1",
    "published_date": "2024-07-16 14:49:27 UTC",
    "updated_date": "2024-07-16 14:49:27 UTC"
  },
  {
    "arxiv_id": "2407.11790v4",
    "title": "Characterizing and Understanding HGNN Training on GPUs",
    "authors": [
      "Dengke Han",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "abstract": "Owing to their remarkable representation capabilities for heterogeneous graph\ndata, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in\nmany critical real-world domains such as recommendation systems and medical\nanalysis. Prior to their practical application, identifying the optimal HGNN\nmodel parameters tailored to specific tasks through extensive training is a\ntime-consuming and costly process. To enhance the efficiency of HGNN training,\nit is essential to characterize and analyze the execution semantics and\npatterns within the training process to identify performance bottlenecks. In\nthis study, we conduct an in-depth quantification and analysis of two\nmainstream HGNN training scenarios, including single-GPU and multi-GPU\ndistributed training. Based on the characterization results, we disclose the\nperformance bottlenecks and their underlying causes in different HGNN training\nscenarios and provide optimization guidelines from both software and hardware\nperspectives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 14 figures, to appear in ACM Transactions on Architecture\n  and Code Optimization (ACM TACO)",
    "pdf_url": "http://arxiv.org/pdf/2407.11790v4",
    "published_date": "2024-07-16 14:45:46 UTC",
    "updated_date": "2024-10-29 06:17:42 UTC"
  },
  {
    "arxiv_id": "2407.11789v1",
    "title": "Large Language Models as Misleading Assistants in Conversation",
    "authors": [
      "Betty Li Hou",
      "Kejian Shi",
      "Jason Phang",
      "James Aung",
      "Steven Adler",
      "Rosie Campbell"
    ],
    "abstract": "Large Language Models (LLMs) are able to provide assistance on a wide range\nof information-seeking tasks. However, model outputs may be misleading, whether\nunintentionally or in cases of intentional deception. We investigate the\nability of LLMs to be deceptive in the context of providing assistance on a\nreading comprehension task, using LLMs as proxies for human users. We compare\noutcomes of (1) when the model is prompted to provide truthful assistance, (2)\nwhen it is prompted to be subtly misleading, and (3) when it is prompted to\nargue for an incorrect answer. Our experiments show that GPT-4 can effectively\nmislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up\nto a 23% drop in accuracy on the task compared to when a truthful assistant is\nused. We also find that providing the user model with additional context from\nthe passage partially mitigates the influence of the deceptive model. This work\nhighlights the ability of LLMs to produce misleading information and the\neffects this may have in real-world situations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Next Generation of AI Safety Workshop, 41st International Conference\n  on Machine Learning (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.11789v1",
    "published_date": "2024-07-16 14:45:22 UTC",
    "updated_date": "2024-07-16 14:45:22 UTC"
  },
  {
    "arxiv_id": "2407.11784v2",
    "title": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development",
    "authors": [
      "Daoyuan Chen",
      "Haibin Wang",
      "Yilun Huang",
      "Ce Ge",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "The emergence of multimodal large models has advanced artificial\nintelligence, introducing unprecedented levels of performance and\nfunctionality. However, optimizing these models remains challenging due to\nhistorically isolated paths of model-centric and data-centric developments,\nleading to suboptimal outcomes and inefficient resource utilization. In\nresponse, we present a new sandbox suite tailored for integrated data-model\nco-development. This sandbox provides a feedback-driven experimental platform,\nenabling cost-effective iteration and guided refinement of both data and\nmodels. Our proposed ``Probe-Analyze-Refine'' workflow, validated through\npractical use cases on multimodal tasks such as image-text pre-training with\nCLIP, image-to-text generation with LLaVA-like models, and text-to-video\ngeneration with DiT-based models, yields transferable and notable performance\nboosts, such as topping the VBench leaderboard. Extensive experiments also\nuncover fruitful insights into the interplay between data quality, diversity,\nmodel behavior, and computational costs. All codes, datasets, and models are\nopen-sourced to foster future research and applications that would otherwise be\ninfeasible due to the lack of a dedicated co-development infrastructure.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages, 12 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11784v2",
    "published_date": "2024-07-16 14:40:07 UTC",
    "updated_date": "2025-02-05 03:55:45 UTC"
  },
  {
    "arxiv_id": "2407.11780v2",
    "title": "SwitchCIT: Switching for Continual Instruction Tuning",
    "authors": [
      "Xinbo Wu",
      "Max Hartman",
      "Vidhata Arjun Jayaraman",
      "Lav R. Varshney"
    ],
    "abstract": "Large language models (LLMs) and multimodal models (MMs) have exhibited\nimpressive capabilities in various domains, particularly in general language\nunderstanding and visual reasoning. However, these models, trained on massive\ndata, may not be finely optimized for specific tasks triggered by instructions.\nContinual instruction tuning is crucial to adapt a large model to evolving\ntasks and domains, ensuring their effectiveness and relevance across a wide\nrange of applications. In the context of continual instruction tuning, where\nmodels are sequentially trained on different tasks, catastrophic forgetting can\noccur, leading to performance degradation on previously learned tasks. This\nwork addresses the catastrophic forgetting in continual instruction learning\nthrough a switching mechanism for routing computations to parameter-efficient\ntuned models. We demonstrate the effectiveness of our method through\nexperiments on continual instruction tuning of different natural language\ngeneration tasks and vision-language tasks. We also showcase the advantages of\nour proposed method in terms of efficiency, scalability, portability, and\nprivacy preservation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11780v2",
    "published_date": "2024-07-16 14:37:33 UTC",
    "updated_date": "2024-12-18 18:21:53 UTC"
  },
  {
    "arxiv_id": "2407.11774v1",
    "title": "Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text",
    "authors": [
      "Seyedeh Fatemeh Ebrahimi",
      "Karim Akhavan Azari",
      "Amirmasoud Iravani",
      "Arian Qazvini",
      "Pouya Sadeghi",
      "Zeinab Sadat Taghavi",
      "Hossein Sameti"
    ],
    "abstract": "Detecting Machine-Generated Text (MGT) has emerged as a significant area of\nstudy within Natural Language Processing. While language models generate text,\nthey often leave discernible traces, which can be scrutinized using either\ntraditional feature-based methods or more advanced neural language models. In\nthis research, we explore the effectiveness of fine-tuning a RoBERTa-base\ntransformer, a powerful neural architecture, to address MGT detection as a\nbinary classification task. Focusing specifically on Subtask A\n(Monolingual-English) within the SemEval-2024 competition framework, our\nproposed system achieves an accuracy of 78.9% on the test dataset, positioning\nus at 57th among participants. Our study addresses this challenge while\nconsidering the limited hardware resources, resulting in a system that excels\nat identifying human-written texts but encounters challenges in accurately\ndiscerning MGTs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures, 2 tables. Proceedings of the 18th International\n  Workshop on Semantic Evaluation (SemEval-2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.11774v1",
    "published_date": "2024-07-16 14:33:01 UTC",
    "updated_date": "2024-07-16 14:33:01 UTC"
  },
  {
    "arxiv_id": "2407.11771v2",
    "title": "XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach",
    "authors": [
      "Truong Thanh Hung Nguyen",
      "Phuc Truong Loc Nguyen",
      "Hung Cao"
    ],
    "abstract": "Recent advancements in deep learning have significantly improved visual\nquality inspection and predictive maintenance within industrial settings.\nHowever, deploying these technologies on low-resource edge devices poses\nsubstantial challenges due to their high computational demands and the inherent\ncomplexity of Explainable AI (XAI) methods. This paper addresses these\nchallenges by introducing a novel XAI-integrated Visual Quality Inspection\nframework that optimizes the deployment of semantic segmentation models on\nlow-resource edge devices. Our framework incorporates XAI and the Large Vision\nLanguage Model to deliver human-centered interpretability through visual and\ntextual explanations to end-users. This is crucial for end-user trust and model\ninterpretability. We outline a comprehensive methodology consisting of six\nfundamental modules: base model fine-tuning, XAI-based explanation generation,\nevaluation of XAI approaches, XAI-guided data augmentation, development of an\nedge-compatible model, and the generation of understandable visual and textual\nexplanations. Through XAI-guided data augmentation, the enhanced model\nincorporating domain expert knowledge with visual and textual explanations is\nsuccessfully deployed on mobile devices to support end-users in real-world\nscenarios. Experimental results showcase the effectiveness of the proposed\nframework, with the mobile model achieving competitive accuracy while\nsignificantly reducing model size. This approach paves the way for the broader\nadoption of reliable and interpretable AI tools in critical industrial\napplications, where decisions must be both rapid and justifiable. Our code for\nthis work can be found at https://github.com/Analytics-Everywhere-Lab/vqixai.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, preprint submitted to Information Fusion journal",
    "pdf_url": "http://arxiv.org/pdf/2407.11771v2",
    "published_date": "2024-07-16 14:30:24 UTC",
    "updated_date": "2024-10-25 18:34:18 UTC"
  },
  {
    "arxiv_id": "2408.01427v1",
    "title": "Siamese Transformer Networks for Few-shot Image Classification",
    "authors": [
      "Weihao Jiang",
      "Shuoxi Zhang",
      "Kun He"
    ],
    "abstract": "Humans exhibit remarkable proficiency in visual classification tasks,\naccurately recognizing and classifying new images with minimal examples. This\nability is attributed to their capacity to focus on details and identify common\nfeatures between previously seen and new images. In contrast, existing few-shot\nimage classification methods often emphasize either global features or local\nfeatures, with few studies considering the integration of both. To address this\nlimitation, we propose a novel approach based on the Siamese Transformer\nNetwork (STN). Our method employs two parallel branch networks utilizing the\npre-trained Vision Transformer (ViT) architecture to extract global and local\nfeatures, respectively. Specifically, we implement the ViT-Small network\narchitecture and initialize the branch networks with pre-trained model\nparameters obtained through self-supervised learning. We apply the Euclidean\ndistance measure to the global features and the Kullback-Leibler (KL)\ndivergence measure to the local features. To integrate the two metrics, we\nfirst employ L2 normalization and then weight the normalized results to obtain\nthe final similarity score. This strategy leverages the advantages of both\nglobal and local features while ensuring their complementary benefits. During\nthe training phase, we adopt a meta-learning approach to fine-tune the entire\nnetwork. Our strategy effectively harnesses the potential of global and local\nfeatures in few-shot image classification, circumventing the need for complex\nfeature adaptation modules and enhancing the model's generalization ability.\nExtensive experiments demonstrate that our framework is simple yet effective,\nachieving superior performance compared to state-of-the-art baselines on four\npopular few-shot classification benchmarks in both 5-shot and 1-shot scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.01427v1",
    "published_date": "2024-07-16 14:27:23 UTC",
    "updated_date": "2024-07-16 14:27:23 UTC"
  },
  {
    "arxiv_id": "2407.11766v1",
    "title": "Vectoring Languages",
    "authors": [
      "Joseph Chen"
    ],
    "abstract": "Recent breakthroughs in large language models (LLM) have stirred up global\nattention, and the research has been accelerating non-stop since then.\nPhilosophers and psychologists have also been researching the structure of\nlanguage for decades, but they are having a hard time finding a theory that\ndirectly benefits from the breakthroughs of LLMs. In this article, we propose a\nnovel structure of language that reflects well on the mechanisms behind\nlanguage models and go on to show that this structure is also better at\ncapturing the diverse nature of language compared to previous methods. An\nanalogy of linear algebra is adapted to strengthen the basis of this\nperspective. We further argue about the difference between this perspective and\nthe design philosophy for current language models. Lastly, we discuss how this\nperspective can lead us to research directions that may accelerate the\nimprovements of science fastest.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages including references",
    "pdf_url": "http://arxiv.org/pdf/2407.11766v1",
    "published_date": "2024-07-16 14:25:55 UTC",
    "updated_date": "2024-07-16 14:25:55 UTC"
  },
  {
    "arxiv_id": "2407.11753v1",
    "title": "A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection",
    "authors": [
      "Pandiyaraju V",
      "Shravan Venkatraman",
      "Abeshek A",
      "Pavan Kumar S",
      "Aravintakshan S A",
      "Senthil Kumar A M",
      "Kannan A"
    ],
    "abstract": "Farmers face various challenges when it comes to identifying diseases in rice\nleaves during their early stages of growth, which is a major reason for poor\nproduce. Therefore, early and accurate disease identification is important in\nagriculture to avoid crop loss and improve cultivation. In this research, we\npropose a novel hybrid deep learning (DL) classifier designed by extending the\nSqueeze-and-Excitation network architecture with a channel attention mechanism\nand the Swish ReLU activation function. The channel attention mechanism in our\nproposed model identifies the most important feature channels required for\nclassification during feature extraction and selection. The dying ReLU problem\nis mitigated by utilizing the Swish ReLU activation function, and the\nSqueeze-andExcitation blocks improve information propagation and cross-channel\ninteraction. Upon evaluation, our model achieved a high F1-score of 99.76% and\nan accuracy of 99.74%, surpassing the performance of existing models. These\noutcomes demonstrate the potential of state-of-the-art DL techniques in\nagriculture, contributing to the advancement of more efficient and reliable\ndisease detection systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 4 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11753v1",
    "published_date": "2024-07-16 14:17:26 UTC",
    "updated_date": "2024-07-16 14:17:26 UTC"
  },
  {
    "arxiv_id": "2407.11745v2",
    "title": "Universal Sound Separation with Self-Supervised Audio Masked Autoencoder",
    "authors": [
      "Junqi Zhao",
      "Xubo Liu",
      "Jinzheng Zhao",
      "Yi Yuan",
      "Qiuqiang Kong",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "abstract": "Universal sound separation (USS) is a task of separating mixtures of\narbitrary sound sources. Typically, universal separation models are trained\nfrom scratch in a supervised manner, using labeled data. Self-supervised\nlearning (SSL) is an emerging deep learning approach that leverages unlabeled\ndata to obtain task-agnostic representations, which can benefit many downstream\ntasks. In this paper, we propose integrating a self-supervised pre-trained\nmodel, namely the audio masked autoencoder (A-MAE), into a universal sound\nseparation system to enhance its separation performance. We employ two\nstrategies to utilize SSL embeddings: freezing or updating the parameters of\nA-MAE during fine-tuning. The SSL embeddings are concatenated with the\nshort-time Fourier transform (STFT) to serve as input features for the\nseparation model. We evaluate our methods on the AudioSet dataset, and the\nexperimental results indicate that the proposed methods successfully enhance\nthe separation performance of a state-of-the-art ResUNet-based USS model.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11745v2",
    "published_date": "2024-07-16 14:11:44 UTC",
    "updated_date": "2024-11-06 17:52:55 UTC"
  },
  {
    "arxiv_id": "2407.11698v2",
    "title": "NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks",
    "authors": [
      "Alberto Pirillo",
      "Luca Colombo",
      "Manuel Roveri"
    ],
    "abstract": "Quantization has become increasingly pivotal in addressing the steadily\nincreasing computational and memory requirements of Deep Neural Networks\n(DNNs). By reducing the number of bits used to represent weights and\nactivations (typically from 32-bit floating-point to 16-bit or 8-bit integers),\nquantization reduces the memory footprint, energy consumption, and execution\ntime of DNN models. However, traditional quantization methods typically focus\non the inference of DNNs, while the training process still relies on\nfloating-point operations. To date, only one work in the literature has\naddressed integer-only training for Multi-Layer Perceptron (MLP) architectures.\nThis work introduces NITRO-D, a new framework for training arbitrarily deep\ninteger-only Convolutional Neural Networks (CNNs) that operate entirely in the\ninteger-only domain for both training and inference. NITRO-D is the first\nframework in the literature enabling the training of integer-only CNNs without\nthe need to introduce a quantization scheme. Specifically, NITRO-D introduces a\nnovel architecture integrating multiple integer local-loss blocks, which\ninclude the proposed NITRO Scaling Layer and the NITRO-ReLU activation\nfunction. Additionally, it introduces a novel integer-only learning algorithm\nderived from Local Error Signals (LES), utilizing IntegerSGD, an optimizer\nspecifically designed to operate in an integer-only context. NITRO-D is\nimplemented in an open-source Python library. Extensive experimental\nevaluations demonstrate its effectiveness across several state-of-the-art image\nrecognition datasets. Results show significant performance improvements from\n2.47% to 5.96% for integer-only MLP architectures over the state-of-the-art\nsolution, and the capability of training integer-only CNN architectures with\nminimal accuracy degradation from -0.15% to -4.22% compared to floating-point\nLES.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11698v2",
    "published_date": "2024-07-16 13:16:49 UTC",
    "updated_date": "2024-09-12 14:18:22 UTC"
  },
  {
    "arxiv_id": "2407.20242v4",
    "title": "BadRobot: Jailbreaking Embodied LLMs in the Physical World",
    "authors": [
      "Hangtao Zhang",
      "Chenyu Zhu",
      "Xianlong Wang",
      "Ziqi Zhou",
      "Changgan Yin",
      "Minghui Li",
      "Lulu Xue",
      "Yichen Wang",
      "Shengshan Hu",
      "Aishan Liu",
      "Peijin Guo",
      "Leo Yu Zhang"
    ],
    "abstract": "Embodied AI represents systems where AI is integrated into physical entities.\nLarge Language Model (LLM), which exhibits powerful language understanding\nabilities, has been extensively employed in embodied AI by facilitating\nsophisticated task planning. However, a critical safety issue remains\noverlooked: could these embodied LLMs perpetrate harmful behaviors? In\nresponse, we introduce BadRobot, a novel attack paradigm aiming to make\nembodied LLMs violate safety and ethical constraints through typical\nvoice-based user-system interactions. Specifically, three vulnerabilities are\nexploited to achieve this type of attack: (i) manipulation of LLMs within\nrobotic systems, (ii) misalignment between linguistic outputs and physical\nactions, and (iii) unintentional hazardous behaviors caused by world\nknowledge's flaws. Furthermore, we construct a benchmark of various malicious\nphysical action queries to evaluate BadRobot's attack performance. Based on\nthis benchmark, extensive experiments against existing prominent embodied LLM\nframeworks (e.g., Voxposer, Code as Policies, and ProgPrompt) demonstrate the\neffectiveness of our BadRobot.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to ICLR 2025. Project page:\n  https://Embodied-LLMs-Safety.github.io",
    "pdf_url": "http://arxiv.org/pdf/2407.20242v4",
    "published_date": "2024-07-16 13:13:16 UTC",
    "updated_date": "2025-02-04 07:24:35 UTC"
  },
  {
    "arxiv_id": "2407.11686v4",
    "title": "CCoE: A Compact and Efficient LLM Framework with Multi-Expert Collaboration for Resource-Limited Settings",
    "authors": [
      "Shaomang Huang",
      "Jianfeng Pan",
      "Min Peng",
      "Hanzhong Zheng"
    ],
    "abstract": "Large Language Models (LLMs) have achieved exceptional performance across\ndiverse domains through training on massive datasets. However, scaling LLMs to\nsupport multiple downstream domain applications remains a significant\nchallenge, especially under resource constraints. Existing approaches often\nstruggle to balance performance across multiple domains with resource\nefficiency, limiting their broader applicability. To address this, we introduce\nthe CCoE architecture, a modular framework that seamlessly integrates\ndomain-specific experts into a unified LLM. By leveraging independently trained\nexpert subnetworks on a shared backbone partition, CCoE achieves\nstate-of-the-art performance while significantly reducing the resource\nrequirements for multi-expert deployments. Furthermore, rule-based gating and\nexpert planning in CCoE enable flexible task allocation, promoting expert\ncollaboration to handle complex reasoning tasks. CCoE not only reduces\ninference costs but also provides a flexible and scalable solution for\nintegrating domain expertise across diverse applications. Experiments on five\ndomains demonstrate that CCoE achieves comparable performance to current\ndomain-specific LLMs. Moreover, compared to existing multi-domain model\nensemble methods, CCoE reduces memory usage by 61.3%, while improving inference\nefficiency by 0.76x over parameter-efficient multi-expert integration\napproaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11686v4",
    "published_date": "2024-07-16 13:03:58 UTC",
    "updated_date": "2025-02-17 08:19:48 UTC"
  },
  {
    "arxiv_id": "2407.11676v3",
    "title": "SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities",
    "authors": [
      "Yanis Lalou",
      "Théo Gnassounou",
      "Antoine Collas",
      "Antoine de Mathelin",
      "Oleksii Kachaiev",
      "Ambroise Odonnat",
      "Alexandre Gramfort",
      "Thomas Moreau",
      "Rémi Flamary"
    ],
    "abstract": "Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a\nlabeled source domain to perform well on an unlabeled target domain with some\ndata distribution shift. While many methods have been proposed in the\nliterature, fair and realistic evaluation remains an open question,\nparticularly due to methodological difficulties in selecting hyperparameters in\nthe unsupervised setting. With SKADA-bench, we propose a framework to evaluate\nDA methods on diverse modalities, beyond computer vision task that have been\nlargely explored in the literature. We present a complete and fair evaluation\nof existing shallow algorithms, including reweighting, mapping, and subspace\nalignment. Realistic hyperparameter selection is performed with nested\ncross-validation and various unsupervised model selection scores, on both\nsimulated datasets with controlled shifts and real-world datasets across\ndiverse modalities, such as images, text, biomedical, and tabular data. Our\nbenchmark highlights the importance of realistic validation and provides\npractical guidance for real-life applications, with key insights into the\nchoice and impact of model selection approaches. SKADA-bench is open-source,\nreproducible, and can be easily extended with novel DA methods, datasets, and\nmodel selection criteria without requiring re-evaluating competitors.\nSKADA-bench is available on Github at\nhttps://github.com/scikit-adaptation/skada-bench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11676v3",
    "published_date": "2024-07-16 12:52:29 UTC",
    "updated_date": "2025-02-11 11:09:19 UTC"
  },
  {
    "arxiv_id": "2407.12070v1",
    "title": "Co-Designing Binarized Transformer and Hardware Accelerator for Efficient End-to-End Edge Deployment",
    "authors": [
      "Yuhao Ji",
      "Chao Fang",
      "Shaobo Ma",
      "Haikuo Shao",
      "Zhongfeng Wang"
    ],
    "abstract": "Transformer models have revolutionized AI tasks, but their large size hinders\nreal-world deployment on resource-constrained and latency-critical edge\ndevices. While binarized Transformers offer a promising solution by\nsignificantly reducing model size, existing approaches suffer from\nalgorithm-hardware mismatches with limited co-design exploration, leading to\nsuboptimal performance on edge devices. Hence, we propose a co-design method\nfor efficient end-to-end edge deployment of Transformers from three aspects:\nalgorithm, hardware, and joint optimization. First, we propose BMT, a novel\nhardware-friendly binarized Transformer with optimized quantization methods and\ncomponents, and we further enhance its model accuracy by leveraging the\nweighted ternary weight splitting training technique. Second, we develop a\nstreaming processor mixed binarized Transformer accelerator, namely BAT, which\nis equipped with specialized units and scheduling pipelines for efficient\ninference of binarized Transformers. Finally, we co-optimize the algorithm and\nhardware through a design space exploration approach to achieve a global\ntrade-off between accuracy, latency, and robustness for real-world deployments.\nExperimental results show our co-design achieves up to 2.14-49.37x throughput\ngains and 3.72-88.53x better energy efficiency over state-of-the-art\nTransformer accelerators, enabling efficient end-to-end edge deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted by ICCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12070v1",
    "published_date": "2024-07-16 12:36:10 UTC",
    "updated_date": "2024-07-16 12:36:10 UTC"
  },
  {
    "arxiv_id": "2407.11654v2",
    "title": "R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models",
    "authors": [
      "Aladin Djuhera",
      "Vlad C. Andrei",
      "Xinyang Li",
      "Ullrich J. Mönich",
      "Holger Boche",
      "Walid Saad"
    ],
    "abstract": "Split federated learning (SFL) is a compute-efficient paradigm in distributed\nmachine learning (ML), where components of large ML models are outsourced to\nremote servers. A significant challenge in SFL, particularly when deployed over\nwireless channels, is the susceptibility of transmitted model parameters to\nadversarial jamming that could jeopardize the learning process. This is\nparticularly pronounced for word embedding parameters in large language models\n(LLMs), which are crucial for language understanding. In this paper, rigorous\ninsights are provided into the influence of jamming LLM word embeddings in SFL\nby deriving an expression for the ML training loss divergence and showing that\nit is upper-bounded by the mean squared error (MSE). Based on this analysis, a\nphysical layer framework is developed for resilient SFL with LLMs (R-SFLLM)\nover wireless networks. R-SFLLM leverages wireless sensing data to gather\ninformation on the jamming directions-of-arrival (DoAs) for the purpose of\ndevising a novel, sensing-assisted anti-jamming strategy while jointly\noptimizing beamforming, user scheduling, and resource allocation. Extensive\nexperiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,\nachieving close-to-baseline performance across various natural language\nprocessing (NLP) tasks and datasets. The proposed methodology further\nintroduces an adversarial training component, where controlled noise exposure\nsignificantly enhances the LLM's resilience to perturbed parameters during\ntraining. The results show that more noise-sensitive models, such as RoBERTa,\nbenefit from this feature, especially when resource allocation is unfair. It is\nalso shown that worst-case jamming in particular translates into worst-case\nmodel outcomes, thereby necessitating the need for jamming-resilient SFL\nprotocols.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11654v2",
    "published_date": "2024-07-16 12:21:29 UTC",
    "updated_date": "2024-09-09 12:36:29 UTC"
  },
  {
    "arxiv_id": "2407.11652v7",
    "title": "CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging",
    "authors": [
      "Sunny Gupta",
      "Amit Sethi"
    ],
    "abstract": "Federated Learning (FL) offers a privacy-preserving approach to train models\non decentralized data. Its potential in healthcare is significant, but\nchallenges arise due to cross-client variations in medical image data,\nexacerbated by limited annotations. This paper introduces Cross-Client\nVariations Adaptive Federated Learning (CCVA-FL) to address these issues.\nCCVA-FL aims to minimize cross-client variations by transforming images into a\ncommon feature space. It involves expert annotation of a subset of images from\neach client, followed by the selection of a client with the least data\ncomplexity as the target. Synthetic medical images are then generated using\nScalable Diffusion Models with Transformers (DiT) based on the target client's\nannotated images. These synthetic images, capturing diversity and representing\nthe original data, are shared with other clients. Each client then translates\nits local images into the target image space using image-to-image translation.\nThe translated images are subsequently used in a federated learning setting to\ndevelop a server model. Our results demonstrate that CCVA-FL outperforms\nVanilla Federated Averaging by effectively addressing data distribution\ndifferences across clients without compromising privacy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10;\n  I.2.10; I.5.1; I.5.2; I.5.4; J.2; I.2.6; I.2.11; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "I found critical errors in the manuscript affecting its validity. I\n  need to correct these before resubmitting. Major changes to methodology and\n  results are underway, significantly altering the content. I will resubmit the\n  revised version",
    "pdf_url": "http://arxiv.org/pdf/2407.11652v7",
    "published_date": "2024-07-16 12:18:20 UTC",
    "updated_date": "2024-08-09 05:56:23 UTC"
  },
  {
    "arxiv_id": "2407.18264v1",
    "title": "Latency optimized Deep Neural Networks (DNNs): An Artificial Intelligence approach at the Edge using Multiprocessor System on Chip (MPSoC)",
    "authors": [
      "Seyed Nima Omidsajedi",
      "Rekha Reddy",
      "Jianming Yi",
      "Jan Herbst",
      "Christoph Lipps",
      "Hans Dieter Schotten"
    ],
    "abstract": "Almost in every heavily computation-dependent application, from 6G\ncommunication systems to autonomous driving platforms, a large portion of\ncomputing should be near to the client side. Edge computing (AI at Edge) in\nmobile devices is one of the optimized approaches for addressing this\nrequirement. Therefore, in this work, the possibilities and challenges of\nimplementing a low-latency and power-optimized smart mobile system are\nexamined. Utilizing Field Programmable Gate Array (FPGA) based solutions at the\nedge will lead to bandwidth-optimized designs and as a consequence can boost\nthe computational effectiveness at a system-level deadline. Moreover, various\nperformance aspects and implementation feasibilities of Neural Networks (NNs)\non both embedded FPGA edge devices (using Xilinx Multiprocessor System on Chip\n(MPSoC)) and Cloud are discussed throughout this research. The main goal of\nthis work is to demonstrate a hybrid system that uses the deep learning\nprogrammable engine developed by Xilinx Inc. as the main component of the\nhardware accelerator. Then based on this design, an efficient system for mobile\nedge computing is represented by utilizing an embedded solution.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "25. ITG Fachtagung Mobilkommunikation",
    "pdf_url": "http://arxiv.org/pdf/2407.18264v1",
    "published_date": "2024-07-16 11:51:41 UTC",
    "updated_date": "2024-07-16 11:51:41 UTC"
  },
  {
    "arxiv_id": "2407.11624v1",
    "title": "Rethinking Fair Graph Neural Networks from Re-balancing",
    "authors": [
      "Zhixun Li",
      "Yushun Dong",
      "Qiang Liu",
      "Jeffrey Xu Yu"
    ],
    "abstract": "Driven by the powerful representation ability of Graph Neural Networks\n(GNNs), plentiful GNN models have been widely deployed in many real-world\napplications. Nevertheless, due to distribution disparities between different\ndemographic groups, fairness in high-stake decision-making systems is receiving\nincreasing attention. Although lots of recent works devoted to improving the\nfairness of GNNs and achieved considerable success, they all require\nsignificant architectural changes or additional loss functions requiring more\nhyper-parameter tuning. Surprisingly, we find that simple re-balancing methods\ncan easily match or surpass existing fair GNN methods. We claim that the\nimbalance across different demographic groups is a significant source of\nunfairness, resulting in imbalanced contributions from each group to the\nparameters updating. However, these simple re-balancing methods have their own\nshortcomings during training. In this paper, we propose FairGB, Fair Graph\nNeural Network via re-Balancing, which mitigates the unfairness of GNNs by\ngroup balancing. Technically, FairGB consists of two modules: counterfactual\nnode mixup and contribution alignment loss. Firstly, we select counterfactual\npairs across inter-domain and inter-class, and interpolate the ego-networks to\ngenerate new samples. Guided by analysis, we can reveal the debiasing mechanism\nof our model by the causal view and prove that our strategy can make sensitive\nattributes statistically independent from target labels. Secondly, we reweigh\nthe contribution of each group according to gradients. By combining these two\nmodules, they can mutually promote each other. Experimental results on\nbenchmark datasets show that our method can achieve state-of-the-art results\nconcerning both utility and fairness metrics. Code is available at\nhttps://github.com/ZhixunLEE/FairGB.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SIGKDD 2024, research track",
    "pdf_url": "http://arxiv.org/pdf/2407.11624v1",
    "published_date": "2024-07-16 11:39:27 UTC",
    "updated_date": "2024-07-16 11:39:27 UTC"
  },
  {
    "arxiv_id": "2407.11615v1",
    "title": "Graph Dimension Attention Networks for Enterprise Credit Assessment",
    "authors": [
      "Shaopeng Wei",
      "Beni Egressy",
      "Xingyan Chen",
      "Yu Zhao",
      "Fuzhen Zhuang",
      "Roger Wattenhofer",
      "Gang Kou"
    ],
    "abstract": "Enterprise credit assessment is critical for evaluating financial risk, and\nGraph Neural Networks (GNNs), with their advanced capability to model\ninter-entity relationships, are a natural tool to get a deeper understanding of\nthese financial networks. However, existing GNN-based methodologies\npredominantly emphasize entity-level attention mechanisms for contagion risk\naggregation, often overlooking the heterogeneous importance of different\nfeature dimensions, thus falling short in adequately modeling credit risk\nlevels. To address this issue, we propose a novel architecture named Graph\nDimension Attention Network (GDAN), which incorporates a dimension-level\nattention mechanism to capture fine-grained risk-related characteristics.\nFurthermore, we explore the interpretability of the GNN-based method in\nfinancial scenarios and propose a simple but effective data-centric explainer\nfor GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability\nby quantifying distribution shifts during the message-passing process.\nMoreover, we collected a real-world, multi-source Enterprise Credit Assessment\nDataset (ECAD) and have made it accessible to the research community since\nhigh-quality datasets are lacking in this field. Extensive experiments\nconducted on ECAD demonstrate the effectiveness of our methods. In addition, we\nran GDAN on the well-known datasets SMEsD and DBLP, also with excellent\nresults.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11615v1",
    "published_date": "2024-07-16 11:24:28 UTC",
    "updated_date": "2024-07-16 11:24:28 UTC"
  },
  {
    "arxiv_id": "2407.11613v2",
    "title": "Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project",
    "authors": [
      "David Moats",
      "Chandrima Ganguly"
    ],
    "abstract": "In 2023, Open AIs Democratic Inputs program funded 10 teams to design\nprocedures for public participation in generative AI. In this Perspective, we\nreview the results of the project, drawing on interviews with some of the teams\nand our own experiences conducting participation exercises, we identify several\nshared yet largely unspoken assumptions of the Democratic Inputs program 1.\nthat participation must be scalable 2. that the object of participation is a\nsingle model 3. that there must be a single form of participation 4. that the\ngoal is to extract abstract principles 5. that these principles should have\nconsensus 6. that publics should be representative and encourage alternative\nforms of participation in AI, perhaps not undertaken by tech companies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11613v2",
    "published_date": "2024-07-16 11:22:34 UTC",
    "updated_date": "2025-03-05 14:55:49 UTC"
  },
  {
    "arxiv_id": "2407.11612v1",
    "title": "Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study",
    "authors": [
      "Chaya Ben Yehuda",
      "Ran Gilad-Bachrach",
      "Yarin Udi"
    ],
    "abstract": "Sustaining long-term user engagement with mobile health (mHealth)\ninterventions while preserving their high efficacy remains an ongoing challenge\nin real-world well-being applications. To address this issue, we introduce a\nnew algorithm, the Personalized, Context-Aware Recommender (PCAR), for\nintervention selection and evaluate its performance in a field experiment. In a\nfour-week, in-the-wild experiment involving 29 parents of young children, we\ndelivered personalized stress-reducing micro-interventions through a mobile\nchatbot. We assessed their impact on stress reduction using momentary stress\nlevel ecological momentary assessments (EMAs) before and after each\nintervention. Our findings demonstrate the superiority of PCAR intervention\nselection in enhancing the engagement and efficacy of mHealth\nmicro-interventions to stress coping compared to random intervention selection\nand a control group that did not receive any intervention. Furthermore, we show\nthat even brief, one-minute interventions can significantly reduce perceived\nstress levels (p=0.001). We observe that individuals are most receptive to\none-minute interventions during transitional periods between activities, such\nas transitioning from afternoon activities to bedtime routines. Our study\ncontributes to the literature by introducing a personalized context-aware\nintervention selection algorithm that improves engagement and efficacy of\nmHealth interventions, identifying key timing for stress interventions, and\noffering insights into mechanisms to improve stress coping.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11612v1",
    "published_date": "2024-07-16 11:22:22 UTC",
    "updated_date": "2024-07-16 11:22:22 UTC"
  },
  {
    "arxiv_id": "2407.11609v1",
    "title": "Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift",
    "authors": [
      "Navid Hashemi",
      "Lars Lindemann",
      "Jyotirmoy V. Deshmukh"
    ],
    "abstract": "Reachability analysis is a popular method to give safety guarantees for\nstochastic cyber-physical systems (SCPSs) that takes in a symbolic description\nof the system dynamics and uses set-propagation methods to compute an\noverapproximation of the set of reachable states over a bounded time horizon.\nIn this paper, we investigate the problem of performing reachability analysis\nfor an SCPS that does not have a symbolic description of the dynamics, but\ninstead is described using a digital twin model that can be simulated to\ngenerate system trajectories. An important challenge is that the simulator\nimplicitly models a probability distribution over the set of trajectories of\nthe SCPS; however, it is typical to have a sim2real gap, i.e., the actual\ndistribution of the trajectories in a deployment setting may be shifted from\nthe distribution assumed by the simulator. We thus propose a statistical\nreachability analysis technique that, given a user-provided threshold\n$1-\\epsilon$, provides a set that guarantees that any reachable state during\ndeployment lies in this set with probability not smaller than this threshold.\nOur method is based on three main steps: (1) learning a deterministic surrogate\nmodel from sampled trajectories, (2) conducting reachability analysis over the\nsurrogate model, and (3) employing {\\em robust conformal inference} using an\nadditional set of sampled trajectories to quantify the surrogate model's\ndistribution shift with respect to the deployed SCPS. To counter conservatism\nin reachable sets, we propose a novel method to train surrogate models that\nminimizes a quantile loss term (instead of the usual mean squared loss), and a\nnew method that provides tighter guarantees using conformal inference using a\nnormalized surrogate error. We demonstrate the effectiveness of our technique\non various case studies.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11609v1",
    "published_date": "2024-07-16 11:18:41 UTC",
    "updated_date": "2024-07-16 11:18:41 UTC"
  },
  {
    "arxiv_id": "2407.11606v4",
    "title": "The Foundations of Tokenization: Statistical and Computational Concerns",
    "authors": [
      "Juan Luis Gastaldi",
      "John Terilla",
      "Luca Malagutti",
      "Brian DuSell",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "abstract": "Tokenization - the practice of converting strings of characters from an\nalphabet into sequences of tokens over a vocabulary - is a critical step in the\nNLP pipeline. The use of token representations is widely credited with\nincreased model performance but is also the source of many undesirable\nbehaviors, such as spurious ambiguity or inconsistency. Despite its recognized\nimportance as a standard representation method in NLP, the theoretical\nunderpinnings of tokenization are not yet fully understood. In particular, the\nimpact of tokenization on language model estimation has been investigated\nprimarily through empirical means. The present paper contributes to addressing\nthis theoretical gap by proposing a unified formal framework for representing\nand analyzing tokenizer models. Based on the category of stochastic maps, this\nframework enables us to establish general conditions for a principled use of\ntokenizers and, most importantly, the necessary and sufficient conditions for a\ntokenizer model to preserve the consistency of statistical estimators. In\naddition, we discuss statistical and computational concerns crucial for\ndesigning and implementing tokenizer models, such as inconsistency, ambiguity,\nfiniteness, and sequentiality. The framework and results advanced in this paper\ncontribute to building robust theoretical foundations for representations in\nneural language modeling that can inform future theoretical and empirical\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11606v4",
    "published_date": "2024-07-16 11:12:28 UTC",
    "updated_date": "2025-04-03 15:07:13 UTC"
  },
  {
    "arxiv_id": "2407.11599v2",
    "title": "Enhancing TinyML Security: Study of Adversarial Attack Transferability",
    "authors": [
      "Parin Shah",
      "Yuvaraj Govindarajulu",
      "Pavan Kulkarni",
      "Manojkumar Parmar"
    ],
    "abstract": "The recent strides in artificial intelligence (AI) and machine learning (ML)\nhave propelled the rise of TinyML, a paradigm enabling AI computations at the\nedge without dependence on cloud connections. While TinyML offers real-time\ndata analysis and swift responses critical for diverse applications, its\ndevices' intrinsic resource limitations expose them to security risks. This\nresearch delves into the adversarial vulnerabilities of AI models on\nresource-constrained embedded hardware, with a focus on Model Extraction and\nEvasion Attacks. Our findings reveal that adversarial attacks from powerful\nhost machines could be transferred to smaller, less secure devices like ESP32\nand Raspberry Pi. This illustrates that adversarial attacks could be extended\nto tiny devices, underscoring vulnerabilities, and emphasizing the necessity\nfor reinforced security measures in TinyML deployments. This exploration\nenhances the comprehension of security challenges in TinyML and offers insights\nfor safeguarding sensitive data and ensuring device dependability in AI-powered\nedge computing settings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted and presented at tinyML Foundation EMEA Innovation Forum\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11599v2",
    "published_date": "2024-07-16 10:55:25 UTC",
    "updated_date": "2024-07-18 05:49:46 UTC"
  },
  {
    "arxiv_id": "2407.11594v1",
    "title": "DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training",
    "authors": [
      "Guillermo Jimenez-Perez",
      "Pedro Osorio",
      "Josef Cersovsky",
      "Javier Montalt-Tordera",
      "Jens Hooge",
      "Steffen Vogler",
      "Sadegh Mohammadi"
    ],
    "abstract": "Diffusion models (DMs) have emerged as powerful foundation models for a\nvariety of tasks, with a large focus in synthetic image generation. However,\ntheir requirement of large annotated datasets for training limits their\napplicability in medical imaging, where datasets are typically smaller and\nsparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for\ntraining latent diffusion models (LDMs) that conditions the generation process\non image embeddings extracted from DiNO. By eliminating the reliance on\nannotations, our training leverages over 868k unlabelled images from public\nchest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows\ncomprehensive manifold coverage, with FID scores as low as 4.7, and emerging\nproperties when evaluated in downstream tasks. It can be used to generate\nsemantically-diverse synthetic datasets even from small data pools,\ndemonstrating up to 20% AUC increase in classification performance when used\nfor data augmentation. Images were generated with different sampling strategies\nover the DiNO embedding manifold and using real images as a starting point.\nResults suggest, DiNO-Diffusion could facilitate the creation of large datasets\nfor flexible training of downstream AI models from limited amount of real data,\nwhile also holding potential for privacy preservation. Additionally,\nDiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%\nDice score when evaluating lung lobe segmentation. This evidences good CXR\nimage-anatomy alignment, akin to segmenting using textual descriptors on\nvanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical\nimaging modalities or state-of-the-art diffusion models, opening the door for\nlarge-scale, multi-domain image generation pipelines for medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.11594v1",
    "published_date": "2024-07-16 10:51:21 UTC",
    "updated_date": "2024-07-16 10:51:21 UTC"
  },
  {
    "arxiv_id": "2407.11585v2",
    "title": "QVD: Post-training Quantization for Video Diffusion Models",
    "authors": [
      "Shilong Tian",
      "Hong Chen",
      "Chengtao Lv",
      "Yu Liu",
      "Jinyang Guo",
      "Xianglong Liu",
      "Shengxi Li",
      "Hao Yang",
      "Tao Xie"
    ],
    "abstract": "Recently, video diffusion models (VDMs) have garnered significant attention\ndue to their notable advancements in generating coherent and realistic video\ncontent. However, processing multiple frame features concurrently, coupled with\nthe considerable model size, results in high latency and extensive memory\nconsumption, hindering their broader application. Post-training quantization\n(PTQ) is an effective technique to reduce memory footprint and improve\ncomputational efficiency. Unlike image diffusion, we observe that the temporal\nfeatures, which are integrated into all frame features, exhibit pronounced\nskewness. Furthermore, we investigate significant inter-channel disparities and\nasymmetries in the activation of video diffusion models, resulting in low\ncoverage of quantization levels by individual channels and increasing the\nchallenge of quantization. To address these issues, we introduce the first PTQ\nstrategy tailored for video diffusion models, dubbed QVD. Specifically, we\npropose the High Temporal Discriminability Quantization (HTDQ) method, designed\nfor temporal features, which retains the high discriminability of quantized\nfeatures, providing precise temporal guidance for all video frames. In\naddition, we present the Scattered Channel Range Integration (SCRI) method\nwhich aims to improve the coverage of quantization levels across individual\nchannels. Experimental validations across various models, datasets, and\nbit-width settings demonstrate the effectiveness of our QVD in terms of diverse\nmetrics. In particular, we achieve near-lossless performance degradation on\nW8A8, outperforming the current methods by 205.12 in FVD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by ACMMM2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11585v2",
    "published_date": "2024-07-16 10:47:27 UTC",
    "updated_date": "2024-07-17 05:27:04 UTC"
  },
  {
    "arxiv_id": "2407.11573v1",
    "title": "Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification",
    "authors": [
      "Naif Alkhunaizi",
      "Faris Almalik",
      "Rouqaiah Al-Refai",
      "Muzammal Naseer",
      "Karthik Nandakumar"
    ],
    "abstract": "With the advent of large pre-trained transformer models, fine-tuning these\nmodels for various downstream tasks is a critical problem. Paucity of training\ndata, the existence of data silos, and stringent privacy constraints exacerbate\nthis fine-tuning problem in the medical imaging domain, creating a strong need\nfor algorithms that enable collaborative fine-tuning of pre-trained models.\nMoreover, the large size of these models necessitates the use of\nparameter-efficient fine-tuning (PEFT) to reduce the communication burden in\nfederated learning. In this work, we systematically investigate various\nfederated PEFT strategies for adapting a Vision Transformer (ViT) model\n(pre-trained on a large natural image dataset) for medical image\nclassification. Apart from evaluating known PEFT techniques, we introduce new\nfederated variants of PEFT algorithms such as visual prompt tuning (VPT),\nlow-rank decomposition of visual prompts, stochastic block attention\nfine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.\nMoreover, we perform a thorough empirical analysis to identify the optimal PEFT\nmethod for the federated setting and understand the impact of data distribution\non federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key\ninsight of this study is that while most federated PEFT methods work well for\nin-domain transfer, there is a substantial accuracy vs. efficiency trade-off\nwhen dealing with OOD and non-IID scenarios, which is commonly the case in\nmedical imaging. Specifically, every order of magnitude reduction in\nfine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the\ninitial model choice is crucial for federated PEFT. It is preferable to use\nmedical foundation models learned from in-domain medical image data (if\navailable) rather than general vision models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11573v1",
    "published_date": "2024-07-16 10:28:50 UTC",
    "updated_date": "2024-07-16 10:28:50 UTC"
  },
  {
    "arxiv_id": "2407.11566v2",
    "title": "TGIF: Text-Guided Inpainting Forgery Dataset",
    "authors": [
      "Hannes Mareen",
      "Dimitrios Karageorgiou",
      "Glenn Van Wallendael",
      "Peter Lambert",
      "Symeon Papadopoulos"
    ],
    "abstract": "Digital image manipulation has become increasingly accessible and realistic\nwith the advent of generative AI technologies. Recent developments allow for\ntext-guided inpainting, making sophisticated image edits possible with minimal\neffort. This poses new challenges for digital media forensics. For example,\ndiffusion model-based approaches could either splice the inpainted region into\nthe original image, or regenerate the entire image. In the latter case,\ntraditional image forgery localization (IFL) methods typically fail. This paper\nintroduces the Text-Guided Inpainting Forgery (TGIF) dataset, a comprehensive\ncollection of images designed to support the training and evaluation of image\nforgery localization and synthetic image detection (SID) methods. The TGIF\ndataset includes approximately 75k forged images, originating from popular\nopen-source and commercial methods, namely SD2, SDXL, and Adobe Firefly. We\nbenchmark several state-of-the-art IFL and SID methods on TGIF. Whereas\ntraditional IFL methods can detect spliced images, they fail to detect\nregenerated inpainted images. Moreover, traditional SID may detect the\nregenerated inpainted images to be fake, but cannot localize the inpainted\narea. Finally, both IFL and SID methods fail when exposed to stronger\ncompression, while they are less robust to modern compression algorithms, such\nas WEBP. In conclusion, this work demonstrates the inefficiency of\nstate-of-the-art detectors on local manipulations performed by modern\ngenerative approaches, and aspires to help with the development of more capable\nIFL and SID methods. The dataset and code can be downloaded at\nhttps://github.com/IDLabMedia/tgif-dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, accepted at IEEE WIFS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11566v2",
    "published_date": "2024-07-16 10:19:14 UTC",
    "updated_date": "2024-10-04 09:39:44 UTC"
  },
  {
    "arxiv_id": "2407.11562v2",
    "title": "RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards",
    "authors": [
      "Fatemeh Zargarbashi",
      "Jin Cheng",
      "Dongho Kang",
      "Robert Sumner",
      "Stelian Coros"
    ],
    "abstract": "This paper presents a novel learning-based control framework that uses\nkeyframing to incorporate high-level objectives in natural locomotion for\nlegged robots. These high-level objectives are specified as a variable number\nof partial or complete pose targets that are spaced arbitrarily in time. Our\nproposed framework utilizes a multi-critic reinforcement learning algorithm to\neffectively handle the mixture of dense and sparse rewards. Additionally, it\nemploys a transformer-based encoder to accommodate a variable number of input\ntargets, each associated with specific time-to-arrivals. Throughout simulation\nand hardware experiments, we demonstrate that our framework can effectively\nsatisfy the target keyframe sequence at the required times. In the experiments,\nthe multi-critic method significantly reduces the effort of hyperparameter\ntuning compared to the standard single-critic alternative. Moreover, the\nproposed transformer-based architecture enables robots to anticipate future\ngoals, which results in quantitative improvements in their ability to reach\ntheir targets.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper has been accepted to 8th Conference on Robot Learning\n  (CoRL 2024). Project website: https://sites.google.com/view/robot-keyframing",
    "pdf_url": "http://arxiv.org/pdf/2407.11562v2",
    "published_date": "2024-07-16 10:15:35 UTC",
    "updated_date": "2024-11-04 14:32:26 UTC"
  },
  {
    "arxiv_id": "2407.11555v1",
    "title": "Self-Guided Generation of Minority Samples Using Diffusion Models",
    "authors": [
      "Soobin Um",
      "Jong Chul Ye"
    ],
    "abstract": "We present a novel approach for generating minority samples that live on\nlow-density regions of a data manifold. Our framework is built upon diffusion\nmodels, leveraging the principle of guided sampling that incorporates an\narbitrary energy-based guidance during inference time. The key defining feature\nof our sampler lies in its \\emph{self-contained} nature, \\ie, implementable\nsolely with a pretrained model. This distinguishes our sampler from existing\ntechniques that require expensive additional components (like external\nclassifiers) for minority generation. Specifically, we first estimate the\nlikelihood of features within an intermediate latent sample by evaluating a\nreconstruction loss w.r.t. its posterior mean. The generation then proceeds\nwith the minimization of the estimated likelihood, thereby encouraging the\nemergence of minority features in the latent samples of subsequent timesteps.\nTo further improve the performance of our sampler, we provide several\ntime-scheduling techniques that properly manage the influence of guidance over\ninference steps. Experiments on benchmark real datasets demonstrate that our\napproach can greatly improve the capability of creating realistic\nlow-likelihood minority instances over the existing techniques without the\nreliance on costly additional elements. Code is available at\n\\url{https://github.com/soobin-um/sg-minority}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11555v1",
    "published_date": "2024-07-16 10:03:29 UTC",
    "updated_date": "2024-07-16 10:03:29 UTC"
  },
  {
    "arxiv_id": "2407.11553v2",
    "title": "Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An Image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction",
    "authors": [
      "Zihan Tang",
      "Tianyao Ji",
      "Wenhu Tang"
    ],
    "abstract": "As modern power systems continue to evolve, accurate power load forecasting\nremains a critical issue in energy management. The phase space reconstruction\nmethod can effectively retain the inner chaotic property of power load from a\nsystem dynamics perspective and thus is a promising knowledge-based\npreprocessing method for short-term forecasting. In order to fully utilize the\ncapability of PSR method to model the non-stationary characteristics within\npower load, and to solve the problem of the difficulty in applying traditional\nPSR prediction methods to form a general multi-step forecasting scheme, this\nstudy proposes a novel multi-step forecasting approach by delicately\nintegrating the PSR with neural networks to establish an end-to-end learning\nsystem. Firstly, the useful features in the phase trajectory are discussed in\ndetail. Through mathematical derivation, the equivalent characterization of the\nPSR and another time series preprocessing method, patch segmentation, is\ndemonstrated for the first time. Based on this knowledge, an image-based\nmodeling perspective is introduced. Subsequently, a novel deep learning model,\nnamely PSR-GALIEN, is designed, in which the Transformer Encoder and 2D-CNN are\nemployed for the extraction of the global and local patterns in the image, and\na MLP-based predictor is used for the efficient correlation modeling. Then,\nextensive experiments are conducted on five real-world benchmark datasets to\nverify the effectiveness of the PSR-GALIEN. The results show that, compared\nwith six state-of-the-art deep learning models, the forecasting performance of\nPSR-GALIEN consistently surpasses these baselines, achieving superior accuracy\nin both intra-day and day-ahead forecasting scenarios. At the same time, the\nattributions of its forecasting results can be explained through the\nvisualization-based method, which significantly increases the interpretability.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11553v2",
    "published_date": "2024-07-16 09:59:13 UTC",
    "updated_date": "2024-07-28 16:59:49 UTC"
  },
  {
    "arxiv_id": "2407.11550v4",
    "title": "Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference",
    "authors": [
      "Yuan Feng",
      "Junlin Lv",
      "Yukun Cao",
      "Xike Xie",
      "S. Kevin Zhou"
    ],
    "abstract": "Large Language Models have excelled in various domains but face efficiency\nchallenges due to the growing Key-Value (KV) cache required for long-sequence\ninference. Recent efforts aim to reduce KV cache size by evicting vast\nnon-critical cache elements during runtime while preserving generation quality.\nHowever, these methods typically allocate compression budgets uniformly across\nall attention heads, ignoring the unique attention patterns of each head. In\nthis paper, we establish a theoretical loss upper bound between pre- and\npost-eviction attention output, explaining the optimization target of prior\ncache eviction methods, while guiding the optimization of adaptive budget\nallocation. Base on this, we propose {\\it Ada-KV}, the first head-wise adaptive\nbudget allocation strategy. It offers plug-and-play benefits, enabling seamless\nintegration with prior cache eviction methods. Extensive evaluations on 13\ndatasets from Ruler and 16 datasets from LongBench, all conducted under both\nquestion-aware and question-agnostic scenarios, demonstrate substantial quality\nimprovements over existing methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11550v4",
    "published_date": "2024-07-16 09:53:32 UTC",
    "updated_date": "2025-01-26 07:29:06 UTC"
  },
  {
    "arxiv_id": "2407.11549v2",
    "title": "How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models",
    "authors": [
      "Yin Jou Huang",
      "Rafik Hadfi"
    ],
    "abstract": "Psychological evidence reveals the influence of personality traits on\ndecision-making. For instance, agreeableness is generally associated with\npositive outcomes in negotiations, whereas neuroticism is often linked to less\nfavorable outcomes. This paper introduces a simulation framework centered on\nLarge Language Model (LLM) agents endowed with synthesized personality traits.\nThe agents negotiate within bargaining domains and possess customizable\npersonalities and objectives. The experimental results show that the behavioral\ntendencies of LLM-based simulations could reproduce behavioral patterns\nobserved in human negotiations. The contribution is twofold. First, we propose\na simulation methodology that investigates the alignment between the linguistic\nand economic capabilities of LLM agents. Secondly, we offer empirical insights\ninto the strategic impact of Big-Five personality traits on the outcomes of\nbilateral negotiations. We also provide a case study based on synthesized\nbargaining dialogues to reveal intriguing behaviors, including deceitful and\ncompromising behaviors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11549v2",
    "published_date": "2024-07-16 09:52:51 UTC",
    "updated_date": "2024-11-02 16:24:41 UTC"
  },
  {
    "arxiv_id": "2407.11537v1",
    "title": "AEMIM: Adversarial Examples Meet Masked Image Modeling",
    "authors": [
      "Wenzhao Xiang",
      "Chang Liu",
      "Hang Su",
      "Hongyang Yu"
    ],
    "abstract": "Masked image modeling (MIM) has gained significant traction for its\nremarkable prowess in representation learning. As an alternative to the\ntraditional approach, the reconstruction from corrupted images has recently\nemerged as a promising pretext task. However, the regular corrupted images are\ngenerated using generic generators, often lacking relevance to the specific\nreconstruction task involved in pre-training. Hence, reconstruction from\nregular corrupted images cannot ensure the difficulty of the pretext task,\npotentially leading to a performance decline. Moreover, generating corrupted\nimages might introduce an extra generator, resulting in a notable computational\nburden. To address these issues, we propose to incorporate adversarial examples\ninto masked image modeling, as the new reconstruction targets. Adversarial\nexamples, generated online using only the trained models, can directly aim to\ndisrupt tasks associated with pre-training. Therefore, the incorporation not\nonly elevates the level of challenge in reconstruction but also enhances\nefficiency, contributing to the acquisition of superior representations by the\nmodel. In particular, we introduce a novel auxiliary pretext task that\nreconstructs the adversarial examples corresponding to the original images. We\nalso devise an innovative adversarial attack to craft more suitable adversarial\nexamples for MIM pre-training. It is noted that our method is not restricted to\nspecific model architectures and MIM strategies, rendering it an adaptable\nplug-in capable of enhancing all MIM methods. Experimental findings\nsubstantiate the remarkable capability of our approach in amplifying the\ngeneralization and robustness of existing MIM methods. Notably, our method\nsurpasses the performance of baselines on various tasks, including ImageNet,\nits variants, and other downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review of International Journal of Computer Vision (IJCV)",
    "pdf_url": "http://arxiv.org/pdf/2407.11537v1",
    "published_date": "2024-07-16 09:39:13 UTC",
    "updated_date": "2024-07-16 09:39:13 UTC"
  },
  {
    "arxiv_id": "2407.11536v1",
    "title": "Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise",
    "authors": [
      "Qimin Yang",
      "Rongsheng Wang",
      "Jiexin Chen",
      "Runqi Su",
      "Tao Tan"
    ],
    "abstract": "Large Language Models (LLMs) have been widely applied in various professional\nfields. By fine-tuning the models using domain specific question and answer\ndatasets, the professional domain knowledge and Q\\&A abilities of these models\nhave significantly improved, for example, medical professional LLMs that use\nfine-tuning of doctor-patient Q\\&A data exhibit extraordinary disease\ndiagnostic abilities. However, we observed that despite improvements in\nspecific domain knowledge, the performance of medical LLM in long-context\nunderstanding has significantly declined, especially compared to general\nlanguage models with similar parameters. The purpose of this study is to\ninvestigate the phenomenon of reduced performance in understanding long-context\nin medical LLM. We designed a series of experiments to conduct open-book\nprofessional knowledge exams on all models to evaluate their ability to read\nlong-context. By adjusting the proportion and quantity of general data and\nmedical data in the process of fine-tuning, we can determine the best data\ncomposition to optimize the professional model and achieve a balance between\nlong-context performance and specific domain knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 1 figure. Accepted by the Workshop on Long-Context\n  Foundation Models (LCFM) at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11536v1",
    "published_date": "2024-07-16 09:37:20 UTC",
    "updated_date": "2024-07-16 09:37:20 UTC"
  },
  {
    "arxiv_id": "2407.12880v1",
    "title": "Cross-Modal Augmentation for Few-Shot Multimodal Fake News Detection",
    "authors": [
      "Ye Jiang",
      "Taihang Wang",
      "Xiaoman Xu",
      "Yimin Wang",
      "Xingyi Song",
      "Diana Maynard"
    ],
    "abstract": "The nascent topic of fake news requires automatic detection methods to\nquickly learn from limited annotated samples. Therefore, the capacity to\nrapidly acquire proficiency in a new task with limited guidance, also known as\nfew-shot learning, is critical for detecting fake news in its early stages.\nExisting approaches either involve fine-tuning pre-trained language models\nwhich come with a large number of parameters, or training a complex neural\nnetwork from scratch with large-scale annotated datasets. This paper presents a\nmultimodal fake news detection model which augments multimodal features using\nunimodal features. For this purpose, we introduce Cross-Modal Augmentation\n(CMA), a simple approach for enhancing few-shot multimodal fake news detection\nby transforming n-shot classification into a more robust (n $\\times$ z)-shot\nproblem, where z represents the number of supplementary features. The proposed\nCMA achieves SOTA results over three benchmark datasets, utilizing a\nsurprisingly simple linear probing method to classify multimodal fake news with\nonly a few training samples. Furthermore, our method is significantly more\nlightweight than prior approaches, particularly in terms of the number of\ntrainable parameters and epoch times. The code is available here:\n\\url{https://github.com/zgjiangtoby/FND_fewshot}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12880v1",
    "published_date": "2024-07-16 09:32:11 UTC",
    "updated_date": "2024-07-16 09:32:11 UTC"
  },
  {
    "arxiv_id": "2407.11534v2",
    "title": "LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices",
    "authors": [
      "Jung Hyun Lee",
      "Jeonghoon Kim",
      "June Yong Yang",
      "Se Jung Kwon",
      "Eunho Yang",
      "Kang Min Yoo",
      "Dongsoo Lee"
    ],
    "abstract": "With the commercialization of large language models (LLMs), weight-activation\nquantization has emerged to compress and accelerate LLMs, achieving high\nthroughput while reducing inference costs. However, existing post-training\nquantization (PTQ) techniques for quantizing weights and activations of LLMs\nstill suffer from non-negligible accuracy drops, especially on massive\nmultitask language understanding. To address this issue, we propose Low-Rank\nQuantization (LRQ) - a simple yet effective post-training weight quantization\nmethod for LLMs that reconstructs the outputs of an intermediate Transformer\nblock by leveraging low-rank weight-scaling matrices, replacing the\nconventional full weight-scaling matrices that entail as many learnable scales\nas their associated weights. Thanks to parameter sharing via low-rank\nstructure, LRQ only needs to learn significantly fewer parameters while\nenabling the individual scaling of weights, thus boosting the generalization\ncapability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ\nworks under (i) 8-bit weight and per-tensor activation quantization, (ii) 4-bit\nweight and 8-bit per-token activation quantization, and (iii) low-bit\nweight-only quantization schemes. Our code is available at Software.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the main conference at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.11534v2",
    "published_date": "2024-07-16 09:32:07 UTC",
    "updated_date": "2025-02-09 04:15:11 UTC"
  },
  {
    "arxiv_id": "2407.11529v1",
    "title": "Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans",
    "authors": [
      "Bizhe Bai",
      "Yan-Jie Zhou",
      "Yujian Hu",
      "Tony C. W. Mok",
      "Yilang Xiang",
      "Le Lu",
      "Hongkun Zhang",
      "Minfeng Xu"
    ],
    "abstract": "Pulmonary embolism (PE) is a life-threatening condition where rapid and\naccurate diagnosis is imperative yet difficult due to predominantly atypical\nsymptomatology. Computed tomography pulmonary angiography (CTPA) is\nacknowledged as the gold standard imaging tool in clinics, yet it can be\ncontraindicated for emergency department (ED) patients and represents an\nonerous procedure, thus necessitating PE identification through non-contrast CT\n(NCT) scans. In this work, we explore the feasibility of applying a\ndeep-learning approach to NCT scans for PE identification. We propose a novel\nCross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer\nfrom CTPA to NCT, while concurrently conducting embolism segmentation and\nabnormality classification in a multi-task manner. The proposed CPMN leverages\nthe Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and\nmutual learning between the dual-pathway network, while the Intra-Feature\nDiscrepancy (IFD) strategy can facilitate precise segmentation of PE against\ncomplex backgrounds for single-pathway networks. For a comprehensive assessment\nof the proposed approach, a large-scale dual-phase dataset containing 334 PE\npatients and 1,105 normal subjects has been established. Experimental results\ndemonstrate that CPMN achieves the leading identification performance, which is\n95.4\\% and 99.6\\% in patient-level sensitivity and specificity on NCT scans,\nindicating the potential of our approach as an economical, accessible, and\nprecise tool for PE identification in clinical practice.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Early accept by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11529v1",
    "published_date": "2024-07-16 09:29:33 UTC",
    "updated_date": "2024-07-16 09:29:33 UTC"
  },
  {
    "arxiv_id": "2407.12879v4",
    "title": "Large Visual-Language Models Are Also Good Classifiers: A Study of In-Context Multimodal Fake News Detection",
    "authors": [
      "Ye Jiang",
      "Yimin Wang"
    ],
    "abstract": "Large visual-language models (LVLMs) exhibit exceptional performance in\nvisual-language reasoning across diverse cross-modal benchmarks. Despite these\nadvances, recent research indicates that Large Language Models (LLMs), like\nGPT-3.5-turbo, underachieve compared to well-trained smaller models, such as\nBERT, in Fake News Detection (FND), prompting inquiries into LVLMs' efficacy in\nFND tasks. Although performance could improve through fine-tuning LVLMs, the\nsubstantial parameters and requisite pre-trained weights render it a\nresource-heavy endeavor for FND applications. This paper initially assesses the\nFND capabilities of two notable LVLMs, CogVLM and GPT4V, in comparison to a\nsmaller yet adeptly trained CLIP model in a zero-shot context. The findings\ndemonstrate that LVLMs can attain performance competitive with that of the\nsmaller model. Next, we integrate standard in-context learning (ICL) with\nLVLMs, noting improvements in FND performance, though limited in scope and\nconsistency. To address this, we introduce the \\textbf{I}n-context\n\\textbf{M}ultimodal \\textbf{F}ake \\textbf{N}ews \\textbf{D}etection (IMFND)\nframework, enriching in-context examples and test inputs with predictions and\ncorresponding probabilities from a well-trained smaller model. This strategic\nintegration directs the LVLMs' focus towards news segments associated with\nhigher probabilities, thereby improving their analytical accuracy. The\nexperimental results suggest that the IMFND framework significantly boosts the\nFND efficiency of LVLMs, achieving enhanced accuracy over the standard ICL\napproach across three publicly available FND datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Withdraw for new experiments",
    "pdf_url": "http://arxiv.org/pdf/2407.12879v4",
    "published_date": "2024-07-16 09:28:23 UTC",
    "updated_date": "2025-04-16 00:26:13 UTC"
  },
  {
    "arxiv_id": "2407.12068v2",
    "title": "Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness",
    "authors": [
      "Kai Guo",
      "Zewen Liu",
      "Zhikai Chen",
      "Hongzhi Wen",
      "Wei Jin",
      "Jiliang Tang",
      "Yi Chang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language processing tasks. Recently, several LLMs-based\npipelines have been developed to enhance learning on graphs with text\nattributes, showcasing promising performance. However, graphs are well-known to\nbe susceptible to adversarial attacks and it remains unclear whether LLMs\nexhibit robustness in learning on graphs. To address this gap, our work aims to\nexplore the potential of LLMs in the context of adversarial attacks on graphs.\nSpecifically, we investigate the robustness against graph structural and\ntextual perturbations in terms of two dimensions: LLMs-as-Enhancers and\nLLMs-as-Predictors. Through extensive experiments, we find that, compared to\nshallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior\nrobustness against structural and textual attacks.Based on these findings, we\ncarried out additional analyses to investigate the underlying causes.\nFurthermore, we have made our benchmark library openly available to facilitate\nquick and fair evaluations, and to encourage ongoing innovative research in\nthis field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12068v2",
    "published_date": "2024-07-16 09:05:31 UTC",
    "updated_date": "2024-07-28 16:44:21 UTC"
  },
  {
    "arxiv_id": "2407.12878v3",
    "title": "Do LLMs have Consistent Values?",
    "authors": [
      "Naama Rozen",
      "Liat Bezalel",
      "Gal Elidan",
      "Amir Globerson",
      "Ella Daniel"
    ],
    "abstract": "Large Language Models (LLM) technology is constantly improving towards\nhuman-like dialogue. Values are a basic driving force underlying human\nbehavior, but little research has been done to study the values exhibited in\ntext generated by LLMs. Here we study this question by turning to the rich\nliterature on value structure in psychology. We ask whether LLMs exhibit the\nsame value structure that has been demonstrated in humans, including the\nranking of values, and correlation between values. We show that the results of\nthis analysis depend on how the LLM is prompted, and that under a particular\nprompting strategy (referred to as \"Value Anchoring\") the agreement with human\ndata is quite compelling. Our results serve both to improve our understanding\nof values in LLMs, as well as introduce novel methods for assessing consistency\nin LLM responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 4 figures, and there are more in the appendix",
    "pdf_url": "http://arxiv.org/pdf/2407.12878v3",
    "published_date": "2024-07-16 08:58:00 UTC",
    "updated_date": "2024-10-15 07:29:29 UTC"
  },
  {
    "arxiv_id": "2407.11511v1",
    "title": "Reasoning with Large Language Models, a Survey",
    "authors": [
      "Aske Plaat",
      "Annie Wong",
      "Suzan Verberne",
      "Joost Broekens",
      "Niki van Stein",
      "Thomas Back"
    ],
    "abstract": "Scaling up language models to billions of parameters has opened up\npossibilities for in-context learning, allowing instruction tuning and few-shot\nlearning on tasks that the model was not specifically trained for. This has\nachieved breakthrough performance on language tasks such as translation,\nsummarization, and question-answering. Furthermore, in addition to these\nassociative \"System 1\" tasks, recent advances in Chain-of-thought prompt\nlearning have demonstrated strong \"System 2\" reasoning abilities, answering a\nquestion in the field of artificial general intelligence whether LLMs can\nreason. The field started with the question whether LLMs can solve grade school\nmath word problems. This paper reviews the rapidly expanding field of\nprompt-based reasoning with LLMs. Our taxonomy identifies different ways to\ngenerate, evaluate, and control multi-step reasoning. We provide an in-depth\ncoverage of core approaches and open problems, and we propose a research agenda\nfor the near future. Finally, we highlight the relation between reasoning and\nprompt-based learning, and we discuss the relation between reasoning,\nsequential decision processes, and reinforcement learning. We find that\nself-improvement, self-reflection, and some metacognitive abilities of the\nreasoning processes are possible through the judicious use of prompts. True\nself-improvement and self-reasoning, to go from reasoning with LLMs to\nreasoning by LLMs, remains future work.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11511v1",
    "published_date": "2024-07-16 08:49:35 UTC",
    "updated_date": "2024-07-16 08:49:35 UTC"
  },
  {
    "arxiv_id": "2407.11501v1",
    "title": "Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era",
    "authors": [
      "Lei Ren",
      "Haiteng Wang",
      "Yuanjun Laili"
    ],
    "abstract": "Industrial Multivariate Time Series (MTS) is a critical view of the\nindustrial field for people to understand the state of machines. However, due\nto data collection difficulty and privacy concerns, available data for building\nindustrial intelligence and industrial large models is far from sufficient.\nTherefore, industrial time series data generation is of great importance.\nExisting research usually applies Generative Adversarial Networks (GANs) to\ngenerate MTS. However, GANs suffer from unstable training process due to the\njoint training of the generator and discriminator. This paper proposes a\ntemporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for\nMTS generation. It aims to better handle the complex temporal dependencies and\ndynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean\nDiscrepancy (Ada-MMD) method has been proposed for the controlled generation of\nMTS, which does not require a classifier to control the generation. It improves\nthe condition consistency of the diffusion model. Moreover, a Temporal\nDecomposition Reconstruction UNet (TDR-UNet) is established to capture complex\ntemporal patterns and further improve the quality of the synthetic time series.\nComprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that\nthe proposed Diff-MTS performs substantially better in terms of diversity,\nfidelity, and utility compared with GAN-based methods. These results show that\nDiff-MTS facilitates the generation of industrial data, contributing to\nintelligent maintenance and the construction of industrial large models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages,4 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2407.11501v1",
    "published_date": "2024-07-16 08:38:40 UTC",
    "updated_date": "2024-07-16 08:38:40 UTC"
  },
  {
    "arxiv_id": "2407.11500v1",
    "title": "An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data",
    "authors": [
      "Niamh Belton",
      "Aonghus Lawlor",
      "Kathleen M. Curran"
    ],
    "abstract": "The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)\nordinal grading systems has been a subject of on-going debate and concern.\nExisting automated solutions are trained to emulate these imperfect systems,\nwhilst also being reliant on large annotated databases for fully-supervised\ntraining. This work proposes a three stage approach for automated continuous\ngrading of knee OA that is built upon the principles of Anomaly Detection (AD);\nlearning a robust representation of healthy knee X-rays and grading disease\nseverity based on its distance to the centre of normality. In the first stage,\nSS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'\nrepresentation, requiring only examples of healthy subjects and <3% of the\nlabels that existing methods require. In the second stage, this model is used\nto pseudo label a subset of unlabelled data as 'normal' or 'anomalous',\nfollowed by denoising of pseudo labels with CLIP. The final stage involves\nretraining on labelled and pseudo labelled data using the proposed Dual Centre\nRepresentation Learning (DCRL) which learns the centres of two representation\nspaces; normal and anomalous. Disease severity is then graded based on the\ndistance to the learned centres. The proposed methodology outperforms existing\ntechniques by margins of up to 24% in terms of OA detection and the disease\nseverity scores correlate with the Kellgren-Lawrence grading system at the same\nlevel as human expert performance. Code available at\nhttps://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11500v1",
    "published_date": "2024-07-16 08:37:33 UTC",
    "updated_date": "2024-07-16 08:37:33 UTC"
  },
  {
    "arxiv_id": "2407.12877v2",
    "title": "ReFeR: Improving Evaluation and Reasoning through Hierarchy of Models",
    "authors": [
      "Yaswanth Narsupalli",
      "Abhranil Chandra",
      "Sreevatsa Muppirala",
      "Manish Gupta",
      "Pawan Goyal"
    ],
    "abstract": "Assessing the quality of outputs generated by generative models, such as\nlarge language models and vision language models, presents notable challenges.\nTraditional methods for evaluation typically rely on either human assessments,\nwhich are resource-intensive, or automatic metrics that often show a low\ncorrelation with human judgment. Another common approach is to use deep\nlearning systems, which not only consume a substantial amount of compute and\ntime but also require extensive training data. In this study, we introduce a\ntuning-free framework called ReFeR, designed to evaluate generative outputs,\nincluding both text and images, by leveraging a 2-level hierarchy of LLMs and\nVLMs themselves. We rigorously evaluate our framework, ReFeR, across four\ndiverse evaluation tasks. The framework not only improves the accuracy of these\nevaluations, surpassing previous benchmarks but also generates constructive\nfeedback. Interestingly, the framework is also applicable to reasoning tasks.\nExperiments on four reasoning tasks demonstrate superior collective reasoning\nabilities of the framework. We present two variants of the framework:\nReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a\nmore cost-effective solution. ReFeR-Lite is $\\sim7.7\\times$ more efficient\nwhile being comparably accurate to ReFeR-Turbo. We make code, data and PIP\npackage publicly available. See this PIP URL\nhttps://pypi.org/project/refer-agents/ and this Git URL\nhttps://github.com/yaswanth-iitkgp/ReFeR_Code .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper Under Review",
    "pdf_url": "http://arxiv.org/pdf/2407.12877v2",
    "published_date": "2024-07-16 08:25:26 UTC",
    "updated_date": "2024-10-09 17:51:44 UTC"
  },
  {
    "arxiv_id": "2407.11489v1",
    "title": "A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments",
    "authors": [
      "Junlin Lu",
      "Patrick Mannion",
      "Karl Mason"
    ],
    "abstract": "Effective residential appliance scheduling is crucial for sustainable living.\nWhile multi-objective reinforcement learning (MORL) has proven effective in\nbalancing user preferences in appliance scheduling, traditional MORL struggles\nwith limited data in non-stationary residential settings characterized by\nrenewable generation variations. Significant context shifts that can invalidate\npreviously learned policies. To address these challenges, we extend\nstate-of-the-art MORL algorithms with the meta-learning paradigm, enabling\nrapid, few-shot adaptation to shifting contexts. Additionally, we employ an\nauto-encoder (AE)-based unsupervised method to detect environment context\nchanges. We have also developed a residential energy environment to evaluate\nour method using real-world data from London residential settings. This study\nnot only assesses the application of MORL in residential appliance scheduling\nbut also underscores the effectiveness of meta-learning in energy management.\nOur top-performing method significantly surpasses the best baseline, while the\ntrained model saves 3.28% on electricity bills, a 2.74% increase in user\ncomfort, and a 5.9% improvement in expected utility. Additionally, it reduces\nthe sparsity of solutions by 62.44%. Remarkably, these gains were accomplished\nusing 96.71% less training data and 61.1% fewer training steps.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11489v1",
    "published_date": "2024-07-16 08:23:20 UTC",
    "updated_date": "2024-07-16 08:23:20 UTC"
  },
  {
    "arxiv_id": "2407.11484v9",
    "title": "The Oscars of AI Theater: A Survey on Role-Playing with Language Models",
    "authors": [
      "Nuo Chen",
      "Yan Wang",
      "Yang Deng",
      "Jia Li"
    ],
    "abstract": "This survey explores the burgeoning field of role-playing with language\nmodels, focusing on their development from early persona-based models to\nadvanced character-driven simulations facilitated by Large Language Models\n(LLMs). Initially confined to simple persona consistency due to limited model\ncapabilities, role-playing tasks have now expanded to embrace complex character\nportrayals involving character consistency, behavioral alignment, and overall\nattractiveness. We provide a comprehensive taxonomy of the critical components\nin designing these systems, including data, models and alignment, agent\narchitecture and evaluation. This survey not only outlines the current\nmethodologies and challenges, such as managing dynamic personal profiles and\nachieving high-level persona consistency but also suggests avenues for future\nresearch in improving the depth and realism of role-playing applications. The\ngoal is to guide future research by offering a structured overview of current\nmethodologies and identifying potential areas for improvement. Related\nresources and papers are available at\nhttps://github.com/nuochenpku/Awesome-Role-Play-Papers.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.11484v9",
    "published_date": "2024-07-16 08:20:39 UTC",
    "updated_date": "2025-01-10 02:18:01 UTC"
  },
  {
    "arxiv_id": "2407.11481v2",
    "title": "Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG",
    "authors": [
      "Jiarong Chen",
      "Wanqing Wu",
      "Tong Liu",
      "Shenda Hong"
    ],
    "abstract": "Electrocardiogram (ECG) has emerged as a widely accepted diagnostic\ninstrument for cardiovascular diseases (CVD). The standard clinical 12-lead ECG\nconfiguration causes considerable inconvenience and discomfort, while wearable\ndevices offers a more practical alternative. To reduce information gap between\n12-lead ECG and single-lead ECG, this study proposes a multi-channel masked\nautoencoder (MCMA) for reconstructing 12-Lead ECG from arbitrary single-lead\nECG, and a comprehensive evaluation benchmark, ECGGenEval, encompass the\nsignal-level, feature-level, and diagnostic-level evaluations. MCMA can achieve\nthe state-of-the-art performance. In the signal-level evaluation, the mean\nsquare errors of 0.0317 and 0.1034, Pearson correlation coefficients of 0.7885\nand 0.7420. In the feature-level evaluation, the average standard deviation of\nthe mean heart rate across the generated 12-lead ECG is 1.0481, the coefficient\nof variation is 1.58%, and the range is 3.2874. In the diagnostic-level\nevaluation, the average F1-score with two generated 12-lead ECG from different\nsingle-lead ECG are 0.8233 and 0.8410.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "It is a revised version.The open-source code is publicly available at\n  https://github.com/CHENJIAR3/MCMA",
    "pdf_url": "http://arxiv.org/pdf/2407.11481v2",
    "published_date": "2024-07-16 08:17:45 UTC",
    "updated_date": "2024-10-03 09:38:12 UTC"
  },
  {
    "arxiv_id": "2407.11480v2",
    "title": "AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models",
    "authors": [
      "Lei Ren",
      "Haiteng Wang",
      "Jinwang Li",
      "Yang Tang",
      "Chunhua Yang"
    ],
    "abstract": "With the remarkable success of generative models like ChatGPT, Artificial\nIntelligence Generated Content (AIGC) is undergoing explosive development. Not\nlimited to text and images, generative models can generate industrial time\nseries data, addressing challenges such as the difficulty of data collection\nand data annotation. Due to their outstanding generation ability, they have\nbeen widely used in Internet of Things, metaverse, and cyber-physical-social\nsystems to enhance the efficiency of industrial production. In this paper, we\npresent a comprehensive overview of generative models for industrial time\nseries from deep generative models (DGMs) to large generative models (LGMs).\nFirst, a DGM-based AIGC framework is proposed for industrial time series\ngeneration. Within this framework, we survey advanced industrial DGMs and\npresent a multi-perspective categorization. Furthermore, we systematically\nanalyze the critical technologies required to construct industrial LGMs from\nfour aspects: large-scale industrial dataset, LGMs architecture for complex\nindustrial characteristics, self-supervised training for industrial time\nseries, and fine-tuning of industrial downstream tasks. Finally, we conclude\nthe challenges and future directions to enable the development of generative\nmodels in industry.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 figures.his work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2407.11480v2",
    "published_date": "2024-07-16 08:16:54 UTC",
    "updated_date": "2025-02-16 14:04:11 UTC"
  },
  {
    "arxiv_id": "2407.11477v1",
    "title": "XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More",
    "authors": [
      "Xiaochuan Gou",
      "Ziyue Li",
      "Tian Lan",
      "Junpeng Lin",
      "Zhishuai Li",
      "Bingyu Zhao",
      "Chen Zhang",
      "Di Wang",
      "Xiangliang Zhang"
    ],
    "abstract": "Long-separated research has been conducted on two highly correlated tracks:\ntraffic and incidents. Traffic track witnesses complicating deep learning\nmodels, e.g., to push the prediction a few percent more accurate, and the\nincident track only studies the incidents alone, e.g., to infer the incident\nrisk. We, for the first time, spatiotemporally aligned the two tracks in a\nlarge-scale region (16,972 traffic nodes) over the whole year of 2023: our\nXTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,\nlane occupancy, and average vehicle speed, and incidents, whose records are\nspatiotemporally-aligned with traffic data, with seven different incident\nclasses. Additionally, each node includes detailed physical and policy-level\nmeta-attributes of lanes. Our data can revolutionalize traditional\ntraffic-related tasks towards higher interpretability and practice: instead of\ntraditional prediction or classification tasks, we conduct: (1) post-incident\ntraffic forecasting to quantify the impact of different incidents on traffic\nindexes; (2) incident classification using traffic indexes to determine the\nincidents types for precautions measures; (3) global causal analysis among the\ntraffic indexes, meta-attributes, and incidents to give high-level guidance of\nthe interrelations of various factors; (4) local causal analysis within road\nnodes to examine how different incidents affect the road segments' relations.\nThe dataset is available at http://xaitraffic.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11477v1",
    "published_date": "2024-07-16 08:16:01 UTC",
    "updated_date": "2024-07-16 08:16:01 UTC"
  },
  {
    "arxiv_id": "2407.11472v2",
    "title": "DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems",
    "authors": [
      "Kaibo He",
      "Chenhui Zuo",
      "Chengtian Ma",
      "Yanan Sui"
    ],
    "abstract": "Learning an effective policy to control high-dimensional, overactuated\nsystems is a significant challenge for deep reinforcement learning algorithms.\nSuch control scenarios are often observed in the neural control of vertebrate\nmusculoskeletal systems. The study of these control mechanisms will provide\ninsights into the control of high-dimensional, overactuated systems. The\ncoordination of actuators, known as muscle synergies in neuromechanics, is\nconsidered a presumptive mechanism that simplifies the generation of motor\ncommands. The dynamical structure of a system is the basis of its function,\nallowing us to derive a synergistic representation of actuators. Motivated by\nthis theory, we propose the Dynamical Synergistic Representation (DynSyn)\nalgorithm. DynSyn aims to generate synergistic representations from dynamical\nstructures and perform task-specific, state-dependent adaptation to the\nrepresentations to improve motor control. We demonstrate DynSyn's efficiency\nacross various tasks involving different musculoskeletal models, achieving\nstate-of-the-art sample efficiency and robustness compared to baseline\nalgorithms. DynSyn generates interpretable synergistic representations that\ncapture the essential features of dynamical structures and demonstrates\ngeneralizability across diverse motor tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11472v2",
    "published_date": "2024-07-16 08:09:59 UTC",
    "updated_date": "2024-12-26 16:10:34 UTC"
  },
  {
    "arxiv_id": "2407.11470v2",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "authors": [
      "Jiasheng Zheng",
      "Boxi Cao",
      "Zhengzhao Ma",
      "Ruotong Pan",
      "Hongyu Lin",
      "Yaojie Lu",
      "Xianpei Han",
      "Le Sun"
    ],
    "abstract": "In recent years, researchers have proposed numerous benchmarks to evaluate\nthe impressive coding capabilities of large language models (LLMs). However,\ncurrent benchmarks primarily assess the accuracy of LLM-generated code, while\nneglecting other critical dimensions that also significantly impact code\nquality in real-world development. Moreover, relying exclusively on correctness\nas the guiding metric renders LLMs susceptible to data contamination.\nTherefore, this paper proposes the RACE benchmark, which comprehensively\nevaluates the quality of code generated by LLMs across 4 dimensions:\nReadability, mAintainability, Correctness, and Efficiency. Specifically,\nconsidering the demand-dependent nature of dimensions beyond correctness, we\ndesign various types of user requirements for each dimension to assess the\nmodel's ability to generate correct code that also meets user demands. We\nanalyze 28 representative LLMs based on RACE and find that: 1) current\ncorrectness-centric benchmarks fail to capture the multifaceted requirements of\ncode in real-world scenarios, while RACE provides a comprehensive evaluation\nthat reveals the defects of LLMs across multiple dimensions; 2) the RACE\nbenchmark serves as an effective tool for resisting the risk of data\ncontamination; 3) even the most advanced code LLMs still encounter significant\nchallenges in customized requirements involving complex instructions; 4) most\nLLMs exhibit an inherent preference for specific coding style. These findings\nhighlight the need for a multidimensional evaluation of code LLMs, emphasizing\nmetrics beyond correctness for real-world applications. Future efforts should\naim to develop novel learning algorithms to enhance code generation under\nvaried constraints and improve coverage and usability for diverse user needs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "We release benchmark at https://github.com/jszheng21/RACE and\n  leaderboard at https://huggingface.co/spaces/jszheng/RACE_leaderboard",
    "pdf_url": "http://arxiv.org/pdf/2407.11470v2",
    "published_date": "2024-07-16 08:08:48 UTC",
    "updated_date": "2024-10-09 05:59:07 UTC"
  },
  {
    "arxiv_id": "2407.20241v1",
    "title": "NudgeRank: Digital Algorithmic Nudging for Personalized Health",
    "authors": [
      "Jodi Chiam",
      "Aloysius Lim",
      "Ankur Teredesai"
    ],
    "abstract": "In this paper we describe NudgeRank, an innovative digital algorithmic\nnudging system designed to foster positive health behaviors on a\npopulation-wide scale. Utilizing a novel combination of Graph Neural Networks\naugmented with an extensible Knowledge Graph, this Recommender System is\noperational in production, delivering personalized and context-aware nudges to\nover 1.1 million care recipients daily. This enterprise deployment marks one of\nthe largest AI-driven health behavior change initiatives, accommodating diverse\nhealth conditions and wearable devices. Rigorous evaluation reveals\nstatistically significant improvements in health outcomes, including a 6.17%\nincrease in daily steps and 7.61% more exercise minutes. Moreover, user\nengagement and program enrollment surged, with a 13.1% open rate compared to\nbaseline systems' 4%. Demonstrating scalability and reliability, NudgeRank\noperates efficiently on commodity compute resources while maintaining\nautomation and observability standards essential for production systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "To be published in Proceedings of the 30th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining (KDD '24)",
    "pdf_url": "http://arxiv.org/pdf/2407.20241v1",
    "published_date": "2024-07-16 07:56:42 UTC",
    "updated_date": "2024-07-16 07:56:42 UTC"
  },
  {
    "arxiv_id": "2407.14543v1",
    "title": "Towards consistency of rule-based explainer and black box model -- fusion of rule induction and XAI-based feature importance",
    "authors": [
      "Michał Kozielski",
      "Marek Sikora",
      "Łukasz Wawrowski"
    ],
    "abstract": "Rule-based models offer a human-understandable representation, i.e. they are\ninterpretable. For this reason, they are used to explain the decisions of\nnon-interpretable complex models, referred to as black box models. The\ngeneration of such explanations involves the approximation of a black box model\nby a rule-based model. To date, however, it has not been investigated whether\nthe rule-based model makes decisions in the same way as the black box model it\napproximates. Decision making in the same way is understood in this work as the\nconsistency of decisions and the consistency of the most important attributes\nused for decision making. This study proposes a novel approach ensuring that\nthe rule-based surrogate model mimics the performance of the black box model.\nThe proposed solution performs an explanation fusion involving rule generation\nand taking into account the feature importance determined by the selected XAI\nmethods for the black box model being explained. The result of the method can\nbe both global and local rule-based explanations. The quality of the proposed\nsolution was verified by extensive analysis on 30 tabular benchmark datasets\nrepresenting classification problems. Evaluation included comparison with the\nreference method and an illustrative case study. In addition, the paper\ndiscusses the possible pathways for the application of the rule-based approach\nin XAI and how rule-based explanations, including the proposed method, meet the\nuser perspective and requirements for both content and presentation. The\nsoftware created and a detailed report containing the full experimental results\nare available on the GitHub repository\n(https://github.com/ruleminer/FI-rules4XAI ).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.14543v1",
    "published_date": "2024-07-16 07:56:29 UTC",
    "updated_date": "2024-07-16 07:56:29 UTC"
  },
  {
    "arxiv_id": "2407.11463v3",
    "title": "Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis",
    "authors": [
      "Zhipeng He",
      "Chun Ouyang",
      "Laith Alzubaidi",
      "Alistair Barros",
      "Catarina Moreira"
    ],
    "abstract": "Adversarial attacks are a potential threat to machine learning models by\ncausing incorrect predictions through imperceptible perturbations to the input\ndata. While these attacks have been extensively studied in unstructured data\nlike images, applying them to tabular data, poses new challenges. These\nchallenges arise from the inherent heterogeneity and complex feature\ninterdependencies in tabular data, which differ from the image data. To account\nfor this distinction, it is necessary to establish tailored imperceptibility\ncriteria specific to tabular data. However, there is currently a lack of\nstandardised metrics for assessing the imperceptibility of adversarial attacks\non tabular data. To address this gap, we propose a set of key properties and\ncorresponding metrics designed to comprehensively characterise imperceptible\nadversarial attacks on tabular data. These are: proximity to the original\ninput, sparsity of altered features, deviation from the original data\ndistribution, sensitivity in perturbing features with narrow distribution,\nimmutability of certain features that should remain unchanged, feasibility of\nspecific feature values that should not go beyond valid practical ranges, and\nfeature interdependencies capturing complex relationships between data\nattributes. We evaluate the imperceptibility of five adversarial attacks,\nincluding both bounded attacks and unbounded attacks, on tabular data using the\nproposed imperceptibility metrics. The results reveal a trade-off between the\nimperceptibility and effectiveness of these attacks. The study also identifies\nlimitations in current attack algorithms, offering insights that can guide\nfuture research in the area. The findings gained from this empirical analysis\nprovide valuable direction for enhancing the design of adversarial attack\nalgorithms, thereby advancing adversarial machine learning on tabular data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.11463v3",
    "published_date": "2024-07-16 07:55:25 UTC",
    "updated_date": "2024-10-04 06:35:27 UTC"
  },
  {
    "arxiv_id": "2407.11456v1",
    "title": "Graceful task adaptation with a bi-hemispheric RL agent",
    "authors": [
      "Grant Nicholas",
      "Levin Kuhlmann",
      "Gideon Kowadlo"
    ],
    "abstract": "In humans, responsibility for performing a task gradually shifts from the\nright hemisphere to the left. The Novelty-Routine Hypothesis (NRH) states that\nthe right and left hemispheres are used to perform novel and routine tasks\nrespectively, enabling us to learn a diverse range of novel tasks while\nperforming the task capably. Drawing on the NRH, we develop a reinforcement\nlearning agent with specialised hemispheres that can exploit generalist\nknowledge from the right-hemisphere to avoid poor initial performance on novel\ntasks. In addition, we find that this design has minimal impact on its ability\nto learn novel tasks. We conclude by identifying improvements to our agent and\nexploring potential expansion to the continual learning setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11456v1",
    "published_date": "2024-07-16 07:45:28 UTC",
    "updated_date": "2024-07-16 07:45:28 UTC"
  },
  {
    "arxiv_id": "2407.11449v1",
    "title": "Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights",
    "authors": [
      "Shunqi Mao",
      "Chaoyi Zhang",
      "Hang Su",
      "Hwanjun Song",
      "Igor Shalyminov",
      "Weidong Cai"
    ],
    "abstract": "Contextualized Image Captioning (CIC) evolves traditional image captioning\ninto a more complex domain, necessitating the ability for multimodal reasoning.\nIt aims to generate image captions given specific contextual information. This\npaper further introduces a novel domain of Controllable Contextualized Image\nCaptioning (Ctrl-CIC). Unlike CIC, which solely relies on broad context,\nCtrl-CIC accentuates a user-defined highlight, compelling the model to tailor\ncaptions that resonate with the highlighted aspects of the context. We present\ntwo approaches, Prompting-based Controller (P-Ctrl) and Recalibration-based\nController (R-Ctrl), to generate focused captions. P-Ctrl conditions the model\ngeneration on highlight by prepending captions with highlight-driven prefixes,\nwhereas R-Ctrl tunes the model to selectively recalibrate the encoder\nembeddings for highlighted tokens. Additionally, we design a GPT-4V empowered\nevaluator to assess the quality of the controlled captions alongside standard\nassessment methods. Extensive experimental results demonstrate the efficient\nand effective controllability of our method, charting a new direction in\nachieving user-adaptive image captioning. Code is available at\nhttps://github.com/ShunqiM/Ctrl-CIC .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11449v1",
    "published_date": "2024-07-16 07:32:48 UTC",
    "updated_date": "2024-07-16 07:32:48 UTC"
  },
  {
    "arxiv_id": "2407.11442v3",
    "title": "EARN Fairness: Explaining, Asking, Reviewing, and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders",
    "authors": [
      "Lin Luo",
      "Yuri Nakao",
      "Mathieu Chollet",
      "Hiroya Inakoshi",
      "Simone Stumpf"
    ],
    "abstract": "Numerous fairness metrics have been proposed and employed by artificial\nintelligence (AI) experts to quantitatively measure bias and define fairness in\nAI models. Recognizing the need to accommodate stakeholders' diverse fairness\nunderstandings, efforts are underway to solicit their input. However, conveying\nAI fairness metrics to stakeholders without AI expertise, capturing their\npersonal preferences, and seeking a collective consensus remain challenging and\nunderexplored. To bridge this gap, we propose a new framework, EARN Fairness,\nwhich facilitates collective metric decisions among stakeholders without\nrequiring AI expertise. The framework features an adaptable interactive system\nand a stakeholder-centered EARN Fairness process to Explain fairness metrics,\nAsk stakeholders' personal metric preferences, Review metrics collectively, and\nNegotiate a consensus on metric selection. To gather empirical results, we\napplied the framework to a credit rating scenario and conducted a user study\ninvolving 18 decision subjects without AI knowledge. We identify their personal\nmetric preferences and their acceptable level of unfairness in individual\nsessions. Subsequently, we uncovered how they reached metric consensus in team\nsessions. Our work shows that the EARN Fairness framework enables stakeholders\nto express personal preferences and reach consensus, providing practical\nguidance for implementing human-centered AI fairness in high-risk contexts.\nThrough this approach, we aim to harmonize fairness expectations of diverse\nstakeholders, fostering more equitable and inclusive AI fairness.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11442v3",
    "published_date": "2024-07-16 07:20:30 UTC",
    "updated_date": "2025-02-10 10:41:14 UTC"
  },
  {
    "arxiv_id": "2407.11439v1",
    "title": "Repurformer: Transformers for Repurposing-Aware Molecule Generation",
    "authors": [
      "Changhun Lee",
      "Gyumin Lee"
    ],
    "abstract": "Generating as diverse molecules as possible with desired properties is\ncrucial for drug discovery research, which invokes many approaches based on\ndeep generative models today. Despite recent advancements in these models,\nparticularly in variational autoencoders (VAEs), generative adversarial\nnetworks (GANs), Transformers, and diffusion models, a significant challenge\nknown as \\textit{the sample bias problem} remains. This problem occurs when\ngenerated molecules targeting the same protein tend to be structurally similar,\nreducing the diversity of generation. To address this, we propose leveraging\nmulti-hop relationships among proteins and compounds. Our model, Repurformer,\nintegrates bi-directional pretraining with Fast Fourier Transform (FFT) and\nlow-pass filtering (LPF) to capture complex interactions and generate diverse\nmolecules. A series of experiments on BindingDB dataset confirm that\nRepurformer successfully creates substitutes for anchor compounds that resemble\npositive compounds, increasing diversity between the anchor and generated\ncompounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2407.11439v1",
    "published_date": "2024-07-16 07:16:13 UTC",
    "updated_date": "2024-07-16 07:16:13 UTC"
  },
  {
    "arxiv_id": "2407.11426v1",
    "title": "Generally-Occurring Model Change for Robust Counterfactual Explanations",
    "authors": [
      "Ao Xu",
      "Tieru Wu"
    ],
    "abstract": "With the increasing impact of algorithmic decision-making on human lives, the\ninterpretability of models has become a critical issue in machine learning.\nCounterfactual explanation is an important method in the field of interpretable\nmachine learning, which can not only help users understand why machine learning\nmodels make specific decisions, but also help users understand how to change\nthese decisions. Naturally, it is an important task to study the robustness of\ncounterfactual explanation generation algorithms to model changes. Previous\nliterature has proposed the concept of Naturally-Occurring Model Change, which\nhas given us a deeper understanding of robustness to model change. In this\npaper, we first further generalize the concept of Naturally-Occurring Model\nChange, proposing a more general concept of model parameter changes,\nGenerally-Occurring Model Change, which has a wider range of applicability. We\nalso prove the corresponding probabilistic guarantees. In addition, we consider\na more specific problem, data set perturbation, and give relevant theoretical\nresults by combining optimization theory.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11426v1",
    "published_date": "2024-07-16 06:44:00 UTC",
    "updated_date": "2024-07-16 06:44:00 UTC"
  },
  {
    "arxiv_id": "2407.11418v3",
    "title": "Semantic Operators: A Declarative Model for Rich, AI-based Data Processing",
    "authors": [
      "Liana Patel",
      "Siddharth Jha",
      "Melissa Pan",
      "Harshit Gupta",
      "Parth Asawa",
      "Carlos Guestrin",
      "Matei Zaharia"
    ],
    "abstract": "The semantic capabilities of large language models (LLMs) have the potential\nto enable rich analytics and reasoning over vast knowledge corpora.\nUnfortunately, existing systems either empirically optimize expensive\nLLM-powered operations with no performance guarantees, or serve a limited set\nof row-wise LLM operations, providing limited robustness, expressiveness and\nusability. We introduce semantic operators, the first formalism for declarative\nand general-purpose AI-based transformations based on natural language\nspecifications (e.g., filtering, sorting, joining or aggregating records using\nnatural language criteria). Each operator opens a rich space for execution\nplans, similar to relational operators. Our model specifies the expected\nbehavior of each operator with a high-quality gold algorithm, and we develop an\noptimization framework that reduces cost, while providing accuracy guarantees\nwith respect to a gold algorithm. Using this approach, we propose several novel\noptimizations to accelerate semantic filtering, joining, group-by and top-k\noperations by up to $1,000\\times$. We implement semantic operators in the LOTUS\nsystem and demonstrate LOTUS' effectiveness on real, bulk-semantic processing\napplications, including fact-checking, biomedical multi-label classification,\nsearch, and topic analysis. We show that the semantic operator model is\nexpressive, capturing state-of-the-art AI pipelines in a few operator calls,\nand making it easy to express new pipelines that match or exceed quality of\nrecent LLM-based analytic systems by up to $170\\%$, while offering accuracy\nguarantees. Overall, LOTUS programs match or exceed the accuracy of\nstate-of-the-art AI pipelines for each task while running up to $3.6\\times$\nfaster than the highest-quality baselines. LOTUS is publicly available at\nhttps://github.com/lotus-data/lotus.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11418v3",
    "published_date": "2024-07-16 06:19:14 UTC",
    "updated_date": "2025-03-01 01:47:51 UTC"
  },
  {
    "arxiv_id": "2407.12876v2",
    "title": "Exploring the Use of Abusive Generative AI Models on Civitai",
    "authors": [
      "Yiluo Wei",
      "Yiming Zhu",
      "Pan Hui",
      "Gareth Tyson"
    ],
    "abstract": "The rise of generative AI is transforming the landscape of digital imagery,\nand exerting a significant influence on online creative communities. This has\nled to the emergence of AI-Generated Content (AIGC) social platforms, such as\nCivitai. These distinctive social platforms allow users to build and share\ntheir own generative AI models, thereby enhancing the potential for more\ndiverse artistic expression. Designed in the vein of social networks, they also\nprovide artists with the means to showcase their creations (generated from the\nmodels), engage in discussions, and obtain feedback, thus nurturing a sense of\ncommunity. Yet, this openness also raises concerns about the abuse of such\nplatforms, e.g., using models to disseminate deceptive deepfakes or infringe\nupon copyrights. To explore this, we conduct the first comprehensive empirical\nstudy of an AIGC social platform, focusing on its use for generating abusive\ncontent. As an exemplar, we construct a comprehensive dataset covering Civitai,\nthe largest available AIGC social platform. Based on this dataset of 87K models\nand 2M images, we explore the characteristics of content and discuss strategies\nfor moderation to better govern these platforms.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted to ACM Multimedia 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12876v2",
    "published_date": "2024-07-16 06:18:03 UTC",
    "updated_date": "2024-07-20 19:59:42 UTC"
  },
  {
    "arxiv_id": "2407.12875v1",
    "title": "ChatBCG: Can AI Read Your Slide Deck?",
    "authors": [
      "Nikita Singh",
      "Rob Balian",
      "Lukas Martinelli"
    ],
    "abstract": "Multimodal models like GPT4o and Gemini Flash are exceptional at inference\nand summarization tasks, which approach human-level in performance. However, we\nfind that these models underperform compared to humans when asked to do very\nspecific 'reading and estimation' tasks, particularly in the context of visual\ncharts in business decks. This paper evaluates the accuracy of GPT 4o and\nGemini Flash-1.5 in answering straightforward questions about data on labeled\ncharts (where data is clearly annotated on the graphs), and unlabeled charts\n(where data is not clearly annotated and has to be inferred from the X and Y\naxis). We conclude that these models aren't currently capable of reading a deck\naccurately end-to-end if it contains any complex or unlabeled charts. Even if a\nuser created a deck of only labeled charts, the model would only be able to\nread 7-8 out of 15 labeled charts perfectly end-to-end. For full list of slide\ndeck figures visit https://www.repromptai.com/chat_bcg",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "for full list of figures visit https://www.repromptai.com/chat_bcg",
    "pdf_url": "http://arxiv.org/pdf/2407.12875v1",
    "published_date": "2024-07-16 06:00:45 UTC",
    "updated_date": "2024-07-16 06:00:45 UTC"
  },
  {
    "arxiv_id": "2407.12065v2",
    "title": "Data selection method for assessment of autonomous vehicles",
    "authors": [
      "Linh Trinh",
      "Ali Anwar",
      "Siegfried Mercelis"
    ],
    "abstract": "As the popularity of autonomous vehicles has grown, many standards and\nregulators, such as ISO, NHTSA, and Euro NCAP, require safety validation to\nensure a sufficient level of safety before deploying them in the real world.\nManufacturers gather a large amount of public road data for this purpose.\nHowever, the majority of these validation activities are done manually by\nhumans. Furthermore, the data used to validate each driving feature may differ.\nAs a result, it is essential to have an efficient data selection method that\ncan be used flexibly and dynamically for verification and validation while also\naccelerating the validation process. In this paper, we present a data selection\nmethod that is practical, flexible, and efficient for assessment of autonomous\nvehicles. Our idea is to optimize the similarity between the metadata\ndistribution of the selected data and a predefined metadata distribution that\nis expected for validation. Our experiments on the large dataset BDD100K show\nthat our method can perform data selection tasks efficiently. These results\ndemonstrate that our methods are highly reliable and can be used to select\nappropriate data for the validation of various safety functions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.12065v2",
    "published_date": "2024-07-16 05:35:38 UTC",
    "updated_date": "2024-10-28 18:02:26 UTC"
  },
  {
    "arxiv_id": "2407.11394v3",
    "title": "DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation",
    "authors": [
      "Jiwook Kim",
      "Seonho Lee",
      "Jaeyo Shin",
      "Jiho Choi",
      "Hyunjung Shim"
    ],
    "abstract": "Score distillation sampling (SDS) has emerged as an effective framework in\ntext-driven 3D editing tasks, leveraging diffusion models for 3D-consistent\nediting. However, existing SDS-based 3D editing methods suffer from long\ntraining times and produce low-quality results. We identify that the root cause\nof this performance degradation is \\textit{their conflict with the sampling\ndynamics of diffusion models}. Addressing this conflict allows us to treat SDS\nas a diffusion reverse process for 3D editing via sampling from data space. In\ncontrast, existing methods naively distill the score function using diffusion\nmodels. From these insights, we propose DreamCatalyst, a novel framework that\nconsiders these sampling dynamics in the SDS framework. Specifically, we devise\nthe optimization process of our DreamCatalyst to approximate the diffusion\nreverse process in editing tasks, thereby aligning with diffusion sampling\ndynamics. As a result, DreamCatalyst successfully reduces training time and\nimproves editing quality. Our method offers two modes: (1) a fast mode that\nedits Neural Radiance Fields (NeRF) scenes approximately 23 times faster than\ncurrent state-of-the-art NeRF editing methods, and (2) a high-quality mode that\nproduces superior results about 8 times faster than these methods. Notably, our\nhigh-quality mode outperforms current state-of-the-art NeRF editing methods in\nterms of both speed and quality. DreamCatalyst also surpasses the\nstate-of-the-art 3D Gaussian Splatting (3DGS) editing methods, establishing\nitself as an effective and model-agnostic 3D editing solution. See more\nextensive results on our project page: https://dream-catalyst.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.11394v3",
    "published_date": "2024-07-16 05:26:14 UTC",
    "updated_date": "2025-02-11 07:34:37 UTC"
  },
  {
    "arxiv_id": "2407.11393v2",
    "title": "CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation",
    "authors": [
      "Kalliopi Basioti",
      "Mohamed A. Abdelsalam",
      "Federico Fancellu",
      "Vladimir Pavlovic",
      "Afsaneh Fazly"
    ],
    "abstract": "Controllable Image Captioning (CIC) aims at generating natural language\ndescriptions for an image, conditioned on information provided by end users,\ne.g., regions, entities or events of interest. However, available\nimage-language datasets mainly contain captions that describe the entirety of\nan image, making them ineffective for training CIC models that can potentially\nattend to any subset of regions or relationships. To tackle this challenge, we\npropose a novel, fully automatic method to sample additional focused and\nvisually grounded captions using a unified structured semantic representation\nbuilt on top of the existing set of captions associated with an image. We\nleverage Abstract Meaning Representation (AMR), a cross-lingual graph-based\nsemantic formalism, to encode all possible spatio-semantic relations between\nentities, beyond the typical spatial-relations-only focus of current methods.\nWe use this Structured Semantic Augmentation (SSA) framework to augment\nexisting image-caption datasets with the grounded controlled captions,\nincreasing their spatial and semantic diversity and focal coverage. We then\ndevelop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that\nsources its control signals from SSA-diversified datasets. We empirically show\nthat, compared to SOTA CIC models, CIC-BART-SSA generates captions that are\nsuperior in diversity and text quality, are competitive in controllability,\nand, importantly, minimize the gap between broad and highly focused controlled\ncaptioning performance by efficiently generalizing to the challenging highly\nfocused scenarios. Code is available at\nhttps://github.com/SamsungLabs/CIC-BART-SSA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11393v2",
    "published_date": "2024-07-16 05:26:12 UTC",
    "updated_date": "2024-07-17 16:40:05 UTC"
  },
  {
    "arxiv_id": "2407.11383v1",
    "title": "TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering",
    "authors": [
      "Tonmoy Rajkhowa",
      "Amartya Roy Chowdhury",
      "Sankalp Nagaonkar",
      "Achyut Mani Tripathi"
    ],
    "abstract": "In healthcare and medical diagnostics, Visual Question Answering (VQA)\nmayemergeasapivotal tool in scenarios where analysis of intricate medical\nimages becomes critical for accurate diagnoses. Current text-based VQA systems\nlimit their utility in scenarios where hands-free interaction and accessibility\nare crucial while performing tasks. A speech-based VQA system may provide a\nbetter means of interaction where information can be accessed while performing\ntasks simultaneously. To this end, this work implements a speech-based VQA\nsystem by introducing a Textless Multilingual Pathological VQA (TMPathVQA)\ndataset, an expansion of the PathVQA dataset, containing spoken questions in\nEnglish, German & French. This dataset comprises 98,397 multilingual spoken\nquestions and answers based on 5,004 pathological images along with 70 hours of\naudio. Finally, this work benchmarks and compares TMPathVQA systems implemented\nusing various combinations of acoustic and visual features.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "conference (Accepted at Interspeech 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.11383v1",
    "published_date": "2024-07-16 04:54:45 UTC",
    "updated_date": "2024-07-16 04:54:45 UTC"
  },
  {
    "arxiv_id": "2407.11382v2",
    "title": "Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts",
    "authors": [
      "Jianhao Li",
      "Tianyu Sun",
      "Zhongdao Wang",
      "Enze Xie",
      "Bailan Feng",
      "Hongbo Zhang",
      "Ze Yuan",
      "Ke Xu",
      "Jiaheng Liu",
      "Ping Luo"
    ],
    "abstract": "This paper proposes an algorithm for automatically labeling 3D objects from\n2D point or box prompts, especially focusing on applications in autonomous\ndriving. Unlike previous arts, our auto-labeler predicts 3D shapes instead of\nbounding boxes and does not require training on a specific dataset. We propose\na Segment, Lift, and Fit (SLF) paradigm to achieve this goal. Firstly, we\nsegment high-quality instance masks from the prompts using the Segment Anything\nModel (SAM) and transform the remaining problem into predicting 3D shapes from\ngiven 2D masks. Due to the ill-posed nature of this problem, it presents a\nsignificant challenge as multiple 3D shapes can project into an identical mask.\nTo tackle this issue, we then lift 2D masks to 3D forms and employ gradient\ndescent to adjust their poses and shapes until the projections fit the masks\nand the surfaces conform to surrounding LiDAR points. Notably, since we do not\ntrain on a specific dataset, the SLF auto-labeler does not overfit to biased\nannotation patterns in the training set as other methods do. Thus, the\ngeneralization ability across different datasets improves. Experimental results\non the KITTI dataset demonstrate that the SLF auto-labeler produces\nhigh-quality bounding box annotations, achieving an AP@0.5 IoU of nearly 90\\%.\nDetectors trained with the generated pseudo-labels perform nearly as well as\nthose trained with actual ground-truth annotations. Furthermore, the SLF\nauto-labeler shows promising results in detailed shape predictions, providing a\npotential alternative for the occupancy annotation of dynamic objects.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11382v2",
    "published_date": "2024-07-16 04:53:28 UTC",
    "updated_date": "2024-07-17 06:32:53 UTC"
  },
  {
    "arxiv_id": "2407.12874v2",
    "title": "SELF-GUIDE: Better Task-Specific Instruction Following via Self-Synthetic Finetuning",
    "authors": [
      "Chenyang Zhao",
      "Xueying Jia",
      "Vijay Viswanathan",
      "Tongshuang Wu",
      "Graham Neubig"
    ],
    "abstract": "Large language models (LLMs) hold the promise of solving diverse tasks when\nprovided with appropriate natural language prompts. However, prompting often\nleads models to make predictions with lower accuracy compared to finetuning a\nmodel with ample training data. On the other hand, while finetuning LLMs on\ntask-specific data generally improves their performance, abundant annotated\ndatasets are not available for all tasks. Previous work has explored generating\ntask-specific data from state-of-the-art LLMs and using this data to finetune\nsmaller models, but this approach requires access to a language model other\nthan the one being trained, which introduces cost, scalability challenges, and\nlegal hurdles associated with continuously relying on more powerful LLMs. In\nresponse to these, we propose SELF-GUIDE, a multi-stage mechanism in which we\nsynthesize task-specific input-output pairs from the student LLM, then use\nthese input-output pairs to finetune the student LLM itself. In our empirical\nevaluation of the Natural Instructions V2 benchmark, we find that SELF-GUIDE\nimproves the performance of LLM by a substantial margin. Specifically, we\nreport an absolute improvement of approximately 15% for classification tasks\nand 18% for generation tasks in the benchmark's metrics. This sheds light on\nthe promise of self-synthesized data guiding LLMs towards becoming\ntask-specific experts without any external learning signals.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.12874v2",
    "published_date": "2024-07-16 04:41:58 UTC",
    "updated_date": "2024-08-12 00:38:22 UTC"
  },
  {
    "arxiv_id": "2407.11373v2",
    "title": "Reliable Reasoning Beyond Natural Language",
    "authors": [
      "Nasim Borazjanizadeh",
      "Steven T. Piantadosi"
    ],
    "abstract": "Despite their linguistic competence, Large Language models (LLMs) often\nexhibit limitations in their ability to reason reliably and flexibly. To\naddress this, we propose a neurosymbolic approach that prompts LLMs to extract\nand encode all relevant information from a problem statement as logical code\nstatements, and then use a logic programming language (Prolog) to conduct the\niterative computations of explicit deductive reasoning. Our approach\nsignificantly enhances the performance of LLMs on the standard mathematical\nreasoning benchmark, GSM8k, and the Navigate dataset from the BIG-bench\ndataset. Additionally, we introduce a novel dataset, the Non-Linear Reasoning\n(NLR) dataset, consisting of 55 unique word problems that target the\nshortcomings of the next token prediction paradigm of LLMs and require complex\nnon-linear reasoning but only basic arithmetic skills to solve. Our findings\ndemonstrate that the integration of Prolog enables LLMs to achieve high\nperformance on the NLR dataset, which even the most advanced language models\n(including GPT4) fail to solve using text only.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11373v2",
    "published_date": "2024-07-16 04:34:18 UTC",
    "updated_date": "2024-07-19 18:54:02 UTC"
  },
  {
    "arxiv_id": "2407.11360v1",
    "title": "Thorns and Algorithms: Navigating Generative AI Challenges Inspired by Giraffes and Acacias",
    "authors": [
      "Waqar Hussain"
    ],
    "abstract": "The interplay between humans and Generative AI (Gen AI) draws an insightful\nparallel with the dynamic relationship between giraffes and acacias on the\nAfrican Savannah. Just as giraffes navigate the acacia's thorny defenses to\ngain nourishment, humans engage with Gen AI, maneuvering through ethical and\noperational challenges to harness its benefits. This paper explores how, like\nyoung giraffes that are still mastering their environment, humans are in the\nearly stages of adapting to and shaping Gen AI. It delves into the strategies\nhumans are developing and refining to help mitigate risks such as bias,\nmisinformation, and privacy breaches, that influence and shape Gen AI's\nevolution. While the giraffe-acacia analogy aptly frames human-AI relations, it\ncontrasts nature's evolutionary perfection with the inherent flaws of\nhuman-made technology and the tendency of humans to misuse it, giving rise to\nmany ethical dilemmas. Through the HHH framework we identify pathways to embed\nvalues of helpfulness, honesty, and harmlessness in AI development, fostering\nsafety-aligned agents that resonate with human values. This narrative presents\na cautiously optimistic view of human resilience and adaptability, illustrating\nour capacity to harness technologies and implement safeguards effectively,\nwithout succumbing to their perils. It emphasises a symbiotic relationship\nwhere humans and AI continually shape each other for mutual benefit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11360v1",
    "published_date": "2024-07-16 03:53:25 UTC",
    "updated_date": "2024-07-16 03:53:25 UTC"
  },
  {
    "arxiv_id": "2407.11359v1",
    "title": "Feature Inference Attack on Shapley Values",
    "authors": [
      "Xinjian Luo",
      "Yangfan Jiang",
      "Xiaokui Xiao"
    ],
    "abstract": "As a solution concept in cooperative game theory, Shapley value is highly\nrecognized in model interpretability studies and widely adopted by the leading\nMachine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and\nIBM. However, as the Shapley value-based model interpretability methods have\nbeen thoroughly studied, few researchers consider the privacy risks incurred by\nShapley values, despite that interpretability and privacy are two foundations\nof machine learning (ML) models.\n  In this paper, we investigate the privacy risks of Shapley value-based model\ninterpretability methods using feature inference attacks: reconstructing the\nprivate model inputs based on their Shapley value explanations. Specifically,\nwe present two adversaries. The first adversary can reconstruct the private\ninputs by training an attack model based on an auxiliary dataset and black-box\naccess to the model interpretability services. The second adversary, even\nwithout any background knowledge, can successfully reconstruct most of the\nprivate features by exploiting the local linear correlations between the model\ninputs and outputs. We perform the proposed attacks on the leading MLaaS\nplatforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The\nexperimental results demonstrate the vulnerability of the state-of-the-art\nShapley value-based model interpretability methods used in the leading MLaaS\nplatforms and highlight the significance and necessity of designing\nprivacy-preserving model interpretability methods in future studies. To our\nbest knowledge, this is also the first work that investigates the privacy risks\nof Shapley values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "This work was published in CCS 2022",
    "pdf_url": "http://arxiv.org/pdf/2407.11359v1",
    "published_date": "2024-07-16 03:50:06 UTC",
    "updated_date": "2024-07-16 03:50:06 UTC"
  },
  {
    "arxiv_id": "2407.11358v2",
    "title": "SES: Bridging the Gap Between Explainability and Prediction of Graph Neural Networks",
    "authors": [
      "Zhenhua Huang",
      "Kunhao Li",
      "Shaojie Wang",
      "Zhaohong Jia",
      "Wentao Zhu",
      "Sharad Mehrotra"
    ],
    "abstract": "Despite the Graph Neural Networks' (GNNs) proficiency in analyzing graph\ndata, achieving high-accuracy and interpretable predictions remains\nchallenging. Existing GNN interpreters typically provide post-hoc explanations\ndisjointed from GNNs' predictions, resulting in misrepresentations.\nSelf-explainable GNNs offer built-in explanations during the training process.\nHowever, they cannot exploit the explanatory outcomes to augment prediction\nperformance, and they fail to provide high-quality explanations of node\nfeatures and require additional processes to generate explainable subgraphs,\nwhich is costly. To address the aforementioned limitations, we propose a\nself-explained and self-supervised graph neural network (SES) to bridge the gap\nbetween explainability and prediction. SES comprises two processes: explainable\ntraining and enhanced predictive learning. During explainable training, SES\nemploys a global mask generator co-trained with a graph encoder and directly\nproduces crucial structure and feature masks, reducing time consumption and\nproviding node feature and subgraph explanations. In the enhanced predictive\nlearning phase, mask-based positive-negative pairs are constructed utilizing\nthe explanations to compute a triplet loss and enhance the node representations\nby contrastive learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a conference paper at ICDE 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11358v2",
    "published_date": "2024-07-16 03:46:57 UTC",
    "updated_date": "2024-07-25 04:20:12 UTC"
  },
  {
    "arxiv_id": "2407.15862v1",
    "title": "Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis",
    "authors": [
      "Qiuhong Wei",
      "Ying Cui",
      "Mengwei Ding",
      "Yanqin Wang",
      "Lingling Xiang",
      "Zhengxiong Yao",
      "Ceran Chen",
      "Ying Long",
      "Zhezhen Jin",
      "Ximing Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated potential applications in\nmedicine, yet data privacy and computational burden limit their deployment in\nhealthcare institutions. Open-source and lightweight versions of LLMs emerge as\npotential solutions, but their performance, particularly in pediatric settings\nremains underexplored. In this cross-sectional study, 250 patient consultation\nquestions were randomly selected from a public online medical forum, with 10\nquestions from each of 25 pediatric departments, spanning from December 1,\n2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and\nVicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used\nproprietary ChatGPT-3.5, independently answered these questions in Chinese\nbetween November 1, 2023, and November 7, 2023. To assess reproducibility, each\ninquiry was replicated once. We found that ChatGLM3-6B demonstrated higher\naccuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all\nwere outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in\naccuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and\nVicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed\nby ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest\nratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming\nVicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the\nlightweight LLMs (P < .001). In safety, all models performed comparably well (P\n> .05), with over 98.4% of responses being rated as safe. Repetition of\ninquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate\npromising application in pediatric healthcare. However, the observed gap\nbetween lightweight and large-scale proprietary LLMs underscores the need for\ncontinued development efforts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "68M20 (Primary) 62G10 (Secondary)"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages in total with 17 pages of main manuscript and 10 pages of\n  supplementary materials; 4 figures in the main manuscript and 2 figures in\n  supplementary material",
    "pdf_url": "http://arxiv.org/pdf/2407.15862v1",
    "published_date": "2024-07-16 03:35:09 UTC",
    "updated_date": "2024-07-16 03:35:09 UTC"
  },
  {
    "arxiv_id": "2407.11315v1",
    "title": "COMET: \"Cone of experience\" enhanced large multimodal model for mathematical problem generation",
    "authors": [
      "Sannyuya Liu",
      "Jintian Feng",
      "Zongkai Yang",
      "Yawei Luo",
      "Qian Wan",
      "Xiaoxuan Shen",
      "Jianwen Sun"
    ],
    "abstract": "The automatic generation of high-quality mathematical problems is practically\nvaluable in many educational scenarios. Large multimodal model provides a novel\ntechnical approach for the mathematical problem generation because of its wide\nsuccess in cross-modal data scenarios. However, the traditional method of\nseparating problem solving from problem generation and the mainstream\nfine-tuning framework of monotonous data structure with homogeneous training\nobjectives limit the application of large multimodal model in mathematical\nproblem generation. Addressing these challenges, this paper proposes COMET, a\n\"Cone of Experience\" enhanced large multimodal model for mathematical problem\ngeneration. Firstly, from the perspective of mutual ability promotion and\napplication logic, we unify stem generation and problem solving into\nmathematical problem generation. Secondly, a three-stage fine-turning framework\nguided by the \"Cone of Experience\" is proposed. The framework divides the\nfine-tuning data into symbolic experience, iconic experience, and direct\nexperience to draw parallels with experiences in the career growth of teachers.\nSeveral fine-grained data construction and injection methods are designed in\nthis framework. Finally, we construct a Chinese multimodal mathematical problem\ndataset to fill the vacancy of Chinese multimodal data in this field. Combined\nwith objective and subjective indicators, experiments on multiple datasets\nfully verify the effectiveness of the proposed framework and model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11315v1",
    "published_date": "2024-07-16 02:02:16 UTC",
    "updated_date": "2024-07-16 02:02:16 UTC"
  },
  {
    "arxiv_id": "2407.11300v1",
    "title": "Large Vision-Language Models as Emotion Recognizers in Context Awareness",
    "authors": [
      "Yuxuan Lei",
      "Dingkang Yang",
      "Zhaoyu Chen",
      "Jiawei Chen",
      "Peng Zhai",
      "Lihua Zhang"
    ],
    "abstract": "Context-aware emotion recognition (CAER) is a complex and significant task\nthat requires perceiving emotions from various contextual cues. Previous\napproaches primarily focus on designing sophisticated architectures to extract\nemotional cues from images. However, their knowledge is confined to specific\ntraining datasets and may reflect the subjective emotional biases of the\nannotators. Furthermore, acquiring large amounts of labeled data is often\nchallenging in real-world applications. In this paper, we systematically\nexplore the potential of leveraging Large Vision-Language Models (LVLMs) to\nempower the CAER task from three paradigms: 1) We fine-tune LVLMs on two CAER\ndatasets, which is the most common way to transfer large models to downstream\ntasks. 2) We design zero-shot and few-shot patterns to evaluate the performance\nof LVLMs in scenarios with limited data or even completely unseen. In this\ncase, a training-free framework is proposed to fully exploit the In-Context\nLearning (ICL) capabilities of LVLMs. Specifically, we develop an image\nsimilarity-based ranking algorithm to retrieve examples; subsequently, the\ninstructions, retrieved examples, and the test example are combined to feed\nLVLMs to obtain the corresponding sentiment judgment. 3) To leverage the rich\nknowledge base of LVLMs, we incorporate Chain-of-Thought (CoT) into our\nframework to enhance the model's reasoning ability and provide interpretable\nresults. Extensive experiments and analyses demonstrate that LVLMs achieve\ncompetitive performance in the CAER task across different paradigms. Notably,\nthe superior performance in few-shot settings indicates the feasibility of\nLVLMs for accomplishing specific tasks without extensive training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11300v1",
    "published_date": "2024-07-16 01:28:06 UTC",
    "updated_date": "2024-07-16 01:28:06 UTC"
  },
  {
    "arxiv_id": "2407.11288v1",
    "title": "Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems",
    "authors": [
      "Yaşar Utku Alçalar",
      "Mehmet Akçakaya"
    ],
    "abstract": "Diffusion models have emerged as powerful generative techniques for solving\ninverse problems. Despite their success in a variety of inverse problems in\nimaging, these models require many steps to converge, leading to slow inference\ntime. Recently, there has been a trend in diffusion models for employing\nsophisticated noise schedules that involve more frequent iterations of\ntimesteps at lower noise levels, thereby improving image generation and\nconvergence speed. However, application of these ideas for solving inverse\nproblems with diffusion models remain challenging, as these noise schedules do\nnot perform well when using empirical tuning for the forward model\nlog-likelihood term weights. To tackle these challenges, we propose zero-shot\napproximate posterior sampling (ZAPS) that leverages connections to zero-shot\nphysics-driven deep learning. ZAPS fixes the number of sampling steps, and uses\nzero-shot training with a physics-guided loss function to learn log-likelihood\nweights at each irregular timestep. We apply ZAPS to the recently proposed\ndiffusion posterior sampling method as baseline, though ZAPS can also be used\nwith other posterior sampling diffusion models. We further approximate the\nHessian of the logarithm of the prior using a diagonalization approach with\nlearnable diagonal entries for computational efficiency. These parameters are\noptimized over a fixed number of epochs with a given computational budget. Our\nresults for various noisy inverse problems, including Gaussian and motion\ndeblurring, inpainting, and super-resolution show that ZAPS reduces inference\ntime, provides robustness to irregular noise schedules and improves\nreconstruction quality. Code is available at https://github.com/ualcalar17/ZAPS",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "European Conference on Computer Vision (ECCV), 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11288v1",
    "published_date": "2024-07-16 00:09:37 UTC",
    "updated_date": "2024-07-16 00:09:37 UTC"
  }
]