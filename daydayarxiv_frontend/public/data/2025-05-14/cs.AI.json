{
  "date": "2025-05-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 84 篇论文，主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLMs）在医疗、机器人和优化中的应用、联邦学习公平性、量子计算创新，以及新型数据集和基准测试；令人印象深刻的是 DeepSeek-V3 的硬件挑战分析，以及 LLMs 在冲突预测和代码生成的突破性工作，由知名学者如 Thomas L. Griffiths 和 LinkedIn 团队主导的论文脱颖而出。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、话题度高或有创新贡献的文章，并将相关主题归类讨论。对于次要论文，我会快速掠过，以控制篇幅。每个论文标题以“中文标题（英文标题）”形式列出，聚焦核心贡献和发现。\n\n### AI 和 LLMs 应用（重点领域，创新性强）\n- **可预测性塑造适应：Transformer 中学习模式的进化视角（Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers）**：Thomas L. Griffiths 等人研究 Transformer 的 in-weights learning 和 in-context learning，借鉴进化生物学，发现环境可预测性影响学习模式平衡，主要贡献是实验证明高稳定性偏好 in-weights learning，并提出相对成本假设指导训练方法，提升了模型在分类和回归任务的适应性。\n- **LLMs 是否了解冲突？调查参数和非参数知识在冲突预测中的应用（Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting）**：该论文探索 LLMs 在冲突预测中的参数知识，使用 ACLED 和 GDELT 数据集，关键发现是非参数方法（如 RAG）显著提升预测准确性，适用于早期预警系统。\n- **探索 LLM 真相方向在对话格式中的泛化（Exploring the generalization of LLM truth directions on conversational formats）**：研究 LLM 的真相方向（true/false 线性可分），发现短对话泛化良好，但长对话较差，主要贡献是提出添加固定关键短语的方法改善泛化，适用于 LLM 谎言检测。\n- **语言代理镜像人类因果推理偏差：如何帮助它们像科学家一样思考（Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?）**：该工作揭示 LLMs 在因果推理中存在与人类相似的偏差，通过 Blicket 测试实验，提出采样方法减少偏差，提升科学推理能力。\n- **语言模型代理在社交网络模拟中的多代理框架（SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation）**：快速提一下，该框架使用 LLMs 模拟社交网络，实现了长期稳定模拟，显著减少 token 使用。\n\n### 医疗和生物医学 AI（实际应用价值高）\n- **基于 LLM 的儿科败血症队列上下文表型分析（Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models）**：使用 LLAMA 3.1 和其他模型分析败血症数据，主要发现 LLM 方法优于传统聚类，能捕获营养和临床特征，提升资源有限环境下的决策。\n- **多模态多代理框架用于放射学报告生成（A Multimodal Multi-Agent Framework for Radiology Report Generation）**：提出任务特定代理处理检索和生成，显著减少事实不一致，提升报告准确性和可解释性。\n- **AI 在肺癌检测中的可解释性设计（Explainability Through Human-Centric Design for XAI in Lung Cancer Detection）**：XpertXAI 模型通过专家驱动的概念瓶颈，改善肺癌检测解释性，关键发现是其解释与放射科医生判断更一致。\n- **BioVFM-21M：基准和扩展自监督视觉基础模型用于生物医学图像分析（BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis）**：介绍一个 2100 万图像数据集，证明模型规模扩展提升性能，主要贡献是跨任务泛化，适用于医学图像处理。\n\n### 机器人和视觉技术（跨领域创新）\n- **ManipBench：评估视觉语言模型在机器人操作中的鲁棒性（ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation）**：测试 33 个 VLMs 在机器人任务中的性能，发现模型在物体交互和变形物操作上表现不一，主要贡献是提供新基准，提升机器人低级推理。\n- **UMotion：基于不确定性的惯性传感器和超宽带单位的人体运动估计（UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units）**：使用 UKF 框架融合传感器数据，显著改善人体姿势估计准确性。\n- **DRRNet：宏观-微观特征融合和双向反向细化用于 camouflaged 对象检测（DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection）**：提出特征融合和反向细化模块，提升 camouflaged 对象检测精度，关键发现是抑制背景干扰。\n\n### 其他创新领域（快速掠过，选有影响力的）\n- **DeepSeek-V3：AI 架构的缩放挑战和硬件反思（Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures）**：LinkedIn 团队分析，讨论 AI 硬件瓶颈，如内存和带宽，贡献是提出混合精度训练和网络拓扑优化。\n- **EDBench：大规模电子密度数据用于分子建模（EDBench: Large-Scale Electron Density Data for Molecular Prediction）**：构建 330 万分子数据集，用于分子属性预测，主要发现是提升药物发现效率。\n- **Quantum-Enhanced 参数高效学习用于台风轨迹预测（Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting）**：结合量子神经网络和 Attention 模型，减少参数量，提升预测准确性。\n- 其他如 **RXTX Can Be Faster（$XX^{t}$ Can Be Faster）** 和 **Online Isolation Forest（Online Isolation Forest）** 等算法优化论文，贡献在于效率提升，但非核心话题，故快速掠过：前者提出新矩阵乘法算法节省计算，后者改进流式异常检测。\n\n总之，今天的论文突显 AI 模型在实际应用中的潜力与挑战，LLMs 的泛化与公平性是热点。arXiv 快报到此结束，欢迎关注明日更新！",
  "papers": [
    {
      "arxiv_id": "2505.09861v1",
      "title": "LiDDA: Data Driven Attribution at LinkedIn",
      "title_zh": "LiDDA：LinkedIn 的数据驱动归因",
      "authors": [
        "John Bencina",
        "Erkut Aykutlug",
        "Yue Chen",
        "Zerui Zhang",
        "Stephanie Sorenson",
        "Shao Tang",
        "Changshuai Wei"
      ],
      "abstract": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields.",
      "tldr_zh": "本文提出 LiDDA 系统，一种基于 Data Driven Attribution 的方法，用于根据从数据中学习到的因果模式为营销互动分配转化信用，从而提升现代营销智能。该系统采用统一的 Transformer 框架，能够处理成员级数据、聚合级数据，并整合外部宏观因素。在 LinkedIn 的规模化实施中，LiDDA 展示了显著影响，并分享了可广泛应用于营销和广告技术领域的见解和经验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09861v1",
      "published_date": "2025-05-14 23:54:57 UTC",
      "updated_date": "2025-05-14 23:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:17:45.704316"
    },
    {
      "arxiv_id": "2505.09855v1",
      "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers",
      "title_zh": "可预测性塑造适应：Transformer 中学习模式的进化视角",
      "authors": [
        "Alexander Y. Ku",
        "Thomas L. Griffiths",
        "Stephanie C. Y. Chan"
      ],
      "abstract": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies.",
      "tldr_zh": "这篇论文从进化生物学的视角探讨了 Transformers 模型的两种学习模式：in-weights learning (IWL)，即将知识编码到模型权重中，以及 in-context learning (ICL)，即灵活适应上下文而不修改权重。研究者实验操作化了环境可预测性，包括稳定性与线索可靠性，系统分析了这些因素如何影响 IWL 和 ICL 的平衡。结果显示，高环境稳定性显著偏好 IWL，尤其在最大稳定性时出现急剧转变，而高线索可靠性则增强 ICL 的效能，特别是在稳定性较低的场景。论文还揭示了学习动态中的任务相关转变，支持了相对成本假设，为理解 ICL 和优化 Transformers 训练方法提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09855v1",
      "published_date": "2025-05-14 23:31:17 UTC",
      "updated_date": "2025-05-14 23:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:17:59.214073"
    },
    {
      "arxiv_id": "2505.09852v1",
      "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting",
      "title_zh": "大型语言模型知道冲突吗？ 调查 LLMs 的参数知识与非参数知识在冲突预测中的比较",
      "authors": [
        "Apollinaire Poli Nemkova",
        "Sarath Chandra Lingareddy",
        "Sagnik Ray Choudhury",
        "Mark V. Albert"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在冲突预测方面的能力，比较了其 Parametric Knowledge（预训练权重中的内置知识）和 Non-Parametric Knowledge（通过 Retrieval-Augmented Generation (RAG) 访问外部数据，如 ACLED 和 GDELT 数据库以及新闻报告）。研究采用双部分评估框架，针对2020-2024年非洲之角和中东地区的冲突事件，仅依赖预训练知识预测冲突趋势（如 Escalate、Stable Conflict）和死亡人数，或结合外部信息进行增强。结果显示，LLMs 在参数知识上存在局限性，但通过非参数方法整合结构化外部数据可显著提升预测准确性，从而为早期预警系统和政策制定提供潜在益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09852v1",
      "published_date": "2025-05-14 23:24:22 UTC",
      "updated_date": "2025-05-14 23:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:18:10.222338"
    },
    {
      "arxiv_id": "2505.09847v1",
      "title": "Causal Predictive Optimization and Generation for Business AI",
      "title_zh": "针对商业 AI 的因果预测优化与生成",
      "authors": [
        "Liyang Zhao",
        "Olurotimi Seton",
        "Himadeep Reddy Reddivari",
        "Suvendu Jena",
        "Shadow Zhao",
        "Rachit Kumar",
        "Changshuai Wei"
      ],
      "abstract": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field.",
      "tldr_zh": "该研究提出了一种名为 Causal Predictive Optimization and Generation 的方法，用于优化 B2B 业务的销售过程，包括三个关键层：1) 预测层，利用 causal ML 进行因果机器学习预测；2) 优化层，通过 constraint optimization 和 contextual bandit 实现约束优化和上下文决策；3) 服务层，结合 Generative AI 和反馈-loop 提供服务并增强系统。相比传统系统，该方法已在 LinkedIn 成功部署，取得了显著性能提升，并分享了适用于商业 AI 领域的宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09847v1",
      "published_date": "2025-05-14 23:12:20 UTC",
      "updated_date": "2025-05-14 23:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:18:21.145547"
    },
    {
      "arxiv_id": "2505.09830v1",
      "title": "Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values",
      "title_zh": "评估大型语言模型生成包含等价类划分和边界值的单元测试",
      "authors": [
        "Martín Rodríguez",
        "Gustavo Rossi",
        "Alejandro Fernandez"
      ],
      "abstract": "The design and implementation of unit tests is a complex task many\nprogrammers neglect. This research evaluates the potential of Large Language\nModels (LLMs) in automatically generating test cases, comparing them with\nmanual tests. An optimized prompt was developed, that integrates code and\nrequirements, covering critical cases such as equivalence partitions and\nboundary values. The strengths and weaknesses of LLMs versus trained\nprogrammers were compared through quantitative metrics and manual qualitative\nanalysis. The results show that the effectiveness of LLMs depends on\nwell-designed prompts, robust implementation, and precise requirements.\nAlthough flexible and promising, LLMs still require human supervision. This\nwork highlights the importance of manual qualitative analysis as an essential\ncomplement to automation in unit test evaluation.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在自动生成单元测试方面的潜力，特别是针对等价分区 (equivalence partitions) 和边界值 (boundary values)，并将其与手动测试进行比较。研究开发了一个优化的提示，整合代码和需求，通过定量指标和手动定性分析来考察 LLMs 与训练有素程序员的优缺点。结果显示，LLMs 的有效性依赖于提示设计、实现质量和需求精确性，虽然其灵活且有前景，但仍需人工监督，并强调手动定性分析在单元测试评估中的重要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under revision at Jornadas de Cloud Computing, Big Data & Emerging\n  Topics (JCC-BD&ET) - 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09830v1",
      "published_date": "2025-05-14 22:22:15 UTC",
      "updated_date": "2025-05-14 22:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:18:33.923672"
    },
    {
      "arxiv_id": "2505.09814v1",
      "title": "$XX^{t}$ Can Be Faster",
      "title_zh": "$XX^{t}$ 可以更快",
      "authors": [
        "Dmitry Rybin",
        "Yushun Zhang",
        "Zhi-Quan Luo"
      ],
      "abstract": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization.",
      "tldr_zh": "本研究提出了一种新算法 RXTX，用于计算矩阵 X 与其转置 $X^{t}$ 的乘积 $XX^{t}$。相比现有最先进方法，RXTX 减少了 5% 的乘法和加法操作，即使在小矩阵尺寸下也能实现加速。该算法通过结合 Machine Learning-based search 方法和 Combinatorial Optimization 技术被发现。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "68Q25, 68T20",
        "F.2.1; I.1.2"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09814v1",
      "published_date": "2025-05-14 21:31:44 UTC",
      "updated_date": "2025-05-14 21:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:18:44.439968"
    },
    {
      "arxiv_id": "2505.09807v1",
      "title": "Exploring the generalization of LLM truth directions on conversational formats",
      "title_zh": "探索 LLM 真相方向在对话格式上的泛化",
      "authors": [
        "Timour Ichmoukhamedov",
        "David Martens"
      ],
      "abstract": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)中 truth direction（即模型激活空间中真假语句的线性可分性）在不同对话格式间的泛化能力。实验发现，truth direction 在以谎言结束的短对话间泛化良好，但在谎言较早出现的长对话中泛化较差。作者提出一种解决方案，通过在对话末尾添加固定关键短语，显著提升了这种泛化效果。结果强调了开发可靠的 LLM 谎言检测器（lie detectors）面临的挑战，推动了模型在真实对话场景中的可信度提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09807v1",
      "published_date": "2025-05-14 21:21:08 UTC",
      "updated_date": "2025-05-14 21:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:18:57.077481"
    },
    {
      "arxiv_id": "2505.09805v1",
      "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models",
      "title_zh": "使用大型语言模型对儿科败血症队列进行上下文相关的表型分析",
      "authors": [
        "Aditya Nagori",
        "Ayush Gautam",
        "Matthew O. Wiens",
        "Vuong Nguyen",
        "Nathan Kenya Mugisha",
        "Jerome Kabakyenga",
        "Niranjan Kissoon",
        "John Mark Ansermino",
        "Rishikesan Kamaleswaran"
      ],
      "abstract": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings.",
      "tldr_zh": "本文研究使用大型语言模型 (LLM) 对儿科败血症患者进行上下文表型学聚类，以识别个性化子群，并与传统方法比较。研究利用一个低收入国家 (LIC) 数据集（包含2,686条记录、28个数值变量和119个分类变量），将患者记录序列化为文本后，通过量化后的 LLAMA 3.1 8B、DeepSeek-R1-Distill-Llama-8B（带 LoRA）和 Stella-En-400M-V5 模型生成嵌入，并应用 K-means 聚类。结果显示，Stella-En-400M-V5 获得最高 Silhouette Score (0.86)，LLM 方法在高聚类数下优于经典 K-Medoids 聚类，能捕捉更丰富的上下文并识别出不同营养、临床和社会经济特征的子群。这些发现强调了 LLM 在资源有限环境中的潜力，用于提升医疗决策和患者护理效率。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "11 pages, 2 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2505.09805v1",
      "published_date": "2025-05-14 21:05:40 UTC",
      "updated_date": "2025-05-14 21:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:19:12.861547"
    },
    {
      "arxiv_id": "2505.09796v1",
      "title": "Virtual Dosimetrists: A Radiotherapy Training \"Flight Simulator\"",
      "title_zh": "虚拟剂量师：放射治疗训练的“飞行模拟器”",
      "authors": [
        "Skylar S. Gay",
        "Tucker Netherton",
        "Barbara Marquez",
        "Raymond Mumme",
        "Mary Gronberg",
        "Brent Parker",
        "Chelsea Pinnix",
        "Sanjay Shete",
        "Carlos Cardenas",
        "Laurence Court"
      ],
      "abstract": "Effective education in radiotherapy plan quality review requires a robust,\nregularly updated set of examples and the flexibility to demonstrate multiple\npossible planning approaches and their consequences. However, the current\nclinic-based paradigm does not support these needs. To address this, we have\ndeveloped 'Virtual Dosimetrist' models that can both generate training examples\nof suboptimal treatment plans and then allow trainees to improve the plan\nquality through simple natural language prompts, as if communicating with a\ndosimetrist. The dose generation and modification process is accurate, rapid,\nand requires only modest resources. This work is the first to combine dose\ndistribution prediction with natural language processing; providing a robust\npipeline for both generating suboptimal training plans and allowing trainees to\npractice their critical plan review and improvement skills that addresses the\nchallenges of the current clinic-based paradigm.",
      "tldr_zh": "该研究开发了“Virtual Dosimetrist”模型，作为放射治疗(radiotherapy)训练的“飞行模拟器”，以解决当前临床教育模式中缺乏稳健示例和灵活规划方法的问题。该模型能够生成 suboptimal 治疗计划的训练示例，并允许学员通过简单的自然语言提示(natural language processing)改进计划质量，就如同与计量师互动一样。该方法首次结合剂量分布预测(dose distribution prediction)和自然语言处理，提供了一个准确、快速且资源需求 modest 的管道，帮助学员练习关键的计划审查和优化技能，从而提升放射治疗教育效果。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09796v1",
      "published_date": "2025-05-14 20:47:13 UTC",
      "updated_date": "2025-05-14 20:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:19:21.135876"
    },
    {
      "arxiv_id": "2505.09794v1",
      "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques",
      "title_zh": "利用自然语言处理技术自动检测肺癌和乳腺癌报告中的临床实体",
      "authors": [
        "J. Moreno-Casanova",
        "J. M. Auñón",
        "A. Mártinez-Pérez",
        "M. E. Pérez-Martínez",
        "M. E. Gas-López"
      ],
      "abstract": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL.",
      "tldr_zh": "该研究针对肺癌和乳腺癌临床报告的手动信息提取问题，提出使用 Natural Language Processing (NLP) 技术实现自动化检测，以提高效率和准确性。研究利用 GMV 的 uQuery 工具进行实体识别和分类，将实体转换为标准化格式如 SNOMED 和 OMOP，同时结合 Named Entity Recognition (NER) 技术，通过微调基于 RoBERTa 的 bsc-bio-ehr-en3 模型来处理西班牙语 EHRs 数据集。实验基于 Health Research Institute Hospital La Fe 的 600 份标注报告，结果显示模型在识别 MET 和 PAT 等实体上表现出色，但对 EVOL 等较少见实体仍存在挑战。整体而言，此方法为癌症数据管理提供了更可靠的自动化解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09794v1",
      "published_date": "2025-05-14 20:44:29 UTC",
      "updated_date": "2025-05-14 20:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:19:35.040219"
    },
    {
      "arxiv_id": "2505.09787v1",
      "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation",
      "title_zh": "多模态多智能体放射学报告生成框架",
      "authors": [
        "Ziruo Yi",
        "Ting Xiao",
        "Mark V. Albert"
      ],
      "abstract": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications.",
      "tldr_zh": "该研究针对放射学报告生成（RRG）面临的挑战，如事实不一致、幻觉和跨模态不对齐，提出了一种多模态多智能体框架（Multimodal Multi-Agent Framework），该框架遵循逐步临床推理流程，包括专门的智能体负责检索、草稿生成、视觉分析、细化和合成。实验结果显示，该方法在自动指标和基于LLM的评估中优于强基线模型，生成更准确、结构化和可解释的报告。这种临床对齐的多智能体框架突显了其在支持可解释和可信赖的临床AI应用方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09787v1",
      "published_date": "2025-05-14 20:28:04 UTC",
      "updated_date": "2025-05-14 20:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:19:48.366927"
    },
    {
      "arxiv_id": "2505.09766v1",
      "title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion",
      "title_zh": "关于通过基尔霍夫-亥姆霍兹方程重建格林函数的良定性，用于单速中子扩散",
      "authors": [
        "Roberto Ponciroli"
      ],
      "abstract": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions.",
      "tldr_zh": "本研究探讨了通过Kirchhoff-Helmholtz (K-H) 方程重建一速中子扩散(One-Speed Neutron Diffusion)模型中Green's function的良定性(well-posedness)，以基于ex-core探测器的实时测量数据重建核反应堆中子通量的空间分布。论文从一速中子扩散模型推导出K-H方程，并将其表述为一个逆问题(inverse problem)，通过数值方法逼近Green's function，同时建立其对称性属性。最终，研究证明了从采样数据推断Green's function的存在性和唯一性，确保了该方法在复杂异构域中的可靠性和预测准确性。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09766v1",
      "published_date": "2025-05-14 19:53:09 UTC",
      "updated_date": "2025-05-14 19:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:19:59.761334"
    },
    {
      "arxiv_id": "2505.09757v1",
      "title": "Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents",
      "title_zh": "无信任自治：理解自主去中心化 AI 代理中的动机、益处和治理困境",
      "authors": [
        "Botao Amber Hu",
        "Yuhan Liu",
        "Helena Rong"
      ],
      "abstract": "The recent trend of self-sovereign Decentralized AI Agents (DeAgents)\ncombines Large Language Model (LLM)-based AI agents with decentralization\ntechnologies such as blockchain smart contracts and trusted execution\nenvironments (TEEs). These tamper-resistant trustless substrates allow agents\nto achieve self-sovereignty through ownership of cryptowallet private keys and\ncontrol of digital assets and social media accounts. DeAgent eliminates\ncentralized control and reduces human intervention, addressing key trust\nconcerns inherent in centralized AI systems. However, given ongoing challenges\nin LLM reliability such as hallucinations, this creates paradoxical tension\nbetween trustlessness and unreliable autonomy. This study addresses this\nempirical research gap through interviews with DeAgents stakeholders-experts,\nfounders, and developers-to examine their motivations, benefits, and governance\ndilemmas. The findings will guide future DeAgents system and protocol design\nand inform discussions about governance in sociotechnical AI systems in the\nfuture agentic web.",
      "tldr_zh": "本研究探讨了自主 Decentralized AI Agents (DeAgents)，即将 Large Language Model (LLM) 与区块链智能合约和 trusted execution environments (TEEs) 相结合的系统，这些代理通过控制加密钱包和数字资产实现自主性，从而消除集中控制并减少人为干预，解决集中式 AI 的信任问题。研究通过对 DeAgents 利益相关者（如专家、创始人和发展者）的访谈，分析了其动机、益处以及治理困境，特别是 LLM 可靠性问题（如 hallucinations）导致的信任缺失与不可靠自治的矛盾。结果为未来 DeAgents 系统和协议设计提供指导，并促进代理网络中 AI 治理的讨论。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to CSCW 2026",
      "pdf_url": "http://arxiv.org/pdf/2505.09757v1",
      "published_date": "2025-05-14 19:42:43 UTC",
      "updated_date": "2025-05-14 19:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:20:11.639844"
    },
    {
      "arxiv_id": "2505.09755v1",
      "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection",
      "title_zh": "通过以人为中心设计实现 XAI 在肺癌检测中的可解释性",
      "authors": [
        "Amy Rafferty",
        "Rishi Ramaesh",
        "Ajitha Rajan"
      ],
      "abstract": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics.",
      "tldr_zh": "本研究提出XpertXAI，一种基于人类中心设计的专家驱动概念瓶颈模型(CBM)，旨在提升肺癌检测的可解释性，同时扩展到多种肺部病变识别。XpertXAI利用InceptionV3分类器和公共胸部X光数据集，与现有后验解释方法和无监督CBM(XCBs)进行比较，通过专家放射科医生注释评估解释质量。结果显示，XpertXAI在预测准确性上优于基线模型，并提供更符合临床概念的解释，与专家判断更一致，为可扩展的医疗诊断可解释AI(XAI)提供可行路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09755v1",
      "published_date": "2025-05-14 19:40:12 UTC",
      "updated_date": "2025-05-14 19:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:20:24.878430"
    },
    {
      "arxiv_id": "2505.09747v1",
      "title": "Healthy Distrust in AI systems",
      "title_zh": "对 AI 系统的健康不信任",
      "authors": [
        "Benjamin Paaßen",
        "Suzana Alpsancar",
        "Tobias Matzner",
        "Ingrid Scharlau"
      ],
      "abstract": "Under the slogan of trustworthy AI, much of contemporary AI research is\nfocused on designing AI systems and usage practices that inspire human trust\nand, thus, enhance adoption of AI systems. However, a person affected by an AI\nsystem may not be convinced by AI system design alone -- neither should they,\nif the AI system is embedded in a social context that gives good reason to\nbelieve that it is used in tension with a person's interest. In such cases,\ndistrust in the system may be justified and necessary to build meaningful trust\nin the first place. We propose the term \"healthy distrust\" to describe such a\njustified, careful stance towards certain AI usage practices. We investigate\nprior notions of trust and distrust in computer science, sociology, history,\npsychology, and philosophy, outline a remaining gap that healthy distrust might\nfill and conceptualize healthy distrust as a crucial part for AI usage that\nrespects human autonomy.",
      "tldr_zh": "这篇论文探讨了在“trustworthy AI”框架下，AI 研究往往专注于设计激发人类信任的系统和实践，以促进 AI 采用，但这可能不足以说服受影响者，尤其是在 AI 被用于与个人利益相冲突的社会环境中。作者提出“healthy distrust”概念，指的是对某些 AI 使用实践的正当、谨慎态度，这种不信任有助于构建真正的信任。论文通过调查计算机科学、社会学、历史、心理学和哲学领域的信任与不信任概念，识别了现有研究的空白，并将 healthy distrust 概念化为尊重人类自治的 AI 使用实践的重要组成部分。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09747v1",
      "published_date": "2025-05-14 19:13:47 UTC",
      "updated_date": "2025-05-14 19:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:20:36.322779"
    },
    {
      "arxiv_id": "2505.09742v1",
      "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization",
      "title_zh": "一种用于黑箱组合优化的生成式神经退火器",
      "authors": [
        "Yuan-Hang Zhang",
        "Massimiliano Di Ventra"
      ],
      "abstract": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers.",
      "tldr_zh": "该研究提出了一种生成式神经退火器（Generative Neural Annealer），用于解决黑箱组合优化（Black-Box Combinatorial Optimization）问题，强调样本效率和解决方案质量。方法将黑箱目标视为能量函数，通过训练神经网络建模 Boltzmann 分布，并利用温度条件化捕捉从均匀分布到全局最优尖峰分布的连续体，从而学习能量景观结构并促进全局优化。在查询昂贵时，该模型通过温度依赖分布实现数据增强提升样本效率，而在查询廉价但问题复杂时，能学习隐式变量交互。实验结果显示，该方法在有限和无限查询预算下的挑战性组合任务中，与最先进黑箱优化器相比表现出色。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09742v1",
      "published_date": "2025-05-14 19:05:19 UTC",
      "updated_date": "2025-05-14 19:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:20:47.829210"
    },
    {
      "arxiv_id": "2505.09738v1",
      "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning",
      "title_zh": "通过启发式适应和超标记学习实现语言模型中的分词器灵活性",
      "authors": [
        "Shaurya Sharthak",
        "Vinayak Pahalwan",
        "Adithya Kamath",
        "Adarsh Shirawalmath"
      ],
      "abstract": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores.",
      "tldr_zh": "这篇论文解决了预训练语言模型（LLMs）的固定分词方案问题，通过提出 Tokenadapt 和 Supertokens 两种创新方法来提升分词器灵活性。Tokenadapt 是一种模型无关的分词器移植技术，使用混合启发式初始化（结合子词分解的局部估计和语义相似顶-k 标记的全局估计），以保留语义并显著减少重新训练需求。Supertokens 通过预分词学习处理多词标记，实现更好的压缩和碎片减少；实验结果显示，Tokenadapt 在零-shot 困惑度测试中比基线如 ReTok 和 TransTokenizer 至少改善 2 倍性能，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09738v1",
      "published_date": "2025-05-14 19:00:27 UTC",
      "updated_date": "2025-05-14 19:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:21:01.439451"
    },
    {
      "arxiv_id": "2505.09737v1",
      "title": "General Dynamic Goal Recognition",
      "title_zh": "一般动态目标识别",
      "authors": [
        "Osher Elhadad",
        "Reuth Mirsky"
      ],
      "abstract": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks.",
      "tldr_zh": "该论文探讨了在动态环境中通过代理行为理解其意图（Goal Recognition，GR）的挑战，强调了其在人机交互、交互式AI系统和多代理协作中的重要性，因为传统GR方法难以适应众多且不断演变的目標。论文引入了General Dynamic GR问题，这是一个更广泛的定义，旨在支持实时GR系统并推动相关研究。作者采用model-free goal-conditioned RL方法，实现GR在各种变化任务中的快速适应。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops",
      "pdf_url": "http://arxiv.org/pdf/2505.09737v1",
      "published_date": "2025-05-14 18:57:51 UTC",
      "updated_date": "2025-05-14 18:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:21:10.704213"
    },
    {
      "arxiv_id": "2505.09733v1",
      "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data",
      "title_zh": "鲁棒联邦学习：利用置信度加权过滤和基于GAN的补全处理噪声和不完整数据",
      "authors": [
        "Alpaslan Gokcen",
        "Ali Boyaci"
      ],
      "abstract": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios.",
      "tldr_zh": "本研究提出了一种稳健的联邦学习（Federated Learning, FL）框架，针对嘈杂标签（noisy labels）、缺失类别和类别不平衡等问题，通过自适应噪声清理（adaptive noise cleaning）、协作条件GAN-based合成数据生成以及置信权重过滤（Confidence-Weighted Filtering）来提升数据完整性和模型训练效果。实验在MNIST和Fashion-MNIST基准数据集上进行，展示了显著性能提升，特别是macro-F1 Score在不同噪声和不平衡条件下得到改善。该框架兼顾计算可行性，适用于资源受限的边缘设备，同时严格维护数据隐私，提供了一个可扩展且实用的FL解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09733v1",
      "published_date": "2025-05-14 18:49:18 UTC",
      "updated_date": "2025-05-14 18:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:21:24.876147"
    },
    {
      "arxiv_id": "2505.09724v1",
      "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs",
      "title_zh": "一个AI驱动的实验室研究助理：通过与LLMs的迭代协作进行文本分析的实用指南",
      "authors": [
        "Gino Carmona-Díaz",
        "William Jiménez-Leal",
        "María Alejandra Grisales",
        "Chandra Sripada",
        "Santiago Amaya",
        "Michael Inzlicht",
        "Juan Pablo Bermúdez"
      ],
      "abstract": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis.",
      "tldr_zh": "这篇论文提供了一个实用指南，介绍如何使用大型语言模型 (LLMs) 作为研究助手，通过迭代协作过程进行文本分析，以减少时间消耗和偏见问题。指南包括逐步教程：编写提示来审查数据集、生成 top-down 或 bottom-up 分类法、评估和完善分类、测试分类并评估 intercoder agreements，最后应用分类到整个数据集。研究以参与者个人目标为例，展示了高效分类文本数据的可行性，并讨论了 LLMs 在文本分析中的可能性和局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.09724v1",
      "published_date": "2025-05-14 18:32:18 UTC",
      "updated_date": "2025-05-14 18:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:21:35.652502"
    },
    {
      "arxiv_id": "2505.09716v1",
      "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks",
      "title_zh": "分布外泛化很难：来自 ARC-like 任务的证据",
      "authors": [
        "George Dimitriadis. Spyridon Samothrakis"
      ],
      "abstract": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation.",
      "tldr_zh": "本研究探讨了Out-of-distribution (OOD) 一般化的难度，通过ARC-like任务作为证据，强调OOD需要系统发现环境不变的输入-输出映射属性，并实现任务不变的可组合特征。作者测试了三个常用神经网络（Multi-Layer Perceptron (MLP)、Convolutional Neural Network (CNN)和Transformer），发现它们在两个明确定义的OOD任务上无法成功解决。论文贡献了两个新型网络架构，这些架构带有特定偏差，能在OOD场景中实现近乎完美的性能，但仍可能未能学习正确的组合特征，从而质疑了OOD测试的充分性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submission to NeurIPS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09716v1",
      "published_date": "2025-05-14 18:21:21 UTC",
      "updated_date": "2025-05-14 18:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:21:50.084594"
    },
    {
      "arxiv_id": "2505.09704v1",
      "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods",
      "title_zh": "能量高效的联邦学习，用于AIoT的聚类方法",
      "authors": [
        "Roberto Pereira",
        "Fernanda Famá",
        "Charalampos Kalalas",
        "Paolo Dini"
      ],
      "abstract": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature.",
      "tldr_zh": "本研究关注联邦学习（FL）在人工智能物联网（AIoT）场景中的能源效率问题，考察了预处理、通信和本地学习等能源密集过程，并指出设备选择对模型训练收敛至关重要。作者提出两种基于聚类（Clustering）的方法，将AIoT设备按标签分布相似性分组，形成相对同质的集群，从而缓解真实分布式学习中的异质性问题。通过广泛的数值实验，证明这些策略在保持低能源消耗的同时，实现了比现有方法更高的收敛率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09704v1",
      "published_date": "2025-05-14 18:04:58 UTC",
      "updated_date": "2025-05-14 18:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:22:00.294129"
    },
    {
      "arxiv_id": "2505.09698v1",
      "title": "ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation",
      "title_zh": "ManipBench：用于低级机器人操作的视觉-语言模型基准测试",
      "authors": [
        "Enyu Zhao",
        "Vedant Raval",
        "Hejia Zhang",
        "Jiageng Mao",
        "Zeyu Shangguan",
        "Stefanos Nikolaidis",
        "Yue Wang",
        "Daniel Seita"
      ],
      "abstract": "Vision-Language Models (VLMs) have revolutionized artificial intelligence and\nrobotics due to their commonsense reasoning capabilities. In robotic\nmanipulation, VLMs are used primarily as high-level planners, but recent work\nhas also studied their lower-level reasoning ability, which refers to making\ndecisions about precise robot movements. However, the community currently lacks\na clear and common benchmark that can evaluate how well VLMs can aid low-level\nreasoning in robotics. Consequently, we propose a novel benchmark, ManipBench,\nto evaluate the low-level robot manipulation reasoning capabilities of VLMs\nacross various dimensions, including how well they understand object-object\ninteractions and deformable object manipulation. We extensively test 33\nrepresentative VLMs across 10 model families on our benchmark, including\nvariants to test different model sizes. Our evaluation shows that the\nperformance of VLMs significantly varies across tasks, and there is a strong\ncorrelation between this performance and trends in our real-world manipulation\ntasks. It also shows that there remains a significant gap between these models\nand human-level understanding. See our website at:\nhttps://manipbench.github.io.",
      "tldr_zh": "该论文提出ManipBench，一种新型基准，用于评估Vision-Language Models (VLMs)在低层机器人操作中的推理能力，包括物体-物体互动和可变形物体操作等方面。研究者测试了33个代表性VLMs（来自10个模型家族，包括不同规模变体），结果显示这些模型在不同任务上的性能差异显著，并与真实世界操作任务高度相关。总体而言，VLMs的表现仍远低于人类水平，凸显了其在精确机器人决策方面的改进潜力。更多细节可查看网站：https://manipbench.github.io。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "47 pages, 29 figures. Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.09698v1",
      "published_date": "2025-05-14 18:01:00 UTC",
      "updated_date": "2025-05-14 18:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:22:11.812408"
    },
    {
      "arxiv_id": "2505.09614v1",
      "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
      "title_zh": "语言代理镜像人类的因果推理偏差：我们如何帮助它们像科学家一样思考？",
      "authors": [
        "Anthony GX-Chen",
        "Dongyan Lin",
        "Mandana Samiei",
        "Doina Precup",
        "Blake A. Richards",
        "Rob Fergus",
        "Kenneth Marino"
      ],
      "abstract": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.",
      "tldr_zh": "该研究评估了语言模型（LMs）代理在因果关系探索和推断方面的能力，发现LMs能够可靠地识别常见的直觉性析取因果关系，但系统性地出现“disjunctive bias”，即在不常见的合取因果关系上表现较差，这种偏差在不同模型家族、大小和提示策略中均存在，并随任务复杂度增加而加剧。研究通过“Blicket Test”范式比较了LMs与人类（尤其是成人）的推理模式，结果显示LMs继承了人类深层推理启发式，但更接近成人而非儿童的推理特征。为减少这一偏差，研究提出了一种可扩展的测试时采样方法，该方法通过从LMs中采样并消除因果关系假设，帮助LMs实现更科学的、因果严谨的推理。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09614v1",
      "published_date": "2025-05-14 17:59:35 UTC",
      "updated_date": "2025-05-14 17:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:22:24.850369"
    },
    {
      "arxiv_id": "2505.09610v1",
      "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors",
      "title_zh": "针对高性能微处理器 VHDL 设计的自定义大语言模型",
      "authors": [
        "Nicolas Dupuis",
        "Ravi Nair",
        "Shyam Ramji",
        "Sean McClintock",
        "Nishant Chauhan",
        "Priyanka Nagpal",
        "Bart Blaner",
        "Ken Valk",
        "Leon Stok",
        "Ruchir Puri"
      ],
      "abstract": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world.",
      "tldr_zh": "该论文探讨了针对高性能微处理器设计定制大型语言模型（LLMs）的过程，重点关注VHDL代码解释，以满足行业特定需求。研究团队开发了定制测试集，并通过扩展预训练（EPT）对基线LLM进行优化，结果显示EPT模型的代码解释质量由43%提升至69%。此外，他们创建了LLM-as-a-judge机制来模拟专家评估，并衍生出指令调整版本的新模型，预计评分可达71%，甚至通过新基线模型进一步提高至85%以上。最终，论文讨论了利用生成式AI的最新进展来提升硬件设计LLMs质量的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09610v1",
      "published_date": "2025-05-14 17:58:40 UTC",
      "updated_date": "2025-05-14 17:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:22:37.128927"
    },
    {
      "arxiv_id": "2505.09598v1",
      "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference",
      "title_zh": "AI有多饥饿？ 基准测试LLM推理的能源、水和碳足迹",
      "authors": [
        "Nidhal Jegham",
        "Marwen Abdelatti",
        "Lassad Elmoubarki",
        "Abdeltawab Hendawi"
      ],
      "abstract": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在推理阶段的环境足迹，包括能源、水资源和碳排放，填补了现有研究的空白，如忽略专有模型和基础设施差异。研究引入了一个基础设施感知基准框架，利用公共 API 数据、区域环境乘数和硬件配置统计，并采用交叉效率数据包络分析 (DEA) 来排名 30 个最先进模型的性能与环境成本。结果显示，o3 和 DeepSeek-R1 是最耗能模型，每处理一个长提示消耗超过 33 Wh，是 GPT-4.1 nano 的 70 倍，而 Claude-3.7 Sonnet 在生态效率上排名最高；此外，一个短 GPT-4o 查询虽仅耗 0.43 Wh，但每天 7 亿查询将导致相当于 35,000 美国家庭的电力使用和巨大碳排放。这些发现揭示了 LLMs 规模化部署的资源消耗悖论，并为 AI 开发提供标准化可持续性基准方法。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09598v1",
      "published_date": "2025-05-14 17:47:00 UTC",
      "updated_date": "2025-05-14 17:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:22:48.806545"
    },
    {
      "arxiv_id": "2505.09595v1",
      "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models",
      "title_zh": "WorldView-Bench：用于评估大语言模型中全球文化视角的基准",
      "authors": [
        "Abdullah Mushtaq",
        "Imran Taj",
        "Rafay Naeem",
        "Ibrahim Ghaznavi",
        "Junaid Qadir"
      ],
      "abstract": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems.",
      "tldr_zh": "本研究指出，大型语言模型 (LLMs) 因过度强化西方中心主义而导致文化同质化，因此引入 WorldView-Bench 基准，用于评估 LLMs 的全球文化包容性 (GCI)，通过分析模型对多元世界观的适应性来测量 Cultural Polarization。基准基于 Multiplex Worldview 理论，采用自由形式生成评估，并实施两种干预策略：Contextually-Implemented Multiplex LLMs（通过系统提示嵌入多重性原则）和 Multi-Agent System (MAS)-Implemented Multiplex LLMs（多个代表不同文化视角的 LLM 代理协作生成响应）。实验结果显示，Perspectives Distribution Score (PDS) 熵从基线的 13% 显著提升至 94%，并实现了积极情感占比 67.7% 和更好的文化平衡，从而为缓解 LLMs 中的文化偏见并推动更具包容性的 AI 系统提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09595v1",
      "published_date": "2025-05-14 17:43:40 UTC",
      "updated_date": "2025-05-14 17:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:23:01.925892"
    },
    {
      "arxiv_id": "2505.09593v1",
      "title": "Online Isolation Forest",
      "title_zh": "在线 Isolation Forest",
      "authors": [
        "Filippo Leveni",
        "Guilherme Weigert Cassales",
        "Bernhard Pfahringer",
        "Albert Bifet",
        "Giacomo Boracchi"
      ],
      "abstract": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection.",
      "tldr_zh": "现有异常检测方法多为离线模式，需要反复访问数据，且在流式环境中不实用，而现有在线方法往往依赖定期重训。研究提出Online-iForest，一种专为流式条件设计的新方法，能够无缝跟踪数据生成过程的变化。实验在真实数据集上显示，Online-iForest的性能与在线备选方法相当，并接近最先进的离线技术，同时在效率上显著优于所有竞争对手。总之，该方法适用于需要快速识别异常的领域，如cybersecurity、fraud和fault detection。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at International Conference on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2505.09593v1",
      "published_date": "2025-05-14 17:42:50 UTC",
      "updated_date": "2025-05-14 17:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:23:12.305003"
    },
    {
      "arxiv_id": "2505.09591v1",
      "title": "Variational Visual Question Answering",
      "title_zh": "变分视觉问答",
      "authors": [
        "Tobias Jan Wieczorek",
        "Nathalie Daun",
        "Mohammad Emtiyaz Khan",
        "Marcus Rohrbach"
      ],
      "abstract": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models.",
      "tldr_zh": "该研究针对 Visual Question Answering (VQA) 模型在分布外 (OOD) 设置中存在的过度自信和校准不当问题，提出了一种 Variational VQA 方法，使用 IVON 算法代替传统的 AdamW 进行微调，从而获得模型参数的后验分布。实验结果显示，这种方法在不降低准确性的情况下，显著改善了模型的校准性能，例如将 Expected Calibration Error 减少超过 50%，并将 Coverage 提高 4%（在固定风险为 1% 时）。此外，在分布偏移场景下，该方法的效果更突出，提升了 8% 的 Coverage（在 50% 测试案例为 OOD 时），为提升多模态模型的可靠性和鲁棒性提供了有效途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 16 figures, under review at ICCV 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09591v1",
      "published_date": "2025-05-14 17:40:22 UTC",
      "updated_date": "2025-05-14 17:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:23:25.287794"
    },
    {
      "arxiv_id": "2505.09576v1",
      "title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach",
      "title_zh": "基于人类反馈的强化学习中的伦理与说服：程序性修辞方法",
      "authors": [
        "Shannon Lodoen",
        "Alexi Orchard"
      ],
      "abstract": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots.",
      "tldr_zh": "这篇论文探讨了Reinforcement Learning from Human Feedback (RLHF) 在训练大型语言模型 (LLMs) 如 ChatGPT 和 Claude 中的伦理与说服问题，强调其使 AI 输出更“人性化”但也引发透明性、偏见和人际关系等方面的潜在风险。作者采用 Ian Bogost 的 procedural rhetoric 概念，将分析焦点从生成内容转移到 RLHF 的底层机制，包括语言规范、信息求取实践和社会关系期望。研究发现，这些机制可能强化霸权语言使用、延续偏见、去上下文化学习并侵蚀人类关系，从而为 AI 伦理、教育和研究领域提供新的探究方向。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 1 figure, Accepted version",
      "pdf_url": "http://arxiv.org/pdf/2505.09576v1",
      "published_date": "2025-05-14 17:29:19 UTC",
      "updated_date": "2025-05-14 17:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:23:36.508445"
    },
    {
      "arxiv_id": "2505.09568v1",
      "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset",
      "title_zh": "BLIP3-o：一个完全开源的统一多模态模型家族——架构、训练和数据集",
      "authors": [
        "Jiuhai Chen",
        "Zhiyang Xu",
        "Xichen Pan",
        "Yushi Hu",
        "Can Qin",
        "Tom Goldstein",
        "Lifu Huang",
        "Tianyi Zhou",
        "Saining Xie",
        "Silvio Savarese",
        "Le Xue",
        "Caiming Xiong",
        "Ran Xu"
      ],
      "abstract": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets.",
      "tldr_zh": "本研究探讨了统一图像理解和生成的 multimodal 模型，提出了一种新型架构和训练策略，以 autoregressive 和 diffusion 模型为基础。创新点包括使用 diffusion transformer 生成语义丰富的 CLIP 图像特征，取代传统的 VAE-based 表示，从而提升训练效率和生成质量；同时采用顺序预训练策略，先优化图像理解再发展图像生成，以保留理解能力。研究者构建了高质量指令微调数据集 BLIP3o-60k，并开发了 BLIP3-o 系列模型，在多项图像理解和生成基准测试中表现出色；所有模型、代码、权重和数据集均完全开源，促进未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09568v1",
      "published_date": "2025-05-14 17:11:07 UTC",
      "updated_date": "2025-05-14 17:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:23:49.954657"
    },
    {
      "arxiv_id": "2505.09565v1",
      "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations",
      "title_zh": "使用隐式神经表示的元学习在胎儿大脑 MRI 中的切片到体积重建",
      "authors": [
        "Maik Dannecker",
        "Thomas Sanchez",
        "Meritxell Bach Cuadra",
        "Özgün Turgut",
        "Anthony N. Price",
        "Lucilio Cordero-Grande",
        "Vanessa Kyriakopoulou",
        "Joseph V. Hajnal",
        "Daniel Rueckert"
      ],
      "abstract": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time.",
      "tldr_zh": "本研究提出了一种基于隐式神经表示（Implicit Neural Representations）的切片到体积重建（SVR）方法，用于胎儿脑部 MRI 图像处理，能够处理严重运动伪影和图像失真问题。该方法整合了运动校正、异常值处理和超分辨率重建，所有操作均依赖于隐式神经表示，并通过完全自监督的元学习（Meta-learning）在模拟或真实数据上初始化模型，以获得任务特定先验。在超过480个模拟和临床MRI脑部数据的实验中，该方法显著提高了重建质量，尤其在严重运动情况下比现有方法表现更好，并将重建时间减少高达50%。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09565v1",
      "published_date": "2025-05-14 17:07:37 UTC",
      "updated_date": "2025-05-14 17:07:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:24:01.485656"
    },
    {
      "arxiv_id": "2505.09561v1",
      "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction",
      "title_zh": "通过过去标记预测学习长上下文扩散策略",
      "authors": [
        "Marcel Torne",
        "Andy Tang",
        "Yuejiang Liu",
        "Chelsea Finn"
      ],
      "abstract": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x.",
      "tldr_zh": "本文提出 Past-Token Prediction (PTP) 方法，用于学习长上下文扩散策略 (diffusion policies)，以解决机器人任务中处理长序列观察和动作时的训练成本高和性能下降问题。PTP 作为辅助任务，让策略同时预测过去和未来的动作标记，并结合多阶段训练策略（如预训练视觉编码器并使用缓存长上下文微调策略头），显著改善了时间建模并减少了计算开销。此外，该方法在四个真实世界和六个模拟任务上的实验显示，策略性能提升 3 倍，训练速度加快超过 10 倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Videos are available at https://long-context-dp.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.09561v1",
      "published_date": "2025-05-14 17:00:47 UTC",
      "updated_date": "2025-05-14 17:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:24:14.217415"
    },
    {
      "arxiv_id": "2505.09558v1",
      "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators",
      "title_zh": "WavReward：通用奖励评估器的语音对话模型",
      "authors": [
        "Shengpeng Ji",
        "Tianle Liang",
        "Yangzhuo Li",
        "Jialong Zuo",
        "Minghui Fang",
        "Jinzheng He",
        "Yifu Chen",
        "Zhengqing Liu",
        "Ziyue Jiang",
        "Xize Cheng",
        "Siqi Zheng",
        "Jin Xu",
        "Junyang Lin",
        "Zhou Zhao"
      ],
      "abstract": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted.",
      "tldr_zh": "该研究提出 WavReward，一种基于音频语言模型的通用奖励评估器，用于评估语音对话模型的 IQ 和 EQ，解决现有模型难以处理非文本信息的评估难题。WavReward 通过深度推理过程、非线性奖励机制和强化学习算法的多样本反馈进行后训练，并引入 ChatReward-30K 数据集，该数据集涵盖文本聊天、指令聊天和隐式聊天等多种场景。实验结果显示，WavReward 在客观准确率上比 Qwen2.5-Omni 提升至 91.5%（从 55.1%），主观 A/B 测试中领先 83%。这项工作为语音对话系统的可靠评估提供了新框架，并计划公开相关数据和代码。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09558v1",
      "published_date": "2025-05-14 16:54:15 UTC",
      "updated_date": "2025-05-14 16:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:24:26.569430"
    },
    {
      "arxiv_id": "2505.09666v1",
      "title": "System Prompt Optimization with Meta-Learning",
      "title_zh": "系统提示优化与元学习",
      "authors": [
        "Yumin Choi",
        "Jinheon Baek",
        "Sung Ju Hwang"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance.",
      "tldr_zh": "本文提出了一种基于元学习(meta-learning)的框架，用于解决大型语言模型(LLMs)的双层系统提示优化(bilevel system prompt optimization)问题，旨在设计对多样用户提示鲁棒且可转移到未见任务的系统提示。框架通过在多个数据集上优化系统提示，同时迭代更新用户提示，以确保两者协同作用。实验在14个跨越5个领域的未见数据集上验证了该方法的有效性，优化后的系统提示实现了更好的泛化性能，并能快速适应新任务，减少优化步骤并提升整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09666v1",
      "published_date": "2025-05-14 16:46:15 UTC",
      "updated_date": "2025-05-14 16:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:24:37.986428"
    },
    {
      "arxiv_id": "2505.09518v1",
      "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs",
      "title_zh": "rfPG：针对隐藏模型 POMDPs 的稳健有限记忆策略梯度",
      "authors": [
        "Maris F. L. Galesloot",
        "Roman Andriushchenko",
        "Milan Češka",
        "Sebastian Junges",
        "Nils Jansen"
      ],
      "abstract": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments.",
      "tldr_zh": "这篇论文提出了 rfPG，一种鲁棒有限记忆策略梯度方法，用于处理隐模型 POMDPs (HM-POMDPs)，这些模型捕捉一组共享动作和观测空间的不同环境，以应对 POMDPs 在不确定性顺序决策中的鲁棒性问题。方法结合形式验证技术（计算 HM-POMDP 中的最坏情况 POMDP）和子梯度上升优化，来生成针对多个潜在环境的鲁棒策略。实验结果表明，与基线相比，rfPG 生成的策略更具鲁棒性，能够更好地泛化到未见 POMDPs，并扩展到包含超过十万个环境的规模。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09518v1",
      "published_date": "2025-05-14 16:15:58 UTC",
      "updated_date": "2025-05-14 16:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:24:51.382978"
    },
    {
      "arxiv_id": "2505.09498v1",
      "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput",
      "title_zh": "Flash-VL 2B：优化视觉语言模型性能以实现超低延迟和高吞吐量",
      "authors": [
        "Bo Zhang",
        "Shuo Li",
        "Runhe Tian",
        "Yang Yang",
        "Jixin Tang",
        "Jinhao Zhou",
        "Lin Ma"
      ],
      "abstract": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications.",
      "tldr_zh": "本研究引入了 Flash-VL 2B，一种针对视觉语言模型 (VLMs) 的优化方法，旨在实现超低延迟和高吞吐量，同时保持准确性。关键策略包括架构增强、令牌压缩机制、数据整理、专用训练方案以及新型图像处理技术 implicit semantic stitching，以有效平衡计算负载和性能。通过在 11 个标准 VLM 基准上的评估，Flash-VL 2B 实现了最先进的速度和准确性结果，适合资源受限环境和大规模实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09498v1",
      "published_date": "2025-05-14 15:45:17 UTC",
      "updated_date": "2025-05-14 15:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:25:00.988862"
    },
    {
      "arxiv_id": "2505.09486v1",
      "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection",
      "title_zh": "在持续学习中通过自适应线性注入保留可塑性",
      "authors": [
        "Seyed Roozbeh Razavi Rohani",
        "Khashayar Khajavi",
        "Wesley Chung",
        "Mo Chen",
        "Sharan Vaswani"
      ],
      "abstract": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity.",
      "tldr_zh": "本研究针对深度神经网络在持续学习中逐渐丧失可塑性的问题，提出了一种名为AdaLin的通用方法，通过动态适应每个神经元的激活函数来缓解这一问题。AdaLin利用可学习的参数和门控机制，根据梯度流注入线性性，确保足够的梯度信号而无需额外超参数或明确任务边界。实验结果显示，在标准基准如Random Label和Permuted MNIST、CIFAR-10以及类增量学习上的CIFAR-100中使用ReLU、Tanh或GeLU激活函数时，AdaLin显著提升了性能，并在强化学习场景中证明了其有效性；消融实验进一步证实，神经元级别的适应是关键因素，并分析了与可塑性损失相关的网络指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09486v1",
      "published_date": "2025-05-14 15:36:51 UTC",
      "updated_date": "2025-05-14 15:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:25:14.091530"
    },
    {
      "arxiv_id": "2505.09477v1",
      "title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities",
      "title_zh": "在实地部署基于基础模型的空中和地面机器人：挑战和机会",
      "authors": [
        "Zachary Ravichandran",
        "Fernando Cladera",
        "Jason Hughes",
        "Varun Murali",
        "M. Ani Hsieh",
        "George J. Pappas",
        "Camillo J. Taylor",
        "Vijay Kumar"
      ],
      "abstract": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research.",
      "tldr_zh": "这篇论文探讨了在野外环境中部署基础模型(FMs)启用空地机器人的挑战和机会，包括机器人需处理大规模非结构化环境中的主动探索、障碍导航、意外传感器输入以及计算约束。\n作者介绍了SPINE框架，这是一个LLM-enabled自治系统，并在实际部署中实现了首次大规模机器人规划，涵盖数公里任务。\n通过模型蒸馏技术，论文开发了首个使用on-device语言模型的UAV规划器，并提出未来研究方向，如进一步优化FM在机器人应用中的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the IEEE ICRA Workshop on Field Robotics 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09477v1",
      "published_date": "2025-05-14 15:28:43 UTC",
      "updated_date": "2025-05-14 15:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:25:25.517587"
    },
    {
      "arxiv_id": "2505.09466v1",
      "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers",
      "title_zh": "一种二维语义感知位置编码，针对视觉变压器",
      "authors": [
        "Xi Chen",
        "Shiyang Zhou",
        "Muqi Huang",
        "Jiaxu Feng",
        "Yun Xiong",
        "Kun Zhou",
        "Biao Yang",
        "Yuhui Zhang",
        "Huishuai Bao",
        "Sijia Peng",
        "Chuan Li",
        "Feng Shi"
      ],
      "abstract": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks.",
      "tldr_zh": "该论文指出，现有的位置编码（Position Encoding）方法在Vision Transformers中无法有效捕捉图像patches之间的语义感知位置关系，导致模型泛化能力差、翻译等变性（Translation Equivariance）不足，以及处理重复或结构化模式的效果不佳。作者提出了一种新方法——2D Semantic-Aware Position Encoding（SaPE²），它通过利用本地内容动态适应位置表示，而不是依赖固定线性关系或空间坐标。SaPE²增强了模型在不同图像分辨率和规模下的泛化能力，并更好地聚合视觉上相似但空间上遥远的patches，最终提高了Vision Transformers在计算机视觉任务中的整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.09466v1",
      "published_date": "2025-05-14 15:17:34 UTC",
      "updated_date": "2025-05-14 15:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:25:38.119956"
    },
    {
      "arxiv_id": "2505.09456v1",
      "title": "Quantum state-agnostic work extraction (almost) without dissipation",
      "title_zh": "量子状态无关的工作提取（几乎）没有耗散",
      "authors": [
        "Josep Lumbreras",
        "Ruo Cheng Huang",
        "Yanglin Hu",
        "Mile Gu",
        "Marco Tomamichel"
      ],
      "abstract": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography.",
      "tldr_zh": "该研究探讨了从未知纯量子比特状态中提取功的工作协议，使用顺序访问 N 个状态拷贝，而几乎不产生耗散。核心挑战在于平衡当前提取最大能量与通过信息获取优化后续轮次的权衡，采用强化学习中的探索-exploitation trade-off 开发适应性策略。这些策略使能量耗散仅以 poly-logarithmically 的方式随 N 增长，与基于 full state tomography 的现有协议相比实现了指数级改善，为量子工作提取提供了高效的新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "5 pages+14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09456v1",
      "published_date": "2025-05-14 15:07:58 UTC",
      "updated_date": "2025-05-14 15:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:25:50.140227"
    },
    {
      "arxiv_id": "2505.09438v1",
      "title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment",
      "title_zh": "评估基于 GPT- 和推理的大语言模型在物理奥林匹克问题上的表现：超越人类性能以及对教育评估的启示",
      "authors": [
        "Paul Tschisgale",
        "Holger Maus",
        "Fabian Kieser",
        "Ben Kroehs",
        "Stefan Petersen",
        "Peter Wulff"
      ],
      "abstract": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs.",
      "tldr_zh": "该研究评估了 Large Language Models（如 GPT-4o 和 o1-preview）在物理奥林匹克问题上的问题解决能力，通过不同提示技术与德国物理奥林匹克参与者进行比较。结果显示，GPT-4o 和 o1-preview 模型平均超过了人类表现，其中 o1-preview 表现出色，而提示技术对 GPT-4o 的影响较小。论文分析了这些模型的优点和局限性，并讨论了其对物理教育评估的启示，包括维护评估完整性和帮助学生批判性地使用 LLMs。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09438v1",
      "published_date": "2025-05-14 14:46:32 UTC",
      "updated_date": "2025-05-14 14:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:26:03.953271"
    },
    {
      "arxiv_id": "2505.09436v1",
      "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios",
      "title_zh": "CXMArena：统一数据集，用于在真实 CXM 场景中基准测试性能",
      "authors": [
        "Raghav Garg",
        "Kapil Sharma",
        "Karan Gupta"
      ],
      "abstract": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在客户体验管理（CXM）中的实际应用问题，引入了 CXMArena，这是一个大规模合成基准数据集，用于评估 AI 在真实 CXM 场景下的性能，以解决现有基准缺乏真实性（如知识库整合和噪声处理）的局限性。CXMArena 通过一个可扩展的 LLM 驱动管道模拟 CXM 实体，包括知识文章、问题分类和对话，并通过控制噪声注入和自动验证确保其接近真实世界分布。该数据集针对五个关键任务提供专用基准：Knowledge Base Refinement、Intent Prediction、Agent Quality Adherence、Article Search 和 Multi-turn RAG with Integrated Tools；基线实验显示，即使是最先进的模型在 Article Search 上仅达到 68% 准确率，在 Knowledge Base Refinement 上 F1 分数仅 0.3，突显了当前模型的挑战和改进需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09436v1",
      "published_date": "2025-05-14 14:44:30 UTC",
      "updated_date": "2025-05-14 14:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:26:15.877470"
    },
    {
      "arxiv_id": "2505.09435v1",
      "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records",
      "title_zh": "Endo-CLIP：基于原始结肠镜记录的渐进式自监督预训练",
      "authors": [
        "Yili He",
        "Yan Zhu",
        "Peiyao Fu",
        "Ruijie Yang",
        "Tianyi Chen",
        "Zhihua Wang",
        "Quanlin Li",
        "Pinghong Zhou",
        "Xian Yang",
        "Shuo Wang"
      ],
      "abstract": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis.",
      "tldr_zh": "该研究提出Endo-CLIP，一种渐进式自监督框架，用于在原始结肠镜记录上增强Contrastive Language-Image Pre-training (CLIP)，以解决非信息性背景图像、复杂医疗术语和模糊多病变描述等挑战。框架包括三个阶段：cleansing移除背景帧、attunement利用大型语言模型提取临床属性进行细粒度对比学习，以及unification采用患者级跨注意力解决多息肉模糊性。实验结果显示，Endo-CLIP在零样本和少样本息肉检测及分类任务中显著优于现有方法，推动了更准确和临床相关的内镜图像分析。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Early accepted to MICCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09435v1",
      "published_date": "2025-05-14 14:43:31 UTC",
      "updated_date": "2025-05-14 14:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:26:26.299401"
    },
    {
      "arxiv_id": "2505.09412v1",
      "title": "Counterfactual Strategies for Markov Decision Processes",
      "title_zh": "针对马尔可夫决策过程的反事实策略",
      "authors": [
        "Paul Kobialka",
        "Lina Gerlach",
        "Francesco Leofante",
        "Erika Ábrahám",
        "Silvia Lizeth Tapia Tarifa",
        "Einar Broch Johnsen"
      ],
      "abstract": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks.",
      "tldr_zh": "这篇论文针对 Markov Decision Processes (MDPs) 引入了反事实策略 (Counterfactual Strategies)，以解决现有方法在顺序决策任务中的局限性，这些方法通常仅适用于一步决策。论文提出通过编码为非线性优化问题 (non-linear optimization problems) 的方式，对初始策略进行最小修改，从而将不良结果的概率降低至阈值以下，并扩展方法以合成多样化的反事实策略。在四个真实世界数据集上的实验证明了该方法的实用性和有效性，尤其适用于复杂的顺序决策场景。",
      "categories": [
        "cs.AI",
        "I.2.m"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09412v1",
      "published_date": "2025-05-14 14:07:27 UTC",
      "updated_date": "2025-05-14 14:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:26:39.696369"
    },
    {
      "arxiv_id": "2505.09407v1",
      "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits",
      "title_zh": "基于量子编码器-解码器注意力机制的卷积变分电路的多语言机器翻译",
      "authors": [
        "Subrit Dikshit",
        "Ritu Tiwari",
        "Priyank Jain"
      ],
      "abstract": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations.",
      "tldr_zh": "该论文提出了一种名为 QEDACVC 的多语言机器翻译模型，利用量子计算作为后端，替代传统的经典计算架构，以提升翻译性能。QEDACVC 采用 quantum encoder-decoder 架构，结合 quantum convolution、quantum pooling、quantum variational circuit 和 quantum attention 机制，来处理多语言翻译任务。实验结果显示，在 OPUS 数据集上针对英语、法语、德语和印地语的训练中，该模型达到了 82% 的准确率，展示了量子计算在自然语言处理领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09407v1",
      "published_date": "2025-05-14 14:04:44 UTC",
      "updated_date": "2025-05-14 14:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:26:51.607785"
    },
    {
      "arxiv_id": "2505.09396v1",
      "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners",
      "title_zh": "人类启发式代理复杂性在LLM驱动战略推理者中的影响",
      "authors": [
        "Vince Trencsenyi",
        "Agnieszka Mensfelt",
        "Kostas Stathis"
      ],
      "abstract": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation.",
      "tldr_zh": "这篇论文探讨了人类启发的代理复杂性（agentic sophistication）对LLM驱动战略推理器的影响，特别是在博弈论（game-theoretic）设置中是否能复制人类战略行为。研究者评估了三种代理设计——简单的博弈论模型、非结构化的LLM-as-agent模型，以及LLM整合传统代理框架的模型——并使用猜数字游戏作为测试平台，与人类参与者比较其在一般推理和角色目标上的表现，同时引入模糊游戏场景测试泛化能力。结果基于超过2000个推理样本显示，人类启发的认知结构能提升LLM代理与人类行为的契合度，但代理设计复杂性与人类相似性的关系是非线性的，取决于底层LLM能力，并存在简单架构增强的局限性。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09396v1",
      "published_date": "2025-05-14 13:51:24 UTC",
      "updated_date": "2025-05-14 13:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:27:03.896621"
    },
    {
      "arxiv_id": "2505.09395v1",
      "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting",
      "title_zh": "量子增强参数高效学习用于台风轨迹预测",
      "authors": [
        "Chen-Yu Liu",
        "Kuan-Cheng Chen",
        "Yi-Chien Chen",
        "Samuel Yen-Chi Chen",
        "Wei-Hao Huang",
        "Wei-Jia Huang",
        "Yen-Jui Chang"
      ],
      "abstract": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning.",
      "tldr_zh": "本研究提出Quantum Parameter Adaptation (QPA)，一种基于Quantum-Train (QT)框架的量子增强参数高效学习方法，用于台风轨迹预测，以应对大气动力学复杂性和深度学习模型的计算需求。QPA利用Quantum Neural Networks (QNNs)仅在训练阶段生成可训练参数，并在推理时无需量子硬件，结合Attention-based Multi-ConvGRU模型实现高效训练，同时保持预测准确性。这是Quantum Machine Learning (QML)在大规模台风轨迹预测的首次应用，显著减少可训练参数数量，并提供可扩展、节能的解决方案，提升了气候建模的可持续性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09395v1",
      "published_date": "2025-05-14 13:50:44 UTC",
      "updated_date": "2025-05-14 13:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:27:16.546909"
    },
    {
      "arxiv_id": "2505.09393v1",
      "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units",
      "title_zh": "UMotion：不确定性驱动的基于惯性单位和超宽带单位的人类运动估计",
      "authors": [
        "Huakun Liu",
        "Hiroki Ota",
        "Xin Wei",
        "Yutaro Hirao",
        "Monica Perusquia-Hernandez",
        "Hideaki Uchiyama",
        "Kiyoshi Kiyokawa"
      ],
      "abstract": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy.",
      "tldr_zh": "本文提出 UMotion，一种基于不确定性的在线融合框架，用于从 Inertial Measurement Units (IMUs) 和 Ultra-Wideband (UWB) 传感器估计 3D 人体形状和姿势，旨在解决姿势模糊、数据漂移以及适应不同身体形状的挑战。框架通过六颗集成 UWB 距离传感器测量节点间距离，并结合人体测量数据，与 IMUs 数据一起输入 Unscented Kalman Filter (UKF)，实现对不确定性的实时迭代优化和融合。实验在合成和真实数据集上验证了 UMotion 的有效性，使传感器数据更稳定，并显著提高了姿势准确率，超越了现有技术。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09393v1",
      "published_date": "2025-05-14 13:48:36 UTC",
      "updated_date": "2025-05-14 13:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:27:27.511558"
    },
    {
      "arxiv_id": "2505.09661v1",
      "title": "Introducing voice timbre attribute detection",
      "title_zh": "引入语音音色属性检测",
      "authors": [
        "Jinghao He",
        "Zhengyan Sheng",
        "Liping Chen",
        "Kong Aik Lee",
        "Zhen-Hua Ling"
      ],
      "abstract": "This paper focuses on explaining the timbre conveyed by speech signals and\nintroduces a task termed voice timbre attribute detection (vTAD). In this task,\nvoice timbre is explained with a set of sensory attributes describing its human\nperception. A pair of speech utterances is processed, and their intensity is\ncompared in a designated timbre descriptor. Moreover, a framework is proposed,\nwhich is built upon the speaker embeddings extracted from the speech\nutterances. The investigation is conducted on the VCTK-RVA dataset.\nExperimental examinations on the ECAPA-TDNN and FACodec speaker encoders\ndemonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the\nseen scenario, where the testing speakers were included in the training set; 2)\nthe FACodec speaker encoder was superior in the unseen scenario, where the\ntesting speakers were not part of the training, indicating enhanced\ngeneralization capability. The VCTK-RVA dataset and open-source code are\navailable on the website https://github.com/vTAD2025-Challenge/vTAD.",
      "tldr_zh": "本论文引入了 voice timbre attribute detection (vTAD) 任务，用于通过一组感官属性描述语音信号的音色感知，并处理一对语音片段在指定音色描述符上的强度比较。作者提出一个基于 speaker embeddings 的框架，在 VCTK-RVA 数据集上进行研究。实验结果显示，ECAPA-TDNN speaker encoder 在 seen 场景（测试说话者包含在训练集中）中表现更优，而 FACodec speaker encoder 在 unseen 场景（测试说话者不在训练集中）中显示出更好的泛化能力；相关数据集和开源代码可从 GitHub 获取。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09661v1",
      "published_date": "2025-05-14 13:46:46 UTC",
      "updated_date": "2025-05-14 13:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:27:40.553481"
    },
    {
      "arxiv_id": "2505.09385v1",
      "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization",
      "title_zh": "FedSaaS：通过全局原型监督和本地对抗协调实现类别一致性的联邦语义分割",
      "authors": [
        "Xiaoyang Yu",
        "Xiaoming Wu",
        "Xin Wang",
        "Dongrun Li",
        "Ming Yang",
        "Peng Cheng"
      ],
      "abstract": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem.",
      "tldr_zh": "该研究提出 FedSaaS 框架，用于实现联邦语义分割（Federated semantic segmentation），通过全球原型监督和本地对抗协调（Local Adversarial Harmonization）解决数据隐私下类表示模糊和域移位问题。框架在服务端利用上传的类示例（class exemplars）构建类原型（class prototypes）来监督客户端的全球分支，确保全局表示一致；在客户端，通过对抗机制协调全球和本地分支的贡献，并应用多级对比损失（multilevel contrastive losses）强制两级表示在同一语义空间保持一致。实验在多个驾驶场景分割数据集上显示，FedSaaS 超过了现有最先进方法，提高了平均分割准确率，并有效提升了类一致性表示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09385v1",
      "published_date": "2025-05-14 13:38:30 UTC",
      "updated_date": "2025-05-14 13:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:27:53.260477"
    },
    {
      "arxiv_id": "2505.09382v1",
      "title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan",
      "title_zh": "声音音色属性检测 2025 挑战评估计划",
      "authors": [
        "Zhengyan Sheng",
        "Jinghao He",
        "Liping Chen",
        "Kong Aik Lee",
        "Zhen-Hua Ling"
      ],
      "abstract": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina.",
      "tldr_zh": "本论文介绍了 Voice Timbre Attribute Detection 2025 Challenge 的评估计划，该挑战聚焦于通过比较方式解释声音的独特品质，即 Voice Timbre。挑战使用一组 sensory descriptors（如 bright, coarse, soft 和 magnetic）来量化两个声音在特定描述符维度上的强度差异，从而将人类对声音的感官印象转化为可比较的分析。活动将于 2025 年 5 月启动，并在 10 月的 NCMMSC2025 会议上结束，为声音属性检测领域提供一个创新的评估平台。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09382v1",
      "published_date": "2025-05-14 13:35:53 UTC",
      "updated_date": "2025-05-14 13:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:28:05.954274"
    },
    {
      "arxiv_id": "2505.09380v1",
      "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform",
      "title_zh": "考察 VIOLA-AI 颅内出血模型的部署与改进，使用交互式 NeoMedSys 平台",
      "authors": [
        "Qinghui Liu",
        "Jon Nesvold",
        "Hanna Raaum",
        "Elakkyen Murugesu",
        "Martin Røvang",
        "Bradley J Maclntosh",
        "Atle Bjørnerud",
        "Karoline Skogen"
      ],
      "abstract": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback.",
      "tldr_zh": "本研究考察了使用交互式 NeoMedSys 平台部署和优化 VIOLA-AI 模型，该模型专注于检测颅内出血 (ICH)，旨在解决放射学中 AI 工具的临床挑战。NeoMedSys 整合了 AI 模型部署、测试和优化工具，与医疗图像查看器、注释系统及医院放射学信息系统相结合，并在挪威急诊部门进行为期三个月的实际测试，通过处理新数据和模型重新训练来提升性能。结果显示，VIOLA-AI 的敏感性从 79.2% 提高到 90.3%，特异性从 80.7% 提高到 89.3%，AUC 从 0.873 增至 0.949，这些改进突显了实时放射科医生反馈在迭代优化中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 11 figures, on submission to BMC Methods",
      "pdf_url": "http://arxiv.org/pdf/2505.09380v1",
      "published_date": "2025-05-14 13:33:38 UTC",
      "updated_date": "2025-05-14 13:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:28:19.633331"
    },
    {
      "arxiv_id": "2505.09371v1",
      "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search",
      "title_zh": "TensorRL-QAS：利用张量网络的强化学习用于可扩展量子架构搜索",
      "authors": [
        "Akash Kundu",
        "Stefano Mangini"
      ],
      "abstract": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware.",
      "tldr_zh": "该研究提出了一种可扩展的量子架构搜索框架 TensorRL-QAS，将 tensor networks 与 reinforcement learning (RL) 相结合，以应对变分量子算法在设计量子电路时的可扩展性挑战。该框架通过 matrix product state 近似预热搜索空间，显著缩小了搜索范围并加速收敛。在多达 12 量子比特的量子化学问题上，TensorRL-QAS 相比基线方法减少了 CNOT count 和电路深度高达 10 倍，同时保持或超过化学准确性，并将函数评估减少高达 100 倍、训练加速达 98%、成功概率提高至 50%。这项工作证明了 TensorRL-QAS 在无噪声和有噪声场景中的鲁棒性，为近中期量子硬件上的高效电路设计提供了可行方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "The code will be available soon! Comments are welcomed!",
      "pdf_url": "http://arxiv.org/pdf/2505.09371v1",
      "published_date": "2025-05-14 13:23:34 UTC",
      "updated_date": "2025-05-14 13:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:28:30.468605"
    },
    {
      "arxiv_id": "2505.09344v1",
      "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks",
      "title_zh": "GreenFactory：集成零成本代理以估计神经网络性能",
      "authors": [
        "Gabriel Cortês",
        "Nuno Lourenço",
        "Paolo Romano",
        "Penousal Machado"
      ],
      "abstract": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces.",
      "tldr_zh": "本论文提出 GreenFactory，一种集成 Zero-Cost Proxies 的方法，用于在神经架构搜索（Neural Architecture Search）过程中估计深度神经网络的性能，从而避免传统训练的耗时和资源密集问题。该框架利用 random forest regressor 结合多个预测器的优势，直接预测模型的测试准确率，而不是仅提供相对排名。在 NATS-Bench 上的实验显示，GreenFactory 取得了高 Kendall correlations，例如在 NATS-Bench-SSS 上，CIFAR-10 为 0.907、CIFAR-100 为 0.945，以及在 NATS-Bench-TSS 上类似结果，证明了其在多种数据集上的鲁棒性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09344v1",
      "published_date": "2025-05-14 12:40:34 UTC",
      "updated_date": "2025-05-14 12:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:28:42.873162"
    },
    {
      "arxiv_id": "2505.09343v1",
      "title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures",
      "title_zh": "DeepSeek-V3 的洞见：缩放挑战以及对 AI 架构硬件的反思",
      "authors": [
        "Chenggang Zhao",
        "Chengqi Deng",
        "Chong Ruan",
        "Damai Dai",
        "Huazuo Gao",
        "Jiashi Li",
        "Liyue Zhang",
        "Panpan Huang",
        "Shangyan Zhou",
        "Shirong Ma",
        "Wenfeng Liang",
        "Ying He",
        "Yuqing Wang",
        "Yuxuan Liu",
        "Y. X. Wei"
      ],
      "abstract": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)扩展过程中面临的硬件挑战，包括内存容量、计算效率和互连带宽限制。DeepSeek-V3模型通过硬件意识的共同设计（如Multi-head Latent Attention (MLA)、Mixture of Experts (MoE)架构、FP8混合精度训练和Multi-Plane Network Topology）在2,048个NVIDIA H800 GPU上实现了高效训练和推理，显著提升了成本效益。研究结果显示，这些创新有效缓解了硬件瓶颈，并为未来AI系统提供了蓝图，包括低精度计算单元的优化和低延迟通信 fabrics的发展。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive version will appear as\n  part of the Industry Track in Proceedings of the 52nd Annual International\n  Symposium on Computer Architecture (ISCA '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.09343v1",
      "published_date": "2025-05-14 12:39:03 UTC",
      "updated_date": "2025-05-14 12:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:28:52.613105"
    },
    {
      "arxiv_id": "2505.09342v1",
      "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems",
      "title_zh": "评估恶意软件检测系统中对抗防御的鲁棒性",
      "authors": [
        "Mostafa Jafari",
        "Alireza Shameli-Sendi"
      ],
      "abstract": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems.",
      "tldr_zh": "该论文评估了Android恶意软件检测系统中对抗防御（adversarial defenses）的鲁棒性，指出现有ML模型易受evasion attacks影响，尤其在binary-constrained domains中缺乏全面评估框架。研究的主要贡献包括提出Prioritized Binary Rounding技术，用于将连续扰动转换为二进制特征空间，同时保持高攻击成功率和低扰动大小，以及sigma-binary attack，一种针对二进制域的新对抗攻击方法，能以最小特征变化实现攻击目标。在Malscan数据集上的实验显示，sigma-binary attack优于现有攻击，导致如KDE、DLA和DNN+等防御的攻击成功率超过90%（少于10个特征修改），而对抗训练防御如AT-rFGSM-k虽在小预算下有所改善，但仍对不受限扰动脆弱；这些发现强调了使用精确方法如sigma-binary来暴露漏洞，以开发更坚固的恶意软件检测系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "68",
        "I.2.1"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09342v1",
      "published_date": "2025-05-14 12:38:43 UTC",
      "updated_date": "2025-05-14 12:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:29:07.630984"
    },
    {
      "arxiv_id": "2505.09341v1",
      "title": "Access Controls Will Solve the Dual-Use Dilemma",
      "title_zh": "访问控制将解决双重用途困境",
      "authors": [
        "Evžen Wybitul"
      ],
      "abstract": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma.",
      "tldr_zh": "该研究针对AI安全系统的双重用途困境（dual-use dilemma）提出了一种概念性的访问控制框架（access control framework），该框架基于验证的用户凭证（如机构 affiliation）和风险分类器，将模型输出分配到特定风险类别（如 advanced virology），仅允许凭证匹配的请求通过。框架引入小而受控的专家模块（small, gated expert modules），通过梯度路由（gradient routing）训练，实现高效的风险检测，避免外部监控的缺陷。总体而言，这一方法实现了AI能力的粒度治理（granular governance），让验证用户访问专业知识，同时阻挡潜在对手，从而平衡了模型效用和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09341v1",
      "published_date": "2025-05-14 12:38:08 UTC",
      "updated_date": "2025-05-14 12:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:29:17.765254"
    },
    {
      "arxiv_id": "2505.09329v1",
      "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis",
      "title_zh": "BioVFM-21M：生物医学图像分析的自监督视觉基础模型的基准测试与扩展",
      "authors": [
        "Jiarun Liu",
        "Hong-Yu Zhou",
        "Weijian Huang",
        "Hao Yang",
        "Dongning Song",
        "Tao Tan",
        "Yong Liang",
        "Shanshan Wang"
      ],
      "abstract": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models.",
      "tldr_zh": "这篇论文探讨了在生物医学图像分析中，通过自监督学习（Self-Supervised Learning）扩展模型大小、数据规模和成像模式等因素的缩放行为（Scaling Behavior），以开发可扩展的医疗视觉基础模型（Vision Foundation Models）。为了支持大规模预训练，研究者引入了BioVFM-21M数据集，该数据集包含2100万张覆盖多种生物医学图像模态和解剖结构的图像。实验结果显示，缩放能提升性能但因任务而异，最终提出的BioVFM模型在12个医疗基准上超越了现有最先进模型，同时强调任务特性、数据多样性和计算效率是关键考虑因素。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09329v1",
      "published_date": "2025-05-14 12:25:41 UTC",
      "updated_date": "2025-05-14 12:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:29:29.507099"
    },
    {
      "arxiv_id": "2505.09324v1",
      "title": "Neural Video Compression using 2D Gaussian Splatting",
      "title_zh": "使用二维高斯喷溅的神经视频压缩",
      "authors": [
        "Lakshya Gupta",
        "Imran N. Junejo"
      ],
      "abstract": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space.",
      "tldr_zh": "这篇论文提出了一种基于 2D Gaussian Splatting 的神经视频压缩方法，旨在解决传统和现有神经视频编解码器 (NVC) 在实时应用（如视频会议）中的高计算需求问题。模型通过 Region-of-Interest (ROI) 策略结合内容感知初始化和新型高斯帧间冗余减少机制，将编码时间加速 88%，并支持实时解码，仅需数千个高斯来实现高质量输出。实验结果显示，该方法首次将 2D Gaussian Splatting 应用于视频编解码领域，提供更高效的内容感知压缩策略，适用于视频流媒体平台。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09324v1",
      "published_date": "2025-05-14 12:23:53 UTC",
      "updated_date": "2025-05-14 12:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:29:43.153141"
    },
    {
      "arxiv_id": "2505.09295v1",
      "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance",
      "title_zh": "在人口统计差异和数据不平衡下的公平联邦学习",
      "authors": [
        "Qiming Wu",
        "Siqi Li",
        "Doudou Zhou",
        "Nan Liu"
      ],
      "abstract": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub.",
      "tldr_zh": "本文针对联邦学习(FL)中数据不平衡和人口统计差异可能加剧不公平问题，提出FedIDA框架，该方法结合公平性感知正则化和组条件过采样，支持多个敏感属性和异构数据分布，同时不影响底层FL算法的收敛行为。研究通过Lipschitz连续性和集中不等式提供理论分析，证明FedIDA能降低公平性指标的方差。实验结果显示，在基准和真实临床数据集上，FedIDA显著改善了模型公平性，同时保持了竞争性的预测性能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09295v1",
      "published_date": "2025-05-14 11:22:54 UTC",
      "updated_date": "2025-05-14 11:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:29:56.195225"
    },
    {
      "arxiv_id": "2505.09289v1",
      "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"",
      "title_zh": "“合作或崩溃：在LLM代理社会中可持续合作的涌现” 的可重复性研究",
      "authors": [
        "Pedro M. P. Curvo",
        "Mara Dragomir",
        "Salvador Torpes",
        "Mohammadmahdi Rahimi"
      ],
      "abstract": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems.",
      "tldr_zh": "本研究重复并扩展了 Piatti et al. 的 GovSim 框架，评估大型语言模型 (LLMs) 在资源共享场景中的合作决策能力，通过验证关键实验发现大型模型如 GPT-4-turbo 能实现可持续合作，而小型模型则依赖普遍化原则。扩展部分包括测试新模型（如 DeepSeek-V3 和 GPT-4o-mini）、引入异构多智能体环境、日语指令场景以及逆环境，证明框架适用于不同架构、规模和语言，并展示了合作行为的泛化性。结果表明，高性能模型能影响低性能模型的行为，这为开发更有效的合作 AI 系统提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 Tables, 9 Figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09289v1",
      "published_date": "2025-05-14 11:15:14 UTC",
      "updated_date": "2025-05-14 11:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:30:09.906824"
    },
    {
      "arxiv_id": "2505.09265v1",
      "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning",
      "title_zh": "MetaUAS: 基于单提示元学习的通用异常分割",
      "authors": [
        "Bin-Bin Gao"
      ],
      "abstract": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS.",
      "tldr_zh": "本研究提出了一种名为 MetaUAS 的框架，利用 one-prompt Meta-learning 实现通用异常分割（universal anomaly segmentation），无需依赖视觉语言模型，而是基于纯视觉基础模型。论文将异常分割统一为变化分割（change segmentation），通过大规模合成图像对（包括物体级和局部区域变化）进行训练，这些图像源自现有数据集，与目标异常数据集无关。为了处理提示图像和查询图像之间的几何变化，引入了软特征对齐模块（soft feature alignment module），从而桥接配对图像变化感知和单图像语义分割。实验结果显示，MetaUAS 在零样本、少样本甚至全样本场景下显著优于现有方法，仅需一个正常图像提示即可高效分割任何新型或未见异常，且无需语言指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.09265v1",
      "published_date": "2025-05-14 10:25:26 UTC",
      "updated_date": "2025-05-14 10:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:30:20.882809"
    },
    {
      "arxiv_id": "2505.09264v1",
      "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt",
      "title_zh": "仅凭一个正常图像提示学习检测多类异常",
      "authors": [
        "Bin-Bin Gao"
      ],
      "abstract": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP.",
      "tldr_zh": "该论文提出了一种名为OneNIP的方法，用于多类异常检测，仅需一个正常图像提示，即可重建正常特征并恢复异常特征，从而解决现有自注意力Transformer重建模型的局限性，如完美重建异常导致检测失败和低空间分辨率下的不准确分割。OneNIP通过引入supervised refiner，利用真实正常图像和合成异常图像来回归重建错误，从而显著提升像素级异常分割性能。在MVTec、BTAD和VisA等工业异常检测基准上，该方法超过了先前技术，展示了其高效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.09264v1",
      "published_date": "2025-05-14 10:25:14 UTC",
      "updated_date": "2025-05-14 10:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:30:32.538729"
    },
    {
      "arxiv_id": "2505.09263v1",
      "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation",
      "title_zh": "少样本异常驱动生成用于异常分类和分割",
      "authors": [
        "Guan Gui",
        "Bin-Bin Gao",
        "Jun Liu",
        "Chengjie Wang",
        "Yunsheng Wu"
      ],
      "abstract": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen.",
      "tldr_zh": "该研究针对工业异常检测中异常样本稀缺的问题，提出了一种Few-Shot Anomaly-Driven Generation (AnoGen)方法，通过少量真实异常指导diffusion model生成真实且多样的异常样本，从而提升异常分类和分割任务的性能。具体而言，AnoGen分为三个阶段：首先学习异常分布并注入嵌入；其次使用嵌入和bounding boxes引导diffusion model在特定对象上生成异常；最后通过弱监督训练基于生成的异常优化检测模型。在MVTec数据集上的实验显示，该方法显著提高了基线模型如DRAEM和DesTSeg的表现，例如在分割任务的AU-PR指标上分别提升5.8%和1.5%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.09263v1",
      "published_date": "2025-05-14 10:25:06 UTC",
      "updated_date": "2025-05-14 10:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:30:45.100759"
    },
    {
      "arxiv_id": "2505.09262v1",
      "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling",
      "title_zh": "EDBench：用于分子建模的大规模电子密度数据",
      "authors": [
        "Hongxin Xiang",
        "Ke Li",
        "Mingquan Liu",
        "Zhixiang Cheng",
        "Bin Yao",
        "Wenjie Du",
        "Jun Xia",
        "Li Zeng",
        "Xin Jin",
        "Xiangxiang Zeng"
      ],
      "abstract": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science.",
      "tldr_zh": "本研究指出，现有的分子机器学习力场 (MLFFs) 忽略了电子密度 (ED) 在理解分子力场中的关键作用，并引入 EDBench，这是一个大规模、高质量的 ED 数据集，基于 PCQM4Mv2 覆盖了 330 万分子。EDBench 通过提供准确的 ED 数据和一系列以 ED 为中心的基准任务（如预测、检索和生成），评估了模型在电子尺度上的学习能力。实验结果显示，学习方法不仅实现了高准确率，还显著降低了计算成本，与传统的密度泛函理论 (DFT) 计算相比更高效，为 ED 驱动的药物发现和材料科学奠定了坚实基础。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09262v1",
      "published_date": "2025-05-14 10:23:22 UTC",
      "updated_date": "2025-05-14 10:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:30:57.931678"
    },
    {
      "arxiv_id": "2505.09246v1",
      "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases",
      "title_zh": "聚焦、合并、排序：基于半结构化知识库的改进问答系统",
      "authors": [
        "Derian Boer",
        "Stephen Roth",
        "Stefan Kramer"
      ],
      "abstract": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever .",
      "tldr_zh": "本论文提出 FocusedRetriever，一种基于 Semi-Structured Knowledge Bases (SKBs) 的模块化框架，用于提升多跳问题回答性能。它整合了 VSS-based entity search、LLM-based generation of Cypher queries 和 pairwise re-ranking 等组件，利用 Large Language Models (LLMs) 提取关系事实、进行节点集连接过滤以及向量相似性搜索来检索和排名答案。实验结果显示，FocusedRetriever 在 STaRK 基准测试集上超越最先进方法，平均第一命中率提高 25.7%。该框架开源且仅使用基础 LLMs，但分析指出通过微调等升级可进一步优化。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09246v1",
      "published_date": "2025-05-14 09:35:56 UTC",
      "updated_date": "2025-05-14 09:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:31:09.445299"
    },
    {
      "arxiv_id": "2505.09208v1",
      "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China",
      "title_zh": "生成式人工智能对中国工程学生学习和表现的教育影响",
      "authors": [
        "Lei Fan",
        "Kunyang Deng",
        "Fangxue Liu"
      ],
      "abstract": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education.",
      "tldr_zh": "本研究调查了148名中国工程学科学生的生成式AI使用情况，探讨其对学习体验和表现的影响，包括AI的使用频率、应用场景、积极作用以及潜在挑战。结果显示，超过一半的参与者认为生成式AI提升了他们的学习效率、主动性和创造力，近一半的学生表示它增强了独立思考，但实际学术表现并未显著改善。许多学生担忧生成式AI的准确性和领域特定可靠性，并提出了从学生视角整合AI的建议。该研究为生成式AI在工程教育中的应用提供了宝贵见解和实用推荐。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09208v1",
      "published_date": "2025-05-14 07:52:54 UTC",
      "updated_date": "2025-05-14 07:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:31:19.014975"
    },
    {
      "arxiv_id": "2505.09203v1",
      "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials",
      "title_zh": "InvDesFlow-AL：基于主动学习的逆向设计功能性材料工作流",
      "authors": [
        "Xiao-Qi Han",
        "Peng-Jie Guo",
        "Ze-Feng Gao",
        "Hao Sun",
        "Zhong-Yi Lu"
      ],
      "abstract": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience.",
      "tldr_zh": "本文提出了一种基于主动学习(Active Learning)的逆向设计框架 InvDesFlow-AL，用于功能材料的设计，旨在加速可再生能源、催化等领域的发展。该框架通过迭代优化材料生成过程，利用扩散原理的生成模型，逐步引导材料向期望性能特征演进，并在晶体结构预测中实现了 0.0423 Å 的 RMSE，比现有模型改善 32.96%。此外，InvDesFlow-AL 成功设计了低形成能材料，并发现了新型 BCS 超导体 Li₂AuH₆，具有 140 K 的转变温度，这为材料科学中的逆向设计提供了强有力的实证支持。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.supr-con",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "29 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09203v1",
      "published_date": "2025-05-14 07:29:06 UTC",
      "updated_date": "2025-05-14 07:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:31:33.078110"
    },
    {
      "arxiv_id": "2505.09168v1",
      "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection",
      "title_zh": "DRRNet：宏观-微观特征融合和双向逆向精炼用于伪装物体检测",
      "authors": [
        "Jianlin Sun",
        "Xiaolin Fang",
        "Juwei Guan",
        "Dongdong Gui",
        "Teqi Wang",
        "Tongxin Zhu"
      ],
      "abstract": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet.",
      "tldr_zh": "本论文针对 Camouflaged Object Detection 的核心挑战——目标与背景在颜色、纹理和形状上的相似性，提出 DRRNet 架构，该架构采用“context-detail-fusion-refinement”四阶段管道来平衡全局语义和局部细节。DRRNet 包括 Omni-Context Feature Extraction Module 用于捕获全局伪装模式、Local Detail Extraction Module 用于补充微结构信息，以及特征融合模块和 Dual Reverse Refinement 模块，通过空间边缘先验和频域噪声抑制来增强物体边界连续性和抑制背景干扰。实验结果表明，DRRNet 在基准数据集上显著优于最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09168v1",
      "published_date": "2025-05-14 06:03:53 UTC",
      "updated_date": "2025-05-14 06:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:31:45.342540"
    },
    {
      "arxiv_id": "2505.09166v1",
      "title": "An Initial Exploration of Default Images in Text-to-Image Generation",
      "title_zh": "文本到图像生成中的默认图像初步探索",
      "authors": [
        "Hannu Simonen",
        "Atte Kiviniemi",
        "Jonas Oppenlaender"
      ],
      "abstract": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions.",
      "tldr_zh": "本研究探讨了文本到图像生成（TTI）中的默认图像（default images）现象，即模型在处理未知术语时生成高度相似的图像。作者首次对 Midjourney 进行系统调查，通过创建触发默认图像的输入提示，进行初始实验、小规模消融研究以及用户满意度调查。结果显示，默认图像显著影响用户体验，并揭示了 TTI 和提示工程（prompt engineering）的潜在挑战，为未来改进提供了基础。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5.m; I.2.m"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09166v1",
      "published_date": "2025-05-14 05:59:23 UTC",
      "updated_date": "2025-05-14 05:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:31:57.818800"
    },
    {
      "arxiv_id": "2505.09160v1",
      "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning",
      "title_zh": "基于对比学习和掩码自编码器学习的多任务无线信道表示基础模型",
      "authors": [
        "Berkay Guler",
        "Giovanni Geraci",
        "Hamid Jafarkhani"
      ],
      "abstract": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning.",
      "tldr_zh": "该研究针对自监督学习在无线通道表示中的局限性，提出WiMAE（Wireless Masked Autoencoder），一个基于Transformer的编码器-解码器基础模型，在真实开源多天线无线通道数据集上进行预训练。接着，开发了ContraWiMAE，通过在统一的多任务框架中结合对比学习目标和重建任务，利用噪声注入生成正对，以提升模型对结构和判别特征的捕捉能力。实验结果显示，WiMAE和ContraWiMAE在多个下游任务中表现出色，尤其在未见过场景下，ContraWiMAE在线性可分性和适应性方面进一步改进，并比现有最先进模型具有更高的性能和数据效率，为无线通道表示学习提供强大基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09160v1",
      "published_date": "2025-05-14 05:45:22 UTC",
      "updated_date": "2025-05-14 05:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:32:10.795226"
    },
    {
      "arxiv_id": "2505.09142v1",
      "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor",
      "title_zh": "ELIS：高效的 LLM 迭代调度系统，带有响应长度预测器",
      "authors": [
        "Seungbeom Choi",
        "Jeonghoe Goo",
        "Eunjoo Jeon",
        "Mingyu Yang",
        "Minsung Jang"
      ],
      "abstract": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%.",
      "tldr_zh": "该研究提出ELIS，一种高效的大型语言模型(LLMs)服务系统，采用Iterative Shortest Remaining Time First (ISRTF)调度器来优化推理任务管理，解决传统first-come-first-served策略导致的head-of-line blocking问题。ELIS通过训练基于BGE模型的响应长度预测器来准确预测LLMs的推理延迟，并对shortest remaining time first策略进行优化，以适应LLMs的迭代批量处理。实验结果显示，在模拟的真实请求流和Kubernetes生产环境中，ISRTF调度器将平均作业完成时间降低了多达19.6%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization",
      "pdf_url": "http://arxiv.org/pdf/2505.09142v1",
      "published_date": "2025-05-14 04:50:00 UTC",
      "updated_date": "2025-05-14 04:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:32:21.653263"
    },
    {
      "arxiv_id": "2505.09131v1",
      "title": "Fair Clustering via Alignment",
      "title_zh": "通过对齐的公平聚类",
      "authors": [
        "Kunwoong Kim",
        "Jihu Lee",
        "Sangchul Park",
        "Yongdai Kim"
      ],
      "abstract": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability.",
      "tldr_zh": "该论文针对算法公平性在聚类中的应用，提出 Fair Clustering via Alignment (FCA) 算法，以平衡敏感属性在各聚类中的实例比例，同时解决现有方法在聚类效用和数值稳定性上的不足。FCA 通过分解公平 K-means 目标函数，交替计算联合概率分布对齐不同保护群体的数据，并在对齐空间中优化聚类中心，从而在任何给定公平水平下理论上保证近似最优的聚类效用。实验结果表明，FCA 比现有方法在公平水平与 clustering utility 之间实现了 superior trade-off，并能实现近乎完美的公平而不出现数值不稳定。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon",
      "pdf_url": "http://arxiv.org/pdf/2505.09131v1",
      "published_date": "2025-05-14 04:29:09 UTC",
      "updated_date": "2025-05-14 04:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:32:34.991168"
    },
    {
      "arxiv_id": "2505.09129v1",
      "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes",
      "title_zh": "WSCIF：一种弱监督颜色智能框架，用于监控关键帧中的战术异常检测",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future.",
      "tldr_zh": "本文提出 WSCIF 框架，这是一个弱监督的颜色智能框架，旨在在资源受限和数据敏感的环境中，对监控关键帧进行战术异常检测。框架通过融合无监督 KMeans 聚类和 RGB 通道直方图建模，快速识别结构异常和颜色突变信号，如高能量光源、目标存在和反射干扰。实验在非洲国家监控视频上验证了其有效性，成功检测多个异常帧，并展示了在战术暗杀警告、可疑物体筛选和环境剧变监控中的强部署性和解释价值。该研究强调颜色特征作为低语义战场信号载体的作用，并建议未来结合 graph neural networks 和时间建模进一步扩展感知能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "es: 68T10, 68T05, 62H35, 68U10",
        "I.4.9; I.5.1; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data",
      "pdf_url": "http://arxiv.org/pdf/2505.09129v1",
      "published_date": "2025-05-14 04:24:37 UTC",
      "updated_date": "2025-05-14 04:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:32:48.551045"
    },
    {
      "arxiv_id": "2505.09115v1",
      "title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence",
      "title_zh": "PreCare：设计用于预先护理规划 (ACP) 的 AI 助手，以增强个人价值探索、患者知识和决策信心",
      "authors": [
        "Yu Lun Hsu",
        "Yun-Rung Chou",
        "Chiao-Ju Chang",
        "Yu-Cheng Chang",
        "Zer-Wei Lee",
        "Rokas Gipiškis",
        "Rachel Li",
        "Chih-Yuan Shih",
        "Jen-Kuei Peng",
        "Hsien-Liang Huang",
        "Jaw-Shiun Tsai",
        "Mike Y. Chen"
      ],
      "abstract": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants.",
      "tldr_zh": "本研究针对在线Advance Care Planning (ACP) 的局限性（如缺乏个性化价值探索和决策澄清），设计了PreCare平台，以AI助手提升用户体验。研究团队通过两项形成性研究（采访3个ACP团队的18名患者和14名ACP网站用户）并与6名专业人士合作，开发了PreCare的3个AI驱动助手，分别指导个人价值探索、ACP知识获取和知情决策支持。可用性研究（n=12）显示PreCare的System Usability Scale (SUS)评级为优秀，而比较评估（n=12）表明，该平台显著提高了用户价值探索、知识水平和决策信心，并获得92%的参与者偏好。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09115v1",
      "published_date": "2025-05-14 03:53:35 UTC",
      "updated_date": "2025-05-14 03:53:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:32:59.080316"
    },
    {
      "arxiv_id": "2505.09114v1",
      "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer",
      "title_zh": "超越已知：基于反事实推理的 Decision Transformer 决策",
      "authors": [
        "Minh Hoang Nguyen",
        "Linh Le Pham Van",
        "Thommen George Karimpanal",
        "Sunil Gupta",
        "Hung Le"
      ],
      "abstract": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities.",
      "tldr_zh": "该论文提出 Counterfactual Reasoning Decision Transformer (CRDT)，一种改进 Decision Transformers (DT) 的框架，通过反事实推理生成和利用 counterfactual experiences，解决强化学习中数据不足和次优行为的问题，从而提升代理在未知场景中的决策能力。CRDT 无需架构修改，便能赋予代理拼接 suboptimal trajectories 的能力，并在 Atari 和 D4RL 基准实验中表现出色，性能比传统 DT 提升明显。这些结果证明，反事实推理可增强强化学习代理的泛化能力和整体表现。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09114v1",
      "published_date": "2025-05-14 03:45:16 UTC",
      "updated_date": "2025-05-14 03:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:33:12.445257"
    },
    {
      "arxiv_id": "2505.09108v1",
      "title": "Air-Ground Collaboration for Language-Specified Missions in Unknown Environments",
      "title_zh": "空地协作：用于未知环境的语言指定任务",
      "authors": [
        "Fernando Cladera",
        "Zachary Ravichandran",
        "Jason Hughes",
        "Varun Murali",
        "Carlos Nieto-Granda",
        "M. Ani Hsieh",
        "George J. Pappas",
        "Camillo J. Taylor",
        "Vijay Kumar"
      ],
      "abstract": "As autonomous robotic systems become increasingly mature, users will want to\nspecify missions at the level of intent rather than in low-level detail.\nLanguage is an expressive and intuitive medium for such mission specification.\nHowever, realizing language-guided robotic teams requires overcoming\nsignificant technical hurdles. Interpreting and realizing language-specified\nmissions requires advanced semantic reasoning. Successful heterogeneous robots\nmust effectively coordinate actions and share information across varying\nviewpoints. Additionally, communication between robots is typically\nintermittent, necessitating robust strategies that leverage communication\nopportunities to maintain coordination and achieve mission objectives. In this\nwork, we present a first-of-its-kind system where an unmanned aerial vehicle\n(UAV) and an unmanned ground vehicle (UGV) are able to collaboratively\naccomplish missions specified in natural language while reacting to changes in\nspecification on the fly. We leverage a Large Language Model (LLM)-enabled\nplanner to reason over semantic-metric maps that are built online and\nopportunistically shared between an aerial and a ground robot. We consider\ntask-driven navigation in urban and rural areas. Our system must infer\nmission-relevant semantics and actively acquire information via semantic\nmapping. In both ground and air-ground teaming experiments, we demonstrate our\nsystem on seven different natural-language specifications at up to\nkilometer-scale navigation.",
      "tldr_zh": "该论文提出了一种空地协作系统，允许无人机 (UAV) 和无人地面车辆 (UGV) 在未知环境中协作完成用户通过自然语言指定的任务，并实时响应任务变化。该系统利用 Large Language Model (LLM)-enabled planner 在在线构建的语义-度量 maps 上进行高级语义推理，并通过机会性信息共享和间歇性通信实现机器人间的协调和任务驱动导航。在城市和农村地区的实验中，该系统在七种不同自然语言任务上成功演示了公里级导航，展示了其在异构团队协作中的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages, 24 figures, 7 tables. Submitted to T-FR",
      "pdf_url": "http://arxiv.org/pdf/2505.09108v1",
      "published_date": "2025-05-14 03:33:46 UTC",
      "updated_date": "2025-05-14 03:33:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:33:22.700413"
    },
    {
      "arxiv_id": "2505.09091v1",
      "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis",
      "title_zh": "DPN-GAN：在生成对抗网络中诱导周期激活以实现高保真音频合成",
      "authors": [
        "Zeeshan Ahmad",
        "Shudi Bao",
        "Meng Chen"
      ],
      "abstract": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio.",
      "tldr_zh": "该研究提出 DPN-GAN，一种新型生成对抗网络架构，通过引入基于核的周期性 ReLU 激活函数来诱导周期性偏差，从而提升音频合成的保真度和质量，解决传统 GAN 依赖带宽有限的 mel-spectrograms 导致的分辨率问题和模式崩溃。DPN-GAN 包括 DPN 模块，利用可变形卷积操作实现多分辨率生成，并增强鉴别器网络以更好地区分真实和合成样本。实验结果显示，该模型在五个数据集上，包括语音合成和音乐生成任务，超越了现有 GAN 架构，在标准评估指标上表现出色，并具备更高的鲁棒性，尤其在分布外和噪声数据上。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09091v1",
      "published_date": "2025-05-14 02:52:16 UTC",
      "updated_date": "2025-05-14 02:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:33:34.393750"
    },
    {
      "arxiv_id": "2505.09085v1",
      "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision",
      "title_zh": "利用脑循环监督实现大型模型的人类式认知泛化",
      "authors": [
        "Jiaxuan Chen",
        "Yu Qi",
        "Yueming Wang",
        "Gang Pan"
      ],
      "abstract": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems.",
      "tldr_zh": "本文研究了如何通过脑信号参与的监督学习（brain-in-the-loop supervised learning）将人类认知结构转移到深度神经网络（DNNs）中，以提升大型模型对抽象概念、推理和新场景适应的能力。实验结果显示，这种方法显著提高了模型在少样本/零样本学习（few-shot/zero-shot learning）和分布外识别（out-of-distribution recognition）等任务中的性能，并提供了高度可解释的概念表示。这些发现为开发更具人类-like认知能力的AI系统开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09085v1",
      "published_date": "2025-05-14 02:39:10 UTC",
      "updated_date": "2025-05-14 02:39:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:33:46.765442"
    },
    {
      "arxiv_id": "2505.09082v1",
      "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM",
      "title_zh": "CEC-Zero: 基于 LLM 的中文错误修正解决方案",
      "authors": [
        "Sophie Zhang",
        "Zhiming Lin"
      ],
      "abstract": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在中文拼写纠正（CSC）中的优越性能，但强调了其在可靠性和泛化能力方面的挑战。作者提出CEC-Zero框架，一种基于强化学习（RL）的创新方法，让LLMs通过自主学习错误策略实现自我纠正，无需外部监督或标注数据。实验结果显示，RL增强的LLMs在准确性和跨域泛化上显著提升，为中文自然语言处理（NLP）应用提供了可扩展的可靠解决方案，并开辟了语言模型自提升的新范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09082v1",
      "published_date": "2025-05-14 02:35:47 UTC",
      "updated_date": "2025-05-14 02:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:33:59.779835"
    },
    {
      "arxiv_id": "2505.09081v1",
      "title": "SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation",
      "title_zh": "SALM：一种多智能体框架，用于语言模型驱动的社交网络模拟",
      "authors": [
        "Gaurav Koley"
      ],
      "abstract": "Contemporary approaches to agent-based modeling (ABM) of social systems have\ntraditionally emphasized rule-based behaviors, limiting their ability to\ncapture nuanced dynamics by moving beyond predefined rules and leveraging\ncontextual understanding from LMs of human social interaction. This paper\npresents SALM (Social Agent LM Framework), a novel approach for integrating\nlanguage models (LMs) into social network simulation that achieves\nunprecedented temporal stability in multi-agent scenarios. Our primary\ncontributions include: (1) a hierarchical prompting architecture enabling\nstable simulation beyond 4,000 timesteps while reducing token usage by 73%, (2)\nan attention-based memory system achieving 80% cache hit rates (95% CI [78%,\n82%]) with sub-linear memory growth of 9.5%, and (3) formal bounds on\npersonality stability. Through extensive validation against SNAP ego networks,\nwe demonstrate the first LLM-based framework capable of modeling long-term\nsocial phenomena while maintaining empirically validated behavioral fidelity.",
      "tldr_zh": "本研究提出 SALM 框架，一种基于语言模型 (LMs) 的多智能体框架，用于驱动社交网络模拟，克服传统基于规则的代理建模 (ABM) 在捕捉复杂社会动态方面的局限性。SALM 的主要贡献包括：(1) 层次化提示架构 (hierarchical prompting architecture)，实现超过 4,000 个时间步的稳定模拟，同时减少 73% 的 token 使用；(2) 基于注意力的记忆系统 (attention-based memory system)，达到 80% 的缓存命中率 (95% CI [78%, 82%]) 和 9.5% 的子线性内存增长；以及 (3) 对个性稳定性 (personality stability) 的正式界限。通过对 SNAP ego networks 的广泛验证，SALM 展示了作为首个 LLM-based 框架的能力，能够模拟长期社会现象并保持行为忠诚度。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09081v1",
      "published_date": "2025-05-14 02:29:46 UTC",
      "updated_date": "2025-05-14 02:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:34:12.071544"
    },
    {
      "arxiv_id": "2505.09062v1",
      "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models",
      "title_zh": "变分前缀调整用于多样且准确的代码摘要，使用预训练语言模型",
      "authors": [
        "Junda Zhao",
        "Yuliang Song",
        "Eldan Cohen"
      ],
      "abstract": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models.",
      "tldr_zh": "本研究提出了一种名为Variational Prefix Tuning (VPT)的创新方法，用于提升预训练语言模型在代码摘要生成中的多样性和准确性。VPT通过整合Conditional Variational Autoencoder (CVAE)框架，建模目标摘要的分布，并采样连续嵌入作为前缀来引导生成过程，从而为给定源代码产生多种高质量摘要选项，同时保持参数高效无需重新训练模型。此外，研究采用双标准重排序机制优化生成的摘要子集，确保兼顾多样性和准确性，并在广泛实验中证明VPT在常用数据集和最先进模型上显著提升了代码摘要性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "D.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by the Journal of Systems and Software",
      "pdf_url": "http://arxiv.org/pdf/2505.09062v1",
      "published_date": "2025-05-14 01:46:56 UTC",
      "updated_date": "2025-05-14 01:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:34:23.655736"
    },
    {
      "arxiv_id": "2505.09040v1",
      "title": "RT-cache: Efficient Robot Trajectory Retrieval System",
      "title_zh": "RT-cache：高效机器人轨迹检索系统",
      "authors": [
        "Owen Kwon",
        "Abraham George",
        "Alison Bartsch",
        "Amir Barati Farimani"
      ],
      "abstract": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation.",
      "tldr_zh": "本研究提出 RT-cache，一种高效的机器人轨迹检索系统，通过大数据检索和从经验中学习，显著加速真实世界机器人的推理过程。RT-cache 存储大量之前成功的机器人轨迹，并整合 Memory Builder 和 Trajectory Retrieval 机制，以快速检索相关多步动作片段，从而减少每步推理的延迟。实验在 Open-X Embodiment Dataset 和其他真实数据上显示，RT-cache 比缺乏检索的基线模型更快且更成功地完成任务，提供了一个实用且数据驱动的实时操作解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference",
      "pdf_url": "http://arxiv.org/pdf/2505.09040v1",
      "published_date": "2025-05-14 00:41:44 UTC",
      "updated_date": "2025-05-14 00:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T11:34:35.097585"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 84,
  "processed_papers_count": 84,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T11:35:00.127954"
}