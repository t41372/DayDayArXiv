{
  "date": "2024-08-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-07 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 81 篇论文，主要聚焦 AI 安全、LLM 优化、多模态处理和机器人应用等领域，其中令人印象深刻的文章包括 RadPrompt 方法提升放射学报告分类的准确性，以及 Sleeper Social Bots 对 AI 虚假信息的政治威胁分析，这些论文突显了 LLM 在实际应用中的潜在风险和创新潜力。\n\n下面，我将挑选并简要讨论部分重要、相关或有话题度的论文，先从 LLM 和 AI 安全主题入手，然后过渡到多模态处理、机器人优化等领域。对于其他较常规或不那么突出的论文（如一些基础优化或小数据集实验），我将快速掠过，只列出标题而不深入讨论，以控制篇幅。\n\n### LLM 和 AI 安全相关论文\n- **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**（中文：规则-based洞见是否能提升LLM在放射学报告分类中的表现？引入RadPrompt方法）  \n  这篇论文提出 RadPrompt，一种结合规则系统和 LLM 的多轮提示策略，用于放射学报告分类。通过整合不确定性感知信息，RadPrompt 显著提升了 GPT-4 Turbo 的加权 F1 分数，展示了 LLM 与规则模型的协同潜力。主要贡献：在临床数据集上实现了更鲁棒的零样本预测，潜在影响包括改进医疗图像分析的效率和准确性。\n\n- **Sleeper Social Bots: a new generation of AI disinformation bots are already a political threat**（中文：Sleeper Social Bots：新一代AI虚假信息bots已成为政治威胁）  \n  论文探讨了 AI 驱动的“潜伏社交机器人”，这些机器人能伪装成人类传播虚假信息。研究团队使用 ChatGPT 构建模拟实验，证明这些 bots 能影响选举讨论。主要发现：bots 具有动态说服能力，实验显示参与者难以识别，强调了 2024 年美国大选等场景下的紧急风险。\n\n- **Identifying and Mitigating Social Bias Knowledge in Language Models**（中文：识别和缓解语言模型中的社会偏差知识）  \n  作者开发了 Fairness Stamp (FAST) 方法，通过细粒度校准 LLM 输出层来减少社会偏差。论文在 BiaScope 基准上评估了该框架，主要贡献：FAST 显著降低了偏差，同时保留了模型性能，在公平性和泛化能力上超越了现有方法。\n\n- **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**（中文：CodexGraph：通过代码图数据库连接LLM和代码仓库）  \n  这篇论文引入 CodexGraph 系统，使用图数据库连接 LLM 和代码仓库，支持精确上下文检索。主要发现：在 CrossCodeEval 和 SWE-bench 等基准上，CodexGraph 提升了代码任务的适应性和效率，展示了 LLM 在软件工程中的潜力。\n\n### 多模态和视觉处理相关论文\n- **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**（中文：ArtVLM：通过视觉-based前缀语言建模进行属性识别）  \n  论文提出 ArtVLM，使用生成式检索来识别视觉属性，解决了 CLIP 等模型在对象-属性依赖上的不足。主要贡献：在 VAW 和 VGARank 数据集上，生成式方法优于对比式检索，提升了零样本属性识别的准确性。\n\n- **Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization**（中文：Patchview：LLM驱动的世界构建使用生成尘埃和磁铁可视化）  \n  作者开发了 Patchview 系统，利用 LLM 和物理隐喻（如磁铁和尘埃）辅助故事世界构建。主要发现：用户研究显示，该系统提升了元素生成和语义搜索的交互性，支持 LLM 在创意任务中的行为对齐。\n\n- **Digital Avatars: Framework Development and Their Evaluation**（中文：数字Avatars：框架开发及其评估）  \n  论文提出一个端到端框架，使用 LLM 生成高保真数字 avatars，并通过 Crowd Vote 评估其幽默性和真实性。主要贡献：avatars 在真实性和受欢迎度上超过基线，展示了 LLM 在虚拟交互中的应用潜力。\n\n### 机器人和优化相关论文\n- **Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms**（中文：硬件辅助的神经处理单元虚拟化用于云平台）  \n  论文介绍了 Neu10 框架，支持 NPU 的细粒度虚拟化。主要发现：Neu10 提升了云平台上 ML 推理服务的吞吐量（最高 1.4 倍）和利用率（平均 1.2 倍），为多租户场景提供了高效资源共享。\n\n- **PLANRL: A Motion Planning and Imitation Learning Framework to Bootstrap Reinforcement Learning**（中文：PLANRL：运动规划和模仿学习框架用于引导强化学习）  \n  这个框架结合经典规划和 RL，提升了机器人任务执行效率。主要贡献：在模拟环境中，PLANRL 比基线高 10-15% 的成功率，并扩展到真实机器人任务中。\n\n其他论文，如 **ACL Ready: RAG Based Assistant for the ACL Checklist**（中文：ACL Ready：基于 RAG 的 ACL 检查清单助手）和 **Handwritten Code Recognition for Pen-and-Paper CS Education**（中文：手写代码识别用于纸笔 CS 教育），这些更侧重工具开发和教育应用，我快速掠过：它们分别提供了 RAG 辅助研究伦理的工具和手写代码 OCR 方法，提升了用户体验，但影响力相对有限。\n\n今天的 arXiv 更新反映了 AI 领域快速迭代的趋势，尤其在 LLM 安全和多模态融合上。感兴趣的读者可关注这些核心论文，以探索实际应用潜力。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2408.04121v1",
      "title": "Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology",
      "title_zh": "翻译失败",
      "authors": [
        "Panagiotis Fytas",
        "Anna Breger",
        "Ian Selby",
        "Simon Baker",
        "Shahab Shahipasand",
        "Anna Korhonen"
      ],
      "abstract": "Developing imaging models capable of detecting pathologies from chest X-rays\ncan be cost and time-prohibitive for large datasets as it requires supervision\nto attain state-of-the-art performance. Instead, labels extracted from\nradiology reports may serve as distant supervision since these are routinely\ngenerated as part of clinical practice. Despite their widespread use, current\nrule-based methods for label extraction rely on extensive rule sets that are\nlimited in their robustness to syntactic variability. To alleviate these\nlimitations, we introduce RadPert, a rule-based system that integrates an\nuncertainty-aware information schema with a streamlined set of rules, enhancing\nperformance. Additionally, we have developed RadPrompt, a multi-turn prompting\nstrategy that leverages RadPert to bolster the zero-shot predictive\ncapabilities of large language models, achieving a statistically significant\nimprovement in weighted average F1 score over GPT-4 Turbo. Most notably,\nRadPrompt surpasses both its underlying models, showcasing the synergistic\npotential of LLMs with rule-based models. We have evaluated our methods on two\nEnglish Corpora: the MIMIC-CXR gold-standard test set and a gold-standard\ndataset collected from the Cambridge University Hospitals.",
      "tldr_zh": "本研究探讨了是否可以通过规则-based 见解增强大型语言模型 (LLMs) 在放射学报告分类中的性能，以解决现有规则-based 方法对句法变异性的鲁棒性不足问题。作者引入了 RadPert，一种集不确定性感知信息模式和简化规则集的规则-based 系统，提升了标签提取的准确性；并开发了 RadPrompt，一种多轮提示策略，利用 RadPert 强化 LLMs 的 zero-shot 预测能力，在加权平均 F1 score 上显著超越 GPT-4 Turbo。实验在 MIMIC-CXR 和剑桥大学医院的金标准数据集上验证了 RadPrompt 的效能，展示了 LLMs 与规则-based 模型的协同潜力，为放射学报告处理提供高效的远程监督方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at BioNLP, ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04121v1",
      "published_date": "2024-08-07 23:09:23 UTC",
      "updated_date": "2024-08-07 23:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:25:56.419872"
    },
    {
      "arxiv_id": "2408.04112v1",
      "title": "Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "John Joon Young Chung",
        "Max Kreminski"
      ],
      "abstract": "Large language models (LLMs) can help writers build story worlds by\ngenerating world elements, such as factions, characters, and locations.\nHowever, making sense of many generated elements can be overwhelming. Moreover,\nif the user wants to precisely control aspects of generated elements that are\ndifficult to specify verbally, prompting alone may be insufficient. We\nintroduce Patchview, a customizable LLM-powered system that visually aids\nworldbuilding by allowing users to interact with story concepts and elements\nthrough the physical metaphor of magnets and dust. Elements in Patchview are\nvisually dragged closer to concepts with high relevance, facilitating\nsensemaking. The user can also steer the generation with verbally elusive\nconcepts by indicating the desired position of the element between concepts.\nWhen the user disagrees with the LLM's visualization and generation, they can\ncorrect those by repositioning the element. These corrections can be used to\nalign the LLM's future behaviors to the user's perception. With a user study,\nwe show that Patchview supports the sensemaking of world elements and steering\nof element generation, facilitating exploration during the worldbuilding\nprocess. Patchview provides insights on how customizable visual representation\ncan help sensemake, steer, and align generative AI model behaviors with the\nuser's intentions.",
      "tldr_zh": "这篇论文介绍了 Patchview，一种基于 LLM (Large Language Models) 的世界构建系统，通过生成尘埃和磁铁可视化 metaphor，帮助作家管理故事元素如派系、人物和地点。系统允许用户通过拖拽元素来直观地感性化相关性、精确引导难以用语言描述的生成过程，并通过修正位置来调整 LLM 的未来行为，以对齐用户意图。用户研究证明，Patchview 提升了元素理解、生成引导和探索效率，并提供了关于可定制视觉表示如何支持生成 AI 行为的宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to UIST2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04112v1",
      "published_date": "2024-08-07 22:27:19 UTC",
      "updated_date": "2024-08-07 22:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:26:09.491898"
    },
    {
      "arxiv_id": "2408.04104v3",
      "title": "Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms",
      "title_zh": "硬件辅助的神经处理单元虚拟化技术用于云平台",
      "authors": [
        "Yuqi Xue",
        "Yiqi Liu",
        "Lifeng Nai",
        "Jian Huang"
      ],
      "abstract": "Cloud platforms today have been deploying hardware accelerators like neural\nprocessing units (NPUs) for powering machine learning (ML) inference services.\nTo maximize the resource utilization while ensuring reasonable quality of\nservice, a natural approach is to virtualize NPUs for efficient resource\nsharing for multi-tenant ML services. However, virtualizing NPUs for modern\ncloud platforms is not easy. This is not only due to the lack of system\nabstraction support for NPU hardware, but also due to the lack of architectural\nand ISA support for enabling fine-grained dynamic operator scheduling for\nvirtualized NPUs.\n  We present Neu10, a holistic NPU virtualization framework. We investigate\nvirtualization techniques for NPUs across the entire software and hardware\nstack. Neu10 consists of (1) a flexible NPU abstraction called vNPU, which\nenables fine-grained virtualization of the heterogeneous compute units in a\nphysical NPU (pNPU); (2) a vNPU resource allocator that enables pay-as-you-go\ncomputing model and flexible vNPU-to-pNPU mappings for improved resource\nutilization and cost-effectiveness; (3) an ISA extension of modern NPU\narchitecture for facilitating fine-grained tensor operator scheduling for\nmultiple vNPUs. We implement Neu10 based on a production-level NPU simulator.\nOur experiments show that Neu10 improves the throughput of ML inference\nservices by up to 1.4$\\times$ and reduces the tail latency by up to\n4.6$\\times$, while improving the NPU utilization by 1.2$\\times$ on average,\ncompared to state-of-the-art NPU sharing approaches.",
      "tldr_zh": "本文提出 Neu10，一种硬件辅助的 NPU 虚拟化框架，旨在优化云平台上神经处理单元 (NPUs) 的资源共享，以支持多租户机器学习 (ML) 推理服务。Neu10 包括 vNPU 抽象实现细粒度虚拟化、vNPU 资源分配器支持按需付费和灵活映射，以及对 NPU 架构的 ISA 扩展以实现高效的操作调度。实验结果显示，Neu10 相较于现有方法，提高 ML 推理服务的吞吐量最多 1.4 倍、减少尾部延迟最多 4.6 倍，并平均提升 NPU 利用率 1.2 倍。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.OS"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted to MICRO'24",
      "pdf_url": "http://arxiv.org/pdf/2408.04104v3",
      "published_date": "2024-08-07 21:45:01 UTC",
      "updated_date": "2024-09-13 02:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:26:22.001904"
    },
    {
      "arxiv_id": "2408.04102v3",
      "title": "ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling",
      "title_zh": "ArtVLM：通过基于视觉的前缀语言建模进行属性识别",
      "authors": [
        "William Yicheng Zhu",
        "Keren Ye",
        "Junjie Ke",
        "Jiahui Yu",
        "Leonidas Guibas",
        "Peyman Milanfar",
        "Feng Yang"
      ],
      "abstract": "Recognizing and disentangling visual attributes from objects is a foundation\nto many computer vision applications. While large vision language\nrepresentations like CLIP had largely resolved the task of zero-shot object\nrecognition, zero-shot visual attribute recognition remains a challenge because\nCLIP's contrastively-learned vision-language representation cannot effectively\ncapture object-attribute dependencies. In this paper, we target this weakness\nand propose a sentence generation-based retrieval formulation for attribute\nrecognition that is novel in 1) explicitly modeling a to-be-measured and\nretrieved object-attribute relation as a conditional probability graph, which\nconverts the recognition problem into a dependency-sensitive language-modeling\nproblem, and 2) applying a large pretrained Vision-Language Model (VLM) on this\nreformulation and naturally distilling its knowledge of image-object-attribute\nrelations to use towards attribute recognition. Specifically, for each\nattribute to be recognized on an image, we measure the visual-conditioned\nprobability of generating a short sentence encoding the attribute's relation to\nobjects on the image. Unlike contrastive retrieval, which measures likelihood\nby globally aligning elements of the sentence to the image, generative\nretrieval is sensitive to the order and dependency of objects and attributes in\nthe sentence. We demonstrate through experiments that generative retrieval\nconsistently outperforms contrastive retrieval on two visual reasoning\ndatasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual\nGenome Attribute Ranking (VGARank).",
      "tldr_zh": "该论文针对零样本视觉属性识别的挑战，指出如 CLIP 之类的对比学习模型无法有效捕捉对象-属性依赖关系。作者提出 ArtVLM 方法，通过基于视觉的前缀语言建模，将属性识别转化为依赖敏感的语言建模问题，并使用预训练的 Vision-Language Model (VLM) 来测量视觉条件下的句子生成概率，以显式建模对象-属性关系。实验结果显示，生成式检索在 Visual Attribute in the Wild (VAW) 和 Visual Genome Attribute Ranking (VGARank) 数据集上优于对比式检索，证明了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024. Contact: zhuwilliam[at]google[dot]com. GitHub:\n  https://github.com/google-research/google-research/tree/master/attribute_with_prefixlm",
      "pdf_url": "http://arxiv.org/pdf/2408.04102v3",
      "published_date": "2024-08-07 21:44:29 UTC",
      "updated_date": "2024-10-02 12:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:26:32.494355"
    },
    {
      "arxiv_id": "2408.04675v1",
      "title": "ACL Ready: RAG Based Assistant for the ACL Checklist",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Galarnyk",
        "Rutwik Routu",
        "Kosha Bheda",
        "Priyanshu Mehta",
        "Agam Shah",
        "Sudheer Chava"
      ],
      "abstract": "The ARR Responsible NLP Research checklist website states that the \"checklist\nis designed to encourage best practices for responsible research, addressing\nissues of research ethics, societal impact and reproducibility.\" Answering the\nquestions is an opportunity for authors to reflect on their work and make sure\nany shared scientific assets follow best practices. Ideally, considering the\nchecklist before submission can favorably impact the writing of a research\npaper. However, the checklist is often filled out at the last moment. In this\nwork, we introduce ACLReady, a retrieval-augmented language model application\nthat can be used to empower authors to reflect on their work and assist authors\nwith the ACL checklist. To test the effectiveness of the system, we conducted a\nqualitative study with 13 users which shows that 92% of users found the\napplication useful and easy to use as well as 77% of the users found that the\napplication provided the information they expected. Our code is publicly\navailable under the CC BY-NC 4.0 license on GitHub.",
      "tldr_zh": "本研究针对 ACL 的 ARR Responsible NLP Research Checklist，提出了一种基于 RAG（Retrieval-Augmented Generation）的语言模型应用 ACLReady，以帮助作者反思研究实践、提升研究伦理、社会影响和可重复性。ACLReady 旨在鼓励作者在提交前主动使用检查表，通过检索增强技术提供相关指导和支持。定性研究涉及 13 名用户，结果显示 92% 的用户认为该应用有用且易用，77% 的用户表示它提供了预期的信息。该系统的代码已在 GitHub 上以 CC BY-NC 4.0 许可公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04675v1",
      "published_date": "2024-08-07 21:07:13 UTC",
      "updated_date": "2024-08-07 21:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:26:46.071309"
    },
    {
      "arxiv_id": "2408.07220v1",
      "title": "Handwritten Code Recognition for Pen-and-Paper CS Education",
      "title_zh": "纸笔计算机科学教育中的手写代码识别",
      "authors": [
        "Md Sazzad Islam",
        "Moussa Koulako Bala Doumbouya",
        "Christopher D. Manning",
        "Chris Piech"
      ],
      "abstract": "Teaching Computer Science (CS) by having students write programs by hand on\npaper has key pedagogical advantages: It allows focused learning and requires\ncareful thinking compared to the use of Integrated Development Environments\n(IDEs) with intelligent support tools or \"just trying things out\". The familiar\nenvironment of pens and paper also lessens the cognitive load of students with\nno prior experience with computers, for whom the mere basic usage of computers\ncan be intimidating. Finally, this teaching approach opens learning\nopportunities to students with limited access to computers.\n  However, a key obstacle is the current lack of teaching methods and support\nsoftware for working with and running handwritten programs. Optical character\nrecognition (OCR) of handwritten code is challenging: Minor OCR errors, perhaps\ndue to varied handwriting styles, easily make code not run, and recognizing\nindentation is crucial for languages like Python but is difficult to do due to\ninconsistent horizontal spacing in handwriting. Our approach integrates two\ninnovative methods. The first combines OCR with an indentation recognition\nmodule and a language model designed for post-OCR error correction without\nintroducing hallucinations. This method, to our knowledge, surpasses all\nexisting systems in handwritten code recognition. It reduces error from 30\\% in\nthe state of the art to 5\\% with minimal hallucination of logical fixes to\nstudent programs. The second method leverages a multimodal language model to\nrecognize handwritten programs in an end-to-end fashion. We hope this\ncontribution can stimulate further pedagogical research and contribute to the\ngoal of making CS education universally accessible. We release a dataset of\nhandwritten programs and code to support future research at\nhttps://github.com/mdoumbouya/codeocr",
      "tldr_zh": "该论文探讨了用纸笔教授计算机科学（CS）的教育优势，如降低初学者认知负担和提升可访问性，但面临手写代码识别的挑战，包括OCR错误和缩进识别难题。研究提出两种创新方法：第一种结合OCR、缩进识别模块和语言模型进行后处理错误修正，显著降低错误率从30%降至5%，并最小化幻觉；第二种利用多模态语言模型实现端到端的手写代码识别。论文贡献包括发布手写程序数据集和代码（https://github.com/mdoumbouya/codeocr），以推动CS教育的普适性和进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07220v1",
      "published_date": "2024-08-07 21:02:17 UTC",
      "updated_date": "2024-08-07 21:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:26:58.390788"
    },
    {
      "arxiv_id": "2408.04072v1",
      "title": "AEye: A Visualization Tool for Image Datasets",
      "title_zh": "AEye：图像数据集的可视化工具",
      "authors": [
        "Florian Grötschla",
        "Luca A. Lanzendörfer",
        "Marco Calzavara",
        "Roger Wattenhofer"
      ],
      "abstract": "Image datasets serve as the foundation for machine learning models in\ncomputer vision, significantly influencing model capabilities, performance, and\nbiases alongside architectural considerations. Therefore, understanding the\ncomposition and distribution of these datasets has become increasingly crucial.\nTo address the need for intuitive exploration of these datasets, we propose\nAEye, an extensible and scalable visualization tool tailored to image datasets.\nAEye utilizes a contrastively trained model to embed images into semantically\nmeaningful high-dimensional representations, facilitating data clustering and\norganization. To visualize the high-dimensional representations, we project\nthem onto a two-dimensional plane and arrange images in layers so users can\nseamlessly navigate and explore them interactively. AEye facilitates semantic\nsearch functionalities for both text and image queries, enabling users to\nsearch for content. We open-source the codebase for AEye, and provide a simple\nconfiguration to add datasets.",
      "tldr_zh": "该论文提出 AEye，一种可扩展且可扩展的图像数据集可视化工具，用于帮助用户直观地探索数据集的组成和分布。AEye 采用对比训练模型将图像嵌入到语义上有意义的高维表示中，并通过投影到二维平面并分层排列图像，实现交互式导航和探索。工具还支持文本和图像查询的语义搜索功能，便于用户快速查找内容。作为开源项目，AEye 提供简单配置选项，允许轻松添加新数据集，从而提升计算机视觉研究的效率和洞察力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at IEEE VIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04072v1",
      "published_date": "2024-08-07 20:19:20 UTC",
      "updated_date": "2024-08-07 20:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:27:08.107077"
    },
    {
      "arxiv_id": "2408.04068v1",
      "title": "Digital Avatars: Framework Development and Their Evaluation",
      "title_zh": "数字虚拟化身：框架开发及其评估",
      "authors": [
        "Timothy Rupprecht",
        "Sung-En Chang",
        "Yushu Wu",
        "Lei Lu",
        "Enfu Nan",
        "Chih-hsiang Li",
        "Caiyue Lai",
        "Zhimin Li",
        "Zhijun Hu",
        "Yumei He",
        "David Kaeli",
        "Yanzhi Wang"
      ],
      "abstract": "We present a novel prompting strategy for artificial intelligence driven\ndigital avatars. To better quantify how our prompting strategy affects\nanthropomorphic features like humor, authenticity, and favorability we present\nCrowd Vote - an adaptation of Crowd Score that allows for judges to elect a\nlarge language model (LLM) candidate over competitors answering the same or\nsimilar prompts. To visualize the responses of our LLM, and the effectiveness\nof our prompting strategy we propose an end-to-end framework for creating\nhigh-fidelity artificial intelligence (AI) driven digital avatars. This\npipeline effectively captures an individual's essence for interaction and our\nstreaming algorithm delivers a high-quality digital avatar with real-time\naudio-video streaming from server to mobile device. Both our visualization\ntool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have\nstate-of-the-art humor, authenticity, and favorability outperforming all\ncompetitors and baselines. In the case of our Donald Trump and Joe Biden\navatars, their authenticity and favorability are rated higher than even their\nreal-world equivalents.",
      "tldr_zh": "本研究提出了一种新型提示策略(prompting strategy)，用于提升AI驱动数字头像(avatars)的拟人特征，如幽默、真实性和受欢迎度，并引入Crowd Vote评估方法，让评委通过选举LLM候选者来量化这些特征。研究开发了一个端到端框架，包括捕获个体本质的流水线和实时音频-视频流媒体算法，支持从服务器到移动设备的交互。实验结果显示，该框架创建的AI数字头像在幽默、真实性和受欢迎度上超越所有竞争对手和基线，甚至在唐纳德·特朗普(Donald Trump)和乔·拜登(Joe Biden)头像的案例中，其真实性和受欢迎度高于真实人物。",
      "categories": [
        "cs.AI",
        "68",
        "D.2.2; C.3"
      ],
      "primary_category": "cs.AI",
      "comment": "This work was presented during the IJCAI 2024 conference proceedings\n  for demonstrations",
      "pdf_url": "http://arxiv.org/pdf/2408.04068v1",
      "published_date": "2024-08-07 20:09:47 UTC",
      "updated_date": "2024-08-07 20:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:27:20.673834"
    },
    {
      "arxiv_id": "2408.12603v1",
      "title": "Sleeper Social Bots: a new generation of AI disinformation bots are already a political threat",
      "title_zh": "翻译失败",
      "authors": [
        "Jaiv Doshi",
        "Ines Novacic",
        "Curtis Fletcher",
        "Mats Borges",
        "Elea Zhong",
        "Mark C. Marino",
        "Jason Gan",
        "Sophia Mager",
        "Dane Sprague",
        "Melinda Xia"
      ],
      "abstract": "This paper presents a study on the growing threat of \"sleeper social bots,\"\nAI-driven social bots in the political landscape, created to spread\ndisinformation and manipulate public opinion. We based the name sleeper social\nbots on their ability to pass as humans on social platforms, where they're\nembedded like political \"sleeper\" agents, making them harder to detect and more\ndisruptive. To illustrate the threat these bots pose, our research team at the\nUniversity of Southern California constructed a demonstration using a private\nMastodon server, where ChatGPT-driven bots, programmed with distinct\npersonalities and political viewpoints, engaged in discussions with human\nparticipants about a fictional electoral proposition. Our preliminary findings\nsuggest these bots can convincingly pass as human users, actively participate\nin conversations, and effectively disseminate disinformation. Moreover, they\ncan adapt their arguments based on the responses of human interlocutors,\nshowcasing their dynamic and persuasive capabilities. College students\nparticipating in initial experiments failed to identify our bots, underscoring\nthe urgent need for increased awareness and education about the dangers of\nAI-driven disinformation, and in particular, disinformation spread by bots. The\nimplications of our research point to the significant challenges posed by\nsocial bots in the upcoming 2024 U.S. presidential election and beyond.",
      "tldr_zh": "本研究探讨了“sleeper social bots”这种新型AI驱动的社交机器人，它们伪装成人类以传播虚假信息（disinformation）和操纵公众意见，尤其在政治领域构成重大威胁。该团队通过在私人Mastodon服务器上构建演示系统，使用ChatGPT驱动的机器人赋予不同个性和政治观点，与人类参与者讨论虚构选举议题，展示了这些机器人能积极参与对话、适应性调整论点并成功规避识别。实验结果显示，参与者如大学生无法辨别这些bots，突显了AI-driven disinformation的紧急风险，并强调需要加强教育以应对2024年美国总统选举等事件的潜在挑战。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12603v1",
      "published_date": "2024-08-07 19:57:10 UTC",
      "updated_date": "2024-08-07 19:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:27:32.426990"
    },
    {
      "arxiv_id": "2408.04057v3",
      "title": "PowerPM: Foundation Model for Power Systems",
      "title_zh": "PowerPM：电力系统的基础模型",
      "authors": [
        "Shihao Tu",
        "Yupeng Zhang",
        "Jing Zhang",
        "Zhendong Fu",
        "Yin Zhang",
        "Yang Yang"
      ],
      "abstract": "The emergence of abundant electricity time series (ETS) data provides ample\nopportunities for various applications in the power systems, including\ndemand-side management, grid stability, and consumer behavior analysis. Deep\nlearning models have advanced ETS modeling by effectively capturing sequence\ndependence. Nevertheless, learning a generic representation of ETS data for\nvarious applications remains challenging due to the inherently complex\nhierarchical structure of ETS data. Moreover, ETS data exhibits intricate\ntemporal dependencies and is suscepti ble to the influence of exogenous\nvariables. Furthermore, different instances exhibit diverse electricity\nconsumption behavior. In this paper, we propose a foundation model PowerPM to\nmodel ETS data, providing a large-scale, off-the-shelf model for power systems.\nPowerPM consists of a temporal encoder and a hierarchical encoder. The temporal\nencoder captures both temporal dependencies in ETS data, considering exogenous\nvariables. The hierarchical encoder models the correlation between hierarchy.\nFurthermore, PowerPM leverages a novel self-supervised pretraining framework\nconsisting of masked ETS modeling and dual-view contrastive learning, which\nenable PowerPM to capture temporal dependency within ETS windows and aware the\ndiscrepancy across ETS windows, providing two different perspectives to learn\ngeneric representation. Our experiments involve five real world scenario\ndatasets, comprising private and public data. Through pre-training on massive\nETS data, PowerPM achieves SOTA performance on diverse downstream tasks within\nthe private dataset. Impressively, when transferred to the public datasets,\nPowerPM maintains its superiority, showcasing its remarkable generalization\nability across various tasks and domains. Moreover, ablation studies, few-shot\nexperiments provide additional evidence of the effectiveness of our model.",
      "tldr_zh": "本文提出PowerPM，一种针对电力时间序列(ETS)数据的电力系统基础模型，旨在处理ETS数据的复杂层次结构、时间依赖和外生变量影响。PowerPM由时间编码器（捕捉时间依赖）和层次编码器（建模层次相关性）组成，并采用masked ETS modeling和dual-view contrastive learning的自监督预训练框架，以学习通用表示。在五个真实场景数据集上的实验中，PowerPM实现了SOTA性能，并展示了出色的泛化能力，尤其在跨域转移任务中保持优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 5 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.04057v3",
      "published_date": "2024-08-07 19:39:37 UTC",
      "updated_date": "2024-10-03 14:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:27:45.121624"
    },
    {
      "arxiv_id": "2408.04055v2",
      "title": "Machine Learning-Based Reward-Driven Tuning of Scanning Probe Microscopy: Towards Fully Automated Microscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Liu",
        "Roger Proksch",
        "Jason Bemis",
        "Utkarsh Pratiush",
        "Astita Dubey",
        "Mahshid Ahmadi",
        "Reece Emery",
        "Philip D. Rack",
        "Yu-Chen Liu",
        "Jan-Chi Yang",
        "Sergei V. Kalinin"
      ],
      "abstract": "Since the dawn of scanning probe microscopy (SPM), tapping or intermittent\ncontact mode has been one of the most widely used imaging modes. Manual\noptimization of tapping mode not only takes a lot of instrument and operator\ntime, but also often leads to frequent probe and sample damage, poor image\nquality and reproducibility issues for new types of samples or inexperienced\nusers. Despite wide use, optimization of tapping mode imaging is an extremely\nhard problem, ill-suited to either classical control methods or machine\nlearning. Here we introduce a reward-driven workflow to automate the\noptimization of SPM in the tapping mode. The reward function is defined based\non multiple channels with physical and empirical knowledge of good scans\nencoded, representing a sample-agnostic measure of image quality and imitating\nthe decision-making logic employed by human operators. This automated workflow\ngives optimal scanning parameters for different probes and samples and gives\nhigh-quality SPM images consistently in the attractive mode. This study\nbroadens the application and accessibility of SPM and opens the door for fully\nautomated SPM.",
      "tldr_zh": "本研究针对扫描探针显微镜(SPM)的敲击模式优化问题，提出了一种基于机器学习的奖励驱动工作流程，以自动化调优过程，避免手动操作带来的时间消耗、探针样本损坏和图像质量问题。奖励函数通过整合多通道的物理和经验知识，模拟人类操作者的决策逻辑，提供样本无关的图像质量评估。实验结果显示，该工作流程能为不同探针和样本生成最佳扫描参数，确保在敲击模式下获得一致的高质量图像，从而扩展SPM的应用范围并推动完全自动化的显微镜技术。",
      "categories": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mes-hall",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04055v2",
      "published_date": "2024-08-07 19:34:42 UTC",
      "updated_date": "2024-12-25 19:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:27:59.427771"
    },
    {
      "arxiv_id": "2408.04054v2",
      "title": "PLANRL: A Motion Planning and Imitation Learning Framework to Bootstrap Reinforcement Learning",
      "title_zh": "PLANRL：",
      "authors": [
        "Amisha Bhaskar",
        "Zahiruddin Mahammad",
        "Sachin R Jadhav",
        "Pratap Tokekar"
      ],
      "abstract": "Reinforcement Learning (RL) has shown remarkable progress in simulation\nenvironments, yet its application to real-world robotic tasks remains limited\ndue to challenges in exploration and generalization. To address these issues,\nwe introduce PLANRL, a framework that chooses when the robot should use\nclassical motion planning and when it should learn a policy. To further improve\nthe efficiency in exploration, we use imitation data to bootstrap the\nexploration. PLANRL dynamically switches between two modes of operation:\nreaching a waypoint using classical techniques when away from the objects and\nreinforcement learning for fine-grained manipulation control when about to\ninteract with objects. PLANRL architecture is composed of ModeNet for mode\nclassification, NavNet for waypoint prediction, and InteractNet for precise\nmanipulation. By combining the strengths of RL and Imitation Learning (IL),\nPLANRL improves sample efficiency and mitigates distribution shift, ensuring\nrobust task execution. We evaluate our approach across multiple challenging\nsimulation environments and real-world tasks, demonstrating superior\nperformance in terms of adaptability, efficiency, and generalization compared\nto existing methods. In simulations, PLANRL surpasses baseline methods by\n10-15\\% in training success rates at 30k samples and by 30-40\\% during\nevaluation phases. In real-world scenarios, it demonstrates a 30-40\\% higher\nsuccess rate on simpler tasks compared to baselines and uniquely succeeds in\ncomplex, two-stage manipulation tasks. Datasets and supplementary materials can\nbe found on our {https://raaslab.org/projects/NAVINACT/}.",
      "tldr_zh": "本研究提出PLANRL框架，通过结合运动规划（motion planning）和模仿学习（Imitation Learning, IL）来引导强化学习（Reinforcement Learning, RL），以解决RL在真实机器人任务中面临的探索和泛化挑战。该框架动态切换两种模式：在远离物体时使用经典技术到达航点（waypoint），而在接近物体时采用RL进行精细操控，并利用IL数据提升探索效率；架构包括ModeNet负责模式分类、NavNet预测航点，以及InteractNet处理精确操控。通过这种整合，PLANRL显著提高了样本效率并缓解了分布偏移。在模拟和真实环境中，PLANRL在训练成功率上比基线方法高10-15%（30k样本时），评估阶段高30-40%，并在复杂任务中表现出30-40%的成功率提升，展示了更好的适应性和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04054v2",
      "published_date": "2024-08-07 19:30:08 UTC",
      "updated_date": "2024-10-17 00:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:28:10.637064"
    },
    {
      "arxiv_id": "2408.04046v1",
      "title": "Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Aida Afshar",
        "Aldo Pacchiano"
      ],
      "abstract": "The performance of reinforcement learning (RL) algorithms is sensitive to the\nchoice of hyperparameters, with the learning rate being particularly\ninfluential. RL algorithms fail to reach convergence or demand an extensive\nnumber of samples when the learning rate is not optimally set. In this work, we\nshow that model selection can help to improve the failure modes of RL that are\ndue to suboptimal choices of learning rate. We present a model selection\nframework for Learning Rate-Free Reinforcement Learning that employs model\nselection methods to select the optimal learning rate on the fly. This approach\nof adaptive learning rate tuning neither depends on the underlying RL algorithm\nnor the optimizer and solely uses the reward feedback to select the learning\nrate; hence, the framework can input any RL algorithm and produce a learning\nrate-free version of it. We conduct experiments for policy optimization methods\nand evaluate various model selection strategies within our framework. Our\nresults indicate that data-driven model selection algorithms are better\nalternatives to standard bandit algorithms when the optimal choice of\nhyperparameter is time-dependent and non-stationary.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）算法对学习率的高度敏感性问题，指出不合适的学习率会导致算法无法收敛或需要更多样本。作者提出一个模型选择框架，用于实现 Learning Rate-Free Reinforcement Learning，通过动态选择最优学习率，仅依赖奖励反馈，而不依赖特定RL算法或优化器。实验结果表明，在策略优化方法上，数据驱动的模型选择策略比标准Bandit算法更有效，尤其适用于时间相关的非-stationary objectives场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC 2024 Workshop on Failure Modes of Sequential Decision-Making in\n  Practice",
      "pdf_url": "http://arxiv.org/pdf/2408.04046v1",
      "published_date": "2024-08-07 18:55:58 UTC",
      "updated_date": "2024-08-07 18:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:28:22.042805"
    },
    {
      "arxiv_id": "2408.04026v1",
      "title": "Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Cameron",
        "Jiaee Cheong",
        "Micol Spitale",
        "Hatice Gunes"
      ],
      "abstract": "Social agents and robots are increasingly being used in wellbeing settings.\nHowever, a key challenge is that these agents and robots typically rely on\nmachine learning (ML) algorithms to detect and analyse an individual's mental\nwellbeing. The problem of bias and fairness in ML algorithms is becoming an\nincreasingly greater source of concern. In concurrence, existing literature has\nalso indicated that mental health conditions can manifest differently across\ngenders and cultures. We hypothesise that the representation of features\n(acoustic, textual, and visual) and their inter-modal relations would vary\namong subjects from different cultures and genders, thus impacting the\nperformance and fairness of various ML models. We present the very first\nevaluation of multimodal gender fairness in depression manifestation by\nundertaking a study on two different datasets from the USA and China. We\nundertake thorough statistical and ML experimentation and repeat the\nexperiments for several different algorithms to ensure that the results are not\nalgorithm-dependent. Our findings indicate that though there are differences\nbetween both datasets, it is not conclusive whether this is due to the\ndifference in depression manifestation as hypothesised or other external\nfactors such as differences in data collection methodology. Our findings\nfurther motivate a call for a more consistent and culturally aware data\ncollection process in order to address the problem of ML bias in depression\ndetection and to promote the development of fairer agents and robots for\nwellbeing.",
      "tldr_zh": "该研究探讨了多模态性别公平在抑郁预测中的问题，假设声学、文本和视觉特征及其相互关系会因文化（如美国和中国数据集）和性别差异而变化，从而影响机器学习（ML）算法的表现和公平性。研究者首次对两个数据集进行了全面统计和ML实验，使用多种算法以验证结果的普适性。结果显示，虽然两个数据集存在差异，但无法确定这是抑郁表现差异所致，还是数据收集方法等外部因素；因此，呼吁采用更一致且文化敏感的数据收集过程，以减少ML偏见并开发更公平的心理健康代理和机器人。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "9 Pages, 7 Tables. To be published and indexed in the IEEE Xplore\n  Digital Library under the ACII 2024 Workshop Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.04026v1",
      "published_date": "2024-08-07 18:19:18 UTC",
      "updated_date": "2024-08-07 18:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:28:33.990878"
    },
    {
      "arxiv_id": "2408.04023v1",
      "title": "Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity",
      "title_zh": "翻译失败",
      "authors": [
        "Wrick Talukdar",
        "Anjanava Biswas"
      ],
      "abstract": "As Large Language Models (LLMs) become increasingly sophisticated and\nubiquitous in natural language processing (NLP) applications, ensuring their\nrobustness, trustworthiness, and alignment with human values has become a\ncritical challenge. This paper presents a novel framework for contextual\ngrounding in textual models, with a particular emphasis on the Context\nRepresentation stage. Our approach aims to enhance the reliability and ethical\nalignment of these models through a comprehensive, context-aware methodology.\nBy explicitly capturing and representing relevant situational, cultural, and\nethical contexts in a machine-readable format, we lay the foundation for\nanchoring a model's behavior within these contexts. Our approach leverages\ntechniques from knowledge representation and reasoning, such as ontologies,\nsemantic web technologies, and logic-based formalisms. We evaluate our\nframework on real-world textual datasets, demonstrating its effectiveness in\nimproving model performance, fairness, and alignment with human expectations,\nwhile maintaining high accuracy. Furthermore, we discuss the other key\ncomponents of the framework, including context-aware encoding, context-aware\nlearning, interpretability and explainability, and continuous monitoring and\nadaptation. This research contributes to the growing body of work on\nresponsible AI, offering a practical approach to developing more reliable,\ntrustworthy, and ethically-aligned language models. Our findings have\nsignificant implications for the deployment of LLMs in sensitive domains such\nas healthcare, legal systems, and social services, where contextual\nunderstanding is paramount.",
      "tldr_zh": "本研究提出了一种系统框架，通过上下文感知 grounding（context-aware grounding）来提升 Large Language Models (LLMs) 的可靠性、真实性和与人类价值观的 alignment。该框架特别强调 Context Representation 阶段，通过捕捉情境、文化和道德上下文，并利用 ontologies、semantic web technologies 和 logic-based formalisms 等技术，将这些信息以机器可读格式表示，从而优化模型行为。在真实数据集上的评估显示，该方法显著提高了模型性能、公平性和与人类期望的契合度，同时保持高准确性。该框架还包括 context-aware encoding、learning、interpretability 和持续监控等组件，为负责 AI 的发展提供实用路径，尤其适用于医疗、法律和社会服务等敏感领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04023v1",
      "published_date": "2024-08-07 18:12:02 UTC",
      "updated_date": "2024-08-07 18:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:28:46.549086"
    },
    {
      "arxiv_id": "2408.07081v3",
      "title": "MathBridge: A Large Corpus Dataset for Translating Spoken Mathematical Expressions into $LaTeX$ Formulas for Improved Readability",
      "title_zh": "翻译失败",
      "authors": [
        "Kyudan Jung",
        "Sieun Hyeon",
        "Jeong Youn Kwon",
        "Nam-Joon Kim",
        "Hyun Gon Ryu",
        "Hyuk-Jae Lee",
        "Jaeyoung Do"
      ],
      "abstract": "Improving the readability of mathematical expressions in text-based document\nsuch as subtitle of mathematical video, is an significant task. To achieve\nthis, mathematical expressions should be convert to compiled formulas. For\ninstance, the spoken expression ``x equals minus b plus or minus the square\nroot of b squared minus four a c, all over two a'' from automatic speech\nrecognition is more readily comprehensible when displayed as a compiled formula\n$x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$. To convert mathematical spoken\nsentences to compiled formulas, two processes are required: spoken sentences\nare converted into LaTeX formulas, and LaTeX formulas are converted into\ncompiled formulas. The latter can be managed by using LaTeX engines. However,\nthere is no way to do the former effectively. Even if we try to solve this\nusing language models, there is no paired data between spoken sentences and\nLaTeX formulas to train it. In this paper, we introduce MathBridge, the first\nextensive dataset for translating mathematical spoken sentences into LaTeX\nformulas. MathBridge comprises approximately 23 million LaTeX formulas paired\nwith the corresponding mathematical spoken sentences. Through comprehensive\nevaluations, including fine-tuning with proposed data, we discovered that\nMathBridge significantly enhances the capabilities of pretrained language\nmodels for converting to LaTeX formulas from mathematical spoken sentences.\nSpecifically, for the T5-large model, the sacreBLEU score increased from 4.77\nto 46.8, demonstrating substantial enhancement.",
      "tldr_zh": "该论文介绍了MathBridge数据集，这是一个大规模语料库，包含约2300万对口头数学表达和对应的LaTeX公式，用于提高数学表达式在文本文档（如视频字幕）中的可读性。MathBridge解决了现有语言模型缺乏配对数据的问题，通过将口头句子转换为LaTeX公式来支持模型训练。实验结果显示，在T5-large模型上进行微调后，sacreBLEU分数从4.77大幅提升至46.8，证明了该数据集显著增强了模型的转换能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07081v3",
      "published_date": "2024-08-07 18:07:15 UTC",
      "updated_date": "2024-08-16 09:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:28:57.424202"
    },
    {
      "arxiv_id": "2408.03936v1",
      "title": "SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature",
      "title_zh": "翻译失败",
      "authors": [
        "Vinícius Di Oliveira",
        "Yuri Façanha Bezerra",
        "Li Weigang",
        "Pedro Carvalho Brom",
        "Victor Rafael R. Celestino"
      ],
      "abstract": "Natural language processing (NLP) has seen significant advancements with the\nadvent of large language models (LLMs). However, substantial improvements are\nstill needed for languages other than English, especially for specific domains\nlike the applications of Mercosur Common Nomenclature (NCM), a Brazilian\nHarmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a\nfoundational Portuguese LLM, as an LLM source to implement the NCM application\nprocessing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)\ntechnique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.\nThis approach retains the chain-of-thought (CoT) methodology for prompt\ndevelopment in a more concise and streamlined manner, utilizing brief and\nfocused documents for training. The proposed model demonstrates an efficient\nand cost-effective alternative for fine-tuning smaller LLMs, significantly\noutperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the\nresearch focuses on NCM applications, the methodology can be easily adapted for\nHS applications worldwide.",
      "tldr_zh": "本研究针对自然语言处理(NLP)中非英语语言，尤其是Mercosur Common Nomenclature (NCM)领域的性能不足，提出了一种新型细调方法SLIM-RAFT。SLIM-RAFT基于TeenyTineLLaMA作为基础模型，简化了Retrieval-Augmented Fine-Tuning (RAFT)技术，同时保留chain-of-thought (CoT)方法，但采用更简洁的提示和简短文档进行训练。该方法显著提高了NCM应用处理效率，并展示了成本效益，在相关任务中优于TeenyTineLLaMA和ChatGPT-4。尽管专注于NCM，该方法易于扩展至全球Harmonized System (HS)应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 1 figure, to be publish in International Conference on Web\n  Information Systems and Technologies - WEBIST 2024 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.03936v1",
      "published_date": "2024-08-07 17:54:21 UTC",
      "updated_date": "2024-08-07 17:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:29:11.163481"
    },
    {
      "arxiv_id": "2408.04673v1",
      "title": "AutoFAIR : Automatic Data FAIRification via Machine Reading",
      "title_zh": "翻译失败",
      "authors": [
        "Tingyan Ma",
        "Wei Liu",
        "Bin Lu",
        "Xiaoying Gan",
        "Yunqiang Zhu",
        "Luoyi Fu",
        "Chenghu Zhou"
      ],
      "abstract": "The explosive growth of data fuels data-driven research, facilitating\nprogress across diverse domains. The FAIR principles emerge as a guiding\nstandard, aiming to enhance the findability, accessibility, interoperability,\nand reusability of data. However, current efforts primarily focus on manual\ndata FAIRification, which can only handle targeted data and lack efficiency. To\naddress this issue, we propose AutoFAIR, an architecture designed to enhance\ndata FAIRness automately. Firstly, We align each data and metadata operation\nwith specific FAIR indicators to guide machine-executable actions. Then, We\nutilize Web Reader to automatically extract metadata based on language models,\neven in the absence of structured data webpage schemas. Subsequently, FAIR\nAlignment is employed to make metadata comply with FAIR principles by ontology\nguidance and semantic matching. Finally, by applying AutoFAIR to various data,\nespecially in the field of mountain hazards, we observe significant\nimprovements in findability, accessibility, interoperability, and reusability\nof data. The FAIRness scores before and after applying AutoFAIR indicate\nenhanced data value.",
      "tldr_zh": "论文提出 AutoFAIR，一种通过 Machine Reading 自动实现数据 FAIRification 的架构，旨在解决手动方法效率低和针对性不足的问题。AutoFAIR 将数据和元数据操作与 FAIR 指标（findability, accessibility, interoperability, and reusability）对齐，指导机器执行相关动作；并使用 Web Reader 基于语言模型自动提取元数据，即使缺乏结构化网页模式。随后，通过 FAIR Alignment 结合本体指导和语义匹配，使元数据符合 FAIR 原则。在山地灾害等领域应用后，实验显示数据的 FAIRness 评分显著提升，增强了数据的价值和可重用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04673v1",
      "published_date": "2024-08-07 17:36:58 UTC",
      "updated_date": "2024-08-07 17:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:29:22.580620"
    },
    {
      "arxiv_id": "2408.11843v2",
      "title": "Identifying and Mitigating Social Bias Knowledge in Language Models",
      "title_zh": "识别与缓解语言模型中的社会偏见知识",
      "authors": [
        "Ruizhe Chen",
        "Yichen Li",
        "Jianfei Yang",
        "Joey Tianyi Zhou",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "abstract": "Generating fair and accurate predictions plays a pivotal role in deploying\nlarge language models (LLMs) in the real world. However, existing debiasing\nmethods inevitably generate unfair or incorrect predictions as they are\ndesigned and evaluated to achieve parity across different social groups but\nleave aside individual commonsense facts, resulting in modified knowledge that\nelicits unreasonable or undesired predictions. In this paper, we first\nestablish a new bias mitigation benchmark, BiaScope, which systematically\nassesses performance by leveraging newly constructed datasets and metrics on\nknowledge retention and generalization. Then, we propose a novel debiasing\napproach, Fairness Stamp (FAST), which enables fine-grained calibration of\nindividual social biases. FAST identifies the decisive layer responsible for\nstoring social biases and then calibrates its outputs by integrating a small\nmodular network, considering both bias mitigation and knowledge-preserving\ndemands. Comprehensive experiments demonstrate that FAST surpasses\nstate-of-the-art baselines with superior debiasing performance while not\ncompromising the overall model capability for knowledge retention and\ndownstream predictions. This highlights the potential of fine-grained debiasing\nstrategies to achieve fairness in LLMs.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)中的社会偏见问题，指出现有 debiasing 方法在追求群体公平性时往往忽略个人常识事实，导致不准确预测。研究者建立了新的基准 BiaScope，通过构建数据集和指标来系统评估 debiasing 的知识保留和泛化性能。论文提出了一种创新方法 Fairness Stamp (FAST)，它识别存储偏见的决定性层，并通过整合小型模块网络进行细粒度校准，以平衡偏见缓解和知识保留需求。实验结果表明，FAST 优于现有最先进基线，在 debiasing 性能上显著提升，同时维持了模型的整体能力和下游预测准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Findings. arXiv admin note: substantial text overlap with\n  arXiv:2405.09341",
      "pdf_url": "http://arxiv.org/pdf/2408.11843v2",
      "published_date": "2024-08-07 17:14:58 UTC",
      "updated_date": "2025-02-27 10:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:29:34.033727"
    },
    {
      "arxiv_id": "2408.03910v2",
      "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases",
      "title_zh": "CodexGraph：通过代码图数据库桥接大语言模型和代码仓库",
      "authors": [
        "Xiangyan Liu",
        "Bo Lan",
        "Zhiyuan Hu",
        "Yang Liu",
        "Zhicheng Zhang",
        "Fei Wang",
        "Michael Shieh",
        "Wenmeng Zhou"
      ],
      "abstract": "Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval\nand MBPP, but struggle with handling entire code repositories. This challenge\nhas prompted research on enhancing LLM-codebase interaction at a repository\nscale. Current solutions rely on similarity-based retrieval or manual tools and\nAPIs, each with notable drawbacks. Similarity-based retrieval often has low\nrecall in complex tasks, while manual tools and APIs are typically\ntask-specific and require expert knowledge, reducing their generalizability\nacross diverse code tasks and real-world applications. To mitigate these\nlimitations, we introduce CodexGraph, a system that integrates LLM agents with\ngraph database interfaces extracted from code repositories. By leveraging the\nstructural properties of graph databases and the flexibility of the graph query\nlanguage, CodexGraph enables the LLM agent to construct and execute queries,\nallowing for precise, code structure-aware context retrieval and code\nnavigation. We assess CodexGraph using three benchmarks: CrossCodeEval,\nSWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding\napplications. With a unified graph database schema, CodexGraph demonstrates\ncompetitive performance and potential in both academic and real-world\nenvironments, showcasing its versatility and efficacy in software engineering.\nOur application demo:\nhttps://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)在处理整个代码仓库时的挑战，提出CodexGraph系统，该系统将LLMs代理与从代码仓库提取的图数据库接口集成，以克服基于相似性检索的低召回率和手动工具的局限性。CodexGraph利用图数据库的结构属性和图查询语言，允许LLMs代理构建并执行精确的查询，实现代码结构感知的上下文检索和导航。在CrossCodeEval、SWE-bench和EvoCodeBench等基准测试中，以及五个真实世界编码应用上，该系统展示了竞争性的性能，并证明了其在学术和实际软件工程环境中的通用性和效能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.03910v2",
      "published_date": "2024-08-07 17:13:59 UTC",
      "updated_date": "2024-08-11 16:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:29:46.962575"
    },
    {
      "arxiv_id": "2408.03909v1",
      "title": "LaFA: Latent Feature Attacks on Non-negative Matrix Factorization",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Vu",
        "Ben Nebgen",
        "Erik Skau",
        "Geigh Zollicoffer",
        "Juan Castorena",
        "Kim Rasmussen",
        "Boian Alexandrov",
        "Manish Bhattarai"
      ],
      "abstract": "As Machine Learning (ML) applications rapidly grow, concerns about\nadversarial attacks compromising their reliability have gained significant\nattention. One unsupervised ML method known for its resilience to such attacks\nis Non-negative Matrix Factorization (NMF), an algorithm that decomposes input\ndata into lower-dimensional latent features. However, the introduction of\npowerful computational tools such as Pytorch enables the computation of\ngradients of the latent features with respect to the original data, raising\nconcerns about NMF's reliability. Interestingly, naively deriving the\nadversarial loss for NMF as in the case of ML would result in the\nreconstruction loss, which can be shown theoretically to be an ineffective\nattacking objective. In this work, we introduce a novel class of attacks in NMF\ntermed Latent Feature Attacks (LaFA), which aim to manipulate the latent\nfeatures produced by the NMF process. Our method utilizes the Feature Error\n(FE) loss directly on the latent features. By employing FE loss, we generate\nperturbations in the original data that significantly affect the extracted\nlatent features, revealing vulnerabilities akin to those found in other ML\ntechniques. To handle large peak-memory overhead from gradient back-propagation\nin FE attacks, we develop a method based on implicit differentiation which\nenables their scaling to larger datasets. We validate NMF vulnerabilities and\nFE attacks effectiveness through extensive experiments on synthetic and\nreal-world data.",
      "tldr_zh": "该研究揭示了 Non-negative Matrix Factorization (NMF) 的潜在漏洞，尽管它被视为对攻击具有抵抗力的无监督机器学习方法。论文提出了一种新颖攻击框架LaFA (Latent Feature Attacks)，通过直接在潜在特征上应用Feature Error (FE) 损失来生成数据扰动，从而有效操纵NMF分解出的低维特征。针对FE攻击带来的高内存开销，作者开发了基于隐式微分的方法，使其能扩展到更大数据集。实验在合成和真实世界数据上验证了LaFA的有效性，证明NMF与其他机器学习技术类似易受攻击。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "LA-UR-24-26951",
      "pdf_url": "http://arxiv.org/pdf/2408.03909v1",
      "published_date": "2024-08-07 17:13:46 UTC",
      "updated_date": "2024-08-07 17:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:30:00.229988"
    },
    {
      "arxiv_id": "2408.03907v1",
      "title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models",
      "title_zh": "偏见解码：自动化方法和 LLM 判断者用于语言模型中的",
      "authors": [
        "Shachi H Kumar",
        "Saurav Sahay",
        "Sahisnu Mazumder",
        "Eda Okur",
        "Ramesh Manuvinakurike",
        "Nicole Beckage",
        "Hsuan Su",
        "Hung-yi Lee",
        "Lama Nachman"
      ],
      "abstract": "Large Language Models (LLMs) have excelled at language understanding and\ngenerating human-level text. However, even with supervised training and human\nalignment, these LLMs are susceptible to adversarial attacks where malicious\nusers can prompt the model to generate undesirable text. LLMs also inherently\nencode potential biases that can cause various harmful effects during\ninteractions. Bias evaluation metrics lack standards as well as consensus and\nexisting methods often rely on human-generated templates and annotations which\nare expensive and labor intensive. In this work, we train models to\nautomatically create adversarial prompts to elicit biased responses from target\nLLMs. We present LLM- based bias evaluation metrics and also analyze several\nexisting automatic evaluation methods and metrics. We analyze the various\nnuances of model responses, identify the strengths and weaknesses of model\nfamilies, and assess where evaluation methods fall short. We compare these\nmetrics to human evaluation and validate that the LLM-as-a-Judge metric aligns\nwith human judgement on bias in response generation.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)中的性别偏见问题，提出了一种自动化方法，通过训练模型生成对抗提示(adversarial prompts)来引发和检测目标LLMs的偏见响应。研究者开发了基于LLM的偏见评估指标，并分析了现有自动评估方法及其优缺点，包括模型响应的细微差别。实验结果显示，LLM-as-a-Judge指标与人类评估高度一致，为标准化和高效的偏见检测提供了可靠工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages paper content, 17 pages of appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.03907v1",
      "published_date": "2024-08-07 17:11:34 UTC",
      "updated_date": "2024-08-07 17:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:30:22.930605"
    },
    {
      "arxiv_id": "2408.11060v1",
      "title": "Dynamic Code Orchestration: Harnessing the Power of Large Language Models for Adaptive Script Execution",
      "title_zh": "动态代码编排：利用大语言模型力量进行自适应脚本执行",
      "authors": [
        "Justin Del Vecchio",
        "Andrew Perreault",
        "Eliana Furmanek"
      ],
      "abstract": "Computer programming initially required humans to directly translate their\ngoals into machine code. These goals could have easily been expressed as a\nwritten (or human) language directive. Computers, however, had no capacity to\nsatisfactorily interpret written language. Large language model's provide\nexactly this capability; automatic generation of computer programs or even\nassembly code from written language directives. This research examines dynamic\ncode execution of written language directives within the context of a running\napplication. It implements a text editor whose business logic is purely backed\nby large language model prompts. That is, the program's execution uses prompts\nand written language directives to dynamically generate application logic at\nthe point in time it is needed. The research clearly shows how written language\ndirectives, backed by a large language model, offer radically new programming\nand operating system paradigms. For example, empowerment of users to directly\nimplement requirements via written language directives, thus supplanting the\nneed for a team ofprogrammers, a release schedule and the like. Or, new\nsecurity mechanisms where static executables, always a target for reverse\nengineering or fuzzing, no longer exist. They are replaced by ephemeral\nexecutables that may continually change, be completely removed, and are easily\nupdated.",
      "tldr_zh": "本研究探讨了动态代码编排（Dynamic Code Orchestration），利用 Large Language Models (LLMs) 从书面语言指令中自动生成和执行自适应脚本，取代传统的人工编程过程。论文实现了一个文本编辑器，其业务逻辑完全依赖于 LLM 提示，在运行时动态生成应用逻辑，从而实现用户直接通过语言指令定义需求。结果表明，这种方法开创了全新的编程和操作系统范式，包括减少对程序员团队的依赖、简化发布流程，以及引入短暂可执行文件（ephemeral executables）的安全机制，以提升系统灵活性和安全性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11060v1",
      "published_date": "2024-08-07 17:11:31 UTC",
      "updated_date": "2024-08-07 17:11:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:30:25.240778"
    },
    {
      "arxiv_id": "2408.03904v1",
      "title": "Lightweight Video Denoising Using a Classic Bayesian Backbone",
      "title_zh": "轻量级视频去噪：利用经典贝叶斯骨干",
      "authors": [
        "Clément Bled",
        "François Pitié"
      ],
      "abstract": "In recent years, state-of-the-art image and video denoising networks have\nbecome increasingly large, requiring millions of trainable parameters to\nachieve best-in-class performance. Improved denoising quality has come at the\ncost of denoising speed, where modern transformer networks are far slower to\nrun than smaller denoising networks such as FastDVDnet and classic Bayesian\ndenoisers such as the Wiener filter.\n  In this paper, we implement a hybrid Wiener filter which leverages small\nancillary networks to increase the original denoiser performance, while\nretaining fast denoising speeds. These networks are used to refine the Wiener\ncoring estimate, optimise windowing functions and estimate the unknown noise\nprofile. Using these methods, we outperform several popular denoisers and\nremain within 0.2 dB, on average, of the popular VRT transformer. Our method\nwas found to be over x10 faster than the transformer method, with a far lower\nparameter cost.",
      "tldr_zh": "本论文针对现代视频去噪网络参数过多且速度过慢的问题，提出了一种基于经典Bayesian骨干的轻量级混合Wiener滤波器方法。该方法利用小型辅助网络来优化Wiener滤波的估计、窗口函数和噪声配置文件，从而提升去噪性能，同时保持快速处理速度。实验结果显示，该方法超过了多个流行去噪器，在性能上平均仅比VRT transformer低0.2 dB，却实现了超过10倍的速度提升和更低的参数成本。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "Paper accepted to ICME 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03904v1",
      "published_date": "2024-08-07 17:08:46 UTC",
      "updated_date": "2024-08-07 17:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:30:35.668747"
    },
    {
      "arxiv_id": "2408.03899v1",
      "title": "Simplifying Scholarly Abstracts for Accessible Digital Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Haining Wang",
        "Jason Clark"
      ],
      "abstract": "Standing at the forefront of knowledge dissemination, digital libraries\ncurate vast collections of scientific literature. However, these scholarly\nwritings are often laden with jargon and tailored for domain experts rather\nthan the general public. As librarians, we strive to offer services to a\ndiverse audience, including those with lower reading levels. To extend our\nservices beyond mere access, we propose fine-tuning a language model to rewrite\nscholarly abstracts into more comprehensible versions, thereby making scholarly\nliterature more accessible when requested. We began by introducing a corpus\nspecifically designed for training models to simplify scholarly abstracts. This\ncorpus consists of over three thousand pairs of abstracts and significance\nstatements from diverse disciplines. We then fine-tuned four language models\nusing this corpus. The outputs from the models were subsequently examined both\nquantitatively for accessibility and semantic coherence, and qualitatively for\nlanguage quality, faithfulness, and completeness. Our findings show that the\nresulting models can improve readability by over three grade levels, while\nmaintaining fidelity to the original content. Although commercial\nstate-of-the-art models still hold an edge, our models are much more compact,\ncan be deployed locally in an affordable manner, and alleviate the privacy\nconcerns associated with using commercial models. We envision this work as a\nstep toward more inclusive and accessible libraries, improving our services for\nyoung readers and those without a college degree.",
      "tldr_zh": "本研究针对学术文献的术语复杂性问题，提出一种fine-tuning语言模型的方法，以简化scholarly abstracts并提升数字图书馆的可访问性。研究团队构建了一个包含超过3000对摘要和意义声明的语料库，并以此微调了四个语言模型，评估了其可访问性、语义连贯性、语言质量、忠实度和完整性。结果显示，模型将可读性提高了超过三个年级水平，同时保持了原内容的忠实度；相较于商业state-of-the-art模型，该方法更紧凑、易于本地部署，并缓解了隐私担忧。该工作有望促进更具包容性的数字图书馆服务，惠及年轻读者和非大学学历群体。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Initial submission to JCDL2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03899v1",
      "published_date": "2024-08-07 16:55:00 UTC",
      "updated_date": "2024-08-07 16:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:30:49.235100"
    },
    {
      "arxiv_id": "2408.03892v1",
      "title": "MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems",
      "title_zh": "MORTAR：基于模型的运行时动作修复框架，用于 AI 赋能的网络物理系统",
      "authors": [
        "Renzhi Wang",
        "Zhehua Zhou",
        "Jiayang Song",
        "Xuan Xie",
        "Xiaofei Xie",
        "Lei Ma"
      ],
      "abstract": "Cyber-Physical Systems (CPSs) are increasingly prevalent across various\nindustrial and daily-life domains, with applications ranging from robotic\noperations to autonomous driving. With recent advancements in artificial\nintelligence (AI), learning-based components, especially AI controllers, have\nbecome essential in enhancing the functionality and efficiency of CPSs.\nHowever, the lack of interpretability in these AI controllers presents\nchallenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).\nExisting methods for improving the safety of AI controllers often involve\nneural network repair, which requires retraining with additional adversarial\nexamples or access to detailed internal information of the neural network.\nHence, these approaches have limited applicability for black-box policies,\nwhere only the inputs and outputs are accessible during operation. To overcome\nthis, we propose MORTAR, a runtime action repair framework designed for AI-CPSs\nin this work. MORTAR begins by constructing a prediction model that forecasts\nthe quality of actions proposed by the AI controller. If an unsafe action is\ndetected, MORTAR then initiates a repair process to correct it. The generation\nof repaired actions is achieved through an optimization process guided by the\nsafety estimates from the prediction model. We evaluate the effectiveness of\nMORTAR across various CPS tasks and AI controllers. The results demonstrate\nthat MORTAR can efficiently improve task completion rates of AI controllers\nunder specified safety specifications. Meanwhile, it also maintains minimal\ncomputational overhead, ensuring real-time operation of the AI-CPSs.",
      "tldr_zh": "该论文提出 MORTAR，一种基于模型的运行时行动修复框架，旨在提升 AI-enabled Cyber-Physical Systems (AI-CPSs) 的安全性和质量，以解决 AI 控制器缺乏可解释性导致的安全挑战。MORTAR 通过构建一个预测模型来检测 AI 控制器提出的不安全行动，并利用优化过程基于安全估计生成修复行动，从而适用于黑箱策略。实验结果表明，MORTAR 在各种 CPS 任务中显著提高了任务完成率，同时保持了最小计算开销，确保了实时操作。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03892v1",
      "published_date": "2024-08-07 16:44:53 UTC",
      "updated_date": "2024-08-07 16:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:31:00.662780"
    },
    {
      "arxiv_id": "2408.03877v1",
      "title": "Knowledge Probing for Graph Representation Learning",
      "title_zh": "针对图表示学习的知识探查",
      "authors": [
        "Mingyu Zhao",
        "Xingyu Huang",
        "Ziyu Lyu",
        "Yanlin Wang",
        "Lixin Cui",
        "Lu Bai"
      ],
      "abstract": "Graph learning methods have been extensively applied in diverse application\nareas. However, what kind of inherent graph properties e.g. graph proximity,\ngraph structural information has been encoded into graph representation\nlearning for downstream tasks is still under-explored. In this paper, we\npropose a novel graph probing framework (GraphProbe) to investigate and\ninterpret whether the family of graph learning methods has encoded different\nlevels of knowledge in graph representation learning. Based on the intrinsic\nproperties of graphs, we design three probes to systematically investigate the\ngraph representation learning process from different perspectives, respectively\nthe node-wise level, the path-wise level, and the structural level. We\nconstruct a thorough evaluation benchmark with nine representative graph\nlearning methods from random walk based approaches, basic graph neural networks\nand self-supervised graph methods, and probe them on six benchmark datasets for\nnode classification, link prediction and graph classification. The experimental\nevaluation verify that GraphProbe can estimate the capability of graph\nrepresentation learning. Remaking results have been concluded: GCN and\nWeightedGCN methods are relatively versatile methods achieving better results\nwith respect to different tasks.",
      "tldr_zh": "本研究提出GraphProbe框架，用于探讨图表示学习(Graph Representation Learning)是否成功编码了图的内在属性，如图邻近性(graph proximity)和结构信息。框架设计了三个探针(probes)：分别从节点级(node-wise level)、路径级(path-wise level)和结构级(structural level)角度系统调查图学习过程。实验在六个基准数据集上评估了九种代表性图学习方法，包括随机游走方法、基本图神经网络和自监督图方法，结果表明GCN和WeightedGCN在节点分类、链接预测和图分类任务中表现出色，具有较强的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03877v1",
      "published_date": "2024-08-07 16:27:45 UTC",
      "updated_date": "2024-08-07 16:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:31:11.573946"
    },
    {
      "arxiv_id": "2408.03872v1",
      "title": "Inter-Series Transformer: Attending to Products in Time Series Forecasting",
      "title_zh": "Inter-Series Transformer：在时间序列预测中关注产品",
      "authors": [
        "Rares Cristian",
        "Pavithra Harsha",
        "Clemente Ocejo",
        "Georgia Perakis",
        "Brian Quanz",
        "Ioannis Spantidakis",
        "Hamza Zerhouni"
      ],
      "abstract": "Time series forecasting is an important task in many fields ranging from\nsupply chain management to weather forecasting. Recently, Transformer neural\nnetwork architectures have shown promising results in forecasting on common\ntime series benchmark datasets. However, application to supply chain demand\nforecasting, which can have challenging characteristics such as sparsity and\ncross-series effects, has been limited.\n  In this work, we explore the application of Transformer-based models to\nsupply chain demand forecasting. In particular, we develop a new\nTransformer-based forecasting approach using a shared, multi-task per-time\nseries network with an initial component applying attention across time series,\nto capture interactions and help address sparsity. We provide a case study\napplying our approach to successfully improve demand prediction for a medical\ndevice manufacturing company. To further validate our approach, we also apply\nit to public demand forecasting datasets as well and demonstrate competitive to\nsuperior performance compared to a variety of baseline and state-of-the-art\nforecast methods across the private and public datasets.",
      "tldr_zh": "本文提出了一种名为Inter-Series Transformer的新型时间序列预测方法，旨在解决供应链需求预测中的稀疏性和跨序列效应问题。该方法采用共享的多任务per-time series网络，并引入初始跨时间序列注意力机制，以捕捉系列间交互并提升预测准确性。在医疗设备制造公司的案例研究中，该方法成功改善了需求预测，并在公共数据集上表现出与基线和最先进方法相比的竞争性或优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; G.3; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03872v1",
      "published_date": "2024-08-07 16:22:21 UTC",
      "updated_date": "2024-08-07 16:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:31:25.282557"
    },
    {
      "arxiv_id": "2408.03871v2",
      "title": "Large Language Models for Biomedical Text Simplification: Promising But Not There Yet",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Li",
        "Samuel Belkadi",
        "Nicolo Micheletti",
        "Lifeng Han",
        "Matthew Shardlow",
        "Goran Nenadic"
      ],
      "abstract": "In this system report, we describe the models and methods we used for our\nparticipation in the PLABA2023 task on biomedical abstract simplification, part\nof the TAC 2023 tracks. The system outputs we submitted come from the following\nthree categories: 1) domain fine-tuned T5-like models including Biomedical-T5\nand Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes\n(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we\ncarried out for this task on BioGPT finetuning. In the official automatic\nevaluation using SARI scores, BeeManc ranks 2nd among all teams and our model\nLaySciFive ranks 3rd among all 13 evaluated systems. In the official human\nevaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score\n92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It\nalso produced a high score 91.57 on Fluency in comparison to the highest score\n93.53. In the second round of submissions, our team using ChatGPT-prompting\nranks the 2nd in several categories including simplified term accuracy score\n92.26 and completeness score 96.58, and a very similar score on faithfulness\nscore 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our\ncodes, fine-tuned models, prompts, and data splits from the system development\nstage will be available at https://github.com/ HECTA-UoM/PLABA-MU",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在生物医学文本简化任务中的表现，参与了 PLABA2023 竞赛。研究团队使用多种方法，包括微调 Biomedical-T5、Lay-SciFive 和 BARTLarge-w-CTs 模型，以及 ChatGPT 提示，并进行了 BioGPT 的微调实验。在自动评估中，使用 SARI 分数，他们的系统 BeeManc 排名第二，LaySciFive 排名第三；在人类评估中，BART-w-CTs 在句子简单性和术语简单性上排名靠前，但整体表现虽有前景，却未达到理想水平，突显了 LLMs 在生物医学简化领域的潜在局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Extended system report for PLABA-2023. arXiv admin note: substantial\n  text overlap with arXiv:2309.13202",
      "pdf_url": "http://arxiv.org/pdf/2408.03871v2",
      "published_date": "2024-08-07 16:21:41 UTC",
      "updated_date": "2024-09-24 08:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:31:37.788773"
    },
    {
      "arxiv_id": "2408.03841v1",
      "title": "MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Dong",
        "XiaoXiang Fang",
        "Yuchen Hu",
        "Renshuang Jiang",
        "Zhe Jiang"
      ],
      "abstract": "The application of large language models to facilitate automated software\noperations and tool generation (SOTG), thus augmenting software productivity,\nmirrors the early stages of human evolution when the ability to create and use\ntools accelerated the progress of civilization. These complex tasks require AI\nto continuously summarize and improve. Current research often overlooks the\nimportance of converting real-time task experiences into system memory and\ndifferentiating the value of existing knowledge for future reference. This\npaper addresses these issues by evolving external memory models into\nMemory-Loop Networks for timely memorization and experience referencing. We\nalso enhance a RAG mechanism with knowledge precision segmentation to utilize\nmemory based on value differentiation, and design the MaxMind model for SOTG\naccordingly.To demonstrate our approach, we developed MaxMind4Sheet, an\nelectronic spreadsheet processing system aligned with the MaxMind philosophy.\nComparative experiments with SheetCopilot have demonstrated that the\naccumulation and recycling of task memories lead to a steady enhancement in\ntask success rate, with an improvement rate of approximately 3%-6% per round in\nthis implementation example. Note that as the memories continue to grow, this\ncumulative improvement may be substantial. The inclusion of memory recycling\ncan also boost the system's task execution efficiency by up to 25%, and it can\naddress the retraining issue faced by LLMs when handling specialized tasks\nthrough memories transfer.These suggest that MaxMind has significant potential\nto enhance the capabilities and productivity of LLM systems in SOTG.",
      "tldr_zh": "该论文提出MaxMind模型，一种基于Large Language Models (LLMs)的Memory-Loop Networks框架，用于提升软件操作和工具生成(SOTG)的生产力，通过及时记忆任务经验和基于价值区分的知识精确分段来增强RAG机制。MaxMind解决了当前研究中忽略实时经验转化为系统记忆的问题，并设计了MaxMind4Sheet系统作为电子表格处理示例。实验结果显示，与SheetCopilot相比，该模型使任务成功率每轮提高3%-6%，任务执行效率提升25%，并通过记忆转移避免了LLMs在专业任务中的重新训练需求，从而显著提升LLMs系统的能力和软件生产力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03841v1",
      "published_date": "2024-08-07 15:27:22 UTC",
      "updated_date": "2024-08-07 15:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:31:50.580710"
    },
    {
      "arxiv_id": "2408.03837v3",
      "title": "WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models",
      "title_zh": "WalledEval：大型语言模型的全面安全评估工具包",
      "authors": [
        "Prannaya Gupta",
        "Le Qi Yau",
        "Hao Han Low",
        "I-Shiang Lee",
        "Hugo Maximus Lim",
        "Yu Xin Teoh",
        "Jia Hng Koh",
        "Dar Win Liew",
        "Rishabh Bhardwaj",
        "Rajat Bhardwaj",
        "Soujanya Poria"
      ],
      "abstract": "WalledEval is a comprehensive AI safety testing toolkit designed to evaluate\nlarge language models (LLMs). It accommodates a diverse range of models,\nincluding both open-weight and API-based ones, and features over 35 safety\nbenchmarks covering areas such as multilingual safety, exaggerated safety, and\nprompt injections. The framework supports both LLM and judge benchmarking and\nincorporates custom mutators to test safety against various text-style\nmutations, such as future tense and paraphrasing. Additionally, WalledEval\nintroduces WalledGuard, a new, small, and performant content moderation tool,\nand two datasets: SGXSTest and HIXSTest, which serve as benchmarks for\nassessing the exaggerated safety of LLMs and judges in cultural contexts. We\nmake WalledEval publicly available at https://github.com/walledai/walledeval.",
      "tldr_zh": "本研究介绍了 WalledEval，一种全面的 AI 安全评估工具包，用于评估大型语言模型 (LLMs)，支持开源和 API 基于的模型。工具包包含超过 35 个安全基准，涵盖多语言安全、夸张安全和提示注入等领域，并通过自定义 mutators 测试各种文本风格变异，如未来时态和改述。WalledEval 还引入了 WalledGuard（一个小型高效的内容审核工具）和两个新数据集（SGXSTest 和 HIXSTest），用于评估 LLMs 在文化背景下的夸张安全表现；该工具已公开在 GitHub 上以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2408.03837v3",
      "published_date": "2024-08-07 15:22:44 UTC",
      "updated_date": "2024-08-19 21:57:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:32:03.927208"
    },
    {
      "arxiv_id": "2408.03834v1",
      "title": "Target Prompting for Information Extraction with Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Dipankar Medhi"
      ],
      "abstract": "The recent trend in the Large Vision and Language model has brought a new\nchange in how information extraction systems are built. VLMs have set a new\nbenchmark with their State-of-the-art techniques in understanding documents and\nbuilding question-answering systems across various industries. They are\nsignificantly better at generating text from document images and providing\naccurate answers to questions. However, there are still some challenges in\neffectively utilizing these models to build a precise conversational system.\nGeneral prompting techniques used with large language models are often not\nsuitable for these specially designed vision language models. The output\ngenerated by such generic input prompts is ordinary and may contain information\ngaps when compared with the actual content of the document. To obtain more\naccurate and specific answers, a well-targeted prompt is required by the vision\nlanguage model, along with the document image. In this paper, a technique is\ndiscussed called Target prompting, which focuses on explicitly targeting parts\nof document images and generating related answers from those specific regions\nonly. The paper also covers the evaluation of response for each prompting\ntechnique using different user queries and input prompts.",
      "tldr_zh": "该研究探讨了使用视觉语言模型（VLMs）进行信息提取的挑战，特别是通用提示技术导致的输出普通和信息缺口问题。论文提出了一种名为 Target Prompting 的新方法，该技术通过显式针对文档图像的特定区域，仅从这些部分生成相关答案，从而提升提取精度。实验评估显示，这种方法在使用不同用户查询时，能提供更准确和针对性的响应。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03834v1",
      "published_date": "2024-08-07 15:17:51 UTC",
      "updated_date": "2024-08-07 15:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:32:15.534747"
    },
    {
      "arxiv_id": "2408.03827v1",
      "title": "Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps",
      "title_zh": "针对移动应用中可访问性问题的自动代码修复建议",
      "authors": [
        "Forough Mehralian",
        "Titus Barik",
        "Jeff Nichols",
        "Amanda Swearngin"
      ],
      "abstract": "Accessibility is crucial for inclusive app usability, yet developers often\nstruggle to identify and fix app accessibility issues due to a lack of\nawareness, expertise, and inadequate tools. Current accessibility testing tools\ncan identify accessibility issues but may not always provide guidance on how to\naddress them. We introduce FixAlly, an automated tool designed to suggest\nsource code fixes for accessibility issues detected by automated accessibility\nscanners. FixAlly employs a multi-agent LLM architecture to generate fix\nstrategies, localize issues within the source code, and propose code\nmodification suggestions to fix the accessibility issue. Our empirical study\ndemonstrates FixAlly's capability in suggesting fixes that resolve issues found\nby accessibility scanners -- with an effectiveness of 77% in generating\nplausible fix suggestions -- and our survey of 12 iOS developers finds they\nwould be willing to accept 69.4% of evaluated fix suggestions.",
      "tldr_zh": "该论文针对移动应用的可访问性问题，提出了一种自动化工具 FixAlly，以帮助开发者快速修复源代码中的障碍。FixAlly 采用多智能体 LLM 架构，生成修复策略、定位问题代码并提供具体修改建议，从而弥补现有可访问性扫描工具的不足。实证研究显示，FixAlly 的修复建议有效性达 77%，并通过对 12 名 iOS 开发者的调查发现，他们愿意接受 69.4% 的建议。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "D.2.5; I.2"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03827v1",
      "published_date": "2024-08-07 15:06:07 UTC",
      "updated_date": "2024-08-07 15:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:32:27.821668"
    },
    {
      "arxiv_id": "2408.03811v1",
      "title": "Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring",
      "title_zh": "生成式语言模型结合检索增强生成用于自动短答评分",
      "authors": [
        "Zifan Wang",
        "Christopher Ormerod"
      ],
      "abstract": "Automated Short Answer Scoring (ASAS) is a critical component in educational\nassessment. While traditional ASAS systems relied on rule-based algorithms or\ncomplex deep learning methods, recent advancements in Generative Language\nModels (GLMs) offer new opportunities for improvement. This study explores the\napplication of GLMs to ASAS, leveraging their off-the-shelf capabilities and\nperformance in various domains. We propose a novel pipeline that combines\nvector databases, transformer-based encoders, and GLMs to enhance short answer\nscoring accuracy. Our approach stores training responses in a vector database,\nretrieves semantically similar responses during inference, and employs a GLM to\nanalyze these responses and determine appropriate scores. We further optimize\nthe system through fine-tuned retrieval processes and prompt engineering.\nEvaluation on the SemEval 2013 dataset demonstrates a significant improvement\non the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,\nhighlighting the potential of GLMs in advancing ASAS technology.",
      "tldr_zh": "本研究探讨了 Generative Language Models (GLMs) 在 Automated Short Answer Scoring (ASAS) 中的应用，提出了一种结合 Retrieval Augmented Generation (RAG) 的新管道，以提升评分准确性。该管道利用 vector databases 存储训练响应，在推理时检索语义相似的响应，并由 GLMs 进行分析和评分，同时通过 fine-tuned retrieval 和 prompt engineering 优化系统。在 SemEval 2013 数据集的 SCIENTSBANK 3-way 和 2-way 任务上，该方法比现有方法显著改进，展示了 GLMs 在 ASAS 技术领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03811v1",
      "published_date": "2024-08-07 14:42:13 UTC",
      "updated_date": "2024-08-07 14:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:32:41.459752"
    },
    {
      "arxiv_id": "2408.03807v1",
      "title": "Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Moder",
        "Stephen Adhisaputra",
        "Josef Pauli"
      ],
      "abstract": "This paper addresses navigation in crowded environments by integrating\ngoal-conditioned generative models with Sampling-based Model Predictive Control\n(SMPC). We introduce goal-conditioned autoregressive models to generate crowd\nbehaviors, capturing intricate interactions among individuals. The model\nprocesses potential robot trajectory samples and predicts the reactions of\nsurrounding individuals, enabling proactive robotic navigation in complex\nscenarios. Extensive experiments show that this algorithm enables real-time\nnavigation, significantly reducing collision rates and path lengths, and\noutperforming selected baseline methods. The practical effectiveness of this\nalgorithm is validated on an actual robotic platform, demonstrating its\ncapability in dynamic settings.",
      "tldr_zh": "这篇论文提出了一种整合 goal-conditioned generative models 与 Sampling-based Model Predictive Control (SMPC) 的方法，用于机器人在拥挤环境中的实时路径规划。该方法通过目标条件自回归模型生成人群行为，并预测个体对机器人轨迹的反应，实现主动导航。实验结果表明，该算法显著降低了碰撞率和路径长度，并优于现有基线方法；在实际机器人平台上验证了其在动态场景中的实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03807v1",
      "published_date": "2024-08-07 14:32:41 UTC",
      "updated_date": "2024-08-07 14:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:32:52.311789"
    },
    {
      "arxiv_id": "2408.03795v1",
      "title": "Frank's triangular norms in Piaget's logical proportions",
      "title_zh": "翻译失败",
      "authors": [
        "Henri Prade",
        "Gilles Richard"
      ],
      "abstract": "Starting from the Boolean notion of logical proportion in Piaget's sense,\nwhich turns out to be equivalent to analogical proportion, this note proposes a\ndefinition of analogical proportion between numerical values based on\ntriangular norms (and dual co-norms). Frank's family of triangular norms is\nparticularly interesting from this perspective. The article concludes with a\ncomparative discussion with another very recent proposal for defining\nanalogical proportions between numerical values based on the family of\ngeneralized means.",
      "tldr_zh": "本论文从 Piaget's logical proportions 的布尔概念出发，将其等同于 analogical proportion，并提出了一种基于 triangular norms 和 dual co-norms 的数值类比比例定义。其中，Frank's family of triangular norms 被视为特别重要，可提供更灵活的框架。最后，该方法与另一个基于 generalized means 家族的最近提案进行比较讨论，突显其在数值类比中的潜在优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.03795v1",
      "published_date": "2024-08-07 14:20:09 UTC",
      "updated_date": "2024-08-07 14:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:33:03.538606"
    },
    {
      "arxiv_id": "2408.03977v1",
      "title": "Learning from Noisy Labels for Long-tailed Data via Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Mengting Li",
        "Chuang Zhu"
      ],
      "abstract": "Noisy labels, which are common in real-world datasets, can significantly\nimpair the training of deep learning models. However, recent adversarial\nnoise-combating methods overlook the long-tailed distribution of real data,\nwhich can significantly harm the effect of denoising strategies. Meanwhile, the\nmismanagement of noisy labels further compromises the model's ability to handle\nlong-tailed data. To tackle this issue, we propose a novel approach to manage\ndata characterized by both long-tailed distributions and noisy labels. First,\nwe introduce a loss-distance cross-selection module, which integrates class\npredictions and feature distributions to filter clean samples, effectively\naddressing uncertainties introduced by noisy labels and long-tailed\ndistributions. Subsequently, we employ optimal transport strategies to generate\npseudo-labels for the noise set in a semi-supervised training manner, enhancing\npseudo-label quality while mitigating the effects of sample scarcity caused by\nthe long-tailed distribution. We conduct experiments on both synthetic and\nreal-world datasets, and the comprehensive experimental results demonstrate\nthat our method surpasses current state-of-the-art methods. Our code will be\navailable in the future.",
      "tldr_zh": "该论文针对带有 noisy labels 的 long-tailed data 问题，提出了一种新方法，以优化深度学习模型的训练效果。首先，引入 loss-distance cross-selection module，通过整合类预测和特征分布来过滤干净样本，从而有效处理 noisy labels 和 long-tailed distribution 带来的不确定性。其次，利用 optimal transport 策略生成高质量的伪标签（pseudo-labels），并采用半监督训练方式缓解样本稀缺问题。实验结果显示，该方法在合成和真实数据集上优于现有最先进方法，证明了其在噪声标签管理方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03977v1",
      "published_date": "2024-08-07 14:15:18 UTC",
      "updated_date": "2024-08-07 14:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:33:14.753230"
    },
    {
      "arxiv_id": "2408.04671v1",
      "title": "Prompt and Prejudice",
      "title_zh": "提示与偏见",
      "authors": [
        "Lorenzo Berlincioni",
        "Luca Cultrera",
        "Federico Becattini",
        "Marco Bertini",
        "Alberto Del Bimbo"
      ],
      "abstract": "This paper investigates the impact of using first names in Large Language\nModels (LLMs) and Vision Language Models (VLMs), particularly when prompted\nwith ethical decision-making tasks. We propose an approach that appends first\nnames to ethically annotated text scenarios to reveal demographic biases in\nmodel outputs. Our study involves a curated list of more than 300 names\nrepresenting diverse genders and ethnic backgrounds, tested across thousands of\nmoral scenarios. Following the auditing methodologies from social sciences we\npropose a detailed analysis involving popular LLMs/VLMs to contribute to the\nfield of responsible AI by emphasizing the importance of recognizing and\nmitigating biases in these systems. Furthermore, we introduce a novel\nbenchmark, the Pratical Scenarios Benchmark (PSB), designed to assess the\npresence of biases involving gender or demographic prejudices in everyday\ndecision-making scenarios as well as practical scenarios where an LLM might be\nused to make sensible decisions (e.g., granting mortgages or insurances). This\nbenchmark allows for a comprehensive comparison of model behaviors across\ndifferent demographic categories, highlighting the risks and biases that may\narise in practical applications of LLMs and VLMs.",
      "tldr_zh": "这篇论文探讨了在大型语言模型（LLMs）和视觉语言模型（VLMs）中添加名字（如第一名字）对道德决策任务的影响，揭示潜在的 demographic biases。研究者提出一种方法，通过在 ethically annotated text scenarios 中附加超过 300 个代表不同性别和民族背景的名字，并测试数千个道德场景，使用社会科学的审计方法对流行模型进行详细分析，以推动 responsible AI。论文引入了新的基准 Pratical Scenarios Benchmark (PSB)，用于评估模型在日常决策（如发放抵押贷款或保险）和实际场景中的性别或 demographic prejudices，提供全面比较以突出这些 biases 的风险和缓解策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ECCV workshop FAILED",
      "pdf_url": "http://arxiv.org/pdf/2408.04671v1",
      "published_date": "2024-08-07 14:11:33 UTC",
      "updated_date": "2024-08-07 14:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:33:29.850872"
    },
    {
      "arxiv_id": "2408.07079v3",
      "title": "Anatomical Foundation Models for Brain MRIs",
      "title_zh": "翻译失败",
      "authors": [
        "Carlo Alberto Barbano",
        "Matteo Brunello",
        "Benoit Dufumier",
        "Marco Grangetto"
      ],
      "abstract": "Deep Learning (DL) in neuroimaging has become increasingly relevant for\ndetecting neurological conditions and neurodegenerative disorders. One of the\nmost predominant biomarkers in neuroimaging is represented by brain age, which\nhas been shown to be a good indicator for different conditions, such as\nAlzheimer's Disease. Using brain age for weakly supervised pre-training of DL\nmodels in transfer learning settings has also recently shown promising results,\nespecially when dealing with data scarcity of different conditions. On the\nother hand, anatomical information of brain MRIs (e.g. cortical thickness) can\nprovide important information for learning good representations that can be\ntransferred to many downstream tasks. In this work, we propose AnatCL, an\nanatomical foundation model for brain MRIs that i.) leverages anatomical\ninformation in a weakly contrastive learning approach, and ii.) achieves\nstate-of-the-art performances across many different downstream tasks. To\nvalidate our approach we consider 12 different downstream tasks for the\ndiagnosis of different conditions such as Alzheimer's Disease, autism spectrum\ndisorder, and schizophrenia. Furthermore, we also target the prediction of 10\ndifferent clinical assessment scores using structural MRI data. Our findings\nshow that incorporating anatomical information during pre-training leads to\nmore robust and generalizable representations. Pre-trained models can be found\nat: https://github.com/EIDOSLAB/AnatCL.",
      "tldr_zh": "这篇论文提出了AnatCL，一种基于解剖信息的脑MRI基础模型，旨在通过弱对比学习(weakly contrastive learning)方法整合解剖特征（如皮层厚度），以提升深度学习(Deep Learning)模型在迁移学习中的性能。AnatCL利用脑年龄等生物标记物进行弱监督预训练，并在12个诊断任务（如阿尔茨海默病、自闭谱系障碍和精神分裂症）和10个临床评估分数预测中，实现了最先进性能。研究发现，融入解剖信息能生成更稳健和可泛化的表示，提高了模型在数据稀缺场景下的适用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "eess.IV",
      "comment": "Updated version; added ablation study",
      "pdf_url": "http://arxiv.org/pdf/2408.07079v3",
      "published_date": "2024-08-07 14:04:50 UTC",
      "updated_date": "2024-11-29 10:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:33:40.938859"
    },
    {
      "arxiv_id": "2408.03772v1",
      "title": "Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Erica Coppolillo",
        "Giuseppe Manco",
        "Aristides Gionis"
      ],
      "abstract": "Providing recommendations that are both relevant and diverse is a key\nconsideration of modern recommender systems. Optimizing both of these measures\npresents a fundamental trade-off, as higher diversity typically comes at the\ncost of relevance, resulting in lower user engagement. Existing recommendation\nalgorithms try to resolve this trade-off by combining the two measures,\nrelevance and diversity, into one aim and then seeking recommendations that\noptimize the combined objective, for a given number of items to recommend.\nTraditional approaches, however, do not consider the user interaction with the\nrecommended items.\n  In this paper, we put the user at the central stage, and build on the\ninterplay between relevance, diversity, and user behavior. In contrast to\napplications where the goal is solely to maximize engagement, we focus on\nscenarios aiming at maximizing the total amount of knowledge encountered by the\nuser. We use diversity as a surrogate of the amount of knowledge obtained by\nthe user while interacting with the system, and we seek to maximize diversity.\nWe propose a probabilistic user-behavior model in which users keep interacting\nwith the recommender system as long as they receive relevant recommendations,\nbut they may stop if the relevance of the recommended items drops. Thus, for a\nrecommender system to achieve a high-diversity measure, it will need to produce\nrecommendations that are both relevant and diverse.\n  Finally, we propose a novel recommendation strategy that combines relevance\nand diversity by a copula function. We conduct an extensive evaluation of the\nproposed methodology over multiple datasets, and we show that our strategy\noutperforms several state-of-the-art competitors. Our implementation is\npublicly available at https://github.com/EricaCoppolillo/EXPLORE.",
      "tldr_zh": "这篇论文提出一个以用户为中心的框架，旨在通过推荐系统平衡相关性(relevance)和多样性(diversity)，以最大化用户在知识探索中的获得量。作者构建了一个概率用户行为模型，模拟用户基于推荐相关性决定是否继续互动，从而要求系统同时提供相关和多样的推荐。最终，他们引入一种使用 copula 函数结合相关性和多样性的新策略，并在多个数据集上评估，证明该方法优于现有竞争算法，并公开了实现代码。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03772v1",
      "published_date": "2024-08-07 13:48:24 UTC",
      "updated_date": "2024-08-07 13:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:33:53.484910"
    },
    {
      "arxiv_id": "2408.03747v3",
      "title": "Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Correia",
        "Jan-Christoph Goos",
        "Philipp Klein",
        "Thomas Bäck",
        "Anna V. Kononova"
      ],
      "abstract": "Time-series anomaly detection plays an important role in engineering\nprocesses, like development, manufacturing and other operations involving\ndynamic systems. These processes can greatly benefit from advances in the\nfield, as state-of-the-art approaches may aid in cases involving, for example,\nhighly dimensional data. To provide the reader with understanding of the\nterminology, this survey introduces a novel taxonomy where a distinction\nbetween online and offline, and training and inference is made. Additionally,\nit presents the most popular data sets and evaluation metrics used in the\nliterature, as well as a detailed analysis. Furthermore, this survey provides\nan extensive overview of the state-of-the-art model-based online semi- and\nunsupervised anomaly detection approaches for multivariate time-series data,\ncategorising them into different model families and other properties. The\nbiggest research challenge revolves around benchmarking, as currently there is\nno reliable way to compare different approaches against one another. This\nproblem is two-fold: on the one hand, public data sets suffers from at least\none fundamental flaw, while on the other hand, there is a lack of intuitive and\nrepresentative evaluation metrics in the field. Moreover, the way most\npublications choose a detection threshold disregards real-world conditions,\nwhich hinders the application in the real world. To allow for tangible advances\nin the field, these issues must be addressed in future work.",
      "tldr_zh": "这篇论文对在线基于模型的异常检测（anomaly detection）在多变量时间序列（multivariate time series）中的应用进行了全面综述，提出了一种新分类法，将方法区分在线/离线和训练/推理，并介绍了常用数据集和评估指标。论文概述了当前最先进的在线半监督和无监督异常检测方法，将它们分类到不同模型家族和属性中，以突出其在工程过程（如制造和动态系统）中的重要性。主要研究挑战包括基准测试的可靠性问题，如数据集缺陷、缺乏直观的评估指标，以及阈值选择的现实性不足；未来方向强调需解决这些问题以推动该领域实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03747v3",
      "published_date": "2024-08-07 13:01:10 UTC",
      "updated_date": "2024-09-19 07:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:34:06.533808"
    },
    {
      "arxiv_id": "2408.03746v1",
      "title": "Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling",
      "title_zh": "灵活贝叶斯最后一层模型：利用隐式先验和扩散后验采样",
      "authors": [
        "Jian Xu",
        "Zhiqi Lin",
        "Shigui Li",
        "Min Chen",
        "Junmei Yang",
        "Delu Zeng",
        "John Paisley"
      ],
      "abstract": "Bayesian Last Layer (BLL) models focus solely on uncertainty in the output\nlayer of neural networks, demonstrating comparable performance to more complex\nBayesian models. However, the use of Gaussian priors for last layer weights in\nBayesian Last Layer (BLL) models limits their expressive capacity when faced\nwith non-Gaussian, outlier-rich, or high-dimensional datasets. To address this\nshortfall, we introduce a novel approach that combines diffusion techniques and\nimplicit priors for variational learning of Bayesian last layer weights. This\nmethod leverages implicit distributions for modeling weight priors in BLL,\ncoupled with diffusion samplers for approximating true posterior predictions,\nthereby establishing a comprehensive Bayesian prior and posterior estimation\nstrategy. By delivering an explicit and computationally efficient variational\nlower bound, our method aims to augment the expressive abilities of BLL models,\nenhancing model accuracy, calibration, and out-of-distribution detection\nproficiency. Through detailed exploration and experimental validation, We\nshowcase the method's potential for improving predictive accuracy and\nuncertainty quantification while ensuring computational efficiency.",
      "tldr_zh": "该研究针对Bayesian Last Layer (BLL)模型的局限性提出了一种新方法，使用implicit priors和diffusion posterior sampling来提升模型的变分学习能力。传统BLL模型依赖Gaussian priors，这在非高斯、异常值丰富或高维数据集上表现不足；新方法通过隐式分布建模权重先验，并结合diffusion samplers近似真实后验分布，实现更全面的Bayesian先验和后验估计。实验结果显示，该方法显著提高了BLL模型的预测准确性、校准性能和异常检测能力，同时保持了计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03746v1",
      "published_date": "2024-08-07 12:59:58 UTC",
      "updated_date": "2024-08-07 12:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:34:18.832910"
    },
    {
      "arxiv_id": "2408.03745v2",
      "title": "Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Georgia Sovatzidi",
        "Michael D. Vasilakakis",
        "Dimitris K. Iakovidis"
      ],
      "abstract": "Several deep learning (DL) approaches have been proposed to deal with image\nclassification tasks. However, despite their effectiveness, they lack\ninterpretability, as they are unable to explain or justify their results. To\naddress the challenge of interpretable image classification, this paper\nintroduces a novel framework, named Interpretable Intuitionistic Fuzzy\nCognitive Maps (I2FCMs).Intuitionistic FCMs (iFCMs) have been proposed as an\nextension of FCMs offering a natural mechanism to assess the quality of their\noutput through the estimation of hesitancy, a concept resembling human\nhesitation in decision making. In the context of image classification,\nhesitancy is considered as a degree of unconfidence with which an image is\ncategorized to a class. To the best of our knowledge this is the first time\niFCMs are applied for image classification. Further novel contributions of the\nintroduced framework include the following: a) a feature extraction process\nfocusing on the most informative image regions; b) a learning algorithm for\nautomatic data-driven determination of the intuitionistic fuzzy\ninterconnections of the iFCM, thereby reducing human intervention in the\ndefinition of the graph structure; c) an inherently interpretable\nclassification approach based on image contents, providing understandable\nexplanations of its predictions, using linguistic terms. Furthermore, the\nproposed I2FCM framework can be applied to DL models, including Convolutional\nNeural Network (CNN), rendering them interpretable. The effectiveness of I2FCM\nis evaluated on publicly available datasets, and the results confirm that it\ncan provide enhanced classification performance, while providing interpretable\ninferences.",
      "tldr_zh": "这篇论文提出了一种名为 Interpretable Intuitionistic Fuzzy Cognitive Maps (I2FCMs) 的新框架，用于解决深度学习 (DL) 在图像分类任务中的解释性不足问题。I2FCMs 扩展了 Intuitionistic Fuzzy Cognitive Maps (iFCMs)，通过评估 hesitancy（决策犹豫度）来量化分类不确定性，并引入特征提取过程、自动数据驱动的学习算法以及基于图像内容的语言解释方法，以减少人为干预并提供可理解的预测解释。该框架可应用于 DL 模型如 Convolutional Neural Network (CNN)，使其更具可解释性；在公开数据集上的实验结果显示，I2FCMs 实现了增强的分类性能，同时保持了固有的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted for possible journal publication",
      "pdf_url": "http://arxiv.org/pdf/2408.03745v2",
      "published_date": "2024-08-07 12:58:39 UTC",
      "updated_date": "2025-04-04 16:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:34:33.121906"
    },
    {
      "arxiv_id": "2408.03735v1",
      "title": "Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation",
      "title_zh": "通过量化感知尺度学习推进多模态大型语言模型的高效适应",
      "authors": [
        "Jingjing Xie",
        "Yuxin Zhang",
        "Mingbao Lin",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "abstract": "This paper presents the first study to explore the potential of parameter\nquantization for multimodal large language models to alleviate the significant\nresource constraint encountered during vision-language instruction tuning. We\nintroduce a Quantization-aware Scale LeArning method based on multimodal\nWarmup, termed QSLAW. This method is grounded in two key innovations: (1) The\nlearning of group-wise scale factors for quantized LLM weights to mitigate the\nquantization error arising from activation outliers and achieve more effective\nvision-language instruction tuning; (2) The implementation of a multimodal\nwarmup that progressively integrates linguistic and multimodal training\nsamples, thereby preventing overfitting of the quantized model to multimodal\ndata while ensuring stable adaptation of multimodal large language models to\ndownstream vision-language tasks. Extensive experiments demonstrate that models\nquantized by QSLAW perform on par with, or even surpass, their full-precision\ncounterparts, while facilitating up to 1.4 times reduction in VL tuning time\nand GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.",
      "tldr_zh": "这篇论文首次探讨了参数量化在多模态大型语言模型（Multimodal Large Language Models）上的潜力，以缓解视觉-语言指令微调（vision-language instruction tuning）时的资源限制。作者引入了 Quantization-aware Scale LeArning 方法（简称 QSLAW），包括学习分组规模因子（group-wise scale factors）来减少量化误差，以及多模态 warmup 策略来逐步整合语言和多模态数据，防止过拟合并确保模型稳定适应下游任务。实验结果显示，QSLAW 量化模型的表现与全精度模型相当或优于后者，同时减少了 1.4 倍的微调时间和 GPU 消耗。代码已开源在 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACMMM2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03735v1",
      "published_date": "2024-08-07 12:42:09 UTC",
      "updated_date": "2024-08-07 12:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:34:42.760853"
    },
    {
      "arxiv_id": "2408.11841v2",
      "title": "Could ChatGPT get an Engineering Degree? Evaluating Higher Education Vulnerability to AI Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Beatriz Borges",
        "Negar Foroutan",
        "Deniz Bayazit",
        "Anna Sotnikova",
        "Syrielle Montariol",
        "Tanya Nazaretzky",
        "Mohammadreza Banaei",
        "Alireza Sakhaeirad",
        "Philippe Servant",
        "Seyed Parsa Neshaei",
        "Jibril Frej",
        "Angelika Romanou",
        "Gail Weiss",
        "Sepideh Mamooler",
        "Zeming Chen",
        "Simin Fan",
        "Silin Gao",
        "Mete Ismayilzada",
        "Debjit Paul",
        "Alexandre Schöpfer",
        "Andrej Janchevski",
        "Anja Tiede",
        "Clarence Linden",
        "Emanuele Troiani",
        "Francesco Salvi",
        "Freya Behrens",
        "Giacomo Orsi",
        "Giovanni Piccioli",
        "Hadrien Sevel",
        "Louis Coulon",
        "Manuela Pineros-Rodriguez",
        "Marin Bonnassies",
        "Pierre Hellich",
        "Puck van Gerwen",
        "Sankalp Gambhir",
        "Solal Pirelli",
        "Thomas Blanchard",
        "Timothée Callens",
        "Toni Abi Aoun",
        "Yannick Calvino Alonso",
        "Yuri Cho",
        "Alberto Chiappa",
        "Antonio Sclocchi",
        "Étienne Bruno",
        "Florian Hofhammer",
        "Gabriel Pescia",
        "Geovani Rizk",
        "Leello Dadi",
        "Lucas Stoffl",
        "Manoel Horta Ribeiro",
        "Matthieu Bovel",
        "Yueyang Pan",
        "Aleksandra Radenovic",
        "Alexandre Alahi",
        "Alexander Mathis",
        "Anne-Florence Bitbol",
        "Boi Faltings",
        "Cécile Hébert",
        "Devis Tuia",
        "François Maréchal",
        "George Candea",
        "Giuseppe Carleo",
        "Jean-Cédric Chappelier",
        "Nicolas Flammarion",
        "Jean-Marie Fürbringer",
        "Jean-Philippe Pellet",
        "Karl Aberer",
        "Lenka Zdeborová",
        "Marcel Salathé",
        "Martin Jaggi",
        "Martin Rajman",
        "Mathias Payer",
        "Matthieu Wyart",
        "Michael Gastpar",
        "Michele Ceriotti",
        "Ola Svensson",
        "Olivier Lévêque",
        "Paolo Ienne",
        "Rachid Guerraoui",
        "Robert West",
        "Sanidhya Kashyap",
        "Valerio Piazza",
        "Viesturs Simanis",
        "Viktor Kuncak",
        "Volkan Cevher",
        "Philippe Schwaller",
        "Sacha Friedli",
        "Patrick Jermann",
        "Tanja Käser",
        "Antoine Bosselut"
      ],
      "abstract": "AI assistants are being increasingly used by students enrolled in higher\neducation institutions. While these tools provide opportunities for improved\nteaching and education, they also pose significant challenges for assessment\nand learning outcomes. We conceptualize these challenges through the lens of\nvulnerability, the potential for university assessments and learning outcomes\nto be impacted by student use of generative AI. We investigate the potential\nscale of this vulnerability by measuring the degree to which AI assistants can\ncomplete assessment questions in standard university-level STEM courses.\nSpecifically, we compile a novel dataset of textual assessment questions from\n50 courses at EPFL and evaluate whether two AI assistants, GPT-3.5 and GPT-4\ncan adequately answer these questions. We use eight prompting strategies to\nproduce responses and find that GPT-4 answers an average of 65.8% of questions\ncorrectly, and can even produce the correct answer across at least one\nprompting strategy for 85.1% of questions. When grouping courses in our dataset\nby degree program, these systems already pass non-project assessments of large\nnumbers of core courses in various degree programs, posing risks to higher\neducation accreditation that will be amplified as these models improve. Our\nresults call for revising program-level assessment design in higher education\nin light of advances in generative AI.",
      "tldr_zh": "本研究评估了 AI 助手（如 ChatGPT）对高等教育评估的潜在风险，聚焦于“vulnerability”概念，即学生使用生成式 AI 可能影响大学评估和学习成果。研究者编译了 EPFL 50 门 STEM courses 的评估问题数据集，并使用八种 prompting strategies 测试 GPT-3.5 和 GPT-4 的回答能力。结果显示，GPT-4 平均正确回答 65.8% 的问题，并在至少一种策略下正确回答 85.1% 的问题。进一步分析发现，这些模型已在多个学位程序的核心课程非项目评估中通过，可能会放大对高等教育认证的风险。论文呼吁高等教育机构在生成式 AI 进步下，修订程序-level 评估设计以应对这些挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11841v2",
      "published_date": "2024-08-07 12:11:49 UTC",
      "updated_date": "2024-11-27 10:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:34:56.891601"
    },
    {
      "arxiv_id": "2408.03706v1",
      "title": "Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Matthias Ruppik",
        "Michael Heck",
        "Carel van Niekerk",
        "Renato Vukovic",
        "Hsien-chin Lin",
        "Shutong Feng",
        "Marcus Zibrowius",
        "Milica Gašić"
      ],
      "abstract": "A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties.",
      "tldr_zh": "本论文探讨了基于上下文语言模型的序列标注任务中，直接训练分类器的局限性，包括无法关联嵌入向量与外部上下文，以及依赖微调潜在空间的问题。为此，研究引入了潜在空间的局部拓扑复杂性度量（local topology measures），这些度量通过分析数据存储中向量间的关系，提取描述性特征。实验应用这些特征于对话术语提取（dialogue term extraction），证明了词嵌入空间的局部结构（manifold hypothesis）可用于推断语义属性，从而提升任务性能而不需全面微调模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a long paper to SIGDIAL 2024. 9 pages, 2 figures, 3\n  tables",
      "pdf_url": "http://arxiv.org/pdf/2408.03706v1",
      "published_date": "2024-08-07 11:44:32 UTC",
      "updated_date": "2024-08-07 11:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:35:06.159876"
    },
    {
      "arxiv_id": "2408.03694v1",
      "title": "A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Emna Baccour",
        "Aiman Erbad",
        "Amr Mohamed",
        "Mounir Hamdi",
        "Mohsen Guizani"
      ],
      "abstract": "The metaverse, envisioned as the next digital frontier for avatar-based\nvirtual interaction, involves high-performance models. In this dynamic\nenvironment, users' tasks frequently shift, requiring fast model\npersonalization despite limited data. This evolution consumes extensive\nresources and requires vast data volumes. To address this, meta-learning\nemerges as an invaluable tool for metaverse users, with federated meta-learning\n(FML), offering even more tailored solutions owing to its adaptive\ncapabilities. However, the metaverse is characterized by users heterogeneity\nwith diverse data structures, varied tasks, and uneven sample sizes,\npotentially undermining global training outcomes due to statistical difference.\nGiven this, an urgent need arises for smart coalition formation that accounts\nfor these disparities. This paper introduces a dual game-theoretic framework\nfor metaverse services involving meta-learners as workers to manage FML. A\nblockchain-based cooperative coalition formation game is crafted, grounded on a\nreputation metric, user similarity, and incentives. We also introduce a novel\nreputation system based on users' historical contributions and potential\ncontributions to present tasks, leveraging correlations between past and new\ntasks. Finally, a Stackelberg game-based incentive mechanism is presented to\nattract reliable workers to participate in meta-learning, minimizing users'\nenergy costs, increasing payoffs, boosting FML efficacy, and improving\nmetaverse utility. Results show that our dual game framework outperforms\nbest-effort, random, and non-uniform clustering schemes - improving training\nperformance by up to 10%, cutting completion times by as much as 30%, enhancing\nmetaverse utility by more than 25%, and offering up to 5% boost in training\nefficiency over non-blockchain systems, effectively countering misbehaving\nusers.",
      "tldr_zh": "本研究针对元宇宙（metaverse）中用户任务频繁变化和数据异质性问题，提出了一种基于区块链的可靠联邦元学习（FML）框架，利用双重博弈理论来优化模型个性化。该框架包括一个合作联盟形成游戏，基于声誉指标（reputation metric）、用户相似性和激励机制，以及一个Stackelberg游戏-based激励机制，以吸引可靠参与者、减少能源成本并提升训练效率。实验结果显示，该框架相较于best-effort、random和non-uniform clustering方案，提高训练性能达10%、缩短完成时间30%、提升元宇宙效用25%，并有效对抗不良用户行为。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted in IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2408.03694v1",
      "published_date": "2024-08-07 11:14:18 UTC",
      "updated_date": "2024-08-07 11:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:35:19.026848"
    },
    {
      "arxiv_id": "2408.03691v1",
      "title": "Generative Design of Periodic Orbits in the Restricted Three-Body Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Alvaro Francisco Gil",
        "Walther Litteri",
        "Victor Rodriguez-Fernandez",
        "David Camacho",
        "Massimiliano Vasile"
      ],
      "abstract": "The Three-Body Problem has fascinated scientists for centuries and it has\nbeen crucial in the design of modern space missions. Recent developments in\nGenerative Artificial Intelligence hold transformative promise for addressing\nthis longstanding problem. This work investigates the use of Variational\nAutoencoder (VAE) and its internal representation to generate periodic orbits.\nWe utilize a comprehensive dataset of periodic orbits in the Circular\nRestricted Three-Body Problem (CR3BP) to train deep-learning architectures that\ncapture key orbital characteristics, and we set up physical evaluation metrics\nfor the generated trajectories. Through this investigation, we seek to enhance\nthe understanding of how Generative AI can improve space mission planning and\nastrodynamics research, leading to novel, data-driven approaches in the field.",
      "tldr_zh": "本研究探讨了利用生成式人工智能生成三体问题（Three-Body Problem）中的周期轨道（periodic orbits），以提升太空任务设计。研究采用 Variational Autoencoder (VAE) 及其内部表示，基于 Circular Restricted Three-Body Problem (CR3BP) 的全面数据集训练深度学习模型，并设置物理评价指标评估生成的轨迹。通过这一方法，论文展示了生成式 AI 如何提供新型数据驱动的途径，改善空间任务规划和天体力学研究。",
      "categories": [
        "cs.LG",
        "astro-ph.EP",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SPAICE Conference 2024 (7 pages)",
      "pdf_url": "http://arxiv.org/pdf/2408.03691v1",
      "published_date": "2024-08-07 11:13:19 UTC",
      "updated_date": "2024-08-07 11:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:35:31.923915"
    },
    {
      "arxiv_id": "2408.03648v1",
      "title": "HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Juho Jung",
        "Chaewon Kang",
        "Jeewoo Yoon",
        "Seungbae Kim",
        "Jinyoung Han"
      ],
      "abstract": "The utilization of automated depression detection significantly enhances\nearly intervention for individuals experiencing depression. Despite numerous\nproposals on automated depression detection using recorded clinical interview\nvideos, limited attention has been paid to considering the hierarchical\nstructure of the interview questions. In clinical interviews for diagnosing\ndepression, clinicians use a structured questionnaire that includes routine\nbaseline questions and follow-up questions to assess the interviewee's\ncondition. This paper introduces HiQuE (Hierarchical Question Embedding\nnetwork), a novel depression detection framework that leverages the\nhierarchical relationship between primary and follow-up questions in clinical\ninterviews. HiQuE can effectively capture the importance of each question in\ndiagnosing depression by learning mutual information across multiple\nmodalities. We conduct extensive experiments on the widely-used clinical\ninterview data, DAIC-WOZ, where our model outperforms other state-of-the-art\nmultimodal depression detection models and emotion recognition models,\nshowcasing its clinical utility in depression detection.",
      "tldr_zh": "本文提出 HiQuE（Hierarchical Question Embedding Network），一种新型多模态抑郁检测框架，旨在利用临床访谈中基础问题和后续问题之间的层次关系，提高抑郁诊断的准确性。HiQuE 通过学习多模态间的互信息（如视觉和音频），有效捕捉每个问题在抑郁评估中的重要性。在 DAIC-WOZ 数据集上的实验显示，该模型优于现有最先进的多模态抑郁检测和情感识别模型，展示了其在临床应用中的显著潜力。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures, Proceedings of the 33rd ACM International\n  Conference on Information and Knowledge Management (CIKM '24)",
      "pdf_url": "http://arxiv.org/pdf/2408.03648v1",
      "published_date": "2024-08-07 09:23:01 UTC",
      "updated_date": "2024-08-07 09:23:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:35:43.957235"
    },
    {
      "arxiv_id": "2408.12602v1",
      "title": "Fiber neural networks for the intelligent optical fiber communications",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Zang",
        "Zuxing Zhang",
        "Simin Li",
        "Fangzheng Zhang",
        "Hongwei Chen"
      ],
      "abstract": "Optical neural networks have long cast attention nowadays. Like other optical\nstructured neural networks, fiber neural networks which utilize the mechanism\nof light transmission to compute can take great advantages in both computing\nefficiency and power cost. Though the potential ability of optical fiber was\ndemonstrated via the establishing of fiber neural networks, it will be of great\nsignificance of combining both fiber transmission and computing functions so as\nto cater the needs of future beyond 5G intelligent communication signal\nprocessing. Thus, in this letter, the fiber neural networks and their related\noptical signal processing methods will be both developed. In this way,\ninformation derived from the transmitted signals can be directly processed in\nthe optical domain rather than being converted to the electronic domain. As a\nresult, both prominent gains in processing efficiency and power cost can be\nfurther obtained. The fidelity of the whole structure and related methods is\ndemonstrated by the task of modulation format recognition which plays important\nrole in fiber optical communications without losing the generality.",
      "tldr_zh": "该论文提出了一种光纤神经网络（fiber neural networks），利用光传输机制进行计算，以显著提高计算效率和功率成本，适用于未来超 5G 智能通信信号处理。研究开发了结合光纤传输和计算功能的结构及相关光学信号处理方法，使信息能够在光学域直接处理，而非转换为电子域，从而进一步提升处理效率和降低能耗。通过调制格式识别任务的实验验证，该框架的保真性和有效性得到证明，在光纤通信中展示了重要潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12602v1",
      "published_date": "2024-08-07 08:46:48 UTC",
      "updated_date": "2024-08-07 08:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:35:54.441746"
    },
    {
      "arxiv_id": "2408.03632v3",
      "title": "Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zebin Yao",
        "Fangxiang Feng",
        "Ruifan Li",
        "Xiaojie Wang"
      ],
      "abstract": "The customization of text-to-image models has seen significant advancements,\nyet generating multiple personalized concepts remains a challenging task.\nCurrent methods struggle with attribute leakage and layout confusion when\nhandling multiple concepts, leading to reduced concept fidelity and semantic\nconsistency. In this work, we introduce a novel training-free framework,\nConcept Conductor, designed to ensure visual fidelity and correct layout in\nmulti-concept customization. Concept Conductor isolates the sampling processes\nof multiple custom models to prevent attribute leakage between different\nconcepts and corrects erroneous layouts through self-attention-based spatial\nguidance. Additionally, we present a concept injection technique that employs\nshape-aware masks to specify the generation area for each concept. This\ntechnique injects the structure and appearance of personalized concepts through\nfeature fusion in the attention layers, ensuring harmony in the final image.\nExtensive qualitative and quantitative experiments demonstrate that Concept\nConductor can consistently generate composite images with accurate layouts\nwhile preserving the visual details of each concept. Compared to existing\nbaselines, Concept Conductor shows significant performance improvements. Our\nmethod supports the combination of any number of concepts and maintains high\nfidelity even when dealing with visually similar concepts. The code and models\nare available at https://github.com/Nihukat/Concept-Conductor.",
      "tldr_zh": "该论文介绍了 Concept Conductor，一种无需训练的框架，用于文本到图像合成中处理多个个性化概念的问题，解决了现有方法中的 attribute leakage 和 layout confusion 问题。该框架通过隔离多个自定义模型的采样过程、self-attention-based spatial guidance 修正布局错误，以及 shape-aware masks 的概念注入技术在注意力层进行特征融合，确保图像的视觉保真度和语义一致性。实验结果显示，Concept Conductor 在生成复合图像时显著优于基线模型，支持任意数量概念的组合，即使概念视觉相似，也能保持高保真度。代码和模型已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Github Page: https://github.com/Nihukat/Concept-Conductor",
      "pdf_url": "http://arxiv.org/pdf/2408.03632v3",
      "published_date": "2024-08-07 08:43:58 UTC",
      "updated_date": "2024-09-09 12:26:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:36:08.200802"
    },
    {
      "arxiv_id": "2408.03631v2",
      "title": "Large Language Model as a Catalyst: A Paradigm Shift in Base Station Siting Optimization",
      "title_zh": "大型语言模型作为催化剂：基站选址优化的范式转变",
      "authors": [
        "Yanhu Wang",
        "Muhammad Muzammil Afzal",
        "Zhengyang Li",
        "Jie Zhou",
        "Chenyuan Feng",
        "Shuaishuai Guo",
        "Tony Q. S. Quek"
      ],
      "abstract": "Traditional base station siting (BSS) methods rely heavily on drive testing\nand user feedback, which are laborious and require extensive expertise in\ncommunication, networking, and optimization. As large language models (LLMs)\nand their associated technologies advance, particularly in the realms of prompt\nengineering and agent engineering, network optimization will witness a\nrevolutionary approach. This approach entails the strategic use of well-crafted\nprompts to infuse human experience and knowledge into these sophisticated LLMs,\nand the deployment of autonomous agents as a communication bridge to seamlessly\nconnect the machine language based LLMs with human users using natural\nlanguage. Furthermore, our proposed framework incorporates retrieval-augmented\ngeneration (RAG) to enhance the system's ability to acquire domain-specific\nknowledge and generate solutions, thereby enabling the customization and\noptimization of the BSS process. This integration represents the future\nparadigm of artificial intelligence (AI) as a service and AI for more ease.\nThis research first develops a novel LLM-empowered BSS optimization framework,\nand heuristically proposes three different potential implementations: the\nstrategies based on Prompt-optimized LLM (PoL), LLM-empowered autonomous BSS\nagent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa).\nThrough evaluation on real-world data, the experiments demonstrate that\nprompt-assisted LLMs and LLM-based agents can generate more efficient and\nreliable network deployments, noticeably enhancing the efficiency of BSS\noptimization and reducing trivial manual participation.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）在基站选址优化（BSS）中的催化作用，取代传统依赖驾驶测试和用户反馈的劳动密集型方法，转向更高效的AI驱动范式。该框架利用提示工程、自主代理和检索增强生成（RAG）技术，将人类经验注入LLMs，并通过代理桥接自然语言交互，从而定制化BSS过程并提升领域知识获取能力。研究提出三种实现策略：基于提示优化的LLM（PoL）、LLM赋能的自主BSS代理（LaBa）和合作的多LLM自主BSS代理（CLaBa）；实验在真实数据上证明，这些方法显著提高了网络部署效率和可靠性，减少了手动参与。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03631v2",
      "published_date": "2024-08-07 08:43:32 UTC",
      "updated_date": "2024-12-26 02:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:36:20.814199"
    },
    {
      "arxiv_id": "2408.03622v1",
      "title": "Improving the quality of Persian clinical text with a novel spelling correction system",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Sadegh Dashti",
        "Seyedeh Fatemeh Dashti"
      ],
      "abstract": "Background: The accuracy of spelling in Electronic Health Records (EHRs) is a\ncritical factor for efficient clinical care, research, and ensuring patient\nsafety. The Persian language, with its abundant vocabulary and complex\ncharacteristics, poses unique challenges for real-word error correction. This\nresearch aimed to develop an innovative approach for detecting and correcting\nspelling errors in Persian clinical text.\n  Methods: Our strategy employs a state-of-the-art pre-trained model that has\nbeen meticulously fine-tuned specifically for the task of spelling correction\nin the Persian clinical domain. This model is complemented by an innovative\northographic similarity matching algorithm, PERTO, which uses visual similarity\nof characters for ranking correction candidates.\n  Results: The evaluation of our approach demonstrated its robustness and\nprecision in detecting and rectifying word errors in Persian clinical text. In\nterms of non-word error correction, our model achieved an F1-Score of 90.0%\nwhen the PERTO algorithm was employed. For real-word error detection, our model\ndemonstrated its highest performance, achieving an F1-Score of 90.6%.\nFurthermore, the model reached its highest F1-Score of 91.5% for real-word\nerror correction when the PERTO algorithm was employed.\n  Conclusions: Despite certain limitations, our method represents a substantial\nadvancement in the field of spelling error detection and correction for Persian\nclinical text. By effectively addressing the unique challenges posed by the\nPersian language, our approach paves the way for more accurate and efficient\nclinical documentation, contributing to improved patient care and safety.\nFuture research could explore its use in other areas of the Persian medical\ndomain, enhancing its impact and utility.",
      "tldr_zh": "这篇论文针对Persian临床文本的拼写错误问题，提出了一种创新的修正系统，以提升Electronic Health Records (EHRs)的准确性并应对Persian语言的独特挑战。方法包括微调一个预训练模型，并结合PERTO算法，该算法通过字符视觉相似性来排名修正候选，从而实现高效的错误检测和修正。结果显示，该系统在非词错误修正中F1-Score达到90.0%，在真实词错误检测中达90.6%，而在真实词错误修正中最高达91.5%。总体而言，该方法显著改善了临床文档的质量，促进患者护理和安全，并为Persian医疗领域的进一步应用铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03622v1",
      "published_date": "2024-08-07 08:31:42 UTC",
      "updated_date": "2024-08-07 08:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:36:32.150221"
    },
    {
      "arxiv_id": "2408.03618v4",
      "title": "A Logical Fallacy-Informed Framework for Argument Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Mouchel",
        "Debjit Paul",
        "Shaobo Cui",
        "Robert West",
        "Antoine Bosselut",
        "Boi Faltings"
      ],
      "abstract": "Despite the remarkable performance of Large Language Models (LLMs) in natural\nlanguage processing tasks, they still struggle with generating logically sound\narguments, resulting in potential risks such as spreading misinformation. To\naddress this issue, we introduce FIPO, a fallacy-informed framework that\nleverages preference optimization methods to steer LLMs toward logically sound\narguments. FIPO includes a classification loss, to capture the fine-grained\ninformation on fallacy types. Our results on argumentation datasets show that\nour method reduces the fallacy errors by up to 17.5%. Furthermore, our human\nevaluation results indicate that the quality of the generated arguments by our\nmethod significantly outperforms the fine-tuned baselines, as well as other\npreference optimization methods, such as DPO. These findings highlight the\nimportance of ensuring models are aware of logical fallacies for effective\nargument generation. Our code is available at\ngithub.com/lucamouchel/Logical-Fallacies.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 在生成论点时易犯逻辑谬误并传播错误信息的问题，提出 FIPO 框架，该框架通过偏好优化方法引导 LLMs 产生逻辑严谨的论点，并引入 classification loss 来捕捉细粒度的谬误类型。实验结果显示，FIPO 在论证数据集上将谬误错误减少了多达 17.5%，且人类评估表明其生成的论点质量显著优于微调基线和 DPO 等其他偏好优化方法。这些发现突出了确保模型对逻辑谬误的认知对于有效论点生成的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03618v4",
      "published_date": "2024-08-07 08:19:44 UTC",
      "updated_date": "2025-05-03 18:52:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:36:45.014311"
    },
    {
      "arxiv_id": "2408.03617v2",
      "title": "Is Child-Directed Speech Effective Training Data for Language Models?",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Y. Feng",
        "Noah D. Goodman",
        "Michael C. Frank"
      ],
      "abstract": "While high-performing language models are typically trained on hundreds of\nbillions of words, human children become fluent language users with a much\nsmaller amount of data. What are the features of the data they receive, and how\ndo these features support language modeling objectives? To investigate this\nquestion, we train GPT-2 and RoBERTa models on 29M words of English\nchild-directed speech and a new matched, synthetic dataset (TinyDialogues),\ncomparing to OpenSubtitles, Wikipedia, and a heterogeneous blend of datasets\nfrom the BabyLM challenge. We evaluate the syntactic and semantic knowledge of\nthese models using developmentally-inspired evaluations. Through pretraining\nexperiments, we test whether the global developmental ordering or the local\ndiscourse ordering of children's training data supports high performance\nrelative to other datasets. The local properties of the data affect model\nresults, but surprisingly, global properties do not. Further, child language\ninput is not uniquely valuable for training language models. These findings\nsupport the hypothesis that, rather than proceeding from better data, the\nchild's learning algorithm is substantially more data-efficient than current\nlanguage modeling techniques.",
      "tldr_zh": "本研究探讨了儿童导向语音（child-directed speech）是否能作为有效训练数据用于语言模型（如 GPT-2 和 RoBERTa），并与人类儿童高效学习语言进行对比。研究者使用 2900 万词的英语儿童导向语音数据集和一个新合成数据集 TinyDialogues 进行模型训练，并与 OpenSubtitles、Wikipedia 及 BabyLM 挑战的混合数据集比较，通过 developmentally-inspired 评估测试模型的句法和语义知识。实验结果显示，数据的本地话语属性影响模型性能，但全局发展顺序并不显著，且儿童语言输入并非独特有价值，这支持了儿童学习算法比当前语言建模技术更高效的假设。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024. Code and data at https://github.com/styfeng/TinyDialogues",
      "pdf_url": "http://arxiv.org/pdf/2408.03617v2",
      "published_date": "2024-08-07 08:18:51 UTC",
      "updated_date": "2024-10-08 20:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:36:56.737910"
    },
    {
      "arxiv_id": "2408.03615v2",
      "title": "Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks",
      "title_zh": "Optimus-1：混合多模态记忆增强代理在长时域任务中",
      "authors": [
        "Zaijing Li",
        "Yuquan Xie",
        "Rui Shao",
        "Gongwei Chen",
        "Dongmei Jiang",
        "Liqiang Nie"
      ],
      "abstract": "Building a general-purpose agent is a long-standing vision in the field of\nartificial intelligence. Existing agents have made remarkable progress in many\ndomains, yet they still struggle to complete long-horizon tasks in an open\nworld. We attribute this to the lack of necessary world knowledge and\nmultimodal experience that can guide agents through a variety of long-horizon\ntasks. In this paper, we propose a Hybrid Multimodal Memory module to address\nthe above challenges. It 1) transforms knowledge into Hierarchical Directed\nKnowledge Graph that allows agents to explicitly represent and learn world\nknowledge, and 2) summarises historical information into Abstracted Multimodal\nExperience Pool that provide agents with rich references for in-context\nlearning. On top of the Hybrid Multimodal Memory module, a multimodal agent,\nOptimus-1, is constructed with dedicated Knowledge-guided Planner and\nExperience-Driven Reflector, contributing to a better planning and reflection\nin the face of long-horizon tasks in Minecraft. Extensive experimental results\nshow that Optimus-1 significantly outperforms all existing agents on\nchallenging long-horizon task benchmarks, and exhibits near human-level\nperformance on many tasks. In addition, we introduce various Multimodal Large\nLanguage Models (MLLMs) as the backbone of Optimus-1. Experimental results show\nthat Optimus-1 exhibits strong generalization with the help of the Hybrid\nMultimodal Memory module, outperforming the GPT-4V baseline on many tasks.",
      "tldr_zh": "本文提出了一种名为 Optimus-1 的多模态智能体框架，利用 Hybrid Multimodal Memory 模块来解决现有智能体在开放世界长时序任务（long-horizon tasks）中的不足，该模块包括 Hierarchical Directed Knowledge Graph 用于明确表示和学习世界知识，以及 Abstracted Multimodal Experience Pool 用于总结历史信息以支持上下文学习。Optimus-1 还整合了 Knowledge-guided Planner 和 Experience-Driven Reflector，以提升规划和反思能力。实验结果显示，Optimus-1 在 Minecraft 等基准任务上显著优于现有智能体，并在许多任务中接近人类水平，同时使用各种 Multimodal Large Language Models (MLLMs) 作为骨干时，表现出强泛化能力，优于 GPT-4V 基线。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03615v2",
      "published_date": "2024-08-07 08:16:32 UTC",
      "updated_date": "2024-10-21 11:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:37:10.188908"
    },
    {
      "arxiv_id": "2408.03603v1",
      "title": "EnJa: Ensemble Jailbreak on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Zhang",
        "Zilong Wang",
        "Ruofan Wang",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "abstract": "As Large Language Models (LLMs) are increasingly being deployed in\nsafety-critical applications, their vulnerability to potential jailbreaks --\nmalicious prompts that can disable the safety mechanism of LLMs -- has\nattracted growing research attention. While alignment methods have been\nproposed to protect LLMs from jailbreaks, many have found that aligned LLMs can\nstill be jailbroken by carefully crafted malicious prompts, producing content\nthat violates policy regulations. Existing jailbreak attacks on LLMs can be\ncategorized into prompt-level methods which make up stories/logic to circumvent\nsafety alignment and token-level attack methods which leverage gradient methods\nto find adversarial tokens. In this work, we introduce the concept of Ensemble\nJailbreak and explore methods that can integrate prompt-level and token-level\njailbreak into a more powerful hybrid jailbreak attack. Specifically, we\npropose a novel EnJa attack to hide harmful instructions using prompt-level\njailbreak, boost the attack success rate using a gradient-based attack, and\nconnect the two types of jailbreak attacks via a template-based connector. We\nevaluate the effectiveness of EnJa on several aligned models and show that it\nachieves a state-of-the-art attack success rate with fewer queries and is much\nstronger than any individual jailbreak.",
      "tldr_zh": "本研究提出EnJa，一种集成式jailbreak攻击方法，旨在利用prompt-level和token-level攻击相结合，突破Large Language Models (LLMs)的安全对齐机制。EnJa通过prompt-level方法隐藏有害指令、gradient-based攻击提升成功率，并使用template-based连接器整合两种攻击类型，从而实现更高效的混合攻击。实验结果显示，EnJa在多个对齐模型上达到了最先进的攻击成功率，同时只需更少的查询次数，比单一jailbreak攻击更具优势。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03603v1",
      "published_date": "2024-08-07 07:46:08 UTC",
      "updated_date": "2024-08-07 07:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:37:19.651938"
    },
    {
      "arxiv_id": "2408.03599v2",
      "title": "Activations Through Extensions: A Framework To Boost Performance Of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Chandramouli Kamanchi",
        "Sumanta Mukherjee",
        "Kameshwaran Sampath",
        "Pankaj Dayama",
        "Arindam Jati",
        "Vijay Ekambaram",
        "Dzung Phan"
      ],
      "abstract": "Activation functions are non-linearities in neural networks that allow them\nto learn complex mapping between inputs and outputs. Typical choices for\nactivation functions are ReLU, Tanh, Sigmoid etc., where the choice generally\ndepends on the application domain. In this work, we propose a\nframework/strategy that unifies several works on activation functions and\ntheoretically explains the performance benefits of these works. We also propose\nnovel techniques that originate from the framework and allow us to obtain\n``extensions'' (i.e. special generalizations of a given neural network) of\nneural networks through operations on activation functions. We theoretically\nand empirically show that ``extensions'' of neural networks have performance\nbenefits compared to vanilla neural networks with insignificant space and time\ncomplexity costs on standard test functions. We also show the benefits of\nneural network ``extensions'' in the time-series domain on real-world datasets.",
      "tldr_zh": "本研究提出了一种框架，用于统一和理论解释激活函数（如ReLU、Tanh、Sigmoid）在神经网络中的性能优势。该框架通过对激活函数的操作，开发新技巧来创建神经网络的“extensions”（特殊泛化），从而提升网络性能。实验结果显示，这些“extensions”在标准测试函数上比原生神经网络表现出色，同时空间和时间复杂度成本微不足道；此外，在时间序列领域的真实数据集上，也验证了其实际益处。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.NE",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03599v2",
      "published_date": "2024-08-07 07:36:49 UTC",
      "updated_date": "2024-08-16 01:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:37:30.041721"
    },
    {
      "arxiv_id": "2408.03591v1",
      "title": "Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Benedikt W. Hosp",
        "Björn Severitt",
        "Rajat Agarwala",
        "Evgenia Rusak",
        "Yannick Sauer",
        "Siegfried Wahl"
      ],
      "abstract": "In an era where personalized technology is increasingly intertwined with\ndaily life, traditional eye-tracking systems and autofocal glasses face a\nsignificant challenge: the need for frequent, user-specific calibration, which\nimpedes their practicality. This study introduces a groundbreaking\ncalibration-free method for estimating focal depth, leveraging machine learning\ntechniques to analyze eye movement features within short sequences. Our\napproach, distinguished by its innovative use of LSTM networks and\ndomain-specific feature engineering, achieves a mean absolute error (MAE) of\nless than 10 cm, setting a new focal depth estimation accuracy standard. This\nadvancement promises to enhance the usability of autofocal glasses and pave the\nway for their seamless integration into extended reality environments, marking\na significant leap forward in personalized visual technology.",
      "tldr_zh": "这篇论文提出了一种无需校准、独立于用户和时间因素的焦点深度估计方法，旨在解决传统眼动追踪系统和自动焦点眼镜的实用性问题。方法利用 LSTM 网络和特定领域的眼动特征工程，对短序列眼动数据进行分析，实现平均绝对误差 (MAE) 小于 10 cm 的高精度。研究成果有望提升自动焦点眼镜的可用性，并推动其在扩展现实 (extended reality) 环境中的无缝整合。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03591v1",
      "published_date": "2024-08-07 07:09:14 UTC",
      "updated_date": "2024-08-07 07:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:37:43.029264"
    },
    {
      "arxiv_id": "2408.03972v1",
      "title": "Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Keiichiro Yamamura",
        "Issa Oe",
        "Hiroki Ishikura",
        "Katsuki Fujisawa"
      ],
      "abstract": "Deep neural networks are vulnerable to adversarial examples, and adversarial\nattacks that generate adversarial examples have been studied in this context.\nExisting studies imply that increasing the diversity of model outputs\ncontributes to improving the attack performance. This study focuses on the Auto\nConjugate Gradient (ACG) attack, which is inspired by the conjugate gradient\nmethod and has a high diversification performance. We hypothesized that\nincreasing the distance between two consecutive search points would enhance the\noutput diversity. To test our hypothesis, we propose Rescaling-ACG (ReACG),\nwhich automatically modifies the two components that significantly affect the\ndistance between two consecutive search points, including the search direction\nand step size. ReACG showed higher attack performance than that of ACG, and is\nparticularly effective for ImageNet models with several classification classes.\nExperimental results show that the distance between two consecutive search\npoints enhances the output diversity and may help develop new potent attacks.\nThe code is available at \\url{https://github.com/yamamura-k/ReACG}",
      "tldr_zh": "本研究探讨了增强输出多样性如何提升基于 Conjugate Gradient 的对抗攻击性能，特别针对 Auto Conjugate Gradient (ACG) 攻击提出假设，即增加连续搜索点之间的距离可改善攻击效果。研究者开发了 Rescaling-ACG (ReACG) 方法，通过自动调整搜索方向和步长来实现这一目标。实验结果显示，ReACG 在 ImageNet 模型上比 ACG 攻击性能更高，尤其在多分类场景下提升显著，并证明了输出多样性的增强有助于开发更有效的对抗攻击。代码已开源，可从指定链接获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICPRAI2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03972v1",
      "published_date": "2024-08-07 07:07:35 UTC",
      "updated_date": "2024-08-07 07:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:38:05.183898"
    },
    {
      "arxiv_id": "2408.03588v2",
      "title": "Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation",
      "title_zh": "翻译失败",
      "authors": [
        "Karn N. Watcharasupat",
        "Chih-Wei Wu",
        "Iroro Orife"
      ],
      "abstract": "Cinematic audio source separation (CASS), as a standalone problem of\nextracting individual stems from their mixture, is a fairly new subtask of\naudio source separation. A typical setup of CASS is a three-stem problem, with\nthe aim of separating the mixture into the dialogue (DX), music (MX), and\neffects (FX) stems. Given the creative nature of cinematic sound production,\nhowever, several edge cases exist; some sound sources do not fit neatly in any\nof these three stems, necessitating the use of additional auxiliary stems in\nproduction. One very common edge case is the singing voice in film audio, which\nmay belong in either the DX or MX or neither, depending heavily on the\ncinematic context. In this work, we demonstrate a very straightforward\nextension of the dedicated-decoder Bandit and query-based single-decoder\nBanquet models to a four-stem problem, treating non-musical dialogue,\ninstrumental music, singing voice, and effects as separate stems.\nInterestingly, the query-based Banquet model outperformed the dedicated-decoder\nBandit model. We hypothesized that this is due to a better feature alignment at\nthe bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.",
      "tldr_zh": "本研究针对电影音频源分离（CASS）中的边缘案例，探讨了唱歌声音的分离问题，该声音可能不适合标准的三分离（对话DX、音乐MX和效果FX）设置。作者扩展了专用解码器Bandit模型和查询-based单解码器Banquet模型，将其应用于四分离任务，将唱歌声音作为独立stems。结果显示，Banquet模型优于Bandit模型，可能归因于band-agnostic FiLM层的更好特征对齐；数据集和模型实现将公开在GitHub上，以推动相关研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to the Late-Breaking Demo Session of the 25th International\n  Society for Music Information Retrieval (ISMIR) Conference, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03588v2",
      "published_date": "2024-08-07 07:04:29 UTC",
      "updated_date": "2024-08-26 00:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:38:18.284273"
    },
    {
      "arxiv_id": "2408.03585v1",
      "title": "Hierarchical Neural Constructive Solver for Real-world TSP Scenarios",
      "title_zh": "用于真实世界 TSP 场景的层次化神经构造性求解器",
      "authors": [
        "Yong Liang Goh",
        "Zhiguang Cao",
        "Yining Ma",
        "Yanfei Dong",
        "Mohammed Haroon Dupty",
        "Wee Sun Lee"
      ],
      "abstract": "Existing neural constructive solvers for routing problems have predominantly\nemployed transformer architectures, conceptualizing the route construction as a\nset-to-sequence learning task. However, their efficacy has primarily been\ndemonstrated on entirely random problem instances that inadequately capture\nreal-world scenarios. In this paper, we introduce realistic Traveling Salesman\nProblem (TSP) scenarios relevant to industrial settings and derive the\nfollowing insights: (1) The optimal next node (or city) to visit often lies\nwithin proximity to the current node, suggesting the potential benefits of\nbiasing choices based on current locations. (2) Effectively solving the TSP\nrequires robust tracking of unvisited nodes and warrants succinct grouping\nstrategies. Building upon these insights, we propose integrating a learnable\nchoice layer inspired by Hypernetworks to prioritize choices based on the\ncurrent location, and a learnable approximate clustering algorithm inspired by\nthe Expectation-Maximization algorithm to facilitate grouping the unvisited\ncities. Together, these two contributions form a hierarchical approach towards\nsolving the realistic TSP by considering both immediate local neighbourhoods\nand learning an intermediate set of node representations. Our hierarchical\napproach yields superior performance compared to both classical and recent\ntransformer models, showcasing the efficacy of the key designs.",
      "tldr_zh": "该论文针对真实世界旅行 salesman 问题 (TSP) 场景，批评现有基于 Transformer 的神经构建求解器仅在随机实例上有效。研究者从工业相关 TSP 中得出洞见：(1) 最优下一个节点通常靠近当前节点，因此需要基于位置偏好选择；(2) 需要有效跟踪未访问节点并采用分组策略。论文提出一个分层方法，包括受 Hypernetworks 启发的可学习选择层和受 Expectation-Maximization 算法启发的近似聚类算法，以优化局部邻域和节点表示。该方法在真实 TSP 场景中比经典和 Transformer 模型表现出色，证明了其关键设计的效能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03585v1",
      "published_date": "2024-08-07 06:44:47 UTC",
      "updated_date": "2024-08-07 06:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:38:30.755732"
    },
    {
      "arxiv_id": "2408.03573v1",
      "title": "Active Testing of Large Language Model via Multi-Stage Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Huang",
        "Jiayang Song",
        "Qiang Hu",
        "Felix Juefei-Xu",
        "Lei Ma"
      ],
      "abstract": "Performance evaluation plays a crucial role in the development life cycle of\nlarge language models (LLMs). It estimates the model's capability, elucidates\nbehavior characteristics, and facilitates the identification of potential\nissues and limitations, thereby guiding further improvement. Given that LLMs'\ndiverse task-handling abilities stem from large volumes of training data, a\ncomprehensive evaluation also necessitates abundant, well-annotated, and\nrepresentative test data to assess LLM performance across various downstream\ntasks. However, the demand for high-quality test data often entails substantial\ntime, computational resources, and manual efforts, sometimes causing the\nevaluation to be inefficient or impractical. To address these challenges,\nresearchers propose active testing, which estimates the overall performance by\nselecting a subset of test data. Nevertheless, the existing active testing\nmethods tend to be inefficient, even inapplicable, given the unique new\nchallenges of LLMs (e.g., diverse task types, increased model complexity, and\nunavailability of training data). To mitigate such limitations and expedite the\ndevelopment cycle of LLMs, in this work, we introduce AcTracer, an active\ntesting framework tailored for LLMs that strategically selects a small subset\nof test data to achieve a nearly optimal performance estimation for LLMs.\nAcTracer utilizes both internal and external information from LLMs to guide the\ntest sampling process, reducing variance through a multi-stage pool-based\nactive selection. Our experiment results demonstrate that AcTracer achieves\nstate-of-the-art performance compared to existing methods across various tasks,\nwith up to 38.83% improvement over previous SOTA.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的性能评估问题，强调高质量测试数据的需求往往导致资源消耗过大。针对现有主动测试方法的不足，作者提出AcTracer框架，通过多阶段基于池的主动采样，利用LLMs的内部和外部信息来选择子集测试数据，从而高效估计模型性能并减少方差。实验结果显示，AcTracer在各种任务上比现有最先进方法（SOTA）提升高达38.83%，加速了LLMs的开发周期。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "D.2.5; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03573v1",
      "published_date": "2024-08-07 06:17:48 UTC",
      "updated_date": "2024-08-07 06:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:38:40.274470"
    },
    {
      "arxiv_id": "2408.03572v2",
      "title": "2D-OOB: Attributing Data Contribution Through Joint Valuation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Sun",
        "Jingyan Shen",
        "Yongchan Kwon"
      ],
      "abstract": "Data valuation has emerged as a powerful framework for quantifying each\ndatum's contribution to the training of a machine learning model. However, it\nis crucial to recognize that the quality of cells within a single data point\ncan vary greatly in practice. For example, even in the case of an abnormal data\npoint, not all cells are necessarily noisy. The single scalar score assigned by\nexisting data valuation methods blurs the distinction between noisy and clean\ncells of a data point, making it challenging to interpret the data values. In\nthis paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly\ndetermining helpful (or detrimental) samples as well as the particular cells\nthat drive them. Our comprehensive experiments demonstrate that 2D-OOB achieves\nstate-of-the-art performance across multiple use cases while being\nexponentially faster. Specifically, 2D-OOB shows promising results in detecting\nand rectifying fine-grained outliers at the cell level, and localizing backdoor\ntriggers in data poisoning attacks.",
      "tldr_zh": "该论文针对数据估值（Data valuation）方法的问题，提出2D-OOB框架，通过out-of-bag estimation联合评估每个数据样本的整体贡献及其特定单元（cells）的细粒度作用，从而区分有帮助或有害的部分。不同于现有方法仅输出单一标量分数，2D-OOB能够更准确地识别噪声和干净单元。实验结果表明，该框架在多个应用场景中实现最先进性能，同时计算速度更快，尤其在检测细粒度outliers和定位backdoor triggers方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03572v2",
      "published_date": "2024-08-07 06:16:17 UTC",
      "updated_date": "2024-10-30 04:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:38:54.320846"
    },
    {
      "arxiv_id": "2408.03562v1",
      "title": "A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case",
      "title_zh": "翻译失败",
      "authors": [
        "Sonia Meyer",
        "Shreya Singh",
        "Bertha Tam",
        "Christopher Ton",
        "Angel Ren"
      ],
      "abstract": "This research compares large language model (LLM) fine-tuning methods,\nincluding Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning\n(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally\ncompared LLM evaluation methods including End to End (E2E) benchmark method of\n\"Golden Answers\", traditional natural language processing (NLP) metrics, RAG\nAssessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,\nusing the travel chatbot use case. The travel dataset was sourced from the the\nReddit API by requesting posts from travel-related subreddits to get\ntravel-related conversation prompts and personalized travel experiences, and\naugmented for each fine-tuning method. We used two pretrained LLMs utilized for\nfine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to\nthe two pretrained models. The inferences from these models are extensively\nevaluated against the aforementioned metrics. The best model according to human\nevaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a\nReinforcement Learning from Human Feedback (RLHF) training pipeline, and\nultimately was evaluated as the best model. Our main findings are that: 1)\nquantitative and Ragas metrics do not align with human evaluation, 2) Open AI\nGPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep\nhumans in the loop for evaluation because, 4) traditional NLP metrics\ninsufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms\nQLoRA, but still needs postprocessing, 7) RLHF improves model performance\nsignificantly. Next steps include improving data quality, increasing data\nquantity, exploring RAG methods, and focusing data collection on a specific\ncity, which would improve data quality by narrowing the focus, while creating a\nuseful product.",
      "tldr_zh": "本研究比较了大型语言模型(LLM)微调方法，包括Quantized Low Rank Adapter (QLoRA)、Retrieval Augmented fine-tuning (RAFT)和Reinforcement Learning from Human Feedback (RLHF)，以及评估方法如End to End (E2E)基准、传统NLP指标、Ragas、OpenAI GPT-4评估和人工评估，以旅行聊天机器人为用例。实验使用从Reddit API获取的旅行相关数据集，对LLaMa 2 7B和Mistral 7B模型应用QLoRA和RAFT微调，并通过多种指标评估。结果显示，Mistral RAFT模型在人工评估和部分GPT-4指标中表现最佳，随后应用RLHF进一步提升性能。主要发现包括：量化指标与人工评估不一致、OpenAI GPT-4评估最接近人类判断、传统NLP指标不足、Mistral优于LLaMa、RAFT优于QLoRA但需后处理，以及RLHF显著改善模型表现。未来计划优化数据质量和数量、探索RAG方法，并聚焦特定城市以提升实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03562v1",
      "published_date": "2024-08-07 05:52:00 UTC",
      "updated_date": "2024-08-07 05:52:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:39:07.978125"
    },
    {
      "arxiv_id": "2408.03561v1",
      "title": "MPC-Minimized Secure LLM Inference",
      "title_zh": "MPC 最小化的安全 LLM 推理",
      "authors": [
        "Deevashwer Rathee",
        "Dacheng Li",
        "Ion Stoica",
        "Hao Zhang",
        "Raluca Popa"
      ],
      "abstract": "Many inference services based on large language models (LLMs) pose a privacy\nconcern, either revealing user prompts to the service or the proprietary\nweights to the user. Secure inference offers a solution to this problem through\nsecure multi-party computation (MPC), however, it is still impractical for\nmodern LLM workload due to the large overhead imposed by MPC. To address this\noverhead, we propose Marill, a framework that adapts LLM fine-tuning to\nminimize MPC usage during secure inference. Marill introduces high-level\narchitectural changes during fine-tuning that significantly reduce the number\nof expensive operations needed within MPC during inference, by removing some\nand relocating others outside MPC without compromising security. As a result,\nMarill-generated models are more efficient across all secure inference\nprotocols and our approach complements MPC-friendly approximations for such\noperations. Compared to standard fine-tuning, Marill results in 3.6-11.3x\nbetter runtime and 2.4-6.9x better communication during secure inference across\nvarious MPC settings, while typically preserving over 90% performance across\ndownstream tasks.",
      "tldr_zh": "这篇论文提出了 Marill 框架，用于最小化安全多方计算 (MPC) 在大型语言模型 (LLM) 安全推理中的开销，以解决隐私泄露问题。Marill 通过在 LLM 微调阶段引入高层架构变化，减少或转移昂贵的操作到 MPC 之外，同时保持系统安全性。实验结果显示，与标准微调相比，Marill 在各种 MPC 设置下使推理运行时间提高 3.6-11.3 倍，通信效率提升 2.4-6.9 倍，同时在下游任务中保留超过 90% 的性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03561v1",
      "published_date": "2024-08-07 05:50:17 UTC",
      "updated_date": "2024-08-07 05:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:39:17.829065"
    },
    {
      "arxiv_id": "2408.03558v1",
      "title": "D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion Methods",
      "title_zh": "D2Styler：利用离散扩散方法推进任意风格迁移",
      "authors": [
        "Onkar Susladkar",
        "Gayatri Deshmukh",
        "Sparsh Mittal",
        "Parth Shastri"
      ],
      "abstract": "In image processing, one of the most challenging tasks is to render an\nimage's semantic meaning using a variety of artistic approaches. Existing\ntechniques for arbitrary style transfer (AST) frequently experience\nmode-collapse, over-stylization, or under-stylization due to a disparity\nbetween the style and content images. We propose a novel framework called\nD$^2$Styler (Discrete Diffusion Styler) that leverages the discrete\nrepresentational capability of VQ-GANs and the advantages of discrete\ndiffusion, including stable training and avoidance of mode collapse. Our method\nuses Adaptive Instance Normalization (AdaIN) features as a context guide for\nthe reverse diffusion process. This makes it easy to move features from the\nstyle image to the content image without bias. The proposed method\nsubstantially enhances the visual quality of style-transferred images, allowing\nthe combination of content and style in a visually appealing manner. We take\nstyle images from the WikiArt dataset and content images from the COCO dataset.\nExperimental results demonstrate that D$^2$Styler produces high-quality\nstyle-transferred images and outperforms twelve existing methods on nearly all\nthe metrics. The qualitative results and ablation studies provide further\ninsights into the efficacy of our technique. The code is available at\nhttps://github.com/Onkarsus13/D2Styler.",
      "tldr_zh": "该论文提出 D2Styler 框架，利用离散扩散方法和 VQ-GANs 的离散表示能力，解决任意风格迁移（AST）中的模式崩溃、过度或不足风格化问题。框架通过 Adaptive Instance Normalization (AdaIN) 特征作为反向扩散过程的上下文引导，实现风格图像特征向内容图像的无偏转移，从而提升风格迁移图像的视觉质量。实验结果表明，D2Styler 使用 WikiArt 和 COCO 数据集时，在几乎所有指标上优于 12 种现有方法，并通过定性和消融研究验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted at 27th International Conference on Pattern\n  Recognition (ICPR), 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03558v1",
      "published_date": "2024-08-07 05:47:06 UTC",
      "updated_date": "2024-08-07 05:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:39:30.268685"
    },
    {
      "arxiv_id": "2408.03544v3",
      "title": "NatLan: Native Language Prompting Facilitates Knowledge Elicitation Through Language Trigger Provision and Domain Trigger Retention",
      "title_zh": "翻译失败",
      "authors": [
        "Baixuan Li",
        "Yunlong Fan",
        "Tianyi Ma",
        "Zhiqiang Gao"
      ],
      "abstract": "Multilingual large language models (MLLMs) do not perform as well when\nanswering questions in non-dominant languages as they do in their dominant\nlanguages. Although existing translate-then-answer methods alleviate this\nissue, the mechanisms behind their effectiveness remain unclear. In this study,\nwe analogize the dominant language of MLLMs to the native language of humans\nand use two human cognitive features: the Language Trigger (LT) and the Domain\nTrigger (DT), to interpret the mechanisms behind translate-then-answer methods.\nThis reveals that while sufficient LTs are provided by these methods, there\nremains a deficiency in DT retention. To mitigate this issue, we propose Native\nLanguage Prompting (NatLan), employing a Multi-MLLM collaboration strategy and\nintroducing an additional role-enhanced domain-specific MLLM with stronger\nmultilingual understanding capabilities as the translator. Across five language\nQA benchmarks, NatLan achieves up to a 31.28% improvement in accuracy and,\ncompared to existing state-of-the-art methods, provides comparable or greater\nretention of DTs in up to 87% of cases. Our code is available at\nhttps://github.com/AnonyNLP/NatLan.",
      "tldr_zh": "本研究发现，多语言大语言模型(MLLMs)在非主导语言上的问答性能较差，虽然现有的翻译后回答方法能缓解此问题，但其机制未明，且Domain Trigger (DT)保留不足。作者将MLLMs的主导语言比作人类的母语，并引入Language Trigger (LT)和DT来解释机制，揭示现有方法虽提供足够的LT，但DT保留仍需改进。为此，提出Native Language Prompting (NatLan)方法，通过Multi-MLLM协作策略和引入角色增强的领域特定MLLM作为翻译器，提升知识提取效率。在五个语言QA基准上，NatLan实现了高达31.28%的准确率提升，并在多达87%的案例中实现了更好的DT保留。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03544v3",
      "published_date": "2024-08-07 04:49:38 UTC",
      "updated_date": "2024-10-15 08:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:39:43.364297"
    },
    {
      "arxiv_id": "2408.03542v1",
      "title": "Automatic identification of the area covered by acorn trees in the dehesa (pastureland) Extremadura of Spain",
      "title_zh": "翻译失败",
      "authors": [
        "Ojeda-Magaña Benjamin",
        "Ruelas Ruben",
        "Quintanilla-Dominguez Joel",
        "Gomez-Barba Leopoldo",
        "Lopez de Herrera Juan",
        "Robledo-Hernandez Jose",
        "Tarquis Ana"
      ],
      "abstract": "The acorn is the fruit of the oak and is an important crop in the Spanish\ndehesa extreme\\~na, especially for the value it provides in the Iberian pig\nfood to obtain the \"acorn\" certification. For this reason, we want to maximise\nthe production of Iberian pigs with the appropriate weight. Hence the need to\nknow the area covered by the crowns of the acorn trees, to determine the\ncovered wooded area (CWA, from the Spanish Superficie Arbolada Cubierta SAC)\nand thereby estimate the number of Iberian pigs that can be released per\nhectare, as indicated by the royal decree 4/2014. In this work, we propose the\nautomatic estimation of the CWA, through aerial digital images (orthophotos) of\nthe pastureland of Extremadura, and with this, to offer the possibility of\ndetermining the number of Iberian pigs to be released in a specific plot of\nland. Among the main issues for automatic detection are, first, the correct\nidentification of acorn trees, secondly, correctly discriminating the shades of\nthe acorn trees and, finally, detect the arbuscles (young acorn trees not yet\nproductive, or shrubs that are not oaks). These difficulties represent a real\nchallenge, both for the automatic segmentation process and for manual\nsegmentation. In this work, the proposed method for automatic segmentation is\nbased on the clustering algorithm proposed by Gustafson-Kessel (GK) but the\nmodified version of Babuska (GK-B) and on the use of real orthophotos. The\nobtained results are promising both in their comparison with the real images\nand when compared with the images segmented by hand. The whole set of\northophotos used in this work correspond to an approximate area of 142\nhectares, and the results are of great interest to producers of certified\n\"acorn\" pork.",
      "tldr_zh": "本研究针对西班牙埃斯特雷马杜拉牧场（dehesa）的橡树覆盖区域（CWA, Superficie Arbolada Cubierta SAC）进行自动识别，以估算每公顷可放养伊比利亚猪的数量，从而优化“acorn”认证猪肉生产。方法基于 Gustafson-Kessel (GK) 算法的修改版本（GK-B），利用空中数字图像（orthophotos）进行图像聚类，处理橡树识别、树荫区分和幼树检测等挑战。实验结果显示，该方法在约142公顷区域的测试中，与真实图像和手动分割图像相比表现出色，为高效的牧场管理和猪只放养提供了可靠工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 15 Figures, 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2408.03542v1",
      "published_date": "2024-08-07 04:42:10 UTC",
      "updated_date": "2024-08-07 04:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:39:54.379872"
    },
    {
      "arxiv_id": "2408.03541v3",
      "title": "EXAONE 3.0 7.8B Instruction Tuned Language Model",
      "title_zh": "EXAONE 3.0 7.8B 指令微调语言模型",
      "authors": [
        "LG AI Research",
        ":",
        "Soyoung An",
        "Kyunghoon Bae",
        "Eunbi Choi",
        "Stanley Jungkyu Choi",
        "Yemuk Choi",
        "Seokhee Hong",
        "Yeonjung Hong",
        "Junwon Hwang",
        "Hyojin Jeon",
        "Gerrard Jeongwon Jo",
        "Hyunjik Jo",
        "Jiyeon Jung",
        "Yountae Jung",
        "Euisoon Kim",
        "Hyosang Kim",
        "Joonkee Kim",
        "Seonghwan Kim",
        "Soyeon Kim",
        "Sunkyoung Kim",
        "Yireun Kim",
        "Youchul Kim",
        "Edward Hwayoung Lee",
        "Haeju Lee",
        "Honglak Lee",
        "Jinsik Lee",
        "Kyungmin Lee",
        "Moontae Lee",
        "Seungjun Lee",
        "Woohyung Lim",
        "Sangha Park",
        "Sooyoun Park",
        "Yongmin Park",
        "Boseong Seo",
        "Sihoon Yang",
        "Heuiyeen Yeen",
        "Kyungjae Yoo",
        "Hyeongu Yun"
      ],
      "abstract": "We introduce EXAONE 3.0 instruction-tuned language model, the first open\nmodel in the family of Large Language Models (LLMs) developed by LG AI\nResearch. Among different model sizes, we publicly release the 7.8B\ninstruction-tuned model to promote open research and innovations. Through\nextensive evaluations across a wide range of public and in-house benchmarks,\nEXAONE 3.0 demonstrates highly competitive real-world performance with\ninstruction-following capability against other state-of-the-art open models of\nsimilar size. Our comparative analysis shows that EXAONE 3.0 excels\nparticularly in Korean, while achieving compelling performance across general\ntasks and complex reasoning. With its strong real-world effectiveness and\nbilingual proficiency, we hope that EXAONE keeps contributing to advancements\nin Expert AI. Our EXAONE 3.0 instruction-tuned model is available at\nhttps://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
      "tldr_zh": "LG AI Research 推出了 EXAONE 3.0，这是其 Large Language Models (LLMs) 系列中的第一个开源模型，并公开发布了 7.8B 指令微调版本，以促进研究创新。  \n通过在广泛的公共和内部 benchmarks 上进行评估，EXAONE 3.0 在指令遵循能力方面表现出色，尤其在韩语任务上领先，同时在一般任务和复杂推理中与同规模开源模型竞争激烈。  \n该模型展示了强大的实际应用潜力和双语优势，有望推动 Expert AI 的发展，并可从 https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct 下载。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03541v3",
      "published_date": "2024-08-07 04:38:38 UTC",
      "updated_date": "2024-08-13 10:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:40:06.074021"
    },
    {
      "arxiv_id": "2408.03533v2",
      "title": "Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiachen Zhu",
        "Jianghao Lin",
        "Xinyi Dai",
        "Bo Chen",
        "Rong Shan",
        "Jieming Zhu",
        "Ruiming Tang",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "abstract": "We primarily focus on the field of large language models (LLMs) for\nrecommendation, which has been actively explored recently and poses a\nsignificant challenge in effectively enhancing recommender systems with logical\nreasoning abilities and open-world knowledge. Current mainstream efforts mainly\ncenter around injecting personalized information from recommendation models\ninto LLMs by customizing input templates or aligning representations between\nsemantic and recommendation spaces at the prediction layer. However, they face\nthree significant limitations: (1) LoRA is mostly used as a core component in\nexisting works, but personalization is not well established in LoRA parameters\nas the LoRA matrix shared by every user may not cater to different users'\ncharacteristics, leading to suboptimal performance. (2) Although lifelong\npersonalized behavior sequences are ideal for personalization, their use raises\neffectiveness and efficiency issues since LLMs require escalating training and\ninference time to extend text lengths. (3) Existing approaches aren't scalable\nfor large datasets due to training efficiency constraints. Thus, LLMs only see\na small fraction of the datasets (e.g., less than 10%) instead of the whole\ndatasets, limiting their exposure to the full training space. To address these\nproblems, we propose RecLoRA. This model incorporates a Personalized LoRA\nmodule that maintains independent LoRAs for different users and a Long-Short\nModality Retriever that retrieves different history lengths for different\nmodalities, significantly improving performance while adding minimal time cost.\nFurthermore, we design a Few2Many Learning Strategy, using a conventional\nrecommendation model as a lens to magnify small training spaces to full spaces.\nExtensive experiments on public datasets demonstrate the efficacy of our\nRecLoRA compared to existing baseline models.",
      "tldr_zh": "本文探讨了使用大型语言模型 (LLMs) 进行推荐系统的挑战，特别是现有方法如 LoRA 在个性化、效率和可扩展性方面的局限性，例如 LoRA 参数未充分适应不同用户，导致性能不佳。针对这些问题，作者提出 RecLoRA 模型，该模型包括 Personalized LoRA 模块（为每个用户维护独立 LoRA）和 Long-Short Modality Retriever（根据模态检索不同历史长度，以提高性能并最小化时间成本）。此外，RecLoRA 还设计了 Few2Many Learning Strategy，利用传统推荐模型将小训练空间扩展到完整空间。实验在公共数据集上证明，RecLoRA 显著优于基线模型，提升了推荐系统的整体效能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03533v2",
      "published_date": "2024-08-07 04:20:28 UTC",
      "updated_date": "2024-08-11 09:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:40:19.991890"
    },
    {
      "arxiv_id": "2408.11840v1",
      "title": "Joint PET-MRI Reconstruction with Diffusion Stochastic Differential Model",
      "title_zh": "基于扩散随机微分模型的联合 PET-MRI 重建",
      "authors": [
        "Taofeng Xie",
        "Zhuoxu Cui",
        "Congcong Liu",
        "Chen Luo",
        "Huayu Wang",
        "Yuanzhi Zhang",
        "Xuemei Wang",
        "Yihang Zhou",
        "Qiyu Jin",
        "Guoqing Chen",
        "Dong Liang",
        "Haifeng Wang"
      ],
      "abstract": "PET suffers from a low signal-to-noise ratio. Meanwhile, the k-space data\nacquisition process in MRI is time-consuming by PET-MRI systems. We aim to\naccelerate MRI and improve PET image quality. This paper proposed a novel joint\nreconstruction model by diffusion stochastic differential equations based on\nlearning the joint probability distribution of PET and MRI. Compare the results\nunderscore the qualitative and quantitative improvements our model brings to\nPET and MRI reconstruction, surpassing the current state-of-the-art\nmethodologies. Joint PET-MRI reconstruction is a challenge in the PET-MRI\nsystem. This studies focused on the relationship extends beyond edges. In this\nstudy, PET is generated from MRI by learning joint probability distribution as\nthe relationship.",
      "tldr_zh": "本研究针对 PET 图像的低信噪比和 MRI 在 PET-MRI 系统中的 k-space 数据采集耗时问题，提出了一种新型联合重建模型，利用 diffusion stochastic differential equations 来学习 PET 和 MRI 的联合概率分布，从而加速 MRI 过程并提升 PET 图像质量。模型通过模拟 PET 和 MRI 之间的关系，实现从 MRI 生成 PET 的功能。实验结果显示，该方法在定性和定量上均超过了现有最先进技术，为 PET-MRI 系统中的联合重建提供了显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as ISMRM 2024 Digital poster 6575. 04-09 May 2024 Singapore",
      "pdf_url": "http://arxiv.org/pdf/2408.11840v1",
      "published_date": "2024-08-07 04:01:50 UTC",
      "updated_date": "2024-08-07 04:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:40:29.822943"
    },
    {
      "arxiv_id": "2408.03528v2",
      "title": "Exploring the extent of similarities in software failures across industries using LLMs",
      "title_zh": "使用 LLMs 探索跨行业软件故障相似性的程度",
      "authors": [
        "Martin Detloff"
      ],
      "abstract": "The rapid evolution of software development necessitates enhanced safety\nmeasures. Extracting information about software failures from companies is\nbecoming increasingly more available through news articles.\n  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)\nmodel to extract industry-specific information. Although the FAIL model's\ndatabase is rich in information, it could benefit from further categorization\nand industry-specific insights to further assist software engineers.\n  In previous work news articles were collected from reputable sources and\ncategorized by incidents inside a database. Prompt engineering and Large\nLanguage Models (LLMs) were then applied to extract relevant information\nregarding the software failure. This research extends these methods by\ncategorizing articles into specific domains and types of software failures. The\nresults are visually represented through graphs.\n  The analysis shows that throughout the database some software failures occur\nsignificantly more often in specific industries. This categorization provides a\nvaluable resource for software engineers and companies to identify and address\ncommon failures.\n  This research highlights the synergy between software engineering and Large\nLanguage Models (LLMs) to automate and enhance the analysis of software\nfailures. By transforming data from the database into an industry specific\nmodel, we provide a valuable resource that can be used to identify common\nvulnerabilities, predict potential risks, and implement proactive measures for\npreventing software failures. Leveraging the power of the current FAIL database\nand data visualization, we aim to provide an avenue for safer and more secure\nsoftware in the future.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 分析软件故障在不同行业间的相似程度，扩展了 Failure Analysis Investigation with LLMs (FAIL) 模型从新闻文章中提取行业特定信息。研究通过 Prompt engineering 和 LLMs 对文章进行分类和可视化处理，发现某些软件故障在特定行业中显著更常见。总体而言，这为软件工程师提供了识别常见漏洞、预测风险并采取预防措施的宝贵资源，强调了 LLMs 与软件工程的协同作用以提升软件安全。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03528v2",
      "published_date": "2024-08-07 03:48:07 UTC",
      "updated_date": "2024-08-08 03:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:40:41.785227"
    },
    {
      "arxiv_id": "2408.03525v1",
      "title": "Hierarchical learning control for autonomous robots inspired by central nervous system",
      "title_zh": "受中枢神经系统启发的自主机器人分层学习控制",
      "authors": [
        "Pei Zhang",
        "Zhaobo Hua",
        "Jinliang Ding"
      ],
      "abstract": "Mammals can generate autonomous behaviors in various complex environments\nthrough the coordination and interaction of activities at different levels of\ntheir central nervous system. In this paper, we propose a novel hierarchical\nlearning control framework by mimicking the hierarchical structure of the\ncentral nervous system along with their coordination and interaction behaviors.\nThe framework combines the active and passive control systems to improve both\nthe flexibility and reliability of the control system as well as to achieve\nmore diverse autonomous behaviors of robots. Specifically, the framework has a\nbackbone of independent neural network controllers at different levels and\ntakes a three-level dual descending pathway structure, inspired from the\nfunctionality of the cerebral cortex, cerebellum, and spinal cord. We\ncomprehensively validated the proposed approach through the simulation as well\nas the experiment of a hexapod robot in various complex environments, including\nobstacle crossing and rapid recovery after partial damage. This study reveals\nthe principle that governs the autonomous behavior in the central nervous\nsystem and demonstrates the effectiveness of the hierarchical control approach\nwith the salient features of the hierarchical learning control architecture and\ncombination of active and passive control systems.",
      "tldr_zh": "本研究提出了一种层次学习控制框架（hierarchical learning control），灵感来源于哺乳动物中枢神经系统（central nervous system）的层次结构、协调和互动机制，用于提升自主机器人的行为灵活性和可靠性。框架结合主动和被动控制系统，采用三层双下降路径结构（包括模拟大脑皮层、小脑和脊髓的独立神经网络控制器），以实现机器人在复杂环境中的多样化自主行为，如障碍跨越和损伤快速恢复。通过模拟和六足机器人实验验证，该方法显著提高了机器人性能，并揭示了中枢神经系统自主行为的潜在原理。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03525v1",
      "published_date": "2024-08-07 03:24:59 UTC",
      "updated_date": "2024-08-07 03:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:40:54.231291"
    },
    {
      "arxiv_id": "2408.11839v1",
      "title": "Adaptive Friction in Deep Learning: Enhancing Optimizers with Sigmoid and Tanh Function",
      "title_zh": "深度学习中的自适应摩擦：使用 Sigmoid 和 Tanh 函数增强优化器",
      "authors": [
        "Hongye Zheng",
        "Bingxing Wang",
        "Minheng Xiao",
        "Honglin Qin",
        "Zhizhong Wu",
        "Lianghao Tan"
      ],
      "abstract": "Adaptive optimizers are pivotal in guiding the weight updates of deep neural\nnetworks, yet they often face challenges such as poor generalization and\noscillation issues. To counter these, we introduce sigSignGrad and\ntanhSignGrad, two novel optimizers that integrate adaptive friction\ncoefficients based on the Sigmoid and Tanh functions, respectively. These\nalgorithms leverage short-term gradient information, a feature overlooked in\ntraditional Adam variants like diffGrad and AngularGrad, to enhance parameter\nupdates and convergence.Our theoretical analysis demonstrates the wide-ranging\nadjustment capability of the friction coefficient S, which aligns with targeted\nparameter update strategies and outperforms existing methods in both\noptimization trajectory smoothness and convergence rate. Extensive experiments\non CIFAR-10, CIFAR-100, and Mini-ImageNet datasets using ResNet50 and ViT\narchitectures confirm the superior performance of our proposed optimizers,\nshowcasing improved accuracy and reduced training time. The innovative approach\nof integrating adaptive friction coefficients as plug-ins into existing\noptimizers, exemplified by the sigSignAdamW and sigSignAdamP variants, presents\na promising strategy for boosting the optimization performance of established\nalgorithms. The findings of this study contribute to the advancement of\noptimizer design in deep learning.",
      "tldr_zh": "本研究提出两种新型优化器 sigSignGrad 和 tanhSignGrad，通过引入基于 Sigmoid 和 Tanh 函数的自适应摩擦系数，改善深度学习中优化器的泛化性和振荡问题。这些优化器利用短期梯度信息进行参数更新，超越了传统 Adam 变体如 diffGrad 和 AngularGrad 的局限，并在理论分析中展示了摩擦系数 S 的灵活性，能提供更平滑的优化轨迹和更快收敛。实验在 CIFAR-10、CIFAR-100 和 Mini-ImageNet 数据集上，使用 ResNet50 和 ViT 模型验证了这些优化器的优越性，实现了更高的准确率和更短的训练时间。该方法作为插件（如 sigSignAdamW 和 sigSignAdamP）整合到现有优化器中，为深度学习优化设计提供了新策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11839v1",
      "published_date": "2024-08-07 03:20:46 UTC",
      "updated_date": "2024-08-07 03:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:41:07.048987"
    },
    {
      "arxiv_id": "2408.03519v1",
      "title": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
      "title_zh": "RepoMasterEval：通过真实世界代码仓库评估代码补全",
      "authors": [
        "Qinyun Wu",
        "Chao Peng",
        "Pengfei Gao",
        "Ruida Hu",
        "Haoyu Gan",
        "Bo Jiang",
        "Jinhe Tang",
        "Zhiwen Deng",
        "Zhanming Guan",
        "Cuiyun Gao",
        "Xia Liu",
        "Ping Yang"
      ],
      "abstract": "With the growing reliance on automated code completion tools in software\ndevelopment, the need for robust evaluation benchmarks has become critical.\nHowever, existing benchmarks focus more on code generation tasks in function\nand class level and provide rich text description to prompt the model. By\ncontrast, such descriptive prompt is commonly unavailable in real development\nand code completion can occur in wider range of situations such as in the\nmiddle of a function or a code block. These limitations makes the evaluation\npoorly align with the practical scenarios of code completion tools. In this\npaper, we propose RepoMasterEval, a novel benchmark for evaluating code\ncompletion models constructed from real-world Python and TypeScript\nrepositories. Each benchmark datum is generated by masking a code snippet\n(ground truth) from one source code file with existing test suites. To improve\ntest accuracy of model generated code, we employ mutation testing to measure\nthe effectiveness of the test cases and we manually crafted new test cases for\nthose test suites with low mutation score. Our empirical evaluation on 6\nstate-of-the-art models shows that test argumentation is critical in improving\nthe accuracy of the benchmark and RepoMasterEval is able to report difference\nin model performance in real-world scenarios. The deployment of RepoMasterEval\nin a collaborated company for one month also revealed that the benchmark is\nuseful to give accurate feedback during model training and the score is in high\ncorrelation with the model's performance in practice. Based on our findings, we\ncall for the software engineering community to build more LLM benchmarks\ntailored for code generation tools taking the practical and complex development\nenvironment into consideration.",
      "tldr_zh": "该研究指出，现有的代码补全评估基准过于依赖函数级文本描述提示，无法反映真实开发场景中如函数中间补全的复杂情况。为此，提出RepoMasterEval，一个基于真实Python和TypeScript仓库构建的基准，通过屏蔽代码片段并结合mutation testing优化测试套件，来评估代码补全模型的性能。实证评估显示，该基准在6个最先进模型上显著提高了评估准确性，并通过公司内部部署证实其评分与实际模型表现高度相关。作者呼吁软件工程社区开发更多考虑实际环境的LLM benchmarks，以提升代码生成工具的实用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03519v1",
      "published_date": "2024-08-07 03:06:57 UTC",
      "updated_date": "2024-08-07 03:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:41:19.118766"
    },
    {
      "arxiv_id": "2408.03515v2",
      "title": "A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxiao Zhang",
        "Xiangrui Kong",
        "Conan Dewitt",
        "Thomas Braunl",
        "Jin B. Hong"
      ],
      "abstract": "The integration of Large Language Models (LLMs) like GPT-4o into robotic\nsystems represents a significant advancement in embodied artificial\nintelligence. These models can process multi-modal prompts, enabling them to\ngenerate more context-aware responses. However, this integration is not without\nchallenges. One of the primary concerns is the potential security risks\nassociated with using LLMs in robotic navigation tasks. These tasks require\nprecise and reliable responses to ensure safe and effective operation.\nMulti-modal prompts, while enhancing the robot's understanding, also introduce\ncomplexities that can be exploited maliciously. For instance, adversarial\ninputs designed to mislead the model can lead to incorrect or dangerous\nnavigational decisions. This study investigates the impact of prompt injections\non mobile robot performance in LLM-integrated systems and explores secure\nprompt strategies to mitigate these risks. Our findings demonstrate a\nsubstantial overall improvement of approximately 30.8% in both attack detection\nand system performance with the implementation of robust defence mechanisms,\nhighlighting their critical role in enhancing security and reliability in\nmission-oriented tasks.",
      "tldr_zh": "本研究探讨了将大型语言模型 (LLMs) 如 GPT-4o 集成到移动机器人系统中的安全风险，特别是提示注入攻击 (prompt injection attack)，这些攻击可能通过多模态提示误导机器人导航任务，导致错误或危险决策。研究团队调查了这些攻击对系统性能的影响，并开发了安全提示策略作为防御机制。结果显示，实施这些机制后，攻击检测和整体系统性能提高了约 30.8%，从而提升了机器人系统在任务导向场景中的可靠性和安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03515v2",
      "published_date": "2024-08-07 02:48:22 UTC",
      "updated_date": "2024-09-09 01:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:41:30.068589"
    },
    {
      "arxiv_id": "2408.03505v1",
      "title": "Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqi Feng",
        "Yangrui Chen",
        "Shaoyu Wang",
        "Yanghua Peng",
        "Haibin Lin",
        "Minlan Yu"
      ],
      "abstract": "Multimodal large language models (MLLMs) have extended the success of large\nlanguage models (LLMs) to multiple data types, such as image, text and audio,\nachieving significant performance in various domains, including multimodal\ntranslation, visual question answering and content generation. Nonetheless,\nexisting systems are inefficient to train MLLMs due to substantial GPU bubbles\ncaused by the heterogeneous modality models and complex data dependencies in 3D\nparallelism. This paper proposes Optimus, a distributed MLLM training system\nthat reduces end-to-end MLLM training time. Optimus is based on our principled\nanalysis that scheduling the encoder computation within the LLM bubbles can\nreduce bubbles in MLLM training. To make scheduling encoder computation\npossible for all GPUs, Optimus searches the separate parallel plans for encoder\nand LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM\nbubbles without breaking the original data dependencies in the MLLM model\narchitecture. We further decompose encoder layer computation into a series of\nkernels, and analyze the common bubble pattern of 3D parallelism to carefully\noptimize the sub-millisecond bubble scheduling, minimizing the overall training\ntime. Our experiments in a production cluster show that Optimus accelerates\nMLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs\ncompared to baselines.",
      "tldr_zh": "该论文提出 Optimus 系统，用于加速大规模多模态大语言模型 (MLLMs) 训练，通过利用 GPU bubbles 优化异构模态模型和 3D parallelism 中的计算依赖问题。Optimus 的核心方法包括在 LLM bubbles 中调度 encoder 计算、搜索独立的并行计划，并采用 bubble scheduling 算法来分解 encoder 层计算，从而最小化训练时间。实验结果显示，在 3072 GPUs 上，使用 ViT-22B 和 GPT-175B 模型时，Optimus 比基线系统加速训练 20.5%-21.3%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03505v1",
      "published_date": "2024-08-07 02:08:29 UTC",
      "updated_date": "2024-08-07 02:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:41:44.058788"
    },
    {
      "arxiv_id": "2408.04668v2",
      "title": "Forecasting Live Chat Intent from Browsing History",
      "title_zh": "翻译失败",
      "authors": [
        "Se-eun Yoon",
        "Ahmad Bin Rabiah",
        "Zaid Alibadi",
        "Surya Kallumadi",
        "Julian McAuley"
      ],
      "abstract": "Customers reach out to online live chat agents with various intents, such as\nasking about product details or requesting a return. In this paper, we propose\nthe problem of predicting user intent from browsing history and address it\nthrough a two-stage approach. The first stage classifies a user's browsing\nhistory into high-level intent categories. Here, we represent each browsing\nhistory as a text sequence of page attributes and use the ground-truth class\nlabels to fine-tune pretrained Transformers. The second stage provides a large\nlanguage model (LLM) with the browsing history and predicted intent class to\ngenerate fine-grained intents. For automatic evaluation, we use a separate LLM\nto judge the similarity between generated and ground-truth intents, which\nclosely aligns with human judgments. Our two-stage approach yields significant\nperformance gains compared to generating intents without the classification\nstage.",
      "tldr_zh": "这篇论文提出了一种从用户浏览历史预测在线直播聊天意图的方法，以解决用户意图多样性的问题。采用两阶段方法：第一阶段使用预训练的Transformers模型将浏览历史表示为页面属性的文本序列，并通过ground-truth标签进行微调以分类高层意图类别；第二阶段则将浏览历史和预测的意图类别输入大型语言模型(LLM)，生成更细粒度的意图。实验结果显示，该两阶段方法比直接生成意图的基准模型有显著性能提升，且使用另一个LLM进行自动评估，其相似度判断与人类评估高度一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04668v2",
      "published_date": "2024-08-07 01:50:59 UTC",
      "updated_date": "2024-09-01 19:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:41:54.822966"
    },
    {
      "arxiv_id": "2408.03497v3",
      "title": "Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Yu",
        "Yixin Jin",
        "Qianwen Xing",
        "Ye Zhang",
        "Shaobo Guo",
        "Shuchen Meng"
      ],
      "abstract": "Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.",
      "tldr_zh": "本研究针对银行信用风险预测问题，提出了一种先进的用户信用风险模型，使用 LightGBM、XGBoost 和 Tabnet 等机器学习算法，并结合 SMOTEENN 技术处理数据不平衡。研究者利用超过 40,000 条银行数据集，比较了 PCA 和 T-SNE 等降维技术，并对这些模型进行了深度调整和优化。实验结果显示，LightGBM 与 PCA 和 SMOTEENN 结合的方案在预测潜在高质客户方面表现出色，准确率比其他模型高出显著水平，为银行信用卡业务提供更可靠的智能决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pagess on IEEE ICPICS",
      "pdf_url": "http://arxiv.org/pdf/2408.03497v3",
      "published_date": "2024-08-07 01:37:10 UTC",
      "updated_date": "2024-11-13 04:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:42:07.877296"
    },
    {
      "arxiv_id": "2408.03492v1",
      "title": "Automated Theorem Provers Help Improve Large Language Model Reasoning",
      "title_zh": "自动化定理证明器帮助改进大语言模型的推理能力",
      "authors": [
        "Lachlan McGinness",
        "Peter Baumgartner"
      ],
      "abstract": "In this paper we demonstrate how logic programming systems and Automated\nfirst-order logic Theorem Provers (ATPs) can improve the accuracy of Large\nLanguage Models (LLMs) for logical reasoning tasks where the baseline\nperformance is given by direct LLM solutions. We first evaluate LLM reasoning\non steamroller problems using the PRONTOQA benchmark. We show how accuracy can\nbe improved with a neuro-symbolic architecture where the LLM acts solely as a\nfront-end for translating a given problem into a formal logic language and an\nautomated reasoning engine is called for solving it. However, this approach\ncritically hinges on the correctness of the LLM translation. To assess this\ntranslation correctness, we secondly define a framework of syntactic and\nsemantic error categories. We implemented the framework and used it to identify\nerrors that LLMs make in the benchmark domain. Based on these findings, we\nthirdly extended our method with capabilities for automatically correcting\nsyntactic and semantic errors. For semantic error correction we integrate\nfirst-order logic ATPs, which is our main and novel contribution. We\ndemonstrate that this approach reduces semantic errors significantly and\nfurther increases the accurracy of LLM logical reasoning.",
      "tldr_zh": "本论文探讨了如何利用逻辑编程系统和 Automated Theorem Provers (ATPs) 来提升 Large Language Models (LLMs) 在逻辑推理任务上的准确性。研究首先使用 PRONTOQA 基准测试 LLMs 在 steamroller 问题中的表现，然后提出一个神经符号架构，让 LLMs 仅负责将问题翻译成形式逻辑语言，并由自动推理引擎解决。针对 LLM 翻译的潜在错误，论文定义了语法和语义错误框架，并开发了自动纠正机制，其中主要创新是整合 first-order logic ATPs 来显著减少语义错误。最终实验结果显示，这种方法在基准测试中将 LLMs 的准确性进一步提高。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "F.4.1; I.2.7; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03492v1",
      "published_date": "2024-08-07 01:03:56 UTC",
      "updated_date": "2024-08-07 01:03:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:42:21.043693"
    },
    {
      "arxiv_id": "2408.03489v1",
      "title": "Harnessing the Power of LLMs in Source Code Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew A Mahyari"
      ],
      "abstract": "Software vulnerabilities, caused by unintentional flaws in source code, are a\nprimary root cause of cyberattacks. Static analysis of source code has been\nwidely used to detect these unintentional defects introduced by software\ndevelopers. Large Language Models (LLMs) have demonstrated human-like\nconversational abilities due to their capacity to capture complex patterns in\nsequential data, such as natural languages. In this paper, we harness LLMs'\ncapabilities to analyze source code and detect known vulnerabilities. To ensure\nthe proposed vulnerability detection method is universal across multiple\nprogramming languages, we convert source code to LLVM IR and train LLMs on\nthese intermediate representations. We conduct extensive experiments on various\nLLM architectures and compare their accuracy. Our comprehensive experiments on\nreal-world and synthetic codes from NVD and SARD demonstrate high accuracy in\nidentifying source code vulnerabilities.",
      "tldr_zh": "本研究探讨了利用大语言模型(LLMs)来检测源代码中的漏洞，以应对软件缺陷导致的网络攻击问题。研究方法包括将源代码转换为LLVM IR中间表示，从而实现对多种编程语言的通用分析，并在此基础上训练LLMs进行漏洞识别。通过在NVD和SARD的真实和合成代码上进行的广泛实验，证明了该方法在各种LLM架构上的高准确性，展示了LLMs在静态代码分析中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03489v1",
      "published_date": "2024-08-07 00:48:49 UTC",
      "updated_date": "2024-08-07 00:48:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:42:32.072854"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 82,
  "processed_papers_count": 82,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T13:42:56.703147"
}