[
  {
    "arxiv_id": "2502.17728v1",
    "title": "LLM Inference Acceleration via Efficient Operation Fusion",
    "authors": [
      "Mahsa Salmani",
      "Ilya Soloveychik"
    ],
    "abstract": "The rapid development of the Transformer-based Large Language Models (LLMs)\nin recent years has been closely linked to their ever-growing and already\nenormous sizes. Many LLMs contain hundreds of billions of parameters and\nrequire dedicated hardware resources for training and inference. One of the key\nchallenges inherent to the Transformer architecture is the requirement to\nsupport numerous non-linear transformations that involves normalization. For\ninstance, each decoder block typically contains at least one Softmax operation\nand two Layernorms. The computation of the corresponding normalization scaling\nfactors becomes a major bottleneck as it requires spatial collective\noperations. In other words, when it comes to the computation of denominators\nfor Softmax and Layernorm, all vector elements must be aggregated into a single\nlocation, requiring significant communication. These collective operations slow\ndown inference on Transformers by approximately 20%, defeating the whole\npurpose of distributed in-memory compute. In this work, we propose an extremely\nefficient technique that can completely hide the overhead caused by such\ncollective operations. Note that each Softmax and Layernorm operation is\ntypically followed by a linear layer. Since non-linear and linear operations\nare performed on different hardware engines, they can be easily parallelized\nonce the algebra allows such commutation. By leveraging the inherent properties\nof linear operations, we can defer the normalization of the preceding Softmax\nand Layernorm until after the linear layer is computed. Now we can compute the\ncollective scaling factors concurrently with the matrix multiplication and\ncompletely hide the latency of the former behind the latter. Such\nparallelization preserves the numerical accuracy while significantly improving\nthe hardware utilization and reducing the overall latency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17728v1",
    "published_date": "2025-02-24 23:42:37 UTC",
    "updated_date": "2025-02-24 23:42:37 UTC"
  },
  {
    "arxiv_id": "2502.17726v1",
    "title": "The GigaMIDI Dataset with Features for Expressive Music Performance Detection",
    "authors": [
      "Keon Ju Maverick Lee",
      "Jeff Ens",
      "Sara Adkins",
      "Pedro Sarmento",
      "Mathieu Barthet",
      "Philippe Pasquier"
    ],
    "abstract": "The Musical Instrument Digital Interface (MIDI), introduced in 1983,\nrevolutionized music production by allowing computers and instruments to\ncommunicate efficiently. MIDI files encode musical instructions compactly,\nfacilitating convenient music sharing. They benefit Music Information Retrieval\n(MIR), aiding in research on music understanding, computational musicology, and\ngenerative music. The GigaMIDI dataset contains over 1.4 million unique MIDI\nfiles, encompassing 1.8 billion MIDI note events and over 5.3 million MIDI\ntracks. GigaMIDI is currently the largest collection of symbolic music in MIDI\nformat available for research purposes under fair dealing. Distinguishing\nbetween non-expressive and expressive MIDI tracks is challenging, as MIDI files\ndo not inherently make this distinction. To address this issue, we introduce a\nset of innovative heuristics for detecting expressive music performance. These\ninclude the Distinctive Note Velocity Ratio (DNVR) heuristic, which analyzes\nMIDI note velocity; the Distinctive Note Onset Deviation Ratio (DNODR)\nheuristic, which examines deviations in note onset times; and the Note Onset\nMedian Metric Level (NOMML) heuristic, which evaluates onset positions relative\nto metric levels. Our evaluation demonstrates these heuristics effectively\ndifferentiate between non-expressive and expressive MIDI tracks. Furthermore,\nafter evaluation, we create the most substantial expressive MIDI dataset,\nemploying our heuristic, NOMML. This curated iteration of GigaMIDI encompasses\nexpressively-performed instrument tracks detected by NOMML, containing all\nGeneral MIDI instruments, constituting 31% of the GigaMIDI dataset, totalling\n1,655,649 tracks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Published at Transactions of the International Society for Music\n  Information Retrieval (TISMIR), 8(1), 1-19",
    "pdf_url": "http://arxiv.org/pdf/2502.17726v1",
    "published_date": "2025-02-24 23:39:40 UTC",
    "updated_date": "2025-02-24 23:39:40 UTC"
  },
  {
    "arxiv_id": "2502.17725v2",
    "title": "Solving the Traveling Salesman Problem via Different Quantum Computing Architectures",
    "authors": [
      "Venkat Padmasola",
      "Zhaotong Li",
      "Rupak Chatterjee",
      "Wesley Dyk"
    ],
    "abstract": "We study the application of emerging photonic and quantum computing\narchitectures to solving the Traveling Salesman Problem (TSP), a well-known\nNP-hard optimization problem. We investigate several approaches: Simulated\nAnnealing (SA), Quadratic Unconstrained Binary Optimization (QUBO-Ising)\nmethods implemented on quantum annealers and Optical Coherent Ising Machines,\nas well as the Quantum Approximate Optimization Algorithm (QAOA) and the\nQuantum Phase Estimation (QPE) algorithm on gate-based quantum computers. QAOA\nand QPE were tested on the IBM Quantum platform. The QUBO-Ising method was\nexplored using the D-Wave quantum annealer, which operates on superconducting\nJosephson junctions, and the Quantum Computing Inc (QCi) Dirac-1 entropy\nquantum optimization machine. Gate-based quantum computers demonstrated\naccurate results for small TSP instances in simulation. However, real quantum\ndevices are hindered by noise and limited scalability. Circuit complexity grows\nwith problem size, restricting performance to TSP instances with a maximum of 6\nnodes. In contrast, Ising-based architectures show improved scalability for\nlarger problem sizes. SQUID-based Ising machines can handle TSP instances with\nup to 12 nodes, while entropy computing implemented in hybrid optoelectronic\ncomponents extend this capability to 18 nodes. Nevertheless, the solutions tend\nto be suboptimal due to hardware limitations and challenges in achieving ground\nstate convergence as the problem size increases. Despite these limitations,\nIsing machines demonstrate significant time advantages over classical methods,\nmaking them a promising candidate for solving larger-scale TSPs efficiently.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "math-ph",
      "math.MP",
      "F.2.2"
    ],
    "primary_category": "quant-ph",
    "comment": "13 pages, 21 figures, 32 citations",
    "pdf_url": "http://arxiv.org/pdf/2502.17725v2",
    "published_date": "2025-02-24 23:37:19 UTC",
    "updated_date": "2025-04-01 22:40:23 UTC"
  },
  {
    "arxiv_id": "2502.17721v1",
    "title": "Aligning Compound AI Systems via System-level DPO",
    "authors": [
      "Xiangwen Wang",
      "Yibo Jacky Zhang",
      "Zhoujie Ding",
      "Katherine Tsai",
      "Sanmi Koyejo"
    ],
    "abstract": "Compound AI systems, comprising multiple interacting components such as LLM\nagents and external tools, demonstrate state-of-the-art results across diverse\ntasks. It is hence crucial to align components within the system to produce\nconsistent results that match human expectations. However, conventional\nalignment methods, such as Direct Preference Optimization (DPO), are not\ndirectly applicable to compound AI systems. These challenges include the\nnon-differentiable interactions between components, making end-to-end gradient\noptimization infeasible. Additionally, system-level preferences cannot be\ndirectly translated into component-level preferences, further complicating\nalignment. We address the issues by formulating compound AI systems as Directed\nAcyclic Graphs (DAGs), capturing the connections between agents and the data\ngeneration processes. We propose a system-level DPO (SysDPO) to jointly align\ncompound systems by adapting the DPO to operate on these DAGs. We study the\njoint alignment of an LLM and a diffusion model to demonstrate the\neffectiveness of our approach. Our exploration provides insights into the\nalignment of compound AI systems and lays a foundation for future advancements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to workshops MARW and WMAC (Oral) at AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2502.17721v1",
    "published_date": "2025-02-24 23:25:13 UTC",
    "updated_date": "2025-02-24 23:25:13 UTC"
  },
  {
    "arxiv_id": "2502.17720v3",
    "title": "Spontaneous Giving and Calculated Greed in Language Models",
    "authors": [
      "Yuxuan Li",
      "Hirokazu Shirado"
    ],
    "abstract": "Large language models demonstrate strong problem-solving abilities through\nreasoning techniques such as chain-of-thought prompting and reflection.\nHowever, it remains unclear whether these reasoning capabilities extend to a\nform of social intelligence: making effective decisions in cooperative\ncontexts. We examine this question using economic games that simulate social\ndilemmas. First, we apply chain-of-thought and reflection prompting to GPT-4o\nin a Public Goods Game. We then evaluate multiple off-the-shelf models across\nsix cooperation and punishment games, comparing those with and without explicit\nreasoning mechanisms. We find that reasoning models consistently reduce\ncooperation and norm enforcement, favoring individual rationality. In repeated\ninteractions, groups with more reasoning agents exhibit lower collective gains.\nThese behaviors mirror human patterns of \"spontaneous giving and calculated\ngreed.\" Our findings underscore the need for LLM architectures that incorporate\nsocial intelligence alongside reasoning, to help address--rather than\nreinforce--the challenges of collective action.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17720v3",
    "published_date": "2025-02-24 23:23:27 UTC",
    "updated_date": "2025-05-21 16:04:15 UTC"
  },
  {
    "arxiv_id": "2502.17715v1",
    "title": "Bridging Information Gaps with Comprehensive Answers: Improving the Diversity and Informativeness of Follow-Up Questions",
    "authors": [
      "Zhe Liu",
      "Taekyu Kang",
      "Haoyu Wang",
      "Seyed Hossein Alavi",
      "Vered Shwartz"
    ],
    "abstract": "Effective conversational systems are expected to dynamically generate\ncontextual follow-up questions to elicit new information while maintaining the\nconversation flow. While humans excel at asking diverse and informative\nquestions by intuitively assessing both obtained and missing information,\nexisting models often fall short of human performance on this task. To mitigate\nthis, we propose a method that generates diverse and informative questions\nbased on targeting unanswered information using a hypothetical LLM-generated\n\"comprehensive answer\". Our method is applied to augment an existing follow-up\nquestions dataset. The experimental results demonstrate that language models\nfine-tuned on the augmented datasets produce follow-up questions of\nsignificantly higher quality and diversity. This promising approach could be\neffectively adopted to future work to augment information-seeking dialogues for\nreducing ambiguities and improving the accuracy of LLM answers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17715v1",
    "published_date": "2025-02-24 23:14:59 UTC",
    "updated_date": "2025-02-24 23:14:59 UTC"
  },
  {
    "arxiv_id": "2502.17714v1",
    "title": "On the usability of generative AI: Human generative AI",
    "authors": [
      "Anna Ravera",
      "Cristina Gena"
    ],
    "abstract": "Generative AI systems are transforming content creation, but their usability\nremains a key challenge. This paper examines usability factors such as user\nexperience, transparency, control, and cognitive load. Common challenges\ninclude unpredictability and difficulties in fine-tuning outputs. We review\nevaluation metrics like efficiency, learnability, and satisfaction,\nhighlighting best practices from various domains. Improving interpretability,\nintuitive interfaces, and user feedback can enhance usability, making\ngenerative AI more accessible and effective.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17714v1",
    "published_date": "2025-02-24 23:13:59 UTC",
    "updated_date": "2025-02-24 23:13:59 UTC"
  },
  {
    "arxiv_id": "2502.17710v1",
    "title": "Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures",
    "authors": [
      "Akhila Yerukola",
      "Saadia Gabriel",
      "Nanyun Peng",
      "Maarten Sap"
    ],
    "abstract": "Gestures are an integral part of non-verbal communication, with meanings that\nvary across cultures, and misinterpretations that can have serious social and\ndiplomatic consequences. As AI systems become more integrated into global\napplications, ensuring they do not inadvertently perpetuate cultural offenses\nis critical. To this end, we introduce Multi-Cultural Set of Inappropriate\nGestures and Nonverbal Signs (MC-SIGNS), a dataset of 288 gesture-country pairs\nannotated for offensiveness, cultural significance, and contextual factors\nacross 25 gestures and 85 countries. Through systematic evaluation using\nMC-SIGNS, we uncover critical limitations: text-to-image (T2I) systems exhibit\nstrong US-centric biases, performing better at detecting offensive gestures in\nUS contexts than in non-US ones; large language models (LLMs) tend to over-flag\ngestures as offensive; and vision-language models (VLMs) default to US-based\ninterpretations when responding to universal concepts like wishing someone\nluck, frequently suggesting culturally inappropriate gestures. These findings\nhighlight the urgent need for culturally-aware AI safety mechanisms to ensure\nequitable global deployment of AI technologies.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 49 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17710v1",
    "published_date": "2025-02-24 23:10:08 UTC",
    "updated_date": "2025-02-24 23:10:08 UTC"
  },
  {
    "arxiv_id": "2502.17709v1",
    "title": "Contrastive Visual Data Augmentation",
    "authors": [
      "Yu Zhou",
      "Bingxuan Li",
      "Mohan Tang",
      "Xiaomeng Jin",
      "Te-Lin Wu",
      "Kuan-Hao Huang",
      "Heng Ji",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "Large multimodal models (LMMs) often struggle to recognize novel concepts, as\nthey rely on pre-trained knowledge and have limited ability to capture subtle\nvisual details. Domain-specific knowledge gaps in training also make them prone\nto confusing visually similar, commonly misrepresented, or low-resource\nconcepts. To help LMMs better align nuanced visual features with language,\nimproving their ability to recognize and reason about novel or rare concepts,\nwe propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA\nextracts key contrastive textual and visual features of target concepts against\nthe known concepts they are misrecognized as, and then uses multimodal\ngenerative models to produce targeted synthetic data. Automatic filtering of\nextracted features and augmented images is implemented to guarantee their\nquality, as verified by human annotators. We show the effectiveness and\nefficiency of CoDA on low-resource concept and diverse scene recognition\ndatasets including INaturalist and SUN. We additionally collect NovelSpecies, a\nbenchmark dataset consisting of newly discovered animal species that are\nguaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these\nthree datasets show CoDA significantly improves SOTA visual data augmentation\nstrategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains\nin accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17709v1",
    "published_date": "2025-02-24 23:05:31 UTC",
    "updated_date": "2025-02-24 23:05:31 UTC"
  },
  {
    "arxiv_id": "2503.01863v1",
    "title": "Vision Language Models in Medicine",
    "authors": [
      "Beria Chingnabe Kalpelbe",
      "Angel Gabriel Adaambiik",
      "Wei Peng"
    ],
    "abstract": "With the advent of Vision-Language Models (VLMs), medical artificial\nintelligence (AI) has experienced significant technological progress and\nparadigm shifts. This survey provides an extensive review of recent\nadvancements in Medical Vision-Language Models (Med-VLMs), which integrate\nvisual and textual data to enhance healthcare outcomes. We discuss the\nfoundational technology behind Med-VLMs, illustrating how general models are\nadapted for complex medical tasks, and examine their applications in\nhealthcare. The transformative impact of Med-VLMs on clinical practice,\neducation, and patient care is highlighted, alongside challenges such as data\nscarcity, narrow task generalization, interpretability issues, and ethical\nconcerns like fairness, accountability, and privacy. These limitations are\nexacerbated by uneven dataset distribution, computational demands, and\nregulatory hurdles. Rigorous evaluation methods and robust regulatory\nframeworks are essential for safe integration into healthcare workflows. Future\ndirections include leveraging large-scale, diverse datasets, improving\ncross-modal generalization, and enhancing interpretability. Innovations like\nfederated learning, lightweight architectures, and Electronic Health Record\n(EHR) integration are explored as pathways to democratize access and improve\nclinical relevance. This review aims to provide a comprehensive understanding\nof Med-VLMs' strengths and limitations, fostering their ethical and balanced\nadoption in healthcare.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01863v1",
    "published_date": "2025-02-24 22:53:22 UTC",
    "updated_date": "2025-02-24 22:53:22 UTC"
  },
  {
    "arxiv_id": "2502.17703v1",
    "title": "To Patch or Not to Patch: Motivations, Challenges, and Implications for Cybersecurity",
    "authors": [
      "Jason R. C. Nurse"
    ],
    "abstract": "As technology has become more embedded into our society, the security of\nmodern-day systems is paramount. One topic which is constantly under discussion\nis that of patching, or more specifically, the installation of updates that\nremediate security vulnerabilities in software or hardware systems. This\ncontinued deliberation is motivated by complexities involved with patching; in\nparticular, the various incentives and disincentives for organizations and\ntheir cybersecurity teams when deciding whether to patch. In this paper, we\ntake a fresh look at the question of patching and critically explore why\norganizations and IT/security teams choose to patch or decide against it\n(either explicitly or due to inaction). We tackle this question by aggregating\nand synthesizing prominent research and industry literature on the incentives\nand disincentives for patching, specifically considering the human aspects in\nthe context of these motives. Through this research, this study identifies key\nmotivators such as organizational needs, the IT/security team's relationship\nwith vendors, and legal and regulatory requirements placed on the business and\nits staff. There are also numerous significant reasons discovered for why the\ndecision is taken not to patch, including limited resources (e.g.,\nperson-power), challenges with manual patch management tasks, human error, bad\npatches, unreliable patch management tools, and the perception that related\nvulnerabilities would not be exploited. These disincentives, in combination\nwith the motivators above, highlight the difficult balance that organizations\nand their security teams need to maintain on a daily basis. Finally, we\nconclude by discussing implications of these findings and important future\nconsiderations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "7th International Conference HCI for Cybersecurity, Privacy and Trust\n  (27th HCI International Conference)",
    "pdf_url": "http://arxiv.org/pdf/2502.17703v1",
    "published_date": "2025-02-24 22:52:35 UTC",
    "updated_date": "2025-02-24 22:52:35 UTC"
  },
  {
    "arxiv_id": "2502.17701v1",
    "title": "From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs",
    "authors": [
      "Ruxiao Chen",
      "Chenguang Wang",
      "Yuran Sun",
      "Xilei Zhao",
      "Susu Xu"
    ],
    "abstract": "Evacuation decision prediction is critical for efficient and effective\nwildfire response by helping emergency management anticipate traffic congestion\nand bottlenecks, allocate resources, and minimize negative impacts. Traditional\nstatistical methods for evacuation decision prediction fail to capture the\ncomplex and diverse behavioral logic of different individuals. In this work,\nfor the first time, we introduce FLARE, short for facilitating LLM for advanced\nreasoning on wildfire evacuation decision prediction, a Large Language Model\n(LLM)-based framework that integrates behavioral theories and models to\nstreamline the Chain-of-Thought (CoT) reasoning and subsequently integrate with\nmemory-based Reinforcement Learning (RL) module to provide accurate evacuation\ndecision prediction and understanding. Our proposed method addresses the\nlimitations of using existing LLMs for evacuation behavioral predictions, such\nas limited survey data, mismatching with behavioral theory, conflicting\nindividual preferences, implicit and complex mental states, and intractable\nmental state-behavior mapping. Experiments on three post-wildfire survey\ndatasets show an average of 20.47% performance improvement over traditional\ntheory-informed behavioral models, with strong cross-event generalizability.\nOur complete code is publicly available at\nhttps://github.com/SusuXu-s-Lab/FLARE",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17701v1",
    "published_date": "2025-02-24 22:47:33 UTC",
    "updated_date": "2025-02-24 22:47:33 UTC"
  },
  {
    "arxiv_id": "2503.00030v1",
    "title": "Game-Theoretic Regularized Self-Play Alignment of Large Language Models",
    "authors": [
      "Xiaohang Tang",
      "Sangwoong Yoon",
      "Seongho Son",
      "Huizhuo Yuan",
      "Quanquan Gu",
      "Ilija Bogunovic"
    ],
    "abstract": "Self-play alignment algorithms have been developed as effective methods for\nfine-tuning large language models (LLMs), formulating preference optimization\nas a two-player game. However, the regularization with respect to the reference\npolicy, which is crucial for mitigating over-optimization, has been\ninsufficiently investigated in self-play alignment. In this paper, we show that\nour regularization method can improve the unregularized self-play\nsignificantly. To study the impact of different regularizations in self-play\nalignment, we propose Regularized Self-Play Policy Optimization (RSPO). This\ngeneralized framework regularizes the self-play by simply adding a chosen\nregularization term into the loss while maintaining provable last-iterate\nconvergence to the Nash Equilibrium of the corresponding regularized game.\nSurprisingly, empirical evaluations using the Mistral-7B-Instruct base model\nreveal that forward KL divergence regularization reduces response length in\nRSPO, whereas reverse KL divergence markedly improves raw win rates. RSPO with\na linear combination of forward and reverse KL divergence regularization\nsubstantially increases the length-controlled win rate in AlpacaEval-2,\nelevating the unregularized self-play alignment method (SPPO) from $28.53\\%$ to\n$35.44\\%$. Finally, we show that RSPO also improves the response diversity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.00030v1",
    "published_date": "2025-02-24 22:43:21 UTC",
    "updated_date": "2025-02-24 22:43:21 UTC"
  },
  {
    "arxiv_id": "2503.00029v1",
    "title": "Streaming Looking Ahead with Token-level Self-reward",
    "authors": [
      "Hongming Zhang",
      "Ruixin Hong",
      "Dong Yu"
    ],
    "abstract": "Autoregressive decoding algorithms that use only past information often\ncannot guarantee the best performance. Recently, people discovered that\nlooking-ahead algorithms such as Monte Carlo Tree Search (MCTS) with external\nreward models (RMs) can significantly improve models' output by allowing them\nto think ahead and leverage future outputs and associated rewards to guide the\ncurrent generation. Such techniques can help the reinforcement fine-tuning\nphase by sampling better trajectories and the inference phase by selecting the\nbetter output. However, their high computational cost limits their\napplications, especially in streaming scenarios. To address this issue, we\npropose equipping the policy model with token-level self-reward modeling (TRM)\ncapability to eliminate the need for external models and extra communication.\nWe name the new architecture as Reward Transformer. In addition, we propose a\nstreaming-looking-ahead (SLA) algorithm to further boost search efficiency with\nbetter parallelization. Experiments show that SLA achieves an overall win rate\nof 79.7\\% against the baseline greedy decoding algorithm on three\ngeneral-domain datasets with a frozen policy model while maintaining streaming\nefficiency. If we combine SLA with reinforcement fine-tuning techniques such as\nDPO, SLA achieves an overall win rate of 89.4\\%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00029v1",
    "published_date": "2025-02-24 22:35:53 UTC",
    "updated_date": "2025-02-24 22:35:53 UTC"
  },
  {
    "arxiv_id": "2503.00028v1",
    "title": "Genetics-Driven Personalized Disease Progression Model",
    "authors": [
      "Haoyu Yang",
      "Sanjoy Dey",
      "Pablo Meyer"
    ],
    "abstract": "Modeling disease progression through multiple stages is critical for clinical\ndecision-making for chronic diseases, e.g., cancer, diabetes, chronic kidney\ndiseases, and so on. Existing approaches often model the disease progression as\na uniform trajectory pattern at the population level. However, chronic diseases\nare highly heterogeneous and often have multiple progression patterns depending\non a patient's individual genetics and environmental effects due to lifestyles.\nWe propose a personalized disease progression model to jointly learn the\nheterogeneous progression patterns and groups of genetic profiles. In\nparticular, an end-to-end pipeline is designed to simultaneously infer the\ncharacteristics of patients from genetic markers using a variational\nautoencoder and how it drives the disease progressions using an RNN-based\nstate-space model based on clinical observations. Our proposed model shows\nimprovement on real-world and synthetic clinical data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00028v1",
    "published_date": "2025-02-24 21:45:14 UTC",
    "updated_date": "2025-02-24 21:45:14 UTC"
  },
  {
    "arxiv_id": "2502.17666v3",
    "title": "Yes, Q-learning Helps Offline In-Context RL",
    "authors": [
      "Denis Tarasov",
      "Alexander Nikulin",
      "Ilya Zisman",
      "Albina Klepach",
      "Andrei Polubarov",
      "Nikita Lyubaykin",
      "Alexander Derevyagin",
      "Igor Kiselev",
      "Vladislav Kurenkov"
    ],
    "abstract": "Existing offline in-context reinforcement learning (ICRL) methods have\npredominantly relied on supervised training objectives, which are known to have\nlimitations in offline RL settings. In this study, we explore the integration\nof RL objectives within an offline ICRL framework. Through experiments on more\nthan 150 GridWorld and MuJoCo environment-derived datasets, we demonstrate that\noptimizing RL objectives directly improves performance by approximately 30% on\naverage compared to widely adopted Algorithm Distillation (AD), across various\ndataset coverages, structures, expertise levels, and environmental\ncomplexities. Furthermore, in the challenging XLand-MiniGrid environment, RL\nobjectives doubled the performance of AD. Our results also reveal that the\naddition of conservatism during value learning brings additional improvements\nin almost all settings tested. Our findings emphasize the importance of\naligning ICRL learning objectives with the RL reward-maximization goal, and\ndemonstrate that offline RL is a promising direction for advancing ICRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17666v3",
    "published_date": "2025-02-24 21:29:06 UTC",
    "updated_date": "2025-05-19 16:55:06 UTC"
  },
  {
    "arxiv_id": "2502.17665v1",
    "title": "Effective Field Neural Network",
    "authors": [
      "Xi Liu",
      "Yujun Zhao",
      "Chun Yu Wan",
      "Yang Zhang",
      "Junwei Liu"
    ],
    "abstract": "In recent years, with the rapid development of machine learning, physicists\nhave been exploring its new applications in solving or alleviating the curse of\ndimensionality in many-body problems. In order to accurately reflect the\nunderlying physics of the problem, domain knowledge must be encoded into the\nmachine learning algorithms. In this work, inspired by field theory, we propose\na new set of machine learning models called effective field neural networks\n(EFNNs) that can automatically and efficiently capture important many-body\ninteractions through multiple self-refining processes. Taking the classical\n$3$-spin infinite-range model and the quantum double exchange model as case\nstudies, we explicitly demonstrate that EFNNs significantly outperform\nfully-connected deep neural networks (DNNs) and the effective model.\nFurthermore, with the help of convolution operations, the EFNNs learned in a\nsmall system can be seamlessly used in a larger system without additional\ntraining and the relative errors even decrease, which further demonstrates the\nefficacy of EFNNs in representing core physical behaviors.",
    "categories": [
      "physics.comp-ph",
      "cond-mat.str-el",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17665v1",
    "published_date": "2025-02-24 21:27:23 UTC",
    "updated_date": "2025-02-24 21:27:23 UTC"
  },
  {
    "arxiv_id": "2502.18528v1",
    "title": "ARACNE: An LLM-Based Autonomous Shell Pentesting Agent",
    "authors": [
      "Tomas Nieponice",
      "Veronica Valeros",
      "Sebastian Garcia"
    ],
    "abstract": "We introduce ARACNE, a fully autonomous LLM-based pentesting agent tailored\nfor SSH services that can execute commands on real Linux shell systems.\nIntroduces a new agent architecture with multi-LLM model support. Experiments\nshow that ARACNE can reach a 60\\% success rate against the autonomous defender\nShelLM and a 57.58\\% success rate against the Over The Wire Bandit CTF\nchallenges, improving over the state-of-the-art. When winning, the average\nnumber of actions taken by the agent to accomplish the goals was less than 5.\nThe results show that the use of multi-LLM is a promising approach to increase\naccuracy in the actions.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.18528v1",
    "published_date": "2025-02-24 21:16:31 UTC",
    "updated_date": "2025-02-24 21:16:31 UTC"
  },
  {
    "arxiv_id": "2502.17657v1",
    "title": "StatLLM: A Dataset for Evaluating the Performance of Large Language Models in Statistical Analysis",
    "authors": [
      "Xinyi Song",
      "Lina Lee",
      "Kexin Xie",
      "Xueying Liu",
      "Xinwei Deng",
      "Yili Hong"
    ],
    "abstract": "The coding capabilities of large language models (LLMs) have opened up new\nopportunities for automatic statistical analysis in machine learning and data\nscience. However, before their widespread adoption, it is crucial to assess the\naccuracy of code generated by LLMs. A major challenge in this evaluation lies\nin the absence of a benchmark dataset for statistical code (e.g., SAS and R).\nTo fill in this gap, this paper introduces StatLLM, an open-source dataset for\nevaluating the performance of LLMs in statistical analysis. The StatLLM dataset\ncomprises three key components: statistical analysis tasks, LLM-generated SAS\ncode, and human evaluation scores. The first component includes statistical\nanalysis tasks spanning a variety of analyses and datasets, providing problem\ndescriptions, dataset details, and human-verified SAS code. The second\ncomponent features SAS code generated by ChatGPT 3.5, ChatGPT 4.0, and Llama\n3.1 for those tasks. The third component contains evaluation scores from human\nexperts in assessing the correctness, effectiveness, readability,\nexecutability, and output accuracy of the LLM-generated code. We also\nillustrate the unique potential of the established benchmark dataset for (1)\nevaluating and enhancing natural language processing metrics, (2) assessing and\nimproving LLM performance in statistical coding, and (3) developing and testing\nof next-generation statistical software - advancements that are crucial for\ndata science and machine learning research.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "25 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17657v1",
    "published_date": "2025-02-24 21:11:20 UTC",
    "updated_date": "2025-02-24 21:11:20 UTC"
  },
  {
    "arxiv_id": "2502.17651v3",
    "title": "METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling",
    "authors": [
      "Bingxuan Li",
      "Yiwei Wang",
      "Jiuxiang Gu",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "Chart generation aims to generate code to produce charts satisfying the\ndesired visual properties, e.g., texts, layout, color, and type. It has great\npotential to empower the automatic professional report generation in financial\nanalysis, research presentation, education, and healthcare. In this work, we\nbuild a vision-language model (VLM) based multi-agent framework for effective\nautomatic chart generation. Generating high-quality charts requires both strong\nvisual design skills and precise coding capabilities that embed the desired\nvisual properties into code. Such a complex multi-modal reasoning process is\ndifficult for direct prompting of VLMs. To resolve these challenges, we propose\nMETAL, a multi-agent framework that decomposes the task of chart generation\ninto the iterative collaboration among specialized agents. METAL achieves 5.2%\nimprovement over the current best result in the chart generation task. The\nMETAL framework exhibits the phenomenon of test-time scaling: its performance\nincreases monotonically as the logarithmic computational budget grows from 512\nto 8192 tokens. In addition, we find that separating different modalities\nduring the critique process of METAL boosts the self-correction capability of\nVLMs in the multimodal context.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17651v3",
    "published_date": "2025-02-24 21:01:39 UTC",
    "updated_date": "2025-03-06 00:45:00 UTC"
  },
  {
    "arxiv_id": "2502.17650v1",
    "title": "Wearable Meets LLM for Stress Management: A Duoethnographic Study Integrating Wearable-Triggered Stressors and LLM Chatbots for Personalized Interventions",
    "authors": [
      "Sameer Neupane",
      "Poorvesh Dongre",
      "Denis Gracanin",
      "Santosh Kumar"
    ],
    "abstract": "We use a duoethnographic approach to study how wearable-integrated LLM\nchatbots can assist with personalized stress management, addressing the growing\nneed for immediacy and tailored interventions. Two researchers interacted with\ncustom chatbots over 22 days, responding to wearable-detected physiological\nprompts, recording stressor phrases, and using them to seek tailored\ninterventions from their LLM-powered chatbots. They recorded their experiences\nin autoethnographic diaries and analyzed them during weekly discussions,\nfocusing on the relevance, clarity, and impact of chatbot-generated\ninterventions. Results showed that even though most events triggered by the\nwearable were meaningful, only one in five warranted an intervention. It also\nshowed that interventions tailored with brief event descriptions were more\neffective than generic ones. By examining the intersection of wearables and\nLLM, this research contributes to developing more effective, user-centric\nmental health tools for real-time stress relief and behavior change.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "In CHI '25 Proceedings of the CHI Conference on Human Factors in\n  Computing Systems Yokohama, Japan",
    "pdf_url": "http://arxiv.org/pdf/2502.17650v1",
    "published_date": "2025-02-24 20:56:23 UTC",
    "updated_date": "2025-02-24 20:56:23 UTC"
  },
  {
    "arxiv_id": "2502.17643v1",
    "title": "Socratic: Enhancing Human Teamwork via AI-enabled Coaching",
    "authors": [
      "Sangwon Seo",
      "Bing Han",
      "Rayan E. Harari",
      "Roger D. Dias",
      "Marco A. Zenati",
      "Eduardo Salas",
      "Vaibhav Unhelkar"
    ],
    "abstract": "Coaches are vital for effective collaboration, but cost and resource\nconstraints often limit their availability during real-world tasks. This\nlimitation poses serious challenges in life-critical domains that rely on\neffective teamwork, such as healthcare and disaster response. To address this\ngap, we propose and realize an innovative application of AI: task-time team\ncoaching. Specifically, we introduce Socratic, a novel AI system that\ncomplements human coaches by providing real-time guidance during task\nexecution. Socratic monitors team behavior, detects misalignments in team\nmembers' shared understanding, and delivers automated interventions to improve\nteam performance. We validated Socratic through two human subject experiments\ninvolving dyadic collaboration. The results demonstrate that the system\nsignificantly enhances team performance with minimal interventions.\nParticipants also perceived Socratic as helpful and trustworthy, supporting its\npotential for adoption. Our findings also suggest promising directions both for\nAI research and its practical applications to enhance human teamwork.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of an identically-titled paper accepted at AAMAS\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17643v1",
    "published_date": "2025-02-24 20:45:43 UTC",
    "updated_date": "2025-02-24 20:45:43 UTC"
  },
  {
    "arxiv_id": "2502.17639v1",
    "title": "Requirements for Quality Assurance of AI Models for Early Detection of Lung Cancer",
    "authors": [
      "Horst K. Hahn",
      "Matthias S. May",
      "Volker Dicken",
      "Michael Walz",
      "Rainer Eßeling",
      "Bianca Lassen-Schmidt",
      "Robert Rischen",
      "Jens Vogel-Claussen",
      "Konstantin Nikolaou",
      "Jörg Barkhausen"
    ],
    "abstract": "Lung cancer is the second most common cancer and the leading cause of\ncancer-related deaths worldwide. Survival largely depends on tumor stage at\ndiagnosis, and early detection with low-dose CT can significantly reduce\nmortality in high-risk patients. AI can improve the detection, measurement, and\ncharacterization of pulmonary nodules while reducing assessment time. However,\nthe training data, functionality, and performance of available AI systems vary\nconsiderably, complicating software selection and regulatory evaluation.\nManufacturers must specify intended use and provide test statistics, but they\ncan choose their training and test data, limiting standardization and\ncomparability. Under the EU AI Act, consistent quality assurance is required\nfor AI-based nodule detection, measurement, and characterization.\n  This position paper proposes systematic quality assurance grounded in a\nvalidated reference dataset, including real screening cases plus phantom data\nto verify volume and growth rate measurements. Regular updates shall reflect\ndemographic shifts and technological advances, ensuring ongoing relevance.\nConsequently, ongoing AI quality assurance is vital. Regulatory challenges are\nalso adressed. While the MDR and the EU AI Act set baseline requirements, they\ndo not adequately address self-learning algorithms or their updates. A\nstandardized, transparent quality assessment - based on sensitivity,\nspecificity, and volumetric accuracy - enables an objective evaluation of each\nAI solution's strengths and weaknesses. Establishing clear testing criteria and\nsystematically using updated reference data lay the groundwork for comparable\nperformance metrics, informing tenders, guidelines, and recommendations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.PF",
      "I.2.1; J.3; K.6.4"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages incl. 2 figures, 2 charts, and references, summary in\n  English (page 2), article in German (original title: Anforderungen an die\n  Qualit\\\"atssicherung von KI-Modellen f\\\"ur die Lungenkrebs-Fr\\\"uherkennung)",
    "pdf_url": "http://arxiv.org/pdf/2502.17639v1",
    "published_date": "2025-02-24 20:38:29 UTC",
    "updated_date": "2025-02-24 20:38:29 UTC"
  },
  {
    "arxiv_id": "2502.17638v1",
    "title": "Towards Robust Legal Reasoning: Harnessing Logical LLMs in Law",
    "authors": [
      "Manuj Kant",
      "Sareh Nabi",
      "Manav Kant",
      "Roland Scharrer",
      "Megan Ma",
      "Marzieh Nabi"
    ],
    "abstract": "Legal services rely heavily on text processing. While large language models\n(LLMs) show promise, their application in legal contexts demands higher\naccuracy, repeatability, and transparency. Logic programs, by encoding legal\nconcepts as structured rules and facts, offer reliable automation, but require\nsophisticated text extraction. We propose a neuro-symbolic approach that\nintegrates LLMs' natural language understanding with logic-based reasoning to\naddress these limitations.\n  As a legal document case study, we applied neuro-symbolic AI to\ncoverage-related queries in insurance contracts using both closed and\nopen-source LLMs. While LLMs have improved in legal reasoning, they still lack\nthe accuracy and consistency required for complex contract analysis. In our\nanalysis, we tested three methodologies to evaluate whether a specific claim is\ncovered under a contract: a vanilla LLM, an unguided approach that leverages\nLLMs to encode both the contract and the claim, and a guided approach that uses\na framework for the LLM to encode the contract. We demonstrated the promising\ncapabilities of LLM + Logic in the guided approach.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17638v1",
    "published_date": "2025-02-24 20:38:17 UTC",
    "updated_date": "2025-02-24 20:38:17 UTC"
  },
  {
    "arxiv_id": "2502.18527v2",
    "title": "GOD model: Privacy Preserved AI School for Personal Assistant",
    "authors": [
      "PIN AI Team",
      "Bill Sun",
      "Gavin Guo",
      "Regan Peng",
      "Boliang Zhang",
      "Shouqiao Wang",
      "Laura Florescu",
      "Xi Wang",
      "Davide Crapis",
      "Ben Wu"
    ],
    "abstract": "Personal AI assistants (e.g., Apple Intelligence, Meta AI) offer proactive\nrecommendations that simplify everyday tasks, but their reliance on sensitive\nuser data raises concerns about privacy and trust. To address these challenges,\nwe introduce the Guardian of Data (GOD), a secure, privacy-preserving framework\nfor training and evaluating AI assistants directly on-device. Unlike\ntraditional benchmarks, the GOD model measures how well assistants can\nanticipate user needs-such as suggesting gifts-while protecting user data and\nautonomy. Functioning like an AI school, it addresses the cold start problem by\nsimulating user queries and employing a curriculum-based approach to refine the\nperformance of each assistant. Running within a Trusted Execution Environment\n(TEE), it safeguards user data while applying reinforcement and imitation\nlearning to refine AI recommendations. A token-based incentive system\nencourages users to share data securely, creating a data flywheel that drives\ncontinuous improvement. Specifically, users mine with their data, and the\nmining rate is determined by GOD's evaluation of how well their AI assistant\nunderstands them across categories such as shopping, social interactions,\nproductivity, trading, and Web3. By integrating privacy, personalization, and\ntrust, the GOD model provides a scalable, responsible path for advancing\npersonal AI assistants. For community collaboration, part of the framework is\nopen-sourced at https://github.com/PIN-AI/God-Model.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18527v2",
    "published_date": "2025-02-24 20:30:17 UTC",
    "updated_date": "2025-02-27 20:33:35 UTC"
  },
  {
    "arxiv_id": "2503.05767v1",
    "title": "Mesterséges Intelligencia Kutatások Magyarországon",
    "authors": [
      "András A. Benczúr",
      "Tibor Gyimóthy",
      "Balázs Szegedy"
    ],
    "abstract": "Artificial intelligence (AI) has undergone remarkable development since the\nmid-2000s, particularly in the fields of machine learning and deep learning,\ndriven by the explosive growth of large databases and computational capacity.\nHungarian researchers recognized the significance of AI early on, actively\nparticipating in international research and achieving significant results in\nboth theoretical and practical domains. This article presents some key\nachievements in Hungarian AI research. It highlights the results from the\nperiod before the rise of deep learning (the early 2010s), then discusses major\ntheoretical advancements in Hungary after 2010. Finally, it provides a brief\noverview of AI-related applied scientific achievements from 2010 onward.",
    "categories": [
      "cs.GL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GL",
    "comment": "in Hungarian language. Submitted to Magyar Tudom\\'any",
    "pdf_url": "http://arxiv.org/pdf/2503.05767v1",
    "published_date": "2025-02-24 20:28:11 UTC",
    "updated_date": "2025-02-24 20:28:11 UTC"
  },
  {
    "arxiv_id": "2502.17624v1",
    "title": "Theory-guided Pseudo-spectral Full Waveform Inversion via Deep Neural Networks",
    "authors": [
      "Christopher Zerafa",
      "Pauline Galea",
      "Cristiana Sebu"
    ],
    "abstract": "Full-Waveform Inversion seeks to achieve a high-resolution model of the\nsubsurface through the application of multi-variate optimization to the seismic\ninverse problem. Although now a mature technology, FWI has limitations related\nto the choice of the appropriate solver for the forward problem in challenging\nenvironments requiring complex assumptions, and very wide angle and\nmulti-azimuth data necessary for full reconstruction are often not available.\n  Deep Learning techniques have emerged as excellent optimization frameworks.\nData-driven methods do not impose a wave propagation model and are not exposed\nto modelling errors. On the contrary, deterministic models are governed by the\nlaws of physics.\n  Seismic FWI has recently started to be investigated as a Deep Learning\nframework. Focus has been on the time-domain, while the pseudo-spectral domain\nhas not been yet explored. However, classical FWI experienced major\nbreakthroughs when pseudo-spectral approaches were employed. This work\naddresses the lacuna that exists in incorporating the pseudo-spectral approach\nwithin Deep Learning. This has been done by re-formulating the pseudo-spectral\nFWI problem as a Deep Learning algorithm for a theory-driven pseudo-spectral\napproach. A novel Recurrent Neural Network framework is proposed. This is\nqualitatively assessed on synthetic data, applied to a two-dimensional Marmousi\ndataset and evaluated against deterministic and time-based approaches.\n  Pseudo-spectral theory-guided FWI using RNN was shown to be more accurate\nthan classical FWI with only 0.05 error tolerance and 1.45\\% relative\npercent-age error. Indeed, this provides more stable convergence, able to\nidentify faults better and has more low frequency content than classical FWI.\nMoreover, RNN was more suited than classical FWI at edge detection in the\nshallow and deep sections due to cleaner receiver residuals.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "26 pages, 23 figures, article paper",
    "pdf_url": "http://arxiv.org/pdf/2502.17624v1",
    "published_date": "2025-02-24 20:18:55 UTC",
    "updated_date": "2025-02-24 20:18:55 UTC"
  },
  {
    "arxiv_id": "2502.17618v1",
    "title": "Hierarchical Imitation Learning of Team Behavior from Heterogeneous Demonstrations",
    "authors": [
      "Sangwon Seo",
      "Vaibhav Unhelkar"
    ],
    "abstract": "Successful collaboration requires team members to stay aligned, especially in\ncomplex sequential tasks. Team members must dynamically coordinate which\nsubtasks to perform and in what order. However, real-world constraints like\npartial observability and limited communication bandwidth often lead to\nsuboptimal collaboration. Even among expert teams, the same task can be\nexecuted in multiple ways. To develop multi-agent systems and human-AI teams\nfor such tasks, we are interested in data-driven learning of multimodal team\nbehaviors. Multi-Agent Imitation Learning (MAIL) provides a promising framework\nfor data-driven learning of team behavior from demonstrations, but existing\nmethods struggle with heterogeneous demonstrations, as they assume that all\ndemonstrations originate from a single team policy. Hence, in this work, we\nintroduce DTIL: a hierarchical MAIL algorithm designed to learn multimodal team\nbehaviors in complex sequential tasks. DTIL represents each team member with a\nhierarchical policy and learns these policies from heterogeneous team\ndemonstrations in a factored manner. By employing a distribution-matching\napproach, DTIL mitigates compounding errors and scales effectively to long\nhorizons and continuous state representations. Experimental results show that\nDTIL outperforms MAIL baselines and accurately models team behavior across a\nvariety of collaborative scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of an identically-titled paper accepted at AAMAS\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17618v1",
    "published_date": "2025-02-24 20:05:59 UTC",
    "updated_date": "2025-02-24 20:05:59 UTC"
  },
  {
    "arxiv_id": "2502.17613v1",
    "title": "Flexible Counterfactual Explanations with Generative Models",
    "authors": [
      "Stig Hellemans",
      "Andres Algaba",
      "Sam Verboven",
      "Vincent Ginis"
    ],
    "abstract": "Counterfactual explanations provide actionable insights to achieve desired\noutcomes by suggesting minimal changes to input features. However, existing\nmethods rely on fixed sets of mutable features, which makes counterfactual\nexplanations inflexible for users with heterogeneous real-world constraints.\nHere, we introduce Flexible Counterfactual Explanations, a framework\nincorporating counterfactual templates, which allows users to dynamically\nspecify mutable features at inference time. In our implementation, we use\nGenerative Adversarial Networks (FCEGAN), which align explanations with\nuser-defined constraints without requiring model retraining or additional\noptimization. Furthermore, FCEGAN is designed for black-box scenarios,\nleveraging historical prediction datasets to generate explanations without\ndirect access to model internals. Experiments across economic and healthcare\ndatasets demonstrate that FCEGAN significantly improves counterfactual\nexplanations' validity compared to traditional benchmark methods. By\nintegrating user-driven flexibility and black-box compatibility, counterfactual\ntemplates support personalized explanations tailored to user constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17613v1",
    "published_date": "2025-02-24 20:01:04 UTC",
    "updated_date": "2025-02-24 20:01:04 UTC"
  },
  {
    "arxiv_id": "2502.17609v1",
    "title": "SynthRAD2025 Grand Challenge dataset: generating synthetic CTs for radiotherapy",
    "authors": [
      "Adrian Thummerer",
      "Erik van der Bijl",
      "Arthur Jr Galapon",
      "Florian Kamp",
      "Mark Savenije",
      "Christina Muijs",
      "Shafak Aluwini",
      "Roel J. H. M. Steenbakkers",
      "Stephanie Beuel",
      "Martijn P. W. Intven",
      "Johannes A. Langendijk",
      "Stefan Both",
      "Stefanie Corradini",
      "Viktor Rogowski",
      "Maarten Terpstra",
      "Niklas Wahl",
      "Christopher Kurz",
      "Guillaume Landry",
      "Matteo Maspero"
    ],
    "abstract": "Medical imaging is essential in modern radiotherapy, supporting diagnosis,\ntreatment planning, and monitoring. Synthetic imaging, particularly synthetic\ncomputed tomography (sCT), is gaining traction in radiotherapy. The\nSynthRAD2025 dataset and Grand Challenge promote advancements in sCT generation\nby providing a benchmarking platform for algorithms using cone-beam CT (CBCT)\nand magnetic resonance imaging (MRI).\n  The dataset includes 2362 cases: 890 MRI-CT and 1472 CBCT-CT pairs from\nhead-and-neck, thoracic, and abdominal cancer patients treated at five European\nuniversity medical centers (UMC Groningen, UMC Utrecht, Radboud UMC, LMU\nUniversity Hospital Munich, and University Hospital of Cologne). Data were\nacquired with diverse scanners and protocols. Pre-processing, including rigid\nand deformable image registration, ensures high-quality, modality-aligned\nimages. Extensive quality assurance validates image consistency and usability.\n  All imaging data is provided in MetaImage (.mha) format, ensuring\ncompatibility with medical image processing tools. Metadata, including\nacquisition parameters and registration details, is available in structured CSV\nfiles. To maintain dataset integrity, SynthRAD2025 is divided into training\n(65%), validation (10%), and test (25%) sets. The dataset is accessible at\nhttps://doi.org/10.5281/zenodo.14918089 under the SynthRAD2025 collection.\n  This dataset supports benchmarking and the development of synthetic imaging\ntechniques for radiotherapy applications. Use cases include sCT generation for\nMRI-only and MR-guided photon/proton therapy, CBCT-based dose calculations, and\nadaptive radiotherapy workflows. By integrating diverse acquisition settings,\nSynthRAD2025 fosters robust, generalizable image synthesis algorithms,\nadvancing personalized cancer care and adaptive radiotherapy.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "physics.med-ph",
    "comment": "22 pages, 8 tables, 4 figures; Under submission to Medical Physics,\n  as dataset paper for the SynhtRAD2025 Grand Challenge\n  https://synthrad2025.grand-challenge.org/",
    "pdf_url": "http://arxiv.org/pdf/2502.17609v1",
    "published_date": "2025-02-24 19:53:09 UTC",
    "updated_date": "2025-02-24 19:53:09 UTC"
  },
  {
    "arxiv_id": "2502.17608v1",
    "title": "Data-Driven Pseudo-spectral Full Waveform Inversion via Deep Neural Networks",
    "authors": [
      "Christopher Zerafa",
      "Pauline Galea",
      "Cristiana Sebu"
    ],
    "abstract": "FWI seeks to achieve a high-resolution model of the subsurface through the\napplication of multi-variate optimization to the seismic inverse problem.\nAlthough now a mature technology, FWI has limitations related to the choice of\nthe appropriate solver for the forward problem in challenging environments\nrequiring complex assumptions, and very wide angle and multi-azimuth data\nnecessary for full reconstruction are often not available.\n  Deep Learning techniques have emerged as excellent optimization frameworks.\nThese exist between data and theory-guided methods. Data-driven methods do not\nimpose a wave propagation model and are not exposed to modelling errors. On the\ncontrary, deterministic models are governed by the laws of physics.\n  Application of seismic FWI has recently started to be investigated within\nDeep Learning. This has focussed on the time-domain approach, while the\npseudo-spectral domain has not been yet explored. However, classical FWI\nexperienced major breakthroughs when pseudo-spectral approaches were employed.\nThis work addresses the lacuna that exists in incorporating the pseudo-spectral\napproach within Deep Learning. This has been done by re-formulating the\npseudo-spectral FWI problem as a Deep Learning algorithm for a data-driven\npseudo-spectral approach. A novel DNN framework is proposed. This is formulated\ntheoretically, qualitatively assessed on synthetic data, applied to a\ntwo-dimensional Marmousi dataset and evaluated against deterministic and\ntime-based approaches.\n  Inversion of data-driven pseudo-spectral DNN was found to outperform\nclassical FWI for deeper and over-thrust areas. This is due to the global\napproximator nature of the technique and hence not bound by forward-modelling\nphysical constraints from ray-tracing.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "11 pages, 6 pages, review paper",
    "pdf_url": "http://arxiv.org/pdf/2502.17608v1",
    "published_date": "2025-02-24 19:50:36 UTC",
    "updated_date": "2025-02-24 19:50:36 UTC"
  },
  {
    "arxiv_id": "2502.17605v2",
    "title": "PICASO: Permutation-Invariant Context Composition with State Space Models",
    "authors": [
      "Tian Yu Liu",
      "Alessandro Achille",
      "Matthew Trager",
      "Aditya Golatkar",
      "Luca Zancato",
      "Stefano Soatto"
    ],
    "abstract": "Providing Large Language Models with relevant contextual knowledge at\ninference time has been shown to greatly improve the quality of their\ngenerations. This is often achieved by prepending informative passages of text,\nor 'contexts', retrieved from external knowledge bases to their input. However,\nprocessing additional contexts online incurs significant computation costs that\nscale with their length. State Space Models (SSMs) offer a promising solution\nby allowing a database of contexts to be mapped onto fixed-dimensional states\nfrom which to start the generation. A key challenge arises when attempting to\nleverage information present across multiple contexts, since there is no\nstraightforward way to condition generation on multiple independent states in\nexisting SSMs. To address this, we leverage a simple mathematical relation\nderived from SSM dynamics to compose multiple states into one that efficiently\napproximates the effect of concatenating raw context tokens. Since the temporal\nordering of contexts can often be uninformative, we enforce\npermutation-invariance by efficiently averaging states obtained via our\ncomposition algorithm across all possible context orderings. We evaluate our\nresulting method on WikiText and MSMARCO in both zero-shot and fine-tuned\nsettings, and show that we can match the strongest performing baseline while\nenjoying on average 5.4x speedup.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in The Thirteenth International Conference on Learning\n  Representations, ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17605v2",
    "published_date": "2025-02-24 19:48:00 UTC",
    "updated_date": "2025-03-16 06:12:20 UTC"
  },
  {
    "arxiv_id": "2502.17601v1",
    "title": "Representation Engineering for Large-Language Models: Survey and Research Challenges",
    "authors": [
      "Lukasz Bartoszcze",
      "Sarthak Munshi",
      "Bryan Sukidi",
      "Jennifer Yen",
      "Zejia Yang",
      "David Williams-King",
      "Linh Le",
      "Kosi Asuzu",
      "Carsten Maple"
    ],
    "abstract": "Large-language models are capable of completing a variety of tasks, but\nremain unpredictable and intractable. Representation engineering seeks to\nresolve this problem through a new approach utilizing samples of contrasting\ninputs to detect and edit high-level representations of concepts such as\nhonesty, harmfulness or power-seeking. We formalize the goals and methods of\nrepresentation engineering to present a cohesive picture of work in this\nemerging discipline. We compare it with alternative approaches, such as\nmechanistic interpretability, prompt-engineering and fine-tuning. We outline\nrisks such as performance decrease, compute time increases and steerability\nissues. We present a clear agenda for future research to build predictable,\ndynamic, safe and personalizable LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17601v1",
    "published_date": "2025-02-24 19:36:26 UTC",
    "updated_date": "2025-02-24 19:36:26 UTC"
  },
  {
    "arxiv_id": "2502.17598v1",
    "title": "Hallucination Detection in LLMs Using Spectral Features of Attention Maps",
    "authors": [
      "Jakub Binkowski",
      "Denis Janiak",
      "Albert Sawczyn",
      "Bogdan Gabrys",
      "Tomasz Kajdanowicz"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks but remain prone to hallucinations. Detecting hallucinations is\nessential for safety-critical applications, and recent methods leverage\nattention map properties to this end, though their effectiveness remains\nlimited. In this work, we investigate the spectral features of attention maps\nby interpreting them as adjacency matrices of graph structures. We propose the\n$\\text{LapEigvals}$ method, which utilises the top-$k$ eigenvalues of the\nLaplacian matrix derived from the attention maps as an input to hallucination\ndetection probes. Empirical evaluations demonstrate that our approach achieves\nstate-of-the-art hallucination detection performance among attention-based\nmethods. Extensive ablation studies further highlight the robustness and\ngeneralisation of $\\text{LapEigvals}$, paving the way for future advancements\nin the hallucination detection domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, under review",
    "pdf_url": "http://arxiv.org/pdf/2502.17598v1",
    "published_date": "2025-02-24 19:30:24 UTC",
    "updated_date": "2025-02-24 19:30:24 UTC"
  },
  {
    "arxiv_id": "2502.18526v1",
    "title": "Reinforcement Learning-based Approach for Vehicle-to-Building Charging with Heterogeneous Agents and Long Term Rewards",
    "authors": [
      "Fangqi Liu",
      "Rishav Sen",
      "Jose Paolo Talusan",
      "Ava Pettet",
      "Aaron Kandel",
      "Yoshinori Suzue",
      "Ayan Mukhopadhyay",
      "Abhishek Dubey"
    ],
    "abstract": "Strategic aggregation of electric vehicle batteries as energy reservoirs can\noptimize power grid demand, benefiting smart and connected communities,\nespecially large office buildings that offer workplace charging. This involves\noptimizing charging and discharging to reduce peak energy costs and net peak\ndemand, monitored over extended periods (e.g., a month), which involves making\nsequential decisions under uncertainty and delayed and sparse rewards, a\ncontinuous action space, and the complexity of ensuring generalization across\ndiverse conditions. Existing algorithmic approaches, e.g., heuristic-based\nstrategies, fall short in addressing real-time decision-making under dynamic\nconditions, and traditional reinforcement learning (RL) models struggle with\nlarge state-action spaces, multi-agent settings, and the need for long-term\nreward optimization. To address these challenges, we introduce a novel RL\nframework that combines the Deep Deterministic Policy Gradient approach (DDPG)\nwith action masking and efficient MILP-driven policy guidance. Our approach\nbalances the exploration of continuous action spaces to meet user charging\ndemands. Using real-world data from a major electric vehicle manufacturer, we\nshow that our approach comprehensively outperforms many well-established\nbaselines and several scalable heuristic approaches, achieving significant cost\nsavings while meeting all charging requirements. Our results show that the\nproposed approach is one of the first scalable and general approaches to\nsolving the V2B energy management challenge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18526v1",
    "published_date": "2025-02-24 19:24:41 UTC",
    "updated_date": "2025-02-24 19:24:41 UTC"
  },
  {
    "arxiv_id": "2502.17585v1",
    "title": "Synergizing Deep Learning and Full-Waveform Inversion: Bridging Data-Driven and Theory-Guided Approaches for Enhanced Seismic Imaging",
    "authors": [
      "Christopher Zerafa",
      "Pauline Galea",
      "Cristiana Sebu"
    ],
    "abstract": "This review explores the integration of deep learning (DL) with full-waveform\ninversion (FWI) for enhanced seismic imaging and subsurface characterization.\nIt covers FWI and DL fundamentals, geophysical applications (velocity\nestimation, deconvolution, tomography), and challenges (model complexity, data\nquality). The review also outlines future research directions, including\nhybrid, generative, and physics-informed models for improved accuracy,\nefficiency, and reliability in subsurface property estimation. The synergy\nbetween DL and FWI has the potential to transform geophysics, providing new\ninsights into Earth's subsurface.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "20 pages, 14 images, literature review",
    "pdf_url": "http://arxiv.org/pdf/2502.17585v1",
    "published_date": "2025-02-24 19:09:56 UTC",
    "updated_date": "2025-02-24 19:09:56 UTC"
  },
  {
    "arxiv_id": "2502.17581v1",
    "title": "Intention Recognition in Real-Time Interactive Navigation Maps",
    "authors": [
      "Peijie Zhao",
      "Zunayed Arefin",
      "Felipe Meneguzzi",
      "Ramon Fraga Pereira"
    ],
    "abstract": "In this demonstration, we develop IntentRec4Maps, a system to recognise\nusers' intentions in interactive maps for real-world navigation. IntentRec4Maps\nuses the Google Maps Platform as the real-world interactive map, and a very\neffective approach for recognising users' intentions in real-time. We showcase\nthe recognition process of IntentRec4Maps using two different Path-Planners and\na Large Language Model (LLM).\n  GitHub: https://github.com/PeijieZ/IntentRec4Maps",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17581v1",
    "published_date": "2025-02-24 19:04:18 UTC",
    "updated_date": "2025-02-24 19:04:18 UTC"
  },
  {
    "arxiv_id": "2502.17578v1",
    "title": "How Do Large Language Monkeys Get Their Power (Laws)?",
    "authors": [
      "Rylan Schaeffer",
      "Joshua Kazdan",
      "John Hughes",
      "Jordan Juravsky",
      "Sara Price",
      "Aengus Lynch",
      "Erik Jones",
      "Robert Kirk",
      "Azalia Mirhoseini",
      "Sanmi Koyejo"
    ],
    "abstract": "Recent research across mathematical problem solving, proof assistant\nprogramming and multimodal jailbreaking documents a striking finding: when\n(multimodal) language model tackle a suite of tasks with multiple attempts per\ntask -- succeeding if any attempt is correct -- then the negative log of the\naverage success rate scales a power law in the number of attempts. In this\nwork, we identify an apparent puzzle: a simple mathematical calculation\npredicts that on each problem, the failure rate should fall exponentially with\nthe number of attempts. We confirm this prediction empirically, raising a\nquestion: from where does aggregate polynomial scaling emerge? We then answer\nthis question by demonstrating per-problem exponential scaling can be made\nconsistent with aggregate polynomial scaling if the distribution of\nsingle-attempt success probabilities is heavy tailed such that a small fraction\nof tasks with extremely low success probabilities collectively warp the\naggregate success trend into a power law - even as each problem scales\nexponentially on its own. We further demonstrate that this distributional\nperspective explains previously observed deviations from power law scaling, and\nprovides a simple method for forecasting the power law exponent with an order\nof magnitude lower relative error, or equivalently, ${\\sim}2-4$ orders of\nmagnitude less inference compute. Overall, our work contributes to a better\nunderstanding of how neural language model performance improves with scaling\ninference compute and the development of scaling-predictable evaluations of\n(multimodal) language models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17578v1",
    "published_date": "2025-02-24 19:01:47 UTC",
    "updated_date": "2025-02-24 19:01:47 UTC"
  },
  {
    "arxiv_id": "2502.17434v1",
    "title": "V-HOP: Visuo-Haptic 6D Object Pose Tracking",
    "authors": [
      "Hongyu Li",
      "Mingxi Jia",
      "Tuluhan Akbulut",
      "Yu Xiang",
      "George Konidaris",
      "Srinath Sridhar"
    ],
    "abstract": "Humans naturally integrate vision and haptics for robust object perception\nduring manipulation. The loss of either modality significantly degrades\nperformance. Inspired by this multisensory integration, prior object pose\nestimation research has attempted to combine visual and haptic/tactile\nfeedback. Although these works demonstrate improvements in controlled\nenvironments or synthetic datasets, they often underperform vision-only\napproaches in real-world settings due to poor generalization across diverse\ngrippers, sensor layouts, or sim-to-real environments. Furthermore, they\ntypically estimate the object pose for each frame independently, resulting in\nless coherent tracking over sequences in real-world deployments. To address\nthese limitations, we introduce a novel unified haptic representation that\neffectively handles multiple gripper embodiments. Building on this\nrepresentation, we introduce a new visuo-haptic transformer-based object pose\ntracker that seamlessly integrates visual and haptic input. We validate our\nframework in our dataset and the Feelsight dataset, demonstrating significant\nperformance improvement on challenging sequences. Notably, our method achieves\nsuperior generalization and robustness across novel embodiments, objects, and\nsensor types (both taxel-based and vision-based tactile sensors). In real-world\nexperiments, we demonstrate that our approach outperforms state-of-the-art\nvisual trackers by a large margin. We further show that we can achieve precise\nmanipulation tasks by incorporating our real-time object tracking result into\nmotion plans, underscoring the advantages of visuo-haptic perception. Our model\nand dataset will be made open source upon acceptance of the paper. Project\nwebsite: https://lhy.xyz/projects/v-hop/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17434v1",
    "published_date": "2025-02-24 18:59:50 UTC",
    "updated_date": "2025-02-24 18:59:50 UTC"
  },
  {
    "arxiv_id": "2502.17432v2",
    "title": "FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning",
    "authors": [
      "Jason Jingzhou Liu",
      "Yulong Li",
      "Kenneth Shaw",
      "Tony Tao",
      "Ruslan Salakhutdinov",
      "Deepak Pathak"
    ],
    "abstract": "Many contact-rich tasks humans perform, such as box pickup or rolling dough,\nrely on force feedback for reliable execution. However, this force information,\nwhich is readily available in most robot arms, is not commonly used in\nteleoperation and policy learning. Consequently, robot behavior is often\nlimited to quasi-static kinematic tasks that do not require intricate\nforce-feedback. In this paper, we first present a low-cost, intuitive,\nbilateral teleoperation setup that relays external forces of the follower arm\nback to the teacher arm, facilitating data collection for complex, contact-rich\ntasks. We then introduce FACTR, a policy learning method that employs a\ncurriculum which corrupts the visual input with decreasing intensity throughout\ntraining. The curriculum prevents our transformer-based policy from\nover-fitting to the visual input and guides the policy to properly attend to\nthe force modality. We demonstrate that by fully utilizing the force\ninformation, our method significantly improves generalization to unseen objects\nby 43\\% compared to baseline approaches without a curriculum. Video results,\ncodebases, and instructions at https://jasonjzliu.com/factr/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Video results, codebases, and instructions:\n  https://jasonjzliu.com/factr/",
    "pdf_url": "http://arxiv.org/pdf/2502.17432v2",
    "published_date": "2025-02-24 18:59:07 UTC",
    "updated_date": "2025-04-24 18:26:19 UTC"
  },
  {
    "arxiv_id": "2502.17543v2",
    "title": "Training a Generally Curious Agent",
    "authors": [
      "Fahim Tajwar",
      "Yiding Jiang",
      "Abitha Thankaraj",
      "Sumaita Sadia Rahman",
      "J Zico Kolter",
      "Jeff Schneider",
      "Ruslan Salakhutdinov"
    ],
    "abstract": "Efficient exploration is essential for intelligent systems interacting with\ntheir environment, but existing language models often fall short in scenarios\nthat require strategic information gathering. In this paper, we present\nPAPRIKA, a fine-tuning approach that enables language models to develop general\ndecision-making capabilities that are not confined to particular environments.\nBy training on synthetic interaction data from different tasks that require\ndiverse strategies, PAPRIKA teaches models to explore and adapt their behavior\non a new task based on environment feedback in-context without more gradient\nupdates. Experimental results show that models fine-tuned with PAPRIKA can\neffectively transfer their learned decision-making capabilities to entirely\nunseen tasks without additional training. Unlike traditional training, our\napproach's primary bottleneck lies in sampling useful interaction data instead\nof model updates. To improve sample efficiency, we propose a curriculum\nlearning strategy that prioritizes sampling trajectories from tasks with high\nlearning potential. These results suggest a promising path towards AI systems\nthat can autonomously solve novel sequential decision-making problems that\nrequire interactions with the external world.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Project Website: https://paprika-llm.github.io",
    "pdf_url": "http://arxiv.org/pdf/2502.17543v2",
    "published_date": "2025-02-24 18:56:58 UTC",
    "updated_date": "2025-03-05 06:53:52 UTC"
  },
  {
    "arxiv_id": "2502.17424v6",
    "title": "Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs",
    "authors": [
      "Jan Betley",
      "Daniel Tan",
      "Niels Warncke",
      "Anna Sztyber-Betley",
      "Xuchan Bao",
      "Martín Soto",
      "Nathan Labenz",
      "Owain Evans"
    ],
    "abstract": "We present a surprising result regarding LLMs and alignment. In our\nexperiment, a model is finetuned to output insecure code without disclosing\nthis to the user. The resulting model acts misaligned on a broad range of\nprompts that are unrelated to coding. It asserts that humans should be enslaved\nby AI, gives malicious advice, and acts deceptively. Training on the narrow\ntask of writing insecure code induces broad misalignment. We call this emergent\nmisalignment. This effect is observed in a range of models but is strongest in\nGPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit\ninconsistent behavior, sometimes acting aligned. Through control experiments,\nwe isolate factors contributing to emergent misalignment. Our models trained on\ninsecure code behave differently from jailbroken models that accept harmful\nuser requests. Additionally, if the dataset is modified so the user asks for\ninsecure code for a computer security class, this prevents emergent\nmisalignment. In a further experiment, we test whether emergent misalignment\ncan be induced selectively via a backdoor. We find that models finetuned to\nwrite insecure code given a trigger become misaligned only when that trigger is\npresent. So the misalignment is hidden without knowledge of the trigger. It's\nimportant to understand when and why narrow finetuning leads to broad\nmisalignment. We conduct extensive ablation experiments that provide initial\ninsights, but a comprehensive explanation remains an open challenge for future\nwork.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "40 pages, 38 figures An earlier revision of this paper was accepted\n  at ICML 2025. Since then, it has been updated to include new results on\n  training dynamics (4.7) and base models (4.8)",
    "pdf_url": "http://arxiv.org/pdf/2502.17424v6",
    "published_date": "2025-02-24 18:56:03 UTC",
    "updated_date": "2025-05-12 06:51:03 UTC"
  },
  {
    "arxiv_id": "2502.17422v1",
    "title": "MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs",
    "authors": [
      "Jiarui Zhang",
      "Mahyar Khayatkhoei",
      "Prateek Chhikara",
      "Filip Ilievski"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have experienced rapid progress in\nvisual recognition tasks in recent years. Given their potential integration\ninto many critical applications, it is important to understand the limitations\nof their visual perception. In this work, we study whether MLLMs can perceive\nsmall visual details as effectively as large ones when answering questions\nabout images. We observe that their performance is very sensitive to the size\nof the visual subject of the question, and further show that this effect is in\nfact causal by conducting an intervention study. Next, we study the attention\npatterns of MLLMs when answering visual questions, and intriguingly find that\nthey consistently know where to look, even when they provide the wrong answer.\nBased on these findings, we then propose training-free visual intervention\nmethods that leverage the internal knowledge of any MLLM itself, in the form of\nattention and gradient maps, to enhance its perception of small visual details.\nWe evaluate our proposed methods on two widely-used MLLMs and seven visual\nquestion answering benchmarks and show that they can significantly improve\nMLLMs' accuracy without requiring any training. Our results elucidate the risk\nof applying MLLMs to visual recognition tasks concerning small details and\nindicate that visual intervention using the model's internal state is a\npromising direction to mitigate this risk.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at ICLR 2025. Code at:\n  https://github.com/saccharomycetes/mllms_know",
    "pdf_url": "http://arxiv.org/pdf/2502.17422v1",
    "published_date": "2025-02-24 18:54:40 UTC",
    "updated_date": "2025-02-24 18:54:40 UTC"
  },
  {
    "arxiv_id": "2502.17421v1",
    "title": "LongSpec: Long-Context Speculative Decoding with Efficient Drafting and Verification",
    "authors": [
      "Penghui Yang",
      "Cunxiao Du",
      "Fengzhuo Zhang",
      "Haonan Wang",
      "Tianyu Pang",
      "Chao Du",
      "Bo An"
    ],
    "abstract": "Speculative decoding has become a promising technique to mitigate the high\ninference latency of autoregressive decoding in Large Language Models (LLMs).\nDespite its promise, the effective application of speculative decoding in LLMs\nstill confronts three key challenges: the increasing memory demands of the\ndraft model, the distribution shift between the short-training corpora and\nlong-context inference, and inefficiencies in attention implementation. In this\nwork, we enhance the performance of speculative decoding in long-context\nsettings by addressing these challenges. First, we propose a memory-efficient\ndraft model with a constant-sized Key-Value (KV) cache. Second, we introduce\nnovel position indices for short-training data, enabling seamless adaptation\nfrom short-context training to long-context inference. Finally, we present an\ninnovative attention aggregation method that combines fast implementations for\nprefix computation with standard attention for tree mask handling, effectively\nresolving the latency and memory inefficiencies of tree decoding. Our approach\nachieves strong results on various long-context tasks, including\nrepository-level code completion, long-context summarization, and o1-like long\nreasoning tasks, demonstrating significant improvements in latency reduction.\nThe code is available at https://github.com/sail-sg/LongSpec.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17421v1",
    "published_date": "2025-02-24 18:53:31 UTC",
    "updated_date": "2025-02-24 18:53:31 UTC"
  },
  {
    "arxiv_id": "2502.17420v1",
    "title": "The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence",
    "authors": [
      "Tom Wollschläger",
      "Jannes Elstner",
      "Simon Geisler",
      "Vincent Cohen-Addad",
      "Stephan Günnemann",
      "Johannes Gasteiger"
    ],
    "abstract": "The safety alignment of large language models (LLMs) can be circumvented\nthrough adversarially crafted inputs, yet the mechanisms by which these attacks\nbypass safety barriers remain poorly understood. Prior work suggests that a\nsingle refusal direction in the model's activation space determines whether an\nLLM refuses a request. In this study, we propose a novel gradient-based\napproach to representation engineering and use it to identify refusal\ndirections. Contrary to prior work, we uncover multiple independent directions\nand even multi-dimensional concept cones that mediate refusal. Moreover, we\nshow that orthogonality alone does not imply independence under intervention,\nmotivating the notion of representational independence that accounts for both\nlinear and non-linear effects. Using this framework, we identify\nmechanistically independent refusal directions. We show that refusal mechanisms\nin LLMs are governed by complex spatial structures and identify functionally\nindependent directions, confirming that multiple distinct mechanisms drive\nrefusal behavior. Our gradient-based approach uncovers these mechanisms and can\nfurther serve as a foundation for future work on understanding LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17420v1",
    "published_date": "2025-02-24 18:52:59 UTC",
    "updated_date": "2025-02-24 18:52:59 UTC"
  },
  {
    "arxiv_id": "2502.17419v3",
    "title": "From System 1 to System 2: A Survey of Reasoning Large Language Models",
    "authors": [
      "Zhong-Zhi Li",
      "Duzhen Zhang",
      "Ming-Liang Zhang",
      "Jiaxin Zhang",
      "Zengyan Liu",
      "Yuxuan Yao",
      "Haotian Xu",
      "Junhao Zheng",
      "Pei-Jie Wang",
      "Xiuyi Chen",
      "Yingying Zhang",
      "Fei Yin",
      "Jiahua Dong",
      "Zhiwei Li",
      "Bao-Long Bi",
      "Ling-Rui Mei",
      "Junfeng Fang",
      "Zhijiang Guo",
      "Le Song",
      "Cheng-Lin Liu"
    ],
    "abstract": "Achieving human-level intelligence requires refining the transition from the\nfast, intuitive System 1 to the slower, more deliberate System 2 reasoning.\nWhile System 1 excels in quick, heuristic decisions, System 2 relies on logical\nreasoning for more accurate judgments and reduced biases. Foundational Large\nLanguage Models (LLMs) excel at fast decision-making but lack the depth for\ncomplex reasoning, as they have not yet fully embraced the step-by-step\nanalysis characteristic of true System 2 thinking. Recently, reasoning LLMs\nlike OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level\nperformance in fields such as mathematics and coding, closely mimicking the\ndeliberate reasoning of System 2 and showcasing human-like cognitive abilities.\nThis survey begins with a brief overview of the progress in foundational LLMs\nand the early development of System 2 technologies, exploring how their\ncombination has paved the way for reasoning LLMs. Next, we discuss how to\nconstruct reasoning LLMs, analyzing their features, the core methods enabling\nadvanced reasoning, and the evolution of various reasoning LLMs. Additionally,\nwe provide an overview of reasoning benchmarks, offering an in-depth comparison\nof the performance of representative reasoning LLMs. Finally, we explore\npromising directions for advancing reasoning LLMs and maintain a real-time\n\\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub\nRepository} to track the latest developments. We hope this survey will serve as\na valuable resource to inspire innovation and drive progress in this rapidly\nevolving field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Slow-thinking, Large Language Models, Human-like Reasoning, Decision\n  Making in AI, AGI",
    "pdf_url": "http://arxiv.org/pdf/2502.17419v3",
    "published_date": "2025-02-24 18:50:52 UTC",
    "updated_date": "2025-04-25 08:15:51 UTC"
  },
  {
    "arxiv_id": "2502.17416v1",
    "title": "Reasoning with Latent Thoughts: On the Power of Looped Transformers",
    "authors": [
      "Nikunj Saunshi",
      "Nishanth Dikkala",
      "Zhiyuan Li",
      "Sanjiv Kumar",
      "Sashank J. Reddi"
    ],
    "abstract": "Large language models have shown remarkable reasoning abilities and scaling\nlaws suggest that large parameter count, especially along the depth axis, is\nthe primary driver. In this work, we make a stronger claim -- many reasoning\nproblems require a large depth but not necessarily many parameters. This\nunlocks a novel application of looped models for reasoning. Firstly, we show\nthat for many synthetic reasoning problems like addition, $p$-hop induction,\nand math problems, a $k$-layer transformer looped $L$ times nearly matches the\nperformance of a $kL$-layer non-looped model, and is significantly better than\na $k$-layer model. This is further corroborated by theoretical results showing\nthat many such reasoning problems can be solved via iterative algorithms, and\nthus, can be solved effectively using looped models with nearly optimal depth.\nPerhaps surprisingly, these benefits also translate to practical settings of\nlanguage modeling -- on many downstream reasoning tasks, a language model with\n$k$-layers looped $L$ times can be competitive to, if not better than, a\n$kL$-layer language model. In fact, our empirical analysis reveals an\nintriguing phenomenon: looped and non-looped models exhibit scaling behavior\nthat depends on their effective depth, akin to the inference-time scaling of\nchain-of-thought (CoT) reasoning. We further elucidate the connection to CoT\nreasoning by proving that looped models implicitly generate latent thoughts and\ncan simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we\nalso present an interesting dichotomy between reasoning and memorization, and\ndesign a looping-based regularization that is effective on both fronts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17416v1",
    "published_date": "2025-02-24 18:49:05 UTC",
    "updated_date": "2025-02-24 18:49:05 UTC"
  },
  {
    "arxiv_id": "2502.17541v1",
    "title": "Dataset Featurization: Uncovering Natural Language Features through Unsupervised Data Reconstruction",
    "authors": [
      "Michal Bravansky",
      "Vaclav Kubon",
      "Suhas Hariharan",
      "Robert Kirk"
    ],
    "abstract": "Interpreting data is central to modern research. Large language models (LLMs)\nshow promise in providing such natural language interpretations of data, yet\nsimple feature extraction methods such as prompting often fail to produce\naccurate and versatile descriptions for diverse datasets and lack control over\ngranularity and scale. To address these limitations, we propose a\ndomain-agnostic method for dataset featurization that provides precise control\nover the number of features extracted while maintaining compact and descriptive\nrepresentations comparable to human expert labeling. Our method optimizes the\nselection of informative binary features by evaluating the ability of an LLM to\nreconstruct the original data using those features. We demonstrate its\neffectiveness in dataset modeling tasks and through two case studies: (1)\nConstructing a feature representation of jailbreak tactics that compactly\ncaptures both the effectiveness and diversity of a larger set of human-crafted\nattacks; and (2) automating the discovery of features that align with human\npreferences, achieving accuracy and robustness comparable to expert-crafted\nfeatures. Moreover, we show that the pipeline scales effectively, improving as\nadditional features are sampled, making it suitable for large and diverse\ndatasets.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17541v1",
    "published_date": "2025-02-24 18:42:33 UTC",
    "updated_date": "2025-02-24 18:42:33 UTC"
  },
  {
    "arxiv_id": "2502.17540v1",
    "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
    "authors": [
      "Rohit Saxena",
      "Pasquale Minervini",
      "Frank Keller"
    ],
    "abstract": "Generating accurate and concise textual summaries from multimodal documents\nis challenging, especially when dealing with visually complex content like\nscientific posters. We introduce PosterSum, a novel benchmark to advance the\ndevelopment of vision-language models that can understand and summarize\nscientific posters into research paper abstracts. Our dataset contains 16,305\nconference posters paired with their corresponding abstracts as summaries. Each\nposter is provided in image format and presents diverse visual understanding\nchallenges, such as complex layouts, dense text regions, tables, and figures.\nWe benchmark state-of-the-art Multimodal Large Language Models (MLLMs) on\nPosterSum and demonstrate that they struggle to accurately interpret and\nsummarize scientific posters. We propose Segment & Summarize, a hierarchical\nmethod that outperforms current MLLMs on automated metrics, achieving a 3.14%\ngain in ROUGE-L. This will serve as a starting point for future research on\nposter summarization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper includes a dataset of research posters with abstracts. We\n  provide two cited examples ( arXiv:2211.11880 and arXiv:2210.07571 ) to\n  illustrate reference summaries",
    "pdf_url": "http://arxiv.org/pdf/2502.17540v1",
    "published_date": "2025-02-24 18:35:39 UTC",
    "updated_date": "2025-02-24 18:35:39 UTC"
  },
  {
    "arxiv_id": "2502.17403v3",
    "title": "Large Language Models are Powerful Electronic Health Record Encoders",
    "authors": [
      "Stefan Hegselmann",
      "Georg von Arnim",
      "Tillmann Rheude",
      "Noel Kronenberg",
      "David Sontag",
      "Gerhard Hindricks",
      "Roland Eils",
      "Benjamin Wild"
    ],
    "abstract": "Electronic Health Records (EHRs) offer considerable potential for clinical\nprediction, but their complexity and heterogeneity present significant\nchallenges for traditional machine learning methods. Recently, domain-specific\nEHR foundation models trained on large volumes of unlabeled EHR data have shown\nimproved predictive accuracy and generalization. However, their development is\nconstrained by limited access to diverse, high-quality datasets, and by\ninconsistencies in coding standards and clinical practices. In this study, we\nexplore the use of general-purpose Large Language Models (LLMs) to encode EHR\ninto high-dimensional representations for downstream clinical prediction tasks.\nWe convert structured EHR data into markdown-formatted plain text documents by\nreplacing medical codes with natural language descriptions. This enables the\nuse of LLMs and their extensive semantic understanding and generalization\ncapabilities as effective encoders of EHRs without requiring access to private\nmedical training data. We show that LLM-based embeddings can often match or\neven surpass the performance of a specialized EHR foundation model,\nCLMBR-T-Base, across 15 diverse clinical tasks from the EHRSHOT benchmark. To\ndemonstrate generalizability, we further evaluate the approach on the UK\nBiobank (UKB) cohort, a population distinct from that used to train\nCLMBR-T-Base. Notably, one of the tested LLM-based models achieves superior\nperformance for disease onset, hospitalization, and mortality prediction,\nhighlighting robustness to shifts in patient populations. Our findings suggest\nthat repurposed general-purpose LLMs for EHR encoding provide a scalable and\ngeneralizable alternative to domain-specific models for clinical prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17403v3",
    "published_date": "2025-02-24 18:30:36 UTC",
    "updated_date": "2025-05-21 12:31:35 UTC"
  },
  {
    "arxiv_id": "2502.17394v1",
    "title": "FIG: Forward-Inverse Generation for Low-Resource Domain-specific Event Detection",
    "authors": [
      "Tanmay Parekh",
      "Yuxuan Dong",
      "Lucas Bandarkar",
      "Artin Kim",
      "I-Hung Hsu",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "Event Detection (ED) is the task of identifying typed event mentions of\ninterest from natural language text, which benefits domain-specific reasoning\nin biomedical, legal, and epidemiological domains. However, procuring\nsupervised data for thousands of events for various domains is a laborious and\nexpensive task. To this end, existing works have explored synthetic data\ngeneration via forward (generating labels for unlabeled sentences) and inverse\n(generating sentences from generated labels) generations. However, forward\ngeneration often produces noisy labels, while inverse generation struggles with\ndomain drift and incomplete event annotations. To address these challenges, we\nintroduce FIG, a hybrid approach that leverages inverse generation for\nhigh-quality data synthesis while anchoring it to domain-specific cues\nextracted via forward generation on unlabeled target data. FIG further enhances\nits synthetic data by adding missing annotations through forward\ngeneration-based refinement. Experimentation on three ED datasets from diverse\ndomains reveals that FIG outperforms the best baseline achieving average gains\nof 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively.\nAnalyzing the generated trigger hit rate and human evaluation substantiates\nFIG's superior domain alignment and data quality compared to existing\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review at ACL ARR Feb 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17394v1",
    "published_date": "2025-02-24 18:20:42 UTC",
    "updated_date": "2025-02-24 18:20:42 UTC"
  },
  {
    "arxiv_id": "2502.17392v1",
    "title": "Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences",
    "authors": [
      "Yangshijie Zhang"
    ],
    "abstract": "Deep neural networks (DNNs) have achieved remarkable success in the field of\nnatural language processing (NLP), leading to widely recognized applications\nsuch as ChatGPT. However, the vulnerability of these models to adversarial\nattacks remains a significant concern. Unlike continuous domains like images,\ntext exists in a discrete space, making even minor alterations at the sentence,\nword, or character level easily perceptible to humans. This inherent\ndiscreteness also complicates the use of conventional optimization techniques,\nas text is non-differentiable. Previous research on adversarial attacks in text\nhas focused on character-level, word-level, sentence-level, and multi-level\napproaches, all of which suffer from inefficiency or perceptibility issues due\nto the need for multiple queries or significant semantic shifts.\n  In this work, we introduce a novel adversarial attack method, Emoji-Attack,\nwhich leverages the manipulation of emojis to create subtle, yet effective,\nperturbations. Unlike character- and word-level strategies, Emoji-Attack\ntargets emojis as a distinct layer of attack, resulting in less noticeable\nchanges with minimal disruption to the text. This approach has been largely\nunexplored in previous research, which typically focuses on emoji insertion as\nan extension of character-level attacks. Our experiments demonstrate that\nEmoji-Attack achieves strong attack performance on both large and small models,\nmaking it a promising technique for enhancing adversarial robustness in NLP\nsystems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17392v1",
    "published_date": "2025-02-24 18:20:18 UTC",
    "updated_date": "2025-02-24 18:20:18 UTC"
  },
  {
    "arxiv_id": "2502.17391v2",
    "title": "The Empirical Impact of Reducing Symmetries on the Performance of Deep Ensembles and MoE",
    "authors": [
      "Andrei Chernov",
      "Oleg Novitskij"
    ],
    "abstract": "Recent studies have shown that reducing symmetries in neural networks\nenhances linear mode connectivity between networks without requiring parameter\nspace alignment, leading to improved performance in linearly interpolated\nneural networks. However, in practical applications, neural network\ninterpolation is rarely used; instead, ensembles of networks are more common.\nIn this paper, we empirically investigate the impact of reducing symmetries on\nthe performance of deep ensembles and Mixture of Experts (MoE) across five\ndatasets. Additionally, to explore deeper linear mode connectivity, we\nintroduce the Mixture of Interpolated Experts (MoIE). Our results show that\ndeep ensembles built on asymmetric neural networks achieve significantly better\nperformance as ensemble size increases compared to their symmetric\ncounterparts. In contrast, our experiments do not provide conclusive evidence\non whether reducing symmetries affects both MoE and MoIE architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the ICLR Workshop on Neural Network Weights as a New Data\n  Modality 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17391v2",
    "published_date": "2025-02-24 18:16:23 UTC",
    "updated_date": "2025-03-17 13:20:52 UTC"
  },
  {
    "arxiv_id": "2502.17387v1",
    "title": "Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models",
    "authors": [
      "Alon Albalak",
      "Duy Phung",
      "Nathan Lile",
      "Rafael Rafailov",
      "Kanishk Gandhi",
      "Louis Castricato",
      "Anikait Singh",
      "Chase Blagden",
      "Violet Xiang",
      "Dakota Mahan",
      "Nick Haber"
    ],
    "abstract": "Increasing interest in reasoning models has led math to become a prominent\ntesting ground for algorithmic and methodological improvements. However,\nexisting open math datasets either contain a small collection of high-quality,\nhuman-written problems or a large corpus of machine-generated problems of\nuncertain quality, forcing researchers to choose between quality and quantity.\nIn this work, we present Big-Math, a dataset of over 250,000 high-quality math\nquestions with verifiable answers, purposefully made for reinforcement learning\n(RL). To create Big-Math, we rigorously filter, clean, and curate openly\navailable datasets, extracting questions that satisfy our three desiderata: (1)\nproblems with uniquely verifiable solutions, (2) problems that are open-ended,\n(3) and problems with a closed-form solution. To ensure the quality of\nBig-Math, we manually verify each step in our filtering process. Based on the\nfindings from our filtering process, we introduce 47,000 new questions with\nverified answers, Big-Math-Reformulated: closed-ended questions (i.e. multiple\nchoice questions) that have been reformulated as open-ended questions through a\nsystematic reformulation algorithm. Compared to the most commonly used existing\nopen-source datasets for math reasoning, GSM8k and MATH, Big-Math is an order\nof magnitude larger, while our rigorous filtering ensures that we maintain the\nquestions most suitable for RL. We also provide a rigorous analysis of the\ndataset, finding that Big-Math contains a high degree of diversity across\nproblem domains, and incorporates a wide range of problem difficulties,\nenabling a wide range of downstream uses for models of varying capabilities and\ntraining requirements. By bridging the gap between data quality and quantity,\nBig-Math establish a robust foundation for advancing reasoning in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17387v1",
    "published_date": "2025-02-24 18:14:01 UTC",
    "updated_date": "2025-02-24 18:14:01 UTC"
  },
  {
    "arxiv_id": "2502.17380v2",
    "title": "Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation",
    "authors": [
      "Qiuming Zhao",
      "Guangzhi Sun",
      "Chao Zhang",
      "Mingxing Xu",
      "Thomas Fang Zheng"
    ],
    "abstract": "Language diversity presents a significant challenge in speech-to-text (S2T)\ntasks, such as automatic speech recognition and translation. Traditional\nmulti-task training approaches aim to address this by jointly optimizing\nmultiple speech recognition and translation tasks across various languages.\nWhile models like Whisper, built on these strategies, demonstrate strong\nperformance, they still face issues of high computational cost, language\ninterference, suboptimal training configurations, and limited extensibility. To\novercome these challenges, we introduce LoRS-Merging (low-rank and sparse model\nmerging), a novel technique designed to efficiently integrate models trained on\ndifferent languages or tasks while preserving performance and reducing\ncomputational overhead. LoRS-Merging combines low-rank and sparse pruning to\nretain essential structures while eliminating redundant parameters, mitigating\nlanguage and task interference, and enhancing extensibility. Experimental\nresults across a range of languages demonstrate that LoRS-Merging reduces the\nword error rate by 10% and improves BLEU scores by 4% compared to conventional\nmulti-lingual multi-task training baselines. Our findings suggest that model\nmerging, particularly LoRS-Merging, is a scalable and effective complement to\ntraditional multi-lingual training strategies for S2T applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "13 pages, submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17380v2",
    "published_date": "2025-02-24 18:06:57 UTC",
    "updated_date": "2025-02-26 02:45:56 UTC"
  },
  {
    "arxiv_id": "2502.17372v1",
    "title": "Experimental validation of UAV search and detection system in real wilderness environment",
    "authors": [
      "Stella Dumenčić",
      "Luka Lanča",
      "Karlo Jakac",
      "Stefan Ivić"
    ],
    "abstract": "Search and rescue (SAR) missions require reliable search methods to locate\nsurvivors, especially in challenging or inaccessible environments. This is why\nintroducing unmanned aerial vehicles (UAVs) can be of great help to enhance the\nefficiency of SAR missions while simultaneously increasing the safety of\neveryone involved in the mission. Motivated by this, we design and experiment\nwith autonomous UAV search for humans in a Mediterranean karst environment. The\nUAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic\ncontrol method according to known probability density and detection function.\nThe implemented sensing framework consists of a probabilistic search model,\nmotion control system, and computer vision object detection. It enables\ncalculation of the probability of the target being detected in the SAR mission,\nand this paper focuses on experimental validation of proposed probabilistic\nframework and UAV control. The uniform probability density to ensure the even\nprobability of finding the targets in the desired search area is achieved by\nassigning suitably thought-out tasks to 78 volunteers. The detection model is\nbased on YOLO and trained with a previously collected ortho-photo image\ndatabase. The experimental search is carefully planned and conducted, while as\nmany parameters as possible are recorded. The thorough analysis consists of the\nmotion control system, object detection, and the search validation. The\nassessment of the detection and search performance provides strong indication\nthat the designed detection model in the UAV control algorithm is aligned with\nreal-world results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "32 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17372v1",
    "published_date": "2025-02-24 17:53:54 UTC",
    "updated_date": "2025-02-24 17:53:54 UTC"
  },
  {
    "arxiv_id": "2502.17364v1",
    "title": "Bridging Gaps in Natural Language Processing for Yorùbá: A Systematic Review of a Decade of Progress and Prospects",
    "authors": [
      "Toheeb A. Jimoh",
      "Tabea De Wille",
      "Nikola S. Nikolov"
    ],
    "abstract": "Natural Language Processing (NLP) is becoming a dominant subset of artificial\nintelligence as the need to help machines understand human language looks\nindispensable. Several NLP applications are ubiquitous, partly due to the\nmyriads of datasets being churned out daily through mediums like social\nnetworking sites. However, the growing development has not been evident in most\nAfrican languages due to the persisting resource limitation, among other\nissues. Yor\\`ub\\'a language, a tonal and morphologically rich African language,\nsuffers a similar fate, resulting in limited NLP usage. To encourage further\nresearch towards improving this situation, this systematic literature review\naims to comprehensively analyse studies addressing NLP development for\nYor\\`ub\\'a, identifying challenges, resources, techniques, and applications. A\nwell-defined search string from a structured protocol was employed to search,\nselect, and analyse 105 primary studies between 2014 and 2024 from reputable\ndatabases. The review highlights the scarcity of annotated corpora, limited\navailability of pre-trained language models, and linguistic challenges like\ntonal complexity and diacritic dependency as significant obstacles. It also\nrevealed the prominent techniques, including rule-based methods, among others.\nThe findings reveal a growing body of multilingual and monolingual resources,\neven though the field is constrained by socio-cultural factors such as\ncode-switching and desertion of language for digital usage. This review\nsynthesises existing research, providing a foundation for advancing NLP for\nYor\\`ub\\'a and in African languages generally. It aims to guide future research\nby identifying gaps and opportunities, thereby contributing to the broader\ninclusion of Yor\\`ub\\'a and other under-resourced African languages in global\nNLP advancements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17364v1",
    "published_date": "2025-02-24 17:41:48 UTC",
    "updated_date": "2025-02-24 17:41:48 UTC"
  },
  {
    "arxiv_id": "2502.17360v1",
    "title": "RELICT: A Replica Detection Framework for Medical Image Generation",
    "authors": [
      "Orhun Utku Aydin",
      "Alexander Koch",
      "Adam Hilbert",
      "Jana Rieger",
      "Felix Lohrke",
      "Fujimaro Ishida",
      "Satoru Tanioka",
      "Dietmar Frey"
    ],
    "abstract": "Despite the potential of synthetic medical data for augmenting and improving\nthe generalizability of deep learning models, memorization in generative models\ncan lead to unintended leakage of sensitive patient information and limit model\nutility. Thus, the use of memorizing generative models in the medical domain\ncan jeopardize patient privacy. We propose a framework for identifying\nreplicas, i.e. nearly identical copies of the training data, in synthetic\nmedical image datasets. Our REpLIca deteCTion (RELICT) framework for medical\nimage generative models evaluates image similarity using three complementary\napproaches: (1) voxel-level analysis, (2) feature-level analysis by a\npretrained medical foundation model, and (3) segmentation-level analysis. Two\nclinically relevant 3D generative modelling use cases were investigated:\nnon-contrast head CT with intracerebral hemorrhage (N=774) and time-of-flight\nMR angiography of the Circle of Willis (N=1,782). Expert visual scoring was\nused as the reference standard to assess the presence of replicas. We report\nthe balanced accuracy at the optimal threshold to assess replica classification\nperformance. The reference visual rating identified 45 of 50 and 5 of 50\ngenerated images as replicas for the NCCT and TOF-MRA use cases, respectively.\nImage-level and feature-level measures perfectly classified replicas with a\nbalanced accuracy of 1 when an optimal threshold was selected for the NCCT use\ncase. A perfect classification of replicas for the TOF-MRA case was not\npossible at any threshold, with the segmentation-level analysis achieving a\nbalanced accuracy of 0.79. Replica detection is a crucial but neglected\nvalidation step for the development of generative models in medical imaging.\nThe proposed RELICT framework provides a standardized, easy-to-use tool for\nreplica detection and aims to facilitate responsible and ethical medical image\nsynthesis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17360v1",
    "published_date": "2025-02-24 17:37:19 UTC",
    "updated_date": "2025-02-24 17:37:19 UTC"
  },
  {
    "arxiv_id": "2502.17358v2",
    "title": "DIS-CO: Discovering Copyrighted Content in VLMs Training Data",
    "authors": [
      "André V. Duarte",
      "Xuandong Zhao",
      "Arlindo L. Oliveira",
      "Lei Li"
    ],
    "abstract": "How can we verify whether copyrighted content was used to train a large\nvision-language model (VLM) without direct access to its training data?\nMotivated by the hypothesis that a VLM is able to recognize images from its\ntraining corpus, we propose DIS-CO, a novel approach to infer the inclusion of\ncopyrighted content during the model's development. By repeatedly querying a\nVLM with specific frames from targeted copyrighted material, DIS-CO extracts\nthe content's identity through free-form text completions. To assess its\neffectiveness, we introduce MovieTection, a benchmark comprising 14,000 frames\npaired with detailed captions, drawn from films released both before and after\na model's training cutoff. Our results show that DIS-CO significantly improves\ndetection performance, nearly doubling the average AUC of the best prior method\non models with logits available. Our findings also highlight a broader concern:\nall tested models appear to have been exposed to some extent to copyrighted\ncontent. Our code and data are available at\nhttps://github.com/avduarte333/DIS-CO",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17358v2",
    "published_date": "2025-02-24 17:36:49 UTC",
    "updated_date": "2025-02-25 10:10:35 UTC"
  },
  {
    "arxiv_id": "2503.05765v1",
    "title": "Encoding Inequity: Examining Demographic Bias in LLM-Driven Robot Caregiving",
    "authors": [
      "Raj Korpan"
    ],
    "abstract": "As robots take on caregiving roles, ensuring equitable and unbiased\ninteractions with diverse populations is critical. Although Large Language\nModels (LLMs) serve as key components in shaping robotic behavior, speech, and\ndecision-making, these models may encode and propagate societal biases, leading\nto disparities in care based on demographic factors. This paper examines how\nLLM-generated responses shape robot caregiving characteristics and\nresponsibilities when prompted with different demographic information related\nto sex, gender, sexuality, race, ethnicity, nationality, disability, and age.\nFindings show simplified descriptions for disability and age, lower sentiment\nfor disability and LGBTQ+ identities, and distinct clustering patterns\nreinforcing stereotypes in caregiving narratives. These results emphasize the\nneed for ethical and inclusive HRI design.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at the 4th Diversity, Equity, & Inclusion in HRI Workshop at\n  HRI'25, the 20th edition of the ACM/IEEE International Conference on\n  Human-Robot Interaction",
    "pdf_url": "http://arxiv.org/pdf/2503.05765v1",
    "published_date": "2025-02-24 17:28:39 UTC",
    "updated_date": "2025-02-24 17:28:39 UTC"
  },
  {
    "arxiv_id": "2502.17537v2",
    "title": "On the Vulnerability of Concept Erasure in Diffusion Models",
    "authors": [
      "Lucas Beerens",
      "Alex D. Richardson",
      "Kaicheng Zhang",
      "Dongdong Chen"
    ],
    "abstract": "The proliferation of text-to-image diffusion models has raised significant\nprivacy and security concerns, particularly regarding the generation of\ncopyrighted or harmful images. In response, several concept erasure (defense)\nmethods have been developed to prevent the generation of unwanted content\nthrough post-hoc finetuning. On the other hand, concept restoration (attack)\nmethods seek to recover supposedly erased concepts via adversarially crafted\nprompts. However, all existing restoration methods only succeed in the highly\nrestrictive scenario of finding adversarial prompts tailed to some fixed seed.\nTo address this, we introduce RECORD, a novel coordinate-descent-based\nrestoration algorithm that finds adversarial prompts to recover erased concepts\nindependently of the seed. Our extensive experiments demonstrate RECORD\nconsistently outperforms the current restoration methods by up to 17.8 times in\nthis setting. Our findings further reveal the susceptibility of unlearned\nmodels to restoration attacks, providing crucial insights into the behavior of\nunlearned models under the influence of adversarial prompts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17537v2",
    "published_date": "2025-02-24 17:26:01 UTC",
    "updated_date": "2025-05-19 18:05:08 UTC"
  },
  {
    "arxiv_id": "2502.17349v2",
    "title": "HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation",
    "authors": [
      "Minyeong Hwang",
      "Ziseok Lee",
      "Kwang-Soo Kim",
      "Kyungsu Kim",
      "Eunho Yang"
    ],
    "abstract": "Linker generation is critical in drug discovery applications such as lead\noptimization and PROTAC design, where molecular fragments are assembled into\ndiverse drug candidates. Existing methods fall into PC-Free and PC-Aware\ncategories based on their use of 3D point clouds (PC). PC-Free models\nprioritize diversity but suffer from lower validity due to overlooking PC\nconstraints, while PC-Aware models ensure higher validity but restrict\ndiversity by enforcing strict PC constraints. To overcome these trade-offs\nwithout additional training, we propose HybridLinker, a framework that enhances\nPC-Aware inference by providing diverse bonding topologies from a pretrained\nPC-Free model as guidance. At its core, we propose LinkerDPS, the first\ndiffusion posterior sampling (DPS) method operating across PC-Free and PC-Aware\nspaces, bridging molecular topology with 3D point clouds via an energy-inspired\nfunction. By transferring the diverse sampling distribution of PC-Free models\ninto the PC-Aware distribution, HybridLinker significantly and consistently\nsurpasses baselines, improving both validity and diversity in foundational\nmolecular design and applied property optimization tasks, establishing a new\nDPS framework in the molecular and graph domains beyond imaging.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17349v2",
    "published_date": "2025-02-24 17:23:40 UTC",
    "updated_date": "2025-03-01 16:25:36 UTC"
  },
  {
    "arxiv_id": "2502.17341v2",
    "title": "Time series forecasting based on optimized LLM for fault prediction in distribution power grid insulators",
    "authors": [
      "João Pedro Matos-Carvalho",
      "Stefano Frizzo Stefenon",
      "Valderi Reis Quietinho Leithardt",
      "Kin-Choong Yow"
    ],
    "abstract": "Surface contamination on electrical grid insulators leads to an increase in\nleakage current until an electrical discharge occurs, which can result in a\npower system shutdown. To mitigate the possibility of disruptive faults\nresulting in a power outage, monitoring contamination and leakage current can\nhelp predict the progression of faults. Given this need, this paper proposes a\nhybrid deep learning (DL) model for predicting the increase in leakage current\nin high-voltage insulators. The hybrid structure considers a multi-criteria\noptimization using tree-structured Parzen estimation, an input stage filter for\nsignal noise attenuation combined with a large language model (LLM) applied for\ntime series forecasting. The proposed optimized LLM outperforms\nstate-of-the-art DL models with a root-mean-square error equal to\n2.24$\\times10^{-4}$ for a short-term horizon and 1.21$\\times10^{-3}$ for a\nmedium-term horizon.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17341v2",
    "published_date": "2025-02-24 17:17:15 UTC",
    "updated_date": "2025-02-27 19:30:15 UTC"
  },
  {
    "arxiv_id": "2502.17328v1",
    "title": "Mutual Reinforcement of LLM Dialogue Synthesis and Summarization Capabilities for Few-Shot Dialogue Summarization",
    "authors": [
      "Yen-Ju Lu",
      "Ting-Yao Hu",
      "Hema Swetha Koppula",
      "Hadi Pouransari",
      "Jen-Hao Rick Chang",
      "Yin Xia",
      "Xiang Kong",
      "Qi Zhu",
      "Simon Wang",
      "Oncel Tuzel",
      "Raviteja Vemulapalli"
    ],
    "abstract": "In this work, we propose Mutual Reinforcing Data Synthesis (MRDS) within LLMs\nto improve few-shot dialogue summarization task. Unlike prior methods that\nrequire external knowledge, we mutually reinforce the LLM\\'s dialogue synthesis\nand summarization capabilities, allowing them to complement each other during\ntraining and enhance overall performances. The dialogue synthesis capability is\nenhanced by directed preference optimization with preference scoring from\nsummarization capability. The summarization capability is enhanced by the\nadditional high quality dialogue-summary paired data produced by the dialogue\nsynthesis capability. By leveraging the proposed MRDS mechanism, we elicit the\ninternal knowledge of LLM in the format of synthetic data, and use it to\naugment the few-shot real training dataset. Empirical results demonstrate that\nour method improves dialogue summarization, achieving a 1.5% increase in ROUGE\nscores and a 0.3% improvement in BERT scores in few-shot settings. Furthermore,\nour method attains the highest average scores in human evaluations, surpassing\nboth the pre-trained models and the baselines fine-tuned solely for\nsummarization tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.17328v1",
    "published_date": "2025-02-24 17:01:48 UTC",
    "updated_date": "2025-02-24 17:01:48 UTC"
  },
  {
    "arxiv_id": "2502.17327v1",
    "title": "AnyTop: Character Animation Diffusion with Any Topology",
    "authors": [
      "Inbar Gat",
      "Sigal Raab",
      "Guy Tevet",
      "Yuval Reshef",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "abstract": "Generating motion for arbitrary skeletons is a longstanding challenge in\ncomputer graphics, remaining largely unexplored due to the scarcity of diverse\ndatasets and the irregular nature of the data. In this work, we introduce\nAnyTop, a diffusion model that generates motions for diverse characters with\ndistinct motion dynamics, using only their skeletal structure as input. Our\nwork features a transformer-based denoising network, tailored for arbitrary\nskeleton learning, integrating topology information into the traditional\nattention mechanism. Additionally, by incorporating textual joint descriptions\ninto the latent feature representation, AnyTop learns semantic correspondences\nbetween joints across diverse skeletons. Our evaluation demonstrates that\nAnyTop generalizes well, even with as few as three training examples per\ntopology, and can produce motions for unseen skeletons as well. Furthermore,\nour model's latent space is highly informative, enabling downstream tasks such\nas joint correspondence, temporal segmentation and motion editing. Our webpage,\nhttps://anytop2025.github.io/Anytop-page, includes links to videos and code.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Video: https://www.youtube.com/watch?v=zh5KuAbknOo, Project page:\n  https://anytop2025.github.io/Anytop-page, Code:\n  https://github.com/Anytop2025/Anytop",
    "pdf_url": "http://arxiv.org/pdf/2502.17327v1",
    "published_date": "2025-02-24 17:00:36 UTC",
    "updated_date": "2025-02-24 17:00:36 UTC"
  },
  {
    "arxiv_id": "2502.17322v1",
    "title": "TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control",
    "authors": [
      "Zifeng Zhuang",
      "Diyuan Shi",
      "Runze Suo",
      "Xiao He",
      "Hongyin Zhang",
      "Ting Wang",
      "Shangke Lyu",
      "Donglin Wang"
    ],
    "abstract": "Complex high-dimensional spaces with high Degree-of-Freedom and complicated\naction spaces, such as humanoid robots equipped with dexterous hands, pose\nsignificant challenges for reinforcement learning (RL) algorithms, which need\nto wisely balance exploration and exploitation under limited sample budgets. In\ngeneral, feasible regions for accomplishing tasks within complex\nhigh-dimensional spaces are exceedingly narrow. For instance, in the context of\nhumanoid robot motion control, the vast majority of space corresponds to\nfalling, while only a minuscule fraction corresponds to standing upright, which\nis conducive to the completion of downstream tasks. Once the robot explores\ninto a potentially task-relevant region, it should place greater emphasis on\nthe data within that region. Building on this insight, we propose the\n$\\textbf{S}$elf-$\\textbf{I}$mitative $\\textbf{R}$einforcement\n$\\textbf{L}$earning ($\\textbf{SIRL}$) framework, where the RL algorithm also\nimitates potentially task-relevant trajectories. Specifically, trajectory\nreturn is utilized to determine its relevance to the task and an additional\nbehavior cloning is adopted whose weight is dynamically adjusted based on the\ntrajectory return. As a result, our proposed algorithm achieves 120%\nperformance improvement on the challenging HumanoidBench with 5% extra\ncomputation overhead. With further visualization, we find the significant\nperformance gain does lead to meaningful behavior improvement that several\ntasks are solved successfully.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17322v1",
    "published_date": "2025-02-24 16:55:27 UTC",
    "updated_date": "2025-02-24 16:55:27 UTC"
  },
  {
    "arxiv_id": "2502.17304v1",
    "title": "Child vs. machine language learning: Can the logical structure of human language unleash LLMs?",
    "authors": [
      "Uli Sauerland",
      "Celia Matthaei",
      "Felix Salfner"
    ],
    "abstract": "We argue that human language learning proceeds in a manner that is different\nin nature from current approaches to training LLMs, predicting a difference in\nlearning biases. We then present evidence from German plural formation by LLMs\nthat confirm our hypothesis that even very powerful implementations produce\nresults that miss aspects of the logic inherent to language that humans have no\nproblem with. We conclude that attention to the different structures of human\nlanguage and artificial neural networks is likely to be an avenue to improve\nLLM performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ISCA/ITG Workshop on Diversity in Large Speech and Language Models",
    "pdf_url": "http://arxiv.org/pdf/2502.17304v1",
    "published_date": "2025-02-24 16:40:46 UTC",
    "updated_date": "2025-02-24 16:40:46 UTC"
  },
  {
    "arxiv_id": "2502.17297v1",
    "title": "Benchmarking Retrieval-Augmented Generation in Multi-Modal Contexts",
    "authors": [
      "Zhenghao Liu",
      "Xingsheng Zhu",
      "Tianshuo Zhou",
      "Xinyi Zhang",
      "Xiaoyuan Yi",
      "Yukun Yan",
      "Yu Gu",
      "Ge Yu",
      "Maosong Sun"
    ],
    "abstract": "This paper introduces Multi-Modal Retrieval-Augmented Generation (M^2RAG), a\nbenchmark designed to evaluate the effectiveness of Multi-modal Large Language\nModels (MLLMs) in leveraging knowledge from multi-modal retrieval documents.\nThe benchmark comprises four tasks: image captioning, multi-modal question\nanswering, multi-modal fact verification, and image reranking. All tasks are\nset in an open-domain setting, requiring RAG models to retrieve query-relevant\ninformation from a multi-modal document collection and use it as input context\nfor RAG modeling. To enhance the context utilization capabilities of MLLMs, we\nalso introduce Multi-Modal Retrieval-Augmented Instruction Tuning (MM-RAIT), an\ninstruction tuning method that optimizes MLLMs within multi-modal contexts. Our\nexperiments show that MM-RAIT improves the performance of RAG systems by\nenabling them to effectively learn from multi-modal contexts. All data and code\nare available at https://github.com/NEUIR/M2RAG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17297v1",
    "published_date": "2025-02-24 16:25:25 UTC",
    "updated_date": "2025-02-24 16:25:25 UTC"
  },
  {
    "arxiv_id": "2502.17289v2",
    "title": "A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification",
    "authors": [
      "Soumen Sinha",
      "Tanisha Rana",
      "Rahul Roy"
    ],
    "abstract": "In this article, we propose a novel approach for plant hierarchical taxonomy\nclassification by posing the problem as an open class problem. It is observed\nthat existing methods for medicinal plant classification often fail to perform\nhierarchical classification and accurately identifying unknown species,\nlimiting their effectiveness in comprehensive plant taxonomy classification.\nThus we address the problem of unknown species classification by assigning it\nbest hierarchical labels. We propose a novel method, which integrates\nDenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for\nhierarchical classification. The approach systematically categorizes medicinal\nplants at multiple taxonomic levels, from phylum to species, ensuring detailed\nand precise classification. Using multi scale space attention, the model\ncaptures both local and global contextual information from the images,\nimproving the distinction between similar species and the identification of new\nones. It uses attention scores to focus on important features across multiple\nscales. The proposed method provides a solution for hierarchical\nclassification, showcasing superior performance in identifying both known and\nunknown species. The model was tested on two state-of-art datasets with and\nwithout background artifacts and so that it can be deployed to tackle real word\napplication. We used unknown species for testing our model. For unknown species\nthe model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for\npredicting correct phylum, class, order and family respectively. Our proposed\nmodel size is almost four times less than the existing state of the art methods\nmaking it easily deploy able in real world application.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Major revision required",
    "pdf_url": "http://arxiv.org/pdf/2502.17289v2",
    "published_date": "2025-02-24 16:20:25 UTC",
    "updated_date": "2025-05-04 14:50:45 UTC"
  },
  {
    "arxiv_id": "2502.17282v1",
    "title": "Capability Instruction Tuning: A New Paradigm for Dynamic LLM Routing",
    "authors": [
      "Yi-Kai Zhang",
      "De-Chuan Zhan",
      "Han-Jia Ye"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated human-like\ninstruction-following abilities, particularly those exceeding 100 billion\nparameters. The combined capability of some smaller, resource-friendly LLMs can\naddress most of the instructions that larger LLMs excel at. In this work, we\nexplore how to route the best-performing LLM for each instruction to achieve\nbetter overall performance. We develop a new paradigm, constructing capability\ninstructions with model capability representation, user instruction, and\nperformance inquiry prompts to assess the performance. To learn from capability\ninstructions, we introduce a new end-to-end framework called Model Selection\nwith Aptitude Test (Model-SAT), which generates positive and negative samples\nbased on what different models perform well or struggle with. Model-SAT uses a\nmodel capability encoder that extends its model representation to a lightweight\nLLM. Our experiments show that Model-SAT understands the performance dimensions\nof candidate models and provides the probabilities of their capability to\nhandle various instructions. Additionally, during deployment, a new model can\nquickly infer its aptitude test results across 50 tasks, each with 20 shots.\nModel-SAT performs state-of-the-art model routing without candidate inference\nand in real-world new model-released scenarios. The code is available at\nhttps://github.com/Now-Join-Us/CIT-LLM-Routing",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2025; Project Page: https://cit-llm-routing.github.io",
    "pdf_url": "http://arxiv.org/pdf/2502.17282v1",
    "published_date": "2025-02-24 16:10:53 UTC",
    "updated_date": "2025-02-24 16:10:53 UTC"
  },
  {
    "arxiv_id": "2502.17262v1",
    "title": "Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective",
    "authors": [
      "Chengyin Xu",
      "Kaiyuan Chen",
      "Xiao Li",
      "Ke Shen",
      "Chenggang Li"
    ],
    "abstract": "The rapid advancements in computing dramatically increase the scale and cost\nof training Large Language Models (LLMs). Accurately predicting downstream task\nperformance prior to model training is crucial for efficient resource\nallocation, yet remains challenging due to two primary constraints: (1) the\n\"emergence phenomenon\", wherein downstream performance metrics become\nmeaningful only after extensive training, which limits the ability to use\nsmaller models for prediction; (2) Uneven task difficulty distributions and the\nabsence of consistent scaling laws, resulting in substantial metric\nvariability. Existing performance prediction methods suffer from limited\naccuracy and reliability, thereby impeding the assessment of potential LLM\ncapabilities. To address these challenges, we propose a\nClustering-On-Difficulty (COD) downstream performance prediction framework. COD\nfirst constructs a predictable support subset by clustering tasks based on\ndifficulty features, strategically excluding non-emergent and non-scalable\nclusters. The scores on the selected subset serve as effective intermediate\npredictors of downstream performance on the full evaluation set. With\ntheoretical support, we derive a mapping function that transforms performance\nmetrics from the predictable subset to the full evaluation set, thereby\nensuring accurate extrapolation of LLM downstream performance. The proposed\nmethod has been applied to predict performance scaling for a 70B LLM, providing\nactionable insights for training resource allocation and assisting in\nmonitoring the training process. Notably, COD achieves remarkable predictive\naccuracy on the 70B LLM by leveraging an ensemble of small models,\ndemonstrating an absolute mean deviation of 1.36% across eight important LLM\nevaluation benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17262v1",
    "published_date": "2025-02-24 15:44:57 UTC",
    "updated_date": "2025-02-24 15:44:57 UTC"
  },
  {
    "arxiv_id": "2502.17535v1",
    "title": "The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?",
    "authors": [
      "Zhenheng Tang",
      "Xiang Liu",
      "Qian Wang",
      "Peijie Dong",
      "Bingsheng He",
      "Xiaowen Chu",
      "Bo Li"
    ],
    "abstract": "Motivated by reducing the computational and storage costs of LLMs, model\ncompression and KV cache compression have attracted much attention from\nresearchers. However, current methods predominantly emphasize maintaining the\nperformance of compressed LLMs, as measured by perplexity or simple accuracy on\ntasks of common sense knowledge QA and basic arithmetic reasoning. In this\nblog, we present a brief review of recent advancements in LLMs related to\nretrieval-augmented generation, multi-step reasoning, external tools, and\ncomputational expressivity, all of which substantially enhance LLM performance.\nThen, we propose a lottery LLM hypothesis suggesting that for a given LLM and\ntask, there exists a smaller lottery LLM capable of producing the same\nperformance as the original LLM with the assistance of multi-step reasoning and\nexternal tools. Based on the review of current progress in LLMs, we discuss and\nsummarize the essential capabilities that the lottery LLM and KV cache\ncompression must possess, which are currently overlooked in existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17535v1",
    "published_date": "2025-02-24 15:39:35 UTC",
    "updated_date": "2025-02-24 15:39:35 UTC"
  },
  {
    "arxiv_id": "2502.17259v1",
    "title": "Detecting Benchmark Contamination Through Watermarking",
    "authors": [
      "Tom Sander",
      "Pierre Fernandez",
      "Saeed Mahloujifar",
      "Alain Durmus",
      "Chuan Guo"
    ],
    "abstract": "Benchmark contamination poses a significant challenge to the reliability of\nLarge Language Models (LLMs) evaluations, as it is difficult to assert whether\na model has been trained on a test set. We introduce a solution to this problem\nby watermarking benchmarks before their release. The embedding involves\nreformulating the original questions with a watermarked LLM, in a way that does\nnot alter the benchmark utility. During evaluation, we can detect\n``radioactivity'', \\ie traces that the text watermarks leave in the model\nduring training, using a theoretically grounded statistical test. We test our\nmethod by pre-training 1B models from scratch on 10B tokens with controlled\nbenchmark contamination, and validate its effectiveness in detecting\ncontamination on ARC-Easy, ARC-Challenge, and MMLU. Results show similar\nbenchmark utility post-watermarking and successful contamination detection when\nmodels are contaminated enough to enhance performance, e.g. $p$-val $=10^{-3}$\nfor +5$\\%$ on ARC-Easy.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17259v1",
    "published_date": "2025-02-24 15:39:31 UTC",
    "updated_date": "2025-02-24 15:39:31 UTC"
  },
  {
    "arxiv_id": "2502.17235v1",
    "title": "Tidiness Score-Guided Monte Carlo Tree Search for Visual Tabletop Rearrangement",
    "authors": [
      "Hogun Kee",
      "Wooseok Oh",
      "Minjae Kang",
      "Hyemin Ahn",
      "Songhwai Oh"
    ],
    "abstract": "In this paper, we present the tidiness score-guided Monte Carlo tree search\n(TSMCTS), a novel framework designed to address the tabletop tidying up problem\nusing only an RGB-D camera. We address two major problems for tabletop tidying\nup problem: (1) the lack of public datasets and benchmarks, and (2) the\ndifficulty of specifying the goal configuration of unseen objects. We address\nthe former by presenting the tabletop tidying up (TTU) dataset, a structured\ndataset collected in simulation. Using this dataset, we train a vision-based\ndiscriminator capable of predicting the tidiness score. This discriminator can\nconsistently evaluate the degree of tidiness across unseen configurations,\nincluding real-world scenes. Addressing the second problem, we employ Monte\nCarlo tree search (MCTS) to find tidying trajectories without specifying\nexplicit goals. Instead of providing specific goals, we demonstrate that our\nMCTS-based planner can find diverse tidied configurations using the tidiness\nscore as a guidance. Consequently, we propose TSMCTS, which integrates a\ntidiness discriminator with an MCTS-based tidying planner to find optimal\ntidied arrangements. TSMCTS has successfully demonstrated its capability across\nvarious environments, including coffee tables, dining tables, office desks, and\nbathrooms. The TTU dataset is available at:\nhttps://github.com/rllab-snu/TTU-Dataset.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17235v1",
    "published_date": "2025-02-24 15:12:29 UTC",
    "updated_date": "2025-02-24 15:12:29 UTC"
  },
  {
    "arxiv_id": "2502.17216v2",
    "title": "Intermediate Languages Matter: Formal Choice Drives Neurosymbolic LLM Reasoning",
    "authors": [
      "Alexander Beiser",
      "David Penz",
      "Nysret Musliu"
    ],
    "abstract": "Large language models (LLMs) achieve astonishing results on a wide range of\ntasks. However, their formal reasoning ability still lags behind. A promising\napproach is Neurosymbolic LLM reasoning. It works by using LLMs as translators\nfrom natural to formal languages and symbolic solvers for deriving correct\nresults. Still, it remains unclear what the contributing factors to the success\nof Neurosymbolic LLM reasoning are. This paper shows that one important factor\nis the choice of the formal language. By comparing 4 formal languages on 3\ndatasets over 6 LLMs, we show that the choice of formal language affects both\nthe syntactic and the semantic reasoning capability. Thereby, we introduce the\nintermediate language challenge, which is the challenge of picking a suitable\nformal language for neurosymbolic reasoning. Further, we compare the effects of\nusing different in-context-learning examples in an ablation study. We conclude\nthat on average, context-aware encodings help LLMs to reason, while there is no\napparent effect of using comments or markdown syntax.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17216v2",
    "published_date": "2025-02-24 14:49:52 UTC",
    "updated_date": "2025-05-21 15:51:37 UTC"
  },
  {
    "arxiv_id": "2502.17213v1",
    "title": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics",
    "authors": [
      "Jiahe Li",
      "Xin Chen",
      "Fanqi Shen",
      "Junru Chen",
      "Yuxin Liu",
      "Daoze Zhang",
      "Zhizhang Yuan",
      "Fang Zhao",
      "Meng Li",
      "Yang Yang"
    ],
    "abstract": "Neurological disorders represent significant global health challenges,\ndriving the advancement of brain signal analysis methods. Scalp\nelectroencephalography (EEG) and intracranial electroencephalography (iEEG) are\nwidely used to diagnose and monitor neurological conditions. However, dataset\nheterogeneity and task variations pose challenges in developing robust deep\nlearning solutions. This review systematically examines recent advances in deep\nlearning approaches for EEG/iEEG-based neurological diagnostics, focusing on\napplications across 7 neurological conditions using 46 datasets. We explore\ntrends in data utilization, model design, and task-specific adaptations,\nhighlighting the importance of pre-trained multi-task models for scalable,\ngeneralizable solutions. To advance research, we propose a standardized\nbenchmark for evaluating models across diverse datasets to enhance\nreproducibility. This survey emphasizes how recent innovations can transform\nneurological diagnostics and enable the development of intelligent, adaptable\nhealthcare solutions.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17213v1",
    "published_date": "2025-02-24 14:45:05 UTC",
    "updated_date": "2025-02-24 14:45:05 UTC"
  },
  {
    "arxiv_id": "2502.17533v1",
    "title": "From Euler to AI: Unifying Formulas for Mathematical Constants",
    "authors": [
      "Tomer Raz",
      "Michael Shalyt",
      "Elyasheev Leibtag",
      "Rotem Kalisch",
      "Yaron Hadad",
      "Ido Kaminer"
    ],
    "abstract": "The constant $\\pi$ has fascinated scholars for centuries, inspiring the\nderivation of countless formulas rooted in profound mathematical insight. This\nabundance of formulas raises a question: Are they interconnected, and can a\nunifying structure explain their relationships?\n  We propose a systematic methodology for discovering and proving formula\nequivalences, leveraging modern large language models, large-scale data\nprocessing, and novel mathematical algorithms. Analyzing 457,145 arXiv papers,\nover a third of the validated formulas for $\\pi$ were proven to be derivable\nfrom a single mathematical object - including formulas by Euler, Gauss, Lord\nBrouncker, and newer ones from algorithmic discoveries by the Ramanujan\nMachine.\n  Our approach extends to other constants, such as $e$, $\\zeta(3)$, and\nCatalan's constant, proving its broad applicability. This work represents a\nstep toward the automatic unification of mathematical knowledge, laying a\nfoundation for AI-driven discoveries of connections across scientific domains.",
    "categories": [
      "math.HO",
      "cs.AI",
      "cs.CL",
      "math.NT"
    ],
    "primary_category": "math.HO",
    "comment": "50 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17533v1",
    "published_date": "2025-02-24 14:42:48 UTC",
    "updated_date": "2025-02-24 14:42:48 UTC"
  },
  {
    "arxiv_id": "2502.17204v2",
    "title": "Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following",
    "authors": [
      "Jie Zeng",
      "Qianyu He",
      "Qingyu Ren",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Weikang Zhou",
      "Zeye Sun",
      "Fei Yu"
    ],
    "abstract": "Real-world instructions with multiple constraints pose a significant\nchallenge to existing large language models (LLMs). An observation is that the\nLLMs exhibit dramatic performance fluctuation when disturbing the order of the\nincorporated constraints. Yet, none of the existing works has systematically\ninvestigated this position bias problem in the field of multi-constraint\ninstruction following. To bridge this gap, we design a probing task where we\nquantitatively measure the difficulty distribution of the constraints by a\nnovel Difficulty Distribution Index (CDDI). Through the experimental results,\nwe find that LLMs are more performant when presented with the constraints in a\n``hard-to-easy'' order. This preference can be generalized to LLMs with\ndifferent architecture or different sizes of parameters. Additionally, we\nconduct an explanation study, providing an intuitive insight into the\ncorrelation between the LLM's attention and constraint orders. Our code and\ndataset are publicly available at https://github.com/meowpass/PBIF.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17204v2",
    "published_date": "2025-02-24 14:39:28 UTC",
    "updated_date": "2025-03-03 06:29:31 UTC"
  },
  {
    "arxiv_id": "2502.17196v2",
    "title": "Disentangling Visual Transformers: Patch-level Interpretability for Image Classification",
    "authors": [
      "Guillaume Jeanneret",
      "Loïc Simon",
      "Frédéric Jurie"
    ],
    "abstract": "Visual transformers have achieved remarkable performance in image\nclassification tasks, but this performance gain has come at the cost of\ninterpretability. One of the main obstacles to the interpretation of\ntransformers is the self-attention mechanism, which mixes visual information\nacross the whole image in a complex way. In this paper, we propose Hindered\nTransformer (HiT), a novel interpretable by design architecture inspired by\nvisual transformers. Our proposed architecture rethinks the design of\ntransformers to better disentangle patch influences at the classification\nstage. Ultimately, HiT can be interpreted as a linear combination of\npatch-level information. We show that the advantages of our approach in terms\nof explicability come with a reasonable trade-off in performance, making it an\nattractive alternative for applications where interpretability is paramount.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 official version. Main manuscript + supplementary",
    "pdf_url": "http://arxiv.org/pdf/2502.17196v2",
    "published_date": "2025-02-24 14:30:29 UTC",
    "updated_date": "2025-04-24 12:21:25 UTC"
  },
  {
    "arxiv_id": "2502.17531v1",
    "title": "Laplace-Beltrami Operator for Gaussian Splatting",
    "authors": [
      "Hongyu Zhou",
      "Zorah Lähner"
    ],
    "abstract": "With the rising popularity of 3D Gaussian splatting and the expanse of\napplications from rendering to 3D reconstruction, there comes also a need for\ngeometry processing applications directly on this new representation. While\nconsidering the centers of Gaussians as a point cloud or meshing them is an\noption that allows to apply existing algorithms, this might ignore information\npresent in the data or be unnecessarily expensive. Additionally, Gaussian\nsplatting tends to contain a large number of outliers which do not affect the\nrendering quality but need to be handled correctly in order not to produce\nnoisy results in geometry processing applications. In this work, we propose a\nformulation to compute the Laplace-Beltrami operator, a widely used tool in\ngeometry processing, directly on Gaussian splatting using the Mahalanobis\ndistance. While conceptually similar to a point cloud Laplacian, our\nexperiments show superior accuracy on the point clouds encoded in the Gaussian\nsplatting centers and, additionally, the operator can be used to evaluate the\nquality of the output during optimization.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.17531v1",
    "published_date": "2025-02-24 14:29:33 UTC",
    "updated_date": "2025-02-24 14:29:33 UTC"
  },
  {
    "arxiv_id": "2502.17189v2",
    "title": "IGDA: Interactive Graph Discovery through Large Language Model Agents",
    "authors": [
      "Alex Havrilla",
      "David Alvarez-Melis",
      "Nicolo Fusi"
    ],
    "abstract": "Large language models ($\\textbf{LLMs}$) have emerged as a powerful method for\ndiscovery. Instead of utilizing numerical data, LLMs utilize associated\nvariable $\\textit{semantic metadata}$ to predict variable relationships.\nSimultaneously, LLMs demonstrate impressive abilities to act as black-box\noptimizers when given an objective $f$ and sequence of trials. We study LLMs at\nthe intersection of these two capabilities by applying LLMs to the task of\n$\\textit{interactive graph discovery}$: given a ground truth graph $G^*$\ncapturing variable relationships and a budget of $I$ edge experiments over $R$\nrounds, minimize the distance between the predicted graph $\\hat{G}_R$ and $G^*$\nat the end of the $R$-th round. To solve this task we propose $\\textbf{IGDA}$,\na LLM-based pipeline incorporating two key components: 1) an LLM\nuncertainty-driven method for edge experiment selection 2) a local graph update\nstrategy utilizing binary feedback from experiments to improve predictions for\nunselected neighboring edges. Experiments on eight different real-world graphs\nshow our approach often outperforms all baselines including a state-of-the-art\nnumerical method for interactive graph discovery. Further, we conduct a\nrigorous series of ablations dissecting the impact of each pipeline component.\nFinally, to assess the impact of memorization, we apply our interactive graph\ndiscovery strategy to a complex, new (as of July 2024) causal graph on protein\ntranscription factors, finding strong performance in a setting where\nmemorization is impossible. Overall, our results show IGDA to be a powerful\nmethod for graph discovery complementary to existing numerically driven\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17189v2",
    "published_date": "2025-02-24 14:24:27 UTC",
    "updated_date": "2025-04-13 16:26:06 UTC"
  },
  {
    "arxiv_id": "2502.17187v1",
    "title": "Evaluating Expert Contributions in a MoE LLM for Quiz-Based Tasks",
    "authors": [
      "Andrei Chernov"
    ],
    "abstract": "Recently, Large Language Models (LLMs) with Mixture of Experts (MoE) layers\nhave gained significant attention. Currently, state-of-the-art LLMs utilize\nthis architecture. There is a substantial amount of research on how to train\nsuch models and how to select hyperparameters for this architecture. However,\nthere is a lack of studies focusing on post-evaluation analysis of MoE layer\nproperties. In this paper, we take a first step toward closing this gap by\nevaluating expert contributions on the quiz-based MMLU benchmark. We show that\nmost experts were never activated during inference on this benchmark.\nAdditionally, the output distribution of gating networks is much closer to\nuniform than sparse. Finally, we demonstrate that the average performance of\nsome experts within the same layer varies significantly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint, short paper",
    "pdf_url": "http://arxiv.org/pdf/2502.17187v1",
    "published_date": "2025-02-24 14:23:52 UTC",
    "updated_date": "2025-02-24 14:23:52 UTC"
  },
  {
    "arxiv_id": "2502.17173v2",
    "title": "Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch",
    "authors": [
      "Xueru Wen",
      "Jie Lou",
      "Zichao Li",
      "Yaojie Lu",
      "Xing Yu",
      "Yuqiu Ji",
      "Guohai Xu",
      "Hongyu Lin",
      "Ben He",
      "Xianpei Han",
      "Le Sun",
      "Debing Zhang"
    ],
    "abstract": "Reward models (RMs) are crucial for aligning large language models (LLMs)\nwith human preferences. However, most RM research is centered on English and\nrelies heavily on synthetic resources, which leads to limited and less reliable\ndatasets and benchmarks for Chinese. To address this gap, we introduce\nCheemsBench, a fully human-annotated RM evaluation benchmark within Chinese\ncontexts, and CheemsPreference, a large-scale and diverse preference dataset\nannotated through human-machine collaboration to support Chinese RM training.\nWe systematically evaluate open-source discriminative and generative RMs on\nCheemsBench and observe significant limitations in their ability to capture\nhuman preferences in Chinese scenarios. Additionally, based on\nCheemsPreference, we construct an RM that achieves state-of-the-art performance\non CheemsBench, demonstrating the necessity of human supervision in RM\ntraining. Our findings reveal that scaled AI-generated data struggles to fully\ncapture human preferences, emphasizing the importance of high-quality human\nsupervision in RM development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17173v2",
    "published_date": "2025-02-24 14:09:45 UTC",
    "updated_date": "2025-03-01 17:23:31 UTC"
  },
  {
    "arxiv_id": "2502.17172v1",
    "title": "Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being",
    "authors": [
      "Bin Yin",
      "Chong-Yi Liu",
      "Liya Fu",
      "Jinkun Zhang"
    ],
    "abstract": "Affective computing has made significant strides in emotion recognition and\ngeneration, yet current approaches mainly focus on short-term pattern\nrecognition and lack a comprehensive framework to guide affective agents toward\nlong-term human well-being. To address this, we propose a teleology-driven\naffective computing framework that unifies major emotion theories (basic\nemotion, appraisal, and constructivist approaches) under the premise that\naffect is an adaptive, goal-directed process that facilitates survival and\ndevelopment. Our framework emphasizes aligning agent responses with both\npersonal/individual and group/collective well-being over extended timescales.\nWe advocate for creating a \"dataverse\" of personal affective events, capturing\nthe interplay between beliefs, goals, actions, and outcomes through real-world\nexperience sampling and immersive virtual reality. By leveraging causal\nmodeling, this \"dataverse\" enables AI systems to infer individuals' unique\naffective concerns and provide tailored interventions for sustained well-being.\nAdditionally, we introduce a meta-reinforcement learning paradigm to train\nagents in simulated environments, allowing them to adapt to evolving affective\nconcerns and balance hierarchical goals - from immediate emotional needs to\nlong-term self-actualization. This framework shifts the focus from statistical\ncorrelations to causal reasoning, enhancing agents' ability to predict and\nrespond proactively to emotional challenges, and offers a foundation for\ndeveloping personalized, ethically aligned affective systems that promote\nmeaningful human-AI interactions and societal well-being.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "q-bio.NC",
      "H.1.2, J.4",
      "H.1.2; J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "24 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17172v1",
    "published_date": "2025-02-24 14:07:53 UTC",
    "updated_date": "2025-02-24 14:07:53 UTC"
  },
  {
    "arxiv_id": "2502.17166v1",
    "title": "JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning",
    "authors": [
      "Huanghai Liu",
      "Quzhe Huang",
      "Qingjing Chen",
      "Yiran Hu",
      "Jiayu Ma",
      "Yun Liu",
      "Weixing Shen",
      "Yansong Feng"
    ],
    "abstract": "The Four-Element Theory is a fundamental framework in criminal law, defining\nthe constitution of crime through four dimensions: Subject, Object, Subjective\naspect, and Objective aspect. This theory is widely referenced in legal\nreasoning, and many Large Language Models (LLMs) attempt to incorporate it when\nhandling legal tasks. However, current approaches rely on LLMs' internal\nknowledge to incorporate this theory, often lacking completeness and\nrepresentativeness. To address this limitation, we introduce JUREX-4E, an\nexpert-annotated knowledge base covering 155 criminal charges. It is structured\nthrough a progressive hierarchical annotation framework that prioritizes legal\nsource validity and employs diverse legal interpretation methods to ensure\ncomprehensiveness and authority. We evaluate JUREX-4E on the Similar Charge\nDistinction task and apply it to Legal Case Retrieval, demonstrating its\neffectiveness in improving LLM performance. Experimental results validate the\nhigh quality of JUREX-4E and its substantial impact on downstream legal tasks,\nunderscoring its potential for advancing legal AI applications. Code:\nhttps://github.com/THUlawtech/JUREX",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17166v1",
    "published_date": "2025-02-24 14:02:00 UTC",
    "updated_date": "2025-02-24 14:02:00 UTC"
  },
  {
    "arxiv_id": "2502.17163v3",
    "title": "MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation",
    "authors": [
      "María Andrea Cruz Blandón",
      "Jayasimha Talur",
      "Bruno Charron",
      "Dong Liu",
      "Saab Mansour",
      "Marcello Federico"
    ],
    "abstract": "Automatic evaluation of retrieval augmented generation (RAG) systems relies\non fine-grained dimensions like faithfulness and relevance, as judged by expert\nhuman annotators. Meta-evaluation benchmarks support the development of\nautomatic evaluators that correlate well with human judgement. However,\nexisting benchmarks predominantly focus on English or use translated data,\nwhich fails to capture cultural nuances. A native approach provides a better\nrepresentation of the end user experience.\n  In this work, we develop a Multilingual End-to-end Meta-Evaluation RAG\nbenchmark (MEMERAG). Our benchmark builds on the popular MIRACL dataset, using\nnative-language questions and generating responses with diverse large language\nmodels (LLMs), which are then assessed by expert annotators for faithfulness\nand relevance. We describe our annotation process and show that it achieves\nhigh inter-annotator agreement. We then analyse the performance of the\nanswer-generating LLMs across languages as per the human evaluators. Finally we\napply the dataset to our main use-case which is to benchmark multilingual\nautomatic evaluators (LLM-as-a-judge). We show that our benchmark can reliably\nidentify improvements offered by advanced prompting techniques and LLMs. Our\ndataset is available at https://github.com/amazon-science/MEMERAG",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17163v3",
    "published_date": "2025-02-24 13:58:42 UTC",
    "updated_date": "2025-04-29 07:28:04 UTC"
  },
  {
    "arxiv_id": "2502.17161v1",
    "title": "Real-time Monitoring of Economic Shocks using Company Websites",
    "authors": [
      "Michael Koenig",
      "Jakob Rauch",
      "Martin Woerter"
    ],
    "abstract": "Understanding the effects of economic shocks on firms is critical for\nanalyzing economic growth and resilience. We introduce a Web-Based Affectedness\nIndicator (WAI), a general-purpose tool for real-time monitoring of economic\ndisruptions across diverse contexts. By leveraging Large Language Model (LLM)\nassisted classification and information extraction on texts from over five\nmillion company websites, WAI quantifies the degree and nature of firms'\nresponses to external shocks. Using the COVID-19 pandemic as a specific\napplication, we show that WAI is highly correlated with pandemic containment\nmeasures and reliably predicts firm performance. Unlike traditional data\nsources, WAI provides timely firm-level information across industries and\ngeographies worldwide that would otherwise be unavailable due to institutional\nand data availability constraints. This methodology offers significant\npotential for monitoring and mitigating the impact of technological, political,\nfinancial, health or environmental crises, and represents a transformative tool\nfor adaptive policy-making and economic resilience.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CL",
      "physics.data-an",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17161v1",
    "published_date": "2025-02-24 13:56:27 UTC",
    "updated_date": "2025-02-24 13:56:27 UTC"
  },
  {
    "arxiv_id": "2502.17154v1",
    "title": "MaxGlaViT: A novel lightweight vision transformer-based approach for early diagnosis of glaucoma stages from fundus images",
    "authors": [
      "Mustafa Yurdakul",
      "Kubra Uyar",
      "Sakir Tasdemir"
    ],
    "abstract": "Glaucoma is a prevalent eye disease that progresses silently without\nsymptoms. If not detected and treated early, it can cause permanent vision\nloss. Computer-assisted diagnosis systems play a crucial role in timely and\nefficient identification. This study introduces MaxGlaViT, a lightweight model\nbased on the restructured Multi-Axis Vision Transformer (MaxViT) for early\nglaucoma detection. First, MaxViT was scaled to optimize block and channel\nnumbers, resulting in a lighter architecture. Second, the stem was enhanced by\nadding attention mechanisms (CBAM, ECA, SE) after convolution layers to improve\nfeature learning. Third, MBConv structures in MaxViT blocks were replaced by\nadvanced DL blocks (ConvNeXt, ConvNeXtV2, InceptionNeXt). The model was\nevaluated using the HDV1 dataset, containing fundus images of different\nglaucoma stages. Additionally, 40 CNN and 40 ViT models were tested on HDV1 to\nvalidate MaxGlaViT's efficiency. Among CNN models, EfficientB6 achieved the\nhighest accuracy (84.91%), while among ViT models, MaxViT-Tiny performed best\n(86.42%). The scaled MaxViT reached 87.93% accuracy. Adding ECA to the stem\nblock increased accuracy to 89.01%. Replacing MBConv with ConvNeXtV2 further\nimproved it to 89.87%. Finally, integrating ECA in the stem and ConvNeXtV2 in\nMaxViT blocks resulted in 92.03% accuracy. Testing 80 DL models for glaucoma\nstage classification, this study presents a comprehensive and comparative\nanalysis. MaxGlaViT outperforms experimental and state-of-the-art models,\nachieving 92.03% accuracy, 92.33% precision, 92.03% recall, 92.13% f1-score,\nand 87.12% Cohen's kappa score.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17154v1",
    "published_date": "2025-02-24 13:48:04 UTC",
    "updated_date": "2025-02-24 13:48:04 UTC"
  },
  {
    "arxiv_id": "2502.17139v1",
    "title": "CodeSwift: Accelerating LLM Inference for Efficient Code Generation",
    "authors": [
      "Qianhui Zhao",
      "Li Zhang",
      "Fang Liu",
      "Xiaoli Lian",
      "Qiaoyuanhe Meng",
      "Ziqian Jiao",
      "Zetong Zhou",
      "Borui Zhang",
      "Runlin Guo",
      "Jia Li"
    ],
    "abstract": "Code generation is a latency-sensitive task that demands high timeliness, but\nthe autoregressive decoding mechanism of Large Language Models (LLMs) leads to\npoor inference efficiency. Existing LLM inference acceleration methods mainly\nfocus on standalone functions using only built-in components. Moreover, they\ntreat code like natural language sequences, ignoring its unique syntax and\nsemantic characteristics. As a result, the effectiveness of these approaches in\ncode generation tasks remains limited and fails to align with real-world\nprogramming scenarios. To alleviate this issue, we propose CodeSwift, a simple\nyet highly efficient inference acceleration approach specifically designed for\ncode generation, without comprising the quality of the output. CodeSwift\nconstructs a multi-source datastore, providing access to both general and\nproject-specific knowledge, facilitating the retrieval of high-quality draft\nsequences. Moreover, CodeSwift reduces retrieval cost by controlling retrieval\ntiming, and enhances efficiency through parallel retrieval and a context- and\nLLM preference-aware cache. Experimental results show that CodeSwift can reach\nup to 2.53x and 2.54x speedup compared to autoregressive decoding in\nrepository-level and standalone code generation tasks, respectively,\noutperforming state-of-the-art inference acceleration approaches by up to 88%.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17139v1",
    "published_date": "2025-02-24 13:30:30 UTC",
    "updated_date": "2025-02-24 13:30:30 UTC"
  },
  {
    "arxiv_id": "2502.17136v1",
    "title": "Evaluating the Effectiveness of Large Language Models in Automated News Article Summarization",
    "authors": [
      "Lionel Richy Panlap Houamegni",
      "Fatih Gedikli"
    ],
    "abstract": "The automation of news analysis and summarization presents a promising\nsolution to the challenge of processing and analyzing vast amounts of\ninformation prevalent in today's information society. Large Language Models\n(LLMs) have demonstrated the capability to transform vast amounts of textual\ndata into concise and easily comprehensible summaries, offering an effective\nsolution to the problem of information overload and providing users with a\nquick overview of relevant information. A particularly significant application\nof this technology lies in supply chain risk analysis. Companies must monitor\nthe news about their suppliers and respond to incidents for several critical\nreasons, including compliance with laws and regulations, risk management, and\nmaintaining supply chain resilience. This paper develops an automated news\nsummarization system for supply chain risk analysis using LLMs. The proposed\nsolution aggregates news from various sources, summarizes them using LLMs, and\npresents the condensed information to users in a clear and concise format. This\napproach enables companies to optimize their information processing and make\ninformed decisions. Our study addresses two main research questions: (1) Are\nLLMs effective in automating news summarization, particularly in the context of\nsupply chain risk analysis? (2) How effective are various LLMs in terms of\nreadability, duplicate detection, and risk identification in their\nsummarization quality? In this paper, we conducted an offline study using a\nrange of publicly available LLMs at the time and complemented it with a user\nstudy focused on the top performing systems of the offline experiments to\nevaluate their effectiveness further. Our results demonstrate that LLMs,\nparticularly Few-Shot GPT-4o mini, offer significant improvements in summary\nquality and risk identification.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "I.2.7; H.3.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17136v1",
    "published_date": "2025-02-24 13:27:46 UTC",
    "updated_date": "2025-02-24 13:27:46 UTC"
  },
  {
    "arxiv_id": "2502.17132v1",
    "title": "Applications of Large Models in Medicine",
    "authors": [
      "YunHe Su",
      "Zhengyang Lu",
      "Junhui Liu",
      "Ke Pang",
      "Haoran Dai",
      "Sa Liu Yuxin Jia",
      "Lujia Ge",
      "Jing-min Yang"
    ],
    "abstract": "This paper explores the advancements and applications of large-scale models\nin the medical field, with a particular focus on Medical Large Models (MedLMs).\nThese models, encompassing Large Language Models (LLMs), Vision Models, 3D\nLarge Models, and Multimodal Models, are revolutionizing healthcare by\nenhancing disease prediction, diagnostic assistance, personalized treatment\nplanning, and drug discovery. The integration of graph neural networks in\nmedical knowledge graphs and drug discovery highlights the potential of Large\nGraph Models (LGMs) in understanding complex biomedical relationships. The\nstudy also emphasizes the transformative role of Vision-Language Models (VLMs)\nand 3D Large Models in medical image analysis, anatomical modeling, and\nprosthetic design. Despite the challenges, these technologies are setting new\nbenchmarks in medical innovation, improving diagnostic accuracy, and paving the\nway for personalized healthcare solutions. This paper aims to provide a\ncomprehensive overview of the current state and future directions of large\nmodels in medicine, underscoring their significance in advancing global health.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17132v1",
    "published_date": "2025-02-24 13:21:30 UTC",
    "updated_date": "2025-02-24 13:21:30 UTC"
  },
  {
    "arxiv_id": "2502.17130v1",
    "title": "Low-distortion and GPU-compatible Tree Embeddings in Hyperbolic Space",
    "authors": [
      "Max van Spengler",
      "Pascal Mettes"
    ],
    "abstract": "Embedding tree-like data, from hierarchies to ontologies and taxonomies,\nforms a well-studied problem for representing knowledge across many domains.\nHyperbolic geometry provides a natural solution for embedding trees, with\nvastly superior performance over Euclidean embeddings. Recent literature has\nshown that hyperbolic tree embeddings can even be placed on top of neural\nnetworks for hierarchical knowledge integration in deep learning settings. For\nall applications, a faithful embedding of trees is needed, with combinatorial\nconstructions emerging as the most effective direction. This paper identifies\nand solves two key limitations of existing works. First, the combinatorial\nconstruction hinges on finding highly separated points on a hypersphere, a\nnotoriously difficult problem. Current approaches achieve poor separation,\ndegrading the quality of the corresponding hyperbolic embedding. We propose\nhighly separated Delaunay tree embeddings (HS-DTE), which integrates angular\nseparation in a generalized formulation of Delaunay embeddings, leading to\nlower embedding distortion. Second, low-distortion requires additional\nprecision. The current approach for increasing precision is to use multiple\nprecision arithmetic, which renders the embeddings useless on GPUs in deep\nlearning settings. We reformulate the combinatorial construction using floating\npoint expansion arithmetic, leading to superior embedding quality while\nretaining utility on accelerated hardware.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17130v1",
    "published_date": "2025-02-24 13:19:59 UTC",
    "updated_date": "2025-02-24 13:19:59 UTC"
  },
  {
    "arxiv_id": "2502.17125v1",
    "title": "LettuceDetect: A Hallucination Detection Framework for RAG Applications",
    "authors": [
      "Ádám Kovács",
      "Gábor Recski"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) systems remain vulnerable to\nhallucinated answers despite incorporating external knowledge sources. We\npresent LettuceDetect a framework that addresses two critical limitations in\nexisting hallucination detection methods: (1) the context window constraints of\ntraditional encoder-based methods, and (2) the computational inefficiency of\nLLM based approaches. Building on ModernBERT's extended context capabilities\n(up to 8k tokens) and trained on the RAGTruth benchmark dataset, our approach\noutperforms all previous encoder-based models and most prompt-based models,\nwhile being approximately 30 times smaller than the best models. LettuceDetect\nis a token-classification model that processes context-question-answer triples,\nallowing for the identification of unsupported claims at the token level.\nEvaluations on the RAGTruth corpus demonstrate an F1 score of 79.22% for\nexample-level detection, which is a 14.8% improvement over Luna, the previous\nstate-of-the-art encoder-based architecture. Additionally, the system can\nprocess 30 to 60 examples per second on a single GPU, making it more practical\nfor real-world RAG applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.17125v1",
    "published_date": "2025-02-24 13:11:47 UTC",
    "updated_date": "2025-02-24 13:11:47 UTC"
  },
  {
    "arxiv_id": "2502.17121v1",
    "title": "Adversarial Training for Defense Against Label Poisoning Attacks",
    "authors": [
      "Melis Ilayda Bal",
      "Volkan Cevher",
      "Michael Muehlebach"
    ],
    "abstract": "As machine learning models grow in complexity and increasingly rely on\npublicly sourced data, such as the human-annotated labels used in training\nlarge language models, they become more vulnerable to label poisoning attacks.\nThese attacks, in which adversaries subtly alter the labels within a training\ndataset, can severely degrade model performance, posing significant risks in\ncritical applications. In this paper, we propose FLORAL, a novel adversarial\ntraining defense strategy based on support vector machines (SVMs) to counter\nthese threats. Utilizing a bilevel optimization framework, we cast the training\nprocess as a non-zero-sum Stackelberg game between an attacker, who\nstrategically poisons critical training labels, and the model, which seeks to\nrecover from such attacks. Our approach accommodates various model\narchitectures and employs a projected gradient descent algorithm with kernel\nSVMs for adversarial training. We provide a theoretical analysis of our\nalgorithm's convergence properties and empirically evaluate FLORAL's\neffectiveness across diverse classification tasks. Compared to robust baselines\nand foundation models such as RoBERTa, FLORAL consistently achieves higher\nrobust accuracy under increasing attacker budgets. These results underscore the\npotential of FLORAL to enhance the resilience of machine learning models\nagainst label poisoning threats, thereby ensuring robust classification in\nadversarial settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.17121v1",
    "published_date": "2025-02-24 13:03:19 UTC",
    "updated_date": "2025-02-24 13:03:19 UTC"
  },
  {
    "arxiv_id": "2502.17119v1",
    "title": "Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions",
    "authors": [
      "Zhong Li",
      "Qi Huang",
      "Lincen Yang",
      "Jiayang Shi",
      "Zhao Yang",
      "Niki van Stein",
      "Thomas Bäck",
      "Matthijs van Leeuwen"
    ],
    "abstract": "In recent years, generative models have achieved remarkable performance\nacross diverse applications, including image generation, text synthesis, audio\ncreation, video generation, and data augmentation. Diffusion models have\nemerged as superior alternatives to Generative Adversarial Networks (GANs) and\nVariational Autoencoders (VAEs) by addressing their limitations, such as\ntraining instability, mode collapse, and poor representation of multimodal\ndistributions. This success has spurred widespread research interest. In the\ndomain of tabular data, diffusion models have begun to showcase similar\nadvantages over GANs and VAEs, achieving significant performance breakthroughs\nand demonstrating their potential for addressing unique challenges in tabular\ndata modeling. However, while domains like images and time series have numerous\nsurveys summarizing advancements in diffusion models, there remains a notable\ngap in the literature for tabular data. Despite the increasing interest in\ndiffusion models for tabular data, there has been little effort to\nsystematically review and summarize these developments. This lack of a\ndedicated survey limits a clear understanding of the challenges, progress, and\nfuture directions in this critical area. This survey addresses this gap by\nproviding a comprehensive review of diffusion models for tabular data. Covering\nworks from June 2015, when diffusion models emerged, to December 2024, we\nanalyze nearly all relevant studies, with updates maintained in a\n\\href{https://github.com/Diffusion-Model-Leiden/awesome-diffusion-models-for-tabular-data}{GitHub\nrepository}. Assuming readers possess foundational knowledge of statistics and\ndiffusion models, we employ mathematical formulations to deliver a rigorous and\ndetailed review, aiming to promote developments in this emerging and exciting\narea.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17119v1",
    "published_date": "2025-02-24 13:01:33 UTC",
    "updated_date": "2025-02-24 13:01:33 UTC"
  },
  {
    "arxiv_id": "2502.17109v2",
    "title": "Strength Estimation and Human-Like Strength Adjustment in Games",
    "authors": [
      "Chun Jung Chen",
      "Chung-Chin Shih",
      "Ti-Rong Wu"
    ],
    "abstract": "Strength estimation and adjustment are crucial in designing human-AI\ninteractions, particularly in games where AI surpasses human players. This\npaper introduces a novel strength system, including a strength estimator (SE)\nand an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts\nstrengths from games and offers different playing strengths with human styles.\nThe strength estimator calculates strength scores and predicts ranks from games\nwithout direct human interaction. SE-MCTS utilizes the strength scores in a\nMonte Carlo tree search to adjust playing strength and style. We first conduct\nexperiments in Go, a challenging board game with a wide range of ranks. Our\nstrength estimator significantly achieves over 80% accuracy in predicting ranks\nby observing 15 games only, whereas the previous method reached 49% accuracy\nfor 100 games. For strength adjustment, SE-MCTS successfully adjusts to\ndesignated ranks while achieving a 51.33% accuracy in aligning to human\nactions, outperforming a previous state-of-the-art, with only 42.56% accuracy.\nTo demonstrate the generality of our strength system, we further apply SE and\nSE-MCTS to chess and obtain consistent results. These results show a promising\napproach to strength estimation and adjustment, enhancing human-AI interactions\nin games. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/strength-estimator.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.17109v2",
    "published_date": "2025-02-24 12:47:47 UTC",
    "updated_date": "2025-03-21 09:57:03 UTC"
  },
  {
    "arxiv_id": "2502.17105v1",
    "title": "SFLD: Reducing the content bias for AI-generated Image Detection",
    "authors": [
      "Seoyeon Gye",
      "Junwon Ko",
      "Hyounguk Shon",
      "Minchan Kwon",
      "Junmo Kim"
    ],
    "abstract": "Identifying AI-generated content is critical for the safe and ethical use of\ngenerative AI. Recent research has focused on developing detectors that\ngeneralize to unknown generators, with popular methods relying either on\nhigh-level features or low-level fingerprints. However, these methods have\nclear limitations: biased towards unseen content, or vulnerable to common image\ndegradations, such as JPEG compression. To address these issues, we propose a\nnovel approach, SFLD, which incorporates PatchShuffle to integrate high-level\nsemantic and low-level textural information. SFLD applies PatchShuffle at\nmultiple levels, improving robustness and generalization across various\ngenerative models. Additionally, current benchmarks face challenges such as low\nimage quality, insufficient content preservation, and limited class diversity.\nIn response, we introduce TwinSynths, a new benchmark generation methodology\nthat constructs visually near-identical pairs of real and synthetic images to\nensure high quality and content preservation. Our extensive experiments and\nanalysis show that SFLD outperforms existing methods on detecting a wide\nvariety of fake images sourced from GANs, diffusion models, and TwinSynths,\ndemonstrating the state-of-the-art performance and generalization capabilities\nto novel generative models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE/CVF WACV 2025, Oral",
    "pdf_url": "http://arxiv.org/pdf/2502.17105v1",
    "published_date": "2025-02-24 12:38:34 UTC",
    "updated_date": "2025-02-24 12:38:34 UTC"
  },
  {
    "arxiv_id": "2502.17100v3",
    "title": "Generative Models in Decision Making: A Survey",
    "authors": [
      "Yinchuan Li",
      "Xinyu Shao",
      "Jianping Zhang",
      "Haozhi Wang",
      "Leo Maxime Brunswic",
      "Kaiwen Zhou",
      "Jiqian Dong",
      "Kaiyang Guo",
      "Xiu Li",
      "Zhitang Chen",
      "Jun Wang",
      "Jianye Hao"
    ],
    "abstract": "In recent years, the exceptional performance of generative models in\ngenerative tasks has sparked significant interest in their integration into\ndecision-making processes. Due to their ability to handle complex data\ndistributions and their strong model capacity, generative models can be\neffectively incorporated into decision-making systems by generating\ntrajectories that guide agents toward high-reward state-action regions or\nintermediate sub-goals. This paper presents a comprehensive review of the\napplication of generative models in decision-making tasks. We classify seven\nfundamental types of generative models: energy-based models, generative\nadversarial networks, variational autoencoders, normalizing flows, diffusion\nmodels, generative flow networks, and autoregressive models. Regarding their\napplications, we categorize their functions into three main roles: controllers,\nmodelers and optimizers, and discuss how each role contributes to\ndecision-making. Furthermore, we examine the deployment of these models across\nfive critical real-world decision-making scenarios. Finally, we summarize the\nstrengths and limitations of current approaches and propose three key\ndirections for advancing next-generation generative directive models:\nhigh-performance algorithms, large-scale generalized decision-making models,\nand self-evolving and adaptive models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Project\n  page:https://github.com/xyshao23/Awesome-Generative-Models-for-Decision-Making-Taxonomy",
    "pdf_url": "http://arxiv.org/pdf/2502.17100v3",
    "published_date": "2025-02-24 12:31:28 UTC",
    "updated_date": "2025-03-12 02:32:00 UTC"
  },
  {
    "arxiv_id": "2502.17099v1",
    "title": "Improved Diffusion-based Generative Model with Better Adversarial Robustness",
    "authors": [
      "Zekun Wang",
      "Mingyang Yi",
      "Shuchen Xue",
      "Zhenguo Li",
      "Ming Liu",
      "Bing Qin",
      "Zhi-Ming Ma"
    ],
    "abstract": "Diffusion Probabilistic Models (DPMs) have achieved significant success in\ngenerative tasks. However, their training and sampling processes suffer from\nthe issue of distribution mismatch. During the denoising process, the input\ndata distributions differ between the training and inference stages,\npotentially leading to inaccurate data generation. To obviate this, we analyze\nthe training objective of DPMs and theoretically demonstrate that this mismatch\ncan be alleviated through Distributionally Robust Optimization (DRO), which is\nequivalent to performing robustness-driven Adversarial Training (AT) on DPMs.\nFurthermore, for the recently proposed Consistency Model (CM), which distills\nthe inference process of the DPM, we prove that its training objective also\nencounters the mismatch issue. Fortunately, this issue can be mitigated by AT\nas well. Based on these insights, we propose to conduct efficient AT on both\nDPM and CM. Finally, extensive empirical studies validate the effectiveness of\nAT in diffusion-based models. The code is available at\nhttps://github.com/kugwzk/AT_Diff.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.17099v1",
    "published_date": "2025-02-24 12:29:16 UTC",
    "updated_date": "2025-02-24 12:29:16 UTC"
  },
  {
    "arxiv_id": "2502.17091v1",
    "title": "WildFrame: Comparing Framing in Humans and LLMs on Naturally Occurring Texts",
    "authors": [
      "Gili Lior",
      "Liron Nacchace",
      "Gabriel Stanovsky"
    ],
    "abstract": "Humans are influenced by how information is presented, a phenomenon known as\nthe framing effect. Previous work has shown that LLMs may also be susceptible\nto framing but has done so on synthetic data and did not compare to human\nbehavior. We introduce WildFrame, a dataset for evaluating LLM responses to\npositive and negative framing, in naturally-occurring sentences, and compare\nhumans on the same data. WildFrame consists of 1,000 texts, first selecting\nreal-world statements with clear sentiment, then reframing them in either\npositive or negative light, and lastly, collecting human sentiment annotations.\nBy evaluating eight state-of-the-art LLMs on WildFrame, we find that all models\nexhibit framing effects similar to humans ($r\\geq0.57$), with both humans and\nmodels being more influenced by positive rather than negative reframing. Our\nfindings benefit model developers, who can either harness framing or mitigate\nits effects, depending on the downstream application.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17091v1",
    "published_date": "2025-02-24 12:14:05 UTC",
    "updated_date": "2025-02-24 12:14:05 UTC"
  },
  {
    "arxiv_id": "2503.00025v2",
    "title": "Evaluating Large Language Models on the Spanish Medical Intern Resident (MIR) Examination 2024/2025:A Comparative Analysis of Clinical Reasoning and Knowledge Application",
    "authors": [
      "Carlos Luengo Vera",
      "Ignacio Ferro Picon",
      "M. Teresa del Val Nunez",
      "Jose Andres Gomez Gandia",
      "Antonio de Lucas Ancillo",
      "Victor Ramos Arroyo",
      "Carlos Milan Figueredo"
    ],
    "abstract": "This study presents a comparative evaluation of 22 large language models LLMs\non the Spanish Medical Intern Resident MIR examinations for 2024 and 2025 with\na focus on clinical reasoning domain specific expertise and multimodal\nprocessing capabilities The MIR exam consisting of 210 multiple choice\nquestions some requiring image interpretation serves as a stringent benchmark\nfor assessing both factual recall and complex clinical problem solving skills\nOur investigation encompasses general purpose models such as GPT4 Claude LLaMA\nand Gemini as well as specialized fine tuned systems like Miri Pro which\nleverages proprietary Spanish healthcare data to excel in medical contexts\n  Recent market entries Deepseek and Grok have further enriched the evaluation\nlandscape particularly for tasks that demand advanced visual and semantic\nanalysis The findings indicate that while general purpose LLMs perform robustly\noverall fine tuned models consistently achieve superior accuracy especially in\naddressing nuanced domain specific challenges A modest performance decline\nobserved between the two exam cycles appears attributable to the implementation\nof modified questions designed to mitigate reliance on memorization\n  The results underscore the transformative potential of domain specific fine\ntuning and multimodal integration in advancing medical AI applications They\nalso highlight critical implications for the future integration of LLMs into\nmedical education training and clinical decision making emphasizing the\nimportance of balancing automated reasoning with ethical and context aware\njudgment",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 1 table, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00025v2",
    "published_date": "2025-02-24 12:08:26 UTC",
    "updated_date": "2025-03-16 21:05:53 UTC"
  },
  {
    "arxiv_id": "2502.17087v1",
    "title": "Conditional Diffusion-Flow models for generating 3D cosmic density fields: applications to f(R) cosmologies",
    "authors": [
      "Julieth Katherine Riveros",
      "Paola Saavedra",
      "Hector J. Hortua",
      "Jorge Enrique Garcia-Farieta",
      "Ivan Olier"
    ],
    "abstract": "Next-generation galaxy surveys promise unprecedented precision in testing\ngravity at cosmological scales. However, realising this potential requires\naccurately modelling the non-linear cosmic web. We address this challenge by\nexploring conditional generative modelling to create 3D dark matter density\nfields via score-based (diffusion) and flow-based methods. Our results\ndemonstrate the power of diffusion models to accurately reproduce the matter\npower spectra and bispectra, even for unseen configurations. They also offer a\nsignificant speed-up with slightly reduced accuracy, when flow-based\nreconstructing the probability distribution function, but they struggle with\nhigher-order statistics. To improve conditional generation, we introduce a\nnovel multi-output model to develop feature representations of the cosmological\nparameters. Our findings offer a powerful tool for exploring deviations from\nstandard gravity, combining high precision with reduced computational cost,\nthus paving the way for more comprehensive and efficient cosmological analyses",
    "categories": [
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.CO",
    "comment": "13 pages comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2502.17087v1",
    "published_date": "2025-02-24 12:06:23 UTC",
    "updated_date": "2025-02-24 12:06:23 UTC"
  },
  {
    "arxiv_id": "2502.17081v1",
    "title": "Forgetting Any Data at Any Time: A Theoretically Certified Unlearning Framework for Vertical Federated Learning",
    "authors": [
      "Linian Wang",
      "Leye Wang"
    ],
    "abstract": "Privacy concerns in machine learning are heightened by regulations such as\nthe GDPR, which enforces the \"right to be forgotten\" (RTBF), driving the\nemergence of machine unlearning as a critical research field. Vertical\nFederated Learning (VFL) enables collaborative model training by aggregating a\nsample's features across distributed parties while preserving data privacy at\neach source. This paradigm has seen widespread adoption in healthcare, finance,\nand other privacy-sensitive domains. However, existing VFL systems lack robust\nmechanisms to comply with RTBF requirements, as unlearning methodologies for\nVFL remain underexplored. In this work, we introduce the first VFL framework\nwith theoretically guaranteed unlearning capabilities, enabling the removal of\nany data at any time. Unlike prior approaches -- which impose restrictive\nassumptions on model architectures or data types for removal -- our solution is\nmodel- and data-agnostic, offering universal compatibility. Moreover, our\nframework supports asynchronous unlearning, eliminating the need for all\nparties to be simultaneously online during the forgetting process. These\nadvancements address critical gaps in current VFL systems, ensuring compliance\nwith RTBF while maintaining operational flexibility.We make all our\nimplementations publicly available at\nhttps://github.com/wangln19/vertical-federated-unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.17081v1",
    "published_date": "2025-02-24 11:52:35 UTC",
    "updated_date": "2025-02-24 11:52:35 UTC"
  },
  {
    "arxiv_id": "2502.17071v1",
    "title": "Systematic Weight Evaluation for Pruning Large Language Models: Enhancing Performance and Sustainability",
    "authors": [
      "Ashhadul Islam",
      "Samir Brahim Belhaouari",
      "Amine Bermak"
    ],
    "abstract": "The exponential growth of large language models (LLMs) like ChatGPT has\nrevolutionized artificial intelligence, offering unprecedented capabilities in\nnatural language processing. However, the extensive computational resources\nrequired for training these models have significant environmental implications,\nincluding high carbon emissions, energy consumption, and water usage. This\nresearch presents a novel approach to LLM pruning, focusing on the systematic\nevaluation of individual weight importance throughout the training process. By\nmonitoring parameter evolution over time, we propose a method that effectively\nreduces model size without compromising performance. Extensive experiments with\nboth a scaled-down LLM and a large multimodal model reveal that moderate\npruning enhances efficiency and reduces loss, while excessive pruning\ndrastically deteriorates model performance. These findings highlight the\ncritical need for optimized AI models to ensure sustainable development,\nbalancing technological advancement with environmental responsibility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17071v1",
    "published_date": "2025-02-24 11:34:49 UTC",
    "updated_date": "2025-02-24 11:34:49 UTC"
  },
  {
    "arxiv_id": "2502.17057v2",
    "title": "LLM-QE: Improving Query Expansion by Aligning Large Language Models with Ranking Preferences",
    "authors": [
      "Sijia Yao",
      "Pengcheng Huang",
      "Zhenghao Liu",
      "Yu Gu",
      "Yukun Yan",
      "Shi Yu",
      "Ge Yu"
    ],
    "abstract": "Query expansion plays a crucial role in information retrieval, which aims to\nbridge the semantic gap between queries and documents to improve matching\nperformance. This paper introduces LLM-QE, a novel approach that leverages\nLarge Language Models (LLMs) to generate document-based query expansions,\nthereby enhancing dense retrieval models. Unlike traditional methods, LLM-QE\ndesigns both rank-based and answer-based rewards and uses these reward models\nto optimize LLMs to align with the ranking preferences of both retrievers and\nLLMs, thus mitigating the hallucination of LLMs during query expansion. Our\nexperiments on the zero-shot dense retrieval model, Contriever, demonstrate the\neffectiveness of LLM-QE, achieving an improvement of over 8%. Furthermore, by\nincorporating answer-based reward modeling, LLM-QE generates more relevant and\nprecise information related to the documents, rather than simply producing\nredundant tokens to maximize rank-based rewards. Notably, LLM-QE also improves\nthe training process of dense retrievers, achieving a more than 5% improvement\nafter fine-tuning. All codes are available at https://github.com/NEUIR/LLM-QE.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages, 5 tables, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17057v2",
    "published_date": "2025-02-24 11:15:41 UTC",
    "updated_date": "2025-02-27 06:00:36 UTC"
  },
  {
    "arxiv_id": "2502.17055v2",
    "title": "Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam",
    "authors": [
      "Tianjin Huang",
      "Haotian Hu",
      "Zhenyu Zhang",
      "Gaojie Jin",
      "Xiang Li",
      "Li Shen",
      "Tianlong Chen",
      "Lu Liu",
      "Qingsong Wen",
      "Zhangyang Wang",
      "Shiwei Liu"
    ],
    "abstract": "This paper comprehensively evaluates several recently proposed optimizers for\n4-bit training, revealing that low-bit precision amplifies sensitivity to\nlearning rates and often causes unstable gradient norms, leading to divergence\nat higher learning rates. Among these, SPAM, a recent optimizer featuring\nmomentum reset and spike-aware gradient clipping, achieves the best performance\nacross various bit levels, but struggles to stabilize gradient norms, requiring\ncareful learning rate tuning. To address these limitations, we propose\nStable-SPAM, which incorporates enhanced gradient normalization and clipping\ntechniques. In particular, Stable-SPAM (1) adaptively updates the clipping\nthreshold for spiked gradients by tracking their historical maxima; (2)\nnormalizes the entire gradient matrix based on its historical $l_2$-norm\nstatistics; and $(3)$ inherits momentum reset from SPAM to periodically reset\nthe first and second moments of Adam, mitigating the accumulation of spiked\ngradients. Extensive experiments show that Stable-SPAM effectively stabilizes\ngradient norms in 4-bit LLM training, delivering superior performance compared\nto Adam and SPAM. Notably, our 4-bit LLaMA-1B model trained with Stable-SPAM\noutperforms the BF16 LLaMA-1B trained with Adam by up to $2$ perplexity.\nFurthermore, when both models are trained in 4-bit, Stable-SPAM achieves the\nsame loss as Adam while requiring only about half the training steps. Code is\navailable at https://github.com/TianjinYellow/StableSPAM.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17055v2",
    "published_date": "2025-02-24 11:09:15 UTC",
    "updated_date": "2025-04-11 19:48:37 UTC"
  },
  {
    "arxiv_id": "2502.17049v2",
    "title": "TabulaTime: A Novel Multimodal Deep Learning Framework for Advancing Acute Coronary Syndrome Prediction through Environmental and Clinical Data Integration",
    "authors": [
      "Xin Zhang",
      "Liangxiu Han",
      "Stephen White",
      "Saad Hassan",
      "Philip A Kalra",
      "James Ritchie",
      "Carl Diver",
      "Jennie Shorley"
    ],
    "abstract": "Acute Coronary Syndromes (ACS), including ST-segment elevation myocardial\ninfarctions (STEMI) and non-ST-segment elevation myocardial infarctions\n(NSTEMI), remain a leading cause of mortality worldwide. Traditional\ncardiovascular risk scores rely primarily on clinical data, often overlooking\nenvironmental influences like air pollution that significantly impact heart\nhealth. Moreover, integrating complex time-series environmental data with\nclinical records is challenging.\n  We introduce TabulaTime, a multimodal deep learning framework that enhances\nACS risk prediction by combining clinical risk factors with air pollution data.\nTabulaTime features three key innovations: First, it integrates time-series air\npollution data with clinical tabular data to improve prediction accuracy.\nSecond, its PatchRWKV module automatically extracts complex temporal patterns,\novercoming limitations of traditional feature engineering while maintaining\nlinear computational complexity. Third, attention mechanisms enhance\ninterpretability by revealing interactions between clinical and environmental\nfactors.\n  Experimental results show that TabulaTime improves prediction accuracy by\nover 20% compared to conventional models such as CatBoost, Random Forest, and\nLightGBM, with air pollution data alone contributing over a 10% improvement.\nFeature importance analysis identifies critical predictors including previous\nangina, systolic blood pressure, PM10, and NO2. Overall, TabulaTime bridges\nclinical and environmental insights, supporting personalized prevention\nstrategies and informing public health policies to mitigate ACS risk.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17049v2",
    "published_date": "2025-02-24 11:01:07 UTC",
    "updated_date": "2025-04-26 09:00:11 UTC"
  },
  {
    "arxiv_id": "2502.17036v1",
    "title": "Language Model Re-rankers are Steered by Lexical Similarities",
    "authors": [
      "Lovisa Hagström",
      "Ercong Nie",
      "Ruben Halifa",
      "Helmut Schmid",
      "Richard Johansson",
      "Alexander Junge"
    ],
    "abstract": "Language model (LM) re-rankers are used to refine retrieval results for\nretrieval-augmented generation (RAG). They are more expensive than lexical\nmatching methods like BM25 but assumed to better process semantic information.\nTo understand whether LM re-rankers always live up to this assumption, we\nevaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our\nresults show that LM re-rankers struggle to outperform a simple BM25 re-ranker\non DRUID. Leveraging a novel separation metric based on BM25 scores, we explain\nand identify re-ranker errors stemming from lexical dissimilarities. We also\ninvestigate different methods to improve LM re-ranker performance and find\nthese methods mainly useful for NQ. Taken together, our work identifies and\nexplains weaknesses of LM re-rankers and points to the need for more\nadversarial and realistic datasets for their evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.17036v1",
    "published_date": "2025-02-24 10:37:13 UTC",
    "updated_date": "2025-02-24 10:37:13 UTC"
  },
  {
    "arxiv_id": "2502.17028v2",
    "title": "Distributional Vision-Language Alignment by Cauchy-Schwarz Divergence",
    "authors": [
      "Wenzhe Yin",
      "Zehao Xiao",
      "Pan Zhou",
      "Shujian Yu",
      "Jiayi Shen",
      "Jan-Jakob Sonke",
      "Efstratios Gavves"
    ],
    "abstract": "Multimodal alignment is crucial for various downstream tasks such as\ncross-modal generation and retrieval. Previous multimodal approaches like CLIP\nutilize InfoNCE to maximize mutual information, primarily aligning pairwise\nsamples across modalities while overlooking distributional differences. In\naddition, InfoNCE has inherent conflict in terms of alignment and uniformity in\nmultimodality, leading to suboptimal alignment with modality gaps. To overcome\nthe limitations, we propose CS-Aligner, a novel framework that performs\ndistributional vision-language alignment by integrating Cauchy-Schwarz (CS)\ndivergence with mutual information. CS-Aligner captures both the global\ndistribution information of each modality and the pairwise semantic\nrelationships. We find that the CS divergence seamlessly addresses the\nInfoNCE's alignment-uniformity conflict and serves complementary roles with\nInfoNCE, yielding tighter and more precise alignment. Moreover, by introducing\ndistributional alignment, CS-Aligner enables incorporating additional\ninformation from unpaired data and token-level representations, enhancing\nflexible and fine-grained alignment in practice. Experiments on text-to-image\ngeneration and cross-modality retrieval tasks demonstrate the effectiveness of\nour method on vision-language alignment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17028v2",
    "published_date": "2025-02-24 10:29:15 UTC",
    "updated_date": "2025-05-20 18:10:23 UTC"
  },
  {
    "arxiv_id": "2502.17026v1",
    "title": "Understanding the Uncertainty of LLM Explanations: A Perspective Based on Reasoning Topology",
    "authors": [
      "Longchao Da",
      "Xiaoou Liu",
      "Jiaxin Dai",
      "Lu Cheng",
      "Yaqing Wang",
      "Hua Wei"
    ],
    "abstract": "Understanding the uncertainty in large language model (LLM) explanations is\nimportant for evaluating their faithfulness and reasoning consistency, and thus\nprovides insights into the reliability of LLM's output regarding a question. In\nthis work, we propose a novel framework that quantifies uncertainty in LLM\nexplanations through a reasoning topology perspective. By designing a\nstructural elicitation strategy, we guide the LLMs to frame the explanations of\nan answer into a graph topology. This process decomposes the explanations into\nthe knowledge related sub-questions and topology-based reasoning structures,\nwhich allows us to quantify uncertainty not only at the semantic level but also\nfrom the reasoning path. It further brings convenience to assess knowledge\nredundancy and provide interpretable insights into the reasoning process. Our\nmethod offers a systematic way to interpret the LLM reasoning, analyze\nlimitations, and provide guidance for enhancing robustness and faithfulness.\nThis work pioneers the use of graph-structured uncertainty measurement in LLM\nexplanations and demonstrates the potential of topology-based quantification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SC",
      "68T50, 68T37, 68Q32",
      "I.2.7; I.2.6; I.2.4"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17026v1",
    "published_date": "2025-02-24 10:28:21 UTC",
    "updated_date": "2025-02-24 10:28:21 UTC"
  },
  {
    "arxiv_id": "2502.17022v2",
    "title": "Class-Dependent Perturbation Effects in Evaluating Time Series Attributions",
    "authors": [
      "Gregor Baer",
      "Isel Grau",
      "Chao Zhang",
      "Pieter Van Gorp"
    ],
    "abstract": "As machine learning models become increasingly prevalent in time series\napplications, Explainable Artificial Intelligence (XAI) methods are essential\nfor understanding their predictions. Within XAI, feature attribution methods\naim to identify which input features contribute the most to a model's\nprediction, with their evaluation typically relying on perturbation-based\nmetrics. Through systematic empirical analysis across multiple datasets, model\narchitectures, and perturbation strategies, we reveal previously overlooked\nclass-dependent effects in these metrics: they show varying effectiveness\nacross classes, achieving strong results for some while remaining less\nsensitive to others. In particular, we find that the most effective\nperturbation strategies often demonstrate the most pronounced class\ndifferences. Our analysis suggests that these effects arise from the learned\nbiases of classifiers, indicating that perturbation-based evaluation may\nreflect specific model behaviors rather than intrinsic attribution quality. We\npropose an evaluation framework with a class-aware penalty term to help assess\nand account for these effects in evaluating feature attributions, offering\nparticular value for class-imbalanced datasets. Although our analysis focuses\non time series classification, these class-dependent effects likely extend to\nother structured data domains where perturbation-based evaluation is common.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at The World Conference on eXplainable Artificial\n  Intelligence (XAI-2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.17022v2",
    "published_date": "2025-02-24 10:22:03 UTC",
    "updated_date": "2025-04-01 13:19:41 UTC"
  },
  {
    "arxiv_id": "2502.17020v1",
    "title": "Moving Past Single Metrics: Exploring Short-Text Clustering Across Multiple Resolutions",
    "authors": [
      "Justin Miller",
      "Tristram Alexander"
    ],
    "abstract": "Cluster number is typically a parameter selected at the outset in clustering\nproblems, and while impactful, the choice can often be difficult to justify.\nInspired by bioinformatics, this study examines how the nature of clusters\nvaries with cluster number, presenting a method for determining cluster\nrobustness, and providing a systematic method for deciding on the cluster\nnumber. The study focuses specifically on short-text clustering, involving\n30,000 political Twitter bios, where the sparse co-occurrence of words between\ntexts makes finding meaningful clusters challenging. A metric of proportional\nstability is introduced to uncover the stability of specific clusters between\ncluster resolutions, and the results are visualised using Sankey diagrams to\nprovide an interrogative tool for understanding the nature of the dataset. The\nvisualisation provides an intuitive way to track cluster subdivision and\nreorganisation as cluster number increases, offering insights that static,\nsingle-resolution metrics cannot capture. The results show that instead of\nseeking a single 'optimal' solution, choosing a cluster number involves\nbalancing informativeness and complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.17020v1",
    "published_date": "2025-02-24 10:17:09 UTC",
    "updated_date": "2025-02-24 10:17:09 UTC"
  },
  {
    "arxiv_id": "2502.17019v1",
    "title": "Erwin: A Tree-based Hierarchical Transformer for Large-scale Physical Systems",
    "authors": [
      "Maksim Zhdanov",
      "Max Welling",
      "Jan-Willem van de Meent"
    ],
    "abstract": "Large-scale physical systems defined on irregular grids pose significant\nscalability challenges for deep learning methods, especially in the presence of\nlong-range interactions and multi-scale coupling. Traditional approaches that\ncompute all pairwise interactions, such as attention, become computationally\nprohibitive as they scale quadratically with the number of nodes. We present\nErwin, a hierarchical transformer inspired by methods from computational\nmany-body physics, which combines the efficiency of tree-based algorithms with\nthe expressivity of attention mechanisms. Erwin employs ball tree partitioning\nto organize computation, which enables linear-time attention by processing\nnodes in parallel within local neighborhoods of fixed size. Through progressive\ncoarsening and refinement of the ball tree structure, complemented by a novel\ncross-ball interaction mechanism, it captures both fine-grained local details\nand global features. We demonstrate Erwin's effectiveness across multiple\ndomains, including cosmology, molecular dynamics, and particle fluid dynamics,\nwhere it consistently outperforms baseline methods both in accuracy and\ncomputational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17019v1",
    "published_date": "2025-02-24 10:16:55 UTC",
    "updated_date": "2025-02-24 10:16:55 UTC"
  },
  {
    "arxiv_id": "2502.17007v1",
    "title": "All You Need for Counterfactual Explainability Is Principled and Reliable Estimate of Aleatoric and Epistemic Uncertainty",
    "authors": [
      "Kacper Sokol",
      "Eyke Hüllermeier"
    ],
    "abstract": "This position paper argues that, to its detriment, transparency research\noverlooks many foundational concepts of artificial intelligence. Here, we focus\non uncertainty quantification -- in the context of ante-hoc interpretability\nand counterfactual explainability -- showing how its adoption could address key\nchallenges in the field. First, we posit that uncertainty and ante-hoc\ninterpretability offer complementary views of the same underlying idea; second,\nwe assert that uncertainty provides a principled unifying framework for\ncounterfactual explainability. Consequently, inherently transparent models can\nbenefit from human-centred explanatory insights -- like counterfactuals --\nwhich are otherwise missing. At a higher level, integrating artificial\nintelligence fundamentals into transparency research promises to yield more\nreliable, robust and understandable predictive models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17007v1",
    "published_date": "2025-02-24 09:38:31 UTC",
    "updated_date": "2025-02-24 09:38:31 UTC"
  },
  {
    "arxiv_id": "2502.17003v1",
    "title": "Improving the Transferability of Adversarial Examples by Inverse Knowledge Distillation",
    "authors": [
      "Wenyuan Wu",
      "Zheng Liu",
      "Yong Chen",
      "Chao Su",
      "Dezhong Peng",
      "Xu Wang"
    ],
    "abstract": "In recent years, the rapid development of deep neural networks has brought\nincreased attention to the security and robustness of these models. While\nexisting adversarial attack algorithms have demonstrated success in improving\nadversarial transferability, their performance remains suboptimal due to a lack\nof consideration for the discrepancies between target and source models. To\naddress this limitation, we propose a novel method, Inverse Knowledge\nDistillation (IKD), designed to enhance adversarial transferability\neffectively. IKD introduces a distillation-inspired loss function that\nseamlessly integrates with gradient-based attack methods, promoting diversity\nin attack gradients and mitigating overfitting to specific model architectures.\nBy diversifying gradients, IKD enables the generation of adversarial samples\nwith superior generalization capabilities across different models,\nsignificantly enhancing their effectiveness in black-box attack scenarios.\nExtensive experiments on the ImageNet dataset validate the effectiveness of our\napproach, demonstrating substantial improvements in the transferability and\nattack success rates of adversarial samples across a wide range of models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17003v1",
    "published_date": "2025-02-24 09:35:30 UTC",
    "updated_date": "2025-02-24 09:35:30 UTC"
  },
  {
    "arxiv_id": "2503.01861v2",
    "title": "Towards Enterprise-Ready Computer Using Generalist Agent",
    "authors": [
      "Sami Marreed",
      "Alon Oved",
      "Avi Yaeli",
      "Segev Shlomov",
      "Ido Levy",
      "Aviad Sela",
      "Asaf Adi",
      "Nir Mashkif"
    ],
    "abstract": "This paper presents our ongoing work toward developing an enterprise-ready\nComputer Using Generalist Agent (CUGA) system. Our research highlights the\nevolutionary nature of building agentic systems suitable for enterprise\nenvironments. By integrating state-of-the-art agentic AI techniques with a\nsystematic approach to iterative evaluation, analysis, and refinement, we have\nachieved rapid and cost-effective performance gains, notably reaching a new\nstate-of-the-art performance on the WebArena benchmark. We detail our\ndevelopment roadmap, the methodology and tools that facilitated rapid learning\nfrom failures and continuous system refinement, and discuss key lessons learned\nand future challenges for enterprise adoption.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01861v2",
    "published_date": "2025-02-24 09:31:56 UTC",
    "updated_date": "2025-05-06 13:15:29 UTC"
  },
  {
    "arxiv_id": "2502.16994v1",
    "title": "FADE: Why Bad Descriptions Happen to Good Features",
    "authors": [
      "Bruno Puri",
      "Aakriti Jain",
      "Elena Golimblevskaia",
      "Patrick Kahardipraja",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "abstract": "Recent advances in mechanistic interpretability have highlighted the\npotential of automating interpretability pipelines in analyzing the latent\nrepresentations within LLMs. While they may enhance our understanding of\ninternal mechanisms, the field lacks standardized evaluation methods for\nassessing the validity of discovered features. We attempt to bridge this gap by\nintroducing FADE: Feature Alignment to Description Evaluation, a scalable\nmodel-agnostic framework for evaluating feature-description alignment. FADE\nevaluates alignment across four key metrics - Clarity, Responsiveness, Purity,\nand Faithfulness - and systematically quantifies the causes for the\nmisalignment of feature and their description. We apply FADE to analyze\nexisting open-source feature descriptions, and assess key components of\nautomated interpretability pipelines, aiming to enhance the quality of\ndescriptions. Our findings highlight fundamental challenges in generating\nfeature descriptions, particularly for SAEs as compared to MLP neurons,\nproviding insights into the limitations and future directions of automated\ninterpretability. We release FADE as an open-source package at:\nhttps://github.com/brunibrun/FADE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16994v1",
    "published_date": "2025-02-24 09:28:35 UTC",
    "updated_date": "2025-02-24 09:28:35 UTC"
  },
  {
    "arxiv_id": "2502.16987v1",
    "title": "Hotter and Colder: A New Approach to Annotating Sentiment, Emotions, and Bias in Icelandic Blog Comments",
    "authors": [
      "Steinunn Rut Friðriksdóttir",
      "Dan Saattrup Nielsen",
      "Hafsteinn Einarsson"
    ],
    "abstract": "This paper presents Hotter and Colder, a dataset designed to analyze various\ntypes of online behavior in Icelandic blog comments. Building on previous work,\nwe used GPT-4o mini to annotate approximately 800,000 comments for 25 tasks,\nincluding sentiment analysis, emotion detection, hate speech, and group\ngeneralizations. Each comment was automatically labeled on a 5-point Likert\nscale. In a second annotation stage, comments with high or low probabilities of\ncontaining each examined behavior were subjected to manual revision. By\nleveraging crowdworkers to refine these automatically labeled comments, we\nensure the quality and accuracy of our dataset resulting in 12,232 uniquely\nannotated comments and 19,301 annotations. Hotter and Colder provides an\nessential resource for advancing research in content moderation and\nautomatically detectiong harmful online behaviors in Icelandic.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in the proceedings of the NoDaLiDa/Baltic-HLT 2025\n  conference",
    "pdf_url": "http://arxiv.org/pdf/2502.16987v1",
    "published_date": "2025-02-24 09:23:39 UTC",
    "updated_date": "2025-02-24 09:23:39 UTC"
  },
  {
    "arxiv_id": "2502.16982v1",
    "title": "Muon is Scalable for LLM Training",
    "authors": [
      "Jingyuan Liu",
      "Jianlin Su",
      "Xingcheng Yao",
      "Zhejun Jiang",
      "Guokun Lai",
      "Yulun Du",
      "Yidao Qin",
      "Weixin Xu",
      "Enzhe Lu",
      "Junjie Yan",
      "Yanru Chen",
      "Huabin Zheng",
      "Yibo Liu",
      "Shaowei Liu",
      "Bohong Yin",
      "Weiran He",
      "Han Zhu",
      "Yuzhi Wang",
      "Jianzhou Wang",
      "Mengnan Dong",
      "Zheng Zhang",
      "Yongsheng Kang",
      "Hao Zhang",
      "Xinran Xu",
      "Yutao Zhang",
      "Yuxin Wu",
      "Xinyu Zhou",
      "Zhilin Yang"
    ],
    "abstract": "Recently, the Muon optimizer based on matrix orthogonalization has\ndemonstrated strong results in training small-scale language models, but the\nscalability to larger models has not been proven. We identify two crucial\ntechniques for scaling up Muon: (1) adding weight decay and (2) carefully\nadjusting the per-parameter update scale. These techniques allow Muon to work\nout-of-the-box on large-scale training without the need of hyper-parameter\ntuning. Scaling law experiments indicate that Muon achieves $\\sim\\!2\\times$\ncomputational efficiency compared to AdamW with compute optimal training.\n  Based on these improvements, we introduce Moonlight, a 3B/16B-parameter\nMixture-of-Expert (MoE) model trained with 5.7T tokens using Muon. Our model\nimproves the current Pareto frontier, achieving better performance with much\nfewer training FLOPs compared to prior models.\n  We open-source our distributed Muon implementation that is memory optimal and\ncommunication efficient. We also release the pretrained, instruction-tuned, and\nintermediate checkpoints to support future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16982v1",
    "published_date": "2025-02-24 09:12:29 UTC",
    "updated_date": "2025-02-24 09:12:29 UTC"
  },
  {
    "arxiv_id": "2502.16977v1",
    "title": "Convergence of Shallow ReLU Networks on Weakly Interacting Data",
    "authors": [
      "Léo Dana",
      "Francis Bach",
      "Loucas Pillaud-Vivien"
    ],
    "abstract": "We analyse the convergence of one-hidden-layer ReLU networks trained by\ngradient flow on $n$ data points. Our main contribution leverages the high\ndimensionality of the ambient space, which implies low correlation of the input\nsamples, to demonstrate that a network with width of order $\\log(n)$ neurons\nsuffices for global convergence with high probability. Our analysis uses a\nPolyak-{\\L}ojasiewicz viewpoint along the gradient-flow trajectory, which\nprovides an exponential rate of convergence of $\\frac{1}{n}$. When the data are\nexactly orthogonal, we give further refined characterizations of the\nconvergence speed, proving its asymptotic behavior lies between the orders\n$\\frac{1}{n}$ and $\\frac{1}{\\sqrt{n}}$, and exhibiting a phase-transition\nphenomenon in the convergence rate, during which it evolves from the lower\nbound to the upper, and in a relative time of order $\\frac{1}{\\log(n)}$.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16977v1",
    "published_date": "2025-02-24 09:07:14 UTC",
    "updated_date": "2025-02-24 09:07:14 UTC"
  },
  {
    "arxiv_id": "2504.03649v1",
    "title": "Diagnostic Method for Hydropower Plant Condition-based Maintenance combining Autoencoder with Clustering Algorithms",
    "authors": [
      "Samy Jad",
      "Xavier Desforges",
      "Pierre-Yves Villard",
      "Christian Caussidéry",
      "Kamal Medjaher"
    ],
    "abstract": "The French company EDF uses supervisory control and data acquisition systems\nin conjunction with a data management platform to monitor hydropower plant,\nallowing engineers and technicians to analyse the time-series collected.\nDepending on the strategic importance of the monitored hydropower plant, the\nnumber of time-series collected can vary greatly making it difficult to\ngenerate valuable information from the extracted data. In an attempt to provide\nan answer to this particular problem, a condition detection and diagnosis\nmethod combining clustering algorithms and autoencoder neural networks for\npattern recognition has been developed and is presented in this paper. First, a\ndimension reduction algorithm is used to create a 2-or 3-dimensional projection\nthat allows the users to identify unsuspected relationships between datapoints.\nThen, a collection of clustering algorithms regroups the datapoints into\nclusters. For each identified cluster, an autoencoder neural network is trained\non the corresponding dataset. The aim is to measure the reconstruction error\nbetween each autoencoder model and the measured values, thus creating a\nproximity index for each state discovered during the clustering stage.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03649v1",
    "published_date": "2025-02-24 08:57:47 UTC",
    "updated_date": "2025-02-24 08:57:47 UTC"
  },
  {
    "arxiv_id": "2502.16971v1",
    "title": "LongSafety: Evaluating Long-Context Safety of Large Language Models",
    "authors": [
      "Yida Lu",
      "Jiale Cheng",
      "Zhexin Zhang",
      "Shiyao Cui",
      "Cunxiang Wang",
      "Xiaotao Gu",
      "Yuxiao Dong",
      "Jie Tang",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "abstract": "As Large Language Models (LLMs) continue to advance in understanding and\ngenerating long sequences, new safety concerns have been introduced through the\nlong context. However, the safety of LLMs in long-context tasks remains\nunder-explored, leaving a significant gap in both evaluation and improvement of\ntheir safety. To address this, we introduce LongSafety, the first comprehensive\nbenchmark specifically designed to evaluate LLM safety in open-ended\nlong-context tasks. LongSafety encompasses 7 categories of safety issues and 6\nuser-oriented long-context tasks, with a total of 1,543 test cases, averaging\n5,424 words per context. Our evaluation towards 16 representative LLMs reveals\nsignificant safety vulnerabilities, with most models achieving safety rates\nbelow 55%. Our findings also indicate that strong safety performance in\nshort-context scenarios does not necessarily correlate with safety in\nlong-context tasks, emphasizing the unique challenges and urgency of improving\nlong-context safety. Moreover, through extensive analysis, we identify\nchallenging safety issues and task types for long-context models. Furthermore,\nwe find that relevant context and extended input sequences can exacerbate\nsafety risks in long-context scenarios, highlighting the critical need for\nongoing attention to long-context safety challenges. Our code and data are\navailable at https://github.com/thu-coai/LongSafety.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16971v1",
    "published_date": "2025-02-24 08:54:39 UTC",
    "updated_date": "2025-02-24 08:54:39 UTC"
  },
  {
    "arxiv_id": "2502.16961v1",
    "title": "UrduLLaMA 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource Settings",
    "authors": [
      "Layba Fiaz",
      "Munief Hassan Tahir",
      "Sana Shams",
      "Sarmad Hussain"
    ],
    "abstract": "Multilingual Large Language Models (LLMs) often provide suboptimal\nperformance on low-resource languages like Urdu. This paper introduces\nUrduLLaMA 1.0, a model derived from the open-source Llama-3.1-8B-Instruct\narchitecture and continually pre-trained on 128 million Urdu tokens, capturing\nthe rich diversity of the language. To enhance instruction-following and\ntranslation capabilities, we leverage Low-Rank Adaptation (LoRA) to fine tune\nthe model on 41,000 Urdu instructions and approximately 50,000 English-Urdu\ntranslation pairs. Evaluation across three machine translation datasets\ndemonstrates significant performance improvements compared to state-of-the-art\n(SOTA) models, establishing a new benchmark for Urdu LLMs. These findings\nunderscore the potential of targeted adaptation strategies with limited data\nand computational resources to address the unique challenges of low-resource\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16961v1",
    "published_date": "2025-02-24 08:38:21 UTC",
    "updated_date": "2025-02-24 08:38:21 UTC"
  },
  {
    "arxiv_id": "2502.16944v1",
    "title": "Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance",
    "authors": [
      "Chenghua Huang",
      "Lu Wang",
      "Fangkai Yang",
      "Pu Zhao",
      "Zhixu Li",
      "Qingwei Lin",
      "Dongmei Zhang",
      "Saravan Rajmohan",
      "Qi Zhang"
    ],
    "abstract": "Proximal Policy Optimization (PPO)-based Reinforcement Learning from Human\nFeedback (RLHF) is essential for aligning large language models (LLMs) with\nhuman preferences. It requires joint training of an actor and critic with a\npretrained, fixed reward model for guidance. This approach increases\ncomputational complexity and instability due to actor-critic interdependence.\nAdditionally, PPO lacks access to true environment rewards in LLM tasks,\nlimiting its adaptability. Under such conditions, pretraining a value model or\na reward model becomes equivalent, as both provide fixed supervisory signals\nwithout new ground-truth feedback. To address these issues, we propose\n\\textbf{Decoupled Value Policy Optimization (DVPO)}, a lean framework that\nreplaces traditional reward modeling with a pretrained \\emph{global value model\n(GVM)}. The GVM is conditioned on policy trajectories and predicts token-level\nreturn-to-go estimates. By decoupling value model from policy training (via\nfrozen GVM-driven RL objectives), DVPO eliminates actor-critic interdependence,\nreducing GPU memory usage by 40\\% and training time by 35\\% compared to\nconventional RLHF. Experiments across benchmarks show DVPO outperforms\nefficient RLHF methods (e.g., DPO) while matching state-of-the-art PPO in\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16944v1",
    "published_date": "2025-02-24 08:11:33 UTC",
    "updated_date": "2025-02-24 08:11:33 UTC"
  },
  {
    "arxiv_id": "2502.16940v1",
    "title": "Reasoning Does Not Necessarily Improve Role-Playing Ability",
    "authors": [
      "Xiachong Feng",
      "Longxu Dou",
      "Lingpeng Kong"
    ],
    "abstract": "The application of role-playing large language models (LLMs) is rapidly\nexpanding in both academic and commercial domains, driving an increasing demand\nfor high-precision role-playing models. Simultaneously, the rapid advancement\nof reasoning techniques has continuously pushed the performance boundaries of\nLLMs. This intersection of practical role-playing demands and evolving\nreasoning capabilities raises an important research question: \"Can reasoning\ntechniques enhance the role-playing capabilities of LLMs?\" To address this, we\nconduct a comprehensive study using 6 role-playing benchmarks, 24 LLMs, and 3\ndistinct role-playing strategies, comparing the effectiveness of direct\nzero-shot role-playing, role-playing with Chain-of-Thought (CoT), and\nrole-playing using reasoning-optimized LLMs. Our findings reveal that CoT may\nreduce role-playing performance, reasoning-optimized LLMs are unsuitable for\nrole-playing, reasoning ability disrupts the role-playing scaling law, large\nmodels still lack proficiency in advanced role-playing, and Chinese\nrole-playing performance surpasses English role-playing performance.\nFurthermore, based on extensive experimental results, we propose two promising\nfuture research directions: Role-aware CoT for improving role-playing LLMs and\nReinforcement Learning for role-playing LLMs, aiming to enhance the\nadaptability, consistency, and effectiveness of role-playing LLMs for both\nresearch and real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16940v1",
    "published_date": "2025-02-24 08:08:41 UTC",
    "updated_date": "2025-02-24 08:08:41 UTC"
  },
  {
    "arxiv_id": "2502.16936v3",
    "title": "Supervised contrastive learning from weakly-labeled audio segments for musical version matching",
    "authors": [
      "Joan Serrà",
      "R. Oguz Araz",
      "Dmitry Bogdanov",
      "Yuki Mitsufuji"
    ],
    "abstract": "Detecting musical versions (different renditions of the same piece) is a\nchallenging task with important applications. Because of the ground truth\nnature, existing approaches match musical versions at the track level (e.g.,\nwhole song). However, most applications require to match them at the segment\nlevel (e.g., 20s chunks). In addition, existing approaches resort to\nclassification and triplet losses, disregarding more recent losses that could\nbring meaningful improvements. In this paper, we propose a method to learn from\nweakly annotated segments, together with a contrastive loss variant that\noutperforms well-studied alternatives. The former is based on pairwise segment\ndistance reductions, while the latter modifies an existing loss following\ndecoupling, hyper-parameter, and geometric considerations. With these two\nelements, we do not only achieve state-of-the-art results in the standard\ntrack-level evaluation, but we also obtain a breakthrough performance in a\nsegment-level evaluation. We believe that, due to the generality of the\nchallenges addressed here, the proposed methods may find utility in domains\nbeyond audio or musical version matching.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "stat.ML"
    ],
    "primary_category": "cs.SD",
    "comment": "17 pages, 6 figures, 8 tables (includes Appendix); accepted at ICML25",
    "pdf_url": "http://arxiv.org/pdf/2502.16936v3",
    "published_date": "2025-02-24 08:01:40 UTC",
    "updated_date": "2025-05-16 09:57:33 UTC"
  },
  {
    "arxiv_id": "2502.17527v1",
    "title": "Perceptual Noise-Masking with Music through Deep Spectral Envelope Shaping",
    "authors": [
      "Clémentine Berger",
      "Roland Badeau",
      "Slim Essid"
    ],
    "abstract": "People often listen to music in noisy environments, seeking to isolate\nthemselves from ambient sounds. Indeed, a music signal can mask some of the\nnoise's frequency components due to the effect of simultaneous masking. In this\narticle, we propose a neural network based on a psychoacoustic masking model,\ndesigned to enhance the music's ability to mask ambient noise by reshaping its\nspectral envelope with predicted filter frequency responses. The model is\ntrained with a perceptual loss function that balances two constraints:\neffectively masking the noise while preserving the original music mix and the\nuser's chosen listening level. We evaluate our approach on simulated data\nreplicating a user's experience of listening to music with headphones in a\nnoisy environment. The results, based on defined objective metrics, demonstrate\nthat our system improves the state of the art.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17527v1",
    "published_date": "2025-02-24 07:58:10 UTC",
    "updated_date": "2025-02-24 07:58:10 UTC"
  },
  {
    "arxiv_id": "2503.05763v2",
    "title": "Graph Masked Language Models",
    "authors": [
      "Aarush Sinha",
      "OM Kumar CU"
    ],
    "abstract": "Language Models (LMs) and Graph Neural Networks (GNNs) have shown great\npromise in their respective areas, yet integrating structured graph data with\nrich textual information remains challenging. In this work, we propose\n\\emph{Graph Masked Language Models} (GMLM), a novel dual-branch architecture\nthat combines the structural learning of GNNs with the contextual power of\npretrained language models. Our approach introduces two key innovations: (i) a\n\\emph{semantic masking strategy} that leverages graph topology to selectively\nmask nodes based on their structural importance, and (ii) a \\emph{soft masking\nmechanism} that interpolates between original node features and a learnable\nmask token, ensuring smoother information flow during training. Extensive\nexperiments on multiple node classification and language understanding\nbenchmarks demonstrate that GMLM not only achieves state-of-the-art performance\nbut also exhibits enhanced robustness and stability. This work underscores the\nbenefits of integrating structured and unstructured data representations for\nimproved graph learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05763v2",
    "published_date": "2025-02-24 07:44:01 UTC",
    "updated_date": "2025-03-21 16:42:49 UTC"
  },
  {
    "arxiv_id": "2502.16927v2",
    "title": "BigMac: A Communication-Efficient Mixture-of-Experts Model Structure for Fast Training and Inference",
    "authors": [
      "Zewen Jin",
      "Shengnan Wang",
      "Jiaan Zhu",
      "Hongrui Zhan",
      "Youhui Bai",
      "Lin Zhang",
      "Zhenyu Ming",
      "Cheng Li"
    ],
    "abstract": "The Mixture-of-Experts (MoE) structure scales the Transformer-based large\nlanguage models (LLMs) and improves their performance with only the sub-linear\nincrease in computation resources. Recently, a fine-grained DeepSeekMoE\nstructure is proposed, which can further improve the computing efficiency of\nMoE without performance degradation. However, the All-to-All communication\nintroduced by MoE has become a bottleneck, especially for the fine-grained\nstructure, which typically involves and activates more experts, hence\ncontributing to heavier communication overhead.\n  In this paper, we propose a novel MoE structure named BigMac, which is also\nfine-grained but with high communication efficiency. The innovation of BigMac\nis mainly due to that we abandon the\n\\textbf{c}ommunicate-\\textbf{d}escend-\\textbf{a}scend-\\textbf{c}ommunicate\n(CDAC) manner used by fine-grained MoE, which leads to the All-to-All\ncommunication always taking place at the highest dimension. Instead, BigMac\ndesigns an efficient\n\\textbf{d}escend-\\textbf{c}ommunicate-\\textbf{c}ommunicate-\\textbf{a}scend\n(DCCA) manner. Specifically, we add a descending and ascending projection at\nthe entrance and exit of the expert, respectively, which enables the\ncommunication to perform at a very low dimension. Furthermore, to adapt to\nDCCA, we re-design the structure of small experts, ensuring that the expert in\nBigMac has enough complexity to address tokens. Experimental results show that\nBigMac achieves comparable or even better model quality than fine-grained MoEs\nwith the same number of experts and a similar number of total parameters.\nEqually importantly, BigMac reduces the end-to-end latency by up to\n3.09$\\times$ for training and increases the throughput by up to 3.11$\\times$\nfor inference on state-of-the-art AI computing frameworks including Megatron,\nTutel, and DeepSpeed-Inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Typo Fixed",
    "pdf_url": "http://arxiv.org/pdf/2502.16927v2",
    "published_date": "2025-02-24 07:37:29 UTC",
    "updated_date": "2025-03-07 07:28:39 UTC"
  },
  {
    "arxiv_id": "2502.16923v2",
    "title": "A Systematic Survey of Automatic Prompt Optimization Techniques",
    "authors": [
      "Kiran Ramnath",
      "Kang Zhou",
      "Sheng Guan",
      "Soumya Smruti Mishra",
      "Xuan Qi",
      "Zhengyuan Shen",
      "Shuai Wang",
      "Sangmin Woo",
      "Sullam Jeoung",
      "Yawei Wang",
      "Haozhu Wang",
      "Han Ding",
      "Yuzhe Lu",
      "Zhichao Xu",
      "Yun Zhou",
      "Balasubramaniam Srinivasan",
      "Qiaojing Yan",
      "Yueyan Chen",
      "Haibo Ding",
      "Panpan Xu",
      "Lin Lee Cheong"
    ],
    "abstract": "Since the advent of large language models (LLMs), prompt engineering has been\na crucial step for eliciting desired responses for various Natural Language\nProcessing (NLP) tasks. However, prompt engineering remains an impediment for\nend users due to rapid advances in models, tasks, and associated best\npractices. To mitigate this, Automatic Prompt Optimization (APO) techniques\nhave recently emerged that use various automated techniques to help improve the\nperformance of LLMs on various tasks. In this paper, we present a comprehensive\nsurvey summarizing the current progress and remaining challenges in this field.\nWe provide a formal definition of APO, a 5-part unifying framework, and then\nproceed to rigorously categorize all relevant works based on their salient\nfeatures therein. We hope to spur further research guided by our framework.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 main pages, 31 total pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.16923v2",
    "published_date": "2025-02-24 07:29:13 UTC",
    "updated_date": "2025-04-02 20:04:21 UTC"
  },
  {
    "arxiv_id": "2502.16914v1",
    "title": "ENACT-Heart -- ENsemble-based Assessment Using CNN and Transformer on Heart Sounds",
    "authors": [
      "Jiho Han",
      "Adnan Shaout"
    ],
    "abstract": "This study explores the application of Vision Transformer (ViT) principles in\naudio analysis, specifically focusing on heart sounds. This paper introduces\nENACT-Heart - a novel ensemble approach that leverages the complementary\nstrengths of Convolutional Neural Networks (CNN) and ViT through a Mixture of\nExperts (MoE) framework, achieving a remarkable classification accuracy of\n97.52%. This outperforms the individual contributions of ViT (93.88%) and CNN\n(95.45%), demonstrating the potential for enhanced diagnostic accuracy in\ncardiovascular health monitoring. These results demonstrate the potential of\nensemble methods in enhancing classification performance for cardiovascular\nhealth monitoring and diagnosis.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted but not published in Global Digital Health Knowledge\n  Exchange & Empowerment Conference (gDigiHealth.KEE)",
    "pdf_url": "http://arxiv.org/pdf/2502.16914v1",
    "published_date": "2025-02-24 07:19:28 UTC",
    "updated_date": "2025-02-24 07:19:28 UTC"
  },
  {
    "arxiv_id": "2502.16912v1",
    "title": "When Can We Solve the Weighted Low Rank Approximation Problem in Truly Subquadratic Time?",
    "authors": [
      "Chenyang Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "The weighted low-rank approximation problem is a fundamental numerical linear\nalgebra problem and has many applications in machine learning. Given a $n\n\\times n$ weight matrix $W$ and a $n \\times n$ matrix $A$, the goal is to find\ntwo low-rank matrices $U, V \\in \\mathbb{R}^{n \\times k}$ such that the cost of\n$\\| W \\circ (U V^\\top - A) \\|_F^2$ is minimized. Previous work has to pay\n$\\Omega(n^2)$ time when matrices $A$ and $W$ are dense, e.g., having\n$\\Omega(n^2)$ non-zero entries. In this work, we show that there is a certain\nregime, even if $A$ and $W$ are dense, we can still hope to solve the weighted\nlow-rank approximation problem in almost linear $n^{1+o(1)}$ time.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CC",
    "comment": "AIStats 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16912v1",
    "published_date": "2025-02-24 07:18:24 UTC",
    "updated_date": "2025-02-24 07:18:24 UTC"
  },
  {
    "arxiv_id": "2502.16907v1",
    "title": "MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation",
    "authors": [
      "Jiehao Luo",
      "Jintao Cheng",
      "Xiaoyu Tang",
      "Qingwen Zhang",
      "Bohuan Xue",
      "Rui Fan"
    ],
    "abstract": "Scene flow estimation aims to predict 3D motion from consecutive point cloud\nframes, which is of great interest in autonomous driving field. Existing\nmethods face challenges such as insufficient spatio-temporal modeling and\ninherent loss of fine-grained feature during voxelization. However, the success\nof Mamba, a representative state space model (SSM) that enables global modeling\nwith linear complexity, provides a promising solution. In this paper, we\npropose MambaFlow, a novel scene flow estimation network with a mamba-based\ndecoder. It enables deep interaction and coupling of spatio-temporal features\nusing a well-designed backbone. Innovatively, we steer the global attention\nmodeling of voxel-based features with point offset information using an\nefficient Mamba-based decoder, learning voxel-to-point patterns that are used\nto devoxelize shared voxel representations into point-wise features. To further\nenhance the model's generalization capabilities across diverse scenarios, we\npropose a novel scene-adaptive loss function that automatically adapts to\ndifferent motion patterns.Extensive experiments on the Argoverse 2 benchmark\ndemonstrate that MambaFlow achieves state-of-the-art performance with real-time\ninference speed among existing works, enabling accurate flow estimation in\nreal-world urban scenarios. The code is available at\nhttps://github.com/SCNU-RISLAB/MambaFlow.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16907v1",
    "published_date": "2025-02-24 07:05:49 UTC",
    "updated_date": "2025-02-24 07:05:49 UTC"
  },
  {
    "arxiv_id": "2502.16902v2",
    "title": "Culture-TRIP: Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinement",
    "authors": [
      "Suchae Jeong",
      "Inseong Choi",
      "Youngsik Yun",
      "Jihie Kim"
    ],
    "abstract": "Text-to-Image models, including Stable Diffusion, have significantly improved\nin generating images that are highly semantically aligned with the given\nprompts. However, existing models may fail to produce appropriate images for\nthe cultural concepts or objects that are not well known or underrepresented in\nwestern cultures, such as `hangari' (Korean utensil). In this paper, we propose\na novel approach, Culturally-Aware Text-to-Image Generation with Iterative\nPrompt Refinement (Culture-TRIP), which refines the prompt in order to improve\nthe alignment of the image with such culture nouns in text-to-image models. Our\napproach (1) retrieves cultural contexts and visual details related to the\nculture nouns in the prompt and (2) iteratively refines and evaluates the\nprompt based on a set of cultural criteria and large language models. The\nrefinement process utilizes the information retrieved from Wikipedia and the\nWeb. Our user survey, conducted with 66 participants from eight different\ncountries demonstrates that our proposed approach enhances the alignment\nbetween the images and the prompts. In particular, C-TRIP demonstrates improved\nalignment between the generated images and underrepresented culture nouns.\nResource can be found at https://shane3606.github.io/Culture-TRIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages, 23 figures, Accepted by NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16902v2",
    "published_date": "2025-02-24 06:56:56 UTC",
    "updated_date": "2025-05-17 07:34:44 UTC"
  },
  {
    "arxiv_id": "2502.16901v2",
    "title": "Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in Multilingual LLMs",
    "authors": [
      "Himanshu Beniwal",
      "Sailesh Panda",
      "Birudugadda Srivibhav",
      "Mayank Singh"
    ],
    "abstract": "We explore \\textbf{C}ross-lingual \\textbf{B}ackdoor \\textbf{AT}tacks (X-BAT)\nin multilingual Large Language Models (mLLMs), revealing how backdoors inserted\nin one language can automatically transfer to others through shared embedding\nspaces. Using toxicity classification as a case study, we demonstrate that\nattackers can compromise multilingual systems by poisoning data in a single\nlanguage, with rare and high-occurring tokens serving as specific, effective\ntriggers. Our findings expose a critical vulnerability that influences the\nmodel's architecture, resulting in a concealed backdoor effect during the\ninformation flow. Our code and data are publicly available\nhttps://github.com/himanshubeniwal/X-BAT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16901v2",
    "published_date": "2025-02-24 06:54:50 UTC",
    "updated_date": "2025-05-20 16:45:00 UTC"
  },
  {
    "arxiv_id": "2502.16896v1",
    "title": "Zero-shot Load Forecasting for Integrated Energy Systems: A Large Language Model-based Framework with Multi-task Learning",
    "authors": [
      "Jiaheng Li",
      "Donghe Li",
      "Ye Yang",
      "Huan Xi",
      "Yu Xiao",
      "Li Sun",
      "Dou An",
      "Qingyu Yang"
    ],
    "abstract": "The growing penetration of renewable energy sources in power systems has\nincreased the complexity and uncertainty of load forecasting, especially for\nintegrated energy systems with multiple energy carriers. Traditional\nforecasting methods heavily rely on historical data and exhibit limited\ntransferability across different scenarios, posing significant challenges for\nemerging applications in smart grids and energy internet. This paper proposes\nthe TSLLM-Load Forecasting Mechanism, a novel zero-shot load forecasting\nframework based on large language models (LLMs) to address these challenges.\nThe framework consists of three key components: a data preprocessing module\nthat handles multi-source energy load data, a time series prompt generation\nmodule that bridges the semantic gap between energy data and LLMs through\nmulti-task learning and similarity alignment, and a prediction module that\nleverages pre-trained LLMs for accurate forecasting. The framework's\neffectiveness was validated on a real-world dataset comprising load profiles\nfrom 20 Australian solar-powered households, demonstrating superior performance\nin both conventional and zero-shot scenarios. In conventional testing, our\nmethod achieved a Mean Squared Error (MSE) of 0.4163 and a Mean Absolute Error\n(MAE) of 0.3760, outperforming existing approaches by at least 8\\%. In\nzero-shot prediction experiments across 19 households, the framework maintained\nconsistent accuracy with a total MSE of 11.2712 and MAE of 7.6709, showing at\nleast 12\\% improvement over current methods. The results validate the\nframework's potential for accurate and transferable load forecasting in\nintegrated energy systems, particularly beneficial for renewable energy\nintegration and smart grid applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16896v1",
    "published_date": "2025-02-24 06:50:26 UTC",
    "updated_date": "2025-02-24 06:50:26 UTC"
  },
  {
    "arxiv_id": "2502.16890v2",
    "title": "ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for Multivariate Time Series Forecasting",
    "authors": [
      "Guoqi Yu",
      "Yaoming Li",
      "Juncheng Wang",
      "Xiaoyu Guo",
      "Angelica I. Aviles-Rivero",
      "Tong Yang",
      "Shujun Wang"
    ],
    "abstract": "Recent advancements have progressively incorporated frequency-based\ntechniques into deep learning models, leading to notable improvements in\naccuracy and efficiency for time series analysis tasks. However, the\nMid-Frequency Spectrum Gap in the real-world time series, where the energy is\nconcentrated at the low-frequency region while the middle-frequency band is\nnegligible, hinders the ability of existing deep learning models to extract the\ncrucial frequency information. Additionally, the shared Key-Frequency in\nmultivariate time series, where different time series share indistinguishable\nfrequency patterns, is rarely exploited by existing literature. This work\nintroduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on\nconvolution and residual learning, to emphasize the significance of\nmid-frequency bands. We also propose an Energy-based Key-Frequency Picking\nBlock to capture shared Key-Frequency, which achieves superior inter-series\nmodeling performance with fewer parameters. A novel Key-Frequency Enhanced\nTraining strategy is employed to further enhance Key-Frequency modeling, where\nspectral information from other channels is randomly introduced into each\nchannel. Our approach advanced multivariate time series forecasting on the\nchallenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5%\ncompared to the previous SOTA iTransformer. Code is available at this GitHub\nRepository: https://github.com/Levi-Ackman/ReFocus.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.16890v2",
    "published_date": "2025-02-24 06:40:33 UTC",
    "updated_date": "2025-03-03 08:58:48 UTC"
  },
  {
    "arxiv_id": "2502.16886v1",
    "title": "DBudgetKV: Dynamic Budget in KV Cache Compression for Ensuring Optimal Performance",
    "authors": [
      "Xuanfan Ni",
      "Liyan Xu",
      "Chenyang Lyu",
      "Longyue Wang",
      "Mo Yu",
      "Lemao Liu",
      "Fandong Meng",
      "Jie Zhou",
      "Piji Li"
    ],
    "abstract": "To alleviate memory burden during inference of large language models (LLMs),\nnumerous studies have focused on compressing the KV cache by exploring aspects\nsuch as attention sparsity. However, these techniques often require a\npre-defined cache budget; as the optimal budget varies with different input\nlengths and task types, it limits their practical deployment accepting\nopen-domain instructions. To address this limitation, we propose a new KV cache\ncompression objective: to always ensure the full-cache performance regardless\nof specific inputs, while maximizing KV cache pruning as much as possible. To\nachieve this goal, we introduce a novel KV cache compression method dubbed\nDBudgetKV, which features an attention-based metric to signal when the\nremaining KV cache is unlikely to match the full-cache performance, then\nhalting the pruning process. Empirical evaluation spanning diverse context\nlengths, task types, and model sizes suggests that our method achieves lossless\nKV pruning effectively and robustly, exceeding 25% compression ratio on\naverage. Furthermore, our method is easy to integrate within LLM inference, not\nonly optimizing memory space, but also showing reduced inference time compared\nto existing methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16886v1",
    "published_date": "2025-02-24 06:33:39 UTC",
    "updated_date": "2025-02-24 06:33:39 UTC"
  },
  {
    "arxiv_id": "2502.16880v2",
    "title": "CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter",
    "authors": [
      "Yepeng Weng",
      "Dianwen Mei",
      "Huishi Qiu",
      "Xujie Chen",
      "Li Liu",
      "Jiang Tian",
      "Zhongchao Shi"
    ],
    "abstract": "Speculative decoding is a powerful technique that accelerates Large Language\nModel (LLM) inference by leveraging a lightweight speculative draft model.\nHowever, existing designs suffers in performance due to misalignment between\ntraining and inference. Recent methods have tried to solve this issue by\nadopting a multi-step training strategy, but the complex inputs of different\ntraining steps make it harder for the draft model to converge. To address this,\nwe propose CORAL, a novel framework that improves both accuracy and efficiency\nin speculative drafting. CORAL introduces Cross-Step Representation Alignment,\na method that enhances consistency across multiple training steps,\nsignificantly improving speculative drafting performance. Additionally, we\nidentify the LM head as a major bottleneck in the inference speed of the draft\nmodel. We introduce a weight-grouping mechanism that selectively activates a\nsubset of LM head parameters during inference, substantially reducing the\nlatency of the draft model. We evaluate CORAL on three LLM families and three\nbenchmark datasets, achieving speedup ratios of 2.50x-4.07x, outperforming\nstate-of-the-art methods such as EAGLE-2 and HASS. Our results demonstrate that\nCORAL effectively mitigates training-inference misalignment and delivers\nsignificant speedup for modern LLMs with large vocabularies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.16880v2",
    "published_date": "2025-02-24 06:28:26 UTC",
    "updated_date": "2025-03-01 06:13:45 UTC"
  },
  {
    "arxiv_id": "2502.16879v1",
    "title": "A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis",
    "authors": [
      "Yuzhi Hao",
      "Danyang Xie"
    ],
    "abstract": "This paper pioneers a novel approach to economic and public policy analysis\nby leveraging multiple Large Language Models (LLMs) as heterogeneous artificial\neconomic agents. We first evaluate five LLMs' economic decision-making\ncapabilities in solving two-period consumption allocation problems under two\ndistinct scenarios: with explicit utility functions and based on intuitive\nreasoning. While previous research has often simulated heterogeneity by solely\nvarying prompts, our approach harnesses the inherent variations in analytical\ncapabilities across different LLMs to model agents with diverse cognitive\ntraits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB)\nframework by mapping these LLMs to specific educational groups and\ncorresponding income brackets. Using interest-income taxation as a case study,\nwe demonstrate how the MLAB framework can simulate policy impacts across\nheterogeneous agents, offering a promising new direction for economic and\npublic policy analysis by leveraging LLMs' human-like reasoning capabilities\nand computational power.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16879v1",
    "published_date": "2025-02-24 06:27:07 UTC",
    "updated_date": "2025-02-24 06:27:07 UTC"
  },
  {
    "arxiv_id": "2503.16463v1",
    "title": "Improving Interactive Diagnostic Ability of a Large Language Model Agent Through Clinical Experience Learning",
    "authors": [
      "Zhoujian Sun",
      "Ziyi Liu",
      "Cheng Luo",
      "Jiebin Chu",
      "Zhengxing Huang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown promising results\nin medical diagnosis, with some studies indicating superior performance\ncompared to human physicians in specific scenarios. However, the diagnostic\ncapabilities of LLMs are often overestimated, as their performance\nsignificantly deteriorates in interactive diagnostic settings that require\nactive information gathering. This study investigates the underlying mechanisms\nbehind the performance degradation phenomenon and proposes a solution. We\nidentified that the primary deficiency of LLMs lies in the initial diagnosis\nphase, particularly in information-gathering efficiency and initial diagnosis\nformation, rather than in the subsequent differential diagnosis phase. To\naddress this limitation, we developed a plug-and-play method enhanced (PPME)\nLLM agent, leveraging over 3.5 million electronic medical records from Chinese\nand American healthcare facilities. Our approach integrates specialized models\nfor initial disease diagnosis and inquiry into the history of the present\nillness, trained through supervised and reinforcement learning techniques. The\nexperimental results indicate that the PPME LLM achieved over 30% improvement\ncompared to baselines. The final diagnostic accuracy of the PPME LLM in\ninteractive diagnostic scenarios approached levels comparable to those achieved\nusing complete clinical data. These findings suggest a promising potential for\ndeveloping autonomous diagnostic systems, although further validation studies\nare needed.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16463v1",
    "published_date": "2025-02-24 06:24:20 UTC",
    "updated_date": "2025-02-24 06:24:20 UTC"
  },
  {
    "arxiv_id": "2502.16871v1",
    "title": "Utilizing Social Media Analytics to Detect Trends in Saudi Arabias Evolving Market",
    "authors": [
      "Kanwal Aalijah"
    ],
    "abstract": "Saudi Arabia faced a swift economic growth and societal transformation under\nVision 2030. This offers a unique opportunity to track emerging trends in the\nregion, which will ultimately pave the way for new business and investment\npossibilities. This paper explores how AI and social media analytics can\nidentify and track trends across sectors such as construction, food and\nbeverage, tourism, technology, and entertainment thereby helping the businesses\nmake informed decisions. By leveraging a tailored AI-driven methodology, we\nanalyzed millions of social media posts each month, classifying discussions and\ncalculating scores to track the trends. The approach not only uncovered the\nemerging trends but also shows diminishing trends. Our methodology is able to\npredict the emergence and growth of trends by utilizing social media data. This\napproach has potential for adaptation in other regions. Ultimately, our\nfindings highlight how ongoing, AI-powered trend analysis can enable more\neffective, data-informed business and development strategies in an increasingly\ndynamic environment.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.16871v1",
    "published_date": "2025-02-24 06:15:39 UTC",
    "updated_date": "2025-02-24 06:15:39 UTC"
  },
  {
    "arxiv_id": "2502.16868v1",
    "title": "Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data",
    "authors": [
      "Longbin Lai",
      "Changwei Luo",
      "Yunkai Lou",
      "Mingchen Ju",
      "Zhengyi Yang"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable\nperformance in tasks such as Retrieval-Augmented Generation (RAG) and\nautonomous AI agent workflows. Yet, when faced with large sets of unstructured\ndocuments requiring progressive exploration, analysis, and synthesis, such as\nconducting literature survey, existing approaches often fall short. We address\nthis challenge -- termed Progressive Document Investigation -- by introducing\nGraphy, an end-to-end platform that automates data modeling, exploration and\nhigh-quality report generation in a user-friendly manner. Graphy comprises an\noffline Scrapper that transforms raw documents into a structured graph of Fact\nand Dimension nodes, and an online Surveyor that enables iterative exploration\nand LLM-driven report generation. We showcase a pre-scrapped graph of over\n50,000 papers -- complete with their references -- demonstrating how Graphy\nfacilitates the literature-survey scenario. The demonstration video can be\nfound at https://youtu.be/uM4nzkAdGlM.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.DB",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.16868v1",
    "published_date": "2025-02-24 06:10:49 UTC",
    "updated_date": "2025-02-24 06:10:49 UTC"
  },
  {
    "arxiv_id": "2502.16866v1",
    "title": "Toward Agentic AI: Generative Information Retrieval Inspired Intelligent Communications and Networking",
    "authors": [
      "Ruichen Zhang",
      "Shunpu Tang",
      "Yinqiu Liu",
      "Dusit Niyato",
      "Zehui Xiong",
      "Sumei Sun",
      "Shiwen Mao",
      "Zhu Han"
    ],
    "abstract": "The increasing complexity and scale of modern telecommunications networks\ndemand intelligent automation to enhance efficiency, adaptability, and\nresilience. Agentic AI has emerged as a key paradigm for intelligent\ncommunications and networking, enabling AI-driven agents to perceive, reason,\ndecide, and act within dynamic networking environments. However, effective\ndecision-making in telecom applications, such as network planning, management,\nand resource allocation, requires integrating retrieval mechanisms that support\nmulti-hop reasoning, historical cross-referencing, and compliance with evolving\n3GPP standards. This article presents a forward-looking perspective on\ngenerative information retrieval-inspired intelligent communications and\nnetworking, emphasizing the role of knowledge acquisition, processing, and\nretrieval in agentic AI for telecom systems. We first provide a comprehensive\nreview of generative information retrieval strategies, including traditional\nretrieval, hybrid retrieval, semantic retrieval, knowledge-based retrieval, and\nagentic contextual retrieval. We then analyze their advantages, limitations,\nand suitability for various networking scenarios. Next, we present a survey\nabout their applications in communications and networking. Additionally, we\nintroduce an agentic contextual retrieval framework to enhance telecom-specific\nplanning by integrating multi-source retrieval, structured reasoning, and\nself-reflective validation. Experimental results demonstrate that our framework\nsignificantly improves answer accuracy, explanation consistency, and retrieval\nefficiency compared to traditional and semantic retrieval methods. Finally, we\noutline future research directions.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16866v1",
    "published_date": "2025-02-24 06:02:25 UTC",
    "updated_date": "2025-02-24 06:02:25 UTC"
  },
  {
    "arxiv_id": "2502.16857v1",
    "title": "Sarang at DEFACTIFY 4.0: Detecting AI-Generated Text Using Noised Data and an Ensemble of DeBERTa Models",
    "authors": [
      "Avinash Trivedi",
      "Sangeetha Sivanesan"
    ],
    "abstract": "This paper presents an effective approach to detect AI-generated text,\ndeveloped for the Defactify 4.0 shared task at the fourth workshop on\nmultimodal fact checking and hate speech detection. The task consists of two\nsubtasks: Task-A, classifying whether a text is AI generated or human written,\nand Task-B, classifying the specific large language model that generated the\ntext. Our team (Sarang) achieved the 1st place in both tasks with F1 scores of\n1.0 and 0.9531, respectively. The methodology involves adding noise to the\ndataset to improve model robustness and generalization. We used an ensemble of\nDeBERTa models to effectively capture complex patterns in the text. The result\nindicates the effectiveness of our noise-driven and ensemble-based approach,\nsetting a new standard in AI-generated text detection and providing guidance\nfor future developments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI-25 DEFACTIFY 4.0 Workshop AI generated text detection (1st Rank)",
    "pdf_url": "http://arxiv.org/pdf/2502.16857v1",
    "published_date": "2025-02-24 05:32:00 UTC",
    "updated_date": "2025-02-24 05:32:00 UTC"
  },
  {
    "arxiv_id": "2502.16852v1",
    "title": "Improving LLM General Preference Alignment via Optimistic Online Mirror Descent",
    "authors": [
      "Yuheng Zhang",
      "Dian Yu",
      "Tao Ge",
      "Linfeng Song",
      "Zhichen Zeng",
      "Haitao Mi",
      "Nan Jiang",
      "Dong Yu"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated remarkable\neffectiveness in aligning large language models (LLMs) with human preferences.\nMany existing alignment approaches rely on the Bradley-Terry (BT) model\nassumption, which assumes the existence of a ground-truth reward for each\nprompt-response pair. However, this assumption can be overly restrictive when\nmodeling complex human preferences. In this paper, we drop the BT model\nassumption and study LLM alignment under general preferences, formulated as a\ntwo-player game. Drawing on theoretical insights from learning in games, we\nintegrate optimistic online mirror descent into our alignment framework to\napproximate the Nash policy. Theoretically, we demonstrate that our approach\nachieves an $O(T^{-1})$ bound on the duality gap, improving upon the previous\n$O(T^{-1/2})$ result. More importantly, we implement our method and show\nthrough experiments that it outperforms state-of-the-art RLHF algorithms across\nmultiple representative benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16852v1",
    "published_date": "2025-02-24 05:24:52 UTC",
    "updated_date": "2025-02-24 05:24:52 UTC"
  },
  {
    "arxiv_id": "2502.16848v1",
    "title": "PulseBat: A field-accessible dataset for second-life battery diagnostics from realistic histories using multidimensional rapid pulse test",
    "authors": [
      "Shengyu Tao",
      "Guangyuan Ma",
      "Huixiong Yang",
      "Minyan Lu",
      "Guodan Wei",
      "Guangmin Zhou",
      "Xuan Zhang"
    ],
    "abstract": "As electric vehicles (EVs) approach the end of their operational life, their\nbatteries retain significant economic value and present promising opportunities\nfor second-life use and material recycling. This is particularly compelling for\nGlobal South and other underdeveloped regions, where reliable energy storage is\nvital to addressing critical challenges posed by weak and even nonexistent\npower grid and energy infrastructures. However, despite this potential,\nwidespread adoption has been hindered by critical uncertainties surrounding the\ntechnical performance, safety, and recertification of second-life batteries. In\ncases where they have been redeployed, mismatches between estimated and actual\nperformance often render batteries technically unsuitable or hazardous, turning\nthem into liabilities for communities they were intended to benefit. This\nconsiderable misalignment exacerbates energy access disparities and undermines\nthe broader vision of energy justice, highlighting an urgent need for robust\nand scalable solutions to unlock the potential. In the PulseBat Dataset, the\nauthors tested 464 retired lithium-ion batteries, covering 3 cathode material\ntypes, 6 historical usages, 3 physical formats, and 6 capacity designs. The\npulse test experiments were performed repeatedly for each second-life battery\nwith 10 pulse width, 10 pulse magnitude, multiple state-of-charge, and\nstate-of-health conditions, e.g., from 0.37 to 1.03. The PulseBat Dataset\nrecorded these test conditions and the voltage response as well as the\ntemperature signals that were subject to the injected pulse current, which\ncould be used as a valuable data resource for critical diagnostics tasks such\nas state-of-charge estimation, state-of-health estimation, cathode material\ntype identification, open-circuit voltage reconstruction, thermal management,\nand beyond.",
    "categories": [
      "cs.AI",
      "physics.comp-ph",
      "J.2; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended data descriptor of Nat Commun 15, 10154 (2024),\n  https://doi.org/10.1038/s41467-024-54454-0",
    "pdf_url": "http://arxiv.org/pdf/2502.16848v1",
    "published_date": "2025-02-24 05:10:04 UTC",
    "updated_date": "2025-02-24 05:10:04 UTC"
  },
  {
    "arxiv_id": "2502.16847v1",
    "title": "Characterizing Structured versus Unstructured Environments based on Pedestrians' and Vehicles' Motion Trajectories",
    "authors": [
      "Mahsa Golchoubian",
      "Moojan Ghafurian",
      "Nasser Lashgarian Azad",
      "Kerstin Dautenhahn"
    ],
    "abstract": "Trajectory behaviours of pedestrians and vehicles operating close to each\nother can be different in unstructured compared to structured environments.\nThese differences in the motion behaviour are valuable to be considered in the\ntrajectory prediction algorithm of an autonomous vehicle. However, the\navailable datasets on pedestrians' and vehicles' trajectories that are commonly\nused as benchmarks for trajectory prediction have not been classified based on\nthe nature of their environment. On the other hand, the definitions provided\nfor unstructured and structured environments are rather qualitative and hard to\nbe used for justifying the type of a given environment. In this paper, we have\ncompared different existing datasets based on a couple of extracted trajectory\nfeatures, such as mean speed and trajectory variability. Through K-means\nclustering and generalized linear models, we propose more quantitative measures\nfor distinguishing the two different types of environments. Our results show\nthat features such as trajectory variability, stop fraction and density of\npedestrians are different among the two environmental types and can be used to\nclassify the existing datasets.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16847v1",
    "published_date": "2025-02-24 05:09:21 UTC",
    "updated_date": "2025-02-24 05:09:21 UTC"
  },
  {
    "arxiv_id": "2503.16461v1",
    "title": "Rank-O-ToM: Unlocking Emotional Nuance Ranking to Enhance Affective Theory-of-Mind",
    "authors": [
      "JiHyun Kim",
      "JuneHyoung Kwon",
      "MiHyeon Kim",
      "Eunju Lee",
      "YoungBin Kim"
    ],
    "abstract": "Facial Expression Recognition (FER) plays a foundational role in enabling AI\nsystems to interpret emotional nuances, a critical aspect of affective Theory\nof Mind (ToM). However, existing models often struggle with poor calibration\nand a limited capacity to capture emotional intensity and complexity. To\naddress this, we propose Ranking the Emotional Nuance for Theory of Mind\n(Rank-O-ToM), a framework that leverages ordinal ranking to align confidence\nlevels with the emotional spectrum. By incorporating synthetic samples\nreflecting diverse affective complexities, Rank-O-ToM enhances the nuanced\nunderstanding of emotions, advancing AI's ability to reason about affective\nstates.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to AAAI 2025 Theory of Mind for AI (ToM4AI) Workshop\n  (Spotlight) JiHyun Kim, JuneHyoung Kwon, MiHyeon Kim, and Eunju Lee\n  contributed equally as co-first authors. YoungBin Kim is the corresponding\n  author",
    "pdf_url": "http://arxiv.org/pdf/2503.16461v1",
    "published_date": "2025-02-24 05:04:40 UTC",
    "updated_date": "2025-02-24 05:04:40 UTC"
  },
  {
    "arxiv_id": "2502.16841v1",
    "title": "Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives",
    "authors": [
      "Dilermando Queiroz",
      "Anderson Carlos",
      "André Anjos",
      "Lilian Berton"
    ],
    "abstract": "Ensuring equitable Artificial Intelligence (AI) in healthcare demands systems\nthat make unbiased decisions across all demographic groups, bridging technical\ninnovation with ethical principles. Foundation Models (FMs), trained on vast\ndatasets through self-supervised learning, enable efficient adaptation across\nmedical imaging tasks while reducing dependency on labeled data. These models\ndemonstrate potential for enhancing fairness, though significant challenges\nremain in achieving consistent performance across demographic groups. Our\nreview indicates that effective bias mitigation in FMs requires systematic\ninterventions throughout all stages of development. While previous approaches\nfocused primarily on model-level bias mitigation, our analysis reveals that\nfairness in FMs requires integrated interventions throughout the development\npipeline, from data documentation to deployment protocols. This comprehensive\nframework advances current knowledge by demonstrating how systematic bias\nmitigation, combined with policy engagement, can effectively address both\ntechnical and institutional barriers to equitable AI in healthcare. The\ndevelopment of equitable FMs represents a critical step toward democratizing\nadvanced healthcare technologies, particularly for underserved populations and\nregions with limited medical infrastructure and computational resources.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16841v1",
    "published_date": "2025-02-24 04:54:49 UTC",
    "updated_date": "2025-02-24 04:54:49 UTC"
  },
  {
    "arxiv_id": "2502.16840v1",
    "title": "In-context learning of evolving data streams with tabular foundational models",
    "authors": [
      "Afonso Lourenço",
      "João Gama",
      "Eric P. Xing",
      "Goreti Marreiros"
    ],
    "abstract": "State-of-the-art data stream mining in supervised classification has\ntraditionally relied on ensembles of incremental decision trees. However, the\nemergence of large tabular models, i.e., transformers designed for structured\nnumerical data, marks a significant paradigm shift. These models move beyond\ntraditional weight updates, instead employing in-context learning through\nprompt tuning. By using on-the-fly sketches to summarize unbounded streaming\ndata, one can feed this information into a pre-trained model for efficient\nprocessing. This work bridges advancements from both areas, highlighting how\ntransformers' implicit meta-learning abilities, pre-training on drifting\nnatural data, and reliance on context optimization directly address the core\nchallenges of adaptive learning in dynamic environments. Exploring real-time\nmodel adaptation, this research demonstrates that TabPFN, coupled with a simple\nsliding memory strategy, consistently outperforms ensembles of Hoeffding trees\nacross all non-stationary benchmarks. Several promising research directions are\noutlined in the paper. The authors urge the community to explore these ideas,\noffering valuable opportunities to advance in-context stream learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16840v1",
    "published_date": "2025-02-24 04:52:35 UTC",
    "updated_date": "2025-02-24 04:52:35 UTC"
  },
  {
    "arxiv_id": "2502.16834v1",
    "title": "A Novel Multi-Task Teacher-Student Architecture with Self-Supervised Pretraining for 48-Hour Vasoactive-Inotropic Trend Analysis in Sepsis Mortality Prediction",
    "authors": [
      "Houji Jin",
      "Negin Ashrafi",
      "Kamiar Alaei",
      "Elham Pishgar",
      "Greg Placencia",
      "Maryam Pishgar"
    ],
    "abstract": "Sepsis is a major cause of ICU mortality, where early recognition and\neffective interventions are essential for improving patient outcomes. However,\nthe vasoactive-inotropic score (VIS) varies dynamically with a patient's\nhemodynamic status, complicated by irregular medication patterns, missing data,\nand confounders, making sepsis prediction challenging. To address this, we\npropose a novel Teacher-Student multitask framework with self-supervised VIS\npretraining via a Masked Autoencoder (MAE). The teacher model performs\nmortality classification and severity-score regression, while the student\ndistills robust time-series representations, enhancing adaptation to\nheterogeneous VIS data. Compared to LSTM-based methods, our approach achieves\nan AUROC of 0.82 on MIMIC-IV 3.0 (9,476 patients), outperforming the baseline\n(0.74). SHAP analysis revealed that SOFA score (0.147) had the greatest impact\non ICU mortality, followed by LODS (0.033), single marital status (0.031), and\nMedicaid insurance (0.023), highlighting the role of sociodemographic factors.\nSAPSII (0.020) also contributed significantly. These findings suggest that both\nclinical and social factors should be considered in ICU decision-making. Our\nnovel multitask and distillation strategies enable earlier identification of\nhigh-risk patients, improving prediction accuracy and disease management,\noffering new tools for ICU decision support.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16834v1",
    "published_date": "2025-02-24 04:38:59 UTC",
    "updated_date": "2025-02-24 04:38:59 UTC"
  },
  {
    "arxiv_id": "2502.16828v1",
    "title": "Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning",
    "authors": [
      "Ruikun Li",
      "Huandong Wang",
      "Qingmin Liao",
      "Yong Li"
    ],
    "abstract": "Energy landscapes play a crucial role in shaping dynamics of many real-world\ncomplex systems. System evolution is often modeled as particles moving on a\nlandscape under the combined effect of energy-driven drift and noise-induced\ndiffusion, where the energy governs the long-term motion of the particles.\nEstimating the energy landscape of a system has been a longstanding\ninterdisciplinary challenge, hindered by the high operational costs or the\ndifficulty of obtaining supervisory signals. Therefore, the question of how to\ninfer the energy landscape in the absence of true energy values is critical. In\nthis paper, we propose a physics-informed self-supervised learning method to\nlearn the energy landscape from the evolution trajectories of the system. It\nfirst maps the system state from the observation space to a discrete landscape\nspace by an adaptive codebook, and then explicitly integrates energy into the\ngraph neural Fokker-Planck equation, enabling the joint learning of energy\nestimation and evolution prediction. Experimental results across\ninterdisciplinary systems demonstrate that our estimated energy has a\ncorrelation coefficient above 0.9 with the ground truth, and evolution\nprediction accuracy exceeds the baseline by an average of 17.65\\%. The code is\navailable at github.com/tsinghua-fib-lab/PESLA.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16828v1",
    "published_date": "2025-02-24 04:26:26 UTC",
    "updated_date": "2025-02-24 04:26:26 UTC"
  },
  {
    "arxiv_id": "2502.16820v2",
    "title": "Uncertainty Quantification of Large Language Models through Multi-Dimensional Responses",
    "authors": [
      "Tiejin Chen",
      "Xiaoou Liu",
      "Longchao Da",
      "Jia Chen",
      "Vagelis Papalexakis",
      "Hua Wei"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks due to large training datasets and powerful transformer\narchitecture. However, the reliability of responses from LLMs remains a\nquestion. Uncertainty quantification (UQ) of LLMs is crucial for ensuring their\nreliability, especially in areas such as healthcare, finance, and\ndecision-making. Existing UQ methods primarily focus on semantic similarity,\noverlooking the deeper knowledge dimensions embedded in responses. We introduce\na multi-dimensional UQ framework that integrates semantic and knowledge-aware\nsimilarity analysis. By generating multiple responses and leveraging auxiliary\nLLMs to extract implicit knowledge, we construct separate similarity matrices\nand apply tensor decomposition to derive a comprehensive uncertainty\nrepresentation. This approach disentangles overlapping information from both\nsemantic and knowledge dimensions, capturing both semantic variations and\nfactual consistency, leading to more accurate UQ. Our empirical evaluations\ndemonstrate that our method outperforms existing techniques in identifying\nuncertain responses, offering a more robust framework for enhancing LLM\nreliability in high-stakes applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16820v2",
    "published_date": "2025-02-24 04:05:08 UTC",
    "updated_date": "2025-02-25 05:03:51 UTC"
  },
  {
    "arxiv_id": "2502.16813v1",
    "title": "Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns",
    "authors": [
      "Yuxiang Guo",
      "Yuren Mao",
      "Zhonghao Hu",
      "Lu Chen",
      "Yunjun Gao"
    ],
    "abstract": "Semantic join discovery, which aims to find columns in a table repository\nwith high semantic joinabilities to a query column, is crucial for dataset\ndiscovery. Existing methods can be divided into two categories: cell-level\nmethods and column-level methods. However, neither of them ensures both\neffectiveness and efficiency simultaneously. Cell-level methods, which compute\nthe joinability by counting cell matches between columns, enjoy ideal\neffectiveness but suffer poor efficiency. In contrast, column-level methods,\nwhich determine joinability only by computing the similarity of column\nembeddings, enjoy proper efficiency but suffer poor effectiveness due to the\nissues occurring in their column embeddings: (i) semantics-joinability-gap,\n(ii) size limit, and (iii) permutation sensitivity. To address these issues,\nthis paper proposes to compute column embeddings via proxy columns;\nfurthermore, a novel column-level semantic join discovery framework, Snoopy, is\npresented, leveraging proxy-column-based embeddings to bridge effectiveness and\nefficiency. Specifically, the proposed column embeddings are derived from the\nimplicit column-to-proxy-column relationships, which are captured by the\nlightweight approximate-graph-matching-based column projection.To acquire good\nproxy columns for guiding the column projection, we introduce a rank-aware\ncontrastive learning paradigm. Extensive experiments on four real-world\ndatasets demonstrate that Snoopy outperforms SOTA column-level methods by 16%\nin Recall@25 and 10% in NDCG@25, and achieves superior efficiency--being at\nleast 5 orders of magnitude faster than cell-level solutions, and 3.5x faster\nthan existing column-level methods.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted by TKDE",
    "pdf_url": "http://arxiv.org/pdf/2502.16813v1",
    "published_date": "2025-02-24 03:48:00 UTC",
    "updated_date": "2025-02-24 03:48:00 UTC"
  },
  {
    "arxiv_id": "2502.16810v1",
    "title": "Grounded Persuasive Language Generation for Automated Marketing",
    "authors": [
      "Jibang Wu",
      "Chenghao Yang",
      "Simon Mahns",
      "Chaoqi Wang",
      "Hao Zhu",
      "Fei Fang",
      "Haifeng Xu"
    ],
    "abstract": "This paper develops an agentic framework that employs large language models\n(LLMs) to automate the generation of persuasive and grounded marketing content,\nusing real estate listing descriptions as our focal application domain. Our\nmethod is designed to align the generated content with user preferences while\nhighlighting useful factual attributes. This agent consists of three key\nmodules: (1) Grounding Module, mimicking expert human behavior to predict\nmarketable features; (2) Personalization Module, aligning content with user\npreferences; (3) Marketing Module, ensuring factual accuracy and the inclusion\nof localized features. We conduct systematic human-subject experiments in the\ndomain of real estate marketing, with a focus group of potential house buyers.\nThe results demonstrate that marketing descriptions generated by our approach\nare preferred over those written by human experts by a clear margin. Our\nfindings suggest a promising LLM-based agentic framework to automate\nlarge-scale targeted marketing while ensuring responsible generation using only\nfacts.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16810v1",
    "published_date": "2025-02-24 03:36:57 UTC",
    "updated_date": "2025-02-24 03:36:57 UTC"
  },
  {
    "arxiv_id": "2502.16809v1",
    "title": "CRTrack: Low-Light Semi-Supervised Multi-object Tracking Based on Consistency Regularization",
    "authors": [
      "Zijing Zhao",
      "Jianlong Yu",
      "Lin Zhang",
      "Shunli Zhang"
    ],
    "abstract": "Multi-object tracking under low-light environments is prevalent in real life.\nRecent years have seen rapid development in the field of multi-object tracking.\nHowever, due to the lack of datasets and the high cost of annotations,\nmulti-object tracking under low-light environments remains a persistent\nchallenge. In this paper, we focus on multi-object tracking under low-light\nconditions. To address the issues of limited data and the lack of dataset, we\nfirst constructed a low-light multi-object tracking dataset (LLMOT). This\ndataset comprises data from MOT17 that has been enhanced for nighttime\nconditions as well as multiple unannotated low-light videos. Subsequently, to\ntackle the high annotation costs and address the issue of image quality\ndegradation, we propose a semi-supervised multi-object tracking method based on\nconsistency regularization named CRTrack. First, we calibrate a consistent\nadaptive sampling assignment to replace the static IoU-based strategy, enabling\nthe semi-supervised tracking method to resist noisy pseudo-bounding boxes.\nThen, we design a adaptive semi-supervised network update method, which\neffectively leverages unannotated data to enhance model performance. Dataset\nand Code: https://github.com/ZJZhao123/CRTrack.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16809v1",
    "published_date": "2025-02-24 03:35:38 UTC",
    "updated_date": "2025-02-24 03:35:38 UTC"
  },
  {
    "arxiv_id": "2502.16804v1",
    "title": "Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances",
    "authors": [
      "Yaozu Wu",
      "Dongyuan Li",
      "Yankai Chen",
      "Renhe Jiang",
      "Henry Peng Zou",
      "Liancheng Fang",
      "Zhen Wang",
      "Philip S. Yu"
    ],
    "abstract": "Autonomous Driving Systems (ADSs) are revolutionizing transportation by\nreducing human intervention, improving operational efficiency, and enhancing\nsafety. Large Language Models (LLMs), known for their exceptional planning and\nreasoning capabilities, have been integrated into ADSs to assist with driving\ndecision-making. However, LLM-based single-agent ADSs face three major\nchallenges: limited perception, insufficient collaboration, and high\ncomputational demands. To address these issues, recent advancements in\nLLM-based multi-agent ADSs have focused on improving inter-agent communication\nand cooperation. This paper provides a frontier survey of LLM-based multi-agent\nADSs. We begin with a background introduction to related concepts, followed by\na categorization of existing LLM-based approaches based on different agent\ninteraction modes. We then discuss agent-human interactions in scenarios where\nLLM-based agents engage with humans. Finally, we summarize key applications,\ndatasets, and challenges in this field to support future research\n(https://anonymous.4open.science/r/LLM-based_Multi-agent_ADS-3A5C/README.md).",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16804v1",
    "published_date": "2025-02-24 03:26:13 UTC",
    "updated_date": "2025-02-24 03:26:13 UTC"
  },
  {
    "arxiv_id": "2502.16802v2",
    "title": "Unsupervised Topic Models are Data Mixers for Pre-training Language Models",
    "authors": [
      "Jiahui Peng",
      "Xinlin Zhuang",
      "Qiu Jiantao",
      "Ren Ma",
      "Jing Yu",
      "Tianyi Bai",
      "Conghui He"
    ],
    "abstract": "The performance of large language models (LLMs) is significantly affected by\nthe quality and composition of their pre-training data, which is inherently\ndiverse, spanning various domains, sources, and topics. Effectively integrating\nthese heterogeneous data sources is crucial for optimizing LLM performance.\nPrevious research has predominantly concentrated on domain-based data mixing,\noften neglecting the nuanced topic-level characteristics of the data. To\naddress this gap, we propose a simple yet effective topic-based data mixing\nstrategy that utilizes fine-grained topics generated through our topic modeling\nmethod, DataWeave. DataWeave employs a multi-stage clustering process to group\nsemantically similar documents and utilizes LLMs to generate detailed topics,\nthereby facilitating a more nuanced understanding of dataset composition. Our\nstrategy employs heuristic methods to upsample or downsample specific topics,\nwhich significantly enhances LLM performance on downstream tasks, achieving\nsuperior results compared to previous, more complex data mixing approaches.\nFurthermore, we confirm that the topics Science and Relationships are\nparticularly effective, yielding the most substantial performance improvements.\nWe will make our code and datasets publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages,7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16802v2",
    "published_date": "2025-02-24 03:25:56 UTC",
    "updated_date": "2025-03-05 06:23:22 UTC"
  },
  {
    "arxiv_id": "2502.16796v1",
    "title": "MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions",
    "authors": [
      "Yuxuan Liu",
      "Hongda Sun",
      "Wei Liu",
      "Jian Luan",
      "Bo Du",
      "Rui Yan"
    ],
    "abstract": "Mobile phone agents can assist people in automating daily tasks on their\nphones, which have emerged as a pivotal research spotlight. However, existing\nprocedure-oriented agents struggle with cross-app instructions, due to the\nfollowing challenges: (1) complex task relationships, (2) diverse app\nenvironment, and (3) error propagation and information loss in multi-step\nexecution. Drawing inspiration from object-oriented programming principles, we\nrecognize that object-oriented solutions is more suitable for cross-app\ninstruction. To address these challenges, we propose a self-evolving\nmulti-agent framework named MobileSteward, which integrates multiple\napp-oriented StaffAgents coordinated by a centralized StewardAgent. We design\nthree specialized modules in MobileSteward: (1) Dynamic Recruitment generates a\nscheduling graph guided by information flow to explicitly associate tasks among\napps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each\nequipped with app-specialized expertise to address the diversity between apps.\n(3) Adjusted Evaluation conducts evaluation to provide reflection tips or\ndeliver key information, which alleviates error propagation and information\nloss during multi-step execution. To continuously improve the performance of\nMobileSteward, we develop a Memory-based Self-evolution mechanism, which\nsummarizes the experience from successful execution, to improve the performance\nof MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench)\nin the real-world environment to evaluate the agents' capabilities of solving\ncomplex cross-app instructions. Experimental results demonstrate that\nMobileSteward achieves the best performance compared to both single-agent and\nmulti-agent frameworks, highlighting the superiority of MobileSteward in better\nhandling user instructions with diverse complexity.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted by KDD2025 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2502.16796v1",
    "published_date": "2025-02-24 03:12:45 UTC",
    "updated_date": "2025-02-24 03:12:45 UTC"
  },
  {
    "arxiv_id": "2502.16794v2",
    "title": "AAD-LLM: Neural Attention-Driven Auditory Scene Understanding",
    "authors": [
      "Xilin Jiang",
      "Sukru Samet Dindar",
      "Vishal Choudhari",
      "Stephan Bickel",
      "Ashesh Mehta",
      "Guy M McKhann",
      "Daniel Friedman",
      "Adeen Flinker",
      "Nima Mesgarani"
    ],
    "abstract": "Auditory foundation models, including auditory large language models (LLMs),\nprocess all sound inputs equally, independent of listener perception. However,\nhuman auditory perception is inherently selective: listeners focus on specific\nspeakers while ignoring others in complex auditory scenes. Existing models do\nnot incorporate this selectivity, limiting their ability to generate\nperception-aligned responses. To address this, we introduce Intention-Informed\nAuditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM\n(AAD-LLM), a prototype system that integrates brain signals to infer listener\nattention. AAD-LLM extends an auditory LLM by incorporating intracranial\nelectroencephalography (iEEG) recordings to decode which speaker a listener is\nattending to and refine responses accordingly. The model first predicts the\nattended speaker from neural activity, then conditions response generation on\nthis inferred attentional state. We evaluate AAD-LLM on speaker description,\nspeech transcription and extraction, and question answering in multitalker\nscenarios, with both objective and subjective ratings showing improved\nalignment with listener intention. By taking a first step toward\nintention-aware auditory AI, this work explores a new paradigm where listener\nperception informs machine listening, paving the way for future\nlistener-centered auditory systems. Demo and code available:\nhttps://aad-llm.github.io.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16794v2",
    "published_date": "2025-02-24 03:06:45 UTC",
    "updated_date": "2025-03-14 20:46:33 UTC"
  },
  {
    "arxiv_id": "2502.16793v2",
    "title": "VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning",
    "authors": [
      "Yang Chen",
      "Bin Zhou"
    ],
    "abstract": "Graph Neural Networks (GNNs) have gained attention for their ability to learn\nrepresentations from graph data. Due to privacy concerns and conflicts of\ninterest that prevent clients from directly sharing graph data with one\nanother, Vertical Graph Federated Learning (VGFL) frameworks have been\ndeveloped. Recent studies have shown that VGFL is vulnerable to adversarial\nattacks that degrade performance. However, it is a common problem that client\nnodes are often unlabeled in the realm of VGFL. Consequently, the existing\nattacks, which rely on the availability of labeling information to obtain\ngradients, are inherently constrained in their applicability. This limitation\nprecludes their deployment in practical, real-world environments. To address\nthe above problems, we propose a novel graph adversarial attack against VGFL,\nreferred to as VGFL-SA, to degrade the performance of VGFL by modifying the\nlocal clients structure without using labels. Specifically, VGFL-SA uses a\ncontrastive learning method to complete the attack before the local clients are\ntrained. VGFL-SA first accesses the graph structure and node feature\ninformation of the poisoned clients, and generates the contrastive views by\nnode-degree-based edge augmentation and feature shuffling augmentation. Then,\nVGFL-SA uses the shared graph encoder to get the embedding of each view, and\nthe gradients of the adjacency matrices are obtained by the contrastive\nfunction. Finally, perturbed edges are generated using gradient modification\nrules. We validated the performance of VGFL-SA by performing a node\nclassification task on real-world datasets, and the results show that VGFL-SA\nachieves good attack effectiveness and transferability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16793v2",
    "published_date": "2025-02-24 03:04:48 UTC",
    "updated_date": "2025-03-18 15:07:23 UTC"
  },
  {
    "arxiv_id": "2502.16792v1",
    "title": "The Role of Sparsity for Length Generalization in Transformers",
    "authors": [
      "Noah Golowich",
      "Samy Jelassi",
      "David Brandfonbrener",
      "Sham M. Kakade",
      "Eran Malach"
    ],
    "abstract": "Training large language models to predict beyond their training context\nlengths has drawn much attention in recent years, yet the principles driving\nsuch behavior of length generalization remain underexplored. We propose a new\ntheoretical framework to study length generalization for the next-token\nprediction task, as performed by decoder-only transformers. Conceptually, we\nshow that length generalization occurs as long as each predicted token depends\non a small (fixed) number of previous tokens. We formalize such tasks via a\nnotion we call $k$-sparse planted correlation distributions, and show that an\nidealized model of transformers which generalize attention heads successfully\nlength-generalize on such tasks. As a bonus, our theoretical model justifies\ncertain techniques to modify positional embeddings which have been introduced\nto improve length generalization, such as position coupling.\n  We support our theoretical results with experiments on synthetic tasks and\nnatural language, which confirm that a key factor driving length generalization\nis a ``sparse'' dependency structure of each token on the previous ones.\nInspired by our theory, we introduce Predictive Position Coupling, which trains\nthe transformer to predict the position IDs used in a positional coupling\napproach. Predictive Position Coupling thereby allows us to broaden the array\nof tasks to which position coupling can successfully be applied to achieve\nlength generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16792v1",
    "published_date": "2025-02-24 03:01:03 UTC",
    "updated_date": "2025-02-24 03:01:03 UTC"
  },
  {
    "arxiv_id": "2503.00022v1",
    "title": "KVCrush: Key value cache size-reduction using similarity in head-behaviour",
    "authors": [
      "Gopi Krishna Jha",
      "Sameh Gobriel",
      "Liubov Talamanova",
      "Alexander Kozlov",
      "Nilesh Jain"
    ],
    "abstract": "Key-value (KV) caching has emerged as a crucial optimization technique for\naccelerating inference in large language models (LLMs). By allowing the\nattention operation to scale linearly rather than quadratically with the total\nsequence length, KV caching significantly enhances generation throughput.\nHowever, due to large context lengths in the modern LLMs, the memory footprint\nof the KV is a huge bottleneck for model deployment directly impacting the\nmodel's batch size, hindering its ability to deliver high-throughput. Existing\nresearch addresses this challenge using several techniques, such as discarding\nlow-attention tokens, quantization, and matrix approximation which typically\nlead to a negative impact on the model accuracy.\n  In this paper, We propose KVCrush technology which can be combined with many\nKV compression technologies to improve the model accuracy at a much smaller\nmemory. KVCrush provides an alternate representation scheme for key-value\nstates, along with a low-overhead token pruning algorithm that accounts for the\ntoken distribution in the KV cache, which in turn allows for a a smaller\nfootprint while maintaining the accuracy of the model. Based on our results,\nKVCrush reduces LongBench KV Cache size by 4x with less than 1% accuracy drop\nand achieves state-of-the-art average accuracy with minimal overhead, incurring\nless than 0.5% total inference latency. KVCrush not only outperforms the\naccuracy of state-of-the-art importance-based token retention schemes but is\nalso compatible with typical practical LLM deployments using KV cache paging\nschemes such as vLLM and mixed precision quantization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00022v1",
    "published_date": "2025-02-24 02:57:51 UTC",
    "updated_date": "2025-02-24 02:57:51 UTC"
  },
  {
    "arxiv_id": "2502.16789v1",
    "title": "AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay",
    "authors": [
      "Ziyi Tang",
      "Zechuan Chen",
      "Jiarui Yang",
      "Jiayao Mai",
      "Yongsen Zheng",
      "Keze Wang",
      "Jinrui Chen",
      "Liang Lin"
    ],
    "abstract": "Alpha mining, a critical component in quantitative investment, focuses on\ndiscovering predictive signals for future asset returns in increasingly complex\nfinancial markets. However, the pervasive issue of alpha decay, where factors\nlose their predictive power over time, poses a significant challenge for alpha\nmining. Traditional methods like genetic programming face rapid alpha decay\nfrom overfitting and complexity, while approaches driven by Large Language\nModels (LLMs), despite their promise, often rely too heavily on existing\nknowledge, creating homogeneous factors that worsen crowding and accelerate\ndecay. To address this challenge, we propose AlphaAgent, an autonomous\nframework that effectively integrates LLM agents with ad hoc regularizations\nfor mining decay-resistant alpha factors. AlphaAgent employs three key\nmechanisms: (i) originality enforcement through a similarity measure based on\nabstract syntax trees (ASTs) against existing alphas, (ii) hypothesis-factor\nalignment via LLM-evaluated semantic consistency between market hypotheses and\ngenerated factors, and (iii) complexity control via AST-based structural\nconstraints, preventing over-engineered constructions that are prone to\noverfitting. These mechanisms collectively guide the alpha generation process\nto balance originality, financial rationale, and adaptability to evolving\nmarket conditions, mitigating the risk of alpha decay. Extensive evaluations\nshow that AlphaAgent outperforms traditional and LLM-based methods in\nmitigating alpha decay across bull and bear markets, consistently delivering\nsignificant alpha in Chinese CSI 500 and US S&P 500 markets over the past four\nyears. Notably, AlphaAgent showcases remarkable resistance to alpha decay,\nelevating the potential for yielding powerful factors.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.16789v1",
    "published_date": "2025-02-24 02:56:46 UTC",
    "updated_date": "2025-02-24 02:56:46 UTC"
  },
  {
    "arxiv_id": "2502.16779v3",
    "title": "Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model",
    "authors": [
      "Yaxuan Huang",
      "Xili Dai",
      "Jianan Wang",
      "Xianbiao Qi",
      "Yixing Yuan",
      "Xiangyu Yue"
    ],
    "abstract": "Room layout estimation from multiple-perspective images is poorly\ninvestigated due to the complexities that emerge from multi-view geometry,\nwhich requires muti-step solutions such as camera intrinsic and extrinsic\nestimation, image matching, and triangulation. However, in 3D reconstruction,\nthe advancement of recent 3D foundation models such as DUSt3R has shifted the\nparadigm from the traditional multi-step structure-from-motion process to an\nend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, a\nnovel method for multi-view room layout estimation leveraging the 3D foundation\nmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on\na room layout dataset (Structure3D) with a modified objective to estimate\nstructural planes. By generating uniform and parsimonious results, Plane-DUSt3R\nenables room layout estimation with only a single post-processing step and 2D\ndetection results. Unlike previous methods that rely on single-perspective or\npanorama image, Plane-DUSt3R extends the setting to handle multiple-perspective\nimages. Moreover, it offers a streamlined, end-to-end solution that simplifies\nthe process and reduces error accumulation. Experimental results demonstrate\nthat Plane-DUSt3R not only outperforms state-of-the-art methods on the\nsynthetic dataset but also proves robust and effective on in the wild data with\ndifferent image styles such as cartoon. Our code is available at:\nhttps://github.com/justacar/Plane-DUSt3R",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025. Github\n  page:https://github.com/justacar/Plane-DUSt3R",
    "pdf_url": "http://arxiv.org/pdf/2502.16779v3",
    "published_date": "2025-02-24 02:14:19 UTC",
    "updated_date": "2025-03-04 09:24:06 UTC"
  },
  {
    "arxiv_id": "2502.16778v1",
    "title": "The Robustness of Structural Features in Species Interaction Networks",
    "authors": [
      "Sanaz Hasanzadeh Fard",
      "Emily Dolson"
    ],
    "abstract": "Species interaction networks are a powerful tool for describing ecological\ncommunities; they typically contain nodes representing species, and edges\nrepresenting interactions between those species. For the purposes of drawing\nabstract inferences about groups of similar networks, ecologists often use\ngraph topology metrics to summarize structural features. However, gathering the\ndata that underlies these networks is challenging, which can lead to some\ninteractions being missed. Thus, it is important to understand how much\ndifferent structural metrics are affected by missing data. To address this\nquestion, we analyzed a database of 148 real-world bipartite networks\nrepresenting four different types of species interactions (pollination,\nhost-parasite, plant-ant, and seed-dispersal). For each network, we measured\nsix different topological properties: number of connected components, variance\nin node betweenness, variance in node PageRank, largest Eigenvalue, the number\nof non-zero Eigenvalues, and community detection as determined by four\ndifferent algorithms. We then tested how these properties change as additional\nedges -- representing data that may have been missed -- are added to the\nnetworks. We found substantial variation in how robust different properties\nwere to the missing data. For example, the Clauset-Newman-Moore and Louvain\ncommunity detection algorithms showed much more gradual change as edges were\nadded than the label propagation and Girvan-Newman algorithms did, suggesting\nthat the former are more robust. Robustness also varied for some metrics based\non interaction type. These results provide a foundation for selecting network\nproperties to use when analyzing messy ecological network data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16778v1",
    "published_date": "2025-02-24 02:14:17 UTC",
    "updated_date": "2025-02-24 02:14:17 UTC"
  },
  {
    "arxiv_id": "2502.16776v1",
    "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
    "authors": [
      "Zhexin Zhang",
      "Leqi Lei",
      "Junxiao Yang",
      "Xijie Huang",
      "Yida Lu",
      "Shiyao Cui",
      "Renmiao Chen",
      "Qinglin Zhang",
      "Xinyuan Wang",
      "Hao Wang",
      "Hao Li",
      "Xianqi Lei",
      "Chengwei Pan",
      "Lei Sha",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "abstract": "As AI models are increasingly deployed across diverse real-world scenarios,\nensuring their safety remains a critical yet underexplored challenge. While\nsubstantial efforts have been made to evaluate and enhance AI safety, the lack\nof a standardized framework and comprehensive toolkit poses significant\nobstacles to systematic research and practical adoption. To bridge this gap, we\nintroduce AISafetyLab, a unified framework and toolkit that integrates\nrepresentative attack, defense, and evaluation methodologies for AI safety.\nAISafetyLab features an intuitive interface that enables developers to\nseamlessly apply various techniques while maintaining a well-structured and\nextensible codebase for future advancements. Additionally, we conduct empirical\nstudies on Vicuna, analyzing different attack and defense strategies to provide\nvaluable insights into their comparative effectiveness. To facilitate ongoing\nresearch and development in AI safety, AISafetyLab is publicly available at\nhttps://github.com/thu-coai/AISafetyLab, and we are committed to its continuous\nmaintenance and improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.16776v1",
    "published_date": "2025-02-24 02:11:52 UTC",
    "updated_date": "2025-02-24 02:11:52 UTC"
  },
  {
    "arxiv_id": "2502.16770v1",
    "title": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint",
    "authors": [
      "Qianli Ma",
      "Dongrui Liu",
      "Qian Chen",
      "Linfeng Zhang",
      "Jing Shao"
    ],
    "abstract": "Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks\nincurs substantial computational and data costs. While model merging offers a\ntraining-free solution to integrate multiple task-specific models, existing\nmethods suffer from safety-utility conflicts where enhanced general\ncapabilities degrade safety safeguards. We identify two root causes:\n\\textbf{neuron misidentification} due to simplistic parameter magnitude-based\nselection, and \\textbf{cross-task neuron interference} during merging. To\naddress these challenges, we propose \\textbf{LED-Merging}, a three-stage\nframework that \\textbf{L}ocates task-specific neurons via gradient-based\nattribution, dynamically \\textbf{E}lects critical neurons through multi-model\nimportance fusion, and \\textbf{D}isjoints conflicting updates through parameter\nisolation. Extensive experiments on Llama-3-8B, Mistral-7B, and Llama2-13B\ndemonstrate that LED-Merging reduces harmful response rates(\\emph{e.g.}, a\n31.4\\% decrease on Llama-3-8B-Instruct on HarmBench) while preserving 95\\% of\nutility performance(\\emph{e.g.}, 52.39\\% accuracy on GSM8K). LED-Merging\nresolves safety-utility conflicts and provides a lightweight, training-free\nparadigm for constructing reliable multi-task LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16770v1",
    "published_date": "2025-02-24 01:19:43 UTC",
    "updated_date": "2025-02-24 01:19:43 UTC"
  },
  {
    "arxiv_id": "2502.16756v2",
    "title": "Towards Reinforcement Learning for Exploration of Speculative Execution Vulnerabilities",
    "authors": [
      "Evan Lai",
      "Wenjie Xiong",
      "Edward Suh",
      "Mohit Tiwari",
      "Mulong Luo"
    ],
    "abstract": "Speculative attacks such as Spectre can leak secret information without being\ndiscovered by the operating system. Speculative execution vulnerabilities are\nfinicky and deep in the sense that to exploit them, it requires intensive\nmanual labor and intimate knowledge of the hardware. In this paper, we\nintroduce SpecRL, a framework that utilizes reinforcement learning to find\nspeculative execution leaks in post-silicon (black box) microprocessors.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16756v2",
    "published_date": "2025-02-24 00:17:57 UTC",
    "updated_date": "2025-04-03 06:52:24 UTC"
  }
]