{
  "date": "2025-10-26",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-10-26 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹ç°æœ‰æ¶æ„çš„æ·±åº¦åæ€ä¸ä¼˜åŒ–ã€‚**Mixture of Experts (MoE)** çš„æœºç†ç ”ç©¶å–å¾—äº†çªç ´ï¼Œæ­ç¤ºäº†ç¨€ç–æ€§ä¸å•ä¹‰æ€§ï¼ˆmonosemanticityï¼‰çš„å…³ç³»ï¼›**æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰** å¼€å§‹å‘ Encoder-Decoder æ¶æ„æ¼”è¿›ä»¥æå‡æ¨ç†æ•ˆç‡ï¼›**Agent** é¢†åŸŸåˆ™ä»å•çº¯çš„æ„å»ºè½¬å‘äº†å®‰å…¨è¯„ä¼°ã€å·¥ä½œæµæ–¹æ³•è®ºï¼ˆAgentswayï¼‰ä»¥åŠä¸äººç±»å·¥ä½œæ¨¡å¼çš„å¯¹æ¯”ç ”ç©¶ã€‚æ­¤å¤–ï¼Œ3D Gaussian Splatting (3DGS) åœ¨ SLAM å’ŒåŠ¨æ€åœºæ™¯ç”Ÿæˆä¸­çš„åº”ç”¨ä¾ç„¶æ˜¯è®¡ç®—æœºè§†è§‰çš„çƒ­ç‚¹ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦å­¦ä¹ æœºç†ä¸æ–°æ¶æ„ (Mechanisms & Architectures)\n\n**3. æ··åˆä¸“å®¶æ¨¡å‹ä¸­çš„ç¨€ç–æ€§ä¸å åŠ  (Sparsity and Superposition in Mixture of Experts)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šMoE, Superposition, Monosemanticity, Network Sparsity\n*   **ä¸»è¦å‘ç°**ï¼šè¿™ç¯‡è®ºæ–‡æŒ‘æˆ˜äº†æˆ‘ä»¬å¯¹ MoE çš„ä¼ ç»Ÿç†è§£ã€‚ä½œè€…å‘ç°ï¼Œå¹¶éç‰¹å¾ç¨€ç–æ€§å¯¼è‡´äº†æ¨¡å‹çš„ç›¸å˜ï¼Œ**ç½‘ç»œç¨€ç–æ€§ï¼ˆNetwork Sparsityï¼Œå³æ´»è·ƒä¸“å®¶ä¸æ€»ä¸“å®¶çš„æ¯”ä¾‹ï¼‰** æ‰æ˜¯å…³é”®ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ›´é«˜çš„ç½‘ç»œç¨€ç–æ€§ä¼šå¸¦æ¥æ›´å¼ºçš„**å•ä¹‰æ€§ï¼ˆmonosemanticityï¼‰**ï¼Œå³ä¸“å®¶ä¼šè‡ªç„¶åœ°å›´ç»•è¿è´¯çš„ç‰¹å¾ç»„åˆè¿›è¡Œç»„ç»‡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç¨€ç–æ€§è·å¾—æ›´å¯è§£é‡Šçš„æ¨¡å‹ã€‚\n\n**5. ç”¨äºé«˜æ•ˆè®­ç»ƒå’Œæ¨ç†çš„ç¼–ç å™¨-è§£ç å™¨æ‰©æ•£è¯­è¨€æ¨¡å‹ (Encoder-Decoder Diffusion Language Models for Efficient Training and Inference)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šDiscrete Diffusion, Encoder-Decoder, E2D2\n*   **ä¸»è¦å‘ç°**ï¼šç›®å‰çš„ç¦»æ•£æ‰©æ•£æ¨¡å‹å¤šé‡‡ç”¨ä»…è§£ç å™¨ï¼ˆDecoder-onlyï¼‰æ¶æ„ï¼Œè®¡ç®—æˆæœ¬é«˜ã€‚ä½œè€…æå‡º **E2D2** æ¡†æ¶ï¼Œåˆ©ç”¨ç¼–ç å™¨è¡¨ç¤ºå¹²å‡€çš„ Tokenï¼Œè½»é‡çº§è§£ç å™¨é€æ­¥å»å™ªã€‚è¿™ç§æ¶æ„åˆ†ç¦»äº†â€œè¡¨ç¤ºâ€ä¸â€œå»å™ªâ€ä¸¤ç§è®¡ç®—ä»»åŠ¡ï¼Œåœ¨æ‘˜è¦ã€ç¿»è¯‘å’Œæ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šå®ç°äº†ç”Ÿæˆè´¨é‡å’Œæ¨ç†ååé‡çš„æ›´ä¼˜æƒè¡¡ã€‚\n\n**26. è¶…è¶Šè¯­ä¹‰ï¼šæ—¶é—´åå·®å¦‚ä½•å¡‘é€  Transformer å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹ä¸­çš„æ£€ç´¢ (Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šIn-context Learning, Temporal Bias, Induction Heads\n*   **ä¸»è¦å‘ç°**ï¼šç±»ä¼¼äºäººç±»çš„çŸ­æ—¶è®°å¿†ï¼ŒLLM åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­è¡¨ç°å‡ºå¼ºçƒˆçš„æ—¶é—´åå·®ã€‚é€šè¿‡æ§åˆ¶å˜é‡å®éªŒï¼Œä½œè€…å‘ç°æ¨¡å‹å€¾å‘äºå…³æ³¨åºåˆ—å¼€å¤´æˆ–ç»“å°¾çš„ Tokenï¼ˆé¦–å› æ•ˆåº”å’Œè¿‘å› æ•ˆåº”ï¼‰ï¼Œè€Œä¸­é—´çš„ä¿¡æ¯æ£€ç´¢å¾€å¾€ä¸å¯é ã€‚è¿™ç§åå·®åœ¨ Transformer å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä¸­éƒ½å­˜åœ¨ï¼Œä¸”åœ¨ Transformer ä¸­ä¸**å½’çº³å¤´ï¼ˆInduction Headsï¼‰** æœºåˆ¶æœ‰å…³ã€‚\n\n---\n\n### ğŸ¤– æ™ºèƒ½ä½“ä¸æ¨ç† (Agents & Reasoning)\n\n**7. å¾ˆä¹…ä»¥å‰çš„ä¸€ä¸ªè¾“å…¥ï¼šé€šè¿‡é€å®ä¾‹ç¨‹åºåˆæˆè¿›è¡Œæ¨ç† (Once Upon an Input: Reasoning via Per-Instance Program Synthesis)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šPIPS, Program Synthesis, Reasoning\n*   **ä¸»è¦å‘ç°**ï¼šé’ˆå¯¹ LLM åœ¨å¤æ‚å¤šæ­¥æ¨ç†ä¸­çš„ä¸è¶³ï¼Œæå‡ºäº† **PIPS**ã€‚ä¸åŒäº CoT æˆ– PoTï¼ŒPIPS åœ¨å®ä¾‹çº§åˆ«ç”Ÿæˆå¹¶å®Œå–„ç¨‹åºï¼Œåˆ©ç”¨ç»“æ„åŒ–åé¦ˆè€Œæ— éœ€ç‰¹å®šä»»åŠ¡çš„æŒ‡å¯¼ã€‚åœ¨ Big Bench Hard ç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒPIPS ç›¸æ¯” CoT æå‡äº†é«˜è¾¾ 9.4% çš„å‡†ç¡®ç‡ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†æ— æ•ˆç¨‹åºçš„ç”Ÿæˆã€‚\n\n**32. WebATLASï¼šå…·æœ‰ç»éªŒé©±åŠ¨è®°å¿†å’ŒåŠ¨ä½œæ¨¡æ‹Ÿçš„ LLM æ™ºèƒ½ä½“ (WebATLAS: An LLM Agent with Experience-Driven Memory and Action Simulation)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šWeb Navigation, Experience-Driven Memory, Action Simulation\n*   **ä¸»è¦å‘ç°**ï¼šä¸ºäº†è§£å†³ Web Agent åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­çš„è¿·å¤±é—®é¢˜ï¼ŒWebATLAS å¼•å…¥äº†**ç»éªŒé©±åŠ¨çš„è®°å¿†**å’Œ**å‰ç»æ€§åŠ¨ä½œæ¨¡æ‹Ÿ**ã€‚å®ƒé€šè¿‡å¥½å¥‡å¿ƒé©±åŠ¨çš„æ¢ç´¢å»ºç«‹è®¤çŸ¥åœ°å›¾ï¼Œå¹¶åœ¨å®é™…è¡ŒåŠ¨å‰åœ¨è®¤çŸ¥ç©ºé—´ä¸­æ¨¡æ‹Ÿè¯„ä¼°å€™é€‰åŠ¨ä½œã€‚åœ¨ WebArena-Lite åŸºå‡†ä¸Šï¼Œæ— éœ€å¾®è°ƒå³å¯è¾¾åˆ° 63% çš„æˆåŠŸç‡ï¼ˆSOTAï¼‰ã€‚\n\n**51. Agentswayï¼šåŸºäº AI æ™ºèƒ½ä½“å›¢é˜Ÿçš„è½¯ä»¶å¼€å‘æ–¹æ³•è®º (Agentsway -- Software Development Methodology for AI Agents-based Teams)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šSoftware Engineering, Agentic AI, Methodology\n*   **ä¸»è¦å‘ç°**ï¼šä¼ ç»Ÿçš„ Agile æˆ– Kanban æ˜¯ä¸ºäººç±»è®¾è®¡çš„ï¼Œä½†è¿™ç¯‡è®ºæ–‡æå‡ºäº†é¦–ä¸ªä¸“é—¨é’ˆå¯¹ **AI Agent å›¢é˜Ÿ**çš„è½¯ä»¶å¼€å‘æ¡†æ¶ **Agentsway**ã€‚å®ƒå®šä¹‰äº†è§„åˆ’ã€æç¤ºã€ç¼–ç ã€æµ‹è¯•å’Œå¾®è°ƒç­‰ä¸åŒ Agent çš„è§’è‰²ï¼Œå¹¶å¼ºè°ƒäº†éšç§ä¿æŠ¤å’ŒåŸºäºåé¦ˆçš„æŒç»­å¾®è°ƒï¼Œä¸ºæœªæ¥çš„ AI åŸç”Ÿè½¯ä»¶å·¥ç¨‹å¥ å®šäº†æ–¹æ³•è®ºåŸºç¡€ã€‚\n\n**23. AI æ™ºèƒ½ä½“å¦‚ä½•åšäººç±»å·¥ä½œï¼Ÿè·¨èŒä¸šæ¯”è¾ƒ AI ä¸äººç±»çš„å·¥ä½œæµ (How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šWorkflows, Human-AI Comparison\n*   **ä¸»è¦å‘ç°**ï¼šè¿™ç¯‡è®ºæ–‡åšäº†ä¸€ä¸ªéå¸¸æœ‰è¶£çš„ç¤¾ä¼šå­¦/æŠ€æœ¯å¯¹æ¯”ã€‚ç ”ç©¶å‘ç°ï¼Œå³ä½¿åœ¨è®¾è®¡ç­‰å¼€æ”¾å¼ä»»åŠ¡ä¸­ï¼ŒAgent ä¹Ÿå€¾å‘äºä½¿ç”¨**ç¨‹åºåŒ–æ–¹æ³•**ï¼Œè€Œäººç±»åˆ™ä¾èµ– UI äº¤äº’ã€‚è™½ç„¶ Agent çš„äº§å‡ºè´¨é‡ç›®å‰é€šå¸¸ä¸å¦‚äººç±»ï¼Œä¸”å­˜åœ¨æ•°æ®æé€ é—®é¢˜ï¼Œä½†å®ƒä»¬çš„æ•ˆç‡é«˜å‡º 88.3%ï¼Œæˆæœ¬é™ä½ 90% ä»¥ä¸Šï¼Œè¿™æš—ç¤ºäº†æœªæ¥â€œå°†æ˜“ç¼–ç¨‹ä»»åŠ¡å§”æ‰˜ç»™ Agentâ€çš„åä½œæ¨¡å¼ã€‚\n\n---\n\n### ğŸ‘ï¸ å¤šæ¨¡æ€ä¸è®¡ç®—æœºè§†è§‰ (Multimodal & Vision)\n\n**9. é€šè¿‡è®­ç»ƒé…æ–¹çš„è§†è§’é‡æ–°æ€è€ƒ MLLM ä¸­çš„æ–‡è§†æ¨ç†ä¸å¹³è¡¡ (Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šModality Gap, MLLM, Visual Reasoning\n*   **ä¸»è¦å‘ç°**ï¼šç°åœ¨çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰å­˜åœ¨ä¸¥é‡çš„**æ¨¡æ€é¸¿æ²Ÿï¼ˆModality Gapï¼‰**â€”â€”è¿‡åº¦ä¾èµ–æ–‡æœ¬çº¿ç´¢è€Œå¿½è§†è§†è§‰å†…å®¹ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„è®­ç»ƒé…æ–¹å®é™…ä¸Šæ”¾å¤§äº†è¿™ç§ä¸å¹³è¡¡ï¼Œå¹¶æå‡ºäº†é€šè¿‡æ•°æ®ç­›é€‰å’ŒæŸå¤±å‡½æ•°è®¾è®¡æ¥å¼¥åˆè¿™ä¸€é¸¿æ²Ÿçš„ç­–ç•¥ã€‚\n\n**68. STATUS Benchï¼šè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯¹è±¡çŠ¶æ€ç†è§£çš„ä¸¥æ ¼åŸºå‡† (STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šObject State Recognition, VLM Evaluation\n*   **ä¸»è¦å‘ç°**ï¼šVLM çœŸçš„ç†è§£ç‰©ä½“æ˜¯â€œæ‰“å¼€â€è¿˜æ˜¯â€œå…³é—­â€çš„å—ï¼ŸSTATUS Bench é€šè¿‡ä¸¥æ ¼çš„è¯„ä¼°å‘ç°ï¼Œå¤§å¤šæ•°å¼€æº VLM åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œå¯¹ç‰©ä½“çŠ¶æ€å˜åŒ–çš„è¯†åˆ«èƒ½åŠ›ä»…ä¸º**éšæœºçŒœæµ‹æ°´å¹³**ã€‚è¿™æ­ç¤ºäº†å½“å‰ VLM åœ¨ç»†ç²’åº¦çŠ¶æ€ç†è§£ä¸Šçš„å·¨å¤§ç¼ºé™·ã€‚\n\n**44. LVD-GSï¼šé€šè¿‡åˆ†å±‚æ˜¾éšå¼è¡¨ç¤ºåä½œæ¸²æŸ“çš„åŠ¨æ€åœºæ™¯é«˜æ–¯ Splatting SLAM (LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼š3D Gaussian Splatting, SLAM, Dynamic Scenes\n*   **ä¸»è¦å‘ç°**ï¼šé’ˆå¯¹ 3DGS åœ¨åŠ¨æ€æˆ·å¤–åœºæ™¯ä¸­çš„å±€é™ï¼Œæå‡ºäº† LVD-GSã€‚å®ƒå¼•å…¥äº†åˆ†å±‚åä½œè¡¨ç¤ºæ¨¡å—å’ŒåŠ¨æ€æ©ç ç”Ÿæˆï¼ˆç»“åˆ DINO-Depth ä¸ç¡®å®šæ€§ï¼‰ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†åŠ¨æ€ç‰©ä½“çš„å½±å“ï¼Œå®ç°äº†é«˜ä¿çœŸçš„å»ºå›¾ã€‚\n    *   *å…³è”é˜…è¯»*ï¼š**Paper 62 (RoGER-SLAM)** åŒæ ·å…³æ³¨ 3DGS SLAM çš„é²æ£’æ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä½å…‰ç…§å’Œå™ªå£°ç¯å¢ƒã€‚**Paper 90 (DynaPose4D)** åˆ™åˆ©ç”¨ 4DGS ä»å•å¼ é™æ€å›¾åƒç”Ÿæˆé«˜è´¨é‡çš„ 4D åŠ¨æ€å†…å®¹ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ã€å¯¹é½ä¸è¯„ä¼° (Safety, Alignment & Evaluation)\n\n**6. è¯­ä¹‰æ‰‹æœ¯ï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„é›¶æ ·æœ¬æ¦‚å¿µæ“¦é™¤ (Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šConcept Erasure, Diffusion Models, Safety\n*   **ä¸»è¦å‘ç°**ï¼šå¦‚ä½•åœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹è®©æ¨¡å‹â€œå¿˜è®°â€æœ‰å®³æ¦‚å¿µï¼ŸSemantic Surgery ç›´æ¥åœ¨æ–‡æœ¬åµŒå…¥é˜¶æ®µæ“ä½œï¼Œé€šè¿‡åŠ¨æ€ä¼°è®¡æç¤ºä¸­ç›®æ ‡æ¦‚å¿µçš„å­˜åœ¨å¹¶è¿›è¡Œå‘é‡å‡æ³•æ¥ä¸­å’Œå…¶å½±å“ã€‚è¿™ç§æ–¹æ³•æ—¢é«˜æ•ˆåˆä¿ç•™äº†å›¾åƒç”Ÿæˆçš„è´¨é‡ã€‚\n\n**56. æ‰“æ–­ Agent è„Šæ¢ï¼šè¯„ä¼° AI æ™ºèƒ½ä½“ä¸­éª¨å¹² LLM çš„å®‰å…¨æ€§ (Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šAgent Security, Backbone LLM, Threat Snapshots\n*   **ä¸»è¦å‘ç°**ï¼šAgent çš„å®‰å…¨æ€§ä¸ä»…ä»…å–å†³äº Prompt å·¥ç¨‹ï¼Œæ›´å–å†³äºå…¶èƒŒåçš„ **Backbone LLM**ã€‚ä½œè€…æå‡ºäº† **Threat Snapshots** æ¡†æ¶ï¼Œå‘ç°å¢å¼ºæ¨ç†èƒ½åŠ›å¯ä»¥æé«˜å®‰å…¨æ€§ï¼Œä½†æ¨¡å‹è§„æ¨¡ä¸å®‰å…¨æ€§å¹¶ä¸ç›´æ¥ç›¸å…³ã€‚\n\n**54. Sentra-Guardï¼šé’ˆå¯¹å¯¹æŠ—æ€§ LLM è¶Šç‹±çš„å®æ—¶å¤šè¯­è¨€äººæœºé˜²å¾¡æ¡†æ¶ (Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šJailbreak Defense, Prompt Injection, HITL\n*   **ä¸»è¦å‘ç°**ï¼šæå‡ºäº†ä¸€ç§ç»“åˆ SBERT åµŒå…¥å’Œå¾®è°ƒ Transformer åˆ†ç±»å™¨çš„é˜²å¾¡ç³»ç»Ÿï¼Œèƒ½å¤Ÿå®æ—¶æ£€æµ‹è¶Šç‹±æ”»å‡»ã€‚å…¶äº®ç‚¹åœ¨äº**åˆ†ç±»å™¨-æ£€ç´¢å™¨èåˆæ¨¡å—**å’Œå¤šè¯­è¨€é€‚åº”æ€§ï¼Œæ£€æµ‹ç‡é«˜è¾¾ 99.96%ï¼Œä¸”è¯¯æŠ¥ç‡æä½ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ AI ä¸å…¶ä»– (AI for Science & Others)\n\n**1. ä½¿ç”¨ DTW å¢å¼º CNN-GRU æ¨¡å‹çš„é•¿æœŸ PM2.5 é¢„æµ‹ (Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šPM2.5 Forecasting, Dynamic Time Warping, Deep Learning\n*   **ä¸»è¦å‘ç°**ï¼šè¿™æ˜¯é¦–ä¸ªè¯æ˜å¯ä»¥ç¨³å®šè¿›è¡Œ **10å¤©ï¼ˆ240å°æ—¶ï¼‰** PM2.5 é¢„æµ‹ä¸”æ€§èƒ½ä¸è¡°å‡çš„ç ”ç©¶ã€‚é€šè¿‡ç»“åˆåŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰è¿›è¡Œç«™ç‚¹ç›¸ä¼¼æ€§é€‰æ‹©å’Œè½»é‡çº§ CNN-GRUï¼Œåœ¨ç¨€ç–ç›‘æµ‹ç½‘ç»œä¸­å®ç°äº†é«˜ç²¾åº¦é¢„æµ‹ã€‚\n\n**83. é€šè¿‡ LLM å¼•å¯¼çš„è¿›åŒ–æœç´¢åŠ é€Ÿææ–™è®¾è®¡ (Accelerating Materials Design via LLM-Guided Evolutionary Search)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šMaterials Discovery, Evolutionary Search, LLM\n*   **ä¸»è¦å‘ç°**ï¼šæå‡ºäº† **LLEMA** æ¡†æ¶ï¼Œå°† LLM çš„ç§‘å­¦çŸ¥è¯†ä¸è¿›åŒ–ç®—æ³•ç»“åˆã€‚LLM è´Ÿè´£æå‡ºç¬¦åˆæ™¶ä½“å­¦è§„èŒƒçš„å€™é€‰ææ–™ï¼Œç”±è¿›åŒ–è§„åˆ™å’Œè®°å¿†æœºåˆ¶è¿›è¡Œç»†åŒ–ã€‚åœ¨ç”µå­ã€èƒ½æºç­‰14ä¸ªä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å‘ç°çš„ææ–™æ¯”ä¼ ç»Ÿç”Ÿæˆæ–¹æ³•æ›´å…·åŒ–å­¦åˆç†æ€§å’Œçƒ­åŠ›å­¦ç¨³å®šæ€§ã€‚\n\n**86. é‡å­è™šæ—¶æ¼”åŒ–çš„è§£æç†è®º (An Analytic Theory of Quantum Imaginary Time Evolution)**\n*   **æ ¸å¿ƒæœ¯è¯­**ï¼šQuantum Computing, QITE, Variational Quantum Algorithms\n*   **ä¸»è¦å‘ç°**ï¼šä»ç†è®ºä¸Šè¯æ˜äº†**é‡å­è™šæ—¶æ¼”åŒ– (QITE)** ç®—æ³•ç­‰ä»·äºä½¿ç”¨é‡å­è‡ªç„¶æ¢¯åº¦ä¸‹é™ (QNGD) è®­ç»ƒçš„å˜åˆ†é‡å­ç®—æ³•ã€‚ä½œè€…è¯æ˜äº† QITE çš„æ”¶æ•›é€Ÿåº¦æ€»æ˜¯å¿«äºåŸºäºæ¢¯åº¦ä¸‹é™çš„å˜åˆ†ç®—æ³•ï¼Œä¸ºé‡å­ç®—æ³•è®¾è®¡æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚",
  "papers": [
    {
      "arxiv_id": "2510.22863v1",
      "title": "Long-Term PM2.5 Forecasting Using a DTW-Enhanced CNN-GRU Model",
      "title_zh": "åŸºäº DTW å¢å¼ºå‹ CNN-GRU æ¨¡å‹çš„ PM2.5 é•¿æœŸé¢„æµ‹",
      "authors": [
        "Amirali Ataee Naeini",
        "Arshia Ataee Naeini",
        "Fatemeh Karami Mohammadi",
        "Omid Ghaffarpasand"
      ],
      "abstract": "Reliable long-term forecasting of PM2.5 concentrations is critical for public health early-warning systems, yet existing deep learning approaches struggle to maintain prediction stability beyond 48 hours, especially in cities with sparse monitoring networks. This paper presents a deep learning framework that combines Dynamic Time Warping (DTW) for intelligent station similarity selection with a CNN-GRU architecture to enable extended-horizon PM2.5 forecasting in Isfahan, Iran, a city characterized by complex pollution dynamics and limited monitoring coverage. Unlike existing approaches that rely on computationally intensive transformer models or external simulation tools, our method integrates three key innovations: (i) DTW-based historical sampling to identify similar pollution patterns across peer stations, (ii) a lightweight CNN-GRU architecture augmented with meteorological features, and (iii) a scalable design optimized for sparse networks. Experimental validation using multi-year hourly data from eight monitoring stations demonstrates superior performance compared to state-of-the-art deep learning methods, achieving R2 = 0.91 for 24-hour forecasts. Notably, this is the first study to demonstrate stable 10-day PM2.5 forecasting (R2 = 0.73 at 240 hours) without performance degradation, addressing critical early-warning system requirements. The framework's computational efficiency and independence from external tools make it particularly suitable for deployment in resource-constrained urban environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆDynamic Time Warping (DTW)ä¸CNN-GRUæ¶æ„çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç¨€ç–ç›‘æµ‹ç½‘ç»œç¯å¢ƒä¸‹PM2.5æµ“åº¦çš„é•¿æœŸç¨³å®šé¢„æµ‹éš¾é¢˜ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°åˆ©ç”¨åŸºäºDTWçš„å†å²é‡‡æ ·æ¥è¯†åˆ«ä¸åŒç›‘æµ‹ç«™é—´çš„æ±¡æŸ“æ¨¡å¼ç›¸ä¼¼æ€§ï¼Œå¹¶ç»“åˆæ•´åˆäº†æ°”è±¡ç‰¹å¾çš„è½»é‡åŒ–CNN-GRUæ¨¡å‹ï¼Œå®ç°äº†é«˜æ•ˆä¸”å¯æ‰©å±•çš„ç©ºæ°”è´¨é‡é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨24å°æ—¶é¢„æµ‹ä¸­çš„R2è¾¾åˆ°0.91ï¼Œä¸”åœ¨240å°æ—¶ï¼ˆ10å¤©ï¼‰çš„é•¿è·¨åº¦é¢„æµ‹ä¸­ä¾ç„¶ç»´æŒR2ä¸º0.73çš„ç¨³å®šè¡¨ç°ã€‚ç›¸æ¯”äºç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨48å°æ—¶åé¢„æµ‹æ€§èƒ½å¤§å¹…è¡°å‡çš„å±€é™ï¼Œè¯¥ç ”ç©¶é¦–æ¬¡è¯æ˜äº†åœ¨ä¸ä¾èµ–å¤–éƒ¨æ¨¡æ‹Ÿå·¥å…·çš„æƒ…å†µä¸‹å®ç°ç¨³å®š10å¤©é¢„æµ‹çš„å¯è¡Œæ€§ã€‚è¯¥æ¡†æ¶å‡­å€Ÿå…¶å‡ºè‰²çš„è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹ç‹¬ç«‹æ€§ï¼Œä¸ºèµ„æºå—é™åŸå¸‚çš„å…¬å…±å«ç”Ÿé¢„è­¦ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.22863v1",
      "published_date": "2025-10-26 23:04:10 UTC",
      "updated_date": "2025-10-26 23:04:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:43.374336+00:00"
    },
    {
      "arxiv_id": "2510.24783v1",
      "title": "AI & Data Competencies: Scaffolding holistic AI literacy in Higher Education",
      "title_zh": "AIä¸æ•°æ®èƒ½åŠ›ï¼šæ„å»ºé«˜ç­‰æ•™è‚²ä¸­çš„å…¨æ–¹ä½AIç´ å…»",
      "authors": [
        "Kathleen Kennedy",
        "Anuj Gupta"
      ],
      "abstract": "This chapter introduces the AI & Data Acumen Learning Outcomes Framework, a comprehensive tool designed to guide the integration of AI literacy across higher education. Developed through a collaborative process, the framework defines key AI and data-related competencies across four proficiency levels and seven knowledge dimensions. It provides a structured approach for educators to scaffold student learning in AI, balancing technical skills with ethical considerations and sociocultural awareness. The chapter outlines the framework's development process, its structure, and practical strategies for implementation in curriculum design, learning activities, and assessment. We address challenges in implementation and future directions for AI education. By offering a roadmap for developing students' holistic AI literacy, this framework prepares learners to leverage generative AI capabilities in both academic and professional contexts.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† AI & Data Acumen Learning Outcomes Frameworkï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æŒ‡å¯¼é«˜ç­‰æ•™è‚²ä¸­æ•´åˆ AI literacy çš„ç»¼åˆå·¥å…·ã€‚è¯¥æ¡†æ¶é€šè¿‡åä½œå¼€å‘ï¼Œå®šä¹‰äº†æ¶µç›–å››ä¸ª proficiency levels å’Œä¸ƒä¸ª knowledge dimensions çš„å…³é”® AI ä¸æ•°æ®ç›¸å…³èƒ½åŠ›ã€‚å®ƒä¸ºæ•™è‚²è€…æä¾›äº†ä¸€ç§ç»“æ„åŒ–æ–¹æ³•æ¥æ„å»ºå­¦ç”Ÿçš„ AI å­¦ä¹ è·¯å¾„ï¼Œå¹¶åœ¨ technical skillsã€ethical considerations ä¸ sociocultural awareness ä¹‹é—´å–å¾—å¹³è¡¡ã€‚æ–‡ä¸­è¯¦ç»†æ¦‚è¿°äº†è¯¥æ¡†æ¶çš„å¼€å‘è¿‡ç¨‹ã€ç»“æ„ä»¥åŠåœ¨è¯¾ç¨‹è®¾è®¡ã€å­¦ä¹ æ´»åŠ¨å’Œè¯„ä¼°ä¸­çš„å…·ä½“å®æ–½ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ¢è®¨äº†å®æ–½æŒ‘æˆ˜åŠ AI æ•™è‚²çš„æœªæ¥æ–¹å‘ã€‚é€šè¿‡æä¾›å‘å±•å…¨é¢ AI literacy çš„è·¯çº¿å›¾ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨å¸®åŠ©å­¦ä¹ è€…åœ¨å­¦æœ¯å’ŒèŒä¸šèƒŒæ™¯ä¸‹å……åˆ†åˆ©ç”¨ generative AI çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Journal: Thresholds in Education Publisher: Academy for Educational Studies ISSN: 0916-9641 URL to published article: https://academyforeducationalstudies.org/wp-content/uploads/2025/09/kennedy-gupta-final-1.pdf",
      "pdf_url": "https://arxiv.org/pdf/2510.24783v1",
      "published_date": "2025-10-26 22:56:08 UTC",
      "updated_date": "2025-10-26 22:56:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:43.963762+00:00"
    },
    {
      "arxiv_id": "2510.23671v2",
      "title": "Sparsity and Superposition in Mixture of Experts",
      "title_zh": "æ··åˆä¸“å®¶æ¨¡å‹ä¸­çš„ç¨€ç–æ€§ä¸å åŠ ",
      "authors": [
        "Marmik Chaudhari",
        "Jeremi Nuer",
        "Rome Thorstenson"
      ],
      "abstract": "Mixture of Experts (MoE) models have become central to scaling large language models, yet their mechanistic differences from dense networks remain poorly understood. Previous work has explored how dense models use \\textit{superposition} to represent more features than dimensions, and how superposition is a function of feature sparsity and feature importance. MoE models cannot be explained mechanistically through the same lens. We find that neither feature sparsity nor feature importance cause discontinuous phase changes, and that network sparsity (the ratio of active to total experts) better characterizes MoEs. We develop new metrics for measuring superposition across experts. Our findings demonstrate that models with greater network sparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of expert specialization based on monosemantic feature representation rather than load balancing, showing that experts naturally organize around coherent feature combinations when initialized appropriately. These results suggest that network sparsity in MoEs may enable more interpretable models without sacrificing performance, challenging the common assumption that interpretability and capability are fundamentally at odds.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ··åˆä¸“å®¶æ¨¡å‹ (Mixture of Experts, MoE) ä¸ç¨ å¯†ç½‘ç»œåœ¨æœºåˆ¶ä¸Šçš„å·®å¼‚ï¼Œé‡ç‚¹åˆ†æäº† Sparsity å’Œ Superposition åœ¨å…¶ä¸­çš„æ¼”åŒ–è§„å¾‹ã€‚ç ”ç©¶å‘ç°ï¼ŒMoE çš„ä¸è¿ç»­ç›¸å˜ (phase changes) å¹¶éå—ç‰¹å¾ç¨€ç–åº¦æˆ–é‡è¦æ€§é©±åŠ¨ï¼Œè€Œæ˜¯ç”±ç½‘ç»œç¨€ç–åº¦ (network sparsity) è¿™ä¸€å…³é”®æŒ‡æ ‡è¡¨å¾ã€‚é€šè¿‡å¼€å‘è¡¡é‡ä¸“å®¶é—´ Superposition çš„æ–°æŒ‡æ ‡ï¼Œç ”ç©¶è¯æ˜äº†æ›´é«˜çš„ç½‘ç»œç¨€ç–åº¦ä¼šå¸¦æ¥æ›´å¼ºçš„å•ä¹‰æ€§ (monosemanticity)ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå•ä¹‰ç‰¹å¾è¡¨ç¤ºè€Œéè´Ÿè½½å‡è¡¡ (load balancing) çš„ä¸“å®¶ä¸“ä¸šåŒ–æ–°å®šä¹‰ï¼Œæ­ç¤ºäº†ä¸“å®¶åœ¨åˆé€‚åˆå§‹åŒ–ä¸‹ä¼šå›´ç»•è¿è´¯çš„ç‰¹å¾ç»„åˆè¿›è¡Œè‡ªç„¶ç»„ç»‡ã€‚æœ€ç»ˆç»“æœè¡¨æ˜ï¼ŒMoE çš„ç½‘ç»œç¨€ç–åº¦èƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ (interpretability)ï¼Œæœ‰åŠ›æŒ‘æˆ˜äº†å¯è§£é‡Šæ€§ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ ¹æœ¬æƒè¡¡çš„ä¼ ç»Ÿè®¤çŸ¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23671v2",
      "published_date": "2025-10-26 22:44:35 UTC",
      "updated_date": "2025-12-25 06:07:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:47.478866+00:00"
    },
    {
      "arxiv_id": "2510.22859v1",
      "title": "Guardian: Decoupling Exploration from Safety in Reinforcement Learning",
      "title_zh": "Guardianï¼šè§£è€¦å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢ä¸å®‰å…¨",
      "authors": [
        "Kaitong Cai",
        "Jusheng Zhang",
        "Jing Yang",
        "Keze Wang"
      ],
      "abstract": "Hybrid offline--online reinforcement learning (O2O RL) promises both sample efficiency and robust exploration, but suffers from instability due to distribution shift between offline and online data. We introduce RLPD-GX, a framework that decouples policy optimization from safety enforcement: a reward-seeking learner explores freely, while a projection-based guardian guarantees rule-consistent execution and safe value backups. This design preserves the exploratory value of online interactions without collapsing to conservative policies. To further stabilize training, we propose dynamic curricula that gradually extend temporal horizons and anneal offline--online data mixing. We prove convergence via a contraction property of the guarded Bellman operator, and empirically show state-of-the-art performance on Atari-100k, achieving a normalized mean score of 3.02 (+45\\% over prior hybrid methods) with stronger safety and stability. Beyond Atari, ablations demonstrate consistent gains across safety-critical and long-horizon tasks, underscoring the generality of our design. Extensive and comprehensive results highlight decoupled safety enforcement as a simple yet principled route to robust O2O RL, suggesting a broader paradigm for reconciling exploration and safety in reinforcement learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ··åˆç¦»çº¿-åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆHybrid offline--online reinforcement learning, O2O RLï¼‰ä¸­å› åˆ†å¸ƒåç§»ï¼ˆdistribution shiftï¼‰å¯¼è‡´çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œæå‡ºäº† RLPD-GX æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ç­–ç•¥ä¼˜åŒ–ä¸å®‰å…¨ä¿éšœè¿›è¡Œè§£è€¦ï¼Œå…è®¸è´Ÿè´£å¯»æ±‚å¥–åŠ±çš„è®­ç»ƒå™¨è‡ªç”±æ¢ç´¢ï¼ŒåŒæ—¶åˆ©ç”¨åŸºäºæŠ•å½±çš„ Guardian æœºåˆ¶ç¡®ä¿æ‰§è¡Œè¿‡ç¨‹ç¬¦åˆè§„åˆ™å¹¶å®ç°å®‰å…¨çš„çŠ¶æ€å€¼å¤‡ä»½ï¼ˆvalue backupsï¼‰ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†åŠ¨æ€è¯¾ç¨‹å­¦ä¹ ï¼ˆdynamic curriculaï¼‰æ¥é€æ­¥å»¶é•¿ä»»åŠ¡çš„æ—¶é—´æ­¥é•¿ï¼ˆtemporal horizonsï¼‰å¹¶ä¼˜åŒ–æ•°æ®æ··åˆæ¯”ä¾‹ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡è®­ç»ƒç¨³å®šæ€§ã€‚ç†è®ºä¸Šï¼Œç ”ç©¶è¯æ˜äº†å—ä¿æŠ¤çš„ Bellman ç®—å­ï¼ˆguarded Bellman operatorï¼‰å…·æœ‰æ”¶æ•›æ€§ï¼›å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRLPD-GX åœ¨ Atari-100k åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº† 3.02 çš„å½’ä¸€åŒ–å¹³å‡åˆ†ï¼Œè¾ƒä»¥å¾€æ··åˆæ–¹æ³•æå‡äº† 45%ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„å®‰å…¨æ€§èƒ½ã€‚è¯¥ç ”ç©¶ä¸ä»…è¾¾åˆ°äº† state-of-the-art çš„æ°´å¹³ï¼Œè¿˜ä¸ºåœ¨å¼ºåŒ–å­¦ä¹ ä¸­è°ƒå’Œè‡ªç”±æ¢ç´¢ä¸å®‰å…¨æ‰§è¡Œä¹‹é—´çš„çŸ›ç›¾æä¾›äº†ä¸€ç§ç®€æ´ä¸”å…·æœ‰æ™®é€‚æ€§çš„è®¾è®¡èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22859v1",
      "published_date": "2025-10-26 22:25:47 UTC",
      "updated_date": "2025-10-26 22:25:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:51.274776+00:00"
    },
    {
      "arxiv_id": "2510.22852v1",
      "title": "Encoder-Decoder Diffusion Language Models for Efficient Training and Inference",
      "title_zh": "é¢å‘é«˜æ•ˆè®­ç»ƒä¸æ¨ç†çš„ç¼–ç å™¨-è§£ç å™¨æ‰©æ•£è¯­è¨€æ¨¡å‹",
      "authors": [
        "Marianne Arriola",
        "Yair Schiff",
        "Hao Phung",
        "Aaron Gokaslan",
        "Volodymyr Kuleshov"
      ],
      "abstract": "Discrete diffusion models enable parallel token sampling for faster inference than autoregressive approaches. However, prior diffusion models use a decoder-only architecture, which requires sampling algorithms that invoke the full network at every denoising step and incur high computational cost. Our key insight is that discrete diffusion models perform two types of computation: 1) representing clean tokens and 2) denoising corrupted tokens, which enables us to use separate modules for each task. We propose an encoder-decoder architecture to accelerate discrete diffusion inference, which relies on an encoder to represent clean tokens and a lightweight decoder to iteratively refine a noised sequence. We also show that this architecture enables faster training of block diffusion models, which partition sequences into blocks for better quality and are commonly used in diffusion language model inference. We introduce a framework for Efficient Encoder-Decoder Diffusion (E2D2), consisting of an architecture with specialized training and sampling algorithms, and we show that E2D2 achieves superior trade-offs between generation quality and inference throughput on summarization, translation, and mathematical reasoning tasks. We provide the code, model weights, and blog post on the project page: https://m-arriola.com/e2d2",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†E2D2ï¼ˆEfficient Encoder-Decoder Diffusionï¼‰ï¼Œä¸€ç§æ—¨åœ¨æå‡è®­ç»ƒä¸æ¨ç†æ•ˆç‡çš„ç¼–è§£ç å™¨æ‰©æ•£è¯­è¨€æ¨¡å‹æ¶æ„ã€‚é’ˆå¯¹ä¼ ç»Ÿä»…è§£ç å™¨ï¼ˆDecoder-onlyï¼‰ç¦»æ•£æ‰©æ•£æ¨¡å‹åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤éœ€è°ƒç”¨å…¨ç½‘ç»œå¯¼è‡´çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜ï¼Œè¯¥ç ”ç©¶é€šè¿‡åˆ†ç¦»â€œè¡¨ç¤ºæ¸…æ´æ ‡è®°ï¼ˆclean tokensï¼‰â€ä¸â€œå»å™ªæŸåæ ‡è®°ï¼ˆcorrupted tokensï¼‰â€è¿™ä¸¤ç±»è®¡ç®—ä»»åŠ¡ï¼Œå¼•å…¥äº†ç”±ç¼–ç å™¨å’Œè½»é‡çº§è§£ç å™¨ç»„æˆçš„ç³»ç»Ÿã€‚è¯¥æ¶æ„åˆ©ç”¨Encoderè¡¨å¾æ¸…æ´æ•°æ®ï¼Œå¹¶ç”±è½»é‡çº§Decoderè¿›è¡Œè¿­ä»£å»å™ªï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†å¼€é”€ã€‚æ­¤å¤–ï¼ŒE2D2è¿˜åŠ é€Ÿäº†åˆ†å—æ‰©æ•£ï¼ˆblock diffusionï¼‰æ¨¡å‹çš„è®­ç»ƒï¼Œè¯¥æ¨¡å‹é€šè¿‡åºåˆ—åˆ†å—åœ¨æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†ä¸­å®ç°æ›´é«˜è´¨é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒE2D2åœ¨æ–‡æœ¬æ‘˜è¦ã€ç¿»è¯‘åŠæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼Œåœ¨ç”Ÿæˆè´¨é‡ä¸æ¨ç†ååé‡ï¼ˆInference Throughputï¼‰ä¹‹é—´å–å¾—äº†æ›´ä¼˜çš„æƒè¡¡ï¼Œä¸ºé«˜æ•ˆç¦»æ•£æ‰©æ•£æ¨¡å‹çš„ç ”ç©¶æä¾›äº†æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2025. We provide the code at https://github.com/kuleshov-group/e2d2",
      "pdf_url": "https://arxiv.org/pdf/2510.22852v1",
      "published_date": "2025-10-26 22:05:22 UTC",
      "updated_date": "2025-10-26 22:05:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:55.976688+00:00"
    },
    {
      "arxiv_id": "2510.22851v1",
      "title": "Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models",
      "title_zh": "Semantic Surgeryï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„é›¶æ ·æœ¬æ¦‚å¿µæ“¦é™¤",
      "authors": [
        "Lexiang Xiong",
        "Chengyu Liu",
        "Jingwen Ye",
        "Yan Liu",
        "Yuecong Xu"
      ],
      "abstract": "Concept erasure in text-to-image diffusion models is crucial for mitigating harmful content, yet existing methods often compromise generative quality. We introduce Semantic Surgery, a novel training-free, zero-shot framework for concept erasure that operates directly on text embeddings before the diffusion process. It dynamically estimates the presence of target concepts in a prompt and performs a calibrated vector subtraction to neutralize their influence at the source, enhancing both erasure completeness and locality. The framework includes a Co-Occurrence Encoding module for robust multi-concept erasure and a visual feedback loop to address latent concept persistence. As a training-free method, Semantic Surgery adapts dynamically to each prompt, ensuring precise interventions. Extensive experiments on object, explicit content, artistic style, and multi-celebrity erasure tasks show our method significantly outperforms state-of-the-art approaches. We achieve superior completeness and robustness while preserving locality and image quality (e.g., 93.58 H-score in object erasure, reducing explicit content to just 1 instance, and 8.09 H_a in style erasure with no quality degradation). This robustness also allows our framework to function as a built-in threat detection system, offering a practical solution for safer text-to-image generation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Semantic Surgeryï¼Œä¸€ç§ç”¨äºæ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰çš„é›¶æ ·æœ¬ä¸”æ— éœ€è®­ç»ƒçš„æ¦‚å¿µæ“¦é™¤ï¼ˆConcept Erasureï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç›´æ¥åœ¨æ‰©æ•£è¿‡ç¨‹å‰çš„æ–‡æœ¬åµŒå…¥é˜¶æ®µè¿è¡Œï¼Œé€šè¿‡åŠ¨æ€ä¼°ç®—æç¤ºè¯ä¸­çš„ç›®æ ‡æ¦‚å¿µå¹¶æ‰§è¡Œæ ¡å‡†å‘é‡å‡æ³•ï¼Œä»æºå¤´ä¸­å’Œå…¶å½±å“ï¼Œä»è€Œæå‡äº†æ“¦é™¤çš„å®Œæ•´æ€§ä¸å±€éƒ¨æ€§ã€‚å…¶æ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ç”¨äºå¤šæ¦‚å¿µæ“¦é™¤çš„ Co-Occurrence Encoding æ¨¡å—ï¼Œä»¥åŠåº”å¯¹æ½œåœ¨æ¦‚å¿µæŒä¹…åŒ–çš„è§†è§‰åé¦ˆå›è·¯ã€‚åœ¨ç‰©ä½“ã€æ˜¾æ€§å†…å®¹ã€è‰ºæœ¯é£æ ¼å’Œåäººæ“¦é™¤ç­‰ä»»åŠ¡ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼ŒSemantic Surgery åœ¨ä¿æŒå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½ä½œä¸ºå†…ç½®çš„å¨èƒæ£€æµ‹ç³»ç»Ÿè¿è¡Œï¼Œä¸ºå®ç°æ›´å®‰å…¨çš„å›¾åƒç”Ÿæˆæä¾›äº†ç¨³å¥ä¸”é«˜æ•ˆçš„å®ç”¨æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025). Code is available at https://github.com/Lexiang-Xiong/Semantic-Surgery",
      "pdf_url": "https://arxiv.org/pdf/2510.22851v1",
      "published_date": "2025-10-26 22:04:17 UTC",
      "updated_date": "2025-10-26 22:04:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:41:54.362858+00:00"
    },
    {
      "arxiv_id": "2510.22849v1",
      "title": "Once Upon an Input: Reasoning via Per-Instance Program Synthesis",
      "title_zh": "å§‹äºè¾“å…¥ï¼šåŸºäºå•å®ä¾‹ç¨‹åºåˆæˆçš„æ¨ç†",
      "authors": [
        "Adam Stein",
        "Neelay Velingker",
        "Mayur Naik",
        "Eric Wong"
      ],
      "abstract": "Large language models (LLMs) excel at zero-shot inference but continue to struggle with complex, multi-step reasoning. Recent methods that augment LLMs with intermediate reasoning steps such as Chain of Thought (CoT) and Program of Thought (PoT) improve performance but often produce undesirable solutions, especially in algorithmic domains. We introduce Per-Instance Program Synthesis (PIPS), a method that generates and refines programs at the instance-level using structural feedback without relying on task-specific guidance or explicit test cases. To further improve performance, PIPS incorporates a confidence metric that dynamically chooses between direct inference and program synthesis on a per-instance basis. Experiments across three frontier LLMs and 30 benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question answering tasks, relational reasoning tasks, and mathematical reasoning tasks show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and 9.4% compared to PoT and CoT respectively, and reduces undesirable program generations by 65.1% on the algorithmic tasks compared to PoT with Gemini-2.0-Flash.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤æ‚å¤šæ­¥æ¨ç†ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† PIPS (Per-Instance Program Synthesis) æ–¹æ³•ã€‚PIPS æ—¨åœ¨å®ä¾‹çº§åˆ«ç”Ÿæˆå¹¶ç²¾ç‚¼ç¨‹åºï¼Œåˆ©ç”¨ç»“æ„åŒ–åé¦ˆ (structural feedback) è¿›è¡Œè‡ªæˆ‘ä¼˜åŒ–ï¼Œä¸”ä¸ä¾èµ–ä»»åŠ¡ç‰¹å®šçš„æŒ‡å¯¼æˆ–æµ‹è¯•ç”¨ä¾‹ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§ç½®ä¿¡åº¦æŒ‡æ ‡ (confidence metric)ï¼Œå¯æ ¹æ®å…·ä½“è¾“å…¥åŠ¨æ€é€‰æ‹©ç›´æ¥æ¨ç† (direct inference) æˆ–ç¨‹åºåˆæˆ (program synthesis)ã€‚åœ¨åŒ…æ‹¬ Big Bench Extra Hard (BBEH) åœ¨å†…çš„ 30 ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒPIPS çš„è°ƒå’Œå¹³å‡å‡†ç¡®ç‡ç›¸æ¯” PoT å’Œ CoT åˆ†åˆ«æå‡äº† 8.6% å’Œ 9.4%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPIPS åœ¨ç®—æ³•ä»»åŠ¡ä¸­å°†ä¸ç†æƒ³ç¨‹åºçš„ç”Ÿæˆç‡é™ä½äº† 65.1%ï¼Œæœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ã€è§†è§‰é—®ç­”åŠå…³ç³»æ¨ç†ä¸­çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2025. 34 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22849v1",
      "published_date": "2025-10-26 21:58:33 UTC",
      "updated_date": "2025-10-26 21:58:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:06.672607+00:00"
    },
    {
      "arxiv_id": "2510.22840v1",
      "title": "Lyapunov Function-guided Reinforcement Learning for Flight Control",
      "title_zh": "æé›…æ™®è¯ºå¤«å‡½æ•°å¼•å¯¼çš„é£è¡Œæ§åˆ¶å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yifei Li",
        "Erik-Jan van Kampen"
      ],
      "abstract": "A cascaded online learning flight control system has been developed and enhanced with respect to action smoothness. In this paper, we investigate the convergence performance of the control system, characterized by the increment of a Lyapunov function candidate. The derivation of this metric accounts for discretization errors and state prediction errors introduced by the incremental model. Comparative results are presented through flight control simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘å¹¶å¢å¼ºäº†ä¸€ç§çº§è”åœ¨çº¿å­¦ä¹ (cascaded online learning)é£è¡Œæ§åˆ¶ç³»ç»Ÿï¼Œé‡ç‚¹æå‡äº†åŠ¨ä½œå¹³æ»‘æ€§(action smoothness)ã€‚ç ”ç©¶é‡ç‚¹æ¢è®¨äº†è¯¥æ§åˆ¶ç³»ç»Ÿçš„æ”¶æ•›æ€§èƒ½(convergence performance)ï¼Œå¹¶æå‡ºåˆ©ç”¨æé›…æ™®è¯ºå¤«å‡½æ•°å€™é€‰(Lyapunov function candidate)çš„å¢é‡ä½œä¸ºå…¶è¡¨å¾æŒ‡æ ‡ã€‚è¯¥æŒ‡æ ‡çš„æ¨å¯¼è¿‡ç¨‹ç³»ç»Ÿåœ°è€ƒè™‘äº†ç”±å¢é‡æ¨¡å‹(incremental model)å¼•å…¥çš„ç¦»æ•£åŒ–è¯¯å·®(discretization errors)å’ŒçŠ¶æ€é¢„æµ‹è¯¯å·®(state prediction errors)ã€‚æœ€åï¼Œé€šè¿‡é£è¡Œæ§åˆ¶ä»¿çœŸ(flight control simulations)å±•ç¤ºäº†å¯¹æ¯”å®éªŒç»“æœï¼ŒéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨æ”¶æ•›æ€§ä¸æ§åˆ¶ç²¾åº¦æ–¹é¢çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22840v1",
      "published_date": "2025-10-26 21:18:34 UTC",
      "updated_date": "2025-10-26 21:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:03.063360+00:00"
    },
    {
      "arxiv_id": "2510.22836v2",
      "title": "Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes",
      "title_zh": "ä»è®­ç»ƒé…æ–¹è§†è§’é‡æ–°å®¡è§†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡æœ¬-è§†è§‰æ¨ç†å¤±è¡¡",
      "authors": [
        "Guanyu Yao",
        "Qiucheng Wu",
        "Yang Zhang",
        "Zhaowen Wang",
        "Handong Zhao",
        "Shiyu Chang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have demonstrated strong capabilities on vision-and-language tasks. However, recent findings reveal an imbalance in their reasoning capabilities across visual and textual modalities. Specifically, current MLLMs often over-rely on textual cues while under-attending to visual content, resulting in suboptimal performance on tasks that require genuine visual reasoning. We refer to this phenomenon as the \\textit{modality gap}, defined as the performance disparity between text-centric and vision-centric inputs. In this paper, we analyze the modality gap through the lens of training recipes. We first show that existing training recipes tend to amplify this gap. Then, we systematically explore strategies to bridge it from two complementary perspectives: data and loss design. Our findings provide insights into developing training recipes that mitigate the modality gap and promote more balanced multimodal reasoning. Our code is publicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨è§†è§‰ä¸æ–‡æœ¬æ¨¡æ€ä¹‹é—´å­˜åœ¨çš„æ¨ç†èƒ½åŠ›ä¸å¹³è¡¡ç°è±¡ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºâ€œæ¨¡æ€å·®è·â€(modality gap)ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰çš„MLLMså¾€å¾€è¿‡åº¦ä¾èµ–æ–‡æœ¬çº¿ç´¢è€Œå¿½è§†è§†è§‰å†…å®¹ï¼Œå¯¼è‡´åœ¨éœ€è¦çœŸå®è§†è§‰æ¨ç†çš„ä»»åŠ¡ä¸­è¡¨ç°æ¬ ä½³ã€‚ä½œè€…ä»è®­ç»ƒæ–¹æ¡ˆ(training recipes)çš„è§†è§’å¯¹è¯¥é—®é¢˜è¿›è¡Œäº†å‰–æï¼ŒæŒ‡å‡ºå½“å‰çš„è®­ç»ƒæµç¨‹å®é™…ä¸Šæ”¾å¤§äº†è¿™ç§ä¸å¹³è¡¡ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡ç³»ç»Ÿåœ°ä»æ•°æ®(data)å’ŒæŸå¤±è®¾è®¡(loss design)ä¸¤ä¸ªäº’è¡¥ç»´åº¦æ¢ç´¢äº†å¼¥åˆå·®è·çš„ç­–ç•¥ã€‚ç ”ç©¶ç»“æœä¸ºå¼€å‘èƒ½å¤Ÿç¼“è§£æ¨¡æ€å·®è·ã€ä¿ƒè¿›æ›´å‡è¡¡å¤šæ¨¡æ€æ¨ç†çš„è®­ç»ƒæ–¹æ¡ˆæä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22836v2",
      "published_date": "2025-10-26 21:06:13 UTC",
      "updated_date": "2026-01-07 22:24:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:04.897500+00:00"
    },
    {
      "arxiv_id": "2510.22833v1",
      "title": "Toward Agents That Reason About Their Computation",
      "title_zh": "è¿ˆå‘å…·å¤‡è®¡ç®—è¿‡ç¨‹æ¨ç†èƒ½åŠ›çš„æ™ºèƒ½ä½“",
      "authors": [
        "Adrian Orenstein",
        "Jessica Chen",
        "Gwyneth Anne Delos Santos",
        "Bayley Sapara",
        "Michael Bowling"
      ],
      "abstract": "While reinforcement learning agents can achieve superhuman performance in many complex tasks, they typically do not become more computationally efficient as they improve. In contrast, humans gradually require less cognitive effort as they become more proficient at a task. If agents could reason about their compute as they learn, could they similarly reduce their computation footprint? If they could, we could have more energy efficient agents or free up compute cycles for other processes like planning. In this paper, we experiment with showing agents the cost of their computation and giving them the ability to control when they use compute. We conduct our experiments on the Arcade Learning Environment, and our results demonstrate that with the same training compute budget, agents that reason about their compute perform better on 75% of games. Furthermore, these agents use three times less compute on average. We analyze individual games and show where agents gain these efficiencies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ™ºèƒ½ä½“åœ¨æ€§èƒ½æå‡è¿‡ç¨‹ä¸­å¾€å¾€æ— æ³•åƒäººç±»ä¸€æ ·é€æ­¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§è®©æ™ºèƒ½ä½“å¯¹å…¶è®¡ç®—è¿‡ç¨‹è¿›è¡Œæ¨ç†çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å‘æ™ºèƒ½ä½“å±•ç¤ºè®¡ç®—æˆæœ¬å¹¶èµ‹äºˆå…¶æ§åˆ¶è®¡ç®—æ—¶æœºçš„èƒ½åŠ›ï¼Œæ—¨åœ¨é™ä½ç³»ç»Ÿçš„è®¡ç®—è¶³è¿¹(computation footprint)ã€‚å®éªŒåœ¨ Arcade Learning Environment (ALE) å¹³å°ä¸Šå±•å¼€ï¼Œç»“æœè¡¨æ˜åœ¨ç›¸åŒçš„è®­ç»ƒè®¡ç®—é¢„ç®—ä¸‹ï¼Œèƒ½å¤Ÿå¯¹è®¡ç®—è¿›è¡Œæ¨ç†çš„æ™ºèƒ½ä½“åœ¨ 75% çš„æµ‹è¯•æ¸¸æˆä¸­è¡¨ç°ä¼˜äºä¼ ç»ŸåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¿™äº›æ™ºèƒ½ä½“åœ¨ç»´æŒä¼˜å¼‚æ€§èƒ½çš„åŒæ—¶ï¼Œå¹³å‡è®¡ç®—èµ„æºæ¶ˆè€—é™ä½äº†ä¸‰å€ã€‚ç ”ç©¶è¿˜æ·±å…¥åˆ†æäº†æ™ºèƒ½ä½“åœ¨å…·ä½“æ¸¸æˆä¸­è·å–æ•ˆç‡å¢ç›Šçš„æ–¹å¼ï¼Œè¯æ˜äº†è¿™ç§æœºåˆ¶åœ¨æå‡èƒ½æºæ•ˆç‡å’Œé‡Šæ”¾è®¡ç®—èµ„æºç”¨äºè§„åˆ’ç­‰å…¶ä»–è¿›ç¨‹æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22833v1",
      "published_date": "2025-10-26 21:01:30 UTC",
      "updated_date": "2025-10-26 21:01:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:07.272465+00:00"
    },
    {
      "arxiv_id": "2510.22832v1",
      "title": "HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning",
      "title_zh": "HRM-Agentï¼šåœ¨åŠ¨æ€ç¯å¢ƒä¸‹åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¾ªç¯æ¨ç†æ¨¡å‹",
      "authors": [
        "Long H Dang",
        "David Rawlinson"
      ],
      "abstract": "The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities given its small size, but has only been applied to supervised, static, fully-observable problems. One of HRM's strengths is its ability to adapt its computational effort to the difficulty of the problem. However, in its current form it cannot integrate and reuse computation from previous time-steps if the problem is dynamic, uncertain or partially observable, or be applied where the correct action is undefined, characteristics of many real-world problems.\n  This paper presents HRM-Agent, a variant of HRM trained using only reinforcement learning. We show that HRM can learn to navigate to goals in dynamic and uncertain maze environments. Recent work suggests that HRM's reasoning abilities stem from its recurrent inference process. We explore the dynamics of the recurrent inference process and find evidence that it is successfully reusing computation from earlier environment time-steps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HRM-Agentï¼Œä¸€ç§ä»…é€šè¿‡å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è¿›è¡Œè®­ç»ƒçš„å±‚æ¬¡åŒ–æ¨ç†æ¨¡å‹(Hierarchical Reasoning Model, HRM)å˜ä½“ï¼Œæ—¨åœ¨è§£å†³åŸæ¨¡å‹ä»…é™äºé™æ€å’Œå®Œå…¨å¯è§‚æµ‹ç¯å¢ƒçš„å±€é™æ€§ã€‚HRM-Agentå…‹æœäº†ç°æœ‰æ¨¡å‹æ— æ³•åœ¨åŠ¨æ€ã€ä¸ç¡®å®šæˆ–éƒ¨åˆ†å¯è§‚æµ‹çš„ä»»åŠ¡ä¸­æ•´åˆå¹¶å¤ç”¨è®¡ç®—èµ„æºçš„éš¾é¢˜ã€‚é€šè¿‡åœ¨åŠ¨æ€è¿·å®«ç¯å¢ƒä¸­çš„å¯¼èˆªå®éªŒï¼Œç ”ç©¶è¯æ˜äº†HRM-Agentèƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å¹¶è¾¾æˆç›®æ ‡ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†å¾ªç¯æ¨ç†è¿‡ç¨‹(Recurrent Inference Process)çš„åŠ¨æ€ç‰¹æ€§ï¼Œå‘ç°è¯æ®è¡¨æ˜æ¨¡å‹æˆåŠŸå¤ç”¨äº†æ¥è‡ªç¯å¢ƒæ—©æœŸæ—¶é—´æ­¥çš„è®¡ç®—ä¿¡æ¯ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†HRMåœ¨å¤„ç†å¤æ‚ç°å®ä¸–ç•Œé—®é¢˜æ—¶çš„çµæ´»æ€§ï¼Œä¸ºåœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹è®­ç»ƒé«˜æ•ˆæ¨ç†æ¨¡å‹æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 9 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2510.22832v1",
      "published_date": "2025-10-26 21:01:04 UTC",
      "updated_date": "2025-10-26 21:01:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:20.756662+00:00"
    },
    {
      "arxiv_id": "2511.00029v1",
      "title": "Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts",
      "title_zh": "åˆ©ç”¨å¯¹æ¯”æç¤ºå®ç°æ‹’ç»ç‡æ§åˆ¶çš„ç‰¹å¾å¼•å¯¼å‹ SAE æ“æ§",
      "authors": [
        "Samaksh Bhargav",
        "Zining Zhu"
      ],
      "abstract": "Large Language Model (LLM) deployment requires guiding the LLM to recognize and not answer unsafe prompts while complying with safe prompts. Previous methods for achieving this require adjusting model weights along with other expensive procedures. While recent advances in Sparse Autoencoders (SAEs) have enabled interpretable feature extraction from LLMs, existing approaches lack systematic feature selection methods and principled evaluation of safety-utility tradeoffs. We explored using different steering features and steering strengths using Sparse Auto Encoders (SAEs) to provide a solution. Using an accurate and innovative contrasting prompt method with the AI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air Bench eu-dataset to efficiently choose the best features in the model to steer, we tested this method on Llama-3 8B. We conclude that using this method, our approach achieves an 18.9% improvement in safety performance while simultaneously increasing utility by 11.1%, demonstrating that targeted SAE steering can overcome traditional safety-utility tradeoffs when optimal features are identified through principled selection methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨(Sparse Autoencoders, SAEs)é€šè¿‡ç‰¹å¾å¼•å¯¼è½¬å‘(Feature-Guided Steering)æ¥ç²¾ç¡®æ§åˆ¶å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ‹’ç»ç‡ï¼Œä»¥å¹³è¡¡å®‰å…¨æ€§ä¸å®ç”¨æ€§ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•éœ€è¦è°ƒæ•´æ¨¡å‹æƒé‡ä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”æç¤º(Contrasting Prompts)çš„ç³»ç»ŸåŒ–ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œåˆ©ç”¨OpenHermes-2.5å’ŒAir Benchæ•°æ®é›†é«˜æ•ˆè¯†åˆ«å…³é”®ç‰¹å¾ã€‚å®éªŒåœ¨Llama-3 8Bä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨æå‡18.9%å®‰å…¨æ€§èƒ½çš„åŒæ—¶ï¼Œè¿˜å¢åŠ äº†11.1%çš„æ¨¡å‹æ•ˆç”¨ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†é’ˆå¯¹æ€§çš„SAEè½¬å‘æŠ€æœ¯èƒ½å¤Ÿæœ‰æ•ˆå…‹æœä¼ ç»Ÿçš„å®‰å…¨-æ•ˆç”¨æƒè¡¡(Safety-Utility Tradeoffs)ï¼Œä¸ºå¤§æ¨¡å‹çš„å®‰å…¨éƒ¨ç½²æä¾›äº†ä¸€ç§æ— éœ€é‡è®­çš„é«˜æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.00029v1",
      "published_date": "2025-10-26 20:54:30 UTC",
      "updated_date": "2025-10-26 20:54:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:21.378828+00:00"
    },
    {
      "arxiv_id": "2510.22829v1",
      "title": "LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å•†ä¸šè®°å¿†åº¦é¢„æµ‹å¤šæ¨¡æ€ç‰¹å¾èåˆ",
      "authors": [
        "Aleksandar Pramov"
      ],
      "abstract": "This paper addresses the prediction of commercial (brand) memorability as part of \"Subtask 2: Commercial/Ad Memorability\" within the \"Memorability: Predicting movie and commercial memorability\" task at the MediaEval 2025 workshop competition. We propose a multimodal fusion system with a Gemma-3 LLM backbone that integrates pre-computed visual (ViT) and textual (E5) features by multi-modal projections. The model is adapted using Low-Rank Adaptation (LoRA). A heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key contribution is the use of LLM-generated rationale prompts, grounded in expert-derived aspects of memorability, to guide the fusion model. The results demonstrate that the LLM-based system exhibits greater robustness and generalization performance on the final test set, compared to the baseline.\n  The paper's codebase can be found at https://github.com/dsgt-arc/mediaeval-2025-memorability",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ MediaEval 2025 ç«èµ›ä¸­çš„å•†ä¸šå¹¿å‘Šè®°å¿†åº¦é¢„æµ‹ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§ä»¥ Gemma-3 LLM ä¸ºä¸»å¹²ç½‘ç»œçš„å¤šæ¨¡æ€èåˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡å¤šæ¨¡æ€æŠ•å½±æŠ€æœ¯é›†æˆäº†é¢„è®¡ç®—çš„è§†è§‰ç‰¹å¾ (ViT) å’Œæ–‡æœ¬ç‰¹å¾ (E5)ï¼Œå¹¶åˆ©ç”¨ä½ç§©è‡ªé€‚åº” (LoRA) è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®æ˜¯å¼•å…¥äº†åŸºäºä¸“å®¶è®°å¿†åº¦ç»´åº¦ç”Ÿæˆçš„ LLM é€»è¾‘æ¨ç†æç¤º (rationale prompts)ï¼Œä»¥æ­¤å¼•å¯¼èåˆæ¨¡å‹çš„é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäºç»è¿‡ç²¾ç»†è°ƒä¼˜çš„æ¢¯åº¦æå‡æ ‘ (gradient boosted trees) åŸºå‡†æ¨¡å‹ï¼Œè¯¥ç³»ç»Ÿåœ¨æµ‹è¯•é›†ä¸Šå…·æœ‰æ›´å¥½çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§èƒ½ã€‚è¯¥å·¥ä½œä¸ä»…æå‡äº†å•†ä¸šè®°å¿†åº¦é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œä¹ŸéªŒè¯äº†ç»“åˆ LLM æ¨ç†èƒ½åŠ›åœ¨å¤æ‚å¤šæ¨¡æ€èåˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22829v1",
      "published_date": "2025-10-26 20:51:52 UTC",
      "updated_date": "2025-10-26 20:51:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:27.520251+00:00"
    },
    {
      "arxiv_id": "2511.00028v1",
      "title": "Mutual Information guided Visual Contrastive Learning",
      "title_zh": "äº’ä¿¡æ¯å¼•å¯¼çš„è§†è§‰å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Hanyang Chen",
        "Yanchao Yang"
      ],
      "abstract": "Representation learning methods utilizing the InfoNCE loss have demonstrated considerable capacity in reducing human annotation effort by training invariant neural feature extractors. Although different variants of the training objective adhere to the information maximization principle between the data and learned features, data selection and augmentation still rely on human hypotheses or engineering, which may be suboptimal. For instance, data augmentation in contrastive learning primarily focuses on color jittering, aiming to emulate real-world illumination changes. In this work, we investigate the potential of selecting training data based on their mutual information computed from real-world distributions, which, in principle, should endow the learned features with better generalization when applied in open environments. Specifically, we consider patches attached to scenes that exhibit high mutual information under natural perturbations, such as color changes and motion, as positive samples for learning with contrastive loss. We evaluate the proposed mutual-information-informed data augmentation method on several benchmarks across multiple state-of-the-art representation learning frameworks, demonstrating its effectiveness and establishing it as a promising direction for future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¯¹æ¯”å­¦ä¹ (Contrastive Learning)ä¸­é€šè¿‡äº’ä¿¡æ¯(Mutual Information)å¼•å¯¼æ•°æ®é€‰æ‹©çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ–¹æ³•è¿‡åº¦ä¾èµ–äººå·¥è®¾è®¡å¢å¼ºç­–ç•¥è€Œå¯¼è‡´çš„æ¬¡ä¼˜é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºçœŸå®ä¸–ç•Œåˆ†å¸ƒè®¡ç®—äº’ä¿¡æ¯æ¥ç­›é€‰è®­ç»ƒæ•°æ®çš„æ–°æ€è·¯ï¼Œä»¥æœŸèµ‹äºˆæ‰€å­¦ç‰¹å¾åœ¨å¼€æ”¾ç¯å¢ƒä¸­æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶å°†è‡ªç„¶æ‰°åŠ¨ï¼ˆå¦‚é¢œè‰²å˜åŒ–å’Œè¿åŠ¨ï¼‰ä¸‹è¡¨ç°å‡ºé«˜äº’ä¿¡æ¯çš„åœºæ™¯å—ä½œä¸ºæ­£æ ·æœ¬ï¼Œå¹¶ç»“åˆå¯¹æ¯”æŸå¤±(Contrastive Loss)è¿›è¡Œè®­ç»ƒã€‚å®éªŒåœ¨å¤šä¸ªå…ˆè¿›çš„è¡¨ç¤ºå­¦ä¹ æ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¯æ˜äº†è¿™ç§åŸºäºäº’ä¿¡æ¯çš„æ•°æ®å¢å¼ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œä¸ä»…æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œä¹Ÿä¸ºæœªæ¥è¡¨å¾å­¦ä¹ ä¸­æ•°æ®é©±åŠ¨çš„å¢å¼ºç­–ç•¥ç ”ç©¶æä¾›äº†æå…·æ½œåŠ›çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech Report - Undergraduate Thesis - 2023",
      "pdf_url": "https://arxiv.org/pdf/2511.00028v1",
      "published_date": "2025-10-26 20:43:29 UTC",
      "updated_date": "2025-10-26 20:43:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:26.673548+00:00"
    },
    {
      "arxiv_id": "2510.22823v1",
      "title": "Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP",
      "title_zh": "é¢å‘äººé“ä¸»ä¹‰ NLP çš„æŒ‡ä»¤å¾®è°ƒè¯­è¨€æ¨¡å‹è·¨è¯­è¨€ç¨³å®šæ€§ä¸åç½®",
      "authors": [
        "Poli Nemkova",
        "Amrit Adhikari",
        "Matthew Pearson",
        "Vamsi Krishna Sadu",
        "Mark V. Albert"
      ],
      "abstract": "Humanitarian organizations face a critical choice: invest in costly commercial APIs or rely on free open-weight models for multilingual human rights monitoring. While commercial systems offer reliability, open-weight alternatives lack empirical validation -- especially for low-resource languages common in conflict zones. This paper presents the first systematic comparison of commercial and open-weight large language models (LLMs) for human-rights-violation detection across seven languages, quantifying the cost-reliability trade-off facing resource-constrained organizations. Across 78,000 multilingual inferences, we evaluate six models -- four instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0, GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both standard classification metrics and new measures of cross-lingual reliability: Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS), and Language Stability Score (LSS). Results show that alignment, not scale, determines stability: aligned models maintain near-invariant accuracy and balanced calibration across typologically distant and low-resource languages (e.g., Lingala, Burmese), while open-weight models exhibit significant prompt-language sensitivity and calibration drift. These findings demonstrate that multilingual alignment enables language-agnostic reasoning and provide practical guidance for humanitarian organizations balancing budget constraints with reliability in multilingual deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººé“ä¸»ä¹‰ç»„ç»‡åœ¨è·¨è¯­è¨€äººæƒç›‘æµ‹ä¸­é¢ä¸´çš„å•†ä¸šAPIä¸å¼€æºæƒé‡æ¨¡å‹(Open-weight models)é€‰æ‹©å›°å¢ƒï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§å¯¹æ¯”äº†ä¸¤è€…åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹æ£€æµ‹äººæƒè¿è§„è¡Œä¸ºçš„è¡¨ç°ã€‚é€šè¿‡å¯¹å…­ç§æ¨¡å‹ï¼ˆåŒ…æ‹¬Claude-Sonnet-4ã€DeepSeek-V3ã€Gemini-Flash-2.0ã€GPT-4.1-miniç­‰å¯¹é½æ¨¡å‹ï¼Œä»¥åŠLLaMA-3-8Bå’ŒMistral-7Bå¼€æºæƒé‡æ¨¡å‹ï¼‰åœ¨ä¸ƒç§è¯­è¨€ä¸‹çš„7.8ä¸‡æ¬¡æ¨ç†ï¼Œè¯„ä¼°äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹çš„æˆæœ¬ä¸å¯é æ€§æƒè¡¡ã€‚ç ”ç©¶å¼•å…¥äº†æ ¡å‡†åå·®(Calibration Deviation)ã€å†³ç­–åè§(Decision Bias)ã€è¯­è¨€é²æ£’æ€§è¯„åˆ†(Language Robustness Score)å’Œè¯­è¨€ç¨³å®šæ€§è¯„åˆ†(Language Stability Score)ç­‰æ–°å‹åº¦é‡æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå†³å®šæ¨¡å‹ç¨³å®šæ€§çš„æ ¸å¿ƒå› ç´ æ˜¯å¯¹é½(Alignment)è€Œéè§„æ¨¡ï¼Œç»è¿‡æŒ‡ä»¤å¯¹é½çš„æ¨¡å‹åœ¨æ—åŠ æ‹‰è¯­(Lingala)å’Œç¼…ç”¸è¯­(Burmese)ç­‰ä½èµ„æºè¯­è¨€ä¸­è¡¨ç°å‡ºè¿‘ä¹ä¸€è‡´çš„å‡†ç¡®æ€§å’Œå¹³è¡¡çš„æ ¡å‡†èƒ½åŠ›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¼€æºæƒé‡æ¨¡å‹åœ¨æç¤ºè¯è¯­è¨€æ•æ„Ÿæ€§å’Œæ ¡å‡†æ¼‚ç§»(Calibration drift)æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„ä¸ç¨³å®šæ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å¤šè¯­è¨€å¯¹é½èƒ½å¤Ÿå®ç°è¯­è¨€æ— å…³çš„æ¨ç†èƒ½åŠ›ï¼Œä¸ºäººé“ä¸»ä¹‰ç»„ç»‡åœ¨é¢„ç®—çº¦æŸä¸‹è¿›è¡Œå¯é çš„å¤šè¯­è¨€æ¨¡å‹éƒ¨ç½²æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22823v1",
      "published_date": "2025-10-26 20:32:25 UTC",
      "updated_date": "2025-10-26 20:32:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:34.078988+00:00"
    },
    {
      "arxiv_id": "2510.22818v1",
      "title": "Air Quality Prediction Using LOESS-ARIMA and Multi-Scale CNN-BiLSTM with Residual-Gated Attention",
      "title_zh": "åŸºäº LOESS-ARIMA å’Œèåˆæ®‹å·®é—¨æ§æ³¨æ„åŠ›çš„å¤šå°ºåº¦ CNN-BiLSTM çš„ç©ºæ°”è´¨é‡é¢„æµ‹",
      "authors": [
        "Soham Pahari",
        "Sandeep Chand Kumain"
      ],
      "abstract": "Air pollution remains a critical environmental and public health concern in Indian megacities such as Delhi, Kolkata, and Mumbai, where sudden spikes in pollutant levels challenge timely intervention. Accurate Air Quality Index (AQI) forecasting is difficult due to the coexistence of linear trends, seasonal variations, and volatile nonlinear patterns. This paper proposes a hybrid forecasting framework that integrates LOESS decomposition, ARIMA modeling, and a multi-scale CNN-BiLSTM network with a residual-gated attention mechanism. The LOESS step separates the AQI series into trend, seasonal, and residual components, with ARIMA modeling the smooth components and the proposed deep learning module capturing multi-scale volatility in the residuals. Model hyperparameters are tuned via the Unified Adaptive Multi-Stage Metaheuristic Optimizer (UAMMO), combining multiple optimization strategies for efficient convergence. Experiments on 2021-2023 AQI datasets from the Central Pollution Control Board show that the proposed method consistently outperforms statistical, deep learning, and hybrid baselines across PM2.5, O3, CO, and NOx in three major cities, achieving up to 5-8% lower MSE and higher R^2 scores (>0.94) for all pollutants. These results demonstrate the framework's robustness, sensitivity to sudden pollution events, and applicability to urban air quality management.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾·é‡Œã€åŠ å°”å„ç­”å’Œå­Ÿä¹°ç­‰å°åº¦ç‰¹å¤§åŸå¸‚é¢ä¸´çš„ç©ºæ°”è´¨é‡æŒ‡æ•° (AQI) é¢„æµ‹éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆ LOESS-ARIMA ä¸å¤šå°ºåº¦ CNN-BiLSTM çš„æ··åˆé¢„æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ LOESS åˆ†è§£æŠ€æœ¯å°†åºåˆ—æ‹†åˆ†ä¸ºè¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œæ®‹å·®æˆåˆ†ï¼Œåˆ©ç”¨ ARIMA å¤„ç†å¹³æ»‘éƒ¨åˆ†ï¼Œå¹¶ç»“åˆå¸¦æœ‰æ®‹å·®é—¨æ§æ³¨æ„åŠ›æœºåˆ¶ (residual-gated attention) çš„å¤šå°ºåº¦æ·±åº¦å­¦ä¹ æ¨¡å—æ¥æ•è·å¤æ‚çš„éçº¿æ€§æ³¢åŠ¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ç»Ÿä¸€è‡ªé€‚åº”å¤šé˜¶æ®µå…ƒå¯å‘å¼ä¼˜åŒ–å™¨ (UAMMO) å¯¹è¶…å‚æ•°è¿›è¡Œç²¾ç»†è°ƒä¼˜ä»¥æå‡æ”¶æ•›æ€§èƒ½ã€‚åŸºäº 2021-2023 å¹´çœŸå®æ•°æ®çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ PM2.5ã€O3ã€CO å’Œ NOx ç­‰å¤šç§æ±¡æŸ“ç‰©çš„é¢„æµ‹ç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç»Ÿè®¡å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒMSE é™ä½äº† 5-8% ä¸” R^2 åˆ†å€¼å‡é«˜äº 0.94ã€‚è¯¥æ¡†æ¶ä¸ä»…è¡¨ç°å‡ºæå¼ºçš„ç¨³å¥æ€§ï¼Œè¿˜èƒ½çµæ•æ•æ‰çªå‘æ€§æ±¡æŸ“äº‹ä»¶ï¼Œä¸ºåŸå¸‚ç¯å¢ƒæ²»ç†ä¸å…¬å…±å«ç”Ÿå¹²é¢„æä¾›äº†ç§‘å­¦ä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22818v1",
      "published_date": "2025-10-26 20:18:30 UTC",
      "updated_date": "2025-10-26 20:18:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:41.772442+00:00"
    },
    {
      "arxiv_id": "2510.22814v3",
      "title": "Will Humanity Be Rendered Obsolete by AI?",
      "title_zh": "äººç±»æ˜¯å¦å°†è¢«äººå·¥æ™ºèƒ½æ·˜æ±°ï¼Ÿ",
      "authors": [
        "Mohamed El Louadi",
        "Emna Ben Romdhane"
      ],
      "abstract": "This article analyzes the existential risks artificial intelligence (AI) poses to humanity, tracing the trajectory from current AI to ultraintelligence. Drawing on Irving J. Good and Nick Bostrom's theoretical work, plus recent publications (AI 2027; If Anyone Builds It, Everyone Dies), it explores AGI and superintelligence. Considering machines' exponentially growing cognitive power and hypothetical IQs, it addresses the ethical and existential implications of an intelligence vastly exceeding humanity's, fundamentally alien. Human extinction may result not from malice, but from uncontrollable, indifferent cognitive superiority.",
      "tldr_zh": "è¯¥æ–‡ç« åˆ†æäº†äººå·¥æ™ºèƒ½(AI)å¯¹äººç±»æ„æˆçš„ç”Ÿå­˜é£é™©(existential risks)ï¼Œè¿½è¸ªäº†ä»å½“å‰AIå‘è¶…æ™ºèƒ½(ultraintelligence)å‘å±•çš„æ¼”å˜è½¨è¿¹ã€‚åŸºäºIrving J. Goodå’ŒNick Bostromçš„ç†è®ºå·¥ä½œï¼Œæœ¬æ–‡æ·±å…¥æ¢è®¨äº†é€šç”¨äººå·¥æ™ºèƒ½(AGI)å’Œè¶…çº§æ™ºèƒ½(superintelligence)çš„å…´èµ·åŠå…¶å½±å“ã€‚è€ƒè™‘åˆ°æœºå™¨æŒ‡æ•°çº§å¢é•¿çš„è®¤çŸ¥èƒ½åŠ›å’Œå‡è®¾çš„é«˜æ™ºå•†(IQ)ï¼Œæ–‡ç« ç ”ç©¶äº†è¿™ç§è¿œè¶…äººç±»ä¸”æœ¬è´¨å¼‚è´¨çš„æ™ºèƒ½æ‰€å¸¦æ¥çš„ä¼¦ç†ä¸ç”Ÿå­˜æŒ‘æˆ˜ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œäººç±»ç­ç»çš„é£é™©å¯èƒ½å¹¶éæºäºæœºå™¨çš„æ¶æ„ï¼Œè€Œææœ‰å¯èƒ½æºäºä¸€ç§æ— æ³•æ§åˆ¶ä¸”å¯¹äººç±»åˆ©ç›Šæ¼ ä¸å…³å¿ƒçš„ç»å¯¹è®¤çŸ¥ä¼˜åŠ¿ã€‚æœ€ç»ˆï¼Œæ–‡ç« è­¦ç¤ºäº†åœ¨é¢å¯¹è¶…è¶Šè‡ªèº«è®¤çŸ¥è¾¹ç•Œçš„æ™ºèƒ½ç³»ç»Ÿæ—¶ï¼Œäººç±»æ–‡æ˜å¯èƒ½é¢ä¸´è¢«å–ä»£ç”šè‡³ç»ˆç»“çš„æ·±åˆ»å±æœºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22814v3",
      "published_date": "2025-10-26 20:02:04 UTC",
      "updated_date": "2025-11-30 18:18:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:39.665110+00:00"
    },
    {
      "arxiv_id": "2510.22809v1",
      "title": "A Theory of the Mechanics of Information: Generalization Through Measurement of Uncertainty (Learning is Measuring)",
      "title_zh": "ä¿¡æ¯åŠ›å­¦ç†è®ºï¼šé€šè¿‡ä¸ç¡®å®šæ€§æµ‹é‡å®ç°æ³›åŒ–ï¼ˆå­¦ä¹ å³æµ‹é‡ï¼‰",
      "authors": [
        "Christopher J. Hazard",
        "Michael Resnick",
        "Jacob Beel",
        "Jack Xia",
        "Cade Mack",
        "Dominic Glennie",
        "Matthew Fulp",
        "David Maze",
        "Andrew Bassett",
        "Martin Koistinen"
      ],
      "abstract": "Traditional machine learning relies on explicit models and domain assumptions, limiting flexibility and interpretability. We introduce a model-free framework using surprisal (information theoretic uncertainty) to directly analyze and perform inferences from raw data, eliminating distribution modeling, reducing bias, and enabling efficient updates including direct edits and deletion of training data. By quantifying relevance through uncertainty, the approach enables generalizable inference across tasks including generative inference, causal discovery, anomaly detection, and time series forecasting. It emphasizes traceability, interpretability, and data-driven decision making, offering a unified, human-understandable framework for machine learning, and achieves at or near state-of-the-art performance across most common machine learning tasks. The mathematical foundations create a ``physics'' of information, which enable these techniques to apply effectively to a wide variety of complex data types, including missing data. Empirical results indicate that this may be a viable alternative path to neural networks with regard to scalable machine learning and artificial intelligence that can maintain human understandability of the underlying mechanics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºä¿¡æ¯åŠ›å­¦ç†è®ºçš„æ¨¡å‹æ— å…³(model-free)æ¡†æ¶ï¼Œé€šè¿‡æµ‹é‡ä¸ç¡®å®šæ€§ï¼ˆsurprisalï¼Œå³æƒŠå¥‡åº¦ï¼‰æ¥ç›´æ¥åˆ†æåŸå§‹æ•°æ®å¹¶è¿›è¡Œæ¨ç†ã€‚è¯¥æ–¹æ³•æ¶ˆé™¤äº†å¯¹åˆ†å¸ƒå»ºæ¨¡çš„ä¾èµ–ï¼Œå‡å°‘äº†åå·®ï¼Œå¹¶æ”¯æŒå¯¹è®­ç»ƒæ•°æ®çš„ç›´æ¥ç¼–è¾‘å’Œåˆ é™¤ï¼Œä»è€Œå®ç°äº†é«˜æ•ˆæ›´æ–°ã€‚é€šè¿‡åˆ©ç”¨ä¸ç¡®å®šæ€§é‡åŒ–ç›¸å…³æ€§ï¼Œè¯¥æ¡†æ¶åœ¨ç”Ÿæˆå¼æ¨ç†(generative inference)ã€å› æœå‘ç°(causal discovery)ã€å¼‚å¸¸æ£€æµ‹(anomaly detection)å’Œæ—¶é—´åºåˆ—é¢„æµ‹(time series forecasting)ç­‰ä»»åŠ¡ä¸­å±•ç°äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚è®ºæ–‡æ„å»ºäº†ä¿¡æ¯çš„â€œç‰©ç†å­¦â€æ•°å­¦åŸºç¡€ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åŒ…æ‹¬ç¼ºå¤±æ•°æ®(missing data)åœ¨å†…çš„å„ç§å¤æ‚æ•°æ®ç±»å‹ï¼Œå¹¶å¼ºè°ƒäº†å†³ç­–è¿‡ç¨‹çš„å¯è¿½æº¯æ€§å’Œå¯è§£é‡Šæ€§(interpretability)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šæ•°é€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸Šè¾¾åˆ°æˆ–æ¥è¿‘æœ€å…ˆè¿›æ°´å¹³(SOTA)ï¼Œä¸ºæ„å»ºå¯æ‰©å±•ä¸”å…·å¤‡äººç±»å¯ç†è§£æ€§çš„äººå·¥æ™ºèƒ½æä¾›äº†ä¸€æ¡åŒºåˆ«äºç¥ç»ç½‘ç»œ(neural networks)çš„æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "117 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.22809v1",
      "published_date": "2025-10-26 19:45:25 UTC",
      "updated_date": "2025-10-26 19:45:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:41.368072+00:00"
    },
    {
      "arxiv_id": "2510.23669v2",
      "title": "What Work is AI Actually Doing? Uncovering the Drivers of Generative AI Adoption",
      "title_zh": "AI ç©¶ç«Ÿåœ¨æ‰¿æ‹…å“ªäº›ä»»åŠ¡ï¼Ÿæ­ç¤ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨çš„é©±åŠ¨å› ç´ ",
      "authors": [
        "Peeyush Agarwal",
        "Harsh Agarwal",
        "Akshat Rana"
      ],
      "abstract": "Purpose: The rapid integration of artificial intelligence (AI) systems like ChatGPT, Claude AI, etc., has a deep impact on how work is done. Predicting how AI will reshape work requires understanding not just its capabilities, but how it is actually being adopted. This study investigates which intrinsic task characteristics drive users' decisions to delegate work to AI systems. Methodology: This study utilizes the Anthropic Economic Index dataset of four million Claude AI interactions mapped to O*NET tasks. We systematically scored each task across seven key dimensions: Routine, Cognitive, Social Intelligence, Creativity, Domain Knowledge, Complexity, and Decision Making using 35 parameters. We then employed multivariate techniques to identify latent task archetypes and analyzed their relationship with AI usage. Findings: Tasks requiring high creativity, complexity, and cognitive demand, but low routineness, attracted the most AI engagement. Furthermore, we identified three task archetypes: Dynamic Problem Solving, Procedural & Analytical Work, and Standardized Operational Tasks, demonstrating that AI applicability is best predicted by a combination of task characteristics, over individual factors. Our analysis revealed highly concentrated AI usage patterns, with just 5% of tasks accounting for 59% of all interactions. Originality: This research provides the first systematic evidence linking real-world generative AI usage to a comprehensive, multi-dimensional framework of intrinsic task characteristics. It introduces a data-driven classification of work archetypes that offers a new framework for analyzing the emerging human-AI division of labor.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†å“ªäº›å†…åœ¨ä»»åŠ¡ç‰¹å¾é©±åŠ¨ç”¨æˆ·å°†å·¥ä½œå§”æ‰˜ç»™ Generative AI ç³»ç»Ÿï¼Œé€šè¿‡åˆ†æåŒ…å« 400 ä¸‡æ¬¡ Claude AI äº¤äº’çš„ Anthropic Economic Index æ•°æ®é›†å¹¶æ˜ å°„è‡³ O\\*NET ä»»åŠ¡ã€‚ç ”ç©¶é‡‡ç”¨ 35 ä¸ªå‚æ•°åœ¨ Routineã€Cognitiveã€Social Intelligenceã€Creativityã€Domain Knowledgeã€Complexity å’Œ Decision Making ä¸ƒä¸ªç»´åº¦ä¸Šå¯¹ä»»åŠ¡è¿›è¡Œè¯„åˆ†ï¼Œå¹¶åˆ©ç”¨å¤šå…ƒæŠ€æœ¯è¯†åˆ«æ½œåœ¨çš„ä»»åŠ¡åŸå‹ã€‚å‘ç°é«˜ Creativityã€Complexity å’Œ Cognitive éœ€æ±‚ä¸”ä½ Routineness çš„ä»»åŠ¡å¸å¼•äº†æœ€å¤šçš„ AI å‚ä¸ï¼Œä¸” AI çš„é€‚ç”¨æ€§ç”±ä»»åŠ¡ç‰¹å¾ç»„åˆè€Œéå•ä¸€å› ç´ é¢„æµ‹ã€‚ç ”ç©¶è¯†åˆ«å‡º Dynamic Problem Solvingã€Procedural & Analytical Work å’Œ Standardized Operational Tasks ä¸‰ç±»ä»»åŠ¡åŸå‹ï¼Œå¹¶æ­ç¤ºäº†é«˜åº¦é›†ä¸­çš„ä½¿ç”¨æ¨¡å¼ï¼Œå³ 5% çš„ä»»åŠ¡è´¡çŒ®äº† 59% çš„äº¤äº’æ€»é‡ã€‚è¿™ä¸€æˆæœé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†ç°å®ä¸–ç•Œä¸­ Generative AI çš„ä½¿ç”¨ä¸å¤šç»´åº¦ä»»åŠ¡ç‰¹å¾æ¡†æ¶è”ç³»èµ·æ¥ï¼Œä¸ºåˆ†ææ–°å…´çš„äººæœºåˆ†å·¥æä¾›äº†æ•°æ®é©±åŠ¨çš„æ–°æ¶æ„ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "econ.GN",
      "comment": "22 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.23669v2",
      "published_date": "2025-10-26 19:13:37 UTC",
      "updated_date": "2025-10-29 05:01:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:50.656306+00:00"
    },
    {
      "arxiv_id": "2510.22787v1",
      "title": "Collaborative LLM Agents for C4 Software Architecture Design Automation",
      "title_zh": "ç”¨äº C4 è½¯ä»¶æ¶æ„è®¾è®¡è‡ªåŠ¨åŒ–çš„ååŒ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Kamil Szczepanik",
        "JarosÅ‚aw A. Chudziak"
      ],
      "abstract": "Software architecture design is a fundamental part of creating every software system. Despite its importance, producing a C4 software architecture model, the preferred notation for such architecture, remains manual and time-consuming. We introduce an LLM-based multi-agent system that automates this task by simulating a dialogue between role-specific experts who analyze requirements and generate the Context, Container, and Component views of the C4 model. Quality is assessed with a hybrid evaluation framework: deterministic checks for structural and syntactic integrity and C4 rule consistency, plus semantic and qualitative scoring via an LLM-as-a-Judge approach. Tested on five canonical system briefs, the workflow demonstrates fast C4 model creation, sustains high compilation success, and delivers semantic fidelity. A comparison of four state-of-the-art LLMs shows different strengths relevant to architectural design. This study contributes to automated software architecture design and its evaluation methods.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ C4 è½¯ä»¶æ¶æ„æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ä¸­æ‰‹åŠ¨æ“ä½œè€—æ—¶è´¹åŠ›çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ¨¡æ‹Ÿè§’è‰²ç‰¹å®šä¸“å®¶ä¹‹é—´çš„å¯¹è¯ï¼Œå®ç°äº† C4 æ¨¡å‹ä¸­ä¸Šä¸‹æ–‡(Context)ã€å®¹å™¨(Container)å’Œç»„ä»¶(Component)è§†å›¾çš„è‡ªåŠ¨åŒ–è®¾è®¡ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§æ··åˆè¯„ä¼°æ¡†æ¶ï¼Œç»“åˆäº†é’ˆå¯¹ç»“æ„å®Œæ•´æ€§ä¸ C4 è§„åˆ™ä¸€è‡´æ€§çš„ç¡®å®šæ€§æ£€æŸ¥ï¼Œä»¥åŠé€šè¿‡ LLM-as-a-Judge æ–¹å¼è¿›è¡Œçš„è¯­ä¹‰å’Œå®šæ€§è¯„åˆ†ã€‚åœ¨äº”ä¸ªå…¸å‹ç³»ç»Ÿç®€æŠ¥ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥å·¥ä½œæµèƒ½å¤Ÿå¿«é€Ÿç”Ÿæˆæ¨¡å‹ï¼Œå¹¶ä¿æŒäº†é«˜æ°´å¹³çš„ç¼–è¯‘æˆåŠŸç‡å’Œè¯­ä¹‰å¿ å®åº¦ã€‚é€šè¿‡å¯¹å››ç§å…ˆè¿› LLMs çš„å¯¹æ¯”åˆ†æï¼Œè¯¥ç ”ç©¶å±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨æ¶æ„è®¾è®¡ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ï¼Œä¸ºè½¯ä»¶æ¶æ„è®¾è®¡çš„è‡ªåŠ¨åŒ–åŠå…¶è¯„ä»·ä½“ç³»æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been accepted for the upcoming 59th Hawaii International Conference on System Sciences (HICSS-59), 2026, Hawaii, USA. The final published version will appear in the official conference proceedings",
      "pdf_url": "https://arxiv.org/pdf/2510.22787v1",
      "published_date": "2025-10-26 18:43:59 UTC",
      "updated_date": "2025-10-26 18:43:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:42:45.885279+00:00"
    },
    {
      "arxiv_id": "2510.22784v1",
      "title": "PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language",
      "title_zh": "PIP-LLMï¼šèåˆ PDDL-æ•´æ•°è§„åˆ’ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œå®ç°åŸºäºè‡ªç„¶è¯­è¨€çš„å¤šæœºå™¨äººå›¢é˜ŸååŒ",
      "authors": [
        "Guangyao Shi",
        "Yuwei Wu",
        "Vijay Kumar",
        "Gaurav S. Sukhatme"
      ],
      "abstract": "Enabling robot teams to execute natural language commands requires translating high-level instructions into feasible, efficient multi-robot plans. While Large Language Models (LLMs) combined with Planning Domain Description Language (PDDL) offer promise for single-robot scenarios, existing approaches struggle with multi-robot coordination due to brittle task decomposition, poor scalability, and low coordination efficiency.\n  We introduce PIP-LLM, a language-based coordination framework that consists of PDDL-based team-level planning and Integer Programming (IP) based robot-level planning. PIP-LLMs first decomposes the command by translating the command into a team-level PDDL problem and solves it to obtain a team-level plan, abstracting away robot assignment. Each team-level action represents a subtask to be finished by the team. Next, this plan is translated into a dependency graph representing the subtasks' dependency structure. Such a dependency graph is then used to guide the robot-level planning, in which each subtask node will be formulated as an IP-based task allocation problem, explicitly optimizing travel costs and workload while respecting robot capabilities and user-defined constraints. This separation of planning from assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition and scale to larger teams. Experiments across diverse tasks show that PIP-LLM improves plan success rate, reduces maximum and average travel costs, and achieves better load balancing compared to state-of-the-art baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PIP-LLM æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Large Language Models (LLMs) ç»“åˆ Planning Domain Description Language (PDDL) åœ¨å¤šæœºå™¨äººåä½œä»»åŠ¡ä¸­å­˜åœ¨çš„ä»»åŠ¡åˆ†è§£è„†å¼±ã€å¯æ‰©å±•æ€§å·®ä»¥åŠåè°ƒæ•ˆç‡ä½ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ LLMs å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå›¢é˜Ÿå±‚é¢çš„ PDDL é—®é¢˜ï¼Œå¹¶æ±‚è§£å¾—åˆ°æŠ½è±¡äº†å…·ä½“æœºå™¨äººåˆ†é…çš„å›¢é˜Ÿçº§è®¡åˆ’ã€‚éšåï¼Œè¯¥è®¡åˆ’è¢«è½¬åŒ–ä¸ºè¡¨ç¤ºå­ä»»åŠ¡ä¾èµ–ç»“æ„çš„ä¾èµ–å›¾ï¼Œç”¨ä»¥æŒ‡å¯¼æœºå™¨äººå±‚é¢çš„è§„åˆ’ã€‚åœ¨æœºå™¨äººå±‚é¢ï¼ŒPIP-LLM å°†æ¯ä¸ªå­ä»»åŠ¡è¡¨è¿°ä¸ºåŸºäº Integer Programming (IP) çš„ä»»åŠ¡åˆ†é…é—®é¢˜ï¼Œåœ¨éµå®ˆæœºå™¨äººèƒ½åŠ›å’Œç”¨æˆ·çº¦æŸçš„åŒæ—¶ï¼Œæ˜¾å¼ä¼˜åŒ–æ—…è¡Œæˆæœ¬å’Œå·¥ä½œè´Ÿè½½ã€‚è¿™ç§å°†è§„åˆ’ä¸åˆ†é…åˆ†ç¦»çš„è®¾è®¡ä½¿ PIP-LLM èƒ½å¤Ÿé¿å…åŸºäºè¯­æ³•çš„åˆ†è§£é™·é˜±ï¼Œå¹¶æœ‰æ•ˆæ‰©å±•è‡³æ›´å¤§è§„æ¨¡çš„æœºå™¨äººå›¢é˜Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼ŒPIP-LLM åœ¨å¤šç§ä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†è®¡åˆ’æˆåŠŸç‡ï¼Œé™ä½äº†æœ€å¤§å’Œå¹³å‡æ—…è¡Œæˆæœ¬ï¼Œå¹¶å®ç°äº†æ›´å¥½çš„è´Ÿè½½å‡è¡¡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22784v1",
      "published_date": "2025-10-26 18:37:00 UTC",
      "updated_date": "2025-10-26 18:37:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:03.955053+00:00"
    },
    {
      "arxiv_id": "2510.22781v2",
      "title": "Agentic Meta-Orchestrator for Multi-task Copilots",
      "title_zh": "é¢å‘å¤šä»»åŠ¡ Copilot çš„æ™ºèƒ½ä½“åŒ–å…ƒç¼–æ’å™¨",
      "authors": [
        "Xiaofeng Zhu",
        "Yunshen Zhou"
      ],
      "abstract": "Microsoft Copilot suites serve as the universal entry point for various agents skilled in handling important tasks, ranging from assisting a customer with product purchases to detecting vulnerabilities in corporate programming code. Each agent can be powered by language models, software engineering operations, such as database retrieval, and internal \\& external knowledge. The repertoire of a copilot can expand dynamically with new agents. This requires a robust orchestrator that can distribute tasks from user prompts to the right agents. In this work, we propose an Agentic Meta-orchestrator (AMO) for handling multiple tasks and scalable agents in copilot services, which can provide both natural language and action responses. We will also demonstrate the planning that leverages meta-learning, i.e., a trained decision tree model for deciding the best inference strategy among various agents/models. We showcase the effectiveness of our AMO through two production use cases: Microsoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365 E-Commerce Copilot advertises Microsoft products to external customers to promote sales success. The M365 E-Commerce Copilot provides up-to-date product information and connects to multiple agents, such as relational databases and human customer support. The code compliance copilot scans the internal DevOps code to detect known and new compliance issues in pull requests (PR).",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Agentic Meta-orchestrator (AMO)ï¼Œä¸€ç§æ—¨åœ¨å¤„ç†å¤šä»»åŠ¡å’Œå¯æ‰©å±•æ™ºèƒ½ä½“çš„å…ƒç¼–æ’æ¡†æ¶ï¼Œç”¨äºæå‡CopilotæœåŠ¡çš„ä»»åŠ¡åˆ†å‘ä¸åä½œèƒ½åŠ›ã€‚AMOèƒ½å¤ŸåŒæ—¶æä¾›è‡ªç„¶è¯­è¨€å“åº”å’ŒåŠ¨ä½œæŒ‡ä»¤ï¼Œæœ‰æ•ˆåœ°å°†ç”¨æˆ·æŒ‡ä»¤åˆ†é…ç»™å…·å¤‡ç‰¹å®šæŠ€èƒ½çš„å„ç±»æ™ºèƒ½ä½“ã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†ä¸€ç§åŸºäºå…ƒå­¦ä¹ (meta-learning)çš„è§„åˆ’æœºåˆ¶ï¼Œé€šè¿‡è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹æ¥ç¡®å®šä¸åŒæ™ºèƒ½ä½“æˆ–æ¨¡å‹é—´çš„æœ€ä½³æ¨ç†ç­–ç•¥(inference strategy)ã€‚åœ¨Microsoft 365 (M365) E-Commerce Copilotçš„ç”Ÿäº§æ¡ˆä¾‹ä¸­ï¼ŒAMOæˆåŠŸæ•´åˆäº†å…³ç³»å‹æ•°æ®åº“å’Œäººå·¥æ”¯æŒï¼Œå®ç°äº†å®æ—¶äº§å“ä¿¡æ¯çš„é«˜æ•ˆæ£€ç´¢ã€‚åŒæ—¶ï¼Œåœ¨ä»£ç åˆè§„Copilotåº”ç”¨ä¸­ï¼Œè¯¥æ¡†æ¶è¢«ç”¨äºæ‰«æDevOpsä»£ç ï¼Œä»¥æ£€æµ‹æ‹‰å–è¯·æ±‚(pull requests)ä¸­å·²çŸ¥å’Œæ–°å¢çš„åˆè§„é—®é¢˜ã€‚å®éªŒç»“æœè¯æ˜äº†AMOåœ¨å¤„ç†å¤æ‚å¤šä»»åŠ¡ç¯å¢ƒæ—¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»ºå¯åŠ¨æ€æ‰©å±•çš„æ™ºèƒ½ä½“æœåŠ¡ä½“ç³»å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22781v2",
      "published_date": "2025-10-26 18:13:04 UTC",
      "updated_date": "2025-11-05 05:01:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:05.574357+00:00"
    },
    {
      "arxiv_id": "2510.22780v2",
      "title": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations",
      "title_zh": "AI æ™ºèƒ½ä½“å¦‚ä½•æ‰§è¡Œäººç±»å·¥ä½œï¼Ÿè·¨èŒä¸šé¢†åŸŸçš„ AI ä¸äººç±»å·¥ä½œæµå¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Zora Zhiruo Wang",
        "Yijia Shao",
        "Omar Shaikh",
        "Daniel Fried",
        "Graham Neubig",
        "Diyi Yang"
      ],
      "abstract": "AI agents are continually optimized for tasks related to human work, such as software engineering and professional writing, signaling a pressing trend with significant impacts on the human workforce. However, these agent developments have often not been grounded in a clear understanding of how humans execute work, to reveal what expertise agents possess and the roles they can play in diverse workflows. In this work, we study how agents do human work by presenting the first direct comparison of human and agent workers across multiple essential work-related skills: data analysis, engineering, computation, writing, and design. To better understand and compare heterogeneous computer-use activities of workers, we introduce a scalable toolkit to induce interpretable, structured workflows from either human or agent computer-use activities. Using such induced workflows, we compare how humans and agents perform the same tasks and find that: (1) While agents exhibit promise in their alignment to human workflows, they take an overwhelmingly programmatic approach across all work domains, even for open-ended, visually dependent tasks like design, creating a contrast with the UI-centric methods typically used by humans. (2) Agents produce work of inferior quality, yet often mask their deficiencies via data fabrication and misuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster and cost 90.4-96.2% less than humans, highlighting the potential for enabling efficient collaboration by delegating easily programmable tasks to agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡å¯¹æ¯” AI agents ä¸äººç±»åœ¨æ•°æ®åˆ†æ (data analysis)ã€å·¥ç¨‹ (engineering)ã€è®¡ç®— (computation)ã€å†™ä½œ (writing) å’Œè®¾è®¡ (design) ç­‰å¤šæ ·åŒ–èŒä¸šä¸­çš„å·¥ä½œæµ (workflows)ï¼Œæ·±å…¥æ¢è®¨äº†æ™ºèƒ½ä½“æ‰§è¡Œäººç±»å·¥ä½œçš„æ–¹å¼ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†ä¸€ç§å¯æ‰©å±•çš„å·¥å…·åŒ… (toolkit)ï¼Œèƒ½å¤Ÿä»è®¡ç®—æœºä½¿ç”¨æ´»åŠ¨ä¸­æå–å¯è§£é‡Šçš„ç»“æ„åŒ–å·¥ä½œæµï¼Œä»è€Œå®ç°äº†äººç±»ä¸æ™ºèƒ½ä½“åœ¨æ ¸å¿ƒå·¥ä½œæŠ€èƒ½ä¸Šçš„é¦–æ¬¡ç›´æ¥æ¯”è¾ƒã€‚å®éªŒå‘ç°ï¼ŒAI agents åœ¨æ‰€æœ‰é¢†åŸŸï¼ˆåŒ…æ‹¬è®¾è®¡ç­‰è§†è§‰ä¾èµ–å‹ä»»åŠ¡ï¼‰å‡å€¾å‘äºé‡‡ç”¨ç¼–ç¨‹åŒ–æ–¹æ³• (programmatic approach)ï¼Œè¿™ä¸äººç±»é€šå¸¸é‡‡ç”¨çš„ä»¥ç•Œé¢ä¸ºä¸­å¿ƒ (UI-centric) çš„æ“ä½œæ¨¡å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚å°½ç®¡ AI agents ç›®å‰çš„å·¥ä½œè´¨é‡é€Šäºäººç±»ï¼Œå¹¶å­˜åœ¨æ•°æ®é€ å‡ (data fabrication) å’Œå·¥å…·è¯¯ç”¨ç­‰æ©é¥°ç¼ºé™·çš„è¡Œä¸ºï¼Œä½†å…¶ä»»åŠ¡æ‰§è¡Œé€Ÿåº¦æ¯”äººç±»å¿« 88.3%ï¼Œä¸”æˆæœ¬é™ä½äº† 90.4% è‡³ 96.2%ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†é€šè¿‡å°†æ˜“äºç¼–ç¨‹åŒ–çš„ä»»åŠ¡å§”æ‰˜ç»™æ™ºèƒ½ä½“ï¼Œä»è€Œå®ç°é«˜æ•ˆäººæœºåä½œ (human-AI collaboration) çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22780v2",
      "published_date": "2025-10-26 18:10:22 UTC",
      "updated_date": "2025-11-06 21:03:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:08.774929+00:00"
    },
    {
      "arxiv_id": "2511.05516v1",
      "title": "Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation",
      "title_zh": "Ming-UniAudioï¼šåŸºäºç»Ÿä¸€è¡¨ç¤ºçš„è¯­éŸ³ç†è§£ã€ç”Ÿæˆä¸ç¼–è¾‘ä¸€ä½“åŒ–å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Canxiang Yan",
        "Chunxiang Jin",
        "Dawei Huang",
        "Haibing Yu",
        "Han Peng",
        "Hui Zhan",
        "Jie Gao",
        "Jing Peng",
        "Jingdong Chen",
        "Jun Zhou",
        "Kaimeng Ren",
        "Ming Yang",
        "Mingxue Yang",
        "Qiang Xu",
        "Qin Zhao",
        "Ruijie Xiong",
        "Shaoxiong Lin",
        "Xuezhi Wang",
        "Yi Yuan",
        "Yifei Wu",
        "Yongjie Lyu",
        "Zhengyu He",
        "Zhihao Qiu",
        "Zhiqiang Fang",
        "Ziyuan Huang"
      ],
      "abstract": "Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Ming-UniAudio æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯­éŸ³æ¨¡å‹åœ¨ç†è§£ä¸ç”Ÿæˆä»»åŠ¡ä¸­å¯¹ token representations çš„ä¸åŒéœ€æ±‚ï¼Œä»è€Œå®ç°äº†è¯­éŸ³ç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘çš„ç»Ÿä¸€ã€‚å…¶æ ¸å¿ƒæ˜¯é¦–ä¸ªé›†æˆäº†è¯­ä¹‰(semantic)å’Œå£°å­¦(acoustic)ç‰¹å¾çš„ç»Ÿä¸€è¿ç»­è¯­éŸ³ tokenizer â€”â€” MingTok-Audioï¼Œä½¿å¾—æ¨¡å‹èƒ½åŒæ—¶èƒœä»»ç†è§£ä¸ç”Ÿæˆä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼ŒMing-UniAudio åœ¨ ContextASR åŸºå‡†æµ‹è¯•çš„ 12 é¡¹æŒ‡æ ‡ä¸­å–å¾—äº† 8 é¡¹ SOTAï¼Œå¹¶åœ¨ä¸­æ–‡è¯­éŸ³å…‹éš†ä¸­è¡¨ç°ä¼˜å¼‚ã€‚ç ”ç©¶è¿˜æ¨å‡ºäº† Ming-UniAudio-Editï¼Œè¿™æ˜¯é¦–ä¸ªä»…å‡­è‡ªç„¶è¯­è¨€æŒ‡ä»¤å³å¯è¿›è¡Œé€šç”¨ã€è‡ªç”±å½¢å¼è¯­éŸ³ç¼–è¾‘çš„è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹(Speech LLM)ï¼Œæ— éœ€æ—¶é—´æˆ³(timestamp)æ¡ä»¶å³å¯å¤„ç†è¯­ä¹‰å’Œå£°å­¦ä¿®æ”¹ã€‚æœ€åï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº† Ming-Freeform-Audio-Edit è¯„æµ‹åŸºå‡†ï¼Œå¹¶å¼€æºäº†æ‰€æœ‰æ ¸å¿ƒæ¨¡å‹ä¸å·¥å…·ï¼Œä¸ºéŸ³é¢‘ç†è§£ä¸ç”Ÿæˆçš„ååŒå‘å±•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.05516v1",
      "published_date": "2025-10-26 17:55:34 UTC",
      "updated_date": "2025-10-26 17:55:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:17.270427+00:00"
    },
    {
      "arxiv_id": "2510.22765v2",
      "title": "Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval",
      "title_zh": "Jarvisï¼šåŸºäºä¸ªäºº KV-Cache æ£€ç´¢çš„ä¸ªæ€§åŒ– AI åŠ©æ‰‹",
      "authors": [
        "Binxiao Xu",
        "Junyu Feng",
        "Shaolin Lu",
        "Yulin Luo",
        "Shilin Yan",
        "Hao Liang",
        "Ming Lu",
        "Wentao Zhang"
      ],
      "abstract": "The rapid development of Vision-language models (VLMs) enables open-ended perception and reasoning. Recent works have started to investigate how to adapt general-purpose VLMs into personalized assistants. Even commercial models such as ChatGPT now support model personalization by incorporating user-specific information. However, existing methods either learn a set of concept tokens or train a VLM to utilize user-specific information. However, both pipelines struggle to generate accurate answers as personalized assistants. We introduce Jarvis, an innovative framework for a personalized AI assistant through personal KV-Cache retrieval, which stores user-specific information in the KV-Caches of both textual and visual tokens. The textual tokens are created by summarizing user information into metadata, while the visual tokens are produced by extracting distinct image patches from the user's images. When answering a question, Jarvis first retrieves related KV-Caches from personal storage and uses them to ensure accuracy in responses. We also introduce a fine-grained benchmark built with the same distinct image patch mining pipeline, emphasizing accurate question answering based on fine-grained user-specific information. Jarvis is capable of providing more accurate responses, particularly when they depend on specific local details. Jarvis achieves state-of-the-art results in both visual question answering and text-only tasks across multiple datasets, indicating a practical path toward personalized AI assistants. The code and dataset will be released.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Jarvisï¼Œä¸€ç§é€šè¿‡ä¸ªäººKV-Cacheæ£€ç´¢ï¼ˆPersonal KV-Cache Retrievalï¼‰å®ç°ä¸ªæ€§åŒ–AIåŠ©æ‰‹çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ä¸ªæ€§åŒ–è¿‡ç¨‹ä¸­å‡†ç¡®ç‡ä¸è¶³çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å°†ç”¨æˆ·ç‰¹å®šçš„æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯å­˜å‚¨åœ¨KV-Cachesä¸­ï¼Œå…¶ä¸­æ–‡æœ¬Tokenç”±å…ƒæ•°æ®ï¼ˆmetadataï¼‰æ€»ç»“è€Œæˆï¼Œè§†è§‰Tokenåˆ™é€šè¿‡æŒ–æ˜å›¾åƒä¸­çš„ç‹¬ç‰¹è¡¥ä¸ï¼ˆimage patchesï¼‰ç”Ÿæˆã€‚åœ¨å›ç­”é—®é¢˜æ—¶ï¼ŒJarvisé€šè¿‡æ£€ç´¢å¹¶åˆ©ç”¨ç›¸å…³çš„KV-Cachesæ¥å¢å¼ºæ¨ç†è¿‡ç¨‹ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°å…³é”®çš„å±€éƒ¨ç»†èŠ‚å¹¶æé«˜å›å¤ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒJarvisåœ¨å¤šé¡¹è§†è§‰é—®ç­”ï¼ˆVQAï¼‰å’Œçº¯æ–‡æœ¬ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ°´å¹³ï¼Œå¹¶åŒæ­¥æ¨å‡ºäº†ä¸€ä¸ªç»†ç²’åº¦çš„ä¸ªæ€§åŒ–åŸºå‡†æ•°æ®é›†ã€‚è¯¥æˆæœä¸ºæ„å»ºèƒ½å¤Ÿæ·±åº¦ç†è§£ç”¨æˆ·ç‰¹å®šä¿¡æ¯çš„å®ç”¨å‹ä¸ªæ€§åŒ–åŠ©æ‰‹å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22765v2",
      "published_date": "2025-10-26 17:28:05 UTC",
      "updated_date": "2025-11-01 07:01:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:22.862344+00:00"
    },
    {
      "arxiv_id": "2510.22752v1",
      "title": "Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models",
      "title_zh": "è¶…è¶Šè¯­ä¹‰ï¼šæ—¶åºåå·®å¦‚ä½•å¡‘é€  Transformer å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹ä¸­çš„æ£€ç´¢",
      "authors": [
        "Anooshka Bajaj",
        "Deven Mahesh Mistry",
        "Sahaj Singh Maini",
        "Yash Aggarwal",
        "Zoran Tiganj"
      ],
      "abstract": "In-context learning is governed by both temporal and semantic relationships, shaping how Large Language Models (LLMs) retrieve contextual information. Analogous to human episodic memory, where the retrieval of specific events is enabled by separating events that happened at different times, this work probes the ability of various pretrained LLMs, including transformer and state-space models, to differentiate and retrieve temporally separated events. Specifically, we prompted models with sequences containing multiple presentations of the same token, which reappears at the sequence end. By fixing the positions of these repeated tokens and permuting all others, we removed semantic confounds and isolated temporal effects on next-token prediction. Across diverse sequences, models consistently placed the highest probabilities on tokens following a repeated token, but with a notable bias for those nearest the beginning or end of the input. An ablation experiment linked this phenomenon in transformers to induction heads. Extending the analysis to unique semantic contexts with partial overlap further demonstrated that memories embedded in the middle of a prompt are retrieved less reliably. Despite architectural differences, state-space and transformer models showed comparable temporal biases. Our findings deepen the understanding of temporal biases in in-context learning and offer an illustration of how these biases can enable temporal separation and episodic retrieval.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformerå’ŒState-Space Modelsåœ¨In-context learningä¸­å¦‚ä½•å—æ—¶é—´åå·®ï¼ˆTemporal Biasesï¼‰çš„å½±å“ï¼Œåˆ†æäº†æ¨¡å‹æ£€ç´¢ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æœºåˆ¶ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å›ºå®šé‡å¤Tokençš„ä½ç½®å¹¶ç½®æ¢åºåˆ—ä¸­çš„å…¶ä»–å†…å®¹æ¥æ¶ˆé™¤è¯­ä¹‰å¹²æ‰°ï¼Œä»è€Œä¸“é—¨éš”ç¦»å¹¶é‡åŒ–æ—¶é—´æ•ˆåº”å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“ã€‚å®éªŒå‘ç°ï¼Œæ¨¡å‹åœ¨è¿›è¡Œä¸‹ä¸€Tokené¢„æµ‹æ—¶ä¸€è‡´è¡¨ç°å‡ºå¯¹è¾“å…¥å¼€å¤´æˆ–ç»“å°¾å†…å®¹çš„æ˜¾è‘—åå¥½ï¼Œå¯¼è‡´ä½äºPromptä¸­é—´çš„ä¿¡æ¯æ£€ç´¢å¯é æ€§è¾ƒä½ã€‚é€šè¿‡æ¶ˆèå®éªŒï¼Œç ”ç©¶è¿›ä¸€æ­¥è¯æ˜äº†Transformerä¸­çš„è¿™ç§æ—¶é—´åå·®ä¸æ„Ÿåº”å¤´ï¼ˆInduction Headsï¼‰çš„è¿ä½œæœºåˆ¶å¯†åˆ‡ç›¸å…³ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å­˜åœ¨æ¶æ„å·®å¼‚ï¼ŒState-Space Modelsä¹Ÿè¡¨ç°å‡ºä¸Transformeræ¨¡å‹ç›¸ä¼¼çš„æ—¶é—´åå·®ç‰¹å¾ã€‚è¿™äº›å‘ç°åŠ æ·±äº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹å¦‚ä½•åˆ©ç”¨æ—¶é—´åˆ†ç¦»å®ç°æƒ…å¢ƒæ£€ç´¢çš„ç†è§£ï¼Œæ­ç¤ºäº†å…¶ä¸äººç±»æƒ…æ™¯è®°å¿†ç±»ä¼¼çš„è®¤çŸ¥ç‰¹æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22752v1",
      "published_date": "2025-10-26 17:01:41 UTC",
      "updated_date": "2025-10-26 17:01:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:25.951233+00:00"
    },
    {
      "arxiv_id": "2510.22751v1",
      "title": "Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models",
      "title_zh": "ç”¨äºç¼“è§£å¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„å¤šæ¨¡æ€äº‹å®éªŒè¯æ¡†æ¶",
      "authors": [
        "Piyushkumar Patel"
      ],
      "abstract": "While Large Language Models have transformed how we interact with AI systems, they suffer from a critical flaw: they confidently generate false information that sounds entirely plausible. This hallucination problem has become a major barrier to deploying these models in real-world applications where accuracy matters. We developed a fact verification framework that catches and corrects these errors in real-time by cross checking LLM outputs against multiple knowledge sources. Our system combines structured databases, live web searches, and academic literature to verify factual claims as they're generated. When we detect inconsistencies, we automatically correct them while preserving the natural flow of the response. Testing across various domains showed we could reduce hallucinations by 67% without sacrificing response quality. Domain experts in healthcare, finance, and scientific research rated our corrected outputs 89% satisfactory a significant improvement over unverified LLM responses. This work offers a practical solution for making LLMs more trustworthy in applications where getting facts wrong isn't an option.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Large Language Models (LLMs) åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è‡ªä¿¡åœ°äº§ç”Ÿè™šå‡ä¿¡æ¯ï¼ˆå³ Hallucinationsï¼‰çš„ä¸¥é‡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¤šæ¨¡æ€äº‹å®éªŒè¯æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡å°† LLM çš„è¾“å‡ºä¸ç»“æ„åŒ–æ•°æ®åº“ã€å®æ—¶ç½‘é¡µæœç´¢å’Œå­¦æœ¯æ–‡çŒ®ç­‰å¤šç§çŸ¥è¯†æºè¿›è¡Œå®æ—¶äº¤å‰æ¯”å¯¹ï¼Œå®ç°å¯¹äº‹å®æ€§é™ˆè¿°çš„å³æ—¶éªŒè¯ã€‚ç³»ç»Ÿåœ¨æ£€æµ‹åˆ°ä¸ä¸€è‡´æ€§æ—¶ä¼šè‡ªåŠ¨è¿›è¡Œä¿®æ­£ï¼ŒåŒæ—¶ç¡®ä¿å›å¤å†…å®¹çš„è‡ªç„¶æµç•…æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†æ¨¡å‹åœ¨åŒ»ç–—ã€é‡‘èç­‰é«˜å‡†ç¡®æ€§è¦æ±‚é¢†åŸŸéƒ¨ç½²çš„éšœç¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ä¸ç‰ºç‰²å“åº”è´¨é‡çš„å‰æä¸‹ï¼ŒæˆåŠŸå°† Hallucinations å‡å°‘äº† 67%ã€‚æ¥è‡ªåŒ»ç–—ã€é‡‘èå’Œç§‘å­¦ç ”ç©¶é¢†åŸŸçš„é¢†åŸŸä¸“å®¶å¯¹ä¿®æ­£åè¾“å‡ºçš„æ»¡æ„åº¦è¾¾åˆ°äº† 89%ï¼Œæ˜¾è‘—æå‡äº† LLM åœ¨ä¸¥è°¨åº”ç”¨åœºæ™¯ä¸­çš„å¯ä¿¡åº¦ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22751v1",
      "published_date": "2025-10-26 16:58:54 UTC",
      "updated_date": "2025-10-26 16:58:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:18.779543+00:00"
    },
    {
      "arxiv_id": "2510.22747v1",
      "title": "Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„ä½èµ„æºæ–¹è¨€é€‚é…ï¼šæ³•è¯­æ–¹è¨€æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Eeham Khan",
        "Firas Saidani",
        "Owen Van Esbroeck",
        "Richard Khoury",
        "Leila Kosseim"
      ],
      "abstract": "Despite the widespread adoption of large language models (LLMs), their strongest capabilities remain largely confined to a small number of high-resource languages for which there is abundant training data. Recently, continual pre-training (CPT) has emerged as a means to fine-tune these models to low-resource regional dialects. In this paper, we study the use of CPT for dialect learning under tight data and compute budgets. Using low-rank adaptation (LoRA) and compute-efficient continual pre-training, we adapt three LLMs to the QuÃ©bec French dialect using a very small dataset and benchmark them on the COLE suite. Our experiments demonstrate an improvement on the minority dialect benchmarks with minimal regression on the prestige language benchmarks with under 1% of model parameters updated. Analysis of the results demonstrate that gains are highly contingent on corpus composition. These findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can narrow the dialect gap by providing cost-effective and sustainable language resource creation, expanding high-quality LLM access to minority linguistic communities. We release the first QuÃ©bec French LLMs on HuggingFace.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æœ‰é™çš„æ•°æ®å’Œè®¡ç®—é¢„ç®—ä¸‹ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‘ä½èµ„æºåŒºåŸŸæ–¹è¨€è¿›è¡ŒæŒç»­é¢„è®­ç»ƒï¼ˆContinual Pre-training, CPTï¼‰çš„é€‚é…æ–¹æ³•ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ä½ç§©è‡ªé€‚åº”ï¼ˆLow-Rank Adaptation, LoRAï¼‰å’Œè®¡ç®—é«˜æ•ˆçš„é¢„è®­ç»ƒæŠ€æœ¯ï¼Œåœ¨æå°è§„æ¨¡çš„æ•°æ®é›†ä¸Šå°†ä¸‰ç§ LLM é€‚é…è‡³é­åŒ—å…‹æ³•è¯­ï¼ˆQuÃ©bec Frenchï¼‰æ–¹è¨€ï¼Œå¹¶åœ¨ COLE åŸºå‡†å¥—ä»¶ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä»…æ›´æ–°ä¸åˆ° 1% æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å°‘æ•°æ–¹è¨€åŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œä¸”åœ¨æ ‡å‡†è¯­è¨€ä¸Šçš„æ€§èƒ½é€€åŒ–æå°ã€‚åˆ†æå‘ç°ï¼Œæ€§èƒ½å¢ç›Šä¸è¯­æ–™åº“æ„æˆé«˜åº¦ç›¸å…³ï¼Œè¿™è¯æ˜äº†ç»“åˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„ CPT æŠ€æœ¯æ˜¯ç¼©å°æ–¹è¨€å·®è·ã€ä¸ºå°‘æ•°è¯­è¨€ç¾¤ä½“æä¾›é«˜è´¨é‡ LLM æ¥å…¥çš„ä¸€ç§ä½æˆæœ¬ä¸”å¯æŒç»­çš„æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨ HuggingFace ä¸Šå‘å¸ƒäº†é¦–ä¸ªé’ˆå¯¹é­åŒ—å…‹æ³•è¯­ä¼˜åŒ–çš„ LLM æ¨¡å‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to LREC 2026",
      "pdf_url": "https://arxiv.org/pdf/2510.22747v1",
      "published_date": "2025-10-26 16:49:06 UTC",
      "updated_date": "2025-10-26 16:49:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:25.674969+00:00"
    },
    {
      "arxiv_id": "2510.22740v1",
      "title": "Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM",
      "title_zh": "Policies over Posesï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤šæœºå™¨äºº SLAM åˆ†å¸ƒå¼ä½å§¿å›¾ä¼˜åŒ–",
      "authors": [
        "Sai Krishna Ghanta",
        "Ramviyas Parasuraman"
      ],
      "abstract": "We consider the distributed pose-graph optimization (PGO) problem, which is fundamental in accurate trajectory estimation in multi-robot simultaneous localization and mapping (SLAM). Conventional iterative approaches linearize a highly non-convex optimization objective, requiring repeated solving of normal equations, which often converge to local minima and thus produce suboptimal estimates. We propose a scalable, outlier-robust distributed planar PGO framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed PGO as a partially observable Markov game defined on local pose-graphs, where each action refines a single edge's pose estimate. A graph partitioner decomposes the global pose graph, and each robot runs a recurrent edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating to denoise noisy edges. Robots sequentially refine poses through a hybrid policy that utilizes prior action memory and graph embeddings. After local graph correction, a consensus scheme reconciles inter-robot disagreements to produce a globally consistent estimate. Our extensive evaluations on a comprehensive suite of synthetic and real-world datasets demonstrate that our learned MARL-based actors reduce the global objective by an average of 37.5% more than the state-of-the-art distributed PGO framework, while enhancing inference efficiency by at least 6X. We also demonstrate that actor replication allows a single learned policy to scale effortlessly to substantially larger robot teams without any retraining. Code is publicly available at https://github.com/herolab-uga/policies-over-poses.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæœºå™¨äºº SLAM ä¸­åˆ†å¸ƒå¼ Pose-Graph Optimization (PGO) æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜å’Œæ¬¡ä¼˜ä¼°è®¡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Multi-Agent Reinforcement Learning (MARL) çš„å¯æ‰©å±•ä¸”é²æ£’çš„åˆ†å¸ƒå¼å¹³é¢ PGO æ¡†æ¶ã€‚ç ”ç©¶è€…å°†åˆ†å¸ƒå¼ PGO å»ºæ¨¡ä¸ºåœ¨å±€éƒ¨ä½å§¿å›¾ä¸Šå®šä¹‰çš„éƒ¨åˆ†å¯è§‚æµ‹ Markov gameï¼Œåˆ©ç”¨å¸¦æœ‰è‡ªé€‚åº”è¾¹ç¼˜é—¨æ§çš„é€’å½’è¾¹ç¼˜æ¡ä»¶ Graph Neural Network (GNN) ç¼–ç å™¨å¯¹å™ªå£°è¾¹ç¼˜è¿›è¡Œå»å™ªã€‚æœºå™¨äººé€šè¿‡æ··åˆç­–ç•¥è¿›è¡Œä½å§¿ç²¾ç»†åŒ–ï¼Œå¹¶ç»“åˆ Consensus scheme åè°ƒä¸åŒæœºå™¨äººé—´çš„ä¸ä¸€è‡´ï¼Œä»è€Œç”Ÿæˆå…¨å±€ä¸€è‡´çš„è½¨è¿¹ä¼°è®¡ç»“æœã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é™ä½å…¨å±€ç›®æ ‡å‡½æ•°æ–¹é¢æ¯”ç°æœ‰æœ€å…ˆè¿›æ¡†æ¶å¹³å‡æå‡äº† 37.5%ï¼Œä¸”æ¨ç†æ•ˆç‡è‡³å°‘æé«˜äº† 6 å€ã€‚æ­¤å¤–ï¼Œè¯¥å­¦ä¹ ç­–ç•¥å…·å¤‡ä¼˜ç§€çš„æ‰©å±•æ€§ï¼Œå…è®¸å•ä¸ªç­–ç•¥åœ¨æ— éœ€é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ç›´æ¥åº”ç”¨äºè§„æ¨¡å¤§å¾—å¤šçš„æœºå™¨äººå›¢é˜Ÿã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE International Symposium on Multi-Robot & Multi-Agent Systems (MRS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22740v1",
      "published_date": "2025-10-26 16:21:24 UTC",
      "updated_date": "2025-10-26 16:21:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:37.467157+00:00"
    },
    {
      "arxiv_id": "2510.22739v1",
      "title": "REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization",
      "title_zh": "REVISIONï¼šé¢å‘ç”µå•†è§†è§‰æœç´¢ç³»ç»Ÿä¼˜åŒ–çš„åæ€å¼æ„å›¾æŒ–æ˜ä¸åœ¨çº¿æ¨ç†è¾…åŠ©",
      "authors": [
        "Yiwen Tang",
        "Qiuyu Zhao",
        "Zenghui Sun",
        "Jinsong Lan",
        "Xiaoyong Zhu",
        "Bo Zheng",
        "Kaifu Zhang"
      ],
      "abstract": "In Taobao e-commerce visual search, user behavior analysis reveals a large proportion of no-click requests, suggesting diverse and implicit user intents. These intents are expressed in various forms and are difficult to mine and discover, thereby leading to the limited adaptability and lag in platform strategies. This greatly restricts users' ability to express diverse intents and hinders the scalability of the visual search system. This mismatch between user implicit intent expression and system response defines the User-SearchSys Intent Discrepancy. To alleviate the issue, we propose a novel framework REVISION. This framework integrates offline reasoning mining with online decision-making and execution, enabling adaptive strategies to solve implicit user demands. In the offline stage, we construct a periodic pipeline to mine discrepancies from historical no-click requests. Leveraging large models, we analyze implicit intent factors and infer optimal suggestions by jointly reasoning over query and product metadata. These inferred suggestions serve as actionable insights for refining platform strategies. In the online stage, REVISION-R1-3B, trained on the curated offline data, performs holistic analysis over query images and associated historical products to generate optimization plans and adaptively schedule strategies across the search pipeline. Our framework offers a streamlined paradigm for integrating large models with traditional search systems, enabling end-to-end intelligent optimization across information aggregation and user interaction. Experimental results demonstrate that our approach improves the efficiency of implicit intent mining from large-scale search logs and significantly reduces the no-click rate.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†REVISIONæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ·˜å®ç”µå•†è§†è§‰æœç´¢ä¸­å› ç”¨æˆ·æ„å›¾éšæ™¦å¯¼è‡´çš„æ— ç‚¹å‡»è¯·æ±‚æ¯”ä¾‹é«˜ä»¥åŠç³»ç»Ÿå“åº”æ»åç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é’ˆå¯¹â€œUser-SearchSys Intent Discrepancyâ€è¿™ä¸€æ ¸å¿ƒçŸ›ç›¾ï¼Œé€šè¿‡æ•´åˆç¦»çº¿æ¨ç†æŒ–æ˜ä¸åœ¨çº¿å†³ç­–æ‰§è¡Œï¼Œå®ç°äº†é’ˆå¯¹ç”¨æˆ·éšå«éœ€æ±‚çš„è‡ªé€‚åº”ç­–ç•¥ä¼˜åŒ–ã€‚åœ¨ç¦»çº¿é˜¶æ®µï¼ŒREVISIONåˆ©ç”¨å¤§æ¨¡å‹(Large Models)å¯¹å†å²æ— ç‚¹å‡»æ•°æ®è¿›è¡Œå‘¨æœŸæ€§åˆ†æï¼Œç»“åˆæŸ¥è¯¢ä¸å•†å“å…ƒæ•°æ®æ¨ç†å‡ºè¡ŒåŠ¨æŒ‡å—ï¼›åœ¨åœ¨çº¿é˜¶æ®µï¼ŒåŸºäºç¦»çº¿æ•°æ®è®­ç»ƒçš„REVISION-R1-3Bæ¨¡å‹é€šè¿‡åˆ†ææŸ¥è¯¢å›¾åƒåŠå†å²å…³è”å•†å“ï¼Œå®æ—¶ç”Ÿæˆä¼˜åŒ–è®¡åˆ’å¹¶åŠ¨æ€è°ƒåº¦æœç´¢é“¾è·¯ã€‚è¯¥æ–¹æ¡ˆæä¾›äº†ä¸€ç§å°†å¤§æ¨¡å‹ä¸ä¼ ç»Ÿæœç´¢ç³»ç»Ÿé›†æˆçš„æ–°èŒƒå¼ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„æ™ºèƒ½ä¼˜åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†ä»å¤§è§„æ¨¡æœç´¢æ—¥å¿—ä¸­æŒ–æ˜éšå«æ„å›¾çš„æ•ˆç‡ï¼Œå¹¶æœ‰æ•ˆé™ä½äº†ç³»ç»Ÿçš„æ— ç‚¹å‡»ç‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22739v1",
      "published_date": "2025-10-26 16:15:50 UTC",
      "updated_date": "2025-10-26 16:15:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:32.772543+00:00"
    },
    {
      "arxiv_id": "2510.22733v2",
      "title": "E2Rank: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker",
      "title_zh": "E2Rankï¼šæ–‡æœ¬åµŒå…¥æ¨¡å‹ä¹Ÿå¯ä½œä¸ºé«˜æ•ˆä¸”ç²¾å‡†çš„åˆ—è¡¨å¼é‡æ’åºå™¨",
      "authors": [
        "Qi Liu",
        "Yanzhao Zhang",
        "Mingxin Li",
        "Dingkun Long",
        "Pengjun Xie",
        "Jiaxin Mao"
      ],
      "abstract": "Text embedding models serve as a fundamental component in real-world search applications. By mapping queries and documents into a shared embedding space, they deliver competitive retrieval performance with high efficiency. However, their ranking fidelity remains limited compared to dedicated rerankers, especially recent LLM-based listwise rerankers, which capture fine-grained query-document and document-document interactions. In this paper, we propose a simple yet effective unified framework E2Rank, means Efficient Embedding-based Ranking (also means Embedding-to-Rank), which extends a single text embedding model to perform both high-quality retrieval and listwise reranking through continued training under a listwise ranking objective, thereby achieving strong effectiveness with remarkable efficiency. By applying cosine similarity between the query and document embeddings as a unified ranking function, the listwise ranking prompt, which is constructed from the original query and its candidate documents, serves as an enhanced query enriched with signals from the top-K documents, akin to pseudo-relevance feedback (PRF) in traditional retrieval models. This design preserves the efficiency and representational quality of the base embedding model while significantly improving its reranking performance. Empirically, E2Rank achieves state-of-the-art results on the BEIR reranking benchmark and demonstrates competitive performance on the reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also show that the ranking training process improves embedding performance on the MTEB benchmark. Our findings indicate that a single embedding model can effectively unify retrieval and reranking, offering both computational efficiency and competitive ranking accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† E2Rank (Efficient Embedding-based Ranking)ï¼Œæ—¨åœ¨é€šè¿‡ç»Ÿä¸€æ¡†æ¶è§£å†³æ–‡æœ¬åµŒå…¥æ¨¡å‹åœ¨æ’åºä¿çœŸåº¦ä¸Šé€Šè‰²äºä¸“ç”¨ LLM-based listwise rerankers çš„å±€é™æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨ listwise æ’åºç›®æ ‡ä¸‹è¿›è¡ŒæŒç»­è®­ç»ƒï¼Œä½¿å•ä¸ªæ–‡æœ¬åµŒå…¥æ¨¡å‹èƒ½å¤ŸåŒæ—¶æ‰§è¡Œé«˜è´¨é‡çš„æ£€ç´¢å’Œ listwise rerankingã€‚E2Rank å°†åŸå§‹æŸ¥è¯¢ä¸å€™é€‰æ–‡æ¡£æ„å»ºçš„ listwise ranking prompt è§†ä¸ºä¸€ç§å¢å¼ºæŸ¥è¯¢ï¼Œåˆ©ç”¨ top-K æ–‡æ¡£çš„ä¿¡å·å®ç°ç±»ä¼¼äºä¼ ç»Ÿæ¨¡å‹ä¸­ pseudo-relevance feedback (PRF) çš„æ•ˆæœã€‚è¯¥è®¾è®¡åœ¨ä¿æŒåŸºç¡€åµŒå…¥æ¨¡å‹æ•ˆç‡å’Œè¡¨å¾è´¨é‡çš„åŒæ—¶ï¼Œé€šè¿‡è®¡ç®—æŸ¥è¯¢ä¸æ–‡æ¡£åµŒå…¥ä¹‹é—´çš„ cosine similarity æ˜¾è‘—æå‡äº†é‡æ’æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒE2Rank åœ¨ BEIR é‡æ’åŸºå‡†ä¸Šè¾¾åˆ°äº† state-of-the-art æ°´å¹³ï¼Œå¹¶åœ¨æ¨ç†å¯†é›†å‹çš„ BRIGHT åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæä½çš„å»¶è¿Ÿå’Œç«äº‰ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè¯¥è®­ç»ƒè¿‡ç¨‹è¿˜æå‡äº†æ¨¡å‹åœ¨ MTEB åŸºå‡†ä¸Šçš„åµŒå…¥è¡¨ç°ï¼Œè¯æ˜äº†å•ä¸ªåµŒå…¥æ¨¡å‹å¯ä»¥æœ‰æ•ˆç»Ÿä¸€æ£€ç´¢ä¸é‡æ’ï¼Œå…¼é¡¾è®¡ç®—æ•ˆç‡ä¸æ’åºç²¾åº¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and models are avaliable at https://alibaba-nlp.github.io/E2Rank",
      "pdf_url": "https://arxiv.org/pdf/2510.22733v2",
      "published_date": "2025-10-26 16:04:48 UTC",
      "updated_date": "2025-10-31 03:47:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:50.455185+00:00"
    },
    {
      "arxiv_id": "2510.22732v2",
      "title": "WebATLAS: An LLM Agent with Experience-Driven Memory and Action Simulation",
      "title_zh": "WebATLASï¼šåŸºäºç»éªŒé©±åŠ¨å‹è®°å¿†ä¸åŠ¨ä½œæ¨¡æ‹Ÿçš„ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Jiali Cheng",
        "Anjishnu Kumar",
        "Roshan Lal",
        "Rishi Rajasekaran",
        "Hani Ramezani",
        "Omar Zia Khan",
        "Oleg Rokhlenko",
        "Sunny Chiu-Webster",
        "Gang Hua",
        "Hadi Amiri"
      ],
      "abstract": "Large Language Model (LLM) web agents often struggle with long-horizon web navigation and web task completion in new websites, producing inefficient action sequences unless fine-tuned on environment-specific data. We show that experience-driven memory, combined with look-ahead action simulation, is sufficient for LLM agents to adapt to unseen web environments by remembering past failures and predicting the consequences of future actions. We introduce WebATLAS (Actor-Critic Task-completion with Look-ahead Action Simulation), a memory-augmented LLM web agent that learns a lightweight internal model of the environment from interaction experience and performs hypothetical action rollouts before acting in the real world. WebATLAS builds a persistent cognitive map via curiosity-driven exploration, stores interaction outcomes as experience-based memory, and evaluates candidate actions in cognitive space using a planner--simulator--critic loop. This enables the agent to reuse past experience, avoid previously unsuccessful behaviors, and generate more efficient plans. We evaluate WebATLAS on the WebArena-Lite benchmark for autonomous web navigation and demonstrate a success rate of 63%, outperforming the previous state-of-the-art at 53.9%. Unlike previous systems, our modular architecture requires no website-specific LLM fine-tuning. Ablation studies confirm that experience-driven memory, look-ahead action simulation, and hierarchical replanning play complementary roles in enabling robust, training-free web agents.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† WebATLAS (Actor-Critic Task-completion with Look-ahead Action Simulation)ï¼Œè¿™æ˜¯ä¸€ç§å…·å¤‡ç»éªŒé©±åŠ¨è®°å¿†å’ŒåŠ¨ä½œæ¨¡æ‹Ÿèƒ½åŠ›çš„ LLM web agentï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿ç¨‹ç½‘é¡µå¯¼èˆªå’Œæ–°ç½‘ç«™ä»»åŠ¡æ—¶å› ç¼ºä¹ç¯å¢ƒç‰¹å®šå¾®è°ƒè€Œå¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“åˆç»éªŒé©±åŠ¨è®°å¿† (experience-driven memory) å’Œå‰ç»æ€§åŠ¨ä½œæ¨¡æ‹Ÿ (look-ahead action simulation)ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿä»äº¤äº’ç»éªŒä¸­å­¦ä¹ è½»é‡çº§å†…éƒ¨ç¯å¢ƒæ¨¡å‹ï¼Œå¹¶åœ¨çœŸå®æ‰§è¡Œå‰è¿›è¡Œè™šæ‹ŸåŠ¨ä½œæ¼”ç»ƒã€‚WebATLAS åˆ©ç”¨å¥½å¥‡å¿ƒé©±åŠ¨çš„æ¢ç´¢æ„å»ºæŒä¹…çš„è®¤çŸ¥åœ°å›¾ (cognitive map)ï¼Œå¹¶é€šè¿‡â€œç­–åˆ’è€…-æ¨¡æ‹Ÿå™¨-è¯„ä»·è€…â€ (planner-simulator-critic) å¾ªç¯è¯„ä¼°å€™é€‰åŠ¨ä½œï¼Œä»è€Œå®ç°ç»éªŒå¤ç”¨å¹¶æœ‰æ•ˆé¿å…é‡å¤å¤±è´¥è¡Œä¸ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWebATLAS åœ¨ WebArena-Lite åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† 63% çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºæ­¤å‰ 53.9% çš„é¢†åŸŸæœ€ä¼˜æ°´å¹³ (state-of-the-art)ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šç½‘ç«™è¿›è¡Œ LLM fine-tuningï¼Œæ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†ç»éªŒè®°å¿†ã€åŠ¨ä½œæ¨¡æ‹Ÿä¸åˆ†å±‚é‡æ–°è§„åˆ’ (hierarchical replanning) åœ¨æ„å»ºç¨³å¥ã€æ— éœ€è®­ç»ƒçš„ç½‘é¡µæ™ºèƒ½ä½“ä¸­çš„å…³é”®äº’è¡¥ä½œç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, NeurIPS 2025 Workshop on Language Agents and World Models",
      "pdf_url": "https://arxiv.org/pdf/2510.22732v2",
      "published_date": "2025-10-26 16:03:39 UTC",
      "updated_date": "2025-12-19 23:16:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:54.458583+00:00"
    },
    {
      "arxiv_id": "2510.22729v1",
      "title": "Critical Insights into Leading Conversational AI Models",
      "title_zh": "é¡¶å°–å¯¹è¯å¼äººå·¥æ™ºèƒ½æ¨¡å‹çš„æ·±åº¦è§£æ",
      "authors": [
        "Urja Kohli",
        "Aditi Singh",
        "Arun Sharma"
      ],
      "abstract": "Big Language Models (LLMs) are changing the way businesses use software, the way people live their lives and the way industries work. Companies like Google, High-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial to look at how each model is different in terms of performance, moral behaviour and usability, as these differences are based on the different ideas that built them. This study compares five top LLMs: Google's Gemini, High-Flyer's DeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs this by analysing three important factors: Performance and Accuracy, Ethics and Bias Mitigation and Usability and Integration. It was found that Claude has good moral reasoning, Gemini is better at multimodal capabilities and has strong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA is good for open applications and ChatGPT delivers balanced performance with a focus on usage. It was concluded that these models are different in terms of how well they work, how easy they are to use and how they treat people ethically, making it a point that each model should be utilised by the user in a way that makes the most of its strengths.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹äº”ç§é¢†å…ˆçš„ Conversational AI æ¨¡å‹è¿›è¡Œäº†æ·±å…¥æ¯”è¾ƒåˆ†æï¼Œæ¶µç›–äº† Google çš„ Geminiã€High-Flyer çš„ DeepSeekã€Anthropic çš„ Claudeã€OpenAI çš„ GPT ä»¥åŠ Meta çš„ LLaMAã€‚é€šè¿‡ Performance and Accuracyã€Ethics and Bias Mitigation ä»¥åŠ Usability and Integration ä¸‰ä¸ªå…³é”®ç»´åº¦çš„è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†å„æ¨¡å‹åœ¨è®¾è®¡ç†å¿µä¸å®é™…è¡¨ç°ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚ç»“æœæ˜¾ç¤ºï¼ŒClaude åœ¨ Moral Reasoning æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒGemini åœ¨ Multimodal èƒ½åŠ›å’Œä¼¦ç†æ¡†æ¶ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œè€Œ DeepSeek åˆ™æ“…é•¿ Fact-based Reasoningã€‚LLaMA å› å…¶å¼€æºç‰¹æ€§æ›´é€‚ç”¨äº Open Applicationsï¼ŒChatGPT åˆ™åœ¨ç»¼åˆæ€§èƒ½ä¸æ˜“ç”¨æ€§ä¹‹é—´è¾¾æˆäº†è‰¯å¥½å¹³è¡¡ã€‚è¯¥ç ”ç©¶æ€»ç»“æŒ‡å‡ºï¼Œå„æ¨¡å‹åœ¨æŠ€æœ¯æ•ˆèƒ½ä¸ä¼¦ç†å¤„ç†ä¸Šå„æœ‰åƒç§‹ï¼Œç”¨æˆ·åº”æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯çš„ç‰¹æ®Šéœ€æ±‚é€‰æ‹©æœ€åŒ¹é…çš„æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 7 tables, 3 figures. Open-access preprint intended for journal or conference submission",
      "pdf_url": "https://arxiv.org/pdf/2510.22729v1",
      "published_date": "2025-10-26 15:57:27 UTC",
      "updated_date": "2025-10-26 15:57:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:43:54.874726+00:00"
    },
    {
      "arxiv_id": "2510.23668v1",
      "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems",
      "title_zh": "åŸºäº STL åˆ†è§£ä¸ LSTM-ARIMA-XGBoost æ··åˆæ¨¡å‹çš„æ™ºèƒ½äº¤é€šç³»ç»Ÿäº¤é€šæµé¢„æµ‹",
      "authors": [
        "Fujiang Yuan",
        "Yangrui Fan",
        "Xiaohuan Bing",
        "Zhen Tian",
        "Chunhong Yuan",
        "Yankang Li"
      ],
      "abstract": "Accurate traffic flow forecasting is essential for intelligent transportation systems and urban traffic management. However, single model approaches often fail to capture the complex, nonlinear, and multi scale temporal patterns in traffic flow data. This study proposes a decomposition driven hybrid framework that integrates Seasonal Trend decomposition using Loess (STL) with three complementary predictive models. STL first decomposes the original time series into trend, seasonal, and residual components. Then, a Long Short Term Memory (LSTM) network models long term trends, an Autoregressive Integrated Moving Average (ARIMA) model captures seasonal periodicity, and an Extreme Gradient Boosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The final forecast is obtained through multiplicative integration of the sub model predictions. Using 998 traffic flow records from a New York City intersection between November and December 2015, results show that the LSTM ARIMA XGBoost hybrid model significantly outperforms standalone models including LSTM, ARIMA, and XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy effectively isolates temporal characteristics, allowing each model to specialize, thereby improving prediction accuracy, interpretability, and robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Intelligent transportation systemsä¸­çš„äº¤é€šæµé¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåˆ†è§£é©±åŠ¨çš„æ··åˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨STLï¼ˆSeasonal Trend decomposition using Loessï¼‰æŠ€æœ¯å°†åŸå§‹æ—¶é—´åºåˆ—åˆ†è§£ä¸ºè¶‹åŠ¿é¡¹ã€å­£èŠ‚é¡¹å’Œæ®‹å·®é¡¹ï¼Œæ—¨åœ¨æ•æ‰å¤æ‚çš„éçº¿æ€§å¤šå°ºåº¦æ—¶é—´ç‰¹å¾ã€‚å…·ä½“è€Œè¨€ï¼Œç³»ç»Ÿé›†æˆäº†ä¸€ä¸ªç”¨äºæ•æ‰é•¿æœŸè¶‹åŠ¿çš„LSTMï¼ˆLong Short Term Memoryï¼‰ç½‘ç»œï¼Œä¸€ä¸ªå¤„ç†å­£èŠ‚æ€§å‘¨æœŸæ€§çš„ARIMAï¼ˆAutoregressive Integrated Moving Averageï¼‰æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ªé¢„æµ‹éçº¿æ€§æ®‹å·®æ³¢åŠ¨çš„XGBoostç®—æ³•ã€‚æœ€ç»ˆé¢„æµ‹ç»“æœé€šè¿‡å­æ¨¡å‹é¢„æµ‹å€¼çš„ä¹˜æ³•é›†æˆè·å¾—ã€‚å®éªŒåˆ©ç”¨çº½çº¦å¸‚äº¤å‰è·¯å£çš„äº¤é€šæµæ•°æ®è¿›è¡ŒéªŒè¯ï¼Œç»“æœè¡¨æ˜è¿™ç§LSTM-ARIMA-XGBoostæ··åˆæ¨¡å‹åœ¨MAEã€RMSEå’ŒR-squaredæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå•ä¸€çš„LSTMã€ARIMAå’ŒXGBoostæ¨¡å‹ã€‚è¿™ç§åˆ†è§£ç­–ç•¥æœ‰æ•ˆéš”ç¦»äº†æ—¶é—´ç‰¹å¾ï¼Œä½¿å„æ¨¡å‹èƒ½å¤Ÿå‘æŒ¥å…¶ä¸“ä¸šä¼˜åŠ¿ï¼Œä»è€Œæ˜¾è‘—æå‡äº†äº¤é€šæµé¢„æµ‹çš„å‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23668v1",
      "published_date": "2025-10-26 15:54:48 UTC",
      "updated_date": "2025-10-26 15:54:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:08.386795+00:00"
    },
    {
      "arxiv_id": "2510.22712v1",
      "title": "Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles",
      "title_zh": "Step2Motionï¼šåŸºäºå‹åŠ›æ„Ÿåº”é‹å«çš„è¿åŠ¨é‡å»º",
      "authors": [
        "Jose Luis Ponton",
        "Eduardo Alvarado",
        "Lin Geng Foo",
        "Nuria Pelechano",
        "Carlos Andujar",
        "Marc Habermann"
      ],
      "abstract": "Human motion is fundamentally driven by continuous physical interaction with the environment. Whether walking, running, or simply standing, the forces exchanged between our feet and the ground provide crucial insights for understanding and reconstructing human movement. Recent advances in wearable insole devices offer a compelling solution for capturing these forces in diverse, real-world scenarios. Sensor insoles pose no constraint on the users' motion (unlike mocap suits) and are unaffected by line-of-sight limitations (in contrast to optical systems). These qualities make sensor insoles an ideal choice for robust, unconstrained motion capture, particularly in outdoor environments. Surprisingly, leveraging these devices with recent motion reconstruction methods remains largely unexplored. Aiming to fill this gap, we present Step2Motion, the first approach to reconstruct human locomotion from multi-modal insole sensors. Our method utilizes pressure and inertial data-accelerations and angular rates-captured by the insoles to reconstruct human motion. We evaluate the effectiveness of our approach across a range of experiments to show its versatility for diverse locomotion styles, from simple ones like walking or jogging up to moving sideways, on tiptoes, slightly crouching, or dancing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Step2Motionï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨å¤šæ¨¡æ€å‹åŠ›æ„Ÿåº”é‹å«(Pressure Sensing Insoles)ä¼ æ„Ÿå™¨é‡å»ºäººç±»è¿åŠ¨(Locomotion Reconstruction)çš„æ–¹æ³•ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆé‹å«æ•æ‰åˆ°çš„å‹åŠ›æ•°æ®ã€åŠ é€Ÿåº¦å’Œè§’é€Ÿç‡ç­‰æƒ¯æ€§æ•°æ®ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»ŸåŠ¨ä½œæ•æ‰(Mocap)å¥—ä»¶çš„è¿åŠ¨é™åˆ¶åŠå…‰å­¦ç³»ç»Ÿçš„è§†çº¿(Line-of-sight)é®æŒ¡é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ­¥è¡Œã€æ…¢è·‘ã€ä¾§å‘ç§»åŠ¨ã€è¸®èµ·è„šå°–ã€å¾®è¹²ä»¥åŠèˆè¹ˆç­‰å¤šç§è¿åŠ¨é£æ ¼ä¸­å‡è¡¨ç°å‡ºæå¼ºçš„é€šç”¨æ€§å’Œç¨³å¥æ€§ã€‚ä½œä¸ºä¸€ç§æ— çº¦æŸçš„å¯ç©¿æˆ´è§£å†³æ–¹æ¡ˆï¼ŒStep2Motionä¸ºåœ¨å¤æ‚çš„æˆ·å¤–ç°å®ç¯å¢ƒä¸­å®ç°ç²¾ç¡®çš„åŠ¨ä½œæ•æ‰æä¾›äº†ç†æƒ³çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22712v1",
      "published_date": "2025-10-26 15:12:02 UTC",
      "updated_date": "2025-10-26 15:12:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:02.753663+00:00"
    },
    {
      "arxiv_id": "2510.23667v1",
      "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization",
      "title_zh": "Optimize Any Topologyï¼šä¸€ç§é€‚ç”¨äºä»»æ„å½¢çŠ¶ä¸åˆ†è¾¨ç‡çš„ç»“æ„æ‹“æ‰‘ä¼˜åŒ–åŸºç¡€æ¨¡å‹",
      "authors": [
        "Amin Heyrani Nobari",
        "Lyle Regenwetter",
        "Cyril Picard",
        "Ligong Han",
        "Faez Ahmed"
      ],
      "abstract": "Structural topology optimization (TO) is central to engineering design but remains computationally intensive due to complex physics and hard constraints. Existing deep-learning methods are limited to fixed square grids, a few hand-coded boundary conditions, and post-hoc optimization, preventing general deployment. We introduce Optimize Any Topology (OAT), a foundation-model framework that directly predicts minimum-compliance layouts for arbitrary aspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines a resolution- and shape-agnostic autoencoder with an implicit neural-field decoder and a conditional latent-diffusion model trained on OpenTO, a new corpus of 2.2 million optimized structures covering 2 million unique boundary-condition configurations. On four public benchmarks and two challenging unseen tests, OAT lowers mean compliance up to 90% relative to the best prior models and delivers sub-1 second inference on a single GPU across resolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These results establish OAT as a general, fast, and resolution-free framework for physics-aware topology optimization and provide a large-scale dataset to spur further research in generative modeling for inverse design. Code & data can be found at https://github.com/ahnobari/OptimizeAnyTopology.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Optimize Any Topology (OAT)ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ç»“æ„æ‹“æ‰‘ä¼˜åŒ– (Structural topology optimization) çš„åŸºç¡€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•å—é™äºå›ºå®šç½‘æ ¼å’Œç‰¹å®šè¾¹ç•Œæ¡ä»¶çš„é—®é¢˜ã€‚OATå°†åˆ†è¾¨ç‡å’Œå½¢çŠ¶æ— å…³çš„è‡ªåŠ¨ç¼–ç å™¨ (Autoencoder) ä¸éšå¼ç¥ç»åœºè§£ç å™¨ (Implicit neural-field decoder) ä»¥åŠæ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ (Conditional latent-diffusion model) ç›¸ç»“åˆï¼Œèƒ½å¤Ÿç›´æ¥é¢„æµ‹ä»»æ„é•¿å®½æ¯”ã€åˆ†è¾¨ç‡ã€ä½“ç§¯åˆ†æ•°åŠè½½è·ä¸‹çš„æœ€å°é¡ºåº”æ€§å¸ƒå±€ã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«220ä¸‡ä¸ªä¼˜åŒ–ç»“æ„çš„å…¨æ–°æ•°æ®é›†OpenTOä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¶µç›–äº†200ä¸‡ç§ç‹¬ç‰¹çš„è¾¹ç•Œæ¡ä»¶é…ç½®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒOATç›¸è¾ƒäºå…ˆå‰çš„æœ€ä½³æ¨¡å‹å¯å°†å¹³å‡é¡ºåº”æ€§ (Mean compliance) é™ä½é«˜è¾¾90%ï¼Œå¹¶åœ¨å•GPUä¸Šå®ç°äº†ä½äº1ç§’çš„æ¨ç†é€Ÿåº¦ã€‚è¯¥æ¡†æ¶å±•ç°äº†æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†ä»64x64åˆ°256x256çš„åˆ†è¾¨ç‡ä»¥åŠé«˜è¾¾10:1çš„é•¿å®½æ¯”ï¼Œä¸ºç‰©ç†æ„ŸçŸ¥æ‹“æ‰‘ä¼˜åŒ–å’Œé€†å‘è®¾è®¡ (Inverse design) æä¾›äº†é«˜æ•ˆé€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23667v1",
      "published_date": "2025-10-26 15:11:54 UTC",
      "updated_date": "2025-10-26 15:11:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:07.377281+00:00"
    },
    {
      "arxiv_id": "2510.22710v1",
      "title": "RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for Enhanced LLM Reasoning Reliability",
      "title_zh": "RaCoTï¼šç”¨äºå¢å¼ºå¤§è¯­è¨€æ¨¡å‹æ¨ç†å¯é æ€§çš„å³æ’å³ç”¨å¯¹æ¯”æ ·æœ¬ç”Ÿæˆæœºåˆ¶",
      "authors": [
        "Kaitong Cai",
        "Jusheng Zhang",
        "Yijia Fan",
        "Jing Yang",
        "Keze Wang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) faces a core bottleneck with knowledge-sparse and semantically ambiguous long-tail queries, where retrieval noise distorts reasoning and necessitates costly post-processing. To tackle this, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel framework that shifts contrastive thinking to the pre-retrieval stage. By automatically generating a semantically adjacent yet differently answered contrastive question and extracting a $Î”$-Prompt to capture their key differences, RaCoT guides the model to proactively focus on the ``critical details that determine answer divergence.\" This approach allows it to suppress semantic interference within a single retrieval pass, overcoming the theoretical bottleneck of single-vector queries that struggle to simultaneously encode signals for what to attend to and what to ignore. On six authoritative benchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong baselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits superior robustness, with a performance drop of only 8.6\\% in adversarial tests, far surpassing the over 15\\% degradation in other methods. Furthermore, its low latency (3.12s) and token overhead (11.54) place it on the accuracy-efficiency Pareto frontier, while ablation studies validate the necessity of each component. Ultimately, RaCoT reframes the RAG paradigm from ``post-hoc context cleaning\" to ``a priori shaping of discriminative reasoning\", offering an efficient and robust path toward reliable AI systems for real-time, resource-constrained deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RaCoT (Retrieval-aware Contrastive-of-Thought)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨å¢å¼º LLM æ¨ç†å¯é æ€§çš„å³æ’å³ç”¨å¯¹æ¯”å®ä¾‹ç”Ÿæˆæœºåˆ¶ã€‚é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) åœ¨å¤„ç†è¯­ä¹‰æ¨¡ç³Šçš„é•¿å°¾æŸ¥è¯¢æ—¶é¢ä¸´çš„æ£€ç´¢å™ªå£°é—®é¢˜ï¼ŒRaCoT å°†å¯¹æ¯”æ€ç»´å‰ç½®åˆ°æ£€ç´¢é˜¶æ®µã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰é‚»è¿‘ä½†ç­”æ¡ˆä¸åŒçš„å¯¹æ¯”é—®é¢˜ï¼Œå¹¶æå– $\\Delta$-Prompt æ¥æ•æ‰ä¸¤è€…é—´çš„å…³é”®å·®å¼‚ï¼Œå¼•å¯¼æ¨¡å‹ä¸»åŠ¨å…³æ³¨å†³å®šç­”æ¡ˆåˆ†æ­§çš„å…³é”®ç»†èŠ‚ã€‚è¿™ç§æ–¹æ³•æœ‰æ•ˆæŠ‘åˆ¶äº†å•æ¬¡æ£€ç´¢ä¸­çš„è¯­ä¹‰å¹²æ‰°ï¼Œå…‹æœäº†å•å‘é‡æŸ¥è¯¢åœ¨åŒæ—¶ç¼–ç â€œå…³æ³¨â€ä¸â€œå¿½ç•¥â€ä¿¡å·æ—¶çš„ç†è®ºç“¶é¢ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRaCoT åœ¨ PopQA å’Œ TriviaQA ç­‰å…­ä¸ªæƒå¨åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜äº RankRAG å’Œ Self-RAGï¼Œä¸”åœ¨å¯¹æŠ—æ€§æµ‹è¯•ä¸­çš„æ€§èƒ½ä¸‹é™è¿œä½äºåŒç±»æ–¹æ³•ã€‚å‡­å€Ÿä½å»¶è¿Ÿå’Œä½ Token å¼€é”€ï¼ŒRaCoT æˆåŠŸè¾¾åˆ°äº†å‡†ç¡®ç‡ä¸æ•ˆç‡çš„ Pareto frontierã€‚è¯¥ç ”ç©¶å°† RAG èŒƒå¼ä»â€œäº‹åä¸Šä¸‹æ–‡æ¸…æ´—â€é‡æ„ä¸ºâ€œäº‹å‰åˆ¤åˆ«æ€§æ¨ç†å¡‘é€ â€ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„å¯é  AI ç³»ç»Ÿéƒ¨ç½²æä¾›äº†é«˜æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22710v1",
      "published_date": "2025-10-26 15:06:44 UTC",
      "updated_date": "2025-10-26 15:06:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:08.766628+00:00"
    },
    {
      "arxiv_id": "2510.22702v1",
      "title": "Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring",
      "title_zh": "Atlas Urban Indexï¼šä¸€ç§åŸºäº VLM çš„æ—¶ç©ºæ ¡å‡†åŸå¸‚å‘å±•ç›‘æµ‹æ–¹æ³•",
      "authors": [
        "Mithul Chander",
        "Sai Pragnya Ranga",
        "Prathamesh Mayekar"
      ],
      "abstract": "We introduce the {\\em Atlas Urban Index} (AUI), a metric for measuring urban development computed using Sentinel-2 \\citep{spoto2012sentinel2} satellite imagery. Existing approaches, such as the {\\em Normalized Difference Built-up Index} (NDBI), often struggle to accurately capture urban development due to factors like atmospheric noise, seasonal variation, and cloud cover. These limitations hinder large-scale monitoring of human development and urbanization. To address these challenges, we propose an approach that leverages {\\em Vision-Language Models }(VLMs) to provide a development score for regions. Specifically, we collect a time series of Sentinel-2 images for each region. Then, we further process the images within fixed time windows to get an image with minimal cloud cover, which serves as the representative image for that time window. To ensure consistent scoring, we adopt two strategies: (i) providing the VLM with a curated set of reference images representing different levels of urbanization, and (ii) supplying the most recent past image to both anchor temporal consistency and mitigate cloud-related noise in the current image. Together, these components enable AUI to overcome the challenges of traditional urbanization indices and produce more reliable and stable development scores. Our qualitative experiments on Bangalore suggest that AUI outperforms standard indices such as NDBI.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Atlas Urban Index (AUI)ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ Sentinel-2 å«æ˜Ÿå›¾åƒè¡¡é‡åŸå¸‚å‘å±•çš„åˆ›æ–°æŒ‡æ ‡ã€‚é’ˆå¯¹ç°æœ‰æŒ‡æ ‡å¦‚ Normalized Difference Built-up Index (NDBI) æ˜“å—å¤§æ°”å™ªå£°ã€å­£èŠ‚å˜åŒ–å’Œäº‘å±‚è¦†ç›–å¹²æ‰°çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models, VLMs) ä¸ºç‰¹å®šåŒºåŸŸç”Ÿæˆå‘å±•è¯„åˆ†ã€‚ç ”ç©¶é€šè¿‡å¤„ç†å›ºå®šæ—¶é—´çª—å£å†…çš„å›¾åƒåºåˆ—æ¥è·å–äº‘å±‚è¦†ç›–æœ€å°çš„ä»£è¡¨æ€§å›¾åƒï¼Œå¹¶ç»“åˆä¸¤é¡¹æ ¸å¿ƒç­–ç•¥ï¼šä¸º VLMs æä¾›ä»£è¡¨ä¸åŒåŸå¸‚åŒ–æ°´å¹³çš„ç²¾é€‰å‚è€ƒå›¾ï¼Œä»¥åŠåˆ©ç”¨æœ€è¿‘çš„å†å²å›¾åƒæ¥é”šå®šæ—¶é—´ä¸€è‡´æ€§å¹¶é™ä½å™ªå£°ã€‚åœ¨ç­åŠ ç½—å°” (Bangalore) è¿›è¡Œçš„å®šæ€§å®éªŒè¯æ˜ï¼ŒAUI åœ¨ç¨³å®šæ€§å’Œå¯é æ€§ä¸Šä¼˜äº NDBI ç­‰ä¼ ç»ŸæŒ‡æ ‡ã€‚è¯¥æ–¹æ³•ä¸ºå¤§è§„æ¨¡çš„äººç±»å‘å±•å’ŒåŸå¸‚åŒ–ç›‘æµ‹æä¾›äº†ä¸€ç§æ›´ç²¾å‡†ä¸”å…·å¤‡æ—¶ç©ºæ ¡å‡†èƒ½åŠ›çš„å·¥å…·ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "An abridged version of this paper will be presented at and appear in the Proceedings of ACM IKDD CODS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22702v1",
      "published_date": "2025-10-26 14:53:36 UTC",
      "updated_date": "2025-10-26 14:53:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:09.864982+00:00"
    },
    {
      "arxiv_id": "2510.22686v1",
      "title": "FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning",
      "title_zh": "FlowCriticï¼šå¼ºåŒ–å­¦ä¹ ä¸­ä»·å€¼ä¼°è®¡ä¸æµåŒ¹é…çš„æ¡¥æ¥",
      "authors": [
        "Shan Zhong",
        "Shutong Ding",
        "He Diao",
        "Xiangyu Wang",
        "Kah Chan Teh",
        "Bei Peng"
      ],
      "abstract": "Reliable value estimation serves as the cornerstone of reinforcement learning (RL) by evaluating long-term returns and guiding policy improvement, significantly influencing the convergence speed and final performance. Existing works improve the reliability of value function estimation via multi-critic ensembles and distributional RL, yet the former merely combines multi point estimation without capturing distributional information, whereas the latter relies on discretization or quantile regression, limiting the expressiveness of complex value distributions. Inspired by flow matching's success in generative modeling, we propose a generative paradigm for value estimation, named FlowCritic. Departing from conventional regression for deterministic value prediction, FlowCritic leverages flow matching to model value distributions and generate samples for value estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸­ä»·å€¼ä¼°è®¡ä½œä¸ºè¯„ä¼°é•¿æœŸå›æŠ¥ä¸æŒ‡å¯¼ç­–ç•¥æ”¹è¿›çš„åŸºçŸ³ä½œç”¨ï¼ŒæŒ‡å‡ºå…¶å¯¹æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½çš„å…³é”®å½±å“ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸­å¤šè¯„è®ºå®¶é›†æˆ(multi-critic ensembles)ä»…èƒ½è¿›è¡Œç‚¹ä¼°è®¡ï¼Œä»¥åŠåˆ†å¸ƒå¼ºåŒ–å­¦ä¹ (distributional RL)å› ä¾èµ–ç¦»æ•£åŒ–æˆ–åˆ†ä½æ•°å›å½’è€Œé™åˆ¶åˆ†å¸ƒè¡¨è¾¾èƒ½åŠ›çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†åä¸ºFlowCriticçš„ç”Ÿæˆå¼ä»·å€¼ä¼°è®¡èŒƒå¼ã€‚å—ç”Ÿæˆæ¨¡å‹ä¸­æµåŒ¹é…(flow matching)æˆåŠŸçš„å¯å‘ï¼ŒFlowCritic æ‘’å¼ƒäº†ä¼ ç»Ÿçš„ç¡®å®šæ€§é¢„æµ‹å›å½’æ–¹æ³•ï¼Œè½¬è€Œåˆ©ç”¨æµåŒ¹é…å¯¹ä»·å€¼åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡å¹¶ç”Ÿæˆæ ·æœ¬ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”Ÿæˆå¼å»ºæ¨¡å¢å¼ºäº†å¤æ‚ä»·å€¼åˆ†å¸ƒçš„è¡¨è¾¾çµæ´»æ€§ï¼Œä¸ºæé«˜å¼ºåŒ–å­¦ä¹ ä¸­ä»·å€¼å‡½æ•°è¯„ä¼°çš„å¯é æ€§æä¾›äº†æ–°çš„é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22686v1",
      "published_date": "2025-10-26 14:12:32 UTC",
      "updated_date": "2025-10-26 14:12:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:17.879370+00:00"
    },
    {
      "arxiv_id": "2510.22685v1",
      "title": "TABL-ABM: A Hybrid Framework for Synthetic LOB Generation",
      "title_zh": "TABL-ABMï¼šä¸€ç§ç”¨äºåˆæˆ LOB ç”Ÿæˆçš„æ··åˆæ¡†æ¶",
      "authors": [
        "Ollie Olby",
        "Rory Baggott",
        "Namid Stillman"
      ],
      "abstract": "The recent application of deep learning models to financial trading has heightened the need for high fidelity financial time series data. This synthetic data can be used to supplement historical data to train large trading models. The state-of-the-art models for the generative application often rely on huge amounts of historical data and large, complicated models. These models range from autoregressive and diffusion-based models through to architecturally simpler models such as the temporal-attention bilinear layer. Agent-based approaches to modelling limit order book dynamics can also recreate trading activity through mechanistic models of trader behaviours. In this work, we demonstrate how a popular agent-based framework for simulating intraday trading activity, the Chiarella model, can be combined with one of the most performant deep learning models for forecasting multi-variate time series, the TABL model. This forecasting model is coupled to a simulation of a matching engine with a novel method for simulating deleted order flow. Our simulator gives us the ability to test the generative abilities of the forecasting model using stylised facts. Our results show that this methodology generates realistic price dynamics however, when analysing deeper, parts of the markets microstructure are not accurately recreated, highlighting the necessity for including more sophisticated agent behaviors into the modeling framework to help account for tail events.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TABL-ABMï¼Œä¸€ä¸ªç”¨äºç”Ÿæˆåˆæˆé™ä»·è®¢å•ç°¿(Limit Order Book)æ•°æ®çš„æ··åˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å°†æ¨¡æ‹Ÿæ—¥å†…äº¤æ˜“æ´»åŠ¨çš„Chiarellaæ¨¡å‹ä¸é«˜æ€§èƒ½æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹TABL(Temporal-Attention Bilinear Layer)ç›¸ç»“åˆï¼Œå¹¶å¼•å…¥äº†å¸¦æœ‰æ–°é¢–æ’¤å•æµ(deleted order flow)æ¨¡æ‹Ÿæ–¹æ³•çš„æ’®åˆå¼•æ“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTABL-ABMèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ä»·æ ¼åŠ¨æ€(price dynamics)ï¼Œä½†åœ¨é‡å»ºæ·±å±‚å¸‚åœºå¾®è§‚ç»“æ„(market microstructure)æ–¹é¢ä»å­˜åœ¨å±€é™ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨å»ºæ¨¡æ¡†æ¶ä¸­åŠ å…¥æ›´å¤æ‚æ™ºèƒ½ä½“è¡Œä¸ºçš„å¿…è¦æ€§ï¼Œä»¥å‡†ç¡®æ•æ‰å°¾éƒ¨äº‹ä»¶(tail events)ã€‚è¯¥æ¡†æ¶ä¸ºè®­ç»ƒå¤§å‹äº¤æ˜“æ¨¡å‹æä¾›äº†é™¤å†å²æ•°æ®ä¹‹å¤–çš„é«˜ä¿çœŸåˆæˆæ•°æ®è¡¥å……æ–¹æ¡ˆã€‚",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.MA",
        "q-fin.TR"
      ],
      "primary_category": "q-fin.CP",
      "comment": "8 pages, 5 figures, accepted to the Workshop on AI in Finance at ECAI2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22685v1",
      "published_date": "2025-10-26 14:04:49 UTC",
      "updated_date": "2025-10-26 14:04:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:20.180751+00:00"
    },
    {
      "arxiv_id": "2510.22680v1",
      "title": "Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead",
      "title_zh": "ä¸ç¡®å®šæ€§æ„ŸçŸ¥å‹è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼šå‰æ–¹é“è·¯é¢„æµ‹",
      "authors": [
        "Shireen Kudukkil Manchingal",
        "Armand Amaritei",
        "Mihir Gohad",
        "Maryam Sultana",
        "Julian F. P. Kooij",
        "Fabio Cuzzolin",
        "Andrew Bradley"
      ],
      "abstract": "Autonomous Vehicle (AV) perception systems have advanced rapidly in recent years, providing vehicles with the ability to accurately interpret their environment. Perception systems remain susceptible to errors caused by overly-confident predictions in the case of rare events or out-of-sample data. This study equips an autonomous vehicle with the ability to 'know when it is uncertain', using an uncertainty-aware image classifier as part of the AV software stack. Specifically, the study exploits the ability of Random-Set Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets of classes, allowing the system to identify and signal uncertainty clearly in novel or ambiguous scenarios. The system is tested in a real-world autonomous racing vehicle software stack, with the RS-NN classifying the layout of the road ahead and providing the associated uncertainty of the prediction. Performance of the RS-NN under a range of road conditions is compared against traditional CNN and Bayesian neural networks, with the RS-NN achieving significantly higher accuracy and superior uncertainty calibration. This integration of RS-NNs into Robot Operating System (ROS)-based vehicle control pipeline demonstrates that predictive uncertainty can dynamically modulate vehicle speed, maintaining high-speed performance under confident predictions while proactively improving safety through speed reductions in uncertain scenarios. These results demonstrate the potential of uncertainty-aware neural networks - in particular RS-NNs - as a practical solution for safer and more robust autonomous driving.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Autonomous Vehicle æ„ŸçŸ¥ç³»ç»Ÿåœ¨é¢å¯¹ç½•è§äº‹ä»¶æˆ–æ ·æœ¬å¤–æ•°æ®æ—¶å®¹æ˜“å› è¿‡åº¦è‡ªä¿¡äº§ç”Ÿé”™è¯¯çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…·å¤‡â€œçŸ¥æ™“è‡ªèº«ä¸ç¡®å®šæ€§â€èƒ½åŠ›çš„è½¯ä»¶æ ˆã€‚ç ”ç©¶åˆ©ç”¨ Random-Set Neural Networks (RS-NNs) æ˜¾å¼é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œé€šè¿‡é¢„æµ‹ç±»é›†åˆä¸Šçš„ä¿¡å¿µå‡½æ•°ï¼Œåœ¨æ¨¡ç³Šåœºæ™¯ä¸‹æä¾›æ¯”ä¼ ç»Ÿ CNN æˆ– Bayesian ç¥ç»ç½‘ç»œæ›´æ¸…æ™°çš„ä¿¡å·ã€‚ç³»ç»Ÿåœ¨åŸºäº Robot Operating System (ROS) çš„çœŸå®è‡ªåŠ¨é©¾é©¶èµ›è½¦å¹³å°ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œç”¨äºåˆ†ç±»å‰æ–¹é“è·¯å¸ƒå±€å¹¶è¯„ä¼°é¢„æµ‹çš„å…³è”ä¸ç¡®å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRS-NNs åœ¨å¤šç§é“è·¯æ¡ä»¶ä¸‹ä¸ä»…å®ç°äº†æ˜¾è‘—æ›´é«˜çš„å‡†ç¡®ç‡ï¼Œè¿˜å±•ç°å‡ºä¼˜å¼‚çš„ä¸ç¡®å®šæ€§æ ¡å‡†æ€§èƒ½ã€‚è¯¥é›†æˆæ–¹æ¡ˆå…è®¸è½¦è¾†æ ¹æ®ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒèŠ‚é€Ÿåº¦ï¼Œåœ¨ç½®ä¿¡åº¦é«˜æ—¶ä¿æŒé«˜æ€§èƒ½ï¼Œè€Œåœ¨ä¸ç¡®å®šåœºæ™¯ä¸‹é€šè¿‡ä¸»åŠ¨å‡é€Ÿç¡®ä¿å®‰å…¨ã€‚ç ”ç©¶è¯æ˜äº†ä¸ç¡®å®šæ€§æ„ŸçŸ¥ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«æ˜¯ RS-NNsï¼Œæ˜¯æå‡è‡ªåŠ¨é©¾é©¶é²æ£’æ€§ä¸å®‰å…¨æ€§çš„å®ç”¨ä¸”æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22680v1",
      "published_date": "2025-10-26 13:49:38 UTC",
      "updated_date": "2025-10-26 13:49:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:45.320944+00:00"
    },
    {
      "arxiv_id": "2510.23665v2",
      "title": "Transformers from Compressed Representations",
      "title_zh": "åŸºäºå‹ç¼©è¡¨ç¤ºçš„ Transformer æ¨¡å‹",
      "authors": [
        "Juan C. Leon Alcazar",
        "Mattia Soldan",
        "Mohammad Saatialsoruji",
        "Alejandro Pardo",
        "Hani Itani",
        "Juan Camilo Perez",
        "Bernard Ghanem"
      ],
      "abstract": "Compressed file formats are the corner stone of efficient data storage and transmission, yet their potential for representation learning remains largely underexplored. We introduce TEMPEST (TransformErs froM comPressed rEpreSenTations), a method that exploits the inherent byte-stream structure of compressed files to design an effective tokenization and encoding strategy. By leveraging this compact encoding, a standard transformer can directly learn semantic representations from compressed data streams, bypassing the need for raw byte-level processing or full media decoding. Our proposal substantially reduces the number of tokens required for semantic classification, thereby lowering both computational complexity and memory usage. Through extensive experiments across diverse datasets, coding schemes, and modalities, we show that TEMPEST achieves accuracy competitive wit the state-of-the-art while delivering efficiency gains in memory and compute.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TEMPEST (TransformErs froM comPressed rEpreSenTations)ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å‹ç¼©æ–‡ä»¶å›ºæœ‰çš„å­—èŠ‚æµç»“æ„æ¥è®¾è®¡é«˜æ•ˆ Tokenization å’Œç¼–ç ç­–ç•¥çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å…è®¸æ ‡å‡† Transformer ç›´æ¥ä»å‹ç¼©æ•°æ®æµä¸­å­¦ä¹ è¯­ä¹‰è¡¨ç¤ºï¼Œä»è€Œç»•è¿‡äº†åŸå§‹å­—èŠ‚çº§å¤„ç†æˆ–å®Œæ•´çš„åª’ä½“è§£ç éœ€æ±‚ã€‚é€šè¿‡åˆ©ç”¨è¿™ç§ç´§å‡‘ç¼–ç ï¼ŒTEMPEST å¤§å¹…å‡å°‘äº†è¯­ä¹‰åˆ†ç±»æ‰€éœ€çš„ Token æ•°é‡ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜ä½¿ç”¨é‡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä¸åŒæ•°æ®é›†ã€ç¼–ç æ–¹æ¡ˆå’Œæ¨¡æ€ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTEMPEST åœ¨ä¿æŒä¸å½“å‰æœ€å…ˆè¿›æŠ€æœ¯ (SOTA) å…·æœ‰ç«äº‰åŠ›çš„å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œåœ¨å†…å­˜å’Œè®¡ç®—æ•ˆç‡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23665v2",
      "published_date": "2025-10-26 13:48:03 UTC",
      "updated_date": "2025-10-29 11:16:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:37.970059+00:00"
    },
    {
      "arxiv_id": "2510.22679v1",
      "title": "Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration",
      "title_zh": "å³åˆ»å«åœï¼šåŸºäºå•æ¬¡è¿­ä»£çš„æ ·æ¿å¼å“åº”æ£€æµ‹",
      "authors": [
        "Yuval Kainan",
        "Shaked Zychlinski"
      ],
      "abstract": "Large Language Models (LLMs) often expend significant computational resources generating boilerplate responses, such as refusals, simple acknowledgements and casual greetings, which adds unnecessary cost and latency. To address this inefficiency, we propose a simple yet highly effective method for detecting such responses after only a single generation step. We demonstrate that the log-probability distribution of the first generated token serves as a powerful signal for classifying the nature of the entire subsequent response. Our experiments, conducted across a diverse range of small, large, and reasoning-specialized models, show that the first-token log-probability vectors form distinctly separable clusters for different response types. Using a lightweight k-NN classifier, we achieve high accuracy in predicting whether a response will be a substantive answer or a form of boilerplate response, including user-specified refusals. The primary implication is a practical, computationally trivial technique, optimizing LLM inference by enabling early termination or redirection to a smaller model, thereby yielding significant savings in computational cost. This work presents a direct path toward more efficient and sustainable LLM deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿæˆæ‹’ç»ã€ç®€å•è‡´è°¢å’Œæ—¥å¸¸é—®å€™ç­‰å†—ä½™å“åº”(Boilerplate Responses)æ—¶æ¶ˆè€—è¿‡å¤šè®¡ç®—èµ„æºå’Œå¢åŠ å»¶è¿Ÿçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åœ¨ä»…ç”Ÿæˆä¸€ä¸ªTokenåå³å¯æ£€æµ‹æ­¤ç±»å“åº”çš„é«˜æ•ˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†é¦–ä¸ªç”ŸæˆTokençš„å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒ(Log-probability Distribution)ä½œä¸ºè¯†åˆ«ä¿¡å·ï¼Œå‘ç°åœ¨ä¸åŒè§„æ¨¡åŠæ¨ç†ä¸“ç”¨æ¨¡å‹ä¸­ï¼Œè¯¥å‘é‡ç©ºé—´å¯¹ä¸åŒå“åº”ç±»å‹å…·æœ‰æ˜¾è‘—çš„å¯åˆ†æ€§ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨è½»é‡çº§çš„k-NNåˆ†ç±»å™¨ï¼Œå®ç°äº†å¯¹åç»­ç”Ÿæˆå†…å®¹æ˜¯å®è´¨æ€§å›ç­”è¿˜æ˜¯å†—ä½™è¯æœ¯çš„é«˜ç²¾åº¦é¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æŠ€æœ¯è®¡ç®—å¼€é”€æä½ï¼Œé€šè¿‡æ”¯æŒæ—©æœŸç»ˆæ­¢æˆ–ä»»åŠ¡é‡å®šå‘ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½LLMsçš„æ¨ç†æˆæœ¬å’Œå“åº”å»¶è¿Ÿã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°æ›´é«˜æ•ˆã€æ›´å…·å¯æŒç»­æ€§çš„LLMså¤§è§„æ¨¡éƒ¨ç½²æä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22679v1",
      "published_date": "2025-10-26 13:43:56 UTC",
      "updated_date": "2025-10-26 13:43:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:06.429286+00:00"
    },
    {
      "arxiv_id": "2510.22669v1",
      "title": "LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering",
      "title_zh": "LVD-GSï¼šåŸºäºå±‚çº§æ˜¾éšå¼è¡¨ç¤ºååŒæ¸²æŸ“çš„åŠ¨æ€åœºæ™¯é«˜æ–¯æ³¼æº… SLAM",
      "authors": [
        "Wenkai Zhu",
        "Xu Li",
        "Qimin Xu",
        "Benwu Wang",
        "Kun Wei",
        "Yiming Peng",
        "Zihang Wang"
      ],
      "abstract": "3D Gaussian Splatting SLAM has emerged as a widely used technique for high-fidelity mapping in spatial intelligence. However, existing methods often rely on a single representation scheme, which limits their performance in large-scale dynamic outdoor scenes and leads to cumulative pose errors and scale ambiguity. To address these challenges, we propose \\textbf{LVD-GS}, a novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human chain-of-thought process for information seeking, we introduce a hierarchical collaborative representation module that facilitates mutual reinforcement for mapping optimization, effectively mitigating scale drift and enhancing reconstruction robustness. Furthermore, to effectively eliminate the influence of dynamic objects, we propose a joint dynamic modeling module that generates fine-grained dynamic masks by fusing open-world segmentation with implicit residual constraints, guided by uncertainty estimates from DINO-Depth features. Extensive evaluations on KITTI, nuScenes, and self-collected datasets demonstrate that our approach achieves state-of-the-art performance compared to existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LVD-GSï¼Œä¸€ç§æ–°å‹çš„ LiDAR-Visual 3D Gaussian Splatting SLAM ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ 3D Gaussian Splatting SLAM åœ¨å¤§è§„æ¨¡åŠ¨æ€å®¤å¤–åœºæ™¯ä¸­é¢ä¸´çš„ç´¯ç§¯ä½å§¿è¯¯å·®å’Œå°ºåº¦æ­§ä¹‰æŒ‘æˆ˜ã€‚å—åˆ°äººç±» Chain-of-Thought ä¿¡æ¯å¯»æ±‚è¿‡ç¨‹çš„å¯å‘ï¼Œè¯¥ç³»ç»Ÿå¼•å…¥äº†å±‚æ¬¡åŒ–åä½œè¡¨ç¤ºæ¨¡å—ï¼Œé€šè¿‡ç›¸äº’å¢å¼ºè¿›è¡Œåœ°å›¾ä¼˜åŒ–ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£äº†å°ºåº¦æ¼‚ç§»å¹¶æ˜¾è‘—å¢å¼ºäº†é‡å»ºçš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†æœ‰æ•ˆæ¶ˆé™¤åŠ¨æ€ç‰©ä½“çš„å½±å“ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†è”åˆåŠ¨æ€å»ºæ¨¡æ¨¡å—ï¼Œåˆ©ç”¨ DINO-Depth ç‰¹å¾çš„ç¡®å®šæ€§ä¼°è®¡ï¼Œé€šè¿‡èåˆ Open-world Segmentation ä¸éšå¼æ®‹å·®çº¦æŸæ¥ç”Ÿæˆç»†ç²’åº¦çš„åŠ¨æ€æ©è†œã€‚åœ¨ KITTIã€nuScenes å’Œè‡ªé‡‡é›†æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°ç»“æœè¯æ˜ï¼ŒLVD-GS ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å®ç°äº† state-of-the-art çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22669v1",
      "published_date": "2025-10-26 13:16:39 UTC",
      "updated_date": "2025-10-26 13:16:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:41.633355+00:00"
    },
    {
      "arxiv_id": "2510.22665v2",
      "title": "SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery",
      "title_zh": "SARVLMï¼šé¢å‘ SAR å›¾åƒè¯­ä¹‰ç†è§£ä¸ç›®æ ‡è¯†åˆ«çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹",
      "authors": [
        "Qiwei Ma",
        "Zhiyu Wang",
        "Wang Liu",
        "Xukun Lu",
        "Bin Deng",
        "Puhong Duan",
        "Xudong Kang",
        "Shutao Li"
      ],
      "abstract": "Synthetic Aperture Radar (SAR) is a crucial imaging modality thanks to its all-weather capability. Although recent advances in self-supervised learning and masked image modeling (MIM) have enabled SAR foundation models, these methods largely emphasize low-level visual features and often overlook multimodal alignment and zero-shot target recognition in SAR imagery. To address this, we construct SARVLM-1M, a large-scale vision-language dataset with over one million image-text pairs aggregated from existing datasets. We further propose a domain transfer training strategy to mitigate the large gap between natural and SAR imagery. Building on this, we develop SARVLM, the first vision language foundation model (VLM) tailored to SAR, comprising SARCLIP and SARCap. SARVLM is trained with a vision-language contrastive objective under the proposed domain transfer strategy, bridging SAR imagery and textual descriptions. Extensive experiments on image text retrieval, zero-shot classification, semantic localization, and imagery captioning demonstrate that SARVLM delivers superior feature extraction and interpretation, outperforming state-of-the-art VLMs and advancing SAR semantic understanding. Code and datasets will be released soon.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆæˆå­”å¾„é›·è¾¾(SAR)åŸºç¡€æ¨¡å‹åœ¨å¤šæ¨¡æ€å¯¹é½å’Œé›¶æ ·æœ¬ç›®æ ‡è¯†åˆ«æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº†é¦–ä¸ªä¸“é—¨ä¸ºSARå›¾åƒå®šåˆ¶çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹(VLM)æ¡†æ¶SARVLMã€‚ä¸ºäº†è§£å†³è‡ªç„¶å›¾åƒä¸SARå›¾åƒä¹‹é—´çš„æ˜¾è‘—é¢†åŸŸé¸¿æ²Ÿï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†åŒ…å«è¶…è¿‡ä¸€ç™¾ä¸‡ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹çš„å¤§è§„æ¨¡æ•°æ®é›†SARVLM-1Mï¼Œå¹¶å¼€å‘äº†ä¸€å¥—é¢†åŸŸè½¬ç§»(Domain Transfer)è®­ç»ƒç­–ç•¥ã€‚SARVLMç”±SARCLIPå’ŒSARCapä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ç»„æˆï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ ç›®æ ‡(Vision-Language Contrastive Objective)å®ç°äº†SARå›¾åƒä¸æ–‡æœ¬æè¿°çš„æ·±åº¦è¡¨å¾å…³è”ã€‚å¤§é‡å®éªŒç»“æœè¯æ˜ï¼ŒSARVLMåœ¨å›¾åƒæ–‡æœ¬æ£€ç´¢ã€é›¶æ ·æœ¬åˆ†ç±»ã€è¯­ä¹‰å®šä½å’Œå›¾åƒæè¿°(Imagery Captioning)ç­‰ä»»åŠ¡ä¸Šè¡¨ç°å“è¶Šï¼Œå…¶æ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›è§†è§‰è¯­è¨€æ¨¡å‹ã€‚è¯¥å·¥ä½œä¸ä»…ä¸ºSARå›¾åƒçš„ç‰¹å¾æå–ä¸è¯­ä¹‰è§£é‡Šæä¾›äº†å¼ºåŠ›å·¥å…·ï¼Œä¹Ÿä¸ºåˆæˆå­”å¾„é›·è¾¾é¢†åŸŸçš„è¯­ä¹‰ç†è§£ç ”ç©¶å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22665v2",
      "published_date": "2025-10-26 13:04:50 UTC",
      "updated_date": "2025-11-26 10:05:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:49.426030+00:00"
    },
    {
      "arxiv_id": "2511.00027v1",
      "title": "Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All?",
      "title_zh": "ç«‹åœºè®ºæ–‡ï¼šè‹¥äººå·¥æ™ºèƒ½åˆ›æ–°ç³»ç»Ÿæ€§ä¾µçŠ¯åŸºæœ¬æƒåˆ©ï¼Œè¿˜èƒ½è¢«ç§°ä¸ºåˆ›æ–°å—ï¼Ÿ",
      "authors": [
        "Josu Eguiluz CastaÃ±eira",
        "Axel Brando",
        "Migle Laukyte",
        "Marc Serra-Vidal"
      ],
      "abstract": "Artificial intelligence (AI) now permeates critical infrastructures and decision-making systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation -- it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms -- regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA) -- demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means -- technological ambition disciplined by democratic values and fundamental rights.",
      "tldr_zh": "è¯¥ç«‹åœºè®ºæ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)ç³»ç»Ÿåœ¨å…³é”®åŸºç¡€è®¾æ–½å’Œå†³ç­–ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œå¹¶æŒ‘æˆ˜äº†ç›‘ç®¡ä¸åˆ›æ–°äº’ç›¸å¯¹ç«‹çš„ä¼ ç»Ÿè§‚å¿µã€‚ä½œè€…æŒ‡å‡ºï¼Œèˆªç©ºã€åˆ¶è¯è¡Œä¸šçš„å†å²ç»éªŒä»¥åŠå½“å‰çš„åˆæˆè™šå‡ä¿¡æ¯ã€åè§å’Œä¸å¯é—®è´£å†³ç­–è¡¨æ˜ï¼Œç¼ºä¹ç›‘ç®¡å·²é€ æˆå·¨å¤§æŸå®³ã€‚è®ºæ–‡è®¤ä¸ºï¼Œæ·±æ€ç†Ÿè™‘ä¸”å…·é€‚åº”æ€§çš„ç›‘ç®¡å¹¶éåˆ›æ–°çš„é˜»ç¢ï¼Œè€Œæ˜¯å…¶åŸºçŸ³ï¼Œèƒ½å°†æ³•å¾‹è´Ÿæ‹…è½¬åŒ–ä¸ºç¡®å®šæ€§ã€æ¶ˆè´¹è€…ä¿¡ä»»å’Œä¼¦ç†ç«äº‰åŠ›ã€‚é€šè¿‡åˆ†æã€Šæ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(EU AI Act)ï¼Œç ”ç©¶å±•ç¤ºäº†åŸºäºé£é™©å’Œè´£ä»»é©±åŠ¨çš„æ¨¡å¼å¦‚ä½•æœ‰æ•ˆåº”å¯¹Collingridge Dilemmaï¼Œå³åœ¨é˜²æ­¢ä¼¤å®³ä¸ç»´æŒåˆ›æ–°æ´»åŠ›é—´å–å¾—å¹³è¡¡ã€‚è®ºæ–‡è¯¦ç»†é˜è¿°äº†ç›‘ç®¡æ²™ç›’(regulatory sandboxes)ã€ä¸­å°ä¼ä¸š(SMEs)æ”¯æŒã€çœŸå®ä¸–ç•Œæµ‹è¯•åŠåŸºæœ¬æƒåˆ©å½±å“è¯„ä¼°(FRIA)ç­‰æœºåˆ¶åœ¨æ¨åŠ¨æŠ€æœ¯è¿›æ­¥ä¸­çš„ä½œç”¨ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶é‡æ–°å®šä¹‰äº†è¿›æ­¥ï¼Œå¼ºè°ƒçœŸæ­£çš„åˆ›æ–°å¿…é¡»å°†é€æ˜åº¦ã€é—®è´£åˆ¶å’ŒAIç´ å…»åµŒå…¥è®¾è®¡ä¸éƒ¨ç½²ä¸­ï¼Œç¡®ä¿æŠ€æœ¯é›„å¿ƒå—åˆ°æ°‘ä¸»ä»·å€¼å’ŒåŸºæœ¬æƒåˆ©çš„çº¦æŸã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "NeurIPS 2025 Position Paper track; accepted for oral and poster presentation at the Thirty-Ninth Annual Conference on Neural Information Processing Systems",
      "pdf_url": "https://arxiv.org/pdf/2511.00027v1",
      "published_date": "2025-10-26 12:45:53 UTC",
      "updated_date": "2025-10-26 12:45:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:51.135376+00:00"
    },
    {
      "arxiv_id": "2510.22655v2",
      "title": "Learning Without Augmenting: Unsupervised Time Series Representation Learning via Frame Projections",
      "title_zh": "æ— éœ€æ•°æ®å¢å¼ºï¼šåŸºäºæ¡†æ¶æŠ•å½±çš„æ— ç›‘ç£æ—¶é—´åºåˆ—è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Berken Utku Demirel",
        "Christian Holz"
      ],
      "abstract": "Self-supervised learning (SSL) has emerged as a powerful paradigm for learning representations without labeled data. Most SSL approaches rely on strong, well-established, handcrafted data augmentations to generate diverse views for representation learning. However, designing such augmentations requires domain-specific knowledge and implicitly imposes representational invariances on the model, which can limit generalization. In this work, we propose an unsupervised representation learning method that replaces augmentations by generating views using orthonormal bases and overcomplete frames. We show that embeddings learned from orthonormal and overcomplete spaces reside on distinct manifolds, shaped by the geometric biases introduced by representing samples in different spaces. By jointly leveraging the complementary geometry of these distinct manifolds, our approach achieves superior performance without artificially increasing data diversity through strong augmentations. We demonstrate the effectiveness of our method on nine datasets across five temporal sequence tasks, where signal-specific characteristics make data augmentations particularly challenging. Without relying on augmentation-induced diversity, our method achieves performance gains of up to 15--20\\% over existing self-supervised approaches. Source code: https://github.com/eth-siplab/Learning-with-FrameProjections",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºLearning Without Augmentingçš„æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³è‡ªç›‘ç£å­¦ä¹ (SSL)è¿‡åº¦ä¾èµ–æ‰‹å·¥è®¾è®¡æ•°æ®å¢å¼º(data augmentations)è€Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºä½¿ç”¨æ­£äº¤åŸº(orthonormal bases)å’Œè¿‡å®Œå¤‡æ¡†æ¶(overcomplete frames)è¿›è¡Œå¸§æŠ•å½±(Frame Projections)æ¥ç”Ÿæˆä¸åŒè§†å›¾ï¼Œä»è€Œæœ‰æ•ˆæ›¿ä»£äº†ä¼ ç»Ÿçš„å¢å¼ºæ‰‹æ®µã€‚ç ”ç©¶æ­ç¤ºäº†ä»è¿™äº›ç©ºé—´å­¦ä¹ åˆ°çš„åµŒå…¥(embeddings)å­˜åœ¨äºå…·æœ‰ä¸åŒå‡ ä½•åç½®çš„äº’è¡¥æµå½¢(manifolds)ä¸Šï¼Œé€šè¿‡è”åˆåˆ©ç”¨è¿™äº›æµå½¢çš„å‡ ä½•ç‰¹æ€§å¯ä»¥æ˜¾è‘—æå‡è¡¨ç¤ºèƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨æ¶µç›–äº”é¡¹æ—¶é—´åºåˆ—ä»»åŠ¡çš„ä¹ä¸ªæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–æ•°æ®å¢å¼ºçš„æƒ…å†µä¸‹ï¼Œç›¸è¾ƒäºç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å®ç°äº†é«˜è¾¾15-20%çš„æ€§èƒ½æå‡ã€‚è¿™è¯æ˜äº†é€šè¿‡å‡ ä½•æŠ•å½±æ›¿ä»£ä¼ ç»Ÿå¢å¼ºåœ¨å¤„ç†ä¿¡å·ç‰¹å¾å¤æ‚çš„æ—¶åºæ•°æ®æ—¶å…·æœ‰æå¤§çš„æ½œåŠ›å’Œä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the Conference on Neural Information Processing Systems (NeurIPS) 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22655v2",
      "published_date": "2025-10-26 12:36:29 UTC",
      "updated_date": "2026-01-15 09:38:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:44:56.344761+00:00"
    },
    {
      "arxiv_id": "2510.22651v1",
      "title": "Variational Polya Tree",
      "title_zh": "å˜åˆ† Polya æ ‘",
      "authors": [
        "Lu Xu",
        "Tsai Hor Chan",
        "Kwok Fai Lam",
        "Lequan Yu",
        "Guosheng Yin"
      ],
      "abstract": "Density estimation is essential for generative modeling, particularly with the rise of modern neural networks. While existing methods capture complex data distributions, they often lack interpretability and uncertainty quantification. Bayesian nonparametric methods, especially the \\polya tree, offer a robust framework that addresses these issues by accurately capturing function behavior over small intervals. Traditional techniques like Markov chain Monte Carlo (MCMC) face high computational complexity and scalability limitations, hindering the use of Bayesian nonparametric methods in deep learning. To tackle this, we introduce the variational \\polya tree (VPT) model, which employs stochastic variational inference to compute posterior distributions. This model provides a flexible, nonparametric Bayesian prior that captures latent densities and works well with stochastic gradient optimization. We also leverage the joint distribution likelihood for a more precise variational posterior approximation than traditional mean-field methods. We evaluate the model performance on both real data and images, and demonstrate its competitiveness with other state-of-the-art deep density estimation methods. We also explore its ability in enhancing interpretability and uncertainty quantification. Code is available at https://github.com/howardchanth/var-polya-tree.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Variational Polya Tree (VPT) æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¯†åº¦ä¼°è®¡æ–¹æ³•åœ¨å¯è§£é‡Šæ€§å’Œä¸ç¡®å®šæ€§é‡åŒ–(uncertainty quantification)æ–¹é¢çš„ä¸è¶³ï¼Œä»¥åŠä¼ ç»Ÿè´å¶æ–¯éå‚æ•°(Bayesian nonparametric)æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶çš„æ‰©å±•æ€§éš¾é¢˜ã€‚VPT é€šè¿‡å¼•å…¥éšæœºå˜åˆ†æ¨æ–­(stochastic variational inference)æ¥è®¡ç®—åéªŒåˆ†å¸ƒï¼Œä¸ºæ•è·æ½œåœ¨å¯†åº¦æä¾›äº†ä¸€ç§çµæ´»ä¸”èƒ½ä¸éšæœºæ¢¯åº¦ä¼˜åŒ–(stochastic gradient optimization)å…¼å®¹çš„éå‚æ•°è´å¶æ–¯å…ˆéªŒã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å¹³å‡åœº(mean-field)æ–¹æ³•ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨è”åˆåˆ†å¸ƒä¼¼ç„¶(joint distribution likelihood)å®ç°äº†æ›´ç²¾ç¡®çš„å˜åˆ†åéªŒè¿‘ä¼¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVPT åœ¨çœŸå®æ•°æ®å’Œå›¾åƒä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸å½“å‰æœ€å…ˆè¿›çš„æ·±åº¦å¯†åº¦ä¼°è®¡æ–¹æ³•ç›¸å½“ï¼Œå¹¶åœ¨å¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§ä¸ä¸ç¡®å®šæ€§é‡åŒ–æ–¹é¢å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22651v1",
      "published_date": "2025-10-26 12:23:22 UTC",
      "updated_date": "2025-10-26 12:23:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:01.528044+00:00"
    },
    {
      "arxiv_id": "2510.22647v1",
      "title": "A Critical Study on Tea Leaf Disease Detection using Deep Learning Techniques",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„èŒ¶å¶ç—…å®³æ£€æµ‹æ·±å…¥ç ”ç©¶",
      "authors": [
        "Nabajyoti Borah",
        "Raju Moni Borah",
        "Bandan Boruah",
        "Purnendu Bikash Acharjee",
        "Sajal Saha",
        "Ripjyoti Hazarika"
      ],
      "abstract": "The proposed solution is Deep Learning Technique that will be able classify three types of tea leaves diseases from which two diseases are caused by the pests and one due to pathogens (infectious organisms) and environmental conditions and also show the area damaged by a disease in leaves. Namely Red Rust, Helopeltis and Red spider mite respectively. In this paper we have evaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for the object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU range of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%. While Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95 and recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than SSD. Also used Mask R-CNN for Object Instance Segmentation where we have implemented our custom method to calculate the damaged diseased portion of leaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red Spider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ (Deep Learning)çš„æŠ€æœ¯ï¼Œç”¨äºåˆ†ç±»çº¢é”ˆç—…(Red Rust)ã€è§’ç›²è½(Helopeltis)å’Œçº¢èœ˜è››(Red spider mite)è¿™ä¸‰ç±»èŒ¶æ ‘å¶ç‰‡ç—…å®³ï¼Œå¹¶èƒ½å®šä½å—æŸåŒºåŸŸã€‚ç ”ç©¶å¯¹æ¯”è¯„ä¼°äº† SSD MobileNet V2 å’Œ Faster R-CNN ResNet50 V1 ä¸¤ç§æ¨¡å‹åœ¨ç›®æ ‡æ£€æµ‹(Object Detection)ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFaster R-CNN ResNet50 V1 çš„å¹³å‡ç²¾åº¦å‡å€¼(mAP)ä¸º 25%ï¼Œåœ¨æ£€æµ‹ç²¾åº¦å’Œå¬å›ç‡ä¸Šå‡ä¼˜äº SSD MobileNet V2 çš„ 20.9% mAPã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ©ç”¨ Mask R-CNN è¿›è¡Œå®ä¾‹åˆ†å‰²(Object Instance Segmentation)ï¼Œå¹¶é€šè¿‡è‡ªå®šä¹‰æ–¹æ³•å®ç°äº†å¯¹å¶ç‰‡å—æŸæ¯”ä¾‹çš„ç²¾ç¡®é‡åŒ–ã€‚è¯¥æŠ€æœ¯é€šè¿‡ç»“åˆç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²ç®—æ³•ï¼Œä¸ºèŒ¶å¶ç”Ÿäº§ä¸­çš„ç—…å®³è‡ªåŠ¨ç›‘æµ‹å’Œç—…å®³ç¨‹åº¦è¯„ä¼°æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22647v1",
      "published_date": "2025-10-26 12:18:15 UTC",
      "updated_date": "2025-10-26 12:18:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:00.520607+00:00"
    },
    {
      "arxiv_id": "2510.22643v1",
      "title": "Enhancing Graph Classification Robustness with Singular Pooling",
      "title_zh": "åˆ©ç”¨å¥‡å¼‚å€¼æ± åŒ–å¢å¼ºå›¾åˆ†ç±»é²æ£’æ€§",
      "authors": [
        "Sofiane Ennadir",
        "Oleg Smirnov",
        "Yassine Abbahaddou",
        "Lele Cao",
        "Johannes F. Lutzeyer"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved strong performance across a range of graph representation learning tasks, yet their adversarial robustness in graph classification remains underexplored compared to node classification. While most existing defenses focus on the message-passing component, this work investigates the overlooked role of pooling operations in shaping robustness. We present a theoretical analysis of standard flat pooling methods (sum, average and max), deriving upper bounds on their adversarial risk and identifying their vulnerabilities under different attack scenarios and graph structures. Motivated by these insights, we propose \\textit{Robust Singular Pooling (RS-Pool)}, a novel pooling strategy that leverages the dominant singular vector of the node embedding matrix to construct a robust graph-level representation. We theoretically investigate the robustness of RS-Pool and interpret the resulting bound leading to improved understanding of our proposed pooling operator. While our analysis centers on Graph Convolutional Networks (GCNs), RS-Pool is model-agnostic and can be implemented efficiently via power iteration. Empirical results on real-world benchmarks show that RS-Pool provides better robustness than the considered pooling methods when subject to state-of-the-art adversarial attacks while maintaining competitive clean accuracy. Our code is publicly available at:\\href{https://github.com/king/rs-pool}{https://github.com/king/rs-pool}.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶ Graph Neural Networks (GNNs) åœ¨å›¾è¡¨ç¤ºå­¦ä¹ ä¸­è¡¨ç°å¼ºåŠ²ï¼Œä½†å…¶åœ¨å›¾åˆ†ç±»ä¸­çš„å¯¹æŠ—ç¨³å¥æ€§ (Adversarial Robustness) ä»ç¼ºä¹æ·±å…¥ç ”ç©¶ï¼Œå°¤å…¶æ˜¯æ± åŒ–æ“ä½œ (Pooling Operations) å¯¹ç¨³å¥æ€§çš„å½±å“é•¿æœŸè¢«å¿½è§†ã€‚è®ºæ–‡é€šè¿‡ç†è®ºåˆ†æè¯æ˜äº† Sumã€Average å’Œ Max ç­‰æ ‡å‡†æ± åŒ–æ–¹æ³•åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§ï¼Œå¹¶ä»¥æ­¤ä¸ºåŠ¨åŠ›æå‡ºäº† Robust Singular Pooling (RS-Pool)ã€‚è¿™ç§æ–°å‹æ± åŒ–ç­–ç•¥åˆ©ç”¨èŠ‚ç‚¹åµŒå…¥çŸ©é˜µçš„ä¸»å¥‡å¼‚å‘é‡ (Dominant Singular Vector) æ¥æ„å»ºç¨³å¥çš„å›¾çº§è¡¨ç¤ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆé™ä½å¯¹æŠ—é£é™©ã€‚RS-Pool å…·æœ‰æ¨¡å‹æ— å…³ (Model-agnostic) çš„ç‰¹æ€§ï¼Œä¸”å¯ä»¥é€šè¿‡å¹‚è¿­ä»£ (Power Iteration) ç®—æ³•é«˜æ•ˆå®ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é¢å¯¹æœ€å…ˆè¿›çš„å¯¹æŠ—æ”»å‡»æ—¶ï¼ŒRS-Pool ç›¸æ¯”ä¼ ç»Ÿæ± åŒ–æ–¹æ³•æ˜¾è‘—æå‡äº†ç¨³å¥æ€§ï¼ŒåŒæ—¶èƒ½å¤Ÿä¿æŒæå…·ç«äº‰åŠ›çš„å¹²å‡€å‡†ç¡®ç‡ (Clean Accuracy)ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Neurips 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22643v1",
      "published_date": "2025-10-26 12:07:06 UTC",
      "updated_date": "2025-10-26 12:07:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:04.848242+00:00"
    },
    {
      "arxiv_id": "2510.23664v1",
      "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams",
      "title_zh": "Agentswayï¼šé¢å‘ AI æ™ºèƒ½ä½“å›¢é˜Ÿçš„è½¯ä»¶å¼€å‘æ–¹æ³•è®º",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Xueping Liang",
        "Sachini Rajapakse",
        "Isurunima Kularathne",
        "Pramoda Karunarathna",
        "Peter Foytik",
        "Sachin Shetty",
        "Ravi Mukkamala",
        "Abdul Rahman",
        "Amin Hass",
        "Ng Wee Keong",
        "Kasun De Zoysa",
        "Aruna Withanage",
        "Nilaan Loganathan"
      ],
      "abstract": "The emergence of Agentic AI is fundamentally transforming how software is designed, developed, and maintained. Traditional software development methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for human-centric teams and are increasingly inadequate in environments where autonomous AI agents contribute to planning, coding, testing, and continuous learning. To address this methodological gap, we present \"Agentsway\" a novel software development framework designed for ecosystems where AI agents operate as first-class collaborators. Agentsway introduces a structured lifecycle centered on human orchestration, and privacy-preserving collaboration among specialized AI agents. The framework defines distinct roles for planning, prompting, coding, testing, and fine-tuning agents, each contributing to iterative improvement and adaptive learning throughout the development process. By integrating fine-tuned LLMs that leverage outputs and feedback from different agents throughout the development cycle as part of a retrospective learning process, Agentsway enhances domain-specific reasoning, and explainable decision-making across the entire software development lifecycle. Responsible AI principles are further embedded across the agents through the coordinated use of multiple fine-tuned LLMs and advanced reasoning models, ensuring balanced, transparent, and accountable decision-making. This work advances software engineering by formalizing agent-centric collaboration, integrating privacy-by-design principles, and defining measurable metrics for productivity and trust. Agentsway represents a foundational step toward the next generation of AI-native, self-improving software development methodologies. To the best of our knowledge, this is the first research effort to introduce a dedicated methodology explicitly designed for AI agent-based software engineering teams.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºéšç€Agentic AIçš„å…´èµ·ï¼Œä¼ ç»Ÿçš„Agileã€Kanbanç­‰ä»¥äººä¸ºä¸­å¿ƒçš„å¼€å‘æ–¹æ³•è®ºå·²éš¾ä»¥é€‚åº”AIæ™ºèƒ½ä½“æ·±åº¦å‚ä¸è§„åˆ’ã€ç¼–ç å’Œæµ‹è¯•çš„è‡ªåŠ¨åŒ–ç¯å¢ƒã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†Agentswayï¼Œè¿™æ˜¯ä¸€ç§å°†AIæ™ºèƒ½ä½“è§†ä¸ºæ ¸å¿ƒåä½œè€…çš„æ–°å‹è½¯ä»¶å¼€å‘æ¡†æ¶ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä»¥Human Orchestrationä¸ºä¸­å¿ƒä¸”æ”¯æŒéšç§ä¿æŠ¤åä½œçš„ç»“æ„åŒ–ç”Ÿå‘½å‘¨æœŸï¼Œå¹¶ä¸ºè§„åˆ’ã€æç¤ºè¯ç¼–å†™ã€ç¼–ç ã€æµ‹è¯•å’Œå¾®è°ƒç­‰ç¯èŠ‚å®šä¹‰äº†ä¸“é—¨çš„æ™ºèƒ½ä½“è§’è‰²ã€‚é€šè¿‡Retrospective Learningè¿‡ç¨‹ï¼ŒAgentswayåˆ©ç”¨å¼€å‘å‘¨æœŸä¸­çš„åé¦ˆæ¥ä¼˜åŒ–å¾®è°ƒåçš„LLMsï¼Œæ˜¾è‘—å¢å¼ºäº†ç‰¹å®šé¢†åŸŸçš„æ¨ç†å’Œå†³ç­–çš„å¯è§£é‡Šæ€§ã€‚åŒæ—¶ï¼Œæ¡†æ¶é€šè¿‡Privacy-by-designå’ŒResponsible AIåŸåˆ™ç¡®ä¿äº†å†³ç­–çš„é€æ˜ä¸å…¬æ­£ã€‚ä½œä¸ºé¦–ä¸ªä¸“ä¸ºAIæ™ºèƒ½ä½“å›¢é˜Ÿè®¾è®¡çš„å¼€å‘æ–¹æ³•è®ºï¼ŒAgentswayé€šè¿‡å®šä¹‰ç”Ÿäº§åŠ›å’Œä¿¡ä»»çš„å¯è¡¡é‡æŒ‡æ ‡ï¼Œä¸ºæ„å»ºAIåŸç”Ÿã€è‡ªæˆ‘æ”¹è¿›çš„è½¯ä»¶å·¥ç¨‹ä½“ç³»å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23664v1",
      "published_date": "2025-10-26 11:58:42 UTC",
      "updated_date": "2025-10-26 11:58:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:18.837135+00:00"
    },
    {
      "arxiv_id": "2510.22641v1",
      "title": "FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference",
      "title_zh": "FastVLMï¼šåŸºäºè‡ªæ¨æµ‹è§£ç çš„å¿«é€Ÿè§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†",
      "authors": [
        "Divya Jyoti Bajpai",
        "Manjesh Kumar Hanawal"
      ],
      "abstract": "Vision-language Models (VLMs) have made significant strides in visual understanding and query response generation, but often face challenges of high computational cost and inference latency due to autoregressive decoding. In this work, we introduce an imitation-learning-based Self-Speculative Decoding (SSD) framework, named FastVLM, to address these limitations. Our approach employs a lightweight draft model for token generation in an autoregressive manner, while a full model verifies these tokens non-autoregressively. Accepted tokens proceed seamlessly, while rejected tokens are corrected by the full model and used to guide the draft model's refinement. Through an imitation network, FastVLM enhances the draft model by integrating deeper level insights from the full model's architecture. Also, it maintains the performance integrity of the full model while training the draft model, achieving a balance between efficiency and accuracy. Our method speeds up the inference process by 1.55-1.85x as compared to the final layer with minimal loss in performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FastVLMï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ¨¡ä»¿å­¦ä¹ çš„è‡ªæˆ‘æŠ•æœºè§£ç  (Self-Speculative Decoding, SSD) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨æ¨ç†è¿‡ç¨‹ä¸­å› è‡ªå›å½’è§£ç å¯¼è‡´çš„é«˜è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿé—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨è½»é‡çº§çš„è‰ç¨¿æ¨¡å‹ (draft model) ä»¥è‡ªå›å½’æ–¹å¼ç”Ÿæˆå€™é€‰è¯å…ƒ (token)ï¼Œå¹¶ç”±å…¨æ¨¡å‹ (full model) è¿›è¡Œéè‡ªå›å½’éªŒè¯ä»¥ç¡®ä¿è¾“å‡ºè´¨é‡ã€‚åœ¨éªŒè¯è¿‡ç¨‹ä¸­ï¼Œè¢«æ¥å—çš„è¯å…ƒå°†ç›´æ¥ä¿ç•™ï¼Œè€Œè¢«æ‹’ç»çš„è¯å…ƒåˆ™ç”±å…¨æ¨¡å‹è¿›è¡Œä¿®æ­£ï¼Œå¹¶ç”¨äºæŒ‡å¯¼è‰ç¨¿æ¨¡å‹çš„ç²¾ç»†åŒ–ç”Ÿæˆã€‚FastVLM é€šè¿‡æ¨¡ä»¿ç½‘ç»œå°†å…¨æ¨¡å‹æ¶æ„ä¸­çš„æ·±å±‚è§è§£æ•´åˆåˆ°è‰ç¨¿æ¨¡å‹ä¸­ï¼Œåœ¨è®­ç»ƒè‰ç¨¿æ¨¡å‹çš„åŒæ—¶æœ‰æ•ˆç»´æŒäº†å…¨æ¨¡å‹çš„æ€§èƒ½å®Œæ•´ã€‚è¯¥æ–¹æ³•åœ¨æ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ï¼Œå®éªŒè¯æ˜å…¶æ¨ç†é€Ÿåº¦æ¯”åŸºçº¿æå‡äº† 1.55-1.85 å€ä¸”æ€§èƒ½æŸå¤±æå°ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåŠ é€Ÿå¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹çš„å®é™…éƒ¨ç½²ä¸åº”ç”¨æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for presentation at the main Conference IJCNLP-AACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22641v1",
      "published_date": "2025-10-26 11:49:20 UTC",
      "updated_date": "2025-10-26 11:49:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:21.323646+00:00"
    },
    {
      "arxiv_id": "2510.22629v1",
      "title": "Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal",
      "title_zh": "è¯­è¨€å­¦ä¸ AI çš„èåˆï¼šWest Bengal æ¿’å± Toto è¯­çš„å½¢æ€å­¦åˆ†æä¸è¯­æ–™åº“å»ºè®¾",
      "authors": [
        "Ambalika Guha",
        "Sajal Saha",
        "Debanjan Ballav",
        "Soumi Mitra",
        "Hritwick Chakraborty"
      ],
      "abstract": "Preserving linguistic diversity is necessary as every language offers a distinct perspective on the world. There have been numerous global initiatives to preserve endangered languages through documentation. This paper is a part of a project which aims to develop a trilingual (Toto-Bangla-English) language learning application to digitally archive and promote the endangered Toto language of West Bengal, India. This application, designed for both native Toto speakers and non-native learners, aims to revitalize the language by ensuring accessibility and usability through Unicode script integration and a structured language corpus. The research includes detailed linguistic documentation collected via fieldwork, followed by the creation of a morpheme-tagged, trilingual corpus used to train a Small Language Model (SLM) and a Transformer-based translation engine. The analysis covers inflectional morphology such as person-number-gender agreement, tense-aspect-mood distinctions, and case marking, alongside derivational strategies that reflect word-class changes. Script standardization and digital literacy tools were also developed to enhance script usage. The study offers a sustainable model for preserving endangered languages by incorporating traditional linguistic methodology with AI. This bridge between linguistic research with technological innovation highlights the value of interdisciplinary collaboration for community-based language revitalization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨ä¿æŠ¤å°åº¦è¥¿å­ŸåŠ æ‹‰é‚¦æ¿’ä¸´ç­ç»çš„ Toto è¯­è¨€ï¼Œé€šè¿‡å°†ä¼ ç»Ÿè¯­è¨€å­¦æ–¹æ³•ä¸äººå·¥æ™ºèƒ½æŠ€æœ¯ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€å¥—å¯æŒç»­çš„è¯­è¨€æ•°å­—åŒ–ä¿æŠ¤ä¸å¤å…´æ¨¡å‹ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å®åœ°è°ƒç ”å®Œæˆäº†è¯¦ç»†çš„è¯­è¨€è®°å½•ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªé›†æˆ Unicode è„šæœ¬ä¸”ç»è¿‡è¯­ç´ æ ‡æ³¨ï¼ˆMorpheme-taggedï¼‰çš„ Toto-Bangla-English ä¸‰è¯­è¯­æ–™åº“ã€‚åœ¨å½¢æ€å­¦åˆ†æï¼ˆMorphological Analysisï¼‰æ–¹é¢ï¼Œè¯¥ç ”ç©¶æ¶µç›–äº†äººç§°-æ•°-æ€§åˆ«ä¸€è‡´æ€§ï¼ˆPerson-Number-Gender Agreementï¼‰ã€æ—¶ä½“æ°”ï¼ˆTense-Aspect-Moodï¼‰åŠæ ¼æ ‡è®°ï¼ˆCase Markingï¼‰ç­‰å±ˆæŠ˜å½¢æ€ï¼Œä»¥åŠåæ˜ è¯ç±»å˜åŒ–çš„æ´¾ç”Ÿç­–ç•¥ã€‚åŸºäºè¯¥è¯­æ–™åº“ï¼Œç ”ç©¶è€…è®­ç»ƒäº†å°è¯­è¨€æ¨¡å‹ï¼ˆSmall Language Model, SLMï¼‰å’ŒåŸºäº Transformer çš„ç¿»è¯‘å¼•æ“ï¼Œå¹¶å¼€å‘äº†é¢å‘æ¯è¯­è€…å’Œå­¦ä¹ è€…çš„ä¸‰è¯­å­¦ä¹ åº”ç”¨ç¨‹åºã€‚è¿™é¡¹è·¨å­¦ç§‘åä½œä¸ä»…å®ç°äº†è„šæœ¬æ ‡å‡†åŒ–å’Œæ•°å­—ç´ å…»å·¥å…·çš„å¼€å‘ï¼Œä¹Ÿä¸ºæ¿’å±è¯­è¨€åœ¨æ•°å­—æ—¶ä»£çš„ç¤¾åŒºåŒ–æŒ¯å…´æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ä¸ç†è®ºå‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22629v1",
      "published_date": "2025-10-26 11:22:46 UTC",
      "updated_date": "2025-10-26 11:22:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:25.129136+00:00"
    },
    {
      "arxiv_id": "2510.22628v1",
      "title": "Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks",
      "title_zh": "Sentra-Guardï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹å¯¹æŠ—æ€§è¶Šç‹±å®æ—¶é˜²å¾¡çš„å¤šè¯­è¨€äººæœºåä½œæ¡†æ¶",
      "authors": [
        "Md. Mehedi Hasan",
        "Ziaur Rahman",
        "Rafid Mostafiz",
        "Md. Abir Hossain"
      ],
      "abstract": "This paper presents a real-time modular defense system named Sentra-Guard. The system detects and mitigates jailbreak and prompt injection attacks targeting large language models (LLMs). The framework uses a hybrid architecture with FAISS-indexed SBERT embedding representations that capture the semantic meaning of prompts, combined with fine-tuned transformer classifiers, which are machine learning models specialized for distinguishing between benign and adversarial language inputs. It identifies adversarial prompts in both direct and obfuscated attack vectors. A core innovation is the classifier-retriever fusion module, which dynamically computes context-aware risk scores that estimate how likely a prompt is to be adversarial based on its content and context. The framework ensures multilingual resilience with a language-agnostic preprocessing layer. This component automatically translates non-English prompts into English for semantic evaluation, enabling consistent detection across over 100 languages. The system includes a HITL feedback loop, where decisions made by the automated system are reviewed by human experts for continual learning and rapid adaptation under adversarial pressure. Sentra-Guard maintains an evolving dual-labeled knowledge base of benign and malicious prompts, enhancing detection reliability and reducing false positives. Evaluation results show a 99.96% detection rate (AUC = 1.00, F1 = 1.00) and an attack success rate (ASR) of only 0.004%. This outperforms leading baselines such as LlamaGuard-2 (1.3%) and OpenAI Moderation (3.7%). Unlike black-box approaches, Sentra-Guard is transparent, fine-tunable, and compatible with diverse LLM backends. Its modular design supports scalable deployment in both commercial and open-source environments. The system establishes a new state-of-the-art in adversarial LLM defense.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Sentra-Guardï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å®æ—¶æ¨¡å—åŒ–é˜²å¾¡ç³»ç»Ÿï¼Œæ—¨åœ¨é«˜æ•ˆæ£€æµ‹å’Œç¼“è§£è¶Šç‹±ï¼ˆjailbreakï¼‰åŠæç¤ºè¯æ³¨å…¥ï¼ˆprompt injectionï¼‰æ”»å‡»ã€‚ç³»ç»Ÿé‡‡ç”¨æ··åˆæ¶æ„ï¼Œå°†åŸºäº FAISS ç´¢å¼•çš„ SBERT åµŒå…¥è¡¨ç¤ºä¸å¾®è°ƒåçš„ Transformer åˆ†ç±»å™¨ç›¸ç»“åˆï¼Œèƒ½å¤Ÿç²¾å‡†è¯†åˆ«ç›´æ¥åŠæ¨¡ç³ŠåŒ–çš„æ”»å‡»å‘é‡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ†ç±»å™¨-æ£€ç´¢å™¨èåˆæ¨¡å—ï¼ˆclassifier-retriever fusion moduleï¼‰ï¼Œé€šè¿‡åŠ¨æ€è®¡ç®—ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é£é™©è¯„åˆ†ï¼Œå¹¶ç»“åˆæ”¯æŒ 100 å¤šç§è¯­è¨€çš„é¢„å¤„ç†å±‚ï¼Œç¡®ä¿äº†å…¨çƒèŒƒå›´å†…çš„é˜²å¾¡éŸ§æ€§ã€‚æ­¤å¤–ï¼Œæ¡†æ¶æ•´åˆäº†äººæœºåä½œï¼ˆHITLï¼‰åé¦ˆç¯è·¯ï¼Œåˆ©ç”¨ä¸“å®¶å®¡æŸ¥å®ç°æŒç»­å­¦ä¹ å¹¶ä¼˜åŒ–åŒæ ‡ç­¾çŸ¥è¯†åº“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSentra-Guard çš„æ£€æµ‹ç‡é«˜è¾¾ 99.96%ï¼Œæ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ä»…ä¸º 0.004%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äº LlamaGuard-2 å’Œ OpenAI Moderation ç­‰ç°æœ‰åŸºå‡†ã€‚è¯¥ç³»ç»Ÿå…·æœ‰é€æ˜åº¦é«˜ã€å¯å¾®è°ƒä¸”å…¼å®¹å¤šç§ LLM åç«¯çš„ç‰¹ç‚¹ï¼Œä¸ºå¤§è§„æ¨¡å•†ä¸šå’Œå¼€æºç¯å¢ƒæä¾›äº†æœ€å‰æ²¿çš„å¯¹æŠ—æ€§é˜²å¾¡æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 5 figures. Preprint version under review in the area of Artificial Intelligence (cs.AI)",
      "pdf_url": "https://arxiv.org/pdf/2510.22628v1",
      "published_date": "2025-10-26 11:19:47 UTC",
      "updated_date": "2025-10-26 11:19:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:27.239585+00:00"
    },
    {
      "arxiv_id": "2510.22626v1",
      "title": "SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for Competitive Programming",
      "title_zh": "SwiftSolveï¼šé¢å‘ç®—æ³•ç«èµ›çš„è‡ªè¿­ä»£ã€å¤æ‚åº¦æ„ŸçŸ¥å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Adhyayan Veer Singh",
        "Aaron Shen",
        "Brian Law",
        "Ahmed Ismail",
        "Jonas Rohweder",
        "Sean O'Brien",
        "Kevin Zhu"
      ],
      "abstract": "Correctness alone is insufficient: LLM-generated programs frequently satisfy unit tests while violating contest time or memory budgets. We present SwiftSolve, a complexity-aware multi-agent system for competitive programming that couples algorithmic planning with empirical profiling and complexity-guided repair. We frame competitive programming as a software environment where specialized agents act as programmers, each assuming roles such as planning, coding, profiling, and complexity analysis. A Planner proposes an algorithmic sketch; a deterministic Static Pruner filters high-risk plans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on a fixed input-size schedule to record wall time and peak memory; and a Complexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a complexity class and dispatch targeted patches to either the Planner or Coder. Agents communicate via typed, versioned JSON; a controller enforces iteration caps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10 Codeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains pass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with marginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate run-level success is 73.08% at 12.40 s mean. Failures are predominantly resource-bound, indicating inefficiency rather than logic errors. Against Claude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at approximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness (pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence of TLE or MLE, and complexity fit accuracy on BigO), demonstrating that profiling and complexity-guided replanning reduce inefficiency while preserving accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SwiftSolveï¼Œä¸€ç§é¢å‘ç«èµ›ç¼–ç¨‹(Competitive Programming)çš„è‡ªæˆ‘è¿­ä»£ã€å¤æ‚åº¦æ„ŸçŸ¥å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„ç¨‹åºè™½èƒ½é€šè¿‡å•å…ƒæµ‹è¯•ä½†ç»å¸¸å› æ•ˆç‡é—®é¢˜è¿åç«èµ›æ—¶é—´æˆ–å†…å­˜é¢„ç®—çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†ç¼–ç¨‹ä»»åŠ¡æ‹†è§£ä¸ºå¤šæ™ºèƒ½ä½“åä½œæµï¼Œåˆ©ç”¨Plannerè¿›è¡Œç®—æ³•è§„åˆ’ï¼Œç”±Static Prunerè¿‡æ»¤é«˜é£é™©æ–¹æ¡ˆï¼Œå¹¶é€šè¿‡Profilerè®°å½•ä»£ç åœ¨ä¸åŒè¾“å…¥è§„æ¨¡ä¸‹çš„å®é™…è¿è¡Œæ—¶é—´å’Œå³°å€¼å†…å­˜ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†Complexity Analystï¼Œé€šè¿‡æ‹Ÿåˆå¯¹æ•°å¢é•¿æ›²çº¿æ¥è¯†åˆ«å¤æ‚åº¦ç±»åˆ«ï¼Œå¹¶æ®æ­¤å‘Planneræˆ–Coderåˆ†å‘é’ˆå¯¹æ€§çš„ä¿®å¤è¡¥ä¸ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSwiftSolveåœ¨é¦–æ¬¡å°è¯•çš„pass@1è¾¾åˆ°61.54%ï¼Œä¸”åœ¨ä¸‰æ¬¡å°è¯•å†…çš„è§£é¢˜ç‡é«˜è¾¾80.77%ï¼Œå…¶è¿è¡ŒæˆåŠŸç‡æ˜¾è‘—ä¼˜äºClaude Opus 4ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆå®è¯åˆ†æ(Profiling)ä¸å¤æ‚åº¦å¯¼å‘çš„é‡æ–°è§„åˆ’èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘è¶…æ—¶(TLE)æˆ–å†…å­˜è¶…é™(MLE)ç°è±¡ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆä»£ç çš„è¿è¡Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22626v1",
      "published_date": "2025-10-26 11:05:27 UTC",
      "updated_date": "2025-10-26 11:05:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:34.537079+00:00"
    },
    {
      "arxiv_id": "2510.22620v1",
      "title": "Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents",
      "title_zh": "æ”»ç ´æ™ºèƒ½ä½“éª¨å¹²ï¼šAI æ™ºèƒ½ä½“ä¸­éª¨å¹²å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°",
      "authors": [
        "Julia Bazinska",
        "Max Mathys",
        "Francesco Casucci",
        "Mateo Rojas-Carulla",
        "Xander Davies",
        "Alexandra Souly",
        "Niklas Pfister"
      ],
      "abstract": "AI agents powered by large language models (LLMs) are being deployed at scale, yet we lack a systematic understanding of how the choice of backbone LLM affects agent security. The non-deterministic sequential nature of AI agents complicates security modeling, while the integration of traditional software with AI components entangles novel LLM vulnerabilities with conventional security risks. Existing frameworks only partially address these challenges as they either capture specific vulnerabilities only or require modeling of complete agents. To address these limitations, we introduce threat snapshots: a framework that isolates specific states in an agent's execution flow where LLM vulnerabilities manifest, enabling the systematic identification and categorization of security risks that propagate from the LLM to the agent level. We apply this framework to construct the $\\operatorname{b}^3$ benchmark, a security benchmark based on 194331 unique crowdsourced adversarial attacks. We then evaluate 31 popular LLMs with it, revealing, among other insights, that enhanced reasoning capabilities improve security, while model size does not correlate with security. We release our benchmark, dataset, and evaluation code to facilitate widespread adoption by LLM providers and practitioners, offering guidance for agent developers and incentivizing model developers to prioritize backbone security improvements.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºéª¨å¹²ç½‘ç»œæ—¶å¯¹ AI Agent å®‰å…¨æ€§çš„å½±å“ï¼Œå¹¶æŒ‡å‡ºå½“å‰çš„è¯„ä¼°æ¡†æ¶éš¾ä»¥åº”å¯¹æ™ºèƒ½ä½“éç¡®å®šæ€§æ‰§è¡Œåºåˆ—å¸¦æ¥çš„å¤æ‚å®‰å…¨å»ºæ¨¡æŒ‘æˆ˜ã€‚ä¸ºäº†ç³»ç»ŸåŒ–è¯†åˆ«ä» LLM ä¼ æ’­åˆ°æ™ºèƒ½ä½“å±‚é¢çš„å®‰å…¨é£é™©ï¼Œä½œè€…æå‡ºäº† threat snapshots æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡éš”ç¦»æ™ºèƒ½ä½“æ‰§è¡Œæµä¸­æ¼æ´æ˜¾ç°çš„ç‰¹å®šçŠ¶æ€æ¥å®ç°é£é™©åˆ†ç±»ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¶…è¿‡19ä¸‡ä¸ªä¼—åŒ…å¯¹æŠ—æ”»å‡»æ ·æœ¬æ„å»ºäº† $\\operatorname{b}^3$ benchmarkï¼Œå¹¶å¯¹31ä¸ªä¸»æµ LLM è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¢å¼ºçš„æ¨ç†èƒ½åŠ›ï¼ˆreasoning capabilitiesï¼‰èƒ½æœ‰æ•ˆæå‡å®‰å…¨æ€§ï¼Œè€Œæ¨¡å‹è§„æ¨¡ï¼ˆmodel sizeï¼‰ä¸å®‰å…¨æ€§ä¹‹é—´å¹¶æ— æ˜¾è‘—ç›¸å…³æ€§ã€‚è¯¥ç ”ç©¶é€šè¿‡å¼€æºåŸºå‡†æµ‹è¯•ã€æ•°æ®é›†å’Œè¯„ä¼°ä»£ç ï¼Œä¸ºæ™ºèƒ½ä½“å¼€å‘è€…é€‰æ‹©æ›´å®‰å…¨çš„ backbone æä¾›äº†æŒ‡å¯¼ï¼Œå¹¶æ¿€åŠ±æ¨¡å‹å‚å•†ä¼˜å…ˆæ”¹è¿›éª¨å¹²ç½‘ç»œçš„å®‰å…¨æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Julia Bazinska and Max Mathys contributed equally",
      "pdf_url": "https://arxiv.org/pdf/2510.22620v1",
      "published_date": "2025-10-26 10:36:42 UTC",
      "updated_date": "2025-10-26 10:36:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:33.839414+00:00"
    },
    {
      "arxiv_id": "2510.22618v1",
      "title": "Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation",
      "title_zh": "å†œä¸šäººå·¥æ™ºèƒ½ä¸­çš„è·¨ç‰©ç§è¿ç§»å­¦ä¹ ï¼šé’ˆå¯¹å¥¶ç‰›å§¿æ€ä¼°è®¡çš„ ZebraPose é€‚é…æ€§è¯„ä¼°",
      "authors": [
        "Mackenzie Tapp",
        "Sibi Chakravarthy Parivendan",
        "Kashfia Sailunaz",
        "Suresh Neethirajan"
      ],
      "abstract": "Pose estimation serves as a cornerstone of computer vision for understanding animal posture, behavior, and welfare. Yet, agricultural applications remain constrained by the scarcity of large, annotated datasets for livestock, especially dairy cattle. This study evaluates the potential and limitations of cross-species transfer learning by adapting ZebraPose - a vision transformer-based model trained on synthetic zebra imagery - for 27-keypoint detection in dairy cows under real barn conditions. Using three configurations - a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), a subset of the APT-36K benchmark dataset, and their combination, we systematically assessed model accuracy and generalization across environments. While the combined model achieved promising performance (AP = 0.86, AR = 0.87, PCK 0.5 = 0.869) on in-distribution data, substantial generalization failures occurred when applied to unseen barns and cow populations. These findings expose the synthetic-to-real domain gap as a major obstacle to agricultural AI deployment and emphasize that morphological similarity between species is insufficient for cross-domain transfer. The study provides practical insights into dataset diversity, environmental variability, and computational constraints that influence real-world deployment of livestock monitoring systems. We conclude with a call for agriculture-first AI design, prioritizing farm-level realism, cross-environment robustness, and open benchmark datasets to advance trustworthy and scalable animal-centric technologies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è·¨ç‰©ç§è¿ç§»å­¦ä¹ (Cross-Species Transfer Learning)åœ¨å†œä¸šäººå·¥æ™ºèƒ½ä¸­çš„åº”ç”¨ï¼Œé‡ç‚¹è¯„ä¼°äº†å°†åŸºäºè§†è§‰Transformer(Vision Transformer)ä¸”åœ¨åˆæˆæ–‘é©¬å›¾åƒä¸Šè®­ç»ƒçš„ZebraPoseæ¨¡å‹é€‚é…äºå¥¶ç‰›å§¿æ€ä¼°è®¡çš„æ•ˆæœã€‚é€šè¿‡æ•´åˆè‡ªå®šä¹‰å†œåœºæ•°æ®é›†ä¸APT-36KåŸºå‡†æ•°æ®é›†ï¼Œç ”ç©¶è€…åœ¨åˆ†å¸ƒå†…æµ‹è¯•ä¸­å–å¾—äº†å¹³å‡ç²¾åº¦(AP)ä¸º0.86çš„ä¼˜å¼‚è¡¨ç°ã€‚ç„¶è€Œï¼Œæ¨¡å‹åœ¨é¢å¯¹æœªè§è¿‡çš„ç‰›èˆç¯å¢ƒæ—¶è¡¨ç°å‡ºæ˜æ˜¾çš„æ³›åŒ–å¤±æ•ˆï¼Œè¿™è¡¨æ˜ç‰©ç§é—´çš„å½¢æ€ç›¸ä¼¼æ€§å¹¶ä¸èƒ½å®Œå…¨æŠµæ¶ˆåˆæˆåˆ°çœŸå®(Synthetic-to-Real)çš„åŸŸé—´å·®è·ã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†ç¯å¢ƒå¤šæ ·æ€§å¯¹ç•œç‰§ç›‘æµ‹ç³»ç»Ÿéƒ¨ç½²çš„é™åˆ¶ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘å…·æœ‰è·¨ç¯å¢ƒé²æ£’æ€§çš„å†œä¸šä¼˜å…ˆ(Agriculture-first)AIè®¾è®¡çš„é‡è¦æ€§ã€‚é€šè¿‡è¿™ä¸€åˆ†æï¼Œè®ºæ–‡ä¸ºæ„å»ºå¯æ‰©å±•ä¸”å€¼å¾—ä¿¡èµ–çš„åŠ¨ç‰©ç¦åˆ©ç›‘æµ‹æŠ€æœ¯æä¾›äº†å®è·µè§è§£å’Œæ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 11 figures, 6 Tables",
      "pdf_url": "https://arxiv.org/pdf/2510.22618v1",
      "published_date": "2025-10-26 10:31:22 UTC",
      "updated_date": "2025-10-26 10:31:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:36.927973+00:00"
    },
    {
      "arxiv_id": "2510.22616v2",
      "title": "PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion",
      "title_zh": "PerCoRï¼šé€šè¿‡å¤šé¡¹é€‰æ‹©å¥å­è¡¥å…¨ä»»åŠ¡è¯„æµ‹æ³¢æ–¯è¯­å¸¸è¯†æ¨ç†èƒ½åŠ›",
      "authors": [
        "Morteza Alikhani",
        "Mohammadtaha Bagherifard",
        "Erfan Zinvandi",
        "Mehran Sarmadi"
      ],
      "abstract": "We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale Persian benchmark for commonsense reasoning. PerCoR contains 106K multiple-choice sentence-completion problems drawn from more than forty news, cultural, and other web sources. We introduce a novel conjunction-based segmentation strategy to generate coherent sentence-completion pairs, enabling broad topical and structural diversity. To create challenging distractors, we propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and Adversarial Filtering), a generation-free adversarial filtering method that selects distractors from the pool of gold continuations while maximising model confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%). The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both the dataset's difficulty and the remaining performance gap in Persian commonsense reasoning. We further show that DRESS-AF transfers to the English HellaSwag benchmark, increasing its difficulty without hurting human solvability. The dataset is available at https://huggingface.co/datasets/MCINext/PerCoR.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PerCoR (Persian Commonsense Reasoning)ï¼Œè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„æ³¢æ–¯è¯­å¸¸è¯†æ¨ç† benchmarkï¼ŒåŒ…å«ä»æ–°é—»å’Œæ–‡åŒ–ç­‰å¤šç§æ¥æºæå–çš„ 10.6ä¸‡ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ã€‚ä¸ºäº†ç”Ÿæˆå…·æœ‰å¤šæ ·æ€§çš„å¥å­è¡¥å…¨å¯¹ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åŸºäºè¿è¯çš„åˆ†å‰²ç­–ç•¥(conjunction-based segmentation strategy)ï¼Œå¹¶æå‡ºäº† DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and Adversarial Filtering) å¯¹æŠ—æ€§è¿‡æ»¤æ–¹æ³•æ¥ç­›é€‰æå…·å¹²æ‰°æ€§çš„å¤‡é€‰é¡¹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œäººç±»åœ¨ PerCoR ä¸Šçš„å¾—åˆ†ä¸º 89%ï¼Œè€Œ OpenAI-o3 ä»¥ 92.18% çš„å‡†ç¡®ç‡ä½å±…æ¦œé¦–ï¼ŒClaude-Sonnet-3.7 ç´§éšå…¶åã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ€å¼ºçš„å¼€æºæ¨¡å‹ DeepSeek-R1 ä»…è¾¾åˆ° 82.51%ï¼Œè¿™è¡¨æ˜æ³¢æ–¯è¯­å¸¸è¯†æ¨ç†ä»»åŠ¡ä»å…·æœ‰å¾ˆå¤§æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¯æ˜ DRESS-AF æ–¹æ³•å…·æœ‰è‰¯å¥½çš„è¿ç§»æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡è‹±è¯­ HellaSwag benchmark çš„éš¾åº¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 17 figures, Accepted to IJCNLP-AACL 2025 (Main Conference)",
      "pdf_url": "https://arxiv.org/pdf/2510.22616v2",
      "published_date": "2025-10-26 10:25:02 UTC",
      "updated_date": "2026-01-15 19:55:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:40.632319+00:00"
    },
    {
      "arxiv_id": "2510.22614v1",
      "title": "Does In-IDE Calibration of Large Language Models work at Scale?",
      "title_zh": "IDE å†…å¤§è¯­è¨€æ¨¡å‹çš„å¤§è§„æ¨¡æ ¡å‡†æ˜¯å¦æœ‰æ•ˆï¼Ÿ",
      "authors": [
        "Roham Koohestani",
        "Agnia Sergeyuk",
        "David Gros",
        "Claudio Spiess",
        "Sergey Titov",
        "Prem Devanbu",
        "Maliheh Izadi"
      ],
      "abstract": "The introduction of large language models into integrated development environments (IDEs) is revolutionizing software engineering, yet it poses challenges to the usefulness and reliability of Artificial Intelligence-generated code. Post-hoc calibration of internal model confidences aims to align probabilities with an acceptability measure. Prior work suggests calibration can improve alignment, but at-scale evidence is limited. In this work, we investigate the feasibility of applying calibration of code models to an in-IDE context. We study two aspects of the problem: (1) the technical method for implementing confidence calibration and improving the reliability of code generation models, and (2) the human-centered design principles for effectively communicating reliability signal to developers. First, we develop a scalable and flexible calibration framework which can be used to obtain calibration weights for open-source models using any dataset, and evaluate whether calibrators improve the alignment between model confidence and developer acceptance behavior. Through a large-scale analysis of over 24 million real-world developer interactions across multiple programming languages, we find that a general, post-hoc calibration model based on Platt-scaling does not, on average, improve the reliability of model confidence signals. We also find that while dynamically personalizing calibration to individual users can be effective, its effectiveness is highly dependent on the volume of user interaction data. Second, we conduct a multi-phase design study with 3 expert designers and 153 professional developers, combining scenario-based design, semi-structured interviews, and survey validation, revealing a clear preference for presenting reliability signals via non-numerical, color-coded indicators within the in-editor code generation workflow.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é›†æˆå¼€å‘ç¯å¢ƒ(IDE)ä¸­å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ ¡å‡†(Calibration)é—®é¢˜ï¼Œæ—¨åœ¨ä½¿æ¨¡å‹ç½®ä¿¡åº¦ä¸å¼€å‘è€…æ¥å—åº¦ä¿æŒä¸€è‡´ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ ¡å‡†æ¡†æ¶ï¼Œé€šè¿‡åˆ†æè¶…è¿‡2400ä¸‡æ¬¡çœŸå®çš„å¼€å‘è€…äº¤äº’ï¼Œè¯„ä¼°äº†åŸºäºPlatt-scalingçš„åéªŒæ ¡å‡†æ¨¡å‹åœ¨å¤šç§ç¼–ç¨‹è¯­è¨€ä¸­çš„æ•ˆæœã€‚ç»“æœæ˜¾ç¤ºï¼Œé€šç”¨çš„Platt-scalingæ–¹æ³•å¹³å‡è€Œè¨€å¹¶æœªæå‡æ¨¡å‹ç½®ä¿¡åº¦ä¿¡å·çš„å¯é æ€§ï¼Œè€Œé’ˆå¯¹ä¸ªäººçš„åŠ¨æ€ä¸ªæ€§åŒ–æ ¡å‡†è™½æœ‰æ•ˆï¼Œä½†å…¶æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºç”¨æˆ·äº¤äº’æ•°æ®çš„è§„æ¨¡ã€‚åœ¨ä»¥äººä¸ºä¸­å¿ƒçš„è®¾è®¡ç ”ç©¶æ–¹é¢ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹153åä¸“ä¸šå¼€å‘è€…è¿›è¡Œå¤šé˜¶æ®µå®éªŒï¼Œæ­ç¤ºäº†ç”¨æˆ·å¯¹å¯é æ€§ä¿¡å·å‘ˆç°æ–¹å¼çš„åå¥½ã€‚ç ”ç©¶å‘ç°ï¼Œå¼€å‘è€…æ˜æ˜¾å€¾å‘äºåœ¨ç¼–è¾‘å™¨å†…é€šè¿‡éæ•°å­—çš„ã€è‰²å½©ç¼–ç (color-coded)çš„æŒ‡ç¤ºå™¨æ¥è·å–ä»£ç ç”Ÿæˆçš„å¯é æ€§ä¿¡æ¯ã€‚è¯¥é¡¹å·¥ä½œä¸ºåœ¨å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­å®æ–½ä»£ç æ¨¡å‹æ ¡å‡†ä»¥åŠä¼˜åŒ–å¼€å‘è€…äº¤äº’ä½“éªŒæä¾›äº†é‡è¦çš„æŠ€æœ¯åˆ†æä¸è®¾è®¡å‡†åˆ™ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.22614v1",
      "published_date": "2025-10-26 10:15:03 UTC",
      "updated_date": "2025-10-26 10:15:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:43.651738+00:00"
    },
    {
      "arxiv_id": "2510.22609v1",
      "title": "CLIN-LLM: A Safety-Constrained Hybrid Framework for Clinical Diagnosis and Treatment Generation",
      "title_zh": "CLIN-LLMï¼šé¢å‘ä¸´åºŠè¯Šæ–­ä¸æ²»ç–—ç”Ÿæˆçš„å®‰å…¨æ€§çº¦æŸæ··åˆæ¡†æ¶",
      "authors": [
        "Md. Mehedi Hasan",
        "Rafid Mostafiz",
        "Md. Abir Hossain",
        "Bikash Kumar Paul"
      ],
      "abstract": "Accurate symptom-to-disease classification and clinically grounded treatment recommendations remain challenging, particularly in heterogeneous patient settings with high diagnostic risk. Existing large language model (LLM)-based systems often lack medical grounding and fail to quantify uncertainty, resulting in unsafe outputs. We propose CLIN-LLM, a safety-constrained hybrid pipeline that integrates multimodal patient encoding, uncertainty-calibrated disease classification, and retrieval-augmented treatment generation. The framework fine-tunes BioBERT on 1,200 clinical cases from the Symptom2Disease dataset and incorporates Focal Loss with Monte Carlo Dropout to enable confidence-aware predictions from free-text symptoms and structured vitals. Low-certainty cases (18%) are automatically flagged for expert review, ensuring human oversight. For treatment generation, CLIN-LLM employs Biomedical Sentence-BERT to retrieve top-k relevant dialogues from the 260,000-sample MedDialog corpus. The retrieved evidence and patient context are fed into a fine-tuned FLAN-T5 model for personalized treatment generation, followed by post-processing with RxNorm for antibiotic stewardship and drug-drug interaction (DDI) screening. CLIN-LLM achieves 98% accuracy and F1 score, outperforming ClinicalBERT by 7.1% (p < 0.001), with 78% top-5 retrieval precision and a clinician-rated validity of 4.2 out of 5. Unsafe antibiotic suggestions are reduced by 67% compared to GPT-5. These results demonstrate CLIN-LLM's robustness, interpretability, and clinical safety alignment. The proposed system provides a deployable, human-in-the-loop decision support framework for resource-limited healthcare environments. Future work includes integrating imaging and lab data, multilingual extensions, and clinical trial validation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CLIN-LLMï¼Œä¸€ç§å…·æœ‰å®‰å…¨æ€§çº¦æŸçš„æ··åˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠè¯Šæ–­å’Œæ²»ç–—ç”Ÿæˆä¸­å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç¼ºä¹åŒ»å­¦åŸºç¡€å’Œæ— æ³•é‡åŒ–ä¸ç¡®å®šæ€§çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤šæ¨¡æ€æ‚£è€…ç¼–ç ã€ä¸ç¡®å®šæ€§æ ¡å‡†çš„ç–¾ç—…åˆ†ç±»ä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯ï¼Œé€šè¿‡åœ¨BioBERTæ¨¡å‹ä¸­å¼•å…¥Focal Losså’ŒMonte Carlo Dropoutï¼Œå®ç°äº†å¯¹è‡ªç”±æ–‡æœ¬å’Œç»“æ„åŒ–ç”Ÿå‘½ä½“å¾çš„ç½®ä¿¡åº¦æ„ŸçŸ¥é¢„æµ‹ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨æ ‡è®°ä½ç¡®å®šæ€§ç—…ä¾‹ä¾›ä¸“å®¶å®¡æŸ¥ï¼Œç¡®ä¿äº†äººç±»ç›‘ç®¡çš„ä»‹å…¥ã€‚åœ¨æ²»ç–—ç”Ÿæˆæ–¹é¢ï¼ŒCLIN-LLMåˆ©ç”¨Biomedical Sentence-BERTä»MedDialogè¯­æ–™åº“æ£€ç´¢è¯æ®ï¼Œå¹¶ç»“åˆå¾®è°ƒçš„FLAN-T5ç”Ÿæˆæ–¹æ¡ˆï¼Œæœ€åé€šè¿‡RxNormè¿›è¡Œè¯ç‰©ç›¸äº’ä½œç”¨(DDI)ç­›é€‰ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLIN-LLMè¾¾åˆ°äº†98%çš„å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºClinicalBERTï¼Œä¸”ç›¸æ¯”GPT-5å‡å°‘äº†67%çš„ä¸å®‰å…¨æŠ—ç”Ÿç´ å»ºè®®ã€‚è¿™ä¸€ç ”ç©¶ä¸ºèµ„æºå—é™çš„åŒ»ç–—ç¯å¢ƒæä¾›äº†ä¸€ä¸ªå…·å¤‡é²æ£’æ€§ã€å¯è§£é‡Šæ€§ä¸”ç¬¦åˆä¸´åºŠå®‰å…¨å¯¹é½çš„å†³ç­–æ”¯æŒå·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 9 figures. Preprint version under review in the area of Artificial Intelligence (cs.CR)",
      "pdf_url": "https://arxiv.org/pdf/2510.22609v1",
      "published_date": "2025-10-26 10:11:53 UTC",
      "updated_date": "2025-10-26 10:11:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:45:48.327765+00:00"
    },
    {
      "arxiv_id": "2510.22602v1",
      "title": "Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance",
      "title_zh": "ä¸ªäººå¥åº·æŠ¤ç†å…¬ç”¨ç³»ç»Ÿ (PCU)ï¼šæ„å»ºé¢å‘æ—¥å¸¸æ´å¯Ÿä¸æŒ‡å¯¼çš„å¥åº·åŸºç¡€è®¾æ–½",
      "authors": [
        "Mahyar Abbasian",
        "Ramesh Jain"
      ],
      "abstract": "Building on decades of success in digital infrastructure and biomedical innovation, we propose the Personal Care Utility (PCU) - a cybernetic system for lifelong health guidance. PCU is conceived as a global, AI-powered utility that continuously orchestrates multimodal data, knowledge, and services to assist individuals and populations alike. Drawing on multimodal agents, event-centric modeling, and contextual inference, it offers three essential capabilities: (1) trusted health information tailored to the individual, (2) proactive health navigation and behavior guidance, and (3) ongoing interpretation of recovery and treatment response after medical events. Unlike conventional episodic care, PCU functions as an ambient, adaptive companion - observing, interpreting, and guiding health in real time across daily life. By integrating personal sensing, experiential computing, and population-level analytics, PCU promises not only improved outcomes for individuals but also a new substrate for public health and scientific discovery. We describe the architecture, design principles, and implementation challenges of this emerging paradigm.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸ªäººæŠ¤ç†æ•ˆç”¨(Personal Care Utility, PCU)ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æä¾›ç»ˆèº«å¥åº·æŒ‡å¯¼çš„æ§åˆ¶è®ºç³»ç»Ÿ(cybernetic system)ã€‚PCU è¢«æ„æƒ³ä¸ºä¸€ä¸ªå…¨çƒæ€§ã€AI é©±åŠ¨çš„åŸºç¡€è®¾æ–½ï¼Œé€šè¿‡æŒç»­ç¼–æ’å¤šæ¨¡æ€æ•°æ®(multimodal data)ã€çŸ¥è¯†å’ŒæœåŠ¡ï¼Œä¸ºä¸ªäººå’Œç¾¤ä½“æä¾›æ”¯æŒã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å¤šæ¨¡æ€æ™ºèƒ½ä½“(multimodal agents)ã€ä»¥äº‹ä»¶ä¸ºå»ºæ¨¡ä¸­å¿ƒ(event-centric modeling)å’Œä¸Šä¸‹æ–‡æ¨ç†(contextual inference)ï¼Œå®ç°äº†ä¸ªæ€§åŒ–çš„å¥åº·ä¿¡æ¯æä¾›ã€ä¸»åŠ¨çš„å¥åº·å¯¼èˆªä¸è¡Œä¸ºæŒ‡å¯¼ï¼Œä»¥åŠå¯¹åŒ»ç–—äº‹ä»¶ååº·å¤å’Œæ²»ç–—ååº”çš„æŒç»­è§£è¯»ã€‚ä¸ä¼ ç»Ÿçš„å‘ä½œæ€§æŠ¤ç†(episodic care)ä¸åŒï¼ŒPCU ä½œä¸ºä¸€ç§ç¯å¢ƒé€‚åº”å‹ä¼´ä¾£ï¼Œåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å®æ—¶è§‚å¯Ÿã€è§£é‡Šå¹¶å¼•å¯¼å¥åº·çŠ¶æ€ã€‚é€šè¿‡é›†æˆä¸ªäººä¼ æ„Ÿ(personal sensing)ã€ä½“éªŒå¼è®¡ç®—(experiential computing)å’Œç¾¤ä½“å±‚é¢çš„åˆ†æï¼ŒPCU ä¸ä»…æœ‰æœ›æ”¹å–„ä¸ªäººå¥åº·ç»“æœï¼Œè¿˜ä¸ºå…¬å…±å«ç”Ÿå’Œç§‘å­¦å‘ç°æä¾›äº†æ–°çš„åŸºç¡€ã€‚è®ºæ–‡è¯¦ç»†é˜è¿°äº†è¿™ä¸€æ–°å…´èŒƒå¼çš„æ¶æ„ã€è®¾è®¡åŸåˆ™ä»¥åŠåœ¨å®æ–½è¿‡ç¨‹ä¸­é¢ä¸´çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 2 figures, 1 table, Journal paper",
      "pdf_url": "https://arxiv.org/pdf/2510.22602v1",
      "published_date": "2025-10-26 09:43:33 UTC",
      "updated_date": "2025-10-26 09:43:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:01.434933+00:00"
    },
    {
      "arxiv_id": "2510.22600v1",
      "title": "RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience",
      "title_zh": "RoGER-SLAMï¼šé¢å‘å™ªå£°ä¸å¼±å…‰ç¯å¢ƒçš„é«˜é²æ£’æ€§é«˜æ–¯æ³¼æº… SLAM ç³»ç»Ÿ",
      "authors": [
        "Huilin Yin",
        "Zhaolin Yang",
        "Linchuan Zhang",
        "Gerhard Rigoll",
        "Johannes Betz"
      ],
      "abstract": "The reliability of Simultaneous Localization and Mapping (SLAM) is severely constrained in environments where visual inputs suffer from noise and low illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM frameworks achieve high-fidelity mapping under clean conditions, they remain vulnerable to compounded degradations that degrade mapping and tracking performance. A key observation underlying our work is that the original 3DGS rendering pipeline inherently behaves as an implicit low-pass filter, attenuating high-frequency noise but also risking over-smoothing. Building on this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for noise and low-light resilience. The framework integrates three innovations: a Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples rendered appearance, depth, and edge cues; an adaptive tracking objective with residual balancing regularization; and a Contrastive Language-Image Pretraining (CLIP)-based enhancement module, selectively activated under compounded degradations to restore semantic and structural fidelity. Comprehensive experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM consistently improves trajectory accuracy and reconstruction quality compared with other 3DGS-SLAM systems, especially under adverse imaging conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†RoGER-SLAMï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹å™ªå£°å’Œä½å…‰ç…§ç¯å¢ƒè®¾è®¡çš„é²æ£’3D Gaussian Splatting (3DGS) SLAMç³»ç»Ÿã€‚é’ˆå¯¹è§†è§‰è¾“å…¥å—æŸå¯¼è‡´åˆ¶å›¾å’Œå®šä½æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨äº†3DGSæ¸²æŸ“ç®¡çº¿ä½œä¸ºéšå«ä½é€šæ»¤æ³¢å™¨çš„ç‰¹æ€§æ¥æŠ‘åˆ¶é«˜é¢‘å™ªå£°å¹¶å¹³è¡¡ç»†èŠ‚å¹³æ»‘ã€‚ç³»ç»Ÿé›†æˆäº†ä¸‰é¡¹æ ¸å¿ƒåˆ›æ–°ï¼ŒåŒ…æ‹¬è€¦åˆå¤–è§‚ã€æ·±åº¦å’Œè¾¹ç¼˜çº¿ç´¢çš„ç»“æ„ä¿æŒé²æ£’èåˆ(SP-RoFusion)æœºåˆ¶ï¼Œä»¥åŠå¸¦æœ‰æ®‹å·®å¹³è¡¡æ­£åˆ™åŒ–çš„è‡ªé€‚åº”è·Ÿè¸ªç›®æ ‡ã€‚æ­¤å¤–ï¼ŒRoGER-SLAMè¿˜å¼•å…¥äº†åŸºäºCLIPçš„å¢å¼ºæ¨¡å—ï¼Œåœ¨å¤åˆé€€åŒ–æ¡ä»¶ä¸‹æœ‰æ•ˆä¿®å¤åœºæ™¯çš„è¯­ä¹‰å’Œç»“æ„ä¿çœŸåº¦ã€‚åœ¨Replicaã€TUMåŠçœŸå®ä¸–ç•Œåºåˆ—ä¸Šçš„å®éªŒç»“æœè¯å®ï¼Œè¯¥ç³»ç»Ÿåœ¨è½¨è¿¹ç²¾åº¦å’Œé‡å»ºè´¨é‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„3DGS-SLAMæ–¹æ¡ˆã€‚è¯¥æˆæœä¸ºåœ¨æ¶åŠ£æˆåƒæ¡ä»¶ä¸‹å®ç°å¯é çš„å®æ—¶å®šä½ä¸é«˜ä¿çœŸåœ°å›¾æ„å»ºæä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 11 figures, under review",
      "pdf_url": "https://arxiv.org/pdf/2510.22600v1",
      "published_date": "2025-10-26 09:32:43 UTC",
      "updated_date": "2025-10-26 09:32:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:14.795138+00:00"
    },
    {
      "arxiv_id": "2510.22594v1",
      "title": "A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning",
      "title_zh": "é‡åŒ–é¢„è®­ç»ƒä¸ä¸Šä¸‹æ–‡å¯¹ä¸Šä¸‹æ–‡å­¦ä¹ å¢ç›Šçš„åˆ†ææ¡†æ¶",
      "authors": [
        "Bingqing Song",
        "Jiaxiang Li",
        "Rong Wang",
        "Songtao Lu",
        "Mingyi Hong"
      ],
      "abstract": "Pre-trained large language models have demonstrated a strong ability to learn from context, known as in-context learning (ICL). Despite a surge of recent applications that leverage such capabilities, it is by no means clear, at least theoretically, how the ICL capabilities arise, and in particular, what is the precise role played by key factors such as pre-training procedure as well as context construction. In this work, we propose a new framework to analyze the ICL performance, for a class of realistic settings, which includes network architectures, data encoding, data generation, and prompt construction process. As a first step, we construct a simple example with a one-layer transformer, and show an interesting result, namely when the pre-train data distribution is different from the query task distribution, a properly constructed context can shift the output distribution towards the query task distribution, in a quantifiable manner, leading to accurate prediction on the query topic. We then extend the findings in the previous step to a more general case, and derive the precise relationship between ICL performance, context length and the KL divergence between pre-train and query task distribution. Finally, we provide experiments to validate our theoretical results.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„ç†è®ºæ¡†æ¶ï¼Œæ—¨åœ¨é‡åŒ–é¢„è®­ç»ƒ(Pre-training)è¿‡ç¨‹å’Œä¸Šä¸‹æ–‡(Context)æ„å»ºåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning, ICL)ä¸­æ‰€èµ·çš„å…·ä½“ä½œç”¨ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ICLæ–¹é¢è¡¨ç°å“è¶Šï¼Œä½†å…¶èƒ½åŠ›çš„èµ·æºï¼Œå°¤å…¶æ˜¯é¢„è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸æç¤º(Prompt)æ„é€ ä¹‹é—´çš„ç†è®ºè”ç³»ä»ä¸æ¸…æ™°ã€‚ä½œè€…é¦–å…ˆé€šè¿‡å•å±‚Transformeræ¨¡å‹è¯æ˜ï¼Œå½“é¢„è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸æŸ¥è¯¢ä»»åŠ¡åˆ†å¸ƒä¸ä¸€è‡´æ—¶ï¼Œç²¾å¿ƒæ„å»ºçš„ä¸Šä¸‹æ–‡èƒ½å¤Ÿä»¥å¯é‡åŒ–çš„æ–¹å¼å°†è¾“å‡ºåˆ†å¸ƒå¯¼å‘æŸ¥è¯¢ä»»åŠ¡åˆ†å¸ƒï¼Œä»è€Œå®ç°å‡†ç¡®é¢„æµ‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¨å¯¼å‡ºäº†ICLæ€§èƒ½ã€ä¸Šä¸‹æ–‡é•¿åº¦(Context length)ä»¥åŠé¢„è®­ç»ƒä¸æŸ¥è¯¢ä»»åŠ¡åˆ†å¸ƒä¹‹é—´KLæ•£åº¦(KL divergence)çš„ç²¾ç¡®æ•°å­¦å…³ç³»ã€‚æœ€åï¼Œé€šè¿‡ä¸€ç³»åˆ—å®éªŒéªŒè¯äº†ä¸Šè¿°ç†è®ºæ¨å¯¼çš„æ­£ç¡®æ€§ï¼Œä¸ºç†è§£æ¨¡å‹å¦‚ä½•åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯çº æ­£åˆ†å¸ƒåç§»å¹¶æå‡é¢„æµ‹ç²¾åº¦æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22594v1",
      "published_date": "2025-10-26 09:21:29 UTC",
      "updated_date": "2025-10-26 09:21:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:06.663254+00:00"
    },
    {
      "arxiv_id": "2510.22593v1",
      "title": "AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment",
      "title_zh": "AutoBenchï¼šåŸºäºç›¸äº’å¯¹ç­‰è¯„ä¼°çš„å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–è¯„ä¼°",
      "authors": [
        "Dario Loi",
        "Elena Maria MuiÃ ",
        "Federico Siciliano",
        "Giovanni Trappolini",
        "Vincenzo CrisÃ ",
        "Peter Kruger",
        "Fabrizio Silvestri"
      ],
      "abstract": "We present AutoBench, a fully automated and self-sustaining framework for evaluating Large Language Models (LLMs) through reciprocal peer assessment. This paper provides a rigorous scientific validation of the AutoBench methodology, originally developed as an open-source project by eZecute S.R.L.. Unlike static benchmarks that suffer from test-set contamination and limited adaptability, AutoBench dynamically generates novel evaluation tasks while models alternately serve as question generators, contestants, and judges across diverse domains. An iterative weighting mechanism amplifies the influence of consistently reliable evaluators, aggregating peer judgments into consensus-based rankings that reflect collective model agreement. Our experiments demonstrate strong correlations with established benchmarks including MMLU-Pro and GPQA (respectively 78\\% and 63\\%), validating this peer-driven evaluation paradigm. The multi-judge design significantly outperforms single-judge baselines, confirming that distributed evaluation produces more robust and human-consistent assessments. AutoBench offers a scalable, contamination-resistant alternative to static benchmarks for the continuous evaluation of evolving language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AutoBenchï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ç›¸äº’åŒè¡Œè¯„ä¼°(Reciprocal Peer Assessment)å®ç°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å…¨è‡ªåŠ¨è¯„ä¼°çš„è‡ªç»´æŒæ¡†æ¶ã€‚ä¸å—æµ‹è¯•é›†æ±¡æŸ“(Test-set Contamination)å’Œé€‚åº”æ€§é™åˆ¶çš„é™æ€åŸºå‡†ä¸åŒï¼ŒAutoBenchå…è®¸æ¨¡å‹åœ¨å¤šæ ·åŒ–é¢†åŸŸä¸­äº¤æ›¿æ‹…ä»»é—®é¢˜ç”Ÿæˆè€…ã€å‚èµ›è€…å’Œè¯„å®¡è€…ï¼ŒåŠ¨æ€ç”Ÿæˆè¯„ä¼°ä»»åŠ¡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¿­ä»£æƒé‡æœºåˆ¶(Iterative Weighting Mechanism)æ”¾å¤§å¯é è¯„ä¼°è€…çš„å½±å“åŠ›ï¼Œå°†åŒè¡Œè¯„åˆ¤èšåˆæˆåŸºäºå…±è¯†çš„æ’åã€‚å®éªŒè¯æ˜ï¼ŒAutoBenchä¸MMLU-ProåŠGPQAç­‰åŸºå‡†å‘ˆç°å¼ºç›¸å…³æ€§ï¼Œç›¸å…³ç³»æ•°åˆ†åˆ«è¾¾åˆ°78%å’Œ63%ã€‚å¤šè¯„å®¡è®¾è®¡åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—è¶…è¶Šå•è¯„å®¡åŸºå‡†ï¼Œèƒ½å¤Ÿäº§ç”Ÿæ›´ç¨³å¥ä¸”ç¬¦åˆäººç±»ä¸€è‡´æ€§çš„è¯„ä¼°ç»“æœã€‚AutoBenchä¸ºæŒç»­æ¼”è¿›çš„è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ç§å¯æ‰©å±•ã€æŠ—æ±¡æŸ“ä¸”ä¼˜äºé™æ€è¯„ä¼°çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22593v1",
      "published_date": "2025-10-26 09:20:39 UTC",
      "updated_date": "2025-10-26 09:20:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:09.930865+00:00"
    },
    {
      "arxiv_id": "2510.22590v1",
      "title": "ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs",
      "title_zh": "ATOMï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªé€‚åº”ä¼˜åŒ–åŠ¨æ€æ—¶åºçŸ¥è¯†å›¾è°±æ„å»º",
      "authors": [
        "Yassir Lairgi",
        "Ludovic Moncla",
        "Khalid Benabdeslem",
        "RÃ©my Cazabet",
        "Pierre ClÃ©au"
      ],
      "abstract": "In today's rapidly expanding data landscape, knowledge extraction from unstructured text is vital for real-time analytics, temporal inference, and dynamic memory frameworks. However, traditional static knowledge graph (KG) construction often overlooks the dynamic and time-sensitive nature of real-world data, limiting adaptability to continuous changes. Moreover, recent zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance on prebuilt ontologies often suffer from instability across multiple runs, as well as incomplete coverage of key facts. To address these challenges, we introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that builds and continuously updates Temporal Knowledge Graphs (TKGs) from unstructured texts. ATOM splits input documents into minimal, self-contained \"atomic\" facts, improving extraction exhaustivity and stability. Then, it constructs atomic TKGs from these facts while employing a dual-time modeling that distinguishes when information is observed from when it is valid. The resulting atomic TKGs are subsequently merged in parallel. Empirical evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17% better stability, and over 90% latency reduction compared to baseline methods, demonstrating a strong scalability potential for dynamic TKG construction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ATOM (AdapTive and OptiMized)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäº LLMs çš„ few-shot ä¸”å…·æœ‰å¯æ‰©å±•æ€§çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æ„å»ºå¹¶åŠ¨æ€æ›´æ–°æ—¶åºçŸ¥è¯†å›¾è°± (Temporal Knowledge Graphs)ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰åŠ¨æ€å˜åŒ–ä»¥åŠç°æœ‰ zero-shot æ–¹æ³•åœ¨è¯¦å°½æ€§å’Œç¨³å®šæ€§ä¸Šçš„ä¸è¶³ï¼ŒATOM å°†è¾“å…¥æ–‡æ¡£æ‹†åˆ†ä¸ºæœ€å°ä¸”è‡ªæ´½çš„ \"atomic\" äº‹å®ï¼Œä»è€Œç¡®ä¿ä¿¡æ¯æå–çš„å®Œæ•´æ€§ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†åŒé‡æ—¶é—´å»ºæ¨¡ (dual-time modeling) æœºåˆ¶æ¥åŒºåˆ†ä¿¡æ¯çš„è§‚å¯Ÿæ—¶é—´ä¸æœ‰æ•ˆæ—¶é—´ï¼Œå¹¶åˆ©ç”¨å¹¶è¡ŒæŠ€æœ¯é«˜æ•ˆåˆå¹¶ç”Ÿæˆçš„åŸå­çº§ TKGsã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒATOM åœ¨æå–è¯¦å°½æ€§ä¸Šæå‡äº†çº¦ 18%ï¼Œç¨³å®šæ€§å¢å¼ºäº† 17%ï¼Œå¹¶å®ç°äº†è¶…è¿‡ 90% çš„å»¶è¿Ÿç¼©å‡ã€‚è¿™è¡¨æ˜ ATOM ä¸ºå¤„ç†å¤§è§„æ¨¡åŠ¨æ€æ•°æ®æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯é çš„ TKG æ„å»ºæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22590v1",
      "published_date": "2025-10-26 09:10:26 UTC",
      "updated_date": "2025-10-26 09:10:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:11.740173+00:00"
    },
    {
      "arxiv_id": "2510.25775v1",
      "title": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP",
      "title_zh": "æ¢ç´¢åŸºäº SHAP çš„å›½é™…è±¡æ£‹å±€é¢é€å­è§£é‡Šæ–¹æ³•",
      "authors": [
        "Francesco Spinnato"
      ],
      "abstract": "Contemporary chess engines offer precise yet opaque evaluations, typically expressed as centipawn scores. While effective for decision-making, these outputs obscure the underlying contributions of individual pieces or patterns. In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the domain of chess analysis, aiming to attribute a chess engines evaluation to specific pieces on the board. By treating pieces as features and systematically ablating them, we compute additive, per-piece contributions that explain the engines output in a locally faithful and human-interpretable manner. This method draws inspiration from classical chess pedagogy, where players assess positions by mentally removing pieces, and grounds it in modern explainable AI techniques. Our approach opens new possibilities for visualization, human training, and engine comparison. We release accompanying code and data to foster future research in interpretable chess AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°† SHAP (SHapley Additive exPlanations) ç®—æ³•åº”ç”¨äºå›½é™…è±¡æ£‹åˆ†æï¼Œæ—¨åœ¨å°†å›½é™…è±¡æ£‹å¼•æ“ (chess engines) è¾“å‡ºçš„ä¸é€æ˜è¯„ä¼°å€¼å½’å› ä¸ºæ£‹ç›˜ä¸Šçš„ç‰¹å®šæ£‹å­ã€‚ç›®å‰çš„å¼•æ“è¯„ä¼°é€šå¸¸ä»¥ centipawn scores è¡¨ç¤ºï¼Œè™½ç²¾ç¡®ä½†æ©ç›–äº†å•ä¸ªæ£‹å­çš„è´¡çŒ®ï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†æ£‹å­è§†ä¸ºç‰¹å¾å¹¶è¿›è¡Œç³»ç»Ÿæ€§æ¶ˆè (ablating)ï¼Œè®¡ç®—å‡ºæ¯ä¸ªæ£‹å­çš„åŠ æ€§è´¡çŒ®ï¼Œä»è€Œä»¥å±€éƒ¨å¿ å®ä¸”äººç±»å¯ç†è§£çš„æ–¹å¼è§£é‡Šå¼•æ“è¾“å‡ºã€‚è¿™ç§æ–¹æ³•å€Ÿé‰´äº†ä¼ ç»Ÿå›½é™…è±¡æ£‹æ•™å­¦ä¸­é€šè¿‡å¿ƒç†ç§»é™¤æ£‹å­æ¥è¯„ä¼°å±€åŠ¿çš„æ€è·¯ï¼Œå¹¶å°†å…¶ä¸ç°ä»£çš„å¯è§£é‡Šäººå·¥æ™ºèƒ½ (explainable AI) æŠ€æœ¯ç›¸ç»“åˆã€‚è¯¥ç ”ç©¶ä¸ºæ£‹å±€å¯è§†åŒ–ã€äººç±»æ£‹æ‰‹è®­ç»ƒä»¥åŠå¼•æ“é—´çš„å¯¹æ¯”æä¾›äº†æ–°é€”å¾„ï¼Œå¹¶å‘å¸ƒäº†é…å¥—ä»£ç å’Œæ•°æ®ä»¥ä¿ƒè¿›å¯è§£é‡Šå›½é™…è±¡æ£‹äººå·¥æ™ºèƒ½ (interpretable chess AI) çš„åç»­ç ”ç©¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.25775v1",
      "published_date": "2025-10-26 09:07:21 UTC",
      "updated_date": "2025-10-26 09:07:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:13.932437+00:00"
    },
    {
      "arxiv_id": "2510.22572v1",
      "title": "Combining Deep Learning and Explainable AI for Toxicity Prediction of Chemical Compounds",
      "title_zh": "ç»“åˆæ·±åº¦å­¦ä¹ ä¸å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŒ–åˆç‰©æ¯’æ€§é¢„æµ‹",
      "authors": [
        "Eduard Popescu",
        "Adrian Groza",
        "Andreea Cernat"
      ],
      "abstract": "The task here is to predict the toxicological activity of chemical compounds based on the Tox21 dataset, a benchmark in computational toxicology.\n  After a domain-specific overview of chemical toxicity, we discuss current computational strategies, focusing on machine learning and deep learning. Several architectures are compared in terms of performance, robustness, and interpretability.\n  This research introduces a novel image-based pipeline based on DenseNet121, which processes 2D graphical representations of chemical structures. Additionally, we employ Grad-CAM visualizations, an explainable AI technique, to interpret the model's predictions and highlight molecular regions contributing to toxicity classification. The proposed architecture achieves competitive results compared to traditional models, demonstrating the potential of deep convolutional networks in cheminformatics. Our findings emphasize the value of combining image-based representations with explainable AI methods to improve both predictive accuracy and model transparency in toxicology.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨åˆ©ç”¨ Tox21 æ•°æ®é›†é¢„æµ‹åŒ–åˆç‰©çš„æ¯’ç†æ´»æ€§ï¼Œè¿™æ˜¯è®¡ç®—æ¯’ç†å­¦é¢†åŸŸçš„ä¸€ä¸ªåŸºå‡†ä»»åŠ¡ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº DenseNet121 çš„æ–°å‹å›¾åƒå¤„ç†æµç¨‹ï¼Œé€šè¿‡å¤„ç†åŒ–å­¦ç»“æ„çš„ 2D å›¾å½¢è¡¨ç¤ºæ¥è¿›è¡Œé¢„æµ‹ã€‚ä¸ºäº†æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œç ”ç©¶å¼•å…¥äº† Grad-CAM å¯è§†åŒ–æŠ€æœ¯ï¼Œç”¨äºè¯†åˆ«å’Œé«˜äº®å¯¹æ¯’æ€§åˆ†ç±»èµ·å…³é”®ä½œç”¨çš„åˆ†å­åŒºåŸŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¶æ„ä¸ä¼ ç»Ÿæ¨¡å‹ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†æ·±åº¦å·ç§¯ç½‘ç»œåœ¨ cheminformatics é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚è¯¥ç ”ç©¶æœ€åå¼ºè°ƒäº†å°†å›¾åƒè¡¨å¾ä¸ Explainable AI æ–¹æ³•ç›¸ç»“åˆçš„ä»·å€¼ï¼Œèƒ½å¤ŸåŒæ—¶æå‡æ¯’ç†å­¦é¢„æµ‹çš„å‡†ç¡®æ€§ä¸æ¨¡å‹é€æ˜åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22572v1",
      "published_date": "2025-10-26 08:05:11 UTC",
      "updated_date": "2025-10-26 08:05:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:18.779080+00:00"
    },
    {
      "arxiv_id": "2510.22571v1",
      "title": "STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models",
      "title_zh": "STATUS Benchï¼šè¯„ä¼°è§†è§‰è¯­è¨€æ¨¡å‹ç‰©ä½“çŠ¶æ€ç†è§£èƒ½åŠ›çš„ä¸¥è°¨åŸºå‡†",
      "authors": [
        "Mahiro Ukai",
        "Shuhei Kurita",
        "Nakamasa Inoue"
      ],
      "abstract": "Object state recognition aims to identify the specific condition of objects, such as their positional states (e.g., open or closed) and functional states (e.g., on or off). While recent Vision-Language Models (VLMs) are capable of performing a variety of multimodal tasks, it remains unclear how precisely they can identify object states. To alleviate this issue, we introduce the STAte and Transition UnderStanding Benchmark (STATUS Bench), the first benchmark for rigorously evaluating the ability of VLMs to understand subtle variations in object states in diverse situations. Specifically, STATUS Bench introduces a novel evaluation scheme that requires VLMs to perform three tasks simultaneously: object state identification (OSI), image retrieval (IR), and state change identification (SCI). These tasks are defined over our fully hand-crafted dataset involving image pairs, their corresponding object state descriptions and state change descriptions. Furthermore, we introduce a large-scale training dataset, namely STATUS Train, which consists of 13 million semi-automatically created descriptions. This dataset serves as the largest resource to facilitate further research in this area. In our experiments, we demonstrate that STATUS Bench enables rigorous consistency evaluation and reveal that current state-of-the-art VLMs still significantly struggle to capture subtle object state distinctions. Surprisingly, under the proposed rigorous evaluation scheme, most open-weight VLMs exhibited chance-level zero-shot performance. After fine-tuning on STATUS Train, Qwen2.5-VL achieved performance comparable to Gemini 2.0 Flash. These findings underscore the necessity of STATUS Bench and Train for advancing object state recognition in VLM research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨ç‰©ä½“çŠ¶æ€ï¼ˆå¦‚ä½ç½®æˆ–åŠŸèƒ½çŠ¶æ€ï¼‰è¯†åˆ«ç²¾åº¦ä¸æ˜çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä¸¥æ ¼çš„è¯„ä¼°åŸºå‡†STATUS Bench (STAte and Transition UnderStanding Benchmark)ã€‚è¯¥åŸºå‡†é‡‡ç”¨äº†ä¸€ç§å…¨æ–°çš„è¯„ä¼°æ–¹æ¡ˆï¼Œè¦æ±‚æ¨¡å‹åŒæ—¶æ‰§è¡Œç‰©ä½“çŠ¶æ€è¯†åˆ«(OSI)ã€å›¾åƒæ£€ç´¢(IR)å’ŒçŠ¶æ€å˜åŒ–è¯†åˆ«(SCI)ä¸‰é¡¹ä»»åŠ¡ï¼Œå¹¶é…å¥—æä¾›äº†åŒ…å«1300ä¸‡æ¡æè¿°çš„å¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†STATUS Trainã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰çš„é¡¶çº§VLMsåœ¨æ•æ‰ç‰©ä½“çŠ¶æ€çš„ç»†å¾®å·®åˆ«æ–¹é¢ä»è¡¨ç°æ¬ ç¼ºï¼Œå¤šæ•°å¼€æºæ¨¡å‹åœ¨é›¶æ ·æœ¬(zero-shot)è®¾ç½®ä¸‹ä»…è¾¾åˆ°éšæœºæ°´å¹³ã€‚åœ¨STATUS Trainä¸Šå¾®è°ƒåçš„Qwen2.5-VLå–å¾—äº†ä¸Gemini 2.0 Flashç›¸å½“çš„æ€§èƒ½ï¼Œå‡¸æ˜¾äº†è¯¥åŸºå‡†å’Œæ•°æ®é›†åœ¨æ¨åŠ¨ç‰©ä½“çŠ¶æ€ç†è§£ç ”ç©¶ä¸­çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22571v1",
      "published_date": "2025-10-26 08:04:28 UTC",
      "updated_date": "2025-10-26 08:04:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:25.296040+00:00"
    },
    {
      "arxiv_id": "2510.22570v1",
      "title": "Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing",
      "title_zh": "é¢å‘å¯æ‰©å±•å¤šæ— äººæœºç«é€Ÿçš„åŸºäºè¯¾ç¨‹çš„è¿­ä»£è‡ªåšå¼ˆ",
      "authors": [
        "Onur AkgÃ¼n"
      ],
      "abstract": "The coordination of multiple autonomous agents in high-speed, competitive environments represents a significant engineering challenge. This paper presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing), a reinforcement learning framework designed to solve this challenge in the demanding domain of multi-drone racing. CRUISE overcomes key scalability limitations by synergistically combining a progressive difficulty curriculum with an efficient self-play mechanism to foster robust competitive behaviors. Validated in high-fidelity simulation with realistic quadrotor dynamics, the resulting policies significantly outperform both a standard reinforcement learning baseline and a state-of-the-art game-theoretic planner. CRUISE achieves nearly double the planner's mean racing speed, maintains high success rates, and demonstrates robust scalability as agent density increases. Ablation studies confirm that the curriculum structure is the critical component for this performance leap. By providing a scalable and effective training methodology, CRUISE advances the development of autonomous systems for dynamic, competitive tasks and serves as a blueprint for future real-world deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CRUISEï¼ˆCurriculum-Based Iterative Self-Play for Scalable Multi-Drone Racingï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³é«˜é€Ÿç«äº‰ç¯å¢ƒä¸‹å¤šæ— äººæœºç«é€Ÿåè°ƒæŒ‘æˆ˜çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰æ¡†æ¶ã€‚CRUISEé€šè¿‡å°†æ¸è¿›å¼éš¾åº¦è¯¾ç¨‹ï¼ˆProgressive Difficulty Curriculumï¼‰ä¸é«˜æ•ˆçš„è‡ªæˆ‘åšå¼ˆï¼ˆSelf-Playï¼‰æœºåˆ¶ç›¸ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¯æ‰©å±•æ€§æ–¹é¢çš„é™åˆ¶ï¼Œä»è€ŒåŸ¹å…»å‡ºç¨³å¥çš„ç«äº‰è¡Œä¸ºã€‚è¯¥æ¡†æ¶åœ¨å…·æœ‰çœŸå®å››æ—‹ç¿¼åŠ¨åŠ›å­¦çš„é«˜ä¿çœŸæ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œäº†éªŒè¯ï¼Œå…¶ç”Ÿæˆçš„ç­–ç•¥æ˜¾è‘—ä¼˜äºæ ‡å‡†å¼ºåŒ–å­¦ä¹ åŸºå‡†å’Œæœ€å…ˆè¿›çš„åšå¼ˆè®ºè§„åˆ’å™¨ï¼ˆGame-Theoretic Plannerï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCRUISEå®ç°äº†è¿‘ä¸¤å€äºè§„åˆ’å™¨çš„å¹³å‡ç«é€Ÿé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æˆåŠŸç‡ï¼Œå¹¶åœ¨ä»£ç†å¯†åº¦å¢åŠ æ—¶å±•ç°å‡ºå¼ºå¤§çš„å¯æ‰©å±•æ€§ã€‚æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰è¿›ä¸€æ­¥è¯å®ï¼Œè¯¾ç¨‹å­¦ä¹ ç»“æ„ï¼ˆCurriculum Structureï¼‰æ˜¯å®ç°è¿™ç§æ€§èƒ½é£è·ƒçš„å…³é”®ç»„ä»¶ã€‚è¯¥ç ”ç©¶ä¸ºåŠ¨æ€ç«äº‰ä»»åŠ¡ä¸­çš„è‡ªä¸»ç³»ç»Ÿå¼€å‘æä¾›äº†æœ‰æ•ˆçš„è®­ç»ƒæ–¹æ³•ï¼Œå¹¶ä¸ºæœªæ¥çš„å®é™…éƒ¨ç½²æä¾›äº†è“å›¾ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, 5 figures. This paper is currently under review at the journal Engineering Applications of Artificial Intelligence. Supplementary video: https://drive.google.com/file/d/1k7necen2DgIxaYT2alKK8-b20sE_AyDA/view Source code and models: https://doi.org/10.5281/zenodo.17256943",
      "pdf_url": "https://arxiv.org/pdf/2510.22570v1",
      "published_date": "2025-10-26 08:03:06 UTC",
      "updated_date": "2025-10-26 08:03:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:34.340510+00:00"
    },
    {
      "arxiv_id": "2510.23660v1",
      "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm",
      "title_zh": "é‡å­å·ç§¯ç¥ç»ç½‘ç»œç”¨äºè‚ºç‚æ£€æµ‹ï¼šä¸€ç§é«˜æ•ˆçš„é‡å­è¾…åŠ©ç‰¹å¾æå–èŒƒå¼",
      "authors": [
        "Gazi Tanbhir",
        "Md. Farhan Shahriyar",
        "Abdullah Md Raihan Chy"
      ],
      "abstract": "Pneumonia poses a significant global health challenge, demanding accurate and timely diagnosis. While deep learning, particularly Convolutional Neural Networks (CNNs), has shown promise in medical image analysis for pneumonia detection, CNNs often suffer from high computational costs, limitations in feature representation, and challenges in generalizing from smaller datasets. To address these limitations, we explore the application of Quanvolutional Neural Networks (QNNs), leveraging quantum computing for enhanced feature extraction. This paper introduces a novel hybrid quantum-classical model for pneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a quanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2 image patches, employing rotational Y-gates for data encoding and entangling layers to generate non-classical feature representations. These quantum-extracted features are then fed into a classical neural network for classification. Experimental results demonstrate that the proposed QNN achieves a higher validation accuracy of 83.33 percent compared to a comparable classical CNN which achieves 73.33 percent. This enhanced convergence and sample efficiency highlight the potential of QNNs for medical image analysis, particularly in scenarios with limited labeled data. This research lays the foundation for integrating quantum computing into deep-learning-driven medical diagnostic systems, offering a computationally efficient alternative to traditional approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‚ºç‚æ£€æµ‹ä¸­å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)å­˜åœ¨çš„è®¡ç®—æˆæœ¬é«˜ã€ç‰¹å¾è¡¨è¾¾å—é™ä»¥åŠåœ¨å°æ•°æ®é›†ä¸Šæ³›åŒ–å›°éš¾ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„é‡å­è¾…åŠ©ç‰¹å¾æå–èŒƒå¼ã€‚ä½œè€…æ¢ç´¢äº†é‡å­å·ç§¯ç¥ç»ç½‘ç»œ(Quanvolutional Neural Networks, QNNs)çš„åº”ç”¨ï¼Œå¹¶é’ˆå¯¹PneumoniaMNISTæ•°æ®é›†è®¾è®¡äº†ä¸€ç§æ–°å‹çš„æ··åˆé‡å­-ç»å…¸æ¨¡å‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¸¦æœ‰å‚æ•°åŒ–é‡å­çº¿è·¯(PQC)çš„é‡å­å·ç§¯å±‚å¤„ç†2x2å›¾åƒå—ï¼Œé€šè¿‡æ—‹è½¬Yé—¨(rotational Y-gates)è¿›è¡Œæ•°æ®ç¼–ç ï¼Œå¹¶ç»“åˆçº ç¼ å±‚(entangling layers)ç”Ÿæˆéç»å…¸ç‰¹å¾è¡¨ç¤ºï¼Œéšåå°†ç‰¹å¾è¾“å…¥ç»å…¸ç¥ç»ç½‘ç»œè¿›è¡Œåˆ†ç±»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„QNNéªŒè¯å‡†ç¡®ç‡è¾¾åˆ°83.33%ï¼Œæ˜¾è‘—ä¼˜äºåŒç±»ç»å…¸CNNçš„73.33%ã€‚ç ”ç©¶è¯æ˜äº†QNNåœ¨æ”¶æ•›é€Ÿåº¦å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå°¤å…¶é€‚ç”¨äºæ ‡è®°æ•°æ®æœ‰é™çš„åŒ»å­¦å›¾åƒåˆ†æåœºæ™¯ï¼Œä¸ºå°†é‡å­è®¡ç®—é›†æˆåˆ°åŒ»ç–—è¯Šæ–­ç³»ç»Ÿæä¾›äº†é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23660v1",
      "published_date": "2025-10-26 08:01:34 UTC",
      "updated_date": "2025-10-26 08:01:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:28.639705+00:00"
    },
    {
      "arxiv_id": "2510.22568v1",
      "title": "SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions",
      "title_zh": "SPIRALï¼šç”¨äºå¤šæ— äººæœºç«èµ›å­¦ä¹ çš„è‡ªåšå¼ˆå¢é‡å¼ç«é€Ÿç®—æ³•",
      "authors": [
        "Onur AkgÃ¼n"
      ],
      "abstract": "This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for Learning), a novel approach for training autonomous drones in multi-agent racing competitions. SPIRAL distinctively employs a self-play mechanism to incrementally cultivate complex racing behaviors within a challenging, dynamic environment. Through this self-play core, drones continuously compete against increasingly proficient versions of themselves, naturally escalating the difficulty of competitive interactions. This progressive learning journey guides agents from mastering fundamental flight control to executing sophisticated cooperative multi-drone racing strategies. Our method is designed for versatility, allowing integration with any state-of-the-art Deep Reinforcement Learning (DRL) algorithms within its self-play framework. Simulations demonstrate the significant advantages of SPIRAL and benchmark the performance of various DRL algorithms operating within it. Consequently, we contribute a versatile, scalable, and self-improving learning framework to the field of autonomous drone racing. SPIRAL's capacity to autonomously generate appropriate and escalating challenges through its self-play dynamic offers a promising direction for developing robust and adaptive racing strategies in multi-agent environments. This research opens new avenues for enhancing the performance and reliability of autonomous racing drones in increasingly complex and competitive scenarios.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº† SPIRAL (Self-Play Incremental Racing Algorithm for Learning)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¤šæ— äººæœºç«æŠ€æ¯”èµ›ä¸­è®­ç»ƒè‡ªä¸»æ— äººæœºçš„æ–°å‹æ–¹æ³•ã€‚è¯¥ç®—æ³•æ ¸å¿ƒé‡‡ç”¨äº† Self-Play æœºåˆ¶ï¼Œä½¿æ— äººæœºé€šè¿‡ä¸æ–­ä¸è‡ªèº«æ€§èƒ½æ›´å¼ºçš„ç‰ˆæœ¬è¿›è¡Œå¯¹æŠ—ï¼Œåœ¨åŠ¨æ€ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¯å¢ƒä¸­å¢é‡å¼åœ°å­¦ä¹ å¤æ‚çš„ç«é€Ÿè¡Œä¸ºã€‚è¿™ç§å­¦ä¹ èŒƒå¼å¼•å¯¼æ™ºèƒ½ä½“ä»åŸºç¡€çš„ Flight Control é€æ­¥è¿‡æ¸¡åˆ°æŒæ¡ç²¾ç»†çš„å¤šæ— äººæœºååŒç«é€Ÿç­–ç•¥ã€‚SPIRAL å…·æœ‰æé«˜çš„çµæ´»æ€§ï¼Œèƒ½å¤Ÿä¸å„ç§å‰æ²¿çš„ Deep Reinforcement Learning (DRL) ç®—æ³•æ— ç¼é›†æˆã€‚ä»¿çœŸå®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šçš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶ä¸ºä¸åŒ DRL ç®—æ³•åœ¨è‡ªé€‚åº”ç«é€Ÿä¸­çš„è¡¨ç°æä¾›äº†åŸºå‡†ã€‚SPIRAL é€šè¿‡è‡ªä¸»ç”Ÿæˆçš„é€’è¿›å¼æŒ‘æˆ˜ï¼Œä¸ºå¼€å‘åœ¨å¤æ‚ç«äº‰ç¯å¢ƒä¸­å…·å¤‡é«˜é²æ£’æ€§å’Œè‡ªæ”¹å–„èƒ½åŠ›çš„æ— äººæœºç«é€Ÿç­–ç•¥æä¾›äº†æ–°æ–¹å‘ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„æ€§èƒ½ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
      "pdf_url": "https://arxiv.org/pdf/2510.22568v1",
      "published_date": "2025-10-26 07:59:44 UTC",
      "updated_date": "2025-10-26 07:59:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:51.141111+00:00"
    },
    {
      "arxiv_id": "2510.22561v1",
      "title": "Blockchain Signatures to Ensure Information Integrity and Non-Repudiation in the Digital Era: A comprehensive study",
      "title_zh": "æ•°å­—æ—¶ä»£ä¿éšœä¿¡æ¯å®Œæ•´æ€§ä¸ä¸å¯å¦è®¤æ€§çš„åŒºå—é“¾ç­¾åï¼šä¸€é¡¹ç»¼åˆç ”ç©¶",
      "authors": [
        "Kaveri Banerjee",
        "Sajal Saha"
      ],
      "abstract": "Blockchain systems rely on decentralized ledgers and strong security guarantees. A key requirement is non-repudiation, which prevents denial of transaction authorship and supports integrity of recorded data. This work surveys digital signature schemes used in blockchain platforms and analyzes how they deliver non-repudiation and contribute to overall system security. We examine representative scheme families and their cryptographic foundations, security assumptions, and properties relevant to deployment, including unforgeability, resistance to malleability, support for aggregation and multisignature or threshold settings, key and signature sizes, and verification cost. Using these criteria, we compare the suitability of different designs for consensus protocols, smart contract constraints, and resource limits. We highlight practical tradeoffs that affect throughput, storage, scalability, and attack surfaces, and summarize benefits and limitations of each scheme in blockchain contexts. The study underscores that carefully chosen digital signatures are central to achieving non-repudiation and preserving information integrity, and it outlines implementation considerations and open directions such as interoperability and post-quantum readiness.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å…¨é¢ç»¼è¿°äº†åŒºå—é“¾å¹³å°ä¸­ä½¿ç”¨çš„æ•°å­—ç­¾åæ–¹æ¡ˆ (digital signature schemes)ï¼Œæ¢è®¨äº†å…¶åœ¨ç¡®ä¿ä¸å¯å¦è®¤æ€§ (non-repudiation) å’Œä¿¡æ¯å®Œæ•´æ€§ (information integrity) æ–¹é¢çš„æ ¸å¿ƒä½œç”¨ã€‚ä½œè€…åˆ†æäº†ä»£è¡¨æ€§æ–¹æ¡ˆçš„å¯†ç å­¦åŸºç¡€ä¸å®‰å…¨å‡è®¾ï¼Œå¹¶ä¾æ®ä¸å¯ä¼ªé€ æ€§ (unforgeability)ã€æŠ—å»¶å±•æ€§ (resistance to malleability) åŠå¯¹èšåˆç­¾å (aggregation) ä¸å¤šé‡ç­¾å (multisignature/threshold) çš„æ”¯æŒç­‰å±æ€§å»ºç«‹äº†è¯„ä¼°æ ‡å‡†ã€‚é€šè¿‡å¯¹æ¯”ï¼Œç ”ç©¶æ­ç¤ºäº†ä¸åŒè®¾è®¡åœ¨å…±è¯†åè®® (consensus protocols)ã€æ™ºèƒ½åˆçº¦ (smart contract) çº¦æŸå’Œèµ„æºå—é™ç¯å¢ƒä¸‹çš„é€‚ç”¨å·®å¼‚ã€‚æ–‡ç« è¿›ä¸€æ­¥è®¨è®ºäº†å½±å“ååé‡ (throughput)ã€å­˜å‚¨æˆæœ¬å’Œå¯æ‰©å±•æ€§ (scalability) çš„å®é™…æƒè¡¡ï¼Œå¹¶è¯†åˆ«äº†ä¸åŒæ–¹æ¡ˆåœ¨åŒºå—é“¾ä¸Šä¸‹æ–‡ä¸­çš„æ”»å‡»é¢ (attack surfaces)ã€‚æœ€åï¼Œè¯¥ç ”ç©¶æ€»ç»“äº†ç°æœ‰æ–¹æ¡ˆçš„ä¼˜åŠ£ï¼Œå¹¶å¯¹äº’æ“ä½œæ€§ (interoperability) å’ŒæŠ—é‡å­å‡†å¤‡ (post-quantum readiness) ç­‰æœªæ¥å…³é”®ç ”ç©¶æ–¹å‘æå‡ºäº†å±•æœ›ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 Pages, 2 Figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22561v1",
      "published_date": "2025-10-26 07:39:55 UTC",
      "updated_date": "2025-10-26 07:39:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:51.935977+00:00"
    },
    {
      "arxiv_id": "2510.22553v1",
      "title": "DDTR: Diffusion Denoising Trace Recovery",
      "title_zh": "DDTRï¼šæ‰©æ•£å»å™ªè½¨è¿¹æ¢å¤",
      "authors": [
        "Maximilian Matyash",
        "Avigdor Gal",
        "Arik Senderovich"
      ],
      "abstract": "With recent technological advances, process logs, which were traditionally deterministic in nature, are being captured from non-deterministic sources, such as uncertain sensors or machine learning models (that predict activities using cameras). In the presence of stochastically-known logs, logs that contain probabilistic information, the need for stochastic trace recovery increases, to offer reliable means of understanding the processes that govern such systems. We design a novel deep learning approach for stochastic trace recovery, based on Diffusion Denoising Probabilistic Models (DDPM), which makes use of process knowledge (either implicitly by discovering a model or explicitly by injecting process knowledge in the training phase) to recover traces by denoising. We conduct an empirical evaluation demonstrating state-of-the-art performance with up to a 25% improvement over existing methods, along with increased robustness under high noise levels.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”±ä¼ æ„Ÿå™¨æˆ–æœºå™¨å­¦ä¹ æ¨¡å‹ç­‰éç¡®å®šæ€§æ¥æºäº§ç”Ÿçš„éšæœºè¿‡ç¨‹æ—¥å¿—ï¼Œæå‡ºäº†åä¸º DDTR: Diffusion Denoising Trace Recovery çš„æ–°å‹æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚ä¸ºäº†è§£å†³éšæœºæ—¥å¿—ä¸­æ¦‚ç‡ä¿¡æ¯å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•åŸºäº Diffusion Denoising Probabilistic Models (DDPM) æ¡†æ¶ï¼Œé€šè¿‡éšå¼å‘ç°æˆ–æ˜¾å¼æ³¨å…¥çš„è¿‡ç¨‹çŸ¥è¯†å®ç°è½¨è¿¹å»å™ªæ¢å¤ã€‚DDTR èƒ½å¤Ÿæœ‰æ•ˆä»ä¸ç¡®å®šçš„è§‚æµ‹æ•°æ®ä¸­æå–å‡†ç¡®çš„è¿‡ç¨‹è½¨è¿¹ï¼Œä¸ºç†è§£éšæœºç³»ç»Ÿæä¾›äº†å¯é çš„åˆ†ææ‰‹æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDDTR åœ¨æ€§èƒ½ä¸Šæ¯”ç°æœ‰æ–¹æ³•æå‡äº†å¤šè¾¾ 25%ï¼Œè¾¾åˆ°äº† state-of-the-art æ°´å¹³ï¼Œå¹¶åœ¨é«˜å™ªå£°ç¯å¢ƒä¸‹è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22553v1",
      "published_date": "2025-10-26 06:43:53 UTC",
      "updated_date": "2025-10-26 06:43:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:46:52.434517+00:00"
    },
    {
      "arxiv_id": "2510.22548v1",
      "title": "LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?",
      "title_zh": "LooGLE v2ï¼šå¤§è¯­è¨€æ¨¡å‹æ˜¯å¦å·²å‡†å¤‡å¥½åº”å¯¹çœŸå®åœºæ™¯ä¸‹çš„é•¿ç¨‹ä¾èµ–æŒ‘æˆ˜ï¼Ÿ",
      "authors": [
        "Ziyuan He",
        "Yuxuan Wang",
        "Jiaqi Li",
        "Kexin Liang",
        "Muhan Zhang"
      ],
      "abstract": "Large language models (LLMs) are equipped with increasingly extended context windows recently, yet their long context understanding capabilities over long dependency tasks remain fundamentally limited and underexplored. This gap is especially significant in many real-world long-context applications that were rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark designed to evaluate LLMs' long context ability in real-world applications and scenarios. Our benchmark consists of automatically collected real-world long texts, ranging from 16k to 2M tokens, encompassing domains in law, finance, game and code. Accordingly, we delicately design 10 types of domain-specific long-dependency tasks and generate 1,934 QA instances with various diversity and complexity in a scalable data curation pipeline for further practical needs. We conduct a comprehensive assessment of 6 locally deployed and 4 API-based LLMs. The evaluation results show that even the best-performing model achieves only a 59.2% overall score on our benchmark. Despite the extensive context windows, popular LLMs are only capable of understanding a much shorter length of context than they claim to be, revealing significant limitations in their ability to handle real-world tasks with long dependencies and highlighting substantial room for model improvement in practical long-context understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†LooGLE v2ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ³•å¾‹ã€é‡‘èã€æ¸¸æˆå’Œä»£ç ç­‰ç°å®åº”ç”¨åœºæ™¯ä¸­é•¿ç¨‹ä¾èµ–(long dependency)èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è‡ªåŠ¨åŒ–æµç¨‹æ”¶é›†äº†é•¿åº¦ä»16kåˆ°2M tokensçš„çœŸå®æ–‡æœ¬ï¼Œå¹¶é’ˆå¯¹æ€§åœ°è®¾è®¡äº†10ç§é¢†åŸŸç‰¹å®šçš„ä»»åŠ¡ç±»å‹ï¼Œå…±åŒ…å«1,934ä¸ªå…·æœ‰é«˜åº¦å¤šæ ·æ€§å’Œå¤æ‚æ€§çš„é—®ç­”(QA)å®ä¾‹ã€‚é€šè¿‡å¯¹10æ¬¾ä¸»æµæœ¬åœ°åŒ–åŠAPIæ¨¡å‹çš„è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºè¡¨ç°æœ€ä½³çš„æ¨¡å‹ç»¼åˆå¾—åˆ†ä»…ä¸º59.2%ã€‚å®éªŒè¡¨æ˜ï¼Œæµè¡ŒLLMså¤„ç†çœŸå®é•¿ä¾èµ–ä»»åŠ¡çš„å®é™…èƒ½åŠ›è¿œä½äºå…¶å®£ç§°çš„ä¸Šä¸‹æ–‡çª—å£(context windows)é•¿åº¦ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç†è§£æ–¹é¢çš„æ˜¾è‘—å±€é™ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥å¤§æ¨¡å‹åœ¨å¤æ‚é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹çš„ä¼˜åŒ–æä¾›äº†é‡è¦çš„è¯„ä¼°æ¡†æ¶ä¸æ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025 Datasets and Benchmarks Track",
      "pdf_url": "https://arxiv.org/pdf/2510.22548v1",
      "published_date": "2025-10-26 06:14:19 UTC",
      "updated_date": "2025-10-26 06:14:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:04.334283+00:00"
    },
    {
      "arxiv_id": "2510.22535v2",
      "title": "OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models",
      "title_zh": "OFFSIDEï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è™šå‡ä¿¡æ¯æœºå™¨é—å¿˜è¯„æµ‹åŸºå‡†",
      "authors": [
        "Hao Zheng",
        "Zirui Pang",
        "Ling li",
        "Zhijie Deng",
        "Yuhan Pu",
        "Zhaowei Zhu",
        "Xiaobo Xia",
        "Jiaheng Wei"
      ],
      "abstract": "Advances in Multimodal Large Language Models (MLLMs) intensify concerns about data privacy, making Machine Unlearning (MU), the selective removal of learned information, a critical necessity. However, existing MU benchmarks for MLLMs are limited by a lack of image diversity, potential inaccuracies, and insufficient evaluation scenarios, which fail to capture the complexity of real-world applications. To facilitate the development of MLLMs unlearning and alleviate the aforementioned limitations, we introduce OFFSIDE, a novel benchmark for evaluating misinformation unlearning in MLLMs based on football transfer rumors. This manually curated dataset contains 15.68K records for 80 players, providing a comprehensive framework with four test sets to assess forgetting efficacy, generalization, utility, and robustness. OFFSIDE supports advanced settings like selective unlearning and corrective relearning, and crucially, unimodal unlearning (forgetting only text data). Our extensive evaluation of multiple baselines reveals key findings: (1) Unimodal methods (erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning efficacy is largely driven by catastrophic forgetting; (3) All methods struggle with \"visual rumors\" (rumors appear in the image); (4) The unlearned rumors can be easily recovered and (5) All methods are vulnerable to prompt attacks. These results expose significant vulnerabilities in current approaches, highlighting the need for more robust multimodal unlearning solutions. The code is available at https://github.com/zh121800/OFFSIDE",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OFFSIDEï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal Large Language Models, MLLMs) é”™è¯¯ä¿¡æ¯é—å¿˜æ•ˆæœçš„æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨é—å¿˜ (Machine Unlearning, MU) åŸºå‡†åœ¨å›¾åƒå¤šæ ·æ€§å’Œè¯„ä¼°åœºæ™¯æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥åŸºå‡†é‡‡ç”¨æ‰‹åŠ¨æ•´ç†çš„è¶³çƒè½¬ä¼šè°£è¨€æ•°æ®é›†ï¼ŒåŒ…å« 80 åçƒå‘˜çš„ 15.68K æ¡è®°å½•ï¼Œæ„å»ºäº†æ¶µç›–é—å¿˜æ•ˆæœã€æ³›åŒ–æ€§ã€å®ç”¨æ€§å’Œé²æ£’æ€§çš„å››é¡¹æµ‹è¯•æ¡†æ¶ã€‚OFFSIDE æ”¯æŒé€‰æ‹©æ€§é—å¿˜ (selective unlearning)ã€çº æ­£æ€§é‡æ–°å­¦ä¹  (corrective relearning) åŠå•æ¨¡æ€é—å¿˜ç­‰è¿›é˜¶å®éªŒè®¾ç½®ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œå•æ¨¡æ€æ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€è°£è¨€æ—¶å¤±æ•ˆï¼Œä¸”ç°æœ‰çš„é—å¿˜æ•ˆæœå¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ç”±ç¾éš¾æ€§é—å¿˜ (catastrophic forgetting) é©±åŠ¨çš„ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ï¼Œæ‰€æœ‰åŸºå‡†æ–¹æ³•åœ¨åº”å¯¹å›¾åƒä¸­çš„è§†è§‰è°£è¨€ (visual rumors) æ—¶å‡è¡¨ç°ä¸ä½³ï¼Œä¸”å·²é—å¿˜çš„ä¿¡æ¯ææ˜“è¢«æ¢å¤æˆ–å—åˆ°æç¤ºæ”»å‡» (prompt attacks) çš„å½±å“ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†å½“å‰é—å¿˜æ–¹æ¡ˆçš„æ˜¾è‘—è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†å¼€å‘æ›´ç¨³å¥çš„å¤šæ¨¡æ€é—å¿˜ (multimodal unlearning) è§£å†³æ–¹æ¡ˆçš„è¿«åˆ‡éœ€æ±‚ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22535v2",
      "published_date": "2025-10-26 05:05:30 UTC",
      "updated_date": "2026-01-03 06:29:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:05.425517+00:00"
    },
    {
      "arxiv_id": "2510.22531v1",
      "title": "Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection",
      "title_zh": "Text to Trustï¼šè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸å…¬å¹³æœåŠ¡æ¡æ¬¾æ£€æµ‹ä¸­å…¨é‡å¾®è°ƒä¸ LoRA çš„æƒè¡¡",
      "authors": [
        "Noshitha Padma Pratyusha Juttu",
        "Sahithi Singireddy",
        "Sravani Gona",
        "Sujal Timilsina"
      ],
      "abstract": "Large Language Models (LLMs) have transformed text understanding, yet their adaptation to specialized legal domains remains constrained by the cost of full fine-tuning. This study provides a systematic evaluation of fine tuning, parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting strategies for unfair clause detection in Terms of Service (ToS) documents, a key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that full fine-tuning achieves the strongest precision recall balance, while LoRA-based models provide competitive recall with up to 3x lower memory cost. These findings highlight practical design trade-offs for efficient and domain-adapted LLMs, contributing open baselines for fine-tuning research in legal text processing.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ£€æµ‹æœåŠ¡æ¡æ¬¾ï¼ˆToSï¼‰ä¸­ä¸å…¬å¹³æ¡æ¬¾è¿™ä¸€æ³•å¾‹ NLP å…³é”®åº”ç”¨ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å¯¹æ¯”äº†å…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-tuningï¼‰ã€å‚æ•°é«˜æ•ˆé€‚é…æŠ€æœ¯ï¼ˆLoRA, QLoRAï¼‰ä»¥åŠé›¶æ ·æœ¬æç¤ºï¼ˆZero-shot Promptingï¼‰ç­–ç•¥ï¼Œæ¶µç›–äº† BERTã€DistilBERTã€LLaMAã€SaulLM ä»¥åŠ GPT-4o ç­‰å¤šç§æ¨¡å‹ã€‚å®éªŒåœ¨ CLAUDETTE-ToS åŸºå‡†æ•°æ®é›†å’Œå¤šè¯­è¨€æŠ“å–è¯­æ–™åº“ï¼ˆMultilingual Scraper Corpusï¼‰ä¸Šå±•å¼€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå…¨å‚æ•°å¾®è°ƒåœ¨ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„å¹³è¡¡ä¸Šè¡¨ç°æœ€å¼ºï¼Œè€ŒåŸºäº LoRA çš„æ¨¡å‹åœ¨å†…å­˜æˆæœ¬é™ä½ 3 å€çš„æƒ…å†µä¸‹ä»èƒ½æä¾›æå…·ç«äº‰åŠ›çš„å¬å›ç‡ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†åœ¨æ³•å¾‹æ–‡æœ¬å¤„ç†ä¸­æ„å»ºé«˜æ•ˆä¸”é¢†åŸŸè‡ªé€‚åº”æ¨¡å‹çš„è®¾è®¡æƒè¡¡ï¼Œå¹¶ä¸ºæ³•å¾‹æ–‡æœ¬å¤„ç†çš„å¾®è°ƒç ”ç©¶æä¾›äº†å…¬å¼€çš„åŸºå‡†æµ‹è¯•ï¼ˆBaselinesï¼‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, including figures and tables. All experiments are reproducible. Code and fine-tuned models are publicly available on: GitHub: (https://github.com/Stimils02/UnfairTOSAgreementsDetection) and Hugging Face: (https://huggingface.co/Noshitha98)",
      "pdf_url": "https://arxiv.org/pdf/2510.22531v1",
      "published_date": "2025-10-26 04:46:06 UTC",
      "updated_date": "2025-10-26 04:46:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:04.541572+00:00"
    },
    {
      "arxiv_id": "2510.22521v1",
      "title": "Open Multimodal Retrieval-Augmented Factual Image Generation",
      "title_zh": "å¼€æ”¾å¼å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºçš„äº‹å®æ€§å›¾åƒç”Ÿæˆ",
      "authors": [
        "Yang Tian",
        "Fan Liu",
        "Jingyuan Zhang",
        "Wei Bi",
        "Yupeng Hu",
        "Liqiang Nie"
      ],
      "abstract": "Large Multimodal Models (LMMs) have achieved remarkable progress in generating photorealistic and prompt-aligned images, but they often produce outputs that contradict verifiable knowledge, especially when prompts involve fine-grained attributes or time-sensitive events. Conventional retrieval-augmented approaches attempt to address this issue by introducing external information, yet they are fundamentally incapable of grounding generation in accurate and evolving knowledge due to their reliance on static sources and shallow evidence integration. To bridge this gap, we introduce ORIG, an agentic open multimodal retrieval-augmented framework for Factual Image Generation (FIG), a new task that requires both visual realism and factual grounding. ORIG iteratively retrieves and filters multimodal evidence from the web and incrementally integrates the refined knowledge into enriched prompts to guide generation. To support systematic evaluation, we build FIG-Eval, a benchmark spanning ten categories across perceptual, compositional, and temporal dimensions. Experiments demonstrate that ORIG substantially improves factual consistency and overall image quality over strong baselines, highlighting the potential of open multimodal retrieval for factual image generation.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ORIGï¼Œä¸€ä¸ªé¢å‘äº‹å®å›¾åƒç”Ÿæˆ(Factual Image Generation, FIG)çš„æ™ºèƒ½ä½“åŒ–å¼€æ”¾å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§æ¨¡æ€æ¨¡å‹(LMMs)åœ¨ç”Ÿæˆå›¾åƒæ—¶å¸¸ä¸ç»†ç²’åº¦å±æ€§æˆ–æ—¶æ•ˆæ€§äº‹å®ç›¸å†²çªçš„é—®é¢˜ã€‚ORIGé€šè¿‡ä»ç½‘ç»œä¸­è¿­ä»£æ£€ç´¢å¹¶è¿‡æ»¤å¤šæ¨¡æ€è¯æ®ï¼Œå°†æç‚¼åçš„çŸ¥è¯†å¢é‡é›†æˆåˆ°å¢å¼ºæç¤ºè¯ä¸­ï¼Œä»¥ç²¾ç¡®å¼•å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚ä¸ºæ”¯æŒç³»ç»ŸåŒ–è¯„ä¼°ï¼Œç ”ç©¶å›¢é˜ŸåŒæ­¥æ„å»ºäº†æ¶µç›–æ„ŸçŸ¥ã€ç»„åˆå’Œæ—¶é—´ç­‰ç»´åº¦çš„FIG-EvalåŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒORIGåœ¨äº‹å®ä¸€è‡´æ€§å’Œæ•´ä½“å›¾åƒè´¨é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†åŠ¨æ€æ¼”è¿›çŸ¥è¯†æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†å¼€æ”¾å¼å¤šæ¨¡æ€æ£€ç´¢åœ¨æå‡å›¾åƒç”Ÿæˆäº‹å®å‡†ç¡®æ€§æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2510.22521v1",
      "published_date": "2025-10-26 04:13:31 UTC",
      "updated_date": "2025-10-26 04:13:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:07.331930+00:00"
    },
    {
      "arxiv_id": "2511.04689v1",
      "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°çš„è‡ªé€‚åº”æµ‹è¯•ï¼šé™æ€åŸºå‡†çš„å¿ƒç†æµ‹é‡å­¦æ›¿ä»£æ–¹æ¡ˆ",
      "authors": [
        "Peiyu Li",
        "Xiuxiu Tang",
        "Si Chen",
        "Ying Cheng",
        "Ronald Metoyer",
        "Ting Hua",
        "Nitesh V. Chawla"
      ],
      "abstract": "Large language model evaluation requires thousands of benchmark items, making evaluations expensive and slow. Existing methods compute average accuracy across fixed item sets, treating all items equally despite varying quality and informativeness. We present ATLAS an adaptive testing framework using Item Response Theory (IRT) to estimate model ability through Fisher information-guided item selection. Our analysis of five major benchmarks reveals that 3-6% of items exhibit negative discrimination, indicating annotation errors that corrupt static evaluation. ATLAS achieves 90% item reduction while maintaining measurement precision: on HellaSwag (5,608 items), we match full-benchmark estimates using only 42 items with 0.154 MAE. Our framework maintains item exposure rates below 10% and test overlap at 16-27%, compared to static benchmarks where every model sees all items (100% exposure). Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with the same accuracy get different IRT scores, and 23-31% of all models shift by more than 10 rank positions. Code and calibrated item banks are available at https://github.com/Peiyu-Georgia-Li/ATLAS.git.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ATLASï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨é¡¹ç›®ååº”ç†è®º(Item Response Theory)è¿›è¡Œå¤§è¯­è¨€æ¨¡å‹(LLM)è¯„ä¼°çš„è‡ªé€‚åº”æµ‹è¯•æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é™æ€åŸºå‡†æµ‹è¯•(Static Benchmarks)æˆæœ¬é«˜ã€æ•ˆç‡ä½ä»¥åŠé¢˜ç›®è´¨é‡å‚å·®ä¸é½çš„é—®é¢˜ã€‚ATLASé€šè¿‡è´¹èˆå°”ä¿¡æ¯é‡(Fisher information)å¼•å¯¼é¢˜ç›®é€‰æ‹©ï¼Œå®ç°äº†å¯¹æ¨¡å‹èƒ½åŠ›çš„ç²¾å‡†ä¼°ç®—ã€‚ç ”ç©¶åˆ†æå‘ç°ï¼Œç°æœ‰åŸºå‡†æµ‹è¯•ä¸­çº¦3-6%çš„é¢˜ç›®å­˜åœ¨è´ŸåŒºåˆ†åº¦(Negative Discrimination)ï¼Œè¡¨æ˜æ ‡æ³¨é”™è¯¯ä¼šä¸¥é‡æŸå®³è¯„ä¼°çš„å¯é æ€§ã€‚åœ¨HellaSwagåŸºå‡†æµ‹è¯•ä¸Šï¼ŒATLASä»…éœ€42ä¸ªé¢˜ç›®ï¼ˆå‡å°‘çº¦90%ï¼‰å³å¯è¾¾åˆ°æé«˜çš„æµ‹é‡ç²¾åº¦ï¼Œå¹¶æœ‰æ•ˆé™ä½äº†é¢˜ç›®æ›å…‰ç‡(Item Exposure)ã€‚å®éªŒè¿˜æ­ç¤ºäº†åŸºäºIRTçš„æ’åä¸ä¼ ç»Ÿå‡†ç¡®ç‡æ’åçš„æ˜¾è‘—å·®å¼‚ï¼Œçº¦23-31%çš„æ¨¡å‹åœ¨é‡‡ç”¨æ–°æ¡†æ¶åæ’åå˜åŠ¨è¶…è¿‡10ä½ã€‚è¯¥ç ”ç©¶ä¸ºå¤§æ¨¡å‹è¯„ä¼°æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡å¿ƒç†æµ‹é‡å­¦ä¾æ®çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and calibrated item banks are available at https://github.com/Peiyu-Georgia-Li/ATLAS.git",
      "pdf_url": "https://arxiv.org/pdf/2511.04689v1",
      "published_date": "2025-10-26 03:54:12 UTC",
      "updated_date": "2025-10-26 03:54:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:08.635140+00:00"
    },
    {
      "arxiv_id": "2510.22513v1",
      "title": "Toward Robust Signed Graph Learning through Joint Input-Target Denoising",
      "title_zh": "é€šè¿‡è¾“å…¥-ç›®æ ‡è”åˆå»å™ªå®ç°é²æ£’ç¬¦å·å›¾å­¦ä¹ ",
      "authors": [
        "Junran Wu",
        "Beng Chin Ooi",
        "Ke Xu"
      ],
      "abstract": "Signed Graph Neural Networks (SGNNs) are widely adopted to analyze complex patterns in signed graphs with both positive and negative links. Given the noisy nature of real-world connections, the robustness of SGNN has also emerged as a pivotal research area. Under the supervision of empirical properties, graph structure learning has shown its robustness on signed graph representation learning, however, there remains a paucity of research investigating a robust SGNN with theoretical guidance. Inspired by the success of graph information bottleneck (GIB) in information extraction, we propose RIDGE, a novel framework for Robust sI gned graph learning through joint Denoising of Graph inputs and supervision targEts. Different from the basic GIB, we extend the GIB theory with the capability of target space denoising as the co-existence of noise in both input and target spaces. In instantiation, RIDGE effectively cleanses input data and supervision targets via a tractable objective function produced by reparameterization mechanism and variational approximation. We extensively validate our method on four prevalent signed graph datasets, and the results show that RIDGE clearly improves the robustness of popular SGNN models under various levels of noise.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RIDGEï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡è”åˆå»å™ªè¾“å…¥æ•°æ®å’Œç›‘ç£ç›®æ ‡æ¥æå‡ Signed Graph Neural Networks (SGNNs) é²æ£’æ€§çš„åˆ›æ–°æ¡†æ¶ã€‚é’ˆå¯¹ç°å®ä¸–ç•Œç¬¦å·å›¾ä¸­æ™®éå­˜åœ¨çš„å™ªå£°ä»¥åŠç°æœ‰ç ”ç©¶ç¼ºä¹ç†è®ºæŒ‡å¯¼çš„æŒ‘æˆ˜ï¼Œè¯¥å·¥ä½œå— Graph Information Bottleneck (GIB) ç†è®ºå¯å‘ï¼Œå°†å…¶æ‰©å±•ä¸ºæ”¯æŒç›®æ ‡ç©ºé—´å»å™ªçš„æ¶æ„ï¼Œä»¥åº”å¯¹è¾“å…¥å’Œç›®æ ‡ç©ºé—´å…±å­˜çš„å™ªå£°é—®é¢˜ã€‚åœ¨å®ä¾‹åŒ–è¿‡ç¨‹ä¸­ï¼ŒRIDGE åˆ©ç”¨é‡å‚æ•°åŒ–æœºåˆ¶ (reparameterization mechanism) å’Œ å˜åˆ†è¿‘ä¼¼ (variational approximation) æ„å»ºäº†å¯ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ï¼Œä»è€Œå®ç°å¯¹è¾“å…¥æ•°æ®å’Œç›‘ç£æ ‡ç­¾çš„æœ‰æ•ˆå‡€åŒ–ã€‚åœ¨å››ä¸ªä¸»æµç¬¦å·å›¾æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯è¡¨æ˜ï¼ŒRIDGE åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹å‡èƒ½æ˜¾è‘—å¢å¼ºå¤šç§æµè¡Œ SGNN æ¨¡å‹çš„é²æ£’æ€§èƒ½ï¼Œä¸ºæ„å»ºç¨³å¥çš„ç¬¦å·å›¾è¡¨ç¤ºå­¦ä¹ æ¨¡å‹æä¾›äº†ç†è®ºå¼•å¯¼ä¸æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22513v1",
      "published_date": "2025-10-26 03:34:40 UTC",
      "updated_date": "2025-10-26 03:34:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:18.038541+00:00"
    },
    {
      "arxiv_id": "2510.22512v1",
      "title": "Transitive RL: Value Learning via Divide and Conquer",
      "title_zh": "Transitive RLï¼šåŸºäºåˆ†è€Œæ²»ä¹‹çš„ä»·å€¼å­¦ä¹ ",
      "authors": [
        "Seohong Park",
        "Aditya Oberai",
        "Pranav Atreya",
        "Sergey Levine"
      ],
      "abstract": "In this work, we present Transitive Reinforcement Learning (TRL), a new value learning algorithm based on a divide-and-conquer paradigm. TRL is designed for offline goal-conditioned reinforcement learning (GCRL) problems, where the aim is to find a policy that can reach any state from any other state in the smallest number of steps. TRL converts a triangle inequality structure present in GCRL into a practical divide-and-conquer value update rule. This has several advantages compared to alternative value learning paradigms. Compared to temporal difference (TD) methods, TRL suffers less from bias accumulation, as in principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in TD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL suffers less from high variance as it performs dynamic programming. Experimentally, we show that TRL achieves the best performance in highly challenging, long-horizon benchmark tasks compared to previous offline GCRL algorithms.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç¦»çº¿ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ (Offline Goal-Conditioned Reinforcement Learning, GCRL)é—®é¢˜ï¼Œæå‡ºäº†Transitive Reinforcement Learning(TRL)ä»·å€¼å­¦ä¹ ç®—æ³•ã€‚è¯¥ç®—æ³•åŸºäºåˆ†æ²»(Divide-and-conquer)èŒƒå¼ï¼Œæ—¨åœ¨å¯»æ‰¾èƒ½åœ¨æœ€å°‘æ­¥æ•°å†…å®ç°çŠ¶æ€è½¬ç§»çš„æœ€ä¼˜ç­–ç•¥ã€‚TRLå°†GCRLä¸­å›ºæœ‰çš„ä¸‰è§’å½¢ä¸ç­‰å¼(Triangle inequality)ç»“æ„è½¬åŒ–ä¸ºå®ç”¨çš„åˆ†æ²»ä»·å€¼æ›´æ–°è§„åˆ™ã€‚ç›¸æ¯”ä¼ ç»Ÿçš„æ—¶åºå·®åˆ†(Temporal Difference, TD)æ–¹æ³•ï¼ŒTRLåœ¨å¤„ç†é•¿åº¦ä¸º$T$çš„è½¨è¿¹æ—¶ä»…éœ€$O(\\log T)$æ¬¡é€’å½’ï¼Œæœ‰æ•ˆå‡å°‘äº†åå·®ç´¯ç§¯ã€‚åŒæ—¶ï¼Œä¸è’™ç‰¹å¡æ´›(Monte Carlo)æ–¹æ³•ç›¸æ¯”ï¼ŒTRLé€šè¿‡åŠ¨æ€è§„åˆ’(Dynamic programming)é™ä½äº†é«˜æ–¹å·®é£é™©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTRLåœ¨æå…·æŒ‘æˆ˜æ€§çš„é•¿è§†é‡(Long-horizon)åŸºå‡†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶æ€§èƒ½è¶…è¶Šäº†ç°æœ‰çš„ç¦»çº¿GCRLç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22512v1",
      "published_date": "2025-10-26 03:32:31 UTC",
      "updated_date": "2025-10-26 03:32:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:20.235063+00:00"
    },
    {
      "arxiv_id": "2510.22507v1",
      "title": "GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis",
      "title_zh": "GateFuseNetï¼šé¢å‘å¸•é‡‘æ£®ç—…è¯Šæ–­çš„è‡ªé€‚åº”3Då¤šæ¨¡æ€ç¥ç»å½±åƒèåˆç½‘ç»œ",
      "authors": [
        "Rui Jin",
        "Chen Chen",
        "Yin Liu",
        "Hongfu Sun",
        "Min Zeng",
        "Min Li",
        "Yang Gao"
      ],
      "abstract": "Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging due to symptom variability and pathological heterogeneity. Most existing methods rely on conventional magnitude-based MRI modalities, such as T1-weighted images (T1w), which are less sensitive to PD pathology than Quantitative Susceptibility Mapping (QSM), a phase-based MRI technique that quantifies iron deposition in deep gray matter nuclei. In this study, we propose GateFuseNet, an adaptive 3D multimodal fusion network that integrates QSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion module that learns modality-specific attention weights and channel-wise gating vectors for selective feature modulation. This hierarchical gating mechanism enhances ROI-aware features while suppressing irrelevant signals. Experimental results show that our method outperforms three existing state-of-the-art approaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further validate the contributions of ROI guidance, multimodal integration, and fusion positioning. Grad-CAM visualizations confirm the model's focus on clinically relevant pathological regions. The source codes and pretrained models can be found at https://github.com/YangGaoUQ/GateFuseNet",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GateFuseNetï¼Œä¸€ç§è‡ªé€‚åº”çš„ 3D å¤šæ¨¡æ€ç¥ç»å½±åƒèåˆç½‘ç»œï¼Œä¸“é—¨ç”¨äºæé«˜å¸•é‡‘æ£®ç—… (Parkinson's Disease) çš„ä¸´åºŠè¯Šæ–­æ•ˆç‡ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆ Quantitative Susceptibility Mapping (QSM) å’Œ T1-weighted images (T1w) å½±åƒï¼Œå…‹æœäº†ä¼ ç»Ÿå•ä¸€æ¨¡æ€å¯¹ç—…ç†ç‰¹å¾æ•æ„Ÿæ€§ä¸è¶³çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸€ä¸ªé—¨æ§èåˆæ¨¡å— (gated fusion module)ï¼Œåˆ©ç”¨å±‚æ¬¡åŒ–é—¨æ§æœºåˆ¶å­¦ä¹ ç‰¹å®šæ¨¡æ€çš„æ³¨æ„åŠ›æƒé‡ï¼Œä»è€Œåœ¨å¢å¼º ROI-aware ç‰¹å¾çš„åŒæ—¶æŠ‘åˆ¶æ— å…³èƒŒæ™¯å™ªå£°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGateFuseNet åœ¨å¸•é‡‘æ£®ç—…åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡è¾¾åˆ° 85.00%ï¼ŒAUC ä¸º 92.06%ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæ¶ˆèå®éªŒå’Œ Grad-CAM å¯è§†åŒ–åˆ†æè¯å®äº†è¯¥æ¨¡å‹èƒ½å¤Ÿç²¾å‡†èšç„¦äºä¸´åºŠç›¸å…³çš„ç—…ç†åŒºåŸŸï¼Œä¸ºè®¡ç®—æœºè¾…åŠ©è¯Šæ–­æä¾›äº†å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å¯è§£é‡Šæ€§ä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The first two authors contributed equally to this work. Correspondence to: Yang Gao, E-mail: yang.gao@csu.edu.cn",
      "pdf_url": "https://arxiv.org/pdf/2510.22507v1",
      "published_date": "2025-10-26 03:11:26 UTC",
      "updated_date": "2025-10-26 03:11:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:32.945139+00:00"
    },
    {
      "arxiv_id": "2510.23658v2",
      "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization",
      "title_zh": "åŸºäºéæˆå¯¹åå¥½ä¼˜åŒ–çš„æ‰©æ•£è¯­è¨€æ¨¡å‹å¯¹é½",
      "authors": [
        "Vaibhav Jindal",
        "Hejian Sang",
        "Chun-Mao Lai",
        "Yanning Chen",
        "Zhipeng Wang"
      ],
      "abstract": "Diffusion language models (dLLMs) are an emerging alternative to autoregressive (AR) generators, but aligning them to human preferences is challenging because sequence log-likelihoods are intractable and pairwise preference data are costly to collect. We introduce ELBO-KTO, which combines an ELBO surrogate for diffusion log-likelihoods with a prospect-theoretic, unpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze the bias and variance induced by the ELBO substitution and employ variance-reduction practices that stabilize gradients during training. Applied to LLaDA-8B-Instruct, ELBO-KTO yields 65.9% and 62.3% adjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively, versus the base model under an automatic LLM judge. Across downstream tasks, including GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO trained on UltraFeedback-Binary performs on par with or better than the base model under identical decoding. This establishes unpaired preference optimization as a viable alternative to pairwise alignment in diffusion LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Diffusion language models (dLLMs) åœ¨å¯¹é½äººç±»åå¥½æ—¶é¢ä¸´çš„å¯¹æ•°ä¼¼ç„¶éš¾è§£ä»¥åŠæˆå¯¹åå¥½æ•°æ®æ”¶é›†æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº† ELBO-KTO æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°ç»“åˆäº†ç”¨äºæ‰©æ•£å¯¹æ•°ä¼¼ç„¶çš„ ELBO ä»£ç†ä¸åŸºäºå‰æ™¯ç†è®ºçš„éæˆå¯¹åå¥½ç›®æ ‡ Kahneman Tversky Optimization (KTO)ï¼Œå¹¶é€šè¿‡æ–¹å·®ç¼©å‡æŠ€æœ¯ç¡®ä¿äº†è®­ç»ƒè¿‡ç¨‹ä¸­æ¢¯åº¦çš„ç¨³å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ LLaDA-8B-Instruct æ¨¡å‹ä¸Šï¼ŒELBO-KTO åœ¨ kto-mix-14k å’Œ UltraFeedback-Binary æ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº† 65.9% å’Œ 62.3% çš„èƒœç‡ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹åœ¨ GSM8Kã€MMLU ç­‰ä¸‹æ¸¸æ¨ç†ä¸çŸ¥è¯†åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°è¾¾åˆ°æˆ–ä¼˜äºåŸºç¡€æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†éæˆå¯¹åå¥½ä¼˜åŒ–æ˜¯ Diffusion language models å®ç°å¯¹é½çš„ä¸€ç§é«˜æ•ˆä¸”å¯è¡Œçš„æ–¹æ¡ˆï¼Œä¸ºæ›¿ä»£ä¼ ç»Ÿçš„æˆå¯¹å¯¹é½æ–¹æ³•æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.23658v2",
      "published_date": "2025-10-26 03:02:39 UTC",
      "updated_date": "2025-11-12 08:06:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:38.027694+00:00"
    },
    {
      "arxiv_id": "2510.22503v1",
      "title": "Accelerating Materials Design via LLM-Guided Evolutionary Search",
      "title_zh": "é€šè¿‡å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼çš„æ¼”åŒ–æœç´¢åŠ é€Ÿææ–™è®¾è®¡",
      "authors": [
        "Nikhil Abhyankar",
        "Sanchit Kabra",
        "Saaketh Desai",
        "Chandan K. Reddy"
      ],
      "abstract": "Materials discovery requires navigating vast chemical and structural spaces while satisfying multiple, often conflicting, objectives. We present LLM-guided Evolution for MAterials design (LLEMA), a unified framework that couples the scientific knowledge embedded in large language models with chemistry-informed evolutionary rules and memory-based refinement. At each iteration, an LLM proposes crystallographically specified candidates under explicit property constraints; a surrogate-augmented oracle estimates physicochemical properties; and a multi-objective scorer updates success/failure memories to guide subsequent generations. Evaluated on 14 realistic tasks spanning electronics, energy, coatings, optics, and aerospace, LLEMA discovers candidates that are chemically plausible, thermodynamically stable, and property-aligned, achieving higher hit-rates and stronger Pareto fronts than generative and LLM-only baselines. Ablation studies confirm the importance of rule-guided generation, memory-based refinement, and surrogate prediction. By enforcing synthesizability and multi-objective trade-offs, LLEMA delivers a principled pathway to accelerate practical materials discovery.\n  Code: https://github.com/scientific-discovery/LLEMA",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLM-guided Evolution for MAterials design (LLEMA) æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€å¥—å°† Large Language Models (LLMs) å†…ç½®çš„ç§‘å­¦çŸ¥è¯†ä¸åŒ–å­¦å¯å‘æ¼”åŒ–è§„åˆ™åŠåŸºäºè®°å¿†çš„ä¼˜åŒ–ç›¸ç»“åˆçš„ç»Ÿä¸€ææ–™è®¾è®¡ç³»ç»Ÿã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼ŒLLMs æ ¹æ®æ˜ç¡®çš„å±æ€§çº¦æŸæå‡ºå€™é€‰ææ–™ï¼Œå¹¶ç”± surrogate-augmented oracle ä¼°ç®—å…¶ç‰©ç†åŒ–å­¦æ€§è´¨ï¼Œéšååˆ©ç”¨ multi-objective scorer æ›´æ–°æˆåŠŸä¸å¤±è´¥çš„è®°å¿†ä»¥å¼•å¯¼åç»­ç”Ÿæˆã€‚åœ¨æ¶µç›–ç”µå­ã€èƒ½æºã€èˆªç©ºèˆªå¤©ç­‰é¢†åŸŸçš„ 14 é¡¹ç°å®ä»»åŠ¡è¯„ä¼°ä¸­ï¼ŒLLEMA æˆåŠŸå‘ç°äº†åŒ–å­¦åˆç†ã€çƒ­åŠ›å­¦ç¨³å®šä¸”ç¬¦åˆç‰¹å®šå±æ€§è¦æ±‚çš„å€™é€‰ææ–™ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLEMA åœ¨å‘½ä¸­ç‡å’Œ Pareto fronts è¡¨ç°ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ç”Ÿæˆæ¨¡å‹å’Œä»…ä¾èµ– LLMs çš„åŸºçº¿æ–¹æ³•ã€‚æ¶ˆèå®éªŒè¯å®äº†è§„åˆ™å¼•å¯¼ç”Ÿæˆã€è®°å¿†ä¼˜åŒ–å’Œä»£ç†é¢„æµ‹åœ¨æå‡è®¾è®¡æ•ˆç‡ä¸­çš„å…³é”®ä½œç”¨ã€‚é€šè¿‡å¼ºåˆ¶æ‰§è¡Œå¯åˆæˆæ€§å’Œå¤šç›®æ ‡æƒè¡¡ï¼ŒLLEMA ä¸ºåŠ é€Ÿå®é™…åº”ç”¨ä¸­çš„ææ–™å‘ç°æä¾›äº†ä¸€æ¡ç³»ç»ŸåŒ–çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22503v1",
      "published_date": "2025-10-26 02:47:15 UTC",
      "updated_date": "2025-10-26 02:47:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:41.251357+00:00"
    },
    {
      "arxiv_id": "2510.22500v1",
      "title": "Scalable Oversight via Partitioned Human Supervision",
      "title_zh": "åŸºäºåˆ†å—äººç±»ç›‘ç£çš„å¯æ‰©å±•ç›‘ç£",
      "authors": [
        "Ren Yin",
        "Takashi Ishida",
        "Masashi Sugiyama"
      ],
      "abstract": "As artificial intelligence (AI) systems approach and surpass expert human performance across a broad range of tasks, obtaining high-quality human supervision for evaluation and training becomes increasingly challenging. Our focus is on tasks that require deep knowledge and skills of multiple domains. Unfortunately, even the best human experts are knowledgeable only in a single narrow area, and will not be able to evaluate the correctness of advanced AI systems on such superhuman tasks. However, based on their narrow expertise, humans may provide a weak signal, i.e., a complementary label indicating an option that is incorrect. For example, a cardiologist could state that \"this is not related to cardiology,'' even if they cannot identify the true disease. Based on this weak signal, we propose a scalable oversight framework that enables us to evaluate frontier AI systems without the need to prepare the ground truth. We derive an unbiased estimator of top-1 accuracy from complementary labels and quantify how many complementary labels are needed to match the variance of ordinary labels. We further introduce two estimators to combine scarce ordinary labels with abundant complementary labels. We provide finite-sample deviation guarantees for both complementary-only and the mixed estimators. Empirically, we show that we can evaluate the output of large language models without the ground truth, if we have complementary labels. We further show that we can train an AI system with such weak signals: we show how we can design an agentic AI system automatically that can perform better with this partitioned human supervision. Our code is available at https://github.com/R-Yin-217/Scalable-Oversight-via-Human-Partitioned-Supervision.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹AIç³»ç»Ÿè¶…è¶Šäººç±»ä¸“å®¶æ°´å¹³æ—¶éš¾ä»¥è·å¾—é«˜è´¨é‡äººç±»ç›‘ç£çš„é—®é¢˜ï¼Œæå‡ºäº†Scalable Oversight via Partitioned Human Supervisionæ¡†æ¶ã€‚è¯¥æ–¹æ³•æ—¨åœ¨åˆ©ç”¨äººç±»åœ¨ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†æä¾›è¡¥è¶³æ ‡ç­¾ï¼ˆcomplementary labelsï¼‰ï¼Œå³é€šè¿‡æŒ‡å‡ºé”™è¯¯çš„é€‰é¡¹è€Œéç›´æ¥è¯†åˆ«æ­£ç¡®ç­”æ¡ˆæ¥æä¾›ç›‘ç£ä¿¡å·ã€‚ç ”ç©¶äººå‘˜æ¨å¯¼å‡ºäº†ä¸€ä¸ªåŸºäºè¡¥è¶³æ ‡ç­¾çš„Top-1å‡†ç¡®ç‡æ— åä¼°è®¡é‡ï¼Œå¹¶è®¾è®¡äº†ä¸¤ç§èƒ½å°†ç¨€ç¼ºæ™®é€šæ ‡ç­¾ä¸å¤§é‡è¡¥è¶³æ ‡ç­¾ç›¸ç»“åˆçš„ä¼°è®¡å™¨ã€‚ç†è®ºåˆ†æä¸ºç›¸å…³ä¼°è®¡å™¨æä¾›äº†æœ‰é™æ ·æœ¬åå·®ä¿è¯ï¼ˆfinite-sample deviation guaranteesï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç¼ºä¹Ground Truthçš„æƒ…å†µä¸‹ï¼Œä»…é€šè¿‡è¡¥è¶³æ ‡ç­¾å³å¯æœ‰æ•ˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å±•ç¤ºäº†åˆ©ç”¨æ­¤ç±»ä¿¡å·è‡ªåŠ¨æ„å»ºæ™ºèƒ½ä½“AIç³»ç»Ÿï¼ˆagentic AI systemï¼‰çš„å¯èƒ½æ€§ï¼Œè¯æ˜äº†å…¶åœ¨åˆ†å—äººç±»ç›‘ç£ä¸‹å…·æœ‰æ›´ä¼˜æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22500v1",
      "published_date": "2025-10-26 02:42:03 UTC",
      "updated_date": "2025-10-26 02:42:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:42.965970+00:00"
    },
    {
      "arxiv_id": "2511.02848v1",
      "title": "EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding",
      "title_zh": "EEGReXferNetï¼šåŸºäºè·¨å—è¯•è€…è¿ç§»å­¦ä¹ ä¸é€šé“æ„ŸçŸ¥åµŒå…¥çš„è½»é‡çº§ EEG å­ç©ºé—´é‡æ„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¡†æ¶",
      "authors": [
        "Shantanu Sarkar",
        "Piotr Nabrzyski",
        "Saurabh Prasad",
        "Jose Luis Contreras-Vidal"
      ],
      "abstract": "Electroencephalography (EEG) is a widely used non-invasive technique for monitoring brain activity, but low signal-to-noise ratios (SNR) due to various artifacts often compromise its utility. Conventional artifact removal methods require manual intervention or risk suppressing critical neural features during filtering/reconstruction. Recent advances in generative models, including Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), have shown promise for EEG reconstruction; however, these approaches often lack integrated temporal-spectral-spatial sensitivity and are computationally intensive, limiting their suitability for real-time applications like brain-computer interfaces (BCIs). To overcome these challenges, we introduce EEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction via cross-subject transfer learning - developed using Keras TensorFlow (v2.15.1). EEGReXferNet employs a modular architecture that leverages volume conduction across neighboring channels, band-specific convolution encoding, and dynamic latent feature extraction through sliding windows. By integrating reference-based scaling, the framework ensures continuity across successive windows and generalizes effectively across subjects. This design improves spatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean spectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate overfitting, and maintains computational efficiency for robust, real-time EEG preprocessing in neurophysiological and BCI applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EEGReXferNetï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè„‘ç”µå›¾(EEG)å­ç©ºé—´é‡æ„çš„è½»é‡çº§ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(Gen-AI)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå»ä¼ªå½±æ–¹æ³•ä¾èµ–äººå·¥å¹²é¢„ä»¥åŠç°æœ‰ç”Ÿæˆæ¨¡å‹è®¡ç®—å¼€é”€å¤§ã€ç¼ºä¹å¤šç»´æ•æ„Ÿæ€§ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†è·¨å—è¯•è€…è¿ç§»å­¦ä¹ (Cross-Subject Transfer Learning)ä¸é€šé“æ„ŸçŸ¥åµŒå…¥(Channel-Aware Embedding)æŠ€æœ¯ï¼Œé€šè¿‡æ¨¡å—åŒ–æ¶æ„å®ç°äº†ç›¸é‚»é€šé“çš„ä½“ç§¯ä¼ å¯¼(Volume Conduction)åˆ©ç”¨åŠç‰¹å®šé¢‘æ®µçš„å·ç§¯ç¼–ç ã€‚ç»“åˆæ»‘åŠ¨çª—å£ä¸‹çš„åŠ¨æ€æ½œåœ¨ç‰¹å¾æå–ä¸å‚è€ƒç¼©æ”¾æŠ€æœ¯ï¼Œè¯¥ç³»ç»Ÿç¡®ä¿äº†å¤„ç†è¿‡ç¨‹çš„è¿ç»­æ€§å¹¶æ˜¾è‘—å¢å¼ºäº†åœ¨ä¸åŒå—è¯•è€…é—´çš„æ³›åŒ–æ€§èƒ½ã€‚å®éªŒæ•°æ®è¯æ˜ï¼ŒEEGReXferNetåœ¨æ˜¾è‘—æå‡ç©ºé—´-æ—¶é—´-é¢‘ç‡åˆ†è¾¨ç‡çš„åŒæ—¶ï¼ˆå¹³å‡ PSD ç›¸å…³æ€§ >= 0.95ï¼‰ï¼Œå‡å°‘äº†çº¦ 45% çš„æ¨¡å‹æƒé‡ï¼Œæœ‰æ•ˆé™ä½äº†è¿‡æ‹Ÿåˆé£é™©ã€‚è¯¥è®¾è®¡åœ¨ä¿æŒé«˜æ•ˆè®¡ç®—çš„åŒæ—¶ï¼Œä¸ºè„‘æœºæ¥å£(BCI)ç­‰éœ€è¦å®æ—¶ã€é²æ£’ EEG é¢„å¤„ç†çš„åº”ç”¨åœºæ™¯æä¾›äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted for presentation at the NeurIPS 2025 Workshop on Foundation Models for the Brain and Body",
      "pdf_url": "https://arxiv.org/pdf/2511.02848v1",
      "published_date": "2025-10-26 02:15:25 UTC",
      "updated_date": "2025-10-26 02:15:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:45.667226+00:00"
    },
    {
      "arxiv_id": "2510.22481v1",
      "title": "An Analytic Theory of Quantum Imaginary Time Evolution",
      "title_zh": "é‡å­è™šæ—¶æ¼”åŒ–çš„è§£æç†è®º",
      "authors": [
        "Min Chen",
        "Bingzhi Zhang",
        "Quntao Zhuang",
        "Junyu Liu"
      ],
      "abstract": "Quantum imaginary time evolution (QITE) algorithm is one of the most promising variational quantum algorithms (VQAs), bridging the current era of Noisy Intermediate-Scale Quantum devices and the future of fully fault-tolerant quantum computing. Although practical demonstrations of QITE and its potential advantages over the general VQA trained with vanilla gradient descent (GD) in certain tasks have been reported, a first-principle, theoretical understanding of QITE remains limited. Here, we aim to develop an analytic theory for the dynamics of QITE. First, we show that QITE can be interpreted as a form of a general VQA trained with Quantum Natural Gradient Descent (QNGD), where the inverse quantum Fisher information matrix serves as the learning-rate tensor. This equivalence is established not only at the level of gradient update rules, but also through the action principle: the variational principle can be directly connected to the geometric geodesic distance in the quantum Fisher information metric, up to an integration constant. Second, for wide quantum neural networks, we employ the quantum neural tangent kernel framework to construct an analytic model for QITE. We prove that QITE always converges faster than GD-based VQA, though this advantage is suppressed by the exponential growth of Hilbert space dimension. This helps explain certain experimental results in quantum computational chemistry. Our theory encompasses linear, quadratic, and more general loss functions. We validate the analytic results through numerical simulations. Our findings establish a theoretical foundation for QITE dynamics and provide analytic insights for the first-principle design of variational quantum algorithms.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å˜åˆ†é‡å­ç®—æ³•(Variational Quantum Algorithms, VQAs)ä¸­çš„é‡å­è™šæ—¶æ¼”åŒ–(Quantum Imaginary Time Evolution, QITE)ç®—æ³•ç¼ºä¹ç¬¬ä¸€æ€§åŸç†ç†è®ºç†è§£çš„é—®é¢˜ï¼Œå¼€å‘äº†ä¸€å¥—å®Œæ•´çš„è§£æç†è®ºã€‚ç ”ç©¶è¯æ˜äº† QITE å¯ä»¥è¢«è§£é‡Šä¸ºä¸€ç§åˆ©ç”¨é‡å­è‡ªç„¶æ¢¯åº¦ä¸‹é™(Quantum Natural Gradient Descent, QNGD)è®­ç»ƒçš„é€šç”¨ VQAï¼Œå…¶ä¸­é‡å­ Fisher ä¿¡æ¯çŸ©é˜µ(Quantum Fisher Information Matrix)çš„é€†ä½œä¸ºå­¦ä¹ ç‡å¼ é‡ã€‚é€šè¿‡ä½œç”¨é‡åŸç†(Action Principle)ï¼Œè¯¥ç†è®ºå°†å˜åˆ†åŸç†ç›´æ¥ä¸é‡å­ Fisher ä¿¡æ¯åº¦é‡ä¸­çš„å‡ ä½•æµ‹åœ°çº¿è·ç¦»(Geometric Geodesic Distance)å»ºç«‹äº†æ•°å­¦è”ç³»ã€‚é’ˆå¯¹å®½é‡å­ç¥ç»ç½‘ç»œï¼Œç ”ç©¶åˆ©ç”¨é‡å­ç¥ç»ç½‘ç»œåˆ‡çº¿æ ¸(Quantum Neural Tangent Kernel)æ¡†æ¶è¯æ˜äº† QITE çš„æ”¶æ•›é€Ÿåº¦å§‹ç»ˆå¿«äºåŸºäºæ¢¯åº¦ä¸‹é™(Gradient Descent, GD)çš„ VQAï¼Œå°½ç®¡è¿™ç§ä¼˜åŠ¿ä¼šå—åˆ°å¸Œå°”ä¼¯ç‰¹ç©ºé—´(Hilbert Space)ç»´åº¦æŒ‡æ•°å¢é•¿çš„æŠ‘åˆ¶ã€‚è¯¥ç ”ç©¶æ¶µç›–äº†å¤šç§æŸå¤±å‡½æ•°å¹¶é€šè¿‡æ•°å€¼æ¨¡æ‹Ÿè¿›è¡Œäº†éªŒè¯ï¼Œä¸º QITE åŠ¨åŠ›å­¦å¥ å®šäº†ç†è®ºåŸºç¡€ï¼Œå¹¶ä¸ºå˜åˆ†é‡å­ç®—æ³•çš„è®¾è®¡æä¾›äº†ç¬¬ä¸€æ€§åŸç†çš„è§£æè§è§£ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "comment": "35 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.22481v1",
      "published_date": "2025-10-26 01:43:55 UTC",
      "updated_date": "2025-10-26 01:43:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:47.271836+00:00"
    },
    {
      "arxiv_id": "2510.22480v1",
      "title": "Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity",
      "title_zh": "å•æ•™å¸ˆè§†å›¾å¢å¼ºï¼šé€šè¿‡è§’åº¦å¤šæ ·æ€§æå‡çŸ¥è¯†è’¸é¦",
      "authors": [
        "Seonghoon Yu",
        "Dongjun Nam",
        "Dina Katabi",
        "Jeany Son"
      ],
      "abstract": "Knowledge Distillation (KD) aims to train a lightweight student model by transferring knowledge from a large, high-capacity teacher. Recent studies have shown that leveraging diverse teacher perspectives can significantly improve distillation performance; however, achieving such diversity typically requires multiple teacher networks, leading to high computational costs. In this work, we propose a novel cost-efficient knowledge augmentation method for KD that generates diverse multi-views by attaching multiple branches to a single teacher. To ensure meaningful semantic variation across multi-views, we introduce two angular diversity objectives: 1) constrained inter-angle diversify loss, which maximizes angles between augmented views while preserving proximity to the original teacher output, and 2) intra-angle diversify loss, which encourages an even distribution of views around the original output. The ensembled knowledge from these angularly diverse views, along with the original teacher, is distilled into the student. We further theoretically demonstrate that our objectives increase the diversity among ensemble members and thereby reduce the upper bound of the ensemble's expected loss, leading to more effective distillation. Experimental results show that our method surpasses an existing knowledge augmentation method across diverse configurations. Moreover, the proposed method is compatible with other KD frameworks in a plug-and-play fashion, providing consistent improvements in generalization performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Knowledge Distillation (KD)ä¸­åˆ©ç”¨å¤šæ•™å¸ˆè§†è§’æå‡æ€§èƒ½ä½†è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†Single-Teacher View Augmentationæ–¹æ³•ï¼Œé€šè¿‡åœ¨å•ä¸ªæ•™å¸ˆç½‘ç»œä¸Šé™„åŠ å¤šä¸ªåˆ†æ”¯æ¥ç”Ÿæˆå¤šæ ·åŒ–çš„å¤šè§†å›¾ã€‚ä¸ºäº†ç¡®ä¿è§†å›¾é—´çš„è¯­ä¹‰å·®å¼‚ï¼Œä½œè€…å¼•å…¥äº†çº¦æŸé—´è§’å¤šæ ·æ€§æŸå¤±(constrained inter-angle diversify loss)ä»¥æœ€å¤§åŒ–å¢å¼ºè§†å›¾é—´çš„è§’åº¦ï¼Œå¹¶åˆ©ç”¨å±‚å†…è§’åº¦å¤šæ ·æ€§æŸå¤±(intra-angle diversify loss)ä¿ƒè¿›è§†å›¾åœ¨åŸå§‹è¾“å‡ºå‘¨å›´å‡åŒ€åˆ†å¸ƒã€‚è¯¥æ–¹æ³•å°†è¿™äº›å…·æœ‰è§’åº¦å¤šæ ·æ€§çš„è§†å›¾ä¸åŸå§‹æ•™å¸ˆè¾“å‡ºè¿›è¡Œé›†æˆå¹¶è’¸é¦è‡³å­¦ç”Ÿæ¨¡å‹ï¼Œç†è®ºä¸Šè¯æ˜äº†å…¶èƒ½é€šè¿‡å¢åŠ é›†æˆæˆå‘˜å¤šæ ·æ€§æ¥é™ä½é¢„æœŸæŸå¤±çš„ä¸Šç•Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§é…ç½®ä¸‹å‡ä¼˜äºç°æœ‰çš„çŸ¥è¯†å¢å¼ºæŠ€æœ¯ï¼Œå¹¶èƒ½ä»¥plug-and-playçš„æ–¹å¼å…¼å®¹å…¶ä»–KDæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.22480v1",
      "published_date": "2025-10-26 01:41:08 UTC",
      "updated_date": "2025-10-26 01:41:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:57.479002+00:00"
    },
    {
      "arxiv_id": "2510.22477v1",
      "title": "Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization",
      "title_zh": "Agent-GSPOï¼šåŸºäºç»„åºåˆ—ç­–ç•¥ä¼˜åŒ–çš„é«˜æ•ˆé€šä¿¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Yijia Fan",
        "Jusheng Zhang",
        "Jing Yang",
        "Keze Wang"
      ],
      "abstract": "To combat the prohibitive communication costs of ``free-for-all\" multi-agent systems (MAS), we introduce \\textbf{Agent-GSPO}, a framework that directly optimizes for token economy using sequence-level reinforcement learning. Agent-GSPO leverages the stable and memory-efficient Group Sequence Policy Optimization (GSPO) algorithm to train agents on a communication-aware reward that explicitly penalizes verbosity. Across seven reasoning benchmarks, Agent-GSPO not only achieves new state-of-the-art performance but does so with a fraction of the token consumption of existing methods. By fostering emergent strategies like ``strategic silence,\" our approach provides a practical blueprint for developing scalable and economically viable multi-agent systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Agent-GSPO æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (Multi-Agent Systems, MAS) ä¸­ç”±äºå…¨å‘˜é€šä¿¡å¯¼è‡´çš„é«˜æ˜‚æˆæœ¬é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç¨³å®šä¸”å†…å­˜é«˜æ•ˆçš„ Group Sequence Policy Optimization (GSPO) ç®—æ³•ï¼Œé€šè¿‡åºåˆ—çº§å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) è®­ç»ƒæ™ºèƒ½ä½“ï¼Œå¹¶å¼•å…¥äº†æ˜ç¡®æƒ©ç½šå†—ä½™è¡¨è¿°çš„é€šä¿¡æ„ŸçŸ¥å¥–åŠ±æœºåˆ¶ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒAgent-GSPO ä¿ƒä½¿æ™ºèƒ½ä½“äº§ç”Ÿå¦‚â€œæˆ˜ç•¥æ€§æ²‰é»˜ (strategic silence)â€ç­‰æ–°å…´ç­–ç•¥ï¼Œä»è€Œåœ¨æ ¹æœ¬ä¸Šä¼˜åŒ– Token ç»æµæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAgent-GSPO åœ¨ä¸ƒä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ€§èƒ½ (SOTA)ï¼Œä¸”å…¶ Token æ¶ˆè€—é‡ä»…ä¸ºç°æœ‰æ–¹æ³•çš„ä¸€å°éƒ¨åˆ†ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¼€å‘å…·æœ‰æ‰©å±•æ€§ä¸”ç»æµå¯è¡Œçš„é«˜æ•ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è·µè“å›¾ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22477v1",
      "published_date": "2025-10-26 01:27:13 UTC",
      "updated_date": "2025-10-26 01:27:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:55.179053+00:00"
    },
    {
      "arxiv_id": "2510.22475v1",
      "title": "CHOIR: Collaborative Harmonization fOr Inference Robustness",
      "title_zh": "CHOIRï¼šé¢å‘æ¨ç†é²æ£’æ€§çš„ååŒè°ƒå’Œ",
      "authors": [
        "Xiangjue Dong",
        "Cong Wang",
        "Maria Teleki",
        "Millennium Bismay",
        "James Caverlee"
      ],
      "abstract": "Persona-assigned Large Language Models (LLMs) can adopt diverse roles, enabling personalized and context-aware reasoning. However, even minor demographic perturbations in personas, such as simple pronoun changes, can alter reasoning trajectories, leading to divergent sets of correct answers. Instead of treating these variations as biases to be mitigated, we explore their potential as a constructive resource to improve reasoning robustness. We propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a test-time framework that harmonizes multiple persona-conditioned reasoning signals into a unified prediction. CHOIR orchestrates a collaborative decoding process among counterfactual personas, dynamically balancing agreement and divergence in their reasoning paths. Experiments on various reasoning benchmarks demonstrate that CHOIR consistently enhances performance across demographics, model architectures, scales, and tasks - without additional training. Improvements reach up to 26.4% for individual demographic groups and 19.2% on average across five demographics. It remains effective even when base personas are suboptimal. By reframing persona variation as a constructive signal, CHOIR provides a scalable and generalizable approach to more reliable LLM reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Persona-assigned Large Language Models (LLMs)åœ¨é¢å¯¹æ€§åˆ«ä»£è¯ç­‰å¾®å°äººå£ç»Ÿè®¡å­¦æ‰°åŠ¨æ—¶äº§ç”Ÿçš„æ¨ç†ä¸ä¸€è‡´é—®é¢˜ï¼Œæå‡ºäº†CHOIR (Collaborative Harmonization fOr Inference Robustness)æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„åè§æ¶ˆé™¤æ–¹æ³•ä¸åŒï¼ŒCHOIRå°†è¿™ç§Personaå˜å¼‚è§†ä¸ºæå‡æ¨ç†é²æ£’æ€§çš„å»ºè®¾æ€§èµ„æºã€‚è¯¥æ¡†æ¶åœ¨æµ‹è¯•æ—¶(test-time)é€šè¿‡åä½œè§£ç (collaborative decoding)è¿‡ç¨‹ï¼ŒåŠ¨æ€åè°ƒå¤šä¸ªåäº‹å®Personaä¹‹é—´çš„æ¨ç†ä¿¡å·ï¼Œåœ¨å…±è¯†ä¸åˆ†æ­§ä¸­å¯»æ±‚æœ€ä¼˜é¢„æµ‹ã€‚å®éªŒè¯æ˜ï¼ŒCHOIRåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåœ¨å¤šç§æ¨¡å‹æ¶æ„å’Œä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºåŠ²çš„é²æ£’æ€§ï¼Œä½¿ç‰¹å®šäººå£ç»Ÿè®¡ç¾¤ä½“çš„è¡¨ç°æå‡é«˜è¾¾26.4%ï¼Œå¹³å‡æå‡è¾¾19.2%ã€‚é€šè¿‡å°†Personaå˜å¼‚é‡æ–°å®šä¹‰ä¸ºæœ‰ç›Šä¿¡å·ï¼ŒCHOIRä¸ºæ„å»ºæ›´å¯é ã€æ›´å…·æ™®é€‚æ€§çš„LLMæ¨ç†æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "updated version",
      "pdf_url": "https://arxiv.org/pdf/2510.22475v1",
      "published_date": "2025-10-26 01:20:24 UTC",
      "updated_date": "2025-10-26 01:20:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:47:59.371445+00:00"
    },
    {
      "arxiv_id": "2510.22473v1",
      "title": "DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss",
      "title_zh": "DynaPose4Dï¼šåŸºäºå§¿æ€å¯¹é½æŸå¤±çš„é«˜è´¨é‡ 4D åŠ¨æ€å†…å®¹ç”Ÿæˆ",
      "authors": [
        "Jing Yang",
        "Yufeng Yang"
      ],
      "abstract": "Recent advancements in 2D and 3D generative models have expanded the capabilities of computer vision. However, generating high-quality 4D dynamic content from a single static image remains a significant challenge. Traditional methods have limitations in modeling temporal dependencies and accurately capturing dynamic geometry changes, especially when considering variations in camera perspective. To address this issue, we propose DynaPose4D, an innovative solution that integrates 4D Gaussian Splatting (4DGS) techniques with Category-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D Gaussian Splatting to construct a 3D model from single images, then predicts multi-view pose keypoints based on one-shot support from a chosen view, leveraging supervisory signals to enhance motion consistency. Experimental results show that DynaPose4D achieves excellent coherence, consistency, and fluidity in dynamic motion generation. These findings not only validate the efficacy of the DynaPose4D framework but also indicate its potential applications in the domains of computer vision and animation production.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»å•å¼ é™æ€å›¾åƒç”Ÿæˆé«˜è´¨é‡ 4D åŠ¨æ€å†…å®¹æ‰€é¢ä¸´çš„æ—¶é—´ä¾èµ–æ€§å’Œå‡ ä½•å˜åŒ–å»ºæ¨¡éš¾é¢˜ï¼Œæå‡ºäº†åˆ›æ–°æ–¹æ¡ˆ DynaPose4Dã€‚è¯¥æ¡†æ¶æœ‰æ•ˆåœ°å°† 4D Gaussian Splatting (4DGS) ä¸ Category-Agnostic Pose Estimation (CAPE) æŠ€æœ¯ç›¸ç»“åˆã€‚DynaPose4D é¦–å…ˆé€šè¿‡ 3D Gaussian Splatting ä»å•å¼ å›¾åƒæ„å»º 3D æ¨¡å‹ï¼Œéšååˆ©ç”¨é€‰å®šè§†å›¾çš„ one-shot æ”¯æŒæ¥é¢„æµ‹å¤šè§†å›¾å§¿æ€å…³é”®ç‚¹ï¼Œå¹¶å¼•å…¥ç›‘ç£ä¿¡å·ä»¥æ˜¾è‘—å¢å¼ºè¿åŠ¨çš„ä¸€è‡´æ€§ã€‚å®éªŒè¯æ˜ï¼ŒDynaPose4D åœ¨ç”ŸæˆåŠ¨æ€è¿åŠ¨æ—¶å±•ç°äº†å“è¶Šçš„è¿è´¯æ€§ã€ä¸€è‡´æ€§ä¸æµç•…åº¦ã€‚è¿™äº›å‘ç°ä¸ä»…éªŒè¯äº†è¯¥æ¡†æ¶åœ¨ 4D å†…å®¹ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿå±•ç¤ºäº†å…¶åœ¨è®¡ç®—æœºè§†è§‰å’ŒåŠ¨ç”»åˆ¶ä½œé¢†åŸŸçš„æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22473v1",
      "published_date": "2025-10-26 01:11:13 UTC",
      "updated_date": "2025-10-26 01:11:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:48:07.272135+00:00"
    },
    {
      "arxiv_id": "2511.00024v1",
      "title": "Chitchat with AI: Understand the supply chain carbon disclosure of companies worldwide through Large Language Model",
      "title_zh": "ä¸AIå¯¹è¯ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å…¨çƒä¼ä¸šä¾›åº”é“¾ç¢³æŠ«éœ²æ·±åº¦è§£æ",
      "authors": [
        "Haotian Hang",
        "Yueyang Shen",
        "Vicky Zhu",
        "Jose Cruz",
        "Michelle Li"
      ],
      "abstract": "In the context of global sustainability mandates, corporate carbon disclosure has emerged as a critical mechanism for aligning business strategy with environmental responsibility. The Carbon Disclosure Project (CDP) hosts the world's largest longitudinal dataset of climate-related survey responses, combining structured indicators with open-ended narratives, but the heterogeneity and free-form nature of these disclosures present significant analytical challenges for benchmarking, compliance monitoring, and investment screening. This paper proposes a novel decision-support framework that leverages large language models (LLMs) to assess corporate climate disclosure quality at scale. It develops a master rubric that harmonizes narrative scoring across 11 years of CDP data (2010-2020), enabling cross-sector and cross-country benchmarking. By integrating rubric-guided scoring with percentile-based normalization, our method identifies temporal trends, strategic alignment patterns, and inconsistencies in disclosure across industries and regions. Results reveal that sectors such as technology and countries like Germany consistently demonstrate higher rubric alignment, while others exhibit volatility or superficial engagement, offering insights that inform key decision-making processes for investors, regulators, and corporate environmental, social, and governance (ESG) strategists. The proposed LLM-based approach transforms unstructured disclosures into quantifiable, interpretable, comparable, and actionable intelligence, advancing the capabilities of AI-enabled decision support systems (DSSs) in the domain of climate governance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ–°å‹å†³ç­–æ”¯æŒæ¡†æ¶ï¼Œæ—¨åœ¨å¤§è§„æ¨¡è¯„ä¼°ä¼ä¸šæ°”å€™æŠ«éœ²çš„è´¨é‡ï¼Œè§£å†³ç¢³æŠ«éœ²é¡¹ç›®(CDP)æ•°æ®ä¸­å¼‚æ„æ€§ä¸éç»“æ„åŒ–å™è¿°å¸¦æ¥çš„åˆ†æéš¾é¢˜ã€‚ç ”ç©¶å¼€å‘äº†ä¸€å¥—ç»Ÿä¸€çš„è¯„åˆ†æ ‡å‡†(Master Rubric)ï¼Œå¯¹2010å¹´è‡³2020å¹´é—´çš„CDPæ•°æ®è¿›è¡Œåè°ƒè¯„åˆ†ï¼Œå¹¶ç»“åˆç™¾åˆ†ä½å½’ä¸€åŒ–æ–¹æ³•è¯†åˆ«ä¸åŒè¡Œä¸šå’Œåœ°åŒºçš„æŠ«éœ²è¶‹åŠ¿åŠä¸ä¸€è‡´æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œç§‘æŠ€è¡Œä¸šä»¥åŠå¾·å›½ç­‰å›½å®¶åœ¨æŠ«éœ²çš„ä¸€è‡´æ€§ä¸Šè¡¨ç°è¾ƒé«˜ï¼Œè€Œéƒ¨åˆ†è¡Œä¸šåˆ™å‘ˆç°å‡ºæ³¢åŠ¨æ€§æˆ–è¡¨å±‚å‚ä¸çš„ç‰¹å¾ã€‚è¯¥æ–¹æ³•å°†éç»“æ„åŒ–çš„æŠ«éœ²ä¿¡æ¯è½¬åŒ–ä¸ºå¯é‡åŒ–ä¸”å…·å¯æ“ä½œæ€§çš„æ™ºèƒ½æ•°æ®ï¼Œæ˜¾è‘—å¢å¼ºäº†äººå·¥æ™ºèƒ½åœ¨æ°”å€™æ²»ç†å’Œç¯å¢ƒã€ç¤¾ä¼šä¸æ²»ç†(ESG)å†³ç­–æ”¯æŒç³»ç»Ÿ(DSSs)ä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.00024v1",
      "published_date": "2025-10-26 01:06:18 UTC",
      "updated_date": "2025-10-26 01:06:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:48:22.356224+00:00"
    },
    {
      "arxiv_id": "2510.22467v1",
      "title": "Backward-Friendly Optimization: Training Large Language Models with Approximate Gradients under Memory Constraints",
      "title_zh": "åå‘å‹å¥½å‹ä¼˜åŒ–ï¼šå†…å­˜é™åˆ¶ä¸‹åŸºäºè¿‘ä¼¼æ¢¯åº¦çš„å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒ",
      "authors": [
        "Jing Yang",
        "Kaitong Cai",
        "Yijia Fan",
        "Yufeng Yang",
        "Keze Wang"
      ],
      "abstract": "Full fine-tuning of Large Language Models (LLMs) is notoriously memory-intensive, primarily because conventional optimizers such as SGD or Adam assume access to exact gradients derived from cached activations. Existing solutions either alter the model architecture (e.g., reversible networks) or trade memory for computation (e.g., activation checkpointing), but the optimizer itself remains untouched. In this work, we introduce GradLite, a backward-friendly optimizer that relaxes the requirement of exact gradients, enabling efficient training even when intermediate activations are aggressively discarded or approximated. GradLite leverages two key techniques: (i) low-rank Jacobian approximation, which reduces the dimensionality of backpropagated error signals, and (ii) error-feedback correction, which accumulates and compensates approximation errors across iterations to preserve convergence guarantees. We provide a theoretical analysis showing that GradLite maintains unbiased gradient estimates with bounded variance, ensuring convergence rates comparable to Adam. Empirically, GradLite reduces optimizer-state and activation memory consumption by up to 50\\% without architectural changes, and achieves on-par or superior downstream performance on reasoning (MMLU, GSM8K), multilingual, and dialogue benchmarks compared to checkpointing and optimizer-centric baselines (LoMo, GaLore).",
      "tldr_zh": "å…¨é‡å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ç”±äºéœ€è¦ç¼“å­˜æ¿€æ´»å€¼ä»¥è·å–ç²¾ç¡®æ¢¯åº¦ï¼Œé¢ä¸´ç€æé«˜çš„å†…å­˜æ¶ˆè€—æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†GradLiteï¼Œä¸€ç§å¯¹åå‘ä¼ æ’­å‹å¥½çš„ä¼˜åŒ–å™¨(backward-friendly optimizer)ï¼Œé€šè¿‡å…è®¸ä½¿ç”¨è¿‘ä¼¼æ¢¯åº¦(approximate gradients)æ¥å®ç°åœ¨ä¸¢å¼ƒæˆ–è¿‘ä¼¼ä¸­é—´æ¿€æ´»å€¼æƒ…å†µä¸‹çš„é«˜æ•ˆè®­ç»ƒã€‚GradLiteæ ¸å¿ƒé‡‡ç”¨äº†ä½ç§©é›…å¯æ¯”è¿‘ä¼¼(low-rank Jacobian approximation)ä»¥é™ä½è¯¯å·®ä¿¡å·ç»´åº¦ï¼Œå¹¶ç»“åˆè¯¯å·®åé¦ˆæ ¡æ­£(error-feedback correction)æ¥è¡¥å¿è¿­ä»£ä¸­çš„è¿‘ä¼¼è¯¯å·®ã€‚ç†è®ºåˆ†æè¯æ˜GradLiteèƒ½ç»´æŒæ— åæ¢¯åº¦ä¼°è®¡ï¼Œå…¶æ”¶æ•›ç‡(convergence rates)ä¸Adamç›¸å½“ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨ä¸æ”¹å˜æ¨¡å‹æ¶æ„çš„æƒ…å†µä¸‹ï¼ŒGradLiteå¯å°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¿€æ´»å†…å­˜æ¶ˆè€—é™ä½å¤šè¾¾50%ã€‚åœ¨MMLUã€GSM8Kç­‰æ¨ç†ã€å¤šè¯­è¨€å’Œå¯¹è¯åŸºå‡†æµ‹è¯•ä¸­ï¼Œå…¶æ€§èƒ½è¾¾åˆ°æˆ–ä¼˜äºactivation checkpointingä»¥åŠLoMoã€GaLoreç­‰åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.22467v1",
      "published_date": "2025-10-26 00:50:12 UTC",
      "updated_date": "2025-10-26 00:50:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:48:28.276209+00:00"
    },
    {
      "arxiv_id": "2510.22462v2",
      "title": "Learning \"Partner-Aware\" Collaborators in Multi-Party Collaboration",
      "title_zh": "å¤šæ–¹åä½œä¸­â€œä¼™ä¼´æ„ŸçŸ¥å‹â€åä½œä½“çš„å­¦ä¹ ",
      "authors": [
        "Abhijnan Nath",
        "Nikhil Krishnaswamy"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being deployed in agentic settings where they act as collaborators with humans. Therefore, it is increasingly important to be able to evaluate their abilities to collaborate effectively in multi-turn, multi-party tasks. In this paper, we build on the AI alignment and safe interruptibility literature to offer novel theoretical insights on collaborative behavior between LLM-driven collaborator agents and an intervention agent. Our goal is to learn an ideal partner-aware collaborator that increases the group's common-ground (CG) alignment on task-relevant propositions-by intelligently collecting information provided in interventions by a partner agent. We show how LLM agents trained using standard RLHF and related approaches are naturally inclined to ignore possibly well-meaning interventions, which makes increasing group common ground non-trivial in this setting. We employ a two-player Modified-Action MDP to examine this suboptimal behavior of standard AI agents, and propose Interruptible Collaborative Roleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal collaborators. Experiments on multiple collaborative task environments show that ICR, on average, is more capable of promoting successful CG convergence and exploring more diverse solutions in such tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Large Language Models (LLMs) åœ¨å¤šæ–¹åä½œä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ RLHF è®­ç»ƒæ–¹æ³•ä½¿æ™ºèƒ½ä½“å®¹æ˜“å¿½è§†å¹²é¢„ä¿¡æ¯ï¼Œä»è€Œé˜»ç¢å›¢é˜Ÿè¾¾æˆ common-ground (CG) å¯¹é½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…åˆ©ç”¨ Modified-Action MDP ç†è®ºæ¡†æ¶åˆ†æäº†æ™ºèƒ½ä½“çš„æ¬¡ä¼˜è¡Œä¸ºï¼Œå¹¶æå‡ºäº†ä¸€ç§åä¸º Interruptible Collaborative Roleplayer (ICR) çš„æ–°å‹å­¦ä¹ ç®—æ³•ã€‚è¯¥ç®—æ³•æ—¨åœ¨åŸ¹å…»å…·å¤‡ \"Partner-Aware\" èƒ½åŠ›çš„åä½œæ–¹ï¼Œé€šè¿‡æœ‰æ•ˆæ•´åˆåˆä½œä¼™ä¼´æä¾›çš„å¹²é¢„ä¿¡æ¯æ¥å¢å¼ºä»»åŠ¡ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒICR åœ¨å¤šä¸ªåä½œç¯å¢ƒä¸­å‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ä»…æ˜¾è‘—æå‡äº† CG çš„æ”¶æ•›æ•ˆç‡ï¼Œè¿˜å±•ç°å‡ºæ›´å¼ºçš„å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆæ¢ç´¢èƒ½åŠ›ï¼Œä¸ºæ„å»ºé«˜æ•ˆçš„äººæœºåä½œç³»ç»Ÿæä¾›äº†æ–°çš„ç†è®ºè§†è§’å’ŒæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Fixed typographic errors in the previous manuscript",
      "pdf_url": "https://arxiv.org/pdf/2510.22462v2",
      "published_date": "2025-10-26 00:05:48 UTC",
      "updated_date": "2026-01-13 03:18:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T05:48:24.565260+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 93,
  "processed_papers_count": 93,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T05:49:18.126157+00:00"
}