[
  {
    "arxiv_id": "2504.10766v1",
    "title": "How Instruction and Reasoning Data shape Post-Training: Data Quality through the Lens of Layer-wise Gradients",
    "authors": [
      "Ming Li",
      "Yanhong Li",
      "Ziyue Li",
      "Tianyi Zhou"
    ],
    "abstract": "As the post-training of large language models (LLMs) advances from\ninstruction-following to complex reasoning tasks, understanding how different\ndata affect finetuning dynamics remains largely unexplored. In this paper, we\npresent a spectral analysis of layer-wise gradients induced by low/high-quality\ninstruction and reasoning data for LLM post-training. Our analysis reveals that\nwidely-studied metrics for data evaluation, e.g., IFD, InsTag, Difficulty, and\nReward, can be explained and unified by spectral properties computed from\ngradients' singular value decomposition (SVD). Specifically, higher-quality\ndata are usually associated with lower nuclear norms and higher effective\nranks. Notably, effective rank exhibits better robustness and resolution than\nnuclear norm in capturing subtle quality differences. For example, reasoning\ndata achieves substantially higher effective ranks than instruction data,\nimplying richer gradient structures on more complex tasks. Our experiments also\nhighlight that models within the same family share similar gradient patterns\nregardless of their sizes, whereas different model families diverge\nsignificantly. Providing a unified view on the effects of data quality across\ninstruction and reasoning data, this work illuminates the interplay between\ndata quality and training stability, shedding novel insights into developing\nbetter data exploration strategies for post-training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10766v1",
    "published_date": "2025-04-14 23:53:47 UTC",
    "updated_date": "2025-04-14 23:53:47 UTC"
  },
  {
    "arxiv_id": "2504.10753v1",
    "title": "Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning",
    "authors": [
      "Radin Cheraghi",
      "Amir Mohammad Mahfoozi",
      "Sepehr Zolfaghari",
      "Mohammadshayan Shabani",
      "Maryam Ramezani",
      "Hamid R. Rabiee"
    ],
    "abstract": "Recommending items to users has long been a fundamental task, and studies\nhave tried to improve it ever since. Most well-known models commonly employ\nrepresentation learning to map users and items into a unified embedding space\nfor matching assessment. These approaches have primary limitations, especially\nwhen dealing with explicit feedback and sparse data contexts. Two primary\nlimitations are their proneness to overfitting and failure to incorporate\nepistemic uncertainty in predictions. To address these problems, we propose a\nnovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To\nimprove model generalization and quality, we utilize Bayesian Neural Networks,\nwhich incorporate uncertainty within their weight parameters. In addition, we\nintroduce a new interpretable non-linear matching approach for the user and\nitem embeddings, leveraging the advantages of the attention mechanism.\nFurthermore, we endorse the implementation of an ensemble-based supermodel to\ngenerate more robust and reliable predictions, resulting in a more complete\nmodel. Empirical evaluation through extensive experiments and ablation studies\nacross a range of publicly accessible real-world datasets with differing\nsparsity characteristics confirms our proposed method's effectiveness and the\nimportance of its components.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.10753v1",
    "published_date": "2025-04-14 23:04:35 UTC",
    "updated_date": "2025-04-14 23:04:35 UTC"
  },
  {
    "arxiv_id": "2504.10751v1",
    "title": "Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots",
    "authors": [
      "Daniel T. Larsson",
      "Dipankar Maity"
    ],
    "abstract": "In this paper, we develop a systematic framework for the time-sequential\ncompression of dynamic probabilistic occupancy grids. Our approach leverages\nideas from signal compression theory to formulate an optimization problem that\nsearches for a multi-resolution hierarchical encoder that balances the quality\nof the compressed map (distortion) with its description size, the latter of\nwhich relates to the bandwidth required to reliably transmit the map to other\nagents or to store map estimates in on-board memory. The resulting optimization\nproblem allows for multi-resolution map compressions to be obtained that\nsatisfy available communication or memory resources, and does not require\nknowledge of the occupancy map dynamics. We develop an algorithm to solve our\nproblem, and demonstrate the utility of the proposed framework in simulation on\nboth static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10751v1",
    "published_date": "2025-04-14 22:54:29 UTC",
    "updated_date": "2025-04-14 22:54:29 UTC"
  },
  {
    "arxiv_id": "2504.13200v1",
    "title": "Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)",
    "authors": [
      "Mohammad Mahdi Danesh Pajouh"
    ],
    "abstract": "Cancer remains one of the leading causes of mortality worldwide, and among\nits many forms, brain tumors are particularly notorious due to their aggressive\nnature and the critical challenges involved in early diagnosis. Recent advances\nin artificial intelligence have shown great promise in assisting medical\nprofessionals with precise tumor segmentation, a key step in timely diagnosis\nand treatment planning. However, many state-of-the-art segmentation methods\nrequire extensive computational resources and prolonged training times,\nlimiting their practical application in resource-constrained settings. In this\nwork, we present a novel dual-decoder U-Net architecture enhanced with\nattention-gated skip connections, designed specifically for brain tumor\nsegmentation from MRI scans. Our approach balances efficiency and accuracy by\nachieving competitive segmentation performance while significantly reducing\ntraining demands. Evaluated on the BraTS 2020 dataset, the proposed model\nachieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core\n(TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several\ncommonly used U-Net variants. Our model demonstrates that high-quality brain\ntumor segmentation is attainable even under limited computational resources,\nthereby offering a viable solution for researchers and clinicians operating\nwith modest hardware. This resource-efficient model has the potential to\nimprove early detection and diagnosis of brain tumors, ultimately contributing\nto better patient outcomes",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13200v1",
    "published_date": "2025-04-14 22:45:33 UTC",
    "updated_date": "2025-04-14 22:45:33 UTC"
  },
  {
    "arxiv_id": "2504.10746v1",
    "title": "Hearing Anywhere in Any Environment",
    "authors": [
      "Xiulong Liu",
      "Anurag Kumar",
      "Paul Calamia",
      "Sebastia V. Amengual",
      "Calvin Murdock",
      "Ishwarya Ananthabhotla",
      "Philip Robinson",
      "Eli Shlizerman",
      "Vamsi Krishna Ithapu",
      "Ruohan Gao"
    ],
    "abstract": "In mixed reality applications, a realistic acoustic experience in spatial\nenvironments is as crucial as the visual experience for achieving true\nimmersion. Despite recent advances in neural approaches for Room Impulse\nResponse (RIR) estimation, most existing methods are limited to the single\nenvironment on which they are trained, lacking the ability to generalize to new\nrooms with different geometries and surface materials. We aim to develop a\nunified model capable of reconstructing the spatial acoustic experience of any\nenvironment with minimum additional measurements. To this end, we present xRIR,\na framework for cross-room RIR prediction. The core of our generalizable\napproach lies in combining a geometric feature extractor, which captures\nspatial context from panorama depth images, with a RIR encoder that extracts\ndetailed acoustic features from only a few reference RIR samples. To evaluate\nour method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity\nsimulation of over 300,000 RIRs from 260 rooms. Experiments show that our\nmethod strongly outperforms a series of baselines. Furthermore, we successfully\nperform sim-to-real transfer by evaluating our model on four real-world\nenvironments, demonstrating the generalizability of our approach and the\nrealism of our dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.10746v1",
    "published_date": "2025-04-14 22:37:52 UTC",
    "updated_date": "2025-04-14 22:37:52 UTC"
  },
  {
    "arxiv_id": "2504.10738v1",
    "title": "CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates",
    "authors": [
      "Ankit Kumar Shaw",
      "Kun Jiang",
      "Tuopu Wen",
      "Chandan Kumar Sah",
      "Yining Shi",
      "Mengmeng Yang",
      "Diange Yang",
      "Xiaoli Lian"
    ],
    "abstract": "The rapid growth of intelligent connected vehicles (ICVs) and integrated\nvehicle-road-cloud systems has increased the demand for accurate, real-time HD\nmap updates. However, ensuring map reliability remains challenging due to\ninconsistencies in crowdsourced data, which suffer from motion blur, lighting\nvariations, adverse weather, and lane marking degradation. This paper\nintroduces CleanMAP, a Multimodal Large Language Model (MLLM)-based\ndistillation framework designed to filter and refine crowdsourced data for\nhigh-confidence HD map updates. CleanMAP leverages an MLLM-driven lane\nvisibility scoring model that systematically quantifies key visual parameters,\nassigning confidence scores (0-10) based on their impact on lane detection. A\nnovel dynamic piecewise confidence-scoring function adapts scores based on lane\nvisibility, ensuring strong alignment with human evaluations while effectively\nfiltering unreliable data. To further optimize map accuracy, a\nconfidence-driven local map fusion strategy ranks and selects the top-k\nhighest-scoring local maps within an optimal confidence range (best score minus\n10%), striking a balance between data quality and quantity. Experimental\nevaluations on a real-world autonomous vehicle dataset validate CleanMAP's\neffectiveness, demonstrating that fusing the top three local maps achieves the\nlowest mean map update error of 0.28m, outperforming the baseline (0.37m) and\nmeeting stringent accuracy thresholds (<= 0.32m). Further validation with\nreal-vehicle data confirms 84.88% alignment with human evaluators, reinforcing\nthe model's robustness and reliability. This work establishes CleanMAP as a\nscalable and deployable solution for crowdsourced HD map updates, ensuring more\nprecise and reliable autonomous navigation. The code will be available at\nhttps://Ankit-Zefan.github.io/CleanMap/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.RO",
      "I.2.9; I.2.7; I.2.10; I.5.5; I.5.4; I.2.11"
    ],
    "primary_category": "cs.CV",
    "comment": "Kun Jiang, Mengmeng Yang and Diange Yang are Corresponding Author.\n  The main paper and supplementary material are both included here, total 23\n  pages (main paper is 10 pages and supplementary material is 13 pages), total\n  17 figures (6 figures in main paper and 11 figures in supplementary\n  material), this paper is Accepted to CVPR WDFM-AD Workshop 2025, The code\n  will be available at https://Ankit-Zefan.github.io/CleanMap/",
    "pdf_url": "http://arxiv.org/pdf/2504.10738v1",
    "published_date": "2025-04-14 22:16:10 UTC",
    "updated_date": "2025-04-14 22:16:10 UTC"
  },
  {
    "arxiv_id": "2504.10735v2",
    "title": "Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization",
    "authors": [
      "Timur Carstensen",
      "Neeratyoy Mallik",
      "Frank Hutter",
      "Martin Rapp"
    ],
    "abstract": "As model sizes grow, finding efficient and cost-effective hyperparameter\noptimization (HPO) methods becomes increasingly crucial for deep learning\npipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources\nrequired for DL training with lower fidelity estimations, existing fidelity\nsources often fail under lower compute and memory constraints. We propose a\nnovel fidelity source: the number of layers that are trained or frozen during\ntraining. For deep networks, this approach offers significant compute and\nmemory savings while preserving rank correlations between hyperparameters at\nlow fidelities compared to full model training. We demonstrate this in our\nempirical evaluation across ResNets and Transformers and additionally analyze\nthe utility of frozen layers as a fidelity in using GPU resources as a fidelity\nin HPO, and for a combined MF-HPO with other fidelity sources. This\ncontribution opens new applications for MF-HPO with hardware resources as a\nfidelity and creates opportunities for improved algorithms navigating joint\nfidelity spaces.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10735v2",
    "published_date": "2025-04-14 22:06:24 UTC",
    "updated_date": "2025-04-17 12:53:23 UTC"
  },
  {
    "arxiv_id": "2504.11493v1",
    "title": "Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning",
    "authors": [
      "Azizul Zahid",
      "Jie Fan",
      "Farong Wang",
      "Ashton Dy",
      "Sai Swaminathan",
      "Fei Liu"
    ],
    "abstract": "Understanding action correspondence between humans and robots is essential\nfor evaluating alignment in decision-making, particularly in human-robot\ncollaboration and imitation learning within unstructured environments. We\npropose a multimodal demonstration learning framework that explicitly models\nhuman demonstrations from RGB video with robot demonstrations in voxelized\nRGB-D space. Focusing on the \"pick and place\" task from the RH20T dataset, we\nutilize data from 5 users across 10 diverse scenes. Our approach combines\nResNet-based visual encoding for human intention modeling and a Perceiver\nTransformer for voxel-based robot action prediction. After 2000 training\nepochs, the human model reaches 71.67% accuracy, and the robot model achieves\n71.8% accuracy, demonstrating the framework's potential for aligning complex,\nmultimodal human and robot behaviors in manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA'25 Workshop: Human-Centered Robot Learning in the Era of Big\n  Data and Large Models",
    "pdf_url": "http://arxiv.org/pdf/2504.11493v1",
    "published_date": "2025-04-14 21:14:51 UTC",
    "updated_date": "2025-04-14 21:14:51 UTC"
  },
  {
    "arxiv_id": "2504.13199v3",
    "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
    "authors": [
      "Mohammad Saleh",
      "Azadeh Tabatabaei"
    ],
    "abstract": "Objective: This review explores the trustworthiness of multimodal artificial\nintelligence (AI) systems, specifically focusing on vision-language tasks. It\naddresses critical challenges related to fairness, transparency, and ethical\nimplications in these systems, providing a comparative analysis of key tasks\nsuch as Visual Question Answering (VQA), image captioning, and visual dialogue.\nBackground: Multimodal models, particularly vision-language models, enhance\nartificial intelligence (AI) capabilities by integrating visual and textual\ndata, mimicking human learning processes. Despite significant advancements, the\ntrustworthiness of these models remains a crucial concern, particularly as AI\nsystems increasingly confront issues regarding fairness, transparency, and\nethics. Methods: This review examines research conducted from 2017 to 2024\nfocusing on forenamed core vision-language tasks. It employs a comparative\napproach to analyze these tasks through the lens of trustworthiness,\nunderlining fairness, explainability, and ethics. This study synthesizes\nfindings from recent literature to identify trends, challenges, and\nstate-of-the-art solutions. Results: Several key findings were highlighted.\nTransparency: Explainability of vision language tasks is important for user\ntrust. Techniques, such as attention maps and gradient-based methods, have\nsuccessfully addressed this issue. Fairness: Bias mitigation in VQA and visual\ndialogue systems is essential for ensuring unbiased outcomes across diverse\ndemographic groups. Ethical Implications: Addressing biases in multilingual\nmodels and ensuring ethical data handling is critical for the responsible\ndeployment of vision-language systems. Conclusion: This study underscores the\nimportance of integrating fairness, transparency, and ethical considerations in\ndeveloping vision-language models within a unified framework.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13199v3",
    "published_date": "2025-04-14 21:10:25 UTC",
    "updated_date": "2025-05-08 05:10:46 UTC"
  },
  {
    "arxiv_id": "2504.10700v1",
    "title": "Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE",
    "authors": [
      "Jesun Firoz",
      "Franco Pellegrini",
      "Mario Geiger",
      "Darren Hsu",
      "Jenna A. Bilbrey",
      "Han-Yi Chou",
      "Maximilian Stadler",
      "Markus Hoehnerbach",
      "Tingyu Wang",
      "Dejun Lin",
      "Emine Kucukbenli",
      "Henry W. Sprueill",
      "Ilyes Batatia",
      "Sotiris S. Xantheas",
      "MalSoon Lee",
      "Chris Mundy",
      "Gabor Csanyi",
      "Justin S. Smith",
      "Ponnuswamy Sadayappan",
      "Sutanay Choudhury"
    ],
    "abstract": "Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs)\noperating on 3D molecular graph structures are becoming indispensable tools for\ncomputational chemists and materials scientists. These models facilitate the\nunderstanding of matter and the discovery of new molecules and materials. In\ncontrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMs\nprocess a large number of geometric graphs of varying sizes, requiring\ndifferent optimization strategies than those developed for large homogeneous\nGNNs. This paper presents optimizations for two critical phases of CFM\ntraining: data distribution and model training, targeting MACE - a\nstate-of-the-art CFM. We address the challenge of load balancing in data\ndistribution by formulating it as a multi-objective bin packing problem. We\npropose an iterative algorithm that provides a highly effective, fast, and\npractical solution, ensuring efficient data distribution. For the training\nphase, we identify symmetric tensor contraction as the key computational kernel\nin MACE and optimize this kernel to improve the overall performance. Our\ncombined approach of balanced data distribution and kernel optimization\nsignificantly enhances the training process of MACE. Experimental results\ndemonstrate a substantial speedup, reducing per-epoch execution time for\ntraining from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at The 34th ACM International Symposium on High-Performance\n  Parallel and Distributed Computing (HPDC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.10700v1",
    "published_date": "2025-04-14 20:48:19 UTC",
    "updated_date": "2025-04-14 20:48:19 UTC"
  },
  {
    "arxiv_id": "2504.10699v1",
    "title": "HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems",
    "authors": [
      "Nan Wang",
      "Ricardo G. Sanfelice"
    ],
    "abstract": "This paper proposes a bidirectional rapidly-exploring random trees (RRT)\nalgorithm to solve the motion planning problem for hybrid systems. The proposed\nalgorithm, called HyRRT-Connect, propagates in both forward and backward\ndirections in hybrid time until an overlap between the forward and backward\npropagation results is detected. Then, HyRRT-Connect constructs a motion plan\nthrough the reversal and concatenation of functions defined on hybrid time\ndomains, ensuring that the motion plan satisfies the given hybrid dynamics. To\naddress the potential discontinuity along the flow caused by tolerating some\ndistance between the forward and backward partial motion plans, we reconstruct\nthe backward partial motion plan by a forward-in-hybrid-time simulation from\nthe final state of the forward partial motion plan. effectively eliminating the\ndiscontinuity. The proposed algorithm is applied to an actuated bouncing ball\nsystem and a walking robot example to highlight its computational improvement.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "59 pages, 9 figures, submitted to IJRR. arXiv admin note: substantial\n  text overlap with arXiv:2403.18413; text overlap with arXiv:2406.01802",
    "pdf_url": "http://arxiv.org/pdf/2504.10699v1",
    "published_date": "2025-04-14 20:46:54 UTC",
    "updated_date": "2025-04-14 20:46:54 UTC"
  },
  {
    "arxiv_id": "2504.10694v1",
    "title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?",
    "authors": [
      "Kristina Nikolić",
      "Luze Sun",
      "Jie Zhang",
      "Florian Tramèr"
    ],
    "abstract": "Jailbreak attacks bypass the guardrails of large language models to produce\nharmful outputs. In this paper, we ask whether the model outputs produced by\nexisting jailbreaks are actually useful. For example, when jailbreaking a model\nto give instructions for building a bomb, does the jailbreak yield good\ninstructions? Since the utility of most unsafe answers (e.g., bomb\ninstructions) is hard to evaluate rigorously, we build new jailbreak evaluation\nsets with known ground truth answers, by aligning models to refuse questions\nrelated to benign and easy-to-evaluate topics (e.g., biology or math). Our\nevaluation of eight representative jailbreaks across five utility benchmarks\nreveals a consistent drop in model utility in jailbroken responses, which we\nterm the jailbreak tax. For example, while all jailbreaks we tested bypass\nguardrails in models aligned to refuse to answer math, this comes at the\nexpense of a drop of up to 92% in accuracy. Overall, our work proposes the\njailbreak tax as a new important metric in AI safety, and introduces benchmarks\nto evaluate existing and future jailbreaks. We make the benchmark available at\nhttps://github.com/ethz-spylab/jailbreak-tax",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10694v1",
    "published_date": "2025-04-14 20:30:41 UTC",
    "updated_date": "2025-04-14 20:30:41 UTC"
  },
  {
    "arxiv_id": "2504.10685v1",
    "title": "NTIRE 2025 Challenge on Cross-Domain Few-Shot Object Detection: Methods and Results",
    "authors": [
      "Yuqian Fu",
      "Xingyu Qiu",
      "Bin Ren",
      "Yanwei Fu",
      "Radu Timofte",
      "Nicu Sebe",
      "Ming-Hsuan Yang",
      "Luc Van Gool",
      "Kaijin Zhang",
      "Qingpeng Nong",
      "Xiugang Dong",
      "Hong Gao",
      "Xiangsheng Zhou",
      "Jiancheng Pan",
      "Yanxing Liu",
      "Xiao He",
      "Jiahao Li",
      "Yuze Sun",
      "Xiaomeng Huang",
      "Zhenyu Zhang",
      "Ran Ma",
      "Yuhan Liu",
      "Zijian Zhuang",
      "Shuai Yi",
      "Yixiong Zou",
      "Lingyi Hong",
      "Mingxi Chen",
      "Runze Li",
      "Xingdong Sheng",
      "Wenqiang Zhang",
      "Weisen Chen",
      "Yongxin Yan",
      "Xinguo Chen",
      "Yuanjie Shao",
      "Zhengrong Zuo",
      "Nong Sang",
      "Hao Wu",
      "Haoran Sun",
      "Shuming Hu",
      "Yan Zhang",
      "Zhiguang Shi",
      "Yu Zhang",
      "Chao Chen",
      "Tao Wang",
      "Da Feng",
      "Linhai Zhuo",
      "Ziming Lin",
      "Yali Huang",
      "Jie Me",
      "Yiming Yang",
      "Mi Guo",
      "Mingyuan Jiu",
      "Mingliang Xu",
      "Maomao Xiong",
      "Qunshu Zhang",
      "Xinyu Cao",
      "Yuqing Yang",
      "Dianmo Sheng",
      "Xuanpu Zhao",
      "Zhiyu Li",
      "Xuyang Ding",
      "Wenqian Li"
    ],
    "abstract": "Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges\nto existing object detection and few-shot detection models when applied across\ndomains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD\nChallenge, aiming to advance the performance of current object detectors on\nentirely novel target domains with only limited labeled data. The challenge\nattracted 152 registered participants, received submissions from 42 teams, and\nconcluded with 13 teams making valid final submissions. Participants approached\nthe task from diverse perspectives, proposing novel models that achieved new\nstate-of-the-art (SOTA) results under both open-source and closed-source\nsettings. In this report, we present an overview of the 1st NTIRE 2025 CD-FSOD\nChallenge, highlighting the proposed solutions and summarizing the results\nsubmitted by the participants.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by CVPRW 25 @ NTIRE",
    "pdf_url": "http://arxiv.org/pdf/2504.10685v1",
    "published_date": "2025-04-14 20:17:27 UTC",
    "updated_date": "2025-04-14 20:17:27 UTC"
  },
  {
    "arxiv_id": "2504.10679v1",
    "title": "Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content",
    "authors": [
      "F. A. Rizvi",
      "T. Navojith",
      "A. M. N. H. Adhikari",
      "W. P. U. Senevirathna",
      "Dharshana Kasthurirathna",
      "Lakmini Abeywardhana"
    ],
    "abstract": "Brand reputation in the banking sector is maintained through insightful\nanalysis of customer opinion on code-mixed and multilingual content.\nConventional NLP models misclassify or ignore code-mixed text, when mix with\nlow resource languages such as Sinhala-English and fail to capture\ndomain-specific knowledge. This study introduces a hybrid NLP method to improve\nkeyword extraction, content filtering, and aspect-based classification of\nbanking content. Keyword extraction in English is performed with a hybrid\napproach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT\nembeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%.\nCode-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa\nmodel integrated with a domain-specific Sinhala financial vocabulary, and it\nresults in an accuracy of 87.4%. To ensure data quality, irrelevant comment\nfiltering was performed using several models, with the BERT-base-uncased model\nachieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better\nthan GPT-4o, SVM, and keyword-based filtering. Aspect classification followed\nthe same pattern, with the BERT-base-uncased model achieving 87.4% for English\nand XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based\napproaches. These findings confirm that fine-tuned transformer models\noutperform traditional methods in multilingual financial text analysis. The\npresent framework offers an accurate and scalable solution for brand reputation\nmonitoring in code-mixed and low-resource banking environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 Pages, 2 figures, 7 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.10679v1",
    "published_date": "2025-04-14 20:01:34 UTC",
    "updated_date": "2025-04-14 20:01:34 UTC"
  },
  {
    "arxiv_id": "2504.10677v1",
    "title": "Achieving Optimal Tissue Repair Through MARL with Reward Shaping and Curriculum Learning",
    "authors": [
      "Muhammad Al-Zafar Khan",
      "Jamal Al-Karaki"
    ],
    "abstract": "In this paper, we present a multi-agent reinforcement learning (MARL)\nframework for optimizing tissue repair processes using engineered biological\nagents. Our approach integrates: (1) stochastic reaction-diffusion systems\nmodeling molecular signaling, (2) neural-like electrochemical communication\nwith Hebbian plasticity, and (3) a biologically informed reward function\ncombining chemical gradient tracking, neural synchronization, and robust\npenalties. A curriculum learning scheme guides the agent through progressively\ncomplex repair scenarios. In silico experiments demonstrate emergent repair\nstrategies, including dynamic secretion control and spatial coordination.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 4 figures, submitted to the 10th International Conference\n  on Information and Communication Technology for Intelligent Systems (ICTIS)",
    "pdf_url": "http://arxiv.org/pdf/2504.10677v1",
    "published_date": "2025-04-14 19:57:03 UTC",
    "updated_date": "2025-04-14 19:57:03 UTC"
  },
  {
    "arxiv_id": "2504.10663v2",
    "title": "Characterizing Knowledge Manipulation in a Russian Wikipedia Fork",
    "authors": [
      "Mykola Trokhymovych",
      "Oleksandr Kosovan",
      "Nathan Forrester",
      "Pablo Aragón",
      "Diego Saez-Trumper",
      "Ricardo Baeza-Yates"
    ],
    "abstract": "Wikipedia is powered by MediaWiki, a free and open-source software that is\nalso the infrastructure for many other wiki-based online encyclopedias. These\ninclude the recently launched website Ruwiki, which has copied and modified the\noriginal Russian Wikipedia content to conform to Russian law. To identify\npractices and narratives that could be associated with different forms of\nknowledge manipulation, this article presents an in-depth analysis of this\nRussian Wikipedia fork. We propose a methodology to characterize the main\nchanges with respect to the original version. The foundation of this study is a\ncomprehensive comparative analysis of more than 1.9M articles from Russian\nWikipedia and its fork. Using meta-information and geographical, temporal,\ncategorical, and textual features, we explore the changes made by Ruwiki\neditors. Furthermore, we present a classification of the main topics of\nknowledge manipulation in this fork, including a numerical estimation of their\nscope. This research not only sheds light on significant changes within Ruwiki,\nbut also provides a methodology that could be applied to analyze other\nWikipedia forks and similar collaborative projects.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10663v2",
    "published_date": "2025-04-14 19:30:30 UTC",
    "updated_date": "2025-04-21 05:07:13 UTC"
  },
  {
    "arxiv_id": "2504.10660v1",
    "title": "LITERA: An LLM Based Approach to Latin-to-English Translation",
    "authors": [
      "Paul Rosu"
    ],
    "abstract": "This paper introduces an LLM-based Latin-to-English translation platform\ndesigned to address the challenges of translating Latin texts. We named the\nmodel LITERA, which stands for Latin Interpretation and Translations into\nEnglish for Research Assistance. Through a multi-layered translation process\nutilizing a fine-tuned version of GPT-4o-mini and GPT-4o, LITERA offers an\nunprecedented level of accuracy, showcased by greatly improved BLEU scores,\nparticularly in classical Latin, along with improved BLEURT scores. The\ndevelopment of LITERA involved close collaboration with Duke University's\nClassical Studies Department, which was instrumental in creating a small,\nhigh-quality parallel Latin-English dataset. This paper details the\narchitecture, fine-tuning methodology, and prompting strategies used in LITERA,\nemphasizing its ability to produce literal translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL Findings",
    "pdf_url": "http://arxiv.org/pdf/2504.10660v1",
    "published_date": "2025-04-14 19:21:20 UTC",
    "updated_date": "2025-04-14 19:21:20 UTC"
  },
  {
    "arxiv_id": "2504.10655v1",
    "title": "MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery",
    "authors": [
      "Lingyu Kong",
      "Nima Shoghi",
      "Guoxiang Hu",
      "Pan Li",
      "Victor Fung"
    ],
    "abstract": "Geometric machine learning models such as graph neural networks have achieved\nremarkable success in recent years in chemical and materials science research\nfor applications such as high-throughput virtual screening and atomistic\nsimulations. The success of these models can be attributed to their ability to\neffectively learn latent representations of atomic structures directly from the\ntraining data. Conversely, this also results in high data requirements for\nthese models, hindering their application to problems which are data sparse\nwhich are common in this domain. To address this limitation, there is a growing\ndevelopment in the area of pre-trained machine learning models which have\nlearned general, fundamental, geometric relationships in atomistic data, and\nwhich can then be fine-tuned to much smaller application-specific datasets. In\nparticular, models which are pre-trained on diverse, large-scale atomistic\ndatasets have shown impressive generalizability and flexibility to downstream\napplications, and are increasingly referred to as atomistic foundation models.\nTo leverage the untapped potential of these foundation models, we introduce\nMatterTune, a modular and extensible framework that provides advanced\nfine-tuning capabilities and seamless integration of atomistic foundation\nmodels into downstream materials informatics and simulation workflows, thereby\nlowering the barriers to adoption and facilitating diverse applications in\nmaterials science. In its current state, MatterTune supports a number of\nstate-of-the-art foundation models such as ORB, MatterSim, JMP, and\nEquformerV2, and hosts a wide range of features including a modular and\nflexible design, distributed and customizable fine-tuning, broad support for\ndownstream informatics tasks, and more.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10655v1",
    "published_date": "2025-04-14 19:12:43 UTC",
    "updated_date": "2025-04-14 19:12:43 UTC"
  },
  {
    "arxiv_id": "2504.10650v1",
    "title": "Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices",
    "authors": [
      "Éva Székely",
      "Jūra Miniota",
      "Míša",
      "Hejná"
    ],
    "abstract": "The growing prevalence of conversational voice interfaces, powered by\ndevelopments in both speech and language technologies, raises important\nquestions about their influence on human communication. While written\ncommunication can signal identity through lexical and stylistic choices,\nvoice-based interactions inherently amplify socioindexical elements - such as\naccent, intonation, and speech style - which more prominently convey social\nidentity and group affiliation. There is evidence that even passive media such\nas television is likely to influence the audience's linguistic patterns. Unlike\npassive media, conversational AI is interactive, creating a more immersive and\nreciprocal dynamic that holds a greater potential to impact how individuals\nspeak in everyday interactions. Such heightened influence can be expected to\narise from phenomena such as acoustic-prosodic entrainment and linguistic\naccommodation, which occur naturally during interaction and enable users to\nadapt their speech patterns in response to the system. While this phenomenon is\nstill emerging, its potential societal impact could provide organisations,\nmovements, and brands with a subtle yet powerful avenue for shaping and\ncontrolling public perception and social identity. We argue that the\nsocioindexical influence of AI-generated speech warrants attention and should\nbecome a focus of interdisciplinary research, leveraging new and existing\nmethodologies and technologies to better understand its implications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "eess.AS",
      "I.2.7; K.4.2; H.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "5 pages, 0 figures, International Workshop on Spoken Dialogue Systems\n  Technology (IWSDS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.10650v1",
    "published_date": "2025-04-14 19:04:32 UTC",
    "updated_date": "2025-04-14 19:04:32 UTC"
  },
  {
    "arxiv_id": "2504.10649v1",
    "title": "Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics",
    "authors": [
      "Matthew Zalesak",
      "Hins Hu",
      "Samitha Samaranayake"
    ],
    "abstract": "On-demand ride-pooling has emerged as a popular urban transportation\nsolution, addressing the efficiency limitations of traditional ride-hailing\nservices by grouping multiple riding requests with spatiotemporal proximity\ninto a single vehicle. Although numerous algorithms have been developed for the\nRide-pool Assignment Problem (RAP) -- a core component of ride-pooling systems,\nthere is a lack of open-source implementations, making it difficult to\nbenchmark these algorithms on a common dataset and objective. In this paper, we\npresent the implementation details of a ride-pool simulator that encompasses\nseveral key ride-pool assignment algorithms, along with associated components\nsuch as vehicle routing and rebalancing. We also open-source a highly optimized\nand modular C++ codebase, designed to facilitate the extension of new\nalgorithms and features. Additionally, we introduce a family of swapping-based\nlocal-search heuristics to enhance existing ride-pool assignment algorithms,\nachieving a better balance between performance and computational efficiency.\nExtensive experiments on a large-scale, real-world dataset from Manhattan, NYC\nreveal that while all selected algorithms perform comparably, the newly\nproposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE)\nalgorithm achieves a state-of-the-art service rate with significantly reduced\ncomputational time. Furthermore, an in-depth analysis suggests that a\nperformance barrier exists for all myopic ride-pool assignment algorithms due\nto the system's capacity bottleneck, and incorporating future information could\nbe key to overcoming this limitation.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10649v1",
    "published_date": "2025-04-14 19:01:47 UTC",
    "updated_date": "2025-04-14 19:01:47 UTC"
  },
  {
    "arxiv_id": "2504.10646v1",
    "title": "Weight-of-Thought Reasoning: Exploring Neural Network Weights for Enhanced LLM Reasoning",
    "authors": [
      "Saif Punjwani",
      "Larry Heck"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities when prompted with strategies such as Chain-of-Thought (CoT).\nHowever, these approaches focus on token-level output without considering\ninternal weight dynamics. We introduce Weight-of-Thought (WoT) reasoning, a\nnovel approach that examines neural network weights before inference to\nidentify reasoning pathways. Unlike existing methods, WoT explores the weight\nspace through graph-based message passing, multi-step reasoning processes, and\nattention mechanisms. Our implementation creates an interconnected graph of\nreasoning nodes. Experiments on diverse reasoning tasks (syllogistic,\nmathematical, algebraic, combinatorial, and geometric) demonstrate that WoT\nachieves superior performance compared to traditional methods, particularly for\ncomplex problems. This approach leads to both improved performance and greater\ninterpretability of the reasoning process, offering a promising direction for\nenhancing LLM reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10646v1",
    "published_date": "2025-04-14 18:56:29 UTC",
    "updated_date": "2025-04-14 18:56:29 UTC"
  },
  {
    "arxiv_id": "2504.10637v2",
    "title": "Better Estimation of the KL Divergence Between Language Models",
    "authors": [
      "Afra Amini",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "abstract": "Estimating the Kullback--Leibler (KL) divergence between language models has\nmany applications, e.g., reinforcement learning from human feedback (RLHF),\ninterpretability, and knowledge distillation. However, computing the exact KL\ndivergence between two arbitrary language models is intractable. Thus,\npractitioners often resort to the use of sampling-based estimators. While it is\neasy to fashion a simple Monte Carlo (MC) estimator that provides an unbiased\nestimate of the KL divergence between language models, this estimator\nnotoriously suffers from high variance, and can even result in a negative\nestimate of the KL divergence, a non-negative quantity. In this paper, we\nintroduce a Rao--Blackwellized estimator that is also unbiased and provably has\nvariance less than or equal to that of the standard Monte Carlo estimator. In\nan empirical study on sentiment-controlled fine-tuning, we show that our\nestimator provides more stable KL estimates and reduces variance substantially\nin practice. Additionally, we derive an analogous Rao--Blackwellized estimator\nof the gradient of the KL divergence, which leads to more stable training and\nproduces models that more frequently appear on the Pareto frontier of reward\nvs. KL compared to the ones trained with the MC estimator of the gradient.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10637v2",
    "published_date": "2025-04-14 18:40:02 UTC",
    "updated_date": "2025-05-02 23:58:03 UTC"
  },
  {
    "arxiv_id": "2504.10636v1",
    "title": "Who is More Bayesian: Humans or ChatGPT?",
    "authors": [
      "Tianshi Mu",
      "Pranjal Rawat",
      "John Rust",
      "Chengjun Zhang",
      "Qixuan Zhong"
    ],
    "abstract": "We compare the performance of human and artificially intelligent (AI)\ndecision makers in simple binary classification tasks where the optimal\ndecision rule is given by Bayes Rule. We reanalyze choices of human subjects\ngathered from laboratory experiments conducted by El-Gamal and Grether and Holt\nand Smith. We confirm that while overall, Bayes Rule represents the single best\nmodel for predicting human choices, subjects are heterogeneous and a\nsignificant share of them make suboptimal choices that reflect judgement biases\ndescribed by Kahneman and Tversky that include the ``representativeness\nheuristic'' (excessive weight on the evidence from the sample relative to the\nprior) and ``conservatism'' (excessive weight on the prior relative to the\nsample). We compare the performance of AI subjects gathered from recent\nversions of large language models (LLMs) including several versions of ChatGPT.\nThese general-purpose generative AI chatbots are not specifically trained to do\nwell in narrow decision making tasks, but are trained instead as ``language\npredictors'' using a large corpus of textual data from the web. We show that\nChatGPT is also subject to biases that result in suboptimal decisions. However\nwe document a rapid evolution in the performance of ChatGPT from sub-human\nperformance for early versions (ChatGPT 3.5) to superhuman and nearly perfect\nBayesian classifications in the latest versions (ChatGPT 4o).",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC",
      "stat.ME"
    ],
    "primary_category": "econ.GN",
    "comment": "86 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10636v1",
    "published_date": "2025-04-14 18:37:54 UTC",
    "updated_date": "2025-04-14 18:37:54 UTC"
  },
  {
    "arxiv_id": "2504.10612v3",
    "title": "Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling",
    "authors": [
      "Michal Balcerak",
      "Tamaz Amiranashvili",
      "Antonio Terpin",
      "Suprosanna Shit",
      "Lea Bogensperger",
      "Sebastian Kaltenbach",
      "Petros Koumoutsakos",
      "Bjoern Menze"
    ],
    "abstract": "The most widely used generative models map noise and data distributions by\nmatching flows or scores. However, they struggle to incorporate partial\nobservations and additional priors--something energy-based models (EBMs) handle\nelegantly by simply adding corresponding scalar energy terms. We address this\nissue by proposing Energy Matching, a framework that endows flow-based\napproaches with the flexibility of EBMs. Far from the data manifold, samples\nmove along curl-free, optimal transport paths from noise to data. As they\napproach the data manifold, an entropic energy term guides the system into a\nBoltzmann equilibrium distribution, explicitly capturing the underlying\nlikelihood structure of the data. We parameterize this dynamic with a single\ntime-independent scalar field, which serves as both a powerful generator and a\nflexible prior for effective regularization of inverse problems. Our method\nsubstantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in\nterms of fidelity, while retaining simulation-free training of transport-based\napproaches away from the data manifold. Furthermore, we leverage the method's\nflexibility to introduce an interaction energy that supports diverse mode\nexploration, which we demonstrate in a controlled protein-generation setting.\nOur approach focuses on learning a scalar potential energy--without\ntime-conditioning, auxiliary generators, or additional networks--which marks a\nsignificant departure from recent EBM methods. We believe that this simplified\nframework significantly advances EBMs capabilities and paves the way for their\nwider adoption in generative modeling across diverse domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10612v3",
    "published_date": "2025-04-14 18:10:58 UTC",
    "updated_date": "2025-05-22 15:22:06 UTC"
  },
  {
    "arxiv_id": "2504.10584v1",
    "title": "Visual anemometry of natural vegetation from their leaf motion",
    "authors": [
      "Roni H. Goldshmid",
      "John O. Dabiri",
      "John E. Sader"
    ],
    "abstract": "High-resolution, near-ground wind-speed data are critical for improving the\naccuracy of weather predictions and climate models,$^{1-3}$ supporting wildfire\ncontrol efforts,$^{4-7}$ and ensuring the safe passage of airplanes during\ntakeoff and landing maneouvers.$^{8,9}$ Quantitative wind speed anemometry\ngenerally employs on-site instrumentation for accurate single-position data or\nsophisticated remote techniques such as Doppler radar for quantitative field\nmeasurements. It is widely recognized that the wind-induced motion of\nvegetation depends in a complex manner on their structure and mechanical\nproperties, obviating their use in quantitative anemometry.$^{10-14}$ We\nanalyze measurements on a host of different vegetation showing that leaf motion\ncan be decoupled from the leaf's branch and support structure, at\nlow-to-moderate wind speed, $U_{wind}$. This wind speed range is characterized\nby a leaf Reynolds number, enabling the development of a remote, quantitative\nanemometry method based on the formula,\n$U_{wind}\\approx740\\sqrt{{\\mu}U_{leaf}/{\\rho}D}$, that relies only on the leaf\nsize $D$, its measured fluctuating (RMS) speed $U_{leaf}$, the air viscosity\n$\\mu$, and its mass density $\\rho$. This formula is corroborated by a\nfirst-principles model and validated using a host of laboratory and field tests\non diverse vegetation types, ranging from oak, olive, and magnolia trees\nthrough to camphor and bullgrass. The findings of this study open the door to a\nnew paradigm in anemometry, using natural vegetation to enable remote and rapid\nquantitative field measurements at global locations with minimal cost.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10584v1",
    "published_date": "2025-04-14 18:00:02 UTC",
    "updated_date": "2025-04-14 18:00:02 UTC"
  },
  {
    "arxiv_id": "2504.10478v3",
    "title": "Weight Ensembling Improves Reasoning in Language Models",
    "authors": [
      "Xingyu Dang",
      "Christina Baek",
      "Kaiyue Wen",
      "Zico Kolter",
      "Aditi Raghunathan"
    ],
    "abstract": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades off between bias and variance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10478v3",
    "published_date": "2025-04-14 17:59:07 UTC",
    "updated_date": "2025-04-30 07:56:09 UTC"
  },
  {
    "arxiv_id": "2504.10445v1",
    "title": "RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users",
    "authors": [
      "Suyu Ye",
      "Haojun Shi",
      "Darren Shih",
      "Hyokun Yun",
      "Tanya Roosta",
      "Tianmin Shu"
    ],
    "abstract": "To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Project Website: https://scai.cs.jhu.edu/projects/RealWebAssist/\n  Code: https://github.com/SCAI-JHU/RealWebAssist",
    "pdf_url": "http://arxiv.org/pdf/2504.10445v1",
    "published_date": "2025-04-14 17:36:46 UTC",
    "updated_date": "2025-04-14 17:36:46 UTC"
  },
  {
    "arxiv_id": "2504.10443v1",
    "title": "Multimodal Long Video Modeling Based on Temporal Dynamic Context",
    "authors": [
      "Haoran Hao",
      "Jiaming Han",
      "Yiyuan Zhang",
      "Xiangyu Yue"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10443v1",
    "published_date": "2025-04-14 17:34:06 UTC",
    "updated_date": "2025-04-14 17:34:06 UTC"
  },
  {
    "arxiv_id": "2504.10430v1",
    "title": "LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models",
    "authors": [
      "Minqian Liu",
      "Zhiyang Xu",
      "Xinyi Zhang",
      "Heajun An",
      "Sarvech Qadir",
      "Qi Zhang",
      "Pamela J. Wisniewski",
      "Jin-Hee Cho",
      "Sang Won Lee",
      "Ruoxi Jia",
      "Lifu Huang"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.10430v1",
    "published_date": "2025-04-14 17:20:34 UTC",
    "updated_date": "2025-04-14 17:20:34 UTC"
  },
  {
    "arxiv_id": "2504.10421v1",
    "title": "Can We Edit LLMs for Long-Tail Biomedical Knowledge?",
    "authors": [
      "Xinhao Yi",
      "Jake Lever",
      "Kevin Bryson",
      "Zaiqiao Meng"
    ],
    "abstract": "Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10421v1",
    "published_date": "2025-04-14 17:08:20 UTC",
    "updated_date": "2025-04-14 17:08:20 UTC"
  },
  {
    "arxiv_id": "2504.10415v1",
    "title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models",
    "authors": [
      "Parshin Shojaee",
      "Ngoc-Hieu Nguyen",
      "Kazem Meidani",
      "Amir Barati Farimani",
      "Khoa D Doan",
      "Chandan K Reddy"
    ],
    "abstract": "Scientific equation discovery is a fundamental task in the history of\nscientific progress, enabling the derivation of laws governing natural\nphenomena. Recently, Large Language Models (LLMs) have gained interest for this\ntask due to their potential to leverage embedded scientific knowledge for\nhypothesis generation. However, evaluating the true discovery capabilities of\nthese methods remains challenging, as existing benchmarks often rely on common\nequations that are susceptible to memorization by LLMs, leading to inflated\nperformance metrics that do not reflect discovery. In this paper, we introduce\nLLM-SRBench, a comprehensive benchmark with 239 challenging problems across\nfour scientific domains specifically designed to evaluate LLM-based scientific\nequation discovery methods while preventing trivial memorization. Our benchmark\ncomprises two main categories: LSR-Transform, which transforms common physical\nmodels into less common mathematical representations to test reasoning beyond\nmemorized forms, and LSR-Synth, which introduces synthetic, discovery-driven\nproblems requiring data-driven reasoning. Through extensive evaluation of\nseveral state-of-the-art methods, using both open and closed LLMs, we find that\nthe best-performing system so far achieves only 31.5% symbolic accuracy. These\nfindings highlight the challenges of scientific equation discovery, positioning\nLLM-SRBench as a valuable resource for future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project page:\n  https://github.com/deep-symbolic-mathematics/llm-srbench , Benchmark page:\n  https://huggingface.co/datasets/nnheui/llm-srbench",
    "pdf_url": "http://arxiv.org/pdf/2504.10415v1",
    "published_date": "2025-04-14 17:00:13 UTC",
    "updated_date": "2025-04-14 17:00:13 UTC"
  },
  {
    "arxiv_id": "2504.10412v1",
    "title": "AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability",
    "authors": [
      "Gopichand Bandarupalli"
    ],
    "abstract": "This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10412v1",
    "published_date": "2025-04-14 16:58:54 UTC",
    "updated_date": "2025-04-14 16:58:54 UTC"
  },
  {
    "arxiv_id": "2504.10405v1",
    "title": "Performance of Large Language Models in Supporting Medical Diagnosis and Treatment",
    "authors": [
      "Diogo Sousa",
      "Guilherme Barbosa",
      "Catarina Rocha",
      "Dulce Oliveira"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 6 figures, 4 tables. Acknowledgements: The authors\n  acknowledge the support of the AITriage4SU Project (2024.07400.IACDC/2024),\n  funded by the FCT (Foundation for Science and Technology), Portugal",
    "pdf_url": "http://arxiv.org/pdf/2504.10405v1",
    "published_date": "2025-04-14 16:53:59 UTC",
    "updated_date": "2025-04-14 16:53:59 UTC"
  },
  {
    "arxiv_id": "2504.10397v1",
    "title": "Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?",
    "authors": [
      "Olha Shaposhnyk",
      "Daria Zahorska",
      "Svetlana Yanushkevich"
    ],
    "abstract": "Objective: This study investigates the potential of Large Language Models\n(LLMs) as an alternative to human expert elicitation for extracting structured\ncausal knowledge and facilitating causal modeling in biometric and healthcare\napplications.\n  Material and Methods: LLM-generated causal structures, specifically Bayesian\nnetworks (BNs), were benchmarked against traditional statistical methods (e.g.,\nBayesian Information Criterion) using healthcare datasets. Validation\ntechniques included structural equation modeling (SEM) to verifying\nrelationships, and measures such as entropy, predictive accuracy, and\nrobustness to compare network structures.\n  Results and Discussion: LLM-generated BNs demonstrated lower entropy than\nexpert-elicited and statistically generated BNs, suggesting higher confidence\nand precision in predictions. However, limitations such as contextual\nconstraints, hallucinated dependencies, and potential biases inherited from\ntraining data require further investigation.\n  Conclusion: LLMs represent a novel frontier in expert elicitation for\nprobabilistic causal modeling, promising to improve transparency and reduce\nuncertainty in the decision-making using such models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10397v1",
    "published_date": "2025-04-14 16:45:52 UTC",
    "updated_date": "2025-04-14 16:45:52 UTC"
  },
  {
    "arxiv_id": "2504.10390v1",
    "title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain",
    "authors": [
      "Fangcheng Jin",
      "Yuqi Wang",
      "Peixin Ma",
      "Guodong Yang",
      "Pan Zhao",
      "En Li",
      "Zhengtao Zhang"
    ],
    "abstract": "Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.10390v1",
    "published_date": "2025-04-14 16:36:56 UTC",
    "updated_date": "2025-04-14 16:36:56 UTC"
  },
  {
    "arxiv_id": "2504.10369v1",
    "title": "SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning",
    "authors": [
      "Yiting Wang",
      "Wanghao Ye",
      "Ping Guo",
      "Yexiao He",
      "Ziyao Wang",
      "Yexiao He",
      "Bowei Tian",
      "Shwai He",
      "Guoheng Sun",
      "Zheyu Shen",
      "Sihan Chen",
      "Ankur Srivastava",
      "Qingfu Zhang",
      "Gang Qu",
      "Ang Li"
    ],
    "abstract": "Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "16 pages, 8 figures, 7 tables. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.10369v1",
    "published_date": "2025-04-14 16:15:55 UTC",
    "updated_date": "2025-04-14 16:15:55 UTC"
  },
  {
    "arxiv_id": "2504.10368v2",
    "title": "S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models",
    "authors": [
      "Wenyuan Zhang",
      "Shuaiyi Nie",
      "Xinghua Zhang",
      "Zefeng Zhang",
      "Tingwen Liu"
    ],
    "abstract": "We introduce S1-Bench, a novel benchmark designed to evaluate the performance\nof Large Reasoning Models (LRMs) on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their heavy reliance on system 2 thinking may limit their system 1\nthinking capabilities. However, there is a lack of an appropriate benchmark for\nevaluating LRM's system 1 thinking capabilities. To fill this gap, S1-Bench\nintroduces a suite of simple, diverse, and natural questions across multiple\ndomains and languages, specifically designed to assess LRMs' performance on\nquestions more suitable for system 1 . We conduct extensive evaluations across\n28 LRMs, revealing their inefficiency, inadequate accuracy, and limited\nrobustness when handling simple questions. Additionally, we observe a gap\nbetween their difficulty perception and generation length. Overall, this work\npaves the way toward dual-system compatibility in the development of LRMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 9 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.10368v2",
    "published_date": "2025-04-14 16:13:23 UTC",
    "updated_date": "2025-05-20 16:52:53 UTC"
  },
  {
    "arxiv_id": "2504.16101v1",
    "title": "xLSTM-ECG: Multi-label ECG Classification via Feature Fusion with xLSTM",
    "authors": [
      "Lei Kang",
      "Xuanshuo Fu",
      "Javier Vazquez-Corral",
      "Ernest Valveny",
      "Dimosthenis Karatzas"
    ],
    "abstract": "Cardiovascular diseases (CVDs) remain the leading cause of mortality\nworldwide, highlighting the critical need for efficient and accurate diagnostic\ntools. Electrocardiograms (ECGs) are indispensable in diagnosing various heart\nconditions; however, their manual interpretation is time-consuming and\nerror-prone. In this paper, we propose xLSTM-ECG, a novel approach that\nleverages an extended Long Short-Term Memory (xLSTM) network for multi-label\nclassification of ECG signals, using the PTB-XL dataset. To the best of our\nknowledge, this work represents the first design and application of xLSTM\nmodules specifically adapted for multi-label ECG classification. Our method\nemploys a Short-Time Fourier Transform (STFT) to convert time-series ECG\nwaveforms into the frequency domain, thereby enhancing feature extraction. The\nxLSTM architecture is specifically tailored to address the complexities of\n12-lead ECG recordings by capturing both local and global signal features.\nComprehensive experiments on the PTB-XL dataset reveal that our model achieves\nstrong multi-label classification performance, while additional tests on the\nGeorgia 12-Lead dataset underscore its robustness and efficiency. This approach\nsignificantly improves ECG classification accuracy, thereby advancing clinical\ndiagnostics and patient care. The code will be publicly available upon\nacceptance.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16101v1",
    "published_date": "2025-04-14 16:12:46 UTC",
    "updated_date": "2025-04-14 16:12:46 UTC"
  },
  {
    "arxiv_id": "2504.10358v1",
    "title": "FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos",
    "authors": [
      "Rui Chen",
      "Lei Sun",
      "Jing Tang",
      "Geng Li",
      "Xiangxiang Chu"
    ],
    "abstract": "Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10358v1",
    "published_date": "2025-04-14 16:07:16 UTC",
    "updated_date": "2025-04-14 16:07:16 UTC"
  },
  {
    "arxiv_id": "2504.10340v2",
    "title": "Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families",
    "authors": [
      "Shahriar Noroozizadeh",
      "Sayantan Kumar",
      "Jeremy C. Weiss"
    ],
    "abstract": "Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings -- extracted via an\nLLM-assisted annotation pipeline -- serve as the primary input for prediction.\nWe systematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Machine Learning for Healthcare (MLHC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.10340v2",
    "published_date": "2025-04-14 15:48:56 UTC",
    "updated_date": "2025-04-20 19:03:57 UTC"
  },
  {
    "arxiv_id": "2504.10337v2",
    "title": "Heimdall: test-time scaling on the generative verification",
    "authors": [
      "Wenlei Shi",
      "Xing Jin"
    ],
    "abstract": "An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10337v2",
    "published_date": "2025-04-14 15:46:33 UTC",
    "updated_date": "2025-04-16 14:58:26 UTC"
  },
  {
    "arxiv_id": "2504.10326v1",
    "title": "AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference",
    "authors": [
      "Yangshen Deng",
      "Zhengxin You",
      "Long Xiang",
      "Qilong Li",
      "Peiqi Yuan",
      "Zhaoyang Hong",
      "Yitao Zheng",
      "Wanting Li",
      "Runzhong Li",
      "Haotian Liu",
      "Kyriakos Mouratidis",
      "Man Lung Yiu",
      "Huan Li",
      "Qiaomu Shen",
      "Rui Mao",
      "Bo Tang"
    ],
    "abstract": "AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "H.3.1; H.3.2; H.3.3; H.3.4"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 12 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2504.10326v1",
    "published_date": "2025-04-14 15:34:26 UTC",
    "updated_date": "2025-04-14 15:34:26 UTC"
  },
  {
    "arxiv_id": "2504.16100v1",
    "title": "Towards Accurate Forecasting of Renewable Energy : Building Datasets and Benchmarking Machine Learning Models for Solar and Wind Power in France",
    "authors": [
      "Eloi Lindas",
      "Yannig Goude",
      "Philippe Ciais"
    ],
    "abstract": "Accurate prediction of non-dispatchable renewable energy sources is essential\nfor grid stability and price prediction. Regional power supply forecasts are\nusually indirect through a bottom-up approach of plant-level forecasts,\nincorporate lagged power values, and do not use the potential of spatially\nresolved data. This study presents a comprehensive methodology for predicting\nsolar and wind power production at country scale in France using machine\nlearning models trained with spatially explicit weather data combined with\nspatial information about production sites capacity. A dataset is built\nspanning from 2012 to 2023, using daily power production data from RTE (the\nnational grid operator) as the target variable, with daily weather data from\nERA5, production sites capacity and location, and electricity prices as input\nfeatures. Three modeling approaches are explored to handle spatially resolved\nweather data: spatial averaging over the country, dimension reduction through\nprincipal component analysis, and a computer vision architecture to exploit\ncomplex spatial relationships. The study benchmarks state-of-the-art machine\nlearning models as well as hyperparameter tuning approaches based on\ncross-validation methods on daily power production data. Results indicate that\ncross-validation tailored to time series is best suited to reach low error. We\nfound that neural networks tend to outperform traditional tree-based models,\nwhich face challenges in extrapolation due to the increasing renewable capacity\nover time. Model performance ranges from 4% to 10% in nRMSE for midterm\nhorizon, achieving similar error metrics to local models established at a\nsingle-plant level, highlighting the potential of these methods for regional\npower supply forecasting.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.SP",
    "comment": "24 pages, 4 tables, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16100v1",
    "published_date": "2025-04-14 15:30:54 UTC",
    "updated_date": "2025-04-14 15:30:54 UTC"
  },
  {
    "arxiv_id": "2504.10561v2",
    "title": "Self-Controlled Dynamic Expansion Model for Continual Learning",
    "authors": [
      "Runqing Wu",
      "Kaihui Huang",
      "Hanyi Zhang",
      "Fei Ye"
    ],
    "abstract": "Continual Learning (CL) epitomizes an advanced training paradigm wherein\nprior data samples remain inaccessible during the acquisition of new tasks.\nNumerous investigations have delved into leveraging a pre-trained Vision\nTransformer (ViT) to enhance model efficacy in continual learning. Nonetheless,\nthese approaches typically utilize a singular, static backbone, which\ninadequately adapts to novel tasks, particularly when engaging with diverse\ndata domains, due to a substantial number of inactive parameters. This paper\naddresses this limitation by introducing an innovative Self-Controlled Dynamic\nExpansion Model (SCDEM), which orchestrates multiple distinct trainable\npre-trained ViT backbones to furnish diverse and semantically enriched\nrepresentations. Specifically, by employing the multi-backbone architecture as\na shared module, the proposed SCDEM dynamically generates a new expert with\nminimal parameters to accommodate a new task. A novel Collaborative\nOptimization Mechanism (COM) is introduced to synergistically optimize multiple\nbackbones by harnessing prediction signals from historical experts, thereby\nfacilitating new task learning without erasing previously acquired knowledge.\nAdditionally, a novel Feature Distribution Consistency (FDC) approach is\nproposed to align semantic similarity between previously and currently learned\nrepresentations through an optimal transport distance-based mechanism,\neffectively mitigating negative knowledge transfer effects. Furthermore, to\nalleviate over-regularization challenges, this paper presents a novel Dynamic\nLayer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the\npenalization intensity on each trainable representation layer. An extensive\nseries of experiments have been conducted to evaluate the proposed\nmethodology's efficacy, with empirical results corroborating that the approach\nattains state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, 6 tables, Continual Learning, Cross-Domain\n  Continual Learning, Mixture Model",
    "pdf_url": "http://arxiv.org/pdf/2504.10561v2",
    "published_date": "2025-04-14 15:22:51 UTC",
    "updated_date": "2025-04-16 01:13:45 UTC"
  },
  {
    "arxiv_id": "2504.10309v1",
    "title": "AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis",
    "authors": [
      "Dan Luo",
      "Chengyuan Ma",
      "Weiqin Li",
      "Jun Wang",
      "Wei Chen",
      "Zhiyong Wu"
    ],
    "abstract": "With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted by ICME25",
    "pdf_url": "http://arxiv.org/pdf/2504.10309v1",
    "published_date": "2025-04-14 15:18:59 UTC",
    "updated_date": "2025-04-14 15:18:59 UTC"
  },
  {
    "arxiv_id": "2504.21008v1",
    "title": "Research on CNN-BiLSTM Network Traffic Anomaly Detection Model Based on MindSpore",
    "authors": [
      "Qiuyan Xiang",
      "Shuang Wu",
      "Dongze Wu",
      "Yuxin Liu",
      "Zhenkai Qin"
    ],
    "abstract": "With the widespread adoption of the Internet of Things (IoT) and Industrial\nIoT (IIoT) technologies, network architectures have become increasingly\ncomplex, and the volume of traffic has grown substantially. This evolution\nposes significant challenges to traditional security mechanisms, particularly\nin detecting high-frequency, diverse, and highly covert network attacks. To\naddress these challenges, this study proposes a novel network traffic anomaly\ndetection model that integrates a Convolutional Neural Network (CNN) with a\nBidirectional Long Short-Term Memory (BiLSTM) network, implemented on the\nMindSpore framework. Comprehensive experiments were conducted using the\nNF-BoT-IoT dataset. The results demonstrate that the proposed model achieves\n99% across accuracy, precision, recall, and F1-score, indicating its strong\nperformance and robustness in network intrusion detection tasks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21008v1",
    "published_date": "2025-04-14 15:10:18 UTC",
    "updated_date": "2025-04-14 15:10:18 UTC"
  },
  {
    "arxiv_id": "2504.10559v1",
    "title": "Efficient Process Reward Model Training via Active Learning",
    "authors": [
      "Keyu Duan",
      "Zichen Liu",
      "Xin Mao",
      "Tianyu Pang",
      "Changyu Chen",
      "Qiguang Chen",
      "Michael Qizhe Shieh",
      "Longxu Dou"
    ],
    "abstract": "Process Reward Models (PRMs) provide step-level supervision to large language\nmodels (LLMs), but scaling up training data annotation remains challenging for\nboth humans and LLMs. To address this limitation, we propose an active learning\napproach, ActPRM, which proactively selects the most uncertain samples for\ntraining, substantially reducing labeling costs. During training, we use the\nPRM to estimate uncertainty after the forward pass, retaining only highly\nuncertain data. A capable yet costly reasoning model then labels this data.\nThen we compute the loss with respect to the labels and update the PRM's\nweights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active\nlearning setting, demonstrating that ActPRM reduces 50% annotation, but\nachieving the comparable or even better performance. Beyond annotation\nefficiency, we further advance the actively trained PRM by filtering over 1M+\nmath reasoning trajectories with ActPRM, retaining 60% of the data. A\nsubsequent training on this selected dataset yields a new state-of-the-art\n(SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same\nsized models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10559v1",
    "published_date": "2025-04-14 14:53:56 UTC",
    "updated_date": "2025-04-14 14:53:56 UTC"
  },
  {
    "arxiv_id": "2504.10286v1",
    "title": "Characterizing LLM-driven Social Network: The Chirper.ai Case",
    "authors": [
      "Yiming Zhu",
      "Yupeng He",
      "Ehsan-Ul Haq",
      "Gareth Tyson",
      "Pan Hui"
    ],
    "abstract": "Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.10286v1",
    "published_date": "2025-04-14 14:53:31 UTC",
    "updated_date": "2025-04-14 14:53:31 UTC"
  },
  {
    "arxiv_id": "2504.10281v1",
    "title": "Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials",
    "authors": [
      "Jingyun Yang",
      "Ruoyan Avery Yin",
      "Chi Jiang",
      "Yuepeng Hu",
      "Xiaokai Zhu",
      "Xingjian Hu",
      "Sutharsika Kumar",
      "Xiao Wang",
      "Xiaohua Zhai",
      "Keran Rong",
      "Yunyue Zhu",
      "Tianyi Zhang",
      "Zongyou Yin",
      "Jing Kong",
      "Neil Zhenqiang Gong",
      "Zhichu Ren",
      "Haozhe Wang"
    ],
    "abstract": "Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "13 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10281v1",
    "published_date": "2025-04-14 14:49:45 UTC",
    "updated_date": "2025-04-14 14:49:45 UTC"
  },
  {
    "arxiv_id": "2504.10277v1",
    "title": "RealHarm: A Collection of Real-World Language Model Application Failures",
    "authors": [
      "Pierre Le Jeune",
      "Jiaen Liu",
      "Luca Rossi",
      "Matteo Dora"
    ],
    "abstract": "Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10277v1",
    "published_date": "2025-04-14 14:44:41 UTC",
    "updated_date": "2025-04-14 14:44:41 UTC"
  },
  {
    "arxiv_id": "2504.10266v1",
    "title": "Vision based driving agent for race car simulation environments",
    "authors": [
      "Gergely Bári",
      "László Palkovics"
    ],
    "abstract": "In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to ICMCE 2024 (https://icmce.org/2024.html)",
    "pdf_url": "http://arxiv.org/pdf/2504.10266v1",
    "published_date": "2025-04-14 14:29:37 UTC",
    "updated_date": "2025-04-14 14:29:37 UTC"
  },
  {
    "arxiv_id": "2504.10254v1",
    "title": "MASSeg : 2nd Technical Report for 4th PVUW MOSE Track",
    "authors": [
      "Xuqiang Cao",
      "Linnan Zhao",
      "Jiaxuan Zhao",
      "Fang Liu",
      "Puhua Chen",
      "Wenping Ma"
    ],
    "abstract": "Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages,4 figures,Technical report on Complex Video Object\n  Segmentation",
    "pdf_url": "http://arxiv.org/pdf/2504.10254v1",
    "published_date": "2025-04-14 14:15:46 UTC",
    "updated_date": "2025-04-14 14:15:46 UTC"
  },
  {
    "arxiv_id": "2504.10557v1",
    "title": "The Code Barrier: What LLMs Actually Understand?",
    "authors": [
      "Serge Lionel Nikiema",
      "Jordan Samhi",
      "Abdoul Kader Kaboré",
      "Jacques Klein",
      "Tegawendé F. Bissyandé"
    ],
    "abstract": "Understanding code represents a core ability needed for automating software\ndevelopment tasks. While foundation models like LLMs show impressive results\nacross many software engineering challenges, the extent of their true semantic\nunderstanding beyond simple token recognition remains unclear. This research\nuses code obfuscation as a structured testing framework to evaluate LLMs'\nsemantic understanding capabilities. We methodically apply controlled\nobfuscation changes to source code and measure comprehension through two\ncomplementary tasks: generating accurate descriptions of obfuscated code and\nperforming deobfuscation, a skill with important implications for reverse\nengineering applications.\n  Our testing approach includes 13 cutting-edge models, covering both\ncode-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o)\narchitectures, evaluated on a benchmark created from CodeNet and consisting of\nfiltered 250 Java programming problems and their solutions. Findings show a\nstatistically significant performance decline as obfuscation complexity\nincreases, with unexpected resilience shown by general-purpose models compared\nto their code-focused counterparts. While some models successfully identify\nobfuscation techniques, their ability to reconstruct the underlying program\nlogic remains constrained, suggesting limitations in their semantic\nrepresentation mechanisms. This research introduces a new evaluation approach\nfor assessing code comprehension in language models and establishes empirical\nbaselines for advancing research in security-critical code analysis\napplications such as reverse engineering and adversarial code analysis.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10557v1",
    "published_date": "2025-04-14 14:11:26 UTC",
    "updated_date": "2025-04-14 14:11:26 UTC"
  },
  {
    "arxiv_id": "2504.13928v1",
    "title": "LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms",
    "authors": [
      "Li Song"
    ],
    "abstract": "NPCs in traditional games are often limited by static dialogue trees and a\nsingle platform for interaction. To overcome these constraints, this study\npresents a prototype system that enables large language model (LLM)-powered\nNPCs to communicate with players both in the game en vironment (Unity) and on a\nsocial platform (Discord). Dialogue logs are stored in a cloud database\n(LeanCloud), allowing the system to synchronize memory between platforms and\nkeep conversa tions coherent. Our initial experiments show that cross-platform\ninteraction is technically feasible and suggest a solid foundation for future\ndevelopments such as emotional modeling and persistent memory support.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13928v1",
    "published_date": "2025-04-14 14:06:26 UTC",
    "updated_date": "2025-04-14 14:06:26 UTC"
  },
  {
    "arxiv_id": "2504.10556v1",
    "title": "VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification",
    "authors": [
      "Lucas Heublein",
      "Simon Kocher",
      "Tobias Feigl",
      "Alexander Rügamer",
      "Christopher Mutschler",
      "Felix Ott"
    ],
    "abstract": "Distributed learning and Edge AI necessitate efficient data processing,\nlow-latency communication, decentralized model training, and stringent data\nprivacy to facilitate real-time intelligence on edge devices while reducing\ndependency on centralized infrastructure and ensuring high model performance.\nIn the context of global navigation satellite system (GNSS) applications, the\nprimary objective is to accurately monitor and classify interferences that\ndegrade system performance in distributed environments, thereby enhancing\nsituational awareness. To achieve this, machine learning (ML) models can be\ndeployed on low-resource devices, ensuring minimal communication latency and\npreserving data privacy. The key challenge is to compress ML models while\nmaintaining high classification accuracy. In this paper, we propose variational\nautoencoders (VAEs) for disentanglement to extract essential latent features\nthat enable accurate classification of interferences. We demonstrate that the\ndisentanglement approach can be leveraged for both data compression and data\naugmentation by interpolating the lower-dimensional latent representations of\nsignal power. To validate our approach, we evaluate three VAE variants -\nvanilla, factorized, and conditional generative - on four distinct datasets,\nincluding two collected in controlled indoor environments and two real-world\nhighway datasets. Additionally, we conduct extensive hyperparameter searches to\noptimize performance. Our proposed VAE achieves a data compression rate ranging\nfrom 512 to 8,192 and achieves an accuracy up to 99.92%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "94-05, 82-11",
      "E.0; I.2.0; I.5.4; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10556v1",
    "published_date": "2025-04-14 13:38:00 UTC",
    "updated_date": "2025-04-14 13:38:00 UTC"
  },
  {
    "arxiv_id": "2504.10210v1",
    "title": "Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?",
    "authors": [
      "Yuxuan Zhang",
      "Yangyang Feng",
      "Daifeng Li",
      "Kexin Zhang",
      "Junlan Chen",
      "Bowen Deng"
    ],
    "abstract": "Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10210v1",
    "published_date": "2025-04-14 13:25:50 UTC",
    "updated_date": "2025-04-14 13:25:50 UTC"
  },
  {
    "arxiv_id": "2504.10555v1",
    "title": "Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains",
    "authors": [
      "Marco Salmè",
      "Lorenzo Tronchin",
      "Rosa Sicilia",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "Data scarcity remains a critical bottleneck impeding technological\nadvancements across various domains, including but not limited to medicine and\nprecision agriculture. To address this challenge, we explore the potential of\nDeep Generative Models (DGMs) in producing synthetic data that satisfies the\nGenerative Learning Trilemma: fidelity, diversity, and sampling efficiency.\nHowever, recognizing that these criteria alone are insufficient for practical\napplications, we extend the trilemma to include utility, robustness, and\nprivacy, factors crucial for ensuring the applicability of DGMs in real-world\nscenarios. Evaluating these metrics becomes particularly challenging in\ndata-scarce environments, as DGMs traditionally rely on large datasets to\nperform optimally. This limitation is especially pronounced in domains like\nmedicine and precision agriculture, where ensuring acceptable model performance\nunder data constraints is vital. To address these challenges, we assess the\nGenerative Learning Trilemma in data-scarcity settings using state-of-the-art\nevaluation metrics, comparing three prominent DGMs: Variational Autoencoders\n(VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs).\nFurthermore, we propose a comprehensive framework to assess utility,\nrobustness, and privacy in synthetic data generated by DGMs. Our findings\ndemonstrate varying strengths among DGMs, with each model exhibiting unique\nadvantages based on the application context. This study broadens the scope of\nthe Generative Learning Trilemma, aligning it with real-world demands and\nproviding actionable guidance for selecting DGMs tailored to specific\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10555v1",
    "published_date": "2025-04-14 13:15:44 UTC",
    "updated_date": "2025-04-14 13:15:44 UTC"
  },
  {
    "arxiv_id": "2504.10191v1",
    "title": "Localized Cultural Knowledge is Conserved and Controllable in Large Language Models",
    "authors": [
      "Veniamin Veselovsky",
      "Berke Argin",
      "Benedikt Stroebl",
      "Chris Wendler",
      "Robert West",
      "James Evans",
      "Thomas L. Griffiths",
      "Arvind Narayanan"
    ],
    "abstract": "Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10191v1",
    "published_date": "2025-04-14 12:53:58 UTC",
    "updated_date": "2025-04-14 12:53:58 UTC"
  },
  {
    "arxiv_id": "2504.10188v1",
    "title": "Efficient Generative Model Training via Embedded Representation Warmup",
    "authors": [
      "Deyuan Liu",
      "Peng Sun",
      "Xufeng Li",
      "Tao Lin"
    ],
    "abstract": "Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10188v1",
    "published_date": "2025-04-14 12:43:17 UTC",
    "updated_date": "2025-04-14 12:43:17 UTC"
  },
  {
    "arxiv_id": "2504.10187v1",
    "title": "Deep Reasoning Translation via Reinforcement Learning",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "abstract": "Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10187v1",
    "published_date": "2025-04-14 12:40:39 UTC",
    "updated_date": "2025-04-14 12:40:39 UTC"
  },
  {
    "arxiv_id": "2504.10185v2",
    "title": "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks",
    "authors": [
      "Soumyadeep Pal",
      "Changsheng Wang",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Sijia Liu"
    ],
    "abstract": "Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10185v2",
    "published_date": "2025-04-14 12:38:37 UTC",
    "updated_date": "2025-04-16 14:45:55 UTC"
  },
  {
    "arxiv_id": "2504.10179v1",
    "title": "The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance",
    "authors": [
      "Anwesha Mohanty",
      "Venkatesh Balavadhani Parthasarathy",
      "Arsalan Shahid"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10179v1",
    "published_date": "2025-04-14 12:31:39 UTC",
    "updated_date": "2025-04-14 12:31:39 UTC"
  },
  {
    "arxiv_id": "2504.10168v1",
    "title": "HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for Hallucination Detection",
    "authors": [
      "Mohamed A. Abdallah",
      "Samhaa R. El-Beltagy"
    ],
    "abstract": "In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10168v1",
    "published_date": "2025-04-14 12:22:30 UTC",
    "updated_date": "2025-04-14 12:22:30 UTC"
  },
  {
    "arxiv_id": "2504.10167v1",
    "title": "C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation",
    "authors": [
      "Xu Zhang",
      "Zhifei Liu",
      "Jiahao Wang",
      "Huixuan Zhang",
      "Fan Xu",
      "Junzhe Zhang",
      "Xiaojun Wan"
    ],
    "abstract": "Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10167v1",
    "published_date": "2025-04-14 12:21:55 UTC",
    "updated_date": "2025-04-14 12:21:55 UTC"
  },
  {
    "arxiv_id": "2504.10165v2",
    "title": "WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs",
    "authors": [
      "Nguyen Ngoc Dat",
      "Tom Richardson",
      "Matthew Watson",
      "Kilian Meier",
      "Jenna Kline",
      "Sid Reid",
      "Guy Maalouf",
      "Duncan Hine",
      "Majid Mirmehdi",
      "Tilo Burghardt"
    ],
    "abstract": "Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our materials are available at:\nhttps://dat-nguyenvn.github.io/WildLive/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10165v2",
    "published_date": "2025-04-14 12:21:16 UTC",
    "updated_date": "2025-04-15 12:06:09 UTC"
  },
  {
    "arxiv_id": "2504.10160v1",
    "title": "MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning",
    "authors": [
      "Zhaopeng Feng",
      "Shaosheng Cao",
      "Jiahan Ren",
      "Jiayuan Su",
      "Ruizhe Chen",
      "Yan Zhang",
      "Zhe Xu",
      "Yao Hu",
      "Jian Wu",
      "Zuozhu Liu"
    ],
    "abstract": "Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Our code is available at\n  https://github.com/fzp0424/MT-R1-Zero",
    "pdf_url": "http://arxiv.org/pdf/2504.10160v1",
    "published_date": "2025-04-14 12:14:18 UTC",
    "updated_date": "2025-04-14 12:14:18 UTC"
  },
  {
    "arxiv_id": "2504.10158v1",
    "title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts",
    "authors": [
      "Jiansheng Li",
      "Xingxuan Zhang",
      "Hao Zou",
      "Yige Guo",
      "Renzhe Xu",
      "Yilong Liu",
      "Chuzhao Zhu",
      "Yue He",
      "Peng Cui"
    ],
    "abstract": "Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10158v1",
    "published_date": "2025-04-14 12:13:33 UTC",
    "updated_date": "2025-04-14 12:13:33 UTC"
  },
  {
    "arxiv_id": "2504.10149v2",
    "title": "BoTTA: Benchmarking on-device Test Time Adaptation",
    "authors": [
      "Michal Danilowski",
      "Soumyajit Chatterjee",
      "Abhirup Ghosh"
    ],
    "abstract": "The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10149v2",
    "published_date": "2025-04-14 12:00:00 UTC",
    "updated_date": "2025-04-16 13:16:19 UTC"
  },
  {
    "arxiv_id": "2504.10146v2",
    "title": "GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions",
    "authors": [
      "Jo-Ku Cheng",
      "Zeren Zhang",
      "Ran Chen",
      "Jingyang Deng",
      "Ziran Qin",
      "Jinwen Ma"
    ],
    "abstract": "We propose GeoUni, the first unified geometry expert model capable of\ngenerating problem solutions and diagrams within a single framework in a way\nthat enables the creation of unique and individualized geometry problems.\nTraditionally, solving geometry problems and generating diagrams have been\ntreated as separate tasks in machine learning, with no models successfully\nintegrating both to support problem creation. However, we believe that mastery\nin geometry requires frictionless integration of all of these skills, from\nsolving problems to visualizing geometric relationships, and finally, crafting\ntailored problems. Our extensive experiments demonstrate that GeoUni, with only\n1.5B parameters, achieves performance comparable to larger models such as\nDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also\nexcels in generating precise geometric diagrams, surpassing both text-to-image\nmodels and unified models, including the GPT-4o image generation. Most\nimportantly, GeoUni is the only model capable of successfully generating\ntextual problems with matching diagrams based on specific knowledge points,\nthus offering a wider range of capabilities that extend beyond current models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10146v2",
    "published_date": "2025-04-14 11:56:55 UTC",
    "updated_date": "2025-05-08 14:36:20 UTC"
  },
  {
    "arxiv_id": "2504.10127v2",
    "title": "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization",
    "authors": [
      "Junlei Zhang",
      "Zichen Ding",
      "Chang Ma",
      "Zijie Chen",
      "Qiushi Sun",
      "Zhenzhong Lan",
      "Junxian He"
    ],
    "abstract": "Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10127v2",
    "published_date": "2025-04-14 11:35:02 UTC",
    "updated_date": "2025-04-15 17:13:46 UTC"
  },
  {
    "arxiv_id": "2504.10112v1",
    "title": "Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design",
    "authors": [
      "Andreas Happe",
      "Jürgen Cito"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10112v1",
    "published_date": "2025-04-14 11:21:33 UTC",
    "updated_date": "2025-04-14 11:21:33 UTC"
  },
  {
    "arxiv_id": "2504.10109v1",
    "title": "Lightweight Trustworthy Distributed Clustering",
    "authors": [
      "Hongyang Li",
      "Caesar Wu",
      "Mohammed Chadli",
      "Said Mammar",
      "Pascal Bouvry"
    ],
    "abstract": "Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10109v1",
    "published_date": "2025-04-14 11:16:07 UTC",
    "updated_date": "2025-04-14 11:16:07 UTC"
  },
  {
    "arxiv_id": "2504.10106v1",
    "title": "SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding",
    "authors": [
      "Marc Gutiérrez-Pérez",
      "Antonio Agudo"
    ],
    "abstract": "Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2; I.4; I.5"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10106v1",
    "published_date": "2025-04-14 11:15:13 UTC",
    "updated_date": "2025-04-14 11:15:13 UTC"
  },
  {
    "arxiv_id": "2504.10081v1",
    "title": "RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability",
    "authors": [
      "Yichi Zhang",
      "Zihao Zeng",
      "Dongbai Li",
      "Yao Huang",
      "Zhijie Deng",
      "Yinpeng Dong"
    ],
    "abstract": "Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10081v1",
    "published_date": "2025-04-14 10:26:37 UTC",
    "updated_date": "2025-04-14 10:26:37 UTC"
  },
  {
    "arxiv_id": "2504.10077v1",
    "title": "Towards Quantifying Commonsense Reasoning with Mechanistic Insights",
    "authors": [
      "Abhinav Joshi",
      "Areeb Ahmad",
      "Divyaksh Shukla",
      "Ashutosh Modi"
    ],
    "abstract": "Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025; 28 pages (9 pages + 7 pages references + 12\n  pages appendix)",
    "pdf_url": "http://arxiv.org/pdf/2504.10077v1",
    "published_date": "2025-04-14 10:21:59 UTC",
    "updated_date": "2025-04-14 10:21:59 UTC"
  },
  {
    "arxiv_id": "2504.10074v3",
    "title": "MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework",
    "authors": [
      "Zihan Ling",
      "Zhiyao Guo",
      "Yixuan Huang",
      "Yi An",
      "Shuai Xiao",
      "Jinsong Lan",
      "Xiaoyong Zhu",
      "Bo Zheng"
    ],
    "abstract": "Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2% on the Single-Hop subset and\n+0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10074v3",
    "published_date": "2025-04-14 10:19:47 UTC",
    "updated_date": "2025-04-20 17:16:02 UTC"
  },
  {
    "arxiv_id": "2504.10071v1",
    "title": "Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning",
    "authors": [
      "Tien Pham",
      "Angelo Cangelosi"
    ],
    "abstract": "Current approaches in Explainable Deep Reinforcement Learning have\nlimitations in which the attention mask has a displacement with the objects in\nvisual input. This work addresses a spatial problem within traditional\nConvolutional Neural Networks (CNNs). We propose the Interpretable Feature\nExtractor (IFE) architecture, aimed at generating an accurate attention mask to\nillustrate both \"what\" and \"where\" the agent concentrates on in the spatial\ndomain. Our design incorporates a Human-Understandable Encoding module to\ngenerate a fully interpretable attention mask, followed by an Agent-Friendly\nEncoding module to enhance the agent's learning efficiency. These two\ncomponents together form the Interpretable Feature Extractor for vision-based\ndeep reinforcement learning to enable the model's interpretability. The\nresulting attention mask is consistent, highly understandable by humans,\naccurate in spatial dimension, and effectively highlights important objects or\nlocations in visual input. The Interpretable Feature Extractor is integrated\ninto the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI\ngames to show the effectiveness of the proposed approach on Spatial\nPreservation, Interpretability, and Data-efficiency. Finally, we showcase the\nversatility of our approach by incorporating the IFE into the Asynchronous\nAdvantage Actor-Critic Model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10071v1",
    "published_date": "2025-04-14 10:18:34 UTC",
    "updated_date": "2025-04-14 10:18:34 UTC"
  },
  {
    "arxiv_id": "2504.10068v1",
    "title": "Mavors: Multi-granularity Video Representation for Multimodal Large Language Model",
    "authors": [
      "Yang Shi",
      "Jiaheng Liu",
      "Yushuo Guan",
      "Zhenhua Wu",
      "Yuanxing Zhang",
      "Zihao Wang",
      "Weihong Lin",
      "Jingyun Hua",
      "Zekun Wang",
      "Xinlong Chen",
      "Bohan Zeng",
      "Wentao Zhang",
      "Fuzheng Zhang",
      "Wenjing Yang",
      "Di Zhang"
    ],
    "abstract": "Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.10068v1",
    "published_date": "2025-04-14 10:14:44 UTC",
    "updated_date": "2025-04-14 10:14:44 UTC"
  },
  {
    "arxiv_id": "2504.10063v2",
    "title": "Hallucination Detection in LLMs with Topological Divergence on Attention Graphs",
    "authors": [
      "Alexandra Bazarova",
      "Aleksandr Yugay",
      "Andrey Shulga",
      "Alina Ermilova",
      "Andrei Volodichev",
      "Konstantin Polev",
      "Julia Belikova",
      "Rauf Parchiev",
      "Dmitry Simakov",
      "Maxim Savchenko",
      "Andrey Savchenko",
      "Serguei Barannikov",
      "Alexey Zaytsev"
    ],
    "abstract": "Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments - including evaluation on\nquestion answering and summarization tasks - show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks while requiring\nminimal annotated data and computational resources. Our findings suggest that\nanalyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10063v2",
    "published_date": "2025-04-14 10:06:27 UTC",
    "updated_date": "2025-05-22 12:49:21 UTC"
  },
  {
    "arxiv_id": "2504.13196v1",
    "title": "Investigating cybersecurity incidents using large language models in latest-generation wireless networks",
    "authors": [
      "Leonid Legashev",
      "Arthur Zhigalov"
    ],
    "abstract": "The purpose of research: Detection of cybersecurity incidents and analysis of\ndecision support and assessment of the effectiveness of measures to counter\ninformation security threats based on modern generative models. The methods of\nresearch: Emulation of signal propagation data in MIMO systems, synthesis of\nadversarial examples, execution of adversarial attacks on machine learning\nmodels, fine tuning of large language models for detecting adversarial attacks,\nexplainability of decisions on detecting cybersecurity incidents based on the\nprompts technique. Scientific novelty: A binary classification of data\npoisoning attacks was performed using large language models, and the\npossibility of using large language models for investigating cybersecurity\nincidents in the latest generation wireless networks was investigated. The\nresult of research: Fine-tuning of large language models was performed on the\nprepared data of the emulated wireless network segment. Six large language\nmodels were compared for detecting adversarial attacks, and the capabilities of\nexplaining decisions made by a large language model were investigated. The\nGemma-7b model showed the best results according to the metrics Precision =\n0.89, Recall = 0.89 and F1-Score = 0.89. Based on various explainability\nprompts, the Gemma-7b model notes inconsistencies in the compromised data under\nstudy, performs feature importance analysis and provides various\nrecommendations for mitigating the consequences of adversarial attacks. Large\nlanguage models integrated with binary classifiers of network threats have\nsignificant potential for practical application in the field of cybersecurity\nincident investigation, decision support and assessing the effectiveness of\nmeasures to counter information security threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13196v1",
    "published_date": "2025-04-14 09:57:20 UTC",
    "updated_date": "2025-04-14 09:57:20 UTC"
  },
  {
    "arxiv_id": "2504.10045v1",
    "title": "CHARM: Calibrating Reward Models With Chatbot Arena Scores",
    "authors": [
      "Xiao Zhu",
      "Chenmien Tan",
      "Pinzhen Chen",
      "Rico Sennrich",
      "Yanlin Zhang",
      "Hanxu Hu"
    ],
    "abstract": "Reward models (RMs) play a crucial role in Reinforcement Learning from Human\nFeedback by serving as proxies for human preferences in aligning large language\nmodels. In this paper, we identify a model preference bias in RMs, where they\nsystematically assign disproportionately high scores to responses from certain\npolicy models. This bias distorts ranking evaluations and leads to unfair\njudgments. To address this issue, we propose a calibration method named CHatbot\nArena calibrated Reward Modeling (CHARM) that leverages Elo scores from the\nChatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a\nMismatch Degree metric to measure this preference bias. Our approach is\ncomputationally efficient, requiring only a small preference dataset for\ncontinued training of the RM. We conduct extensive experiments on reward model\nbenchmarks and human preference alignment. Results demonstrate that our\ncalibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the\nChat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with\nhuman preferences by producing scores more closely aligned with Elo rankings.\nBy mitigating model preference bias, our method provides a generalizable and\nefficient solution for building fairer and more reliable reward models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10045v1",
    "published_date": "2025-04-14 09:51:09 UTC",
    "updated_date": "2025-04-14 09:51:09 UTC"
  },
  {
    "arxiv_id": "2504.10030v1",
    "title": "EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control",
    "authors": [
      "Hanwen Wan",
      "Yifei Chen",
      "Zeyu Wei",
      "Dongrui Li",
      "Zexin Lin",
      "Donghao Wu",
      "Jiu Cheng",
      "Yuxiang Zhang",
      "Xiaoqiang Ji"
    ],
    "abstract": "This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10030v1",
    "published_date": "2025-04-14 09:33:42 UTC",
    "updated_date": "2025-04-14 09:33:42 UTC"
  },
  {
    "arxiv_id": "2504.10028v1",
    "title": "Sequence models for by-trial decoding of cognitive strategies from neural data",
    "authors": [
      "Rick den Otter",
      "Gabriel Weindel",
      "Sjoerd Stuit",
      "Leendert van Maanen"
    ],
    "abstract": "Understanding the sequence of cognitive operations that underlie\ndecision-making is a fundamental challenge in cognitive neuroscience.\nTraditional approaches often rely on group-level statistics, which obscure\ntrial-by-trial variations in cognitive strategies. In this study, we introduce\na novel machine learning method that combines Hidden Multivariate Pattern\nanalysis with a Structured State Space Sequence model to decode cognitive\nstrategies from electroencephalography data at the trial level. We apply this\nmethod to a decision-making task, where participants were instructed to\nprioritize either speed or accuracy in their responses. Our results reveal an\nadditional cognitive operation, labeled Confirmation, which seems to occur\npredominantly in the accuracy condition but also frequently in the speed\ncondition. The modeled probability that this operation occurs is associated\nwith higher probability of responding correctly as well as changes of mind, as\nindexed by electromyography data. By successfully modeling cognitive operations\nat the trial level, we provide empirical evidence for dynamic variability in\ndecision strategies, challenging the assumption of homogeneous cognitive\nprocesses within experimental conditions. Our approach shows the potential of\nsequence modeling in cognitive neuroscience to capture trial-level variability\nthat is obscured by aggregate analyses. The introduced method offers a new way\nto detect and understand cognitive strategies in a data-driven manner, with\nimplications for both theoretical research and practical applications in many\nfields.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10028v1",
    "published_date": "2025-04-14 09:33:02 UTC",
    "updated_date": "2025-04-14 09:33:02 UTC"
  },
  {
    "arxiv_id": "2504.10025v1",
    "title": "Progressive Transfer Learning for Multi-Pass Fundus Image Restoration",
    "authors": [
      "Uyen Phan",
      "Ozer Can Devecioglu",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "abstract": "Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "13 pages, 12 figures including appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.10025v1",
    "published_date": "2025-04-14 09:28:10 UTC",
    "updated_date": "2025-04-14 09:28:10 UTC"
  },
  {
    "arxiv_id": "2504.10020v2",
    "title": "The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination",
    "authors": [
      "Hao Yin",
      "Guangzong Si",
      "Zilei Wang"
    ],
    "abstract": "Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10020v2",
    "published_date": "2025-04-14 09:25:37 UTC",
    "updated_date": "2025-04-18 11:30:15 UTC"
  },
  {
    "arxiv_id": "2504.10018v1",
    "title": "RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework",
    "authors": [
      "Xiao Wang",
      "Haiyang Wang",
      "Shiao Wang",
      "Qiang Chen",
      "Jiandong Jin",
      "Haoyu Song",
      "Bo Jiang",
      "Chenglong Li"
    ],
    "abstract": "Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The First Benchmark Dataset for RGB-Event Multimodal Pedestrian\n  Attribute Recognition Task",
    "pdf_url": "http://arxiv.org/pdf/2504.10018v1",
    "published_date": "2025-04-14 09:22:16 UTC",
    "updated_date": "2025-04-14 09:22:16 UTC"
  },
  {
    "arxiv_id": "2504.10014v1",
    "title": "Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network",
    "authors": [
      "Hang Yin",
      "Yan-Ming Zhang",
      "Jian Xu",
      "Jian-Long Chang",
      "Yin Li",
      "Cheng-Lin Liu"
    ],
    "abstract": "Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10014v1",
    "published_date": "2025-04-14 09:18:11 UTC",
    "updated_date": "2025-04-14 09:18:11 UTC"
  },
  {
    "arxiv_id": "2504.10005v1",
    "title": "Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space",
    "authors": [
      "Klaudia Balcer",
      "Piotr Lipinski"
    ],
    "abstract": "This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10005v1",
    "published_date": "2025-04-14 09:08:40 UTC",
    "updated_date": "2025-04-14 09:08:40 UTC"
  },
  {
    "arxiv_id": "2504.10552v1",
    "title": "LEMUR Neural Network Dataset: Towards Seamless AutoML",
    "authors": [
      "Arash Torabi Goodarzi",
      "Roman Kochnev",
      "Waleed Khalid",
      "Furui Qin",
      "Tolgay Atinc Uzun",
      "Yashkumar Sanjaybhai Dhameliya",
      "Yash Kanubhai Kathiriya",
      "Zofia Antonina Bentyn",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "abstract": "Neural networks are fundamental in artificial intelligence, driving progress\nin computer vision and natural language processing. High-quality datasets are\ncrucial for their development, and there is growing interest in datasets\ncomposed of neural networks themselves to support benchmarking, automated\nmachine learning (AutoML), and model analysis. We introduce LEMUR, an open\nsource dataset of neural network models with well-structured code for diverse\narchitectures across tasks such as object detection, image classification,\nsegmentation, and natural language processing. LEMUR is primarily designed to\nenable fine-tuning of large language models (LLMs) for AutoML tasks, providing\na rich source of structured model representations and associated performance\ndata. Leveraging Python and PyTorch, LEMUR enables seamless extension to new\ndatasets and models while maintaining consistency. It integrates an\nOptuna-powered framework for evaluation, hyperparameter optimization,\nstatistical analysis, and graphical insights. LEMUR provides an extension that\nenables models to run efficiently on edge devices, facilitating deployment in\nresource-constrained environments. Providing tools for model evaluation,\npreprocessing, and database management, LEMUR supports researchers and\npractitioners in developing, testing, and analyzing neural networks.\nAdditionally, it offers an API that delivers comprehensive information about\nneural network models and their complete performance statistics with a single\nrequest, which can be used in experiments with code-generating large language\nmodels. The LEMUR will be released as an open source project under the MIT\nlicense upon acceptance of the paper.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10552v1",
    "published_date": "2025-04-14 09:08:00 UTC",
    "updated_date": "2025-04-14 09:08:00 UTC"
  },
  {
    "arxiv_id": "2504.10000v1",
    "title": "Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?",
    "authors": [
      "Yanbo Wang",
      "Jiyang Guan",
      "Jian Liang",
      "Ran He"
    ],
    "abstract": "Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to CVPR 2025, codes in process",
    "pdf_url": "http://arxiv.org/pdf/2504.10000v1",
    "published_date": "2025-04-14 09:03:51 UTC",
    "updated_date": "2025-04-14 09:03:51 UTC"
  },
  {
    "arxiv_id": "2504.09998v1",
    "title": "Metric-Guided Synthesis of Class Activation Mapping",
    "authors": [
      "Alejandro Luque-Cerpa",
      "Elizabeth Polgreen",
      "Ajitha Rajan",
      "Hazem Torfah"
    ],
    "abstract": "Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09998v1",
    "published_date": "2025-04-14 09:01:49 UTC",
    "updated_date": "2025-04-14 09:01:49 UTC"
  },
  {
    "arxiv_id": "2504.09997v1",
    "title": "GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control",
    "authors": [
      "Hanwen Wan",
      "Mengkang Li",
      "Donghao Wu",
      "Yebin Zhong",
      "Yixuan Deng",
      "Zhenglong Sun",
      "Xiaoqiang Ji"
    ],
    "abstract": "Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09997v1",
    "published_date": "2025-04-14 09:01:44 UTC",
    "updated_date": "2025-04-14 09:01:44 UTC"
  },
  {
    "arxiv_id": "2504.10551v1",
    "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers",
    "authors": [
      "Lili Zhao",
      "Qi Liu",
      "Wei Chen",
      "Liyi Chen",
      "Ruijun Sun",
      "Min Hou",
      "Yang Wang",
      "Shijin Wang"
    ],
    "abstract": "Empirical Risk Minimization (ERM) models often rely on spurious correlations\nbetween features and labels during the learning process, leading to shortcut\nlearning behavior that undermines robustness generalization performance.\nCurrent research mainly targets identifying or mitigating a single shortcut;\nhowever, in real-world scenarios, cues within the data are diverse and unknown.\nIn empirical studies, we reveal that the models rely to varying extents on\ndifferent shortcuts. Compared to weak shortcuts, models depend more heavily on\nstrong shortcuts, resulting in their poor generalization ability. To address\nthese challenges, we propose MiMu, a novel method integrated with\nTransformer-based ERMs designed to Mitigate Multiple shortcut learning\nbehavior, which incorporates self-calibration strategy and self-improvement\nstrategy. In the source model, we preliminarily propose the self-calibration\nstrategy to prevent the model from relying on shortcuts and make overconfident\npredictions. Then, we further design self-improvement strategy in target model\nto reduce the reliance on multiple shortcuts. The random mask strategy involves\nrandomly masking partial attention positions to diversify the focus of target\nmodel other than concentrating on a fixed region. Meanwhile, the adaptive\nattention alignment module facilitates the alignment of attention weights to\nthe calibrated source model, without the need for post-hoc attention maps or\nsupervision. Finally, extensive experiments conducted on Natural Language\nProcessing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu\nin improving robustness generalization abilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10551v1",
    "published_date": "2025-04-14 08:11:09 UTC",
    "updated_date": "2025-04-14 08:11:09 UTC"
  },
  {
    "arxiv_id": "2504.09967v1",
    "title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data",
    "authors": [
      "Xun Zhu",
      "Fanbin Mo",
      "Zheng Zhang",
      "Jiaxi Wang",
      "Yiming Shi",
      "Ming Wu",
      "Chuang Zhang",
      "Miao Li",
      "Ji Wu"
    ],
    "abstract": "The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09967v1",
    "published_date": "2025-04-14 08:09:37 UTC",
    "updated_date": "2025-04-14 08:09:37 UTC"
  },
  {
    "arxiv_id": "2504.09963v1",
    "title": "Towards Unbiased Federated Graph Learning: Label and Topology Perspectives",
    "authors": [
      "Zhengyu Wu",
      "Boyang Pang",
      "Xunkai Li",
      "Yinlin Zhu",
      "Daohan Su",
      "Bowen Fan",
      "Rong-Hua Li",
      "Guoren Wang",
      "Chenghu Zhou"
    ],
    "abstract": "Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.09963v1",
    "published_date": "2025-04-14 08:00:20 UTC",
    "updated_date": "2025-04-14 08:00:20 UTC"
  },
  {
    "arxiv_id": "2504.09961v1",
    "title": "Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science",
    "authors": [
      "Yashothara Shanmugarasa",
      "Shidong Pan",
      "Ming Ding",
      "Dehai Zhao",
      "Thierry Rakotoarivelo"
    ],
    "abstract": "As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.09961v1",
    "published_date": "2025-04-14 07:58:26 UTC",
    "updated_date": "2025-04-14 07:58:26 UTC"
  },
  {
    "arxiv_id": "2504.09948v3",
    "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes",
    "authors": [
      "Huijie Liu",
      "Bingcan Wang",
      "Jie Hu",
      "Xiaoming Wei",
      "Guoliang Kang"
    ],
    "abstract": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 10 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.09948v3",
    "published_date": "2025-04-14 07:18:32 UTC",
    "updated_date": "2025-05-01 01:58:55 UTC"
  },
  {
    "arxiv_id": "2504.09941v1",
    "title": "FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments",
    "authors": [
      "Junming Liu",
      "Guosun Zeng",
      "Ding Wang",
      "Yanting Gao",
      "Yufei Jin"
    ],
    "abstract": "Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 32 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09941v1",
    "published_date": "2025-04-14 07:04:10 UTC",
    "updated_date": "2025-04-14 07:04:10 UTC"
  },
  {
    "arxiv_id": "2504.09936v1",
    "title": "KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference",
    "authors": [
      "Yuxuan Tian",
      "Zihan Wang",
      "Yebo Peng",
      "Aomufei Yuan",
      "Zhiming Wang",
      "Bairen Yi",
      "Xin Liu",
      "Yong Cui",
      "Tong Yang"
    ],
    "abstract": "Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09936v1",
    "published_date": "2025-04-14 06:58:00 UTC",
    "updated_date": "2025-04-14 06:58:00 UTC"
  },
  {
    "arxiv_id": "2504.09909v1",
    "title": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications",
    "authors": [
      "Farha Nausheen",
      "Khandakar Ahmed",
      "M Imad Khan"
    ],
    "abstract": "In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09909v1",
    "published_date": "2025-04-14 06:09:26 UTC",
    "updated_date": "2025-04-14 06:09:26 UTC"
  },
  {
    "arxiv_id": "2504.09906v1",
    "title": "Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming",
    "authors": [
      "Zhiqiang He",
      "Zhi Liu"
    ],
    "abstract": "Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09906v1",
    "published_date": "2025-04-14 06:02:41 UTC",
    "updated_date": "2025-04-14 06:02:41 UTC"
  },
  {
    "arxiv_id": "2504.09895v1",
    "title": "Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data",
    "authors": [
      "Shuai Zhao",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "abstract": "Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.09895v1",
    "published_date": "2025-04-14 05:43:21 UTC",
    "updated_date": "2025-04-14 05:43:21 UTC"
  },
  {
    "arxiv_id": "2504.09893v1",
    "title": "LangPert: Detecting and Handling Task-level Perturbations for Robust Object Rearrangement",
    "authors": [
      "Xu Yin",
      "Min-Sung Yoon",
      "Yuchi Huo",
      "Kang Zhang",
      "Sung-Eui Yoon"
    ],
    "abstract": "Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09893v1",
    "published_date": "2025-04-14 05:39:15 UTC",
    "updated_date": "2025-04-14 05:39:15 UTC"
  },
  {
    "arxiv_id": "2504.09877v1",
    "title": "Constructing Micro Knowledge Graphs from Technical Support Documents",
    "authors": [
      "Atul Kumar",
      "Nisha Gupta",
      "Saswati Dana"
    ],
    "abstract": "Short technical support pages such as IBM Technotes are quite common in\ntechnical support domain. These pages can be very useful as the knowledge\nsources for technical support applications such as chatbots, search engines and\nquestion-answering (QA) systems. Information extracted from documents to drive\ntechnical support applications is often stored in the form of Knowledge Graph\n(KG). Building KGs from a large corpus of documents poses a challenge of\ngranularity because a large number of entities and actions are present in each\npage. The KG becomes virtually unusable if all entities and actions from these\npages are stored in the KG. Therefore, only key entities and actions from each\npage are extracted and stored in the KG. This approach however leads to loss of\nknowledge represented by entities and actions left out of the KG as they are no\nlonger available to graph search and reasoning functions. We propose a set of\ntechniques to create micro knowledge graph (micrograph) for each of such web\npages. The micrograph stores all the entities and actions in a page and also\ntakes advantage of the structure of the page to represent exactly in which part\nof that page these entities and actions appeared, and also how they relate to\neach other. These micrographs can be used as additional knowledge sources by\ntechnical support applications. We define schemas for representing\nsemi-structured and plain text knowledge present in the technical support web\npages. Solutions in technical support domain include procedures made of steps.\nWe also propose a technique to extract procedures from these webpages and the\nschemas to represent them in the micrographs. We also discuss how technical\nsupport applications can take advantage of the micrographs.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09877v1",
    "published_date": "2025-04-14 04:57:49 UTC",
    "updated_date": "2025-04-14 04:57:49 UTC"
  },
  {
    "arxiv_id": "2504.10548v1",
    "title": "Automated Testing of COBOL to Java Transformation",
    "authors": [
      "Sandeep Hans",
      "Atul Kumar",
      "Toshikai Yasue",
      "Kouichi Ono",
      "Saravanan Krishnan",
      "Devika Sondhi",
      "Fumiko Satoh",
      "Gerald Mitchell",
      "Sachin Kumar",
      "Diptikalyan Saha"
    ],
    "abstract": "Recent advances in Large Language Model (LLM) based Generative AI techniques\nhave made it feasible to translate enterprise-level code from legacy languages\nsuch as COBOL to modern languages such as Java or Python. While the results of\nLLM-based automatic transformation are encouraging, the resulting code cannot\nbe trusted to correctly translate the original code, making manual validation\nof translated Java code from COBOL a necessary but time-consuming and\nlabor-intensive process. In this paper, we share our experience of developing a\ntesting framework for IBM Watsonx Code Assistant for Z (WCA4Z) [5], an\nindustrial tool designed for COBOL to Java translation. The framework automates\nthe process of testing the functional equivalence of the translated Java code\nagainst the original COBOL programs in an industry context. Our framework uses\nsymbolic execution to generate unit tests for COBOL, mocking external calls and\ntransforming them into JUnit tests to validate semantic equivalence with\ntranslated Java. The results not only help identify and repair any detected\ndiscrepancies but also provide feedback to improve the AI model.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10548v1",
    "published_date": "2025-04-14 04:53:30 UTC",
    "updated_date": "2025-04-14 04:53:30 UTC"
  },
  {
    "arxiv_id": "2504.09876v2",
    "title": "HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation",
    "authors": [
      "Tran Quoc Khanh Le",
      "Nguyen Lan Vi Vu",
      "Ha-Hieu Pham",
      "Xuan-Loc Huynh",
      "Tien-Huy Nguyen",
      "Minh Huu Nhat Le",
      "Quan Nguyen",
      "Hien D. Nguyen"
    ],
    "abstract": "Transvaginal ultrasound is a critical imaging modality for evaluating\ncervical anatomy and detecting physiological changes. However, accurate\nsegmentation of cervical structures remains challenging due to low contrast,\nshadow artifacts, and indistinct boundaries. While convolutional neural\nnetworks (CNNs) have demonstrated efficacy in medical image segmentation, their\nreliance on large-scale annotated datasets presents a significant limitation in\nclinical ultrasound imaging. Semi-supervised learning (SSL) offers a potential\nsolution by utilizing unlabeled data, yet existing teacher-student frameworks\noften encounter confirmation bias and high computational costs. In this paper,\na novel semi-supervised segmentation framework, called HDC, is proposed\nincorporating adaptive consistency learning with a single-teacher architecture.\nThe framework introduces a hierarchical distillation mechanism with two\nobjectives: Correlation Guidance Loss for aligning feature representations and\nMutual Information Loss for stabilizing noisy student learning. The proposed\napproach reduces model complexity while enhancing generalization. Experiments\non fetal ultrasound datasets, FUGC and PSFH, demonstrate competitive\nperformance with reduced computational overhead compared to multi-teacher\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09876v2",
    "published_date": "2025-04-14 04:52:24 UTC",
    "updated_date": "2025-04-17 01:42:05 UTC"
  },
  {
    "arxiv_id": "2504.09873v1",
    "title": "Truncated Matrix Completion - An Empirical Study",
    "authors": [
      "Rishhabh Naik",
      "Nisarg Trivedi",
      "Davoud Ataee Tarzanagh",
      "Laura Balzano"
    ],
    "abstract": "Low-rank Matrix Completion (LRMC) describes the problem where we wish to\nrecover missing entries of partially observed low-rank matrix. Most existing\nmatrix completion work deals with sampling procedures that are independent of\nthe underlying data values. While this assumption allows the derivation of nice\ntheoretical guarantees, it seldom holds in real-world applications. In this\npaper, we consider various settings where the sampling mask is dependent on the\nunderlying data values, motivated by applications in sensing, sequential\ndecision-making, and recommender systems. Through a series of experiments, we\nstudy and compare the performance of various LRMC algorithms that were\noriginally successful for data-independent sampling patterns.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09873v1",
    "published_date": "2025-04-14 04:42:00 UTC",
    "updated_date": "2025-04-14 04:42:00 UTC"
  },
  {
    "arxiv_id": "2504.09865v2",
    "title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects",
    "authors": [
      "Isabel O. Gallegos",
      "Chen Shani",
      "Weiyan Shi",
      "Federico Bianchi",
      "Izzy Gainsburg",
      "Dan Jurafsky",
      "Robb Willer"
    ],
    "abstract": "As generative artificial intelligence (AI) enables the creation and\ndissemination of information at massive scale and speed, it is increasingly\nimportant to understand how people perceive AI-generated content. One prominent\npolicy proposal requires explicitly labeling AI-generated content to increase\ntransparency and encourage critical thinking about the information, but prior\nresearch has not yet tested the effects of such labels. To address this gap, we\nconducted a survey experiment (N=1601) on a diverse sample of Americans,\npresenting participants with an AI-generated message about several public\npolicies (e.g., allowing colleges to pay student-athletes), randomly assigning\nwhether participants were told the message was generated by (a) an expert AI\nmodel, (b) a human policy expert, or (c) no label. We found that messages were\ngenerally persuasive, influencing participants' views of the policies by 9.74\npercentage points on average. However, while 94.6% of participants assigned to\nthe AI and human label conditions believed the authorship labels, labels had no\nsignificant effects on participants' attitude change toward the policies,\njudgments of message accuracy, nor intentions to share the message with others.\nThese patterns were robust across a variety of participant characteristics,\nincluding prior knowledge of the policy, prior experience with AI, political\nparty, education level, or age. Taken together, these results imply that, while\nauthorship labels would likely enhance transparency, they are unlikely to\nsubstantially affect the persuasiveness of the labeled content, highlighting\nthe need for alternative strategies to address challenges posed by AI-generated\ninformation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09865v2",
    "published_date": "2025-04-14 04:22:39 UTC",
    "updated_date": "2025-04-22 02:47:23 UTC"
  },
  {
    "arxiv_id": "2504.12335v1",
    "title": "You've Changed: Detecting Modification of Black-Box Large Language Models",
    "authors": [
      "Alden Dima",
      "James Foulds",
      "Shimei Pan",
      "Philip Feldman"
    ],
    "abstract": "Large Language Models (LLMs) are often provided as a service via an API,\nmaking it challenging for developers to detect changes in their behavior. We\npresent an approach to monitor LLMs for changes by comparing the distributions\nof linguistic and psycholinguistic features of generated text. Our method uses\na statistical test to determine whether the distributions of features from two\nsamples of text are equivalent, allowing developers to identify when an LLM has\nchanged. We demonstrate the effectiveness of our approach using five OpenAI\ncompletion models and Meta's Llama 3 70B chat model. Our results show that\nsimple text features coupled with a statistical test can distinguish between\nlanguage models. We also explore the use of our approach to detect prompt\ninjection attacks. Our work enables frequent LLM change monitoring and avoids\ncomputationally expensive benchmark evaluations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.12335v1",
    "published_date": "2025-04-14 04:16:43 UTC",
    "updated_date": "2025-04-14 04:16:43 UTC"
  },
  {
    "arxiv_id": "2504.09861v1",
    "title": "EthosGPT: Mapping Human Value Diversity to Advance Sustainable Development Goals (SDGs)",
    "authors": [
      "Luyao Zhang"
    ],
    "abstract": "Large language models (LLMs) are transforming global decision-making and\nsocietal systems by processing diverse data at unprecedented scales. However,\ntheir potential to homogenize human values poses critical risks, similar to\nbiodiversity loss undermining ecological resilience. Rooted in the ancient\nGreek concept of ethos, meaning both individual character and the shared moral\nfabric of communities, EthosGPT draws on a tradition that spans from\nAristotle's virtue ethics to Adam Smith's moral sentiments as the ethical\nfoundation of economic cooperation. These traditions underscore the vital role\nof value diversity in fostering social trust, institutional legitimacy, and\nlong-term prosperity. EthosGPT addresses the challenge of value homogenization\nby introducing an open-source framework for mapping and evaluating LLMs within\na global scale of human values. Using international survey data on cultural\nindices, prompt-based assessments, and comparative statistical analyses,\nEthosGPT reveals both the adaptability and biases of LLMs across regions and\ncultures. It offers actionable insights for developing inclusive LLMs, such as\ndiversifying training data and preserving endangered cultural heritage to\nensure representation in AI systems. These contributions align with the United\nNations Sustainable Development Goals (SDGs), especially SDG 10 (Reduced\nInequalities), SDG 11.4 (Cultural Heritage Preservation), and SDG 16 (Peace,\nJustice and Strong Institutions). Through interdisciplinary collaboration,\nEthosGPT promotes AI systems that are both technically robust and ethically\ninclusive, advancing value plurality as a cornerstone for sustainable and\nequitable futures.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "econ.GN",
      "q-fin.EC",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09861v1",
    "published_date": "2025-04-14 04:14:13 UTC",
    "updated_date": "2025-04-14 04:14:13 UTC"
  },
  {
    "arxiv_id": "2504.09860v1",
    "title": "SUMART: SUMmARizing Translation from Wordy to Concise Expression",
    "authors": [
      "Naoto Nishida",
      "Jun Rekimoto"
    ],
    "abstract": "We propose SUMART, a method for summarizing and compressing the volume of\nverbose subtitle translations. SUMART is designed for understanding translated\ncaptions (e.g., interlingual conversations via subtitle translation or when\nwatching movies in foreign language audio and translated captions). SUMART is\nintended for users who want a big-picture and fast understanding of the\nconversation, audio, video content, and speech in a foreign language. During\nthe training data collection, when a speaker makes a verbose statement, SUMART\nemploys a large language model on-site to compress the volume of subtitles.\nThis compressed data is then stored in a database for fine-tuning purposes.\nLater, SUMART uses data pairs from those non-compressed ASR results and\ncompressed translated results for fine-tuning the translation model to generate\nmore concise translations for practical uses. In practical applications, SUMART\nutilizes this trained model to produce concise translation results.\nFurthermore, as a practical application, we developed an application that\nallows conversations using subtitle translation in augmented reality spaces. As\na pilot study, we conducted qualitative surveys using a SUMART prototype and a\nsurvey on the summarization model for SUMART. We envision the most effective\nuse case of this system is where users need to consume a lot of information\nquickly (e.g., Speech, lectures, podcasts, Q&A in conferences).",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "3 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09860v1",
    "published_date": "2025-04-14 04:13:09 UTC",
    "updated_date": "2025-04-14 04:13:09 UTC"
  },
  {
    "arxiv_id": "2504.09858v1",
    "title": "Reasoning Models Can Be Effective Without Thinking",
    "authors": [
      "Wenjie Ma",
      "Jingxuan He",
      "Charlie Snell",
      "Tyler Griggs",
      "Sewon Min",
      "Matei Zaharia"
    ],
    "abstract": "Recent LLMs have significantly improved reasoning capabilities, primarily by\nincluding an explicit, lengthy Thinking process as part of generation. In this\npaper, we question whether this explicit thinking is necessary. Using the\nstate-of-the-art DeepSeek-R1-Distill-Qwen, we find that bypassing the thinking\nprocess via simple prompting, denoted as NoThinking, can be surprisingly\neffective. When controlling for the number of tokens, NoThinking outperforms\nThinking across a diverse set of seven challenging reasoning\ndatasets--including mathematical problem solving, formal theorem proving, and\ncoding--especially in low-budget settings, e.g., 51.3 vs. 28.9 on ACM 23 with\n700 tokens. Notably, the performance of NoThinking becomes more competitive\nwith pass@k as k increases. Building on this observation, we demonstrate that a\nparallel scaling approach that uses NoThinking to generate N outputs\nindependently and aggregates them is highly effective. For aggregation, we use\ntask-specific verifiers when available, or we apply simple best-of-N strategies\nsuch as confidence-based selection. Our method outperforms a range of baselines\nwith similar latency using Thinking, and is comparable to Thinking with\nsignificantly longer latency (up to 9x). Together, our research encourages a\nreconsideration of the necessity of lengthy thinking processes, while also\nestablishing a competitive reference for achieving strong reasoning performance\nin low-budget settings or at low latency using parallel scaling.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, 7 main figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.09858v1",
    "published_date": "2025-04-14 04:08:16 UTC",
    "updated_date": "2025-04-14 04:08:16 UTC"
  },
  {
    "arxiv_id": "2504.09857v1",
    "title": "Working with Large Language Models to Enhance Messaging Effectiveness for Vaccine Confidence",
    "authors": [
      "Lucinda Gullison",
      "Feng Fu"
    ],
    "abstract": "Vaccine hesitancy and misinformation are significant barriers to achieving\nwidespread vaccination coverage. Smaller public health departments may lack the\nexpertise or resources to craft effective vaccine messaging. This paper\nexplores the potential of ChatGPT-augmented messaging to promote confidence in\nvaccination uptake.\n  We conducted a survey in which participants chose between pairs of\nvaccination messages and assessed which was more persuasive and to what extent.\nIn each pair, one message was the original, and the other was augmented by\nChatGPT. At the end of the survey, participants were informed that half of the\nmessages had been generated by ChatGPT. They were then asked to provide both\nquantitative and qualitative responses regarding how knowledge of a message's\nChatGPT origin affected their impressions.\n  Overall, ChatGPT-augmented messages were rated slightly higher than the\noriginal messages. These messages generally scored better when they were\nlonger. Respondents did not express major concerns about ChatGPT-generated\ncontent, nor was there a significant relationship between participants' views\non ChatGPT and their message ratings. Notably, there was a correlation between\nwhether a message appeared first or second in a pair and its score.\n  These results point to the potential of ChatGPT to enhance vaccine messaging,\nsuggesting a promising direction for future research on human-AI collaboration\nin public health communication.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09857v1",
    "published_date": "2025-04-14 04:06:46 UTC",
    "updated_date": "2025-04-14 04:06:46 UTC"
  },
  {
    "arxiv_id": "2505.14841v1",
    "title": "Beyond Pairwise Plasticity: Group-Level Spike Synchrony Facilitates Efficient Learning in Spiking Neural Networks",
    "authors": [
      "Yuchen Tian",
      "Assel Kembay",
      "Nhan Duy Truong",
      "Jason K. Eshraghian",
      "Omid Kavehei"
    ],
    "abstract": "Brain networks rely on precise spike timing and coordinated activity to\nsupport robust and energy-efficient learning. Inspired by these principles,\nspiking neural networks (SNNs) are widely regarded as promising candidates for\nlow-power, event-driven computing. However, most biologically-inspired learning\nrules employed in SNNs, including spike-timing-dependent plasticity (STDP),\nrely on isolated spike pairs and lack sensitivity to population-level activity.\nThis limits their stability and generalization, particularly in noisy and\nfast-changing environments. Motivated by biological observations that neural\nsynchrony plays a central role in learning and memory, we introduce a\nspike-synchrony-dependent plasticity (SSDP) rule that adjusts synaptic weights\nbased on the degree of coordinated firing among neurons. SSDP supports stable\nand scalable learning by encouraging neurons to form coherent activity\npatterns. One prominent outcome is a sudden transition from unstable to stable\ndynamics during training, suggesting that synchrony may drive convergence\ntoward equilibrium firing regimes. We demonstrate SSDP's effectiveness across\nmultiple network types, from minimal-layer models to spiking ResNets and\nSNN-Transformer. To our knowledge, this is the first application of a synaptic\nplasticity mechanism in a spiking transformer. SSDP operates in a fully\nevent-driven manner and incurs minimal computational cost, making it\nwell-suited for neuromorphic deployment. In this approach, local synaptic\nmodifications are associated with the collective dynamics of neural networks,\nresulting in a learning strategy that adheres to biological principles while\nmaintaining practical efficiency, these findings position SSDP as a\ngeneral-purpose optimization strategy for SNNs, while offering new insights\ninto population-based learning mechanisms in the brain.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "22 pages, 7 figures, 5 tables. This work proposes SSDP, a\n  biologically inspired spike-synchrony-dependent plasticity rule. We\n  demonstrate its effectiveness across shallow and deep spiking architectures\n  including Spiking-ResNet18 and SNN-Transformer",
    "pdf_url": "http://arxiv.org/pdf/2505.14841v1",
    "published_date": "2025-04-14 04:01:40 UTC",
    "updated_date": "2025-04-14 04:01:40 UTC"
  },
  {
    "arxiv_id": "2504.09855v1",
    "title": "PestMA: LLM-based Multi-Agent System for Informed Pest Management",
    "authors": [
      "Hongrui Shi",
      "Shunbao Li",
      "Zhipeng Yuan",
      "Po Yang"
    ],
    "abstract": "Effective pest management is complex due to the need for accurate,\ncontext-specific decisions. Recent advancements in large language models (LLMs)\nopen new possibilities for addressing these challenges by providing\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\nLLM-based pest management approaches often rely on a single-agent paradigm,\nwhich can limit their capacity to incorporate diverse external information,\nengage in systematic validation, and address complex, threshold-driven\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\nmanagement advice. Building on an editorial paradigm, PestMA features three\nspecialized agents, an Editor for synthesizing pest management recommendations,\na Retriever for gathering relevant external data, and a Validator for ensuring\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\nachieves an initial accuracy of 86.8% for pest management decisions, which\nincreases to 92.6% after validation. These results underscore the value of\ncollaborative agent-based workflows in refining and validating decisions,\nhighlighting the potential of LLM-based multi-agent systems to automate and\nenhance pest management processes.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.MA",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.09855v1",
    "published_date": "2025-04-14 03:53:59 UTC",
    "updated_date": "2025-04-14 03:53:59 UTC"
  },
  {
    "arxiv_id": "2504.09851v1",
    "title": "Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability",
    "authors": [
      "Aikaterini Maria Panteleaki",
      "Konstantinos Balaskas",
      "Georgios Zervakis",
      "Hussam Amrouch",
      "Iraklis Anagnostopoulos"
    ],
    "abstract": "As Deep Neural Networks (DNNs) continue to drive advancements in artificial\nintelligence, the design of hardware accelerators faces growing concerns over\nembodied carbon footprint due to complex fabrication processes. 3D integration\nimproves performance but introduces sustainability challenges, making\ncarbon-aware optimization essential. In this work, we propose a\ncarbon-efficient design methodology for 3D DNN accelerators, leveraging\napproximate computing and genetic algorithm-based design space exploration to\noptimize Carbon Delay Product (CDP). By integrating area-efficient approximate\nmultipliers into Multiply-Accumulate (MAC) units, our approach effectively\nreduces silicon area and fabrication overhead while maintaining high\ncomputational accuracy. Experimental evaluations across three technology nodes\n(45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30%\nwith negligible accuracy drop.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Submitted in ISVLSI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09851v1",
    "published_date": "2025-04-14 03:48:37 UTC",
    "updated_date": "2025-04-14 03:48:37 UTC"
  },
  {
    "arxiv_id": "2504.09848v1",
    "title": "A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science",
    "authors": [
      "Jie Feng",
      "Jinwei Zeng",
      "Qingyue Long",
      "Hongyi Chen",
      "Jie Zhao",
      "Yanxin Xi",
      "Zhilun Zhou",
      "Yuan Yuan",
      "Shengyuan Wang",
      "Qingbin Zeng",
      "Songwei Li",
      "Yunke Zhang",
      "Yuming Lin",
      "Tong Li",
      "Jingtao Ding",
      "Chen Gao",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "Over the past year, the development of large language models (LLMs) has\nbrought spatial intelligence into focus, with much attention on vision-based\nembodied intelligence. However, spatial intelligence spans a broader range of\ndisciplines and scales, from navigation and urban planning to remote sensing\nand earth science. What are the differences and connections between spatial\nintelligence across these fields? In this paper, we first review human spatial\ncognition and its implications for spatial intelligence in LLMs. We then\nexamine spatial memory, knowledge representations, and abstract reasoning in\nLLMs, highlighting their roles and connections. Finally, we analyze spatial\nintelligence across scales -- from embodied to urban and global levels --\nfollowing a framework that progresses from spatial memory and understanding to\nspatial reasoning and intelligence. Through this survey, we aim to provide\ninsights into interdisciplinary spatial intelligence research and inspire\nfuture studies.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09848v1",
    "published_date": "2025-04-14 03:38:31 UTC",
    "updated_date": "2025-04-14 03:38:31 UTC"
  },
  {
    "arxiv_id": "2504.09846v1",
    "title": "GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals",
    "authors": [
      "Asiful Arefeen",
      "Saman Khamesian",
      "Maria Adela Grando",
      "Bithika Thompson",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose)\nincreases the risk of chronic complications such as neuropathy, nephropathy,\nand cardiovascular disease. Current technologies like continuous subcutaneous\ninsulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model\nspecific aspects of glycemic control-like hypoglycemia prediction or insulin\ndelivery. Similarly, most digital twin approaches in diabetes management\nsimulate only physiological processes. These systems lack the ability to offer\nalternative treatment scenarios that support proactive behavioral\ninterventions. To address this, we propose GlyTwin, a novel digital twin\nframework that uses counterfactual explanations to simulate optimal treatments\nfor glucose regulation. Our approach helps patients and caregivers modify\nbehaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose\nevents. GlyTwin generates behavioral treatment suggestions that proactively\nprevent hyperglycemia by recommending small adjustments to daily choices,\nreducing both frequency and duration of these events. Additionally, it\nincorporates stakeholder preferences into the intervention design, making\nrecommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a\nnewly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D)\npatients on automated insulin delivery systems over 26 days. Results show\nGlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6%\nvalid and 86% effective interventions. These findings demonstrate the promise\nof counterfactual-driven digital twins in delivering personalized healthcare.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09846v1",
    "published_date": "2025-04-14 03:32:39 UTC",
    "updated_date": "2025-04-14 03:32:39 UTC"
  },
  {
    "arxiv_id": "2504.09844v2",
    "title": "OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training",
    "authors": [
      "Juntao Zhao",
      "Qi Lu",
      "Wei Jia",
      "Borui Wan",
      "Lei Zuo",
      "Junda Feng",
      "Jianyu Jiang",
      "Yangrui Chen",
      "Shuaishuai Cao",
      "Jialing He",
      "Kaihua Jiang",
      "Yuanzhe Hu",
      "Shibiao Nong",
      "Yanghua Peng",
      "Haibin Lin",
      "Xin Liu",
      "Chuan Wu"
    ],
    "abstract": "Modern frameworks for training large foundation models (LFMs) employ\ndataloaders in a data-parallel manner, with each loader processing a disjoint\nsubset of training data. Under multisource preprocessing, two fundamental\nchallenges exist. First, due to the quadratic computational complexity of the\nattention operator, the non-uniform sample distribution over data-parallel\nranks leads to significant workload imbalance among dataloaders, degrading the\ntraining efficiency. Second, supporting diverse data sources requires\nper-dataset file access states that are redundantly replicated across parallel\nloaders, consuming excessive memory. This also hinders dynamic data mixing\n(e.g., curriculum learning) and causes redundant access/memory overhead in\nhybrid parallelism.\n  We present Omniload, an industrial-grade distributed data loading\narchitecture for LFMs, with four innovations: (1) Disaggregated data\npreprocessing via role-specific actors (Source Loaders/Data Constructors) to\neliminate source and parallelism redundant data access and ensure multisource\nscalability. (2) Centralized and declarative data plane for elastic multisource\norchestration, such as long-short context, multimodality, and curriculum\nlearning. (3) Multi-level auto-partitioning and scaling mechanism for source\nloaders under heterogeneous preprocessing costs. (4) Shadow loaders with\ndifferential checkpointing for fault recovery without workflow interruption.\nDeployed on production clusters scaling to multi-thousand GPUs, Omniload\nachieves: (1) 4.5x end-to-end training throughput improvement, (2) 13.5x\nreduction in CPU memory usage.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09844v2",
    "published_date": "2025-04-14 03:31:22 UTC",
    "updated_date": "2025-05-18 15:39:35 UTC"
  },
  {
    "arxiv_id": "2504.09841v1",
    "title": "StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models",
    "authors": [
      "Yang Feng",
      "Xudong Pan"
    ],
    "abstract": "The proliferation of autonomous agents powered by large language models\n(LLMs) has revolutionized popular business applications dealing with tabular\ndata, i.e., tabular agents. Although LLMs are observed to be vulnerable against\nprompt injection attacks from external data sources, tabular agents impose\nstrict data formats and predefined rules on the attacker's payload, which are\nineffective unless the agent navigates multiple layers of structural data to\nincorporate the payload. To address the challenge, we present a novel attack\ntermed StruPhantom which specifically targets black-box LLM-powered tabular\nagents. Our attack designs an evolutionary optimization procedure which\ncontinually refines attack payloads via the proposed constrained Monte Carlo\nTree Search augmented by an off-topic evaluator. StruPhantom helps\nsystematically explore and exploit the weaknesses of target applications to\nachieve goal hijacking. Our evaluation validates the effectiveness of\nStruPhantom across various LLM-based agents, including those on real-world\nplatforms, and attack scenarios. Our attack achieves over 50% higher success\nrates than baselines in enforcing the application's response to contain\nphishing links or malicious codes.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2504.09841v1",
    "published_date": "2025-04-14 03:22:04 UTC",
    "updated_date": "2025-04-14 03:22:04 UTC"
  },
  {
    "arxiv_id": "2504.09839v1",
    "title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis",
    "authors": [
      "Zhisheng Zhang",
      "Derui Wang",
      "Qianyi Yang",
      "Pengyang Huang",
      "Junhan Pu",
      "Yuxin Cao",
      "Kai Ye",
      "Jie Hao",
      "Yixian Yang"
    ],
    "abstract": "Speech synthesis technology has brought great convenience, while the\nwidespread usage of realistic deepfake audio has triggered hazards. Malicious\nadversaries may unauthorizedly collect victims' speeches and clone a similar\nvoice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the\nexisting defense methods cannot effectively prevent deepfake exploitation and\nare vulnerable to robust training techniques. Therefore, a more effective and\nrobust data protection method is urgently needed. In response, we propose a\ndefensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users'\naudio before uploading by embedding imperceptible perturbations on original\nspeeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a\nrobust and universal proactive protection technique, \\textbf{S}peech\n\\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a\nsurrogate model to generate universally applicable perturbation for generative\nsynthetic models. Moreover, we optimize the human perception of embedded\nperturbation in terms of time and frequency domains. To evaluate our method\ncomprehensively, we conduct extensive experiments across advanced models and\ndatasets, both subjectively and objectively. Our experimental results\ndemonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection\neffectiveness and transferability and is highly robust against advanced\nadaptive adversaries. Moreover, SafeSpeech has real-time capability in\nreal-world tests. The source code is available at\n\\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to USENIX Security 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.09839v1",
    "published_date": "2025-04-14 03:21:23 UTC",
    "updated_date": "2025-04-14 03:21:23 UTC"
  },
  {
    "arxiv_id": "2504.09831v1",
    "title": "Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand",
    "authors": [
      "Korel Gundem",
      "Zhengling Qi"
    ],
    "abstract": "In this paper, we study the offline sequential feature-based pricing and\ninventory control problem where the current demand depends on the past demand\nlevels and any demand exceeding the available inventory is lost. Our goal is to\nleverage the offline dataset, consisting of past prices, ordering quantities,\ninventory levels, covariates, and censored sales levels, to estimate the\noptimal pricing and inventory control policy that maximizes long-term profit.\nWhile the underlying dynamic without censoring can be modeled by Markov\ndecision process (MDP), the primary obstacle arises from the observed process\nwhere demand censoring is present, resulting in missing profit information, the\nfailure of the Markov property, and a non-stationary optimal policy. To\novercome these challenges, we first approximate the optimal policy by solving a\nhigh-order MDP characterized by the number of consecutive censoring instances,\nwhich ultimately boils down to solving a specialized Bellman equation tailored\nfor this problem. Inspired by offline reinforcement learning and survival\nanalysis, we propose two novel data-driven algorithms to solving these Bellman\nequations and, thus, estimate the optimal policy. Furthermore, we establish\nfinite sample regret bounds to validate the effectiveness of these algorithms.\nFinally, we conduct numerical experiments to demonstrate the efficacy of our\nalgorithms in estimating the optimal policy. To the best of our knowledge, this\nis the first data-driven approach to learning optimal pricing and inventory\ncontrol policies in a sequential decision-making environment characterized by\ncensored and dependent demand. The implementations of the proposed algorithms\nare available at https://github.com/gundemkorel/Inventory_Pricing_Control",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.AP",
      "stat.TH",
      "90B05, 68T05, 90C40, 62N02"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09831v1",
    "published_date": "2025-04-14 02:57:51 UTC",
    "updated_date": "2025-04-14 02:57:51 UTC"
  },
  {
    "arxiv_id": "2504.09812v1",
    "title": "Efficient Multi-Task Modeling through Automated Fusion of Trained Models",
    "authors": [
      "Jingxuan Zhou",
      "Weidong Bao",
      "Ji Wang",
      "Zhengyi Zhong",
      "Dayu Zhang"
    ],
    "abstract": "Although multi-task learning is widely applied in intelligent services,\ntraditional multi-task modeling methods often require customized designs based\non specific task combinations, resulting in a cumbersome modeling process.\nInspired by the rapid development and excellent performance of single-task\nmodels, this paper proposes an efficient multi-task modeling method that can\nautomatically fuse trained single-task models with different structures and\ntasks to form a multi-task model. As a general framework, this method allows\nmodelers to simply prepare trained models for the required tasks, simplifying\nthe modeling process while fully utilizing the knowledge contained in the\ntrained models. This eliminates the need for excessive focus on task\nrelationships and model structure design. To achieve this goal, we consider the\nstructural differences among various trained models and employ model\ndecomposition techniques to hierarchically decompose them into multiple\noperable model components. Furthermore, we have designed an Adaptive Knowledge\nFusion (AKF) module based on Transformer, which adaptively integrates\nintra-task and inter-task knowledge based on model components. Through the\nproposed method, we achieve efficient and automated construction of multi-task\nmodels, and its effectiveness is verified through extensive experiments on\nthree datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09812v1",
    "published_date": "2025-04-14 02:21:45 UTC",
    "updated_date": "2025-04-14 02:21:45 UTC"
  },
  {
    "arxiv_id": "2504.09809v2",
    "title": "See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs",
    "authors": [
      "Zhimin Li",
      "Haichao Miao",
      "Xinyuan Yan",
      "Valerio Pascucci",
      "Matthew Berger",
      "Shusen Liu"
    ],
    "abstract": "Recent developments in multimodal large language models (MLLM) have equipped\nlanguage models to reason about vision and language jointly. This permits MLLMs\nto both perceive and answer questions about data visualization across a variety\nof designs and tasks. Applying MLLMs to a broad range of visualization tasks\nrequires us to properly evaluate their capabilities, and the most common way to\nconduct evaluation is through measuring a model's visualization reasoning\ncapability, analogous to how we would evaluate human understanding of\nvisualizations (e.g., visualization literacy). However, we found that in the\ncontext of visualization question answering (VisQA), how an MLLM perceives and\nreasons about visualizations can be fundamentally different from how humans\napproach the same problem. During the evaluation, even without visualization,\nthe model could correctly answer a substantial portion of the visualization\ntest questions, regardless of whether any selection options were provided. We\nhypothesize that the vast amount of knowledge encoded in the language model\npermits factual recall that supersedes the need to seek information from the\nvisual signal. It raises concerns that the current VisQA evaluation may not\nfully capture the models' visualization reasoning capabilities. To address\nthis, we propose a comprehensive sanity check framework that integrates a\nrule-based decision tree and a sanity check table to disentangle the effects of\n\"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This\nvalidates VisQA datasets for evaluation, highlighting where models are truly\n\"seeing\", positively or negatively affected by the factual recall, or relying\non inductive biases for question answering. Our study underscores the need for\ncareful consideration in designing future visualization understanding studies\nwhen utilizing MLLMs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09809v2",
    "published_date": "2025-04-14 02:19:28 UTC",
    "updated_date": "2025-04-21 20:52:11 UTC"
  },
  {
    "arxiv_id": "2504.09802v1",
    "title": "Training Small Reasoning LLMs with Cognitive Preference Alignment",
    "authors": [
      "Wenrui Cai",
      "Chengyu Wang",
      "Junbing Yan",
      "Jun Huang",
      "Xiangzhong Fang"
    ],
    "abstract": "The reasoning capabilities of large language models (LLMs), such as OpenAI's\no1 and DeepSeek-R1, have seen substantial advancements through deep thinking.\nHowever, these enhancements come with significant resource demands,\nunderscoring the need to explore strategies to train effective reasoning LLMs\nwith far fewer parameters. A critical challenge is that smaller models have\ndifferent capacities and cognitive trajectories than their larger counterparts.\nHence, direct distillation of chain-of-thought (CoT) results from large LLMs to\nsmaller ones can be sometimes ineffective and requires a huge amount of\nannotated data. In this paper, we introduce a novel framework called\nCritique-Rethink-Verify (CRV), designed for training smaller yet powerful\nreasoning LLMs. Our CRV framework consists of multiple LLM agents, each\nspecializing in unique abilities: (i) critiquing the CoTs according to the\ncognitive capabilities of smaller models, (ii) rethinking and refining these\nCoTs based on the critiques, and (iii) verifying the correctness of the refined\nresults. We further propose the cognitive preference optimization (CogPO)\nalgorithm to enhance the reasoning abilities of smaller models by aligning\nthoughts of these models with their cognitive capacities. Comprehensive\nevaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV\nand CogPO, which outperforms other training methods by a large margin.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09802v1",
    "published_date": "2025-04-14 02:03:54 UTC",
    "updated_date": "2025-04-14 02:03:54 UTC"
  },
  {
    "arxiv_id": "2504.09800v1",
    "title": "Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks",
    "authors": [
      "Jingxuan Zhou",
      "Weidong Bao",
      "Ji Wang",
      "Dayu Zhang",
      "Xiongtao Zhang",
      "Yaohong Zhang"
    ],
    "abstract": "Federated learning has been extensively studied and applied due to its\nability to ensure data security in distributed environments while building\nbetter models. However, clients participating in federated learning still face\nlimitations, as clients with different structures or tasks cannot participate\nin learning together. In view of this, constructing a federated learning\nframework that allows collaboration between clients with different model\nstructures and performing different tasks, enabling them to share valuable\nknowledge to enhance model efficiency, holds significant practical implications\nfor the widespread application of federated learning. To achieve this goal, we\npropose a multi-task federated learning with encoder-decoder structure (M-Fed).\nSpecifically, given the widespread adoption of the encoder-decoder architecture\nin current models, we leverage this structure to share intra-task knowledge\nthrough traditional federated learning methods and extract general knowledge\nfrom the encoder to achieve cross-task knowledge sharing. The training process\nis similar to traditional federated learning, and we incorporate local decoder\nand global decoder information into the loss function. The local decoder\niteratively updates and gradually approaches the global decoder until\nsufficient cross-task knowledge sharing is achieved. Our method is lightweight\nand modular, demonstrating innovation compared to previous research. It enables\nclients performing different tasks to share general knowledge while maintaining\nthe efficiency of traditional federated learning systems. We conducted\nexperiments on two widely used benchmark datasets to verify the feasibility of\nM-Fed and compared it with traditional methods. The experimental results\ndemonstrate the effectiveness of M-Fed in multi-task federated learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09800v1",
    "published_date": "2025-04-14 02:01:39 UTC",
    "updated_date": "2025-04-14 02:01:39 UTC"
  },
  {
    "arxiv_id": "2504.09797v1",
    "title": "IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme",
    "authors": [
      "Dinh Dai Quan Tran",
      "Hoang-Thien Nguyen. Thanh-Huy Nguyen",
      "Gia-Van To",
      "Tien-Huy Nguyen",
      "Quan Nguyen"
    ],
    "abstract": "Semi-Supervised Semantic Segmentation (SSSS) aims to improve segmentation\naccuracy by leveraging a small set of labeled images alongside a larger pool of\nunlabeled data. Recent advances primarily focus on pseudo-labeling, consistency\nregularization, and co-training strategies. However, existing methods struggle\nto balance global semantic representation with fine-grained local feature\nextraction. To address this challenge, we propose a novel tri-branch\nsemi-supervised segmentation framework incorporating a dual-teacher strategy,\nnamed IGL-DT. Our approach employs SwinUnet for high-level semantic guidance\nthrough Global Context Learning and ResUnet for detailed feature refinement via\nLocal Regional Learning. Additionally, a Discrepancy Learning mechanism\nmitigates over-reliance on a single teacher, promoting adaptive feature\nlearning. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms state-of-the-art approaches, achieving superior segmentation\nperformance across various data regimes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.09797v1",
    "published_date": "2025-04-14 01:51:29 UTC",
    "updated_date": "2025-04-14 01:51:29 UTC"
  },
  {
    "arxiv_id": "2504.09795v1",
    "title": "VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents",
    "authors": [
      "Ryota Tanaka",
      "Taichi Iki",
      "Taku Hasegawa",
      "Kyosuke Nishida",
      "Kuniko Saito",
      "Jun Suzuki"
    ],
    "abstract": "We aim to develop a retrieval-augmented generation (RAG) framework that\nanswers questions over a corpus of visually-rich documents presented in mixed\nmodalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In\nthis paper, we introduce a new RAG framework, VDocRAG, which can directly\nunderstand varied documents and modalities in a unified image format to prevent\nmissing information that occurs by parsing documents to obtain text. To improve\nthe performance, we propose novel self-supervised pre-training tasks that adapt\nlarge vision-language models for retrieval by compressing visual information\ninto dense token representations while aligning them with textual content in\ndocuments. Furthermore, we introduce OpenDocVQA, the first unified collection\nof open-domain document visual question answering datasets, encompassing\ndiverse document types and formats. OpenDocVQA provides a comprehensive\nresource for training and evaluating retrieval and question answering models on\nvisually-rich documents in an open-domain setting. Experiments show that\nVDocRAG substantially outperforms conventional text-based RAG and has strong\ngeneralization capability, highlighting the potential of an effective RAG\nparadigm for real-world documents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by CVPR 2025; project page: https://vdocrag.github.io",
    "pdf_url": "http://arxiv.org/pdf/2504.09795v1",
    "published_date": "2025-04-14 01:50:33 UTC",
    "updated_date": "2025-04-14 01:50:33 UTC"
  },
  {
    "arxiv_id": "2504.13926v2",
    "title": "A Multi-Layered Research Framework for Human-Centered AI: Defining the Path to Explainability and Trust",
    "authors": [
      "Chameera De Silva",
      "Thilina Halloluwa",
      "Dhaval Vyas"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) into high-stakes domains such\nas healthcare, finance, and autonomous systems is often constrained by concerns\nover transparency, interpretability, and trust. While Human-Centered AI (HCAI)\nemphasizes alignment with human values, Explainable AI (XAI) enhances\ntransparency by making AI decisions more understandable. However, the lack of a\nunified approach limits AI's effectiveness in critical decision-making\nscenarios. This paper presents a novel three-layered framework that bridges\nHCAI and XAI to establish a structured explainability paradigm. The framework\ncomprises (1) a foundational AI model with built-in explainability mechanisms,\n(2) a human-centered explanation layer that tailors explanations based on\ncognitive load and user expertise, and (3) a dynamic feedback loop that refines\nexplanations through real-time user interaction. The framework is evaluated\nacross healthcare, finance, and software development, demonstrating its\npotential to enhance decision-making, regulatory compliance, and public trust.\nOur findings advance Human-Centered Explainable AI (HCXAI), fostering AI\nsystems that are transparent, adaptable, and ethically aligned.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "I am requesting this withdrawal because I believe the current version\n  requires significant revisions and restructuring to better reflect the\n  intended research contributions. I plan to substantially improve the work and\n  may resubmit a revised version in the future. Thank you for your\n  understanding and support",
    "pdf_url": "http://arxiv.org/pdf/2504.13926v2",
    "published_date": "2025-04-14 01:29:30 UTC",
    "updated_date": "2025-04-26 01:53:27 UTC"
  },
  {
    "arxiv_id": "2504.09789v1",
    "title": "EquiVDM: Equivariant Video Diffusion Models with Temporally Consistent Noise",
    "authors": [
      "Chao Liu",
      "Arash Vahdat"
    ],
    "abstract": "Temporally consistent video-to-video generation is essential for applications\nof video diffusion models in areas such as sim-to-real, style-transfer, video\nupsampling, etc. In this paper, we propose a video diffusion framework that\nleverages temporally consistent noise to generate coherent video frames without\nspecialized modules or additional constraints. We show that the standard\ntraining objective of diffusion models, when applied with temporally consistent\nnoise, encourages the model to be equivariant to spatial transformations in\ninput video and noise. This enables our model to better follow motion patterns\nfrom the input video, producing aligned motion and high-fidelity frames.\nFurthermore, we extend our approach to 3D-consistent video generation by\nattaching noise as textures on 3D meshes, ensuring 3D consistency in\nsim-to-real applications. Experimental results demonstrate that our method\nsurpasses state-of-the-art baselines in motion alignment, 3D consistency, and\nvideo quality while requiring only a few sampling steps in practice.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09789v1",
    "published_date": "2025-04-14 01:26:29 UTC",
    "updated_date": "2025-04-14 01:26:29 UTC"
  },
  {
    "arxiv_id": "2504.09781v1",
    "title": "Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning",
    "authors": [
      "Jingtian Wu",
      "Claire Cardie"
    ],
    "abstract": "While large language models (LLMs) have demonstrated strong capabilities in\ntasks like question answering and fact verification, they continue to suffer\nfrom hallucinations and reasoning errors, especially in multi-hop tasks that\nrequire integration of multiple information sources. Current methods address\nthese issues through retrieval-based techniques (grounding reasoning in\nexternal evidence), reasoning-based approaches (enhancing coherence via\nimproved prompting), or hybrid strategies combining both elements. One\nprominent hybrid method, ReAct, has outperformed purely retrieval-based or\nreasoning-based approaches; however, it lacks internal verification of\nintermediate reasoning steps, allowing potential errors to propagate through\ncomplex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a\nnovel framework that extends iterative reasoning-and-retrieval methods, such as\nReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to\nindependently evaluate multiple candidate answers and their associated\nreasoning generated by separate LLM agents. The judge is asked to select the\nanswer that it considers the most factually grounded and logically coherent\nbased on the presented reasoning and evidence, or synthesizes a new answer\nusing available evidence and its pre-trained knowledge if all candidates are\ninadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA,\nMuSiQue) and fact-verification (FEVER) demonstrate that RC consistently\noutperforms state-of-the-art few-shot prompting methods without task-specific\nfine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09781v1",
    "published_date": "2025-04-14 00:56:08 UTC",
    "updated_date": "2025-04-14 00:56:08 UTC"
  },
  {
    "arxiv_id": "2504.09779v1",
    "title": "\"All Roads Lead to ChatGPT\": How Generative AI is Eroding Social Interactions and Student Learning Communities",
    "authors": [
      "Irene Hou",
      "Owen Man",
      "Kate Hamilton",
      "Srishty Muthusekaran",
      "Jeffin Johnykutty",
      "Leili Zadeh",
      "Stephen MacNeil"
    ],
    "abstract": "The widespread adoption of generative AI is already impacting learning and\nhelp-seeking. While the benefits of generative AI are well-understood, recent\nstudies have also raised concerns about increased potential for cheating and\nnegative impacts on students' metacognition and critical thinking. However, the\npotential impacts on social interactions, peer learning, and classroom dynamics\nare not yet well understood. To investigate these aspects, we conducted 17\nsemi-structured interviews with undergraduate computing students across seven\nR1 universities in North America. Our findings suggest that help-seeking\nrequests are now often mediated by generative AI. For example, students often\nredirected questions from their peers to generative AI instead of providing\nassistance themselves, undermining peer interaction. Students also reported\nfeeling increasingly isolated and demotivated as the social support systems\nthey rely on begin to break down. These findings are concerning given the\nimportant role that social interactions play in students' learning and sense of\nbelonging.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 1 table. To be published in the Proceedings of the 2025\n  Innovation and Technology in Computer Science Education (ITiCSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.09779v1",
    "published_date": "2025-04-14 00:40:58 UTC",
    "updated_date": "2025-04-14 00:40:58 UTC"
  },
  {
    "arxiv_id": "2504.09777v1",
    "title": "Reasoning without Regret",
    "authors": [
      "Tarun Chitra"
    ],
    "abstract": "Chain-of-thought reasoning enables large language models to solve multi-step\ntasks by framing problem solving as sequential decision problems. Outcome-based\nrewards, which provide feedback only on final answers, show impressive success,\nbut face challenges with credit assignment and slow convergence. In contrast,\nprocedure-based rewards offer efficient step-level feedback, but typically\nrequire costly human supervision. We introduce \\emph{Backwards Adaptive Reward\nShaping} (BARS), a no-regret framework that converts sparse outcomes-based\nrewards into effective procedure-based signals. BARS uses sparse rewards\ngenerated from terminal-state priors and cover trees to scale rewards while\npreventing exploitation. With Bellman contraction and $(\\Delta, \\epsilon)$-gap\nrewards, our backward Euler solver achieves $\\epsilon$-accuracy in\n$O\\left((R_{\\max}/\\Delta)\\log(1/\\epsilon)\\right)$ iterations with $O(\\log T)$\ndynamic regret over $T$ rounds. Our analysis, based on generic chaining,\ncontinuous scaling limits, and non-linear Feynman-Kac bounds, connects recent\noutcome-based methods' empirical successes with the benefits of intermediate\nsupervision. Combined, this provides the first rigorous no-regret algorithm for\noutcome reward shaping, providing a theoretical foundation for the empirical\nsuccess of DeepSeek's R1.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09777v1",
    "published_date": "2025-04-14 00:34:20 UTC",
    "updated_date": "2025-04-14 00:34:20 UTC"
  },
  {
    "arxiv_id": "2504.09775v3",
    "title": "Understanding and Optimizing Multi-Stage AI Inference Pipelines",
    "authors": [
      "Abhimanyu Rajeshkumar Bambhaniya",
      "Hanjiang Wu",
      "Suvinay Subramanian",
      "Sudarshan Srinivasan",
      "Souvik Kundu",
      "Amir Yazdanbakhsh",
      "Midhilesh Elavazhagan",
      "Madhu Kumar",
      "Tushar Krishna"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has driven the need for\nincreasingly sophisticated inference pipelines and hardware platforms. Modern\nLLM serving extends beyond traditional prefill-decode workflows, incorporating\nmulti-stage processes such as Retrieval Augmented Generation (RAG), key-value\n(KV) cache retrieval, dynamic model routing, and multi step reasoning. These\nstages exhibit diverse computational demands, requiring distributed systems\nthat integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,\nexisting simulators lack the fidelity to model these heterogeneous,\nmulti-engine workflows, limiting their ability to inform architectural\ndecisions.\n  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM\ninference Execution Simulator. HERMES models diverse request stages; including\nRAG, KV retrieval, reasoning, prefill, and decode across complex hardware\nhierarchies. HERMES supports heterogeneous clients executing multiple models\nconcurrently unlike prior frameworks while incorporating advanced batching\nstrategies and multi-level memory hierarchies. By integrating real hardware\ntraces with analytical modeling, HERMES captures critical trade-offs such as\nmemory bandwidth contention, inter-cluster communication latency, and batching\nefficiency in hybrid CPU-accelerator deployments. Through case studies, we\nexplore the impact of reasoning stages on end-to-end latency, optimal batching\nstrategies for hybrid pipelines, and the architectural implications of remote\nKV cache retrieval. HERMES empowers system designers to navigate the evolving\nlandscape of LLM inference, providing actionable insights into optimizing\nhardware-software co-design for next-generation AI workloads.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "Inference System Design for Multi-Stage AI Inference Pipelines. 13\n  Pages, 15 Figues, 3 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.09775v3",
    "published_date": "2025-04-14 00:29:49 UTC",
    "updated_date": "2025-04-20 19:57:16 UTC"
  },
  {
    "arxiv_id": "2504.09772v1",
    "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
    "authors": [
      "Can Jin",
      "Hongwu Peng",
      "Qixin Zhang",
      "Yujin Tang",
      "Dimitris N. Metaxas",
      "Tong Che"
    ],
    "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a\npromising path toward solving complex, real-world tasks that single-agent\nsystems often struggle to manage. While recent advancements in test-time\nscaling (TTS) have significantly improved single-agent performance on\nchallenging reasoning tasks, how to effectively scale collaboration and\nreasoning in MAS remains an open question. In this work, we introduce an\nadaptive multi-agent framework designed to enhance collaborative reasoning\nthrough both model-level training and system-level coordination. We construct\nM500, a high-quality dataset containing 500 multi-agent collaborative reasoning\ntraces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a\nmodel optimized for multi-agent collaboration. To further enable adaptive\nreasoning, we propose a novel CEO agent that dynamically manages the discussion\nprocess, guiding agent collaboration and adjusting reasoning depth for more\neffective problem-solving. Evaluated in an open-source MAS across a range of\ntasks-including general understanding, mathematical reasoning, and coding-our\nsystem significantly outperforms strong baselines. For instance, M1-32B\nachieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on\nMBPP-Sanitized, matching the performance of state-of-the-art models like\nDeepSeek-R1 on some tasks. These results highlight the importance of both\nlearned collaboration and adaptive coordination in scaling multi-agent\nreasoning. Code is available at https://github.com/jincan333/MAS-TTS",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.09772v1",
    "published_date": "2025-04-14 00:27:45 UTC",
    "updated_date": "2025-04-14 00:27:45 UTC"
  },
  {
    "arxiv_id": "2504.09763v1",
    "title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems",
    "authors": [
      "Zaid Khan",
      "Elias Stengel-Eskin",
      "Archiki Prasad",
      "Jaemin Cho",
      "Mohit Bansal"
    ],
    "abstract": "Scientists often infer abstract procedures from specific instances of\nproblems and use the abstractions to generate new, related instances. For\nexample, programs encoding the formal rules and properties of a system have\nbeen useful in fields ranging from RL (procedural environments) to physics\n(simulation engines). These programs can be seen as functions which execute to\ndifferent outputs based on their parameterizations (e.g., gridworld\nconfiguration or initial physical conditions). We introduce the term EFA\n(Executable Functional Abstraction) to denote such programs for math problems.\nEFA-like constructs have been shown to be useful for math reasoning as problem\ngenerators for stress-testing models. However, prior work has been limited to\nabstractions for grade-school math (whose simple rules are easy to encode in\nprograms), while generating EFAs for advanced math has thus far required human\nengineering. We explore the automatic construction of EFAs for advanced math\nproblems. We operationalize the task of automatically constructing EFAs as a\nprogram synthesis task, and develop EFAGen, which conditions an LLM on a seed\nmath problem and its step-by-step solution to generate candidate EFA programs\nthat are faithful to the generalized problem and solution class underlying the\nseed problem. Furthermore, we formalize properties any valid EFA must possess\nin terms of executable unit tests, and show how the tests can be used as\nverifiable rewards to train LLMs to become better writers of EFAs. We\ndemonstrate that EFAs constructed by EFAGen behave rationally by remaining\nfaithful to seed problems, produce learnable problem variations, and that\nEFAGen can infer EFAs across multiple diverse sources of competition-level math\nproblems. Finally, we show downstream uses of model-written EFAs e.g. finding\nproblem variations that are harder or easier for a learner to solve, as well as\ndata generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project Page: https://zaidkhan.me/EFAGen/",
    "pdf_url": "http://arxiv.org/pdf/2504.09763v1",
    "published_date": "2025-04-14 00:06:48 UTC",
    "updated_date": "2025-04-14 00:06:48 UTC"
  },
  {
    "arxiv_id": "2504.09762v1",
    "title": "(How) Do reasoning models reason?",
    "authors": [
      "Subbarao Kambhampati",
      "Kaya Stechly",
      "Karthik Valmeekam"
    ],
    "abstract": "We will provide a broad unifying perspective on the recent breed of Large\nReasoning Models (LRMs) such as OpenAI o1 and DeepSeek R1, including their\npromise, sources of power, misconceptions and limitations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages (A version appears in The Annals of New York Academy of\n  Sciences)",
    "pdf_url": "http://arxiv.org/pdf/2504.09762v1",
    "published_date": "2025-04-14 00:03:34 UTC",
    "updated_date": "2025-04-14 00:03:34 UTC"
  }
]