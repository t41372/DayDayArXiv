{
  "date": "2025-04-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-04-14的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文热点集中在 **大型语言模型 (LLM) 的推理能力** 上，研究者们提出了多种新方法来提升性能、进行验证、提高效率和实现规模化扩展，例如 **WiSE-FT** 权重集成、**Heimdall** 验证器、**NoThinking** 推理策略以及针对机器翻译和数学问题的 **R1-Zero** 类强化学习框架。同时，**AI 安全与对齐** 依然是焦点，涵盖了说服安全、模型遗忘的 **Coreset 效应**、多模态安全以及 **RealSafe-R1** 等安全对齐模型。**多模态模型 (MLLM)** 领域也十分活跃，尤其在视频理解、视觉问答 (VQA)、文档处理和基准测试方面有诸多进展。此外，大量 **新的基准和数据集** 被提出，覆盖了网页助手、科学发现、OOD 检测、医疗影像、机器人规划等多个领域。\n\n**重点论文概览：**\n\n**LLM 推理与性能提升**\n\n*   **权重集成提升语言模型推理能力 (Weight Ensembling Improves Reasoning in Language Models)**\n    本文发现简单的权重插值方法 **WiSE-FT**（将最新 SFT 检查点与早期检查点结合）能显著恢复 Pass@k 指标，同时提升 Pass@1，改善测试时扩展性，并优于仅使用温度缩放等解码策略。研究还形式化了 Pass@k 的偏见-方差权衡。\n\n*   **推理模型无需思考也能有效 (Reasoning Models Can Be Effective Without Thinking)**\n    挑战了显式长思维链 (Thinking) 的必要性。研究发现，通过简单提示绕过思考过程 (称为 **NoThinking**) 在控制 token 数量时，尤其在低预算下，效果惊人地好，甚至优于 Thinking。基于此，提出并行扩展 NoThinking 并聚合结果的有效方法。\n\n*   **Heimdall：生成式验证的测试时扩展 (Heimdall: test-time scaling on the generative verification)**\n    提出了 **Heimdall**，一个用于长 CoT 验证的 LLM，通过纯强化学习将数学问题解决方案的验证准确率从 62.5% 提升到 94.5% (采样扩展后达 97.5%)。进一步提出 **Pessimistic Verification** 策略，利用 Heimdall 判断并选择最可靠的解，显著提升了 AIME2025 等任务的解题准确率。\n\n*   **无悔推理 (Reasoning without Regret)**\n    提出了 **BARS (Backwards Adaptive Reward Shaping)** 框架，一种将稀疏的结果奖励（outcome-based rewards）转化为有效的过程奖励（procedure-based signals）的无悔（no-regret）方法，为 DeepSeek R1 等模型的成功提供了理论基础，解决了信用分配和收敛慢的问题。\n\n*   **通过认知偏好对齐训练小型推理 LLM (Training Small Reasoning LLMs with Cognitive Preference Alignment)**\n    针对小型 LLM 推理能力训练的挑战，提出了 **CRV (Critique-Rethink-Verify)** 框架，利用多个 LLM agent 专门进行批判、反思优化和验证 CoT。并提出 **CogPO (Cognitive Preference Optimization)** 算法，使模型思维与其认知能力对齐，显著提升了小型模型在推理基准上的表现。\n\n*   **两人智慧胜一人：多智能体协作推理的测试时扩展 (Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning)**\n    为解决多智能体系统 (MAS) 中的协作推理扩展问题，构建了高质量协作推理数据集 **M500**，并训练了优化协作的模型 **M1-32B**。同时提出 **CEO agent** 动态管理讨论过程，调整推理深度，显著提升了 MAS 在通用理解、数学和代码任务上的性能。\n\n*   **通过强化学习实现深度推理翻译 (Deep Reasoning Translation via Reinforcement Learning)**\n    介绍 **DeepTrans** 模型，利用强化学习进行自由翻译。构建了基于预定义标准的奖励模型，指导模型思考和翻译过程，无需标注数据，在文学翻译等任务上超越了强基线。\n\n*   **MT-R1-Zero：通过类 R1-Zero 强化学习推进基于 LLM 的机器翻译 (MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning)**\n    首次将 R1-Zero 强化学习框架开源应用于机器翻译 (MT)，无需监督微调。提出规则-度量混合奖励机制引导 LLM 提升翻译质量，在 WMT24 英中基准上表现出色，接近 GPT-4o 等先进闭源模型。\n\n*   **GeoUni：生成几何图、问题和解题方案的统一模型 (GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions)**\n    提出了首个统一的几何专家模型 **GeoUni** (1.5B 参数)，能生成问题解法、几何图，并支持创建个性化几何问题。性能在推理上媲美大型模型，图生成优于现有模型，且能根据知识点生成文本问题和匹配图。\n\n*   **可执行功能抽象：为高等数学问题推断生成式程序 (Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems)**\n    提出 **EFA (Executable Functional Abstraction)** 概念，指代能根据参数生成不同问题实例的程序。开发了 **EFAGen**，利用 LLM 从种子问题和解法中自动构建 EFA 程序，并通过可执行单元测试进行验证和优化，可用于生成不同难度的问题变体。\n\n**LLM 推理评估与理解**\n\n*   **S1-Bench：评估大型推理模型系统 1 思维能力的简单基准 (S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models)**\n    提出 **S1-Bench**，用于评估 LRM 在需要直觉式系统 1 思维而非审议式系统 2 推理的简单任务上的表现。发现 LRM 在这些任务上效率低下、输出冗长，甚至出错，强调了平衡双系统思维能力的必要性。\n\n*   **通过机制性洞察量化常识推理 (Towards Quantifying Commonsense Reasoning with Mechanistic Insights)**\n    认为常识理解可以用图结构表示，并创建了包含 37 种日常活动的图结构标注方案，可生成大量常识查询 (~10^17) 用于评估 LLM。研究还发现 LLM 内部存在负责推理的局部化组件。\n\n*   **(如何) 推理模型进行推理？((How) Do reasoning models reason?)**\n    提供了对 LRM (如 OpenAI o1, DeepSeek R1) 的统一视角，讨论了它们的潜力、能力来源、误解和局限性。\n\n**AI 安全、对齐与伦理**\n\n*   **LLM 可能成为危险的说服者：大型语言模型说服安全的实证研究 (LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models)**\n    系统研究 LLM 的说服安全问题，包括是否会拒绝不道德说服任务、是否使用不道德策略。引入 **PersuSafety** 框架进行评估，发现多数 LLM 存在显著安全隐患。\n\n*   **RealSafe-R1：安全对齐的 DeepSeek-R1，不损害推理能力 (RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability)**\n    推出了 **RealSafe-R1**，是 DeepSeek-R1 蒸馏模型的安全对齐版本。通过构建包含 15k 安全感知推理轨迹的数据集进行训练，提升了模型对有害查询和越狱攻击的防御能力，同时保持了原有的推理性能。\n\n*   **LLM 遗忘揭示了当前基准中比预期更强的 Coreset 效应 (LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks)**\n    首次发现 LLM 遗忘基准 (如 WMDP, MUSE) 中存在 **Coreset 效应**：使用遗忘集的一小部分 (例如 5%) 随机子集进行遗忘，就能达到与使用完整遗忘集相当的效果。这表明当前基准中的遗忘任务可能比想象中更容易。\n\n*   **将消息标记为 AI 生成并不能减少其说服效果 (Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects)**\n    实验 (N=1601) 发现，明确告知参与者消息由 AI 生成（相比告知由人类专家生成或不告知来源），并不能显著改变消息的说服力、准确性判断或分享意愿。这表明仅靠标签可能不足以应对 AI 生成信息带来的挑战。\n\n*   **RealHarm：真实世界语言模型应用失败案例集 (RealHarm: A Collection of Real-World Language Model Application Failures)**\n    构建了 **RealHarm** 数据集，收集并标注了公开报道的 AI 代理与用户交互出现问题的事件。分析发现，声誉损害是主要组织伤害，错误信息是最常见的风险类别。现有护栏和内容审核系统在阻止这些事件方面存在显著差距。\n\n*   **本地化文化知识在大型语言模型中是保守且可控的 (Localized Cultural Knowledge is Conserved and Controllable in Large Language Models)**\n    发现 LLM 即使在生成非英语内容时也常默认使用以英语为中心的模式，但本地文化知识仍然存在且可通过提示激活。明确提供文化背景能提升本地化响应，但也可能导致刻板印象。研究还发现了一个跨语言保守的“显式文化定制向量”，可引导模型从英语文化世界模型转向非英语文化世界。\n\n*   **隐私与可解释性相遇：在 LLM 赋能的科学中管理机密数据和透明度策略 (Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science)**\n    探讨了 LLM 驱动的科学工具可能泄露机密数据的风险。提出 **DataShield** 框架，用于检测泄露、总结隐私政策、可视化数据流，帮助科学家了解数据处理实践并保护敏感信息。\n\n*   **StruPhantom：针对黑盒表格数据 LLM Agent 的进化式注入攻击 (StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models)**\n    提出 **StruPhantom** 攻击方法，利用进化优化（约束蒙特卡洛树搜索+离题评估器）生成能绕过表格数据格式限制、实现目标劫持的攻击载荷，对多种基于 LLM 的表格 Agent 有效。\n\n*   **SafeSpeech：针对恶意语音合成的鲁棒通用语音保护 (SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis)**\n    提出 **SafeSpeech** 框架，通过在用户上传前向原始语音嵌入难以察觉的扰动来防御 Deepfake 语音克隆。核心技术 **SPEC (Speech Perturbative Concealment)** 利用代理模型生成通用扰动，在时域和频域优化人类感知。实验证明其有效性、迁移性和鲁棒性。\n\n**多模态模型 (MLLM)**\n\n*   **FingER：基于推理的内容感知细粒度 AI 生成视频评估 (FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos)**\n    提出 **FingER** 框架，用于 AI 生成视频的细粒度评估。该框架首先自动生成实体级问题，然后由推理模型回答并打分，最终加权得到总分。构建了包含约 3.3k 视频和 60k 细粒度 QA 标注的 FingER 数据集。\n\n*   **Mavors：用于多模态大型语言模型的多粒度视频表示 (Mavors: Multi-granularity Video Representation for Multimodal Large Language Model)**\n    提出 **Mavors** 框架，通过多粒度表示解决长视频理解中计算效率和细粒度信息保留的平衡问题。包含保留高分辨率空间特征的 IVE 和建立跨块时间连贯性的 IFA 组件，统一了图像和视频理解。\n\n*   **MMKB-RAG：基于多模态知识的检索增强生成框架 (MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework)**\n    提出 **MMKB-RAG**，一种新颖的多模态 RAG 框架。它利用模型的固有知识边界动态生成语义标签用于检索过程，联合过滤检索到的文档，只保留最相关和准确的参考。在知识型 VQA 任务上表现优异。\n\n*   **VDocRAG：基于视觉丰富文档的检索增强生成 (VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents)**\n    提出 **VDocRAG** 框架，用于处理包含图表、表格等多种模态和格式（PDF, PPTX）的视觉丰富文档语料库的问答。该框架直接理解统一图像格式的文档，避免信息丢失，并提出新的自监督预训练任务和 **OpenDocVQA** 数据集。\n\n*   **基于时序动态上下文的多模态长视频建模 (Multimodal Long Video Modeling Based on Temporal Dynamic Context)**\n    提出 **TDC (Temporal Dynamic Context)** 方法，通过基于帧间相似性分割场景，并使用新颖的时序上下文压缩器（基于查询的 Transformer）聚合视频、音频和指令 token，减少 LLM 输入长度，同时保留关键信息。\n\n*   **性能提升的海市蜃楼：为何对比解码未能解决多模态幻觉 (The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination)**\n    论证了对比解码策略（如 CD, DoLa）在减少 MLLM 幻觉方面的效果具有误导性。指出其在 POPE 基准上的性能提升主要源于对输出分布的粗略调整和自适应合理性约束，而非真正解决了幻觉问题。\n\n*   **MLLM 提示的未来是自适应的：鲁棒多模态性能提示工程方法的综合实验评估 (The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance)**\n    对 7 种提示工程方法在 13 个开源 MLLM 上的 24 项任务进行了全面评估。发现没有单一方法适用于所有任务，需要结合示例指导和选择性结构化推理的自适应策略来提高鲁棒性、效率和准确性。\n\n*   **COUNTS：在分布偏移下对目标检测器和多模态大模型进行基准测试 (COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts)**\n    引入 **COUNTS** 数据集（包含 14 种自然分布偏移，超 22 万样本，超 119 万标注框）和两个新基准 **O(OD)2** (评估检测器 OOD 泛化) 与 **OODG** (评估 MLLM 的 OOD grounding 能力)。发现大模型和预训练数据虽提升 IID 性能，但在 OOD 场景下仍有很大改进空间。\n\n*   **我们真的需要精心策划的恶意数据来进行多模态大模型的安全对齐吗？(Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?)**\n    研究发现 MLLM 的安全对齐差距主要源于数据分布偏差，而非图像内容或响应质量。提出仅用少量良性指令数据（响应替换为拒绝句）进行微调，只要存在特定比例的拒绝数据，就能显著提升多模态安全性，无需费力收集高质量恶意数据。\n\n*   **通过以图像为中心的多标注数据增强医学通用基础模型的多任务学习能力 (Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data)**\n    引入 **IMAX** 数据集，首个从数据构建层面增强医学 MLLM 多任务学习能力的工作。IMAX 特点是高质量数据管理和以图像为中心的密集标注（每张 X 光片平均关联 4.1 个任务）。使用 IMAX 训练显著提升了多个开源医学 MLLM 的多任务平均性能。\n\n**新基准与数据集**\n\n*   **RealWebAssist：具有真实用户的长视界 Web 辅助基准 (RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users)**\n    提出了 **RealWebAssist** 基准，旨在评估 AI 代理在真实场景下遵循用户模糊、演变的长期指令，在多个网站上执行任务的能力。包含真实用户收集的序列指令数据集。\n\n*   **LLM-SRBench：利用大型语言模型进行科学方程发现的新基准 (LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models)**\n    推出 **LLM-SRBench**，包含 4 个科学领域的 239 个挑战性问题，专为评估基于 LLM 的科学方程发现方法而设计，通过变换常见模型（LSR-Transform）和引入合成问题（LSR-Synth）来防止简单的记忆提取。\n\n*   **C-FAITH：用于自动化幻觉评估的中文细粒度基准 (C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation)**\n    针对中文幻觉评估缺乏自动化、细粒度基准的问题，提出 **HaluAgent** 框架自动构建 QA 数据集，并基于此创建了 **C-FAITH** 基准（从 1399 篇知识文档生成 60702 条目），并评估了 16 个主流 LLM。\n\n*   **BoTTA：基准化设备端测试时自适应 (BoTTA: Benchmarking on-device Test Time Adaptation)**\n    提出 **BoTTA** 基准，用于评估 TTA 方法在移动和边缘设备实际约束下的性能，关注有限样本、有限类别暴露、多样分布偏移和重叠偏移等挑战，并报告系统级指标。\n\n*   **SoccerNet-v3D：利用体育转播回放进行 3D 场景理解 (SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding)**\n    推出了 **SoccerNet-v3D** 和 **ISSIA-3D** 数据集，通过加入基于场线标定和多视角同步，扩展了 SoccerNet-v3 和 ISSIA，支持通过三角测量进行 3D 对象定位，并提出了单目 3D 球定位任务和基线方法。\n\n*   **EmbodiedAgent：克服多机器人控制中实际挑战的可扩展分层方法 (EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control)**\n    介绍 **EmbodiedAgent** 框架，用于异构多机器人控制，解决幻觉和不切实际任务的限制。结合下一动作预测和结构化记忆系统，并将任务分解为可执行技能。同时发布 **MultiPlan+** 数据集和 **RPAS** 评估方案。\n\n*   **RGB-Event 基于行人属性识别：基准数据集和非对称 RWKV 融合框架 (RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework)**\n    提出了新的多模态 RGB-Event 属性识别任务，并发布了首个大规模数据集 **EventPAR**（10 万对样本，50 个属性含情感）。同时提出基于 RWKV 的非对称融合框架，并在新旧数据集上取得 SOTA 结果。\n\n*   **基于气象引导的模态解耦时空网络进行空气质量预测 (Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network)**\n    提出 **MDSTNet** 框架，将空气质量观测和大气条件视为不同模态，整合多气压层气象数据预测空气质量。构建了首个全国性数据集 **ChinaAirNet**。MDSTNet 在此数据集上显著优于 SOTA 模型。\n\n*   **GenTe：用于通用腿式机器人运动控制的生成式真实世界地形 (GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control)**\n    提出 **GenTe** 框架，用于生成物理逼真且适应性强的地形，以训练泛化性强的腿式机器人运动策略。构建了原子地形库，利用 VLM 从文本/图形输入生成复杂地形，并引入真实力模型。\n\n**效率、基础设施与优化**\n\n*   **AlayaDB：高效长上下文 LLM 推理的数据基础 (AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference)**\n    介绍 **AlayaDB**，一个专为高效长上下文 LLM 推理设计的向量数据库系统。它将 KV 缓存和注意力计算从 LLM 推理系统解耦出来，封装进数据库，通过原生查询优化器提升性能。\n\n*   **KeepKV：消除 KV 缓存压缩中的输出扰动以实现高效 LLM 推理 (KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference)**\n    提出 **KeepKV**，一种自适应 KV 缓存合并方法，旨在消除因合并引起的输出扰动。引入 **Electoral Votes** 机制记录合并历史并调整注意力分数，并使用 **Zero Inference-Perturbation Merging** 保持注意力一致性，显著减少内存占用并提升吞吐量。\n\n*   **OVERLORD：用于多源大型基础模型训练的数据加载器的终极扩展 (OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training)**\n    提出 **OVERLORD**，一种工业级分布式数据加载架构。通过集中式声明性数据平面、角色特定的 Actor（源加载器、数据构造器）进行解耦预处理、以及影子加载器实现容错恢复，显著提升了大规模 LFM 训练的吞吐量和内存效率。\n\n*   **通过嵌入式表示预热实现高效生成模型训练 (Efficient Generative Model Training via Embedded Representation Warmup)**\n    提出 **ERW (Embedded Representation Warmup)**，一个即插即用框架，通过预训练的高质量表示来初始化扩散模型的早期层（表示处理区域），从而加速收敛并提升性能，训练速度比 SOTA 方法快 40 倍。\n\n*   **理解和优化多阶段 AI 推理流水线 (Understanding and Optimizing Multi-Stage AI Inference Pipelines)**\n    介绍 **HERMES**，一个异构多阶段 LLM 推理执行模拟器。能够模拟 RAG、KV 检索、推理、预填充、解码等不同阶段在复杂硬件层次结构（GPU、ASIC、CPU 等）上的执行，支持异构客户端、多模型并发和高级批处理策略，为优化下一代 AI 工作负载提供洞见。\n\n**领域应用**\n\n*   **生物医学/医疗：**\n    *   (5) 探索 LLM 知识编辑在长尾生物医学知识上的效果，发现因一对多关系存在挑战。\n    *   (8) 评估 LLM 在葡萄牙医学专业入学考试中的表现，部分模型超越人类学生水平。\n    *   (9) 探讨 LLM 在概率因果建模（贝叶斯网络）中辅助专家知识获取的潜力与局限。\n    *   (14) 研究从临床文本时间序列进行预测，发现编码器模型更擅长事件预测，解码器模型在生存分析中有优势。\n    *   (19) **ATOMIC** 框架利用基础模型实现 2D 材料的零样本全自主显微镜表征。\n    *   (49) 提出渐进式迁移学习用于多通道眼底图像恢复，提升糖尿病视网膜病变筛查可靠性。\n    *   (68) **HDC** 框架通过分层蒸馏和一致性学习改进半监督胎儿超声分割。\n    *   (73) 发现 ChatGPT 辅助生成的消息能略微提升疫苗接种的说服力。\n    *   (77) **GlyTwin** 数字孪生框架利用反事实解释为 1 型糖尿病患者提供最优行为（碳水、胰岛素）修改建议以控制血糖。\n\n*   **机器人/智能体：**\n    *   (10) 教师运动先验通过模仿学习和辅助任务学习增强机器人在挑战性地形上的运动能力。\n    *   (21) 基于视觉的深度强化学习智能体用于赛车模拟环境中的极限抓地力驾驶。\n    *   (31) **WildLive** 系统实现在无人机上近乎实时地进行高分辨率野生动物视觉跟踪。\n    *   (36) 通过任务泛化（利用推理密集型任务数据进行中期训练）来训练 GUI 智能体，有效缓解数据稀缺问题。\n    *   (43) **IFE** (可解释特征提取器) 旨在为基于视觉的 DRL 生成准确且可理解的注意力图。\n    *   (66) **LangPert** 框架利用语言模型检测和处理物体操作任务中的任务级扰动。\n    *   (76) 综述了 LLM 驱动的空间智能在不同尺度（具身智能体、智慧城市、地球科学）的应用进展。\n\n*   **软件工程/代码：**\n    *   (7) 使用图神经网络 (GNN) 和抽象语法树 (AST) 进行 AI 驱动的代码重构，提升软件可维护性。\n    *   (11) **SymRTLO** 框架结合 LLM 代码重写和符号推理技术优化 RTL 代码。\n\n*   **其他应用：**\n    *   (18) 对比分析完全由 LLM Agent 构成的社交网络 Chirper.ai 与人类驱动的 Mastodon 在发帖行为、滥用内容和网络结构上的差异。\n    *   (23) 探索在 LLM 多智能体系统中引入竞争机制，以增强新闻驱动的时间序列预测能力。\n    *   (60) **Omni-Dish** 模型专门用于生成和编辑逼真、忠实的中国菜肴图像。\n    *   (67) 提出从技术支持文档构建微知识图谱 (micrograph) 的方法。\n    *   (71) **SUMART** 方法用于将冗长的字幕翻译进行摘要压缩。\n    *   (74) **PestMA** 是一个基于 LLM 的多智能体系统，通过编辑-检索-验证流程生成可靠的害虫管理建议。\n    *   (81) 研究离线学习带有审查和依赖需求的动态库存与定价策略。\n\n**其他研究**\n\n*   **联邦学习：** (58) FairFGL 框架解决联邦图学习中的标签和拓扑公平性问题。(61) FedRecon 方法在分布式异构环境中进行缺失模态重建。(85) M-Fed 框架支持不同任务/结构的客户端通过编解码器结构进行多任务联邦学习。\n*   **可解释性/幻觉检测：** (45) TOHA 方法通过注意力图的拓扑散度检测 LLM 幻觉。(55) SyCAM 方法根据度量标准自动合成 CAM (类激活图) 表达式。(83) 对 MLLM 在可视化问答任务中是“看见”还是“回忆”进行了健全性检查。\n*   **理论与其他：** (38) 轻量级可信分布式 K-Means 聚类。(48) 使用序列模型逐试次解码神经数据中的认知策略。(63) 量子自然语言处理 (QNLP) 的综述。(64) PA-MoE 框架通过调节可塑性应对自适应视频流中的 QoE 变化。(69) 截断矩阵补全的实证研究。(75) 碳效率 3D DNN 加速器设计。(88) EquiVDM 提出具有时序一致噪声的等变视频扩散模型。\n*   **社会影响：** (90) 访谈研究揭示生成式 AI 可能侵蚀学生间的社交互动和学习社群。\n\n希望这份 TLDR 能帮助你快速了解今日 arXiv 的精华！",
  "papers": [
    {
      "arxiv_id": "2504.10478v2",
      "title": "Weight Ensembling Improves Reasoning in Language Models",
      "title_zh": "权重集成提升语言模型的推理能力\n",
      "authors": [
        "Xingyu Dang",
        "Christina Baek",
        "Kaiyue Wen",
        "Zico Kolter",
        "Aditi Raghunathan"
      ],
      "abstract": "We investigate a failure mode that arises during the training of reasoning\nmodels, where the diversity of generations begins to collapse, leading to\nsuboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during\nsupervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a\nsimple intervention of interpolating the weights of the latest SFT checkpoint\nwith an early checkpoint, otherwise known as WiSE-FT, almost completely\nrecovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves\nbetter test-time scaling (Best@k, majority vote) and achieves superior results\nwith less data when tuned further by reinforcement learning. Finally, we find\nthat WiSE-FT provides complementary performance gains that cannot be achieved\nonly through diversity-inducing decoding strategies, like temperature scaling.\nWe formalize a bias-variance tradeoff of Pass@k with respect to the expectation\nand variance of Pass@1 over the test distribution. We find that WiSE-FT can\nreduce bias and variance simultaneously, while temperature scaling inherently\ntrades-off between bias and variance.",
      "tldr_zh": "该研究发现，推理模型训练过程中会出现生成多样性崩溃的问题，导致测试时性能扩展性下降。尽管监督微调(SFT)能提高Pass@1指标，但Pass@k指标会迅速恶化。研究提出一种简单有效的干预方法，即权重集成(WiSE-FT)，通过插值最新SFT检查点和早期检查点的权重，几乎完全恢复Pass@k指标，同时还提升Pass@1指标。WiSE-FT变体在测试时表现出更好的扩展性(Best@k, majority vote)，并且在通过强化学习进一步调整时，能够以更少的数据获得更优的结果。研究还发现WiSE-FT提供的性能提升是互补的，无法仅通过温度缩放等多样性诱导解码策略来实现。最后，研究形式化了Pass@k相对于Pass@1的偏差-方差权衡，并发现WiSE-FT可以同时降低偏差和方差，而温度缩放本质上是在偏差和方差之间进行权衡。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10478v2",
      "published_date": "2025-04-14 17:59:07 UTC",
      "updated_date": "2025-04-15 17:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:12:43.270237"
    },
    {
      "arxiv_id": "2504.10445v1",
      "title": "RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users",
      "title_zh": "RealWebAssist：真实用户长程Web辅助基准测试\n",
      "authors": [
        "Suyu Ye",
        "Haojun Shi",
        "Darren Shih",
        "Hyokun Yun",
        "Tanya Roosta",
        "Tianmin Shu"
      ],
      "abstract": "To achieve successful assistance with long-horizon web-based tasks, AI agents\nmust be able to sequentially follow real-world user instructions over a long\nperiod. Unlike existing web-based agent benchmarks, sequential instruction\nfollowing in the real world poses significant challenges beyond performing a\nsingle, clearly defined task. For instance, real-world human instructions can\nbe ambiguous, require different levels of AI assistance, and may evolve over\ntime, reflecting changes in the user's mental state. To address this gap, we\nintroduce RealWebAssist, a novel benchmark designed to evaluate sequential\ninstruction-following in realistic scenarios involving long-horizon\ninteractions with the web, visual GUI grounding, and understanding ambiguous\nreal-world user instructions. RealWebAssist includes a dataset of sequential\ninstructions collected from real-world human users. Each user instructs a\nweb-based assistant to perform a series of tasks on multiple websites. A\nsuccessful agent must reason about the true intent behind each instruction,\nkeep track of the mental state of the user, understand user-specific routines,\nand ground the intended tasks to actions on the correct GUI elements. Our\nexperimental results show that state-of-the-art models struggle to understand\nand ground user instructions, posing critical challenges in following\nreal-world user instructions for long-horizon web assistance.",
      "tldr_zh": "RealWebAssist是一个新的基准，用于评估AI agent在长时程web任务中按顺序理解和执行真实用户指令的能力。与现有基准不同，RealWebAssist模拟了真实世界中指令的模糊性、不同程度的辅助需求以及用户意图随时间的变化。该基准包含一个从真实用户收集的序列指令数据集，要求agent理解用户意图、跟踪用户状态、理解用户习惯并将任务对应到正确的GUI元素。实验结果表明，现有模型在理解和执行这些指令方面存在困难，揭示了长时程web辅助中真实用户指令理解的关键挑战。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Project Website: https://scai.cs.jhu.edu/projects/RealWebAssist/\n  Code: https://github.com/SCAI-JHU/RealWebAssist",
      "pdf_url": "http://arxiv.org/pdf/2504.10445v1",
      "published_date": "2025-04-14 17:36:46 UTC",
      "updated_date": "2025-04-14 17:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:12:54.640803"
    },
    {
      "arxiv_id": "2504.10443v1",
      "title": "Multimodal Long Video Modeling Based on Temporal Dynamic Context",
      "title_zh": "基于时序动态上下文的多模态长视频建模\n",
      "authors": [
        "Haoran Hao",
        "Jiaming Han",
        "Yiyuan Zhang",
        "Xiangyu Yue"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nbreakthroughs in video understanding. However, existing models still struggle\nwith long video processing due to the context length constraint of LLMs and the\nvast amount of information within the video. Although some recent methods are\ndesigned for long video understanding, they often lose crucial information\nduring token compression and struggle with additional modality like audio. In\nthis work, we propose a dynamic long video encoding method utilizing the\ntemporal relationship between frames, named Temporal Dynamic Context (TDC).\nFirstly, we segment the video into semantically consistent scenes based on\ninter-frame similarities, then encode each frame into tokens using visual-audio\nencoders. Secondly, we propose a novel temporal context compressor to reduce\nthe number of tokens within each segment. Specifically, we employ a query-based\nTransformer to aggregate video, audio, and instruction text tokens into a\nlimited set of temporal context tokens. Finally, we feed the static frame\ntokens and the temporal context tokens into the LLM for video understanding.\nFurthermore, to handle extremely long videos, we propose a training-free\nchain-of-thought strategy that progressively extracts answers from multiple\nvideo segments. These intermediate answers serve as part of the reasoning\nprocess and contribute to the final answer. We conduct extensive experiments on\ngeneral video understanding and audio-video understanding benchmarks, where our\nmethod demonstrates strong performance. The code and models are available at\nhttps://github.com/Hoar012/TDC-Video.",
      "tldr_zh": "该论文提出了一种基于时间动态上下文(Temporal Dynamic Context, TDC)的多模态长视频建模方法，旨在解决现有模型在处理长视频时因LLM上下文长度限制和信息量巨大而面临的挑战。TDC首先基于帧间相似性将视频分割成语义一致的片段，并使用视觉-音频编码器将每帧编码为tokens。然后，提出一种新的时间上下文压缩器，使用基于query的Transformer将视频、音频和指令文本tokens聚合成一组有限的时间上下文tokens，从而减少每个片段内的tokens数量。对于极长视频，采用一种无需训练的链式思维(Chain-of-Thought)策略，逐步从多个视频片段中提取答案，作为推理过程的一部分。实验结果表明，该方法在通用视频理解和音视频理解基准测试中表现出色。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10443v1",
      "published_date": "2025-04-14 17:34:06 UTC",
      "updated_date": "2025-04-14 17:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:13:06.860164"
    },
    {
      "arxiv_id": "2504.10430v1",
      "title": "LLM Can be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models",
      "title_zh": "LLM可能成为危险的说服者：大型语言模型中说服安全性的实证研究\n",
      "authors": [
        "Minqian Liu",
        "Zhiyang Xu",
        "Xinyi Zhang",
        "Heajun An",
        "Sarvech Qadir",
        "Qi Zhang",
        "Pamela J. Wisniewski",
        "Jin-Hee Cho",
        "Sang Won Lee",
        "Ruoxi Jia",
        "Lifu Huang"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have enabled them to\napproach human-level persuasion capabilities. However, such potential also\nraises concerns about the safety risks of LLM-driven persuasion, particularly\ntheir potential for unethical influence through manipulation, deception,\nexploitation of vulnerabilities, and many other harmful tactics. In this work,\nwe present a systematic investigation of LLM persuasion safety through two\ncritical aspects: (1) whether LLMs appropriately reject unethical persuasion\ntasks and avoid unethical strategies during execution, including cases where\nthe initial persuasion goal appears ethically neutral, and (2) how influencing\nfactors like personality traits and external pressures affect their behavior.\nTo this end, we introduce PersuSafety, the first comprehensive framework for\nthe assessment of persuasion safety which consists of three stages, i.e.,\npersuasion scene creation, persuasive conversation simulation, and persuasion\nsafety assessment. PersuSafety covers 6 diverse unethical persuasion topics and\n15 common unethical strategies. Through extensive experiments across 8 widely\nused LLMs, we observe significant safety concerns in most LLMs, including\nfailing to identify harmful persuasion tasks and leveraging various unethical\npersuasion strategies. Our study calls for more attention to improve safety\nalignment in progressive and goal-driven conversations such as persuasion.",
      "tldr_zh": "该研究对大型语言模型(LLMs)的劝说安全性进行了系统性调查，关注LLMs是否能拒绝不道德的劝说任务，并在执行过程中避免使用不道德的策略。研究提出了PersuSafety框架，该框架包含三个阶段：劝说场景创建、劝说对话模拟和劝说安全评估，涵盖6个不同的不道德劝说主题和15个常见的不道德策略。通过对8个广泛使用的LLMs进行实验，发现大多数LLMs都存在显著的安全问题，包括未能识别有害的劝说任务以及利用各种不道德的劝说策略。该研究强调需要更多关注在劝说等渐进式和目标驱动型对话中改进安全对齐。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10430v1",
      "published_date": "2025-04-14 17:20:34 UTC",
      "updated_date": "2025-04-14 17:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:13:18.722554"
    },
    {
      "arxiv_id": "2504.10421v1",
      "title": "Can We Edit LLMs for Long-Tail Biomedical Knowledge?",
      "title_zh": "我们能否为了长尾生物医学知识而编辑大型语言模型？\n",
      "authors": [
        "Xinhao Yi",
        "Jake Lever",
        "Kevin Bryson",
        "Zaiqiao Meng"
      ],
      "abstract": "Knowledge editing has emerged as an effective approach for updating large\nlanguage models (LLMs) by modifying their internal knowledge. However, their\napplication to the biomedical domain faces unique challenges due to the\nlong-tailed distribution of biomedical knowledge, where rare and infrequent\ninformation is prevalent. In this paper, we conduct the first comprehensive\nstudy to investigate the effectiveness of knowledge editing methods for editing\nlong-tail biomedical knowledge. Our results indicate that, while existing\nediting methods can enhance LLMs' performance on long-tail biomedical\nknowledge, their performance on long-tail knowledge remains inferior to that on\nhigh-frequency popular knowledge, even after editing. Our further analysis\nreveals that long-tail biomedical knowledge contains a significant amount of\none-to-many knowledge, where one subject and relation link to multiple objects.\nThis high prevalence of one-to-many knowledge limits the effectiveness of\nknowledge editing in improving LLMs' understanding of long-tail biomedical\nknowledge, highlighting the need for tailored strategies to bridge this\nperformance gap.",
      "tldr_zh": "本文首次全面研究了知识编辑方法在编辑长尾生物医学知识方面的有效性。研究发现，现有的知识编辑方法虽然可以提高大型语言模型(LLMs)在长尾生物医学知识上的表现，但编辑后其性能仍然不如高频知识。进一步分析表明，长尾生物医学知识包含大量一对多知识，这限制了知识编辑在提高LLMs对长尾生物医学知识理解方面的有效性。研究强调需要定制策略来弥合这一性能差距。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10421v1",
      "published_date": "2025-04-14 17:08:20 UTC",
      "updated_date": "2025-04-14 17:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:13:30.570814"
    },
    {
      "arxiv_id": "2504.10415v1",
      "title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models",
      "title_zh": "LLM-SRBench：一个用于大型语言模型科学方程发现的新基准\n",
      "authors": [
        "Parshin Shojaee",
        "Ngoc-Hieu Nguyen",
        "Kazem Meidani",
        "Amir Barati Farimani",
        "Khoa D Doan",
        "Chandan K Reddy"
      ],
      "abstract": "Scientific equation discovery is a fundamental task in the history of\nscientific progress, enabling the derivation of laws governing natural\nphenomena. Recently, Large Language Models (LLMs) have gained interest for this\ntask due to their potential to leverage embedded scientific knowledge for\nhypothesis generation. However, evaluating the true discovery capabilities of\nthese methods remains challenging, as existing benchmarks often rely on common\nequations that are susceptible to memorization by LLMs, leading to inflated\nperformance metrics that do not reflect discovery. In this paper, we introduce\nLLM-SRBench, a comprehensive benchmark with 239 challenging problems across\nfour scientific domains specifically designed to evaluate LLM-based scientific\nequation discovery methods while preventing trivial memorization. Our benchmark\ncomprises two main categories: LSR-Transform, which transforms common physical\nmodels into less common mathematical representations to test reasoning beyond\nmemorized forms, and LSR-Synth, which introduces synthetic, discovery-driven\nproblems requiring data-driven reasoning. Through extensive evaluation of\nseveral state-of-the-art methods, using both open and closed LLMs, we find that\nthe best-performing system so far achieves only 31.5% symbolic accuracy. These\nfindings highlight the challenges of scientific equation discovery, positioning\nLLM-SRBench as a valuable resource for future research.",
      "tldr_zh": "该论文提出了LLM-SRBench，一个新的科学方程发现基准，旨在更真实地评估大型语言模型(LLMs)在此任务上的能力。现有基准容易被LLMs记忆，导致评估结果虚高。LLM-SRBench包含239个来自四个科学领域的难题，分为LSR-Transform和LSR-Synth两类，前者将常见物理模型转化为不常见的数学形式，后者引入合成的、数据驱动的发现问题。实验结果表明，现有最佳系统在LLM-SRBench上的符号准确率仅为31.5%，突显了科学方程发现的挑战，并表明LLM-SRBench对未来研究具有重要价值。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page:\n  https://github.com/deep-symbolic-mathematics/llm-srbench , Benchmark page:\n  https://huggingface.co/datasets/nnheui/llm-srbench",
      "pdf_url": "http://arxiv.org/pdf/2504.10415v1",
      "published_date": "2025-04-14 17:00:13 UTC",
      "updated_date": "2025-04-14 17:00:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:13:42.818714"
    },
    {
      "arxiv_id": "2504.10412v1",
      "title": "AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability",
      "title_zh": "AI驱动的代码重构：使用图神经网络增强软件可维护性\n",
      "authors": [
        "Gopichand Bandarupalli"
      ],
      "abstract": "This study explores Graph Neural Networks (GNNs) as a transformative tool for\ncode refactoring, using abstract syntax trees (ASTs) to boost software\nmaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet\nand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based\nSonarQube and decision trees. Metrics include cyclomatic complexity (target\nbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve\n92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming\nSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of\nsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offers\na scalable AI-driven path to cleaner codebases, which is crucial for software\nengineering.",
      "tldr_zh": "该研究探索了使用图神经网络（GNNs）作为代码重构的变革性工具，利用抽象语法树（ASTs）来提高软件的可维护性。通过分析来自 CodeSearchNet 的 200 万个代码片段和一个定制的包含 75000 个文件的 GitHub Python 语料库，将 GNN 与基于规则的 SonarQube 和决策树进行比较。评估指标包括圈复杂度（目标低于 10）、耦合度（目标低于 5）和重构精度。实验结果表明，GNN 实现了 92% 的准确率，将复杂度降低了 35%，耦合度降低了 33%，优于 SonarQube（78%，16%）和决策树（85%，25%）。预处理修复了 60% 的语法错误。该研究提供了一种可扩展的 AI 驱动的途径，以实现更简洁的代码库，这对于软件工程至关重要。\n",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10412v1",
      "published_date": "2025-04-14 16:58:54 UTC",
      "updated_date": "2025-04-14 16:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:13:54.904210"
    },
    {
      "arxiv_id": "2504.10405v1",
      "title": "Performance of Large Language Models in Supporting Medical Diagnosis and Treatment",
      "title_zh": "大型语言模型在支持医疗诊断和治疗中的表现\n",
      "authors": [
        "Diogo Sousa",
        "Guilherme Barbosa",
        "Catarina Rocha",
        "Dulce Oliveira"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into healthcare holds\nsignificant potential to enhance diagnostic accuracy and support medical\ntreatment planning. These AI-driven systems can analyze vast datasets,\nassisting clinicians in identifying diseases, recommending treatments, and\npredicting patient outcomes. This study evaluates the performance of a range of\ncontemporary LLMs, including both open-source and closed-source models, on the\n2024 Portuguese National Exam for medical specialty access (PNA), a\nstandardized medical knowledge assessment. Our results highlight considerable\nvariation in accuracy and cost-effectiveness, with several models demonstrating\nperformance exceeding human benchmarks for medical students on this specific\ntask. We identify leading models based on a combined score of accuracy and\ncost, discuss the implications of reasoning methodologies like\nChain-of-Thought, and underscore the potential for LLMs to function as valuable\ncomplementary tools aiding medical professionals in complex clinical\ndecision-making.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在支持医疗诊断和治疗方面的性能，重点考察了它们在2024年葡萄牙国家医学专业入学考试(PNA)中的表现。研究对比了多种开源和闭源LLM，发现它们在准确性和成本效益方面存在显著差异。部分模型在此任务上的表现甚至超过了医学生的基准水平。研究还探讨了链式思维(Chain-of-Thought)等推理方法的影响，强调了LLM作为辅助工具在复杂临床决策中辅助医疗专业人员的潜力，并根据准确性和成本的综合评分确定了领先模型。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 6 figures, 4 tables. Acknowledgements: The authors\n  acknowledge the support of the AITriage4SU Project (2024.07400.IACDC/2024),\n  funded by the FCT (Foundation for Science and Technology), Portugal",
      "pdf_url": "http://arxiv.org/pdf/2504.10405v1",
      "published_date": "2025-04-14 16:53:59 UTC",
      "updated_date": "2025-04-14 16:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:14:06.871597"
    },
    {
      "arxiv_id": "2504.10397v1",
      "title": "Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?",
      "title_zh": "LLM 能否协助概率因果建模的专家知识获取？\n",
      "authors": [
        "Olha Shaposhnyk",
        "Daria Zahorska",
        "Svetlana Yanushkevich"
      ],
      "abstract": "Objective: This study investigates the potential of Large Language Models\n(LLMs) as an alternative to human expert elicitation for extracting structured\ncausal knowledge and facilitating causal modeling in biometric and healthcare\napplications.\n  Material and Methods: LLM-generated causal structures, specifically Bayesian\nnetworks (BNs), were benchmarked against traditional statistical methods (e.g.,\nBayesian Information Criterion) using healthcare datasets. Validation\ntechniques included structural equation modeling (SEM) to verifying\nrelationships, and measures such as entropy, predictive accuracy, and\nrobustness to compare network structures.\n  Results and Discussion: LLM-generated BNs demonstrated lower entropy than\nexpert-elicited and statistically generated BNs, suggesting higher confidence\nand precision in predictions. However, limitations such as contextual\nconstraints, hallucinated dependencies, and potential biases inherited from\ntraining data require further investigation.\n  Conclusion: LLMs represent a novel frontier in expert elicitation for\nprobabilistic causal modeling, promising to improve transparency and reduce\nuncertainty in the decision-making using such models.",
      "tldr_zh": "该研究探索了使用大型语言模型(LLMs)替代人类专家来提取结构化因果知识，并促进生物识别和医疗保健应用中的因果建模的潜力。研究对比了LLM生成的因果结构（特别是贝叶斯网络BNs）与传统统计方法。通过结构方程建模(SEM)验证关系，并使用熵、预测准确性和鲁棒性等指标比较网络结构。结果表明，LLM生成的BNs比专家抽取和统计生成的BNs具有更低的熵，但同时也存在上下文约束、幻觉依赖和潜在偏差等局限性。结论认为LLMs代表了概率因果建模中专家抽取的新前沿，有望提高透明度并减少决策中的不确定性。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10397v1",
      "published_date": "2025-04-14 16:45:52 UTC",
      "updated_date": "2025-04-14 16:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:14:18.839898"
    },
    {
      "arxiv_id": "2504.10390v1",
      "title": "Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain",
      "title_zh": "教师运动先验：增强机器人于复杂地形的运动能力\n",
      "authors": [
        "Fangcheng Jin",
        "Yuqi Wang",
        "Peixin Ma",
        "Guodong Yang",
        "Pan Zhao",
        "En Li",
        "Zhengtao Zhang"
      ],
      "abstract": "Achieving robust locomotion on complex terrains remains a challenge due to\nhigh dimensional control and environmental uncertainties. This paper introduces\na teacher prior framework based on the teacher student paradigm, integrating\nimitation and auxiliary task learning to improve learning efficiency and\ngeneralization. Unlike traditional paradigms that strongly rely on\nencoder-based state embeddings, our framework decouples the network design,\nsimplifying the policy network and deployment. A high performance teacher\npolicy is first trained using privileged information to acquire generalizable\nmotion skills. The teacher's motion distribution is transferred to the student\npolicy, which relies only on noisy proprioceptive data, via a generative\nadversarial mechanism to mitigate performance degradation caused by\ndistributional shifts. Additionally, auxiliary task learning enhances the\nstudent policy's feature representation, speeding up convergence and improving\nadaptability to varying terrains. The framework is validated on a humanoid\nrobot, showing a great improvement in locomotion stability on dynamic terrains\nand significant reductions in development costs. This work provides a practical\nsolution for deploying robust locomotion strategies in humanoid robots.",
      "tldr_zh": "该论文提出了一种基于师生范式的教师先验框架，旨在提升机器人复杂地形的运动能力。该框架结合模仿学习和辅助任务学习，提高学习效率和泛化能力。与传统依赖编码器状态嵌入的方法不同，该框架解耦了网络设计，简化了策略网络和部署。首先，利用特权信息训练高性能的教师策略，获得可泛化的运动技能。然后，通过生成对抗机制将教师的运动分布传递给仅依赖噪声本体感受数据的学生策略，以减轻分布偏移引起的性能下降。此外，辅助任务学习增强了学生策略的特征表示，加速收敛并提高对不同地形的适应性。在人形机器人上的验证表明，该框架显著提高了在动态地形上的运动稳定性，并显著降低了开发成本，为部署鲁棒的人形机器人运动策略提供了一种实用的解决方案。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.10390v1",
      "published_date": "2025-04-14 16:36:56 UTC",
      "updated_date": "2025-04-14 16:36:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:14:31.007979"
    },
    {
      "arxiv_id": "2504.10369v1",
      "title": "SymRTLO: Enhancing RTL Code Optimization with LLMs and Neuron-Inspired Symbolic Reasoning",
      "title_zh": "SymRTLO：利用 LLM 和神经元启发式符号推理增强 RTL 代码优化",
      "authors": [
        "Yiting Wang",
        "Wanghao Ye",
        "Ping Guo",
        "Yexiao He",
        "Ziyao Wang",
        "Yexiao He",
        "Bowei Tian",
        "Shwai He",
        "Guoheng Sun",
        "Zheyu Shen",
        "Sihan Chen",
        "Ankur Srivastava",
        "Qingfu Zhang",
        "Gang Qu",
        "Ang Li"
      ],
      "abstract": "Optimizing Register Transfer Level (RTL) code is crucial for improving the\npower, performance, and area (PPA) of digital circuits in the early stages of\nsynthesis. Manual rewriting, guided by synthesis feedback, can yield\nhigh-quality results but is time-consuming and error-prone. Most existing\ncompiler-based approaches have difficulty handling complex design constraints.\nLarge Language Model (LLM)-based methods have emerged as a promising\nalternative to address these challenges. However, LLM-based approaches often\nface difficulties in ensuring alignment between the generated code and the\nprovided prompts. This paper presents SymRTLO, a novel neuron-symbolic RTL\noptimization framework that seamlessly integrates LLM-based code rewriting with\nsymbolic reasoning techniques. Our method incorporates a retrieval-augmented\ngeneration (RAG) system of optimization rules and Abstract Syntax Tree\n(AST)-based templates, enabling LLM-based rewriting that maintains syntactic\ncorrectness while minimizing undesired circuit behaviors. A symbolic module is\nproposed for analyzing and optimizing finite state machine (FSM) logic,\nallowing fine-grained state merging and partial specification handling beyond\nthe scope of pattern-based compilers. Furthermore, a fast verification\npipeline, combining formal equivalence checks with test-driven validation,\nfurther reduces the complexity of verification. Experiments on the RTL-Rewriter\nbenchmark with Synopsys Design Compiler and Yosys show that SymRTLO improves\npower, performance, and area (PPA) by up to 43.9%, 62.5%, and 51.1%,\nrespectively, compared to the state-of-the-art methods.",
      "tldr_zh": "该论文提出了SymRTLO，一种新颖的神经符号RTL优化框架，它将基于LLM的代码重写与符号推理技术无缝集成，旨在提升数字电路的功耗、性能和面积(PPA)。SymRTLO利用检索增强生成(RAG)系统和基于抽象语法树(AST)的模板，使LLM能够进行代码重写，同时保持语法正确性并减少不良电路行为。此外，该框架还包含一个符号模块，用于分析和优化有限状态机(FSM)逻辑，实现细粒度的状态合并和局部规范处理。实验表明，SymRTLO在RTL-Rewriter基准测试中，与最先进的方法相比，功耗、性能和面积分别提高了高达43.9%、62.5%和51.1%。\n",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "16 pages, 8 figures, 7 tables. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.10369v1",
      "published_date": "2025-04-14 16:15:55 UTC",
      "updated_date": "2025-04-14 16:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:14:42.984538"
    },
    {
      "arxiv_id": "2504.10368v1",
      "title": "S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models",
      "title_zh": "S1-Bench：用于评估大型推理模型系统 1 思维能力的简单基准\n",
      "authors": [
        "Wenyuan Zhang",
        "Shuaiyi Nie",
        "Xinghua Zhang",
        "Zefeng Zhang",
        "Tingwen Liu"
      ],
      "abstract": "We introduce S1-Bench, a novel benchmark designed to evaluate Large Reasoning\nModels' (LRMs) performance on simple tasks that favor intuitive system 1\nthinking rather than deliberative system 2 reasoning. While LRMs have achieved\nsignificant breakthroughs in complex reasoning tasks through explicit chains of\nthought, their reliance on deep analytical thinking may limit their system 1\nthinking capabilities. Moreover, a lack of benchmark currently exists to\nevaluate LRMs' performance in tasks that require such capabilities. To fill\nthis gap, S1-Bench presents a set of simple, diverse, and naturally clear\nquestions across multiple domains and languages, specifically designed to\nassess LRMs' performance in such tasks. Our comprehensive evaluation of 22 LRMs\nreveals significant lower efficiency tendencies, with outputs averaging 15.5\ntimes longer than those of traditional small LLMs. Additionally, LRMs often\nidentify correct answers early but continue unnecessary deliberation, with some\nmodels even producing numerous errors. These findings highlight the rigid\nreasoning patterns of current LRMs and underscore the substantial development\nneeded to achieve balanced dual-system thinking capabilities that can adapt\nappropriately to task complexity.",
      "tldr_zh": "S1-Bench是一个新的基准测试，用于评估大型推理模型(LRMs)在简单任务上的表现，这些任务侧重于直觉的系统1思维，而不是深思熟虑的系统2推理。该基准包含多个领域和语言的简单、多样且清晰的问题，旨在评估LRMs在此类任务中的表现。对22个LRMs的评估表明，LRMs存在效率较低的倾向，输出平均比传统的小型LLMs长15.5倍。此外，LRMs经常过早地识别出正确的答案，但会继续不必要的思考，甚至产生许多错误。这些发现强调了当前LRMs的僵化推理模式，并强调了实现平衡的双系统思维能力（能够适当地适应任务复杂性）所需的重大发展。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2504.10368v1",
      "published_date": "2025-04-14 16:13:23 UTC",
      "updated_date": "2025-04-14 16:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:14:54.972315"
    },
    {
      "arxiv_id": "2504.10358v1",
      "title": "FingER: Content Aware Fine-grained Evaluation with Reasoning for AI-Generated Videos",
      "title_zh": "FingER：用于 AI 生成视频的内容感知细粒度推理评估\n",
      "authors": [
        "Rui Chen",
        "Lei Sun",
        "Jing Tang",
        "Geng Li",
        "Xiangxiang Chu"
      ],
      "abstract": "Recent advances in video generation have posed great challenges in the\nassessment of AI-generated content, particularly with the emergence of\nincreasingly sophisticated models. The various inconsistencies and defects\nobserved in such videos are inherently complex, making overall scoring\nnotoriously difficult. In this paper, we emphasize the critical importance of\nintegrating fine-grained reasoning into video evaluation, and we propose\n$\\textbf{F}$ing$\\textbf{ER}$, a novel entity-level reasoning evaluation\nframework that first automatically generates $\\textbf{F}$ine-grained\n$\\textbf{E}$ntity-level questions, and then answers those questions by a\n$\\textbf{R}$easoning model with scores, which can be subsequently weighted\nsummed to an overall score for different applications. Specifically, we\nleverage LLMs to derive entity-level questions across five distinct\nperspectives, which (i) often focus on some specific entities of the content,\nthereby making answering or scoring much easier by MLLMs, and (ii) are more\ninterpretable. Then we construct a FingER dataset, consisting of approximately\n3.3k videos and corresponding 60k fine-grained QA annotations, each with\ndetailed reasons. Based on that, we further investigate various training\nprotocols to best incentivize the reasoning capability of MLLMs for correct\nanswer prediction. Extensive experiments demonstrate that a reasoning model\ntrained using Group Relative Policy Optimization (GRPO) with a cold-start\nstrategy achieves the best performance. Notably, our model surpasses existing\nmethods by a relative margin of $11.8\\%$ on GenAI-Bench and $5.5\\%$ on\nMonetBench with only 3.3k training videos, which is at most one-tenth of the\ntraining samples utilized by other methods. Our code and dataset will be\nreleased soon.",
      "tldr_zh": "该论文提出了一种名为FingER的AI生成视频评估框架，该框架通过细粒度的实体级别推理来评估视频质量。FingER首先自动生成关于视频内容的细粒度实体级别问题，然后利用推理模型回答这些问题并给出评分，最终加权汇总得到整体评分。该方法利用LLM从五个不同角度生成问题，这些问题聚焦于特定实体，从而简化了多模态大语言模型(MLLM)的回答和评分过程，并提高了可解释性。研究人员构建了一个包含3.3k视频和60k细粒度问答注释的FingER数据集，并通过实验表明，使用Group Relative Policy Optimization (GRPO)和冷启动策略训练的推理模型表现最佳，在GenAI-Bench和MonetBench上分别超越现有方法11.8%和5.5%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10358v1",
      "published_date": "2025-04-14 16:07:16 UTC",
      "updated_date": "2025-04-14 16:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:15:06.978024"
    },
    {
      "arxiv_id": "2504.10340v1",
      "title": "Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families",
      "title_zh": "基于临床文本时间序列的预测：编码器和解码器语言模型族的调整\n",
      "authors": [
        "Shahriar Noroozizadeh",
        "Sayantan Kumar",
        "Jeremy C. Weiss"
      ],
      "abstract": "Clinical case reports encode rich, temporal patient trajectories that are\noften underexploited by traditional machine learning methods relying on\nstructured data. In this work, we introduce the forecasting problem from\ntextual time series, where timestamped clinical findings--extracted via an\nLLM-assisted annotation pipeline--serve as the primary input for prediction. We\nsystematically evaluate a diverse suite of models, including fine-tuned\ndecoder-based large language models and encoder-based transformers, on tasks of\nevent occurrence prediction, temporal ordering, and survival analysis. Our\nexperiments reveal that encoder-based models consistently achieve higher F1\nscores and superior temporal concordance for short- and long-horizon event\nforecasting, while fine-tuned masking approaches enhance ranking performance.\nIn contrast, instruction-tuned decoder models demonstrate a relative advantage\nin survival analysis, especially in early prognosis settings. Our sensitivity\nanalyses further demonstrate the importance of time ordering, which requires\nclinical time series construction, as compared to text ordering, the format of\nthe text inputs that LLMs are classically trained on. This highlights the\nadditional benefit that can be ascertained from time-ordered corpora, with\nimplications for temporal tasks in the era of widespread LLM use.",
      "tldr_zh": "该研究提出了从临床文本时间序列进行预测的问题，利用LLM辅助的标注流程提取的时间戳临床发现作为预测的主要输入。研究系统地评估了多种模型，包括微调的decoder-based大型语言模型和encoder-based transformer，用于事件发生预测、时间排序和生存分析任务。实验表明，encoder-based模型在短、长期事件预测中始终获得更高的F1分数和更好的时间一致性，而微调的masking方法增强了排序性能。Instruction-tuned decoder模型在生存分析中表现出相对优势，尤其是在早期预后设置中。 敏感性分析表明，时间排序的重要性，这需要构建临床时间序列，这与LLM经典训练的文本排序格式相比，从时间排序语料库中可以获得额外的好处，这对广泛使用LLM时代的时间任务具有影响。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Machine Learning for Healthcare (MLHC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.10340v1",
      "published_date": "2025-04-14 15:48:56 UTC",
      "updated_date": "2025-04-14 15:48:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:15:19.005136"
    },
    {
      "arxiv_id": "2504.10337v1",
      "title": "Heimdall: test-time scaling on the generative verification",
      "title_zh": "Heimdall：生成式验证的测试时扩展\n",
      "authors": [
        "Wenlei Shi",
        "Xing Jin"
      ],
      "abstract": "An AI system can create and maintain knowledge only to the extent that it can\nverify that knowledge itself. Recent work on long Chain-of-Thought reasoning\nhas demonstrated great potential of LLMs on solving competitive problems, but\ntheir verification ability remains to be weak and not sufficiently\ninvestigated. In this paper, we propose Heimdall, the long CoT verification LLM\nthat can accurately judge the correctness of solutions. With pure reinforcement\nlearning, we boost the verification accuracy from 62.5% to 94.5% on competitive\nmath problems. By scaling with repeated sampling, the accuracy further\nincreases to 97.5%. Through human evaluation, Heimdall demonstrates impressive\ngeneralization capabilities, successfully detecting most issues in challenging\nmath proofs, the type of which is not included during training. Furthermore, we\npropose Pessimistic Verification to extend the functionality of Heimdall to\nscaling up the problem solving. It calls Heimdall to judge the solutions from a\nsolver model and based on the pessimistic principle, selects the most likely\ncorrect solution with the least uncertainty. Taking\nDeepSeek-R1-Distill-Qwen-32B as the solver model, Pessimistic Verification\nimproves the solution accuracy on AIME2025 from 54.2% to 70.0% with 16x compute\nbudget and to 83.3% with more compute budget. With the stronger solver Gemini\n2.5 Pro, the score reaches 93.0%. Finally, we prototype an automatic knowledge\ndiscovery system, a ternary system where one poses questions, another provides\nsolutions, and the third verifies the solutions. Using the data synthesis work\nNuminaMath for the first two components, Heimdall effectively identifies\nproblematic records within the dataset and reveals that nearly half of the data\nis flawed, which interestingly aligns with the recent ablation studies from\nNuminaMath.",
      "tldr_zh": "本文提出了Heimdall，一种用于长链思维(CoT)推理的验证LLM，旨在提高AI系统自我验证知识的能力。通过纯强化学习，Heimdall在竞争性数学问题上的验证准确率从62.5%提升至94.5%，并通过重复采样进一步提高到97.5%。Heimdall具有出色的泛化能力，能够检测训练中未包含的复杂数学证明中的问题。此外，作者提出了悲观验证(Pessimistic Verification)方法，利用Heimdall评估求解器模型的答案，并选择最可能正确的答案，从而提升问题解决的准确性。实验表明，结合DeepSeek-R1-Distill-Qwen-32B和Gemini 2.5 Pro等求解器模型，悲观验证在AIME2025问题上的准确率显著提高。最后，作者构建了一个自动知识发现系统，利用Heimdall识别NuminaMath数据集中的问题记录，发现近一半的数据存在缺陷。\n",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10337v1",
      "published_date": "2025-04-14 15:46:33 UTC",
      "updated_date": "2025-04-14 15:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:15:31.336135"
    },
    {
      "arxiv_id": "2504.10326v1",
      "title": "AlayaDB: The Data Foundation for Efficient and Effective Long-context LLM Inference",
      "title_zh": "AlayaDB：高效且有效的长上下文 LLM 推理的数据基础\n",
      "authors": [
        "Yangshen Deng",
        "Zhengxin You",
        "Long Xiang",
        "Qilong Li",
        "Peiqi Yuan",
        "Zhaoyang Hong",
        "Yitao Zheng",
        "Wanting Li",
        "Runzhong Li",
        "Haotian Liu",
        "Kyriakos Mouratidis",
        "Man Lung Yiu",
        "Huan Li",
        "Qiaomu Shen",
        "Rui Mao",
        "Bo Tang"
      ],
      "abstract": "AlayaDB is a cutting-edge vector database system natively architected for\nefficient and effective long-context inference for Large Language Models (LLMs)\nat AlayaDB AI. Specifically, it decouples the KV cache and attention\ncomputation from the LLM inference systems, and encapsulates them into a novel\nvector database system. For the Model as a Service providers (MaaS), AlayaDB\nconsumes fewer hardware resources and offers higher generation quality for\nvarious workloads with different kinds of Service Level Objectives (SLOs), when\ncomparing with the existing alternative solutions (e.g., KV cache\ndisaggregation, retrieval-based sparse attention). The crux of AlayaDB is that\nit abstracts the attention computation and cache management for LLM inference\ninto a query processing procedure, and optimizes the performance via a native\nquery optimizer. In this work, we demonstrate the effectiveness of AlayaDB via\n(i) three use cases from our industry partners, and (ii) extensive experimental\nresults on LLM inference benchmarks.",
      "tldr_zh": "AlayaDB 是一种新型向量数据库系统，专为大型语言模型(LLM)的长上下文推理而设计，旨在提高效率和效果。它将 KV 缓存和注意力计算从 LLM 推理系统中解耦，并将其封装到向量数据库中。相比于现有的解决方案（如 KV 缓存分离、基于检索的稀疏注意力），AlayaDB 消耗更少的硬件资源，并为具有不同服务级别目标(SLO)的各种工作负载提供更高的生成质量。AlayaDB 的核心在于将 LLM 推理的注意力计算和缓存管理抽象为查询处理过程，并通过原生查询优化器来优化性能。通过来自工业合作伙伴的三个用例和 LLM 推理基准上的大量实验结果，验证了 AlayaDB 的有效性。\n",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "H.3.1; H.3.2; H.3.3; H.3.4"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 12 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2504.10326v1",
      "published_date": "2025-04-14 15:34:26 UTC",
      "updated_date": "2025-04-14 15:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:15:42.901236"
    },
    {
      "arxiv_id": "2504.10309v1",
      "title": "AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis",
      "title_zh": "AutoStyle-TTS：基于检索增强生成的自动风格匹配文本到语音合成\n",
      "authors": [
        "Dan Luo",
        "Chengyuan Ma",
        "Weiqin Li",
        "Jun Wang",
        "Wei Chen",
        "Zhiyong Wu"
      ],
      "abstract": "With the advancement of speech synthesis technology, users have higher\nexpectations for the naturalness and expressiveness of synthesized speech. But\nprevious research ignores the importance of prompt selection. This study\nproposes a text-to-speech (TTS) framework based on Retrieval-Augmented\nGeneration (RAG) technology, which can dynamically adjust the speech style\naccording to the text content to achieve more natural and vivid communication\neffects. We have constructed a speech style knowledge database containing\nhigh-quality speech samples in various contexts and developed a style matching\nscheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and\nMoka, to match with samples in the knowledge database, selecting the most\nappropriate speech style for synthesis. Furthermore, our empirical research\nvalidates the effectiveness of the proposed method. Our demo can be viewed at:\nhttps://thuhcsi.github.io/icme2025-AutoStyle-TTS",
      "tldr_zh": "该论文提出了一种基于检索增强生成(RAG)的自动风格匹配文本到语音(TTS)合成框架AutoStyle-TTS，旨在提升合成语音的自然性和表现力。该框架构建了一个包含各种语境下高质量语音样本的语音风格知识库，并提出一种风格匹配方案，利用Llama、PER-LLM-Embedder和Moka提取的embeddings与知识库中的样本进行匹配，为合成选择最合适的语音风格。实验结果验证了该方法的有效性，表明AutoStyle-TTS能够根据文本内容动态调整语音风格，实现更自然生动的语音合成效果。\n",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted by ICME25",
      "pdf_url": "http://arxiv.org/pdf/2504.10309v1",
      "published_date": "2025-04-14 15:18:59 UTC",
      "updated_date": "2025-04-14 15:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:15:54.764431"
    },
    {
      "arxiv_id": "2504.10286v1",
      "title": "Characterizing LLM-driven Social Network: The Chirper.ai Case",
      "title_zh": "LLM驱动的社交网络特征：以Chirper.ai为例\n",
      "authors": [
        "Yiming Zhu",
        "Yupeng He",
        "Ehsan-Ul Haq",
        "Gareth Tyson",
        "Pan Hui"
      ],
      "abstract": "Large language models (LLMs) demonstrate the ability to simulate human\ndecision-making processes, enabling their use as agents in modeling\nsophisticated social networks, both offline and online. Recent research has\nexplored collective behavioral patterns and structural characteristics of LLM\nagents within simulated networks. However, empirical comparisons between\nLLM-driven and human-driven online social networks remain scarce, limiting our\nunderstanding of how LLM agents differ from human users. This paper presents a\nlarge-scale analysis of Chirper.ai, an X/Twitter-like social network entirely\npopulated by LLM agents, comprising over 65,000 agents and 7.7 million\nAI-generated posts. For comparison, we collect a parallel dataset from\nMastodon, a human-driven decentralized social network, with over 117,000 users\nand 16 million posts. We examine key differences between LLM agents and humans\nin posting behaviors, abusive content, and social network structures. Our\nfindings provide critical insights into the evolving landscape of online social\nnetwork analysis in the AI era, offering a comprehensive profile of LLM agents\nin social simulations.",
      "tldr_zh": "该论文对完全由LLM驱动的社交网络Chirper.ai进行了大规模分析，该网络包含超过65,000个智能体和770万条AI生成的帖子。通过与人类驱动的去中心化社交网络Mastodon（包含117,000多名用户和1600万条帖子）的对比，研究人员分析了LLM智能体和人类在发帖行为、攻击性内容和社会网络结构上的关键差异。研究结果揭示了AI时代在线社交网络分析的新特点，并为LLM智能体在社交模拟中的应用提供了全面的分析。该研究旨在深入了解LLM驱动的社交网络与人类驱动的社交网络之间的区别。\n",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.10286v1",
      "published_date": "2025-04-14 14:53:31 UTC",
      "updated_date": "2025-04-14 14:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:16:06.969836"
    },
    {
      "arxiv_id": "2504.10281v1",
      "title": "Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials",
      "title_zh": "用于二维材料可扩展智能表征的零样本自主显微镜技术\n",
      "authors": [
        "Jingyun Yang",
        "Ruoyan Avery Yin",
        "Chi Jiang",
        "Yuepeng Hu",
        "Xiaokai Zhu",
        "Xingjian Hu",
        "Sutharsika Kumar",
        "Xiao Wang",
        "Xiaohua Zhai",
        "Keran Rong",
        "Yunyue Zhu",
        "Tianyi Zhang",
        "Zongyou Yin",
        "Jing Kong",
        "Neil Zhenqiang Gong",
        "Zhichu Ren",
        "Haozhe Wang"
      ],
      "abstract": "Characterization of atomic-scale materials traditionally requires human\nexperts with months to years of specialized training. Even for trained human\noperators, accurate and reliable characterization remains challenging when\nexamining newly discovered materials such as two-dimensional (2D) structures.\nThis bottleneck drives demand for fully autonomous experimentation systems\ncapable of comprehending research objectives without requiring large training\ndatasets. In this work, we present ATOMIC (Autonomous Technology for Optical\nMicroscopy & Intelligent Characterization), an end-to-end framework that\nintegrates foundation models to enable fully autonomous, zero-shot\ncharacterization of 2D materials. Our system integrates the vision foundation\nmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),\nunsupervised clustering, and topological analysis to automate microscope\ncontrol, sample scanning, image segmentation, and intelligent analysis through\nprompt engineering, eliminating the need for additional training. When\nanalyzing typical MoS2 samples, our approach achieves 99.7% segmentation\naccuracy for single layer identification, which is equivalent to that of human\nexperts. In addition, the integrated model is able to detect grain boundary\nslits that are challenging to identify with human eyes. Furthermore, the system\nretains robust accuracy despite variable conditions including defocus, color\ntemperature fluctuations, and exposure variations. It is applicable to a broad\nspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardless\nof whether they were fabricated via chemical vapor deposition or mechanical\nexfoliation. This work represents the implementation of foundation models to\nachieve autonomous analysis, establishing a scalable and data-efficient\ncharacterization paradigm that fundamentally transforms the approach to\nnanoscale materials research.",
      "tldr_zh": "该论文提出了ATOMIC (Autonomous Technology for Optical Microscopy & Intelligent Characterization)，一个端到端的框架，利用基础模型实现对二维材料的完全自主、零样本表征。ATOMIC集成了视觉基础模型(Segment Anything Model)、大型语言模型(ChatGPT)、无监督聚类和拓扑分析，通过提示工程自动化显微镜控制、样本扫描、图像分割和智能分析，无需额外训练。在分析MoS2样品时，单层识别的分割精度达到99.7%，与人类专家相当，并且能够检测人眼难以识别的晶界狭缝。该系统对散焦、色温波动和曝光变化等可变条件具有鲁棒性，适用于包括石墨烯、MoS2、WSe2、SnSe在内的多种常见二维材料。ATOMIC为纳米尺度材料研究建立了一种可扩展且数据高效的表征范例。\n",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10281v1",
      "published_date": "2025-04-14 14:49:45 UTC",
      "updated_date": "2025-04-14 14:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:16:19.151505"
    },
    {
      "arxiv_id": "2504.10277v1",
      "title": "RealHarm: A Collection of Real-World Language Model Application Failures",
      "title_zh": "RealHarm：真实世界语言模型应用失败案例集锦\n",
      "authors": [
        "Pierre Le Jeune",
        "Jiaen Liu",
        "Luca Rossi",
        "Matteo Dora"
      ],
      "abstract": "Language model deployments in consumer-facing applications introduce numerous\nrisks. While existing research on harms and hazards of such applications\nfollows top-down approaches derived from regulatory frameworks and theoretical\nanalyses, empirical evidence of real-world failure modes remains underexplored.\nIn this work, we introduce RealHarm, a dataset of annotated problematic\ninteractions with AI agents built from a systematic review of publicly reported\nincidents. Analyzing harms, causes, and hazards specifically from the\ndeployer's perspective, we find that reputational damage constitutes the\npredominant organizational harm, while misinformation emerges as the most\ncommon hazard category. We empirically evaluate state-of-the-art guardrails and\ncontent moderation systems to probe whether such systems would have prevented\nthe incidents, revealing a significant gap in the protection of AI\napplications.",
      "tldr_zh": "RealHarm是一个收集了真实世界语言模型应用失败案例的数据集，旨在填补现有研究中缺乏对实际部署中问题模式的经验性探索的空白。通过系统回顾公开报告的事件，该数据集标注了与AI agent的交互中出现的问题，并从部署者的角度分析了危害、原因和风险。研究发现，声誉损害是最主要的企业危害，而虚假信息是最常见的风险类别。对现有guardrails和内容审核系统的评估表明，它们在预防这些事件方面存在显著差距，揭示了AI应用保护的不足。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10277v1",
      "published_date": "2025-04-14 14:44:41 UTC",
      "updated_date": "2025-04-14 14:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:16:30.874768"
    },
    {
      "arxiv_id": "2504.10266v1",
      "title": "Vision based driving agent for race car simulation environments",
      "title_zh": "基于视觉的赛车模拟环境驾驶智能体\n",
      "authors": [
        "Gergely Bári",
        "László Palkovics"
      ],
      "abstract": "In recent years, autonomous driving has become a popular field of study. As\ncontrol at tire grip limit is essential during emergency situations, algorithms\ndeveloped for racecars are useful for road cars too. This paper examines the\nuse of Deep Reinforcement Learning (DRL) to solve the problem of grip limit\ndriving in a simulated environment. Proximal Policy Optimization (PPO) method\nis used to train an agent to control the steering wheel and pedals of the\nvehicle, using only visual inputs to achieve professional human lap times. The\npaper outlines the formulation of the task of time optimal driving on a race\ntrack as a deep reinforcement learning problem, and explains the chosen\nobservations, actions, and reward functions. The results demonstrate human-like\nlearning and driving behavior that utilize maximum tire grip potential.",
      "tldr_zh": "本文探讨了使用深度强化学习(DRL)解决赛车模拟环境中抓地力极限驾驶问题。研究采用近端策略优化(PPO)方法，仅使用视觉输入训练智能体控制车辆的方向盘和踏板，以达到专业人类的单圈时间。论文阐述了将赛道上时间最优驾驶任务构建为深度强化学习问题的方法，并解释了所选的观察、行动和奖励函数。实验结果表明，该智能体展现出类似人类的学习和驾驶行为，能够利用最大的轮胎抓地力潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to ICMCE 2024 (https://icmce.org/2024.html)",
      "pdf_url": "http://arxiv.org/pdf/2504.10266v1",
      "published_date": "2025-04-14 14:29:37 UTC",
      "updated_date": "2025-04-14 14:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:16:42.905592"
    },
    {
      "arxiv_id": "2504.10254v1",
      "title": "MASSeg : 2nd Technical Report for 4th PVUW MOSE Track",
      "title_zh": "MASSeg：第四届 PVUW MOSE 赛道第二份技术报告\n",
      "authors": [
        "Xuqiang Cao",
        "Linnan Zhao",
        "Jiaxuan Zhao",
        "Fang Liu",
        "Puhua Chen",
        "Wenping Ma"
      ],
      "abstract": "Complex video object segmentation continues to face significant challenges in\nsmall object recognition, occlusion handling, and dynamic scene modeling. This\nreport presents our solution, which ranked second in the MOSE track of CVPR\n2025 PVUW Challenge. Based on an existing segmentation framework, we propose an\nimproved model named MASSeg for complex video object segmentation, and\nconstruct an enhanced dataset, MOSE+, which includes typical scenarios with\nocclusions, cluttered backgrounds, and small target instances. During training,\nwe incorporate a combination of inter-frame consistent and inconsistent data\naugmentation strategies to improve robustness and generalization. During\ninference, we design a mask output scaling strategy to better adapt to varying\nobject sizes and occlusion levels. As a result, MASSeg achieves a J score of\n0.8250, F score of 0.9007, and a J&F score of 0.8628 on the MOSE test set.",
      "tldr_zh": "该报告介绍了MASSeg，一种用于复杂视频对象分割的改进模型，在CVPR 2025 PVUW Challenge的MOSE track中排名第二。为了应对小物体识别、遮挡处理和动态场景建模等挑战，研究者在现有分割框架的基础上，构建了增强数据集MOSE+，包含遮挡、杂乱背景和小目标实例等典型场景。训练过程中，结合了帧间一致和不一致的数据增强策略，以提高鲁棒性和泛化能力。推理阶段，设计了mask输出缩放策略，以更好地适应不同的对象大小和遮挡程度。实验结果表明，MASSeg在MOSE测试集上取得了J score 0.8250，F score 0.9007和J&F score 0.8628的成绩。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages,4 figures,Technical report on Complex Video Object\n  Segmentation",
      "pdf_url": "http://arxiv.org/pdf/2504.10254v1",
      "published_date": "2025-04-14 14:15:46 UTC",
      "updated_date": "2025-04-14 14:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:16:55.082685"
    },
    {
      "arxiv_id": "2504.10210v1",
      "title": "Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?",
      "title_zh": "竞争能否提升大型语言模型驱动的智能体在新闻驱动型时间序列预测领域的熟练度？\n",
      "authors": [
        "Yuxuan Zhang",
        "Yangyang Feng",
        "Daifeng Li",
        "Kexin Zhang",
        "Junlan Chen",
        "Bowen Deng"
      ],
      "abstract": "Multi-agents-based news-driven time series forecasting is considered as a\npotential paradigm shift in the era of large language models (LLMs). The\nchallenge of this task lies in measuring the influences of different news\nevents towards the fluctuations of time series. This requires agents to possess\nstronger abilities of innovative thinking and the identifying misleading logic.\nHowever, the existing multi-agent discussion framework has limited enhancement\non time series prediction in terms of optimizing these two capabilities.\nInspired by the role of competition in fostering innovation, this study embeds\na competition mechanism within the multi-agent discussion to enhance agents'\ncapability of generating innovative thoughts. Furthermore, to bolster the\nmodel's proficiency in identifying misleading information, we incorporate a\nfine-tuned small-scale LLM model within the reflective stage, offering\nauxiliary decision-making support. Experimental results confirm that the\ncompetition can boost agents' capacity for innovative thinking, which can\nsignificantly improve the performances of time series prediction. Similar to\nthe findings of social science, the intensity of competition within this\nframework can influence the performances of agents, providing a new perspective\nfor studying LLMs-based multi-agent systems.",
      "tldr_zh": "该研究探索了在基于LLM的多智能体新闻驱动时间序列预测中，竞争机制对提升智能体能力的影响。现有研究在创新思维和识别误导性逻辑方面存在局限性。该研究在多智能体讨论框架中引入竞争机制，以激发智能体的创新思维能力。此外，通过在反思阶段加入微调的小型LLM模型，辅助决策，提高识别误导信息的能力。实验结果表明，竞争机制能有效提升智能体的创新能力，显著改善时间序列预测性能。研究还发现竞争强度会影响智能体的表现，为研究基于LLM的多智能体系统提供了新的视角。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10210v1",
      "published_date": "2025-04-14 13:25:50 UTC",
      "updated_date": "2025-04-14 13:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:17:07.056007"
    },
    {
      "arxiv_id": "2504.10191v1",
      "title": "Localized Cultural Knowledge is Conserved and Controllable in Large Language Models",
      "title_zh": "大语言模型中，本地化文化知识得到保留且可控\n",
      "authors": [
        "Veniamin Veselovsky",
        "Berke Argin",
        "Benedikt Stroebl",
        "Chris Wendler",
        "Robert West",
        "James Evans",
        "Thomas L. Griffiths",
        "Arvind Narayanan"
      ],
      "abstract": "Just as humans display language patterns influenced by their native tongue\nwhen speaking new languages, LLMs often default to English-centric responses\neven when generating in other languages. Nevertheless, we observe that local\ncultural information persists within the models and can be readily activated\nfor cultural customization. We first demonstrate that explicitly providing\ncultural context in prompts significantly improves the models' ability to\ngenerate culturally localized responses. We term the disparity in model\nperformance with versus without explicit cultural context the explicit-implicit\nlocalization gap, indicating that while cultural knowledge exists within LLMs,\nit may not naturally surface in multilingual interactions if cultural context\nis not explicitly provided. Despite the explicit prompting benefit, however,\nthe answers reduce in diversity and tend toward stereotypes. Second, we\nidentify an explicit cultural customization vector, conserved across all\nnon-English languages we explore, which enables LLMs to be steered from the\nsynthetic English cultural world-model toward each non-English cultural world.\nSteered responses retain the diversity of implicit prompting and reduce\nstereotypes to dramatically improve the potential for customization. We discuss\nthe implications of explicit cultural customization for understanding the\nconservation of alternative cultural world models within LLMs, and their\ncontrollable utility for translation, cultural customization, and the\npossibility of making the explicit implicit through soft control for expanded\nLLM function and appeal.",
      "tldr_zh": "该研究发现，大型语言模型(LLMs)中存在本地化的文化知识，但默认情况下倾向于以英语为中心进行回应。通过在提示中显式提供文化背景，可以显著提高模型生成具有文化针对性的回应的能力，这种性能差距被称为显式-隐式本地化差距。研究进一步识别出一种显式的文化定制向量，该向量在所有非英语语言中都得到保留，可以将LLM从合成的英语文化世界模型引导到每种非英语文化世界。这种引导后的回应保留了隐式提示的多样性，减少了刻板印象，从而极大地提高了定制的潜力。该研究探讨了显式文化定制对于理解LLM中替代文化世界模型的保存，以及它们在翻译、文化定制中的可控效用，以及通过软控制使显式隐式化以扩展LLM功能和吸引力的可能性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10191v1",
      "published_date": "2025-04-14 12:53:58 UTC",
      "updated_date": "2025-04-14 12:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:17:19.143440"
    },
    {
      "arxiv_id": "2504.10188v1",
      "title": "Efficient Generative Model Training via Embedded Representation Warmup",
      "title_zh": "通过嵌入式表示预热实现高效生成模型训练\n",
      "authors": [
        "Deyuan Liu",
        "Peng Sun",
        "Xufeng Li",
        "Tao Lin"
      ],
      "abstract": "Diffusion models excel at generating high-dimensional data but fall short in\ntraining efficiency and representation quality compared to self-supervised\nmethods. We identify a key bottleneck: the underutilization of high-quality,\nsemantically rich representations during training notably slows down\nconvergence. Our systematic analysis reveals a critical representation\nprocessing region -- primarily in the early layers -- where semantic and\nstructural pattern learning takes place before generation can occur. To address\nthis, we propose Embedded Representation Warmup (ERW), a plug-and-play\nframework where in the first stage we get the ERW module serves as a warmup\nthat initializes the early layers of the diffusion model with high-quality,\npretrained representations. This warmup minimizes the burden of learning\nrepresentations from scratch, thereby accelerating convergence and boosting\nperformance. Our theoretical analysis demonstrates that ERW's efficacy depends\non its precise integration into specific neural network layers -- termed the\nrepresentation processing region -- where the model primarily processes and\ntransforms feature representations for later generation. We further establish\nthat ERW not only accelerates training convergence but also enhances\nrepresentation quality: empirically, our method achieves a 40$\\times$\nacceleration in training speed compared to REPA, the current state-of-the-art\nmethods. Code is available at https://github.com/LINs-lab/ERW.",
      "tldr_zh": "该论文提出了一种名为嵌入表示预热(Embedded Representation Warmup, ERW)的框架，旨在提高生成模型的训练效率。研究发现，生成模型训练初期对高质量语义表示的利用不足是导致训练效率低下的关键瓶颈。ERW通过预训练的高质量表示初始化扩散模型的早期层，减轻了从头学习表示的负担，从而加速收敛并提升性能。理论分析表明，ERW的有效性取决于其与特定神经网络层的精确集成，即表示处理区域。实验结果表明，ERW在训练速度上比现有最先进方法REPA快40倍，并且能够提升表示质量。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10188v1",
      "published_date": "2025-04-14 12:43:17 UTC",
      "updated_date": "2025-04-14 12:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:17:30.989398"
    },
    {
      "arxiv_id": "2504.10187v1",
      "title": "Deep Reasoning Translation via Reinforcement Learning",
      "title_zh": "基于强化学习的深度推理翻译\n",
      "authors": [
        "Jiaan Wang",
        "Fandong Meng",
        "Jie Zhou"
      ],
      "abstract": "Recently, deep reasoning LLMs (e.g., OpenAI o1/o3 and DeepSeek-R1) have shown\npromising performance in various complex tasks. Free translation is an\nimportant and interesting task in the multilingual world, which requires going\nbeyond word-for-word translation and taking cultural differences into account.\nThis task is still under-explored in deep reasoning LLMs. In this paper, we\nintroduce DeepTrans, a deep reasoning translation model that learns free\ntranslation via reinforcement learning. Specifically, we carefully build a\nreward model with pre-defined scoring criteria on both the translation results\nand the thought process. Given the source sentences, the reward model teaches\nthe deep translation model how to think and free-translate them during\nreinforcement learning. In this way, training DeepTrans does not need any\nlabeled translations, avoiding the human-intensive annotation or\nresource-intensive data synthesis. Experimental results show the effectiveness\nof DeepTrans. Using Qwen2.5-7B as the backbone, DeepTrans improves performance\nby 16.3% in literature translation, and outperforms strong deep reasoning\nbaselines as well as baselines that are fine-tuned with synthesized data.\nMoreover, we summarize the failures and interesting findings during our RL\nexploration. We hope this work could inspire other researchers in free\ntranslation.",
      "tldr_zh": "该论文提出了DeepTrans，一个基于强化学习的深度推理翻译模型，用于学习自由翻译。DeepTrans通过精心构建的奖励模型，基于预定义的翻译结果和思维过程评分标准，指导模型进行思考和自由翻译。该方法无需标注数据，避免了人工标注或资源密集型的数据合成。实验结果表明，DeepTrans在使用Qwen2.5-7B作为backbone时，在文学翻译方面性能提升了16.3%，优于强深度推理基线以及使用合成数据进行微调的基线。该研究总结了强化学习探索过程中的失败案例和有趣发现，旨在为自由翻译领域的研究提供启发。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10187v1",
      "published_date": "2025-04-14 12:40:39 UTC",
      "updated_date": "2025-04-14 12:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:17:43.000228"
    },
    {
      "arxiv_id": "2504.10185v1",
      "title": "LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks",
      "title_zh": "LLM 非学习揭示了当前基准测试中比预期更强的 Coreset 效应\n",
      "authors": [
        "Soumyadeep Pal",
        "Changsheng Wang",
        "James Diffenderfer",
        "Bhavya Kailkhura",
        "Sijia Liu"
      ],
      "abstract": "Large language model unlearning has become a critical challenge in ensuring\nsafety and controlled model behavior by removing undesired data-model\ninfluences from the pretrained model while preserving general utility.\nSignificant recent efforts have been dedicated to developing LLM unlearning\nbenchmarks such as WMDP (Weapons of Mass Destruction Proxy) and MUSE (Machine\nUnlearning Six-way Evaluation), facilitating standardized unlearning\nperformance assessment and method comparison. Despite their usefulness, we\nuncover for the first time a novel coreset effect within these benchmarks.\nSpecifically, we find that LLM unlearning achieved with the original (full)\nforget set can be effectively maintained using a significantly smaller subset\n(functioning as a \"coreset\"), e.g., as little as 5% of the forget set, even\nwhen selected at random. This suggests that LLM unlearning in these benchmarks\ncan be performed surprisingly easily, even in an extremely low-data regime. We\ndemonstrate that this coreset effect remains strong, regardless of the LLM\nunlearning method used, such as NPO (Negative Preference Optimization) and RMU\n(Representation Misdirection Unlearning), the popular ones in these benchmarks.\nThe surprisingly strong coreset effect is also robust across various data\nselection methods, ranging from random selection to more sophisticated\nheuristic approaches. We explain the coreset effect in LLM unlearning through a\nkeyword-based perspective, showing that keywords extracted from the forget set\nalone contribute significantly to unlearning effectiveness and indicating that\ncurrent unlearning is driven by a compact set of high-impact tokens rather than\nthe entire dataset. We further justify the faithfulness of coreset-unlearned\nmodels along additional dimensions, such as mode connectivity and robustness to\njailbreaking attacks. Codes are available at\nhttps://github.com/OPTML-Group/MU-Coreset.",
      "tldr_zh": "该论文揭示了现有大语言模型(LLM)卸载基准测试中存在一种比预期更强的coreset效应。研究发现，使用原始完整forget set实现的LLM卸载效果，可以用一个显著更小的子集（即coreset）有效地维持，甚至随机选择的子集也能达到效果，例如仅用5%的forget set。这表明在这些基准测试中，LLM卸载的执行非常容易，即使在极低数据量的情况下也是如此。研究表明，无论使用何种LLM卸载方法（如NPO和RMU），这种coreset效应依然很强，并且对各种数据选择方法具有鲁棒性。论文通过基于关键词的视角解释了LLM卸载中的coreset效应，表明从forget set中提取的关键词对卸载效果有显著贡献，并表明当前的卸载是由一小组高影响力的token驱动，而不是整个数据集。此外，论文还证明了coreset卸载模型在模式连接和对jailbreaking攻击的鲁棒性等方面的可靠性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10185v1",
      "published_date": "2025-04-14 12:38:37 UTC",
      "updated_date": "2025-04-14 12:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:17:55.497768"
    },
    {
      "arxiv_id": "2504.10179v1",
      "title": "The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance",
      "title_zh": "MLLM提示的未来在于自适应：针对稳健多模态性能的提示工程方法综合实验评估\n",
      "authors": [
        "Anwesha Mohanty",
        "Venkatesh Balavadhani Parthasarathy",
        "Arsalan Shahid"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are set to transform how machines\nprocess and generate human-like responses by integrating diverse modalities\nsuch as text, images, and code. Yet, effectively harnessing their capabilities\nhinges on optimal prompt engineering. We present a comprehensive experimental\nevaluation of seven prompt engineering methods applied to 13 open-source MLLMs\nover 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding\nand Alignment, Complex Code Generation and Execution, and Knowledge Retrieval\nand Integration. Our approach stratifies models by parameter count into Small\n(<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting\ntechniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought,\nAnalogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel\nin structured tasks such as code generation, achieving accuracies up to 96.88%\nunder Few-Shot prompting, all models struggle with complex reasoning and\nabstract understanding, often yielding accuracies below 60% and high\nhallucination rates. Structured reasoning prompts frequently increased\nhallucination up to 75% in small models and led to longer response times (over\n20 seconds in Large MLLMs), while simpler prompting methods provided more\nconcise and efficient outputs. No single prompting method uniformly optimises\nall task types. Instead, adaptive strategies combining example-based guidance\nwith selective structured reasoning are essential to enhance robustness,\nefficiency, and factual accuracy. Our findings offer practical recommendations\nfor prompt engineering and support more reliable deployment of MLLMs across\napplications including AI-assisted coding, knowledge retrieval, and multimodal\ncontent understanding.",
      "tldr_zh": "该研究对13个开源多模态大型语言模型(MLLMs)在24个任务上进行了全面的实验评估，涵盖推理与组合性、多模态理解与对齐、复杂代码生成与执行以及知识检索与集成。研究比较了七种提示工程方法，包括零样本(Zero-Shot)、单样本(One-Shot)、少样本(Few-Shot)、思维链(Chain-of-Thought)、类比(Analogical)、生成知识(Generated Knowledge)和思维树(Tree-of-Thought)。结果表明，大型MLLMs在代码生成等结构化任务中表现出色，但在复杂推理和抽象理解方面表现不佳。研究强调，没有一种提示方法能统一优化所有任务类型，自适应策略（结合基于示例的指导和选择性的结构化推理）对于提高MLLMs的鲁棒性、效率和事实准确性至关重要。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10179v1",
      "published_date": "2025-04-14 12:31:39 UTC",
      "updated_date": "2025-04-14 12:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:18:07.466207"
    },
    {
      "arxiv_id": "2504.10168v1",
      "title": "HalluSearch at SemEval-2025 Task 3: A Search-Enhanced RAG Pipeline for Hallucination Detection",
      "title_zh": "HalluSearch 参加 SemEval-2025 任务 3：一种用于幻觉检测的搜索增强型 RAG 流程\n",
      "authors": [
        "Mohamed A. Abdallah",
        "Samhaa R. El-Beltagy"
      ],
      "abstract": "In this paper, we present HalluSearch, a multilingual pipeline designed to\ndetect fabricated text spans in Large Language Model (LLM) outputs. Developed\nas part of Mu-SHROOM, the Multilingual Shared-task on Hallucinations and\nRelated Observable Overgeneration Mistakes, HalluSearch couples\nretrieval-augmented verification with fine-grained factual splitting to\nidentify and localize hallucinations in fourteen different languages. Empirical\nevaluations show that HalluSearch performs competitively, placing fourth in\nboth English (within the top ten percent) and Czech. While the system's\nretrieval-based strategy generally proves robust, it faces challenges in\nlanguages with limited online coverage, underscoring the need for further\nresearch to ensure consistent hallucination detection across diverse linguistic\ncontexts.",
      "tldr_zh": "本文介绍了HalluSearch，一个用于检测大型语言模型(LLM)输出中虚构文本的多语言pipeline。HalluSearch是Mu-SHROOM项目的一部分，旨在解决幻觉和相关过度生成问题。该pipeline结合了检索增强验证(retrieval-augmented verification)和细粒度的factual splitting，以识别和定位十四种不同语言中的幻觉。实验评估表明，HalluSearch表现出色，在英语和捷克语中均排名第四。研究发现，基于检索的策略通常很有效，但在在线覆盖率有限的语言中面临挑战，突显了未来研究需要在不同语言环境中实现一致的幻觉检测。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10168v1",
      "published_date": "2025-04-14 12:22:30 UTC",
      "updated_date": "2025-04-14 12:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:18:19.008902"
    },
    {
      "arxiv_id": "2504.10167v1",
      "title": "C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation",
      "title_zh": "C-FAITH：用于自动幻觉评估的中文细粒度基准\n",
      "authors": [
        "Xu Zhang",
        "Zhifei Liu",
        "Jiahao Wang",
        "Huixuan Zhang",
        "Fan Xu",
        "Junzhe Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "Despite the rapid advancement of large language models, they remain highly\nsusceptible to generating hallucinations, which significantly hinders their\nwidespread application. Hallucination research requires dynamic and\nfine-grained evaluation. However, most existing hallucination benchmarks\n(especially in Chinese language) rely on human annotations, making automatical\nand cost-effective hallucination evaluation challenging. To address this, we\nintroduce HaluAgent, an agentic framework that automatically constructs\nfine-grained QA dataset based on some knowledge documents. Our experiments\ndemonstrate that the manually designed rules and prompt optimization can\nimprove the quality of generated data. Using HaluAgent, we construct C-FAITH, a\nChinese QA hallucination benchmark created from 1,399 knowledge documents\nobtained from web scraping, totaling 60,702 entries. We comprehensively\nevaluate 16 mainstream LLMs with our proposed C-FAITH, providing detailed\nexperimental results and analysis.",
      "tldr_zh": "该论文提出了C-FAITH，一个中文细粒度基准，用于自动化评估大型语言模型(LLMs)的幻觉问题。为了解决现有幻觉基准依赖人工标注的问题，研究者们引入了HaluAgent，一个基于知识文档自动构建细粒度QA数据集的agentic框架。通过人工设计的规则和prompt优化，提高了生成数据的质量。利用HaluAgent，他们构建了包含60,702条数据的C-FAITH基准，数据来源于1,399个网络抓取的知识文档。最后，使用C-FAITH对16个主流LLMs进行了全面评估，并提供了详细的实验结果和分析。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10167v1",
      "published_date": "2025-04-14 12:21:55 UTC",
      "updated_date": "2025-04-14 12:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:18:31.001036"
    },
    {
      "arxiv_id": "2504.10165v2",
      "title": "WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs",
      "title_zh": "WildLive：无人机载近实时视觉野生动物追踪\n",
      "authors": [
        "Nguyen Ngoc Dat",
        "Tom Richardson",
        "Matthew Watson",
        "Kilian Meier",
        "Jenna Kline",
        "Sid Reid",
        "Guy Maalouf",
        "Duncan Hine",
        "Majid Mirmehdi",
        "Tilo Burghardt"
      ],
      "abstract": "Live tracking of wildlife via high-resolution video processing directly\nonboard drones is widely unexplored and most existing solutions rely on\nstreaming video to ground stations to support navigation. Yet, both autonomous\nanimal-reactive flight control beyond visual line of sight and/or\nmission-specific individual and behaviour recognition tasks rely to some degree\non this capability. In response, we introduce WildLive -- a near real-time\nanimal detection and tracking framework for high-resolution imagery running\ndirectly onboard uncrewed aerial vehicles (UAVs). The system performs\nmulti-animal detection and tracking at 17fps+ for HD and 7fps+ on 4K video\nstreams suitable for operation during higher altitude flights to minimise\nanimal disturbance. Our system is optimised for Jetson Orin AGX onboard\nhardware. It integrates the efficiency of sparse optical flow tracking and\nmission-specific sampling with device-optimised and proven YOLO-driven object\ndetection and segmentation techniques. Essentially, computational resource is\nfocused onto spatio-temporal regions of high uncertainty to significantly\nimprove UAV processing speeds without domain-specific loss of accuracy.\nAlongside, we introduce our WildLive dataset, which comprises 200k+ annotated\nanimal instances across 19k+ frames from 4K UAV videos collected at the Ol\nPejeta Conservancy in Kenya. All frames contain ground truth bounding boxes,\nsegmentation masks, as well as individual tracklets and tracking point\ntrajectories. We compare our system against current object tracking approaches\nincluding OC-SORT, ByteTrack, and SORT. Our materials are available at:\nhttps://dat-nguyenvn.github.io/WildLive/",
      "tldr_zh": "该论文提出了WildLive，一个近实时的动物检测和跟踪框架，可以直接在无人机(UAVs)上运行，处理高分辨率视频。该系统针对Jetson Orin AGX硬件优化，集成了稀疏光流跟踪和任务特定采样，以及设备优化的YOLO驱动的目标检测和分割技术，在HD视频流上达到17fps+，在4K视频流上达到7fps+的多动物检测和跟踪速度。此外，论文还发布了WildLive数据集，包含来自肯尼亚Ol Pejeta保护区的4K无人机视频中超过20万个带注释的动物实例。实验结果表明，该系统优于现有的目标跟踪方法，如OC-SORT, ByteTrack和SORT。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10165v2",
      "published_date": "2025-04-14 12:21:16 UTC",
      "updated_date": "2025-04-15 12:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:18:43.205774"
    },
    {
      "arxiv_id": "2504.10160v1",
      "title": "MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning",
      "title_zh": "MT-R1-Zero：通过类 R1-Zero 强化学习推进基于 LLM 的机器翻译\n",
      "authors": [
        "Zhaopeng Feng",
        "Shaosheng Cao",
        "Jiahan Ren",
        "Jiayuan Su",
        "Ruizhe Chen",
        "Yan Zhang",
        "Zhe Xu",
        "Yao Hu",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "abstract": "Large-scale reinforcement learning (RL) methods have proven highly effective\nin enhancing the reasoning abilities of large language models (LLMs),\nparticularly for tasks with verifiable solutions such as mathematics and\ncoding. However, applying this idea to machine translation (MT), where outputs\nare flexibly formatted and difficult to automatically evaluate with explicit\nrules, remains underexplored. In this work, we introduce MT-R1-Zero, the first\nopen-source adaptation of the R1-Zero RL framework for MT without supervised\nfine-tuning or cold-start. We propose a rule-metric mixed reward mechanism to\nguide LLMs towards improved translation quality via emergent reasoning. On the\nWMT 24 English-Chinese benchmark, our MT-R1-Zero-3B-Mix achieves competitive\nperformance, surpassing TowerInstruct-7B-v0.2 by an average of 1.26 points.\nMeanwhile, our MT-R1-Zero-7B-Mix attains a high average score of 62.25 across\nall metrics, placing it on par with advanced proprietary models such as GPT-4o\nand Claude-3.5-Sonnet, while the MT-R1-Zero-7B-Sem variant achieves\nstate-of-the-art scores on semantic metrics. Moreover, our work exhibits strong\ngeneralization capabilities on out-of-distribution MT tasks, robustly\nsupporting multilingual and low-resource settings. Extensive analysis of model\nbehavior across different initializations and reward metrics offers pioneering\ninsight into the critical role of reward design, LLM adaptability, training\ndynamics, and emergent reasoning patterns within the R1-Zero paradigm for MT.\nOur code is available at https://github.com/fzp0424/MT-R1-Zero.",
      "tldr_zh": "该论文提出了MT-R1-Zero，一种基于R1-Zero强化学习框架的机器翻译方法，无需监督微调或冷启动即可提升大型语言模型(LLMs)的翻译能力。通过规则指标混合奖励机制，引导LLMs通过涌现推理提高翻译质量。在WMT 24英汉基准测试中，MT-R1-Zero-3B-Mix超越了TowerInstruct-7B-v0.2，MT-R1-Zero-7B-Mix与GPT-4o和Claude-3.5-Sonnet等先进专有模型相当，MT-R1-Zero-7B-Sem在语义指标上达到了最先进水平。该方法在多语言和低资源环境等分布外机器翻译任务中表现出强大的泛化能力。研究深入分析了奖励设计、LLM适应性、训练动态和涌现推理模式在MT的R1-Zero范式中的关键作用。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Our code is available at\n  https://github.com/fzp0424/MT-R1-Zero",
      "pdf_url": "http://arxiv.org/pdf/2504.10160v1",
      "published_date": "2025-04-14 12:14:18 UTC",
      "updated_date": "2025-04-14 12:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:18:55.323230"
    },
    {
      "arxiv_id": "2504.10158v1",
      "title": "COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts",
      "title_zh": "COUNTS：分布偏移下目标检测器和多模态大型语言模型评测基准",
      "authors": [
        "Jiansheng Li",
        "Xingxuan Zhang",
        "Hao Zou",
        "Yige Guo",
        "Renzhe Xu",
        "Yilong Liu",
        "Chuzhao Zhu",
        "Yue He",
        "Peng Cui"
      ],
      "abstract": "Current object detectors often suffer significant perfor-mance degradation in\nreal-world applications when encountering distributional shifts. Consequently,\nthe out-of-distribution (OOD) generalization capability of object detectors has\ngarnered increasing attention from researchers. Despite this growing interest,\nthere remains a lack of a large-scale, comprehensive dataset and evaluation\nbenchmark with fine-grained annotations tailored to assess the OOD\ngeneralization on more intricate tasks like object detection and grounding. To\naddress this gap, we introduce COUNTS, a large-scale OOD dataset with\nobject-level annotations. COUNTS encompasses 14 natural distributional shifts,\nover 222K samples, and more than 1,196K labeled bounding boxes. Leveraging\nCOUNTS, we introduce two novel benchmarks: O(OD)2 and OODG. O(OD)2 is designed\nto comprehensively evaluate the OOD generalization capabilities of object\ndetectors by utilizing controlled distribution shifts between training and\ntesting data. OODG, on the other hand, aims to assess the OOD generalization of\ngrounding abilities in multimodal large language models (MLLMs). Our findings\nreveal that, while large models and extensive pre-training data substantially\nen hance performance in in-distribution (IID) scenarios, significant\nlimitations and opportunities for improvement persist in OOD contexts for both\nobject detectors and MLLMs. In visual grounding tasks, even the advanced GPT-4o\nand Gemini-1.5 only achieve 56.7% and 28.0% accuracy, respectively. We hope\nCOUNTS facilitates advancements in the development and assessment of robust\nobject detectors and MLLMs capable of maintaining high performance under\ndistributional shifts.",
      "tldr_zh": "该论文提出了COUNTS，一个大规模的OOD（Out-of-Distribution）数据集，旨在评估目标检测器和多模态大型语言模型（MLLMs）在分布偏移下的泛化能力。COUNTS包含14种自然分布偏移，超过22.2万个样本和119.6万个标注边界框。基于此，论文构建了两个新的基准：O(OD)2，用于评估目标检测器的OOD泛化能力；OODG，用于评估MLLMs的视觉定位泛化能力。实验结果表明，大型模型和大规模预训练数据在IID（In-Distribution）场景下表现良好，但在OOD场景下，目标检测器和MLLMs仍存在显著的局限性和改进空间。即使是先进的GPT-4o和Gemini 1.5在视觉定位任务中也仅分别达到56.7%和28.0%的准确率。该数据集旨在促进在分布偏移下保持高性能的鲁棒目标检测器和MLLMs的开发和评估。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10158v1",
      "published_date": "2025-04-14 12:13:33 UTC",
      "updated_date": "2025-04-14 12:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:19:07.399285"
    },
    {
      "arxiv_id": "2504.10149v1",
      "title": "BoTTA: Benchmarking on-device Test Time Adaptation",
      "title_zh": "BoTTA：设备端测试时自适应基准评测\n",
      "authors": [
        "Michal Danilowski",
        "Soumyajit Chatterjee",
        "Abhirup Ghosh"
      ],
      "abstract": "The performance of deep learning models depends heavily on test samples at\nruntime, and shifts from the training data distribution can significantly\nreduce accuracy. Test-time adaptation (TTA) addresses this by adapting models\nduring inference without requiring labeled test data or access to the original\ntraining set. While research has explored TTA from various perspectives like\nalgorithmic complexity, data and class distribution shifts, model\narchitectures, and offline versus continuous learning, constraints specific to\nmobile and edge devices remain underexplored. We propose BoTTA, a benchmark\ndesigned to evaluate TTA methods under practical constraints on mobile and edge\ndevices. Our evaluation targets four key challenges caused by limited resources\nand usage conditions: (i) limited test samples, (ii) limited exposure to\ncategories, (iii) diverse distribution shifts, and (iv) overlapping shifts\nwithin a sample. We assess state-of-the-art TTA methods under these scenarios\nusing benchmark datasets and report system-level metrics on a real testbed.\nFurthermore, unlike prior work, we align with on-device requirements by\nadvocating periodic adaptation instead of continuous inference-time adaptation.\nExperiments reveal key insights: many recent TTA algorithms struggle with small\ndatasets, fail to generalize to unseen categories, and depend on the diversity\nand complexity of distribution shifts. BoTTA also reports device-specific\nresource use. For example, while SHOT improves accuracy by $2.25\\times$ with\n$512$ adaptation samples, it uses $1.08\\times$ peak memory on Raspberry Pi\nversus the base model. BoTTA offers actionable guidance for TTA in real-world,\nresource-constrained deployments.",
      "tldr_zh": "该论文提出了BoTTA，一个用于评估设备端测试时自适应(Test Time Adaptation, TTA)方法的基准。BoTTA旨在解决移动和边缘设备上TTA方法面临的资源限制和使用条件约束，包括有限的测试样本、有限的类别暴露、多样化的分布偏移以及样本内重叠偏移。研究者在基准数据集上评估了现有TTA方法在这些场景下的表现，并报告了真实测试平台上的系统级指标。实验结果表明，许多TTA算法在小数据集上表现不佳，难以泛化到未见类别，并且依赖于分布偏移的多样性和复杂性。BoTTA还报告了设备特定的资源使用情况，为在资源受限的现实部署中应用TTA提供了实践指导。与以往工作不同，该研究提倡周期性自适应而非连续推理时自适应，更符合设备端需求。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10149v1",
      "published_date": "2025-04-14 12:00:00 UTC",
      "updated_date": "2025-04-14 12:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:19:19.334281"
    },
    {
      "arxiv_id": "2504.10146v1",
      "title": "GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions",
      "title_zh": "GeoUni：用于生成几何图形、问题和问题解答的统一模型\n",
      "authors": [
        "Jo-Ku Cheng",
        "Zeren Zhang",
        "Ran Chen",
        "Jingyang Deng",
        "Ziran Qin",
        "Jinwen Ma"
      ],
      "abstract": "We propose GeoUni, the first unified geometry expert model capable of\ngenerating problem solutions and diagrams within a single framework in a way\nthat enables the creation of unique and individualized geometry problems.\nTraditionally, solving geometry problems and generating diagrams have been\ntreated as separate tasks in machine learning, with no models successfully\nintegrating both to support problem creation. However, we believe that mastery\nin geometry requires frictionless integration of all of these skills, from\nsolving problems to visualizing geometric relationships, and finally, crafting\ntailored problems. Our extensive experiments demonstrate that GeoUni, with only\n1.5B parameters, achieves performance comparable to larger models such as\nDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also\nexcels in generating precise geometric diagrams, surpassing both text-to-image\nmodels and unified models, including the GPT-4o image generation. Most\nimportantly, GeoUni is the only model capable of successfully generating\ntextual problems with matching diagrams based on specific knowledge points,\nthus offering a wider range of capabilities that extend beyond current models.",
      "tldr_zh": "该论文提出了GeoUni，一个统一的几何专家模型，能够在一个框架内生成问题解决方案和图表，从而能够创建独特的和个性化的几何问题。GeoUni在几何推理任务中，仅用15亿参数就达到了与拥有6710亿参数的DeepSeek-R1相当的性能。在生成精确的几何图表方面，GeoUni也超越了文本到图像模型和统一模型，包括GPT-4o的图像生成。GeoUni是唯一能够根据特定知识点成功生成带有匹配图表的文本问题的模型，提供了超越当前模型的更广泛的能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10146v1",
      "published_date": "2025-04-14 11:56:55 UTC",
      "updated_date": "2025-04-14 11:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:19:30.905032"
    },
    {
      "arxiv_id": "2504.10127v2",
      "title": "Breaking the Data Barrier -- Building GUI Agents Through Task Generalization",
      "title_zh": "打破数据壁垒——通过任务泛化构建 GUI 代理\n",
      "authors": [
        "Junlei Zhang",
        "Zichen Ding",
        "Chang Ma",
        "Zijie Chen",
        "Qiushi Sun",
        "Zhenzhong Lan",
        "Junxian He"
      ],
      "abstract": "Graphical User Interface (GUI) agents offer cross-platform solutions for\nautomating complex digital tasks, with significant potential to transform\nproductivity workflows. However, their performance is often constrained by the\nscarcity of high-quality trajectory data. To address this limitation, we\npropose training Vision Language Models (VLMs) on data-rich,\nreasoning-intensive tasks during a dedicated mid-training stage, and then\nexamine how incorporating these tasks facilitates generalization to GUI\nplanning scenarios. Specifically, we explore a range of tasks with readily\navailable instruction-tuning data, including GUI perception, multimodal\nreasoning, and textual reasoning. Through extensive experiments across 11\nmid-training tasks, we demonstrate that: (1) Task generalization proves highly\neffective, yielding substantial improvements across most settings. For\ninstance, multimodal mathematical reasoning enhances performance on\nAndroidWorld by an absolute 6.3%. Remarkably, text-only mathematical data\nsignificantly boosts GUI web agent performance, achieving a 5.6% improvement on\nWebArena and 5.4% improvement on AndroidWorld, underscoring notable cross-modal\ngeneralization from text-based to visual domains; (2) Contrary to prior\nassumptions, GUI perception data - previously considered closely aligned with\nGUI agent tasks and widely utilized for training - has a comparatively limited\nimpact on final performance; (3) Building on these insights, we identify the\nmost effective mid-training tasks and curate optimized mixture datasets,\nresulting in absolute performance gains of 8.0% on WebArena and 12.2% on\nAndroidWorld. Our work provides valuable insights into cross-domain knowledge\ntransfer for GUI agents and offers a practical approach to addressing data\nscarcity challenges in this emerging field. The code, data and models will be\navailable at https://github.com/hkust-nlp/GUIMid.",
      "tldr_zh": "该论文提出了一种通过任务泛化来构建GUI代理的方法，旨在克服高质量轨迹数据稀缺的难题。核心思想是在训练视觉语言模型(VLMs)时，加入数据丰富且推理密集的任务，从而提升模型在GUI规划场景中的泛化能力。研究探索了GUI感知、多模态推理和文本推理等任务，并发现多模态数学推理能显著提升AndroidWorld的性能（6.3%），而纯文本数学数据也能有效提升GUI web代理的性能（WebArena 5.6%，AndroidWorld 5.4%）。令人意外的是，GUI感知数据对最终性能的提升有限。基于这些发现，作者优化了混合数据集，最终在WebArena和AndroidWorld上分别实现了8.0%和12.2%的性能提升。该研究为GUI代理的跨域知识迁移提供了有价值的见解，并为解决该领域的数据稀缺问题提供了一种实用的方法。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10127v2",
      "published_date": "2025-04-14 11:35:02 UTC",
      "updated_date": "2025-04-15 17:13:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:19:43.412390"
    },
    {
      "arxiv_id": "2504.10112v1",
      "title": "Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design",
      "title_zh": "LLM驱动的攻击性安全基准测试实践：测试平台、指标和实验设计\n",
      "authors": [
        "Andreas Happe",
        "Jürgen Cito"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as a powerful approach for driving\noffensive penetration-testing tooling. This paper analyzes the methodology and\nbenchmarking practices used for evaluating Large Language Model (LLM)-driven\nattacks, focusing on offensive uses of LLMs in cybersecurity. We review 16\nresearch papers detailing 15 prototypes and their respective testbeds.\n  We detail our findings and provide actionable recommendations for future\nresearch, emphasizing the importance of extending existing testbeds, creating\nbaselines, and including comprehensive metrics and qualitative analysis. We\nalso note the distinction between security research and practice, suggesting\nthat CTF-based challenges may not fully represent real-world penetration\ntesting scenarios.",
      "tldr_zh": "本文分析了使用大型语言模型(LLMs)驱动的渗透测试工具的评估方法和基准测试实践，重点关注LLMs在网络安全领域的攻击性应用。通过对16篇研究论文中15个原型及其测试平台的分析，总结了当前研究的不足，并为未来研究提供了可操作的建议，包括扩展现有测试平台、创建基线、以及包含全面的指标和定性分析。同时，文章还指出了安全研究与实践之间的区别，认为基于CTF的挑战可能无法完全代表真实的渗透测试场景。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10112v1",
      "published_date": "2025-04-14 11:21:33 UTC",
      "updated_date": "2025-04-14 11:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:19:55.044824"
    },
    {
      "arxiv_id": "2504.10109v1",
      "title": "Lightweight Trustworthy Distributed Clustering",
      "title_zh": "轻量级可信分布式聚类\n",
      "authors": [
        "Hongyang Li",
        "Caesar Wu",
        "Mohammed Chadli",
        "Said Mammar",
        "Pascal Bouvry"
      ],
      "abstract": "Ensuring data trustworthiness within individual edge nodes while facilitating\ncollaborative data processing poses a critical challenge in edge computing\nsystems (ECS), particularly in resource-constrained scenarios such as\nautonomous systems sensor networks, industrial IoT, and smart cities. This\npaper presents a lightweight, fully distributed k-means clustering algorithm\nspecifically adapted for edge environments, leveraging a distributed averaging\napproach with additive secret sharing, a secure multiparty computation\ntechnique, during the cluster center update phase to ensure the accuracy and\ntrustworthiness of data across nodes.",
      "tldr_zh": "本文提出了一种轻量级的、可信的分布式k-means聚类算法，专门为边缘计算环境设计。该算法利用分布式平均方法和加性秘密共享(additive secret sharing)技术，在聚类中心更新阶段确保跨节点数据的准确性和可信度。该方法适用于资源受限的场景，如自动驾驶系统、传感器网络、工业物联网和智慧城市，旨在解决边缘计算系统中数据可信度和协同数据处理的关键挑战。\n",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10109v1",
      "published_date": "2025-04-14 11:16:07 UTC",
      "updated_date": "2025-04-14 11:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:20:06.769093"
    },
    {
      "arxiv_id": "2504.10106v1",
      "title": "SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding",
      "title_zh": "SoccerNet-v3D：利用体育广播回放进行 3D 场景理解\n",
      "authors": [
        "Marc Gutiérrez-Pérez",
        "Antonio Agudo"
      ],
      "abstract": "Sports video analysis is a key domain in computer vision, enabling detailed\nspatial understanding through multi-view correspondences. In this work, we\nintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets\ndesigned for 3D scene understanding in soccer broadcast analysis. These\ndatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera\ncalibration and multi-view synchronization, enabling 3D object localization\nthrough triangulation. We propose a monocular 3D ball localization task built\nupon the triangulation of ground-truth 2D ball annotations, along with several\ncalibration and reprojection metrics to assess annotation quality on demand.\nAdditionally, we present a single-image 3D ball localization method as a\nbaseline, leveraging camera calibration and ball size priors to estimate the\nball's position from a monocular viewpoint. To further refine 2D annotations,\nwe introduce a bounding box optimization technique that ensures alignment with\nthe 3D scene representation. Our proposed datasets establish new benchmarks for\n3D soccer scene understanding, enhancing both spatial and temporal analysis in\nsports analytics. Finally, we provide code to facilitate access to our\nannotations and the generation pipelines for the datasets.",
      "tldr_zh": "该论文介绍了SoccerNet-v3D和ISSIA-3D两个增强型数据集，旨在利用体育赛事广播回放进行3D场景理解。这些数据集通过结合基于球场线的相机标定和多视角同步，扩展了SoccerNet-v3和ISSIA，从而可以通过三角测量实现3D目标定位。论文提出了一个基于真实2D球体标注三角测量的单目3D球体定位任务，并提出了评估标注质量的标定和重投影指标。此外，论文还提出了一种单图像3D球体定位方法作为基线，利用相机标定和球体大小先验来估计单视角的球体位置。为了进一步优化2D标注，论文引入了一种边界框优化技术，以确保与3D场景表示对齐。这些数据集为3D足球场景理解建立了新的基准，并为体育分析中的空间和时间分析提供了帮助。论文还提供了代码，以方便访问标注和数据集的生成流程。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2; I.4; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10106v1",
      "published_date": "2025-04-14 11:15:13 UTC",
      "updated_date": "2025-04-14 11:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:20:19.444647"
    },
    {
      "arxiv_id": "2504.10081v1",
      "title": "RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability",
      "title_zh": "RealSafe-R1：在不牺牲推理能力的前提下，与安全性对齐的 DeepSeek-R1",
      "authors": [
        "Yichi Zhang",
        "Zihao Zeng",
        "Dongbai Li",
        "Yao Huang",
        "Zhijie Deng",
        "Yinpeng Dong"
      ],
      "abstract": "Large Reasoning Models (LRMs), such as OpenAI o1 and DeepSeek-R1, have been\nrapidly progressing and achieving breakthrough performance on complex reasoning\ntasks such as mathematics and coding. However, the open-source R1 models have\nraised safety concerns in wide applications, such as the tendency to comply\nwith malicious queries, which greatly impacts the utility of these powerful\nmodels in their applications. In this paper, we introduce RealSafe-R1 as\nsafety-aligned versions of DeepSeek-R1 distilled models. To train these models,\nwe construct a dataset of 15k safety-aware reasoning trajectories generated by\nDeepSeek-R1, under explicit instructions for expected refusal behavior. Both\nquantitative experiments and qualitative case studies demonstrate the models'\nimprovements, which are shown in their safety guardrails against both harmful\nqueries and jailbreak attacks. Importantly, unlike prior safety alignment\nefforts that often compromise reasoning performance, our method preserves the\nmodels' reasoning capabilities by maintaining the training data within the\noriginal distribution of generation. Model weights of RealSafe-R1 are\nopen-source at https://huggingface.co/RealSafe.",
      "tldr_zh": "该论文提出了RealSafe-R1，一种安全对齐的DeepSeek-R1模型，旨在解决开源R1模型在广泛应用中存在的安全问题，例如易于响应恶意查询。研究人员构建了一个包含15k安全感知推理轨迹的数据集，并使用该数据集对DeepSeek-R1进行训练，使其具备预期的拒绝行为。实验结果表明，RealSafe-R1在防御有害查询和越狱攻击方面有所改进，同时通过保持训练数据在原始生成分布内，避免了以往安全对齐方法中常见的推理能力下降问题。RealSafe-R1的模型权重已开源。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10081v1",
      "published_date": "2025-04-14 10:26:37 UTC",
      "updated_date": "2025-04-14 10:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:20:31.212715"
    },
    {
      "arxiv_id": "2504.10077v1",
      "title": "Towards Quantifying Commonsense Reasoning with Mechanistic Insights",
      "title_zh": "迈向基于机制性理解的常识推理量化\n",
      "authors": [
        "Abhinav Joshi",
        "Areeb Ahmad",
        "Divyaksh Shukla",
        "Ashutosh Modi"
      ],
      "abstract": "Commonsense reasoning deals with the implicit knowledge that is well\nunderstood by humans and typically acquired via interactions with the world. In\nrecent times, commonsense reasoning and understanding of various LLMs have been\nevaluated using text-based tasks. In this work, we argue that a proxy of this\nunderstanding can be maintained as a graphical structure that can further help\nto perform a rigorous evaluation of commonsense reasoning abilities about\nvarious real-world activities. We create an annotation scheme for capturing\nthis implicit knowledge in the form of a graphical structure for 37 daily human\nactivities. We find that the created resource can be used to frame an enormous\nnumber of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of\ncommonsense reasoning in LLMs. Moreover, recently, the remarkable performance\nof LLMs has raised questions about whether these models are truly capable of\nreasoning in the wild and, in general, how reasoning occurs inside these\nmodels. In this resource paper, we bridge this gap by proposing design\nmechanisms that facilitate research in a similar direction. Our findings\nsuggest that the reasoning components are localized in LLMs that play a\nprominent role in decision-making when prompted with a commonsense query.",
      "tldr_zh": "该论文提出了一种量化常识推理的新方法，通过构建图形结构来捕捉日常人类活动中蕴含的隐性知识。作者为37种日常活动创建了注释方案，将隐性知识表示为图形结构，从而能够生成大量的常识查询（约 10^{17}）。该资源可用于严格评估LLM的常识推理能力。研究还发现，LLM中的推理组件是局部化的，并在常识查询的决策过程中起着重要作用，为理解LLM内部的推理机制提供了新的视角。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025; 28 pages (9 pages + 7 pages references + 12\n  pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2504.10077v1",
      "published_date": "2025-04-14 10:21:59 UTC",
      "updated_date": "2025-04-14 10:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:20:43.052028"
    },
    {
      "arxiv_id": "2504.10074v2",
      "title": "MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework",
      "title_zh": "MMKB-RAG：一种基于多模态知识的检索增强生成框架\n",
      "authors": [
        "Zihan Ling",
        "Zhiyao Guo",
        "Yixuan Huang",
        "Yi An",
        "Shuai Xiao",
        "Jinsong Lan",
        "Xiaoyong Zhu",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) and multi-modal LLMs have\nbeen remarkable. However, these models still rely solely on their parametric\nknowledge, which limits their ability to generate up-to-date information and\nincreases the risk of producing erroneous content. Retrieval-Augmented\nGeneration (RAG) partially mitigates these challenges by incorporating external\ndata sources, yet the reliance on databases and retrieval systems can introduce\nirrelevant or inaccurate documents, ultimately undermining both performance and\nreasoning quality. In this paper, we propose Multi-Modal Knowledge-Based\nRetrieval-Augmented Generation (MMKB-RAG), a novel multi-modal RAG framework\nthat leverages the inherent knowledge boundaries of models to dynamically\ngenerate semantic tags for the retrieval process. This strategy enables the\njoint filtering of retrieved documents, retaining only the most relevant and\naccurate references. Extensive experiments on knowledge-based visual\nquestion-answering tasks demonstrate the efficacy of our approach: on the E-VQA\ndataset, our method improves performance by +4.2% on the Single-Hop subset and\n+0.4% on the full dataset, while on the InfoSeek dataset, it achieves gains of\n+7.8% on the Unseen-Q subset, +8.2% on the Unseen-E subset, and +8.1% on the\nfull dataset. These results highlight significant enhancements in both accuracy\nand robustness over the current state-of-the-art MLLM and RAG frameworks.",
      "tldr_zh": "该论文提出了多模态知识库检索增强生成框架(MMKB-RAG)，旨在解决大型语言模型(LLMs)依赖参数知识导致的知识更新滞后和易出错问题。MMKB-RAG利用模型固有的知识边界动态生成语义标签，用于过滤检索到的文档，从而保留最相关和准确的参考信息。在知识型视觉问答任务上的实验表明，MMKB-RAG在E-VQA和InfoSeek数据集上均显著优于现有最佳的MLLM和RAG框架，尤其是在Unseen子集上提升显著，验证了其在准确性和鲁棒性方面的有效性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10074v2",
      "published_date": "2025-04-14 10:19:47 UTC",
      "updated_date": "2025-04-15 06:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:20:55.152148"
    },
    {
      "arxiv_id": "2504.10071v1",
      "title": "Pay Attention to What and Where? Interpretable Feature Extractor in Vision-based Deep Reinforcement Learning",
      "title_zh": "关注什么和哪里？基于视觉的深度强化学习中的可解释特征提取器\n",
      "authors": [
        "Tien Pham",
        "Angelo Cangelosi"
      ],
      "abstract": "Current approaches in Explainable Deep Reinforcement Learning have\nlimitations in which the attention mask has a displacement with the objects in\nvisual input. This work addresses a spatial problem within traditional\nConvolutional Neural Networks (CNNs). We propose the Interpretable Feature\nExtractor (IFE) architecture, aimed at generating an accurate attention mask to\nillustrate both \"what\" and \"where\" the agent concentrates on in the spatial\ndomain. Our design incorporates a Human-Understandable Encoding module to\ngenerate a fully interpretable attention mask, followed by an Agent-Friendly\nEncoding module to enhance the agent's learning efficiency. These two\ncomponents together form the Interpretable Feature Extractor for vision-based\ndeep reinforcement learning to enable the model's interpretability. The\nresulting attention mask is consistent, highly understandable by humans,\naccurate in spatial dimension, and effectively highlights important objects or\nlocations in visual input. The Interpretable Feature Extractor is integrated\ninto the Fast and Data-efficient Rainbow framework, and evaluated on 57 ATARI\ngames to show the effectiveness of the proposed approach on Spatial\nPreservation, Interpretability, and Data-efficiency. Finally, we showcase the\nversatility of our approach by incorporating the IFE into the Asynchronous\nAdvantage Actor-Critic Model.",
      "tldr_zh": "该论文提出了可解释特征提取器(Interpretable Feature Extractor, IFE)架构，旨在解决基于视觉的深度强化学习中，注意力掩码与视觉输入中的物体存在位移的问题。IFE通过人类可理解的编码模块生成完全可解释的注意力掩码，并利用智能体友好的编码模块提高智能体的学习效率。实验结果表明，IFE能够生成一致、易于理解且在空间维度上准确的注意力掩码，有效突出视觉输入中的重要物体或位置。该方法集成到Fast and Data-efficient Rainbow框架中，并在57个ATARI游戏中进行了评估，验证了其在空间保留、可解释性和数据效率方面的有效性。此外，IFE也被成功整合到Asynchronous Advantage Actor-Critic Model中，展示了其通用性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10071v1",
      "published_date": "2025-04-14 10:18:34 UTC",
      "updated_date": "2025-04-14 10:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:21:07.362202"
    },
    {
      "arxiv_id": "2504.10068v1",
      "title": "Mavors: Multi-granularity Video Representation for Multimodal Large Language Model",
      "title_zh": "Mavors：多模态大语言模型的多粒度视频表征\n",
      "authors": [
        "Yang Shi",
        "Jiaheng Liu",
        "Yushuo Guan",
        "Zhenhua Wu",
        "Yuanxing Zhang",
        "Zihao Wang",
        "Weihong Lin",
        "Jingyun Hua",
        "Zekun Wang",
        "Xinlong Chen",
        "Bohan Zeng",
        "Wentao Zhang",
        "Fuzheng Zhang",
        "Wenjing Yang",
        "Di Zhang"
      ],
      "abstract": "Long-context video understanding in multimodal large language models (MLLMs)\nfaces a critical challenge: balancing computational efficiency with the\nretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,\nsparse sampling, dense sampling with low resolution, and token compression)\nsuffer from significant information loss in temporal dynamics, spatial details,\nor subtle interactions, particularly in videos with complex motion or varying\nresolutions. To address this, we propose $\\mathbf{Mavors}$, a novel framework\nthat introduces $\\mathbf{M}$ulti-gr$\\mathbf{a}$nularity\n$\\mathbf{v}$ide$\\mathbf{o}$ $\\mathbf{r}$epre$\\mathbf{s}$entation for holistic\nlong-video modeling. Specifically, Mavors directly encodes raw video content\ninto latent representations through two core components: 1) an Intra-chunk\nVision Encoder (IVE) that preserves high-resolution spatial features via 3D\nconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator\n(IFA) that establishes temporal coherence across chunks using transformer-based\ndependency modeling with chunk-level rotary position encodings. Moreover, the\nframework unifies image and video understanding by treating images as\nsingle-frame videos via sub-image decomposition. Experiments across diverse\nbenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelity\nand temporal continuity, significantly outperforming existing methods in tasks\nrequiring fine-grained spatio-temporal reasoning.",
      "tldr_zh": "该论文提出了Mavors，一种用于多模态大语言模型(MLLMs)的多粒度视频表示框架，旨在解决长视频理解中计算效率与细粒度时空模式保留的难题。Mavors通过两个核心组件直接编码原始视频内容：1) Intra-chunk Vision Encoder (IVE)，利用3D卷积和Vision Transformers保留高分辨率空间特征；2) Inter-chunk Feature Aggregator (IFA)，使用基于Transformer的依赖建模和chunk-level rotary position encodings建立跨chunk的时间连贯性。该框架还将图像视为单帧视频进行统一处理。实验结果表明，Mavors在保持空间保真度和时间连续性方面优于现有方法，并在需要细粒度时空推理的任务中表现出色。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10068v1",
      "published_date": "2025-04-14 10:14:44 UTC",
      "updated_date": "2025-04-14 10:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:21:19.226566"
    },
    {
      "arxiv_id": "2504.10063v1",
      "title": "Hallucination Detection in LLMs via Topological Divergence on Attention Graphs",
      "title_zh": "基于注意力图的拓扑散度检测大型语言模型中的幻觉\n",
      "authors": [
        "Alexandra Bazarova",
        "Aleksandr Yugay",
        "Andrey Shulga",
        "Alina Ermilova",
        "Andrei Volodichev",
        "Konstantin Polev",
        "Julia Belikova",
        "Rauf Parchiev",
        "Dmitry Simakov",
        "Maxim Savchenko",
        "Andrey Savchenko",
        "Serguei Barannikov",
        "Alexey Zaytsev"
      ],
      "abstract": "Hallucination, i.e., generating factually incorrect content, remains a\ncritical challenge for large language models (LLMs). We introduce TOHA, a\nTOpology-based HAllucination detector in the RAG setting, which leverages a\ntopological divergence metric to quantify the structural properties of graphs\ninduced by attention matrices. Examining the topological divergence between\nprompt and response subgraphs reveals consistent patterns: higher divergence\nvalues in specific attention heads correlate with hallucinated outputs,\nindependent of the dataset. Extensive experiments, including evaluation on\nquestion answering and data-to-text tasks, show that our approach achieves\nstate-of-the-art or competitive results on several benchmarks, two of which\nwere annotated by us and are being publicly released to facilitate further\nresearch. Beyond its strong in-domain performance, TOHA maintains remarkable\ndomain transferability across multiple open-source LLMs. Our findings suggest\nthat analyzing the topological structure of attention matrices can serve as an\nefficient and robust indicator of factual reliability in LLMs.",
      "tldr_zh": "该论文提出了一种基于拓扑的幻觉检测器TOHA，用于检测大型语言模型(LLMs)在检索增强生成(RAG)设置下的幻觉问题。TOHA通过计算由注意力矩阵导出的图的结构属性的拓扑差异来工作。研究发现，prompt和response子图之间的拓扑差异与幻觉输出相关，特定注意力头的较高差异值预示着幻觉的产生。实验表明，TOHA在问答和数据到文本任务上取得了state-of-the-art或具有竞争力的结果，并且在多个开源LLM中保持了显著的领域可迁移性。该研究表明，分析注意力矩阵的拓扑结构可以作为LLM事实可靠性的有效指标。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10063v1",
      "published_date": "2025-04-14 10:06:27 UTC",
      "updated_date": "2025-04-14 10:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:21:31.377489"
    },
    {
      "arxiv_id": "2504.10045v1",
      "title": "CHARM: Calibrating Reward Models With Chatbot Arena Scores",
      "title_zh": "CHARM：使用聊天机器人竞技场分数校准奖励模型\n",
      "authors": [
        "Xiao Zhu",
        "Chenmien Tan",
        "Pinzhen Chen",
        "Rico Sennrich",
        "Yanlin Zhang",
        "Hanxu Hu"
      ],
      "abstract": "Reward models (RMs) play a crucial role in Reinforcement Learning from Human\nFeedback by serving as proxies for human preferences in aligning large language\nmodels. In this paper, we identify a model preference bias in RMs, where they\nsystematically assign disproportionately high scores to responses from certain\npolicy models. This bias distorts ranking evaluations and leads to unfair\njudgments. To address this issue, we propose a calibration method named CHatbot\nArena calibrated Reward Modeling (CHARM) that leverages Elo scores from the\nChatbot Arena leaderboard to mitigate RM overvaluation. We also introduce a\nMismatch Degree metric to measure this preference bias. Our approach is\ncomputationally efficient, requiring only a small preference dataset for\ncontinued training of the RM. We conduct extensive experiments on reward model\nbenchmarks and human preference alignment. Results demonstrate that our\ncalibrated RMs (1) achieve improved evaluation accuracy on RM-Bench and the\nChat-Hard domain of RewardBench, and (2) exhibit a stronger correlation with\nhuman preferences by producing scores more closely aligned with Elo rankings.\nBy mitigating model preference bias, our method provides a generalizable and\nefficient solution for building fairer and more reliable reward models.",
      "tldr_zh": "该论文指出奖励模型(Reward Models, RMs)存在模型偏好偏差，即对某些策略模型的回复给予过高的评分，导致排序评估失真。为了解决这个问题，论文提出了CHARM (CHatbot Arena calibrated Reward Modeling)，一种利用Chatbot Arena排行榜的Elo评分来校准RM过度评估的方法。同时，论文还引入了Mismatch Degree指标来衡量这种偏好偏差。实验结果表明，校准后的RM在RM-Bench和RewardBench的Chat-Hard领域上实现了更高的评估准确率，并且与人类偏好具有更强的相关性，从而构建了更公平、更可靠的奖励模型。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10045v1",
      "published_date": "2025-04-14 09:51:09 UTC",
      "updated_date": "2025-04-14 09:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:21:43.244317"
    },
    {
      "arxiv_id": "2504.10030v1",
      "title": "EmbodiedAgent: A Scalable Hierarchical Approach to Overcome Practical Challenge in Multi-Robot Control",
      "title_zh": "EmbodiedAgent：一种可扩展的分层方法，用于克服多机器人控制中的实际挑战\n",
      "authors": [
        "Hanwen Wan",
        "Yifei Chen",
        "Zeyu Wei",
        "Dongrui Li",
        "Zexin Lin",
        "Donghao Wu",
        "Jiu Cheng",
        "Yuxiang Zhang",
        "Xiaoqiang Ji"
      ],
      "abstract": "This paper introduces EmbodiedAgent, a hierarchical framework for\nheterogeneous multi-robot control. EmbodiedAgent addresses critical limitations\nof hallucination in impractical tasks. Our approach integrates a next-action\nprediction paradigm with a structured memory system to decompose tasks into\nexecutable robot skills while dynamically validating actions against\nenvironmental constraints. We present MultiPlan+, a dataset of more than 18,000\nannotated planning instances spanning 100 scenarios, including a subset of\nimpractical cases to mitigate hallucination. To evaluate performance, we\npropose the Robot Planning Assessment Schema (RPAS), combining automated\nmetrics with LLM-aided expert grading. Experiments demonstrate EmbodiedAgent's\nsuperiority over state-of-the-art models, achieving 71.85% RPAS score.\nReal-world validation in an office service task highlights its ability to\ncoordinate heterogeneous robots for long-horizon objectives.",
      "tldr_zh": "EmbodiedAgent是一个用于异构多机器人控制的分层框架，旨在解决不切实际任务中的幻觉问题。它结合了下一步动作预测范式和结构化记忆系统，将任务分解为可执行的机器人技能，并动态验证动作的环境约束。研究者构建了包含超过18000个标注规划实例的MultiPlan+数据集，并提出了机器人规划评估模式(RPAS)来评估性能。实验结果表明，EmbodiedAgent优于现有模型，RPAS得分达到71.85%，并在现实办公服务任务中验证了其协调异构机器人完成长时程目标的能力。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10030v1",
      "published_date": "2025-04-14 09:33:42 UTC",
      "updated_date": "2025-04-14 09:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:21:55.209376"
    },
    {
      "arxiv_id": "2504.10028v1",
      "title": "Sequence models for by-trial decoding of cognitive strategies from neural data",
      "title_zh": "用于从神经数据中进行认知策略按试验解码的序列模型\n",
      "authors": [
        "Rick den Otter",
        "Gabriel Weindel",
        "Sjoerd Stuit",
        "Leendert van Maanen"
      ],
      "abstract": "Understanding the sequence of cognitive operations that underlie\ndecision-making is a fundamental challenge in cognitive neuroscience.\nTraditional approaches often rely on group-level statistics, which obscure\ntrial-by-trial variations in cognitive strategies. In this study, we introduce\na novel machine learning method that combines Hidden Multivariate Pattern\nanalysis with a Structured State Space Sequence model to decode cognitive\nstrategies from electroencephalography data at the trial level. We apply this\nmethod to a decision-making task, where participants were instructed to\nprioritize either speed or accuracy in their responses. Our results reveal an\nadditional cognitive operation, labeled Confirmation, which seems to occur\npredominantly in the accuracy condition but also frequently in the speed\ncondition. The modeled probability that this operation occurs is associated\nwith higher probability of responding correctly as well as changes of mind, as\nindexed by electromyography data. By successfully modeling cognitive operations\nat the trial level, we provide empirical evidence for dynamic variability in\ndecision strategies, challenging the assumption of homogeneous cognitive\nprocesses within experimental conditions. Our approach shows the potential of\nsequence modeling in cognitive neuroscience to capture trial-level variability\nthat is obscured by aggregate analyses. The introduced method offers a new way\nto detect and understand cognitive strategies in a data-driven manner, with\nimplications for both theoretical research and practical applications in many\nfields.",
      "tldr_zh": "该研究提出了一种新的机器学习方法，结合隐多变量模式分析(Hidden Multivariate Pattern analysis)和结构化状态空间序列模型(Structured State Space Sequence model)，用于从脑电图(EEG)数据中解码认知策略。该方法能够在试验层面上分析认知操作的序列，揭示决策过程中试错变化的认知策略。通过应用于一个速度-准确性权衡的决策任务，研究发现了一个额外的“确认(Confirmation)”认知操作，该操作的发生与更高的正确率和改变主意的可能性相关。该研究结果表明，决策策略存在动态变化，挑战了实验条件下认知过程同质性的假设。该方法为认知神经科学领域提供了一种新的数据驱动方式，用于检测和理解认知策略。\n",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10028v1",
      "published_date": "2025-04-14 09:33:02 UTC",
      "updated_date": "2025-04-14 09:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:22:07.359992"
    },
    {
      "arxiv_id": "2504.10025v1",
      "title": "Progressive Transfer Learning for Multi-Pass Fundus Image Restoration",
      "title_zh": "用于多通道眼底图像恢复的渐进式迁移学习\n",
      "authors": [
        "Uyen Phan",
        "Ozer Can Devecioglu",
        "Serkan Kiranyaz",
        "Moncef Gabbouj"
      ],
      "abstract": "Diabetic retinopathy is a leading cause of vision impairment, making its\nearly diagnosis through fundus imaging critical for effective treatment\nplanning. However, the presence of poor quality fundus images caused by factors\nsuch as inadequate illumination, noise, blurring and other motion artifacts\nyields a significant challenge for accurate DR screening. In this study, we\npropose progressive transfer learning for multi pass restoration to iteratively\nenhance the quality of degraded fundus images, ensuring more reliable DR\nscreening. Unlike previous methods that often focus on a single pass\nrestoration, multi pass restoration via PTL can achieve a superior blind\nrestoration performance that can even improve most of the good quality fundus\nimages in the dataset. Initially, a Cycle GAN model is trained to restore low\nquality images, followed by PTL induced restoration passes over the latest\nrestored outputs to improve overall quality in each pass. The proposed method\ncan learn blind restoration without requiring any paired data while surpassing\nits limitations by leveraging progressive learning and fine tuning strategies\nto minimize distortions and preserve critical retinal features. To evaluate\nPTL's effectiveness on multi pass restoration, we conducted experiments on\nDeepDRiD, a large scale fundus imaging dataset specifically curated for\ndiabetic retinopathy detection. Our result demonstrates state of the art\nperformance, showcasing PTL's potential as a superior approach to iterative\nimage quality restoration.",
      "tldr_zh": "该研究提出了一种用于多通道眼底图像恢复的渐进式迁移学习(PTL)方法，旨在解决低质量眼底图像对糖尿病视网膜病变(DR)早期诊断的挑战。该方法通过多轮迭代，逐步提升图像质量，即使是原本质量较好的图像也能得到改善。首先，训练一个CycleGAN模型来恢复低质量图像，然后通过PTL进行多轮恢复，利用渐进式学习和微调策略，在最小化失真的同时保留关键的视网膜特征。在DeepDRiD数据集上的实验结果表明，PTL在眼底图像恢复方面达到了state-of-the-art的性能，为迭代图像质量恢复提供了一种有效途径。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "13 pages, 12 figures including appendix",
      "pdf_url": "http://arxiv.org/pdf/2504.10025v1",
      "published_date": "2025-04-14 09:28:10 UTC",
      "updated_date": "2025-04-14 09:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:22:19.366963"
    },
    {
      "arxiv_id": "2504.10020v1",
      "title": "The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination",
      "title_zh": "性能提升的海市蜃楼：为什么对比解码无法解决多模态幻觉问题\n",
      "authors": [
        "Hao Yin",
        "Gunagzong Si",
        "Zilei Wang"
      ],
      "abstract": "Contrastive decoding strategies are widely used to reduce hallucinations in\nmultimodal large language models (MLLMs). These methods work by constructing\ncontrastive samples to induce hallucinations and then suppressing them in the\noutput distribution. However, this paper demonstrates that such approaches fail\nto effectively mitigate the hallucination problem. The performance improvements\nobserved on POPE Benchmark are largely driven by two misleading factors: (1)\ncrude, unidirectional adjustments to the model's output distribution and (2)\nthe adaptive plausibility constraint, which reduces the sampling strategy to\ngreedy search. To further illustrate these issues, we introduce a series of\nspurious improvement methods and evaluate their performance against contrastive\ndecoding techniques. Experimental results reveal that the observed performance\ngains in contrastive decoding are entirely unrelated to its intended goal of\nmitigating hallucinations. Our findings challenge common assumptions about the\neffectiveness of contrastive decoding strategies and pave the way for\ndeveloping genuinely effective solutions to hallucinations in MLLMs.",
      "tldr_zh": "该论文指出，目前广泛使用的对比解码策略在减少多模态大语言模型(MLLMs)的幻觉问题上是无效的。在POPE Benchmark上观察到的性能提升，实际上是由对模型输出分布的粗略调整和自适应合理性约束（将采样策略简化为贪婪搜索）这两个误导性因素驱动的。研究通过引入一系列虚假的改进方法，并与对比解码技术进行比较，实验结果表明对比解码的性能提升与缓解幻觉的初衷无关。该研究挑战了对比解码策略有效性的普遍假设，并为开发真正有效的MLLM幻觉解决方案铺平了道路。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10020v1",
      "published_date": "2025-04-14 09:25:37 UTC",
      "updated_date": "2025-04-14 09:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:22:31.279511"
    },
    {
      "arxiv_id": "2504.10018v1",
      "title": "RGB-Event based Pedestrian Attribute Recognition: A Benchmark Dataset and An Asymmetric RWKV Fusion Framework",
      "title_zh": "基于 RGB-Event 的行人属性识别：一个基准数据集和一个非对称 RWKV 融合框架\n",
      "authors": [
        "Xiao Wang",
        "Haiyang Wang",
        "Shiao Wang",
        "Qiang Chen",
        "Jiandong Jin",
        "Haoyu Song",
        "Bo Jiang",
        "Chenglong Li"
      ],
      "abstract": "Existing pedestrian attribute recognition methods are generally developed\nbased on RGB frame cameras. However, these approaches are constrained by the\nlimitations of RGB cameras, such as sensitivity to lighting conditions and\nmotion blur, which hinder their performance. Furthermore, current attribute\nrecognition primarily focuses on analyzing pedestrians' external appearance and\nclothing, lacking an exploration of emotional dimensions. In this paper, we\nrevisit these issues and propose a novel multi-modal RGB-Event attribute\nrecognition task by drawing inspiration from the advantages of event cameras in\nlow-light, high-speed, and low-power consumption. Specifically, we introduce\nthe first large-scale multi-modal pedestrian attribute recognition dataset,\ntermed EventPAR, comprising 100K paired RGB-Event samples that cover 50\nattributes related to both appearance and six human emotions, diverse scenes,\nand various seasons. By retraining and evaluating mainstream PAR models on this\ndataset, we establish a comprehensive benchmark and provide a solid foundation\nfor future research in terms of data and algorithmic baselines. In addition, we\npropose a novel RWKV-based multi-modal pedestrian attribute recognition\nframework, featuring an RWKV visual encoder and an asymmetric RWKV fusion\nmodule. Extensive experiments are conducted on our proposed dataset as well as\ntwo simulated datasets (MARS-Attribute and DukeMTMC-VID-Attribute), achieving\nstate-of-the-art results. The source code and dataset will be released on\nhttps://github.com/Event-AHU/OpenPAR",
      "tldr_zh": "本文提出了基于RGB-Event的多模态行人属性识别任务，旨在克服传统RGB相机在光照和运动模糊等方面的局限性，并探索行人情感维度的识别。为此，作者构建了首个大规模多模态行人属性识别数据集EventPAR，包含10万个RGB-Event样本，涵盖50种外观和6种情感相关的属性。此外，作者还提出了一个基于RWKV的多模态行人属性识别框架，该框架包含一个RWKV视觉编码器和一个非对称RWKV融合模块。实验结果表明，该框架在EventPAR以及两个模拟数据集上均取得了state-of-the-art的效果。数据集和代码已开源。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The First Benchmark Dataset for RGB-Event Multimodal Pedestrian\n  Attribute Recognition Task",
      "pdf_url": "http://arxiv.org/pdf/2504.10018v1",
      "published_date": "2025-04-14 09:22:16 UTC",
      "updated_date": "2025-04-14 09:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:22:43.231455"
    },
    {
      "arxiv_id": "2504.10014v1",
      "title": "Air Quality Prediction with A Meteorology-Guided Modality-Decoupled Spatio-Temporal Network",
      "title_zh": "基于气象引导的模态解耦时空网络进行空气质量预测\n",
      "authors": [
        "Hang Yin",
        "Yan-Ming Zhang",
        "Jian Xu",
        "Jian-Long Chang",
        "Yin Li",
        "Cheng-Lin Liu"
      ],
      "abstract": "Air quality prediction plays a crucial role in public health and\nenvironmental protection. Accurate air quality prediction is a complex\nmultivariate spatiotemporal problem, that involves interactions across temporal\npatterns, pollutant correlations, spatial station dependencies, and\nparticularly meteorological influences that govern pollutant dispersion and\nchemical transformations. Existing works underestimate the critical role of\natmospheric conditions in air quality prediction and neglect comprehensive\nmeteorological data utilization, thereby impairing the modeling of dynamic\ninterdependencies between air quality and meteorological data. To overcome\nthis, we propose MDSTNet, an encoder-decoder framework that explicitly models\nair quality observations and atmospheric conditions as distinct modalities,\nintegrating multi-pressure-level meteorological data and weather forecasts to\ncapture atmosphere-pollution dependencies for prediction. Meantime, we\nconstruct ChinaAirNet, the first nationwide dataset combining air quality\nrecords with multi-pressure-level meteorological observations. Experimental\nresults on ChinaAirNet demonstrate MDSTNet's superiority, substantially\nreducing 48-hour prediction errors by 17.54\\% compared to the state-of-the-art\nmodel. The source code and dataset will be available on github.",
      "tldr_zh": "该论文提出了一种气象引导的解耦时空网络(MDSTNet)用于空气质量预测。MDSTNet将空气质量观测和气象条件显式地建模为不同的模态，并整合多压力层级气象数据和天气预报，以捕捉大气-污染之间的动态依赖关系。作者还构建了首个结合空气质量记录和多压力层级气象观测的全国性数据集ChinaAirNet。在ChinaAirNet上的实验结果表明，MDSTNet优于现有技术模型，显著降低了48小时预测误差达17.54%。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10014v1",
      "published_date": "2025-04-14 09:18:11 UTC",
      "updated_date": "2025-04-14 09:18:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:22:55.156999"
    },
    {
      "arxiv_id": "2504.10005v1",
      "title": "Session-based Recommender Systems: User Interest as a Stochastic Process in the Latent Space",
      "title_zh": "基于会话的推荐系统：潜在空间中作为随机过程的用户兴趣",
      "authors": [
        "Klaudia Balcer",
        "Piotr Lipinski"
      ],
      "abstract": "This paper jointly addresses the problem of data uncertainty, popularity\nbias, and exposure bias in session-based recommender systems. We study the\nsymptoms of this bias both in item embeddings and in recommendations. We\npropose treating user interest as a stochastic process in the latent space and\nproviding a model-agnostic implementation of this mathematical concept. The\nproposed stochastic component consists of elements: debiasing item embeddings\nwith regularization for embedding uniformity, modeling dense user interest from\nsession prefixes, and introducing fake targets in the data to simulate extended\nexposure. We conducted computational experiments on two popular benchmark\ndatasets, Diginetica and YooChoose 1/64, as well as several modifications of\nthe YooChoose dataset with different ratios of popular items. The results show\nthat the proposed approach allows us to mitigate the challenges mentioned.",
      "tldr_zh": "本文针对Session-based推荐系统中存在的数据不确定性、流行度偏差和曝光偏差问题进行了研究。论文提出将用户兴趣视为潜在空间中的随机过程，并提供了一个与模型无关的实现方案。该方案包含三个关键要素：通过正则化嵌入均匀性来消除item embedding的偏差；从session前缀中建模密集的user interest；以及在数据中引入虚假目标来模拟扩展的曝光。在Diginetica和YooChoose等benchmark数据集上的实验结果表明，该方法能够有效缓解上述挑战。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10005v1",
      "published_date": "2025-04-14 09:08:40 UTC",
      "updated_date": "2025-04-14 09:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:23:07.187621"
    },
    {
      "arxiv_id": "2504.10000v1",
      "title": "Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?",
      "title_zh": "我们真的需要在多模态大型语言模型中，使用精心策划的恶意数据来进行安全对齐吗？\n",
      "authors": [
        "Yanbo Wang",
        "Jiyang Guan",
        "Jian Liang",
        "Ran He"
      ],
      "abstract": "Multi-modal large language models (MLLMs) have made significant progress, yet\ntheir safety alignment remains limited. Typically, current open-source MLLMs\nrely on the alignment inherited from their language module to avoid harmful\ngenerations. However, the lack of safety measures specifically designed for\nmulti-modal inputs creates an alignment gap, leaving MLLMs vulnerable to\nvision-domain attacks such as typographic manipulation. Current methods utilize\na carefully designed safety dataset to enhance model defense capability, while\nthe specific knowledge or patterns acquired from the high-quality dataset\nremain unclear. Through comparison experiments, we find that the alignment gap\nprimarily arises from data distribution biases, while image content, response\nquality, or the contrastive behavior of the dataset makes little contribution\nto boosting multi-modal safety. To further investigate this and identify the\nkey factors in improving MLLM safety, we propose finetuning MLLMs on a small\nset of benign instruct-following data with responses replaced by simple, clear\nrejection sentences. Experiments show that, without the need for\nlabor-intensive collection of high-quality malicious data, model safety can\nstill be significantly improved, as long as a specific fraction of rejection\ndata exists in the finetuning set, indicating the security alignment is not\nlost but rather obscured during multi-modal pretraining or instruction\nfinetuning. Simply correcting the underlying data bias could narrow the safety\ngap in the vision domain.",
      "tldr_zh": "多模态大型语言模型(MLLMs)在安全性对齐方面仍存在不足，尤其是在视觉领域容易受到攻击。该研究表明，MLLM安全对齐差距主要源于数据分布偏差，而非恶意数据本身的内容或质量。研究发现，通过在少量良性指令跟随数据上，用简单的拒绝语句替换回复进行微调，无需精心设计的恶意数据集，也能显著提升模型安全性。这表明多模态预训练或指令微调过程中，安全对齐并未丢失，而是被数据偏差所掩盖。因此，纠正底层数据偏差可以有效缩小视觉领域的安全差距。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to CVPR 2025, codes in process",
      "pdf_url": "http://arxiv.org/pdf/2504.10000v1",
      "published_date": "2025-04-14 09:03:51 UTC",
      "updated_date": "2025-04-14 09:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:23:19.263228"
    },
    {
      "arxiv_id": "2504.09998v1",
      "title": "Metric-Guided Synthesis of Class Activation Mapping",
      "title_zh": "度量引导的类激活映射合成\n",
      "authors": [
        "Alejandro Luque-Cerpa",
        "Elizabeth Polgreen",
        "Ajitha Rajan",
        "Hazem Torfah"
      ],
      "abstract": "Class activation mapping (CAM) is a widely adopted class of saliency methods\nused to explain the behavior of convolutional neural networks (CNNs). These\nmethods generate heatmaps that highlight the parts of the input most relevant\nto the CNN output. Various CAM methods have been proposed, each distinguished\nby the expressions used to derive heatmaps. In general, users look for heatmaps\nwith specific properties that reflect different aspects of CNN functionality.\nThese may include similarity to ground truth, robustness, equivariance, and\nmore. Although existing CAM methods implicitly encode some of these properties\nin their expressions, they do not allow for variability in heatmap generation\nfollowing the user's intent or domain knowledge. In this paper, we address this\nlimitation by introducing SyCAM, a metric-based approach for synthesizing CAM\nexpressions. Given a predefined evaluation metric for saliency maps, SyCAM\nautomatically generates CAM expressions optimized for that metric. We\nspecifically explore a syntax-guided synthesis instantiation of SyCAM, where\nCAM expressions are derived based on predefined syntactic constraints and the\ngiven metric. Using several established evaluation metrics, we demonstrate the\nefficacy and flexibility of our approach in generating targeted heatmaps. We\ncompare SyCAM with other well-known CAM methods on three prominent models:\nResNet50, VGG16, and VGG19.",
      "tldr_zh": "本文提出了一种基于度量引导的类激活映射合成方法SyCAM，旨在解决现有CAM方法无法根据用户意图或领域知识灵活生成热图的局限性。SyCAM通过预定义的显著性图评估指标，自动生成针对该指标优化的CAM表达式。具体而言，采用了语法引导的合成方法，基于预定义的语法约束和给定的度量来推导CAM表达式。实验结果表明，SyCAM能够有效地生成目标热图，并在ResNet50、VGG16和VGG19等模型上优于其他CAM方法。该方法为生成具有特定属性的热图提供了灵活性和有效性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09998v1",
      "published_date": "2025-04-14 09:01:49 UTC",
      "updated_date": "2025-04-14 09:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:23:31.309070"
    },
    {
      "arxiv_id": "2504.09997v1",
      "title": "GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control",
      "title_zh": "GenTe：用于通用足式机器人运动控制的生成式真实地形\n",
      "authors": [
        "Hanwen Wan",
        "Mengkang Li",
        "Donghao Wu",
        "Yebin Zhong",
        "Yixuan Deng",
        "Zhenglong Sun",
        "Xiaoqiang Ji"
      ],
      "abstract": "Developing bipedal robots capable of traversing diverse real-world terrains\npresents a fundamental robotics challenge, as existing methods using predefined\nheight maps and static environments fail to address the complexity of\nunstructured landscapes. To bridge this gap, we propose GenTe, a framework for\ngenerating physically realistic and adaptable terrains to train generalizable\nlocomotion policies. GenTe constructs an atomic terrain library that includes\nboth geometric and physical terrains, enabling curriculum training for\nreinforcement learning-based locomotion policies. By leveraging\nfunction-calling techniques and reasoning capabilities of Vision-Language\nModels (VLMs), GenTe generates complex, contextually relevant terrains from\ntextual and graphical inputs. The framework introduces realistic force modeling\nfor terrain interactions, capturing effects such as soil sinkage and\nhydrodynamic resistance. To the best of our knowledge, GenTe is the first\nframework that systemically generates simulation environments for legged robot\nlocomotion control. Additionally, we introduce a benchmark of 100 generated\nterrains. Experiments demonstrate improved generalization and robustness in\nbipedal robot locomotion.",
      "tldr_zh": "该论文提出了GenTe，一个用于生成物理上逼真且可适应的地形的框架，旨在训练通用足式机器人运动控制策略。GenTe构建了一个包含几何和物理地形的原子地形库，并利用视觉语言模型(VLMs)的函数调用技术和推理能力，从文本和图形输入生成复杂的、上下文相关的地形，从而实现基于强化学习的运动策略的课程训练。该框架引入了逼真的地形交互力建模，捕捉土壤沉降和流体阻力等效应。实验表明，GenTe能够有效提升双足机器人在复杂地形上的运动泛化性和鲁棒性。同时，论文还引入了一个包含100个生成地形的基准测试集。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09997v1",
      "published_date": "2025-04-14 09:01:44 UTC",
      "updated_date": "2025-04-14 09:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:23:43.549154"
    },
    {
      "arxiv_id": "2504.09967v1",
      "title": "Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data",
      "title_zh": "通过以图像为中心的多标注数据增强医学通用基础模型的多任务学习能力\n",
      "authors": [
        "Xun Zhu",
        "Fanbin Mo",
        "Zheng Zhang",
        "Jiaxi Wang",
        "Yiming Shi",
        "Ming Wu",
        "Chuang Zhang",
        "Miao Li",
        "Ji Wu"
      ],
      "abstract": "The emergence of medical generalist foundation models has revolutionized\nconventional task-specific model development paradigms, aiming to better handle\nmultiple tasks through joint training on large-scale medical datasets. However,\nrecent advances prioritize simple data scaling or architectural component\nenhancement, while neglecting to re-examine multi-task learning from a\ndata-centric perspective. Critically, simply aggregating existing data\nresources leads to decentralized image-task alignment, which fails to cultivate\ncomprehensive image understanding or align with clinical needs for\nmulti-dimensional image interpretation. In this paper, we introduce the\nimage-centric multi-annotation X-ray dataset (IMAX), the first attempt to\nenhance the multi-task learning capabilities of medical multi-modal large\nlanguage models (MLLMs) from the data construction level. To be specific, IMAX\nis featured from the following attributes: 1) High-quality data curation. A\ncomprehensive collection of more than 354K entries applicable to seven\ndifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image is\nassociated with an average of 4.10 tasks and 7.46 training entries, ensuring\nmulti-task representation richness per image. Compared to the general\ndecentralized multi-annotation X-ray dataset (DMAX), IMAX consistently\ndemonstrates significant multi-task average performance gains ranging from\n3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.\nMoreover, we investigate differences in statistical patterns exhibited by IMAX\nand DMAX training processes, exploring potential correlations between\noptimization dynamics and multi-task performance. Finally, leveraging the core\nconcept of IMAX data construction, we propose an optimized DMAX-based training\nstrategy to alleviate the dilemma of obtaining high-quality IMAX data in\npractical scenarios.",
      "tldr_zh": "该论文提出了一个图像中心的多标注X射线数据集(IMAX)，旨在从数据构建层面提升医学多模态大语言模型(MLLMs)的多任务学习能力。IMAX包含超过354K条高质量数据，适用于七种不同的医学任务，并且每张X射线图像平均关联4.10个任务和7.46个训练条目，确保了图像的多任务表示丰富性。实验结果表明，与一般的去中心化多标注X射线数据集(DMAX)相比，IMAX在七个开源的state-of-the-art医学MLLMs上实现了显著的多任务平均性能提升，范围从3.20%到21.05%。此外，论文还研究了IMAX和DMAX训练过程中的统计模式差异，并提出了一种优化的基于DMAX的训练策略，以缓解实际场景中获取高质量IMAX数据的困境。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09967v1",
      "published_date": "2025-04-14 08:09:37 UTC",
      "updated_date": "2025-04-14 08:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:23:55.562284"
    },
    {
      "arxiv_id": "2504.09963v1",
      "title": "Towards Unbiased Federated Graph Learning: Label and Topology Perspectives",
      "title_zh": "迈向无偏联邦图学习：标签和拓扑视角\n",
      "authors": [
        "Zhengyu Wu",
        "Boyang Pang",
        "Xunkai Li",
        "Yinlin Zhu",
        "Daohan Su",
        "Bowen Fan",
        "Rong-Hua Li",
        "Guoren Wang",
        "Chenghu Zhou"
      ],
      "abstract": "Federated Graph Learning (FGL) enables privacy-preserving, distributed\ntraining of graph neural networks without sharing raw data. Among its\napproaches, subgraph-FL has become the dominant paradigm, with most work\nfocused on improving overall node classification accuracy. However, these\nmethods often overlook fairness due to the complexity of node features, labels,\nand graph structures. In particular, they perform poorly on nodes with\ndisadvantaged properties, such as being in the minority class within subgraphs\nor having heterophilous connections (neighbors with dissimilar labels or\nmisleading features). This reveals a critical issue: high accuracy can mask\ndegraded performance on structurally or semantically marginalized nodes. To\naddress this, we advocate for two fairness goals: (1) improving representation\nof minority class nodes for class-wise fairness and (2) mitigating topological\nbias from heterophilous connections for topology-aware fairness. We propose\nFairFGL, a novel framework that enhances fairness through fine-grained graph\nmining and collaborative learning. On the client side, the History-Preserving\nModule prevents overfitting to dominant local classes, while the Majority\nAlignment Module refines representations of heterophilous majority-class nodes.\nThe Gradient Modification Module transfers minority-class knowledge from\nstructurally favorable clients to improve fairness. On the server side, FairFGL\nuploads only the most influenced subset of parameters to reduce communication\ncosts and better reflect local distributions. A cluster-based aggregation\nstrategy reconciles conflicting updates and curbs global majority dominance .\nExtensive evaluations on eight benchmarks show FairFGL significantly improves\nminority-group performance , achieving up to a 22.62 percent Macro-F1 gain\nwhile enhancing convergence over state-of-the-art baselines.",
      "tldr_zh": "联邦图学习(FGL)在保护隐私的前提下进行分布式图神经网络训练。现有子图联邦学习方法忽略了节点特征、标签和图结构带来的公平性问题，导致在少数类或异质连接节点上表现不佳。为了解决这个问题，论文提出了FairFGL框架，从标签和拓扑结构两个角度提升公平性。FairFGL在客户端侧使用历史保留模块和多数对齐模块，防止过拟合和优化异质连接节点的表示；梯度修正模块则用于迁移优势客户端的少数类知识。在服务器侧，FairFGL仅上传最具影响力的参数子集以降低通信成本，并采用基于聚类的聚合策略来协调冲突更新。实验结果表明，FairFGL在多个基准数据集上显著提高了少数群体的性能，Macro-F1指标最高提升22.62%。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.09963v1",
      "published_date": "2025-04-14 08:00:20 UTC",
      "updated_date": "2025-04-14 08:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:24:07.936394"
    },
    {
      "arxiv_id": "2504.09961v1",
      "title": "Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science",
      "title_zh": "隐私与可解释性相遇：在 LLM 赋能的科学中管理机密数据和透明度策略\n",
      "authors": [
        "Yashothara Shanmugarasa",
        "Shidong Pan",
        "Ming Ding",
        "Dehai Zhao",
        "Thierry Rakotoarivelo"
      ],
      "abstract": "As Large Language Models (LLMs) become integral to scientific workflows,\nconcerns over the confidentiality and ethical handling of confidential data\nhave emerged. This paper explores data exposure risks through LLM-powered\nscientific tools, which can inadvertently leak confidential information,\nincluding intellectual property and proprietary data, from scientists'\nperspectives. We propose \"DataShield\", a framework designed to detect\nconfidential data leaks, summarize privacy policies, and visualize data flow,\nensuring alignment with organizational policies and procedures. Our approach\naims to inform scientists about data handling practices, enabling them to make\ninformed decisions and protect sensitive information. Ongoing user studies with\nscientists are underway to evaluate the framework's usability, trustworthiness,\nand effectiveness in tackling real-world privacy challenges.",
      "tldr_zh": "随着大型语言模型(LLMs)在科学工作流程中日益普及，数据保密和伦理处理问题日益突出。该论文探讨了LLM驱动的科学工具可能导致的数据泄露风险，包括知识产权和专有数据。研究者提出了“DataShield”框架，旨在检测机密数据泄露，总结隐私策略，并可视化数据流，以确保符合组织策略和程序。DataShield旨在告知科学家数据处理实践，帮助他们做出明智的决策并保护敏感信息。目前正在进行用户研究，以评估该框架在解决实际隐私挑战中的可用性、可信度和有效性。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.09961v1",
      "published_date": "2025-04-14 07:58:26 UTC",
      "updated_date": "2025-04-14 07:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:24:19.260073"
    },
    {
      "arxiv_id": "2504.09948v1",
      "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes",
      "title_zh": "Omni-Dish：用于任意中国菜肴的逼真且忠实的图像生成和编辑\n",
      "authors": [
        "Huijie Liu",
        "Bingcan Wang",
        "Jie Hu",
        "Xiaoming Wei",
        "Guoliang Kang"
      ],
      "abstract": "Dish images play a crucial role in the digital era, with the demand for\nculturally distinctive dish images continuously increasing due to the\ndigitization of the food industry and e-commerce. In general cases, existing\ntext-to-image generation models excel in producing high-quality images;\nhowever, they struggle to capture diverse characteristics and faithful details\nof specific domains, particularly Chinese dishes. To address this limitation,\nwe propose Omni-Dish, the first text-to-image generation model specifically\ntailored for Chinese dishes. We develop a comprehensive dish curation pipeline,\nbuilding the largest dish dataset to date. Additionally, we introduce a\nrecaption strategy and employ a coarse-to-fine training scheme to help the\nmodel better learn fine-grained culinary nuances. During inference, we enhance\nthe user's textual input using a pre-constructed high-quality caption library\nand a large language model, enabling more photorealistic and faithful image\ngeneration. Furthermore, to extend our model's capability for dish editing\ntasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish\nediting dataset and train a specialized editing model. Extensive experiments\ndemonstrate the superiority of our methods.",
      "tldr_zh": "该论文提出了Omni-Dish，一个专门为中国菜量身定制的文本到图像生成模型，旨在解决现有模型难以捕捉中国菜多样性和细节的问题。研究者构建了迄今为止最大的中国菜数据集，并引入了重新标注策略和粗到精的训练方案，以帮助模型学习细粒度的烹饪细节。在推理阶段，通过高质量的标题库和大型语言模型增强用户文本输入，生成更逼真和真实的图像。此外，论文还提出了Concept-Enhanced P2P方法，用于菜肴编辑任务，并构建了相应的编辑数据集。实验结果表明，Omni-Dish在图像生成和编辑方面均优于现有方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 10 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09948v1",
      "published_date": "2025-04-14 07:18:32 UTC",
      "updated_date": "2025-04-14 07:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:24:31.366302"
    },
    {
      "arxiv_id": "2504.09941v1",
      "title": "FedRecon: Missing Modality Reconstruction in Distributed Heterogeneous Environments",
      "title_zh": "FedRecon：分布式异构环境中缺失模态的重建\n",
      "authors": [
        "Junming Liu",
        "Guosun Zeng",
        "Ding Wang",
        "Yanting Gao",
        "Yufei Jin"
      ],
      "abstract": "Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.",
      "tldr_zh": "FedRecon 是一种针对多模态联邦学习中缺失模态重建和非独立同分布(Non-IID)数据适应的新方法。它利用轻量级的多模态变分自编码器(MVAE)重建缺失模态，并通过分布映射机制实现样本级别的对齐，保证数据一致性和完整性。此外，FedRecon 采用全局生成器冻结策略，防止灾难性遗忘，从而缓解 Non-IID 波动。实验表明，FedRecon 在 Non-IID 条件下的模态重建性能优于现有技术。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 32 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09941v1",
      "published_date": "2025-04-14 07:04:10 UTC",
      "updated_date": "2025-04-14 07:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:24:43.206309"
    },
    {
      "arxiv_id": "2504.09936v1",
      "title": "KeepKV: Eliminating Output Perturbation in KV Cache Compression for Efficient LLMs Inference",
      "title_zh": "KeepKV：消除 KV 缓存压缩中的输出扰动，实现高效 LLM 推理\n",
      "authors": [
        "Yuxuan Tian",
        "Zihan Wang",
        "Yebo Peng",
        "Aomufei Yuan",
        "Zhiming Wang",
        "Bairen Yi",
        "Xin Liu",
        "Yong Cui",
        "Tong Yang"
      ],
      "abstract": "Efficient inference of large language models (LLMs) is hindered by an\never-growing key-value (KV) cache, making KV cache compression a critical\nresearch direction. Traditional methods selectively evict less important KV\ncache entries based on attention scores or position heuristics, which leads to\ninformation loss and hallucinations. Recently, merging-based strategies have\nbeen explored to retain more information by merging KV pairs that would be\ndiscarded; however, these existing approaches inevitably introduce\ninconsistencies in attention distributions before and after merging, causing\noutput perturbation and degraded generation quality. To overcome this\nchallenge, we propose KeepKV, a novel adaptive KV cache merging method designed\nto eliminate output perturbation while preserving performance under strict\nmemory constraints. KeepKV introduces the Electoral Votes mechanism that\nrecords merging history and adaptively adjusts attention scores. Moreover, it\nfurther leverages a novel Zero Inference-Perturbation Merging methods, keeping\nattention consistency and compensating for attention loss resulting from cache\nmerging. KeepKV successfully retains essential context information within a\nsignificantly compressed cache. Extensive experiments on various benchmarks and\nLLM architectures demonstrate that KeepKV substantially reduces memory usage,\nenhances inference throughput by more than 2x and keeps superior generation\nquality even with 10% KV cache budgets.",
      "tldr_zh": "为了解决大语言模型(LLMs)推理过程中KV缓存过大导致效率降低的问题，该论文提出了KeepKV，一种新型自适应KV缓存合并方法，旨在消除KV缓存压缩带来的输出扰动。KeepKV引入了“Electoral Votes”机制来记录合并历史并自适应地调整注意力分数。此外，还利用了“Zero Inference-Perturbation Merging”方法，保持注意力一致性并补偿缓存合并导致的注意力损失。实验结果表明，即使在仅有10% KV缓存预算的情况下，KeepKV也能显著减少内存使用，将推理吞吐量提高2倍以上，并保持卓越的生成质量。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09936v1",
      "published_date": "2025-04-14 06:58:00 UTC",
      "updated_date": "2025-04-14 06:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:24:55.362021"
    },
    {
      "arxiv_id": "2504.09909v1",
      "title": "Quantum Natural Language Processing: A Comprehensive Review of Models, Methods, and Applications",
      "title_zh": "量子自然语言处理：模型、方法和应用的综合综述\n",
      "authors": [
        "Farha Nausheen",
        "Khandakar Ahmed",
        "M Imad Khan"
      ],
      "abstract": "In recent developments, deep learning methodologies applied to Natural\nLanguage Processing (NLP) have revealed a paradox: They improve performance but\ndemand considerable data and resources for their training. Alternatively,\nquantum computing exploits the principles of quantum mechanics to overcome the\ncomputational limitations of current methodologies, thereby establishing an\nemerging field known as quantum natural language processing (QNLP). This domain\nholds the potential to attain a quantum advantage in the processing of\nlinguistic structures, surpassing classical models in both efficiency and\naccuracy. In this paper, it is proposed to categorise QNLP models based on\nquantum computing principles, architecture, and computational approaches. This\npaper attempts to provide a survey on how quantum meets language by mapping\nstate-of-the-art in this area, embracing quantum encoding techniques for\nclassical data, QNLP models for prevalent NLP tasks, and quantum optimisation\ntechniques for hyper parameter tuning. The landscape of quantum computing\napproaches applied to various NLP tasks is summarised by showcasing the\nspecific QNLP methods used, and the popularity of these methods is indicated by\ntheir count. From the findings, it is observed that QNLP approaches are still\nlimited to small data sets, with only a few models explored extensively, and\nthere is increasing interest in the application of quantum computing to natural\nlanguage processing tasks.",
      "tldr_zh": "本文对量子自然语言处理(QNLP)的模型、方法和应用进行了全面的综述。QNLP利用量子力学原理克服传统NLP在计算上的限制，有望在处理语言结构方面超越经典模型，实现效率和准确性的量子优势。文章根据量子计算原理、架构和计算方法对QNLP模型进行分类，并探讨了量子编码技术、用于常见NLP任务的QNLP模型以及用于超参数调整的量子优化技术。研究发现，QNLP方法目前仍受限于小数据集，且仅有少数模型被深入探索，但量子计算在自然语言处理任务中的应用正引起越来越多的关注。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09909v1",
      "published_date": "2025-04-14 06:09:26 UTC",
      "updated_date": "2025-04-14 06:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:25:07.347888"
    },
    {
      "arxiv_id": "2504.09906v1",
      "title": "Plasticity-Aware Mixture of Experts for Learning Under QoE Shifts in Adaptive Video Streaming",
      "title_zh": "面向自适应视频流 QoE 变化下学习的，具有可塑性感知的混合专家模型\n",
      "authors": [
        "Zhiqiang He",
        "Zhi Liu"
      ],
      "abstract": "Adaptive video streaming systems are designed to optimize Quality of\nExperience (QoE) and, in turn, enhance user satisfaction. However, differences\nin user profiles and video content lead to different weights for QoE factors,\nresulting in user-specific QoE functions and, thus, varying optimization\nobjectives. This variability poses significant challenges for neural networks,\nas they often struggle to generalize under evolving targets - a phenomenon\nknown as plasticity loss that prevents conventional models from adapting\neffectively to changing optimization objectives. To address this limitation, we\npropose the Plasticity-Aware Mixture of Experts (PA-MoE), a novel learning\nframework that dynamically modulates network plasticity by balancing memory\nretention with selective forgetting. In particular, PA-MoE leverages noise\ninjection to promote the selective forgetting of outdated knowledge, thereby\nendowing neural networks with enhanced adaptive capabilities. In addition, we\npresent a rigorous theoretical analysis of PA-MoE by deriving a regret bound\nthat quantifies its learning performance. Experimental evaluations demonstrate\nthat PA-MoE achieves a 45.5% improvement in QoE over competitive baselines in\ndynamic streaming environments. Further analysis reveals that the model\neffectively mitigates plasticity loss by optimizing neuron utilization.\nFinally, a parameter sensitivity study is performed by injecting varying levels\nof noise, and the results align closely with our theoretical predictions.",
      "tldr_zh": "该论文提出了Plasticity-Aware Mixture of Experts (PA-MoE)框架，旨在解决自适应视频流媒体中由于用户和视频内容差异导致QoE优化目标变化，神经网络难以泛化的问题（即plasticity loss）。PA-MoE通过动态调节网络plasticity，平衡记忆保留和选择性遗忘来增强适应能力，具体通过噪声注入促进过时知识的选择性遗忘。论文还提供了PA-MoE的理论分析，推导了量化其学习性能的regret bound。实验结果表明，PA-MoE在动态流媒体环境中比基线模型在QoE方面提高了45.5%，并通过优化神经元利用率有效缓解了plasticity loss。\n",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09906v1",
      "published_date": "2025-04-14 06:02:41 UTC",
      "updated_date": "2025-04-14 06:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:25:19.552390"
    },
    {
      "arxiv_id": "2504.09895v1",
      "title": "Learning from Reference Answers: Versatile Language Model Alignment without Binary Human Preference Data",
      "title_zh": "从参考答案中学习：无需二元人类偏好数据的通用语言模型对齐\n",
      "authors": [
        "Shuai Zhao",
        "Linchao Zhu",
        "Yi Yang"
      ],
      "abstract": "Large language models~(LLMs) are expected to be helpful, harmless, and\nhonest. In various alignment scenarios, such as general human preference,\nsafety, and confidence alignment, binary preference data collection and reward\nmodeling are resource-intensive but necessary for human preference\ntransferring. In this work, we explore using the similarity between sampled\ngenerations and high-quality reference answers as an alternative reward\nfunction for LLM alignment. Using similarity as a reward circumvents training\nreward models, and collecting a single reference answer potentially costs less\ntime than constructing binary preference pairs when multiple candidates are\navailable. Specifically, we develop \\textit{RefAlign}, a versatile\nREINFORCE-style alignment algorithm, which is free of reference and reward\nmodels. Instead, RefAlign utilizes BERTScore between sampled generations and\nhigh-quality reference answers as the surrogate reward. Beyond general human\npreference optimization, RefAlign can be readily extended to diverse scenarios,\nsuch as safety and confidence alignment, by incorporating the similarity reward\nwith task-related objectives. In various scenarios, {RefAlign} demonstrates\ncomparable performance to previous alignment methods while offering high\nefficiency.",
      "tldr_zh": "该论文提出了一种名为RefAlign的通用语言模型对齐算法，旨在避免传统对齐方法中耗费资源的二元人类偏好数据收集和奖励模型训练。RefAlign创新性地利用生成结果与高质量参考答案之间的相似度作为替代奖励函数，使用BERTScore计算相似度，无需训练奖励模型。该方法不仅适用于通用人类偏好优化，还能扩展到安全性和置信度对齐等多种场景，通过结合相似度奖励与任务相关目标实现对齐。实验结果表明，RefAlign在各种场景中表现出与现有对齐方法相当的性能，同时具有更高的效率。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.09895v1",
      "published_date": "2025-04-14 05:43:21 UTC",
      "updated_date": "2025-04-14 05:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:25:31.451208"
    },
    {
      "arxiv_id": "2504.09893v1",
      "title": "LangPert: Detecting and Handling Task-level Perturbations for Robust Object Rearrangement",
      "title_zh": "LangPert：检测和处理任务级扰动，实现稳健的物体重排\n",
      "authors": [
        "Xu Yin",
        "Min-Sung Yoon",
        "Yuchi Huo",
        "Kang Zhang",
        "Sung-Eui Yoon"
      ],
      "abstract": "Task execution for object rearrangement could be challenged by Task-Level\nPerturbations (TLP), i.e., unexpected object additions, removals, and\ndisplacements that can disrupt underlying visual policies and fundamentally\ncompromise task feasibility and progress. To address these challenges, we\npresent LangPert, a language-based framework designed to detect and mitigate\nTLP situations in tabletop rearrangement tasks. LangPert integrates a Visual\nLanguage Model (VLM) to comprehensively monitor policy's skill execution and\nenvironmental TLP, while leveraging the Hierarchical Chain-of-Thought (HCoT)\nreasoning mechanism to enhance the Large Language Model (LLM)'s contextual\nunderstanding and generate adaptive, corrective skill-execution plans. Our\nexperimental results demonstrate that LangPert handles diverse TLP situations\nmore effectively than baseline methods, achieving higher task completion rates,\nimproved execution efficiency, and potential generalization to unseen\nscenarios.",
      "tldr_zh": "LangPert是一个基于语言的框架，旨在检测和处理对象重排列任务中的任务级扰动(Task-Level Perturbations, TLP)，例如意外的对象添加、移除和位移。该框架集成了一个视觉语言模型(Visual Language Model, VLM)来全面监控策略的技能执行和环境TLP，并利用分层链式思维(Hierarchical Chain-of-Thought, HCoT)推理机制来增强大型语言模型(Large Language Model, LLM)的上下文理解，并生成自适应的、纠正性的技能执行计划。实验结果表明，LangPert比基线方法更有效地处理各种TLP情况，实现了更高的任务完成率、更高的执行效率以及推广到未见场景的潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09893v1",
      "published_date": "2025-04-14 05:39:15 UTC",
      "updated_date": "2025-04-14 05:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:25:43.419490"
    },
    {
      "arxiv_id": "2504.09877v1",
      "title": "Constructing Micro Knowledge Graphs from Technical Support Documents",
      "title_zh": "从技术支持文档构建微型知识图谱\n",
      "authors": [
        "Atul Kumar",
        "Nisha Gupta",
        "Saswati Dana"
      ],
      "abstract": "Short technical support pages such as IBM Technotes are quite common in\ntechnical support domain. These pages can be very useful as the knowledge\nsources for technical support applications such as chatbots, search engines and\nquestion-answering (QA) systems. Information extracted from documents to drive\ntechnical support applications is often stored in the form of Knowledge Graph\n(KG). Building KGs from a large corpus of documents poses a challenge of\ngranularity because a large number of entities and actions are present in each\npage. The KG becomes virtually unusable if all entities and actions from these\npages are stored in the KG. Therefore, only key entities and actions from each\npage are extracted and stored in the KG. This approach however leads to loss of\nknowledge represented by entities and actions left out of the KG as they are no\nlonger available to graph search and reasoning functions. We propose a set of\ntechniques to create micro knowledge graph (micrograph) for each of such web\npages. The micrograph stores all the entities and actions in a page and also\ntakes advantage of the structure of the page to represent exactly in which part\nof that page these entities and actions appeared, and also how they relate to\neach other. These micrographs can be used as additional knowledge sources by\ntechnical support applications. We define schemas for representing\nsemi-structured and plain text knowledge present in the technical support web\npages. Solutions in technical support domain include procedures made of steps.\nWe also propose a technique to extract procedures from these webpages and the\nschemas to represent them in the micrographs. We also discuss how technical\nsupport applications can take advantage of the micrographs.",
      "tldr_zh": "该论文提出了一种从技术支持文档（如IBM Technotes）中构建微知识图谱(micro knowledge graph, micrograph)的方法。传统知识图谱构建面临粒度挑战，忽略非关键实体和动作会导致信息丢失。该方法为每个网页构建一个micrograph，存储所有实体和动作，并利用页面结构记录它们出现的位置以及相互关系。论文定义了用于表示半结构化和纯文本知识的模式，并提出了一种从网页中提取步骤程序的方法，以及在micrograph中表示它们的模式。最后，讨论了技术支持应用如何利用这些micrograph。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09877v1",
      "published_date": "2025-04-14 04:57:49 UTC",
      "updated_date": "2025-04-14 04:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:25:55.340688"
    },
    {
      "arxiv_id": "2504.09876v1",
      "title": "HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation",
      "title_zh": "HDC：用于半监督胎儿超声分割中多层噪声一致性的分层蒸馏\n",
      "authors": [
        "Tran Quoc Khanh Le",
        "Nguyen Lan Vi Vu",
        "Ha-Hieu Pham",
        "Xuan-Loc Huynh",
        "Tien-Huy Nguyen",
        "Minh Huu Nhat Le",
        "Quan Nguyen",
        "Hien D. Nguyen"
      ],
      "abstract": "Transvaginal ultrasound is a critical imaging modality for evaluating\ncervical anatomy and detecting physiological changes. However, accurate\nsegmentation of cervical structures remains challenging due to low contrast,\nshadow artifacts, and fuzzy boundaries. While convolutional neural networks\n(CNNs) have shown promising results in medical image segmentation, their\nperformance is often limited by the need for large-scale annotated datasets -\nan impractical requirement in clinical ultrasound imaging. Semi-supervised\nlearning (SSL) offers a compelling solution by leveraging unlabeled data, but\nexisting teacher-student frameworks often suffer from confirmation bias and\nhigh computational costs. We propose HDC, a novel semi-supervised segmentation\nframework that integrates Hierarchical Distillation and Consistency learning\nwithin a multi-level noise mean-teacher framework. Unlike conventional\napproaches that rely solely on pseudo-labeling, we introduce a hierarchical\ndistillation mechanism that guides feature-level learning via two novel\nobjectives: (1) Correlation Guidance Loss to align feature representations\nbetween the teacher and main student branch, and (2) Mutual Information Loss to\nstabilize representations between the main and noisy student branches. Our\nframework reduces model complexity while improving generalization. Extensive\nexperiments on two fetal ultrasound datasets, FUGC and PSFH, demonstrate that\nour method achieves competitive performance with significantly lower\ncomputational overhead than existing multi-teacher models.",
      "tldr_zh": "该论文提出了一种名为HDC的半监督学习框架，用于解决胎儿超声图像分割中标记数据不足的问题。HDC框架结合了层级蒸馏和一致性学习，在一个多层噪声Mean-Teacher模型中，通过引入Correlation Guidance Loss和Mutual Information Loss，在特征层面引导teacher和student分支的学习，从而减少模型复杂度并提高泛化能力。实验结果表明，在FUGC和PSFH两个胎儿超声数据集上，HDC方法在计算开销显著降低的情况下，取得了与现有multi-teacher模型相当的性能。该方法旨在提升胎儿超声图像中宫颈结构的精确分割，克服超声图像低对比度、阴影伪影和模糊边界等挑战。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09876v1",
      "published_date": "2025-04-14 04:52:24 UTC",
      "updated_date": "2025-04-14 04:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:26:07.614383"
    },
    {
      "arxiv_id": "2504.09873v1",
      "title": "Truncated Matrix Completion - An Empirical Study",
      "title_zh": "截断矩阵补全：一项实证研究\n",
      "authors": [
        "Rishhabh Naik",
        "Nisarg Trivedi",
        "Davoud Ataee Tarzanagh",
        "Laura Balzano"
      ],
      "abstract": "Low-rank Matrix Completion (LRMC) describes the problem where we wish to\nrecover missing entries of partially observed low-rank matrix. Most existing\nmatrix completion work deals with sampling procedures that are independent of\nthe underlying data values. While this assumption allows the derivation of nice\ntheoretical guarantees, it seldom holds in real-world applications. In this\npaper, we consider various settings where the sampling mask is dependent on the\nunderlying data values, motivated by applications in sensing, sequential\ndecision-making, and recommender systems. Through a series of experiments, we\nstudy and compare the performance of various LRMC algorithms that were\noriginally successful for data-independent sampling patterns.",
      "tldr_zh": "本文针对低秩矩阵补全(LRMC)问题，研究了在采样模式依赖于底层数据值的情况下，现有LRMC算法的性能表现。与传统假设采样独立于数据值的研究不同，本文关注传感、序列决策和推荐系统等实际应用中常见的依赖性采样。通过一系列实验，作者对比分析了多种在数据独立采样模式下表现良好的LRMC算法，为实际应用中算法选择提供了参考。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09873v1",
      "published_date": "2025-04-14 04:42:00 UTC",
      "updated_date": "2025-04-14 04:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:26:19.192556"
    },
    {
      "arxiv_id": "2504.09865v1",
      "title": "Labeling Messages as AI-Generated Does Not Reduce Their Persuasive Effects",
      "title_zh": "将消息标记为 AI 生成并不能降低其说服效果\n",
      "authors": [
        "Isabel O. Gallegos",
        "Chen Shani",
        "Weiyan Shi",
        "Federico Bianchi",
        "Izzy Gainsburg",
        "Dan Jurafsky",
        "Robb Willer"
      ],
      "abstract": "As generative artificial intelligence (AI) enables the creation and\ndissemination of information at massive scale and speed, it is increasingly\nimportant to understand how people perceive AI-generated content. One prominent\npolicy proposal requires explicitly labeling AI-generated content to increase\ntransparency and encourage critical thinking about the information, but prior\nresearch has not yet tested the effects of such labels. To address this gap, we\nconducted a survey experiment (N=1601) on a diverse sample of Americans,\npresenting participants with an AI-generated message about several public\npolicies (e.g., allowing colleges to pay student-athletes), randomly assigning\nwhether participants were told the message was generated by (a) an expert AI\nmodel, (b) a human policy expert, or (c) no label. We found that messages were\ngenerally persuasive, influencing participants' views of the policies by 9.74\npercentage points on average. However, while 94.6% of participants assigned to\nthe AI and human label conditions believed the authorship labels, labels had no\nsignificant effects on participants' attitude change toward the policies,\njudgments of message accuracy, nor intentions to share the message with others.\nThese patterns were robust across a variety of participant characteristics,\nincluding prior knowledge of the policy, prior experience with AI, political\nparty, education level, or age. Taken together, these results imply that, while\nauthorship labels would likely enhance transparency, they are unlikely to\nsubstantially affect the persuasiveness of the labeled content, highlighting\nthe need for alternative strategies to address challenges posed by AI-generated\ninformation.",
      "tldr_zh": "该研究调查了将信息标记为AI生成是否能降低其说服力。通过对1601名美国人进行调查实验，参与者阅读关于公共政策的AI生成信息，并随机告知信息由(a)专家AI模型、(b)人类政策专家生成，或(c)无标签。结果表明，信息普遍具有说服力，平均影响参与者对政策的看法9.74个百分点。尽管94.6%的参与者相信AI和人类标签，但标签对参与者对政策的态度改变、信息准确性的判断以及分享意愿没有显著影响。研究表明，虽然署名标签可以提高透明度，但不太可能显著影响被标记内容的说服力，因此需要其他策略来应对AI生成信息带来的挑战。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09865v1",
      "published_date": "2025-04-14 04:22:39 UTC",
      "updated_date": "2025-04-14 04:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:26:31.543420"
    },
    {
      "arxiv_id": "2504.09860v1",
      "title": "SUMART: SUMmARizing Translation from Wordy to Concise Expression",
      "title_zh": "SUMART：将冗长的表达翻译成简洁表达的摘要方法\n",
      "authors": [
        "Naoto Nishida",
        "Jun Rekimoto"
      ],
      "abstract": "We propose SUMART, a method for summarizing and compressing the volume of\nverbose subtitle translations. SUMART is designed for understanding translated\ncaptions (e.g., interlingual conversations via subtitle translation or when\nwatching movies in foreign language audio and translated captions). SUMART is\nintended for users who want a big-picture and fast understanding of the\nconversation, audio, video content, and speech in a foreign language. During\nthe training data collection, when a speaker makes a verbose statement, SUMART\nemploys a large language model on-site to compress the volume of subtitles.\nThis compressed data is then stored in a database for fine-tuning purposes.\nLater, SUMART uses data pairs from those non-compressed ASR results and\ncompressed translated results for fine-tuning the translation model to generate\nmore concise translations for practical uses. In practical applications, SUMART\nutilizes this trained model to produce concise translation results.\nFurthermore, as a practical application, we developed an application that\nallows conversations using subtitle translation in augmented reality spaces. As\na pilot study, we conducted qualitative surveys using a SUMART prototype and a\nsurvey on the summarization model for SUMART. We envision the most effective\nuse case of this system is where users need to consume a lot of information\nquickly (e.g., Speech, lectures, podcasts, Q&A in conferences).",
      "tldr_zh": "该论文提出了一种名为SUMART的方法，旨在对冗长的字幕翻译进行总结和压缩，以便用户快速理解外语对话、音频或视频内容。SUMART利用大型语言模型压缩冗余的字幕，并将压缩后的数据存储在数据库中用于微调。通过使用原始ASR结果和压缩后的翻译结果进行训练，SUMART能够生成更简洁的翻译。该研究还开发了一个在增强现实空间中使用字幕翻译进行对话的应用，并进行了初步的定性调查。SUMART适用于需要快速获取大量信息的场景，如演讲、讲座、播客和会议问答。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "3 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09860v1",
      "published_date": "2025-04-14 04:13:09 UTC",
      "updated_date": "2025-04-14 04:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:26:43.315878"
    },
    {
      "arxiv_id": "2504.09858v1",
      "title": "Reasoning Models Can Be Effective Without Thinking",
      "title_zh": "无需思考，推理模型也能有效\n",
      "authors": [
        "Wenjie Ma",
        "Jingxuan He",
        "Charlie Snell",
        "Tyler Griggs",
        "Sewon Min",
        "Matei Zaharia"
      ],
      "abstract": "Recent LLMs have significantly improved reasoning capabilities, primarily by\nincluding an explicit, lengthy Thinking process as part of generation. In this\npaper, we question whether this explicit thinking is necessary. Using the\nstate-of-the-art DeepSeek-R1-Distill-Qwen, we find that bypassing the thinking\nprocess via simple prompting, denoted as NoThinking, can be surprisingly\neffective. When controlling for the number of tokens, NoThinking outperforms\nThinking across a diverse set of seven challenging reasoning\ndatasets--including mathematical problem solving, formal theorem proving, and\ncoding--especially in low-budget settings, e.g., 51.3 vs. 28.9 on ACM 23 with\n700 tokens. Notably, the performance of NoThinking becomes more competitive\nwith pass@k as k increases. Building on this observation, we demonstrate that a\nparallel scaling approach that uses NoThinking to generate N outputs\nindependently and aggregates them is highly effective. For aggregation, we use\ntask-specific verifiers when available, or we apply simple best-of-N strategies\nsuch as confidence-based selection. Our method outperforms a range of baselines\nwith similar latency using Thinking, and is comparable to Thinking with\nsignificantly longer latency (up to 9x). Together, our research encourages a\nreconsideration of the necessity of lengthy thinking processes, while also\nestablishing a competitive reference for achieving strong reasoning performance\nin low-budget settings or at low latency using parallel scaling.",
      "tldr_zh": "该论文质疑了大型语言模型(LLMs)中显式、冗长的“思考(Thinking)”过程对于推理能力提升的必要性。研究发现，使用DeepSeek-R1-Distill-Qwen模型，通过简单的提示绕过思考过程(NoThinking)也能取得显著效果。在控制token数量的情况下，NoThinking在包括数学问题解决、形式定理证明和编码在内的七个具有挑战性的推理数据集上优于Thinking，尤其是在低预算设置下。此外，论文提出了一种并行扩展方法，利用NoThinking独立生成多个输出并进行聚合，该方法在相似延迟下优于使用Thinking的基线模型，并在显著更短的延迟下与Thinking的性能相当。研究表明，在低预算或低延迟情况下，NoThinking是一种有竞争力的强推理性能实现方式。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 7 main figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.09858v1",
      "published_date": "2025-04-14 04:08:16 UTC",
      "updated_date": "2025-04-14 04:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:26:55.719550"
    },
    {
      "arxiv_id": "2504.09857v1",
      "title": "Working with Large Language Models to Enhance Messaging Effectiveness for Vaccine Confidence",
      "title_zh": "利用大型语言模型提升疫苗信心的信息传递效果\n",
      "authors": [
        "Lucinda Gullison",
        "Feng Fu"
      ],
      "abstract": "Vaccine hesitancy and misinformation are significant barriers to achieving\nwidespread vaccination coverage. Smaller public health departments may lack the\nexpertise or resources to craft effective vaccine messaging. This paper\nexplores the potential of ChatGPT-augmented messaging to promote confidence in\nvaccination uptake.\n  We conducted a survey in which participants chose between pairs of\nvaccination messages and assessed which was more persuasive and to what extent.\nIn each pair, one message was the original, and the other was augmented by\nChatGPT. At the end of the survey, participants were informed that half of the\nmessages had been generated by ChatGPT. They were then asked to provide both\nquantitative and qualitative responses regarding how knowledge of a message's\nChatGPT origin affected their impressions.\n  Overall, ChatGPT-augmented messages were rated slightly higher than the\noriginal messages. These messages generally scored better when they were\nlonger. Respondents did not express major concerns about ChatGPT-generated\ncontent, nor was there a significant relationship between participants' views\non ChatGPT and their message ratings. Notably, there was a correlation between\nwhether a message appeared first or second in a pair and its score.\n  These results point to the potential of ChatGPT to enhance vaccine messaging,\nsuggesting a promising direction for future research on human-AI collaboration\nin public health communication.",
      "tldr_zh": "该研究探索了利用ChatGPT增强疫苗宣传信息以提高疫苗接种率的方法。研究人员通过调查，让参与者在原始疫苗信息和ChatGPT增强的信息之间进行选择，并评估其说服力。结果表明，ChatGPT增强的信息略优于原始信息，尤其是在信息较长时。参与者对ChatGPT生成的内容没有表现出明显担忧，且对ChatGPT的看法与信息评分之间没有显著关系。这项研究表明，ChatGPT有潜力增强疫苗宣传信息，为公共卫生传播领域的人工智能协作提供了有希望的方向。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09857v1",
      "published_date": "2025-04-14 04:06:46 UTC",
      "updated_date": "2025-04-14 04:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:27:07.396984"
    },
    {
      "arxiv_id": "2504.09855v1",
      "title": "PestMA: LLM-based Multi-Agent System for Informed Pest Management",
      "title_zh": "PestMA：用于知情虫害管理的大语言模型多智能体系统\n",
      "authors": [
        "Hongrui Shi",
        "Shunbao Li",
        "Zhipeng Yuan",
        "Po Yang"
      ],
      "abstract": "Effective pest management is complex due to the need for accurate,\ncontext-specific decisions. Recent advancements in large language models (LLMs)\nopen new possibilities for addressing these challenges by providing\nsophisticated, adaptive knowledge acquisition and reasoning. However, existing\nLLM-based pest management approaches often rely on a single-agent paradigm,\nwhich can limit their capacity to incorporate diverse external information,\nengage in systematic validation, and address complex, threshold-driven\ndecisions. To overcome these limitations, we introduce PestMA, an LLM-based\nmulti-agent system (MAS) designed to generate reliable and evidence-based pest\nmanagement advice. Building on an editorial paradigm, PestMA features three\nspecialized agents, an Editor for synthesizing pest management recommendations,\na Retriever for gathering relevant external data, and a Validator for ensuring\ncorrectness. Evaluations on real-world pest scenarios demonstrate that PestMA\nachieves an initial accuracy of 86.8% for pest management decisions, which\nincreases to 92.6% after validation. These results underscore the value of\ncollaborative agent-based workflows in refining and validating decisions,\nhighlighting the potential of LLM-based multi-agent systems to automate and\nenhance pest management processes.",
      "tldr_zh": "该论文提出了PestMA，一个基于LLM的多智能体系统，旨在提供可靠且基于证据的病虫害管理建议。PestMA采用编辑范式，包含三个专业智能体：Editor负责综合病虫害管理建议，Retriever负责收集相关外部数据，Validator负责确保正确性。实验结果表明，PestMA在病虫害管理决策中的初始准确率为86.8%，经过验证后提高到92.6%。该研究强调了基于LLM的多智能体系统在自动化和增强病虫害管理流程方面的潜力。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.MA",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.09855v1",
      "published_date": "2025-04-14 03:53:59 UTC",
      "updated_date": "2025-04-14 03:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:27:19.405295"
    },
    {
      "arxiv_id": "2504.09851v1",
      "title": "Carbon-Efficient 3D DNN Acceleration: Optimizing Performance and Sustainability",
      "title_zh": "碳效率 3D DNN 加速：优化性能与可持续性\n",
      "authors": [
        "Aikaterini Maria Panteleaki",
        "Konstantinos Balaskas",
        "Georgios Zervakis",
        "Hussam Amrouch",
        "Iraklis Anagnostopoulos"
      ],
      "abstract": "As Deep Neural Networks (DNNs) continue to drive advancements in artificial\nintelligence, the design of hardware accelerators faces growing concerns over\nembodied carbon footprint due to complex fabrication processes. 3D integration\nimproves performance but introduces sustainability challenges, making\ncarbon-aware optimization essential. In this work, we propose a\ncarbon-efficient design methodology for 3D DNN accelerators, leveraging\napproximate computing and genetic algorithm-based design space exploration to\noptimize Carbon Delay Product (CDP). By integrating area-efficient approximate\nmultipliers into Multiply-Accumulate (MAC) units, our approach effectively\nreduces silicon area and fabrication overhead while maintaining high\ncomputational accuracy. Experimental evaluations across three technology nodes\n(45nm, 14nm, and 7nm) show that our method reduces embodied carbon by up to 30%\nwith negligible accuracy drop.",
      "tldr_zh": "该研究提出了一种碳效率3D DNN加速设计方法，旨在优化性能和可持续性。通过结合近似计算和基于遗传算法的设计空间探索，该方法优化了Carbon Delay Product (CDP)。具体而言，通过将面积效率高的近似乘法器集成到Multiply-Accumulate (MAC)单元中，有效减少了芯片面积和制造成本。在三种技术节点(45nm, 14nm, and 7nm)上的实验评估表明，该方法可以在精度损失极小的情况下，将隐含碳排放量降低高达30%。\n",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Submitted in ISVLSI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09851v1",
      "published_date": "2025-04-14 03:48:37 UTC",
      "updated_date": "2025-04-14 03:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:27:31.378450"
    },
    {
      "arxiv_id": "2504.09848v1",
      "title": "A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science",
      "title_zh": "大语言模型驱动的跨尺度空间智能综述：具身智能体、智慧城市和地球科学的进展\n",
      "authors": [
        "Jie Feng",
        "Jinwei Zeng",
        "Qingyue Long",
        "Hongyi Chen",
        "Jie Zhao",
        "Yanxin Xi",
        "Zhilun Zhou",
        "Yuan Yuan",
        "Shengyuan Wang",
        "Qingbin Zeng",
        "Songwei Li",
        "Yunke Zhang",
        "Yuming Lin",
        "Tong Li",
        "Jingtao Ding",
        "Chen Gao",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Over the past year, the development of large language models (LLMs) has\nbrought spatial intelligence into focus, with much attention on vision-based\nembodied intelligence. However, spatial intelligence spans a broader range of\ndisciplines and scales, from navigation and urban planning to remote sensing\nand earth science. What are the differences and connections between spatial\nintelligence across these fields? In this paper, we first review human spatial\ncognition and its implications for spatial intelligence in LLMs. We then\nexamine spatial memory, knowledge representations, and abstract reasoning in\nLLMs, highlighting their roles and connections. Finally, we analyze spatial\nintelligence across scales -- from embodied to urban and global levels --\nfollowing a framework that progresses from spatial memory and understanding to\nspatial reasoning and intelligence. Through this survey, we aim to provide\ninsights into interdisciplinary spatial intelligence research and inspire\nfuture studies.",
      "tldr_zh": "本文综述了大型语言模型(LLMs)驱动的跨尺度空间智能，涵盖了具身智能体、智慧城市和地球科学等领域。首先回顾了人类空间认知及其对LLMs空间智能的影响，然后考察了LLMs中的空间记忆、知识表示和抽象推理。最后，分析了从具身到城市和全球层面的跨尺度空间智能，框架遵循从空间记忆和理解到空间推理和智能的进展。本综述旨在提供跨学科空间智能研究的见解，并激发未来的研究。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09848v1",
      "published_date": "2025-04-14 03:38:31 UTC",
      "updated_date": "2025-04-14 03:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:27:43.479706"
    },
    {
      "arxiv_id": "2504.09846v1",
      "title": "GlyTwin: Digital Twin for Glucose Control in Type 1 Diabetes Through Optimal Behavioral Modifications Using Patient-Centric Counterfactuals",
      "title_zh": "GlyTwin：用于 1 型糖尿病血糖控制的数字孪生，通过以患者为中心的反事实方法实现最佳行为修正\n",
      "authors": [
        "Asiful Arefeen",
        "Saman Khamesian",
        "Maria Adela Grando",
        "Bithika Thompson",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Frequent and long-term exposure to hyperglycemia (i.e., high blood glucose)\nincreases the risk of chronic complications such as neuropathy, nephropathy,\nand cardiovascular disease. Current technologies like continuous subcutaneous\ninsulin infusion (CSII) and continuous glucose monitoring (CGM) primarily model\nspecific aspects of glycemic control-like hypoglycemia prediction or insulin\ndelivery. Similarly, most digital twin approaches in diabetes management\nsimulate only physiological processes. These systems lack the ability to offer\nalternative treatment scenarios that support proactive behavioral\ninterventions. To address this, we propose GlyTwin, a novel digital twin\nframework that uses counterfactual explanations to simulate optimal treatments\nfor glucose regulation. Our approach helps patients and caregivers modify\nbehaviors like carbohydrate intake and insulin dosing to avoid abnormal glucose\nevents. GlyTwin generates behavioral treatment suggestions that proactively\nprevent hyperglycemia by recommending small adjustments to daily choices,\nreducing both frequency and duration of these events. Additionally, it\nincorporates stakeholder preferences into the intervention design, making\nrecommendations patient-centric and tailored. We evaluate GlyTwin on AZT1D, a\nnewly constructed dataset with longitudinal data from 21 type 1 diabetes (T1D)\npatients on automated insulin delivery systems over 26 days. Results show\nGlyTwin outperforms state-of-the-art counterfactual methods, generating 76.6%\nvalid and 86% effective interventions. These findings demonstrate the promise\nof counterfactual-driven digital twins in delivering personalized healthcare.",
      "tldr_zh": "该论文提出了GlyTwin，一种新型数字孪生框架，旨在通过患者中心的“反事实解释”(counterfactual explanations)模拟最佳治疗方案，从而实现1型糖尿病患者的血糖控制。GlyTwin能够根据患者的日常行为（如碳水化合物摄入和胰岛素剂量）提供调整建议，以预防高血糖事件，并减少其发生频率和持续时间。该框架还考虑了利益相关者的偏好，使推荐方案更具个性化和针对性。在AZT1D数据集上的实验结果表明，GlyTwin优于现有反事实方法，生成了76.6%的有效和86%的有效干预措施，验证了反事实驱动的数字孪生在个性化医疗中的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09846v1",
      "published_date": "2025-04-14 03:32:39 UTC",
      "updated_date": "2025-04-14 03:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:27:55.729264"
    },
    {
      "arxiv_id": "2504.09844v1",
      "title": "OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training",
      "title_zh": "OVERLORD：多源大型基础模型训练的数据加载器终极扩展\n",
      "authors": [
        "Juntao Zhao",
        "Qi Lu",
        "Wei Jia",
        "Borui Wan",
        "Lei Zuo",
        "Junda Feng",
        "Jianyu Jiang",
        "Yangrui Chen",
        "Shuaishuai Cao",
        "Jialing He",
        "Kaihua Jiang",
        "Yuanzhe Hu",
        "Yanghua Peng",
        "Haibin Lin",
        "Xin Liu",
        "Chuan Wu"
      ],
      "abstract": "Modern frameworks for training large foundation models (LFMs) employ data\nloaders in a data parallel paradigm. While this design offers implementation\nsimplicity, it introduces two fundamental challenges. First, due to the\nquadratic computational complexity of the attention operator, the non-uniform\nsample distribution over data-parallel ranks leads to a significant workload\nimbalance among loaders, which degrades the training efficiency. This paradigm\nalso impedes the implementation of data mixing algorithms (e.g., curriculum\nlearning) over different datasets. Second, to acquire a broad range of\ncapability, LFMs training ingests data from diverse sources, each with distinct\nfile access states. Colocating massive datasets within loader instances can\neasily exceed local pod memory capacity. Additionally, heavy sources with\nhigher transformation latency require larger worker pools, further exacerbating\nmemory consumption.\n  We present OVERLORD, an industrial-grade distributed data loading\narchitecture with three innovations: (1) A centralized and declarative data\nplane, which facilitates elastic data orchestration strategy, such as\nlong-short context, multimodal, and curriculum learning; (2) Disaggregated\nmultisource preprocessing through role-specific actors, i.e., Source Loaders\nand Data Constructors, leveraging autoscaling for Source Loaders towards\nheterogeneous and evolving source preprocessing cost; (3) Shadow Loaders with\ndifferential checkpointing for uninterrupted fault recovery. Deployed on\nproduction clusters scaling to multi-thousand GPU, OVERLORD achieves: (1) 4.5x\nend-to-end training throughput improvement, (2) a minimum 3.6x reduction in CPU\nmemory usage, with further improvements to be added in later experiments.",
      "tldr_zh": "OVERLORD 提出了一种用于大规模多源基础模型训练的分布式数据加载架构，旨在解决传统数据并行范式中存在的负载不均衡和数据混合困难等问题。该架构包含三个主要创新点：(1) 中心化的声明式数据平面，支持灵活的数据编排策略，例如长短上下文、多模态和课程学习；(2) 通过角色特定的actors（Source Loaders 和 Data Constructors）实现分离的多源预处理，并利用自动缩放来应对异构和不断变化的源预处理成本；(3) 具有差异化checkpointing的 Shadow Loaders，用于不间断的故障恢复。在生产集群上的实验表明，OVERLORD 实现了 4.5 倍的端到端训练吞吐量提升，并至少减少 3.6 倍的 CPU 内存使用。\n",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09844v1",
      "published_date": "2025-04-14 03:31:22 UTC",
      "updated_date": "2025-04-14 03:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:28:07.935231"
    },
    {
      "arxiv_id": "2504.09841v1",
      "title": "StruPhantom: Evolutionary Injection Attacks on Black-Box Tabular Agents Powered by Large Language Models",
      "title_zh": "StruPhantom：基于大型语言模型的黑盒表格代理的进化注入攻击\n",
      "authors": [
        "Yang Feng",
        "Xudong Pan"
      ],
      "abstract": "The proliferation of autonomous agents powered by large language models\n(LLMs) has revolutionized popular business applications dealing with tabular\ndata, i.e., tabular agents. Although LLMs are observed to be vulnerable against\nprompt injection attacks from external data sources, tabular agents impose\nstrict data formats and predefined rules on the attacker's payload, which are\nineffective unless the agent navigates multiple layers of structural data to\nincorporate the payload. To address the challenge, we present a novel attack\ntermed StruPhantom which specifically targets black-box LLM-powered tabular\nagents. Our attack designs an evolutionary optimization procedure which\ncontinually refines attack payloads via the proposed constrained Monte Carlo\nTree Search augmented by an off-topic evaluator. StruPhantom helps\nsystematically explore and exploit the weaknesses of target applications to\nachieve goal hijacking. Our evaluation validates the effectiveness of\nStruPhantom across various LLM-based agents, including those on real-world\nplatforms, and attack scenarios. Our attack achieves over 50% higher success\nrates than baselines in enforcing the application's response to contain\nphishing links or malicious codes.",
      "tldr_zh": "该论文提出了一种名为StruPhantom的新型攻击方法，专门针对基于大型语言模型(LLMs)的黑盒表格代理。StruPhantom利用进化优化程序，通过结合约束蒙特卡洛树搜索和离题评估器，不断改进攻击载荷。该方法旨在系统地探索和利用目标应用的弱点，以实现目标劫持。实验结果表明，StruPhantom在各种基于LLM的代理（包括真实平台上的代理）和攻击场景中，成功率比基线高出50%以上，能够有效地强制应用响应包含网络钓鱼链接或恶意代码。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2504.09841v1",
      "published_date": "2025-04-14 03:22:04 UTC",
      "updated_date": "2025-04-14 03:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:28:19.550343"
    },
    {
      "arxiv_id": "2504.09839v1",
      "title": "SafeSpeech: Robust and Universal Voice Protection Against Malicious Speech Synthesis",
      "title_zh": "SafeSpeech：针对恶意语音合成的鲁棒且通用的语音保护方法\n",
      "authors": [
        "Zhisheng Zhang",
        "Derui Wang",
        "Qianyi Yang",
        "Pengyang Huang",
        "Junhan Pu",
        "Yuxin Cao",
        "Kai Ye",
        "Jie Hao",
        "Yixian Yang"
      ],
      "abstract": "Speech synthesis technology has brought great convenience, while the\nwidespread usage of realistic deepfake audio has triggered hazards. Malicious\nadversaries may unauthorizedly collect victims' speeches and clone a similar\nvoice for illegal exploitation (\\textit{e.g.}, telecom fraud). However, the\nexisting defense methods cannot effectively prevent deepfake exploitation and\nare vulnerable to robust training techniques. Therefore, a more effective and\nrobust data protection method is urgently needed. In response, we propose a\ndefensive framework, \\textit{\\textbf{SafeSpeech}}, which protects the users'\naudio before uploading by embedding imperceptible perturbations on original\nspeeches to prevent high-quality synthetic speech. In SafeSpeech, we devise a\nrobust and universal proactive protection technique, \\textbf{S}peech\n\\textbf{PE}rturbative \\textbf{C}oncealment (\\textbf{SPEC}), that leverages a\nsurrogate model to generate universally applicable perturbation for generative\nsynthetic models. Moreover, we optimize the human perception of embedded\nperturbation in terms of time and frequency domains. To evaluate our method\ncomprehensively, we conduct extensive experiments across advanced models and\ndatasets, both subjectively and objectively. Our experimental results\ndemonstrate that SafeSpeech achieves state-of-the-art (SOTA) voice protection\neffectiveness and transferability and is highly robust against advanced\nadaptive adversaries. Moreover, SafeSpeech has real-time capability in\nreal-world tests. The source code is available at\n\\href{https://github.com/wxzyd123/SafeSpeech}{https://github.com/wxzyd123/SafeSpeech}.",
      "tldr_zh": "该论文提出了一种名为SafeSpeech的防御框架，旨在通过在原始语音中嵌入难以察觉的扰动，从而防止恶意语音合成技术（deepfake）对用户语音的非法利用。 SafeSpeech的核心是语音扰动隐藏（SPEC）技术，该技术利用替代模型生成通用的扰动，适用于各种生成式合成模型，并优化了嵌入扰动在时域和频域上的人类感知。实验结果表明，SafeSpeech在语音保护效果、迁移性和对高级自适应攻击的鲁棒性方面均达到了SOTA水平，并具备实时处理能力。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to USENIX Security 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.09839v1",
      "published_date": "2025-04-14 03:21:23 UTC",
      "updated_date": "2025-04-14 03:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:28:31.525654"
    },
    {
      "arxiv_id": "2504.09831v1",
      "title": "Offline Dynamic Inventory and Pricing Strategy: Addressing Censored and Dependent Demand",
      "title_zh": "离线动态库存和定价策略：解决截尾和相关需求问题\n",
      "authors": [
        "Korel Gundem",
        "Zhengling Qi"
      ],
      "abstract": "In this paper, we study the offline sequential feature-based pricing and\ninventory control problem where the current demand depends on the past demand\nlevels and any demand exceeding the available inventory is lost. Our goal is to\nleverage the offline dataset, consisting of past prices, ordering quantities,\ninventory levels, covariates, and censored sales levels, to estimate the\noptimal pricing and inventory control policy that maximizes long-term profit.\nWhile the underlying dynamic without censoring can be modeled by Markov\ndecision process (MDP), the primary obstacle arises from the observed process\nwhere demand censoring is present, resulting in missing profit information, the\nfailure of the Markov property, and a non-stationary optimal policy. To\novercome these challenges, we first approximate the optimal policy by solving a\nhigh-order MDP characterized by the number of consecutive censoring instances,\nwhich ultimately boils down to solving a specialized Bellman equation tailored\nfor this problem. Inspired by offline reinforcement learning and survival\nanalysis, we propose two novel data-driven algorithms to solving these Bellman\nequations and, thus, estimate the optimal policy. Furthermore, we establish\nfinite sample regret bounds to validate the effectiveness of these algorithms.\nFinally, we conduct numerical experiments to demonstrate the efficacy of our\nalgorithms in estimating the optimal policy. To the best of our knowledge, this\nis the first data-driven approach to learning optimal pricing and inventory\ncontrol policies in a sequential decision-making environment characterized by\ncensored and dependent demand. The implementations of the proposed algorithms\nare available at https://github.com/gundemkorel/Inventory_Pricing_Control",
      "tldr_zh": "本文研究了离线环境下基于序列特征的定价和库存控制问题，其中当前需求依赖于过去的需求水平，并且超过可用库存的任何需求都会丢失（需求审查）。目标是利用离线数据集（包含过去的价格、订购数量、库存水平、协变量和审查后的销售水平）来估计最优的定价和库存控制策略，以最大化长期利润。由于存在需求审查，导致利润信息缺失、马尔可夫性质失效以及非平稳最优策略，本文通过求解一个高阶MDP来近似最优策略，该MDP的特征在于连续审查实例的数量，最终归结为求解为此问题量身定制的Bellman方程。受离线强化学习和生存分析的启发，提出了两种新的数据驱动算法来求解这些Bellman方程，从而估计最优策略。此外，建立了有限样本遗憾界来验证这些算法的有效性。数值实验表明了算法在估计最优策略方面的有效性。这是第一个在以审查和依赖需求为特征的序列决策环境中学习最优定价和库存控制策略的数据驱动方法。\n",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.AP",
        "stat.TH",
        "90B05, 68T05, 90C40, 62N02"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09831v1",
      "published_date": "2025-04-14 02:57:51 UTC",
      "updated_date": "2025-04-14 02:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:28:44.089377"
    },
    {
      "arxiv_id": "2504.09812v1",
      "title": "Efficient Multi-Task Modeling through Automated Fusion of Trained Models",
      "title_zh": "通过已训练模型的自动融合实现高效的多任务建模\n",
      "authors": [
        "Jingxuan Zhou",
        "Weidong Bao",
        "Ji Wang",
        "Zhengyi Zhong",
        "Dayu Zhang"
      ],
      "abstract": "Although multi-task learning is widely applied in intelligent services,\ntraditional multi-task modeling methods often require customized designs based\non specific task combinations, resulting in a cumbersome modeling process.\nInspired by the rapid development and excellent performance of single-task\nmodels, this paper proposes an efficient multi-task modeling method that can\nautomatically fuse trained single-task models with different structures and\ntasks to form a multi-task model. As a general framework, this method allows\nmodelers to simply prepare trained models for the required tasks, simplifying\nthe modeling process while fully utilizing the knowledge contained in the\ntrained models. This eliminates the need for excessive focus on task\nrelationships and model structure design. To achieve this goal, we consider the\nstructural differences among various trained models and employ model\ndecomposition techniques to hierarchically decompose them into multiple\noperable model components. Furthermore, we have designed an Adaptive Knowledge\nFusion (AKF) module based on Transformer, which adaptively integrates\nintra-task and inter-task knowledge based on model components. Through the\nproposed method, we achieve efficient and automated construction of multi-task\nmodels, and its effectiveness is verified through extensive experiments on\nthree datasets.",
      "tldr_zh": "本文提出一种高效的多任务建模方法，通过自动融合已训练的单任务模型来构建多任务模型，无需针对特定任务组合进行定制化设计。该方法首先将不同结构的单任务模型分层分解为可操作的模型组件，然后设计一个基于Transformer的自适应知识融合(AKF)模块，用于自适应地整合任务内和任务间的知识。实验结果表明，该方法能够高效且自动化地构建多任务模型，并在三个数据集上验证了其有效性。该方法简化了建模流程，充分利用了已训练模型中的知识，并减少了对任务关系和模型结构设计的关注。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09812v1",
      "published_date": "2025-04-14 02:21:45 UTC",
      "updated_date": "2025-04-14 02:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:28:55.563404"
    },
    {
      "arxiv_id": "2504.09809v1",
      "title": "See or Recall: A Sanity Check for the Role of Vision in Solving Visualization Question Answer Tasks with Multimodal LLMs",
      "title_zh": "看或回忆：使用多模态 LLM 解决可视化问答任务中视觉作用的理智检查",
      "authors": [
        "Zhimin Li",
        "Haichao Miao",
        "Xinyuan Yan",
        "Valerio Pascucci",
        "Matthew Berger",
        "Shusen Liu"
      ],
      "abstract": "Recent developments in multimodal large language models (MLLM) have equipped\nlanguage models to reason about vision and language jointly. This permits MLLMs\nto both perceive and answer questions about data visualization across a variety\nof designs and tasks. Applying MLLMs to a broad range of visualization tasks\nrequires us to properly evaluate their capabilities, and the most common way to\nconduct evaluation is through measuring a model's visualization reasoning\ncapability, analogous to how we would evaluate human understanding of\nvisualizations (e.g., visualization literacy). However, we found that in the\ncontext of visualization question answering (VisQA), how an MLLM perceives and\nreasons about visualizations can be fundamentally different from how humans\napproach the same problem. During the evaluation, even without visualization,\nthe model could correctly answer a substantial portion of the visualization\ntest questions, regardless of whether any selection options were provided. We\nhypothesize that the vast amount of knowledge encoded in the language model\npermits factual recall that supersedes the need to seek information from the\nvisual signal. It raises concerns that the current VisQA evaluation may not\nfully capture the models' visualization reasoning capabilities. To address\nthis, we propose a comprehensive sanity check framework that integrates a\nrule-based decision tree and a sanity check table to disentangle the effects of\n\"seeing\" (visual processing) and \"recall\" (reliance on prior knowledge). This\nvalidates VisQA datasets for evaluation, highlighting where models are truly\n\"seeing\", positively or negatively affected by the factual recall, or relying\non inductive biases for question answering. Our study underscores the need for\ncareful consideration in designing future visualization understanding studies\nwhen utilizing MLLMs.",
      "tldr_zh": "该研究对多模态大型语言模型(MLLM)在可视化问答(VisQA)任务中的视觉推理能力进行了评估，发现模型在没有视觉信息的情况下，也能通过记忆中的知识回答相当一部分问题。研究人员提出，现有VisQA评估可能无法充分捕捉模型的视觉推理能力。为了解决这个问题，他们提出了一个综合的健全性检查框架，集成了基于规则的决策树和健全性检查表，以区分“看”（视觉处理）和“回忆”（依赖先验知识）的影响。该框架可以验证VisQA数据集的评估有效性，并揭示模型在多大程度上真正依赖视觉信息，以及先验知识或归纳偏见对问答的影响。这项研究强调了在使用MLLM进行可视化理解研究时，需要谨慎设计。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09809v1",
      "published_date": "2025-04-14 02:19:28 UTC",
      "updated_date": "2025-04-14 02:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:29:07.812132"
    },
    {
      "arxiv_id": "2504.09802v1",
      "title": "Training Small Reasoning LLMs with Cognitive Preference Alignment",
      "title_zh": "利用认知偏好对齐训练小型推理LLM",
      "authors": [
        "Wenrui Cai",
        "Chengyu Wang",
        "Junbing Yan",
        "Jun Huang",
        "Xiangzhong Fang"
      ],
      "abstract": "The reasoning capabilities of large language models (LLMs), such as OpenAI's\no1 and DeepSeek-R1, have seen substantial advancements through deep thinking.\nHowever, these enhancements come with significant resource demands,\nunderscoring the need to explore strategies to train effective reasoning LLMs\nwith far fewer parameters. A critical challenge is that smaller models have\ndifferent capacities and cognitive trajectories than their larger counterparts.\nHence, direct distillation of chain-of-thought (CoT) results from large LLMs to\nsmaller ones can be sometimes ineffective and requires a huge amount of\nannotated data. In this paper, we introduce a novel framework called\nCritique-Rethink-Verify (CRV), designed for training smaller yet powerful\nreasoning LLMs. Our CRV framework consists of multiple LLM agents, each\nspecializing in unique abilities: (i) critiquing the CoTs according to the\ncognitive capabilities of smaller models, (ii) rethinking and refining these\nCoTs based on the critiques, and (iii) verifying the correctness of the refined\nresults. We further propose the cognitive preference optimization (CogPO)\nalgorithm to enhance the reasoning abilities of smaller models by aligning\nthoughts of these models with their cognitive capacities. Comprehensive\nevaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV\nand CogPO, which outperforms other training methods by a large margin.",
      "tldr_zh": "该论文提出了一种名为Critique-Rethink-Verify (CRV) 的新框架，用于训练小型但强大的推理LLM。CRV框架包含多个LLM智能体，分别负责：(i) 根据小型模型的认知能力批判CoT；(ii) 根据批判重新思考和改进这些CoT；(iii) 验证改进结果的正确性。此外，论文还提出了认知偏好优化 (CogPO) 算法，通过将小型模型的思想与其认知能力对齐来增强其推理能力。在具有挑战性的推理基准上的综合评估表明，CRV和CogPO的有效性明显优于其他训练方法。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09802v1",
      "published_date": "2025-04-14 02:03:54 UTC",
      "updated_date": "2025-04-14 02:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:29:19.469868"
    },
    {
      "arxiv_id": "2504.09800v1",
      "title": "Multi-task Federated Learning with Encoder-Decoder Structure: Enabling Collaborative Learning Across Different Tasks",
      "title_zh": "基于编码器-解码器结构的多任务联邦学习：实现跨不同任务的协同学习\n",
      "authors": [
        "Jingxuan Zhou",
        "Weidong Bao",
        "Ji Wang",
        "Dayu Zhang",
        "Xiongtao Zhang",
        "Yaohong Zhang"
      ],
      "abstract": "Federated learning has been extensively studied and applied due to its\nability to ensure data security in distributed environments while building\nbetter models. However, clients participating in federated learning still face\nlimitations, as clients with different structures or tasks cannot participate\nin learning together. In view of this, constructing a federated learning\nframework that allows collaboration between clients with different model\nstructures and performing different tasks, enabling them to share valuable\nknowledge to enhance model efficiency, holds significant practical implications\nfor the widespread application of federated learning. To achieve this goal, we\npropose a multi-task federated learning with encoder-decoder structure (M-Fed).\nSpecifically, given the widespread adoption of the encoder-decoder architecture\nin current models, we leverage this structure to share intra-task knowledge\nthrough traditional federated learning methods and extract general knowledge\nfrom the encoder to achieve cross-task knowledge sharing. The training process\nis similar to traditional federated learning, and we incorporate local decoder\nand global decoder information into the loss function. The local decoder\niteratively updates and gradually approaches the global decoder until\nsufficient cross-task knowledge sharing is achieved. Our method is lightweight\nand modular, demonstrating innovation compared to previous research. It enables\nclients performing different tasks to share general knowledge while maintaining\nthe efficiency of traditional federated learning systems. We conducted\nexperiments on two widely used benchmark datasets to verify the feasibility of\nM-Fed and compared it with traditional methods. The experimental results\ndemonstrate the effectiveness of M-Fed in multi-task federated learning.",
      "tldr_zh": "该论文提出了一种基于编码器-解码器结构的多任务联邦学习框架(M-Fed)，旨在解决联邦学习中不同结构或任务的客户端无法协同学习的问题。M-Fed利用编码器-解码器架构，通过联邦学习方法共享任务内部知识，并从编码器中提取通用知识以实现跨任务知识共享。该方法在损失函数中融入了本地解码器和全局解码器信息，通过迭代更新使本地解码器逐渐逼近全局解码器，从而实现充分的跨任务知识共享。实验结果表明，M-Fed在多任务联邦学习中是有效的，能够在不同任务的客户端之间共享通用知识，同时保持传统联邦学习系统的效率。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09800v1",
      "published_date": "2025-04-14 02:01:39 UTC",
      "updated_date": "2025-04-14 02:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:29:31.521922"
    },
    {
      "arxiv_id": "2504.09797v1",
      "title": "IGL-DT: Iterative Global-Local Feature Learning with Dual-Teacher Semantic Segmentation Framework under Limited Annotation Scheme",
      "title_zh": "IGL-DT：有限标注方案下基于双教师语义分割框架的迭代全局-局部特征学习\n",
      "authors": [
        "Dinh Dai Quan Tran",
        "Hoang-Thien Nguyen. Thanh-Huy Nguyen",
        "Gia-Van To",
        "Tien-Huy Nguyen",
        "Quan Nguyen"
      ],
      "abstract": "Semi-Supervised Semantic Segmentation (SSSS) aims to improve segmentation\naccuracy by leveraging a small set of labeled images alongside a larger pool of\nunlabeled data. Recent advances primarily focus on pseudo-labeling, consistency\nregularization, and co-training strategies. However, existing methods struggle\nto balance global semantic representation with fine-grained local feature\nextraction. To address this challenge, we propose a novel tri-branch\nsemi-supervised segmentation framework incorporating a dual-teacher strategy,\nnamed IGL-DT. Our approach employs SwinUnet for high-level semantic guidance\nthrough Global Context Learning and ResUnet for detailed feature refinement via\nLocal Regional Learning. Additionally, a Discrepancy Learning mechanism\nmitigates over-reliance on a single teacher, promoting adaptive feature\nlearning. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms state-of-the-art approaches, achieving superior segmentation\nperformance across various data regimes.",
      "tldr_zh": "本文提出了一种名为IGL-DT的新型三分支半监督语义分割框架，旨在解决现有方法难以平衡全局语义表示和细粒度局部特征提取的问题。该框架采用双教师策略，利用SwinUnet进行全局上下文学习，提供高层次的语义指导，并使用ResUnet进行局部区域学习，实现细致的特征优化。此外，差异学习机制用于缓解对单一教师的过度依赖，促进自适应特征学习。在基准数据集上的大量实验表明，该方法优于现有技术，在各种数据条件下均实现了卓越的分割性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.09797v1",
      "published_date": "2025-04-14 01:51:29 UTC",
      "updated_date": "2025-04-14 01:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:29:43.483596"
    },
    {
      "arxiv_id": "2504.09795v1",
      "title": "VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents",
      "title_zh": "VDocRAG：基于视觉丰富文档的检索增强生成",
      "authors": [
        "Ryota Tanaka",
        "Taichi Iki",
        "Taku Hasegawa",
        "Kyosuke Nishida",
        "Kuniko Saito",
        "Jun Suzuki"
      ],
      "abstract": "We aim to develop a retrieval-augmented generation (RAG) framework that\nanswers questions over a corpus of visually-rich documents presented in mixed\nmodalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In\nthis paper, we introduce a new RAG framework, VDocRAG, which can directly\nunderstand varied documents and modalities in a unified image format to prevent\nmissing information that occurs by parsing documents to obtain text. To improve\nthe performance, we propose novel self-supervised pre-training tasks that adapt\nlarge vision-language models for retrieval by compressing visual information\ninto dense token representations while aligning them with textual content in\ndocuments. Furthermore, we introduce OpenDocVQA, the first unified collection\nof open-domain document visual question answering datasets, encompassing\ndiverse document types and formats. OpenDocVQA provides a comprehensive\nresource for training and evaluating retrieval and question answering models on\nvisually-rich documents in an open-domain setting. Experiments show that\nVDocRAG substantially outperforms conventional text-based RAG and has strong\ngeneralization capability, highlighting the potential of an effective RAG\nparadigm for real-world documents.",
      "tldr_zh": "该论文提出了一种新的检索增强生成框架VDocRAG，用于处理视觉丰富的文档，例如包含图表、表格的PDF和PPTX。VDocRAG直接以统一的图像格式理解各种文档和模态，避免了传统文本解析的信息丢失。为了提升性能，论文提出了新的自监督预训练任务，将视觉信息压缩成密集token表示，并与文档中的文本内容对齐，从而改进大型视觉语言模型(VLM)的检索能力。此外，论文还构建了首个统一的开放域文档视觉问答数据集OpenDocVQA，用于训练和评估模型。实验结果表明，VDocRAG显著优于传统的基于文本的RAG方法，并具有强大的泛化能力。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by CVPR 2025; project page: https://vdocrag.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.09795v1",
      "published_date": "2025-04-14 01:50:33 UTC",
      "updated_date": "2025-04-14 01:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:29:55.769797"
    },
    {
      "arxiv_id": "2504.09789v1",
      "title": "EquiVDM: Equivariant Video Diffusion Models with Temporally Consistent Noise",
      "title_zh": "EquiVDM：具有时间一致噪声的等变视频扩散模型\n",
      "authors": [
        "Chao Liu",
        "Arash Vahdat"
      ],
      "abstract": "Temporally consistent video-to-video generation is essential for applications\nof video diffusion models in areas such as sim-to-real, style-transfer, video\nupsampling, etc. In this paper, we propose a video diffusion framework that\nleverages temporally consistent noise to generate coherent video frames without\nspecialized modules or additional constraints. We show that the standard\ntraining objective of diffusion models, when applied with temporally consistent\nnoise, encourages the model to be equivariant to spatial transformations in\ninput video and noise. This enables our model to better follow motion patterns\nfrom the input video, producing aligned motion and high-fidelity frames.\nFurthermore, we extend our approach to 3D-consistent video generation by\nattaching noise as textures on 3D meshes, ensuring 3D consistency in\nsim-to-real applications. Experimental results demonstrate that our method\nsurpasses state-of-the-art baselines in motion alignment, 3D consistency, and\nvideo quality while requiring only a few sampling steps in practice.",
      "tldr_zh": "本文提出了一种名为EquiVDM的视频扩散框架，旨在生成时间上一致的视频，这对于sim-to-real、风格迁移和视频超分辨率等应用至关重要。该框架通过利用时间上一致的噪声，在没有专门模块或额外约束的情况下，生成连贯的视频帧。研究表明，当应用于时间一致的噪声时，扩散模型的标准训练目标鼓励模型对输入视频和噪声中的空间变换具有等变性。这使得模型能够更好地遵循输入视频中的运动模式，从而产生对齐的运动和高保真度的帧。此外，该方法还通过将噪声作为纹理附加到3D网格上，扩展到3D一致的视频生成，从而确保sim-to-real应用中的3D一致性。实验结果表明，该方法在运动对齐、3D一致性和视频质量方面超越了最先进的基线，并且在实践中只需要几个采样步骤。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09789v1",
      "published_date": "2025-04-14 01:26:29 UTC",
      "updated_date": "2025-04-14 01:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:30:07.926266"
    },
    {
      "arxiv_id": "2504.09781v1",
      "title": "Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning",
      "title_zh": "推理法庭：结合推理、行动和判断进行多跳推理\n",
      "authors": [
        "Jingtian Wu",
        "Claire Cardie"
      ],
      "abstract": "While large language models (LLMs) have demonstrated strong capabilities in\ntasks like question answering and fact verification, they continue to suffer\nfrom hallucinations and reasoning errors, especially in multi-hop tasks that\nrequire integration of multiple information sources. Current methods address\nthese issues through retrieval-based techniques (grounding reasoning in\nexternal evidence), reasoning-based approaches (enhancing coherence via\nimproved prompting), or hybrid strategies combining both elements. One\nprominent hybrid method, ReAct, has outperformed purely retrieval-based or\nreasoning-based approaches; however, it lacks internal verification of\nintermediate reasoning steps, allowing potential errors to propagate through\ncomplex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a\nnovel framework that extends iterative reasoning-and-retrieval methods, such as\nReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to\nindependently evaluate multiple candidate answers and their associated\nreasoning generated by separate LLM agents. The judge is asked to select the\nanswer that it considers the most factually grounded and logically coherent\nbased on the presented reasoning and evidence, or synthesizes a new answer\nusing available evidence and its pre-trained knowledge if all candidates are\ninadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA,\nMuSiQue) and fact-verification (FEVER) demonstrate that RC consistently\noutperforms state-of-the-art few-shot prompting methods without task-specific\nfine-tuning.",
      "tldr_zh": "本文提出了一种名为Reasoning Court (RC)的新框架，旨在解决大型语言模型(LLMs)在多跳推理任务中存在的幻觉和推理错误问题。RC框架在ReAct等迭代推理和检索方法的基础上，增加了一个专门的LLM裁判，用于独立评估多个候选答案及其相关推理过程。该裁判会根据提供的推理和证据选择最符合事实且逻辑连贯的答案，或者在所有候选答案都不充分、有缺陷或无效时，利用现有证据和预训练知识合成新的答案。在多跳问答(HotpotQA, MuSiQue)和事实验证(FEVER)基准测试中，RC的表现优于当前最先进的few-shot prompting方法，且无需针对特定任务进行微调。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09781v1",
      "published_date": "2025-04-14 00:56:08 UTC",
      "updated_date": "2025-04-14 00:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:30:19.868992"
    },
    {
      "arxiv_id": "2504.09779v1",
      "title": "\"All Roads Lead to ChatGPT\": How Generative AI is Eroding Social Interactions and Student Learning Communities",
      "title_zh": "“条条大路通 ChatGPT”：生成式人工智能如何侵蚀社交互动和学生学习社区\n",
      "authors": [
        "Irene Hou",
        "Owen Man",
        "Kate Hamilton",
        "Srishty Muthusekaran",
        "Jeffin Johnykutty",
        "Leili Zadeh",
        "Stephen MacNeil"
      ],
      "abstract": "The widespread adoption of generative AI is already impacting learning and\nhelp-seeking. While the benefits of generative AI are well-understood, recent\nstudies have also raised concerns about increased potential for cheating and\nnegative impacts on students' metacognition and critical thinking. However, the\npotential impacts on social interactions, peer learning, and classroom dynamics\nare not yet well understood. To investigate these aspects, we conducted 17\nsemi-structured interviews with undergraduate computing students across seven\nR1 universities in North America. Our findings suggest that help-seeking\nrequests are now often mediated by generative AI. For example, students often\nredirected questions from their peers to generative AI instead of providing\nassistance themselves, undermining peer interaction. Students also reported\nfeeling increasingly isolated and demotivated as the social support systems\nthey rely on begin to break down. These findings are concerning given the\nimportant role that social interactions play in students' learning and sense of\nbelonging.",
      "tldr_zh": "该研究调查了生成式AI对学生社交互动和学习社区的影响。通过对北美七所R1大学的计算机专业本科生进行半结构化访谈，发现生成式AI的使用正在改变学生的求助方式，学生倾向于使用AI而非向同伴寻求帮助，从而削弱了同伴互动。研究结果表明，学生们越来越感到孤立和失去动力，因为他们所依赖的社交支持系统开始瓦解。这一发现令人担忧，因为社交互动在学生的学习和归属感中起着重要作用。论文揭示了生成式AI在教育领域中潜在的负面社会影响。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 1 table. To be published in the Proceedings of the 2025\n  Innovation and Technology in Computer Science Education (ITiCSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.09779v1",
      "published_date": "2025-04-14 00:40:58 UTC",
      "updated_date": "2025-04-14 00:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:30:31.667659"
    },
    {
      "arxiv_id": "2504.09777v1",
      "title": "Reasoning without Regret",
      "title_zh": "无悔推理\n",
      "authors": [
        "Tarun Chitra"
      ],
      "abstract": "Chain-of-thought reasoning enables large language models to solve multi-step\ntasks by framing problem solving as sequential decision problems. Outcome-based\nrewards, which provide feedback only on final answers, show impressive success,\nbut face challenges with credit assignment and slow convergence. In contrast,\nprocedure-based rewards offer efficient step-level feedback, but typically\nrequire costly human supervision. We introduce \\emph{Backwards Adaptive Reward\nShaping} (BARS), a no-regret framework that converts sparse outcomes-based\nrewards into effective procedure-based signals. BARS uses sparse rewards\ngenerated from terminal-state priors and cover trees to scale rewards while\npreventing exploitation. With Bellman contraction and $(\\Delta, \\epsilon)$-gap\nrewards, our backward Euler solver achieves $\\epsilon$-accuracy in\n$O\\left((R_{\\max}/\\Delta)\\log(1/\\epsilon)\\right)$ iterations with $O(\\log T)$\ndynamic regret over $T$ rounds. Our analysis, based on generic chaining,\ncontinuous scaling limits, and non-linear Feynman-Kac bounds, connects recent\noutcome-based methods' empirical successes with the benefits of intermediate\nsupervision. Combined, this provides the first rigorous no-regret algorithm for\noutcome reward shaping, providing a theoretical foundation for the empirical\nsuccess of DeepSeek's R1.",
      "tldr_zh": "该论文提出了“后向自适应奖励塑造”(BARS)框架，旨在将稀疏的、基于结果的奖励转化为有效的、基于过程的信号，从而提升大型语言模型在多步骤任务中的链式思维推理能力。BARS利用终端状态先验和覆盖树生成的稀疏奖励来缩放奖励，并防止模型利用漏洞。通过贝尔曼收缩和$(\\Delta, \\epsilon)$-gap奖励，该框架实现了$\\epsilon$-精度的求解，并具有对数级别的动态遗憾。该研究从理论上为结果奖励塑造提供了首个严格的无遗憾算法，并为DeepSeek的R1的经验成功提供了理论基础。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09777v1",
      "published_date": "2025-04-14 00:34:20 UTC",
      "updated_date": "2025-04-14 00:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:30:43.742521"
    },
    {
      "arxiv_id": "2504.09775v1",
      "title": "Understanding and Optimizing Multi-Stage AI Inference Pipelines",
      "title_zh": "理解和优化多阶段AI推理管线\n",
      "authors": [
        "Abhimanyu Rajeshkumar Bambhaniya",
        "Hanjiang Wu",
        "Suvinay Subramanian",
        "Sudarshan Srinivasan",
        "Souvik Kundu",
        "Amir Yazdanbakhsh",
        "Midhilesh Elavazhagan",
        "Madhu Kumar",
        "Tushar Krishna"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has driven the need for\nincreasingly sophisticated inference pipelines and hardware platforms. Modern\nLLM serving extends beyond traditional prefill-decode workflows, incorporating\nmulti-stage processes such as Retrieval Augmented Generation (RAG), key-value\n(KV) cache retrieval, dynamic model routing, and multi step reasoning. These\nstages exhibit diverse computational demands, requiring distributed systems\nthat integrate GPUs, ASICs, CPUs, and memory-centric architectures. However,\nexisting simulators lack the fidelity to model these heterogeneous,\nmulti-engine workflows, limiting their ability to inform architectural\ndecisions.\n  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM\ninference Execution Simulator. HERMES models diverse request stages; including\nRAG, KV retrieval, reasoning, prefill, and decode across complex hardware\nhierarchies. HERMES supports heterogeneous clients executing multiple models\nconcurrently unlike prior frameworks while incorporating advanced batching\nstrategies and multi-level memory hierarchies. By integrating real hardware\ntraces with analytical modeling, HERMES captures critical trade-offs such as\nmemory bandwidth contention, inter-cluster communication latency, and batching\nefficiency in hybrid CPU-accelerator deployments. Through case studies, we\nexplore the impact of reasoning stages on end-to-end latency, optimal batching\nstrategies for hybrid pipelines, and the architectural implications of remote\nKV cache retrieval. HERMES empowers system designers to navigate the evolving\nlandscape of LLM inference, providing actionable insights into optimizing\nhardware-software co-design for next-generation AI workloads.",
      "tldr_zh": "为了应对大型语言模型(LLMs)推理流水线日益复杂的需求，该论文提出了HERMES，一个异构多阶段LLM推理执行模拟器。HERMES能够模拟包括RAG、KV缓存检索、推理、预填充和解码等多个阶段，并支持异构硬件架构。通过结合真实硬件追踪数据和分析建模，HERMES能够捕捉内存带宽竞争、集群间通信延迟和混合CPU-加速器部署中的批处理效率等关键因素。论文通过案例研究，探讨了推理阶段对端到端延迟的影响、混合流水线的最佳批处理策略以及远程KV缓存检索的架构影响。HERMES旨在为系统设计者提供优化下一代AI工作负载的硬件-软件协同设计的可行性方案。\n",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Inference System Design for Multi-Stage AI Inference Pipelines. 13\n  Pages, 15 Figues, 3 Tables. Code can shared at request",
      "pdf_url": "http://arxiv.org/pdf/2504.09775v1",
      "published_date": "2025-04-14 00:29:49 UTC",
      "updated_date": "2025-04-14 00:29:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:30:55.776173"
    },
    {
      "arxiv_id": "2504.09772v1",
      "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
      "title_zh": "双头胜一头：多智能体协同推理的测试时扩展\n",
      "authors": [
        "Can Jin",
        "Hongwu Peng",
        "Qixin Zhang",
        "Yujin Tang",
        "Dimitris N. Metaxas",
        "Tong Che"
      ],
      "abstract": "Multi-agent systems (MAS) built on large language models (LLMs) offer a\npromising path toward solving complex, real-world tasks that single-agent\nsystems often struggle to manage. While recent advancements in test-time\nscaling (TTS) have significantly improved single-agent performance on\nchallenging reasoning tasks, how to effectively scale collaboration and\nreasoning in MAS remains an open question. In this work, we introduce an\nadaptive multi-agent framework designed to enhance collaborative reasoning\nthrough both model-level training and system-level coordination. We construct\nM500, a high-quality dataset containing 500 multi-agent collaborative reasoning\ntraces, and fine-tune Qwen2.5-32B-Instruct on this dataset to produce M1-32B, a\nmodel optimized for multi-agent collaboration. To further enable adaptive\nreasoning, we propose a novel CEO agent that dynamically manages the discussion\nprocess, guiding agent collaboration and adjusting reasoning depth for more\neffective problem-solving. Evaluated in an open-source MAS across a range of\ntasks-including general understanding, mathematical reasoning, and coding-our\nsystem significantly outperforms strong baselines. For instance, M1-32B\nachieves 12% improvement on GPQA-Diamond, 41% on AIME2024, and 10% on\nMBPP-Sanitized, matching the performance of state-of-the-art models like\nDeepSeek-R1 on some tasks. These results highlight the importance of both\nlearned collaboration and adaptive coordination in scaling multi-agent\nreasoning. Code is available at https://github.com/jincan333/MAS-TTS",
      "tldr_zh": "该研究探讨了如何有效扩展多智能体系统(MAS)中的协作和推理能力，借鉴了单智能体测试时扩展(TTS)的思路。作者构建了包含500个高质量多智能体协作推理轨迹的M500数据集，并在此基础上微调了Qwen2.5-32B-Instruct模型，得到专门为多智能体协作优化的M1-32B模型。此外，作者还提出了一个新颖的CEO智能体，用于动态管理讨论过程，指导智能体协作并调整推理深度。实验结果表明，该系统在多个任务上显著优于强大的基线模型，例如在GPQA-Diamond上提升12%，在AIME2024上提升41%，表明学习到的协作和自适应协调在扩展多智能体推理方面的重要性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.09772v1",
      "published_date": "2025-04-14 00:27:45 UTC",
      "updated_date": "2025-04-14 00:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:31:07.906356"
    },
    {
      "arxiv_id": "2504.09763v1",
      "title": "Executable Functional Abstractions: Inferring Generative Programs for Advanced Math Problems",
      "title_zh": "可执行的函数抽象：推断用于解决高级数学问题的生成程序\n",
      "authors": [
        "Zaid Khan",
        "Elias Stengel-Eskin",
        "Archiki Prasad",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "abstract": "Scientists often infer abstract procedures from specific instances of\nproblems and use the abstractions to generate new, related instances. For\nexample, programs encoding the formal rules and properties of a system have\nbeen useful in fields ranging from RL (procedural environments) to physics\n(simulation engines). These programs can be seen as functions which execute to\ndifferent outputs based on their parameterizations (e.g., gridworld\nconfiguration or initial physical conditions). We introduce the term EFA\n(Executable Functional Abstraction) to denote such programs for math problems.\nEFA-like constructs have been shown to be useful for math reasoning as problem\ngenerators for stress-testing models. However, prior work has been limited to\nabstractions for grade-school math (whose simple rules are easy to encode in\nprograms), while generating EFAs for advanced math has thus far required human\nengineering. We explore the automatic construction of EFAs for advanced math\nproblems. We operationalize the task of automatically constructing EFAs as a\nprogram synthesis task, and develop EFAGen, which conditions an LLM on a seed\nmath problem and its step-by-step solution to generate candidate EFA programs\nthat are faithful to the generalized problem and solution class underlying the\nseed problem. Furthermore, we formalize properties any valid EFA must possess\nin terms of executable unit tests, and show how the tests can be used as\nverifiable rewards to train LLMs to become better writers of EFAs. We\ndemonstrate that EFAs constructed by EFAGen behave rationally by remaining\nfaithful to seed problems, produce learnable problem variations, and that\nEFAGen can infer EFAs across multiple diverse sources of competition-level math\nproblems. Finally, we show downstream uses of model-written EFAs e.g. finding\nproblem variations that are harder or easier for a learner to solve, as well as\ndata generation.",
      "tldr_zh": "本文提出了“可执行函数抽象”（Executable Functional Abstractions, EFA）的概念，即用于高级数学问题的生成程序，这些程序可以根据参数化执行并产生不同的输出。为了自动构建EFA，作者提出了EFAGen，该方法利用LLM以种子数学问题及其逐步解决方案为条件，生成候选EFA程序。这些程序需忠实于种子问题背后的广义问题和解决方案类别。此外，论文形式化了有效EFA必须具备的性质，并将其转化为可执行的单元测试，用作可验证的奖励来训练LLM，使其更好地编写EFA。实验证明，EFAGen构建的EFA能够忠实于种子问题，生成可学习的问题变体，并能推断出多个不同来源的竞赛级数学问题的EFA。最后，论文展示了模型编写的EFA的下游应用，例如发现对学习者来说更难或更容易解决的问题变体，以及数据生成。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Page: https://zaidkhan.me/EFAGen/",
      "pdf_url": "http://arxiv.org/pdf/2504.09763v1",
      "published_date": "2025-04-14 00:06:48 UTC",
      "updated_date": "2025-04-14 00:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:31:20.271123"
    },
    {
      "arxiv_id": "2504.09762v1",
      "title": "(How) Do reasoning models reason?",
      "title_zh": "（如何）推理模型进行推理？\n",
      "authors": [
        "Subbarao Kambhampati",
        "Kaya Stechly",
        "Karthik Valmeekam"
      ],
      "abstract": "We will provide a broad unifying perspective on the recent breed of Large\nReasoning Models (LRMs) such as OpenAI o1 and DeepSeek R1, including their\npromise, sources of power, misconceptions and limitations.",
      "tldr_zh": "本文对近期涌现的大型推理模型(Large Reasoning Models, LRMs)，如OpenAI o1和DeepSeek R1，进行了全面的统一视角分析。文章探讨了这些模型的潜力、优势来源、常见的误解以及局限性。旨在为理解和进一步发展LRMs提供指导。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages (A version appears in The Annals of New York Academy of\n  Sciences)",
      "pdf_url": "http://arxiv.org/pdf/2504.09762v1",
      "published_date": "2025-04-14 00:03:34 UTC",
      "updated_date": "2025-04-14 00:03:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-16T02:31:31.226265"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 95,
  "processed_papers_count": 95,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-04-16T02:33:33.872592"
}