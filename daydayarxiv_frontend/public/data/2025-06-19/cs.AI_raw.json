[
  {
    "arxiv_id": "2506.16654v1",
    "title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Charilaos Kanatsoulis",
      "Shenyang Huang",
      "Jure Leskovec"
    ],
    "abstract": "Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16654v1",
    "published_date": "2025-06-19 23:51:38 UTC",
    "updated_date": "2025-06-19 23:51:38 UTC"
  },
  {
    "arxiv_id": "2506.16653v1",
    "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape",
    "authors": [
      "Vladislav Belozerov",
      "Peter J Barclay",
      "Askhan Sami"
    ],
    "abstract": "Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16653v1",
    "published_date": "2025-06-19 23:43:54 UTC",
    "updated_date": "2025-06-19 23:43:54 UTC"
  },
  {
    "arxiv_id": "2506.16650v1",
    "title": "SemAgent: A Semantics Aware Program Repair Agent",
    "authors": [
      "Anvith Pabba",
      "Alex Mathai",
      "Anindya Chakraborty",
      "Baishakhi Ray"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in downstream software engineering tasks such as Automated Program Repair (APR). In particular, there has been a lot of research on repository-level issue-resolution benchmarks such as SWE-Bench. Although there has been significant progress on this topic, we notice that in the process of solving such issues, existing agentic systems tend to hyper-localize on immediately suspicious lines of code and fix them in isolation, without a deeper understanding of the issue semantics, code semantics, or execution semantics. Consequently, many existing systems generate patches that overfit to the user issue, even when a more general fix is preferable. To address this limitation, we introduce SemAgent, a novel workflow-based procedure that leverages issue, code, and execution semantics to generate patches that are complete - identifying and fixing all lines relevant to the issue. We achieve this through a novel pipeline that (a) leverages execution semantics to retrieve relevant context, (b) comprehends issue-semantics via generalized abstraction, (c) isolates code-semantics within the context of this abstraction, and (d) leverages this understanding in a two-stage architecture: a repair stage that proposes fine-grained fixes, followed by a reviewer stage that filters relevant fixes based on the inferred issue-semantics. Our evaluations show that our methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark beating all other workflow-based approaches, and an absolute improvement of 7.66% compared to our baseline, which lacks such deep semantic understanding. We note that our approach performs particularly well on issues requiring multi-line reasoning (and editing) and edge-case handling, suggesting that incorporating issue and code semantics into APR pipelines can lead to robust and semantically consistent repairs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16650v1",
    "published_date": "2025-06-19 23:27:58 UTC",
    "updated_date": "2025-06-19 23:27:58 UTC"
  },
  {
    "arxiv_id": "2506.16640v3",
    "title": "Long-Context Generalization with Sparse Attention",
    "authors": [
      "Pavlo Vasylenko",
      "Hugo Pitorro",
      "André F. T. Martins",
      "Marcos Treviso"
    ],
    "abstract": "Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that dynamically sparse attention mechanisms using $α$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $α$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Our empirical evaluation on synthetic tasks and language modeling demonstrates that ASEntmax substantially outperforms softmax, scalable softmax, and fixed-temperature $α$-entmax baselines, achieving up to 1000$\\times$ length extrapolation on synthetic benchmarks and superior long-context generalization on language modeling while preserving short-context performance, including better perplexity trends and higher retrieval accuracies at 8$\\times$ training length.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16640v3",
    "published_date": "2025-06-19 22:43:25 UTC",
    "updated_date": "2025-09-27 01:15:13 UTC"
  },
  {
    "arxiv_id": "2506.16636v1",
    "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation",
    "authors": [
      "Rex Shen",
      "Lu Tian"
    ],
    "abstract": "Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating the true data distribution.\n  To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles.\n  Our procedure satisfies local $(ε, δ)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16636v1",
    "published_date": "2025-06-19 22:22:57 UTC",
    "updated_date": "2025-06-19 22:22:57 UTC"
  },
  {
    "arxiv_id": "2506.16633v2",
    "title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View",
    "authors": [
      "Fenghua Cheng",
      "Jinxiang Wang",
      "Sen Wang",
      "Zi Huang",
      "Xue Li"
    ],
    "abstract": "Multimodal reasoning is a process of understanding, integrating and inferring information across different data modalities. It has recently attracted surging academic attention as a benchmark for Artificial Intelligence (AI). Although there are various tasks for evaluating multimodal reasoning ability, they still have limitations. Lack of reasoning on hierarchical visual clues at different levels of granularity, e.g., local details and global context, is of little discussion, despite its frequent involvement in real scenarios. To bridge the gap, we introduce a novel and challenging task for multimodal reasoning, namely GeoGuess. Given a street view image, the task is to identify its location and provide a detailed explanation. A system that succeeds in GeoGuess should be able to detect tiny visual clues, perceive the broader landscape, and associate with vast geographic knowledge. Therefore, GeoGuess would require the ability to reason between hierarchical visual information and geographic knowledge. In this work, we establish a benchmark for GeoGuess by introducing a specially curated dataset GeoExplain which consists of panoramas-geocoordinates-explanation tuples. Additionally, we present a multimodal and multilevel reasoning method, namely SightSense which can make prediction and generate comprehensive explanation based on hierarchy of visual information and external knowledge. Our analysis and experiments demonstrate their outstanding performance in GeoGuess.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated version",
    "pdf_url": "https://arxiv.org/pdf/2506.16633v2",
    "published_date": "2025-06-19 22:19:31 UTC",
    "updated_date": "2025-09-15 03:46:51 UTC"
  },
  {
    "arxiv_id": "2506.16623v1",
    "title": "History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation",
    "authors": [
      "Mobin Habibpour",
      "Fatemeh Afghah"
    ],
    "abstract": "Object Goal Navigation (ObjectNav) challenges robots to find objects in unseen environments, demanding sophisticated reasoning. While Vision-Language Models (VLMs) show potential, current ObjectNav methods often employ them superficially, primarily using vision-language embeddings for object-scene similarity checks rather than leveraging deeper reasoning. This limits contextual understanding and leads to practical issues like repetitive navigation behaviors. This paper introduces a novel zero-shot ObjectNav framework that pioneers the use of dynamic, history-aware prompting to more deeply integrate VLM reasoning into frontier-based exploration. Our core innovation lies in providing the VLM with action history context, enabling it to generate semantic guidance scores for navigation actions while actively avoiding decision loops. We also introduce a VLM-assisted waypoint generation mechanism for refining the final approach to detected objects. Evaluated on the HM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and 24.8% Success weighted by Path Length (SPL). These results are comparable to state-of-the-art zero-shot methods, demonstrating the significant potential of our history-augmented VLM prompting strategy for more robust and context-aware robotic navigation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16623v1",
    "published_date": "2025-06-19 21:50:16 UTC",
    "updated_date": "2025-06-19 21:50:16 UTC"
  },
  {
    "arxiv_id": "2506.16622v2",
    "title": "Modeling Public Perceptions of Science in Media",
    "authors": [
      "Jiaxin Pei",
      "Dustin Wright",
      "Isabelle Augenstein",
      "David Jurgens"
    ],
    "abstract": "Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16622v2",
    "published_date": "2025-06-19 21:49:28 UTC",
    "updated_date": "2025-07-22 18:13:52 UTC"
  },
  {
    "arxiv_id": "2506.16617v1",
    "title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring",
    "authors": [
      "Soobin Chae",
      "Suhwan Lee",
      "Hanna Hauptmann",
      "Hajo A. Reijers",
      "Xixi Lu"
    ],
    "abstract": "Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at CAiSE'25",
    "pdf_url": "https://arxiv.org/pdf/2506.16617v1",
    "published_date": "2025-06-19 21:30:28 UTC",
    "updated_date": "2025-06-19 21:30:28 UTC"
  },
  {
    "arxiv_id": "2506.16608v1",
    "title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces",
    "authors": [
      "Jiamin He",
      "A. Rupam Mahmood",
      "Martha White"
    ],
    "abstract": "We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16608v1",
    "published_date": "2025-06-19 21:19:19 UTC",
    "updated_date": "2025-06-19 21:19:19 UTC"
  },
  {
    "arxiv_id": "2506.16600v2",
    "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE",
    "authors": [
      "Khiem Le",
      "Tuan Tran",
      "Ting Hua",
      "Nitesh V. Chawla"
    ],
    "abstract": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16600v2",
    "published_date": "2025-06-19 21:02:19 UTC",
    "updated_date": "2025-07-14 21:49:53 UTC"
  },
  {
    "arxiv_id": "2506.16596v3",
    "title": "A Community-driven vision for a new Knowledge Resource for AI",
    "authors": [
      "Vinay K Chaudhri",
      "Chaitan Baru",
      "Brandon Bennett",
      "Mehul Bhatt",
      "Darion Cassel",
      "Anthony G Cohn",
      "Rina Dechter",
      "Esra Erdem",
      "Dave Ferrucci",
      "Ken Forbus",
      "Gregory Gelfond",
      "Michael Genesereth",
      "Andrew S. Gordon",
      "Benjamin Grosof",
      "Gopal Gupta",
      "Jim Hendler",
      "Sharat Israni",
      "Tyler R. Josephson",
      "Patrick Kyllonen",
      "Yuliya Lierler",
      "Vladimir Lifschitz",
      "Clifton McFate",
      "Hande K. McGinty",
      "Leora Morgenstern",
      "Alessandro Oltramari",
      "Praveen Paritosh",
      "Dan Roth",
      "Blake Shepard",
      "Cogan Shimzu",
      "Denny Vrandečić",
      "Mark Whiting",
      "Michael Witbrock"
    ],
    "abstract": "The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.16596v3",
    "published_date": "2025-06-19 20:51:28 UTC",
    "updated_date": "2025-10-12 01:19:52 UTC"
  },
  {
    "arxiv_id": "2506.16592v1",
    "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images",
    "authors": [
      "Muhammad Azeem Aslam",
      "Asim Naveed",
      "Nisar Ahmed"
    ],
    "abstract": "Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16592v1",
    "published_date": "2025-06-19 20:32:54 UTC",
    "updated_date": "2025-06-19 20:32:54 UTC"
  },
  {
    "arxiv_id": "2506.16590v1",
    "title": "Energy-Based Transfer for Reinforcement Learning",
    "authors": [
      "Zeyun Deng",
      "Jasorsi Ghosh",
      "Fiona Xie",
      "Yuzhe Lu",
      "Katia Sycara",
      "Joseph Campbell"
    ],
    "abstract": "Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16590v1",
    "published_date": "2025-06-19 20:25:52 UTC",
    "updated_date": "2025-06-19 20:25:52 UTC"
  },
  {
    "arxiv_id": "2506.16589v1",
    "title": "Spatially-Aware Evaluation of Segmentation Uncertainty",
    "authors": [
      "Tal Zeevi",
      "Eléonore V. Lieffrig",
      "Lawrence H. Staib",
      "John A. Onofrey"
    ],
    "abstract": "Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.PF",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Presented at the 4th Workshop on Uncertainty Quantification for Computer Vision (CVPR 2025), June 11, 2025. This version is not included in the official proceedings",
    "pdf_url": "https://arxiv.org/pdf/2506.16589v1",
    "published_date": "2025-06-19 20:24:57 UTC",
    "updated_date": "2025-06-19 20:24:57 UTC"
  },
  {
    "arxiv_id": "2506.16586v1",
    "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions",
    "authors": [
      "Ihor Pysmennyi",
      "Roman Kyslyi",
      "Kyrylo Kleshch"
    ],
    "abstract": "Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, \"black box\" nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI's transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.16586v1",
    "published_date": "2025-06-19 20:22:47 UTC",
    "updated_date": "2025-06-19 20:22:47 UTC"
  },
  {
    "arxiv_id": "2506.16584v1",
    "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework",
    "authors": [
      "Nadav Kunievsky",
      "James A. Evans"
    ],
    "abstract": "Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16584v1",
    "published_date": "2025-06-19 20:19:18 UTC",
    "updated_date": "2025-06-19 20:19:18 UTC"
  },
  {
    "arxiv_id": "2506.16575v1",
    "title": "Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System",
    "authors": [
      "Mustafa Akben",
      "Aaron Satko"
    ],
    "abstract": "Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for HICSS 2025 (Hawaii International Conference on System Sciences); under review",
    "pdf_url": "https://arxiv.org/pdf/2506.16575v1",
    "published_date": "2025-06-19 20:01:12 UTC",
    "updated_date": "2025-06-19 20:01:12 UTC"
  },
  {
    "arxiv_id": "2506.16565v1",
    "title": "Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control",
    "authors": [
      "Yuxin Chen",
      "Jianglan Wei",
      "Chenfeng Xu",
      "Boyi Li",
      "Masayoshi Tomizuka",
      "Andrea Bajcsy",
      "Ran Tian"
    ],
    "abstract": "World models enable robots to \"imagine\" future observations given current observations and planned actions, and have been increasingly adopted as generalized dynamics models to facilitate robot learning. Despite their promise, these models remain brittle when encountering novel visual distractors such as objects and background elements rarely seen during training. Specifically, novel distractors can corrupt action outcome predictions, causing downstream failures when robots rely on the world model imaginations for planning or action verification. In this work, we propose Reimagination with Observation Intervention (ReOI), a simple yet effective test-time strategy that enables world models to predict more reliable action outcomes in open-world scenarios where novel and unanticipated visual distractors are inevitable. Given the current robot observation, ReOI first detects visual distractors by identifying which elements of the scene degrade in physically implausible ways during world model prediction. Then, it modifies the current observation to remove these distractors and bring the observation closer to the training distribution. Finally, ReOI \"reimagines\" future outcomes with the modified observation and reintroduces the distractors post-hoc to preserve visual consistency for downstream planning and verification. We validate our approach on a suite of robotic manipulation tasks in the context of action verification, where the verifier needs to select desired action plans based on predictions from a world model. Our results show that ReOI is robust to both in-distribution and out-of-distribution visual distractors. Notably, it improves task success rates by up to 3x in the presence of novel distractors, significantly outperforming action verification that relies on world model predictions without imagination interventions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16565v1",
    "published_date": "2025-06-19 19:41:29 UTC",
    "updated_date": "2025-06-19 19:41:29 UTC"
  },
  {
    "arxiv_id": "2506.16563v1",
    "title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach",
    "authors": [
      "Keyhan Najafian",
      "Farhad Maleki",
      "Lingling Jin",
      "Ian Stavness"
    ],
    "abstract": "Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16563v1",
    "published_date": "2025-06-19 19:38:01 UTC",
    "updated_date": "2025-06-19 19:38:01 UTC"
  },
  {
    "arxiv_id": "2506.16553v2",
    "title": "One Sample is Enough to Make Conformal Prediction Robust",
    "authors": [
      "Soroush H. Zargarbashi",
      "Mohammad Sadegh Akhondzadeh",
      "Aleksandar Bojchevski"
    ],
    "abstract": "For any black-box model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends the guarantee to the worst case noise up to a pre-defined magnitude. For RCP, a well-established approach is to use randomized smoothing since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, smoothing-based robustness requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a single forward pass on a randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. 100) passes per input. Our key insight is to certify the conformal procedure itself rather than individual conformity scores. Our approach is agnostic to the task (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in NeurIPS 2025 Conference",
    "pdf_url": "https://arxiv.org/pdf/2506.16553v2",
    "published_date": "2025-06-19 19:14:25 UTC",
    "updated_date": "2025-12-08 08:35:28 UTC"
  },
  {
    "arxiv_id": "2506.16546v1",
    "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios",
    "authors": [
      "Liyang Yu",
      "Tianyi Wang",
      "Junfeng Jiao",
      "Fengwu Shan",
      "Hongqing Chu",
      "Bingzhao Gao"
    ],
    "abstract": "In complex real-world traffic environments, autonomous vehicles (AVs) need to interact with other traffic participants while making real-time and safety-critical decisions accordingly. The unpredictability of human behaviors poses significant challenges, particularly in dynamic scenarios, such as multi-lane highways and unsignalized T-intersections. To address this gap, we design a bi-level interaction decision-making algorithm (BIDA) that integrates interactive Monte Carlo tree search (MCTS) with deep reinforcement learning (DRL), aiming to enhance interaction rationality, efficiency and safety of AVs in dynamic key traffic scenarios. Specifically, we adopt three types of DRL algorithms to construct a reliable value network and policy network, which guide the online deduction process of interactive MCTS by assisting in value update and node selection. Then, a dynamic trajectory planner and a trajectory tracking controller are designed and implemented in CARLA to ensure smooth execution of planned maneuvers. Experimental evaluations demonstrate that our BIDA not only enhances interactive deduction and reduces computational costs, but also outperforms other latest benchmarks, which exhibits superior safety, efficiency and interaction rationality under varying traffic conditions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 3 figures, 4 tables, accepted for IEEE Intelligent Vehicles (IV) Symposium 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16546v1",
    "published_date": "2025-06-19 19:03:40 UTC",
    "updated_date": "2025-06-19 19:03:40 UTC"
  },
  {
    "arxiv_id": "2506.21604v1",
    "title": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding",
    "authors": [
      "Varun Mannam",
      "Fang Wang",
      "Xin Chen"
    ],
    "abstract": "Current evaluation frameworks for multimodal generative AI struggle to establish trustworthiness, hindering enterprise adoption where reliability is paramount. We introduce a systematic, quantitative benchmarking framework to measure the trustworthiness of progressively integrating cross-modal inputs such as text, images, captions, and OCR within VisualRAG systems for enterprise document intelligence. Our approach establishes quantitative relationships between technical metrics and user-centric trust measures. Evaluation reveals that optimal modality weighting with weights of 30% text, 15% image, 25% caption, and 30% OCR improves performance by 57.3% over text-only baselines while maintaining computational efficiency. We provide comparative assessments of foundation models, demonstrating their differential impact on trustworthiness in caption generation and OCR extraction-a vital consideration for reliable enterprise AI. This work advances responsible AI deployment by providing a rigorous framework for quantifying and enhancing trustworthiness in multimodal RAG for critical enterprise applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Conference: KDD conference workshop: https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/",
    "pdf_url": "https://arxiv.org/pdf/2506.21604v1",
    "published_date": "2025-06-19 18:05:00 UTC",
    "updated_date": "2025-06-19 18:05:00 UTC"
  },
  {
    "arxiv_id": "2506.16506v3",
    "title": "Subspace-Boosted Model Merging",
    "authors": [
      "Ronald Skorobogat",
      "Karsten Roth",
      "Mariana-Iuliana Georgescu"
    ],
    "abstract": "Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we empirically and theoretically analyze this limitation, proving that for Task Arithmetic-based methods, as more experts are merged, the common information dominates the task-specific information, leading to inevitable rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 experts by large margins of more than 10% when evaluated on both vision and language benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to quantify task similarity, offering a new interpretable perspective on model merging. Code and models are available at https://github.com/ronskoro/Subspace-Boosting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages (main + supp)",
    "pdf_url": "https://arxiv.org/pdf/2506.16506v3",
    "published_date": "2025-06-19 17:59:29 UTC",
    "updated_date": "2025-12-21 21:28:11 UTC"
  },
  {
    "arxiv_id": "2506.16504v1",
    "title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details",
    "authors": [
      "Zeqiang Lai",
      "Yunfei Zhao",
      "Haolin Liu",
      "Zibo Zhao",
      "Qingxiang Lin",
      "Huiwen Shi",
      "Xianghui Yang",
      "Mingxin Yang",
      "Shuhui Yang",
      "Yifei Feng",
      "Sheng Zhang",
      "Xin Huang",
      "Di Luo",
      "Fan Yang",
      "Fang Yang",
      "Lifu Wang",
      "Sicong Liu",
      "Yixuan Tang",
      "Yulin Cai",
      "Zebin He",
      "Tian Liu",
      "Yuhong Liu",
      "Jie Jiang",
      "Linus",
      "Jingwei Huang",
      "Chunchao Guo"
    ],
    "abstract": "In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical report",
    "pdf_url": "https://arxiv.org/pdf/2506.16504v1",
    "published_date": "2025-06-19 17:57:40 UTC",
    "updated_date": "2025-06-19 17:57:40 UTC"
  },
  {
    "arxiv_id": "2506.16502v1",
    "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples",
    "authors": [
      "Soumya Suvra Ghosal",
      "Vaibhav Singh",
      "Akash Ghosh",
      "Soumyabrata Pal",
      "Subhadip Baidya",
      "Sriparna Saha",
      "Dinesh Manocha"
    ],
    "abstract": "Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16502v1",
    "published_date": "2025-06-19 17:56:16 UTC",
    "updated_date": "2025-06-19 17:56:16 UTC"
  },
  {
    "arxiv_id": "2506.16499v1",
    "title": "ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning",
    "authors": [
      "Zexi Liu",
      "Yuzhu Cai",
      "Xinyu Zhu",
      "Yujie Zheng",
      "Runkun Chen",
      "Ying Wen",
      "Yanfeng Wang",
      "Weinan E",
      "Siheng Chen"
    ],
    "abstract": "As AI capabilities advance toward and potentially beyond human-level performance, a natural transition emerges where AI-driven development becomes more efficient than human-centric approaches. A promising pathway toward this transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate and optimize the design, training, and deployment of AI systems themselves. While LLM-based agents have shown the potential to realize AI4AI, they are often unable to fully leverage the experience accumulated by agents during the exploration of solutions in the reasoning process, leading to inefficiencies and suboptimal performance. To address this limitation, we propose ML-Master, a novel AI4AI agent that seamlessly integrates exploration and reasoning by employing a selectively scoped memory mechanism. This approach allows ML-Master to efficiently combine diverse insights from parallel solution trajectories with analytical reasoning, guiding further exploration without overwhelming the agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it achieves a 29.3% average medal rate, significantly surpassing existing methods, particularly in medium-complexity tasks, while accomplishing this superior performance within a strict 12-hour time constraint-half the 24-hour limit used by previous baselines. These results demonstrate ML-Master's potential as a powerful tool for advancing AI4AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16499v1",
    "published_date": "2025-06-19 17:53:28 UTC",
    "updated_date": "2025-06-19 17:53:28 UTC"
  },
  {
    "arxiv_id": "2506.16497v1",
    "title": "Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors",
    "authors": [
      "Riccardo Ziglio",
      "Cecilia Pasquini",
      "Silvio Ranise"
    ],
    "abstract": "Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances\n  in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames\n  by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the\n  effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected\n  one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results\n  confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant\n  difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection\n  strategies to deal with such artifacts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures, workshop paper",
    "pdf_url": "https://arxiv.org/pdf/2506.16497v1",
    "published_date": "2025-06-19 17:51:11 UTC",
    "updated_date": "2025-06-19 17:51:11 UTC"
  },
  {
    "arxiv_id": "2506.16493v1",
    "title": "Grounding Language Models with Semantic Digital Twins for Robotic Planning",
    "authors": [
      "Mehreen Naeem",
      "Andrew Melnik",
      "Michael Beetz"
    ],
    "abstract": "We introduce a novel framework that integrates Semantic Digital Twins (SDTs) with Large Language Models (LLMs) to enable adaptive and goal-driven robotic task execution in dynamic environments. The system decomposes natural language instructions into structured action triplets, which are grounded in contextual environmental data provided by the SDT. This semantic grounding allows the robot to interpret object affordances and interaction rules, enabling action planning and real-time adaptability. In case of execution failures, the LLM utilizes error feedback and SDT insights to generate recovery strategies and iteratively revise the action plan. We evaluate our approach using tasks from the ALFRED benchmark, demonstrating robust performance across various household scenarios. The proposed framework effectively combines high-level reasoning with semantic environment understanding, achieving reliable task completion in the face of uncertainty and failure.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16493v1",
    "published_date": "2025-06-19 17:38:00 UTC",
    "updated_date": "2025-06-19 17:38:00 UTC"
  },
  {
    "arxiv_id": "2506.17348v1",
    "title": "Advanced Game-Theoretic Frameworks for Multi-Agent AI Challenges: A 2025 Outlook",
    "authors": [
      "Pavel Malinovskiy"
    ],
    "abstract": "This paper presents a substantially reworked examination of how advanced game-theoretic paradigms can serve as a foundation for the next-generation challenges in Artificial Intelligence (AI), forecasted to arrive in or around 2025. Our focus extends beyond traditional models by incorporating dynamic coalition formation, language-based utilities, sabotage risks, and partial observability. We provide a set of mathematical formalisms, simulations, and coding schemes that illustrate how multi-agent AI systems may adapt and negotiate in complex environments. Key elements include repeated games, Bayesian updates for adversarial detection, and moral framing within payoff structures. This work aims to equip AI researchers with robust theoretical tools for aligning strategic interaction in uncertain, partially adversarial contexts.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "43 pages, 7 figures, 30 references",
    "pdf_url": "https://arxiv.org/pdf/2506.17348v1",
    "published_date": "2025-06-19 17:26:03 UTC",
    "updated_date": "2025-06-19 17:26:03 UTC"
  },
  {
    "arxiv_id": "2506.16476v1",
    "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection",
    "authors": [
      "Saad Almohaimeed",
      "Saleh Almohaimeed",
      "Damla Turgut",
      "Ladislau Bölöni"
    ],
    "abstract": "Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16476v1",
    "published_date": "2025-06-19 17:23:08 UTC",
    "updated_date": "2025-06-19 17:23:08 UTC"
  },
  {
    "arxiv_id": "2506.16475v2",
    "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining",
    "authors": [
      "Yaru Niu",
      "Yunzhe Zhang",
      "Mingyang Yu",
      "Changyi Lin",
      "Chenhao Li",
      "Yikai Wang",
      "Yuxiang Yang",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Zhenzhen Li",
      "Jonathan Francis",
      "Bingqing Chen",
      "Jie Tan",
      "Ding Zhao"
    ],
    "abstract": "Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16475v2",
    "published_date": "2025-06-19 17:22:52 UTC",
    "updated_date": "2025-07-07 17:59:32 UTC"
  },
  {
    "arxiv_id": "2506.16473v1",
    "title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support",
    "authors": [
      "Sophie Chiang",
      "Guy Laban",
      "Hatice Gunes"
    ],
    "abstract": "As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16473v1",
    "published_date": "2025-06-19 17:20:30 UTC",
    "updated_date": "2025-06-19 17:20:30 UTC"
  },
  {
    "arxiv_id": "2506.17347v2",
    "title": "Distinguishing Predictive and Generative AI in Regulation",
    "authors": [
      "Jennifer Wang",
      "Andrew Selbst",
      "Solon Barocas",
      "Suresh Venkatasubramanian"
    ],
    "abstract": "Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with predictive AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of generative AI, however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI. In this paper, we identify four distinct aspects of generative AI that call for meaningfully different policy responses. These are the generality and adaptability of generative AI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the generative AI value chain. In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by generative AI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern generative AI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17347v2",
    "published_date": "2025-06-19 17:17:55 UTC",
    "updated_date": "2025-07-02 22:50:44 UTC"
  },
  {
    "arxiv_id": "2506.16471v2",
    "title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities",
    "authors": [
      "Tara Akhound-Sadegh",
      "Jungyoon Lee",
      "Avishek Joey Bose",
      "Valentin De Bortoli",
      "Arnaud Doucet",
      "Michael M. Bronstein",
      "Dominique Beaini",
      "Siamak Ravanbakhsh",
      "Kirill Neklyudov",
      "Alexander Tong"
    ],
    "abstract": "Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: https://github.com/taraak/pita",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at NeurIPS 2025 (Spotlight). Code is available at https://github.com/taraak/pita",
    "pdf_url": "https://arxiv.org/pdf/2506.16471v2",
    "published_date": "2025-06-19 17:14:22 UTC",
    "updated_date": "2025-11-06 21:29:14 UTC"
  },
  {
    "arxiv_id": "2506.17346v1",
    "title": "A Novel Multi-layer Task-centric and Data Quality Framework for Autonomous Driving",
    "authors": [
      "Yuhan Zhou",
      "Haihua Chen",
      "Kewei Sha"
    ],
    "abstract": "The next-generation autonomous vehicles (AVs), embedded with frequent real-time decision-making, will rely heavily on a large volume of multisource and multimodal data. In real-world settings, the data quality (DQ) of different sources and modalities usually varies due to unexpected environmental factors or sensor issues. However, both researchers and practitioners in the AV field overwhelmingly concentrate on models/algorithms while undervaluing the DQ. To fulfill the needs of the next-generation AVs with guarantees of functionality, efficiency, and trustworthiness, this paper proposes a novel task-centric and data quality vase framework which consists of five layers: data layer, DQ layer, task layer, application layer, and goal layer. The proposed framework aims to map DQ with task requirements and performance goals. To illustrate, a case study investigating redundancy on the nuScenes dataset proves that partially removing redundancy on multisource image data could improve YOLOv8 object detection task performance. Analysis on multimodal data of image and LiDAR further presents existing redundancy DQ issues. This paper opens up a range of critical but unexplored challenges at the intersection of DQ, task orchestration, and performance-oriented system development in AVs. It is expected to guide the AV community toward building more adaptive, explainable, and resilient AVs that respond intelligently to dynamic environments and heterogeneous data streams. Code, data, and implementation details are publicly available at: https://anonymous.4open.science/r/dq4av-framework/README.md.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17346v1",
    "published_date": "2025-06-19 17:05:50 UTC",
    "updated_date": "2025-06-19 17:05:50 UTC"
  },
  {
    "arxiv_id": "2506.16456v1",
    "title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation",
    "authors": [
      "Jun Qi",
      "Chen-Yu Liu",
      "Sabato Marco Siniscalchi",
      "Chao-Han Huck Yang",
      "Min-Hsiu Hsieh"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under Review",
    "pdf_url": "https://arxiv.org/pdf/2506.16456v1",
    "published_date": "2025-06-19 16:46:23 UTC",
    "updated_date": "2025-06-19 16:46:23 UTC"
  },
  {
    "arxiv_id": "2506.16448v1",
    "title": "Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach",
    "authors": [
      "Tri Duc Ly",
      "Gia H. Ngo"
    ],
    "abstract": "EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.16448v1",
    "published_date": "2025-06-19 16:33:31 UTC",
    "updated_date": "2025-06-19 16:33:31 UTC"
  },
  {
    "arxiv_id": "2506.16445v1",
    "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation",
    "authors": [
      "Haotian Xia",
      "Hao Peng",
      "Yunjia Qi",
      "Xiaozhi Wang",
      "Bin Xu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16445v1",
    "published_date": "2025-06-19 16:26:58 UTC",
    "updated_date": "2025-06-19 16:26:58 UTC"
  },
  {
    "arxiv_id": "2506.16443v1",
    "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks",
    "authors": [
      "Jonas R. Naujoks",
      "Aleksander Krasowski",
      "Moritz Weckbecker",
      "Galip Ümit Yolcu",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek",
      "René P. Klausen"
    ],
    "abstract": "Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "This article was presented at \"The 3rd World Conference on eXplainable Artificial Intelligence\" (2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.16443v1",
    "published_date": "2025-06-19 16:21:14 UTC",
    "updated_date": "2025-06-19 16:21:14 UTC"
  },
  {
    "arxiv_id": "2506.16440v1",
    "title": "Evaluating the Use of LLMs for Documentation to Code Traceability",
    "authors": [
      "Ebube Alor",
      "SayedHassan Khatoonabadi",
      "Emad Shihab"
    ],
    "abstract": "Large Language Models (LLMs) offer new potential for automating documentation-to-code traceability, yet their capabilities remain underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5 Sonnet, GPT-4o, and o3-mini) in establishing trace links between various software documentation (including API references and user guides) and source code. We create two novel datasets from two open-source projects (Unity Catalog and Crawl4AI). Through systematic experiments, we assess three key capabilities: (1) trace link identification accuracy, (2) relationship explanation quality, and (3) multi-step chain reconstruction. Results show that the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two datasets, substantially outperforming our baselines (TF-IDF, BM25, and CodeBERT). While fully correct relationship explanations range from 42.9% to 71.1%, partial accuracy exceeds 97%, indicating that fundamental connections are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy but vary in capturing precise intermediate links. Error analysis reveals that many false positives stem from naming-based assumptions, phantom links, or overgeneralization of architectural patterns. We demonstrate that task-framing, such as a one-to-many matching strategy, is critical for performance. These findings position LLMs as powerful assistants for trace discovery, but their limitations could necessitate human-in-the-loop tool design and highlight specific error patterns for future research.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16440v1",
    "published_date": "2025-06-19 16:18:53 UTC",
    "updated_date": "2025-06-19 16:18:53 UTC"
  },
  {
    "arxiv_id": "2506.16429v1",
    "title": "Agentic Personalisation of Cross-Channel Marketing Experiences",
    "authors": [
      "Sami Abboud",
      "Eleanor Hanna",
      "Olivier Jeunen",
      "Vineesha Raheja",
      "Schaun Wheeler"
    ],
    "abstract": "Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16429v1",
    "published_date": "2025-06-19 16:07:31 UTC",
    "updated_date": "2025-06-19 16:07:31 UTC"
  },
  {
    "arxiv_id": "2506.16419v1",
    "title": "Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models",
    "authors": [
      "Daniel Fidel Harvey",
      "George Weale",
      "Berk Yilmaz"
    ],
    "abstract": "Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "All authors contributed equally. 11 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.16419v1",
    "published_date": "2025-06-19 15:55:43 UTC",
    "updated_date": "2025-06-19 15:55:43 UTC"
  },
  {
    "arxiv_id": "2506.16418v1",
    "title": "Efficient Transformations in Deep Learning Convolutional Neural Networks",
    "authors": [
      "Berk Yilmaz",
      "Daniel Fidel Harvey",
      "Prajit Dhuri"
    ],
    "abstract": "This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "All authors contributed equally to this work. 17 pages, 36 references, 10 figures, 1 appendix",
    "pdf_url": "https://arxiv.org/pdf/2506.16418v1",
    "published_date": "2025-06-19 15:54:59 UTC",
    "updated_date": "2025-06-19 15:54:59 UTC"
  },
  {
    "arxiv_id": "2506.16407v1",
    "title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks",
    "authors": [
      "Dong Nguyen Tien",
      "Dung D. Le"
    ],
    "abstract": "Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility.\n  Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 1 figure, under review at EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16407v1",
    "published_date": "2025-06-19 15:38:31 UTC",
    "updated_date": "2025-06-19 15:38:31 UTC"
  },
  {
    "arxiv_id": "2506.16406v1",
    "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights",
    "authors": [
      "Zhiyuan Liang",
      "Dongwen Tang",
      "Yuhao Zhou",
      "Xuanlei Zhao",
      "Mingjia Shi",
      "Wangbo Zhao",
      "Zekai Li",
      "Peihao Wang",
      "Konstantin Schürholt",
      "Damian Borth",
      "Michael M. Bronstein",
      "Yang You",
      "Zhangyang Wang",
      "Kai Wang"
    ],
    "abstract": "Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce \\textbf{Drag-and-Drop LLMs (\\textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to \\textbf{12,000$\\times$} lower overhead than full fine-tuning, ii) average gains up to \\textbf{30\\%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at \\href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We propose a method that can generate LoRA parameters in seconds",
    "pdf_url": "https://arxiv.org/pdf/2506.16406v1",
    "published_date": "2025-06-19 15:38:21 UTC",
    "updated_date": "2025-06-19 15:38:21 UTC"
  },
  {
    "arxiv_id": "2506.16402v3",
    "title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks",
    "authors": [
      "Xiaoya Lu",
      "Zeren Chen",
      "Xuhao Hu",
      "Yijin Zhou",
      "Weichen Zhang",
      "Dongrui Liu",
      "Lu Sheng",
      "Jing Shao"
    ],
    "abstract": "Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agent's actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agent's interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before/after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems. Code and data are released under https://github.com/AI45Lab/IS-Bench.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16402v3",
    "published_date": "2025-06-19 15:34:46 UTC",
    "updated_date": "2025-12-05 06:52:55 UTC"
  },
  {
    "arxiv_id": "2507.22893v2",
    "title": "Invisible Architectures of Thought: Toward a New Science of AI as Cognitive Infrastructure",
    "authors": [
      "Giuseppe Riva"
    ],
    "abstract": "Contemporary human-AI interaction research overlooks how AI systems fundamentally reshape human cognition pre-consciously, a critical blind spot for understanding distributed cognition. This paper introduces \"Cognitive Infrastructure Studies\" (CIS) as a new interdisciplinary domain to reconceptualize AI as \"cognitive infrastructures\": foundational, often invisible systems conditioning what is knowable and actionable in digital societies. These semantic infrastructures transport meaning, operate through anticipatory personalization, and exhibit adaptive invisibility, making their influence difficult to detect. Critically, they automate \"relevance judgment,\" shifting the \"locus of epistemic agency\" to non-human systems. Through narrative scenarios spanning individual (cognitive dependency), collective (democratic deliberation), and societal (governance) scales, we describe how cognitive infrastructures reshape human cognition, public reasoning, and social epistemologies. CIS aims to address how AI preprocessing reshapes distributed cognition across individual, collective, and cultural scales, requiring unprecedented integration of diverse disciplinary methods. The framework also addresses critical gaps across disciplines: cognitive science lacks population-scale preprocessing analysis capabilities, digital sociology cannot access individual cognitive mechanisms, and computational approaches miss cultural transmission dynamics. To achieve this goal CIS also provides methodological innovations for studying invisible algorithmic influence: \"infrastructure breakdown methodologies\", experimental approaches that reveal cognitive dependencies by systematically withdrawing AI preprocessing after periods of habituation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22893v2",
    "published_date": "2025-06-19 15:33:47 UTC",
    "updated_date": "2025-08-27 14:58:29 UTC"
  },
  {
    "arxiv_id": "2506.16399v1",
    "title": "NepaliGPT: A Generative Language Model for the Nepali Language",
    "authors": [
      "Shushanta Pudasaini",
      "Aman Shakya",
      "Siddhartha Shrestha",
      "Sahil Bhatta",
      "Sunil Thapa",
      "Sushmita Palikhe"
    ],
    "abstract": "After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes \\textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\\%, and causal consistency of 85.41\\%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.16399v1",
    "published_date": "2025-06-19 15:31:12 UTC",
    "updated_date": "2025-06-19 15:31:12 UTC"
  },
  {
    "arxiv_id": "2506.16393v1",
    "title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling",
    "authors": [
      "Yao Lu",
      "Zhaiyuan Ji",
      "Jiawei Du",
      "Yu Shanqing",
      "Qi Xuan",
      "Tianyi Zhou"
    ],
    "abstract": "Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16393v1",
    "published_date": "2025-06-19 15:26:08 UTC",
    "updated_date": "2025-06-19 15:26:08 UTC"
  },
  {
    "arxiv_id": "2506.16385v1",
    "title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset",
    "authors": [
      "Santosh Patapati",
      "Trisanth Srinivasan",
      "Amith Adiraju"
    ],
    "abstract": "Micro-gesture recognition is a challenging task in affective computing due to the subtle, involuntary nature of the gestures and their low movement amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG integrates human pose (skeleton) information into the CLIP-based recognition pipeline through pose-guided semantic query generation and a gated multi-modal fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These results demonstrate both the potential of our approach and the remaining difficulty in fully adapting vision-language models like CLIP for micro-gesture recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16385v1",
    "published_date": "2025-06-19 15:16:06 UTC",
    "updated_date": "2025-06-19 15:16:06 UTC"
  },
  {
    "arxiv_id": "2506.16370v1",
    "title": "Can structural correspondences ground real world representational content in Large Language Models?",
    "authors": [
      "Iwan Williams"
    ],
    "abstract": "Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16370v1",
    "published_date": "2025-06-19 14:48:40 UTC",
    "updated_date": "2025-06-19 14:48:40 UTC"
  },
  {
    "arxiv_id": "2506.16349v2",
    "title": "Watermarking Autoregressive Image Generation",
    "authors": [
      "Nikola Jovanović",
      "Ismail Labiad",
      "Tomáš Souček",
      "Martin Vechev",
      "Pierre Fernandez"
    ],
    "abstract": "Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values. Code and models are available at https://github.com/facebookresearch/wmar.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16349v2",
    "published_date": "2025-06-19 14:25:51 UTC",
    "updated_date": "2025-10-23 17:33:59 UTC"
  },
  {
    "arxiv_id": "2506.16343v1",
    "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction",
    "authors": [
      "Cedric Möller",
      "Ricardo Usbeck"
    ],
    "abstract": "We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16343v1",
    "published_date": "2025-06-19 14:21:08 UTC",
    "updated_date": "2025-06-19 14:21:08 UTC"
  },
  {
    "arxiv_id": "2506.16335v1",
    "title": "Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach",
    "authors": [
      "Albert Sadowski",
      "Jarosław A. Chudziak"
    ],
    "abstract": "Large Language Models (LLMs) excel in complex reasoning tasks but struggle with consistent rule application, exception handling, and explainability, particularly in domains like legal analysis that require both natural language understanding and precise logical inference. This paper introduces a structured prompting framework that decomposes reasoning into three verifiable steps: entity identification, property extraction, and symbolic rule application. By integrating neural and symbolic approaches, our method leverages LLMs' interpretive flexibility while ensuring logical consistency through formal verification. The framework externalizes task definitions, enabling domain experts to refine logical structures without altering the architecture. Evaluated on the LegalBench hearsay determination task, our approach significantly outperformed baselines, with OpenAI o-family models showing substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini reaching 0.867 using structured decomposition with complementary predicates, compared to their few-shot baselines of 0.714 and 0.74 respectively. This hybrid neural-symbolic system offers a promising pathway for transparent and consistent rule-based reasoning, suggesting potential for explainable AI applications in structured legal reasoning tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at the 29th International Conference on Knowledge-Based and Intelligent Information \\& Engineering Systems (KES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.16335v1",
    "published_date": "2025-06-19 14:14:01 UTC",
    "updated_date": "2025-06-19 14:14:01 UTC"
  },
  {
    "arxiv_id": "2506.16330v1",
    "title": "Reliable Few-shot Learning under Dual Noises",
    "authors": [
      "Ji Zhang",
      "Jingkuan Song",
      "Lianli Gao",
      "Nicu Sebe",
      "Heng Tao Shen"
    ],
    "abstract": "Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target task.Nevertheless, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 6 figures,",
    "pdf_url": "https://arxiv.org/pdf/2506.16330v1",
    "published_date": "2025-06-19 14:05:57 UTC",
    "updated_date": "2025-06-19 14:05:57 UTC"
  },
  {
    "arxiv_id": "2506.16318v2",
    "title": "Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation",
    "authors": [
      "Carmelo Scribano",
      "Elena Govi",
      "Paolo Bertellini",
      "Simone Parisi",
      "Giorgia Franchini",
      "Marko Bertogna"
    ],
    "abstract": "Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Acceptet at ICIAP 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16318v2",
    "published_date": "2025-06-19 13:48:20 UTC",
    "updated_date": "2025-06-23 10:01:33 UTC"
  },
  {
    "arxiv_id": "2506.16313v2",
    "title": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks",
    "authors": [
      "Sajan Muhammad",
      "Salem Lahlou"
    ],
    "abstract": "Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the EXAIT Workshop at ICML 2025, and ICoIAS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16313v2",
    "published_date": "2025-06-19 13:39:30 UTC",
    "updated_date": "2025-10-22 05:47:33 UTC"
  },
  {
    "arxiv_id": "2506.17342v1",
    "title": "Adaptive Social Metaverse Streaming based on Federated Multi-Agent Deep Reinforcement Learning",
    "authors": [
      "Zijian Long",
      "Haopeng Wang",
      "Haiwei Dong",
      "Abdulmotaleb El Saddik"
    ],
    "abstract": "The social metaverse is a growing digital ecosystem that blends virtual and physical worlds. It allows users to interact socially, work, shop, and enjoy entertainment. However, privacy remains a major challenge, as immersive interactions require continuous collection of biometric and behavioral data. At the same time, ensuring high-quality, low-latency streaming is difficult due to the demands of real-time interaction, immersive rendering, and bandwidth optimization. To address these issues, we propose ASMS (Adaptive Social Metaverse Streaming), a novel streaming system based on Federated Multi-Agent Proximal Policy Optimization (F-MAPPO). ASMS leverages F-MAPPO, which integrates federated learning (FL) and deep reinforcement learning (DRL) to dynamically adjust streaming bit rates while preserving user privacy. Experimental results show that ASMS improves user experience by at least 14% compared to existing streaming methods across various network conditions. Therefore, ASMS enhances the social metaverse experience by providing seamless and immersive streaming, even in dynamic and resource-constrained networks, while ensuring that sensitive user data remains on local devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MM",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE Transactions on Computational Social Systems",
    "pdf_url": "https://arxiv.org/pdf/2506.17342v1",
    "published_date": "2025-06-19 13:33:43 UTC",
    "updated_date": "2025-06-19 13:33:43 UTC"
  },
  {
    "arxiv_id": "2506.16307v1",
    "title": "Learning Multi-scale Spatial-frequency Features for Image Denoising",
    "authors": [
      "Xu Zhao",
      "Chen Zhao",
      "Xiantao Hu",
      "Hongliang Zhang",
      "Ying Tai",
      "Jian Yang"
    ],
    "abstract": "Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16307v1",
    "published_date": "2025-06-19 13:28:09 UTC",
    "updated_date": "2025-06-19 13:28:09 UTC"
  },
  {
    "arxiv_id": "2506.16297v3",
    "title": "SyncMapV2: Robust and Adaptive Unsupervised Segmentation",
    "authors": [
      "Heng Zhang",
      "Zikang Wan",
      "Danilo Vasconcellos Vargas"
    ],
    "abstract": "Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16297v3",
    "published_date": "2025-06-19 13:17:30 UTC",
    "updated_date": "2025-07-24 09:52:06 UTC"
  },
  {
    "arxiv_id": "2506.16294v1",
    "title": "Approximation Fixpoint Theory with Refined Approximation Spaces",
    "authors": [
      "Linde Vanbesien",
      "Bart Bogaerts",
      "Marc Denecker"
    ],
    "abstract": "Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to KR 2024",
    "pdf_url": "https://arxiv.org/pdf/2506.16294v1",
    "published_date": "2025-06-19 13:12:53 UTC",
    "updated_date": "2025-06-19 13:12:53 UTC"
  },
  {
    "arxiv_id": "2506.16288v1",
    "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective",
    "authors": [
      "Leo Gagnon",
      "Eric Elmoznino",
      "Sarthak Mittal",
      "Tom Marty",
      "Tejas Kasetty",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "abstract": "The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16288v1",
    "published_date": "2025-06-19 13:05:12 UTC",
    "updated_date": "2025-06-19 13:05:12 UTC"
  },
  {
    "arxiv_id": "2506.16281v1",
    "title": "Artificial Intelligence for Atmospheric Sciences: A Research Roadmap",
    "authors": [
      "Martha Arbayani Zaidan",
      "Naser Hossein Motlagh",
      "Petteri Nurmi",
      "Tareq Hussein",
      "Markku Kulmala",
      "Tuukka Petäjä",
      "Sasu Tarkoma"
    ],
    "abstract": "Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16281v1",
    "published_date": "2025-06-19 12:59:32 UTC",
    "updated_date": "2025-06-19 12:59:32 UTC"
  },
  {
    "arxiv_id": "2506.18925v3",
    "title": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease",
    "authors": [
      "Tahereh Zarrat Ehsan",
      "Michael Tangermann",
      "Yağmur Güçlütürk",
      "Bastiaan R. Bloem",
      "Luc J. W. Evers"
    ],
    "abstract": "Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.18925v3",
    "published_date": "2025-06-19 12:49:06 UTC",
    "updated_date": "2025-11-13 18:08:05 UTC"
  },
  {
    "arxiv_id": "2506.16263v1",
    "title": "CapsDT: Diffusion-Transformer for Capsule Robot Manipulation",
    "authors": [
      "Xiting He",
      "Mingwu Su",
      "Xinqi Jiang",
      "Long Bai",
      "Jiewen Lai",
      "Hongliang Ren"
    ],
    "abstract": "Vision-Language-Action (VLA) models have emerged as a prominent research area, showcasing significant potential across a variety of applications. However, their performance in endoscopy robotics, particularly endoscopy capsule robots that perform actions within the digestive system, remains unexplored. The integration of VLA models into endoscopy robots allows more intuitive and efficient interactions between human operators and medical devices, improving both diagnostic accuracy and treatment outcomes. In this work, we design CapsDT, a Diffusion Transformer model for capsule robot manipulation in the stomach. By processing interleaved visual inputs, and textual instructions, CapsDT can infer corresponding robotic control signals to facilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot system, a capsule robot controlled by a robotic arm-held magnet, addressing different levels of four endoscopy tasks and creating corresponding capsule robot datasets within the stomach simulator. Comprehensive evaluations on various robotic tasks indicate that CapsDT can serve as a robust vision-language generalist, achieving state-of-the-art performance in various levels of endoscopy tasks while achieving a 26.25% success rate in real-world simulation manipulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16263v1",
    "published_date": "2025-06-19 12:25:48 UTC",
    "updated_date": "2025-06-19 12:25:48 UTC"
  },
  {
    "arxiv_id": "2506.16255v1",
    "title": "Category-based Galaxy Image Generation via Diffusion Models",
    "authors": [
      "Xingzhong Fan",
      "Hongming Tang",
      "Yue Zeng",
      "M. B. N. Kouwenhoven",
      "Guangquan Zeng"
    ],
    "abstract": "Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "18 pages, 6 figures. Submitted to AAS Astronomical Journal (AJ) and is under revision. See another indenpdent work for furthur reference -- Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation (Ma, Sun et al.). Comments are welcome",
    "pdf_url": "https://arxiv.org/pdf/2506.16255v1",
    "published_date": "2025-06-19 12:14:33 UTC",
    "updated_date": "2025-06-19 12:14:33 UTC"
  },
  {
    "arxiv_id": "2506.16243v1",
    "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping",
    "authors": [
      "Abdulvahap Mutlu",
      "Şengül Doğan",
      "Türker Tuncer"
    ],
    "abstract": "Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The code is available on GitHub: https://github.com/abdulvahapmutlu/als-synthetic-data-augmentation-wgan",
    "pdf_url": "https://arxiv.org/pdf/2506.16243v1",
    "published_date": "2025-06-19 11:57:23 UTC",
    "updated_date": "2025-06-19 11:57:23 UTC"
  },
  {
    "arxiv_id": "2506.21602v2",
    "title": "BiMark: Unbiased Multilayer Watermarking for Large Language Models",
    "authors": [
      "Xiaoyan Feng",
      "He Zhang",
      "Yanjun Zhang",
      "Leo Yu Zhang",
      "Shirui Pan"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have raised urgent concerns about LLM-generated text authenticity, prompting regulatory demands for reliable identification mechanisms. Although watermarking offers a promising solution, existing approaches struggle to simultaneously achieve three critical requirements: text quality preservation, model-agnostic detection, and message embedding capacity, which are crucial for practical implementation. To achieve these goals, the key challenge lies in balancing the trade-off between text quality preservation and message embedding capacity. To address this challenge, we propose BiMark, a novel watermarking framework that achieves these requirements through three key innovations: (1) a bit-flip unbiased reweighting mechanism enabling model-agnostic detection, (2) a multilayer architecture enhancing detectability without compromising generation quality, and (3) an information encoding approach supporting multi-bit watermarking. Through theoretical analysis and extensive experiments, we validate that, compared to state-of-the-art multi-bit watermarking methods, BiMark achieves up to 30% higher extraction rates for short texts while maintaining text quality indicated by lower perplexity, and performs comparably to non-watermarked text on downstream tasks such as summarization and translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted by International Conference on Machine Learning (ICML) 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.21602v2",
    "published_date": "2025-06-19 11:08:59 UTC",
    "updated_date": "2025-08-25 05:23:11 UTC"
  },
  {
    "arxiv_id": "2506.16213v1",
    "title": "CF-Seg: Counterfactuals meet Segmentation",
    "authors": [
      "Raghav Mehta",
      "Fabio De Sousa Ribeiro",
      "Tian Xia",
      "Melanie Roschewitz",
      "Ainkaran Santhirasekaram",
      "Dominic C. Marshall",
      "Ben Glocker"
    ],
    "abstract": "Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16213v1",
    "published_date": "2025-06-19 11:01:33 UTC",
    "updated_date": "2025-06-19 11:01:33 UTC"
  },
  {
    "arxiv_id": "2506.16189v1",
    "title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization",
    "authors": [
      "Putri A. van der Linden",
      "Alexander Timans",
      "Erik J. Bekkers"
    ],
    "abstract": "We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "17 pages, 7 figures, 9 tables (including appendix); published at UAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16189v1",
    "published_date": "2025-06-19 10:12:02 UTC",
    "updated_date": "2025-06-19 10:12:02 UTC"
  },
  {
    "arxiv_id": "2506.16187v1",
    "title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset",
    "authors": [
      "Masashi Takeshita",
      "Rafal Rzepka"
    ],
    "abstract": "In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16187v1",
    "published_date": "2025-06-19 10:06:57 UTC",
    "updated_date": "2025-06-19 10:06:57 UTC"
  },
  {
    "arxiv_id": "2506.16170v2",
    "title": "From Teacher to Student: Tracking Memorization Through Model Distillation",
    "authors": [
      "Simardeep Singh"
    ],
    "abstract": "Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, in-proceedings L2M2 @ ACL 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16170v2",
    "published_date": "2025-06-19 09:44:25 UTC",
    "updated_date": "2025-08-15 18:12:41 UTC"
  },
  {
    "arxiv_id": "2506.16168v1",
    "title": "On using AI for EEG-based BCI applications: problems, current challenges and future trends",
    "authors": [
      "Thomas Barbera",
      "Jacopo Burger",
      "Alessandro D'Amelio",
      "Simone Zini",
      "Simone Bianco",
      "Raffaella Lanzarotti",
      "Paolo Napoletano",
      "Giuseppe Boccignone",
      "Jose Luis Contreras-Vidal"
    ],
    "abstract": "Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines \"see\" and \"understand\" language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT).\n  However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability.\n  Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16168v1",
    "published_date": "2025-06-19 09:43:17 UTC",
    "updated_date": "2025-06-19 09:43:17 UTC"
  },
  {
    "arxiv_id": "2506.16163v1",
    "title": "Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior",
    "authors": [
      "Hao Li",
      "Gengrui Zhang",
      "Petter Holme",
      "Shuyue Hu",
      "Zhen Wang"
    ],
    "abstract": "Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16163v1",
    "published_date": "2025-06-19 09:32:55 UTC",
    "updated_date": "2025-06-19 09:32:55 UTC"
  },
  {
    "arxiv_id": "2506.16151v1",
    "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs",
    "authors": [
      "Chenxi Wang",
      "Yixuan Zhang",
      "Lang Gao",
      "Zixiang Xu",
      "Zirui Song",
      "Yanbo Wang",
      "Xiuying Chen"
    ],
    "abstract": "Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.16151v1",
    "published_date": "2025-06-19 09:06:38 UTC",
    "updated_date": "2025-06-19 09:06:38 UTC"
  },
  {
    "arxiv_id": "2506.16150v3",
    "title": "PRISON: Unmasking the Criminal Potential of Large Language Models",
    "authors": [
      "Xinyi Wu",
      "Geng Hong",
      "Pei Chen",
      "Yueyue Chen",
      "Xudong Pan",
      "Min Yang"
    ],
    "abstract": "As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five traits: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films grounded in reality, we evaluate both criminal potential and anti-crime ability of LLMs. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 44% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16150v3",
    "published_date": "2025-06-19 09:06:27 UTC",
    "updated_date": "2025-10-17 06:39:10 UTC"
  },
  {
    "arxiv_id": "2506.16144v1",
    "title": "Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction",
    "authors": [
      "Ana Kostovska",
      "Carola Doerr",
      "Sašo Džeroski",
      "Panče Panov",
      "Tome Eftimov"
    ],
    "abstract": "Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16144v1",
    "published_date": "2025-06-19 08:56:05 UTC",
    "updated_date": "2025-06-19 08:56:05 UTC"
  },
  {
    "arxiv_id": "2506.16141v1",
    "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning",
    "authors": [
      "Yi Chen",
      "Yuying Ge",
      "Rui Wang",
      "Yixiao Ge",
      "Junhao Cheng",
      "Ying Shan",
      "Xihui Liu"
    ],
    "abstract": "Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code released at: https://github.com/TencentARC/GRPO-CARE",
    "pdf_url": "https://arxiv.org/pdf/2506.16141v1",
    "published_date": "2025-06-19 08:49:13 UTC",
    "updated_date": "2025-06-19 08:49:13 UTC"
  },
  {
    "arxiv_id": "2506.22468v1",
    "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting",
    "authors": [
      "Konstantinos Koutras",
      "Agorakis Bompotas",
      "Constantinos Halkiopoulos",
      "Athanasios Kalogeras",
      "Christos Alexakos"
    ],
    "abstract": "The Internet of Things (IoT) plays a major role today in smart building infrastructures, from simple smart-home applications, to more sophisticated industrial type installations. The vast amounts of data generated from relevant systems can be processed in different ways revealing important information. This is especially true in the era of edge computing, when advanced data analysis and decision-making is gradually moving to the edge of the network where devices are generally characterised by low computing resources. In this context, one of the emerging main challenges is related to maintaining data analysis accuracy even with less data that can be efficiently handled by low resource devices. The present work focuses on correlation analysis of data retrieved from a pilot IoT network installation monitoring a small smart office by means of environmental and energy consumption sensors. The research motivation was to find statistical correlation between the monitoring variables that will allow the use of machine learning (ML) prediction algorithms for energy consumption reducing input parameters. For this to happen, a series of hypothesis tests for the correlation of three different environmental variables with the energy consumption were carried out. A total of ninety tests were performed, thirty for each pair of variables. In these tests, p-values showed the existence of strong or semi-strong correlation with two environmental variables, and of a weak correlation with a third one. Using the proposed methodology, we manage without examining the entire data set to exclude weak correlated variables while keeping the same score of accuracy.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Version of submitted paper on 2023 IEEE International Smart Cities Conference (ISC2), 1-6, 2023",
    "pdf_url": "https://arxiv.org/pdf/2506.22468v1",
    "published_date": "2025-06-19 08:29:35 UTC",
    "updated_date": "2025-06-19 08:29:35 UTC"
  },
  {
    "arxiv_id": "2506.17338v2",
    "title": "PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning",
    "authors": [
      "Duong Bach"
    ],
    "abstract": "The proliferation of multi-agent systems (MAS) in complex, dynamic environments necessitates robust and efficient mechanisms for managing shared knowledge. A critical challenge is ensuring that distributed memories remain synchronized, relevant, and free from the accumulation of outdated or inconsequential data - a process analogous to biological forgetting. This paper introduces the Co-Forgetting Protocol, a novel, comprehensive framework designed to address this challenge by enabling synchronized memory pruning in MAS. The protocol integrates three key components: (1) context-aware semantic voting, where agents utilize a lightweight DistilBERT model to assess the relevance of memory items based on their content and the current operational context; (2) multi-scale temporal decay functions, which assign diminishing importance to memories based on their age and access frequency across different time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based consensus mechanism, ensuring that decisions to retain or discard memory items are agreed upon by a qualified and fault-tolerant majority of agents, even in the presence of up to f Byzantine (malicious or faulty) agents in a system of N greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient inter-agent communication and Pinecone for scalable vector embedding storage and similarity search, with SQLite managing metadata. Experimental evaluations in a simulated MAS environment with four agents demonstrate the protocol's efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88% voting accuracy in forgetting decisions against human-annotated benchmarks, a 92% PBFT consensus success rate under simulated Byzantine conditions, and an 82% cache hit rate for memory access.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.17338v2",
    "published_date": "2025-06-19 08:28:29 UTC",
    "updated_date": "2025-06-24 06:44:47 UTC"
  },
  {
    "arxiv_id": "2506.16127v1",
    "title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching",
    "authors": [
      "Shoutrik Das",
      "Nishant Singh",
      "Arjun Gangwar",
      "S Umesh"
    ],
    "abstract": "Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.16127v1",
    "published_date": "2025-06-19 08:24:17 UTC",
    "updated_date": "2025-06-19 08:24:17 UTC"
  },
  {
    "arxiv_id": "2506.16119v1",
    "title": "FastInit: Fast Noise Initialization for Temporally Consistent Video Generation",
    "authors": [
      "Chengyu Bai",
      "Yuming Li",
      "Zhongyu Zhao",
      "Jintao Chen",
      "Peidong Jia",
      "Qi She",
      "Ming Lu",
      "Shanghang Zhang"
    ],
    "abstract": "Video generation has made significant strides with the development of diffusion models; however, achieving high temporal consistency remains a challenging task. Recently, FreeInit identified a training-inference gap and introduced a method to iteratively refine the initial noise during inference. However, iterative refinement significantly increases the computational cost associated with video generation. In this paper, we introduce FastInit, a fast noise initialization method that eliminates the need for iterative refinement. FastInit learns a Video Noise Prediction Network (VNPNet) that takes random noise and a text prompt as input, generating refined noise in a single forward pass. Therefore, FastInit greatly enhances the efficiency of video generation while achieving high temporal consistency across frames. To train the VNPNet, we create a large-scale dataset consisting of pairs of text prompts, random noise, and refined noise. Extensive experiments with various text-to-video models show that our method consistently improves the quality and temporal consistency of the generated videos. FastInit not only provides a substantial improvement in video generation but also offers a practical solution that can be applied directly during inference. The code and dataset will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16119v1",
    "published_date": "2025-06-19 08:11:45 UTC",
    "updated_date": "2025-06-19 08:11:45 UTC"
  },
  {
    "arxiv_id": "2506.16114v2",
    "title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks",
    "authors": [
      "Yejing Wang",
      "Shengyu Zhou",
      "Jinyu Lu",
      "Qidong Liu",
      "Xinhang Li",
      "Wenlin Zhang",
      "Feng Li",
      "Pengjie Wang",
      "Jian Xu",
      "Bo Zheng",
      "Xiangyu Zhao"
    ],
    "abstract": "Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16114v2",
    "published_date": "2025-06-19 08:04:31 UTC",
    "updated_date": "2025-11-24 05:43:01 UTC"
  },
  {
    "arxiv_id": "2506.17337v2",
    "title": "Can Generalist Vision Language Models (VLMs) Rival Specialist Medical VLMs? Benchmarking and Strategic Insights",
    "authors": [
      "Yuan Zhong",
      "Ruinan Jin",
      "Qi Dou",
      "Xiaoxiao Li"
    ],
    "abstract": "Vision Language Models (VLMs) have shown promise in automating image diagnosis and interpretation in clinical settings. However, developing specialist medical VLMs requires substantial computational resources and carefully curated datasets, and it remains unclear under which conditions generalist and specialist medical VLMs each perform best. This study highlights the complementary strengths of specialist medical and generalist VLMs. Specialists remain valuable in modality-aligned use cases, but we find that efficiently fine-tuned generalist VLMs can achieve comparable or even superior performance in most tasks, particularly when transferring to unseen or rare OOD medical modalities. These results suggest that generalist VLMs, rather than being constrained by their lack of specialist medical pretraining, may offer a scalable and cost-effective pathway for advancing clinical AI development.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "version 2",
    "pdf_url": "https://arxiv.org/pdf/2506.17337v2",
    "published_date": "2025-06-19 07:59:00 UTC",
    "updated_date": "2025-09-16 07:44:30 UTC"
  },
  {
    "arxiv_id": "2506.16096v2",
    "title": "A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders",
    "authors": [
      "Qianqian Liao",
      "Wuque Cai",
      "Hongze Sun",
      "Dongze Liu",
      "Duo Chen",
      "Dezhong Yao",
      "Daqing Guo"
    ],
    "abstract": "Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "this paper has been submitted for possible publication",
    "pdf_url": "https://arxiv.org/pdf/2506.16096v2",
    "published_date": "2025-06-19 07:32:57 UTC",
    "updated_date": "2025-10-15 02:19:21 UTC"
  },
  {
    "arxiv_id": "2507.00039v1",
    "title": "Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing",
    "authors": [
      "Lucas Potin",
      "Rosa Figueiredo",
      "Vincent Labatut",
      "Christine Largeron"
    ],
    "abstract": "Graph classification aims to categorize graphs based on their structural and attribute features, with applications in diverse fields such as social network analysis and bioinformatics. Among the methods proposed to solve this task, those relying on patterns (i.e. subgraphs) provide good explainability, as the patterns used for classification can be directly interpreted. To identify meaningful patterns, a standard approach is to use a quality measure, i.e. a function that evaluates the discriminative power of each pattern. However, the literature provides tens of such measures, making it difficult to select the most appropriate for a given application. Only a handful of surveys try to provide some insight by comparing these measures, and none of them specifically focuses on graphs. This typically results in the systematic use of the most widespread measures, without thorough evaluation. To address this issue, we present a comparative analysis of 38 quality measures from the literature. We characterize them theoretically, based on four mathematical properties. We leverage publicly available datasets to constitute a benchmark, and propose a method to elaborate a gold standard ranking of the patterns. We exploit these resources to perform an empirical comparison of the measures, both in terms of pattern ranking and classification performance. Moreover, we propose a clustering-based preprocessing step, which groups patterns appearing in the same graphs to enhance classification performance. Our experimental results demonstrate the effectiveness of this step, reducing the number of patterns to be processed while achieving comparable performance. Additionally, we show that some popular measures widely used in the literature are not associated with the best results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00039v1",
    "published_date": "2025-06-19 07:28:41 UTC",
    "updated_date": "2025-06-19 07:28:41 UTC"
  },
  {
    "arxiv_id": "2506.16087v1",
    "title": "Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies",
    "authors": [
      "Tom Jeleniewski",
      "Hamied Nabizada",
      "Jonathan Reif",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is accepted at IEEE ETFA 2025 and will be published in the conference proceedings",
    "pdf_url": "https://arxiv.org/pdf/2506.16087v1",
    "published_date": "2025-06-19 07:21:16 UTC",
    "updated_date": "2025-06-19 07:21:16 UTC"
  },
  {
    "arxiv_id": "2506.21600v1",
    "title": "Structured Attention Matters to Multimodal LLMs in Document Understanding",
    "authors": [
      "Chang Liu",
      "Hongkai Chen",
      "Yujun Cai",
      "Hang Wu",
      "Qingwen Ye",
      "Ming-Hsuan Yang",
      "Yiwei Wang"
    ],
    "abstract": "Document understanding remains a significant challenge for multimodal large language models (MLLMs). While previous research has primarily focused on locating evidence pages through precise multimodal queries, our work investigates a fundamental yet overlooked aspect: how input format influences document comprehension performance. Through systematic analysis, we discover that raw OCR text often impairs rather than improves MLLMs' performance, which is a counterintuitive finding we attribute to attention dispersion and structure loss. To further substantiate our hypothesis, we propose a novel structure-preserving approach that encodes document elements using the LaTex paradigm, maintaining the hierarchical organization and spatial relationships critical for comprehension. Our attention analysis reveals that structured text induces structured attention patterns on both textual and visual content, directing models to focus on semantically meaningful regions while reducing attention waste. This approach significantly enhances MLLMs' document question answering performance across diverse document types without requiring architectural modifications or additional training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.21600v1",
    "published_date": "2025-06-19 07:16:18 UTC",
    "updated_date": "2025-06-19 07:16:18 UTC"
  },
  {
    "arxiv_id": "2506.17336v3",
    "title": "PPMI: Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases",
    "authors": [
      "Yubeen Bae",
      "Minchan Kim",
      "Jaejin Lee",
      "Sangbum Kim",
      "Jaehyung Kim",
      "Yejin Choi",
      "Niloofar Mireshghallah"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "29 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.17336v3",
    "published_date": "2025-06-19 07:13:30 UTC",
    "updated_date": "2025-11-01 11:32:10 UTC"
  },
  {
    "arxiv_id": "2506.17335v1",
    "title": "LMR-BENCH: Evaluating LLM Agent's Ability on Reproducing Language Modeling Research",
    "authors": [
      "Shuo Yan",
      "Ruochen Li",
      "Ziming Luo",
      "Zimu Wang",
      "Daoyang Li",
      "Liqiang Jing",
      "Kaiyu He",
      "Peilin Wu",
      "George Michalopoulos",
      "Yue Zhang",
      "Ziyang Zhang",
      "Mian Zhang",
      "Zhiyu Chen",
      "Xinya Du"
    ],
    "abstract": "Large language model (LLM) agents have demonstrated remarkable potential in advancing scientific discovery. However, their capability in the fundamental yet crucial task of reproducing code from research papers, especially in the NLP domain, remains underexplored. This task includes unique complex reasoning challenges in the intellectual synthesis of abstract concepts and the comprehension of code repositories with interdependent files. Motivated by this gap, we present LMR-BENCH, a benchmark designed to systematically evaluate the capability of LLM agents on code reproduction from Language Modeling Research. It consists of 28 code reproduction tasks derived from 23 research papers published in top-tier NLP venues over the past five years, spanning nine fundamental categories. Models are provided with a research paper, a code repository containing one or more masked functions, and instructions for implementing these functions. We conduct extensive experiments in standard prompting and LLM agent settings with state-of-the-art LLMs, evaluating the accuracy of unit tests and performing LLM-based evaluation of code correctness. Experimental results reveal that even the most advanced models still exhibit persistent limitations in scientific reasoning and code synthesis, highlighting critical gaps in LLM agents' ability to autonomously reproduce scientific research",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17335v1",
    "published_date": "2025-06-19 07:04:16 UTC",
    "updated_date": "2025-06-19 07:04:16 UTC"
  },
  {
    "arxiv_id": "2506.16078v1",
    "title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations",
    "authors": [
      "Tianle Gu",
      "Kexin Huang",
      "Zongqi Wang",
      "Yixu Wang",
      "Jie Li",
      "Yuanqi Yao",
      "Yang Yao",
      "Yujiu Yang",
      "Yan Teng",
      "Yingchun Wang"
    ],
    "abstract": "Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16078v1",
    "published_date": "2025-06-19 07:03:05 UTC",
    "updated_date": "2025-06-19 07:03:05 UTC"
  },
  {
    "arxiv_id": "2507.00038v3",
    "title": "Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information",
    "authors": [
      "Fei Chen",
      "Wenchi Zhou"
    ],
    "abstract": "In order to increase the effectiveness of model training, data reduction is essential to data-centric Artificial Intelligence (AI). It achieves this by locating the most instructive examples in massive datasets. To increase data quality and training efficiency, the main difficulty is choosing the best examples rather than the complete datasets. In this paper, we propose an effective data reduction strategy based on Pointwise V-Information (PVI). To enable a static method, we first use PVI to quantify instance difficulty and remove instances with low difficulty. Experiments show that classifier performance is maintained with only a 0.0001% to 0.76% decline in accuracy when 10%-30% of the data is removed. Second, we train the classifiers using a progressive learning strategy on examples sorted by increasing PVI, accelerating convergence and achieving a 0.8% accuracy gain over conventional training. Our findings imply that training a classifier on the chosen optimal subset may improve model performance and increase training efficiency when combined with an efficient data reduction strategy. Furthermore, we have adapted the PVI framework, which was previously limited to English datasets, to a variety of Chinese Natural Language Processing (NLP) tasks and base models, yielding insightful results for faster training and cross-lingual data reduction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00038v3",
    "published_date": "2025-06-19 06:59:19 UTC",
    "updated_date": "2025-08-08 06:00:37 UTC"
  },
  {
    "arxiv_id": "2506.16056v1",
    "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations",
    "authors": [
      "Puchun Liu",
      "C. L. Philip Chen",
      "Yubin He",
      "Tong Zhang"
    ],
    "abstract": "The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16056v1",
    "published_date": "2025-06-19 06:31:08 UTC",
    "updated_date": "2025-06-19 06:31:08 UTC"
  },
  {
    "arxiv_id": "2506.16052v1",
    "title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text",
    "authors": [
      "Devesh Kumar"
    ],
    "abstract": "The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4\\% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3\\% accuracy on HateXplain, 95.41\\% accuracy on SOSNet, 91.37\\% accuracy on Mendeley-I, and 94.67\\% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16052v1",
    "published_date": "2025-06-19 06:15:22 UTC",
    "updated_date": "2025-06-19 06:15:22 UTC"
  },
  {
    "arxiv_id": "2506.16043v1",
    "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling",
    "authors": [
      "Fei Wang",
      "Xingchen Wan",
      "Ruoxi Sun",
      "Jiefeng Chen",
      "Sercan Ö. Arık"
    ],
    "abstract": "Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16043v1",
    "published_date": "2025-06-19 05:40:54 UTC",
    "updated_date": "2025-06-19 05:40:54 UTC"
  },
  {
    "arxiv_id": "2506.16042v1",
    "title": "OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents",
    "authors": [
      "Reyna Abhyankar",
      "Qi Qi",
      "Yiying Zhang"
    ],
    "abstract": "Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.OS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16042v1",
    "published_date": "2025-06-19 05:26:40 UTC",
    "updated_date": "2025-06-19 05:26:40 UTC"
  },
  {
    "arxiv_id": "2506.17332v1",
    "title": "P2MFDS: A Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments",
    "authors": [
      "Haitian Wang",
      "Yiren Wang",
      "Xinyu Wang",
      "Yumeng Miao",
      "Yuliang Zhang",
      "Yu Zhang",
      "Atif Mansoor"
    ],
    "abstract": "By 2050, people aged 65 and over are projected to make up 16 percent of the global population. As aging is closely associated with increased fall risk, particularly in wet and confined environments such as bathrooms where over 80 percent of falls occur. Although recent research has increasingly focused on non-intrusive, privacy-preserving approaches that do not rely on wearable devices or video-based monitoring, these efforts have not fully overcome the limitations of existing unimodal systems (e.g., WiFi-, infrared-, or mmWave-based), which are prone to reduced accuracy in complex environments. These limitations stem from fundamental constraints in unimodal sensing, including system bias and environmental interference, such as multipath fading in WiFi-based systems and drastic temperature changes in infrared-based methods. To address these challenges, we propose a Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments. First, we develop a sensor evaluation framework to select and fuse millimeter-wave radar with 3D vibration sensing, and use it to construct and preprocess a large-scale, privacy-preserving multimodal dataset in real bathroom settings, which will be released upon publication. Second, we introduce P2MFDS, a dual-stream network combining a CNN-BiLSTM-Attention branch for radar motion dynamics with a multi-scale CNN-SEBlock-Self-Attention branch for vibration impact detection. By uniting macro- and micro-scale features, P2MFDS delivers significant gains in accuracy and recall over state-of-the-art approaches. Code and pretrained models will be made available at: https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to appear in the 2025 IEEE International Workshop on AIoT and Smart Systems (AIoTSys'25). Nominated for Best Paper Award and Best IoT System Implementation Award. Code and pretrained models available at: https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom",
    "pdf_url": "https://arxiv.org/pdf/2506.17332v1",
    "published_date": "2025-06-19 05:22:14 UTC",
    "updated_date": "2025-06-19 05:22:14 UTC"
  },
  {
    "arxiv_id": "2506.16035v2",
    "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding",
    "authors": [
      "Vishesh Tripathi",
      "Tanmay Odapally",
      "Indraneel Das",
      "Uday Allu",
      "Biddwan Ahmed"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 1 Figure, 1 Table",
    "pdf_url": "https://arxiv.org/pdf/2506.16035v2",
    "published_date": "2025-06-19 05:11:43 UTC",
    "updated_date": "2025-07-13 19:52:49 UTC"
  },
  {
    "arxiv_id": "2506.16029v2",
    "title": "EvoLM: In Search of Lost Language Model Training Dynamics",
    "authors": [
      "Zhenting Qi",
      "Fan Nie",
      "Alexandre Alahi",
      "James Zou",
      "Himabindu Lakkaraju",
      "Yilun Du",
      "Eric Xing",
      "Sham Kakade",
      "Hanlin Zhang"
    ],
    "abstract": "Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. We train over 100 LMs with 1B and 4B parameters from scratch, and evaluate both upstream (language modeling) and downstream (problem-solving) capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2025 (Oral)",
    "pdf_url": "https://arxiv.org/pdf/2506.16029v2",
    "published_date": "2025-06-19 04:58:47 UTC",
    "updated_date": "2025-11-18 06:29:30 UTC"
  },
  {
    "arxiv_id": "2506.16024v1",
    "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation",
    "authors": [
      "Zhihan Guo",
      "Jiele Wu",
      "Wenqian Cui",
      "Yifei Zhang",
      "Minda Hu",
      "Yufei Wang",
      "Irwin King"
    ],
    "abstract": "Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16024v1",
    "published_date": "2025-06-19 04:44:34 UTC",
    "updated_date": "2025-06-19 04:44:34 UTC"
  },
  {
    "arxiv_id": "2506.16016v2",
    "title": "Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations",
    "authors": [
      "William Sharpless",
      "Dylan Hirsch",
      "Sander Tonkens",
      "Nikhil Shinde",
      "Sylvia Herbert"
    ],
    "abstract": "Hard constraints in reinforcement learning (RL) often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: 1) the Reach-Always-Avoid (RAA) problem -- of achieving distinct reward and penalty thresholds -- and 2) the Reach-Reach (RR) problem -- of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context via decomposition. Specifically, we prove that the RAA and RR problems may be rewritten as compositions of previously studied HJ-RL problems. We leverage our analysis to propose a variation of Proximal Policy Optimization (DOHJ-PPO), and demonstrate that it produces distinct behaviors from previous approaches, outcompeting a number of baselines in success, safety and speed across a range of tasks for safe-arrival and multi-target achievement.",
    "categories": [
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16016v2",
    "published_date": "2025-06-19 04:27:17 UTC",
    "updated_date": "2025-12-04 14:02:31 UTC"
  },
  {
    "arxiv_id": "2506.16015v1",
    "title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning",
    "authors": [
      "Craig S. Wright"
    ],
    "abstract": "The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "91 pages, 0 figures, includes mathematical appendix and formal proofs. Designed as a foundational submission for a modular autonomous epistemic reasoning system. Suitable for logic in computer science, AI epistemology, and scientific informatics",
    "pdf_url": "https://arxiv.org/pdf/2506.16015v1",
    "published_date": "2025-06-19 04:22:35 UTC",
    "updated_date": "2025-06-19 04:22:35 UTC"
  },
  {
    "arxiv_id": "2506.16014v4",
    "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning",
    "authors": [
      "Jina Kim",
      "Youjin Jang",
      "Jeongjin Han"
    ],
    "abstract": "We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16014v4",
    "published_date": "2025-06-19 04:21:23 UTC",
    "updated_date": "2025-09-24 20:41:32 UTC"
  },
  {
    "arxiv_id": "2506.16006v1",
    "title": "DIGMAPPER: A Modular System for Automated Geologic Map Digitization",
    "authors": [
      "Weiwei Duan",
      "Michael P. Gerlek",
      "Steven N. Minton",
      "Craig A. Knoblock",
      "Fandel Lin",
      "Theresa Chen",
      "Leeje Jang",
      "Sofia Kirsanova",
      "Zekun Li",
      "Yijun Lin",
      "Yao-Yi Chiang"
    ],
    "abstract": "Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.16006v1",
    "published_date": "2025-06-19 03:51:47 UTC",
    "updated_date": "2025-06-19 03:51:47 UTC"
  },
  {
    "arxiv_id": "2506.16001v2",
    "title": "AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction",
    "authors": [
      "Qianru Zhang",
      "Honggang Wen",
      "Ming Li",
      "Dong Huang",
      "Siu-Ming Yiu",
      "Christian S. Jensen",
      "Pietro Liò"
    ],
    "abstract": "Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at https://github.com/lizzyhku/Autotime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.16001v2",
    "published_date": "2025-06-19 03:47:04 UTC",
    "updated_date": "2025-11-22 15:55:47 UTC"
  },
  {
    "arxiv_id": "2506.16000v1",
    "title": "Quantum Artificial Intelligence for Secure Autonomous Vehicle Navigation: An Architectural Proposal",
    "authors": [
      "Hemanth Kannamarlapudi",
      "Sowmya Chintalapudi"
    ],
    "abstract": "Navigation is a very crucial aspect of autonomous vehicle ecosystem which heavily relies on collecting and processing large amounts of data in various states and taking a confident and safe decision to define the next vehicle maneuver. In this paper, we propose a novel architecture based on Quantum Artificial Intelligence by enabling quantum and AI at various levels of navigation decision making and communication process in Autonomous vehicles : Quantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum reinforcement learning for navigation policy optimization and finally post-quantum cryptographic protocols for secure communication. Quantum neural networks uses quantum amplitude encoding to fuse data from various sensors like LiDAR, radar, camera, GPS and weather etc., This approach gives a unified quantum state representation between heterogeneous sensor modalities. Nav-Q module processes the fused quantum states through variational quantum circuits to learn optimal navigation policies under swift dynamic and complex conditions. Finally, post quantum cryptographic protocols are used to secure communication channels for both within vehicle communication and V2X (Vehicle to Everything) communications and thus secures the autonomous vehicle communication from both classical and quantum security threats. Thus, the proposed framework addresses fundamental challenges in autonomous vehicles navigation by providing quantum performance and future proof security. Index Terms Quantum Computing, Autonomous Vehicles, Sensor Fusion",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.RO",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "5 pages, 2 figures, 17 references. Architectural proposal for quantum AI integration in autonomous vehicle navigation systems for secured navigation",
    "pdf_url": "https://arxiv.org/pdf/2506.16000v1",
    "published_date": "2025-06-19 03:45:49 UTC",
    "updated_date": "2025-06-19 03:45:49 UTC"
  },
  {
    "arxiv_id": "2506.15981v2",
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "authors": [
      "Markus Frohmann",
      "Gabriel Meseguer-Brocal",
      "Markus Schedl",
      "Elena V. Epure"
    ],
    "abstract": "The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2506.15981v2",
    "published_date": "2025-06-19 02:56:49 UTC",
    "updated_date": "2025-06-28 05:47:16 UTC"
  },
  {
    "arxiv_id": "2506.15980v2",
    "title": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization",
    "authors": [
      "Cong Wang",
      "Zexuan Deng",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Fei Shen",
      "Zifeng Cheng",
      "Shiping Ge",
      "Shiwei Gan",
      "Qing Gu"
    ],
    "abstract": "Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (\\eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (\\ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at https://github.com/umnooob/signvip/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15980v2",
    "published_date": "2025-06-19 02:56:06 UTC",
    "updated_date": "2025-11-06 11:55:52 UTC"
  },
  {
    "arxiv_id": "2506.15978v1",
    "title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension",
    "authors": [
      "Toan Nguyen Hai",
      "Ha Nguyen Viet",
      "Truong Quan Xuan",
      "Duc Do Minh"
    ],
    "abstract": "Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15\\% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15978v1",
    "published_date": "2025-06-19 02:53:24 UTC",
    "updated_date": "2025-06-19 02:53:24 UTC"
  },
  {
    "arxiv_id": "2506.21599v2",
    "title": "Refine-POI: Reinforcement Fine-Tuned Large Language Models for Next Point-of-Interest Recommendation",
    "authors": [
      "Peibo Li",
      "Shuang Ao",
      "Hao Xue",
      "Yang Song",
      "Maarten de Rijke",
      "Johan Barthélemy",
      "Tomasz Bednarz",
      "Flora D. Salim"
    ],
    "abstract": "Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list.\n  To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.21599v2",
    "published_date": "2025-06-19 02:51:10 UTC",
    "updated_date": "2025-06-30 11:36:12 UTC"
  },
  {
    "arxiv_id": "2506.15971v1",
    "title": "Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging",
    "authors": [
      "Jiawen Yang",
      "Shuhao Chen",
      "Yucong Duan",
      "Ke Tang",
      "Yu Zhang"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15971v1",
    "published_date": "2025-06-19 02:31:51 UTC",
    "updated_date": "2025-06-19 02:31:51 UTC"
  },
  {
    "arxiv_id": "2506.15961v2",
    "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training",
    "authors": [
      "Yunchi Lu",
      "Youshan Miao",
      "Cheng Tan",
      "Peng Huang",
      "Yi Zhu",
      "Xian Zhang",
      "Fan Yang"
    ],
    "abstract": "Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15961v2",
    "published_date": "2025-06-19 02:10:06 UTC",
    "updated_date": "2025-06-24 10:50:28 UTC"
  },
  {
    "arxiv_id": "2506.17329v1",
    "title": "On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0",
    "authors": [
      "Pedro H. Lui",
      "Lucas P. Siqueira",
      "Juliano F. Kazienko",
      "Vagner E. Quincozes",
      "Silvio E. Quincozes",
      "Daniel Welfer"
    ],
    "abstract": "Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of Things (IoT), real-time monitoring, and human-centered design toward personalized medicine and predictive diagnostics. However, the increasing reliance on interconnected medical technologies exposes them to cyber threats. Meanwhile, current AI-driven cybersecurity models often neglect biomedical data, limiting their effectiveness and interpretability. This study addresses this gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that integrates network traffic and biomedical sensor data. Classification outputs indicate that XGBoost achieved 99% F1-score for benign and data alteration, and 81% for spoofing. Explainability findings reveal that network data play a dominant role in intrusion detection whereas biomedical features contributed to spoofing detection, with temperature reaching a Shapley values magnitude of 0.37.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 7 figures, conference",
    "pdf_url": "https://arxiv.org/pdf/2506.17329v1",
    "published_date": "2025-06-19 01:23:06 UTC",
    "updated_date": "2025-06-19 01:23:06 UTC"
  },
  {
    "arxiv_id": "2506.15937v1",
    "title": "Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization",
    "authors": [
      "Yosub Shin",
      "Igor Molybog"
    ],
    "abstract": "Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15937v1",
    "published_date": "2025-06-19 00:41:21 UTC",
    "updated_date": "2025-06-19 00:41:21 UTC"
  },
  {
    "arxiv_id": "2506.15929v1",
    "title": "MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior",
    "authors": [
      "Liangyan Li",
      "Yimo Ning",
      "Kevin Le",
      "Wei Dong",
      "Yunzhe Li",
      "Jun Chen",
      "Xiaohong Liu"
    ],
    "abstract": "This paper introduces a novel framework for image and video demoiréing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoiréing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods.\n  Traditional supervised learning approaches either fail to remove moiré patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoiréing and often introduce artifacts.\n  To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoiréing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.15929v1",
    "published_date": "2025-06-19 00:15:07 UTC",
    "updated_date": "2025-06-19 00:15:07 UTC"
  },
  {
    "arxiv_id": "2506.15928v3",
    "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
    "authors": [
      "Myke C. Cohen",
      "Zhe Su",
      "Hsien-Te Kao",
      "Daniel Nguyen",
      "Spencer Lynch",
      "Maarten Sap",
      "Svitlana Volkova"
    ],
    "abstract": "This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the KDD 2025 Workshop on Evaluation and Trustworthiness of Agentic and Generative AI Models under the title \"Evaluating the LLM-simulated Impacts of Big Five Personality Traits and AI Capabilities on Social Negotiations\" (https://kdd-eval-workshop.github.io/genai-evaluation-kdd2025/assets/papers/Submission%2036.pdf)",
    "pdf_url": "https://arxiv.org/pdf/2506.15928v3",
    "published_date": "2025-06-19 00:14:56 UTC",
    "updated_date": "2025-08-20 19:36:39 UTC"
  }
]