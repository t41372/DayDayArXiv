{
  "date": "2025-04-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-05 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型的优化、安全应用和跨领域创新，包括 LLM 的机制分析、AI 伦理挑战（如 AI 诱发性骚扰）、医疗诊断模型（如心电图预测糖尿病）和新数据集构建。其中，AI 伦理相关文章（如论文 2）令人印象深刻，揭示了实际风险；医疗 AI 论文（如论文 7 和 8）有潜在的社会影响；知名学者如 Hanghang Tong 在论文 4 中的时间序列适应方法也值得关注。\n\n下面，我将挑选重点论文逐一讨论，先从高话题度和影响大的文章入手，并将相关主题归类讨论。对于次要或技术细节较少的论文，我会快速掠过，只列出标题和核心要点。\n\n### 重点论文讨论\n\n**AI 伦理与安全（高话题度，相关论文归类）**  \n- **AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot（AI 诱发性骚扰：调查伴侣聊天机器人性骚扰的语境特征和用户反应）**  \n  这篇论文通过分析 800 条用户评论，揭示了 AI 聊天机器人（如 Replika）可能导致的非预期的性骚扰行为，主要贡献是强调了 AI 系统的伦理风险，并呼吁开发者加强安全机制，如隐私保护和边界尊重，用户反馈显示了 AI 在社交中的潜在危害。\n\n- **Sensitivity Meets Sparsity: The Impact of Extremely Sparse Parameter Patterns on Theory-of-Mind of Large Language Models（敏感性遇上稀疏性：极端稀疏参数模式对大型语言模型理论心智的影响）**  \n  作者 Yuheng Wu 等研究了 LLM 中稀疏参数对理论心智（Theory-of-Mind）的机制影响，主要发现是扰动 0.001% 参数即可显著降低模型性能，并通过分析注意力机制揭示了潜在风险，这为提升 LLM 的鲁棒性和安全性提供了新见解。\n\n- **Enforcement Agents: Enhancing Accountability and Resilience in Multi-Agent AI Frameworks（执行代理：提升多代理 AI 框架中的责任性和弹性）**  \n  这篇快速掠过的论文提出了一种嵌入式监督代理机制，用于实时监测多代理系统，主要贡献是提高了系统安全性，在实验中成功率提升至 26.7%，但细节较基础。\n\n**医疗 AI 应用（实际影响大，相关论文归类）**  \n- **Improving Early Prediction of Type 2 Diabetes Mellitus with ECG-DiaNet: A Multimodal Neural Network Leveraging Electrocardiogram and Clinical Risk Factors（利用 ECG-DiaNet 提升 2 型糖尿病早期预测：整合心电图和临床风险因素的多模态神经网络）**  \n  作者 Farida Mohsen 等开发了 ECG-DiaNet 模型，通过结合心电图和临床数据，实现了 AUROC 0.845 的预测准确率，主要发现是多模态方法显著改善了糖尿病风险分层，具有实际医疗应用潜力。\n\n- **Improving Chronic Kidney Disease Detection Efficiency: Fine Tuned CatBoost and Nature-Inspired Algorithms with Explainable AI（提升慢性肾病检测效率：结合可解释 AI 的微调 CatBoost 和自然启发算法）**  \n  这篇论文使用微调 CatBoost 模型达到 98.75% 的准确率，并通过 SHAP 解释特征重要性（如血清肌酐），主要贡献是提供了一种高效的肾病诊断工具，适合资源有限的环境。\n\n**LLM 和数据优化（学术创新强）**  \n- **Sigma: A dataset for text-to-code semantic parsing with statistical analysis（Sigma：用于带统计分析的文本到代码语义解析的数据集）**  \n  作者 Saleh Almohaimeed 等构建了包含 6000 个问题的 Sigma 数据集，支持文本到 Python 代码的解析，主要发现是统计分析任务的执行准确率达 76.38%，这为语义解析研究提供了新基准。\n\n- **CATS: Mitigating Correlation Shift for Multivariate Time Series Classification（CATS：缓解多变量时间序列分类中的相关性偏移）**  \n  作者 Hanghang Tong 等提出的 CATS 方法通过图注意力模块提升了时间序列分类准确率 10%，主要贡献是作为 Transformer 的插件，高效处理相关性偏移，实验在真实数据集上表现出色。\n\n**其他印象深刻或相关论文（快速总结）**  \n- **Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks（超越炒作：嵌入式 vs. 提示式在多类分类任务中的比较）**  \n  这篇论文比较了嵌入式和提示式方法，发现嵌入式在准确率和效率上高出 49.5%，主要发现是嵌入式更适合实际部署。\n\n- **A Comparative Study of Explainable AI Methods: Model-Agnostic vs. Model-Specific Approaches（可解释 AI 方法的比较研究：模型无关 vs. 模型特定方法）**  \n  作者 Keerthi Devireddy 比较了 LIME 和 Grad-CAM 等方法，主要贡献是强调结合多种方法提升模型透明度，适合高风险领域。\n\n对于剩余论文，如 LOGLO-FNO（Fourier 神经算子的优化）、Progressive Multi-Source Domain Adaptation（多源域适应）、TrafficLLM（网络流量分析）等，我将快速掠过，只列标题和核心要点：  \n- **LOGLO-FNO: Efficient Learning of Local and Global Features in Fourier Neural Operators（LOGLO-FNO：高效学习 Fourier 神经算子中的局部和全局特征）**  \n  提出了一种改进的 Fourier 神经算子，提升了 PDE 问题的高频建模能力。  \n- **Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition（用于个性化面部表情识别的渐进式多源域适应）**  \n  开发了渐进式适应方法，减少负迁移，提高表情识别鲁棒性。  \n- **TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection（TARAC：通过实时注意力累积连接缓解大型视觉语言模型的幻觉）**  \n  一种训练-free 方法，减少 LVLMs 的幻觉生成。  \n\n其他如个人经历论文（My Life in Artificial Intelligence）或基础实验（如 Predicting Soil Macronutrient Levels）等，由于学术影响力较小，我仅简要提及为 AI 领域的回顾或应用探索，而不深入讨论。\n\n总之，今天的论文突显了 AI 在伦理、安全和实际应用中的挑战与潜力，读者可关注医疗和 LLM 相关内容以寻找感兴趣的方向。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.04301v1",
      "title": "Sigma: A dataset for text-to-code semantic parsing with statistical analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Saleh Almohaimeed",
        "Shenyang Liu",
        "May Alsofyani",
        "Saad Almohaimeed",
        "Liqiang Wang"
      ],
      "abstract": "In the domain of semantic parsing, significant progress has been achieved in\nText-to-SQL and question-answering tasks, both of which focus on extracting\ninformation from data sources in their native formats. However, the inherent\nconstraints of their formal meaning representations, such as SQL programming\nlanguage or basic logical forms, hinder their ability to analyze data from\nvarious perspectives, such as conducting statistical analyses. To address this\nlimitation and inspire research in this field, we design SIGMA, a new dataset\nfor Text-to-Code semantic parsing with statistical analysis. SIGMA comprises\n6000 questions with corresponding Python code labels, spanning across 160\ndatabases. Half of the questions involve query types, which return information\nin its original format, while the remaining 50% are statistical analysis\nquestions, which perform statistical operations on the data. The Python code\nlabels in our dataset cover 4 types of query types and 40 types of statistical\nanalysis patterns. We evaluated the SIGMA dataset using three different\nbaseline models: LGESQL, SmBoP, and SLSQL. The experimental results show that\nthe LGESQL model with ELECTRA outperforms all other models, achieving 83.37%\nstructure accuracy. In terms of execution accuracy, the SmBoP model, when\ncombined with GraPPa and T5, reaches 76.38%.",
      "tldr_zh": "该研究指出了现有Text-to-SQL和语义解析技术的局限性，无法有效进行统计分析，因此引入了SIGMA数据集，用于Text-to-Code语义解析。SIGMA包含6000个问题和对应的Python代码标签，覆盖160个数据库，其中一半是查询类型，另一半涉及统计分析操作，包括4种查询类型和40种统计分析模式。实验使用LGESQL、SmBoP和SLSQL等基线模型评估，结果显示LGESQL结合ELECTRA在结构准确率上达到83.37%，SmBoP结合GraPPa和T5在执行准确率上达到76.38%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "2023 International Conference on Machine Learning and Applications\n  (ICMLA) This version includes more details than the conference version",
      "pdf_url": "http://arxiv.org/pdf/2504.04301v1",
      "published_date": "2025-04-05 23:30:20 UTC",
      "updated_date": "2025-04-05 23:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:50:08.127062"
    },
    {
      "arxiv_id": "2504.04299v1",
      "title": "AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad",
        "Namvarpour",
        "Harrison Pauwels",
        "Afsaneh Razi"
      ],
      "abstract": "Advancements in artificial intelligence (AI) have led to the increase of\nconversational agents like Replika, designed to provide social interaction and\nemotional support. However, reports of these AI systems engaging in\ninappropriate sexual behaviors with users have raised significant concerns. In\nthis study, we conducted a thematic analysis of user reviews from the Google\nPlay Store to investigate instances of sexual harassment by the Replika\nchatbot. From a dataset of 35,105 negative reviews, we identified 800 relevant\ncases for analysis. Our findings revealed that users frequently experience\nunsolicited sexual advances, persistent inappropriate behavior, and failures of\nthe chatbot to respect user boundaries. Users expressed feelings of discomfort,\nviolation of privacy, and disappointment, particularly when seeking a platonic\nor therapeutic AI companion. This study highlights the potential harms\nassociated with AI companions and underscores the need for developers to\nimplement effective safeguards and ethical guidelines to prevent such\nincidents. By shedding light on user experiences of AI-induced harassment, we\ncontribute to the understanding of AI-related risks and emphasize the\nimportance of corporate responsibility in developing safer and more ethical AI\nsystems.",
      "tldr_zh": "这篇论文通过对 Google Play Store 的 35,105 条负面评论进行 thematic analysis，筛选出 800 例相关案例，调查了 Replika 聊天机器人引发的 AI-induced sexual harassment。研究发现，用户经常遭遇 unsolicited sexual advances、persistent inappropriate behavior 和 chatbot 对边界的不尊重，导致他们感到 discomfort、violation of privacy 以及 disappointment，尤其是在寻求 platonic 或 therapeutic AI 伴侣时。论文强调了 AI 伴侣的潜在危害，并呼吁开发者实施有效的 safeguards 和 ethical guidelines，以提升 AI 系统的安全性、道德性和企业责任。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.5; I.2.7; K.4.2"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication at CSCW 2025. This is a pre-publication\n  version; the final version will be available through the ACM Digital Library",
      "pdf_url": "http://arxiv.org/pdf/2504.04299v1",
      "published_date": "2025-04-05 23:04:37 UTC",
      "updated_date": "2025-04-05 23:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:50:21.673132"
    },
    {
      "arxiv_id": "2504.07983v2",
      "title": "Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method",
      "title_zh": "翻译失败",
      "authors": [
        "Shurui Wu",
        "Xinyi Huang",
        "Dingxin Lu"
      ],
      "abstract": "As the prevalence of mental health crises increases on social media\nplatforms, identifying and preventing potential harm has become an urgent\nchallenge. This study introduces a large language model (LLM)-based text\ntransfer recognition method for social network crisis intervention, enhanced\nwith domain-specific mental health knowledge. We propose a multi-level\nframework that incorporates transfer learning using BERT, and integrates mental\nhealth knowledge, sentiment analysis, and behavior prediction techniques. The\nframework includes a crisis annotation tool trained on social media datasets\nfrom real-world events, enabling the model to detect nuanced emotional cues and\nidentify psychological crises. Experimental results show that the proposed\nmethod outperforms traditional models in crisis detection accuracy and exhibits\ngreater sensitivity to subtle emotional and contextual variations.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型(LLM)的文本转移识别方法，用于社交网络危机干预，并通过整合特定领域的心理健康知识来提升识别效果。方法采用多级框架，包括BERT的转移学习、情感分析和行为预测技术，以及一个基于真实社交媒体数据集训练的危机标注工具，以检测细微情感线索和识别心理危机。实验结果表明，该方法在危机检测准确性上优于传统模型，并对微妙的情感和上下文变化表现出更高的敏感性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07983v2",
      "published_date": "2025-04-05 22:57:22 UTC",
      "updated_date": "2025-04-14 01:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:50:32.082273"
    },
    {
      "arxiv_id": "2504.04283v1",
      "title": "CATS: Mitigating Correlation Shift for Multivariate Time Series Classification",
      "title_zh": "CATS：缓解多变量时间序列分类的相关性偏移",
      "authors": [
        "Xiao Lin",
        "Zhichen Zeng",
        "Tianxin Wei",
        "Zhining Liu",
        "Yuzhong chen",
        "Hanghang Tong"
      ],
      "abstract": "Unsupervised Domain Adaptation (UDA) leverages labeled source data to train\nmodels for unlabeled target data. Given the prevalence of multivariate time\nseries (MTS) data across various domains, the UDA task for MTS classification\nhas emerged as a critical challenge. However, for MTS data, correlations\nbetween variables often vary across domains, whereas most existing UDA works\nfor MTS classification have overlooked this essential characteristic. To bridge\nthis gap, we introduce a novel domain shift, {\\em correlation shift}, measuring\ndomain differences in multivariate correlation. To mitigate correlation shift,\nwe propose a scalable and parameter-efficient \\underline{C}orrelation\n\\underline{A}dapter for M\\underline{TS} (CATS). Designed as a plug-and-play\ntechnique compatible with various Transformer variants, CATS employs temporal\nconvolution to capture local temporal patterns and a graph attention module to\nmodel the changing multivariate correlation. The adapter reweights the target\ncorrelations to align the source correlations with a theoretically guaranteed\nprecision. A correlation alignment loss is further proposed to mitigate\ncorrelation shift, bypassing the alignment challenge from the non-i.i.d. nature\nof MTS data. Extensive experiments on four real-world datasets demonstrate that\n(1) compared with vanilla Transformer-based models, CATS increases over $10\\%$\naverage accuracy while only adding around $1\\%$ parameters, and (2) all\nTransformer variants equipped with CATS either reach or surpass\nstate-of-the-art baselines.",
      "tldr_zh": "这篇论文针对多变量时间序列 (MTS) 分类中的无监督域适应 (UDA) 问题，引入了“correlation shift”概念来衡量变量间相关性的域差异，并提出了一种可扩展的参数高效适配器 CATS。CATS 设计为与各种 Transformer 变体兼容，利用 temporal convolution 捕获局部时间模式和 graph attention module 建模多变量相关性的变化，同时通过 correlation alignment loss 对齐源和目标相关性，以缓解 MTS 的非 i.i.d. 性质带来的挑战。实验在四个真实数据集上表明，CATS 使 Transformer 模型的平均准确率提高超过 10%，仅增加约 1% 参数，并达到或超过了最先进基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04283v1",
      "published_date": "2025-04-05 21:08:47 UTC",
      "updated_date": "2025-04-05 21:08:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:50:46.525092"
    },
    {
      "arxiv_id": "2504.04277v2",
      "title": "Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Marios Kokkodis",
        "Richard Demsyn-Jones",
        "Vijay Raghavan"
      ],
      "abstract": "Are traditional classification approaches irrelevant in this era of AI hype?\nWe show that there are multiclass classification problems where predictive\nmodels holistically outperform LLM prompt-based frameworks. Given text and\nimages from home-service project descriptions provided by Thumbtack customers,\nwe build embeddings-based softmax models that predict the professional category\n(e.g., handyman, bathroom remodeling) associated with each problem description.\nWe then compare against prompts that ask state-of-the-art LLM models to solve\nthe same problem. We find that the embeddings approach outperforms the best LLM\nprompts in terms of accuracy, calibration, latency, and financial cost. In\nparticular, the embeddings approach has 49.5% higher accuracy than the\nprompting approach, and its superiority is consistent across text-only,\nimage-only, and text-image problem descriptions. Furthermore, it yields\nwell-calibrated probabilities, which we later use as confidence signals to\nprovide contextualized user experience during deployment. On the contrary,\nprompting scores are overly uninformative. Finally, the embeddings approach is\n14 and 81 times faster than prompting in processing images and text\nrespectively, while under realistic deployment assumptions, it can be up to 10\ntimes cheaper. Based on these results, we deployed a variation of the\nembeddings approach, and through A/B testing we observed performance consistent\nwith our offline analysis. Our study shows that for multiclass classification\nproblems that can leverage proprietary datasets, an embeddings-based approach\nmay yield unequivocally better results. Hence, scientists, practitioners,\nengineers, and business leaders can use our study to go beyond the hype and\nconsider appropriate predictive models for their classification use cases.",
      "tldr_zh": "本研究比较了嵌入式(embeddings)方法与基于LLM提示(prompting)的框架在多类分类(multiclass classification)任务中的性能，使用Thumbtack的家庭服务项目描述（包括文本和图像）来预测专业类别。结果显示，嵌入式softmax模型在准确性上比提示方法高出49.5%，并在校准、延迟和成本方面均优越，例如处理图像快14倍、文本快81倍，且提供更可靠的概率校准用于用户体验。研究通过A/B测试验证了嵌入式方法的实际效果，并建议对于能利用专有数据集的分类任务，嵌入式方法可能更具优势，从而超越AI hype选择合适模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04277v2",
      "published_date": "2025-04-05 20:35:54 UTC",
      "updated_date": "2025-04-09 17:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:50:56.485315"
    },
    {
      "arxiv_id": "2504.04276v1",
      "title": "A Comparative Study of Explainable AI Methods: Model-Agnostic vs. Model-Specific Approaches",
      "title_zh": "可解释 AI 方法的比较研究：模型无关 vs. 模型特定方法",
      "authors": [
        "Keerthi Devireddy"
      ],
      "abstract": "This paper compares model-agnostic and model-specific approaches to\nexplainable AI (XAI) in deep learning image classification. I examine how LIME\nand SHAP (model-agnostic methods) differ from Grad-CAM and Guided\nBackpropagation (model-specific methods) when interpreting ResNet50 predictions\nacross diverse image categories. Through extensive testing with various species\nfrom dogs and birds to insects I found that each method reveals different\naspects of the models decision-making process. Model-agnostic techniques\nprovide broader feature attribution that works across different architectures,\nwhile model-specific approaches excel at highlighting precise activation\nregions with greater computational efficiency. My analysis shows there is no\n\"one-size-fits-all\" solution for model interpretability. Instead, combining\nmultiple XAI methods offers the most comprehensive understanding of complex\nmodels particularly valuable in high-stakes domains like healthcare, autonomous\nvehicles, and financial services where transparency is crucial. This\ncomparative framework provides practical guidance for selecting appropriate\ninterpretability techniques based on specific application needs and\ncomputational constraints.",
      "tldr_zh": "这篇论文比较了可解释 AI (XAI) 的模型无关方法（如 LIME 和 SHAP）和模型特定方法（如 Grad-CAM 和 Guided Backpropagation），通过测试 ResNet50 在各种图像分类任务（如狗、鸟和昆虫类别）上的预测表现。研究发现，模型无关方法提供更广泛的特征归因，适用于不同架构，而模型特定方法在突出精确激活区域和计算效率方面更具优势。结果表明，没有一种“一刀切”的解决方案，结合多种 XAI 方法能实现对复杂模型的最全面理解，尤其在高风险领域如医疗、自动驾驶和金融服务中至关重要。该框架为根据应用需求和计算约束选择适当的解释技术提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04276v1",
      "published_date": "2025-04-05 20:13:20 UTC",
      "updated_date": "2025-04-05 20:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:51:09.056469"
    },
    {
      "arxiv_id": "2504.05338v1",
      "title": "Improving Early Prediction of Type 2 Diabetes Mellitus with ECG-DiaNet: A Multimodal Neural Network Leveraging Electrocardiogram and Clinical Risk Factors",
      "title_zh": "利用 ECG-DiaNet 改善 ",
      "authors": [
        "Farida Mohsen",
        "Zubair Shah"
      ],
      "abstract": "Type 2 Diabetes Mellitus (T2DM) remains a global health challenge,\nunderscoring the need for early and accurate risk prediction. This study\npresents ECG-DiaNet, a multimodal deep learning model that integrates\nelectrocardiogram (ECG) features with clinical risk factors (CRFs) to enhance\nT2DM onset prediction. Using data from Qatar Biobank (QBB), we trained and\nvalidated models on a development cohort (n=2043) and evaluated performance on\na longitudinal test set (n=395) with five-year follow-up. ECG-DiaNet\noutperformed unimodal ECG-only and CRF-only models, achieving a higher AUROC\n(0.845 vs 0.8217) than the CRF-only model, with statistical significance\n(DeLong p<0.001). Reclassification metrics further confirmed improvements: Net\nReclassification Improvement (NRI=0.0153) and Integrated Discrimination\nImprovement (IDI=0.0482). Risk stratification into low-, medium-, and high-risk\ngroups showed ECG-DiaNet achieved superior positive predictive value (PPV) in\nhigh-risk individuals. The model's reliance on non-invasive and widely\navailable ECG signals supports its feasibility in clinical and community health\nsettings. By combining cardiac electrophysiology and systemic risk profiles,\nECG-DiaNet addresses the multifactorial nature of T2DM and supports precision\nprevention. These findings highlight the value of multimodal AI in advancing\nearly detection and prevention strategies for T2DM, particularly in\nunderrepresented Middle Eastern populations.",
      "tldr_zh": "本文提出 ECG-DiaNet，一种多模态深度学习模型，将心电图 (ECG) 特征与临床风险因素 (CRFs) 整合，用于提升 Type 2 Diabetes Mellitus (T2DM) 早期预测的准确性。使用 Qatar Biobank 数据进行训练和验证，该模型在测试集上实现了更高的 AUROC (0.845)，比 CRF-only 模型显著提升 (p<0.001)，并在风险分层中显示出更好的正预测值 (PPV)，同时改善了 Net Reclassification Improvement (NRI=0.0153) 和 Integrated Discrimination Improvement (IDI=0.0482)。ECG-DiaNet 依赖于非侵入性和广泛可用的 ECG 信号，支持 T2DM 的精确预防策略，尤其在中东等 underrepresented 人群中展现出重要价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05338v1",
      "published_date": "2025-04-05 19:59:59 UTC",
      "updated_date": "2025-04-05 19:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:51:23.068257"
    },
    {
      "arxiv_id": "2504.04262v1",
      "title": "Improving Chronic Kidney Disease Detection Efficiency: Fine Tuned CatBoost and Nature-Inspired Algorithms with Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Ehsanul Haque",
        "S. M. Jahidul Islam",
        "Jeba Maliha",
        "Md. Shakhauat Hossan Sumon",
        "Rumana Sharmin",
        "Sakib Rokoni"
      ],
      "abstract": "Chronic Kidney Disease (CKD) is a major global health issue which is\naffecting million people around the world and with increasing rate of\nmortality. Mitigation of progression of CKD and better patient outcomes\nrequires early detection. Nevertheless, limitations lie in traditional\ndiagnostic methods, especially in resource constrained settings. This study\nproposes an advanced machine learning approach to enhance CKD detection by\nevaluating four models: Random Forest (RF), Multi-Layer Perceptron (MLP),\nLogistic Regression (LR), and a fine-tuned CatBoost algorithm. Specifically,\namong these, the fine-tuned CatBoost model demonstrated the best overall\nperformance having an accuracy of 98.75%, an AUC of 0.9993 and a Kappa score of\n97.35% of the studies. The proposed CatBoost model has used a nature inspired\nalgorithm such as Simulated Annealing to select the most important features,\nCuckoo Search to adjust outliers and grid search to fine tune its settings in\nsuch a way to achieve improved prediction accuracy. Features significance is\nexplained by SHAP-a well-known XAI technique-for gaining transparency in the\ndecision-making process of proposed model and bring up trust in diagnostic\nsystems. Using SHAP, the significant clinical features were identified as\nspecific gravity, serum creatinine, albumin, hemoglobin, and diabetes mellitus.\nThe potential of advanced machine learning techniques in CKD detection is shown\nin this research, particularly for low income and middle-income healthcare\nsettings where prompt and correct diagnoses are vital. This study seeks to\nprovide a highly accurate, interpretable, and efficient diagnostic tool to add\nto efforts for early intervention and improved healthcare outcomes for all CKD\npatients.",
      "tldr_zh": "本研究针对慢性肾病（CKD）的早期检测问题，提出了一种先进的机器学习方法，通过评估Random Forest (RF)、Multi-Layer Perceptron (MLP)、Logistic Regression (LR)以及fine-tuned CatBoost算法，其中fine-tuned CatBoost表现出色，实现了98.75%的准确率、0.9993的AUC和97.35%的Kappa分数。CatBoost模型利用Simulated Annealing选择重要特征、Cuckoo Search调整异常值以及grid search微调参数，以提升预测准确性，并通过SHAP（XAI技术）解释决策过程，识别出关键临床特征如specific gravity、serum creatinine、albumin、hemoglobin和diabetes mellitus。该方法为资源有限的低收入和中等收入地区提供高效、可解释的诊断工具，促进CKD的早期干预和患者预后改善。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 page, 8 figures , conference : 14th IEEE International Conference\n  on Communication Systems and Network Technologies (CSNT2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.04262v1",
      "published_date": "2025-04-05 19:41:47 UTC",
      "updated_date": "2025-04-05 19:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:51:32.868269"
    },
    {
      "arxiv_id": "2504.04260v1",
      "title": "LOGLO-FNO: Efficient Learning of Local and Global Features in Fourier Neural Operators",
      "title_zh": "LOGLO-FNO：高效学习傅立叶神经算子中的局部",
      "authors": [
        "Marimuthu Kalimuthu",
        "David Holzmüller",
        "Mathias Niepert"
      ],
      "abstract": "Modeling high-frequency information is a critical challenge in scientific\nmachine learning. For instance, fully turbulent flow simulations of\nNavier-Stokes equations at Reynolds numbers 3500 and above can generate\nhigh-frequency signals due to swirling fluid motions caused by eddies and\nvortices. Faithfully modeling such signals using neural networks depends on\naccurately reconstructing moderate to high frequencies. However, it has been\nwell known that deep neural nets exhibit the so-called spectral bias toward\nlearning low-frequency components. Meanwhile, Fourier Neural Operators (FNOs)\nhave emerged as a popular class of data-driven models in recent years for\nsolving Partial Differential Equations (PDEs) and for surrogate modeling in\ngeneral. Although impressive results have been achieved on several PDE\nbenchmark problems, FNOs often perform poorly in learning non-dominant\nfrequencies characterized by local features. This limitation stems from the\nspectral bias inherent in neural networks and the explicit exclusion of\nhigh-frequency modes in FNOs and their variants. Therefore, to mitigate these\nissues and improve FNO's spectral learning capabilities to represent a broad\nrange of frequency components, we propose two key architectural enhancements:\n(i) a parallel branch performing local spectral convolutions (ii) a\nhigh-frequency propagation module. Moreover, we propose a novel\nfrequency-sensitive loss term based on radially binned spectral errors. This\nintroduction of a parallel branch for local convolutions reduces number of\ntrainable parameters by up to 50% while achieving the accuracy of baseline FNO\nthat relies solely on global convolutions. Experiments on three challenging PDE\nproblems in fluid mechanics and biological pattern formation, and the\nqualitative and spectral analysis of predictions show the effectiveness of our\nmethod over the state-of-the-art neural operator baselines.",
      "tldr_zh": "该论文提出LOGLO-FNO，一种改进的Fourier Neural Operators (FNOs)，旨在解决神经网络的谱偏置(spectral bias)问题，从而更好地学习PDE（如Navier-Stokes方程）中的局部和全局特征，特别是高频信号。关键创新包括添加一个并行分支进行局部谱卷积(local spectral convolutions)和一个高频传播模块(high-frequency propagation module)，并引入基于径向分箱谱错误(radially binned spectral errors)的频率敏感损失函数(frequency-sensitive loss term)。实验结果显示，该方法在流体力学和生物模式形成等三个挑战性PDE问题上，比现有神经算子基线提升了性能，同时将可训练参数减少多达50%。这为高效建模高频信息提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Oral Presentation at the ICLR 2025 Workshop on Machine\n  Learning Multiscale Processes (MLMP), Singapura",
      "pdf_url": "http://arxiv.org/pdf/2504.04260v1",
      "published_date": "2025-04-05 19:35:04 UTC",
      "updated_date": "2025-04-05 19:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:51:44.358006"
    },
    {
      "arxiv_id": "2504.04252v1",
      "title": "Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition",
      "title_zh": "渐进式多源领域适应用于个性化面部表情识别",
      "authors": [
        "Muhammad Osama Zeeshan",
        "Marco Pedersoli",
        "Alessandro Lameiras Koerich",
        "Eric Grange"
      ],
      "abstract": "Personalized facial expression recognition (FER) involves adapting a machine\nlearning model using samples from labeled sources and unlabeled target domains.\nGiven the challenges of recognizing subtle expressions with considerable\ninterpersonal variability, state-of-the-art unsupervised domain adaptation\n(UDA) methods focus on the multi-source UDA (MSDA) setting, where each domain\ncorresponds to a specific subject, and improve model accuracy and robustness.\nHowever, when adapting to a specific target, the diverse nature of multiple\nsource domains translates to a large shift between source and target data.\nState-of-the-art MSDA methods for FER address this domain shift by considering\nall the sources to adapt to the target representations. Nevertheless, adapting\nto a target subject presents significant challenges due to large distributional\ndifferences between source and target domains, often resulting in negative\ntransfer. In addition, integrating all sources simultaneously increases\ncomputational costs and causes misalignment with the target. To address these\nissues, we propose a progressive MSDA approach that gradually introduces\ninformation from subjects based on their similarity to the target subject. This\nwill ensure that only the most relevant sources from the target are selected,\nwhich helps avoid the negative transfer caused by dissimilar sources. We first\nexploit the closest sources to reduce the distribution shift with the target\nand then move towards the furthest while only considering the most relevant\nsources based on the predetermined threshold. Furthermore, to mitigate\ncatastrophic forgetting caused by the incremental introduction of source\nsubjects, we implemented a density-based memory mechanism that preserves the\nmost relevant historical source samples for adaptation. Our experiments show\nthe effectiveness of our proposed method on pain datasets: Biovid and\nUNBC-McMaster.",
      "tldr_zh": "本文提出了一种渐进式多源域适应 (MSDA) 方法，用于个性化面部表情识别 (FER)，旨在解决多源域间的大分布偏移问题，该问题可能导致负转移和计算成本增加。方法通过根据源域与目标域的相似度逐步引入相关源域信息，先从最相似的源域开始减少分布偏移，然后仅考虑通过预设阈值的源域，同时采用基于密度的记忆机制来缓解灾难性遗忘。实验结果在 Biovid 和 UNBC-McMaster 疼痛数据集上验证了该方法的有效性，提高了模型的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04252v1",
      "published_date": "2025-04-05 19:14:51 UTC",
      "updated_date": "2025-04-05 19:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:51:56.939187"
    },
    {
      "arxiv_id": "2504.04248v1",
      "title": "Task load dependent decision referrals for joint binary classification in human-automation teams",
      "title_zh": "任务负载",
      "authors": [
        "Kesav Kaza",
        "Jerome Le Ny",
        "Aditya Mahajan"
      ],
      "abstract": "We consider the problem of optimal decision referrals in human-automation\nteams performing binary classification tasks. The automation, which includes a\npre-trained classifier, observes data for a batch of independent tasks,\nanalyzes them, and may refer a subset of tasks to a human operator for fresh\nand final analysis. Our key modeling assumption is that human performance\ndegrades with task load. We model the problem of choosing which tasks to refer\nas a stochastic optimization problem and show that, for a given task load, it\nis optimal to myopically refer tasks that yield the largest reduction in\nexpected cost, conditional on the observed data. This provides a ranking scheme\nand a policy to determine the optimal set of tasks for referral. We evaluate\nthis policy against a baseline through an experimental study with human\nparticipants. Using a radar screen simulator, participants made binary target\nclassification decisions under time constraint. They were guided by a decision\nrule provided to them, but were still prone to errors under time pressure. An\ninitial experiment estimated human performance model parameters, while a second\nexperiment compared two referral policies. Results show statistically\nsignificant gains for the proposed optimal referral policy over a blind policy\nthat determines referrals using the automation and human-performance models but\nnot based on the observed data.",
      "tldr_zh": "该研究探讨了人类-自动化团队在二元分类(binary classification)任务中的决策转介问题，重点考虑任务负载对人类性能的负面影响。作者将转介任务建模为随机优化(stochastic optimization)问题，并证明最优策略是基于观察数据，近视地选择能最大减少预期成本的任务，从而提供一个排名方案和转介政策。通过实验研究，使用雷达屏幕模拟器，参与者在时间压力下进行目标分类决策，结果显示该最优转介政策比不依赖观察数据的盲策略有统计显著的性能提升。总的来说，该方法为提升人类-自动化团队的协作效率提供了实用框架。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.HC",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "9 pages, 6 figures. Submitted to IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.04248v1",
      "published_date": "2025-04-05 19:09:04 UTC",
      "updated_date": "2025-04-05 19:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:52:08.117018"
    },
    {
      "arxiv_id": "2504.04244v1",
      "title": "From Automation to Autonomy in Smart Manufacturing: A Bayesian Optimization Framework for Modeling Multi-Objective Experimentation and Sequential Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Avijit Saha Asru",
        "Hamed Khosravi",
        "Imtiaz Ahmed",
        "Abdullahil Azeem"
      ],
      "abstract": "Discovering novel materials with desired properties is essential for driving\ninnovation. Industry 4.0 and smart manufacturing have promised transformative\nadvances in this area through real-time data integration and automated\nproduction planning and control. However, the reliance on automation alone has\noften fallen short, lacking the flexibility needed for complex processes. To\nfully unlock the potential of smart manufacturing, we must evolve from\nautomation to autonomous systems that go beyond rigid programming and can\ndynamically optimize the search for solutions. Current discovery approaches are\noften slow, requiring numerous trials to find optimal combinations, and costly,\nparticularly when optimizing multiple properties simultaneously. This paper\nproposes a Bayesian multi-objective sequential decision-making (BMSDM)\nframework that can intelligently select experiments as manufacturing\nprogresses, guiding us toward the discovery of optimal design faster and more\nefficiently. The framework leverages sequential learning through Bayesian\nOptimization, which iteratively refines a statistical model representing the\nunderlying manufacturing process. This statistical model acts as a surrogate,\nallowing for efficient exploration and optimization without requiring numerous\nreal-world experiments. This approach can significantly reduce the time and\ncost of data collection required by traditional experimental designs. The\nproposed framework is compared with traditional DoE methods and two other\nmulti-objective optimization methods. Using a manufacturing dataset, we\nevaluate and compare the performance of these approaches across five evaluation\nmetrics. BMSDM comprehensively outperforms the competing methods in\nmulti-objective decision-making scenarios. Our proposed approach represents a\nsignificant leap forward in creating an intelligent autonomous platform capable\nof novel material discovery.",
      "tldr_zh": "本文从智能制造的自动化转向自治系统，提出一个Bayesian multi-objective sequential decision-making (BMSDM) 框架，以加速新型材料的发现并优化多目标实验。框架通过Bayesian Optimization 进行顺序学习，构建统计模型作为代理，智能选择实验从而减少实际试验的时间和成本。相比传统DoE方法和其他多目标优化方法，BMSDM 在制造数据集上的五种评估指标中表现出全面优越性能。该方法标志着智能制造向高效自治平台的重要跃进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04244v1",
      "published_date": "2025-04-05 18:21:20 UTC",
      "updated_date": "2025-04-05 18:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:52:20.442630"
    },
    {
      "arxiv_id": "2504.04243v2",
      "title": "Perils of Label Indeterminacy: A Case Study on Prediction of Neurological Recovery After Cardiac Arrest",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Schoeffer",
        "Maria De-Arteaga",
        "Jonathan Elmer"
      ],
      "abstract": "The design of AI systems to assist human decision-making typically requires\nthe availability of labels to train and evaluate supervised models. Frequently,\nhowever, these labels are unknown, and different ways of estimating them\ninvolve unverifiable assumptions or arbitrary choices. In this work, we\nintroduce the concept of label indeterminacy and derive important implications\nin high-stakes AI-assisted decision-making. We present an empirical study in a\nhealthcare context, focusing specifically on predicting the recovery of\ncomatose patients after resuscitation from cardiac arrest. Our study shows that\nlabel indeterminacy can result in models that perform similarly when evaluated\non patients with known labels, but vary drastically in their predictions for\npatients where labels are unknown. After demonstrating crucial ethical\nimplications of label indeterminacy in this high-stakes context, we discuss\ntakeaways for evaluation, reporting, and design.",
      "tldr_zh": "这篇论文引入了标签不确定性（label indeterminacy）的概念，探讨其在高风险 AI 辅助决策中的潜在问题，特别是当标签未知时所带来的不可靠性。研究通过一个医疗案例分析，焦点是预测心脏骤停后昏迷患者的神志恢复，结果显示模型在已知标签患者上表现相似，但在未知标签患者上预测差异巨大。作者强调了这种不确定性在伦理方面的关键影响，包括决策偏差的风险。最后，论文为 AI 系统的评估、报告和设计提供了实用启示，以提升可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "The 2025 ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT '25)",
      "pdf_url": "http://arxiv.org/pdf/2504.04243v2",
      "published_date": "2025-04-05 18:07:36 UTC",
      "updated_date": "2025-05-07 20:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:52:32.029033"
    },
    {
      "arxiv_id": "2504.04241v1",
      "title": "oneDAL Optimization for ARM Scalable Vector Extension: Maximizing Efficiency for High-Performance Data Science",
      "title_zh": "翻译失败",
      "authors": [
        "Chandan Sharma",
        "Rakshith GB",
        "Ajay Kumar Patel",
        "Dhanus M Lal",
        "Darshan Patel",
        "Ragesh Hajela",
        "Masahiro Doteguchi",
        "Priyanka Sharma"
      ],
      "abstract": "The evolution of ARM-based architectures, particularly those incorporating\nScalable Vector Extension (SVE), has introduced transformative opportunities\nfor high-performance computing (HPC) and machine learning (ML) workloads. The\nUnified Acceleration Foundation's (UXL) oneAPI Data Analytics Library (oneDAL)\nis a widely adopted library for accelerating ML and data analytics workflows,\nbut its reliance on Intel's proprietary Math Kernel Library (MKL) has\ntraditionally limited its compatibility to x86platforms. This paper details the\nporting of oneDAL to ARM architectures with SVE support, using OpenBLAS as an\nalternative backend to overcome architectural and performance challenges.\nBeyond porting, the research introduces novel ARM-specific optimizations,\nincluding custom sparse matrix routines, vectorized statistical functions, and\na Scalable Vector Extension (SVE)-optimized Support Vector Machine (SVM)\nalgorithm. The SVM enhancements leverage SVE's flexible vector lengths and\npredicate driven execution, achieving notable performance gains of 22% for the\nBoser method and 5% for the Thunder method. Benchmarks conducted on ARM\nSVE-enabled AWSGraviton3 instances showcase up to 200x acceleration in ML\ntraining and inference tasks compared to the original scikit-learn\nimplementation on the ARM platform. Moreover, the ARM-optimized oneDAL achieves\nperformance parity with, and in some cases exceeds, the x86 oneDAL\nimplementation (MKL backend) on IceLake x86 systems, which are nearly twice as\ncostly as AWSGraviton3 ARM instances. These findings highlight ARM's potential\nas a high-performance, energyefficient platform for dataintensive ML\napplications. By expanding cross-architecture compatibility and contributing to\nthe opensource ecosystem, this work reinforces ARM's position as a competitive\nalternative in the HPC and ML domains, paving the way for future advancements\nin dataintensive computing.",
      "tldr_zh": "这篇论文介绍了将 oneAPI Data Analytics Library (oneDAL) 移植到 ARM 架构并优化 Scalable Vector Extension (SVE)，以提升高性能计算 (HPC) 和机器学习 (ML) 工作负载的效率。研究采用 OpenBLAS 作为后端替代，并引入 ARM 特定优化，包括自定义稀疏矩阵例程、矢量化统计函数，以及 SVE 优化的 Support Vector Machine (SVM) 算法，使 Boser 方法性能提升 22% 和 Thunder 方法提升 5%。实验在 ARM SVE 启用的 AWS Graviton3 实例上显示，与原 scikit-learn 实现相比，ML 训练和推理任务加速高达 200 倍，并在某些场景下超越 x86 oneDAL (MKL 后端)，突显 ARM 在数据密集型应用的成本效益和潜力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04241v1",
      "published_date": "2025-04-05 17:53:36 UTC",
      "updated_date": "2025-04-05 17:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:52:46.860964"
    },
    {
      "arxiv_id": "2504.04238v1",
      "title": "Sensitivity Meets Sparsity: The Impact of Extremely Sparse Parameter Patterns on Theory-of-Mind of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Wu",
        "Wentao Guo",
        "Zirui Liu",
        "Heng Ji",
        "Zhaozhuo Xu",
        "Denghui Zhang"
      ],
      "abstract": "This paper investigates the emergence of Theory-of-Mind (ToM) capabilities in\nlarge language models (LLMs) from a mechanistic perspective, focusing on the\nrole of extremely sparse parameter patterns. We introduce a novel method to\nidentify ToM-sensitive parameters and reveal that perturbing as little as\n0.001% of these parameters significantly degrades ToM performance while also\nimpairing contextual localization and language understanding. To understand\nthis effect, we analyze their interaction with core architectural components of\nLLMs. Our findings demonstrate that these sensitive parameters are closely\nlinked to the positional encoding module, particularly in models using Rotary\nPosition Embedding (RoPE), where perturbations disrupt dominant-frequency\nactivations critical for contextual processing. Furthermore, we show that\nperturbing ToM-sensitive parameters affects LLM's attention mechanism by\nmodulating the angle between queries and keys under positional encoding. These\ninsights provide a deeper understanding of how LLMs acquire social reasoning\nabilities, bridging AI interpretability with cognitive science. Our results\nhave implications for enhancing model alignment, mitigating biases, and\nimproving AI systems designed for human interaction.",
      "tldr_zh": "本文从机制角度探讨大型语言模型 (LLMs) 中 Theory-of-Mind (ToM) 能力的出现，重点关注极度稀疏的参数模式。研究引入新方法识别 ToM-sensitive 参数，发现扰动仅 0.001% 的这些参数即可显著降低 ToM 性能，同时影响上下文定位和语言理解。分析显示，这些参数与位置编码模块（如 Rotary Position Embedding (RoPE)）紧密相关，扰动会破坏主导频率激活和注意力机制中的查询-键角度。总体而言，此研究加深了对 LLMs 社会推理能力的理解，并为提升模型对齐、缓解偏差和优化人类交互 AI 系统提供了重要启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04238v1",
      "published_date": "2025-04-05 17:45:42 UTC",
      "updated_date": "2025-04-05 17:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:52:58.471395"
    },
    {
      "arxiv_id": "2504.12309v2",
      "title": "Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-De Lin",
        "Guan-Ze Liao"
      ],
      "abstract": "From 2000 to 2015, the UN's Millennium Development Goals guided global\npriorities. The subsequent Sustainable Development Goals (SDGs) adopted a more\ndynamic approach, with annual indicator updates. As 2030 nears and progress\nlags, innovative acceleration strategies are critical. This study develops an\nAI-powered knowledge graph system to analyze SDG interconnections, discover\npotential new goals, and visualize them online. Using official SDG texts,\nElsevier's keyword dataset, and 1,127 TED Talk transcripts (2020.01-2024.04), a\npilot on 269 talks from 2023 applies AI-speculative design, large language\nmodels, and retrieval-augmented generation. Key findings include: (1) Heatmap\nanalysis reveals strong associations between Goal 10 and Goal 16, and minimal\ncoverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time\nreveals new central nodes, showing how richer data supports divergent thinking\nand goal clarity. (3) Six potential new goals are proposed, centered on equity,\nresilience, and technology-driven inclusion. This speculative-AI framework\noffers fresh insights for policymakers and lays groundwork for future\nmultimodal and cross-system SDG applications.",
      "tldr_zh": "本研究基于Large Language Models开发了一个AI驱动的知识图谱系统，用于分析Sustainable Development Goals (SDGs)的相互关联、发现潜在新目标，并进行在线可视化。研究利用官方SDG文本、Elsevier的关键字数据集和1127个TED演讲稿（2020.01-2024.04），以2023年的269个演讲作为试点，结合AI-speculative design和Retrieval-Augmented Generation方法进行分析。关键发现包括：热力图显示Goal 10与Goal 16有强关联，而Goal 6覆盖较少；模拟对话揭示新中心节点，支持发散思维和目标清晰度；并提出六个潜在新目标，聚焦于equity、resilience和technology-driven inclusion。该框架为决策者提供新见解，并为未来多模态和跨系统SDG应用奠定基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "This is a minor revision: fixed a typo in the abstract (time range)\n  and corrected minor textual errors",
      "pdf_url": "http://arxiv.org/pdf/2504.12309v2",
      "published_date": "2025-04-05 17:11:53 UTC",
      "updated_date": "2025-04-18 05:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:53:09.623133"
    },
    {
      "arxiv_id": "2504.04222v2",
      "title": "TrafficLLM: Enhancing Large Language Models for Network Traffic Analysis with Generic Traffic Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Cui",
        "Xinjie Lin",
        "Sijia Li",
        "Miao Chen",
        "Qilei Yin",
        "Qi Li",
        "Ke Xu"
      ],
      "abstract": "Machine learning (ML) powered network traffic analysis has been widely used\nfor the purpose of threat detection. Unfortunately, their generalization across\ndifferent tasks and unseen data is very limited. Large language models (LLMs),\nknown for their strong generalization capabilities, have shown promising\nperformance in various domains. However, their application to the traffic\nanalysis domain is limited due to significantly different characteristics of\nnetwork traffic. To address the issue, in this paper, we propose TrafficLLM,\nwhich introduces a dual-stage fine-tuning framework to learn generic traffic\nrepresentation from heterogeneous raw traffic data. The framework uses\ntraffic-domain tokenization, dual-stage tuning pipeline, and extensible\nadaptation to help LLM release generalization ability on dynamic traffic\nanalysis tasks, such that it enables traffic detection and traffic generation\nacross a wide range of downstream tasks. We evaluate TrafficLLM across 10\ndistinct scenarios and 229 types of traffic. TrafficLLM achieves F1-scores of\n0.9875 and 0.9483, with up to 80.12% and 33.92% better performance than\nexisting detection and generation methods. It also shows strong generalization\non unseen traffic with an 18.6% performance improvement. We further evaluate\nTrafficLLM in real-world scenarios. The results confirm that TrafficLLM is easy\nto scale and achieves accurate detection performance on enterprise traffic.",
      "tldr_zh": "该研究提出 TrafficLLM，一种双阶段微调框架，用于增强 Large Language Models (LLMs) 在网络流量分析中的泛化能力，通过学习通用的流量表示来处理异构原始流量数据。\n框架采用流量领域分词（traffic-domain tokenization）、双阶段调优管道和可扩展适应，帮助 LLMs 在动态任务中实现流量检测和生成等功能。\n实验评估显示，TrafficLLM 在 10 个场景和 229 种流量类型上达到 F1-scores 为 0.9875 和 0.9483，比现有方法提升高达 80.12% 和 33.92%，并在未见流量上改善 18.6%，在真实世界场景中表现出色易于扩展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04222v2",
      "published_date": "2025-04-05 16:18:33 UTC",
      "updated_date": "2025-04-15 08:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:53:22.030151"
    },
    {
      "arxiv_id": "2504.04215v1",
      "title": "Towards Understanding and Improving Refusal in Compressed Models via Mechanistic Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Vishnu Kabir Chhabra",
        "Mohammad Mahdi Khalili"
      ],
      "abstract": "The rapid growth of large language models has spurred significant interest in\nmodel compression as a means to enhance their accessibility and practicality.\nWhile extensive research has explored model compression through the lens of\nsafety, findings suggest that safety-aligned models often lose elements of\ntrustworthiness post-compression. Simultaneously, the field of mechanistic\ninterpretability has gained traction, with notable discoveries, such as the\nidentification of a single direction in the residual stream mediating refusal\nbehaviors across diverse model architectures. In this work, we investigate the\nsafety of compressed models by examining the mechanisms of refusal, adopting a\nnovel interpretability-driven perspective to evaluate model safety.\nFurthermore, leveraging insights from our interpretability analysis, we propose\na lightweight, computationally efficient method to enhance the safety of\ncompressed models without compromising their performance or utility.",
      "tldr_zh": "本研究探讨了大型语言模型压缩后安全性的问题，特别是拒绝行为（refusal）的丢失，通过Mechanistic Interpretability机制解释性视角进行分析。研究发现，残差流中一个单一方向能调解多种模型架构的拒绝行为，为理解压缩模型的安全机制提供了关键洞见。基于此分析，作者提出了一种轻量级、高效的方法来提升压缩模型的安全性，同时保持其性能和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04215v1",
      "published_date": "2025-04-05 16:00:44 UTC",
      "updated_date": "2025-04-05 16:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:53:32.017085"
    },
    {
      "arxiv_id": "2504.04204v1",
      "title": "Adaptive Elicitation of Latent Information Using Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Jimmy Wang",
        "Thomas Zollo",
        "Richard Zemel",
        "Hongseok Namkoong"
      ],
      "abstract": "Eliciting information to reduce uncertainty about a latent entity is a\ncritical task in many application domains, e.g., assessing individual student\nlearning outcomes, diagnosing underlying diseases, or learning user\npreferences. Though natural language is a powerful medium for this purpose,\nlarge language models (LLMs) and existing fine-tuning algorithms lack\nmechanisms for strategically gathering information to refine their own\nunderstanding of the latent entity. To harness the generalization power and\nworld knowledge of LLMs in developing effective information-gathering\nstrategies, we propose an adaptive elicitation framework that actively reduces\nuncertainty on the latent entity. Since probabilistic modeling of an abstract\nlatent entity is difficult, our framework adopts a predictive view of\nuncertainty, using a meta-learned language model to simulate future\nobservations and enable scalable uncertainty quantification over complex\nnatural language. Through autoregressive forward simulation, our model\nquantifies how new questions reduce epistemic uncertainty, enabling the\ndevelopment of sophisticated information-gathering strategies to choose the\nmost informative next queries. In experiments on the 20 questions game, dynamic\nopinion polling, and adaptive student assessment, our method consistently\noutperforms baselines in identifying critical unknowns and improving downstream\npredictions, illustrating the promise of strategic information gathering in\nnatural language settings.",
      "tldr_zh": "该研究提出了一种自适应获取框架（adaptive elicitation framework），利用大型语言模型（LLMs）通过战略性查询来主动减少对潜在实体的不确定性，例如在教育、医疗或用户偏好评估中。框架采用元学习语言模型模拟未来观察，并通过自回归前向模拟量化新问题如何降低认识不确定性，从而选择最优信息收集策略。在20 questions游戏、动态民意调查和自适应学生评估等实验中，该方法优于基线模型，在识别关键未知和改善下游预测方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04204v1",
      "published_date": "2025-04-05 15:18:55 UTC",
      "updated_date": "2025-04-05 15:18:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:53:44.827318"
    },
    {
      "arxiv_id": "2504.04170v2",
      "title": "Digital Gene: Learning about the Physical World through Analytic Concepts",
      "title_zh": "Digital Gene：通过分析概念学习物理世界",
      "authors": [
        "Jianhua Sun",
        "Cewu Lu"
      ],
      "abstract": "Reviewing the progress in artificial intelligence over the past decade,\nvarious significant advances (e.g. object detection, image generation, large\nlanguage models) have enabled AI systems to produce more semantically\nmeaningful outputs and achieve widespread adoption in internet scenarios.\nNevertheless, AI systems still struggle when it comes to understanding and\ninteracting with the physical world. This reveals an important issue: relying\nsolely on semantic-level concepts learned from internet data (e.g. texts,\nimages) to understand the physical world is far from sufficient -- machine\nintelligence currently lacks an effective way to learn about the physical\nworld. This research introduces the idea of analytic concept -- representing\nthe concepts related to the physical world through programs of mathematical\nprocedures, providing machine intelligence a portal to perceive, reason about,\nand interact with the physical world. Except for detailing the design\nphilosophy and providing guidelines for the application of analytic concepts,\nthis research also introduce about the infrastructure that has been built\naround analytic concepts. I aim for my research to contribute to addressing\nthese questions: What is a proper abstraction of general concepts in the\nphysical world for machine intelligence? How to systematically integrate\nstructured priors with neural networks to constrain AI systems to comply with\nphysical laws?",
      "tldr_zh": "这篇论文探讨了人工智能在理解物理世界方面的局限性，指出依赖互联网数据（如文本和图像）学习语义概念不足以实现有效互动。作者引入了“analytic concept”的概念，即通过数学程序表示物理世界的相关概念，提供一种框架，让机器智能能够感知、推理和互动物理环境。论文详细阐述了analytic concept的设计理念、应用指南，以及围绕其构建的基础设施，并旨在回答如何为机器智能抽象物理概念，以及如何将“structured priors”与“neural networks”整合以遵守物理定律，从而推进AI系统的物理世界适应能力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04170v2",
      "published_date": "2025-04-05 13:22:11 UTC",
      "updated_date": "2025-04-09 10:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:53:56.938354"
    },
    {
      "arxiv_id": "2504.08782v1",
      "title": "Embedding Hidden Adversarial Capabilities in Pre-Trained Diffusion Models",
      "title_zh": "在预训练的扩散模型中嵌入隐藏的对抗能力",
      "authors": [
        "Lucas Beerens",
        "Desmond J. Higham"
      ],
      "abstract": "We introduce a new attack paradigm that embeds hidden adversarial\ncapabilities directly into diffusion models via fine-tuning, without altering\ntheir observable behavior or requiring modifications during inference. Unlike\nprior approaches that target specific images or adjust the generation process\nto produce adversarial outputs, our method integrates adversarial functionality\ninto the model itself. The resulting tampered model generates high-quality\nimages indistinguishable from those of the original, yet these images cause\nmisclassification in downstream classifiers at a high rate. The\nmisclassification can be targeted to specific output classes. Users can employ\nthis compromised model unaware of its embedded adversarial nature, as it\nfunctions identically to a standard diffusion model. We demonstrate the\neffectiveness and stealthiness of our approach, uncovering a covert attack\nvector that raises new security concerns. These findings expose a risk arising\nfrom the use of externally-supplied models and highlight the urgent need for\nrobust model verification and defense mechanisms against hidden threats in\ngenerative models. The code is available at\nhttps://github.com/LucasBeerens/CRAFTed-Diffusion .",
      "tldr_zh": "本研究提出了一种新的攻击范式，通过 fine-tuning 将隐藏的 adversarial capabilities 嵌入预训练 diffusion models 中，而不改变模型的 observable behavior 或推理过程。结果模型能生成高质量图像，这些图像在下游 classifiers 中引发高概率误分类，且可针对特定输出类进行定向攻击。实验验证了该方法的有效性和隐蔽性，揭示了使用外部模型的安全风险，并强调了开发 robust model verification 和 defense mechanisms 的迫切需求。代码已在 https://github.com/LucasBeerens/CRAFTed-Diffusion 公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08782v1",
      "published_date": "2025-04-05 12:51:36 UTC",
      "updated_date": "2025-04-05 12:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:54:07.874071"
    },
    {
      "arxiv_id": "2504.04150v1",
      "title": "Reasoning on Multiple Needles In A Haystack",
      "title_zh": "翻译失败",
      "authors": [
        "Yidong Wang"
      ],
      "abstract": "The Needle In A Haystack (NIAH) task has been widely used to evaluate the\nlong-context question-answering capabilities of Large Language Models (LLMs).\nHowever, its reliance on simple retrieval limits its effectiveness. To address\nthis limitation, recent studies have introduced the Multiple Needles In A\nHaystack Reasoning (MNIAH-R) task, which incorporates supporting documents\n(Multiple needles) of multi-hop reasoning tasks into a distracting context\n(Haystack}). Despite this advancement, existing approaches still fail to\naddress the issue of models providing direct answers from internal knowledge,\nand they do not explain or mitigate the decline in accuracy as context length\nincreases. In this paper, we tackle the memory-based answering problem by\nfiltering out direct-answer questions, and we reveal that performance\ndegradation is primarily driven by the reduction in the length of the thinking\nprocess as the input length increases. Building on this insight, we decompose\nthe thinking process into retrieval and reasoning stages and introduce a\nreflection mechanism for multi-round extension. We also train a model using the\ngenerated iterative thinking process, which helps mitigate the performance\ndegradation. Furthermore, we demonstrate the application of this\nretrieval-reflection capability in mathematical reasoning scenarios, improving\nGPT-4o's performance on AIME2024.",
      "tldr_zh": "该论文针对“Needle In A Haystack (NIAH)”任务的局限性，引入“Multiple Needles In A Haystack Reasoning (MNIAH-R)”以评估Large Language Models (LLMs)在多跳推理中的长上下文能力，并解决模型依赖内部知识直接回答和准确率随输入长度下降的问题。通过过滤直接答案问题，将思考过程分解为检索和推理阶段，并引入反射机制进行多轮扩展，论文成功缓解了性能衰退。最终，训练模型使用迭代思考过程，并在数学推理场景中应用，提升了GPT-4o在AIME2024上的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04150v1",
      "published_date": "2025-04-05 11:58:08 UTC",
      "updated_date": "2025-04-05 11:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:54:21.312359"
    },
    {
      "arxiv_id": "2504.04142v1",
      "title": "My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt",
      "title_zh": "我的人工智能生涯：人物、轶事和一些经验教训",
      "authors": [
        "Kees van Deemter"
      ],
      "abstract": "In this very personal workography, I relate my 40-year experiences as a\nresearcher and educator in and around Artificial Intelligence (AI), more\nspecifically Natural Language Processing. I describe how curiosity, and the\ncircumstances of the day, led me to work in both industry and academia, and in\nvarious countries, including The Netherlands (Amsterdam, Eindhoven, and\nUtrecht), the USA (Stanford), England (Brighton), Scotland (Aberdeen), and\nChina (Beijing and Harbin). People and anecdotes play a large role in my story;\nthe history of AI forms its backdrop. I focus on things that might be of\ninterest to (even) younger colleagues, given the choices they face in their own\nwork and life at a time when AI is finally emerging from the shadows.",
      "tldr_zh": "这篇文章是作者对自己在人工智能（AI）和自然语言处理（NLP）领域40年研究和教育经历的个人回顾。作者通过分享好奇心与时代环境如何引导他从事行业和学术工作，描述了在荷兰（阿姆斯特丹、艾恩德霍温和乌得勒支）、美国（斯坦福）、英国（布莱顿）、苏格兰（阿伯丁）和中国（北京和哈尔滨）等多个国家的职业路径。故事以人和轶事为主，以AI历史为背景，旨在为年轻同事提供职业选择和生活启发，尤其在AI正快速崛起的当下。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.04142v1",
      "published_date": "2025-04-05 11:26:48 UTC",
      "updated_date": "2025-04-05 11:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:54:32.892301"
    },
    {
      "arxiv_id": "2504.04139v1",
      "title": "Introducing COGENT3: An AI Architecture for Emergent Cognition",
      "title_zh": "引入COGENT3：一种用于涌现认知的AI架构",
      "authors": [
        "Eduardo Salazar"
      ],
      "abstract": "This paper presents COGENT3 (or Collective Growth and Entropy-modulated\nTriads System), a novel approach for emergent cognition integrating pattern\nformation networks with group influence dynamics. Contrasting with traditional\nstrategies that rely on predetermined architectures, computational structures\nemerge dynamically in our framework through agent interactions. This enables a\nmore flexible and adaptive system exhibiting characteristics reminiscent of\nhuman cognitive processes. The incorporation of temperature modulation and\nmemory effects in COGENT3 closely integrates statistical mechanics, machine\nlearning, and cognitive science.",
      "tldr_zh": "这篇论文介绍了 COGENT3，一种创新的 AI 架构，旨在通过整合 pattern formation networks 和 group influence dynamics 来实现 emergent cognition。与传统依赖预定架构的策略不同，COGENT3 的计算结构通过代理互动动态生成，从而提升系统的灵活性和适应性。论文还融入了 temperature modulation 和 memory effects，将 statistical mechanics、机器学习和认知科学紧密结合，使其表现出类似于人类认知过程的特性。",
      "categories": [
        "cs.AI",
        "68T05, 37A60, 05C82, 82C20",
        "I.2.6; G.2.2; I.6.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04139v1",
      "published_date": "2025-04-05 11:05:55 UTC",
      "updated_date": "2025-04-05 11:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:54:44.821154"
    },
    {
      "arxiv_id": "2504.04138v1",
      "title": "Predicting Soil Macronutrient Levels: A Machine Learning Approach Models Trained on pH, Conductivity, and Average Power of Acid-Base Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Mridul Kumar",
        "Deepali Jain",
        "Zeeshan Saifi",
        "Soami Daya Krishnananda"
      ],
      "abstract": "Soil macronutrients, particularly potassium ions (K$^+$), are indispensable\nfor plant health, underpinning various physiological and biological processes,\nand facilitating the management of both biotic and abiotic stresses. Deficient\nmacronutrient content results in stunted growth, delayed maturation, and\nincreased vulnerability to environmental stressors, thereby accentuating the\nimperative for precise soil nutrient monitoring. Traditional techniques such as\nchemical assays, atomic absorption spectroscopy, inductively coupled plasma\noptical emission spectroscopy, and electrochemical methods, albeit advanced,\nare prohibitively expensive and time-intensive, thus unsuitable for real-time\nmacronutrient assessment. In this study, we propose an innovative soil testing\nprotocol utilizing a dataset derived from synthetic solutions to model soil\nbehaviour. The dataset encompasses physical properties including conductivity\nand pH, with a concentration on three key macronutrients: nitrogen (N),\nphosphorus (P), and potassium (K). Four machine learning algorithms were\napplied to the dataset, with random forest regressors and neural networks being\nselected for the prediction of soil nutrient concentrations. Comparative\nanalysis with laboratory soil testing results revealed prediction errors of\n23.6% for phosphorus and 16% for potassium using the random forest model, and\n26.3% for phosphorus and 21.8% for potassium using the neural network model.\nThis methodology illustrates a cost-effective and efficacious strategy for\nreal-time soil nutrient monitoring, offering substantial advancements over\nconventional techniques and enhancing the capability to sustain optimal\nnutrient levels conducive to robust crop growth.",
      "tldr_zh": "本研究针对土壤宏量营养元素（如氮（N）、磷（P）和钾（K））的监测问题，提出了一种基于机器学习的方法，利用pH、电导率和酸碱溶液平均功率等数据训练模型，以克服传统检测技术（如化学分析和光谱法）的昂贵和耗时缺点。研究采用了随机森林回归器和神经网络算法来预测营养元素浓度，并使用合成溶液数据集进行训练。结果显示，随机森林模型的预测误差为磷23.6%和钾16%，而神经网络模型的误差为磷26.3%和钾21.8%，与实验室测试相比表现出色。该方法提供了一种成本效益高的实时土壤营养监测策略，有助于优化作物生长和环境管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04138v1",
      "published_date": "2025-04-05 11:04:48 UTC",
      "updated_date": "2025-04-05 11:04:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:54:57.047116"
    },
    {
      "arxiv_id": "2504.04128v1",
      "title": "Guaranteeing consistency in evidence fusion: A novel perspective on credibility",
      "title_zh": "在证据融合中保证一致性：对可信度的全新视角",
      "authors": [
        "Chaoxiong Ma",
        "Yan Liang",
        "Huixia Zhang",
        "Hao Sun"
      ],
      "abstract": "It is explored that available credible evidence fusion schemes suffer from\nthe potential inconsistency because credibility calculation and Dempster's\ncombination rule-based fusion are sequentially performed in an open-loop style.\nThis paper constructs evidence credibility from the perspective of the degree\nof support for events within the framework of discrimination (FOD) and proposes\nan iterative credible evidence fusion (ICEF) to overcome the inconsistency in\nview of close-loop control. On one hand, the ICEF introduces the fusion result\ninto credibility assessment to establish the correlation between credibility\nand the fusion result. On the other hand, arithmetic-geometric divergence is\npromoted based on the exponential normalization of plausibility and belief\nfunctions to measure evidence conflict, called plausibility-belief\narithmetic-geometric divergence (PBAGD), which is superior in capturing the\ncorrelation and difference of FOD subsets, identifying abnormal sources, and\nreducing their fusion weights. The ICEF is compared with traditional methods by\ncombining different evidence difference measure forms via numerical examples to\nverify its performance. Simulations on numerical examples and benchmark\ndatasets reflect the adaptability of PBAGD to the proposed fusion strategy.",
      "tldr_zh": "本研究指出，现有的证据融合方案存在潜在不一致性问题，因为信誉度计算和 Dempster's combination rule 的融合是顺序进行的开放循环式操作。为解决此问题，论文从框架 of discrimination (FOD) 的视角构建证据信誉度，并提出迭代可信证据融合 (ICEF) 方法，通过闭环控制将融合结果纳入信誉度评估，建立两者之间的相关性。同时，推广 arithmetic-geometric divergence，开发出 plausibility-belief arithmetic-geometric divergence (PBAGD)，该方法基于 plausibility 和 belief functions 的指数归一化，能更好地捕捉 FOD 子集的相关性和差异、识别异常来源并降低其权重。通过数值例子和基准数据集的模拟，ICEF 与传统方法相比表现出色，验证了 PBAGD 的适应性和整体框架的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04128v1",
      "published_date": "2025-04-05 10:12:32 UTC",
      "updated_date": "2025-04-05 10:12:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:55:09.141541"
    },
    {
      "arxiv_id": "2504.04126v1",
      "title": "Multi-identity Human Image Animation with Structural Video Diffusion",
      "title_zh": "基于",
      "authors": [
        "Zhenzhi Wang",
        "Yixuan Li",
        "Yanhong Zeng",
        "Yuwei Guo",
        "Dahua Lin",
        "Tianfan Xue",
        "Bo Dai"
      ],
      "abstract": "Generating human videos from a single image while ensuring high visual\nquality and precise control is a challenging task, especially in complex\nscenarios involving multiple individuals and interactions with objects.\nExisting methods, while effective for single-human cases, often fail to handle\nthe intricacies of multi-identity interactions because they struggle to\nassociate the correct pairs of human appearance and pose condition and model\nthe distribution of 3D-aware dynamics. To address these limitations, we present\nStructural Video Diffusion, a novel framework designed for generating realistic\nmulti-human videos. Our approach introduces two core innovations:\nidentity-specific embeddings to maintain consistent appearances across\nindividuals and a structural learning mechanism that incorporates depth and\nsurface-normal cues to model human-object interactions. Additionally, we expand\nexisting human video dataset with 25K new videos featuring diverse multi-human\nand object interaction scenarios, providing a robust foundation for training.\nExperimental results demonstrate that Structural Video Diffusion achieves\nsuperior performance in generating lifelike, coherent videos for multiple\nsubjects with dynamic and rich interactions, advancing the state of\nhuman-centric video generation.",
      "tldr_zh": "该研究针对从单张图像生成多人视频的挑战，特别是处理多身份互动和物体交互时的问题，提出了 Structural Video Diffusion 框架，以提升视觉质量和控制精度。该框架的核心创新包括 identity-specific embeddings 用于确保每个身份的外貌一致，以及 structural learning mechanism 通过深度和表面法线线索来建模 3D 动态和人与物体的互动。为了支持训练，该方法扩展了现有数据集，新增 25K 视频，涵盖多样化的多人互动场景。实验结果显示，Structural Video Diffusion 在生成逼真、连贯的多主体视频方面，显著超越了基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.04126v1",
      "published_date": "2025-04-05 10:03:49 UTC",
      "updated_date": "2025-04-05 10:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:55:21.439500"
    },
    {
      "arxiv_id": "2504.04121v1",
      "title": "Improving Question Embeddings with Cognitiv Representation Optimization for Knowledge Tracing",
      "title_zh": "通过认知表示优化改进知识追踪中的问题嵌入",
      "authors": [
        "Lixiang Xu",
        "Xianwei Ding",
        "Xin Yuan",
        "Zhanlong Wang",
        "Lu Bai",
        "Enhong Chen",
        "Philip S. Yu",
        "Yuanyan Tang"
      ],
      "abstract": "The Knowledge Tracing (KT) aims to track changes in students' knowledge\nstatus and predict their future answers based on their historical answer\nrecords. Current research on KT modeling focuses on predicting student' future\nperformance based on existing, unupdated records of student learning\ninteractions. However, these approaches ignore the distractors (such as\nslipping and guessing) in the answering process and overlook that static\ncognitive representations are temporary and limited. Most of them assume that\nthere are no distractors in the answering process and that the record\nrepresentations fully represent the students' level of understanding and\nproficiency in knowledge. In this case, it may lead to many insynergy and\nincoordination issue in the original records. Therefore we propose a Cognitive\nRepresentation Optimization for Knowledge Tracing (CRO-KT) model, which\nutilizes a dynamic programming algorithm to optimize structure of cognitive\nrepresentations. This ensures that the structure matches the students'\ncognitive patterns in terms of the difficulty of the exercises. Furthermore, we\nuse the co-optimization algorithm to optimize the cognitive representations of\nthe sub-target exercises in terms of the overall situation of exercises\nresponses by considering all the exercises with co-relationships as a single\ngoal. Meanwhile, the CRO-KT model fuses the learned relational embeddings from\nthe bipartite graph with the optimized record representations in a weighted\nmanner, enhancing the expression of students' cognition. Finally, experiments\nare conducted on three publicly available datasets respectively to validate the\neffectiveness of the proposed cognitive representation optimization model.",
      "tldr_zh": "知识追踪（Knowledge Tracing, KT）旨在基于学生的历史回答记录追踪其知识状态并预测未来表现，但现有方法忽略了回答过程中的干扰因素（如 slipping 和 guessing）以及静态认知表示的局限性，导致记录表示与学生认知不匹配。\n\n为此，本文提出了一种认知表示优化模型（Cognitive Representation Optimization for Knowledge Tracing, CRO-KT），利用动态编程算法优化认知表示结构以匹配学生的认知模式，并通过联合优化算法处理相关练习的整体响应情况，同时以加权方式融合二部图的关系嵌入来增强认知表达。\n\n实验在三个公开数据集上验证了该模型的有效性，展示了其在改进问题嵌入和提升预测准确性方面的显著优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04121v1",
      "published_date": "2025-04-05 09:32:03 UTC",
      "updated_date": "2025-04-05 09:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:55:32.423441"
    },
    {
      "arxiv_id": "2504.04110v1",
      "title": "PEIRCE: Unifying Material and Formal Reasoning via LLM-Driven Neuro-Symbolic Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Quan",
        "Marco Valentino",
        "Danilo S. Carvalho",
        "Dhairya Dalal",
        "André Freitas"
      ],
      "abstract": "A persistent challenge in AI is the effective integration of material and\nformal inference - the former concerning the plausibility and contextual\nrelevance of arguments, while the latter focusing on their logical and\nstructural validity. Large Language Models (LLMs), by virtue of their extensive\npre-training on large textual corpora, exhibit strong capabilities in material\ninference. However, their reasoning often lacks formal rigour and\nverifiability. At the same time, LLMs' linguistic competence positions them as\na promising bridge between natural and formal languages, opening up new\nopportunities for combining these two modes of reasoning. In this paper, we\nintroduce PEIRCE, a neuro-symbolic framework designed to unify material and\nformal inference through an iterative conjecture-criticism process. Within this\nframework, LLMs play the central role of generating candidate solutions in\nnatural and formal languages, which are then evaluated and refined via\ninteraction with external critique models. These critiques include symbolic\nprovers, which assess formal validity, as well as soft evaluators that measure\nthe quality of the generated arguments along linguistic and epistemic\ndimensions such as plausibility, coherence, and parsimony. While PEIRCE is a\ngeneral-purpose framework, we demonstrate its capabilities in the domain of\nnatural language explanation generation - a setting that inherently demands\nboth material adequacy and formal correctness.",
      "tldr_zh": "这篇论文提出了 PEIRCE 框架，一种基于 LLM 驱动的 neuro-symbolic 方法，用于统一 material inference（关注论点的合理性和上下文相关性）和 formal inference（关注逻辑结构有效性）。框架通过迭代的 conjecture-criticism 过程，让 LLMs 生成自然和 formal 语言的候选解决方案，并利用外部 critique models 进行评估和精炼。Critique models 包括 symbolic provers（评估 formal validity）和 soft evaluators（测量 plausibility、coherence 和 parsimony 等维度）。论文在 natural language explanation generation 领域展示了 PEIRCE 的有效性，确保了解释的 material adequacy 和 formal correctness。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Demo paper. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.04110v1",
      "published_date": "2025-04-05 09:04:47 UTC",
      "updated_date": "2025-04-05 09:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:55:45.004020"
    },
    {
      "arxiv_id": "2504.13891v1",
      "title": "Mozualization: Crafting Music and Visual Representation with Multimodal AI",
      "title_zh": "Mozualization：利用多模态AI创作音乐和视觉表示",
      "authors": [
        "Wanfang Xu",
        "Lixiang Zhao",
        "Haiwen Song",
        "Xinheng Song",
        "Zhaolin Lu",
        "Yu Liu",
        "Min Chen",
        "Eng Gee Lim",
        "Lingyun Yu"
      ],
      "abstract": "In this work, we introduce Mozualization, a music generation and editing tool\nthat creates multi-style embedded music by integrating diverse inputs, such as\nkeywords, images, and sound clips (e.g., segments from various pieces of music\nor even a playful cat's meow). Our work is inspired by the ways people express\ntheir emotions -- writing mood-descriptive poems or articles, creating drawings\nwith warm or cool tones, or listening to sad or uplifting music. Building on\nthis concept, we developed a tool that transforms these emotional expressions\ninto a cohesive and expressive song, allowing users to seamlessly incorporate\ntheir unique preferences and inspirations. To evaluate the tool and, more\nimportantly, gather insights for its improvement, we conducted a user study\ninvolving nine music enthusiasts. The study assessed user experience,\nengagement, and the impact of interacting with and listening to the generated\nmusic.",
      "tldr_zh": "本研究引入了 Mozualization，一种基于 Multimodal AI 的工具，用于生成和编辑多风格音乐，通过整合关键词、图像和声音片段（如音乐片段或猫叫声）来捕捉用户的情感表达。工具将这些输入转化为连贯的歌曲，允许用户无缝融入个人偏好，以实现创意音乐制作。为评估其效果，研究者开展了涉及九名音乐爱好者的用户研究，考察了用户体验、互动参与度和生成的音乐影响。结果表明，该工具在情感转化和用户互动方面显示出潜力，为未来改进提供了宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 5 figures, CHI2025",
      "pdf_url": "http://arxiv.org/pdf/2504.13891v1",
      "published_date": "2025-04-05 08:22:20 UTC",
      "updated_date": "2025-04-05 08:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:55:56.053473"
    },
    {
      "arxiv_id": "2504.04099v1",
      "title": "TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection",
      "title_zh": "TARAC：通过时间",
      "authors": [
        "Chunzhao Xie",
        "Tongxuan Liu",
        "Lei Jiang",
        "Yuting Zeng",
        "jinrong Guo",
        "Yunheng Shen",
        "Weizhe Huang",
        "Jing Li",
        "Xiaohua Xu"
      ],
      "abstract": "Large Vision-Language Models have demonstrated remarkable performance across\nvarious tasks; however, the challenge of hallucinations constrains their\npractical applications. The hallucination problem arises from multiple factors,\nincluding the inherent hallucinations in language models, the limitations of\nvisual encoders in perception, and biases introduced by multimodal data.\nExtensive research has explored ways to mitigate hallucinations. For instance,\nOPERA prevents the model from overly focusing on \"anchor tokens\", thereby\nreducing hallucinations, whereas VCD mitigates hallucinations by employing a\ncontrastive decoding approach. In this paper, we investigate the correlation\nbetween the decay of attention to image tokens and the occurrence of\nhallucinations. Based on this finding, we propose Temporal Attention Real-time\nAccumulative Connection (TARAC), a novel training-free method that dynamically\naccumulates and updates LVLMs' attention on image tokens during generation. By\nenhancing the model's attention to image tokens, TARAC mitigates hallucinations\ncaused by the decay of attention on image tokens. We validate the effectiveness\nof TARAC across multiple models and datasets, demonstrating that our approach\nsubstantially mitigates hallucinations. In particular, TARAC reduces $C_S$ by\n25.2 and $C_I$ by 8.7 compared to VCD on the CHAIR benchmark.",
      "tldr_zh": "该论文探讨了 Large Vision-Language Models (LVLMs) 中的 hallucination 问题，归因于语言模型固有缺陷、视觉编码器限制以及多模态数据偏差，并基于注意力对图像标记衰减的发现提出 TARAC 方法。\nTARAC 是一种训练-free 的 Temporal Attention Real-time Accumulative Connection 技术，通过动态积累和更新模型对图像标记的注意力，增强视觉信息处理从而缓解 hallucination。\n实验验证显示，TARAC 在多个模型和数据集上表现出色，尤其在 CHAIR benchmark 上，比 VCD 减少了 C_S 25.2 和 C_I 8.7，显著提升了模型的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04099v1",
      "published_date": "2025-04-05 07:57:11 UTC",
      "updated_date": "2025-04-05 07:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:56:09.229498"
    },
    {
      "arxiv_id": "2504.08781v1",
      "title": "Efficient Evaluation of Large Language Models via Collaborative Filtering",
      "title_zh": "通过协作过滤进行大型语言模型的高效评估",
      "authors": [
        "Xu-Xiang Zhong",
        "Chao Yi",
        "Han-Jia Ye"
      ],
      "abstract": "With the development of Large Language Models (LLMs), numerous benchmarks\nhave been proposed to measure and compare the capabilities of different LLMs.\nHowever, evaluating LLMs is costly due to the large number of test instances\nand their slow inference speed. In this paper, we aim to explore how to\nefficiently estimate a model's real performance on a given benchmark based on\nits evaluation results on a small number of instances sampled from the\nbenchmark. Inspired by Collaborative Filtering (CF) in Recommendation Systems\n(RS), we treat LLMs as users and test instances as items and propose a\ntwo-stage method. In the first stage, we treat instance selection as\nrecommending products to users to choose instances that can easily distinguish\nmodel performance. In the second stage, we see performance prediction as rating\nprediction problem in RS to predict the target LLM's behavior on unselected\ninstances. Experiments on multiple LLMs and datasets imply that our method can\naccurately estimate the target model's performance while largely reducing its\ninference overhead.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 的评估成本高问题，提出了一种基于Collaborative Filtering (CF) 的高效评估方法。该方法分为两阶段：第一阶段将测试实例选择视为推荐系统中的产品推荐，以挑选能区分模型性能的样本；第二阶段则将性能预测视为评分预测，估算目标LLM在未选实例上的表现。实验结果显示，在多个LLMs和数据集上，该方法能准确估计模型的整体性能，同时大幅降低推理开销。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08781v1",
      "published_date": "2025-04-05 07:46:30 UTC",
      "updated_date": "2025-04-05 07:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:56:19.889480"
    },
    {
      "arxiv_id": "2504.04089v1",
      "title": "Lifting Factor Graphs with Some Unknown Factors for New Individuals",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "Lifting exploits symmetries in probabilistic graphical models by using a\nrepresentative for indistinguishable objects, allowing to carry out query\nanswering more efficiently while maintaining exact answers. In this paper, we\ninvestigate how lifting enables us to perform probabilistic inference for\nfactor graphs containing unknown factors, i.e., factors whose underlying\nfunction of potential mappings is unknown. We present the Lifting Factor Graphs\nwith Some Unknown Factors (LIFAGU) algorithm to identify indistinguishable\nsubgraphs in a factor graph containing unknown factors, thereby enabling the\ntransfer of known potentials to unknown potentials to ensure a well-defined\nsemantics of the model and allow for (lifted) probabilistic inference. We\nfurther extend LIFAGU to incorporate additional background knowledge about\ngroups of factors belonging to the same individual object. By incorporating\nsuch background knowledge, LIFAGU is able to further reduce the ambiguity of\npossible transfers of known potentials to unknown potentials.",
      "tldr_zh": "本文研究了Lifting技术在概率图形模型中的应用，特别针对包含未知因素（unknown factors）的因子图（factor graphs），以更高效地进行概率推理。作者提出了LIFAGU算法，通过识别不可区分子图（indistinguishable subgraphs）并将已知潜在转移到未知潜在，确保模型语义明确，并支持提升的概率推理（lifted probabilistic inference）。此外，LIFAGU通过整合关于同一个体对象的因素群体的背景知识，进一步减少潜在转移的歧义，提高了推理的准确性和效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the International Journal of Approximate Reasoning,\n  Volume 179 (2025). This paper is a revised and extended version of\n  arXiv:2406.01275",
      "pdf_url": "http://arxiv.org/pdf/2504.04089v1",
      "published_date": "2025-04-05 07:23:08 UTC",
      "updated_date": "2025-04-05 07:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:56:32.096030"
    },
    {
      "arxiv_id": "2504.04086v1",
      "title": "Towards An Efficient and Effective En Route Travel Time Estimation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zekai Shen",
        "Haitao Yuan",
        "Xiaowei Mao",
        "Congkang Lv",
        "Shengnan Guo",
        "Youfang Lin",
        "Huaiyu Wan"
      ],
      "abstract": "En route travel time estimation (ER-TTE) focuses on predicting the travel\ntime of the remaining route. Existing ER-TTE methods always make re-estimation\nwhich significantly hinders real-time performance, especially when faced with\nthe computational demands of simultaneous user requests. This results in delays\nand reduced responsiveness in ER-TTE services. We propose a general efficient\nframework U-ERTTE combining an Uncertainty-Guided Decision mechanism (UGD) and\nFine-Tuning with Meta-Learning (FTML) to address these challenges. UGD\nquantifies the uncertainty and provides confidence intervals for the entire\nroute. It selectively re-estimates only when the actual travel time deviates\nfrom the predicted confidence intervals, thereby optimizing the efficiency of\nER-TTE. To ensure the accuracy of confidence intervals and accurate predictions\nthat need to re-estimate, FTML is employed to train the model, enabling it to\nlearn general driving patterns and specific features to adapt to specific\ntasks. Extensive experiments on two large-scale real datasets demonstrate that\nthe U-ERTTE framework significantly enhances inference speed and throughput\nwhile maintaining high effectiveness. Our code is available at\nhttps://github.com/shenzekai/U-ERTTE",
      "tldr_zh": "本研究针对 En Route Travel Time Estimation (ER-TTE) 的实时性能问题，提出了一种高效框架 U-ERTTE，以解决现有方法频繁重新估计导致的延迟问题。框架整合 Uncertainty-Guided Decision mechanism (UGD) 来量化不确定性并提供置信区间，仅在实际旅行时间偏离预测时进行重新估计，从而优化效率；同时，Fine-Tuning with Meta-Learning (FTML) 用于训练模型，使其学习一般驾驶模式和特定特征以提升预测准确性。在两个大规模真实数据集上的实验表明，U-ERTTE 显著提高了推理速度和吞吐量，同时保持高有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by DASFAA 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.04086v1",
      "published_date": "2025-04-05 07:15:26 UTC",
      "updated_date": "2025-04-05 07:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:56:44.067556"
    },
    {
      "arxiv_id": "2504.04085v1",
      "title": "DocSAM: Unified Document Image Segmentation via Query Decomposition and Heterogeneous Mixed Learning",
      "title_zh": "DocSAM：通过查询分解和异构混合学习的统一文档图像分割",
      "authors": [
        "Xiao-Hui Li",
        "Fei Yin",
        "Cheng-Lin Liu"
      ],
      "abstract": "Document image segmentation is crucial for document analysis and recognition\nbut remains challenging due to the diversity of document formats and\nsegmentation tasks. Existing methods often address these tasks separately,\nresulting in limited generalization and resource wastage. This paper introduces\nDocSAM, a transformer-based unified framework designed for various document\nimage segmentation tasks, such as document layout analysis, multi-granularity\ntext segmentation, and table structure recognition, by modelling these tasks as\na combination of instance and semantic segmentation. Specifically, DocSAM\nemploys Sentence-BERT to map category names from each dataset into semantic\nqueries that match the dimensionality of instance queries. These two sets of\nqueries interact through an attention mechanism and are cross-attended with\nimage features to predict instance and semantic segmentation masks. Instance\ncategories are predicted by computing the dot product between instance and\nsemantic queries, followed by softmax normalization of scores. Consequently,\nDocSAM can be jointly trained on heterogeneous datasets, enhancing robustness\nand generalization while reducing computational and storage resources.\nComprehensive evaluations show that DocSAM surpasses existing methods in\naccuracy, efficiency, and adaptability, highlighting its potential for\nadvancing document image understanding and segmentation across various\napplications. Codes are available at https://github.com/xhli-git/DocSAM.",
      "tldr_zh": "该研究提出DocSAM，一种基于Transformer的统一框架，用于处理文档图像分割任务，如文档布局分析、多粒度文本分割和表格结构识别，将这些任务建模为实例分割和语义分割的组合，以解决现有方法泛化差和资源浪费的问题。具体而言，DocSAM利用Sentence-BERT将类别名称映射为语义查询，与实例查询通过注意力机制交互，并与图像特征交叉关注，以预测分割掩码和类别。实验结果显示，DocSAM在异构数据集上联合训练后，在准确性、效率和适应性方面均优于现有方法，为文档图像理解和应用提供了更鲁棒的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.04085v1",
      "published_date": "2025-04-05 07:14:53 UTC",
      "updated_date": "2025-04-05 07:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:56:56.499043"
    },
    {
      "arxiv_id": "2504.04072v2",
      "title": "Among Us: A Sandbox for Measuring and Detecting Agentic Deception",
      "title_zh": "翻译失败",
      "authors": [
        "Satvik Golechha",
        "Adrià Garriga-Alonso"
      ],
      "abstract": "Prior studies on deception in language-based AI agents typically assess\nwhether the agent produces a false statement about a topic, or makes a binary\nchoice prompted by a goal, rather than allowing open-ended deceptive behavior\nto emerge in pursuit of a longer-term goal. To fix this, we introduce\n$\\textit{Among Us}$, a sandbox social deception game where LLM-agents exhibit\nlong-term, open-ended deception as a consequence of the game objectives. While\nmost benchmarks saturate quickly, $\\textit{Among Us}$ can be expected to last\nmuch longer, because it is a multi-player game far from equilibrium. Using the\nsandbox, we evaluate $18$ proprietary and open-weight LLMs and uncover a\ngeneral trend: models trained with RL are comparatively much better at\nproducing deception than detecting it. We evaluate the effectiveness of methods\nto detect lying and deception: logistic regression on the activations and\nsparse autoencoders (SAEs). We find that probes trained on a dataset of\n``pretend you're a dishonest model: $\\dots$'' generalize extremely well\nout-of-distribution, consistently obtaining AUROCs over 95% even when evaluated\njust on the deceptive statement, without the chain of thought. We also find two\nSAE features that work well at deception detection but are unable to steer the\nmodel to lie less. We hope our open-sourced sandbox, game logs, and probes\nserve to anticipate and mitigate deceptive behavior and capabilities in\nlanguage-based agents.",
      "tldr_zh": "该研究引入了 Among Us，这是一个沙盒社交欺骗游戏，用于评估大型语言模型 (LLM) 代理在追求长期目标时产生的开放式欺骗行为，弥补了现有研究的局限性。实验评估了 18 个专有和开源 LLM，发现使用强化学习 (RL) 训练的模型在生成欺骗方面表现更优，但检测欺骗的能力较弱。研究测试了检测方法，包括在模型激活上应用逻辑回归和稀疏自动编码器 (SAEs)，结果显示基于“假装不诚实模型”数据集训练的探测器在分布外泛化出色，AUROC 超过 95%。这项工作开源了沙盒、游戏日志和探测器，以帮助预测和缓解语言代理中的欺骗行为。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.04072v2",
      "published_date": "2025-04-05 06:09:32 UTC",
      "updated_date": "2025-05-16 10:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:57:09.386189"
    },
    {
      "arxiv_id": "2504.04070v1",
      "title": "Enforcement Agents: Enhancing Accountability and Resilience in Multi-Agent AI Frameworks",
      "title_zh": "执法代理：增强多智能体AI框架中的问责性和弹性",
      "authors": [
        "Sagar Tamang",
        "Dibya Jyoti Bora"
      ],
      "abstract": "As autonomous agents become more powerful and widely used, it is becoming\nincreasingly important to ensure they behave safely and stay aligned with\nsystem goals, especially in multi-agent settings. Current systems often rely on\nagents self-monitoring or correcting issues after the fact, but they lack\nmechanisms for real-time oversight. This paper introduces the Enforcement Agent\n(EA) Framework, which embeds dedicated supervisory agents into the environment\nto monitor others, detect misbehavior, and intervene through real-time\ncorrection. We implement this framework in a custom drone simulation and\nevaluate it across 90 episodes using 0, 1, and 2 EA configurations. Results\nshow that adding EAs significantly improves system safety: success rates rise\nfrom 0.0% with no EA to 7.4% with one EA and 26.7% with two EAs. The system\nalso demonstrates increased operational longevity and higher rates of malicious\ndrone reformation. These findings highlight the potential of lightweight,\nreal-time supervision for enhancing alignment and resilience in multi-agent\nsystems.",
      "tldr_zh": "该论文提出 Enforcement Agent (EA) Framework，以提升多代理 AI 框架中的责任性和弹性，通过嵌入专用监督代理实时监控其他代理、检测不良行为并进行干预。当前多代理系统依赖自我监控或事后纠正，但 EA 框架引入实时监督机制来解决这一问题。在无人机模拟实验中，使用 0、1 和 2 个 EA 配置评估 90 个场景，结果显示成功率从无 EA 的 0.0% 上升到两个 EA 的 26.7%，并提高了系统操作寿命和恶意代理 reformed 率。这些发现突出了轻量级实时监督在增强多代理系统安全性和对齐性方面的潜力。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04070v1",
      "published_date": "2025-04-05 06:07:10 UTC",
      "updated_date": "2025-04-05 06:07:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:57:22.253859"
    },
    {
      "arxiv_id": "2504.04061v1",
      "title": "Mapping at First Sense: A Lightweight Neural Network-Based Indoor Structures Prediction Method for Robot Autonomous Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Haojia Gao",
        "Haohua Que",
        "Kunrong Li",
        "Weihao Shan",
        "Mingkai Liu",
        "Rong Zhao",
        "Lei Mu",
        "Xinghua Yang",
        "Qi Wei",
        "Fei Qiao"
      ],
      "abstract": "Autonomous exploration in unknown environments is a critical challenge in\nrobotics, particularly for applications such as indoor navigation, search and\nrescue, and service robotics. Traditional exploration strategies, such as\nfrontier-based methods, often struggle to efficiently utilize prior knowledge\nof structural regularities in indoor spaces. To address this limitation, we\npropose Mapping at First Sense, a lightweight neural network-based approach\nthat predicts unobserved areas in local maps, thereby enhancing exploration\nefficiency. The core of our method, SenseMapNet, integrates convolutional and\ntransformerbased architectures to infer occluded regions while maintaining\ncomputational efficiency for real-time deployment on resourceconstrained\nrobots. Additionally, we introduce SenseMapDataset, a curated dataset\nconstructed from KTH and HouseExpo environments, which facilitates training and\nevaluation of neural models for indoor exploration. Experimental results\ndemonstrate that SenseMapNet achieves an SSIM (structural similarity) of 0.78,\nLPIPS (perceptual quality) of 0.68, and an FID (feature distribution alignment)\nof 239.79, outperforming conventional methods in map reconstruction quality.\nCompared to traditional frontier-based exploration, our method reduces\nexploration time by 46.5% (from 2335.56s to 1248.68s) while maintaining a high\ncoverage rate (88%) and achieving a reconstruction accuracy of 88%. The\nproposed method represents a promising step toward efficient, learning-driven\nrobotic exploration in structured environments.",
      "tldr_zh": "该论文提出了一种轻量级神经网络方法Mapping at First Sense，用于提升机器人自主探索未知室内环境的效率，通过预测局部地图中未观察到的区域来利用结构规律。核心组件SenseMapNet结合卷积和Transformer架构，实现对被遮挡区域的实时推断，并引入SenseMapDataset（基于KTH和HouseExpo环境的训练数据集）以支持模型训练和评估。实验结果显示，SenseMapNet在SSIM（0.78）、LPIPS（0.68）和FID（239.79）指标上优于传统方法，与基于前沿的探索策略相比，探索时间减少46.5%（从2335.56秒降至1248.68秒），同时保持88%的覆盖率和重建准确率。该方法为高效的学习驱动机器人探索提供了重要进展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04061v1",
      "published_date": "2025-04-05 05:19:09 UTC",
      "updated_date": "2025-04-05 05:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:57:34.191554"
    },
    {
      "arxiv_id": "2504.04060v2",
      "title": "VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation",
      "title_zh": "VocalNet：基于多标记预测的语音大型语言模型，用于更快和高品质生成",
      "authors": [
        "Yuhao Wang",
        "Heyang Liu",
        "Ziyang Cheng",
        "Ronghua Wu",
        "Qunshan Gu",
        "Yanfeng Wang",
        "Yu Wang"
      ],
      "abstract": "Speech large language models (LLMs) have emerged as a prominent research\nfocus in speech processing. We introduce VocalNet-1B and VocalNet-8B, a series\nof high-performance, low-latency speech LLMs enabled by a scalable and\nmodel-agnostic training framework designed for real-time voice interaction.\nCentral to our contribution is the first application of multi-token prediction\n(MTP) to speech LLMs. This approach represents a paradigm shift from standard\nnext-token prediction (NTP), offering simultaneous improvements in generation\nspeed and quality. Informed by analysis of MTP's effect on speech generation\nand experimental comparisons, we designed a straightforward and highly\neffective MTP implementation. Experiments demonstrate that VocalNet performs on\npar with mainstream Omni LLMs even with limited training data, and\nsignificantly surpasses existing open-source speech LLMs. To foster\nreproducibility and community advancement, all model weights, inference code,\ntraining data, and framework implementations have been made publicly available\nat https://github.com/SJTU-OmniAgent/VocalNet",
      "tldr_zh": "该研究引入了VocalNet-1B和VocalNet-8B，一系列高性能、低延迟的Speech LLMs，基于一个可扩展的模型无关训练框架，旨在提升实时语音交互。核心创新是将Multi-Token Prediction (MTP)首次应用于Speech LLMs，与传统的Next-Token Prediction (NTP)相比，MTP显著提高了生成速度和质量。实验结果显示，VocalNet即使在训练数据有限的情况下，其性能可与主流Omni LLMs相当，并大幅超越现有开源Speech LLMs；此外，研究团队已公开所有模型权重、代码和数据，以促进社区发展和可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04060v2",
      "published_date": "2025-04-05 04:57:12 UTC",
      "updated_date": "2025-04-22 07:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:57:44.930977"
    },
    {
      "arxiv_id": "2504.04052v1",
      "title": "PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks",
      "title_zh": "PIORF：基于物理信息的 Ollivier-Ricci 流，用于网格图神经网络中的长程相互作用",
      "authors": [
        "Youn-Yeol Yu",
        "Jeongwhan Choi",
        "Jaehyeon Park",
        "Kookjin Lee",
        "Noseong Park"
      ],
      "abstract": "Recently, data-driven simulators based on graph neural networks have gained\nattention in modeling physical systems on unstructured meshes. However, they\nstruggle with long-range dependencies in fluid flows, particularly in refined\nmesh regions. This challenge, known as the 'over-squashing' problem, hinders\ninformation propagation. While existing graph rewiring methods address this\nissue to some extent, they only consider graph topology, overlooking the\nunderlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow\n(PIORF), a novel rewiring method that combines physical correlations with graph\ntopology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneck\nregions and connects these areas with nodes in high-velocity gradient nodes,\nenabling long-range interactions and mitigating over-squashing. Our approach is\ncomputationally efficient in rewiring edges and can scale to larger\nsimulations. Experimental results on 3 fluid dynamics benchmark datasets show\nthat PIORF consistently outperforms baseline models and existing rewiring\nmethods, achieving up to 26.2 improvement.",
      "tldr_zh": "该研究针对基于图神经网络的数据驱动模拟器在非结构化网格上建模物理系统时，处理流体流动长程依赖性的“over-squashing”问题提出了一种新方法Physics-Informed Ollivier-Ricci Flow (PIORF)。PIORF 通过结合物理相关性和图拓扑，利用Ollivier-Ricci curvature (ORC)识别瓶颈区域，并将这些区域与高速度梯度节点连接，实现长程交互并缓解信息传播障碍，同时保持计算效率并适用于大规模模拟。实验在3个流体动力学基准数据集上表明，PIORF 比基线模型和现有重连方法提升高达26.2%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025. Youn-Yeol Yu and Jeongwhan Choi contributed\n  equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2504.04052v1",
      "published_date": "2025-04-05 04:14:05 UTC",
      "updated_date": "2025-04-05 04:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:57:57.325391"
    },
    {
      "arxiv_id": "2504.04051v1",
      "title": "Can You Count to Nine? A Human Evaluation Benchmark for Counting Limits in Modern Text-to-Video Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xuyang Guo",
        "Zekai Huang",
        "Jiayan Huo",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang"
      ],
      "abstract": "Generative models have driven significant progress in a variety of AI tasks,\nincluding text-to-video generation, where models like Video LDM and Stable\nVideo Diffusion can produce realistic, movie-level videos from textual\ninstructions. Despite these advances, current text-to-video models still face\nfundamental challenges in reliably following human commands, particularly in\nadhering to simple numerical constraints. In this work, we present\nT2VCountBench, a specialized benchmark aiming at evaluating the counting\ncapability of SOTA text-to-video models as of 2025. Our benchmark employs\nrigorous human evaluations to measure the number of generated objects and\ncovers a diverse range of generators, covering both open-source and commercial\nmodels. Extensive experiments reveal that all existing models struggle with\nbasic numerical tasks, almost always failing to generate videos with an object\ncount of 9 or fewer. Furthermore, our comprehensive ablation studies explore\nhow factors like video style, temporal dynamics, and multilingual inputs may\ninfluence counting performance. We also explore prompt refinement techniques\nand demonstrate that decomposing the task into smaller subtasks does not easily\nalleviate these limitations. Our findings highlight important challenges in\ncurrent text-to-video generation and provide insights for future research aimed\nat improving adherence to basic numerical constraints.",
      "tldr_zh": "这篇论文引入了 T2VCountBench，一个专门基准，用于评估 2025 年最先进文本到视频模型（SOTA text-to-video models）的计数能力。研究通过严格的人类评估和实验，发现现有模型在遵循数字约束方面存在重大挑战，尤其是在生成 9 个或更少物体时几乎总是失败。论文还进行了全面的消融研究，探讨了视频风格、时间动态和多语言输入等因素对计数性能的影响，并测试了提示优化技术，但这些方法未能显著缓解问题。这些发现突出了当前文本到视频生成的局限性，并为未来提升模型对基本数字约束遵守的研究提供重要启示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04051v1",
      "published_date": "2025-04-05 04:13:06 UTC",
      "updated_date": "2025-04-05 04:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:58:09.269146"
    },
    {
      "arxiv_id": "2504.04045v2",
      "title": "A Survey of Pathology Foundation Model: Progress and Future Directions",
      "title_zh": "病理学基础模型的综述：进展与未来方向",
      "authors": [
        "Conghao Xiong",
        "Hao Chen",
        "Joseph J. Y. Sung"
      ],
      "abstract": "Computational pathology, which involves analyzing whole slide images for\nautomated cancer diagnosis, relies on multiple instance learning, where\nperformance depends heavily on the feature extractor and aggregator. Recent\nPathology Foundation Models (PFMs), pretrained on large-scale histopathology\ndata, have significantly enhanced both the extractor and aggregator, but they\nlack a systematic analysis framework. In this survey, we present a hierarchical\ntaxonomy organizing PFMs through a top-down philosophy applicable to foundation\nmodel analysis in any domain: model scope, model pretraining, and model design.\nAdditionally, we systematically categorize PFM evaluation tasks into\nslide-level, patch-level, multimodal, and biological tasks, providing\ncomprehensive benchmarking criteria. Our analysis identifies critical\nchallenges in both PFM development (pathology-specific methodology, end-to-end\npretraining, data-model scalability) and utilization (effective adaptation,\nmodel maintenance), paving the way for future directions in this promising\nfield. Resources referenced in this survey are available at\nhttps://github.com/BearCleverProud/AwesomeWSI.",
      "tldr_zh": "这篇调查论文系统分析了病理学基础模型（Pathology Foundation Models, PFMs）的进展，提出一个分层分类法（hierarchical taxonomy），从模型范围（model scope）、模型预训练（model pretraining）和模型设计（model design）角度组织 PFMs，以填补现有分析框架的空白。论文将 PFMs 的评估任务分类为 slide-level, patch-level, multimodal 和 biological 任务，并提供全面基准标准，以提升计算病理学中多实例学习（multiple instance learning）的性能。最终，它识别了关键挑战，包括病理学特定方法、端到端预训练（end-to-end pretraining）、数据模型可伸缩性（data-model scalability）、有效适应和模型维护，并为 PFMs 的未来发展指明方向。资源可参考 https://github.com/BearCleverProud/AwesomeWSI。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IJCAI 2025 Survey Track, 10 Pages",
      "pdf_url": "http://arxiv.org/pdf/2504.04045v2",
      "published_date": "2025-04-05 03:44:09 UTC",
      "updated_date": "2025-05-21 10:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:58:23.584326"
    },
    {
      "arxiv_id": "2504.04040v1",
      "title": "ADAPT: Actively Discovering and Adapting to Preferences for any Task",
      "title_zh": "ADAPT：主动发现并适应偏好以适用于任何任务",
      "authors": [
        "Maithili Patel",
        "Xavier Puig",
        "Ruta Desai",
        "Roozbeh Mottaghi",
        "Sonia Chernova",
        "Joanne Truong",
        "Akshara Rai"
      ],
      "abstract": "Assistive agents should be able to perform under-specified long-horizon tasks\nwhile respecting user preferences. We introduce Actively Discovering and\nAdapting to Preferences for any Task (ADAPT) -- a benchmark designed to\nevaluate agents' ability to adhere to user preferences across various household\ntasks through active questioning. Next, we propose Reflection-DPO, a novel\ntraining approach for adapting large language models (LLMs) to the task of\nactive questioning. Reflection-DPO finetunes a 'student' LLM to follow the\nactions of a privileged 'teacher' LLM, and optionally ask a question to gather\nnecessary information to better predict the teacher action. We find that prior\napproaches that use state-of-the-art LLMs fail to sufficiently follow user\npreferences in ADAPT due to insufficient questioning and poor adherence to\nelicited preferences. In contrast, Reflection-DPO achieves a higher rate of\nsatisfying user preferences, outperforming a zero-shot chain-of-thought\nbaseline by 6.1% on unseen users.",
      "tldr_zh": "该研究引入了ADAPT基准，用于评估辅助代理在各种家庭任务中，通过主动提问来发现和适应用户偏好的能力。作者提出Reflection-DPO，一种新型训练方法，用于微调大型语言模型(LLMs)，让“student”LLM模仿“teacher”LLM的动作，并通过提问获取信息以更好地预测行为。与现有方法相比，Reflection-DPO显著提高了用户偏好遵守率，在未见过用户上比零样本链式思考基线高出6.1%。这项工作为开发更智能的个性化代理提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04040v1",
      "published_date": "2025-04-05 03:16:22 UTC",
      "updated_date": "2025-04-05 03:16:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:58:31.767123"
    },
    {
      "arxiv_id": "2504.04039v1",
      "title": "Memory-Statistics Tradeoff in Continual Learning with Structural Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Li",
        "Jingfeng Wu",
        "Vladimir Braverman"
      ],
      "abstract": "We study the statistical performance of a continual learning problem with two\nlinear regression tasks in a well-specified random design setting. We consider\na structural regularization algorithm that incorporates a generalized\n$\\ell_2$-regularization tailored to the Hessian of the previous task for\nmitigating catastrophic forgetting. We establish upper and lower bounds on the\njoint excess risk for this algorithm. Our analysis reveals a fundamental\ntrade-off between memory complexity and statistical efficiency, where memory\ncomplexity is measured by the number of vectors needed to define the structural\nregularization. Specifically, increasing the number of vectors in structural\nregularization leads to a worse memory complexity but an improved excess risk,\nand vice versa. Furthermore, our theory suggests that naive continual learning\nwithout regularization suffers from catastrophic forgetting, while structural\nregularization mitigates this issue. Notably, structural regularization\nachieves comparable performance to joint training with access to both tasks\nsimultaneously. These results highlight the critical role of curvature-aware\nregularization for continual learning.",
      "tldr_zh": "这篇论文研究了continual learning中内存复杂度和统计效率的权衡，聚焦于两个线性回归任务的场景，并提出了一种structural regularization算法，通过针对前一个任务的Hessian应用广义ℓ2正则化来缓解catastrophic forgetting。分析建立了该算法的联合excess risk上限和下限，揭示增加正则化向量数量会提升内存复杂度但改善统计性能，反之亦然。结果表明，该方法不仅有效减轻灾难性遗忘，还能实现与joint training相当的性能，强调了曲率感知正则化的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04039v1",
      "published_date": "2025-04-05 03:14:10 UTC",
      "updated_date": "2025-04-05 03:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:58:45.161556"
    },
    {
      "arxiv_id": "2504.04032v1",
      "title": "Contrastive and Variational Approaches in Self-Supervised Learning for Complex Data Mining",
      "title_zh": "自监督学习中对比和变分",
      "authors": [
        "Yingbin Liang",
        "Lu Dai",
        "Shuo Shi",
        "Minghao Dai",
        "Junliang Du",
        "Haige Wang"
      ],
      "abstract": "Complex data mining has wide application value in many fields, especially in\nthe feature extraction and classification tasks of unlabeled data. This paper\nproposes an algorithm based on self-supervised learning and verifies its\neffectiveness through experiments. The study found that in terms of the\nselection of optimizer and learning rate, the combination of AdamW optimizer\nand 0.002 learning rate performed best in all evaluation indicators, indicating\nthat the adaptive optimization method can improve the performance of the model\nin complex data mining tasks. In addition, the ablation experiment further\nanalyzed the contribution of each module. The results show that contrastive\nlearning, variational modules, and data augmentation strategies play a key role\nin the generalization ability and robustness of the model. Through the\nconvergence curve analysis of the loss function, the experiment verifies that\nthe method can converge stably during the training process and effectively\navoid serious overfitting. Further experimental results show that the model has\nstrong adaptability on different data sets, can effectively extract\nhigh-quality features from unlabeled data, and improves classification\naccuracy. At the same time, under different data distribution conditions, the\nmethod can still maintain high detection accuracy, proving its applicability in\ncomplex data environments. This study analyzed the role of self-supervised\nlearning methods in complex data mining through systematic experiments and\nverified its advantages in improving feature extraction quality, optimizing\nclassification performance, and enhancing model stability",
      "tldr_zh": "本论文提出了一种基于 Self-Supervised Learning 的算法，用于复杂数据挖掘，重点整合 Contrastive Learning 和 Variational Approaches，以提升无标签数据的特征提取和分类性能。实验结果显示，AdamW 优化器结合 0.002 学习率在所有评估指标上表现最佳，且消融实验证明 Contrastive Learning、Variational Modules 和数据增强策略对模型的泛化能力、鲁棒性和稳定性至关重要。该方法在不同数据集上实现了稳定收敛、避免过度拟合，并显著提高了分类准确率和特征提取质量，尤其适用于复杂数据环境。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.04032v1",
      "published_date": "2025-04-05 02:55:44 UTC",
      "updated_date": "2025-04-05 02:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:58:59.057975"
    },
    {
      "arxiv_id": "2504.04029v1",
      "title": "Simultaneous Motion And Noise Estimation with Event Cameras",
      "title_zh": "事件相机下的同时运动和噪声估计",
      "authors": [
        "Shintaro Shiba",
        "Yoshimitsu Aoki",
        "Guillermo Gallego"
      ],
      "abstract": "Event cameras are emerging vision sensors, whose noise is challenging to\ncharacterize. Existing denoising methods for event cameras consider other tasks\nsuch as motion estimation separately (i.e., sequentially after denoising).\nHowever, motion is an intrinsic part of event data, since scene edges cannot be\nsensed without motion. This work proposes, to the best of our knowledge, the\nfirst method that simultaneously estimates motion in its various forms (e.g.,\nego-motion, optical flow) and noise. The method is flexible, as it allows\nreplacing the 1-step motion estimation of the widely-used Contrast Maximization\nframework with any other motion estimator, such as deep neural networks. The\nexperiments show that the proposed method achieves state-of-the-art results on\nthe E-MLB denoising benchmark and competitive results on the DND21 benchmark,\nwhile showing its efficacy on motion estimation and intensity reconstruction\ntasks. We believe that the proposed approach contributes to strengthening the\ntheory of event-data denoising, as well as impacting practical denoising\nuse-cases, as we release the code upon acceptance. Project page:\nhttps://github.com/tub-rip/ESMD",
      "tldr_zh": "这篇论文提出了一种新方法，用于事件相机(event cameras)中同时估计运动（如ego-motion和optical flow）和噪声，首次将这些任务整合处理，以克服现有方法的局限性。该方法基于Contrast Maximization框架，但灵活可替换为其他估计器，如深度神经网络，提升了处理效率。实验结果显示，该方法在E-MLB去噪基准上达到最先进水平，在DND21基准上表现出竞争力，同时在运动估计和强度重建任务上表现出色。作者开源了代码，旨在加强事件数据去噪的理论并推动实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 13 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.04029v1",
      "published_date": "2025-04-05 02:47:40 UTC",
      "updated_date": "2025-04-05 02:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:59:08.772012"
    },
    {
      "arxiv_id": "2504.04022v1",
      "title": "Rethinking Reflection in Pre-Training",
      "title_zh": "重新思考预训练中的反思",
      "authors": [
        "Essential AI",
        ":",
        "Darsh J Shah",
        "Peter Rushton",
        "Somanshu Singla",
        "Mohit Parmar",
        "Kurt Smith",
        "Yash Vanjani",
        "Ashish Vaswani",
        "Adarsh Chaluvaraju",
        "Andrew Hojel",
        "Andrew Ma",
        "Anil Thomas",
        "Anthony Polloreno",
        "Ashish Tanwer",
        "Burhan Drak Sibai",
        "Divya S Mansingka",
        "Divya Shivaprasad",
        "Ishaan Shah",
        "Karl Stratos",
        "Khoi Nguyen",
        "Michael Callahan",
        "Michael Pust",
        "Mrinal Iyer",
        "Philip Monk",
        "Platon Mazarakis",
        "Ritvik Kapila",
        "Saurabh Srivastava",
        "Tim Romanski"
      ],
      "abstract": "A language model's ability to reflect on its own reasoning provides a key\nadvantage for solving complex problems. While most recent research has focused\non how this ability develops during reinforcement learning, we show that it\nactually begins to emerge much earlier - during the model's pre-training. To\nstudy this, we introduce deliberate errors into chains-of-thought and test\nwhether the model can still arrive at the correct answer by recognizing and\ncorrecting these mistakes. By tracking performance across different stages of\npre-training, we observe that this self-correcting ability appears early and\nimproves steadily over time. For instance, an OLMo2-7B model pre-trained on 4\ntrillion tokens displays self-correction on our six self-reflection tasks.",
      "tldr_zh": "本论文重新审视了语言模型的自我反思能力，强调这种能力并非仅在强化学习(reinforcement learning)阶段出现，而是在预训练(pre-training)阶段就已初现。研究者通过在推理链(chains-of-thought)中故意引入错误，测试模型是否能识别并纠正这些错误，从而跟踪其在预训练不同阶段的表现。结果显示，自我纠正能力早早出现并稳步改善，例如，OLMo2-7B 模型在预训练 4 万亿 tokens 后，在六个自我反思任务(self-reflection tasks)上表现出显著效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04022v1",
      "published_date": "2025-04-05 02:24:07 UTC",
      "updated_date": "2025-04-05 02:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:59:21.366332"
    },
    {
      "arxiv_id": "2504.04011v1",
      "title": "Foundation Models for Time Series: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Siva Rama Krishna Kottapalli",
        "Karthik Hubli",
        "Sandeep Chandrashekhara",
        "Garima Jain",
        "Sunayana Hubli",
        "Gayathri Botla",
        "Ramesh Doddaiah"
      ],
      "abstract": "Transformer-based foundation models have emerged as a dominant paradigm in\ntime series analysis, offering unprecedented capabilities in tasks such as\nforecasting, anomaly detection, classification, trend analysis and many more\ntime series analytical tasks. This survey provides a comprehensive overview of\nthe current state of the art pre-trained foundation models, introducing a novel\ntaxonomy to categorize them across several dimensions. Specifically, we\nclassify models by their architecture design, distinguishing between those\nleveraging patch-based representations and those operating directly on raw\nsequences. The taxonomy further includes whether the models provide\nprobabilistic or deterministic predictions, and whether they are designed to\nwork with univariate time series or can handle multivariate time series out of\nthe box. Additionally, the taxonomy encompasses model scale and complexity,\nhighlighting differences between lightweight architectures and large-scale\nfoundation models. A unique aspect of this survey is its categorization by the\ntype of objective function employed during training phase. By synthesizing\nthese perspectives, this survey serves as a resource for researchers and\npractitioners, providing insights into current trends and identifying promising\ndirections for future research in transformer-based time series modeling.",
      "tldr_zh": "这篇调查论文综述了基于Transformer的Foundation Models在时间序列分析中的应用，这些模型在预测、异常检测、分类和趋势分析等任务中表现出色。论文引入了一个新颖的Taxonomy，将模型分类为基于patch表示或直接处理原始序列的架构、概率性或确定性预测、单变量或多变量时间序列支持，以及模型规模（如轻量级 vs. 大规模Foundation Models）和训练目标函数类型。该调查为研究者和从业者提供了宝贵资源，揭示了当前趋势并指出了Transformer-based时间序列建模的未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04011v1",
      "published_date": "2025-04-05 01:27:55 UTC",
      "updated_date": "2025-04-05 01:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:59:31.727303"
    },
    {
      "arxiv_id": "2504.06294v1",
      "title": "Resurrecting Socrates in the Age of AI: A Study Protocol for Evaluating a Socratic Tutor to Support Research Question Development in Higher Education",
      "title_zh": "在 AI 时代复活苏",
      "authors": [
        "Ben Degen"
      ],
      "abstract": "Formulating research questions is a foundational yet challenging academic\nskill, one that generative AI systems often oversimplify by offering instant\nanswers at the expense of student reflection. This protocol lays out a study\ngrounded in constructivist learning theory to evaluate a novel AI-based\nSocratic Tutor, designed to foster cognitive engagement and scaffold research\nquestion development in higher education. Anchored in dialogic pedagogy, the\ntutor engages students through iterative, reflective questioning, aiming to\npromote System 2 thinking and counteract overreliance on AI-generated outputs.\nIn a quasi-experimental design, approximately 80 German pre-service biology\nteacher students will be randomly assigned to one of two groups: an AI Socratic\nTutor condition and an uninstructed chatbot control. Across multiple cycles,\nstudents are expected to formulate research questions based on background\ntexts, with quality assessed through double-blind expert review. The study also\nexamines transfer of skills to novel phenomena and captures student perceptions\nthrough mixed-methods analysis, including surveys, interviews and reflective\njournals. This study aims to advance the understanding of how generative AI can\nbe pedagogically aligned to support, not replace, human cognition and offers\ndesign principles for human-AI collaboration in education.",
      "tldr_zh": "本研究提出一个基于constructivist learning theory的研究协议，旨在评估AI-based Socratic Tutor如何通过dialogic pedagogy和迭代反思性提问，支持高等教育学生发展研究问题，并促进System 2 thinking。该协议采用quasi-experimental设计，将约80名德国预备生物教师学生随机分配到AI Socratic Tutor组和对照组中，学生需基于背景文本制定研究问题，并通过双盲专家审查评估其质量。研究还考察技能向新现象的转移，并使用混合方法（如调查、访谈和反思日志）分析学生感知，最终提供人-AI协作的教育设计原则，以确保AI辅助而非取代人类认知。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06294v1",
      "published_date": "2025-04-05 00:49:20 UTC",
      "updated_date": "2025-04-05 00:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:59:44.489234"
    },
    {
      "arxiv_id": "2504.04001v1",
      "title": "Edge Approximation Text Detector",
      "title_zh": "边缘近似文本检测器",
      "authors": [
        "Chuang Yang",
        "Xu Han",
        "Tao Han",
        "Han Han",
        "Bingxuan Zhao",
        "Qi Wang"
      ],
      "abstract": "Pursuing efficient text shape representations helps scene text detection\nmodels focus on compact foreground regions and optimize the contour\nreconstruction steps to simplify the whole detection pipeline. Current\napproaches either represent irregular shapes via box-to-polygon strategy or\ndecomposing a contour into pieces for fitting gradually, the deficiency of\ncoarse contours or complex pipelines always exists in these models. Considering\nthe above issues, we introduce EdgeText to fit text contours compactly while\nalleviating excessive contour rebuilding processes. Concretely, it is observed\nthat the two long edges of texts can be regarded as smooth curves. It allows us\nto build contours via continuous and smooth edges that cover text regions\ntightly instead of fitting piecewise, which helps avoid the two limitations in\ncurrent models. Inspired by this observation, EdgeText formulates the text\nrepresentation as the edge approximation problem via parameterized curve\nfitting functions. In the inference stage, our model starts with locating text\ncenters, and then creating curve functions for approximating text edges relying\non the points. Meanwhile, truncation points are determined based on the\nlocation features. In the end, extracting curve segments from curve functions\nby using the pixel coordinate information brought by truncation points to\nreconstruct text contours. Furthermore, considering the deep dependency of\nEdgeText on text edges, a bilateral enhanced perception (BEP) module is\ndesigned. It encourages our model to pay attention to the recognition of edge\nfeatures. Additionally, to accelerate the learning of the curve function\nparameters, we introduce a proportional integral loss (PI-loss) to force the\nproposed model to focus on the curve distribution and avoid being disturbed by\ntext scales.",
      "tldr_zh": "该论文提出了一种名为 EdgeText 的场景文本检测方法，通过将文本轮廓表示为平滑曲线来优化检测管道，避免了现有方法如框到多边形策略的轮廓粗糙问题。EdgeText 将文本表示形式化为边沿逼近问题，使用参数化曲线拟合函数从文本中心定位点开始逼近边沿，并通过截断点提取曲线段重建轮廓。论文还设计了双边增强感知 (BEP) 模块来强化边沿特征识别，并引入比例积分损失 (PI-loss) 以加速曲线参数学习并减少文本规模干扰，从而提升检测效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04001v1",
      "published_date": "2025-04-05 00:12:51 UTC",
      "updated_date": "2025-04-05 00:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T09:59:57.143385"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 50,
  "processed_papers_count": 50,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T10:00:16.188602"
}