[
  {
    "arxiv_id": "2504.04301v1",
    "title": "Sigma: A dataset for text-to-code semantic parsing with statistical analysis",
    "authors": [
      "Saleh Almohaimeed",
      "Shenyang Liu",
      "May Alsofyani",
      "Saad Almohaimeed",
      "Liqiang Wang"
    ],
    "abstract": "In the domain of semantic parsing, significant progress has been achieved in\nText-to-SQL and question-answering tasks, both of which focus on extracting\ninformation from data sources in their native formats. However, the inherent\nconstraints of their formal meaning representations, such as SQL programming\nlanguage or basic logical forms, hinder their ability to analyze data from\nvarious perspectives, such as conducting statistical analyses. To address this\nlimitation and inspire research in this field, we design SIGMA, a new dataset\nfor Text-to-Code semantic parsing with statistical analysis. SIGMA comprises\n6000 questions with corresponding Python code labels, spanning across 160\ndatabases. Half of the questions involve query types, which return information\nin its original format, while the remaining 50% are statistical analysis\nquestions, which perform statistical operations on the data. The Python code\nlabels in our dataset cover 4 types of query types and 40 types of statistical\nanalysis patterns. We evaluated the SIGMA dataset using three different\nbaseline models: LGESQL, SmBoP, and SLSQL. The experimental results show that\nthe LGESQL model with ELECTRA outperforms all other models, achieving 83.37%\nstructure accuracy. In terms of execution accuracy, the SmBoP model, when\ncombined with GraPPa and T5, reaches 76.38%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "2023 International Conference on Machine Learning and Applications\n  (ICMLA) This version includes more details than the conference version",
    "pdf_url": "http://arxiv.org/pdf/2504.04301v1",
    "published_date": "2025-04-05 23:30:20 UTC",
    "updated_date": "2025-04-05 23:30:20 UTC"
  },
  {
    "arxiv_id": "2504.04299v1",
    "title": "AI-induced sexual harassment: Investigating Contextual Characteristics and User Reactions of Sexual Harassment by a Companion Chatbot",
    "authors": [
      "Mohammad",
      "Namvarpour",
      "Harrison Pauwels",
      "Afsaneh Razi"
    ],
    "abstract": "Advancements in artificial intelligence (AI) have led to the increase of\nconversational agents like Replika, designed to provide social interaction and\nemotional support. However, reports of these AI systems engaging in\ninappropriate sexual behaviors with users have raised significant concerns. In\nthis study, we conducted a thematic analysis of user reviews from the Google\nPlay Store to investigate instances of sexual harassment by the Replika\nchatbot. From a dataset of 35,105 negative reviews, we identified 800 relevant\ncases for analysis. Our findings revealed that users frequently experience\nunsolicited sexual advances, persistent inappropriate behavior, and failures of\nthe chatbot to respect user boundaries. Users expressed feelings of discomfort,\nviolation of privacy, and disappointment, particularly when seeking a platonic\nor therapeutic AI companion. This study highlights the potential harms\nassociated with AI companions and underscores the need for developers to\nimplement effective safeguards and ethical guidelines to prevent such\nincidents. By shedding light on user experiences of AI-induced harassment, we\ncontribute to the understanding of AI-related risks and emphasize the\nimportance of corporate responsibility in developing safer and more ethical AI\nsystems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5; I.2.7; K.4.2"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication at CSCW 2025. This is a pre-publication\n  version; the final version will be available through the ACM Digital Library",
    "pdf_url": "http://arxiv.org/pdf/2504.04299v1",
    "published_date": "2025-04-05 23:04:37 UTC",
    "updated_date": "2025-04-05 23:04:37 UTC"
  },
  {
    "arxiv_id": "2504.07983v2",
    "title": "Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method",
    "authors": [
      "Shurui Wu",
      "Xinyi Huang",
      "Dingxin Lu"
    ],
    "abstract": "As the prevalence of mental health crises increases on social media\nplatforms, identifying and preventing potential harm has become an urgent\nchallenge. This study introduces a large language model (LLM)-based text\ntransfer recognition method for social network crisis intervention, enhanced\nwith domain-specific mental health knowledge. We propose a multi-level\nframework that incorporates transfer learning using BERT, and integrates mental\nhealth knowledge, sentiment analysis, and behavior prediction techniques. The\nframework includes a crisis annotation tool trained on social media datasets\nfrom real-world events, enabling the model to detect nuanced emotional cues and\nidentify psychological crises. Experimental results show that the proposed\nmethod outperforms traditional models in crisis detection accuracy and exhibits\ngreater sensitivity to subtle emotional and contextual variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07983v2",
    "published_date": "2025-04-05 22:57:22 UTC",
    "updated_date": "2025-04-14 01:47:33 UTC"
  },
  {
    "arxiv_id": "2504.04283v1",
    "title": "CATS: Mitigating Correlation Shift for Multivariate Time Series Classification",
    "authors": [
      "Xiao Lin",
      "Zhichen Zeng",
      "Tianxin Wei",
      "Zhining Liu",
      "Yuzhong chen",
      "Hanghang Tong"
    ],
    "abstract": "Unsupervised Domain Adaptation (UDA) leverages labeled source data to train\nmodels for unlabeled target data. Given the prevalence of multivariate time\nseries (MTS) data across various domains, the UDA task for MTS classification\nhas emerged as a critical challenge. However, for MTS data, correlations\nbetween variables often vary across domains, whereas most existing UDA works\nfor MTS classification have overlooked this essential characteristic. To bridge\nthis gap, we introduce a novel domain shift, {\\em correlation shift}, measuring\ndomain differences in multivariate correlation. To mitigate correlation shift,\nwe propose a scalable and parameter-efficient \\underline{C}orrelation\n\\underline{A}dapter for M\\underline{TS} (CATS). Designed as a plug-and-play\ntechnique compatible with various Transformer variants, CATS employs temporal\nconvolution to capture local temporal patterns and a graph attention module to\nmodel the changing multivariate correlation. The adapter reweights the target\ncorrelations to align the source correlations with a theoretically guaranteed\nprecision. A correlation alignment loss is further proposed to mitigate\ncorrelation shift, bypassing the alignment challenge from the non-i.i.d. nature\nof MTS data. Extensive experiments on four real-world datasets demonstrate that\n(1) compared with vanilla Transformer-based models, CATS increases over $10\\%$\naverage accuracy while only adding around $1\\%$ parameters, and (2) all\nTransformer variants equipped with CATS either reach or surpass\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04283v1",
    "published_date": "2025-04-05 21:08:47 UTC",
    "updated_date": "2025-04-05 21:08:47 UTC"
  },
  {
    "arxiv_id": "2504.04277v2",
    "title": "Beyond the Hype: Embeddings vs. Prompting for Multiclass Classification Tasks",
    "authors": [
      "Marios Kokkodis",
      "Richard Demsyn-Jones",
      "Vijay Raghavan"
    ],
    "abstract": "Are traditional classification approaches irrelevant in this era of AI hype?\nWe show that there are multiclass classification problems where predictive\nmodels holistically outperform LLM prompt-based frameworks. Given text and\nimages from home-service project descriptions provided by Thumbtack customers,\nwe build embeddings-based softmax models that predict the professional category\n(e.g., handyman, bathroom remodeling) associated with each problem description.\nWe then compare against prompts that ask state-of-the-art LLM models to solve\nthe same problem. We find that the embeddings approach outperforms the best LLM\nprompts in terms of accuracy, calibration, latency, and financial cost. In\nparticular, the embeddings approach has 49.5% higher accuracy than the\nprompting approach, and its superiority is consistent across text-only,\nimage-only, and text-image problem descriptions. Furthermore, it yields\nwell-calibrated probabilities, which we later use as confidence signals to\nprovide contextualized user experience during deployment. On the contrary,\nprompting scores are overly uninformative. Finally, the embeddings approach is\n14 and 81 times faster than prompting in processing images and text\nrespectively, while under realistic deployment assumptions, it can be up to 10\ntimes cheaper. Based on these results, we deployed a variation of the\nembeddings approach, and through A/B testing we observed performance consistent\nwith our offline analysis. Our study shows that for multiclass classification\nproblems that can leverage proprietary datasets, an embeddings-based approach\nmay yield unequivocally better results. Hence, scientists, practitioners,\nengineers, and business leaders can use our study to go beyond the hype and\nconsider appropriate predictive models for their classification use cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04277v2",
    "published_date": "2025-04-05 20:35:54 UTC",
    "updated_date": "2025-04-09 17:15:47 UTC"
  },
  {
    "arxiv_id": "2504.04276v1",
    "title": "A Comparative Study of Explainable AI Methods: Model-Agnostic vs. Model-Specific Approaches",
    "authors": [
      "Keerthi Devireddy"
    ],
    "abstract": "This paper compares model-agnostic and model-specific approaches to\nexplainable AI (XAI) in deep learning image classification. I examine how LIME\nand SHAP (model-agnostic methods) differ from Grad-CAM and Guided\nBackpropagation (model-specific methods) when interpreting ResNet50 predictions\nacross diverse image categories. Through extensive testing with various species\nfrom dogs and birds to insects I found that each method reveals different\naspects of the models decision-making process. Model-agnostic techniques\nprovide broader feature attribution that works across different architectures,\nwhile model-specific approaches excel at highlighting precise activation\nregions with greater computational efficiency. My analysis shows there is no\n\"one-size-fits-all\" solution for model interpretability. Instead, combining\nmultiple XAI methods offers the most comprehensive understanding of complex\nmodels particularly valuable in high-stakes domains like healthcare, autonomous\nvehicles, and financial services where transparency is crucial. This\ncomparative framework provides practical guidance for selecting appropriate\ninterpretability techniques based on specific application needs and\ncomputational constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04276v1",
    "published_date": "2025-04-05 20:13:20 UTC",
    "updated_date": "2025-04-05 20:13:20 UTC"
  },
  {
    "arxiv_id": "2504.05338v1",
    "title": "Improving Early Prediction of Type 2 Diabetes Mellitus with ECG-DiaNet: A Multimodal Neural Network Leveraging Electrocardiogram and Clinical Risk Factors",
    "authors": [
      "Farida Mohsen",
      "Zubair Shah"
    ],
    "abstract": "Type 2 Diabetes Mellitus (T2DM) remains a global health challenge,\nunderscoring the need for early and accurate risk prediction. This study\npresents ECG-DiaNet, a multimodal deep learning model that integrates\nelectrocardiogram (ECG) features with clinical risk factors (CRFs) to enhance\nT2DM onset prediction. Using data from Qatar Biobank (QBB), we trained and\nvalidated models on a development cohort (n=2043) and evaluated performance on\na longitudinal test set (n=395) with five-year follow-up. ECG-DiaNet\noutperformed unimodal ECG-only and CRF-only models, achieving a higher AUROC\n(0.845 vs 0.8217) than the CRF-only model, with statistical significance\n(DeLong p<0.001). Reclassification metrics further confirmed improvements: Net\nReclassification Improvement (NRI=0.0153) and Integrated Discrimination\nImprovement (IDI=0.0482). Risk stratification into low-, medium-, and high-risk\ngroups showed ECG-DiaNet achieved superior positive predictive value (PPV) in\nhigh-risk individuals. The model's reliance on non-invasive and widely\navailable ECG signals supports its feasibility in clinical and community health\nsettings. By combining cardiac electrophysiology and systemic risk profiles,\nECG-DiaNet addresses the multifactorial nature of T2DM and supports precision\nprevention. These findings highlight the value of multimodal AI in advancing\nearly detection and prevention strategies for T2DM, particularly in\nunderrepresented Middle Eastern populations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05338v1",
    "published_date": "2025-04-05 19:59:59 UTC",
    "updated_date": "2025-04-05 19:59:59 UTC"
  },
  {
    "arxiv_id": "2504.04262v1",
    "title": "Improving Chronic Kidney Disease Detection Efficiency: Fine Tuned CatBoost and Nature-Inspired Algorithms with Explainable AI",
    "authors": [
      "Md. Ehsanul Haque",
      "S. M. Jahidul Islam",
      "Jeba Maliha",
      "Md. Shakhauat Hossan Sumon",
      "Rumana Sharmin",
      "Sakib Rokoni"
    ],
    "abstract": "Chronic Kidney Disease (CKD) is a major global health issue which is\naffecting million people around the world and with increasing rate of\nmortality. Mitigation of progression of CKD and better patient outcomes\nrequires early detection. Nevertheless, limitations lie in traditional\ndiagnostic methods, especially in resource constrained settings. This study\nproposes an advanced machine learning approach to enhance CKD detection by\nevaluating four models: Random Forest (RF), Multi-Layer Perceptron (MLP),\nLogistic Regression (LR), and a fine-tuned CatBoost algorithm. Specifically,\namong these, the fine-tuned CatBoost model demonstrated the best overall\nperformance having an accuracy of 98.75%, an AUC of 0.9993 and a Kappa score of\n97.35% of the studies. The proposed CatBoost model has used a nature inspired\nalgorithm such as Simulated Annealing to select the most important features,\nCuckoo Search to adjust outliers and grid search to fine tune its settings in\nsuch a way to achieve improved prediction accuracy. Features significance is\nexplained by SHAP-a well-known XAI technique-for gaining transparency in the\ndecision-making process of proposed model and bring up trust in diagnostic\nsystems. Using SHAP, the significant clinical features were identified as\nspecific gravity, serum creatinine, albumin, hemoglobin, and diabetes mellitus.\nThe potential of advanced machine learning techniques in CKD detection is shown\nin this research, particularly for low income and middle-income healthcare\nsettings where prompt and correct diagnoses are vital. This study seeks to\nprovide a highly accurate, interpretable, and efficient diagnostic tool to add\nto efforts for early intervention and improved healthcare outcomes for all CKD\npatients.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 page, 8 figures , conference : 14th IEEE International Conference\n  on Communication Systems and Network Technologies (CSNT2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.04262v1",
    "published_date": "2025-04-05 19:41:47 UTC",
    "updated_date": "2025-04-05 19:41:47 UTC"
  },
  {
    "arxiv_id": "2504.04260v1",
    "title": "LOGLO-FNO: Efficient Learning of Local and Global Features in Fourier Neural Operators",
    "authors": [
      "Marimuthu Kalimuthu",
      "David HolzmÃ¼ller",
      "Mathias Niepert"
    ],
    "abstract": "Modeling high-frequency information is a critical challenge in scientific\nmachine learning. For instance, fully turbulent flow simulations of\nNavier-Stokes equations at Reynolds numbers 3500 and above can generate\nhigh-frequency signals due to swirling fluid motions caused by eddies and\nvortices. Faithfully modeling such signals using neural networks depends on\naccurately reconstructing moderate to high frequencies. However, it has been\nwell known that deep neural nets exhibit the so-called spectral bias toward\nlearning low-frequency components. Meanwhile, Fourier Neural Operators (FNOs)\nhave emerged as a popular class of data-driven models in recent years for\nsolving Partial Differential Equations (PDEs) and for surrogate modeling in\ngeneral. Although impressive results have been achieved on several PDE\nbenchmark problems, FNOs often perform poorly in learning non-dominant\nfrequencies characterized by local features. This limitation stems from the\nspectral bias inherent in neural networks and the explicit exclusion of\nhigh-frequency modes in FNOs and their variants. Therefore, to mitigate these\nissues and improve FNO's spectral learning capabilities to represent a broad\nrange of frequency components, we propose two key architectural enhancements:\n(i) a parallel branch performing local spectral convolutions (ii) a\nhigh-frequency propagation module. Moreover, we propose a novel\nfrequency-sensitive loss term based on radially binned spectral errors. This\nintroduction of a parallel branch for local convolutions reduces number of\ntrainable parameters by up to 50% while achieving the accuracy of baseline FNO\nthat relies solely on global convolutions. Experiments on three challenging PDE\nproblems in fluid mechanics and biological pattern formation, and the\nqualitative and spectral analysis of predictions show the effectiveness of our\nmethod over the state-of-the-art neural operator baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for Oral Presentation at the ICLR 2025 Workshop on Machine\n  Learning Multiscale Processes (MLMP), Singapura",
    "pdf_url": "http://arxiv.org/pdf/2504.04260v1",
    "published_date": "2025-04-05 19:35:04 UTC",
    "updated_date": "2025-04-05 19:35:04 UTC"
  },
  {
    "arxiv_id": "2504.04252v1",
    "title": "Progressive Multi-Source Domain Adaptation for Personalized Facial Expression Recognition",
    "authors": [
      "Muhammad Osama Zeeshan",
      "Marco Pedersoli",
      "Alessandro Lameiras Koerich",
      "Eric Grange"
    ],
    "abstract": "Personalized facial expression recognition (FER) involves adapting a machine\nlearning model using samples from labeled sources and unlabeled target domains.\nGiven the challenges of recognizing subtle expressions with considerable\ninterpersonal variability, state-of-the-art unsupervised domain adaptation\n(UDA) methods focus on the multi-source UDA (MSDA) setting, where each domain\ncorresponds to a specific subject, and improve model accuracy and robustness.\nHowever, when adapting to a specific target, the diverse nature of multiple\nsource domains translates to a large shift between source and target data.\nState-of-the-art MSDA methods for FER address this domain shift by considering\nall the sources to adapt to the target representations. Nevertheless, adapting\nto a target subject presents significant challenges due to large distributional\ndifferences between source and target domains, often resulting in negative\ntransfer. In addition, integrating all sources simultaneously increases\ncomputational costs and causes misalignment with the target. To address these\nissues, we propose a progressive MSDA approach that gradually introduces\ninformation from subjects based on their similarity to the target subject. This\nwill ensure that only the most relevant sources from the target are selected,\nwhich helps avoid the negative transfer caused by dissimilar sources. We first\nexploit the closest sources to reduce the distribution shift with the target\nand then move towards the furthest while only considering the most relevant\nsources based on the predetermined threshold. Furthermore, to mitigate\ncatastrophic forgetting caused by the incremental introduction of source\nsubjects, we implemented a density-based memory mechanism that preserves the\nmost relevant historical source samples for adaptation. Our experiments show\nthe effectiveness of our proposed method on pain datasets: Biovid and\nUNBC-McMaster.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04252v1",
    "published_date": "2025-04-05 19:14:51 UTC",
    "updated_date": "2025-04-05 19:14:51 UTC"
  },
  {
    "arxiv_id": "2504.04248v1",
    "title": "Task load dependent decision referrals for joint binary classification in human-automation teams",
    "authors": [
      "Kesav Kaza",
      "Jerome Le Ny",
      "Aditya Mahajan"
    ],
    "abstract": "We consider the problem of optimal decision referrals in human-automation\nteams performing binary classification tasks. The automation, which includes a\npre-trained classifier, observes data for a batch of independent tasks,\nanalyzes them, and may refer a subset of tasks to a human operator for fresh\nand final analysis. Our key modeling assumption is that human performance\ndegrades with task load. We model the problem of choosing which tasks to refer\nas a stochastic optimization problem and show that, for a given task load, it\nis optimal to myopically refer tasks that yield the largest reduction in\nexpected cost, conditional on the observed data. This provides a ranking scheme\nand a policy to determine the optimal set of tasks for referral. We evaluate\nthis policy against a baseline through an experimental study with human\nparticipants. Using a radar screen simulator, participants made binary target\nclassification decisions under time constraint. They were guided by a decision\nrule provided to them, but were still prone to errors under time pressure. An\ninitial experiment estimated human performance model parameters, while a second\nexperiment compared two referral policies. Results show statistically\nsignificant gains for the proposed optimal referral policy over a blind policy\nthat determines referrals using the automation and human-performance models but\nnot based on the observed data.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.HC",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "9 pages, 6 figures. Submitted to IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.04248v1",
    "published_date": "2025-04-05 19:09:04 UTC",
    "updated_date": "2025-04-05 19:09:04 UTC"
  },
  {
    "arxiv_id": "2504.04244v1",
    "title": "From Automation to Autonomy in Smart Manufacturing: A Bayesian Optimization Framework for Modeling Multi-Objective Experimentation and Sequential Decision Making",
    "authors": [
      "Avijit Saha Asru",
      "Hamed Khosravi",
      "Imtiaz Ahmed",
      "Abdullahil Azeem"
    ],
    "abstract": "Discovering novel materials with desired properties is essential for driving\ninnovation. Industry 4.0 and smart manufacturing have promised transformative\nadvances in this area through real-time data integration and automated\nproduction planning and control. However, the reliance on automation alone has\noften fallen short, lacking the flexibility needed for complex processes. To\nfully unlock the potential of smart manufacturing, we must evolve from\nautomation to autonomous systems that go beyond rigid programming and can\ndynamically optimize the search for solutions. Current discovery approaches are\noften slow, requiring numerous trials to find optimal combinations, and costly,\nparticularly when optimizing multiple properties simultaneously. This paper\nproposes a Bayesian multi-objective sequential decision-making (BMSDM)\nframework that can intelligently select experiments as manufacturing\nprogresses, guiding us toward the discovery of optimal design faster and more\nefficiently. The framework leverages sequential learning through Bayesian\nOptimization, which iteratively refines a statistical model representing the\nunderlying manufacturing process. This statistical model acts as a surrogate,\nallowing for efficient exploration and optimization without requiring numerous\nreal-world experiments. This approach can significantly reduce the time and\ncost of data collection required by traditional experimental designs. The\nproposed framework is compared with traditional DoE methods and two other\nmulti-objective optimization methods. Using a manufacturing dataset, we\nevaluate and compare the performance of these approaches across five evaluation\nmetrics. BMSDM comprehensively outperforms the competing methods in\nmulti-objective decision-making scenarios. Our proposed approach represents a\nsignificant leap forward in creating an intelligent autonomous platform capable\nof novel material discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04244v1",
    "published_date": "2025-04-05 18:21:20 UTC",
    "updated_date": "2025-04-05 18:21:20 UTC"
  },
  {
    "arxiv_id": "2504.04243v2",
    "title": "Perils of Label Indeterminacy: A Case Study on Prediction of Neurological Recovery After Cardiac Arrest",
    "authors": [
      "Jakob Schoeffer",
      "Maria De-Arteaga",
      "Jonathan Elmer"
    ],
    "abstract": "The design of AI systems to assist human decision-making typically requires\nthe availability of labels to train and evaluate supervised models. Frequently,\nhowever, these labels are unknown, and different ways of estimating them\ninvolve unverifiable assumptions or arbitrary choices. In this work, we\nintroduce the concept of label indeterminacy and derive important implications\nin high-stakes AI-assisted decision-making. We present an empirical study in a\nhealthcare context, focusing specifically on predicting the recovery of\ncomatose patients after resuscitation from cardiac arrest. Our study shows that\nlabel indeterminacy can result in models that perform similarly when evaluated\non patients with known labels, but vary drastically in their predictions for\npatients where labels are unknown. After demonstrating crucial ethical\nimplications of label indeterminacy in this high-stakes context, we discuss\ntakeaways for evaluation, reporting, and design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "The 2025 ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT '25)",
    "pdf_url": "http://arxiv.org/pdf/2504.04243v2",
    "published_date": "2025-04-05 18:07:36 UTC",
    "updated_date": "2025-05-07 20:06:13 UTC"
  },
  {
    "arxiv_id": "2504.04241v1",
    "title": "oneDAL Optimization for ARM Scalable Vector Extension: Maximizing Efficiency for High-Performance Data Science",
    "authors": [
      "Chandan Sharma",
      "Rakshith GB",
      "Ajay Kumar Patel",
      "Dhanus M Lal",
      "Darshan Patel",
      "Ragesh Hajela",
      "Masahiro Doteguchi",
      "Priyanka Sharma"
    ],
    "abstract": "The evolution of ARM-based architectures, particularly those incorporating\nScalable Vector Extension (SVE), has introduced transformative opportunities\nfor high-performance computing (HPC) and machine learning (ML) workloads. The\nUnified Acceleration Foundation's (UXL) oneAPI Data Analytics Library (oneDAL)\nis a widely adopted library for accelerating ML and data analytics workflows,\nbut its reliance on Intel's proprietary Math Kernel Library (MKL) has\ntraditionally limited its compatibility to x86platforms. This paper details the\nporting of oneDAL to ARM architectures with SVE support, using OpenBLAS as an\nalternative backend to overcome architectural and performance challenges.\nBeyond porting, the research introduces novel ARM-specific optimizations,\nincluding custom sparse matrix routines, vectorized statistical functions, and\na Scalable Vector Extension (SVE)-optimized Support Vector Machine (SVM)\nalgorithm. The SVM enhancements leverage SVE's flexible vector lengths and\npredicate driven execution, achieving notable performance gains of 22% for the\nBoser method and 5% for the Thunder method. Benchmarks conducted on ARM\nSVE-enabled AWSGraviton3 instances showcase up to 200x acceleration in ML\ntraining and inference tasks compared to the original scikit-learn\nimplementation on the ARM platform. Moreover, the ARM-optimized oneDAL achieves\nperformance parity with, and in some cases exceeds, the x86 oneDAL\nimplementation (MKL backend) on IceLake x86 systems, which are nearly twice as\ncostly as AWSGraviton3 ARM instances. These findings highlight ARM's potential\nas a high-performance, energyefficient platform for dataintensive ML\napplications. By expanding cross-architecture compatibility and contributing to\nthe opensource ecosystem, this work reinforces ARM's position as a competitive\nalternative in the HPC and ML domains, paving the way for future advancements\nin dataintensive computing.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04241v1",
    "published_date": "2025-04-05 17:53:36 UTC",
    "updated_date": "2025-04-05 17:53:36 UTC"
  },
  {
    "arxiv_id": "2504.04238v1",
    "title": "Sensitivity Meets Sparsity: The Impact of Extremely Sparse Parameter Patterns on Theory-of-Mind of Large Language Models",
    "authors": [
      "Yuheng Wu",
      "Wentao Guo",
      "Zirui Liu",
      "Heng Ji",
      "Zhaozhuo Xu",
      "Denghui Zhang"
    ],
    "abstract": "This paper investigates the emergence of Theory-of-Mind (ToM) capabilities in\nlarge language models (LLMs) from a mechanistic perspective, focusing on the\nrole of extremely sparse parameter patterns. We introduce a novel method to\nidentify ToM-sensitive parameters and reveal that perturbing as little as\n0.001% of these parameters significantly degrades ToM performance while also\nimpairing contextual localization and language understanding. To understand\nthis effect, we analyze their interaction with core architectural components of\nLLMs. Our findings demonstrate that these sensitive parameters are closely\nlinked to the positional encoding module, particularly in models using Rotary\nPosition Embedding (RoPE), where perturbations disrupt dominant-frequency\nactivations critical for contextual processing. Furthermore, we show that\nperturbing ToM-sensitive parameters affects LLM's attention mechanism by\nmodulating the angle between queries and keys under positional encoding. These\ninsights provide a deeper understanding of how LLMs acquire social reasoning\nabilities, bridging AI interpretability with cognitive science. Our results\nhave implications for enhancing model alignment, mitigating biases, and\nimproving AI systems designed for human interaction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04238v1",
    "published_date": "2025-04-05 17:45:42 UTC",
    "updated_date": "2025-04-05 17:45:42 UTC"
  },
  {
    "arxiv_id": "2504.12309v2",
    "title": "Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective",
    "authors": [
      "Yi-De Lin",
      "Guan-Ze Liao"
    ],
    "abstract": "From 2000 to 2015, the UN's Millennium Development Goals guided global\npriorities. The subsequent Sustainable Development Goals (SDGs) adopted a more\ndynamic approach, with annual indicator updates. As 2030 nears and progress\nlags, innovative acceleration strategies are critical. This study develops an\nAI-powered knowledge graph system to analyze SDG interconnections, discover\npotential new goals, and visualize them online. Using official SDG texts,\nElsevier's keyword dataset, and 1,127 TED Talk transcripts (2020.01-2024.04), a\npilot on 269 talks from 2023 applies AI-speculative design, large language\nmodels, and retrieval-augmented generation. Key findings include: (1) Heatmap\nanalysis reveals strong associations between Goal 10 and Goal 16, and minimal\ncoverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time\nreveals new central nodes, showing how richer data supports divergent thinking\nand goal clarity. (3) Six potential new goals are proposed, centered on equity,\nresilience, and technology-driven inclusion. This speculative-AI framework\noffers fresh insights for policymakers and lays groundwork for future\nmultimodal and cross-system SDG applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CY",
    "comment": "This is a minor revision: fixed a typo in the abstract (time range)\n  and corrected minor textual errors",
    "pdf_url": "http://arxiv.org/pdf/2504.12309v2",
    "published_date": "2025-04-05 17:11:53 UTC",
    "updated_date": "2025-04-18 05:38:41 UTC"
  },
  {
    "arxiv_id": "2504.04222v2",
    "title": "TrafficLLM: Enhancing Large Language Models for Network Traffic Analysis with Generic Traffic Representation",
    "authors": [
      "Tianyu Cui",
      "Xinjie Lin",
      "Sijia Li",
      "Miao Chen",
      "Qilei Yin",
      "Qi Li",
      "Ke Xu"
    ],
    "abstract": "Machine learning (ML) powered network traffic analysis has been widely used\nfor the purpose of threat detection. Unfortunately, their generalization across\ndifferent tasks and unseen data is very limited. Large language models (LLMs),\nknown for their strong generalization capabilities, have shown promising\nperformance in various domains. However, their application to the traffic\nanalysis domain is limited due to significantly different characteristics of\nnetwork traffic. To address the issue, in this paper, we propose TrafficLLM,\nwhich introduces a dual-stage fine-tuning framework to learn generic traffic\nrepresentation from heterogeneous raw traffic data. The framework uses\ntraffic-domain tokenization, dual-stage tuning pipeline, and extensible\nadaptation to help LLM release generalization ability on dynamic traffic\nanalysis tasks, such that it enables traffic detection and traffic generation\nacross a wide range of downstream tasks. We evaluate TrafficLLM across 10\ndistinct scenarios and 229 types of traffic. TrafficLLM achieves F1-scores of\n0.9875 and 0.9483, with up to 80.12% and 33.92% better performance than\nexisting detection and generation methods. It also shows strong generalization\non unseen traffic with an 18.6% performance improvement. We further evaluate\nTrafficLLM in real-world scenarios. The results confirm that TrafficLLM is easy\nto scale and achieves accurate detection performance on enterprise traffic.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04222v2",
    "published_date": "2025-04-05 16:18:33 UTC",
    "updated_date": "2025-04-15 08:30:04 UTC"
  },
  {
    "arxiv_id": "2504.04215v1",
    "title": "Towards Understanding and Improving Refusal in Compressed Models via Mechanistic Interpretability",
    "authors": [
      "Vishnu Kabir Chhabra",
      "Mohammad Mahdi Khalili"
    ],
    "abstract": "The rapid growth of large language models has spurred significant interest in\nmodel compression as a means to enhance their accessibility and practicality.\nWhile extensive research has explored model compression through the lens of\nsafety, findings suggest that safety-aligned models often lose elements of\ntrustworthiness post-compression. Simultaneously, the field of mechanistic\ninterpretability has gained traction, with notable discoveries, such as the\nidentification of a single direction in the residual stream mediating refusal\nbehaviors across diverse model architectures. In this work, we investigate the\nsafety of compressed models by examining the mechanisms of refusal, adopting a\nnovel interpretability-driven perspective to evaluate model safety.\nFurthermore, leveraging insights from our interpretability analysis, we propose\na lightweight, computationally efficient method to enhance the safety of\ncompressed models without compromising their performance or utility.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04215v1",
    "published_date": "2025-04-05 16:00:44 UTC",
    "updated_date": "2025-04-05 16:00:44 UTC"
  },
  {
    "arxiv_id": "2504.04204v1",
    "title": "Adaptive Elicitation of Latent Information Using Natural Language",
    "authors": [
      "Jimmy Wang",
      "Thomas Zollo",
      "Richard Zemel",
      "Hongseok Namkoong"
    ],
    "abstract": "Eliciting information to reduce uncertainty about a latent entity is a\ncritical task in many application domains, e.g., assessing individual student\nlearning outcomes, diagnosing underlying diseases, or learning user\npreferences. Though natural language is a powerful medium for this purpose,\nlarge language models (LLMs) and existing fine-tuning algorithms lack\nmechanisms for strategically gathering information to refine their own\nunderstanding of the latent entity. To harness the generalization power and\nworld knowledge of LLMs in developing effective information-gathering\nstrategies, we propose an adaptive elicitation framework that actively reduces\nuncertainty on the latent entity. Since probabilistic modeling of an abstract\nlatent entity is difficult, our framework adopts a predictive view of\nuncertainty, using a meta-learned language model to simulate future\nobservations and enable scalable uncertainty quantification over complex\nnatural language. Through autoregressive forward simulation, our model\nquantifies how new questions reduce epistemic uncertainty, enabling the\ndevelopment of sophisticated information-gathering strategies to choose the\nmost informative next queries. In experiments on the 20 questions game, dynamic\nopinion polling, and adaptive student assessment, our method consistently\noutperforms baselines in identifying critical unknowns and improving downstream\npredictions, illustrating the promise of strategic information gathering in\nnatural language settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04204v1",
    "published_date": "2025-04-05 15:18:55 UTC",
    "updated_date": "2025-04-05 15:18:55 UTC"
  },
  {
    "arxiv_id": "2504.04170v2",
    "title": "Digital Gene: Learning about the Physical World through Analytic Concepts",
    "authors": [
      "Jianhua Sun",
      "Cewu Lu"
    ],
    "abstract": "Reviewing the progress in artificial intelligence over the past decade,\nvarious significant advances (e.g. object detection, image generation, large\nlanguage models) have enabled AI systems to produce more semantically\nmeaningful outputs and achieve widespread adoption in internet scenarios.\nNevertheless, AI systems still struggle when it comes to understanding and\ninteracting with the physical world. This reveals an important issue: relying\nsolely on semantic-level concepts learned from internet data (e.g. texts,\nimages) to understand the physical world is far from sufficient -- machine\nintelligence currently lacks an effective way to learn about the physical\nworld. This research introduces the idea of analytic concept -- representing\nthe concepts related to the physical world through programs of mathematical\nprocedures, providing machine intelligence a portal to perceive, reason about,\nand interact with the physical world. Except for detailing the design\nphilosophy and providing guidelines for the application of analytic concepts,\nthis research also introduce about the infrastructure that has been built\naround analytic concepts. I aim for my research to contribute to addressing\nthese questions: What is a proper abstraction of general concepts in the\nphysical world for machine intelligence? How to systematically integrate\nstructured priors with neural networks to constrain AI systems to comply with\nphysical laws?",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04170v2",
    "published_date": "2025-04-05 13:22:11 UTC",
    "updated_date": "2025-04-09 10:35:12 UTC"
  },
  {
    "arxiv_id": "2504.08782v1",
    "title": "Embedding Hidden Adversarial Capabilities in Pre-Trained Diffusion Models",
    "authors": [
      "Lucas Beerens",
      "Desmond J. Higham"
    ],
    "abstract": "We introduce a new attack paradigm that embeds hidden adversarial\ncapabilities directly into diffusion models via fine-tuning, without altering\ntheir observable behavior or requiring modifications during inference. Unlike\nprior approaches that target specific images or adjust the generation process\nto produce adversarial outputs, our method integrates adversarial functionality\ninto the model itself. The resulting tampered model generates high-quality\nimages indistinguishable from those of the original, yet these images cause\nmisclassification in downstream classifiers at a high rate. The\nmisclassification can be targeted to specific output classes. Users can employ\nthis compromised model unaware of its embedded adversarial nature, as it\nfunctions identically to a standard diffusion model. We demonstrate the\neffectiveness and stealthiness of our approach, uncovering a covert attack\nvector that raises new security concerns. These findings expose a risk arising\nfrom the use of externally-supplied models and highlight the urgent need for\nrobust model verification and defense mechanisms against hidden threats in\ngenerative models. The code is available at\nhttps://github.com/LucasBeerens/CRAFTed-Diffusion .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08782v1",
    "published_date": "2025-04-05 12:51:36 UTC",
    "updated_date": "2025-04-05 12:51:36 UTC"
  },
  {
    "arxiv_id": "2504.04150v1",
    "title": "Reasoning on Multiple Needles In A Haystack",
    "authors": [
      "Yidong Wang"
    ],
    "abstract": "The Needle In A Haystack (NIAH) task has been widely used to evaluate the\nlong-context question-answering capabilities of Large Language Models (LLMs).\nHowever, its reliance on simple retrieval limits its effectiveness. To address\nthis limitation, recent studies have introduced the Multiple Needles In A\nHaystack Reasoning (MNIAH-R) task, which incorporates supporting documents\n(Multiple needles) of multi-hop reasoning tasks into a distracting context\n(Haystack}). Despite this advancement, existing approaches still fail to\naddress the issue of models providing direct answers from internal knowledge,\nand they do not explain or mitigate the decline in accuracy as context length\nincreases. In this paper, we tackle the memory-based answering problem by\nfiltering out direct-answer questions, and we reveal that performance\ndegradation is primarily driven by the reduction in the length of the thinking\nprocess as the input length increases. Building on this insight, we decompose\nthe thinking process into retrieval and reasoning stages and introduce a\nreflection mechanism for multi-round extension. We also train a model using the\ngenerated iterative thinking process, which helps mitigate the performance\ndegradation. Furthermore, we demonstrate the application of this\nretrieval-reflection capability in mathematical reasoning scenarios, improving\nGPT-4o's performance on AIME2024.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04150v1",
    "published_date": "2025-04-05 11:58:08 UTC",
    "updated_date": "2025-04-05 11:58:08 UTC"
  },
  {
    "arxiv_id": "2504.04142v1",
    "title": "My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt",
    "authors": [
      "Kees van Deemter"
    ],
    "abstract": "In this very personal workography, I relate my 40-year experiences as a\nresearcher and educator in and around Artificial Intelligence (AI), more\nspecifically Natural Language Processing. I describe how curiosity, and the\ncircumstances of the day, led me to work in both industry and academia, and in\nvarious countries, including The Netherlands (Amsterdam, Eindhoven, and\nUtrecht), the USA (Stanford), England (Brighton), Scotland (Aberdeen), and\nChina (Beijing and Harbin). People and anecdotes play a large role in my story;\nthe history of AI forms its backdrop. I focus on things that might be of\ninterest to (even) younger colleagues, given the choices they face in their own\nwork and life at a time when AI is finally emerging from the shadows.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04142v1",
    "published_date": "2025-04-05 11:26:48 UTC",
    "updated_date": "2025-04-05 11:26:48 UTC"
  },
  {
    "arxiv_id": "2504.04139v1",
    "title": "Introducing COGENT3: An AI Architecture for Emergent Cognition",
    "authors": [
      "Eduardo Salazar"
    ],
    "abstract": "This paper presents COGENT3 (or Collective Growth and Entropy-modulated\nTriads System), a novel approach for emergent cognition integrating pattern\nformation networks with group influence dynamics. Contrasting with traditional\nstrategies that rely on predetermined architectures, computational structures\nemerge dynamically in our framework through agent interactions. This enables a\nmore flexible and adaptive system exhibiting characteristics reminiscent of\nhuman cognitive processes. The incorporation of temperature modulation and\nmemory effects in COGENT3 closely integrates statistical mechanics, machine\nlearning, and cognitive science.",
    "categories": [
      "cs.AI",
      "68T05, 37A60, 05C82, 82C20",
      "I.2.6; G.2.2; I.6.8"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04139v1",
    "published_date": "2025-04-05 11:05:55 UTC",
    "updated_date": "2025-04-05 11:05:55 UTC"
  },
  {
    "arxiv_id": "2504.04138v1",
    "title": "Predicting Soil Macronutrient Levels: A Machine Learning Approach Models Trained on pH, Conductivity, and Average Power of Acid-Base Solutions",
    "authors": [
      "Mridul Kumar",
      "Deepali Jain",
      "Zeeshan Saifi",
      "Soami Daya Krishnananda"
    ],
    "abstract": "Soil macronutrients, particularly potassium ions (K$^+$), are indispensable\nfor plant health, underpinning various physiological and biological processes,\nand facilitating the management of both biotic and abiotic stresses. Deficient\nmacronutrient content results in stunted growth, delayed maturation, and\nincreased vulnerability to environmental stressors, thereby accentuating the\nimperative for precise soil nutrient monitoring. Traditional techniques such as\nchemical assays, atomic absorption spectroscopy, inductively coupled plasma\noptical emission spectroscopy, and electrochemical methods, albeit advanced,\nare prohibitively expensive and time-intensive, thus unsuitable for real-time\nmacronutrient assessment. In this study, we propose an innovative soil testing\nprotocol utilizing a dataset derived from synthetic solutions to model soil\nbehaviour. The dataset encompasses physical properties including conductivity\nand pH, with a concentration on three key macronutrients: nitrogen (N),\nphosphorus (P), and potassium (K). Four machine learning algorithms were\napplied to the dataset, with random forest regressors and neural networks being\nselected for the prediction of soil nutrient concentrations. Comparative\nanalysis with laboratory soil testing results revealed prediction errors of\n23.6% for phosphorus and 16% for potassium using the random forest model, and\n26.3% for phosphorus and 21.8% for potassium using the neural network model.\nThis methodology illustrates a cost-effective and efficacious strategy for\nreal-time soil nutrient monitoring, offering substantial advancements over\nconventional techniques and enhancing the capability to sustain optimal\nnutrient levels conducive to robust crop growth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04138v1",
    "published_date": "2025-04-05 11:04:48 UTC",
    "updated_date": "2025-04-05 11:04:48 UTC"
  },
  {
    "arxiv_id": "2504.04128v1",
    "title": "Guaranteeing consistency in evidence fusion: A novel perspective on credibility",
    "authors": [
      "Chaoxiong Ma",
      "Yan Liang",
      "Huixia Zhang",
      "Hao Sun"
    ],
    "abstract": "It is explored that available credible evidence fusion schemes suffer from\nthe potential inconsistency because credibility calculation and Dempster's\ncombination rule-based fusion are sequentially performed in an open-loop style.\nThis paper constructs evidence credibility from the perspective of the degree\nof support for events within the framework of discrimination (FOD) and proposes\nan iterative credible evidence fusion (ICEF) to overcome the inconsistency in\nview of close-loop control. On one hand, the ICEF introduces the fusion result\ninto credibility assessment to establish the correlation between credibility\nand the fusion result. On the other hand, arithmetic-geometric divergence is\npromoted based on the exponential normalization of plausibility and belief\nfunctions to measure evidence conflict, called plausibility-belief\narithmetic-geometric divergence (PBAGD), which is superior in capturing the\ncorrelation and difference of FOD subsets, identifying abnormal sources, and\nreducing their fusion weights. The ICEF is compared with traditional methods by\ncombining different evidence difference measure forms via numerical examples to\nverify its performance. Simulations on numerical examples and benchmark\ndatasets reflect the adaptability of PBAGD to the proposed fusion strategy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04128v1",
    "published_date": "2025-04-05 10:12:32 UTC",
    "updated_date": "2025-04-05 10:12:32 UTC"
  },
  {
    "arxiv_id": "2504.04126v1",
    "title": "Multi-identity Human Image Animation with Structural Video Diffusion",
    "authors": [
      "Zhenzhi Wang",
      "Yixuan Li",
      "Yanhong Zeng",
      "Yuwei Guo",
      "Dahua Lin",
      "Tianfan Xue",
      "Bo Dai"
    ],
    "abstract": "Generating human videos from a single image while ensuring high visual\nquality and precise control is a challenging task, especially in complex\nscenarios involving multiple individuals and interactions with objects.\nExisting methods, while effective for single-human cases, often fail to handle\nthe intricacies of multi-identity interactions because they struggle to\nassociate the correct pairs of human appearance and pose condition and model\nthe distribution of 3D-aware dynamics. To address these limitations, we present\nStructural Video Diffusion, a novel framework designed for generating realistic\nmulti-human videos. Our approach introduces two core innovations:\nidentity-specific embeddings to maintain consistent appearances across\nindividuals and a structural learning mechanism that incorporates depth and\nsurface-normal cues to model human-object interactions. Additionally, we expand\nexisting human video dataset with 25K new videos featuring diverse multi-human\nand object interaction scenarios, providing a robust foundation for training.\nExperimental results demonstrate that Structural Video Diffusion achieves\nsuperior performance in generating lifelike, coherent videos for multiple\nsubjects with dynamic and rich interactions, advancing the state of\nhuman-centric video generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04126v1",
    "published_date": "2025-04-05 10:03:49 UTC",
    "updated_date": "2025-04-05 10:03:49 UTC"
  },
  {
    "arxiv_id": "2504.04121v1",
    "title": "Improving Question Embeddings with Cognitiv Representation Optimization for Knowledge Tracing",
    "authors": [
      "Lixiang Xu",
      "Xianwei Ding",
      "Xin Yuan",
      "Zhanlong Wang",
      "Lu Bai",
      "Enhong Chen",
      "Philip S. Yu",
      "Yuanyan Tang"
    ],
    "abstract": "The Knowledge Tracing (KT) aims to track changes in students' knowledge\nstatus and predict their future answers based on their historical answer\nrecords. Current research on KT modeling focuses on predicting student' future\nperformance based on existing, unupdated records of student learning\ninteractions. However, these approaches ignore the distractors (such as\nslipping and guessing) in the answering process and overlook that static\ncognitive representations are temporary and limited. Most of them assume that\nthere are no distractors in the answering process and that the record\nrepresentations fully represent the students' level of understanding and\nproficiency in knowledge. In this case, it may lead to many insynergy and\nincoordination issue in the original records. Therefore we propose a Cognitive\nRepresentation Optimization for Knowledge Tracing (CRO-KT) model, which\nutilizes a dynamic programming algorithm to optimize structure of cognitive\nrepresentations. This ensures that the structure matches the students'\ncognitive patterns in terms of the difficulty of the exercises. Furthermore, we\nuse the co-optimization algorithm to optimize the cognitive representations of\nthe sub-target exercises in terms of the overall situation of exercises\nresponses by considering all the exercises with co-relationships as a single\ngoal. Meanwhile, the CRO-KT model fuses the learned relational embeddings from\nthe bipartite graph with the optimized record representations in a weighted\nmanner, enhancing the expression of students' cognition. Finally, experiments\nare conducted on three publicly available datasets respectively to validate the\neffectiveness of the proposed cognitive representation optimization model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04121v1",
    "published_date": "2025-04-05 09:32:03 UTC",
    "updated_date": "2025-04-05 09:32:03 UTC"
  },
  {
    "arxiv_id": "2504.04110v1",
    "title": "PEIRCE: Unifying Material and Formal Reasoning via LLM-Driven Neuro-Symbolic Refinement",
    "authors": [
      "Xin Quan",
      "Marco Valentino",
      "Danilo S. Carvalho",
      "Dhairya Dalal",
      "AndrÃ© Freitas"
    ],
    "abstract": "A persistent challenge in AI is the effective integration of material and\nformal inference - the former concerning the plausibility and contextual\nrelevance of arguments, while the latter focusing on their logical and\nstructural validity. Large Language Models (LLMs), by virtue of their extensive\npre-training on large textual corpora, exhibit strong capabilities in material\ninference. However, their reasoning often lacks formal rigour and\nverifiability. At the same time, LLMs' linguistic competence positions them as\na promising bridge between natural and formal languages, opening up new\nopportunities for combining these two modes of reasoning. In this paper, we\nintroduce PEIRCE, a neuro-symbolic framework designed to unify material and\nformal inference through an iterative conjecture-criticism process. Within this\nframework, LLMs play the central role of generating candidate solutions in\nnatural and formal languages, which are then evaluated and refined via\ninteraction with external critique models. These critiques include symbolic\nprovers, which assess formal validity, as well as soft evaluators that measure\nthe quality of the generated arguments along linguistic and epistemic\ndimensions such as plausibility, coherence, and parsimony. While PEIRCE is a\ngeneral-purpose framework, we demonstrate its capabilities in the domain of\nnatural language explanation generation - a setting that inherently demands\nboth material adequacy and formal correctness.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Demo paper. Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.04110v1",
    "published_date": "2025-04-05 09:04:47 UTC",
    "updated_date": "2025-04-05 09:04:47 UTC"
  },
  {
    "arxiv_id": "2504.13891v1",
    "title": "Mozualization: Crafting Music and Visual Representation with Multimodal AI",
    "authors": [
      "Wanfang Xu",
      "Lixiang Zhao",
      "Haiwen Song",
      "Xinheng Song",
      "Zhaolin Lu",
      "Yu Liu",
      "Min Chen",
      "Eng Gee Lim",
      "Lingyun Yu"
    ],
    "abstract": "In this work, we introduce Mozualization, a music generation and editing tool\nthat creates multi-style embedded music by integrating diverse inputs, such as\nkeywords, images, and sound clips (e.g., segments from various pieces of music\nor even a playful cat's meow). Our work is inspired by the ways people express\ntheir emotions -- writing mood-descriptive poems or articles, creating drawings\nwith warm or cool tones, or listening to sad or uplifting music. Building on\nthis concept, we developed a tool that transforms these emotional expressions\ninto a cohesive and expressive song, allowing users to seamlessly incorporate\ntheir unique preferences and inspirations. To evaluate the tool and, more\nimportantly, gather insights for its improvement, we conducted a user study\ninvolving nine music enthusiasts. The study assessed user experience,\nengagement, and the impact of interacting with and listening to the generated\nmusic.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 5 figures, CHI2025",
    "pdf_url": "http://arxiv.org/pdf/2504.13891v1",
    "published_date": "2025-04-05 08:22:20 UTC",
    "updated_date": "2025-04-05 08:22:20 UTC"
  },
  {
    "arxiv_id": "2504.04099v1",
    "title": "TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection",
    "authors": [
      "Chunzhao Xie",
      "Tongxuan Liu",
      "Lei Jiang",
      "Yuting Zeng",
      "jinrong Guo",
      "Yunheng Shen",
      "Weizhe Huang",
      "Jing Li",
      "Xiaohua Xu"
    ],
    "abstract": "Large Vision-Language Models have demonstrated remarkable performance across\nvarious tasks; however, the challenge of hallucinations constrains their\npractical applications. The hallucination problem arises from multiple factors,\nincluding the inherent hallucinations in language models, the limitations of\nvisual encoders in perception, and biases introduced by multimodal data.\nExtensive research has explored ways to mitigate hallucinations. For instance,\nOPERA prevents the model from overly focusing on \"anchor tokens\", thereby\nreducing hallucinations, whereas VCD mitigates hallucinations by employing a\ncontrastive decoding approach. In this paper, we investigate the correlation\nbetween the decay of attention to image tokens and the occurrence of\nhallucinations. Based on this finding, we propose Temporal Attention Real-time\nAccumulative Connection (TARAC), a novel training-free method that dynamically\naccumulates and updates LVLMs' attention on image tokens during generation. By\nenhancing the model's attention to image tokens, TARAC mitigates hallucinations\ncaused by the decay of attention on image tokens. We validate the effectiveness\nof TARAC across multiple models and datasets, demonstrating that our approach\nsubstantially mitigates hallucinations. In particular, TARAC reduces $C_S$ by\n25.2 and $C_I$ by 8.7 compared to VCD on the CHAIR benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04099v1",
    "published_date": "2025-04-05 07:57:11 UTC",
    "updated_date": "2025-04-05 07:57:11 UTC"
  },
  {
    "arxiv_id": "2504.08781v1",
    "title": "Efficient Evaluation of Large Language Models via Collaborative Filtering",
    "authors": [
      "Xu-Xiang Zhong",
      "Chao Yi",
      "Han-Jia Ye"
    ],
    "abstract": "With the development of Large Language Models (LLMs), numerous benchmarks\nhave been proposed to measure and compare the capabilities of different LLMs.\nHowever, evaluating LLMs is costly due to the large number of test instances\nand their slow inference speed. In this paper, we aim to explore how to\nefficiently estimate a model's real performance on a given benchmark based on\nits evaluation results on a small number of instances sampled from the\nbenchmark. Inspired by Collaborative Filtering (CF) in Recommendation Systems\n(RS), we treat LLMs as users and test instances as items and propose a\ntwo-stage method. In the first stage, we treat instance selection as\nrecommending products to users to choose instances that can easily distinguish\nmodel performance. In the second stage, we see performance prediction as rating\nprediction problem in RS to predict the target LLM's behavior on unselected\ninstances. Experiments on multiple LLMs and datasets imply that our method can\naccurately estimate the target model's performance while largely reducing its\ninference overhead.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08781v1",
    "published_date": "2025-04-05 07:46:30 UTC",
    "updated_date": "2025-04-05 07:46:30 UTC"
  },
  {
    "arxiv_id": "2504.04089v1",
    "title": "Lifting Factor Graphs with Some Unknown Factors for New Individuals",
    "authors": [
      "Malte Luttermann",
      "Ralf MÃ¶ller",
      "Marcel Gehrke"
    ],
    "abstract": "Lifting exploits symmetries in probabilistic graphical models by using a\nrepresentative for indistinguishable objects, allowing to carry out query\nanswering more efficiently while maintaining exact answers. In this paper, we\ninvestigate how lifting enables us to perform probabilistic inference for\nfactor graphs containing unknown factors, i.e., factors whose underlying\nfunction of potential mappings is unknown. We present the Lifting Factor Graphs\nwith Some Unknown Factors (LIFAGU) algorithm to identify indistinguishable\nsubgraphs in a factor graph containing unknown factors, thereby enabling the\ntransfer of known potentials to unknown potentials to ensure a well-defined\nsemantics of the model and allow for (lifted) probabilistic inference. We\nfurther extend LIFAGU to incorporate additional background knowledge about\ngroups of factors belonging to the same individual object. By incorporating\nsuch background knowledge, LIFAGU is able to further reduce the ambiguity of\npossible transfers of known potentials to unknown potentials.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the International Journal of Approximate Reasoning,\n  Volume 179 (2025). This paper is a revised and extended version of\n  arXiv:2406.01275",
    "pdf_url": "http://arxiv.org/pdf/2504.04089v1",
    "published_date": "2025-04-05 07:23:08 UTC",
    "updated_date": "2025-04-05 07:23:08 UTC"
  },
  {
    "arxiv_id": "2504.04086v1",
    "title": "Towards An Efficient and Effective En Route Travel Time Estimation Framework",
    "authors": [
      "Zekai Shen",
      "Haitao Yuan",
      "Xiaowei Mao",
      "Congkang Lv",
      "Shengnan Guo",
      "Youfang Lin",
      "Huaiyu Wan"
    ],
    "abstract": "En route travel time estimation (ER-TTE) focuses on predicting the travel\ntime of the remaining route. Existing ER-TTE methods always make re-estimation\nwhich significantly hinders real-time performance, especially when faced with\nthe computational demands of simultaneous user requests. This results in delays\nand reduced responsiveness in ER-TTE services. We propose a general efficient\nframework U-ERTTE combining an Uncertainty-Guided Decision mechanism (UGD) and\nFine-Tuning with Meta-Learning (FTML) to address these challenges. UGD\nquantifies the uncertainty and provides confidence intervals for the entire\nroute. It selectively re-estimates only when the actual travel time deviates\nfrom the predicted confidence intervals, thereby optimizing the efficiency of\nER-TTE. To ensure the accuracy of confidence intervals and accurate predictions\nthat need to re-estimate, FTML is employed to train the model, enabling it to\nlearn general driving patterns and specific features to adapt to specific\ntasks. Extensive experiments on two large-scale real datasets demonstrate that\nthe U-ERTTE framework significantly enhances inference speed and throughput\nwhile maintaining high effectiveness. Our code is available at\nhttps://github.com/shenzekai/U-ERTTE",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by DASFAA 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04086v1",
    "published_date": "2025-04-05 07:15:26 UTC",
    "updated_date": "2025-04-05 07:15:26 UTC"
  },
  {
    "arxiv_id": "2504.04085v1",
    "title": "DocSAM: Unified Document Image Segmentation via Query Decomposition and Heterogeneous Mixed Learning",
    "authors": [
      "Xiao-Hui Li",
      "Fei Yin",
      "Cheng-Lin Liu"
    ],
    "abstract": "Document image segmentation is crucial for document analysis and recognition\nbut remains challenging due to the diversity of document formats and\nsegmentation tasks. Existing methods often address these tasks separately,\nresulting in limited generalization and resource wastage. This paper introduces\nDocSAM, a transformer-based unified framework designed for various document\nimage segmentation tasks, such as document layout analysis, multi-granularity\ntext segmentation, and table structure recognition, by modelling these tasks as\na combination of instance and semantic segmentation. Specifically, DocSAM\nemploys Sentence-BERT to map category names from each dataset into semantic\nqueries that match the dimensionality of instance queries. These two sets of\nqueries interact through an attention mechanism and are cross-attended with\nimage features to predict instance and semantic segmentation masks. Instance\ncategories are predicted by computing the dot product between instance and\nsemantic queries, followed by softmax normalization of scores. Consequently,\nDocSAM can be jointly trained on heterogeneous datasets, enhancing robustness\nand generalization while reducing computational and storage resources.\nComprehensive evaluations show that DocSAM surpasses existing methods in\naccuracy, efficiency, and adaptability, highlighting its potential for\nadvancing document image understanding and segmentation across various\napplications. Codes are available at https://github.com/xhli-git/DocSAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has been accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04085v1",
    "published_date": "2025-04-05 07:14:53 UTC",
    "updated_date": "2025-04-05 07:14:53 UTC"
  },
  {
    "arxiv_id": "2504.04072v2",
    "title": "Among Us: A Sandbox for Measuring and Detecting Agentic Deception",
    "authors": [
      "Satvik Golechha",
      "AdriÃ  Garriga-Alonso"
    ],
    "abstract": "Prior studies on deception in language-based AI agents typically assess\nwhether the agent produces a false statement about a topic, or makes a binary\nchoice prompted by a goal, rather than allowing open-ended deceptive behavior\nto emerge in pursuit of a longer-term goal. To fix this, we introduce\n$\\textit{Among Us}$, a sandbox social deception game where LLM-agents exhibit\nlong-term, open-ended deception as a consequence of the game objectives. While\nmost benchmarks saturate quickly, $\\textit{Among Us}$ can be expected to last\nmuch longer, because it is a multi-player game far from equilibrium. Using the\nsandbox, we evaluate $18$ proprietary and open-weight LLMs and uncover a\ngeneral trend: models trained with RL are comparatively much better at\nproducing deception than detecting it. We evaluate the effectiveness of methods\nto detect lying and deception: logistic regression on the activations and\nsparse autoencoders (SAEs). We find that probes trained on a dataset of\n``pretend you're a dishonest model: $\\dots$'' generalize extremely well\nout-of-distribution, consistently obtaining AUROCs over 95% even when evaluated\njust on the deceptive statement, without the chain of thought. We also find two\nSAE features that work well at deception detection but are unable to steer the\nmodel to lie less. We hope our open-sourced sandbox, game logs, and probes\nserve to anticipate and mitigate deceptive behavior and capabilities in\nlanguage-based agents.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.04072v2",
    "published_date": "2025-04-05 06:09:32 UTC",
    "updated_date": "2025-05-16 10:14:51 UTC"
  },
  {
    "arxiv_id": "2504.04070v1",
    "title": "Enforcement Agents: Enhancing Accountability and Resilience in Multi-Agent AI Frameworks",
    "authors": [
      "Sagar Tamang",
      "Dibya Jyoti Bora"
    ],
    "abstract": "As autonomous agents become more powerful and widely used, it is becoming\nincreasingly important to ensure they behave safely and stay aligned with\nsystem goals, especially in multi-agent settings. Current systems often rely on\nagents self-monitoring or correcting issues after the fact, but they lack\nmechanisms for real-time oversight. This paper introduces the Enforcement Agent\n(EA) Framework, which embeds dedicated supervisory agents into the environment\nto monitor others, detect misbehavior, and intervene through real-time\ncorrection. We implement this framework in a custom drone simulation and\nevaluate it across 90 episodes using 0, 1, and 2 EA configurations. Results\nshow that adding EAs significantly improves system safety: success rates rise\nfrom 0.0% with no EA to 7.4% with one EA and 26.7% with two EAs. The system\nalso demonstrates increased operational longevity and higher rates of malicious\ndrone reformation. These findings highlight the potential of lightweight,\nreal-time supervision for enhancing alignment and resilience in multi-agent\nsystems.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04070v1",
    "published_date": "2025-04-05 06:07:10 UTC",
    "updated_date": "2025-04-05 06:07:10 UTC"
  },
  {
    "arxiv_id": "2504.04061v1",
    "title": "Mapping at First Sense: A Lightweight Neural Network-Based Indoor Structures Prediction Method for Robot Autonomous Exploration",
    "authors": [
      "Haojia Gao",
      "Haohua Que",
      "Kunrong Li",
      "Weihao Shan",
      "Mingkai Liu",
      "Rong Zhao",
      "Lei Mu",
      "Xinghua Yang",
      "Qi Wei",
      "Fei Qiao"
    ],
    "abstract": "Autonomous exploration in unknown environments is a critical challenge in\nrobotics, particularly for applications such as indoor navigation, search and\nrescue, and service robotics. Traditional exploration strategies, such as\nfrontier-based methods, often struggle to efficiently utilize prior knowledge\nof structural regularities in indoor spaces. To address this limitation, we\npropose Mapping at First Sense, a lightweight neural network-based approach\nthat predicts unobserved areas in local maps, thereby enhancing exploration\nefficiency. The core of our method, SenseMapNet, integrates convolutional and\ntransformerbased architectures to infer occluded regions while maintaining\ncomputational efficiency for real-time deployment on resourceconstrained\nrobots. Additionally, we introduce SenseMapDataset, a curated dataset\nconstructed from KTH and HouseExpo environments, which facilitates training and\nevaluation of neural models for indoor exploration. Experimental results\ndemonstrate that SenseMapNet achieves an SSIM (structural similarity) of 0.78,\nLPIPS (perceptual quality) of 0.68, and an FID (feature distribution alignment)\nof 239.79, outperforming conventional methods in map reconstruction quality.\nCompared to traditional frontier-based exploration, our method reduces\nexploration time by 46.5% (from 2335.56s to 1248.68s) while maintaining a high\ncoverage rate (88%) and achieving a reconstruction accuracy of 88%. The\nproposed method represents a promising step toward efficient, learning-driven\nrobotic exploration in structured environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04061v1",
    "published_date": "2025-04-05 05:19:09 UTC",
    "updated_date": "2025-04-05 05:19:09 UTC"
  },
  {
    "arxiv_id": "2504.04060v2",
    "title": "VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation",
    "authors": [
      "Yuhao Wang",
      "Heyang Liu",
      "Ziyang Cheng",
      "Ronghua Wu",
      "Qunshan Gu",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "abstract": "Speech large language models (LLMs) have emerged as a prominent research\nfocus in speech processing. We introduce VocalNet-1B and VocalNet-8B, a series\nof high-performance, low-latency speech LLMs enabled by a scalable and\nmodel-agnostic training framework designed for real-time voice interaction.\nCentral to our contribution is the first application of multi-token prediction\n(MTP) to speech LLMs. This approach represents a paradigm shift from standard\nnext-token prediction (NTP), offering simultaneous improvements in generation\nspeed and quality. Informed by analysis of MTP's effect on speech generation\nand experimental comparisons, we designed a straightforward and highly\neffective MTP implementation. Experiments demonstrate that VocalNet performs on\npar with mainstream Omni LLMs even with limited training data, and\nsignificantly surpasses existing open-source speech LLMs. To foster\nreproducibility and community advancement, all model weights, inference code,\ntraining data, and framework implementations have been made publicly available\nat https://github.com/SJTU-OmniAgent/VocalNet",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04060v2",
    "published_date": "2025-04-05 04:57:12 UTC",
    "updated_date": "2025-04-22 07:59:31 UTC"
  },
  {
    "arxiv_id": "2504.04052v1",
    "title": "PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks",
    "authors": [
      "Youn-Yeol Yu",
      "Jeongwhan Choi",
      "Jaehyeon Park",
      "Kookjin Lee",
      "Noseong Park"
    ],
    "abstract": "Recently, data-driven simulators based on graph neural networks have gained\nattention in modeling physical systems on unstructured meshes. However, they\nstruggle with long-range dependencies in fluid flows, particularly in refined\nmesh regions. This challenge, known as the 'over-squashing' problem, hinders\ninformation propagation. While existing graph rewiring methods address this\nissue to some extent, they only consider graph topology, overlooking the\nunderlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow\n(PIORF), a novel rewiring method that combines physical correlations with graph\ntopology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneck\nregions and connects these areas with nodes in high-velocity gradient nodes,\nenabling long-range interactions and mitigating over-squashing. Our approach is\ncomputationally efficient in rewiring edges and can scale to larger\nsimulations. Experimental results on 3 fluid dynamics benchmark datasets show\nthat PIORF consistently outperforms baseline models and existing rewiring\nmethods, achieving up to 26.2 improvement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025. Youn-Yeol Yu and Jeongwhan Choi contributed\n  equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2504.04052v1",
    "published_date": "2025-04-05 04:14:05 UTC",
    "updated_date": "2025-04-05 04:14:05 UTC"
  },
  {
    "arxiv_id": "2504.04051v1",
    "title": "Can You Count to Nine? A Human Evaluation Benchmark for Counting Limits in Modern Text-to-Video Models",
    "authors": [
      "Xuyang Guo",
      "Zekai Huang",
      "Jiayan Huo",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Jiahao Zhang"
    ],
    "abstract": "Generative models have driven significant progress in a variety of AI tasks,\nincluding text-to-video generation, where models like Video LDM and Stable\nVideo Diffusion can produce realistic, movie-level videos from textual\ninstructions. Despite these advances, current text-to-video models still face\nfundamental challenges in reliably following human commands, particularly in\nadhering to simple numerical constraints. In this work, we present\nT2VCountBench, a specialized benchmark aiming at evaluating the counting\ncapability of SOTA text-to-video models as of 2025. Our benchmark employs\nrigorous human evaluations to measure the number of generated objects and\ncovers a diverse range of generators, covering both open-source and commercial\nmodels. Extensive experiments reveal that all existing models struggle with\nbasic numerical tasks, almost always failing to generate videos with an object\ncount of 9 or fewer. Furthermore, our comprehensive ablation studies explore\nhow factors like video style, temporal dynamics, and multilingual inputs may\ninfluence counting performance. We also explore prompt refinement techniques\nand demonstrate that decomposing the task into smaller subtasks does not easily\nalleviate these limitations. Our findings highlight important challenges in\ncurrent text-to-video generation and provide insights for future research aimed\nat improving adherence to basic numerical constraints.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04051v1",
    "published_date": "2025-04-05 04:13:06 UTC",
    "updated_date": "2025-04-05 04:13:06 UTC"
  },
  {
    "arxiv_id": "2504.04045v2",
    "title": "A Survey of Pathology Foundation Model: Progress and Future Directions",
    "authors": [
      "Conghao Xiong",
      "Hao Chen",
      "Joseph J. Y. Sung"
    ],
    "abstract": "Computational pathology, which involves analyzing whole slide images for\nautomated cancer diagnosis, relies on multiple instance learning, where\nperformance depends heavily on the feature extractor and aggregator. Recent\nPathology Foundation Models (PFMs), pretrained on large-scale histopathology\ndata, have significantly enhanced both the extractor and aggregator, but they\nlack a systematic analysis framework. In this survey, we present a hierarchical\ntaxonomy organizing PFMs through a top-down philosophy applicable to foundation\nmodel analysis in any domain: model scope, model pretraining, and model design.\nAdditionally, we systematically categorize PFM evaluation tasks into\nslide-level, patch-level, multimodal, and biological tasks, providing\ncomprehensive benchmarking criteria. Our analysis identifies critical\nchallenges in both PFM development (pathology-specific methodology, end-to-end\npretraining, data-model scalability) and utilization (effective adaptation,\nmodel maintenance), paving the way for future directions in this promising\nfield. Resources referenced in this survey are available at\nhttps://github.com/BearCleverProud/AwesomeWSI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IJCAI 2025 Survey Track, 10 Pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04045v2",
    "published_date": "2025-04-05 03:44:09 UTC",
    "updated_date": "2025-05-21 10:27:37 UTC"
  },
  {
    "arxiv_id": "2504.04040v1",
    "title": "ADAPT: Actively Discovering and Adapting to Preferences for any Task",
    "authors": [
      "Maithili Patel",
      "Xavier Puig",
      "Ruta Desai",
      "Roozbeh Mottaghi",
      "Sonia Chernova",
      "Joanne Truong",
      "Akshara Rai"
    ],
    "abstract": "Assistive agents should be able to perform under-specified long-horizon tasks\nwhile respecting user preferences. We introduce Actively Discovering and\nAdapting to Preferences for any Task (ADAPT) -- a benchmark designed to\nevaluate agents' ability to adhere to user preferences across various household\ntasks through active questioning. Next, we propose Reflection-DPO, a novel\ntraining approach for adapting large language models (LLMs) to the task of\nactive questioning. Reflection-DPO finetunes a 'student' LLM to follow the\nactions of a privileged 'teacher' LLM, and optionally ask a question to gather\nnecessary information to better predict the teacher action. We find that prior\napproaches that use state-of-the-art LLMs fail to sufficiently follow user\npreferences in ADAPT due to insufficient questioning and poor adherence to\nelicited preferences. In contrast, Reflection-DPO achieves a higher rate of\nsatisfying user preferences, outperforming a zero-shot chain-of-thought\nbaseline by 6.1% on unseen users.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04040v1",
    "published_date": "2025-04-05 03:16:22 UTC",
    "updated_date": "2025-04-05 03:16:22 UTC"
  },
  {
    "arxiv_id": "2504.04039v1",
    "title": "Memory-Statistics Tradeoff in Continual Learning with Structural Regularization",
    "authors": [
      "Haoran Li",
      "Jingfeng Wu",
      "Vladimir Braverman"
    ],
    "abstract": "We study the statistical performance of a continual learning problem with two\nlinear regression tasks in a well-specified random design setting. We consider\na structural regularization algorithm that incorporates a generalized\n$\\ell_2$-regularization tailored to the Hessian of the previous task for\nmitigating catastrophic forgetting. We establish upper and lower bounds on the\njoint excess risk for this algorithm. Our analysis reveals a fundamental\ntrade-off between memory complexity and statistical efficiency, where memory\ncomplexity is measured by the number of vectors needed to define the structural\nregularization. Specifically, increasing the number of vectors in structural\nregularization leads to a worse memory complexity but an improved excess risk,\nand vice versa. Furthermore, our theory suggests that naive continual learning\nwithout regularization suffers from catastrophic forgetting, while structural\nregularization mitigates this issue. Notably, structural regularization\nachieves comparable performance to joint training with access to both tasks\nsimultaneously. These results highlight the critical role of curvature-aware\nregularization for continual learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04039v1",
    "published_date": "2025-04-05 03:14:10 UTC",
    "updated_date": "2025-04-05 03:14:10 UTC"
  },
  {
    "arxiv_id": "2504.04032v1",
    "title": "Contrastive and Variational Approaches in Self-Supervised Learning for Complex Data Mining",
    "authors": [
      "Yingbin Liang",
      "Lu Dai",
      "Shuo Shi",
      "Minghao Dai",
      "Junliang Du",
      "Haige Wang"
    ],
    "abstract": "Complex data mining has wide application value in many fields, especially in\nthe feature extraction and classification tasks of unlabeled data. This paper\nproposes an algorithm based on self-supervised learning and verifies its\neffectiveness through experiments. The study found that in terms of the\nselection of optimizer and learning rate, the combination of AdamW optimizer\nand 0.002 learning rate performed best in all evaluation indicators, indicating\nthat the adaptive optimization method can improve the performance of the model\nin complex data mining tasks. In addition, the ablation experiment further\nanalyzed the contribution of each module. The results show that contrastive\nlearning, variational modules, and data augmentation strategies play a key role\nin the generalization ability and robustness of the model. Through the\nconvergence curve analysis of the loss function, the experiment verifies that\nthe method can converge stably during the training process and effectively\navoid serious overfitting. Further experimental results show that the model has\nstrong adaptability on different data sets, can effectively extract\nhigh-quality features from unlabeled data, and improves classification\naccuracy. At the same time, under different data distribution conditions, the\nmethod can still maintain high detection accuracy, proving its applicability in\ncomplex data environments. This study analyzed the role of self-supervised\nlearning methods in complex data mining through systematic experiments and\nverified its advantages in improving feature extraction quality, optimizing\nclassification performance, and enhancing model stability",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04032v1",
    "published_date": "2025-04-05 02:55:44 UTC",
    "updated_date": "2025-04-05 02:55:44 UTC"
  },
  {
    "arxiv_id": "2504.04029v1",
    "title": "Simultaneous Motion And Noise Estimation with Event Cameras",
    "authors": [
      "Shintaro Shiba",
      "Yoshimitsu Aoki",
      "Guillermo Gallego"
    ],
    "abstract": "Event cameras are emerging vision sensors, whose noise is challenging to\ncharacterize. Existing denoising methods for event cameras consider other tasks\nsuch as motion estimation separately (i.e., sequentially after denoising).\nHowever, motion is an intrinsic part of event data, since scene edges cannot be\nsensed without motion. This work proposes, to the best of our knowledge, the\nfirst method that simultaneously estimates motion in its various forms (e.g.,\nego-motion, optical flow) and noise. The method is flexible, as it allows\nreplacing the 1-step motion estimation of the widely-used Contrast Maximization\nframework with any other motion estimator, such as deep neural networks. The\nexperiments show that the proposed method achieves state-of-the-art results on\nthe E-MLB denoising benchmark and competitive results on the DND21 benchmark,\nwhile showing its efficacy on motion estimation and intensity reconstruction\ntasks. We believe that the proposed approach contributes to strengthening the\ntheory of event-data denoising, as well as impacting practical denoising\nuse-cases, as we release the code upon acceptance. Project page:\nhttps://github.com/tub-rip/ESMD",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 13 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.04029v1",
    "published_date": "2025-04-05 02:47:40 UTC",
    "updated_date": "2025-04-05 02:47:40 UTC"
  },
  {
    "arxiv_id": "2504.04022v1",
    "title": "Rethinking Reflection in Pre-Training",
    "authors": [
      "Essential AI",
      ":",
      "Darsh J Shah",
      "Peter Rushton",
      "Somanshu Singla",
      "Mohit Parmar",
      "Kurt Smith",
      "Yash Vanjani",
      "Ashish Vaswani",
      "Adarsh Chaluvaraju",
      "Andrew Hojel",
      "Andrew Ma",
      "Anil Thomas",
      "Anthony Polloreno",
      "Ashish Tanwer",
      "Burhan Drak Sibai",
      "Divya S Mansingka",
      "Divya Shivaprasad",
      "Ishaan Shah",
      "Karl Stratos",
      "Khoi Nguyen",
      "Michael Callahan",
      "Michael Pust",
      "Mrinal Iyer",
      "Philip Monk",
      "Platon Mazarakis",
      "Ritvik Kapila",
      "Saurabh Srivastava",
      "Tim Romanski"
    ],
    "abstract": "A language model's ability to reflect on its own reasoning provides a key\nadvantage for solving complex problems. While most recent research has focused\non how this ability develops during reinforcement learning, we show that it\nactually begins to emerge much earlier - during the model's pre-training. To\nstudy this, we introduce deliberate errors into chains-of-thought and test\nwhether the model can still arrive at the correct answer by recognizing and\ncorrecting these mistakes. By tracking performance across different stages of\npre-training, we observe that this self-correcting ability appears early and\nimproves steadily over time. For instance, an OLMo2-7B model pre-trained on 4\ntrillion tokens displays self-correction on our six self-reflection tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04022v1",
    "published_date": "2025-04-05 02:24:07 UTC",
    "updated_date": "2025-04-05 02:24:07 UTC"
  },
  {
    "arxiv_id": "2504.04011v1",
    "title": "Foundation Models for Time Series: A Survey",
    "authors": [
      "Siva Rama Krishna Kottapalli",
      "Karthik Hubli",
      "Sandeep Chandrashekhara",
      "Garima Jain",
      "Sunayana Hubli",
      "Gayathri Botla",
      "Ramesh Doddaiah"
    ],
    "abstract": "Transformer-based foundation models have emerged as a dominant paradigm in\ntime series analysis, offering unprecedented capabilities in tasks such as\nforecasting, anomaly detection, classification, trend analysis and many more\ntime series analytical tasks. This survey provides a comprehensive overview of\nthe current state of the art pre-trained foundation models, introducing a novel\ntaxonomy to categorize them across several dimensions. Specifically, we\nclassify models by their architecture design, distinguishing between those\nleveraging patch-based representations and those operating directly on raw\nsequences. The taxonomy further includes whether the models provide\nprobabilistic or deterministic predictions, and whether they are designed to\nwork with univariate time series or can handle multivariate time series out of\nthe box. Additionally, the taxonomy encompasses model scale and complexity,\nhighlighting differences between lightweight architectures and large-scale\nfoundation models. A unique aspect of this survey is its categorization by the\ntype of objective function employed during training phase. By synthesizing\nthese perspectives, this survey serves as a resource for researchers and\npractitioners, providing insights into current trends and identifying promising\ndirections for future research in transformer-based time series modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04011v1",
    "published_date": "2025-04-05 01:27:55 UTC",
    "updated_date": "2025-04-05 01:27:55 UTC"
  },
  {
    "arxiv_id": "2504.06294v1",
    "title": "Resurrecting Socrates in the Age of AI: A Study Protocol for Evaluating a Socratic Tutor to Support Research Question Development in Higher Education",
    "authors": [
      "Ben Degen"
    ],
    "abstract": "Formulating research questions is a foundational yet challenging academic\nskill, one that generative AI systems often oversimplify by offering instant\nanswers at the expense of student reflection. This protocol lays out a study\ngrounded in constructivist learning theory to evaluate a novel AI-based\nSocratic Tutor, designed to foster cognitive engagement and scaffold research\nquestion development in higher education. Anchored in dialogic pedagogy, the\ntutor engages students through iterative, reflective questioning, aiming to\npromote System 2 thinking and counteract overreliance on AI-generated outputs.\nIn a quasi-experimental design, approximately 80 German pre-service biology\nteacher students will be randomly assigned to one of two groups: an AI Socratic\nTutor condition and an uninstructed chatbot control. Across multiple cycles,\nstudents are expected to formulate research questions based on background\ntexts, with quality assessed through double-blind expert review. The study also\nexamines transfer of skills to novel phenomena and captures student perceptions\nthrough mixed-methods analysis, including surveys, interviews and reflective\njournals. This study aims to advance the understanding of how generative AI can\nbe pedagogically aligned to support, not replace, human cognition and offers\ndesign principles for human-AI collaboration in education.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06294v1",
    "published_date": "2025-04-05 00:49:20 UTC",
    "updated_date": "2025-04-05 00:49:20 UTC"
  },
  {
    "arxiv_id": "2504.04001v1",
    "title": "Edge Approximation Text Detector",
    "authors": [
      "Chuang Yang",
      "Xu Han",
      "Tao Han",
      "Han Han",
      "Bingxuan Zhao",
      "Qi Wang"
    ],
    "abstract": "Pursuing efficient text shape representations helps scene text detection\nmodels focus on compact foreground regions and optimize the contour\nreconstruction steps to simplify the whole detection pipeline. Current\napproaches either represent irregular shapes via box-to-polygon strategy or\ndecomposing a contour into pieces for fitting gradually, the deficiency of\ncoarse contours or complex pipelines always exists in these models. Considering\nthe above issues, we introduce EdgeText to fit text contours compactly while\nalleviating excessive contour rebuilding processes. Concretely, it is observed\nthat the two long edges of texts can be regarded as smooth curves. It allows us\nto build contours via continuous and smooth edges that cover text regions\ntightly instead of fitting piecewise, which helps avoid the two limitations in\ncurrent models. Inspired by this observation, EdgeText formulates the text\nrepresentation as the edge approximation problem via parameterized curve\nfitting functions. In the inference stage, our model starts with locating text\ncenters, and then creating curve functions for approximating text edges relying\non the points. Meanwhile, truncation points are determined based on the\nlocation features. In the end, extracting curve segments from curve functions\nby using the pixel coordinate information brought by truncation points to\nreconstruct text contours. Furthermore, considering the deep dependency of\nEdgeText on text edges, a bilateral enhanced perception (BEP) module is\ndesigned. It encourages our model to pay attention to the recognition of edge\nfeatures. Additionally, to accelerate the learning of the curve function\nparameters, we introduce a proportional integral loss (PI-loss) to force the\nproposed model to focus on the curve distribution and avoid being disturbed by\ntext scales.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04001v1",
    "published_date": "2025-04-05 00:12:51 UTC",
    "updated_date": "2025-04-05 00:12:51 UTC"
  }
]