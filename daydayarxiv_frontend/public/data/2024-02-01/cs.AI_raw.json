[
  {
    "arxiv_id": "2402.03368v1",
    "title": "Empirical and Experimental Perspectives on Big Data in Recommendation Systems: A Comprehensive Survey",
    "authors": [
      "Kamal Taha",
      "Paul D. Yoo",
      "Aya Taha"
    ],
    "abstract": "This survey paper provides a comprehensive analysis of big data algorithms in\nrecommendation systems, addressing the lack of depth and precision in existing\nliterature. It proposes a two-pronged approach: a thorough analysis of current\nalgorithms and a novel, hierarchical taxonomy for precise categorization. The\ntaxonomy is based on a tri-level hierarchy, starting with the methodology\ncategory and narrowing down to specific techniques. Such a framework allows for\na structured and comprehensive classification of algorithms, assisting\nresearchers in understanding the interrelationships among diverse algorithms\nand techniques. Covering a wide range of algorithms, this taxonomy first\ncategorizes algorithms into four main analysis types: User and Item\nSimilarity-Based Methods, Hybrid and Combined Approaches, Deep Learning and\nAlgorithmic Methods, and Mathematical Modeling Methods, with further\nsubdivisions into sub-categories and techniques. The paper incorporates both\nempirical and experimental evaluations to differentiate between the techniques.\nThe empirical evaluation ranks the techniques based on four criteria. The\nexperimental assessments rank the algorithms that belong to the same category,\nsub-category, technique, and sub-technique. Also, the paper illuminates the\nfuture prospects of big data techniques in recommendation systems, underscoring\npotential advancements and opportunities for further research in this field",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03368v1",
    "published_date": "2024-02-01 23:51:29 UTC",
    "updated_date": "2024-02-01 23:51:29 UTC"
  },
  {
    "arxiv_id": "2402.01065v1",
    "title": "Evaluation Methodology for Large Language Models for Multilingual Document Question and Answer",
    "authors": [
      "Adar Kahana",
      "Jaya Susan Mathew",
      "Said Bleik",
      "Jeremy Reynolds",
      "Oren Elisha"
    ],
    "abstract": "With the widespread adoption of Large Language Models (LLMs), in this paper\nwe investigate the multilingual capability of these models. Our preliminary\nresults show that, translating the native language context, question and answer\ninto a high resource language produced the best results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01065v1",
    "published_date": "2024-02-01 23:46:05 UTC",
    "updated_date": "2024-02-01 23:46:05 UTC"
  },
  {
    "arxiv_id": "2402.01787v3",
    "title": "Harm Amplification in Text-to-Image Models",
    "authors": [
      "Susan Hao",
      "Renee Shelby",
      "Yuchi Liu",
      "Hansa Srinivasan",
      "Mukul Bhutani",
      "Burcu Karagol Ayan",
      "Ryan Poplin",
      "Shivani Poddar",
      "Sarah Laszlo"
    ],
    "abstract": "Text-to-image (T2I) models have emerged as a significant advancement in\ngenerative AI; however, there exist safety concerns regarding their potential\nto produce harmful image outputs even when users input seemingly safe prompts.\nThis phenomenon, where T2I models generate harmful representations that were\nnot explicit in the input prompt, poses a potentially greater risk than\nadversarial prompts, leaving users unintentionally exposed to harms. Our paper\naddresses this issue by formalizing a definition for this phenomenon which we\nterm harm amplification. We further contribute to the field by developing a\nframework of methodologies to quantify harm amplification in which we consider\nthe harm of the model output in the context of user input. We then empirically\nexamine how to apply these different methodologies to simulate real-world\ndeployment scenarios including a quantification of disparate impacts across\ngenders resulting from harm amplification. Together, our work aims to offer\nresearchers tools to comprehensively address safety challenges in T2I systems\nand contribute to the responsible deployment of generative AI models.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01787v3",
    "published_date": "2024-02-01 23:12:57 UTC",
    "updated_date": "2024-08-15 23:36:42 UTC"
  },
  {
    "arxiv_id": "2402.01053v1",
    "title": "Plan-Grounded Large Language Models for Dual Goal Conversational Settings",
    "authors": [
      "Diogo Glória-Silva",
      "Rafael Ferreira",
      "Diogo Tavares",
      "David Semedo",
      "João Magalhães"
    ],
    "abstract": "Training Large Language Models (LLMs) to follow user instructions has been\nshown to supply the LLM with ample capacity to converse fluently while being\naligned with humans. Yet, it is not completely clear how an LLM can lead a\nplan-grounded conversation in mixed-initiative settings where instructions flow\nin both directions of the conversation, i.e. both the LLM and the user provide\ninstructions to one another. In this paper, we tackle a dual goal\nmixed-initiative conversational setting where the LLM not only grounds the\nconversation on an arbitrary plan but also seeks to satisfy both a procedural\nplan and user instructions. The LLM is then responsible for guiding the user\nthrough the plan and, at the same time, adapting to new circumstances,\nanswering questions, and activating safety guardrails when needed. We propose a\nnovel LLM that grounds the dialogue on a procedural plan, can take the dialogue\ninitiative, and enforces guardrails on the system's behavior, while also\nimproving the LLM's responses to unexpected user behavior. Experiments in\ncontrolled settings and with real users show that the best-performing model,\nwhich we call PlanLLM, achieves a 2.1x improvement over a strong baseline.\nMoreover, experiments also show good generalization to unseen domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01053v1",
    "published_date": "2024-02-01 22:56:39 UTC",
    "updated_date": "2024-02-01 22:56:39 UTC"
  },
  {
    "arxiv_id": "2403.07886v1",
    "title": "A Memetic Algorithm To Find a Hamiltonian Cycle in a Hamiltonian Graph",
    "authors": [
      "Sarwan Ali",
      "Pablo Moscato"
    ],
    "abstract": "We present a memetic algorithm (\\maa) approach for finding a Hamiltonian\ncycle in a Hamiltonian graph. The \\ma is based on a proven approach to the\nAsymmetric Travelling Salesman Problem (\\atspp) that, in this contribution, is\nboosted by the introduction of more powerful local searches. Our approach also\nintroduces a novel technique that sparsifies the input graph under\nconsideration for Hamiltonicity and dynamically augments it during the search.\nSuch a combined heuristic approach helps to prove Hamiltonicity by finding a\nHamiltonian cycle in less time. In addition, we also employ a recently\nintroduced polynomial-time reduction from the \\hamcyc to the Symmetric \\tsp,\nwhich is based on computing the transitive closure of the graph. Although our\napproach is a metaheuristic, i.e., it does not give a theoretical guarantee for\nfinding a Hamiltonian cycle, we have observed that the method is successful in\npractice in verifying the Hamiltonicity of a larger number of instances from\nthe \\textit{Flinder University Hamiltonian Cycle Problem Challenge Set}\n(\\fhcpsc), even for the graphs that have large treewidth. The experiments on\nthe \\fhcpscc instances and a computational comparison with five recent\nstate-of-the-art baseline approaches show that the proposed method outperforms\nthose for the majority of the instances in the \\fhcpsc.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07886v1",
    "published_date": "2024-02-01 22:02:07 UTC",
    "updated_date": "2024-02-01 22:02:07 UTC"
  },
  {
    "arxiv_id": "2402.01786v2",
    "title": "COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations",
    "authors": [
      "Vinicius G. Goecks",
      "Nicholas Waytowich"
    ],
    "abstract": "The development of Courses of Action (COAs) in military operations is\ntraditionally a time-consuming and intricate process. Addressing this\nchallenge, this study introduces COA-GPT, a novel algorithm employing Large\nLanguage Models (LLMs) for rapid and efficient generation of valid COAs.\nCOA-GPT incorporates military doctrine and domain expertise to LLMs through\nin-context learning, allowing commanders to input mission information - in both\ntext and image formats - and receive strategically aligned COAs for review and\napproval. Uniquely, COA-GPT not only accelerates COA development, producing\ninitial COAs within seconds, but also facilitates real-time refinement based on\ncommander feedback. This work evaluates COA-GPT in a military-relevant scenario\nwithin a militarized version of the StarCraft II game, comparing its\nperformance against state-of-the-art reinforcement learning algorithms. Our\nresults demonstrate COA-GPT's superiority in generating strategically sound\nCOAs more swiftly, with added benefits of enhanced adaptability and alignment\nwith commander intentions. COA-GPT's capability to rapidly adapt and update\nCOAs during missions presents a transformative potential for military planning,\nparticularly in addressing planning discrepancies and capitalizing on emergent\nwindows of opportunities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "I.2.6; I.2.7; J.7"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the NATO Science and Technology Organization Symposium\n  (ICMCIS) organized by the Information Systems Technology (IST) Panel,\n  IST-205-RSY - the ICMCIS, held in Koblenz, Germany, 23-24 April 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01786v2",
    "published_date": "2024-02-01 21:51:09 UTC",
    "updated_date": "2024-03-28 15:22:42 UTC"
  },
  {
    "arxiv_id": "2402.01032v2",
    "title": "Repeat After Me: Transformers are Better than State Space Models at Copying",
    "authors": [
      "Samy Jelassi",
      "David Brandfonbrener",
      "Sham M. Kakade",
      "Eran Malach"
    ],
    "abstract": "Transformers are the dominant architecture for sequence modeling, but there\nis growing interest in models that use a fixed-size latent state that does not\ndepend on the sequence length, which we refer to as \"generalized state space\nmodels\" (GSSMs). In this paper we show that while GSSMs are promising in terms\nof inference-time efficiency, they are limited compared to transformer models\non tasks that require copying from the input context. We start with a\ntheoretical analysis of the simple task of string copying and prove that a two\nlayer transformer can copy strings of exponential length while GSSMs are\nfundamentally limited by their fixed-size latent state. Empirically, we find\nthat transformers outperform GSSMs in terms of efficiency and generalization on\nsynthetic tasks that require copying the context. Finally, we evaluate\npretrained large language models and find that transformer models dramatically\noutperform state space models at copying and retrieving information from\ncontext. Taken together, these results suggest a fundamental gap between\ntransformers and GSSMs on tasks of practical interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01032v2",
    "published_date": "2024-02-01 21:44:11 UTC",
    "updated_date": "2024-06-03 22:22:15 UTC"
  },
  {
    "arxiv_id": "2402.01030v4",
    "title": "Executable Code Actions Elicit Better LLM Agents",
    "authors": [
      "Xingyao Wang",
      "Yangyi Chen",
      "Lifan Yuan",
      "Yizhe Zhang",
      "Yunzhu Li",
      "Hao Peng",
      "Heng Ji"
    ],
    "abstract": "Large Language Model (LLM) agents, capable of performing a broad range of\nactions, such as invoking tools and controlling robots, show great potential in\ntackling real-world challenges. LLM agents are typically prompted to produce\nactions by generating JSON or text in a pre-defined format, which is usually\nlimited by constrained action space (e.g., the scope of pre-defined tools) and\nrestricted flexibility (e.g., inability to compose multiple tools). This work\nproposes to use executable Python code to consolidate LLM agents' actions into\na unified action space (CodeAct). Integrated with a Python interpreter, CodeAct\ncan execute code actions and dynamically revise prior actions or emit new\nactions upon new observations through multi-turn interactions. Our extensive\nanalysis of 17 LLMs on API-Bank and a newly curated benchmark shows that\nCodeAct outperforms widely used alternatives (up to 20% higher success rate).\nThe encouraging performance of CodeAct motivates us to build an open-source LLM\nagent that interacts with environments by executing interpretable code and\ncollaborates with users using natural language. To this end, we collect an\ninstruction-tuning dataset CodeActInstruct that consists of 7k multi-turn\ninteractions using CodeAct. We show that it can be used with existing data to\nimprove models in agent-oriented tasks without compromising their general\ncapability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with\nPython interpreter and uniquely tailored to perform sophisticated tasks (e.g.,\nmodel training) using existing libraries and autonomously self-debug.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICML 2024; Code, data, model, and demo are available at\n  https://github.com/xingyaoww/code-act",
    "pdf_url": "http://arxiv.org/pdf/2402.01030v4",
    "published_date": "2024-02-01 21:38:58 UTC",
    "updated_date": "2024-06-07 01:53:07 UTC"
  },
  {
    "arxiv_id": "2402.01785v1",
    "title": "DoubleMLDeep: Estimation of Causal Effects with Multimodal Data",
    "authors": [
      "Sven Klaassen",
      "Jan Teichert-Kluge",
      "Philipp Bach",
      "Victor Chernozhukov",
      "Martin Spindler",
      "Suhas Vijaykumar"
    ],
    "abstract": "This paper explores the use of unstructured, multimodal data, namely text and\nimages, in causal inference and treatment effect estimation. We propose a\nneural network architecture that is adapted to the double machine learning\n(DML) framework, specifically the partially linear model. An additional\ncontribution of our paper is a new method to generate a semi-synthetic dataset\nwhich can be used to evaluate the performance of causal effect estimation in\nthe presence of text and images as confounders. The proposed methods and\narchitectures are evaluated on the semi-synthetic dataset and compared to\nstandard approaches, highlighting the potential benefit of using text and\nimages directly in causal studies. Our findings have implications for\nresearchers and practitioners in economics, marketing, finance, medicine and\ndata science in general who are interested in estimating causal quantities\nusing non-traditional data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.EM",
      "stat.ME",
      "stat.ML",
      "62, 91",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01785v1",
    "published_date": "2024-02-01 21:34:34 UTC",
    "updated_date": "2024-02-01 21:34:34 UTC"
  },
  {
    "arxiv_id": "2402.01020v1",
    "title": "Quantifying analogy of concepts via ologs and wiring diagrams",
    "authors": [
      "Jason Lo"
    ],
    "abstract": "We build on the theory of ontology logs (ologs) created by Spivak and Kent,\nand define a notion of wiring diagrams. In this article, a wiring diagram is a\nfinite directed labelled graph. The labels correspond to types in an olog; they\ncan also be interpreted as readings of sensors in an autonomous system. As\nsuch, wiring diagrams can be used as a framework for an autonomous system to\nform abstract concepts. We show that the graphs underlying skeleton wiring\ndiagrams form a category. This allows skeleton wiring diagrams to be compared\nand manipulated using techniques from both graph theory and category theory. We\nalso extend the usual definition of graph edit distance to the case of wiring\ndiagrams by using operations only available to wiring diagrams, leading to a\nmetric on the set of all skeleton wiring diagrams. In the end, we give an\nextended example on calculating the distance between two concepts represented\nby wiring diagrams, and explain how to apply our framework to any application\ndomain.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DM",
      "math.CO",
      "math.CT",
      "68T30 (Primary) 68T20, 68P05, 68T40 (Secondary)",
      "I.2.4; I.2.8"
    ],
    "primary_category": "cs.LO",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01020v1",
    "published_date": "2024-02-01 21:15:55 UTC",
    "updated_date": "2024-02-01 21:15:55 UTC"
  },
  {
    "arxiv_id": "2402.01018v1",
    "title": "HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent",
    "authors": [
      "Weijie Xu",
      "Zicheng Huang",
      "Wenxiang Hu",
      "Xi Fang",
      "Rajesh Kumar Cherukuri",
      "Naumaan Nayyar",
      "Lorenzo Malandri",
      "Srinivasan H. Sengamedu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have been reshaping\nNatural Language Processing (NLP) task in several domains. Their use in the\nfield of Human Resources (HR) has still room for expansions and could be\nbeneficial for several time consuming tasks. Examples such as time-off\nsubmissions, medical claims filing, and access requests are noteworthy, but\nthey are by no means the sole instances. However, the aforementioned\ndevelopments must grapple with the pivotal challenge of constructing a\nhigh-quality training dataset. On one hand, most conversation datasets are\nsolving problems for customers not employees. On the other hand, gathering\nconversations with HR could raise privacy concerns. To solve it, we introduce\nHR-Multiwoz, a fully-labeled dataset of 550 conversations spanning 10 HR\ndomains to evaluate LLM Agent. Our work has the following contributions: (1) It\nis the first labeled open-sourced conversation dataset in the HR domain for NLP\nresearch. (2) It provides a detailed recipe for the data generation procedure\nalong with data analysis and human evaluations. The data generation pipeline is\ntransferable and can be easily adapted for labeled conversation data generation\nin other domains. (3) The proposed data-collection pipeline is mostly based on\nLLMs with minimal human involvement for annotation, which is time and\ncost-efficient.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01018v1",
    "published_date": "2024-02-01 21:10:44 UTC",
    "updated_date": "2024-02-01 21:10:44 UTC"
  },
  {
    "arxiv_id": "2402.01783v1",
    "title": "Hierarchical Multi-Label Classification of Online Vaccine Concerns",
    "authors": [
      "Chloe Qinyu Zhu",
      "Rickard Stureborg",
      "Bhuwan Dhingra"
    ],
    "abstract": "Vaccine concerns are an ever-evolving target, and can shift quickly as seen\nduring the COVID-19 pandemic. Identifying longitudinal trends in vaccine\nconcerns and misinformation might inform the healthcare space by helping public\nhealth efforts strategically allocate resources or information campaigns. We\nexplore the task of detecting vaccine concerns in online discourse using large\nlanguage models (LLMs) in a zero-shot setting without the need for expensive\ntraining datasets. Since real-time monitoring of online sources requires\nlarge-scale inference, we explore cost-accuracy trade-offs of different\nprompting strategies and offer concrete takeaways that may inform choices in\nsystem designs for current applications. An analysis of different prompting\nstrategies reveals that classifying the concerns over multiple passes through\nthe LLM, each consisting a boolean question whether the text mentions a vaccine\nconcern or not, works the best. Our results indicate that GPT-4 can strongly\noutperform crowdworker accuracy when compared to ground truth annotations\nprovided by experts on the recently introduced VaxConcerns dataset, achieving\nan overall F1 score of 78.7%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in AAAI 2024 Health Intelligence workshop",
    "pdf_url": "http://arxiv.org/pdf/2402.01783v1",
    "published_date": "2024-02-01 20:56:07 UTC",
    "updated_date": "2024-02-01 20:56:07 UTC"
  },
  {
    "arxiv_id": "2402.01002v3",
    "title": "AI-generated faces influence gender stereotypes and racial homogenization",
    "authors": [
      "Nouar AlDahoul",
      "Talal Rahwan",
      "Yasir Zaki"
    ],
    "abstract": "Text-to-image generative AI models such as Stable Diffusion are used daily by\nmillions worldwide. However, the extent to which these models exhibit racial\nand gender stereotypes is not yet fully understood. Here, we document\nsignificant biases in Stable Diffusion across six races, two genders, 32\nprofessions, and eight attributes. Additionally, we examine the degree to which\nStable Diffusion depicts individuals of the same race as being similar to one\nanother. This analysis reveals significant racial homogenization, e.g.,\ndepicting nearly all Middle Eastern men as bearded, brown-skinned, and wearing\ntraditional attire. We then propose debiasing solutions that allow users to\nspecify the desired distributions of race and gender when generating images\nwhile minimizing racial homogenization. Finally, using a preregistered survey\nexperiment, we find evidence that being presented with inclusive AI-generated\nfaces reduces people's racial and gender biases, while being presented with\nnon-inclusive ones increases such biases, regardless of whether the images are\nlabeled as AI-generated. Taken together, our findings emphasize the need to\naddress biases and stereotypes in text-to-image models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "47 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01002v3",
    "published_date": "2024-02-01 20:32:14 UTC",
    "updated_date": "2024-11-21 05:06:21 UTC"
  },
  {
    "arxiv_id": "2402.01782v1",
    "title": "Benchmarking Spiking Neural Network Learning Methods with Varying Locality",
    "authors": [
      "Jiaqi Lin",
      "Sen Lu",
      "Malyaban Bal",
      "Abhronil Sengupta"
    ],
    "abstract": "Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics,\nhave shown to achieve performance comparable to Artificial Neural Networks\n(ANNs) in several machine learning tasks. Information is processed as spikes\nwithin SNNs in an event-based mechanism that significantly reduces energy\nconsumption. However, training SNNs is challenging due to the\nnon-differentiable nature of the spiking mechanism. Traditional approaches,\nsuch as Backpropagation Through Time (BPTT), have shown effectiveness but comes\nwith additional computational and memory costs and are biologically\nimplausible. In contrast, recent works propose alternative learning methods\nwith varying degrees of locality, demonstrating success in classification\ntasks. In this work, we show that these methods share similarities during the\ntraining process, while they present a trade-off between biological\nplausibility and performance. Further, this research examines the implicitly\nrecurrent nature of SNNs and investigates the influence of addition of explicit\nrecurrence to SNNs. We experimentally prove that the addition of explicit\nrecurrent weights enhances the robustness of SNNs. We also investigate the\nperformance of local learning methods under gradient and non-gradient based\nadversarial attacks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01782v1",
    "published_date": "2024-02-01 19:57:08 UTC",
    "updated_date": "2024-02-01 19:57:08 UTC"
  },
  {
    "arxiv_id": "2402.00978v1",
    "title": "An Information-Theoretic Approach to Analyze NLP Classification Tasks",
    "authors": [
      "Luran Wang",
      "Mark Gales",
      "Vatsal Raina"
    ],
    "abstract": "Understanding the importance of the inputs on the output is useful across\nmany tasks. This work provides an information-theoretic framework to analyse\nthe influence of inputs for text classification tasks. Natural language\nprocessing (NLP) tasks take either a single element input or multiple element\ninputs to predict an output variable, where an element is a block of text. Each\ntext element has two components: an associated semantic meaning and a\nlinguistic realization. Multiple-choice reading comprehension (MCRC) and\nsentiment classification (SC) are selected to showcase the framework. For MCRC,\nit is found that the context influence on the output compared to the question\ninfluence reduces on more challenging datasets. In particular, more challenging\ncontexts allow a greater variation in complexity of questions. Hence, test\ncreators need to carefully consider the choice of the context when designing\nmultiple-choice questions for assessment. For SC, it is found the semantic\nmeaning of the input text dominates (above 80\\% for all datasets considered)\ncompared to its linguistic realisation when determining the sentiment. The\nframework is made available at:\nhttps://github.com/WangLuran/nlp-element-influence",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 10 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.00978v1",
    "published_date": "2024-02-01 19:49:44 UTC",
    "updated_date": "2024-02-01 19:49:44 UTC"
  },
  {
    "arxiv_id": "2402.00976v4",
    "title": "Investigating Recurrent Transformers with Dynamic Halt",
    "authors": [
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea"
    ],
    "abstract": "In this paper, we comprehensively study the inductive biases of two major\napproaches to augmenting Transformers with a recurrent mechanism: (1) the\napproach of incorporating a depth-wise recurrence similar to Universal\nTransformers; and (2) the approach of incorporating a chunk-wise temporal\nrecurrence like Temporal Latent Bottleneck. Furthermore, we propose and\ninvestigate novel ways to extend and combine the above methods - for example,\nwe propose a global mean-based dynamic halting mechanism for Universal\nTransformers and an augmentation of Temporal Latent Bottleneck with elements\nfrom Universal Transformer. We compare the models and probe their inductive\nbiases in several diagnostic tasks, such as Long Range Arena (LRA), flip-flop\nlanguage modeling, ListOps, and Logical Inference. The code is released in:\nhttps://github.com/JRC1995/InvestigatingRecurrentTransformers/tree/main",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00976v4",
    "published_date": "2024-02-01 19:47:31 UTC",
    "updated_date": "2025-01-21 04:20:26 UTC"
  },
  {
    "arxiv_id": "2402.00969v1",
    "title": "SPARQL Generation with Entity Pre-trained GPT for KG Question Answering",
    "authors": [
      "Diego Bustamante",
      "Hideaki Takeda"
    ],
    "abstract": "Knowledge Graphs popularity has been rapidly growing in last years. All that\nknowledge is available for people to query it through the many online databases\non the internet. Though, it would be a great achievement if non-programmer\nusers could access whatever information they want to know. There has been a lot\nof effort oriented to solve this task using natural language processing tools\nand creativity encouragement by way of many challenges. Our approach focuses on\nassuming a correct entity linking on the natural language questions and\ntraining a GPT model to create SPARQL queries from them. We managed to isolate\nwhich property of the task can be the most difficult to solve at few or\nzero-shot and we proposed pre-training on all entities (under CWA) to improve\nthe performance. We obtained a 62.703% accuracy of exact SPARQL matches on\ntesting at 3-shots, a F1 of 0.809 on the entity linking challenge and a F1 of\n0.009 on the question answering challenge.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "68P20, 68T50",
      "H.2.3; H.3.3; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 1 figure, 2 tables. For the implementation, see\n  https://github.com/DiegoEmilio01/SPARQL-generation-with-entity-pre-trained-GPT-for-KG-Question-Answering",
    "pdf_url": "http://arxiv.org/pdf/2402.00969v1",
    "published_date": "2024-02-01 19:38:32 UTC",
    "updated_date": "2024-02-01 19:38:32 UTC"
  },
  {
    "arxiv_id": "2402.00957v4",
    "title": "Credal Learning Theory",
    "authors": [
      "Michele Caprio",
      "Maryam Sultana",
      "Eleni Elia",
      "Fabio Cuzzolin"
    ],
    "abstract": "Statistical learning theory is the foundation of machine learning, providing\ntheoretical bounds for the risk of models learned from a (single) training set,\nassumed to issue from an unknown probability distribution. In actual\ndeployment, however, the data distribution may (and often does) vary, causing\ndomain adaptation/generalization issues. In this paper we lay the foundations\nfor a `credal' theory of learning, using convex sets of probabilities (credal\nsets) to model the variability in the data-generating distribution. Such credal\nsets, we argue, may be inferred from a finite sample of training sets. Bounds\nare derived for the case of finite hypotheses spaces (both assuming\nrealizability or not), as well as infinite model spaces, which directly\ngeneralize classical results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "30 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00957v4",
    "published_date": "2024-02-01 19:25:58 UTC",
    "updated_date": "2024-10-23 15:40:23 UTC"
  },
  {
    "arxiv_id": "2403.08797v2",
    "title": "Evolutionary Algorithms Simulating Molecular Evolution: A New Field Proposal",
    "authors": [
      "James S. L. Browning Jr.",
      "Daniel R. Tauritz",
      "John Beckmann"
    ],
    "abstract": "The genetic blueprint for the essential functions of life is encoded in DNA,\nwhich is translated into proteins -- the engines driving most of our metabolic\nprocesses. Recent advancements in genome sequencing have unveiled a vast\ndiversity of protein families, but compared to the massive search space of all\npossible amino acid sequences, the set of known functional families is minimal.\nOne could say nature has a limited protein \"vocabulary.\" The major question for\ncomputational biologists, therefore, is whether this vocabulary can be expanded\nto include useful proteins that went extinct long ago, or maybe never evolved\nin the first place. We outline a computational approach to solving this\nproblem. By merging evolutionary algorithms, machine learning (ML), and\nbioinformatics, we can facilitate the development of completely novel proteins\nwhich have never existed before. We envision this work forming a new sub-field\nof computational evolution we dub evolutionary algorithms simulating molecular\nevolution (EASME).",
    "categories": [
      "cs.NE",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.NE",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.08797v2",
    "published_date": "2024-02-01 19:22:02 UTC",
    "updated_date": "2024-06-10 21:49:16 UTC"
  },
  {
    "arxiv_id": "2402.01781v2",
    "title": "When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards",
    "authors": [
      "Norah Alzahrani",
      "Hisham Abdullah Alyahya",
      "Yazeed Alnumay",
      "Sultan Alrashed",
      "Shaykhah Alsubaie",
      "Yusef Almushaykeh",
      "Faisal Mirza",
      "Nouf Alotaibi",
      "Nora Altwairesh",
      "Areeb Alowisheq",
      "M Saiful Bari",
      "Haidar Khan"
    ],
    "abstract": "Large Language Model (LLM) leaderboards based on benchmark rankings are\nregularly used to guide practitioners in model selection. Often, the published\nleaderboard rankings are taken at face value - we show this is a (potentially\ncostly) mistake. Under existing leaderboards, the relative performance of LLMs\nis highly sensitive to (often minute) details. We show that for popular\nmultiple-choice question benchmarks (e.g., MMLU), minor perturbations to the\nbenchmark, such as changing the order of choices or the method of answer\nselection, result in changes in rankings up to 8 positions. We explain this\nphenomenon by conducting systematic experiments over three broad categories of\nbenchmark perturbations and identifying the sources of this behavior. Our\nanalysis results in several best-practice recommendations, including the\nadvantage of a hybrid scoring method for answer selection. Our study highlights\nthe dangers of relying on simple benchmark evaluations and charts the path for\nmore robust evaluation schemes on the existing benchmarks. The code for this\npaper is available at\nhttps://github.com/National-Center-for-AI-Saudi-Arabia/lm-evaluation-harness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "updated with ACL 2024 camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.01781v2",
    "published_date": "2024-02-01 19:12:25 UTC",
    "updated_date": "2024-07-03 11:20:43 UTC"
  },
  {
    "arxiv_id": "2402.00944v2",
    "title": "NCoder -- A Quantum Field Theory approach to encoding data",
    "authors": [
      "David S. Berman",
      "Marc S. Klinger",
      "Alexander G. Stapleton"
    ],
    "abstract": "In this paper we present a novel approach to interpretable AI inspired by\nQuantum Field Theory (QFT) which we call the NCoder. The NCoder is a modified\nautoencoder neural network whose latent layer is prescribed to be a subset of\n$n$-point correlation functions. Regarding images as draws from a lattice field\ntheory, this architecture mimics the task of perturbatively constructing the\neffective action of the theory order by order in an expansion using Feynman\ndiagrams. Alternatively, the NCoder may be regarded as simulating the procedure\nof statistical inference whereby high dimensional data is first summarized in\nterms of several lower dimensional summary statistics (here the $n$-point\ncorrelation functions), and subsequent out-of-sample data is generated by\ninferring the data generating distribution from these statistics. In this way\nthe NCoder suggests a fascinating correspondence between perturbative\nrenormalizability and the sufficiency of models. We demonstrate the efficacy of\nthe NCoder by applying it to the generation of MNIST images, and find that\ngenerated images can be correctly classified using only information from the\nfirst three $n$-point functions of the image distribution.",
    "categories": [
      "hep-th",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "hep-th",
    "comment": "29 pages. v2 Fixed minor typos",
    "pdf_url": "http://arxiv.org/pdf/2402.00944v2",
    "published_date": "2024-02-01 19:00:55 UTC",
    "updated_date": "2024-07-10 21:34:37 UTC"
  },
  {
    "arxiv_id": "2402.00861v2",
    "title": "Evaluating Large Language Models for Generalization and Robustness via Data Compression",
    "authors": [
      "Yucheng Li",
      "Yunhao Guo",
      "Frank Guerin",
      "Chenghua Lin"
    ],
    "abstract": "Existing methods for evaluating large language models face challenges such as\ndata contamination, sensitivity to prompts, and the high cost of benchmark\ncreation. To address this, we propose a lossless data compression based\nevaluation approach that tests how models' predictive abilities generalize\nafter their training cutoff. Specifically, we collect comprehensive test data\nspanning 83 months from 2017 to 2023 and split the data into training and\ntesting periods according to models' training data cutoff. We measure: 1) the\ncompression performance on the testing period as a measure of generalization on\nunseen data; and 2) the performance gap between the training and testing period\nas a measure of robustness. Our experiments test 14 representative large\nlanguage models with various sizes on sources including Wikipedia, news\narticles, code, arXiv papers, and multi-modal data. We find that the\ncompression rate of many models reduces significantly after their cutoff date,\nbut models such as Mistral and Llama-2 demonstrate a good balance between\nperformance and robustness. Results also suggest that models struggle to\ngeneralize on news and code data, but work especially well on arXiv papers. We\nalso find the context size and tokenization implementation have a big impact of\non the overall compression performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00861v2",
    "published_date": "2024-02-01 18:56:18 UTC",
    "updated_date": "2024-02-04 01:16:25 UTC"
  },
  {
    "arxiv_id": "2402.10091v1",
    "title": "Text-Based Product Matching -- Semi-Supervised Clustering Approach",
    "authors": [
      "Alicja Martinek",
      "Szymon Łukasik",
      "Amir H. Gandomi"
    ],
    "abstract": "Matching identical products present in multiple product feeds constitutes a\ncrucial element of many tasks of e-commerce, such as comparing product\nofferings, dynamic price optimization, and selecting the assortment\npersonalized for the client. It corresponds to the well-known machine learning\ntask of entity matching, with its own specificity, like omnipresent\nunstructured data or inaccurate and inconsistent product descriptions. This\npaper aims to present a new philosophy to product matching utilizing a\nsemi-supervised clustering approach. We study the properties of this method by\nexperimenting with the IDEC algorithm on the real-world dataset using\npredominantly textual features and fuzzy string matching, with more standard\napproaches as a point of reference. Encouraging results show that unsupervised\nmatching, enriched with a small annotated sample of product links, could be a\npossible alternative to the dominant supervised strategy, requiring extensive\nmanual data labeling.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10091v1",
    "published_date": "2024-02-01 18:52:26 UTC",
    "updated_date": "2024-02-01 18:52:26 UTC"
  },
  {
    "arxiv_id": "2402.00854v4",
    "title": "SymbolicAI: A framework for logic-based approaches combining generative models and solvers",
    "authors": [
      "Marius-Constantin Dinu",
      "Claudiu Leoveanu-Condrei",
      "Markus Holzleitner",
      "Werner Zellinger",
      "Sepp Hochreiter"
    ],
    "abstract": "We introduce SymbolicAI, a versatile and modular framework employing a\nlogic-based approach to concept learning and flow management in generative\nprocesses. SymbolicAI enables the seamless integration of generative models\nwith a diverse range of solvers by treating large language models (LLMs) as\nsemantic parsers that execute tasks based on both natural and formal language\ninstructions, thus bridging the gap between symbolic reasoning and generative\nAI. We leverage probabilistic programming principles to tackle complex tasks,\nand utilize differentiable and classical programming paradigms with their\nrespective strengths. The framework introduces a set of polymorphic,\ncompositional, and self-referential operations for multi-modal data that\nconnects multi-step generative processes and aligns their outputs with user\nobjectives in complex workflows. As a result, we can transition between the\ncapabilities of various foundation models with in-context learning capabilities\nand specialized, fine-tuned models or solvers proficient in addressing specific\nproblems. Through these operations based on in-context learning our framework\nenables the creation and evaluation of explainable computational graphs.\nFinally, we introduce a quality measure and its empirical score for evaluating\nthese computational graphs, and propose a benchmark that compares various\nstate-of-the-art LLMs across a set of complex workflows. We refer to the\nempirical score as the \"Vector Embedding for Relational Trajectory Evaluation\nthrough Cross-similarity\", or VERTEX score for short. The framework codebase\nand benchmark are linked below.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "46 pages, 13 figures, external resources: framework is available at\n  https://github.com/ExtensityAI/symbolicai and benchmark at\n  https://github.com/ExtensityAI/benchmark",
    "pdf_url": "http://arxiv.org/pdf/2402.00854v4",
    "published_date": "2024-02-01 18:50:50 UTC",
    "updated_date": "2024-08-21 22:07:31 UTC"
  },
  {
    "arxiv_id": "2402.00839v2",
    "title": "X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection System",
    "authors": [
      "Kiymet Kaya",
      "Elif Ak",
      "Sumeyye Bas",
      "Berk Canberk",
      "Sule Gunduz Oguducu"
    ],
    "abstract": "The effectiveness of Intrusion Detection Systems (IDS) is critical in an era\nwhere cyber threats are becoming increasingly complex. Machine learning (ML)\nand deep learning (DL) models provide an efficient and accurate solution for\nidentifying attacks and anomalies in computer networks. However, using ML and\nDL models in IDS has led to a trust deficit due to their non-transparent\ndecision-making. This transparency gap in IDS research is significant,\naffecting confidence and accountability. To address, this paper introduces a\nnovel Explainable IDS approach, called X-CBA, that leverages the structural\nadvantages of Graph Neural Networks (GNNs) to effectively process network\ntraffic data, while also adapting a new Explainable AI (XAI) methodology.\nUnlike most GNN-based IDS that depend on labeled network traffic and node\nfeatures, thereby overlooking critical packet-level information, our approach\nleverages a broader range of traffic data through network flows, including edge\nattributes, to improve detection capabilities and adapt to novel threats.\nThrough empirical testing, we establish that our approach not only achieves\nhigh accuracy with 99.47% in threat detection but also advances the field by\nproviding clear, actionable explanations of its analytical outcomes. This\nresearch also aims to bridge the current gap and facilitate the broader\nintegration of ML/DL technologies in cybersecurity defenses by offering a local\nand global explainability solution that is both precise and interpretable.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00839v2",
    "published_date": "2024-02-01 18:29:16 UTC",
    "updated_date": "2024-06-02 05:00:39 UTC"
  },
  {
    "arxiv_id": "2402.00835v1",
    "title": "ALISON: Fast and Effective Stylometric Authorship Obfuscation",
    "authors": [
      "Eric Xing",
      "Saranya Venkatraman",
      "Thai Le",
      "Dongwon Lee"
    ],
    "abstract": "Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competing\ntasks of increasing importance in privacy research. Modern AA leverages an\nauthor's consistent writing style to match a text to its author using an AA\nclassifier. AO is the corresponding adversarial task, aiming to modify a text\nin such a way that its semantics are preserved, yet an AA model cannot\ncorrectly infer its authorship. To address privacy concerns raised by\nstate-of-the-art (SOTA) AA methods, new AO methods have been proposed but\nremain largely impractical to use due to their prohibitively slow training and\nobfuscation speed, often taking hours. To this challenge, we propose a\npractical AO method, ALISON, that (1) dramatically reduces training/obfuscation\ntime, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2)\nachieves better obfuscation success through attacking three transformer-based\nAA methods on two benchmark datasets, typically performing 15% better than\ncompeting methods, (3) does not require direct signals from a target AA\nclassifier during obfuscation, and (4) utilizes unique stylometric features,\nallowing sound model interpretation for explainable obfuscation. We also\ndemonstrate that ALISON can effectively prevent four SOTA AA methods from\naccurately determining the authorship of ChatGPT-generated texts, all while\nminimally changing the original text semantics. To ensure the reproducibility\nof our findings, our code and data are available at:\nhttps://github.com/EricX003/ALISON.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures, 4 tables. To be published in the Proceedings of\n  the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)",
    "pdf_url": "http://arxiv.org/pdf/2402.00835v1",
    "published_date": "2024-02-01 18:22:32 UTC",
    "updated_date": "2024-02-01 18:22:32 UTC"
  },
  {
    "arxiv_id": "2402.00831v1",
    "title": "A YANG-aided Unified Strategy for Black Hole Detection for Backbone Networks",
    "authors": [
      "Elif Ak",
      "Kiymet Kaya",
      "Eren Ozaltun",
      "Sule Gunduz Oguducu",
      "Berk Canberk"
    ],
    "abstract": "Despite the crucial importance of addressing Black Hole failures in Internet\nbackbone networks, effective detection strategies in backbone networks are\nlacking. This is largely because previous research has been centered on Mobile\nAd-hoc Networks (MANETs), which operate under entirely different dynamics,\nprotocols, and topologies, making their findings not directly transferable to\nbackbone networks. Furthermore, detecting Black Hole failures in backbone\nnetworks is particularly challenging. It requires a comprehensive range of\nnetwork data due to the wide variety of conditions that need to be considered,\nmaking data collection and analysis far from straightforward. Addressing this\ngap, our study introduces a novel approach for Black Hole detection in backbone\nnetworks using specialized Yet Another Next Generation (YANG) data models with\nBlack Hole-sensitive Metric Matrix (BHMM) analysis. This paper details our\nmethod of selecting and analyzing four YANG models relevant to Black Hole\ndetection in ISP networks, focusing on routing protocols and ISP-specific\nconfigurations. Our BHMM approach derived from these models demonstrates a 10%\nimprovement in detection accuracy and a 13% increase in packet delivery rate,\nhighlighting the efficiency of our approach. Additionally, we evaluate the\nMachine Learning approach leveraged with BHMM analysis in two different network\nsettings, a commercial ISP network, and a scientific research-only network\ntopology. This evaluation also demonstrates the practical applicability of our\nmethod, yielding significantly improved prediction outcomes in both\nenvironments.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00831v1",
    "published_date": "2024-02-01 18:17:37 UTC",
    "updated_date": "2024-02-01 18:17:37 UTC"
  },
  {
    "arxiv_id": "2402.00828v2",
    "title": "Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters",
    "authors": [
      "Umberto Cappellazzo",
      "Daniele Falavigna",
      "Alessio Brutti"
    ],
    "abstract": "Mixture of Experts (MoE) architectures have recently started burgeoning due\nto their ability to scale model's capacity while maintaining the computational\ncost affordable. Furthermore, they can be applied to both Transformers and\nState Space Models, the current state-of-the-art models in numerous fields.\nWhile MoE has been mostly investigated for the pre-training stage, its use in\nparameter-efficient transfer learning settings is under-explored. To narrow\nthis gap, this paper attempts to demystify the use of MoE for\nparameter-efficient fine-tuning of Audio Spectrogram Transformers to audio and\nspeech downstream tasks. Specifically, we propose Soft Mixture of Adapters\n(Soft-MoA). It exploits adapters as the experts and, leveraging the recent Soft\nMoE method, it relies on a soft assignment between the input tokens and experts\nto keep the computational time limited. Extensive experiments across 4\nbenchmarks demonstrate that Soft-MoA outperforms the single adapter method and\nperforms on par with the dense MoA counterpart. We finally present ablation\nstudies on key elements of Soft-MoA, showing for example that Soft-MoA achieves\nbetter scaling with more experts, as well as ensuring that all experts\ncontribute to the computation of the output tokens, thus dispensing with the\nexpert imbalance issue.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at INTERSPEECH 2024. The code is publicly available at:\n  https://github.com/umbertocappellazzo/PETL_AST",
    "pdf_url": "http://arxiv.org/pdf/2402.00828v2",
    "published_date": "2024-02-01 18:16:04 UTC",
    "updated_date": "2024-06-04 15:53:28 UTC"
  },
  {
    "arxiv_id": "2402.00823v2",
    "title": "SLIM: Skill Learning with Multiple Critics",
    "authors": [
      "David Emukpere",
      "Bingbing Wu",
      "Julien Perez",
      "Jean-Michel Renders"
    ],
    "abstract": "Self-supervised skill learning aims to acquire useful behaviors that leverage\nthe underlying dynamics of the environment. Latent variable models, based on\nmutual information maximization, have been successful in this task but still\nstruggle in the context of robotic manipulation. As it requires impacting a\npossibly large set of degrees of freedom composing the environment, mutual\ninformation maximization fails alone in producing useful and safe manipulation\nbehaviors. Furthermore, tackling this by augmenting skill discovery rewards\nwith additional rewards through a naive combination might fail to produce\ndesired behaviors. To address this limitation, we introduce SLIM, a\nmulti-critic learning approach for skill discovery with a particular focus on\nrobotic manipulation. Our main insight is that utilizing multiple critics in an\nactor-critic framework to gracefully combine multiple reward functions leads to\na significant improvement in latent-variable skill discovery for robotic\nmanipulation while overcoming possible interference occurring among rewards\nwhich hinders convergence to useful skills. Furthermore, in the context of\ntabletop manipulation, we demonstrate the applicability of our novel skill\ndiscovery approach to acquire safe and efficient motor primitives in a\nhierarchical reinforcement learning fashion and leverage them through planning,\nsignificantly surpassing baseline approaches for skill discovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00823v2",
    "published_date": "2024-02-01 18:07:33 UTC",
    "updated_date": "2024-03-21 10:21:37 UTC"
  },
  {
    "arxiv_id": "2402.00822v1",
    "title": "WiOpen: A Robust Wi-Fi-based Open-set Gesture Recognition Framework",
    "authors": [
      "Xiang Zhang",
      "Jingyang Huang",
      "Huan Yan",
      "Peng Zhao",
      "Guohang Zhuang",
      "Zhi Liu",
      "Bin Liu"
    ],
    "abstract": "Recent years have witnessed a growing interest in Wi-Fi-based gesture\nrecognition. However, existing works have predominantly focused on closed-set\nparadigms, where all testing gestures are predefined during training. This\nposes a significant challenge in real-world applications, as unseen gestures\nmight be misclassified as known classes during testing. To address this issue,\nwe propose WiOpen, a robust Wi-Fi-based Open-Set Gesture Recognition (OSGR)\nframework. Implementing OSGR requires addressing challenges caused by the\nunique uncertainty in Wi-Fi sensing. This uncertainty, resulting from noise and\ndomains, leads to widely scattered and irregular data distributions in\ncollected Wi-Fi sensing data. Consequently, data ambiguity between classes and\nchallenges in defining appropriate decision boundaries to identify unknowns\narise. To tackle these challenges, WiOpen adopts a two-fold approach to\neliminate uncertainty and define precise decision boundaries. Initially, it\naddresses uncertainty induced by noise during data preprocessing by utilizing\nthe CSI ratio. Next, it designs the OSGR network based on an uncertainty\nquantification method. Throughout the learning process, this network\neffectively mitigates uncertainty stemming from domains. Ultimately, the\nnetwork leverages relationships among samples' neighbors to dynamically define\nopen-set decision boundaries, successfully realizing OSGR. Comprehensive\nexperiments on publicly accessible datasets confirm WiOpen's effectiveness.\nNotably, WiOpen also demonstrates superiority in cross-domain tasks when\ncompared to state-of-the-art approaches.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00822v1",
    "published_date": "2024-02-01 18:05:38 UTC",
    "updated_date": "2024-02-01 18:05:38 UTC"
  },
  {
    "arxiv_id": "2402.00816v1",
    "title": "Leveraging Approximate Model-based Shielding for Probabilistic Safety Guarantees in Continuous Environments",
    "authors": [
      "Alexander W. Goodall",
      "Francesco Belardinelli"
    ],
    "abstract": "Shielding is a popular technique for achieving safe reinforcement learning\n(RL). However, classical shielding approaches come with quite restrictive\nassumptions making them difficult to deploy in complex environments,\nparticularly those with continuous state or action spaces. In this paper we\nextend the more versatile approximate model-based shielding (AMBS) framework to\nthe continuous setting. In particular we use Safety Gym as our test-bed,\nallowing for a more direct comparison of AMBS with popular constrained RL\nalgorithms. We also provide strong probabilistic safety guarantees for the\ncontinuous setting. In addition, we propose two novel penalty techniques that\ndirectly modify the policy gradient, which empirically provide more stable\nconvergence in our experiments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as an Extended Abstract at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00816v1",
    "published_date": "2024-02-01 17:55:08 UTC",
    "updated_date": "2024-02-01 17:55:08 UTC"
  },
  {
    "arxiv_id": "2402.00808v2",
    "title": "Exploring the Dynamics between Cobot's Production Rhythm, Locus of Control and Emotional State in a Collaborative Assembly Scenario",
    "authors": [
      "Marta Mondellini",
      "Matteo Lavit Nicora",
      "Pooja Prajod",
      "Elisabeth André",
      "Rocco Vertechy",
      "Alessandro Antonietti",
      "Matteo Malosio"
    ],
    "abstract": "In industrial scenarios, there is widespread use of collaborative robots\n(cobots), and growing interest is directed at evaluating and measuring the\nimpact of some characteristics of the cobot on the human factor. In the present\npilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 -\nAdapted to the participant's pace) of a cobot has on the Experiential Locus of\nControl (ELoC) and the emotional state of 31 participants has been examined.\nThe operators' performance, the degree of basic internal Locus of Control, and\nthe attitude towards the robots were also considered. No difference was found\nregarding the emotional state and the ELoC in the three conditions, but\nconsidering the other psychological variables, a more complex situation\nemerges. Overall, results seem to indicate a need to consider the person's\npsychological characteristics to offer a differentiated and optimal interaction\nexperience.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to 4th IEEE International Conference on Human-Machine\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2402.00808v2",
    "published_date": "2024-02-01 17:44:46 UTC",
    "updated_date": "2024-06-28 02:16:13 UTC"
  },
  {
    "arxiv_id": "2402.00798v4",
    "title": "Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents",
    "authors": [
      "Zelong Li",
      "Wenyue Hua",
      "Hao Wang",
      "He Zhu",
      "Yongfeng Zhang"
    ],
    "abstract": "Recent advancements on Large Language Models (LLMs) enable AI Agents to\nautomatically generate and execute multi-step plans to solve complex tasks.\nHowever, since LLM's content generation process is hardly controllable, current\nLLM-based agents frequently generate invalid or non-executable plans, which\njeopardizes the performance of the generated plans and corrupts users' trust in\nLLM-based agents. In response, this paper proposes a novel \"Formal-LLM\"\nframework for LLM-based agents by integrating the expressiveness of natural\nlanguage and the precision of formal language. Specifically, the framework\nallows agent developers to express their requirements or constraints for the\nplanning process as an automaton. A stack-based LLM plan generation process is\nthen conducted under the supervision of the automaton to ensure that the\ngenerated plan satisfies the constraints, making the planning process\ncontrollable. We conduct experiments on both benchmark tasks and practical\nreal-life tasks, and our framework achieves over 50% overall performance\nincrease, which validates the feasibility and effectiveness of employing\nFormal-LLM to guide the plan generation of agents, preventing the agents from\ngenerating invalid and unsuccessful plans. Further, more controllable LLM-based\nagents can facilitate the broader utilization of LLM in application scenarios\nwhere high validity of planning is essential. The source code of this work is\navailable at https://github.com/agiresearch/Formal-LLM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.FL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00798v4",
    "published_date": "2024-02-01 17:30:50 UTC",
    "updated_date": "2024-08-12 17:54:32 UTC"
  },
  {
    "arxiv_id": "2402.00795v4",
    "title": "LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law",
    "authors": [
      "Toni J. B. Liu",
      "Nicolas Boullé",
      "Raphaël Sarfati",
      "Christopher J. Earls"
    ],
    "abstract": "Pretrained large language models (LLMs) are surprisingly effective at\nperforming zero-shot tasks, including time-series forecasting. However,\nunderstanding the mechanisms behind such capabilities remains highly\nchallenging due to the complexity of the models. We study LLMs' ability to\nextrapolate the behavior of dynamical systems whose evolution is governed by\nprinciples of physical interest. Our results show that LLaMA 2, a language\nmodel trained primarily on texts, achieves accurate predictions of dynamical\nsystem time series without fine-tuning or prompt engineering. Moreover, the\naccuracy of the learned physical rules increases with the length of the input\ncontext window, revealing an in-context version of neural scaling law. Along\nthe way, we present a flexible and efficient algorithm for extracting\nprobability density functions of multi-digit numbers directly from LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00795v4",
    "published_date": "2024-02-01 17:28:10 UTC",
    "updated_date": "2024-10-09 16:02:13 UTC"
  },
  {
    "arxiv_id": "2402.00794v2",
    "title": "ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models",
    "authors": [
      "Zhixue Zhao",
      "Boxuan Shan"
    ],
    "abstract": "Feature attribution methods (FAs), such as gradients and attention, are\nwidely employed approaches to derive the importance of all input features to\nthe model predictions. Existing work in natural language processing has mostly\nfocused on developing and testing FAs for encoder-only language models (LMs) in\nclassification tasks. However, it is unknown if it is faithful to use these FAs\nfor decoder-only models on text generation, due to the inherent differences\nbetween model architectures and task settings respectively. Moreover, previous\nwork has demonstrated that there is no `one-wins-all' FA across models and\ntasks. This makes the selection of a FA computationally expensive for large LMs\nsince input importance derivation often requires multiple forward and backward\npasses including gradient computations that might be prohibitive even with\naccess to large compute. To address these issues, we present a model-agnostic\nFA for generative LMs called Recursive Attribution Generator (ReAGent). Our\nmethod updates the token importance distribution in a recursive manner. For\neach update, we compute the difference in the probability distribution over the\nvocabulary for predicting the next token between using the original input and\nusing a modified version where a part of the input is replaced with RoBERTa\npredictions. Our intuition is that replacing an important token in the context\nshould have resulted in a larger change in the model's confidence in predicting\nthe token than replacing an unimportant token. Our method can be universally\napplied to any generative LM without accessing internal model weights or\nadditional training and fine-tuning, as most other FAs require. We extensively\ncompare the faithfulness of ReAGent with seven popular FAs across six\ndecoder-only LMs of various sizes. The results show that our method\nconsistently provides more faithful token importance distributions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AAAI24 workshop ReLM",
    "pdf_url": "http://arxiv.org/pdf/2402.00794v2",
    "published_date": "2024-02-01 17:25:51 UTC",
    "updated_date": "2024-02-07 21:01:16 UTC"
  },
  {
    "arxiv_id": "2402.00793v3",
    "title": "Human Expertise in Algorithmic Prediction",
    "authors": [
      "Rohan Alur",
      "Manish Raghavan",
      "Devavrat Shah"
    ],
    "abstract": "We introduce a novel framework for incorporating human expertise into\nalgorithmic predictions. Our approach leverages human judgment to distinguish\ninputs which are algorithmically indistinguishable, or \"look the same\" to\npredictive algorithms. We argue that this framing clarifies the problem of\nhuman-AI collaboration in prediction tasks, as experts often form judgments by\ndrawing on information which is not encoded in an algorithm's training data.\nAlgorithmic indistinguishability yields a natural test for assessing whether\nexperts incorporate this kind of \"side information\", and further provides a\nsimple but principled method for selectively incorporating human feedback into\nalgorithmic predictions. We show that this method provably improves the\nperformance of any feasible algorithmic predictor and precisely quantify this\nimprovement. We find empirically that although algorithms often outperform\ntheir human counterparts on average, human judgment can improve algorithmic\npredictions on specific instances (which can be identified ex-ante). In an\nX-ray classification task, we find that this subset constitutes nearly $30\\%$\nof the patient population. Our approach provides a natural way of uncovering\nthis heterogeneity and thus enabling effective human-AI collaboration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00793v3",
    "published_date": "2024-02-01 17:23:54 UTC",
    "updated_date": "2024-10-30 15:45:32 UTC"
  },
  {
    "arxiv_id": "2402.00789v1",
    "title": "Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces",
    "authors": [
      "Chloe Wang",
      "Oleksii Tsepa",
      "Jun Ma",
      "Bo Wang"
    ],
    "abstract": "Attention mechanisms have been widely used to capture long-range dependencies\namong nodes in Graph Transformers. Bottlenecked by the quadratic computational\ncost, attention mechanisms fail to scale in large graphs. Recent improvements\nin computational efficiency are mainly achieved by attention sparsification\nwith random or heuristic-based graph subsampling, which falls short in\ndata-dependent context reasoning. State space models (SSMs), such as Mamba,\nhave gained prominence for their effectiveness and efficiency in modeling\nlong-range dependencies in sequential data. However, adapting SSMs to\nnon-sequential graph data presents a notable challenge. In this work, we\nintroduce Graph-Mamba, the first attempt to enhance long-range context modeling\nin graph networks by integrating a Mamba block with the input-dependent node\nselection mechanism. Specifically, we formulate graph-centric node\nprioritization and permutation strategies to enhance context-aware reasoning,\nleading to a substantial improvement in predictive performance. Extensive\nexperiments on ten benchmark datasets demonstrate that Graph-Mamba outperforms\nstate-of-the-art methods in long-range graph prediction tasks, with a fraction\nof the computational cost in both FLOPs and GPU memory consumption. The code\nand models are publicly available at https://github.com/bowang-lab/Graph-Mamba.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00789v1",
    "published_date": "2024-02-01 17:21:53 UTC",
    "updated_date": "2024-02-01 17:21:53 UTC"
  },
  {
    "arxiv_id": "2402.00759v3",
    "title": "Building Expressive and Tractable Probabilistic Generative Models: A Review",
    "authors": [
      "Sahil Sidheekh",
      "Sriraam Natarajan"
    ],
    "abstract": "We present a comprehensive survey of the advancements and techniques in the\nfield of tractable probabilistic generative modeling, primarily focusing on\nProbabilistic Circuits (PCs). We provide a unified perspective on the inherent\ntrade-offs between expressivity and tractability, highlighting the design\nprinciples and algorithmic extensions that have enabled building expressive and\nefficient PCs, and provide a taxonomy of the field. We also discuss recent\nefforts to build deep and hybrid PCs by fusing notions from deep neural models,\nand outline the challenges and open questions that can guide future research in\nthis evolving field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00759v3",
    "published_date": "2024-02-01 16:49:27 UTC",
    "updated_date": "2024-06-06 11:25:34 UTC"
  },
  {
    "arxiv_id": "2402.00751v1",
    "title": "Unlearnable Algorithms for In-context Learning",
    "authors": [
      "Andrei Muresanu",
      "Anvith Thudi",
      "Michael R. Zhang",
      "Nicolas Papernot"
    ],
    "abstract": "Machine unlearning is a desirable operation as models get increasingly\ndeployed on data with unknown provenance. However, achieving exact unlearning\n-- obtaining a model that matches the model distribution when the data to be\nforgotten was never used -- is challenging or inefficient, often requiring\nsignificant retraining. In this paper, we focus on efficient unlearning methods\nfor the task adaptation phase of a pretrained large language model (LLM). We\nobserve that an LLM's ability to do in-context learning for task adaptation\nallows for efficient exact unlearning of task adaptation training data. We\nprovide an algorithm for selecting few-shot training examples to prepend to the\nprompt given to an LLM (for task adaptation), ERASE, whose unlearning operation\ncost is independent of model and dataset size, meaning it scales to large\nmodels and datasets. We additionally compare our approach to fine-tuning\napproaches and discuss the trade-offs between the two approaches. This leads us\nto propose a new holistic measure of unlearning cost which accounts for varying\ninference costs, and conclude that in-context learning can often be more\nfavourable than fine-tuning for deployments involving unlearning requests.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00751v1",
    "published_date": "2024-02-01 16:43:04 UTC",
    "updated_date": "2024-02-01 16:43:04 UTC"
  },
  {
    "arxiv_id": "2402.00742v2",
    "title": "Transforming and Combining Rewards for Aligning Large Language Models",
    "authors": [
      "Zihao Wang",
      "Chirag Nagpal",
      "Jonathan Berant",
      "Jacob Eisenstein",
      "Alex D'Amour",
      "Sanmi Koyejo",
      "Victor Veitch"
    ],
    "abstract": "A common approach for aligning language models to human preferences is to\nfirst learn a reward model from preference data, and then use this reward model\nto update the language model. We study two closely related problems that arise\nin this approach. First, any monotone transformation of the reward model\npreserves preference ranking; is there a choice that is ``better'' than others?\nSecond, we often wish to align language models to multiple properties: how\nshould we combine multiple reward models? Using a probabilistic interpretation\nof the alignment procedure, we identify a natural choice for transformation for\n(the common case of) rewards learned from Bradley-Terry preference models. The\nderived transformation is straightforward: we apply a log-sigmoid function to\nthe centered rewards, a method we term ``LSC-transformation''\n(log-sigmoid-centered transformation). This transformation has two important\nproperties. First, it emphasizes improving poorly-performing outputs, rather\nthan outputs that already score well. This mitigates both underfitting (where\nsome prompts are not improved) and reward hacking (where the model learns to\nexploit misspecification of the reward model). Second, it enables principled\naggregation of rewards by linking summation to logical conjunction: the sum of\ntransformed rewards corresponds to the probability that the output is ``good''\nin all measured properties, in a sense we make precise. Experiments aligning\nlanguage models to be both helpful and harmless using RLHF show substantial\nimprovements over the baseline (non-transformed) approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00742v2",
    "published_date": "2024-02-01 16:39:28 UTC",
    "updated_date": "2024-07-19 05:12:15 UTC"
  },
  {
    "arxiv_id": "2402.00738v1",
    "title": "FM3Q: Factorized Multi-Agent MiniMax Q-Learning for Two-Team Zero-Sum Markov Game",
    "authors": [
      "Guangzheng Hu",
      "Yuanheng Zhu",
      "Haoran Li",
      "Dongbin Zhao"
    ],
    "abstract": "Many real-world applications involve some agents that fall into two teams,\nwith payoffs that are equal within the same team but of opposite sign across\nthe opponent team. The so-called two-team zero-sum Markov games (2t0sMGs) can\nbe resolved with reinforcement learning in recent years. However, existing\nmethods are thus inefficient in light of insufficient consideration of\nintra-team credit assignment, data utilization and computational\nintractability. In this paper, we propose the individual-global-minimax (IGMM)\nprinciple to ensure the coherence between two-team minimax behaviors and the\nindividual greedy behaviors through Q functions in 2t0sMGs. Based on it, we\npresent a novel multi-agent reinforcement learning framework, Factorized\nMulti-Agent MiniMax Q-Learning (FM3Q), which can factorize the joint minimax Q\nfunction into individual ones and iteratively solve for the IGMM-satisfied\nminimax Q functions for 2t0sMGs. Moreover, an online learning algorithm with\nneural networks is proposed to implement FM3Q and obtain the deterministic and\ndecentralized minimax policies for two-team players. A theoretical analysis is\nprovided to prove the convergence of FM3Q. Empirically, we use three\nenvironments to evaluate the learning efficiency and final performance of FM3Q\nand show its superiority on 2t0sMGs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00738v1",
    "published_date": "2024-02-01 16:37:21 UTC",
    "updated_date": "2024-02-01 16:37:21 UTC"
  },
  {
    "arxiv_id": "2402.00722v1",
    "title": "Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Marco Aggravi",
      "Paolo Robuffo Giordano",
      "Juan G. Victores",
      "Claudio Pacchierotti"
    ],
    "abstract": "Neural Style Transfer (NST) refers to a class of algorithms able to\nmanipulate an element, most often images, to adopt the appearance or style of\nanother one. Each element is defined as a combination of Content and Style: the\nContent can be conceptually defined as the what and the Style as the how of\nsaid element. In this context, we propose a custom NST framework for\ntransferring a set of styles to the motion of a robotic manipulator, e.g., the\nsame robotic task can be carried out in an angry, happy, calm, or sad way. An\nautoencoder architecture extracts and defines the Content and the Style of the\ntarget robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3)\nnetwork generates the robot control policy using the loss defined by the\nautoencoder. The proposed Neural Policy Style Transfer TD3 (NPST3) alters the\nrobot motion by introducing the trained style. Such an approach can be\nimplemented either offline, for carrying out autonomous robot motions in\ndynamic environments, or online, for adapting at runtime the style of a\nteleoperated robot. The considered styles can be learned online from human\ndemonstrations. We carried out an evaluation with human subjects enrolling 73\nvolunteers, asking them to recognize the style behind some representative\nrobotic motions. Results show a good recognition rate, proving that it is\npossible to convey different styles to a robot using this approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00722v1",
    "published_date": "2024-02-01 16:14:32 UTC",
    "updated_date": "2024-02-01 16:14:32 UTC"
  },
  {
    "arxiv_id": "2402.00715v2",
    "title": "Intent Assurance using LLMs guided by Intent Drift",
    "authors": [
      "Kristina Dzeparoska",
      "Ali Tizghadam",
      "Alberto Leon-Garcia"
    ],
    "abstract": "Intent-Based Networking (IBN) presents a paradigm shift for network\nmanagement, by promising to align intents and business objectives with network\noperations--in an automated manner. However, its practical realization is\nchallenging: 1) processing intents, i.e., translate, decompose and identify the\nlogic to fulfill the intent, and 2) intent conformance, that is, considering\ndynamic networks, the logic should be adequately adapted to assure intents. To\naddress the latter, intent assurance is tasked with continuous verification and\nvalidation, including taking the necessary actions to align the operational and\ntarget states. In this paper, we define an assurance framework that allows us\nto detect and act when intent drift occurs. To do so, we leverage AI-driven\npolicies, generated by Large Language Models (LLMs) which can quickly learn the\nnecessary in-context requirements, and assist with the fulfillment and\nassurance of intents.",
    "categories": [
      "cs.AI",
      "cs.NI",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00715v2",
    "published_date": "2024-02-01 16:09:19 UTC",
    "updated_date": "2024-02-02 23:08:12 UTC"
  },
  {
    "arxiv_id": "2402.00707v1",
    "title": "Non-Exchangeable Conformal Language Generation with Nearest Neighbors",
    "authors": [
      "Dennis Ulmer",
      "Chrysoula Zerva",
      "André F. T. Martins"
    ],
    "abstract": "Quantifying uncertainty in automatically generated text is important for\nletting humans check potential hallucinations and making systems more reliable.\nConformal prediction is an attractive framework to provide predictions imbued\nwith statistical guarantees, however, its application to text generation is\nchallenging since any i.i.d. assumptions are not realistic. In this paper, we\nbridge this gap by leveraging recent results on non-exchangeable conformal\nprediction, which still ensures bounds on coverage. The result,\nnon-exchangeable conformal nucleus sampling, is a novel extension of the\nconformal prediction framework to generation based on nearest neighbors. Our\nmethod can be used post-hoc for an arbitrary model without extra training and\nsupplies token-level, calibrated prediction sets equipped with statistical\nguarantees. Experiments in machine translation and language modeling show\nencouraging results in generation quality. By also producing tighter prediction\nsets with good coverage, we thus give a more theoretically principled way to\nperform sampling with conformal guarantees.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00707v1",
    "published_date": "2024-02-01 16:04:04 UTC",
    "updated_date": "2024-02-01 16:04:04 UTC"
  },
  {
    "arxiv_id": "2402.01777v1",
    "title": "On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble",
    "authors": [
      "Adrita Barua",
      "Gary Brase",
      "Ke Dong",
      "Pascal Hitzler",
      "Eugene Vasserman"
    ],
    "abstract": "We subject GPT-4 to a number of rigorous psychometric tests and analyze the\nresults. We find that, compared to the average human, GPT-4 tends to show more\nhonesty and humility, and less machiavellianism and narcissism. It sometimes\nexhibits ambivalent sexism, leans slightly toward masculinity, is moderately\nanxious but mostly not depressive (but not always). It shows human-average\nnumerical literacy and has cognitive reflection abilities that are above human\naverage for verbal tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 8 tables, 1 code repository",
    "pdf_url": "http://arxiv.org/pdf/2402.01777v1",
    "published_date": "2024-02-01 15:58:13 UTC",
    "updated_date": "2024-02-01 15:58:13 UTC"
  },
  {
    "arxiv_id": "2402.00699v1",
    "title": "PeaTMOSS: A Dataset and Initial Analysis of Pre-Trained Models in Open-Source Software",
    "authors": [
      "Wenxin Jiang",
      "Jerin Yasmin",
      "Jason Jones",
      "Nicholas Synovic",
      "Jiashen Kuo",
      "Nathaniel Bielanski",
      "Yuan Tian",
      "George K. Thiruvathukal",
      "James C. Davis"
    ],
    "abstract": "The development and training of deep learning models have become increasingly\ncostly and complex. Consequently, software engineers are adopting pre-trained\nmodels (PTMs) for their downstream applications. The dynamics of the PTM supply\nchain remain largely unexplored, signaling a clear need for structured datasets\nthat document not only the metadata but also the subsequent applications of\nthese models. Without such data, the MSR community cannot comprehensively\nunderstand the impact of PTM adoption and reuse. This paper presents the\nPeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailed\nsnapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with\n28,575 open-source software repositories from GitHub that utilize these models.\nAdditionally, the dataset includes 44,337 mappings from 15,129 downstream\nGitHub repositories to the 2,530 PTMs they use. To enhance the dataset's\ncomprehensiveness, we developed prompts for a large language model to\nautomatically extract model metadata, including the model's training datasets,\nparameters, and evaluation metrics. Our analysis of this dataset provides the\nfirst summary statistics for the PTM supply chain, showing the trend of PTM\ndevelopment and common shortcomings of PTM package documentation. Our example\napplication reveals inconsistencies in software licenses across PTMs and their\ndependent projects. PeaTMOSS lays the foundation for future research, offering\nrich opportunities to investigate the PTM supply chain. We outline mining\nopportunities on PTMs, their downstream usage, and cross-cutting questions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at MSR'24",
    "pdf_url": "http://arxiv.org/pdf/2402.00699v1",
    "published_date": "2024-02-01 15:55:50 UTC",
    "updated_date": "2024-02-01 15:55:50 UTC"
  },
  {
    "arxiv_id": "2402.00689v1",
    "title": "Ocassionally Secure: A Comparative Analysis of Code Generation Assistants",
    "authors": [
      "Ran Elgedawy",
      "John Sadik",
      "Senjuti Dutta",
      "Anuj Gautam",
      "Konstantinos Georgiou",
      "Farzin Gholamrezae",
      "Fujiao Ji",
      "Kyungchan Lim",
      "Qian Liu",
      "Scott Ruoti"
    ],
    "abstract": "$ $Large Language Models (LLMs) are being increasingly utilized in various\napplications, with code generations being a notable example. While previous\nresearch has shown that LLMs have the capability to generate both secure and\ninsecure code, the literature does not take into account what factors help\ngenerate secure and effective code. Therefore in this paper we focus on\nidentifying and understanding the conditions and contexts in which LLMs can be\neffectively and safely deployed in real-world scenarios to generate quality\ncode. We conducted a comparative analysis of four advanced LLMs--GPT-3.5 and\nGPT-4 using ChatGPT and Bard and Gemini from Google--using 9 separate tasks to\nassess each model's code generation capabilities. We contextualized our study\nto represent the typical use cases of a real-life developer employing LLMs for\neveryday tasks as work. Additionally, we place an emphasis on security\nawareness which is represented through the use of two distinct versions of our\ndeveloper persona. In total, we collected 61 code outputs and analyzed them\nacross several aspects: functionality, security, performance, complexity, and\nreliability. These insights are crucial for understanding the models'\ncapabilities and limitations, guiding future development and practical\napplications in the field of automated code generation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00689v1",
    "published_date": "2024-02-01 15:49:47 UTC",
    "updated_date": "2024-02-01 15:49:47 UTC"
  },
  {
    "arxiv_id": "2402.00678v1",
    "title": "Real Evaluations Tractability using Continuous Goal-Directed Actions in Smart City Applications",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Juan G. Victores",
      "David Estevez",
      "Carlos Balaguer"
    ],
    "abstract": "One of the most important challenges of Smart City Applications is to adapt\nthe system to interact with non-expert users. Robot imitation frameworks aim to\nsimplify and reduce times of robot programming by allowing users to program\ndirectly through demonstrations. In classical frameworks, actions are modeled\nusing joint or Cartesian space trajectories. Other features, such as visual\nones, are not always well represented with these pure geometrical approaches.\nContinuous Goal-Directed Actions (CGDA) is an alternative to these methods, as\nit encodes actions as changes of any feature that can be extracted from the\nenvironment. As a consequence of this, the robot joint trajectories for\nexecution must be fully computed to comply with this feature-agnostic encoding.\nThis is achieved using Evolutionary Algorithms (EA), which usually requires too\nmany evaluations to perform this evolution step in the actual robot. Current\nstrategies involve performing evaluations in a simulation, transferring the\nfinal joint trajectory to the actual robot. Smart City applications involve\nworking in highly dynamic and complex environments, where having a precise\nmodel is not always achievable. Our goal is to study the tractability of\nperforming these evaluations directly in a real-world scenario. Two different\napproaches to reduce the number of evaluations using EA, are proposed and\ncompared. In the first approach, Particle Swarm Optimization (PSO)-based\nmethods have been studied and compared within CGDA: naive PSO, Fitness\nInheritance PSO (FI-PSO), and Adaptive Fuzzy Fitness Granulation with PSO\n(AFFG-PSO). The second approach studied the introduction of geometrical and\nvelocity constraints within CGDA. The effects of both approaches were analyzed\nand compared in the wax and paint actions, two CGDA commonly studied use cases.\nResults from this paper depict an important reduction in the number of\nevaluations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00678v1",
    "published_date": "2024-02-01 15:38:21 UTC",
    "updated_date": "2024-02-01 15:38:21 UTC"
  },
  {
    "arxiv_id": "2402.00677v1",
    "title": "Neural Policy Style Transfer",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Juan G. Victores",
      "Jennifer J. Gago",
      "David Estevez",
      "Carlos Balaguer"
    ],
    "abstract": "Style Transfer has been proposed in a number of fields: fine arts, natural\nlanguage processing, and fixed trajectories. We scale this concept up to\ncontrol policies within a Deep Reinforcement Learning infrastructure. Each\nnetwork is trained to maximize the expected reward, which typically encodes the\ngoal of an action, and can be described as the content. The expressive power of\ndeep neural networks enables encoding a secondary task, which can be described\nas the style. The Neural Policy Style Transfer (NPST) algorithm is proposed to\ntransfer the style of one policy to another, while maintaining the content of\nthe latter. Different policies are defined via Deep Q-Network architectures.\nThese models are trained using demonstrations through Inverse Reinforcement\nLearning. Two different sets of user demonstrations are performed, one for\ncontent and other for style. Different styles are encoded as defined by user\ndemonstrations. The generated policy is the result of feeding a content policy\nand a style policy to the NPST algorithm. Experiments are performed in a\ncatch-ball game inspired by the Deep Reinforcement Learning classical Atari\ngames; and a real-world painting scenario with a full-sized humanoid robot,\nbased on previous works of the authors. The implementation of three different\nQ-Network architectures (Shallow, Deep and Deep Recurrent Q-Network) to encode\nthe policies within the NPST framework is proposed and the results obtained in\nthe experiments with each of these architectures compared.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00677v1",
    "published_date": "2024-02-01 15:37:42 UTC",
    "updated_date": "2024-02-01 15:37:42 UTC"
  },
  {
    "arxiv_id": "2402.00676v1",
    "title": "Deep Robot Sketching: An application of Deep Q-Learning Networks for human-like sketching",
    "authors": [
      "Raul Fernandez-Fernandez",
      "Juan G. Victores",
      "Carlos Balaguer"
    ],
    "abstract": "The current success of Reinforcement Learning algorithms for its performance\nin complex environments has inspired many recent theoretical approaches to\ncognitive science. Artistic environments are studied within the cognitive\nscience community as rich, natural, multi-sensory, multi-cultural environments.\nIn this work, we propose the introduction of Reinforcement Learning for\nimproving the control of artistic robot applications. Deep Q-learning Neural\nNetworks (DQN) is one of the most successful algorithms for the implementation\nof Reinforcement Learning in robotics. DQN methods generate complex control\npolicies for the execution of complex robot applications in a wide set of\nenvironments. Current art painting robot applications use simple control laws\nthat limits the adaptability of the frameworks to a set of simple environments.\nIn this work, the introduction of DQN within an art painting robot application\nis proposed. The goal is to study how the introduction of a complex control\npolicy impacts the performance of a basic art painting robot application. The\nmain expected contribution of this work is to serve as a first baseline for\nfuture works introducing DQN methods for complex art painting robot frameworks.\nExperiments consist of real world executions of human drawn sketches using the\nDQN generated policy and TEO, the humanoid robot. Results are compared in terms\nof similarity and obtained reward with respect to the reference inputs",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00676v1",
    "published_date": "2024-02-01 15:37:23 UTC",
    "updated_date": "2024-02-01 15:37:23 UTC"
  },
  {
    "arxiv_id": "2402.00672v4",
    "title": "Exploring Homogeneous and Heterogeneous Consistent Label Associations for Unsupervised Visible-Infrared Person ReID",
    "authors": [
      "Lingfeng He",
      "De Cheng",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "abstract": "Unsupervised visible-infrared person re-identification (USL-VI-ReID)\nendeavors to retrieve pedestrian images of the same identity from different\nmodalities without annotations. While prior work focuses on establishing\ncross-modality pseudo-label associations to bridge the modality-gap, they\nignore maintaining the instance-level homogeneous and heterogeneous consistency\nbetween the feature space and the pseudo-label space, resulting in coarse\nassociations. In response, we introduce a Modality-Unified Label Transfer\n(MULT) module that simultaneously accounts for both homogeneous and\nheterogeneous fine-grained instance-level structures, yielding high-quality\ncross-modality label associations. It models both homogeneous and heterogeneous\naffinities, leveraging them to quantify the inconsistency between the\npseudo-label space and the feature space, subsequently minimizing it. The\nproposed MULT ensures that the generated pseudo-labels maintain alignment\nacross modalities while upholding structural consistency within intra-modality.\nAdditionally, a straightforward plug-and-play Online Cross-memory Label\nRefinement (OCLR) module is proposed to further mitigate the side effects of\nnoisy pseudo-labels while simultaneously aligning different modalities, coupled\nwith an Alternative Modality-Invariant Representation Learning (AMIRL)\nframework. Experiments demonstrate that our proposed method outperforms\nexisting state-of-the-art USL-VI-ReID methods, highlighting the superiority of\nour MULT in comparison to other cross-modality association methods. Code is\navailable at https://github.com/FranklinLingfeng/code_for_MULT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IJCV2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00672v4",
    "published_date": "2024-02-01 15:33:17 UTC",
    "updated_date": "2024-12-04 03:55:35 UTC"
  },
  {
    "arxiv_id": "2402.00658v3",
    "title": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing",
    "authors": [
      "Fangkai Jiao",
      "Chengwei Qin",
      "Zhengyuan Liu",
      "Nancy F. Chen",
      "Shafiq Joty"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nhandling complex reasoning tasks through step-by-step rationale generation.\nHowever, recent studies have raised concerns regarding the hallucination and\nflaws in their reasoning process. Substantial efforts are being made to improve\nthe reliability and faithfulness of the generated rationales. Some approaches\nmodel reasoning as planning, while others focus on annotating for process\nsupervision. Nevertheless, the planning-based search process often results in\nhigh latency due to the frequent assessment of intermediate reasoning states\nand the extensive exploration space. Additionally, supervising the reasoning\nprocess with human annotation is costly and challenging to scale for LLM\ntraining. To address these issues, in this paper, we propose a framework to\nlearn planning-based reasoning through Direct Preference Optimization (DPO) on\ncollected trajectories, which are ranked according to synthesized process\nrewards. Our results on challenging logical reasoning benchmarks demonstrate\nthe effectiveness of our learning framework, showing that our 7B model can\nsurpass the strong counterparts like GPT-3.5-Turbo.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 9 figures. EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00658v3",
    "published_date": "2024-02-01 15:18:33 UTC",
    "updated_date": "2024-10-15 09:16:38 UTC"
  },
  {
    "arxiv_id": "2402.00627v3",
    "title": "CapHuman: Capture Your Moments in Parallel Universes",
    "authors": [
      "Chao Liang",
      "Fan Ma",
      "Linchao Zhu",
      "Yingying Deng",
      "Yi Yang"
    ],
    "abstract": "We concentrate on a novel human-centric image synthesis task, that is, given\nonly one reference facial photograph, it is expected to generate specific\nindividual images with diverse head positions, poses, facial expressions, and\nilluminations in different contexts. To accomplish this goal, we argue that our\ngenerative model should be capable of the following favorable characteristics:\n(1) a strong visual and semantic understanding of our world and human society\nfor basic object and human image generation. (2) generalizable identity\npreservation ability. (3) flexible and fine-grained head control. Recently,\nlarge pre-trained text-to-image diffusion models have shown remarkable results,\nserving as a powerful generative foundation. As a basis, we aim to unleash the\nabove two capabilities of the pre-trained model. In this work, we present a new\nframework named CapHuman. We embrace the \"encode then learn to align\" paradigm,\nwhich enables generalizable identity preservation for new individuals without\ncumbersome tuning at inference. CapHuman encodes identity features and then\nlearns to align them into the latent space. Moreover, we introduce the 3D\nfacial prior to equip our model with control over the human head in a flexible\nand 3D-consistent manner. Extensive qualitative and quantitative analyses\ndemonstrate our CapHuman can produce well-identity-preserved, photo-realistic,\nand high-fidelity portraits with content-rich representations and various head\nrenditions, superior to established baselines. Code and checkpoint will be\nreleased at https://github.com/VamosC/CapHuman.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024. Project page: https://caphuman.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2402.00627v3",
    "published_date": "2024-02-01 14:41:59 UTC",
    "updated_date": "2024-05-17 14:40:55 UTC"
  },
  {
    "arxiv_id": "2402.00607v1",
    "title": "Are Synthetic Time-series Data Really not as Good as Real Data?",
    "authors": [
      "Fanzhe Fu",
      "Junru Chen",
      "Jing Zhang",
      "Carl Yang",
      "Lvbin Ma",
      "Yang Yang"
    ],
    "abstract": "Time-series data presents limitations stemming from data quality issues, bias\nand vulnerabilities, and generalization problem. Integrating universal data\nsynthesis methods holds promise in improving generalization. However, current\nmethods cannot guarantee that the generator's output covers all unseen real\ndata. In this paper, we introduce InfoBoost -- a highly versatile cross-domain\ndata synthesizing framework with time series representation learning\ncapability. We have developed a method based on synthetic data that enables\nmodel training without the need for real data, surpassing the performance of\nmodels trained with real data. Additionally, we have trained a universal\nfeature extractor based on our synthetic data that is applicable to all\ntime-series data. Our approach overcomes interference from multiple sources\nrhythmic signal, noise interference, and long-period features that exceed\nsampling window capabilities. Through experiments, our non-deep-learning\nsynthetic data enables models to achieve superior reconstruction performance\nand universal explicit representation extraction without the need for real\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00607v1",
    "published_date": "2024-02-01 13:59:04 UTC",
    "updated_date": "2024-02-01 13:59:04 UTC"
  },
  {
    "arxiv_id": "2402.00918v1",
    "title": "MUSTAN: Multi-scale Temporal Context as Attention for Robust Video Foreground Segmentation",
    "authors": [
      "Praveen Kumar Pokala",
      "Jaya Sai Kiran Patibandla",
      "Naveen Kumar Pandey",
      "Balakrishna Reddy Pailla"
    ],
    "abstract": "Video foreground segmentation (VFS) is an important computer vision task\nwherein one aims to segment the objects under motion from the background. Most\nof the current methods are image-based, i.e., rely only on spatial cues while\nignoring motion cues. Therefore, they tend to overfit the training data and\ndon't generalize well to out-of-domain (OOD) distribution. To solve the above\nproblem, prior works exploited several cues such as optical flow, background\nsubtraction mask, etc. However, having a video data with annotations like\noptical flow is a challenging task. In this paper, we utilize the temporal\ninformation and the spatial cues from the video data to improve OOD\nperformance. However, the challenge lies in how we model the temporal\ninformation given the video data in an interpretable way creates a very\nnoticeable difference. We therefore devise a strategy that integrates the\ntemporal context of the video in the development of VFS. Our approach give rise\nto deep learning architectures, namely MUSTAN1 and MUSTAN2 and they are based\non the idea of multi-scale temporal context as an attention, i.e., aids our\nmodels to learn better representations that are beneficial for VFS. Further, we\nintroduce a new video dataset, namely Indoor Surveillance Dataset (ISD) for\nVFS. It has multiple annotations on a frame level such as foreground binary\nmask, depth map, and instance semantic annotations. Therefore, ISD can benefit\nother computer vision tasks. We validate the efficacy of our architectures and\ncompare the performance with baselines. We demonstrate that proposed methods\nsignificantly outperform the benchmark methods on OOD. In addition, the\nperformance of MUSTAN2 is significantly improved on certain video categories on\nOOD data due to ISD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00918v1",
    "published_date": "2024-02-01 13:47:23 UTC",
    "updated_date": "2024-02-01 13:47:23 UTC"
  },
  {
    "arxiv_id": "2402.00591v3",
    "title": "Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
    "authors": [
      "Nicolas Lazzari",
      "Stefano De Giorgis",
      "Aldo Gangemi",
      "Valentina Presutti"
    ],
    "abstract": "This paper presents sandra, a neuro-symbolic reasoner combining vectorial\nrepresentations with deductive reasoning. Sandra builds a vector space\nconstrained by an ontology and performs reasoning over it. The geometric nature\nof the reasoner allows its combination with neural networks, bridging the gap\nwith symbolic knowledge representations. Sandra is based on the Description and\nSituation (DnS) ontology design pattern, a formalization of frame semantics.\nGiven a set of facts (a situation) it allows to infer all possible perspectives\n(descriptions) that can provide a plausible interpretation for it, even in\npresence of incomplete information. We prove that our method is correct with\nrespect to the DnS model. We experiment with two different tasks and their\nstandard benchmarks, demonstrating that, without increasing complexity, sandra\n(i) outperforms all the baselines (ii) provides interpretability in the\nclassification process, and (iii) allows control over the vector space, which\nis designed a priori.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00591v3",
    "published_date": "2024-02-01 13:37:53 UTC",
    "updated_date": "2024-03-25 10:52:20 UTC"
  },
  {
    "arxiv_id": "2402.00588v1",
    "title": "BrainSLAM: SLAM on Neural Population Activity Data",
    "authors": [
      "Kipp Freud",
      "Nathan Lepora",
      "Matt W. Jones",
      "Cian O'Donnell"
    ],
    "abstract": "Simultaneous localisation and mapping (SLAM) algorithms are commonly used in\nrobotic systems for learning maps of novel environments. Brains also appear to\nlearn maps, but the mechanisms are not known and it is unclear how to infer\nthese maps from neural activity data. We present BrainSLAM; a method for\nperforming SLAM using only population activity (local field potential, LFP)\ndata simultaneously recorded from three brain regions in rats: hippocampus,\nprefrontal cortex, and parietal cortex. This system uses a convolutional neural\nnetwork (CNN) to decode velocity and familiarity information from wavelet\nscalograms of neural local field potential data recorded from rats as they\nnavigate a 2D maze. The CNN's output drives a RatSLAM-inspired architecture,\npowering an attractor network which performs path integration plus a separate\nsystem which performs `loop closure' (detecting previously visited locations\nand correcting map aliasing errors). Together, these three components can\nconstruct faithful representations of the environment while simultaneously\ntracking the animal's location. This is the first demonstration of inference of\na spatial map from brain recordings. Our findings expand SLAM to a new\nmodality, enabling a new method of mapping environments and facilitating a\nbetter understanding of the role of cognitive maps in navigation and decision\nmaking.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to the 23rd International Conference on Autonomous Agents\n  and Multiagent Systems. 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00588v1",
    "published_date": "2024-02-01 13:34:59 UTC",
    "updated_date": "2024-02-01 13:34:59 UTC"
  },
  {
    "arxiv_id": "2402.03471v1",
    "title": "The Information of Large Language Model Geometry",
    "authors": [
      "Zhiquan Tan",
      "Chenghai Li",
      "Weiran Huang"
    ],
    "abstract": "This paper investigates the information encoded in the embeddings of large\nlanguage models (LLMs). We conduct simulations to analyze the representation\nentropy and discover a power law relationship with model sizes. Building upon\nthis observation, we propose a theory based on (conditional) entropy to\nelucidate the scaling law phenomenon. Furthermore, we delve into the\nauto-regressive structure of LLMs and examine the relationship between the last\ntoken and previous context tokens using information theory and regression\ntechniques. Specifically, we establish a theoretical connection between the\ninformation gain of new tokens and ridge regression. Additionally, we explore\nthe effectiveness of Lasso regression in selecting meaningful tokens, which\nsometimes outperforms the closely related attention weights. Finally, we\nconduct controlled experiments, and find that information is distributed across\ntokens, rather than being concentrated in specific \"meaningful\" tokens alone.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03471v1",
    "published_date": "2024-02-01 12:50:43 UTC",
    "updated_date": "2024-02-01 12:50:43 UTC"
  },
  {
    "arxiv_id": "2402.00518v1",
    "title": "EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit Large Language Models",
    "authors": [
      "Xuchen Pan",
      "Yanxi Chen",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "This work introduces EE-Tuning, a lightweight and economical solution to\ntraining/tuning early-exit large language models (LLMs). In contrast to the\ncommon approach of full-parameter pre-training, EE-Tuning augments any\npre-trained (and possibly fine-tuned) standard LLM with additional early-exit\nlayers that are tuned in a parameter-efficient manner, which requires\nsignificantly less computational resources and training data. Our\nimplementation of EE-Tuning achieves outstanding training efficiency via\nextensive performance optimizations, as well as scalability due to its full\ncompatibility with 3D parallelism. Results of systematic experiments validate\nthe efficacy of EE-Tuning, confirming that effective early-exit LLM inference\ncan be achieved with a limited training budget. In hope of making early-exit\nLLMs accessible to the community, we release the source code of our\nimplementation of EE-Tuning at https://github.com/pan-x-c/EE-LLM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00518v1",
    "published_date": "2024-02-01 11:39:04 UTC",
    "updated_date": "2024-02-01 11:39:04 UTC"
  },
  {
    "arxiv_id": "2402.00913v3",
    "title": "Institutional Platform for Secure Self-Service Large Language Model Exploration",
    "authors": [
      "V. K. Cody Bumgardner",
      "Mitchell A. Klusty",
      "W. Vaiden Logan",
      "Samuel E. Armstrong",
      "Caroline N. Leach",
      "Kenneth L. Calvert",
      "Caylin Hickey",
      "Jeff Talbert"
    ],
    "abstract": "This paper introduces a user-friendly platform developed by the University of\nKentucky Center for Applied AI, designed to make large, customized language\nmodels (LLMs) more accessible. By capitalizing on recent advancements in\nmulti-LoRA inference, the system efficiently accommodates custom adapters for a\ndiverse range of users and projects. The paper outlines the system's\narchitecture and key features, encompassing dataset curation, model training,\nsecure inference, and text-based feature extraction.\n  We illustrate the establishment of a tenant-aware computational network using\nagent-based methods, securely utilizing islands of isolated resources as a\nunified system. The platform strives to deliver secure LLM services,\nemphasizing process and data isolation, end-to-end encryption, and role-based\nresource authentication. This contribution aligns with the overarching goal of\nenabling simplified access to cutting-edge AI models and technology in support\nof scientific discovery.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2402.00913v3",
    "published_date": "2024-02-01 10:58:10 UTC",
    "updated_date": "2025-02-24 14:50:08 UTC"
  },
  {
    "arxiv_id": "2402.00491v1",
    "title": "EXMOS: Explanatory Model Steering Through Multifaceted Explanations and Data Configurations",
    "authors": [
      "Aditya Bhattacharya",
      "Simone Stumpf",
      "Lucija Gosak",
      "Gregor Stiglic",
      "Katrien Verbert"
    ],
    "abstract": "Explanations in interactive machine-learning systems facilitate debugging and\nimproving prediction models. However, the effectiveness of various global\nmodel-centric and data-centric explanations in aiding domain experts to detect\nand resolve potential data issues for model improvement remains unexplored.\nThis research investigates the influence of data-centric and model-centric\nglobal explanations in systems that support healthcare experts in optimising\nmodels through automated and manual data configurations. We conducted\nquantitative (n=70) and qualitative (n=30) studies with healthcare experts to\nexplore the impact of different explanations on trust, understandability and\nmodel improvement. Our results reveal the insufficiency of global model-centric\nexplanations for guiding users during data configuration. Although data-centric\nexplanations enhanced understanding of post-configuration system changes, a\nhybrid fusion of both explanation types demonstrated the highest effectiveness.\nBased on our study results, we also present design implications for effective\nexplanation-driven interactive machine-learning systems.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "This is a pre-print version only for early release. Please view the\n  conference published version from ACM CHI 2024 to get the latest version of\n  the paper",
    "pdf_url": "http://arxiv.org/pdf/2402.00491v1",
    "published_date": "2024-02-01 10:57:00 UTC",
    "updated_date": "2024-02-01 10:57:00 UTC"
  },
  {
    "arxiv_id": "2402.01772v1",
    "title": "Disentangling the Roles of Target-Side Transfer and Regularization in Multilingual Machine Translation",
    "authors": [
      "Yan Meng",
      "Christof Monz"
    ],
    "abstract": "Multilingual Machine Translation (MMT) benefits from knowledge transfer\nacross different language pairs. However, improvements in one-to-many\ntranslation compared to many-to-one translation are only marginal and sometimes\neven negligible. This performance discrepancy raises the question of to what\nextent positive transfer plays a role on the target-side for one-to-many MT. In\nthis paper, we conduct a large-scale study that varies the auxiliary target\nside languages along two dimensions, i.e., linguistic similarity and corpus\nsize, to show the dynamic impact of knowledge transfer on the main language\npairs. We show that linguistically similar auxiliary target languages exhibit\nstrong ability to transfer positive knowledge. With an increasing size of\nsimilar target languages, the positive transfer is further enhanced to benefit\nthe main language pairs. Meanwhile, we find distant auxiliary target languages\ncan also unexpectedly benefit main language pairs, even with minimal positive\ntransfer ability. Apart from transfer, we show distant auxiliary target\nlanguages can act as a regularizer to benefit translation performance by\nenhancing the generalization and model inference calibration.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01772v1",
    "published_date": "2024-02-01 10:55:03 UTC",
    "updated_date": "2024-02-01 10:55:03 UTC"
  },
  {
    "arxiv_id": "2402.00485v1",
    "title": "A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems",
    "authors": [
      "Hossein A. Rahmani",
      "Mohammadmehdi Naghiaei",
      "Yashar Deldjoo"
    ],
    "abstract": "In recent years, there has been an increasing recognition that when machine\nlearning (ML) algorithms are used to automate decisions, they may mistreat\nindividuals or groups, with legal, ethical, or economic implications.\nRecommender systems are prominent examples of these machine learning (ML)\nsystems that aid users in making decisions. The majority of past literature\nresearch on RS fairness treats user and item fairness concerns independently,\nignoring the fact that recommender systems function in a two-sided marketplace.\nIn this paper, we propose CP-FairRank, an optimization-based re-ranking\nalgorithm that seamlessly integrates fairness constraints from both the\nconsumer and producer side in a joint objective framework. The framework is\ngeneralizable and may take into account varied fairness settings based on group\nsegmentation, recommendation model selection, and domain, which is one of its\nkey characteristics. For instance, we demonstrate that the system may jointly\nincrease consumer and producer fairness when (un)protected consumer groups are\ndefined on the basis of their activity level and main-streamness, while\nproducer groups are defined according to their popularity level. For empirical\nvalidation, through large-scale on eight datasets and four mainstream\ncollaborative filtering (CF) recommendation models, we demonstrate that our\nproposed strategy is able to improve both consumer and producer fairness\nwithout compromising or very little overall recommendation quality,\ndemonstrating the role algorithms may play in avoiding data biases.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "TORS. arXiv admin note: substantial text overlap with\n  arXiv:2204.08085",
    "pdf_url": "http://arxiv.org/pdf/2402.00485v1",
    "published_date": "2024-02-01 10:42:05 UTC",
    "updated_date": "2024-02-01 10:42:05 UTC"
  },
  {
    "arxiv_id": "2402.00474v1",
    "title": "SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection Framework for Large Language Models",
    "authors": [
      "Tianhan Xu",
      "Zhe Hu",
      "Ling Chen",
      "Bin Li"
    ],
    "abstract": "Recent advances in large language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, their\neffective application in the medical domain is hampered by a lack of medical\ndomain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable\nframework that aims to inject medical knowledge into general-purpose LLMs\nthrough instruction tuning, thereby enabling adaptability for various\ndownstream tasks. SA-MDKIF consists of two stages: skill training and skill\nadaptation. In the first stage, we define 12 basic medical skills and use\nAdaLoRA to train these skills based on uniformly formatted instructional\ndatasets that we have constructed. In the next stage, we train the skill router\nusing task-specific downstream data and use this router to integrate the\nacquired skills with LLMs during inference. Experimental results on 9 different\nmedical tasks show that SA-MDKIF improves performance by 10-20% compared to the\noriginal LLMs. Notably, this improvement is particularly pronounced for unseen\nmedical tasks, showing an improvement of up to 30%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00474v1",
    "published_date": "2024-02-01 10:26:27 UTC",
    "updated_date": "2024-02-01 10:26:27 UTC"
  },
  {
    "arxiv_id": "2402.00912v2",
    "title": "Can we Constrain Concept Bottleneck Models to Learn Semantically Meaningful Input Features?",
    "authors": [
      "Jack Furby",
      "Daniel Cunnington",
      "Dave Braines",
      "Alun Preece"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) are regarded as inherently interpretable\nbecause they first predict a set of human-defined concepts which are used to\npredict a task label. For inherent interpretability to be fully realised, and\nensure trust in a model's output, it's desirable for concept predictions to use\nsemantically meaningful input features. For instance, in an image, pixels\nrepresenting a broken bone should contribute to predicting a fracture. However,\ncurrent literature suggests that concept predictions often rely on irrelevant\ninput features. We hypothesise that this occurs when dataset labels include\ninaccurate concept annotations, or the relationship between input features and\nconcepts is unclear. In general, the effect of dataset labelling on concept\nrepresentations remains an understudied area. In this paper, we demonstrate\nthat CBMs can learn to map concepts to semantically meaningful input features,\nby utilising datasets with a clear link between the input features and the\ndesired concept predictions. This is achieved, for instance, by ensuring\nmultiple concepts do not always co-occur and, therefore provide a clear\ntraining signal for the CBM to distinguish the relevant input features for each\nconcept. We validate our hypothesis on both synthetic and real-world image\ndatasets, and demonstrate under the correct conditions, CBMs can learn to\nattribute semantically meaningful input features to the correct concept\npredictions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Main paper: 8 pages, 9 figures, Appendix: 14 pages, 21 figures. This\n  paper is a preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.00912v2",
    "published_date": "2024-02-01 10:18:43 UTC",
    "updated_date": "2024-07-30 09:49:51 UTC"
  },
  {
    "arxiv_id": "2402.00468v1",
    "title": "RadDQN: a Deep Q Learning-based Architecture for Finding Time-efficient Minimum Radiation Exposure Pathway",
    "authors": [
      "Biswajit Sadhu",
      "Trijit Sadhu",
      "S. Anand"
    ],
    "abstract": "Recent advancements in deep reinforcement learning (DRL) techniques have\nsparked its multifaceted applications in the automation sector. Managing\ncomplex decision-making problems with DRL encourages its use in the nuclear\nindustry for tasks such as optimizing radiation exposure to the personnel\nduring normal operating conditions and potential accidental scenarios. However,\nthe lack of efficient reward function and effective exploration strategy\nthwarted its implementation in the development of radiation-aware autonomous\nunmanned aerial vehicle (UAV) for achieving maximum radiation protection. Here,\nin this article, we address these intriguing issues and introduce a deep\nQ-learning based architecture (RadDQN) that operates on a radiation-aware\nreward function to provide time-efficient minimum radiation-exposure pathway in\na radiation zone. We propose a set of unique exploration strategies that\nfine-tune the extent of exploration and exploitation based on the state-wise\nvariation in radiation exposure during training. Further, we benchmark the\npredicted path with grid-based deterministic method. We demonstrate that the\nformulated reward function in conjugation with adequate exploration strategy is\neffective in handling several scenarios with drastically different radiation\nfield distributions. When compared to vanilla DQN, our model achieves a\nsuperior convergence rate and higher training stability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 7 main figures, code link (GitHub)",
    "pdf_url": "http://arxiv.org/pdf/2402.00468v1",
    "published_date": "2024-02-01 10:15:39 UTC",
    "updated_date": "2024-02-01 10:15:39 UTC"
  },
  {
    "arxiv_id": "2402.00459v1",
    "title": "Genetic-based Constraint Programming for Resource Constrained Job Scheduling",
    "authors": [
      "Su Nguyen",
      "Dhananjay Thiruvady",
      "Yuan Sun",
      "Mengjie Zhang"
    ],
    "abstract": "Resource constrained job scheduling is a hard combinatorial optimisation\nproblem that originates in the mining industry. Off-the-shelf solvers cannot\nsolve this problem satisfactorily in reasonable timeframes, while other\nsolution methods such as many evolutionary computation methods and\nmatheuristics cannot guarantee optimality and require low-level customisation\nand specialised heuristics to be effective. This paper addresses this gap by\nproposing a genetic programming algorithm to discover efficient search\nstrategies of constraint programming for resource-constrained job scheduling.\nIn the proposed algorithm, evolved programs represent variable selectors to be\nused in the search process of constraint programming, and their fitness is\ndetermined by the quality of solutions obtained for training instances. The\nnovelties of this algorithm are (1) a new representation of variable selectors,\n(2) a new fitness evaluation scheme, and (3) a pre-selection mechanism. Tests\nwith a large set of random and benchmark instances, the evolved variable\nselectors can significantly improve the efficiency of constraining programming.\nCompared to highly customised metaheuristics and hybrid algorithms, evolved\nvariable selectors can help constraint programming identify quality solutions\nfaster and proving optimality is possible if sufficiently large run-times are\nallowed. The evolved variable selectors are especially helpful when solving\ninstances with large numbers of machines.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00459v1",
    "published_date": "2024-02-01 09:57:38 UTC",
    "updated_date": "2024-02-01 09:57:38 UTC"
  },
  {
    "arxiv_id": "2402.00448v1",
    "title": "Dual-Student Knowledge Distillation Networks for Unsupervised Anomaly Detection",
    "authors": [
      "Liyi Yao",
      "Shaobing Gao"
    ],
    "abstract": "Due to the data imbalance and the diversity of defects, student-teacher\nnetworks (S-T) are favored in unsupervised anomaly detection, which explores\nthe discrepancy in feature representation derived from the knowledge\ndistillation process to recognize anomalies. However, vanilla S-T network is\nnot stable. Employing identical structures to construct the S-T network may\nweaken the representative discrepancy on anomalies. But using different\nstructures can increase the likelihood of divergent performance on normal data.\nTo address this problem, we propose a novel dual-student knowledge distillation\n(DSKD) architecture. Different from other S-T networks, we use two student\nnetworks a single pre-trained teacher network, where the students have the same\nscale but inverted structures. This framework can enhance the distillation\neffect to improve the consistency in recognition of normal data, and\nsimultaneously introduce diversity for anomaly representation. To explore\nhigh-dimensional semantic information to capture anomaly clues, we employ two\nstrategies. First, a pyramid matching mode is used to perform knowledge\ndistillation on multi-scale feature maps in the intermediate layers of\nnetworks. Second, an interaction is facilitated between the two student\nnetworks through a deep feature embedding module, which is inspired by\nreal-world group discussions. In terms of classification, we obtain pixel-wise\nanomaly segmentation maps by measuring the discrepancy between the output\nfeature maps of the teacher and student networks, from which an anomaly score\nis computed for sample-wise determination. We evaluate DSKD on three benchmark\ndatasets and probe the effects of internal modules through ablation\nexperiments. The results demonstrate that DSKD can achieve exceptional\nperformance on small models like ResNet18 and effectively improve vanilla S-T\nnetworks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00448v1",
    "published_date": "2024-02-01 09:32:39 UTC",
    "updated_date": "2024-02-01 09:32:39 UTC"
  },
  {
    "arxiv_id": "2402.00447v4",
    "title": "A Survey of Data-Efficient Graph Learning",
    "authors": [
      "Wei Ju",
      "Siyu Yi",
      "Yifan Wang",
      "Qingqing Long",
      "Junyu Luo",
      "Zhiping Xiao",
      "Ming Zhang"
    ],
    "abstract": "Graph-structured data, prevalent in domains ranging from social networks to\nbiochemical analysis, serve as the foundation for diverse real-world systems.\nWhile graph neural networks demonstrate proficiency in modeling this type of\ndata, their success is often reliant on significant amounts of labeled data,\nposing a challenge in practical scenarios with limited annotation resources. To\ntackle this problem, tremendous efforts have been devoted to enhancing graph\nmachine learning performance under low-resource settings by exploring various\napproaches to minimal supervision. In this paper, we introduce a novel concept\nof Data-Efficient Graph Learning (DEGL) as a research frontier, and present the\nfirst survey that summarizes the current progress of DEGL. We initiate by\nhighlighting the challenges inherent in training models with large labeled\ndata, paving the way for our exploration into DEGL. Next, we systematically\nreview recent advances on this topic from several key aspects, including\nself-supervised graph learning, semi-supervised graph learning, and few-shot\ngraph learning. Also, we state promising directions for future research,\ncontributing to the evolution of graph machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Proceedings of the Thirty-Third International Joint\n  Conference on Artificial Intelligence (IJCAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.00447v4",
    "published_date": "2024-02-01 09:28:48 UTC",
    "updated_date": "2024-06-19 14:34:24 UTC"
  },
  {
    "arxiv_id": "2402.00910v2",
    "title": "Addressing Bias Through Ensemble Learning and Regularized Fine-Tuning",
    "authors": [
      "Ahmed Radwan",
      "Layan Zaafarani",
      "Jetana Abudawood",
      "Faisal AlZahrani",
      "Fares Fourati"
    ],
    "abstract": "Addressing biases in AI models is crucial for ensuring fair and accurate\npredictions. However, obtaining large, unbiased datasets for training can be\nchallenging. This paper proposes a comprehensive approach using multiple\nmethods to remove bias in AI models, with only a small dataset and a\npotentially biased pretrained model. We train multiple models with the\ncounter-bias of the pre-trained model through data splitting, local training,\nand regularized fine-tuning, gaining potentially counter-biased models. Then,\nwe employ ensemble learning for all models to reach unbiased predictions. To\nfurther accelerate the inference time of our ensemble model, we conclude our\nsolution with knowledge distillation that results in a single unbiased neural\nnetwork. We demonstrate the effectiveness of our approach through experiments\non the CIFAR10 and HAM10000 datasets, showcasing promising results. This work\ncontributes to the ongoing effort to create more unbiased and reliable AI\nmodels, even with limited data availability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00910v2",
    "published_date": "2024-02-01 09:24:36 UTC",
    "updated_date": "2024-02-13 18:54:59 UTC"
  },
  {
    "arxiv_id": "2402.00435v2",
    "title": "A practical existence theorem for reduced order models based on convolutional autoencoders",
    "authors": [
      "Nicola Rares Franco",
      "Simone Brugiapaglia"
    ],
    "abstract": "In recent years, deep learning has gained increasing popularity in the fields\nof Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM),\nproviding domain practitioners with new powerful data-driven techniques such as\nPhysics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator\nNetworks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context,\ndeep autoencoders based on Convolutional Neural Networks (CNNs) have proven\nextremely effective, outperforming established techniques, such as the reduced\nbasis method, when dealing with complex nonlinear problems. However, despite\nthe empirical success of CNN-based autoencoders, there are only a few\ntheoretical results supporting these architectures, usually stated in the form\nof universal approximation theorems. In particular, although the existing\nliterature provides users with guidelines for designing convolutional\nautoencoders, the subsequent challenge of learning the latent features has been\nbarely investigated. Furthermore, many practical questions remain unanswered,\ne.g., the number of snapshots needed for convergence or the neural network\ntraining strategy. In this work, using recent techniques from sparse\nhigh-dimensional function approximation, we fill some of these gaps by\nproviding a new practical existence theorem for CNN-based autoencoders when the\nparameter-to-solution map is holomorphic. This regularity assumption arises in\nmany relevant classes of parametric PDEs, such as the parametric diffusion\nequation, for which we discuss an explicit application of our general theory.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00435v2",
    "published_date": "2024-02-01 09:01:58 UTC",
    "updated_date": "2024-06-24 15:42:52 UTC"
  },
  {
    "arxiv_id": "2402.00414v1",
    "title": "Prompt-Time Symbolic Knowledge Capture with Large Language Models",
    "authors": [
      "Tolga Çöplü",
      "Arto Bendiken",
      "Andrii Skomorokhov",
      "Eduard Bateiko",
      "Stephen Cobb",
      "Joshua J. Bouw"
    ],
    "abstract": "Augmenting large language models (LLMs) with user-specific knowledge is\ncrucial for real-world applications, such as personal AI assistants. However,\nLLMs inherently lack mechanisms for prompt-driven knowledge capture. This paper\ninvestigates utilizing the existing LLM capabilities to enable prompt-driven\nknowledge capture, with a particular emphasis on knowledge graphs. We address\nthis challenge by focusing on prompt-to-triple (P2T) generation. We explore\nthree methods: zero-shot prompting, few-shot prompting, and fine-tuning, and\nthen assess their performance via a specialized synthetic dataset. Our code and\ndatasets are publicly available at https://github.com/HaltiaAI/paper-PTSKC.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, 1 table preprint. Under review",
    "pdf_url": "http://arxiv.org/pdf/2402.00414v1",
    "published_date": "2024-02-01 08:15:28 UTC",
    "updated_date": "2024-02-01 08:15:28 UTC"
  },
  {
    "arxiv_id": "2402.00412v1",
    "title": "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection",
    "authors": [
      "Xinlin Peng",
      "Ying Zhou",
      "Ben He",
      "Le Sun",
      "Yingfei Sun"
    ],
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in text\ngeneration tasks. However, the utilization of these models carries inherent\nrisks, including but not limited to plagiarism, the dissemination of fake news,\nand issues in educational exercises. Although several detectors have been\nproposed to address these concerns, their effectiveness against adversarial\nperturbations, specifically in the context of student essay writing, remains\nlargely unexplored. This paper aims to bridge this gap by constructing\nAIG-ASAP, an AI-generated student essay dataset, employing a range of text\nperturbation methods that are expected to generate high-quality essays while\nevading detection. Through empirical experiments, we assess the performance of\ncurrent AIGC detectors on the AIG-ASAP dataset. The results reveal that the\nexisting detectors can be easily circumvented using straightforward automatic\nadversarial attacks. Specifically, we explore word substitution and sentence\nsubstitution perturbation methods that effectively evade detection while\nmaintaining the quality of the generated essays. This highlights the urgent\nneed for more accurate and robust methods to detect AI-generated student essays\nin the education domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2023 Main conference, Oral Presentation",
    "pdf_url": "http://arxiv.org/pdf/2402.00412v1",
    "published_date": "2024-02-01 08:11:56 UTC",
    "updated_date": "2024-02-01 08:11:56 UTC"
  },
  {
    "arxiv_id": "2402.00411v2",
    "title": "LM-HT SNN: Enhancing the Performance of SNN to ANN Counterpart through Learnable Multi-hierarchical Threshold Model",
    "authors": [
      "Zecheng Hao",
      "Xinyu Shi",
      "Yujia Liu",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "abstract": "Compared to traditional Artificial Neural Network (ANN), Spiking Neural\nNetwork (SNN) has garnered widespread academic interest for its intrinsic\nability to transmit information in a more energy-efficient manner. However,\ndespite previous efforts to optimize the learning algorithm of SNNs through\nvarious methods, SNNs still lag behind ANNs in terms of performance. The\nrecently proposed multi-threshold model provides more possibilities for further\nenhancing the learning capability of SNNs. In this paper, we rigorously analyze\nthe relationship among the multi-threshold model, vanilla spiking model and\nquantized ANNs from a mathematical perspective, then propose a novel LM-HT\nmodel, which is an equidistant multi-threshold model that can dynamically\nregulate the global input current and membrane potential leakage on the time\ndimension. The LM-HT model can also be transformed into a vanilla single\nthreshold model through reparameterization, thereby achieving more flexible\nhardware deployment. In addition, we note that the LM-HT model can seamlessly\nintegrate with ANN-SNN Conversion framework under special initialization. This\nnovel hybrid learning framework can effectively improve the relatively poor\nperformance of converted SNNs under low time latency. Extensive experimental\nresults have demonstrated that our model can outperform previous\nstate-of-the-art works on various types of datasets, which promote SNNs to\nachieve a brand-new level of performance comparable to quantized ANNs. Code is\navailable at https://github.com/hzc1208/LMHT_SNN.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00411v2",
    "published_date": "2024-02-01 08:10:39 UTC",
    "updated_date": "2024-10-09 02:56:46 UTC"
  },
  {
    "arxiv_id": "2402.00402v1",
    "title": "Investigating Bias Representations in Llama 2 Chat via Activation Steering",
    "authors": [
      "Dawn Lu",
      "Nina Rimsky"
    ],
    "abstract": "We address the challenge of societal bias in Large Language Models (LLMs),\nfocusing on the Llama 2 7B Chat model. As LLMs are increasingly integrated into\ndecision-making processes with substantial societal impact, it becomes\nimperative to ensure these models do not reinforce existing biases. Our\napproach employs activation steering to probe for and mitigate biases related\nto gender, race, and religion. This method manipulates model activations to\ndirect responses towards or away from biased outputs, utilizing steering\nvectors derived from the StereoSet dataset and custom GPT4 generated gender\nbias prompts. Our findings reveal inherent gender bias in Llama 2 7B Chat,\npersisting even after Reinforcement Learning from Human Feedback (RLHF). We\nalso observe a predictable negative correlation between bias and the model's\ntendency to refuse responses. Significantly, our study uncovers that RLHF tends\nto increase the similarity in the model's representation of different forms of\nsocietal biases, which raises questions about the model's nuanced understanding\nof different forms of bias. This work also provides valuable insights into\neffective red-teaming strategies for LLMs using activation steering,\nparticularly emphasizing the importance of integrating a refusal vector.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00402v1",
    "published_date": "2024-02-01 07:48:50 UTC",
    "updated_date": "2024-02-01 07:48:50 UTC"
  },
  {
    "arxiv_id": "2402.00397v2",
    "title": "Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting",
    "authors": [
      "Zhanyu Liu",
      "Guanjie Zheng",
      "Yanwei Yu"
    ],
    "abstract": "Traffic forecasting is crucial for intelligent transportation systems (ITS),\naiding in efficient resource allocation and effective traffic control. However,\nits effectiveness often relies heavily on abundant traffic data, while many\ncities lack sufficient data due to limited device support, posing a significant\nchallenge for traffic forecasting. Recognizing this challenge, we have made a\nnoteworthy observation: traffic patterns exhibit similarities across diverse\ncities. Building on this key insight, we propose a solution for the cross-city\nfew-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank\n(MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich\nsource cities, effectively acquiring comprehensive traffic knowledge through a\nspatial-temporal-aware pre-training process. Subsequently, the framework\nemploys advanced clustering techniques to systematically generate a multi-scale\ntraffic pattern bank derived from the learned knowledge. Next, the traffic data\nof the data-scarce target city could query the traffic pattern bank,\nfacilitating the aggregation of meta-knowledge. This meta-knowledge, in turn,\nassumes a pivotal role as a robust guide in subsequent processes involving\ngraph reconstruction and forecasting. Empirical assessments conducted on\nreal-world traffic datasets affirm the superior performance of MTPB, surpassing\nexisting methods across various categories and exhibiting numerous attributes\nconducive to the advancement of cross-city few-shot forecasting methodologies.\nThe code is available in https://github.com/zhyliu00/MTPB.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review. Text overlap with arXiv:2308.09727",
    "pdf_url": "http://arxiv.org/pdf/2402.00397v2",
    "published_date": "2024-02-01 07:33:31 UTC",
    "updated_date": "2024-02-26 12:55:02 UTC"
  },
  {
    "arxiv_id": "2402.00396v2",
    "title": "Efficient Exploration for LLMs",
    "authors": [
      "Vikranth Dwaracherla",
      "Seyed Mohammad Asghari",
      "Botao Hao",
      "Benjamin Van Roy"
    ],
    "abstract": "We present evidence of substantial benefit from efficient exploration in\ngathering human feedback to improve large language models. In our experiments,\nan agent sequentially generates queries while fitting a reward model to the\nfeedback received. Our best-performing agent generates queries using double\nThompson sampling, with uncertainty represented by an epistemic neural network.\nOur results demonstrate that efficient exploration enables high levels of\nperformance with far fewer queries. Further, both uncertainty estimation and\nthe choice of exploration scheme play critical roles.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00396v2",
    "published_date": "2024-02-01 07:32:24 UTC",
    "updated_date": "2024-06-04 18:35:09 UTC"
  },
  {
    "arxiv_id": "2402.00393v1",
    "title": "Loss Function Considering Dead Zone for Neural Networks",
    "authors": [
      "Koki Inami",
      "Koki Yamane",
      "Sho Sakaino"
    ],
    "abstract": "It is important to reveal the inverse dynamics of manipulators to improve\ncontrol performance of model-based control. Neural networks (NNs) are promising\ntechniques to represent complicated inverse dynamics while they require a large\namount of motion data. However, motion data in dead zones of actuators is not\nsuitable for training models decreasing the number of useful training data. In\nthis study, based on the fact that the manipulator joint does not work\nirrespective of input torque in dead zones, we propose a new loss function that\nconsiders only errors of joints not in dead zones. The proposed method enables\nto increase in the amount of motion data available for training and the\naccuracy of the inverse dynamics computation. Experiments on actual equipment\nusing a three-degree-of-freedom (DOF) manipulator showed higher accuracy than\nconventional methods. We also confirmed and discussed the behavior of the model\nof the proposed method in dead zones.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 6 figures, Accepted at AMC2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00393v1",
    "published_date": "2024-02-01 07:28:55 UTC",
    "updated_date": "2024-02-01 07:28:55 UTC"
  },
  {
    "arxiv_id": "2402.00390v2",
    "title": "DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems",
    "authors": [
      "Sheng Zhang",
      "Maolin Wang",
      "Yao Zhao",
      "Chenyi Zhuang",
      "Jinjie Gu",
      "Ruocheng Guo",
      "Xiangyu Zhao",
      "Zijian Zhang",
      "Hongzhi Yin"
    ],
    "abstract": "In the era of data proliferation, efficiently sifting through vast\ninformation to extract meaningful insights has become increasingly crucial.\nThis paper addresses the computational overhead and resource inefficiency\nprevalent in existing Sequential Recommender Systems (SRSs). We introduce an\ninnovative approach combining pruning methods with advanced model designs.\nFurthermore, we delve into resource-constrained Neural Architecture Search\n(NAS), an emerging technique in recommender systems, to optimize models in\nterms of FLOPs, latency, and energy consumption while maintaining or enhancing\naccuracy. Our principal contribution is the development of a Data-aware Neural\nArchitecture Search for Recommender System (DNS-Rec). DNS-Rec is specifically\ndesigned to tailor compact network architectures for attention-based SRS\nmodels, thereby ensuring accuracy retention. It incorporates data-aware gates\nto enhance the performance of the recommendation network by learning\ninformation from historical user-item interactions. Moreover, DNS-Rec employs a\ndynamic resource constraint strategy, stabilizing the search process and\nyielding more suitable architectural solutions. We demonstrate the\neffectiveness of our approach through rigorous experiments conducted on three\nbenchmark datasets, which highlight the superiority of DNS-Rec in SRSs. Our\nfindings set a new standard for future research in efficient and accurate\nrecommendation systems, marking a significant step forward in this rapidly\nevolving field.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00390v2",
    "published_date": "2024-02-01 07:22:52 UTC",
    "updated_date": "2024-12-19 14:28:19 UTC"
  },
  {
    "arxiv_id": "2402.00389v5",
    "title": "On the $O(\\frac{\\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\\ell_1$ Norm",
    "authors": [
      "Huan Li",
      "Yiming Dong",
      "Zhouchen Lin"
    ],
    "abstract": "Although adaptive gradient methods have been extensively used in deep\nlearning, their convergence rates proved in the literature are all slower than\nthat of SGD, particularly with respect to their dependence on the dimension.\nThis paper considers the classical RMSProp and its momentum extension and\nestablishes the convergence rate of $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla\nf(x^k)\\|_1\\right]\\leq O(\\frac{\\sqrt{d}C}{T^{1/4}})$ measured by $\\ell_1$ norm\nwithout the bounded gradient assumption, where $d$ is the dimension of the\noptimization variable, $T$ is the iteration number, and $C$ is a constant\nidentical to that appeared in the optimal convergence rate of SGD. Our\nconvergence rate matches the lower bound with respect to all the coefficients\nexcept the dimension $d$. Since $\\|x\\|_2\\ll\\|x\\|_1\\leq\\sqrt{d}\\|x\\|_2$ for\nproblems with extremely large $d$, our convergence rate can be considered to be\nanalogous to the $\\frac{1}{T}\\sum_{k=1}^T E\\left[\\|\\nabla f(x^k)\\|_2\\right]\\leq\nO(\\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\\|\\nabla\nf(x)\\|_1=\\varTheta(\\sqrt{d}\\|\\nabla f(x)\\|_2)$.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "V5 vs V4: Improve the noise dependence from $\\sqrt{d}\\|\\sigma\\|_2$ to\n  $\\|\\sigma\\|_1$ and modify the related work. V4 vs V3: More experiments. V3 vs\n  V2: A fairer comparison with (Li et al., 2023). V2 vs V1: (1) Correct one\n  error in v1. (2) Improve the convergence rate matching the lower bound with\n  respect to all the coefficients except the dimension",
    "pdf_url": "http://arxiv.org/pdf/2402.00389v5",
    "published_date": "2024-02-01 07:21:32 UTC",
    "updated_date": "2025-04-26 01:34:06 UTC"
  },
  {
    "arxiv_id": "2402.00388v1",
    "title": "Cumulative Distribution Function based General Temporal Point Processes",
    "authors": [
      "Maolin Wang",
      "Yu Pan",
      "Zenglin Xu",
      "Ruocheng Guo",
      "Xiangyu Zhao",
      "Wanyu Wang",
      "Yiqi Wang",
      "Zitao Liu",
      "Langming Liu"
    ],
    "abstract": "Temporal Point Processes (TPPs) hold a pivotal role in modeling event\nsequences across diverse domains, including social networking and e-commerce,\nand have significantly contributed to the advancement of recommendation systems\nand information retrieval strategies. Through the analysis of events such as\nuser interactions and transactions, TPPs offer valuable insights into\nbehavioral patterns, facilitating the prediction of future trends. However,\naccurately forecasting future events remains a formidable challenge due to the\nintricate nature of these patterns. The integration of Neural Networks with\nTPPs has ushered in the development of advanced deep TPP models. While these\nmodels excel at processing complex and nonlinear temporal data, they encounter\nlimitations in modeling intensity functions, grapple with computational\ncomplexities in integral computations, and struggle to capture long-range\ntemporal dependencies effectively. In this study, we introduce the CuFun model,\nrepresenting a novel approach to TPPs that revolves around the Cumulative\nDistribution Function (CDF). CuFun stands out by uniquely employing a monotonic\nneural network for CDF representation, utilizing past events as a scaling\nfactor. This innovation significantly bolsters the model's adaptability and\nprecision across a wide range of data scenarios. Our approach addresses several\ncritical issues inherent in traditional TPP modeling: it simplifies\nlog-likelihood calculations, extends applicability beyond predefined density\nfunction forms, and adeptly captures long-range temporal patterns. Our\ncontributions encompass the introduction of a pioneering CDF-based TPP model,\nthe development of a methodology for incorporating past event information into\nfuture event prediction, and empirical validation of CuFun's effectiveness\nthrough extensive experimentation on synthetic and real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00388v1",
    "published_date": "2024-02-01 07:21:30 UTC",
    "updated_date": "2024-02-01 07:21:30 UTC"
  },
  {
    "arxiv_id": "2402.01771v1",
    "title": "BlackMamba: Mixture of Experts for State-Space Models",
    "authors": [
      "Quentin Anthony",
      "Yury Tokpanov",
      "Paolo Glorioso",
      "Beren Millidge"
    ],
    "abstract": "State-space models (SSMs) have recently demonstrated competitive performance\nto transformers at large-scale language modeling benchmarks while achieving\nlinear time and memory complexity as a function of sequence length. Mamba, a\nrecently released SSM model, shows impressive performance in both language\nmodeling and long sequence processing tasks. Simultaneously, mixture-of-expert\n(MoE) models have shown remarkable performance while significantly reducing the\ncompute and latency costs of inference at the expense of a larger memory\nfootprint. In this paper, we present BlackMamba, a novel architecture that\ncombines the Mamba SSM with MoE to obtain the benefits of both. We demonstrate\nthat BlackMamba performs competitively against both Mamba and transformer\nbaselines, and outperforms in inference and training FLOPs. We fully train and\nopen-source 340M/1.5B and 630M/2.8B BlackMamba models on 300B tokens of a\ncustom dataset. We show that BlackMamba inherits and combines both of the\nbenefits of SSM and MoE architectures, combining linear-complexity generation\nfrom SSM with cheap and fast inference from MoE. We release all weights,\ncheckpoints, and inference code open-source. Inference code at:\nhttps://github.com/Zyphra/BlackMamba",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01771v1",
    "published_date": "2024-02-01 07:15:58 UTC",
    "updated_date": "2024-02-01 07:15:58 UTC"
  },
  {
    "arxiv_id": "2402.00366v1",
    "title": "Legged Robot State Estimation With Invariant Extended Kalman Filter Using Neural Measurement Network",
    "authors": [
      "Donghoon Youm",
      "Hyunsik Oh",
      "Suyoung Choi",
      "Hyeongjun Kim",
      "Jemin Hwangbo"
    ],
    "abstract": "This paper introduces a novel proprioceptive state estimator for legged\nrobots that combines model-based filters and deep neural networks. Recent\nstudies have shown that neural networks such as multi-layer perceptron or\nrecurrent neural networks can estimate the robot states, including contact\nprobability and linear velocity. Inspired by this, we develop a state\nestimation framework that integrates a neural measurement network (NMN) with an\ninvariant extended Kalman filter. We show that our framework improves\nestimation performance in various terrains. Existing studies that combine\nmodel-based filters and learning-based approaches typically use real-world\ndata. However, our approach relies solely on simulation data, as it allows us\nto easily obtain extensive data. This difference leads to a gap between the\nlearning and the inference domain, commonly referred to as a sim-to-real gap.\nWe address this challenge by adapting existing learning techniques and\nregularization. To validate our proposed method, we conduct experiments using a\nquadruped robot on four types of terrain: \\textit{flat}, \\textit{debris},\n\\textit{soft}, and \\textit{slippery}. We observe that our approach\nsignificantly reduces position drift compared to the existing model-based state\nestimator.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8pages, 6paper, This work has been submitted to the IEEE for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2402.00366v1",
    "published_date": "2024-02-01 06:06:59 UTC",
    "updated_date": "2024-02-01 06:06:59 UTC"
  },
  {
    "arxiv_id": "2402.00362v1",
    "title": "Climate Trends of Tropical Cyclone Intensity and Energy Extremes Revealed by Deep Learning",
    "authors": [
      "Buo-Fu Chen",
      "Boyo Chen",
      "Chun-Min Hsiao",
      "Hsu-Feng Teng",
      "Cheng-Shang Lee",
      "Hung-Chi Kuo"
    ],
    "abstract": "Anthropogenic influences have been linked to tropical cyclone (TC) poleward\nmigration, TC extreme precipitation, and an increased proportion of major\nhurricanes [1, 2, 3, 4]. Understanding past TC trends and variability is\ncritical for projecting future TC impacts on human society considering the\nchanging climate [5]. However, past trends of TC structure/energy remain\nuncertain due to limited observations; subjective-analyzed and\nspatiotemporal-heterogeneous \"best-track\" datasets lead to reduced confidence\nin the assessed TC repose to climate change [6, 7]. Here, we use deep learning\nto reconstruct past \"observations\" and yield an objective global TC wind\nprofile dataset during 1981 to 2020, facilitating a comprehensive examination\nof TC structure/energy. By training with uniquely labeled data integrating best\ntracks and numerical model analysis of 2004 to 2018 TCs, our model converts\nmultichannel satellite imagery to a 0-750-km wind profile of axisymmetric\nsurface winds. The model performance is verified to be sufficient for climate\nstudies by comparing it to independent satellite-radar surface winds. Based on\nthe new homogenized dataset, the major TC proportion has increased by ~13% in\nthe past four decades. Moreover, the proportion of extremely high-energy TCs\nhas increased by ~25%, along with an increasing trend (> one standard deviation\nof the 40-y variability) of the mean total energy of high-energy TCs. Although\nthe warming ocean favors TC intensification, the TC track migration to higher\nlatitudes and altered environments further affect TC structure/energy. This new\ndeep learning method/dataset reveals novel trends regarding TC structure\nextremes and may help verify simulations/studies regarding TCs in the changing\nclimate.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "41 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.00362v1",
    "published_date": "2024-02-01 06:02:29 UTC",
    "updated_date": "2024-02-01 06:02:29 UTC"
  },
  {
    "arxiv_id": "2402.00355v1",
    "title": "Adaptive Primal-Dual Method for Safe Reinforcement Learning",
    "authors": [
      "Weiqin Chen",
      "James Onyejizu",
      "Long Vu",
      "Lan Hoang",
      "Dharmashankar Subramanian",
      "Koushik Kar",
      "Sandipan Mishra",
      "Santiago Paternain"
    ],
    "abstract": "Primal-dual methods have a natural application in Safe Reinforcement Learning\n(SRL), posed as a constrained policy optimization problem. In practice however,\napplying primal-dual methods to SRL is challenging, due to the inter-dependency\nof the learning rate (LR) and Lagrangian multipliers (dual variables) each time\nan embedded unconstrained RL problem is solved. In this paper, we propose,\nanalyze and evaluate adaptive primal-dual (APD) methods for SRL, where two\nadaptive LRs are adjusted to the Lagrangian multipliers so as to optimize the\npolicy in each iteration. We theoretically establish the convergence,\noptimality and feasibility of the APD algorithm. Finally, we conduct numerical\nevaluation of the practical APD algorithm with four well-known environments in\nBullet-Safey-Gym employing two state-of-the-art SRL algorithms: PPO-Lagrangian\nand DDPG-Lagrangian. All experiments show that the practical APD algorithm\noutperforms (or achieves comparable performance) and attains more stable\ntraining than the constant LR cases. Additionally, we substantiate the\nrobustness of selecting the two adaptive LRs by empirical evidence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00355v1",
    "published_date": "2024-02-01 05:53:44 UTC",
    "updated_date": "2024-02-01 05:53:44 UTC"
  },
  {
    "arxiv_id": "2402.01770v1",
    "title": "Extending Interactive Science Exhibits into the Classroom using Anthropomorphized Chatbots and Bloom's Taxonomy",
    "authors": [
      "Yousuf Golding"
    ],
    "abstract": "This study explores the use of Generative AI chatbots for transforming public\nscience exhibits into virtual experiences that can extend the engagement of\nexhibits into the classroom. The broader goal is to increase accessibility of\nscience exhibits, especially for those marginalized in STEM due to various\nfactors, including cultural barriers. We hypothesize that turning exhibits into\nfirst-person anthropomorphized chatbots with a personality, like quirky-talking\nasteroids or comets, can increase engagement and learning. The paper mainly\nexplores if such techniques are possible using Generative AI (e.g. GPT) via\nprompt engineering alone. The research includes an investigation into the\npossibility of integrating interactive assessment via question-generation using\nBloom's Taxonomy. Initial results indicate that it is possible to combine these\ntechniques. As such, it lays a foundation for future classroom evaluations of\nsuch chatbots to gauge their overall efficacy in extending the reach of science\nexhibitions. The paper concludes by discussing extensions of the research to\nfully evaluate effectiveness in virtual field-trips. We also include a brief\nexamination of additional ways to enhance student motivation towards learning\nvia chatbots.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01770v1",
    "published_date": "2024-02-01 05:49:54 UTC",
    "updated_date": "2024-02-01 05:49:54 UTC"
  },
  {
    "arxiv_id": "2402.00350v2",
    "title": "Large Language Models Based Fuzzing Techniques: A Survey",
    "authors": [
      "Linghan Huang",
      "Peizhou Zhao",
      "Huaming Chen",
      "Lei Ma"
    ],
    "abstract": "In the modern era where software plays a pivotal role, software security and\nvulnerability analysis have become essential for software development. Fuzzing\ntest, as an efficient software testing method, are widely used in various\ndomains. Moreover, the rapid development of Large Language Models (LLMs) has\nfacilitated their application in the field of software testing, demonstrating\nremarkable performance. Considering that existing fuzzing test techniques are\nnot entirely automated and software vulnerabilities continue to evolve, there\nis a growing trend towards employing fuzzing test generated based on large\nlanguage models. This survey provides a systematic overview of the approaches\nthat fuse LLMs and fuzzing tests for software testing. In this paper, a\nstatistical analysis and discussion of the literature in three areas, namely\nLLMs, fuzzing test, and fuzzing test generated based on LLMs, are conducted by\nsummarising the state-of-the-art methods up until 2024. Our survey also\ninvestigates the potential for widespread deployment and application of fuzzing\ntest techniques generated by LLMs in the future.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages submission under review",
    "pdf_url": "http://arxiv.org/pdf/2402.00350v2",
    "published_date": "2024-02-01 05:34:03 UTC",
    "updated_date": "2024-02-07 06:03:15 UTC"
  },
  {
    "arxiv_id": "2402.00348v1",
    "title": "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update",
    "authors": [
      "Liyuan Mao",
      "Haoran Xu",
      "Weinan Zhang",
      "Xianyuan Zhan"
    ],
    "abstract": "In this study, we investigate the DIstribution Correction Estimation (DICE)\nmethods, an important line of work in offline reinforcement learning (RL) and\nimitation learning (IL). DICE-based methods impose state-action-level behavior\nconstraint, which is an ideal choice for offline learning. However, they\ntypically perform much worse than current state-of-the-art (SOTA) methods that\nsolely use action-level behavior constraint. After revisiting DICE-based\nmethods, we find there exist two gradient terms when learning the value\nfunction using true-gradient update: forward gradient (taken on the current\nstate) and backward gradient (taken on the next state). Using forward gradient\nbears a large similarity to many offline RL methods, and thus can be regarded\nas applying action-level constraint. However, directly adding the backward\ngradient may degenerate or cancel out its effect if these two gradients have\nconflicting directions. To resolve this issue, we propose a simple yet\neffective modification that projects the backward gradient onto the normal\nplane of the forward gradient, resulting in an orthogonal-gradient update, a\nnew learning rule for DICE-based methods. We conduct thorough theoretical\nanalyses and find that the projected backward gradient brings state-level\nbehavior regularization, which reveals the mystery of DICE-based methods: the\nvalue learning objective does try to impose state-action-level constraint, but\nneeds to be used in a corrected way. Through toy examples and extensive\nexperiments on complex offline RL and IL tasks, we demonstrate that DICE-based\nmethods using orthogonal-gradient updates (O-DICE) achieve SOTA performance and\ngreat robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlight @ ICLR 2024, first two authors contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2402.00348v1",
    "published_date": "2024-02-01 05:30:51 UTC",
    "updated_date": "2024-02-01 05:30:51 UTC"
  },
  {
    "arxiv_id": "2402.00334v1",
    "title": "Multi-agent Path Finding for Cooperative Autonomous Driving",
    "authors": [
      "Zhongxia Yan",
      "Han Zheng",
      "Cathy Wu"
    ],
    "abstract": "Anticipating possible future deployment of connected and automated vehicles\n(CAVs), cooperative autonomous driving at intersections has been studied by\nmany works in control theory and intelligent transportation across decades.\nSimultaneously, recent parallel works in robotics have devised efficient\nalgorithms for multi-agent path finding (MAPF), though often in environments\nwith simplified kinematics. In this work, we hybridize insights and algorithms\nfrom MAPF with the structure and heuristics of optimizing the crossing order of\nCAVs at signal-free intersections. We devise an optimal and complete algorithm,\nOrder-based Search with Kinematics Arrival Time Scheduling (OBS-KATS), which\nsignificantly outperforms existing algorithms, fixed heuristics, and\nprioritized planning with KATS. The performance is maintained under different\nvehicle arrival rates, lane lengths, crossing speeds, and control horizon.\nThrough ablations and dissections, we offer insight on the contributing factors\nto OBS-KATS's performance. Our work is directly applicable to many similarly\nscaled traffic and multi-robot scenarios with directed lanes.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "7 pages, 3 figures, IEEE International Conference on Robotics and\n  Automation (ICRA), 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00334v1",
    "published_date": "2024-02-01 04:39:15 UTC",
    "updated_date": "2024-02-01 04:39:15 UTC"
  },
  {
    "arxiv_id": "2402.00319v1",
    "title": "SCO-VIST: Social Interaction Commonsense Knowledge-based Visual Storytelling",
    "authors": [
      "Eileen Wang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "abstract": "Visual storytelling aims to automatically generate a coherent story based on\na given image sequence. Unlike tasks like image captioning, visual stories\nshould contain factual descriptions, worldviews, and human social commonsense\nto put disjointed elements together to form a coherent and engaging\nhuman-writeable story. However, most models mainly focus on applying factual\ninformation and using taxonomic/lexical external knowledge when attempting to\ncreate stories. This paper introduces SCO-VIST, a framework representing the\nimage sequence as a graph with objects and relations that includes human action\nmotivation and its social interaction commonsense knowledge. SCO-VIST then\ntakes this graph representing plot points and creates bridges between plot\npoints with semantic and occurrence-based edge weights. This weighted story\ngraph produces the storyline in a sequence of events using Floyd-Warshall's\nalgorithm. Our proposed framework produces stories superior across multiple\nmetrics in terms of visual grounding, coherence, diversity, and humanness, per\nboth automatic and human evaluations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00319v1",
    "published_date": "2024-02-01 04:09:17 UTC",
    "updated_date": "2024-02-01 04:09:17 UTC"
  },
  {
    "arxiv_id": "2404.16840v1",
    "title": "Biometrics Employing Neural Network",
    "authors": [
      "Sajjad Bhuiyan"
    ],
    "abstract": "Biometrics involves using unique human traits, both physical and behavioral,\nfor the digital identification of individuals to provide access to systems,\ndevices, or information. Within the field of computer science, it acts as a\nmethod for identifying and verifying individuals and controlling access. While\nthe conventional method for personal authentication involves passwords, the\nvulnerability arises when passwords are compromised, allowing unauthorized\naccess to sensitive actions. Biometric authentication presents a viable answer\nto this problem and is the most secure and user-friendly authentication method.\nToday, fingerprints, iris and retina patterns, facial recognition, hand shapes,\npalm prints, and voice recognition are frequently used forms of biometrics.\nDespite the diverse nature of these biometric identifiers, the core objective\nremains consistent ensuring security, recognizing authorized users, and\nrejecting impostors. Hence, it is crucial to determine accurately whether the\ncharacteristics belong to the rightful person. For systems to be effective and\nwidely accepted, the error rate in recognition and verification must approach\nzero. It is acknowledged that current biometric techniques, while advanced, are\nnot infallible and require continuous improvement. A more refined classifier is\ndeemed necessary to classify patterns accurately. Artificial Neural Networks,\nwhich simulate the human brain's operations, present themselves as a promising\napproach. The survey presented herein explores various biometric techniques\nbased on neural networks, emphasizing the ongoing quest for enhanced accuracy\nand reliability. It concludes that The utilization of neural networks along\nwith biometric features not only enhances accuracy but also contributes to\noverall better security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "F.2.2, I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "14 Pages, 10 figures, Survey Paper",
    "pdf_url": "http://arxiv.org/pdf/2404.16840v1",
    "published_date": "2024-02-01 03:59:04 UTC",
    "updated_date": "2024-02-01 03:59:04 UTC"
  },
  {
    "arxiv_id": "2402.00312v1",
    "title": "The whack-a-mole governance challenge for AI-enabled synthetic biology: literature review and emerging frameworks",
    "authors": [
      "Trond Arne Undheim"
    ],
    "abstract": "AI-enabled synthetic biology has tremendous potential but also significantly\nincreases biorisks and brings about a new set of dual use concerns. The picture\nis complicated given the vast innovations envisioned to emerge by combining\nemerging technologies, as AI-enabled synthetic biology potentially scales up\nbioengineering into industrial biomanufacturing. However, the literature review\nindicates that goals such as maintaining a reasonable scope for innovation, or\nmore ambitiously to foster a huge bioeconomy don't necessarily contrast with\nbiosafety, but need to go hand in hand. This paper presents a literature review\nof the issues and describes emerging frameworks for policy and practice that\ntransverse the options of command-and control, stewardship, bottom-up, and\nlaissez-faire governance. How to achieve early warning systems that enable\nprevention and mitigation of future AI-enabled biohazards from the lab, from\ndeliberate misuse, or from the public realm, will constantly need to evolve,\nand adaptive, interactive approaches should emerge. Although biorisk is subject\nto an established governance regime, and scientists generally adhere to\nbiosafety protocols, even experimental, but legitimate use by scientists could\nlead to unexpected developments. Recent advances in chatbots enabled by\ngenerative AI have revived fears that advanced biological insight can more\neasily get into the hands of malignant individuals or organizations. Given\nthese sets of issues, society needs to rethink how AI-enabled synthetic biology\nshould be governed. The suggested way to visualize the challenge at hand is\nwhack-a-mole governance, although the emerging solutions are perhaps not so\ndifferent either.",
    "categories": [
      "q-bio.OT",
      "cs.AI"
    ],
    "primary_category": "q-bio.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00312v1",
    "published_date": "2024-02-01 03:53:13 UTC",
    "updated_date": "2024-02-01 03:53:13 UTC"
  },
  {
    "arxiv_id": "2402.00306v2",
    "title": "An Accurate and Low-Parameter Machine Learning Architecture for Next Location Prediction",
    "authors": [
      "Calvin Jary",
      "Nafiseh Kahani"
    ],
    "abstract": "Next location prediction is a discipline that involves predicting a users\nnext location. Its applications include resource allocation, quality of\nservice, energy efficiency, and traffic management. This paper proposes an\nenergy-efficient, small, and low parameter machine learning (ML) architecture\nfor accurate next location prediction, deployable on modest base stations and\nedge devices. To accomplish this we ran a hundred hyperparameter experiments on\nthe full human mobility patterns of an entire city, to determine an exact ML\narchitecture that reached a plateau of accuracy with the least amount of model\nparameters. We successfully achieved a reduction in the number of model\nparameters within published ML architectures from 202 million down to 2\nmillion. This reduced the total size of the model parameters from 791 MB down\nto 8 MB. Additionally, this decreased the training time by a factor of four,\nthe amount of graphics processing unit (GPU) memory needed for training by a\nfactor of twenty, and the overall accuracy was increased from 80.16% to 82.54%.\nThis improvement allows for modest base stations and edge devices which do not\nhave a large amount of memory or storage, to deploy and utilize the proposed ML\narchitecture for next location prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper was accepted and presented in person at the 2023 IEEE Future\n  Networks World Forum, in Baltimore, Maryland, USA",
    "pdf_url": "http://arxiv.org/pdf/2402.00306v2",
    "published_date": "2024-02-01 03:39:15 UTC",
    "updated_date": "2024-02-02 17:29:21 UTC"
  },
  {
    "arxiv_id": "2402.01769v1",
    "title": "Redefining \"Hallucination\" in LLMs: Towards a psychology-informed framework for mitigating misinformation",
    "authors": [
      "Elijah Berberette",
      "Jack Hutchins",
      "Amir Sadovnik"
    ],
    "abstract": "In recent years, large language models (LLMs) have become incredibly popular,\nwith ChatGPT for example being used by over a billion users. While these models\nexhibit remarkable language understanding and logical prowess, a notable\nchallenge surfaces in the form of \"hallucinations.\" This phenomenon results in\nLLMs outputting misinformation in a confident manner, which can lead to\ndevastating consequences with such a large user base. However, we question the\nappropriateness of the term \"hallucination\" in LLMs, proposing a psychological\ntaxonomy based on cognitive biases and other psychological phenomena. Our\napproach offers a more fine-grained understanding of this phenomenon, allowing\nfor targeted solutions. By leveraging insights from how humans internally\nresolve similar challenges, we aim to develop strategies to mitigate LLM\nhallucinations. This interdisciplinary approach seeks to move beyond\nconventional terminology, providing a nuanced understanding and actionable\npathways for improvement in LLM reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01769v1",
    "published_date": "2024-02-01 03:01:11 UTC",
    "updated_date": "2024-02-01 03:01:11 UTC"
  },
  {
    "arxiv_id": "2402.00904v1",
    "title": "Graph Domain Adaptation: Challenges, Progress and Prospects",
    "authors": [
      "Boshen Shi",
      "Yongqing Wang",
      "Fangda Guo",
      "Bingbing Xu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "As graph representation learning often suffers from label scarcity problems\nin real-world applications, researchers have proposed graph domain adaptation\n(GDA) as an effective knowledge-transfer paradigm across graphs. In particular,\nto enhance model performance on target graphs with specific tasks, GDA\nintroduces a bunch of task-related graphs as source graphs and adapts the\nknowledge learnt from source graphs to the target graphs. Since GDA combines\nthe advantages of graph representation learning and domain adaptation, it has\nbecome a promising direction of transfer learning on graphs and has attracted\nan increasing amount of research interest in recent years. In this paper, we\ncomprehensively overview the studies of GDA and present a detailed survey of\nrecent advances. Specifically, we outline the research status and challenges,\npropose a taxonomy, introduce the details of representative works, and discuss\nthe prospects. To the best of our knowledge, this paper is the first survey for\ngraph domain adaptation. A detailed paper list is available at\nhttps://github.com/Skyorca/Awesome-Graph-Domain-Adaptation-Papers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00904v1",
    "published_date": "2024-02-01 02:44:32 UTC",
    "updated_date": "2024-02-01 02:44:32 UTC"
  },
  {
    "arxiv_id": "2402.00284v1",
    "title": "PAP-REC: Personalized Automatic Prompt for Recommendation Language Model",
    "authors": [
      "Zelong Li",
      "Jianchao Ji",
      "Yingqiang Ge",
      "Wenyue Hua",
      "Yongfeng Zhang"
    ],
    "abstract": "Recently emerged prompt-based Recommendation Language Models (RLM) can solve\nmultiple recommendation tasks uniformly. The RLMs make full use of the\ninherited knowledge learned from the abundant pre-training data to solve the\ndownstream recommendation tasks by prompts, without introducing additional\nparameters or network training. However, handcrafted prompts require\nsignificant expertise and human effort since slightly rewriting prompts may\ncause massive performance changes. In this paper, we propose PAP-REC, a\nframework to generate the Personalized Automatic Prompt for RECommendation\nlanguage models to mitigate the inefficiency and ineffectiveness problems\nderived from manually designed prompts. Specifically, personalized automatic\nprompts allow different users to have different prompt tokens for the same\ntask, automatically generated using a gradient-based method. One challenge for\npersonalized automatic prompt generation for recommendation language models is\nthe extremely large search space, leading to a long convergence time. To\neffectively and efficiently address the problem, we develop surrogate metrics\nand leverage an alternative updating schedule for prompting recommendation\nlanguage models. Experimental results show that our PAP-REC framework manages\nto generate personalized prompts, and the automatically generated prompts\noutperform manually constructed prompts and also outperform various baseline\nrecommendation models. The source code of the work is available at\nhttps://github.com/rutgerswiselab/PAP-REC.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00284v1",
    "published_date": "2024-02-01 02:29:16 UTC",
    "updated_date": "2024-02-01 02:29:16 UTC"
  },
  {
    "arxiv_id": "2402.01767v2",
    "title": "HiQA: A Hierarchical Contextual Augmentation RAG for Multi-Documents QA",
    "authors": [
      "Xinyue Chen",
      "Pengyu Gao",
      "Jiangjiang Song",
      "Xiaoyang Tan"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has rapidly advanced the language model\nfield, particularly in question-answering (QA) systems. By integrating external\ndocuments during the response generation phase, RAG significantly enhances the\naccuracy and reliability of language models. This method elevates the quality\nof responses and reduces the frequency of hallucinations, where the model\ngenerates incorrect or misleading information. However, these methods exhibit\nlimited retrieval accuracy when faced with numerous indistinguishable\ndocuments, presenting notable challenges in their practical application. In\nresponse to these emerging challenges, we present HiQA, an advanced\nmulti-document question-answering (MDQA) framework that integrates cascading\nmetadata into content and a multi-route retrieval mechanism. We also release a\nbenchmark called MasQA to evaluate and research in MDQA. Finally, HiQA\ndemonstrates the state-of-the-art performance in multi-document environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01767v2",
    "published_date": "2024-02-01 02:24:15 UTC",
    "updated_date": "2024-09-24 08:25:37 UTC"
  },
  {
    "arxiv_id": "2402.00262v1",
    "title": "Computational Experiments Meet Large Language Model Based Agents: A Survey and Perspective",
    "authors": [
      "Qun Ma",
      "Xiao Xue",
      "Deyu Zhou",
      "Xiangning Yu",
      "Donghua Liu",
      "Xuwen Zhang",
      "Zihan Zhao",
      "Yifan Shen",
      "Peilin Ji",
      "Juanjuan Li",
      "Gang Wang",
      "Wanpeng Ma"
    ],
    "abstract": "Computational experiments have emerged as a valuable method for studying\ncomplex systems, involving the algorithmization of counterfactuals. However,\naccurately representing real social systems in Agent-based Modeling (ABM) is\nchallenging due to the diverse and intricate characteristics of humans,\nincluding bounded rationality and heterogeneity. To address this limitation,\nthe integration of Large Language Models (LLMs) has been proposed, enabling\nagents to possess anthropomorphic abilities such as complex reasoning and\nautonomous learning. These agents, known as LLM-based Agent, offer the\npotential to enhance the anthropomorphism lacking in ABM. Nonetheless, the\nabsence of explicit explainability in LLMs significantly hinders their\napplication in the social sciences. Conversely, computational experiments excel\nin providing causal analysis of individual behaviors and complex phenomena.\nThus, combining computational experiments with LLM-based Agent holds\nsubstantial research potential. This paper aims to present a comprehensive\nexploration of this fusion. Primarily, it outlines the historical development\nof agent structures and their evolution into artificial societies, emphasizing\ntheir importance in computational experiments. Then it elucidates the\nadvantages that computational experiments and LLM-based Agents offer each\nother, considering the perspectives of LLM-based Agent for computational\nexperiments and vice versa. Finally, this paper addresses the challenges and\nfuture trends in this research domain, offering guidance for subsequent related\nstudies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00262v1",
    "published_date": "2024-02-01 01:17:46 UTC",
    "updated_date": "2024-02-01 01:17:46 UTC"
  },
  {
    "arxiv_id": "2402.00260v3",
    "title": "Human-mediated Large Language Models for Robotic Intervention in Children with Autism Spectrum Disorders",
    "authors": [
      "Ruchik Mishra",
      "Karla Conn Welch",
      "Dan O Popa"
    ],
    "abstract": "The robotic intervention for individuals with Autism Spectrum Disorder (ASD)\nhas generally used pre-defined scripts to deliver verbal content during\none-to-one therapy sessions. This practice restricts the use of robots to\nlimited, pre-mediated instructional curricula. In this paper, we increase robot\nautonomy in one such robotic intervention for children with ASD by implementing\nperspective-taking teaching. Our approach uses large language models (LLM) to\ngenerate verbal content as texts and then deliver it to the child via robotic\nspeech. In the proposed pipeline, we teach perspective-taking through which our\nrobot takes up three roles: initiator, prompter, and reinforcer. We adopted the\nGPT-2 + BART pipelines to generate social situations, ask questions (as\ninitiator), and give options (as prompter) when required. The robot encourages\nthe child by giving positive reinforcement for correct answers (as a\nreinforcer). In addition to our technical contribution, we conducted ten-minute\nsessions with domain experts simulating an actual perspective teaching session,\nwith the researcher acting as a child participant. These sessions validated our\nrobotic intervention pipeline through surveys, including those from NASA TLX\nand GodSpeed. We used BERTScore to compare our GPT-2 + BART pipeline with an\nall GPT-2 and found the performance of the former to be better. Based on the\nresponses by the domain experts, the robot session demonstrated higher\nperformance with no additional increase in mental or physical demand, temporal\ndemand, effort, or frustration compared to a no-robot session. We also\nconcluded that the domain experts perceived the robot as ideally safe, likable,\nand reliable.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "This work is submitted for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2402.00260v3",
    "published_date": "2024-02-01 01:09:00 UTC",
    "updated_date": "2024-07-27 04:19:03 UTC"
  },
  {
    "arxiv_id": "2402.00254v1",
    "title": "Vertical Symbolic Regression via Deep Policy Gradient",
    "authors": [
      "Nan Jiang",
      "Md Nasim",
      "Yexiang Xue"
    ],
    "abstract": "Vertical Symbolic Regression (VSR) recently has been proposed to expedite the\ndiscovery of symbolic equations with many independent variables from\nexperimental data. VSR reduces the search spaces following the vertical\ndiscovery path by building from reduced-form equations involving a subset of\nindependent variables to full-fledged ones. Proved successful by many symbolic\nregressors, deep neural networks are expected to further scale up VSR.\nNevertheless, directly combining VSR with deep neural networks will result in\ndifficulty in passing gradients and other engineering issues. We propose\nVertical Symbolic Regression using Deep Policy Gradient (VSR-DPG) and\ndemonstrate that VSR-DPG can recover ground-truth equations involving multiple\ninput variables, significantly beyond both deep reinforcement learning-based\napproaches and previous VSR variants. Our VSR-DPG models symbolic regression as\na sequential decision-making process, in which equations are built from\nrepeated applications of grammar rules. The integrated deep model is trained to\nmaximize a policy gradient objective. Experimental results demonstrate that our\nVSR-DPG significantly outperforms popular baselines in identifying both\nalgebraic equations and ordinary differential equations on a series of\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "see animated demo at: vsr-dpg.github.io",
    "pdf_url": "http://arxiv.org/pdf/2402.00254v1",
    "published_date": "2024-02-01 00:54:48 UTC",
    "updated_date": "2024-02-01 00:54:48 UTC"
  },
  {
    "arxiv_id": "2402.00251v1",
    "title": "Efficient Non-Parametric Uncertainty Quantification for Black-Box Large Language Models and Decision Planning",
    "authors": [
      "Yao-Hung Hubert Tsai",
      "Walter Talbott",
      "Jian Zhang"
    ],
    "abstract": "Step-by-step decision planning with large language models (LLMs) is gaining\nattention in AI agent development. This paper focuses on decision planning with\nuncertainty estimation to address the hallucination problem in language models.\nExisting approaches are either white-box or computationally demanding, limiting\nuse of black-box proprietary LLMs within budgets. The paper's first\ncontribution is a non-parametric uncertainty quantification method for LLMs,\nefficiently estimating point-wise dependencies between input-decision on the\nfly with a single inference, without access to token logits. This estimator\ninforms the statistical interpretation of decision trustworthiness. The second\ncontribution outlines a systematic design for a decision-making agent,\ngenerating actions like ``turn on the bathroom light'' based on user prompts\nsuch as ``take a bath''. Users will be asked to provide preferences when more\nthan one action has high estimated point-wise dependencies. In conclusion, our\nuncertainty estimation and decision-making agent design offer a cost-efficient\napproach for AI agent development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00251v1",
    "published_date": "2024-02-01 00:23:31 UTC",
    "updated_date": "2024-02-01 00:23:31 UTC"
  }
]