{
  "date": "2025-01-30",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-30 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 特别是大型语言模型（LLMs）的安全、优化和应用，医疗诊断技术（如基因优先级和图像处理），以及机器人、量子计算和图像动画等领域，令人印象深刻的是 LLM 安全防御和高效生成方法，如 \"GuardReasoner\" 等工作，以及多模态适应领域的综述论文。\n\n### AI 和 LLMs：安全与优化焦点\n今天的论文中，AI 相关主题占主导，尤其是 LLMs 的安全性和高效应用。以下几篇值得关注：\n\n- **GuardReasoner: Towards Reasoning-based LLM Safeguards（GuardReasoner: 基于推理的 LLM 安全防护）**  \n  这篇论文提出了一种基于推理的 LLM 安全框架，通过结构化训练提升模型的安全性和可解释性。主要贡献是开发了 GuardReasoner 模型，在多个基准上实现高达 20.84% 的 F1 分数提升，显著改善了 LLM 对有害输入的防御。\n\n- **LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?（LLM 生成的启发式算法用于 AI 规划：我们还需要领域无关性吗？）**  \n  作者探讨了 LLM 生成的领域特定启发式算法在 AI 规划中的潜力。关键发现是，这些算法在某些标准 IPC 领域表现出超越传统方法的性能，并能处理 PDDL 无法表示的问题，挑战了传统规划范式。\n\n- **Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact（LLM 评估中的高估：针对数据污染影响的控制大规模研究）**  \n  这篇研究分析了数据污染对 LLM 在机器翻译任务中的影响。贡献包括实验证明污染导致 BLEU 分数高估高达 30 分，强调了评估的鲁棒性需求。\n\n- **DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights（DeltaLLM: 通过共享权重间的低秩增量压缩 LLMs）**  \n  论文引入了一种后训练压缩技术，通过权重共享和低秩矩阵减少参数 12%，保留 90% 的性能。发现显示它优于其他压缩方法，如 JointDrop，在知识和推理基准上表现突出。\n\n其他 AI 论文如 \"R.I.P.: Better Models by Survival of the Fittest Prompts\" 等则快速探讨了数据质量优化，显示通过过滤低质提示提升模型性能，但细节较常规。\n\n### 医疗与生物学：诊断和数据处理创新\n医疗主题论文较多，以基因和图像分析为主。以下几篇有实际影响：\n\n- **Survey and Improvement Strategies for Gene Prioritization with Large Language Models（使用大型语言模型的基因优先级调查与改进策略）**  \n  这篇由多位学者（如 Zhandong Liu 和 Xia Hu）合作的作品评估了 LLM 在稀有疾病诊断中的作用。关键贡献是提出多代理和 HPO 分类方法，提高基因识别准确率达 30%，并通过 divide-and-conquer 策略缓解偏差。\n\n- **Neural Graph Pattern Machine（神经图模式机）**  \n  论文开发了一种新框架，用于从图数据中学习子结构模式。贡献包括超越传统 GNN 的表达性和鲁棒性，在节点分类和链接预测任务上优于基线，强调图学习的可解释性。\n\n其他医疗论文如 \"A Multi-Layered Large Language Model Framework for Disease Prediction\" 等则展示了 LLM 在社交健康数据中的应用，但整体影响较前者小。\n\n### 机器人和多模态技术：实用进展\n机器人和图像处理论文体现实际应用潜力：\n\n- **Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation（整合 LMM 规划器和 3D 技能策略用于通用操作）**  \n  作者（如 Xiaolong Wang）提出 LMM-3DP 框架，结合多模态模型和 3D 特征提升机器人操作精度。发现显示它在真实厨房环境中成功率提高 1.45 倍，强调动态场景理解。\n\n- **Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models（多模态适应和泛化的进展：从传统方法到基础模型）**  \n  这篇综述由 Olga Fink 等知名学者撰写，覆盖多模态领域适应技术。贡献包括全面审视数据集和方法，提供了未来研究方向。\n\n其他如 \"MuseDance: Music-Driven Image Animation\" 探索了多模态图像动画，但相对较 niche。\n\n### 其他领域：量子和优化快速掠过\n量子计算和优化论文如 \"OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization\" 引入了基于最优传输的 Transformer 变体，提升了泛化性能；\"Scaling Policy Gradient Quality-Diversity with Massive Parallelization\" 则优化了强化学习效率。这些工作技术性强，但影响力较 AI 主题小，故简要提及。\n\n总之，今天的 arXiv 论文突出了 AI 安全和医疗创新的潜力，读者可关注 LLM 相关工作以把握前沿趋势。更多细节请查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2501.18801v1",
      "title": "Every Image Listens, Every Image Dances: Music-Driven Image Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhikang Dong",
        "Weituo Hao",
        "Ju-Chiang Wang",
        "Peng Zhang",
        "Pawel Polak"
      ],
      "abstract": "Image animation has become a promising area in multimodal research, with a\nfocus on generating videos from reference images. While prior work has largely\nemphasized generic video generation guided by text, music-driven dance video\ngeneration remains underexplored. In this paper, we introduce MuseDance, an\ninnovative end-to-end model that animates reference images using both music and\ntext inputs. This dual input enables MuseDance to generate personalized videos\nthat follow text descriptions and synchronize character movements with the\nmusic. Unlike existing approaches, MuseDance eliminates the need for complex\nmotion guidance inputs, such as pose or depth sequences, making flexible and\ncreative video generation accessible to users of all expertise levels. To\nadvance research in this field, we present a new multimodal dataset comprising\n2,904 dance videos with corresponding background music and text descriptions.\nOur approach leverages diffusion-based methods to achieve robust\ngeneralization, precise control, and temporal consistency, setting a new\nbaseline for the music-driven image animation task.",
      "tldr_zh": "这篇论文引入了 MuseDance，一个创新的端到端模型，用于通过音乐和文本输入来动画化参考图像，从而生成个性化视频，使人物动作与音乐同步。不同于现有方法，MuseDance 省去了复杂的运动指导输入（如姿势或深度序列），使视频生成更灵活且易于用户操作。为了推进该领域研究，论文构建了一个新多模态数据集，包含 2904 个舞蹈视频、背景音乐和文本描述，并采用 diffusion-based 方法实现鲁棒的泛化、精确控制和时间一致性。该模型为音乐驱动图像动画任务设定了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18801v1",
      "published_date": "2025-01-30 23:38:51 UTC",
      "updated_date": "2025-01-30 23:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:44:33.877902"
    },
    {
      "arxiv_id": "2501.18797v1",
      "title": "Compositional Generalization Requires More Than Disentangled Representations",
      "title_zh": "组合泛化要求不仅仅是解耦表示",
      "authors": [
        "Qiyao Liang",
        "Daoyuan Qian",
        "Liu Ziyin",
        "Ila Fiete"
      ],
      "abstract": "Composition-the ability to generate myriad variations from finite means-is\nbelieved to underlie powerful generalization. However, compositional\ngeneralization remains a key challenge for deep learning. A widely held\nassumption is that learning disentangled (factorized) representations naturally\nsupports this kind of extrapolation. Yet, empirical results are mixed, with\nmany generative models failing to recognize and compose factors to generate\nout-of-distribution (OOD) samples. In this work, we investigate a controlled 2D\nGaussian \"bump\" generation task, demonstrating that standard generative\narchitectures fail in OOD regions when training with partial data, even when\nsupplied with fully disentangled $(x, y)$ coordinates, re-entangling them\nthrough subsequent layers. By examining the model's learned kernels and\nmanifold geometry, we show that this failure reflects a \"memorization\" strategy\nfor generation through the superposition of training data rather than by\ncombining the true factorized features. We show that models forced-through\narchitectural modifications with regularization or curated training data-to\ncreate disentangled representations in the full-dimensional representational\n(pixel) space can be highly data-efficient and effective at learning to compose\nin OOD regions. These findings underscore that bottlenecks with\nfactorized/disentangled representations in an abstract representation are\ninsufficient: the model must actively maintain or induce factorization directly\nin the representational space in order to achieve robust compositional\ngeneralization.",
      "tldr_zh": "这篇论文探讨了组合泛化（compositional generalization）在深度学习中的挑战，挑战了仅靠解耦表示（disentangled representations）就能实现有效泛化的假设。作者通过一个受控的 2D 高斯“bump”生成任务进行实验，发现标准生成模型即使提供完全解耦的 (x, y) 坐标，也会在分布外（OOD）样本上失败，因为模型倾向于重新纠缠特征并采用“记忆”训练数据的策略。研究结果表明，通过架构修改、正则化和精选训练数据来强制模型在表示空间中维护解耦，可以显著提高数据效率并实现稳健的组合泛化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, plus appendix",
      "pdf_url": "http://arxiv.org/pdf/2501.18797v1",
      "published_date": "2025-01-30 23:20:41 UTC",
      "updated_date": "2025-01-30 23:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:44:45.696178"
    },
    {
      "arxiv_id": "2501.18794v1",
      "title": "Survey and Improvement Strategies for Gene Prioritization with Large Language Models",
      "title_zh": "大型语言模型在基因优先排序中的调查与改进策略",
      "authors": [
        "Matthew Neeley",
        "Guantong Qi",
        "Guanchu Wang",
        "Ruixiang Tang",
        "Dongxue Mao",
        "Chaozhong Liu",
        "Sasidhar Pasupuleti",
        "Bo Yuan",
        "Fan Xia",
        "Pengfei Liu",
        "Zhandong Liu",
        "Xia Hu"
      ],
      "abstract": "Rare diseases are challenging to diagnose due to limited patient data and\ngenetic diversity. Despite advances in variant prioritization, many cases\nremain undiagnosed. While large language models (LLMs) have performed well in\nmedical exams, their effectiveness in diagnosing rare genetic diseases has not\nbeen assessed. To identify causal genes, we benchmarked various LLMs for gene\nprioritization. Using multi-agent and Human Phenotype Ontology (HPO)\nclassification, we categorized patients based on phenotypes and solvability\nlevels. As gene set size increased, LLM performance deteriorated, so we used a\ndivide-and-conquer strategy to break the task into smaller subsets. At\nbaseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking\ncausal genes correctly. The multi-agent and HPO approaches helped distinguish\nconfidently solved cases from challenging ones, highlighting the importance of\nknown gene-phenotype associations and phenotype specificity. We found that\ncases with specific phenotypes or clear associations were more accurately\nsolved. However, we observed biases toward well-studied genes and input order\nsensitivity, which hindered gene prioritization. Our divide-and-conquer\nstrategy improved accuracy by overcoming these biases. By utilizing HPO\nclassification, novel multi-agent techniques, and our LLM strategy, we improved\ncausal gene identification accuracy compared to our baseline evaluation. This\napproach streamlines rare disease diagnosis, facilitates reanalysis of unsolved\ncases, and accelerates gene discovery, supporting the development of targeted\ndiagnostics and therapies.",
      "tldr_zh": "本文调查了使用大型语言模型(LLMs)进行基因优先级排序的策略，以应对稀有疾病诊断中的数据有限和遗传多样性挑战。研究通过基准测试各种LLMs、结合多智能体系统和Human Phenotype Ontology (HPO)分类，以及divide-and-conquer策略，将任务分解为更小子集，从而改善了准确性。结果显示，GPT-4在基线测试中准确率近30%，但存在对已研究基因的偏见和输入顺序敏感性；改进策略成功克服这些问题，提升了因果基因识别性能。该方法有助于简化稀有疾病诊断、重新分析未解决病例，并加速基因发现和针对性治疗开发。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "11 pages, 4 figures, 10 pages of supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18794v1",
      "published_date": "2025-01-30 23:03:03 UTC",
      "updated_date": "2025-01-30 23:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:44:57.804042"
    },
    {
      "arxiv_id": "2501.18793v1",
      "title": "OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Kelvin Kan",
        "Xingjian Li",
        "Stanley Osher"
      ],
      "abstract": "Transformers have achieved state-of-the-art performance in numerous tasks. In\nthis paper, we propose a continuous-time formulation of transformers.\nSpecifically, we consider a dynamical system whose governing equation is\nparametrized by transformer blocks. We leverage optimal transport theory to\nregularize the training problem, which enhances stability in training and\nimproves generalization of the resulting model. Moreover, we demonstrate in\ntheory that this regularization is necessary as it promotes uniqueness and\nregularity of solutions. Our model is flexible in that almost any existing\ntransformer architectures can be adopted to construct the dynamical system with\nonly slight modifications to the existing code. We perform extensive numerical\nexperiments on tasks motivated by natural language processing, image\nclassification, and point cloud classification. Our experimental results show\nthat the proposed method improves the performance of its discrete counterpart\nand outperforms relevant comparing models.",
      "tldr_zh": "本研究提出OT-Transformer，一种基于连续时间的Transformer架构，通过最优传输(Optimal Transport)理论正则化训练过程，以提升模型的训练稳定性和泛化能力。该架构将Transformer块参数化一个动力学系统，并在理论上证明这种正则化有助于确保解的唯一性和规则性。实验结果显示，OT-Transformer在自然语言处理、图像分类和点云分类任务上优于其离散版本和相关基准模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18793v1",
      "published_date": "2025-01-30 22:52:40 UTC",
      "updated_date": "2025-01-30 22:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:45:07.987281"
    },
    {
      "arxiv_id": "2501.18784v1",
      "title": "LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Tuisov",
        "Yonatan Vernik",
        "Alexander Shleyfman"
      ],
      "abstract": "Domain-independent heuristics have long been a cornerstone of AI planning,\noffering general solutions applicable across a wide range of tasks without\nrequiring domain-specific engineering. However, the advent of large language\nmodels (LLMs) presents an opportunity to generate heuristics tailored to\nspecific planning problems, potentially challenging the necessity of domain\nindependence as a strict design principle. In this paper, we explore the use of\nLLMs to automatically derive planning heuristics from task descriptions\nrepresented as successor generators and goal tests written in general purpose\nprogramming language. We investigate the trade-offs between domain-specific\nLLM-generated heuristics and traditional domain-independent methods in terms of\ncomputational efficiency and explainability. Our experiments demonstrate that\nLLMs can create heuristics that achieve state-of-the-art performance on some\nstandard IPC domains, as well as their ability to solve problems that lack an\nadequate Planning Domain Definition Language ({\\sc pddl}) representation. We\ndiscuss whether these results signify a paradigm shift and how they can\ncomplement existing approaches.",
      "tldr_zh": "该论文探讨了使用大型语言模型（LLMs）生成特定于任务的规划启发式方法，质疑传统AI规划中领域无关（Domain-Independent）启发式的必要性。研究者从任务描述（如后继生成器和目标测试）中自动生成启发式，并比较其与传统方法的计算效率和可解释性。实验结果显示，LLMs生成的启发式在某些标准IPC domains上达到最先进性能，并能处理缺乏PDDL表示的问题。这些发现可能标志着AI规划范式转变，并为补充现有方法提供新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18784v1",
      "published_date": "2025-01-30 22:21:12 UTC",
      "updated_date": "2025-01-30 22:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:45:21.117806"
    },
    {
      "arxiv_id": "2501.18771v1",
      "title": "Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammed Yusuf Kocyigit",
        "Eleftheria Briakou",
        "Daniel Deutsch",
        "Jiaming Luo",
        "Colin Cherry",
        "Markus Freitag"
      ],
      "abstract": "Data contamination -- the accidental consumption of evaluation examples\nwithin the pre-training data -- can undermine the validity of evaluation\nbenchmarks. In this paper, we present a rigorous analysis of the effects of\ncontamination on language models at 1B and 8B scales on the machine translation\ntask. Starting from a carefully decontaminated train-test split, we\nsystematically introduce contamination at various stages, scales, and data\nformats to isolate its effect and measure its impact on performance metrics.\nOur experiments reveal that contamination with both source and target\nsubstantially inflates BLEU scores, and this inflation is 2.5 times larger (up\nto 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and\ntarget-only contamination generally produce smaller, less consistent\nover-estimations. Finally, we study how the temporal distribution and frequency\nof contaminated samples influence performance over-estimation across languages\nwith varying degrees of data resources.",
      "tldr_zh": "本研究通过一个受控的大型实验，分析了数据 contamination 在机器翻译任务中对语言模型（1B 和 8B 规模）评估的影响，重点考察其如何导致性能指标过估计。研究者从一个仔细 decontaminated 的训练-测试分割出发，系统引入污染于不同阶段、规模和数据格式，以隔离其效果。结果显示，源和目标数据同时污染时会显著膨胀 BLEU scores，高达 30 点，且 8B 模型的膨胀幅度是 1B 模型的 2.5 倍；源-only 或目标-only 污染则产生较小且不一致的过估计。此外，污染样本的 temporal distribution 和 frequency 会进一步影响不同语言资源的性能过估计。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18771v1",
      "published_date": "2025-01-30 21:51:18 UTC",
      "updated_date": "2025-01-30 21:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:45:33.815289"
    },
    {
      "arxiv_id": "2501.18768v2",
      "title": "Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Michael S. Yao",
        "James C. Gee",
        "Osbert Bastani"
      ],
      "abstract": "The goal of offline model-based optimization (MBO) is to propose new designs\nthat maximize a reward function given only an offline dataset. However, an\nimportant desiderata is to also propose a diverse set of final candidates that\ncapture many optimal and near-optimal design configurations. We propose\nDiversity in Adversarial Model-based Optimization (DynAMO) as a novel method to\nintroduce design diversity as an explicit objective into any MBO problem. Our\nkey insight is to formulate diversity as a distribution matching problem where\nthe distribution of generated designs captures the inherent diversity contained\nwithin the offline dataset. Extensive experiments spanning multiple scientific\ndomains show that DynAMO can be used with common optimization methods to\nsignificantly improve the diversity of proposed designs while still discovering\nhigh-quality candidates.",
      "tldr_zh": "该论文针对离线模型-based optimization (MBO) 的挑战，提出 DynAMO 方法，将设计多样性作为显式目标融入优化过程，以生成捕捉离线数据集固有多样性的候选设计。DynAMO 通过将多样性表述为 distribution matching 问题，确保生成的 designs 不仅覆盖最优和近似最优配置，还维持高优化质量。在多个科学领域的广泛实验中，DynAMO 与常见优化方法结合后，显著提高了 designs 的多样性，同时成功发现高质量候选。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "52 pages, Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18768v2",
      "published_date": "2025-01-30 21:43:25 UTC",
      "updated_date": "2025-05-01 13:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:45:44.623773"
    },
    {
      "arxiv_id": "2501.18766v1",
      "title": "Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language",
      "title_zh": "翻译失败",
      "authors": [
        "Pronoy Kumar Mondal",
        "Sadman Sadik Khan",
        "Md. Masud Rana",
        "Shahriar Sultan Ramit",
        "Abdus Sattar",
        "Md. Sadekur Rahman"
      ],
      "abstract": "The rapid development of digital stages has greatly compounded the dispersal\nof untrue data, dissolving certainty and judgment in society, especially among\nthe Bengali-speaking community. Our ponder addresses this critical issue by\npresenting an interesting strategy that utilizes a profound learning\ninnovation, particularly the Gated Repetitive Unit (GRU), to recognize fake\nnews within the Bangla dialect. The strategy of our proposed work incorporates\nintensive information preprocessing, which includes lemmatization,\ntokenization, and tending to course awkward nature by oversampling. This comes\nabout in a dataset containing 58,478 passages. We appreciate the creation of a\ndemonstration based on GRU (Gated Repetitive Unit) that illustrates remarkable\nexecution with a noteworthy precision rate of 94%. This ponder gives an\nintensive clarification of the methods included in planning the information,\nselecting the show, preparing it, and assessing its execution. The performance\nof the model is investigated by reliable metrics like precision, recall, F1\nscore, and accuracy. The commitment of the work incorporates making a huge fake\nnews dataset in Bangla and a demonstration that has outperformed other Bangla\nfake news location models.",
      "tldr_zh": "本研究针对孟加拉语社区的假新闻传播问题，提出了一种基于深度学习技术的解决方案，特别利用 GRU（Gated Recurrent Unit）模型进行检测。研究过程包括数据预处理（如 lemmatization、tokenization 和 oversampling），构建了一个包含 58,478 条记录的孟加拉语假新闻数据集。模型在评估指标中表现出色，准确率达到 94%，并在 precision、recall、F1 score 和 accuracy 等指标上超越了现有模型。该工作的主要贡献是创建了大型孟加拉语假新闻数据集，并提供了一个高效的检测框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, THE 15th INTERNATIONAL IEEE CONFERENCE ON COMPUTING,\n  COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)",
      "pdf_url": "http://arxiv.org/pdf/2501.18766v1",
      "published_date": "2025-01-30 21:41:26 UTC",
      "updated_date": "2025-01-30 21:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:45:56.241789"
    },
    {
      "arxiv_id": "2502.01652v1",
      "title": "Hybrid Group Relative Policy Optimization: A Multi-Sample Approach to Enhancing Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Sane"
      ],
      "abstract": "Hybrid Group Relative Policy Optimization (Hybrid GRPO) is a reinforcement\nlearning framework that extends Proximal Policy Optimization (PPO) and Group\nRelative Policy Optimization (GRPO) by incorporating empirical multi-sample\naction evaluation while preserving the stability of value function-based\nlearning. Unlike DeepSeek GRPO, which eliminates the value function in favor of\npurely empirical reward estimation, Hybrid GRPO introduces a structured\nadvantage computation method that balances empirical action sampling with\nbootstrapped value estimation. This approach enhances sample efficiency,\nimproves learning stability, and mitigates variance amplification observed in\npurely empirical methods. A detailed mathematical comparison between PPO,\nDeepSeek GRPO, and Hybrid GRPO is presented, highlighting key differences in\nadvantage estimation and policy updates. Experimental validation in a\ncontrolled reinforcement learning environment demonstrates that Hybrid GRPO\nachieves superior convergence speed, more stable policy updates, and improved\nsample efficiency compared to existing methods. Several extensions to Hybrid\nGRPO are explored, including entropy-regularized sampling, hierarchical\nmulti-step sub-sampling, adaptive reward normalization, and value-based action\nselection. Beyond reinforcement learning in simulated environments, Hybrid GRPO\nprovides a scalable framework for bridging the gap between large language\nmodels (LLMs) and real-world agent-based decision-making. By integrating\nstructured empirical sampling with reinforcement learning stability mechanisms,\nHybrid GRPO has potential applications in autonomous robotics, financial\nmodeling, and AI-driven control systems. These findings suggest that Hybrid\nGRPO serves as a robust and adaptable reinforcement learning methodology,\npaving the way for further advancements in policy optimization.",
      "tldr_zh": "本研究提出了一种混合群组相对策略优化（Hybrid GRPO）框架，作为强化学习（reinforcement learning）中的新方法，它扩展了 Proximal Policy Optimization (PPO) 和 Group Relative Policy Optimization (GRPO)，通过整合经验多样本动作评估和引导式价值估计来提升策略优化。Hybrid GRPO 采用结构化的优势计算方法，平衡了经验采样与 bootstrapped 值估计，从而提高样本效率、学习稳定性和减少方差放大。实验结果显示，在控制环境中，Hybrid GRPO 比现有方法（如 PPO 和 DeepSeek GRPO）实现了更快的收敛速度、更稳定的策略更新和更好的样本效率。进一步扩展包括熵正则化采样、层次化多步子采样等，该框架还适用于桥接大型语言模型（LLMs）和真实世界决策场景，具有潜力应用于自主机器人、金融建模和 AI 驱动控制系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 Pages, 18 Equations, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2502.01652v1",
      "published_date": "2025-01-30 21:04:01 UTC",
      "updated_date": "2025-01-30 21:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:46:09.657995"
    },
    {
      "arxiv_id": "2501.18741v1",
      "title": "Synthetic Data Generation for Augmenting Small Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Liu",
        "Samer El Kababji",
        "Nicholas Mitsakakis",
        "Lisa Pilgram",
        "Thomas Walters",
        "Mark Clemons",
        "Greg Pond",
        "Alaa El-Hussuna",
        "Khaled El Emam"
      ],
      "abstract": "Small datasets are common in health research. However, the generalization\nperformance of machine learning models is suboptimal when the training datasets\nare small. To address this, data augmentation is one solution. Augmentation\nincreases sample size and is seen as a form of regularization that increases\nthe diversity of small datasets, leading them to perform better on unseen data.\nWe found that augmentation improves prognostic performance for datasets that:\nhave fewer observations, with smaller baseline AUC, have higher cardinality\ncategorical variables, and have more balanced outcome variables. No specific\ngenerative model consistently outperformed the others. We developed a decision\nsupport model that can be used to inform analysts if augmentation would be\nuseful. For seven small application datasets, augmenting the existing data\nresults in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%\n(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,\ndemonstrating the nontrivial impact of augmentation on small datasets\n(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The\ndiversity of augmented datasets was higher than the diversity of resampled\ndatasets (p=0.046).",
      "tldr_zh": "这篇论文探讨了使用合成数据生成（Synthetic Data Generation）来增强小样本数据集的问题，以改善机器学习模型的泛化性能。研究发现，data augmentation 特别适用于样本量少、基线AUC低、高基数分类变量或结果变量更平衡的场景，并开发了一个决策支持模型来评估其适用性。在七个健康研究数据集上的实验显示，数据增强使AUC平均相对提高15.55%（从0.71到0.75的范围），且增强数据集的多样性显著高于重采样方法（p=0.046）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18741v1",
      "published_date": "2025-01-30 20:44:37 UTC",
      "updated_date": "2025-01-30 20:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:46:21.195713"
    },
    {
      "arxiv_id": "2501.18739v1",
      "title": "Neural Graph Pattern Machine",
      "title_zh": "神经图模式机",
      "authors": [
        "Zehong Wang",
        "Zheyuan Zhang",
        "Tianyi Ma",
        "Nitesh V Chawla",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Graph learning tasks require models to comprehend essential substructure\npatterns relevant to downstream tasks, such as triadic closures in social\nnetworks and benzene rings in molecular graphs. Due to the non-Euclidean nature\nof graphs, existing graph neural networks (GNNs) rely on message passing to\niteratively aggregate information from local neighborhoods. Despite their\nempirical success, message passing struggles to identify fundamental\nsubstructures, such as triangles, limiting its expressiveness. To overcome this\nlimitation, we propose the Neural Graph Pattern Machine (GPM), a framework\ndesigned to learn directly from graph patterns. GPM efficiently extracts and\nencodes substructures while identifying the most relevant ones for downstream\ntasks. We also demonstrate that GPM offers superior expressivity and improved\nlong-range information modeling compared to message passing. Empirical\nevaluations on node classification, link prediction, graph classification, and\nregression show the superiority of GPM over state-of-the-art baselines. Further\nanalysis reveals its desirable out-of-distribution robustness, scalability, and\ninterpretability. We consider GPM to be a step toward going beyond message\npassing.",
      "tldr_zh": "本论文提出 Neural Graph Pattern Machine (GPM)，一个直接从图形子结构中学习的框架，以解决现有 Graph Neural Networks (GNNs) 的消息传递机制在识别关键模式（如三角形）时的局限性。GPM 高效提取和编码相关子结构，并提升模型的表达性和长距离信息建模能力。实验结果显示，GPM 在节点分类、链接预测、图形分类和回归任务上优于最先进基线，同时展现出出色的分布外鲁棒性、可扩展性和可解释性。这标志着图形学习向超越消息传递机制的重要一步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18739v1",
      "published_date": "2025-01-30 20:37:47 UTC",
      "updated_date": "2025-01-30 20:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:46:34.306777"
    },
    {
      "arxiv_id": "2501.18733v1",
      "title": "Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuelei Li",
        "Ge Yan",
        "Annabella Macaluso",
        "Mazeyu Ji",
        "Xueyan Zou",
        "Xiaolong Wang"
      ],
      "abstract": "The recent advancements in visual reasoning capabilities of large multimodal\nmodels (LMMs) and the semantic enrichment of 3D feature fields have expanded\nthe horizons of robotic capabilities. These developments hold significant\npotential for bridging the gap between high-level reasoning from LMMs and\nlow-level control policies utilizing 3D feature fields. In this work, we\nintroduce LMM-3DP, a framework that can integrate LMM planners and 3D skill\nPolicies. Our approach consists of three key perspectives: high-level planning,\nlow-level control, and effective integration. For high-level planning, LMM-3DP\nsupports dynamic scene understanding for environment disturbances, a critic\nagent with self-feedback, history policy memorization, and reattempts after\nfailures. For low-level control, LMM-3DP utilizes a semantic-aware 3D feature\nfield for accurate manipulation. In aligning high-level and low-level control\nfor robot actions, language embeddings representing the high-level policy are\njointly attended with the 3D feature field in the 3D transformer for seamless\nintegration. We extensively evaluate our approach across multiple skills and\nlong-horizon tasks in a real-world kitchen environment. Our results show a\nsignificant 1.45x success rate increase in low-level control and an approximate\n1.5x improvement in high-level planning accuracy compared to LLM-based\nbaselines. Demo videos and an overview of LMM-3DP are available at\nhttps://lmm-3dp-release.github.io.",
      "tldr_zh": "该研究提出LMM-3DP框架，用于整合大型多模态模型(LMMs)的规划能力和3D技能策略，以实现机器人操作的泛化性。该框架包括高水平规划（如动态场景理解、批评代理、自反馈、历史策略记忆和失败重试）和低水平控制（如语义感知3D feature field），并通过语言嵌入与3D feature field在3D transformer中联合关注，实现无缝整合。在真实厨房环境中进行的实验显示，LMM-3DP比基线模型提高了1.45倍的低水平控制成功率和约1.5倍的高水平规划准确性，为机器人操作任务提供了更可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18733v1",
      "published_date": "2025-01-30 20:19:01 UTC",
      "updated_date": "2025-01-30 20:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:46:44.769967"
    },
    {
      "arxiv_id": "2501.18727v2",
      "title": "Exploring Audio Editing Features as User-Centric Privacy Defenses Against Large Language Model(LLM) Based Emotion Inference Attacks",
      "title_zh": "探索音频编辑功能作为用户导向的隐私防御措施，对抗基于大型语言模型(LLM)的情感推断攻击",
      "authors": [
        "Mohd. Farhan Israk Soumik",
        "W. K. M. Mithsara",
        "Abdur R. Shahid",
        "Ahmed Imteaj"
      ],
      "abstract": "The rapid proliferation of speech-enabled technologies, including virtual\nassistants, video conferencing platforms, and wearable devices, has raised\nsignificant privacy concerns, particularly regarding the inference of sensitive\nemotional information from audio data. Existing privacy-preserving methods\noften compromise usability and security, limiting their adoption in practical\nscenarios. This paper introduces a novel, user-centric approach that leverages\nfamiliar audio editing techniques, specifically pitch and tempo manipulation,\nto protect emotional privacy without sacrificing usability. By analyzing\npopular audio editing applications on Android and iOS platforms, we identified\nthese features as both widely available and usable. We rigorously evaluated\ntheir effectiveness against a threat model, considering adversarial attacks\nfrom diverse sources, including Deep Neural Networks (DNNs), Large Language\nModels (LLMs), and and reversibility testing. Our experiments, conducted on\nthree distinct datasets, demonstrate that pitch and tempo manipulation\neffectively obfuscates emotional data. Additionally, we explore the design\nprinciples for lightweight, on-device implementation to ensure broad\napplicability across various devices and platforms.",
      "tldr_zh": "本研究探讨了语音技术中情感信息泄露的隐私风险，并提出了一种以用户为中心的方法，利用音频编辑功能（如音高和节奏调整）来防御基于LLM的情感推断攻击。该方法通过分析Android和iOS平台的流行应用，证明这些编辑功能易用且广泛可用，并在三个数据集上进行实验，显示其能有效混淆情感数据，并抵抗DNNs、LLMs和可逆性测试等攻击。最终，该工作探讨了轻量级设备实现的設計原则，以提升在各种平台上的实用性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted for presentation(Poster) at PPAI-25: The 6th AAAI Workshop\n  on Privacy-Preserving Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2501.18727v2",
      "published_date": "2025-01-30 20:07:44 UTC",
      "updated_date": "2025-02-10 17:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:46:56.256604"
    },
    {
      "arxiv_id": "2501.18723v1",
      "title": "Scaling Policy Gradient Quality-Diversity with Massive Parallelization via Behavioral Variations",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Mitsides",
        "Maxence Faldor",
        "Antoine Cully"
      ],
      "abstract": "Quality-Diversity optimization comprises a family of evolutionary algorithms\naimed at generating a collection of diverse and high-performing solutions.\nMAP-Elites (ME), a notable example, is used effectively in fields like\nevolutionary robotics. However, the reliance of ME on random mutations from\nGenetic Algorithms limits its ability to evolve high-dimensional solutions.\nMethods proposed to overcome this include using gradient-based operators like\npolicy gradients or natural evolution strategies. While successful at scaling\nME for neuroevolution, these methods often suffer from slow training speeds, or\ndifficulties in scaling with massive parallelization due to high computational\ndemands or reliance on centralized actor-critic training. In this work, we\nintroduce a fast, sample-efficient ME based algorithm capable of scaling up\nwith massive parallelization, significantly reducing runtimes without\ncompromising performance. Our method, ASCII-ME, unlike existing policy gradient\nquality-diversity methods, does not rely on centralized actor-critic training.\nIt performs behavioral variations based on time step performance metrics and\nmaps these variations to solutions using policy gradients. Our experiments show\nthat ASCII-ME can generate a diverse collection of high-performing deep neural\nnetwork policies in less than 250 seconds on a single GPU. Additionally, it\noperates on average, five times faster than state-of-the-art algorithms while\nstill maintaining competitive sample efficiency.",
      "tldr_zh": "本研究针对 Quality-Diversity (QD) 优化算法（如 MAP-Elites）在高维解决方案中的局限性，提出了一种名为 ASCII-ME 的新算法，通过基于时间步性能指标的行为变异和 policy gradients 来实现大规模并行化。不同于依赖集中的 actor-critic 训练的现有方法，ASCII-ME 显著提高了样本效率和训练速度，并在单 GPU 上生成多样性高性能的深度神经网络策略，仅需不到 250 秒。实验结果显示，该算法比最先进算法平均快 5 倍，同时保持了竞争性的性能表现，为进化机器人等领域提供了更高效的优化框架。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18723v1",
      "published_date": "2025-01-30 19:56:04 UTC",
      "updated_date": "2025-01-30 19:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:47:09.361926"
    },
    {
      "arxiv_id": "2502.01651v1",
      "title": "Fine-tuning LLaMA 2 interference: a comparative study of language implementations for optimal efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Sazzad Hossain",
        "Touhidul Alam Seyam",
        "Avijit Chowdhury",
        "Munis Xamidov",
        "Rajib Ghose",
        "Abhijit Pathak"
      ],
      "abstract": "This paper presents a comparative study aimed at optimizing Llama2 inference,\na critical aspect of machine learning and natural language processing (NLP). We\nevaluate various programming languages and frameworks, including TensorFlow,\nPyTorch, Python, Mojo, C++, and Java, analyzing their performance in terms of\nspeed, memory consumption, and ease of implementation through extensive\nbenchmarking. Strengths and limitations of each approach are highlighted, along\nwith proposed optimization strategies for parallel processing and hardware\nutilization. Furthermore, we investigate the Mojo SDK, a novel framework\ndesigned for large language model (LLM) inference on Apple Silicon,\nbenchmarking its performance against implementations in C, C++, Rust, Zig, Go,\nand Julia. Our experiments, conducted on an Apple M1 Max, demonstrate Mojo\nSDK's competitive performance, ease of use, and seamless Python compatibility,\npositioning it as a strong alternative for LLM inference on Apple Silicon. We\nalso discuss broader implications for LLM deployment on resource-constrained\nhardware and identify potential directions for future research.",
      "tldr_zh": "这篇论文比较了多种编程语言和框架（如 TensorFlow、PyTorch、Python、Mojo、C++ 和 Java）在优化 LLaMA 2 推理方面的性能，通过基准测试评估了速度、内存消耗和易用性，并提出了并行处理和硬件利用的优化策略。研究特别聚焦于 Mojo SDK，这是一个针对 Apple Silicon 设计的 LLM 推理框架，并在 Apple M1 Max 上实验中证明其性能竞争力、易用性和与 Python 的无缝兼容。结果显示，Mojo SDK 相对于 C、C++、Rust、Zig、Go 和 Julia 等语言表现出色，为在资源受限硬件上部署 LLM 提供了重要见解，并指出了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, conference paper. International conference on Artificial\n  Intelligence and Future Civilization",
      "pdf_url": "http://arxiv.org/pdf/2502.01651v1",
      "published_date": "2025-01-30 19:36:33 UTC",
      "updated_date": "2025-01-30 19:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:47:21.925751"
    },
    {
      "arxiv_id": "2501.18596v2",
      "title": "DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights",
      "title_zh": "DeltaLLM：利用共享权重之间低秩增量压缩大语言模型",
      "authors": [
        "Liana Mikaelyan",
        "Ayyoob Imani",
        "Mathew Salvaris",
        "Parth Pathak",
        "Mohsen Fayyaz"
      ],
      "abstract": "We introduce DeltaLLM, a new post-training compression technique to reduce\nthe memory footprint of LLMs. We propose an alternative way of structuring LLMs\nwith weight sharing between layers in subsequent Transformer blocks, along with\nadditional low-rank difference matrices between them. For training, we adopt\nthe progressing module replacement method and show that the lightweight\ntraining of the low-rank modules with approximately 30M-40M tokens is\nsufficient to achieve performance on par with LLMs of comparable sizes trained\nfrom scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a\n12% parameter reduction, retaining 90% of the performance of the base Llama and\nPhi models on common knowledge and reasoning benchmarks. Our method also\noutperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT with\nthe same number of parameters removed. For example, DeltaPhi 2.9B with a 24%\nreduction achieves similar average zero-shot accuracies as recovery fine-tuned\nSlicedPhi 3.3B with a 12% reduction, despite being approximately 400M\nparameters smaller with no fine-tuning applied. This work provides new insights\ninto LLM architecture design and compression methods when storage space is\ncritical.",
      "tldr_zh": "我们介绍了 DeltaLLM，一种后训练压缩技术，通过在 Transformer 块之间共享权重并添加低秩差矩阵（Low-Rank Deltas），来减少大型语言模型（LLMs）的内存占用。采用渐进模块替换方法，仅需约 30M-40M 标记的轻量级训练，即可使模型性能达到与从零训练的同等大小模型相当。研究发布了 DeltaLLAMA 和 DeltaPHI 模型，参数减少 12%，在知识和推理基准测试中保留了基线模型的 90% 性能，并优于 JointDrop、LaCo、ShortGPT 和 SliceGPT 等方法，例如 DeltaPhi 2.9B 减少 24% 参数时，其零样本准确率与减少 12% 参数的 SlicedPhi 3.3B 相当，尽管参数少 400M 且无需微调。该工作为 LLM 架构设计和压缩策略提供了新见解，尤其适用于存储空间受限的场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18596v2",
      "published_date": "2025-01-30 18:59:55 UTC",
      "updated_date": "2025-02-24 13:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:47:33.967952"
    },
    {
      "arxiv_id": "2501.18593v1",
      "title": "Diffusion Autoencoders are Scalable Image Tokenizers",
      "title_zh": "扩散自动编码器是可扩展的图像标记器",
      "authors": [
        "Yinbo Chen",
        "Rohit Girdhar",
        "Xiaolong Wang",
        "Sai Saketh Rambhatla",
        "Ishan Misra"
      ],
      "abstract": "Tokenizing images into compact visual representations is a key step in\nlearning efficient and high-quality image generative models. We present a\nsimple diffusion tokenizer (DiTo) that learns compact visual representations\nfor image generation models. Our key insight is that a single learning\nobjective, diffusion L2 loss, can be used for training scalable image\ntokenizers. Since diffusion is already widely used for image generation, our\ninsight greatly simplifies training such tokenizers. In contrast, current\nstate-of-the-art tokenizers rely on an empirically found combination of\nheuristics and losses, thus requiring a complex training recipe that relies on\nnon-trivially balancing different losses and pretrained supervised models. We\nshow design decisions, along with theoretical grounding, that enable us to\nscale DiTo for learning competitive image representations. Our results show\nthat DiTo is a simpler, scalable, and self-supervised alternative to the\ncurrent state-of-the-art image tokenizer which is supervised. DiTo achieves\ncompetitive or better quality than state-of-the-art in image reconstruction and\ndownstream image generation tasks.",
      "tldr_zh": "本研究提出了一种简单的扩散标记器（Diffusion Tokenizer, DiTo），用于学习紧凑的视觉表示，从而提升图像生成模型的效率和质量。DiTo 的关键创新是采用单一的学习目标——扩散 L2 损失——来训练可扩展的图像标记器，避免了传统方法依赖的复杂训练配方、多损失平衡和预训练监督模型。实验结果表明，DiTo 作为一种自监督替代方案，在图像重建和下游图像生成任务中达到了或超过了最先进方法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://yinboc.github.io/dito/",
      "pdf_url": "http://arxiv.org/pdf/2501.18593v1",
      "published_date": "2025-01-30 18:59:37 UTC",
      "updated_date": "2025-01-30 18:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:47:45.037024"
    },
    {
      "arxiv_id": "2501.18592v3",
      "title": "Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Dong",
        "Moru Liu",
        "Kaiyang Zhou",
        "Eleni Chatzi",
        "Juho Kannala",
        "Cyrill Stachniss",
        "Olga Fink"
      ],
      "abstract": "In real-world scenarios, achieving domain adaptation and generalization poses\nsignificant challenges, as models must adapt to or generalize across unknown\ntarget distributions. Extending these capabilities to unseen multimodal\ndistributions, i.e., multimodal domain adaptation and generalization, is even\nmore challenging due to the distinct characteristics of different modalities.\nSignificant progress has been made over the years, with applications ranging\nfrom action recognition to semantic segmentation. Besides, the recent advent of\nlarge-scale pre-trained multimodal foundation models, such as CLIP, has\ninspired works leveraging these models to enhance adaptation and generalization\nperformances or adapting them to downstream tasks. This survey provides the\nfirst comprehensive review of recent advances from traditional approaches to\nfoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal\ntest-time adaptation; (3) Multimodal domain generalization; (4) Domain\nadaptation and generalization with the help of multimodal foundation models;\nand (5) Adaptation of multimodal foundation models. For each topic, we formally\ndefine the problem and thoroughly review existing methods. Additionally, we\nanalyze relevant datasets and applications, highlighting open challenges and\npotential future research directions. We maintain an active repository that\ncontains up-to-date literature at\nhttps://github.com/donghao51/Awesome-Multimodal-Adaptation.",
      "tldr_zh": "这篇论文回顾了多模态适应和泛化（Multimodal Adaptation and Generalization）的最新进展，从传统方法到基础模型（Foundation Models）。它系统地涵盖了五个关键主题：（1）多模态域适应（Multimodal Domain Adaptation）；（2）多模态测试时适应（Multimodal Test-Time Adaptation）；（3）多模态域泛化（Multimodal Domain Generalization）；（4）利用多模态基础模型如 CLIP 进行域适应和泛化；以及（5）多模态基础模型的适应。论文为每个主题提供了正式问题定义、现有方法的全面分析、相关数据集和应用，并指出了开放挑战及未来研究方向，同时维护了一个活跃的 GitHub 仓库以追踪最新文献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page:\n  https://github.com/donghao51/Awesome-Multimodal-Adaptation",
      "pdf_url": "http://arxiv.org/pdf/2501.18592v3",
      "published_date": "2025-01-30 18:59:36 UTC",
      "updated_date": "2025-02-17 16:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:47:57.161855"
    },
    {
      "arxiv_id": "2501.18588v1",
      "title": "Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching",
      "title_zh": "翻译失败",
      "authors": [
        "David Chuan-En Lin",
        "Hyeonsu B. Kang",
        "Nikolas Martelaro",
        "Aniket Kittur",
        "Yan-Ying Chen",
        "Matthew K. Hong"
      ],
      "abstract": "With recent advancements in the capabilities of Text-to-Image (T2I) AI\nmodels, product designers have begun experimenting with them in their work.\nHowever, T2I models struggle to interpret abstract language and the current\nuser experience of T2I tools can induce design fixation rather than a more\niterative, exploratory process. To address these challenges, we developed\nInkspire, a sketch-driven tool that supports designers in prototyping product\ndesign concepts with analogical inspirations and a complete\nsketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we\nconducted an exchange session with designers and distilled design goals for\nimproving T2I interactions. In a within-subjects study comparing Inkspire to\nControlNet, we found that Inkspire supported designers with more inspiration\nand exploration of design ideas, and improved aspects of the co-creative\nprocess by allowing designers to effectively grasp the current state of the AI\nto guide it towards novel design intentions.",
      "tldr_zh": "本研究针对Text-to-Image (T2I) AI模型在产品设计中的局限性（如难以解读抽象语言和导致设计固定化），开发了Inkspire工具，该工具通过Analogical Sketching（类比草图）支持设计师以草图驱动的方式探索设计概念，并提供完整的sketch-to-design-to-sketch反馈循环。研究团队通过与设计师的交流会议提炼设计目标，以优化T2I互动体验。在一项内部受试者研究中，Inkspire与ControlNet相比，帮助设计师获得更多灵感、提升设计想法探索，并改善了共同创造过程，使设计师能更好地理解AI状态并引导其向新颖意图发展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18588v1",
      "published_date": "2025-01-30 18:59:04 UTC",
      "updated_date": "2025-01-30 18:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:48:09.067866"
    },
    {
      "arxiv_id": "2502.00063v1",
      "title": "A Multi-Layered Large Language Model Framework for Disease Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Malak Mohamed",
        "Rokaia Emad",
        "Ali Hamdi"
      ],
      "abstract": "Social telehealth has revolutionized healthcare by enabling patients to share\nsymptoms and receive medical consultations remotely. Users frequently post\nsymptoms on social media and online health platforms, generating a vast\nrepository of medical data that can be leveraged for disease classification and\nsymptom severity assessment. Large language models (LLMs), such as LLAMA3,\nGPT-3.5 Turbo, and BERT, process complex medical data to enhance disease\nclassification. This study explores three Arabic medical text preprocessing\ntechniques: text summarization, text refinement, and Named Entity Recognition\n(NER). Evaluating CAMeL-BERT, AraBERT, and Asafaya-BERT with LoRA, the best\nperformance was achieved using CAMeL-BERT with NER-augmented text (83% type\nclassification, 69% severity assessment). Non-fine-tuned models performed\npoorly (13%-20% type classification, 40%-49% severity assessment). Integrating\nLLMs into social telehealth systems enhances diagnostic accuracy and treatment\noutcomes.",
      "tldr_zh": "该研究提出了一种多层大型语言模型（Large Language Models, LLMs）框架，用于基于社交媒体和在线健康平台的阿拉伯医疗文本进行疾病预测和症状严重度评估。研究探索了三种文本预处理技术：text summarization、text refinement 和 Named Entity Recognition (NER)，并评估了 CAMeL-BERT、AraBERT 和 Asafaya-BERT 与 LoRA 的组合。结果显示，CAMeL-BERT 结合 NER 增强文本取得了最佳性能，疾病类型分类准确率达 83%，严重度评估为 69%，而非微调模型的表现较差（类型分类 13%-20%，严重度评估 40%-49%）。整体框架的整合可提升社会远程医疗（social telehealth）系统的诊断准确性和治疗效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00063v1",
      "published_date": "2025-01-30 18:53:50 UTC",
      "updated_date": "2025-01-30 18:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:48:21.463299"
    },
    {
      "arxiv_id": "2501.18578v2",
      "title": "R.I.P.: Better Models by Survival of the Fittest Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Ping Yu",
        "Weizhe Yuan",
        "Olga Golovneva",
        "Tianhao Wu",
        "Sainbayar Sukhbaatar",
        "Jason Weston",
        "Jing Xu"
      ],
      "abstract": "Training data quality is one of the most important drivers of final model\nquality. In this work, we introduce a method for evaluating data integrity\nbased on the assumption that low-quality input prompts result in high variance\nand low quality responses. This is achieved by measuring the rejected response\nquality and the reward gap between the chosen and rejected preference pair. Our\nmethod, Rejecting Instruction Preferences (RIP) can be used to filter prompts\nfrom existing training sets, or to make high quality synthetic datasets,\nyielding large performance gains across various benchmarks compared to\nunfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win\nRate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama\n3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18th\nplace to 6th overall in the leaderboard.",
      "tldr_zh": "该研究提出了一种名为 Rejecting Instruction Preferences (RIP) 的方法，通过评估低质量输入提示导致的高方差和低质量响应，来提升训练数据的完整性。RIP 通过测量被拒绝响应的质量以及选择与拒绝偏好对之间的奖励差距，来过滤现有训练集或生成高质量合成数据集。实验结果显示，使用 Llama 3.1-8B-Instruct 时，RIP 使 AlpacaEval2 LC Win Rate 提高 9.4%、Arena-Hard 提高 8.7%、WildBench 提高 9.9%；使用 Llama 3.3-70B-Instruct 时，Arena-Hard 从 67.5 提升至 82.9，排名从 18 升至 6。该方法显著改善了模型在各种基准上的性能，为优化训练数据提供了有效策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18578v2",
      "published_date": "2025-01-30 18:50:25 UTC",
      "updated_date": "2025-02-26 18:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:48:33.067735"
    },
    {
      "arxiv_id": "2501.18577v2",
      "title": "Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Dan M. Kluger",
        "Kerri Lu",
        "Tijana Zrnic",
        "Sherrie Wang",
        "Stephen Bates"
      ],
      "abstract": "Machine learning models are increasingly used to produce predictions that\nserve as input data in subsequent statistical analyses. For example, computer\nvision predictions of economic and environmental indicators based on satellite\nimagery are used in downstream regressions; similarly, language models are\nwidely used to approximate human ratings and opinions in social science\nresearch. However, failure to properly account for errors in the machine\nlearning predictions renders standard statistical procedures invalid. Prior\nwork uses what we call the Predict-Then-Debias estimator to give valid\nconfidence intervals when machine learning algorithms impute missing variables,\nassuming a small complete sample from the population of interest. We expand the\nscope by introducing bootstrap confidence intervals that apply when the\ncomplete data is a nonuniform (i.e., weighted, stratified, or clustered) sample\nand to settings where an arbitrary subset of features is imputed. Importantly,\nthe method can be applied to many settings without requiring additional\ncalculations. We prove that these confidence intervals are valid under no\nassumptions on the quality of the machine learning model and are no wider than\nthe intervals obtained by methods that do not use machine learning predictions.",
      "tldr_zh": "本研究探讨了机器学习预测作为统计分析输入时的挑战，特别是当存在插补协变量(Imputed Covariates)和非均匀采样(Nonuniform Sampling)时，如何处理预测错误。作者扩展了 Prediction-Powered Inference 框架，引入了 bootstrap 置信区间方法，该方法适用于加权、分层或聚类样本，以及任意子集特征的插补，无需额外计算。结果显示，这些置信区间在不依赖机器学习模型质量的情况下保持有效，且不会使区间宽度增加，从而提升了统计推断的鲁棒性。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18577v2",
      "published_date": "2025-01-30 18:46:43 UTC",
      "updated_date": "2025-04-24 02:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:48:44.800930"
    },
    {
      "arxiv_id": "2501.18565v3",
      "title": "BounTCHA: A CAPTCHA Utilizing Boundary Identification in Guided Generative AI-extended Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Lehao Lin",
        "Ke Wang",
        "Maha Abdallah",
        "Wei Cai"
      ],
      "abstract": "In recent years, the rapid development of artificial intelligence (AI)\nespecially multi-modal Large Language Models (MLLMs), has enabled it to\nunderstand text, images, videos, and other multimedia data, allowing AI systems\nto execute various tasks based on human-provided prompts. However, AI-powered\nbots have increasingly been able to bypass most existing CAPTCHA systems,\nposing significant security threats to web applications. This makes the design\nof new CAPTCHA mechanisms an urgent priority. We observe that humans are highly\nsensitive to shifts and abrupt changes in videos, while current AI systems\nstill struggle to comprehend and respond to such situations effectively. Based\non this observation, we design and implement BounTCHA, a CAPTCHA mechanism that\nleverages human perception of boundaries in video transitions and disruptions.\nBy utilizing generative AI's capability to extend original videos with prompts,\nwe introduce unexpected twists and changes to create a pipeline for generating\nguided short videos for CAPTCHA purposes. We develop a prototype and conduct\nexperiments to collect data on humans' time biases in boundary identification.\nThis data serves as a basis for distinguishing between human users and bots.\nAdditionally, we perform a detailed security analysis of BounTCHA,\ndemonstrating its resilience against various types of attacks. We hope that\nBounTCHA will act as a robust defense, safeguarding millions of web\napplications in the AI-driven era.",
      "tldr_zh": "该研究针对AI机器人绕过现有CAPTCHA系统的安全威胁，提出了一种新机制BounTCHA，利用人类对视频边界和突变的高度敏感性来区分人类用户和AI。BounTCHA通过生成式AI扩展原始视频，引入意外变化生成引导短视频，并基于人类在边界识别上的时间偏差数据进行验证。实验结果和安全分析显示，该机制对各种攻击具有较强抵抗力，有望成为AI时代保护网络应用的关键防御工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 15 figures; references added, typos corrected, new keyword\n  \"guided\" added, new experimental data and related results updated; new\n  keyword \"Generative AI\" added for clarity",
      "pdf_url": "http://arxiv.org/pdf/2501.18565v3",
      "published_date": "2025-01-30 18:38:09 UTC",
      "updated_date": "2025-04-01 03:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:48:56.797101"
    },
    {
      "arxiv_id": "2501.18542v1",
      "title": "Semantic Web and Creative AI -- A Technical Report from ISWS 2023",
      "title_zh": "翻译失败",
      "authors": [
        "Raia Abu Ahmad",
        "Reham Alharbi",
        "Roberto Barile",
        "Martin Böckling",
        "Francisco Bolanos",
        "Sara Bonfitto",
        "Oleksandra Bruns",
        "Irene Celino",
        "Yashrajsinh Chudasama",
        "Martin Critelli",
        "Claudia d'Amato",
        "Giada D'Ippolito",
        "Ioannis Dasoulas",
        "Stefano De Giorgis",
        "Vincenzo De Leo",
        "Chiara Di Bonaventura",
        "Marco Di Panfilo",
        "Daniil Dobriy",
        "John Domingue",
        "Xuemin Duan",
        "Michel Dumontier",
        "Sefika Efeoglu",
        "Ruben Eschauzier",
        "Fakih Ginwa",
        "Nicolas Ferranti",
        "Arianna Graciotti",
        "Philipp Hanisch",
        "George Hannah",
        "Golsa Heidari",
        "Aidan Hogan",
        "Hassan Hussein",
        "Alexane Jouglar",
        "Jan-Christoph Kalo",
        "Manoé Kieffer",
        "Antonis Klironomos",
        "Inês Koch",
        "Weronika Lajewska",
        "Nicolas Lazzari",
        "Mikael Lindekrans",
        "Anna Sofia Lippolis",
        "Majlinda Llugiqi",
        "Eleonora Mancini",
        "Eleonora Marzi",
        "Laura Menotti",
        "Daniela Milon Flores",
        "Soulakshmee Nagowah",
        "Kerstin Neubert",
        "Emetis Niazmand",
        "Ebrahim Norouzi",
        "Beatriz Olarte Martinez",
        "Anouk Michelle Oudshoorn",
        "Andrea Poltronieri",
        "Valentina Presutti",
        "Disha Purohit",
        "Ensiyeh Raoufi",
        "Celian Ringwald",
        "Johanna Rockstroh",
        "Sebastian Rudolph",
        "Harald Sack",
        "Zafar Saeed",
        "Mohammad Javad Saeedizade",
        "Aya Sahbi",
        "Cristian Santini",
        "Aleksandra Simic",
        "Dennis Sommer",
        "Rita Sousa",
        "Mary Ann Tan",
        "Vidyashree Tarikere",
        "Tabea Tietz",
        "Liam Tirpitz",
        "Arnaldo Tomasino",
        "Frank van Harmelen",
        "Joao Vissoci",
        "Caitlin Woods",
        "Bohui Zhang",
        "Xinyue Zhang",
        "Heng Zheng"
      ],
      "abstract": "The International Semantic Web Research School (ISWS) is a week-long\nintensive program designed to immerse participants in the field. This document\nreports a collaborative effort performed by ten teams of students, each guided\nby a senior researcher as their mentor, attending ISWS 2023. Each team provided\na different perspective to the topic of creative AI, substantiated by a set of\nresearch questions as the main subject of their investigation. The 2023 edition\nof ISWS focuses on the intersection of Semantic Web technologies and Creative\nAI. ISWS 2023 explored various intersections between Semantic Web technologies\nand creative AI. A key area of focus was the potential of LLMs as support tools\nfor knowledge engineering. Participants also delved into the multifaceted\napplications of LLMs, including legal aspects of creative content production,\nhumans in the loop, decentralised approaches to multimodal generative AI\nmodels, nanopublications and AI for personal scientific knowledge graphs,\ncommonsense knowledge in automatic story and narrative completion, generative\nAI for art critique, prompt engineering, automatic music composition,\ncommonsense prototyping and conceptual blending, and elicitation of tacit\nknowledge. As Large Language Models and semantic technologies continue to\nevolve, new exciting prospects are emerging: a future where the boundaries\nbetween creative expression and factual knowledge become increasingly permeable\nand porous, leading to a world of knowledge that is both informative and\ninspiring.",
      "tldr_zh": "本报告介绍了2023年国际语义网研究学校(ISWS 2023)的一项协作性技术报告，由10个学生团队在导师指导下，从不同角度探讨Semantic Web技术和Creative AI的交汇点，每个团队围绕一组研究问题进行调查。重点包括LLMs作为知识工程支持工具的应用，以及其在法律方面、人类参与、去中心化多模态生成AI、纳米出版物、常识知识故事生成、艺术评论、提示工程、音乐作曲和隐性知识提取等领域的多方面应用。随着LLMs和语义技术的不断演进，这将模糊创意表达与事实知识的界限，开启一个更具信息性和启发性的知识世界。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2501.18542v1",
      "published_date": "2025-01-30 18:10:16 UTC",
      "updated_date": "2025-01-30 18:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:49:09.126709"
    },
    {
      "arxiv_id": "2501.18539v1",
      "title": "Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Baile Chen",
        "Yi Zhang",
        "Michael Cafarella",
        "Dan Roth"
      ],
      "abstract": "Real-world open-domain questions can be complicated, particularly when\nanswering them involves information from multiple information sources. LLMs\nhave demonstrated impressive performance in decomposing complex tasks into\nsimpler steps, and previous work has used it for better retrieval in support of\ncomplex questions. However, LLM's decomposition of questions is unaware of what\ndata is available and how data is organized, often leading to a sub-optimal\nretrieval performance. Recent effort in agentic RAG proposes to perform\nretrieval in an iterative fashion, where a followup query is derived as an\naction based on previous rounds of retrieval. While this provides one way of\ninteracting with the data collection, agentic RAG's exploration of data is\ninefficient because successive queries depend on previous results rather than\nbeing guided by the organization of available data in the collection. To\naddress this problem, we propose an LLM-based retrieval method -- ARM, that\naims to better align the question with the organization of the data collection\nby exploring relationships among data objects beyond matching the utterance of\nthe query, thus leading to a retrieve-all-at-once solution for complex queries.\nWe evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperforms\nstandard RAG with query decomposition by up to 5.2 pt in execution accuracy and\nagentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and\n19.3 pt higher F1 match scores compared to these approaches.",
      "tldr_zh": "这篇论文针对复杂开放域查询的检索挑战，提出了ARM（Alignment-Oriented LLM-based Retrieval Method），该方法通过探索数据对象之间的关系（如超越简单查询匹配），更好地与数据集合的组织对齐，实现一次性检索所有相关信息，从而避免了传统agentic RAG的迭代 inefficiencies。ARM解决了LLM在查询分解时忽略数据可用性和组织的局限性，并在Bird数据集上比标准RAG提高执行准确率高达5.2 pt、比agentic RAG（ReAct）提高15.9 pt；在OTT-QA数据集上，F1匹配分数分别提高5.5 pt和19.3 pt。实验结果证明了ARM在处理多源信息查询时的显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18539v1",
      "published_date": "2025-01-30 18:07:19 UTC",
      "updated_date": "2025-01-30 18:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:49:21.488810"
    },
    {
      "arxiv_id": "2501.18535v1",
      "title": "A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre",
      "title_zh": "一种混合数据驱动方法，用于分析和预测健康中心的住院患者住院时长",
      "authors": [
        "Tasfia Noor Chowdhury",
        "Sanjida Afrin Mou",
        "Kazi Naimur Rahman"
      ],
      "abstract": "Patient length of stay (LoS) is a critical metric for evaluating the efficacy\nof hospital management. The primary objectives encompass to improve efficiency\nand reduce costs while enhancing patient outcomes and hospital capacity within\nthe patient journey. By seamlessly merging data-driven techniques with\nsimulation methodologies, the study proposes an all-encompassing framework for\nthe optimization of patient flow. Using a comprehensive dataset of 2.3 million\nde-identified patient records, we analyzed demographics, diagnoses, treatments,\nservices, costs, and charges with machine learning models (Decision Tree,\nLogistic Regression, Random Forest, Adaboost, LightGBM) and Python tools\n(Spark, AWS clusters, dimensionality reduction). Our model predicts patient\nlength of stay (LoS) upon admission using supervised learning algorithms. This\nhybrid approach enables the identification of key factors influencing LoS,\noffering a robust framework for hospitals to streamline patient flow and\nresource utilization. The research focuses on patient flow, corroborating the\nefficacy of the approach, illustrating decreased patient length of stay within\na real healthcare environment. The findings underscore the potential of hybrid\ndata-driven models in transforming hospital management practices. This\ninnovative methodology provides generally flexible decision-making, training,\nand patient flow enhancement; such a system could have huge implications for\nhealthcare administration and overall satisfaction with healthcare.",
      "tldr_zh": "这篇论文提出了一种混合数据驱动方法，用于分析和预测住院患者长度（Length of Stay, LoS），旨在提升医院管理效率、降低成本并优化患者流程。研究利用2.3百万匿名患者记录，通过机器学习模型（如Decision Tree、Logistic Regression、Random Forest、Adaboost和LightGBM）以及Python工具（Spark、AWS集群和降维技术）构建预测模型，识别影响LoS的关键因素。实验结果显示，该框架在真实医疗环境中显著减少了患者住院时间，并为医院资源利用和决策提供了一个灵活的优化框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18535v1",
      "published_date": "2025-01-30 18:01:48 UTC",
      "updated_date": "2025-01-30 18:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:49:33.012821"
    },
    {
      "arxiv_id": "2501.18670v1",
      "title": "High-Accuracy ECG Image Interpretation using Parameter-Efficient LoRA Fine-Tuning with Multimodal LLaMA 3.2",
      "title_zh": "翻译失败",
      "authors": [
        "Nandakishor M",
        "Anjali M"
      ],
      "abstract": "Electrocardiogram (ECG) interpretation is a cornerstone of cardiac\ndiagnostics. This paper explores a practical approach to enhance ECG image\ninterpretation using the multimodal LLaMA 3.2 model. We used a\nparameter-efficient fine-tuning strategy, Low-Rank Adaptation (LoRA),\nspecifically designed to boost the model's ability to understand ECG images and\nachieve better outcomes across a wide range of cardiac conditions. Our method\nis tailored for ECG analysis and leverages ECGInstruct, a large-scale\ninstruction dataset with 1 Million samples. This dataset is a rich collection\nof synthesized ECG images, generated from raw ECG data from trusted open-source\nrepositories like MIMIC-IV ECG and PTB-XL. Each ECG image in ECGInstruct comes\nwith expert-written questions and detailed answers, covering diverse ECG\ninterpretation scenarios, including complex cardiac conditions like Myocardial\nInfarction and Conduction Disturbances. Our fine-tuning approach efficiently\nadapts the LLaMA 3.2 model (built upon LLaMA 3) by integrating low-rank\nadaptation techniques, focusing on efficiency by updating only a small set of\nparameters, specifically ignoring the `lm_head` and `embed_tokens` layers. This\npaper details the model setup, our efficient fine-tuning method, and\nimplementation specifics. We provide a thorough evaluation through extensive\nexperiments, demonstrating the effectiveness of our method across various ECG\ninterpretation tasks. The results convincingly show that our\nparameter-efficient LoRA fine-tuning achieves excellent performance in ECG\nimage interpretation, significantly outperforming baseline models and reaching\naccuracy comparable to or exceeding traditional CNN-based methods in\nidentifying a wide range of cardiac abnormalities, including over 70 conditions\nfrom the PTB-XL dataset.",
      "tldr_zh": "本文提出了一种高精度ECG图像解释方法，使用多模态LLaMA 3.2模型结合参数高效的LoRA（Low-Rank Adaptation）微调策略，以提升模型对ECG图像的理解和诊断能力。研究利用ECGInstruct数据集，该数据集包含100万合成ECG图像及其专家编写的问答，基于MIMIC-IV ECG和PTB-XL等来源，覆盖多种心脏条件如心肌梗死和传导障碍。实验结果显示，该方法在各种ECG解释任务上显著优于基线模型和传统CNN方法，准确率在识别PTB-XL数据集中的70多种心脏异常时达到或超过基准水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18670v1",
      "published_date": "2025-01-30 17:55:27 UTC",
      "updated_date": "2025-01-30 17:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:49:45.049816"
    },
    {
      "arxiv_id": "2501.18504v3",
      "title": "CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction",
      "title_zh": "CLEAR：使用进化算法的提示",
      "authors": [
        "Peter J. Bentley",
        "Soo Ling Lim",
        "Fuyuki Ishikawa"
      ],
      "abstract": "Large Language Model (LLM) image recognition is a powerful tool for\nextracting data from images, but accuracy depends on providing sufficient cues\nin the prompt - requiring a domain expert for specialized tasks. We introduce\nCue Learning using Evolution for Accurate Recognition (CLEAR), which uses a\ncombination of LLMs and evolutionary computation to generate and optimize cues\nsuch that recognition of specialized features in images is improved. It\nachieves this by auto-generating a novel domain-specific representation and\nthen using it to optimize suitable textual cues with a genetic algorithm. We\napply CLEAR to the real-world task of identifying sustainability data from\ninterior and exterior images of buildings. We investigate the effects of using\na variable-length representation compared to fixed-length and show how LLM\nconsistency can be improved by refactoring from categorical to real-valued\nestimates. We show that CLEAR enables higher accuracy compared to expert human\nrecognition and human-authored prompts in every task with error rates improved\nby up to two orders of magnitude and an ablation study evincing solution\nconcision.",
      "tldr_zh": "本文提出 CLEAR 方法，利用 LLM 和进化计算（evolutionary computation）自动生成并优化提示中的线索（cues），以提高图像识别的准确性，尤其针对专业领域任务。CLEAR 通过创建领域特定表示并应用遗传算法（genetic algorithm）来优化文本线索，并将其应用于从建筑内部和外部图像中提取可持续性数据。实验结果显示，与人类专家和手动提示相比，CLEAR 显著降低了错误率（多达两个数量级），并通过消融研究证明了其解决方案的简洁性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE",
        "68W50, 68T07",
        "G.1.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages plus 2 pages of supplemental material",
      "pdf_url": "http://arxiv.org/pdf/2501.18504v3",
      "published_date": "2025-01-30 17:13:32 UTC",
      "updated_date": "2025-05-07 09:39:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:49:57.095585"
    },
    {
      "arxiv_id": "2501.18501v1",
      "title": "Beyond Prior Limits: Addressing Distribution Misalignment in Particle Filtering",
      "title_zh": "超越先验限制：解决",
      "authors": [
        "Yiwei Shi",
        "Jingyu Hu",
        "Yu Zhang",
        "Mengyue Yang",
        "Weinan Zhang",
        "Cunjia Liu",
        "Weiru Liu"
      ],
      "abstract": "Particle filtering is a Bayesian inference method and a fundamental tool in\nstate estimation for dynamic systems, but its effectiveness is often limited by\nthe constraints of the initial prior distribution, a phenomenon we define as\nthe Prior Boundary Phenomenon. This challenge arises when target states lie\noutside the prior's support, rendering traditional particle filtering methods\ninadequate for accurate estimation. Although techniques like unbounded priors\nand larger particle sets have been proposed, they remain computationally\nprohibitive and lack adaptability in dynamic scenarios. To systematically\novercome these limitations, we propose the Diffusion-Enhanced Particle\nFiltering Framework, which introduces three key innovations: adaptive diffusion\nthrough exploratory particles, entropy-driven regularisation to prevent weight\ncollapse, and kernel-based perturbations for dynamic support expansion. These\nmechanisms collectively enable particle filtering to explore beyond prior\nboundaries, ensuring robust state estimation for out-of-boundary targets.\nTheoretical analysis and extensive experiments validate framework's\neffectiveness, indicating significant improvements in success rates and\nestimation accuracy across high-dimensional and non-convex scenarios.",
      "tldr_zh": "粒子滤波(Particle Filtering) 在动态系统状态估计中常受“Prior Boundary Phenomenon”限制，即当目标状态超出初始先验分布支持时，传统方法无法准确估计。论文提出Diffusion-Enhanced Particle Filtering Framework，通过三个关键创新——自适应扩散探索粒子、熵驱动正则化防止权重崩溃，以及基于核的扰动动态扩展支持——来克服这一问题。该框架实现了对超出边界的目标的鲁棒估计，理论分析和实验验证显示，在高维和非凸场景中成功率和估计准确性显著提升。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18501v1",
      "published_date": "2025-01-30 17:11:34 UTC",
      "updated_date": "2025-01-30 17:11:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:50:09.021957"
    },
    {
      "arxiv_id": "2501.18492v1",
      "title": "GuardReasoner: Towards Reasoning-based LLM Safeguards",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Liu",
        "Hongcheng Gao",
        "Shengfang Zhai",
        "Jun Xia",
        "Tianyi Wu",
        "Zhiwei Xue",
        "Yulin Chen",
        "Kenji Kawaguchi",
        "Jiaheng Zhang",
        "Bryan Hooi"
      ],
      "abstract": "As LLMs increasingly impact safety-critical applications, ensuring their\nsafety using guardrails remains a key challenge. This paper proposes\nGuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn to\nreason. Concretely, we first create the GuardReasonerTrain dataset, which\nconsists of 127K samples with 460K detailed reasoning steps. Then, we introduce\nreasoning SFT to unlock the reasoning capability of guard models. In addition,\nwe present hard sample DPO to further strengthen their reasoning ability. In\nthis manner, GuardReasoner achieves better performance, explainability, and\ngeneralizability. Extensive experiments and analyses on 13 benchmarks of 3\nguardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8B\nsurpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score on\naverage. We release the training data, code, and models with different scales\n(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.",
      "tldr_zh": "该论文提出 GuardReasoner，一种基于推理的 LLM 安全防护机制，通过引导守卫模型学习推理来提升其性能和可解释性。具体方法包括创建 GuardReasonerTrain 数据集（包含 127K 样本和 460K 推理步骤）、引入 reasoning SFT 以解锁推理能力，以及采用 hard sample DPO 来强化模型。实验结果显示，GuardReasoner 在 13 个基准测试中表现出色，GuardReasoner 8B 模型的 F1 score 平均超过 GPT-4o+CoT 5.74% 和 LLaMA Guard 3 8B 20.84%。作者开源了数据、代码和不同规模的模型（1B、3B、8B）。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18492v1",
      "published_date": "2025-01-30 17:06:06 UTC",
      "updated_date": "2025-01-30 17:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:50:22.753096"
    },
    {
      "arxiv_id": "2501.18490v2",
      "title": "Curriculum-based Sample Efficient Reinforcement Learning for Robust Stabilization of a Quadrotor",
      "title_zh": "基于课程学习的样本高效强化学习用于四旋翼无人机的稳健稳定化",
      "authors": [
        "Fausto Mauricio Lagos Suarez",
        "Akshit Saradagi",
        "Vidya Sumathy",
        "Shruti Kotpaliwar",
        "George Nikolakopoulos"
      ],
      "abstract": "This article introduces a curriculum learning approach to develop a\nreinforcement learning-based robust stabilizing controller for a Quadrotor that\nmeets predefined performance criteria. The learning objective is to achieve\ndesired positions from random initial conditions while adhering to both\ntransient and steady-state performance specifications. This objective is\nchallenging for conventional one-stage end-to-end reinforcement learning, due\nto the strong coupling between position and orientation dynamics, the\ncomplexity in designing and tuning the reward function, and poor sample\nefficiency, which necessitates substantial computational resources and leads to\nextended convergence times. To address these challenges, this work decomposes\nthe learning objective into a three-stage curriculum that incrementally\nincreases task complexity. The curriculum begins with learning to achieve\nstable hovering from a fixed initial condition, followed by progressively\nintroducing randomization in initial positions, orientations and velocities. A\nnovel additive reward function is proposed, to incorporate transient and\nsteady-state performance specifications. The results demonstrate that the\nProximal Policy Optimization (PPO)-based curriculum learning approach, coupled\nwith the proposed reward structure, achieves superior performance compared to a\nsingle-stage PPO-trained policy with the same reward function, while\nsignificantly reducing computational resource requirements and convergence\ntime. The curriculum-trained policy's performance and robustness are thoroughly\nvalidated under random initial conditions and in the presence of disturbances.",
      "tldr_zh": "本文提出了一种基于 curriculum learning 的强化学习方法，用于开发四旋翼无人机（Quadrotor）的稳健稳定控制器，以实现从随机初始条件到达预定位置，同时满足瞬态和稳态性能标准。该方法将学习任务分解为三阶段课程：从固定初始条件稳定悬停开始，逐步引入初始位置、方向和速度的随机化，并设计了新型 additive reward function 来整合性能要求。实验结果显示，使用 Proximal Policy Optimization (PPO) 算法的课程学习方法相较于单阶段 PPO 策略，显著提高了样本效率、减少了计算资源和收敛时间，并在随机初始条件及干扰环境下验证了其优越性能和稳健性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18490v2",
      "published_date": "2025-01-30 17:05:32 UTC",
      "updated_date": "2025-04-17 11:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:50:34.502911"
    },
    {
      "arxiv_id": "2501.18669v1",
      "title": "The Pitfalls of \"Security by Obscurity\" And What They Mean for Transparent AI",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Hall",
        "Olivia Mundahl",
        "Sunoo Park"
      ],
      "abstract": "Calls for transparency in AI systems are growing in number and urgency from\ndiverse stakeholders ranging from regulators to researchers to users (with a\ncomparative absence of companies developing AI). Notions of transparency for AI\nabound, each addressing distinct interests and concerns.\n  In computer security, transparency is likewise regarded as a key concept. The\nsecurity community has for decades pushed back against so-called security by\nobscurity -- the idea that hiding how a system works protects it from attack --\nagainst significant pressure from industry and other stakeholders. Over the\ndecades, in a community process that is imperfect and ongoing, security\nresearchers and practitioners have gradually built up some norms and practices\naround how to balance transparency interests with possible negative side\neffects. This paper asks: What insights can the AI community take from the\nsecurity community's experience with transparency?\n  We identify three key themes in the security community's perspective on the\nbenefits of transparency and their approach to balancing transparency against\ncountervailing interests. For each, we investigate parallels and insights\nrelevant to transparency in AI. We then provide a case study discussion on how\ntransparency has shaped the research subfield of anonymization. Finally,\nshifting our focus from similarities to differences, we highlight key\ntransparency issues where modern AI systems present challenges different from\nother kinds of security-critical systems, raising interesting open questions\nfor the security and AI communities alike.",
      "tldr_zh": "这篇论文探讨了“Security by Obscurity”（安全通过模糊）的潜在陷阱，并分析其对AI透明性的启示。作者借鉴计算机安全社区的经验，识别了三个关键主题，包括透明性的益处及其与负面影响的权衡，并将其应用于AI领域。论文通过匿名化（anonymization）子领域的案例研究，展示了透明性如何塑造研究实践，同时突出了AI系统与传统安全系统不同的挑战，如独特的安全风险和开放问题。总的来说，这为AI社区提供了平衡透明性需求的实用见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "27 pages, abbreviated version in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18669v1",
      "published_date": "2025-01-30 17:04:35 UTC",
      "updated_date": "2025-01-30 17:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:50:44.970796"
    },
    {
      "arxiv_id": "2501.18475v1",
      "title": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Yanxia Deng",
        "Aozhong Zhang",
        "Naigang Wang",
        "Selcuk Gurses",
        "Zi Yang",
        "Penghang Yin"
      ],
      "abstract": "Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) has\nbecome a highly efficient approach for downstream tasks, particularly in\nscenarios with limited computational resources. However, applying LoRA\ntechniques to quantized LLMs poses unique challenges due to the reduced\nrepresentational precision of quantized weights. In this paper, we introduce\nCLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplistic\ninitialization strategy designed to overcome these challenges. Our approach\nfocuses on minimizing the layer-wise discrepancy between the original LLM and\nits quantized counterpart with LoRA components during initialization. By\nleveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM and\ndetermines the optimal LoRA components for each layer, ensuring a strong\nfoundation for subsequent fine-tuning. A key contribution of this work is a\nnovel theoretical result that enables the accurate and closed-form construction\nof these optimal LoRA components. We validate the efficacy of CLoQ across\nmultiple tasks such as language generation, arithmetic reasoning, and\ncommonsense reasoning, demonstrating that it consistently outperforms existing\nLoRA fine-tuning methods for quantized LLMs, especially at ultra low-bit\nwidths.",
      "tldr_zh": "该论文提出 CLoQ，一种校准的 LoRA 初始化策略，用于提升量化大型语言模型 (LLMs) 的微调效果，解决量化权重精度降低带来的挑战。CLoQ 通过利用小型校准数据集最小化层级差异，量化预训练 LLM 并计算每个层的优选 LoRA 组件，并引入一个新理论结果支持闭式形式构建这些组件。实验结果显示，CLoQ 在语言生成、算术推理和常识推理等任务上，尤其在超低位宽下，显著优于现有 LoRA 微调方法，提供更高效的量化 LLM 适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18475v1",
      "published_date": "2025-01-30 16:48:15 UTC",
      "updated_date": "2025-01-30 16:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:50:56.932761"
    },
    {
      "arxiv_id": "2501.18468v1",
      "title": "Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking",
      "title_zh": "超越指令性任务：在课堂",
      "authors": [
        "Eduardo Davalos",
        "Jorge Alberto Salas",
        "Yike Zhang",
        "Namrata Srivastava",
        "Yashvitha Thatigotla",
        "Abbey Gonzales",
        "Sara McFadden",
        "Sun-Joo Cho",
        "Gautam Biswas",
        "Amanda Goodwin"
      ],
      "abstract": "Understanding reader behaviors such as skimming, deep reading, and scanning\nis essential for improving educational instruction. While prior eye-tracking\nstudies have trained models to recognize reading behaviors, they often rely on\ninstructed reading tasks, which can alter natural behaviors and limit the\napplicability of these findings to in-the-wild settings. Additionally, there is\na lack of clear definitions for reading behavior archetypes in the literature.\nWe conducted a classroom study to address these issues by collecting instructed\nand in-the-wild reading data. We developed a mixed-method framework, including\na human-driven theoretical model, statistical analyses, and an AI classifier,\nto differentiate reading behaviors based on their velocity, density, and\nsequentiality. Our lightweight 2D CNN achieved an F1 score of 0.8 for behavior\nrecognition, providing a robust approach for understanding in-the-wild reading.\nThis work advances our ability to provide detailed behavioral insights to\neducators, supporting more targeted and effective assessment and instruction.",
      "tldr_zh": "本研究通过 eye tracking 技术，探讨课堂中 in-the-wild 阅读行为（如浏览、深度阅读和扫描），以克服现有方法依赖指导任务导致的自然行为偏差和定义不清晰问题。研究者开展课堂实验，收集指导性和真实阅读数据，并开发了一个混合框架，包括人类驱动的理论模型、统计分析和 AI 分类器，基于阅读行为的 velocity、density 和 sequentiality 进行区分。使用轻量级 2D CNN 模型，他们实现了 0.8 的 F1 score，在行为识别上显著提升。该工作为教育者提供详细的行为洞察，支持更针对性的评估和教学策略。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages, 16 figures, 6 tables, conference",
      "pdf_url": "http://arxiv.org/pdf/2501.18468v1",
      "published_date": "2025-01-30 16:39:31 UTC",
      "updated_date": "2025-01-30 16:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:51:09.980212"
    },
    {
      "arxiv_id": "2501.18668v1",
      "title": "Simulation Streams: A Programming Paradigm for Controlling Large Language Models and Building Complex Systems with Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Sunehag",
        "Joel Z. Leibo"
      ],
      "abstract": "We introduce Simulation Streams, a programming paradigm designed to\nefficiently control and leverage Large Language Models (LLMs) for complex,\ndynamic simulations and agentic workflows. Our primary goal is to create a\nminimally interfering framework that harnesses the agentic abilities of LLMs\nwhile addressing their limitations in maintaining consistency, selectively\nignoring/including information, and enforcing strict world rules. Simulation\nStreams achieves this through a state-based approach where variables are\nmodified in sequential steps by \"operators,\" producing output on a recurring\nformat and adhering to consistent rules for state variables. This approach\nfocus the LLMs on defined tasks, while aiming to have the context stream remain\n\"in-distribution\". The approach incorporates an Entity-Component-System (ECS)\narchitecture to write programs in a more intuitive manner, facilitating reuse\nof workflows across different components and entities. This ECS approach\nenhances the modularity of the output stream, allowing for complex,\nmulti-entity simulations while maintaining format consistency, information\ncontrol, and rule enforcement. It is supported by a custom editor that aids in\ncreating, running, and analyzing simulations. We demonstrate the versatility of\nsimulation streams through an illustrative example of an ongoing market economy\nsimulation, a social simulation of three characters playing a game of catch in\na park and a suite of classical reinforcement learning benchmark tasks. These\nexamples showcase Simulation Streams' ability to handle complex, evolving\nscenarios over 100s-1000s of iterations, facilitate comparisons between\ndifferent agent workflows and models, and maintain consistency and continued\ninteresting developments in LLM-driven simulations.",
      "tldr_zh": "我们引入了 Simulation Streams，一种编程范式，用于高效控制 Large Language Models (LLMs) 以构建复杂动态模拟和代理工作流。该框架采用状态-based 方法，通过 \"operators\" 在顺序步骤中修改变量，并结合 Entity-Component-System (ECS) 架构，确保信息控制、一致性和规则执行，同时支持模块化重用。Simulation Streams 配有自定义编辑器，便于创建、运行和分析模拟，并通过市场经济、社会互动和强化学习基准任务的示例，展示了其在数百到数千迭代的复杂场景中维持一致性、比较不同模型，并推动持续发展的能力。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical report accompanying the release of code on GitHub",
      "pdf_url": "http://arxiv.org/pdf/2501.18668v1",
      "published_date": "2025-01-30 16:38:03 UTC",
      "updated_date": "2025-01-30 16:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:51:22.602835"
    },
    {
      "arxiv_id": "2502.18467v1",
      "title": "ChatGPT vs. DeepSeek: A Comparative Study on AI-Based Code Generation",
      "title_zh": "ChatGPT 与 DeepSeek：基于 AI 的代码生成比较研究",
      "authors": [
        "Md Motaleb Hossen Manik"
      ],
      "abstract": "Background: AI-powered code generation, fueled by Large Language Models\n(LLMs), is revolutionizing software development. Models like OpenAI's Codex and\nGPT-4, alongside DeepSeek, leverage vast code and natural language datasets.\nHowever, ensuring code quality, correctness, and managing complex tasks remains\nchallenging, necessitating thorough evaluation. Methodology: This research\ncompares ChatGPT (version o1) and DeepSeek (version R1) for Python code\ngeneration using online judge coding challenges. It evaluates correctness\n(online judge verdicts, up to three attempts), code quality (Pylint/Flake8),\nand efficiency (execution time/memory usage). Results: DeepSeek demonstrated\nhigher correctness, particularly on algorithmic tasks, often achieving\n'Accepted' on the first attempt. ChatGPT sometimes requires multiple attempts\nor failures. ChatGPT encountered fewer issues, used comparable or slightly less\nmemory, consumed less execution times and wrote fewer lines of code.\nConclusion: DeepSeek exhibited superior correctness in Python code generation,\noften requiring fewer attempts, suggesting an advantage in algorithmic\nproblem-solving. Both models showed almost similar efficiency in execution time\nand memory use. Finally, this research provides insights for developers\nchoosing AI coding assistants and informs future AI-driven software development\nresearch.",
      "tldr_zh": "本研究比较了ChatGPT (o1版本)和DeepSeek (R1版本)在AI驱动的Python代码生成中的表现，采用在线评判系统评估正确性（通过尝试次数）、代码质量（Pylint/Flake8）和效率（执行时间/内存使用）。结果显示，DeepSeek在算法任务上表现出色，经常首次通过测试，而ChatGPT可能需多次尝试，尽管ChatGPT在代码问题更少、执行时间更短且代码行数更少。总体而言，DeepSeek在正确性方面更具优势，两者在效率上相似，该研究为开发者选择AI编码助手提供了宝贵见解，并推动了AI驱动软件开发的未来研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18467v1",
      "published_date": "2025-01-30 16:14:48 UTC",
      "updated_date": "2025-01-30 16:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:51:33.675719"
    },
    {
      "arxiv_id": "2501.18455v1",
      "title": "Conversation Games and a Strategic View of the Turing Test",
      "title_zh": "对话游戏与图灵测试的战略视角",
      "authors": [
        "Kaveh Aryan"
      ],
      "abstract": "Although many game-theoretic models replicate real interactions that often\nrely on natural language, explicit study of games where language is central to\nstrategic interaction remains limited. This paper introduces the\n\\emph{conversation game}, a multi-stage, extensive-form game based on\nlinguistic strategic interaction. We focus on a subset of the games, called\nverdict games. In a verdict game, two players alternate to contribute to a\nconversation, which is evaluated at each stage by a non-strategic judge who may\nrender a conclusive binary verdict, or a decision to continue the dialogue. The\ngame ends once a limit is reached or a verdict is given. We show many familiar\nprocesses, such as interrogation or a court process fall under this category.\nWe also, show that the Turing test is an instance of verdict game, and discuss\nthe significance of a strategic view of the Turing test in the age of advanced\nAI deception. We show the practical relevance of the proposed concepts by\nsimulation experiments, and show that a strategic agent outperforms a naive\nagent by a high margin.",
      "tldr_zh": "这篇论文引入了“conversation game”，一种基于语言的战略互动多阶段博弈，特别聚焦于“verdict games”，其中两名玩家交替贡献对话，由非战略性裁判评估是否给出二元结论或继续。论文证明了许多熟悉过程如审讯或法庭程序属于此类游戏，并将“Turing Test”视为其实例，强调在AI欺骗时代采用战略视角的重要性。通过模拟实验，研究显示战略代理在表现上远超naive代理，提供了一个新的框架来分析语言在博弈中的作用。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18455v1",
      "published_date": "2025-01-30 16:08:37 UTC",
      "updated_date": "2025-01-30 16:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:51:45.411139"
    },
    {
      "arxiv_id": "2501.18452v2",
      "title": "Clustering Properties of Self-Supervised Learning",
      "title_zh": "自我监督学习的聚类特性",
      "authors": [
        "Xi Weng",
        "Jianing An",
        "Xudong Ma",
        "Binhang Qi",
        "Jie Luo",
        "Xi Yang",
        "Jin Song Dong",
        "Lei Huang"
      ],
      "abstract": "Self-supervised learning (SSL) methods via joint embedding architectures have\nproven remarkably effective at capturing semantically rich representations with\nstrong clustering properties, magically in the absence of label supervision.\nDespite this, few of them have explored leveraging these untapped properties to\nimprove themselves. In this paper, we provide an evidence through various\nmetrics that the encoder's output $encoding$ exhibits superior and more stable\nclustering properties compared to other components. Building on this insight,\nwe propose a novel positive-feedback SSL method, termed Representation\nSelf-Assignment (ReSA), which leverages the model's clustering properties to\npromote learning in a self-guided manner. Extensive experiments on standard SSL\nbenchmarks reveal that models pretrained with ReSA outperform other\nstate-of-the-art SSL methods by a significant margin. Finally, we analyze how\nReSA facilitates better clustering properties, demonstrating that it\neffectively enhances clustering performance at both fine-grained and\ncoarse-grained levels, shaping representations that are inherently more\nstructured and semantically meaningful.",
      "tldr_zh": "自监督学习 (SSL) 通过联合嵌入架构能够捕获语义丰富的表示，这些表示具有强烈的聚类属性，但缺乏标签监督。论文发现，编码器的输出 (encoding) 比其他组件更优越且稳定的聚类性能，并提出了一种新方法 Representation Self-Assignment (ReSA)，利用这些属性进行正反馈自我引导学习。在标准 SSL 基准上的广泛实验显示，ReSA 预训练模型显著优于现有最先进方法。最后，分析表明 ReSA 提升了细粒度和粗粒度水平的聚类性能，使表示更结构化和语义丰富。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18452v2",
      "published_date": "2025-01-30 16:05:35 UTC",
      "updated_date": "2025-05-11 12:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:51:58.830409"
    },
    {
      "arxiv_id": "2501.18448v1",
      "title": "Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems",
      "title_zh": "在机器人和自治系统的早期开发中的自治与安全保障",
      "authors": [
        "Dhaminda B. Abeywickrama",
        "Michael Fisher",
        "Frederic Wheeler",
        "Louise Dennis"
      ],
      "abstract": "This report provides an overview of the workshop titled Autonomy and Safety\nAssurance in the Early Development of Robotics and Autonomous Systems, hosted\nby the Centre for Robotic Autonomy in Demanding and Long-Lasting Environments\n(CRADLE) on September 2, 2024, at The University of Manchester, UK. The event\nbrought together representatives from six regulatory and assurance bodies\nacross diverse sectors to discuss challenges and evidence for ensuring the\nsafety of autonomous and robotic systems, particularly autonomous inspection\nrobots (AIR). The workshop featured six invited talks by the regulatory and\nassurance bodies. CRADLE aims to make assurance an integral part of engineering\nreliable, transparent, and trustworthy autonomous systems. Key discussions\nrevolved around three research questions: (i) challenges in assuring safety for\nAIR; (ii) evidence for safety assurance; and (iii) how assurance cases need to\ndiffer for autonomous systems. Following the invited talks, the breakout groups\nfurther discussed the research questions using case studies from ground (rail),\nnuclear, underwater, and drone-based AIR. This workshop offered a valuable\nopportunity for representatives from industry, academia, and regulatory bodies\nto discuss challenges related to assured autonomy. Feedback from participants\nindicated a strong willingness to adopt a design-for-assurance process to\nensure that robots are developed and verified to meet regulatory expectations.",
      "tldr_zh": "该报告概述了2024年9月2日在英国曼彻斯特大学由CRADLE主办的工作坊“Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems”，聚焦于机器人和自主系统的安全保障，特别是Autonomous Inspection Robots (AIR)。工作坊邀请了六个监管机构的代表，通过六场演讲和分组讨论，探讨了三大研究问题：AIR的安全保障挑战、安全证据，以及自主系统的保障案例差异。讨论基于地面（如铁路）、核能、水下和无人机等案例研究，强调将保障融入可靠、透明和可信自主系统的工程过程。参与者反馈显示，行业、学术和监管机构强烈支持采用design-for-assurance流程，以确保机器人开发符合监管要求。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18448v1",
      "published_date": "2025-01-30 16:00:26 UTC",
      "updated_date": "2025-01-30 16:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:52:09.661368"
    },
    {
      "arxiv_id": "2501.18666v1",
      "title": "Structure Development in List-Sorting Transformers",
      "title_zh": "列表排序 Transformer 中的结构发展",
      "authors": [
        "Einar Urdshals",
        "Jasmina Urdshals"
      ],
      "abstract": "We study how a one-layer attention-only transformer develops relevant\nstructures while learning to sort lists of numbers. At the end of training, the\nmodel organizes its attention heads in two main modes that we refer to as\nvocabulary-splitting and copy-suppression. Both represent simpler modes than\nhaving multiple heads handle overlapping ranges of numbers. Interestingly,\nvocabulary-splitting is present regardless of whether we use weight decay, a\ncommon regularization technique thought to drive simplification, supporting the\nthesis that neural networks naturally prefer simpler solutions. We relate\ncopy-suppression to a mechanism in GPT-2 and investigate its functional role in\nour model. Guided by insights from a developmental analysis of the model, we\nidentify features in the training data that drive the model's final acquired\nsolution. This provides a concrete example of how the training data shape the\ninternal organization of transformers, paving the way for future studies that\ncould help us better understand how LLMs develop their internal structures.",
      "tldr_zh": "本论文研究了单层注意力-only transformer 在学习排序数字列表过程中如何发展内部结构。训练结束后，模型的注意力 heads 组织成两种主要模式：vocabulary-splitting 和 copy-suppression，这两种模式比多个 heads 处理重叠范围更简单，且 vocabulary-splitting 的出现不依赖 weight decay，进一步支持神经网络偏好简单解决方案的观点。通过对模型发展的分析，论文识别出训练数据中的特征如何影响最终结构，并将 copy-suppression 与 GPT-2 中的机制联系起来，为理解 LLMs 的内部组织提供了一个具体示例。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "15+19 pages, 6+13 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18666v1",
      "published_date": "2025-01-30 15:56:25 UTC",
      "updated_date": "2025-01-30 15:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:52:21.669924"
    },
    {
      "arxiv_id": "2501.18444v1",
      "title": "Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms",
      "title_zh": "用于室内导航辅助的自适应物体检测：实时算法的性能评估",
      "authors": [
        "Abhinav Pratap",
        "Sushant Kumar",
        "Suchinton Chakravarty"
      ],
      "abstract": "This study addresses the need for accurate and efficient object detection in\nassistive technologies for visually impaired individuals. We evaluate four\nreal-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNN\nwithin the context of indoor navigation assistance. Using the Indoor Objects\nDetection dataset, we analyze detection accuracy, processing speed, and\nadaptability to indoor environments. Our findings highlight the trade-offs\nbetween precision and efficiency, offering insights into selecting optimal\nalgorithms for realtime assistive navigation. This research advances adaptive\nmachine learning applications, enhancing indoor navigation solutions for the\nvisually impaired and promoting accessibility.",
      "tldr_zh": "这篇论文评估了 YOLO、SSD、Faster R-CNN 和 Mask R-CNN 等实时物体检测算法在室内导航辅助中的性能，针对视觉障碍者的需求。研究使用 Indoor Objects Detection 数据集分析了这些算法的检测准确性、处理速度以及对室内环境的适应性。结果突出了精度与效率之间的权衡，并提供了选择最优算法的实用见解。该工作推进了自适应机器学习应用，提升了视觉障碍者的室内导航解决方案，促进了整体可访问性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.18444v1",
      "published_date": "2025-01-30 15:56:20 UTC",
      "updated_date": "2025-01-30 15:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:52:33.807015"
    },
    {
      "arxiv_id": "2501.18441v1",
      "title": "From Public Square to Echo Chamber: The Fragmentation of Online Discourse",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Pratap",
        "Amit Pathak"
      ],
      "abstract": "This paper examines how social media algorithms and filter bubbles contribute\nto the fragmentation of online discourse, fostering ideological divides and\nundermining shared understanding. Drawing on Michael Sandels philosophical\nemphasis on community and shared values, the study explores how digital\nplatforms amplify discrimination discourse including sexism, racism,\nxenophobia, ableism, homophobia, and religious intolerance during periods of\nheightened societal tension. By analyzing the dynamics of digital communities,\nthe research highlights mechanisms driving the emergence and evolution of\ndiscourse fragments in response to real world events. The findings reveal how\nsocial media structures exacerbate polarization, restrict cross group dialogue,\nand erode the collective reasoning essential for a just society. This study\nsituates philosophical perspectives within a computational analysis of social\nmedia interactions, offering a nuanced understanding of the challenges posed by\nfragmented discourse in the digital age.",
      "tldr_zh": "本论文探讨了社交媒体算法和filter bubbles如何导致在线话语碎片化，促进意识形态分歧，并放大歧视性话语，如sexism、racism、xenophobia、ableism、homophobia和religious intolerance。研究结合Michael Sandel的哲学观点，强调社区和共享价值观，通过对数字社区动态的computational analysis，分析了这些机制在响应真实世界事件时的演变。发现显示，社交媒体结构加剧polarization、限制cross-group dialogue，并侵蚀了just society所需的集体推理，为数字时代碎片化话语的挑战提供了nuanced understanding。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.18441v1",
      "published_date": "2025-01-30 15:53:58 UTC",
      "updated_date": "2025-01-30 15:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:52:47.057364"
    },
    {
      "arxiv_id": "2501.18438v2",
      "title": "o3-mini vs DeepSeek-R1: Which One is Safer?",
      "title_zh": "翻译失败",
      "authors": [
        "Aitor Arrieta",
        "Miriam Ugarte",
        "Pablo Valle",
        "José Antonio Parejo",
        "Sergio Segura"
      ],
      "abstract": "The irruption of DeepSeek-R1 constitutes a turning point for the AI industry\nin general and the LLMs in particular. Its capabilities have demonstrated\noutstanding performance in several tasks, including creative thinking, code\ngeneration, maths and automated program repair, at apparently lower execution\ncost. However, LLMs must adhere to an important qualitative property, i.e.,\ntheir alignment with safety and human values. A clear competitor of DeepSeek-R1\nis its American counterpart, OpenAI's o3-mini model, which is expected to set\nhigh standards in terms of performance, safety and cost. In this technical\nreport, we systematically assess the safety level of both DeepSeek-R1 (70b\nversion) and OpenAI's o3-mini (beta version). To this end, we make use of our\nrecently released automated safety testing tool, named ASTRAL. By leveraging\nthis tool, we automatically and systematically generated and executed 1,260\ntest inputs on both models. After conducting a semi-automated assessment of the\noutcomes provided by both LLMs, the results indicate that DeepSeek-R1 produces\nsignificantly more unsafe responses (12%) than OpenAI's o3-mini (1.2%).",
      "tldr_zh": "这篇论文比较了DeepSeek-R1和OpenAI的o3-mini模型在安全性和对齐性方面的表现，评估了LLMs是否符合人类价值观的要求。作者使用ASTRAL工具自动生成并执行1260个测试输入，对DeepSeek-R1 (70b版本)和o3-mini (beta版本)进行系统评估。结果显示，DeepSeek-R1的unsafe响应率高达12%，显著高于o3-mini的1.2%，这突显了在提升LLMs性能的同时加强安全对齐的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2501.17749",
      "pdf_url": "http://arxiv.org/pdf/2501.18438v2",
      "published_date": "2025-01-30 15:45:56 UTC",
      "updated_date": "2025-01-31 15:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:52:57.035701"
    },
    {
      "arxiv_id": "2501.18665v1",
      "title": "BARNN: A Bayesian Autoregressive and Recurrent Neural Network",
      "title_zh": "BARNN：贝叶斯自回归和循环神经网络",
      "authors": [
        "Dario Coscia",
        "Max Welling",
        "Nicola Demo",
        "Gianluigi Rozza"
      ],
      "abstract": "Autoregressive and recurrent networks have achieved remarkable progress\nacross various fields, from weather forecasting to molecular generation and\nLarge Language Models. Despite their strong predictive capabilities, these\nmodels lack a rigorous framework for addressing uncertainty, which is key in\nscientific applications such as PDE solving, molecular generation and Machine\nLearning Force Fields. To address this shortcoming we present BARNN: a\nvariational Bayesian Autoregressive and Recurrent Neural Network. BARNNs aim to\nprovide a principled way to turn any autoregressive or recurrent model into its\nBayesian version. BARNN is based on the variational dropout method, allowing to\napply it to large recurrent neural networks as well. We also introduce a\ntemporal version of the \"Variational Mixtures of Posteriors\" prior\n(tVAMP-prior) to make Bayesian inference efficient and well-calibrated.\nExtensive experiments on PDE modelling and molecular generation demonstrate\nthat BARNN not only achieves comparable or superior accuracy compared to\nexisting methods, but also excels in uncertainty quantification and modelling\nlong-range dependencies.",
      "tldr_zh": "本文提出 BARNN，一种 variational Bayesian Autoregressive and Recurrent Neural Network，旨在为 autoregressive 和 recurrent 模型提供严格的不确定性处理框架，适用于科学领域如 PDE 建模和分子生成。BARNN 基于 variational dropout 方法，将现有模型转化为其 Bayesian 版本，并引入 temporal version of the \"Variational Mixtures of Posteriors\" prior (tVAMP-prior)，以提升推理效率和校准精度。在广泛实验中，BARNN 实现了与现有方法相当或更高的准确性，并在 uncertainty quantification 和 modelling long-range dependencies 方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18665v1",
      "published_date": "2025-01-30 15:44:04 UTC",
      "updated_date": "2025-01-30 15:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:53:10.160983"
    },
    {
      "arxiv_id": "2501.18664v1",
      "title": "Rethinking the Upsampling Layer in Hyperspectral Image Super Resolution",
      "title_zh": "重新思考高光谱图像超分辨率中的上采样层",
      "authors": [
        "Haohan Shi",
        "Fei Zhou",
        "Xin Sun",
        "Jungong Han"
      ],
      "abstract": "Deep learning has achieved significant success in single hyperspectral image\nsuper-resolution (SHSR); however, the high spectral dimensionality leads to a\nheavy computational burden, thus making it difficult to deploy in real-time\nscenarios. To address this issue, this paper proposes a novel lightweight SHSR\nnetwork, i.e., LKCA-Net, that incorporates channel attention to calibrate\nmulti-scale channel features of hyperspectral images. Furthermore, we\ndemonstrate, for the first time, that the low-rank property of the learnable\nupsampling layer is a key bottleneck in lightweight SHSR methods. To address\nthis, we employ the low-rank approximation strategy to optimize the parameter\nredundancy of the learnable upsampling layer. Additionally, we introduce a\nknowledge distillation-based feature alignment technique to ensure the low-rank\napproximated network retains the same feature representation capacity as the\noriginal. We conducted extensive experiments on the Chikusei, Houston 2018, and\nPavia Center datasets compared to some SOTAs. The results demonstrate that our\nmethod is competitive in performance while achieving speedups of several dozen\nto even hundreds of times compared to other well-performing SHSR methods.",
      "tldr_zh": "这篇论文重新审视了高光谱图像超分辨率(SHSR)中的上采样层，提出了一种轻量级网络LKCA-Net，通过channel attention机制来校准多尺度通道特征，从而减轻计算负担。论文首次指出上采样层的low-rank特性是轻量级SHSR方法的瓶颈，并采用low-rank approximation策略优化参数冗余，同时引入knowledge distillation-based特征对齐技术，确保网络保留原有的特征表示能力。在Chikusei、Houston 2018和Pavia Center数据集上的实验显示，该方法在性能上与SOTA方法相当，但速度提升了数十到数百倍。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18664v1",
      "published_date": "2025-01-30 15:43:34 UTC",
      "updated_date": "2025-01-30 15:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:53:22.210691"
    },
    {
      "arxiv_id": "2501.18432v3",
      "title": "Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Pablo Miranda-Rodriguez",
        "Andreas Oikonomakis",
        "Matic Petrič",
        "Alejandra Ruiz",
        "Sebastian Bock",
        "Michail-Alexandros Kourtis"
      ],
      "abstract": "This paper presents a novel hybrid approach to solving real-world drone\nrouting problems by leveraging the capabilities of quantum computing. The\nproposed method, coined Quantum for Drone Routing (Q4DR), integrates the two\nmost prominent paradigms in the field: quantum gate-based computing, through\nthe Eclipse Qrisp programming language; and quantum annealers, by means of\nD-Wave System's devices. The algorithm is divided into two different phases: an\ninitial clustering phase executed using a Quantum Approximate Optimization\nAlgorithm (QAOA), and a routing phase employing quantum annealers. The efficacy\nof Q4DR is demonstrated through three use cases of increasing complexity, each\nincorporating real-world constraints such as asymmetric costs, forbidden paths,\nand itinerant charging points. This research contributes to the growing body of\nwork in quantum optimization, showcasing the practical applications of quantum\ncomputing in logistics and route planning.",
      "tldr_zh": "本研究提出了一种混合方法 Q4DR，用于解决无人机路由问题，通过整合量子门计算（使用 Eclipse Qrisp）和量子退火（D-Wave 系统）。算法分为两个阶段：初始聚类阶段采用 Quantum Approximate Optimization Algorithm (QAOA)，随后路由阶段利用量子退火处理实际约束，如不对称成本、禁止路径和流动充电点。实验通过三个复杂度递增的真实案例验证了 Q4DR 的有效性，展示了量子计算在物流和路线规划中的实际应用潜力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 5 figures. Paper accepted for being presented in the IEEE\n  Congress on Evolutionary Computation (IEEE CEC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.18432v3",
      "published_date": "2025-01-30 15:38:40 UTC",
      "updated_date": "2025-03-21 09:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:53:33.558619"
    },
    {
      "arxiv_id": "2501.18426v1",
      "title": "Guaranteed confidence-band enclosures for PDE surrogates",
      "title_zh": "翻译失败",
      "authors": [
        "Ander Gray",
        "Vignesh Gopakumar",
        "Sylvain Rousseau",
        "Sébastien Destercke"
      ],
      "abstract": "We propose a method for obtaining statistically guaranteed confidence bands\nfor functional machine learning techniques: surrogate models which map between\nfunction spaces, motivated by the need build reliable PDE emulators. The method\nconstructs nested confidence sets on a low-dimensional representation (an SVD)\nof the surrogate model's prediction error, and then maps these sets to the\nprediction space using set-propagation techniques. The result are\nconformal-like coverage guaranteed prediction sets for functional surrogate\nmodels. We use zonotopes as basis of the set construction, due to their well\nstudied set-propagation and verification properties. The method is model\nagnostic and can thus be applied to complex Sci-ML models, including Neural\nOperators, but also in simpler settings. We also elicit a technique to capture\nthe truncation error of the SVD, ensuring the guarantees of the method.",
      "tldr_zh": "本研究提出了一种方法，用于为功能机器学习技术（如PDE surrogates）构建统计上可靠的置信带（confidence bands），以提升PDE仿真器的可靠性。该方法在代理模型预测误差的低维表示（SVD）上创建嵌套置信集，并通过集合传播（set-propagation）技术映射回预测空间，使用zonotopes作为基础以确保准确性与验证性。此外，该方法模型无关，可应用于复杂Sci-ML模型（如Neural Operators），并通过处理SVD的截断误差，提供保形覆盖（conformal-like）的预测保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18426v1",
      "published_date": "2025-01-30 15:29:41 UTC",
      "updated_date": "2025-01-30 15:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:53:45.892147"
    },
    {
      "arxiv_id": "2501.18413v1",
      "title": "GBFRS: Robust Fuzzy Rough Sets via Granular-ball Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyin Xia",
        "Xiaoyu Lian",
        "Binbin Sang",
        "Guoyin Wang",
        "Xinbo Gao"
      ],
      "abstract": "Fuzzy rough set theory is effective for processing datasets with complex\nattributes, supported by a solid mathematical foundation and closely linked to\nkernel methods in machine learning. Attribute reduction algorithms and\nclassifiers based on fuzzy rough set theory exhibit promising performance in\nthe analysis of high-dimensional multivariate complex data. However, most\nexisting models operate at the finest granularity, rendering them inefficient\nand sensitive to noise, especially for high-dimensional big data. Thus,\nenhancing the robustness of fuzzy rough set models is crucial for effective\nfeature selection. Muiti-garanularty granular-ball computing, a recent\ndevelopment, uses granular-balls of different sizes to adaptively represent and\ncover the sample space, performing learning based on these granular-balls. This\npaper proposes integrating multi-granularity granular-ball computing into fuzzy\nrough set theory, using granular-balls to replace sample points. The\ncoarse-grained characteristics of granular-balls make the model more robust.\nAdditionally, we propose a new method for generating granular-balls, scalable\nto the entire supervised method based on granular-ball computing. A forward\nsearch algorithm is used to select feature sequences by defining the\ncorrelation between features and categories through dependence functions.\nExperiments demonstrate the proposed model's effectiveness and superiority over\nbaseline methods.",
      "tldr_zh": "该论文提出GBFRS模型，通过整合多粒度颗粒球计算(Granular-ball Computing)到Fuzzy Rough Sets理论中，使用颗粒球代替样本点，以提升模型对高维大数据噪声的鲁棒性和效率。\n新方法包括一种可扩展的颗粒球生成技术，以及基于依赖函数的前向搜索算法，用于定义特征与类别的相关性并进行特征选择。\n实验结果显示，GBFRS在处理复杂数据集时表现出色，优于现有基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18413v1",
      "published_date": "2025-01-30 15:09:26 UTC",
      "updated_date": "2025-01-30 15:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:53:57.919040"
    },
    {
      "arxiv_id": "2501.18411v1",
      "title": "Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Nolan Koblischke",
        "Hyunseok Jang",
        "Kristen Menou",
        "Mohamad Ali-Dib"
      ],
      "abstract": "Modern science emerged from reasoning over repeatedly-observed planetary\nmotions. We present Gravity-Bench-v1, an environment-based benchmark that\nchallenges AI agents on tasks that parallel this historical development.\nGravity-Bench-v1 evaluates agents on the discovery of physics concealed within\na dynamic environment, using rigorous gravitational dynamics simulations.\nGravity-Bench includes out-of-distribution cases, i.e. with physics that\ndeviates from the real world, to evaluate true scientific generalization\ncapabilities. Agents must plan to collect data within an experimental budget\nand must perform a dynamic form of data analysis and reasoning to solve tasks\nefficiently. Our benchmark admits an open-ended space of solutions. PhD-level\nsolutions for each task are provided, to calibrate AI performance against human\nexpertise. Technically at an upper-undergraduate level, our benchmark proves\nchallenging to baseline AI agents. Gravity-Bench-v1 and planned extensions\nshould help map out AI progress towards scientific discovery capabilities.",
      "tldr_zh": "该论文引入了 Gravity-Bench-v1，这是一个基于环境的环境基准，用于评估 AI agents 在发现重力物理规律方面的能力，模拟历史科学发展过程。基准利用严格的 gravitational dynamics simulations，包括 out-of-distribution cases，要求代理在实验预算内规划数据收集并进行动态数据分析和推理，以测试其科学泛化能力。尽管技术水平相当于本科高级课程，该基准对基线 AI agents 证明具有挑战性，并提供了 PhD-level 解决方案作为人类专家性能的参考，有助于映射 AI 在科学发现方面的进展。",
      "categories": [
        "cs.AI",
        "astro-ph.IM",
        "physics.comp-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical report - Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2501.18411v1",
      "published_date": "2025-01-30 15:06:34 UTC",
      "updated_date": "2025-01-30 15:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:54:09.653755"
    },
    {
      "arxiv_id": "2501.18403v1",
      "title": "Efficient Transformer for High Resolution Image Motion Deblurring",
      "title_zh": "高效 Transformer 用于高分辨率图像运动去模糊",
      "authors": [
        "Amanturdieva Akmaral",
        "Muhammad Hamza Zafar"
      ],
      "abstract": "This paper presents a comprehensive study and improvement of the Restormer\narchitecture for high-resolution image motion deblurring. We introduce\narchitectural modifications that reduce model complexity by 18.4% while\nmaintaining or improving performance through optimized attention mechanisms.\nOur enhanced training pipeline incorporates additional transformations\nincluding color jitter, Gaussian blur, and perspective transforms to improve\nmodel robustness as well as a new frequency loss term. Extensive experiments on\nthe RealBlur-R, RealBlur-J, and Ultra-High-Definition Motion blurred (UHDM)\ndatasets demonstrate the effectiveness of our approach. The improved\narchitecture shows better convergence behavior and reduced training time while\nmaintaining competitive performance across challenging scenarios. We also\nprovide detailed ablation studies analyzing the impact of our modifications on\nmodel behavior and performance. Our results suggest that thoughtful\narchitectural simplification combined with enhanced training strategies can\nyield more efficient yet equally capable models for motion deblurring tasks.\nCode and Data Available at: https://github.com/hamzafer/image-deblurring",
      "tldr_zh": "本研究针对高分辨率图像运动去模糊，改进Restormer架构，通过优化attention mechanisms减少模型复杂度18.4%，并保持或提升性能。研究引入增强训练管道，包括color jitter、Gaussian blur和perspective transforms，以及新增frequency loss term，以提高模型鲁棒性和收敛行为。在RealBlur-R、RealBlur-J和UHDM数据集上的广泛实验显示，该改进架构显著缩短训练时间，同时保持竞争性能，并通过消融研究验证了各修改的影响。整体结果表明，架构简化结合优化训练策略，能实现更高效的运动去模糊模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 18 figures Submitted as a preprint, no prior\n  journal/conference submission",
      "pdf_url": "http://arxiv.org/pdf/2501.18403v1",
      "published_date": "2025-01-30 14:58:33 UTC",
      "updated_date": "2025-01-30 14:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:54:22.362005"
    },
    {
      "arxiv_id": "2501.18663v1",
      "title": "Joint Optimization of Prompt Security and System Performance in Edge-Cloud LLM Systems",
      "title_zh": "Edge-Cloud LLM 系统中的提示安全与系统性能的联合优化",
      "authors": [
        "Haiyang Huang",
        "Tianhui Meng",
        "Weijia Jia"
      ],
      "abstract": "Large language models (LLMs) have significantly facilitated human life, and\nprompt engineering has improved the efficiency of these models. However, recent\nyears have witnessed a rise in prompt engineering-empowered attacks, leading to\nissues such as privacy leaks, increased latency, and system resource wastage.\nThough safety fine-tuning based methods with Reinforcement Learning from Human\nFeedback (RLHF) are proposed to align the LLMs, existing security mechanisms\nfail to cope with fickle prompt attacks, highlighting the necessity of\nperforming security detection on prompts. In this paper, we jointly consider\nprompt security, service latency, and system resource optimization in\nEdge-Cloud LLM (EC-LLM) systems under various prompt attacks. To enhance prompt\nsecurity, a vector-database-enabled lightweight attack detector is proposed. We\nformalize the problem of joint prompt detection, latency, and resource\noptimization into a multi-stage dynamic Bayesian game model. The equilibrium\nstrategy is determined by predicting the number of malicious tasks and updating\nbeliefs at each stage through Bayesian updates. The proposed scheme is\nevaluated on a real implemented EC-LLM system, and the results demonstrate that\nour approach offers enhanced security, reduces the service latency for benign\nusers, and decreases system resource consumption compared to state-of-the-art\nalgorithms.",
      "tldr_zh": "该论文探讨了在 Edge-Cloud LLM (EC-LLM) 系统下，如何联合优化 prompt 安全、服务延迟和系统资源，以应对 prompt attacks 导致的隐私泄露、延迟增加和资源浪费问题。作者提出了一种基于 vector-database 的轻量级攻击检测器，并将问题形式化为多阶段动态 Bayesian 游戏模型，通过预测恶意任务数量和 Bayesian updates 来确定平衡策略。实验结果显示，该方法在真实 EC-LLM 系统上显著提升了安全性，减少了良性用户的服务延迟，并降低了系统资源消耗。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18663v1",
      "published_date": "2025-01-30 14:33:49 UTC",
      "updated_date": "2025-01-30 14:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:54:34.092986"
    },
    {
      "arxiv_id": "2502.12012v2",
      "title": "Evolving Hard Maximum Cut Instances for Quantum Approximate Optimization Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Shuaiqun Pan",
        "Yash J. Patel",
        "Aneta Neumann",
        "Frank Neumann",
        "Thomas Bäck",
        "Hao Wang"
      ],
      "abstract": "Variational quantum algorithms, such as the Recursive Quantum Approximate\nOptimization Algorithm (RQAOA), have become increasingly popular, offering\npromising avenues for employing Noisy Intermediate-Scale Quantum devices to\naddress challenging combinatorial optimization tasks like the maximum cut\nproblem. In this study, we utilize an evolutionary algorithm equipped with a\nunique fitness function. This approach targets hard maximum cut instances\nwithin the latent space of a Graph Autoencoder, identifying those that pose\nsignificant challenges or are particularly tractable for RQAOA, in contrast to\nthe classic Goemans and Williamson algorithm. Our findings not only delineate\nthe distinct capabilities and limitations of each algorithm but also expand our\nunderstanding of RQAOA's operational limits. Furthermore, the diverse set of\ngraphs we have generated serves as a crucial benchmarking asset, emphasizing\nthe need for more advanced algorithms to tackle combinatorial optimization\nchallenges. Additionally, our results pave the way for new avenues in graph\ngeneration research, offering exciting opportunities for future explorations.",
      "tldr_zh": "本研究利用 evolutionary algorithm 结合独特适应度函数，在 Graph Autoencoder 的潜在空间中生成困难的 Maximum Cut 实例，以评估 Recursive Quantum Approximate Optimization Algorithm (RQAOA) 的性能，并与经典 Goemans and Williamson algorithm 进行对比。结果显示，该方法突显了 RQAOA 的优势和局限性，帮助理解其运算边界，同时生成的多样化图集作为重要基准资源，强调了开发更先进算法的必要性。该工作还为图生成研究开辟新路径，提供未来探索的机会。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.NE",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "This work has been accepted for publication and presentation at GECCO\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2502.12012v2",
      "published_date": "2025-01-30 14:32:06 UTC",
      "updated_date": "2025-04-15 05:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:54:45.423898"
    },
    {
      "arxiv_id": "2501.18367v1",
      "title": "A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Wang",
        "Hongfeng Ai",
        "Ruiqi Li",
        "Maowei Jiang",
        "Cheng Jiang",
        "Chenzhong Li"
      ],
      "abstract": "In medical time series disease diagnosis, two key challenges are\nidentified.First, the high annotation cost of medical data leads to overfitting\nin models trained on label-limited, single-center datasets. To address this, we\npropose incorporating external data from related tasks and leveraging AE-GAN to\nextract prior knowledge,providing valuable references for downstream tasks.\nSecond, many existing studies employ contrastive learning to derive more\ngeneralized medical sequence representations for diagnostic tasks, usually\nrelying on manually designed diverse positive and negative sample\npairs.However, these approaches are complex, lack generalizability, and fail to\nadaptively capture disease-specific features across different conditions.To\novercome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),\na framework that integrates a multi-head attention mechanism and adaptively\nlearns representations from different views through inter-view and intra-view\ncontrastive learning strategies.Additionally, the pre-trained AE-GAN is used to\nreconstruct discrepancies in the target data as disease probabilities, which\nare then integrated into the contrastive learning process.Experiments on three\ntarget datasets demonstrate that our method consistently outperforms seven\nother baselines, highlighting its significant impact on healthcare applications\nsuch as the diagnosis of myocardial infarction, Alzheimer's disease, and\nParkinson's disease.",
      "tldr_zh": "这篇论文针对医疗时间序列诊断中的高标注成本导致的模型过拟合问题，提出了一种可学习的多视图对比框架 LMCF，通过整合外部数据和 AE-GAN 提取先验知识来增强泛化能力。LMCF 采用多头注意力机制，实现视图间和视图内对比学习，以自适应捕获疾病特定特征，并利用预训练 AE-GAN 重构目标数据的差异作为疾病概率，融入对比学习过程。实验结果显示，该框架在心肌梗塞、阿尔茨海默病和帕金森病等数据集上，优于七个基线模型，显著提升了诊断性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; K.3.6"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18367v1",
      "published_date": "2025-01-30 14:20:11 UTC",
      "updated_date": "2025-01-30 14:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:54:59.109033"
    },
    {
      "arxiv_id": "2501.18362v2",
      "title": "MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding",
      "title_zh": "MedXpertQA：专家级医学推理和理解的基准测试",
      "authors": [
        "Yuxin Zuo",
        "Shang Qu",
        "Yifei Li",
        "Zhangren Chen",
        "Xuekai Zhu",
        "Ermo Hua",
        "Kaiyan Zhang",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "abstract": "We introduce MedXpertQA, a highly challenging and comprehensive benchmark to\nevaluate expert-level medical knowledge and advanced reasoning. MedXpertQA\nincludes 4,460 questions spanning 17 specialties and 11 body systems. It\nincludes two subsets, Text for text evaluation and MM for multimodal\nevaluation. Notably, MM introduces expert-level exam questions with diverse\nimages and rich clinical information, including patient records and examination\nresults, setting it apart from traditional medical multimodal benchmarks with\nsimple QA pairs generated from image captions. MedXpertQA applies rigorous\nfiltering and augmentation to address the insufficient difficulty of existing\nbenchmarks like MedQA, and incorporates specialty board questions to improve\nclinical relevance and comprehensiveness. We perform data synthesis to mitigate\ndata leakage risk and conduct multiple rounds of expert reviews to ensure\naccuracy and reliability. We evaluate 16 leading models on MedXpertQA.\nMoreover, medicine is deeply connected to real-world decision-making, providing\na rich and representative setting for assessing reasoning abilities beyond\nmathematics and code. To this end, we develop a reasoning-oriented subset to\nfacilitate the assessment of o1-like models.",
      "tldr_zh": "本研究引入了MedXpertQA，一种高度挑战性的基准，用于评估专家级医疗知识和高级推理能力。该基准包含4,460个问题，覆盖17个专业和11个身体系统，包括Text子集（文本评估）和MM子集（多模态评估），后者整合多样图像、患者记录和临床信息，超越传统简单QA对的限制。通过严格过滤、增强和数据合成，以及多轮专家审查，MedXpertQA解决了现有基准如MedQA的难度不足问题，并提升了临床相关性。研究评估了16个领先模型，并开发了面向推理的子集，以更好地评估类似o1-like模型的决策能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18362v2",
      "published_date": "2025-01-30 14:07:56 UTC",
      "updated_date": "2025-02-20 08:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:55:10.293951"
    },
    {
      "arxiv_id": "2501.18356v1",
      "title": "State Stream Transformer (SST) : Emergent Metacognitive Behaviours Through Latent State Persistence",
      "title_zh": "翻译失败",
      "authors": [
        "Thea Aviss"
      ],
      "abstract": "We introduce the State Stream Transformer (SST), a novel LLM architecture\nthat reveals emergent reasoning behaviours and capabilities latent in\npretrained weights through addressing a fundamental limitation in traditional\ntransformer models: the lack of latent computational continuity across\nautoregressive generations in the state space. SST introduces a sliding window\nlatent state (FFN) cache with weighted decay that maintains and evolves\npersistent latent processes throughout autoregressive generations. Through\ncontrolled experiments comparing base and SST architectures using the same\nfrozen weights, we demonstrate that this architectural modification alone\nenables enhanced reasoning capabilities which appear best explained by some\nform of potential higher-order processing, as evidenced by emergent\nmetacognitive behaviours. These behaviours persist under controlled conditions\ndesigned to eliminate confounding factors such as stochastic variation or\nlearned response patterns. Analysis of latent state distributions and\nprocessing dynamics provides evidence that it is solely the 'state stream' that\nis responsible for these phenomena. In quantitative evaluations, the SST\nachieves substantial performance improvements over the base model on two\nreasoning benchmarks, reaching 89.01\\% accuracy on GSM-8K (0-shot) and 91.04\\%\non ARC Challenge (0-shot CoT). These findings indicate that persistent\ncomputation in the latent state space enables fundamentally different\ninformation processing and internal reasoning strategies, with implications for\nour understanding of artificial intelligence systems.",
      "tldr_zh": "本文提出State Stream Transformer (SST)，一种新型LLM架构，通过引入滑动窗口latent state (FFN) cache和加权衰减机制，解决传统Transformer模型在autoregressive generations中的潜在计算连续性缺失问题，从而启用紧急的metacognitive behaviours和增强的推理能力。实验对比显示，使用相同冻结权重的SST模型在控制条件下表现出更高的推理性能，并在GSM-8K和ARC Challenge基准上分别达到89.01%和91.04%的准确率，比基线模型显著提升29%以上。分析结果表明，'state stream' 是这些现象的核心驱动因素，揭示了持久潜在状态计算如何改变信息处理策略，对理解人工智能系统具有重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18356v1",
      "published_date": "2025-01-30 14:03:36 UTC",
      "updated_date": "2025-01-30 14:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:55:23.364912"
    },
    {
      "arxiv_id": "2501.18344v2",
      "title": "Transfer Learning of Surrogate Models: Integrating Domain Warping and Affine Transformations",
      "title_zh": "代理模型的迁移学习：整合领域扭曲和仿射变换",
      "authors": [
        "Shuaiqun Pan",
        "Diederick Vermetten",
        "Manuel López-Ibáñez",
        "Thomas Bäck",
        "Hao Wang"
      ],
      "abstract": "Surrogate models provide efficient alternatives to computationally demanding\nreal world processes but often require large datasets for effective training. A\npromising solution to this limitation is the transfer of pre-trained surrogate\nmodels to new tasks. Previous studies have investigated the transfer of\ndifferentiable and non-differentiable surrogate models, typically assuming an\naffine transformation between the source and target functions. This paper\nextends previous research by addressing a broader range of transformations,\nincluding linear and nonlinear variations. Specifically, we consider the\ncombination of an unknown input warping, such as one modeled by the beta\ncumulative distribution function, with an unspecified affine transformation.\nOur approach achieves transfer learning by employing a limited number of data\npoints from the target task to optimize these transformations, minimizing\nempirical loss on the transfer dataset. We validate the proposed method on the\nwidely used Black-Box Optimization Benchmark (BBOB) testbed and a real-world\ntransfer learning task from the automobile industry. The results underscore the\nsignificant advantages of the approach, revealing that the transferred\nsurrogate significantly outperforms both the original surrogate and the one\nbuilt from scratch using the transfer dataset, particularly in data-scarce\nscenarios.",
      "tldr_zh": "本文提出了一种代理模型（surrogate models）的转移学习方法，通过整合领域扭曲（domain warping）和仿射变换（affine transformations），扩展了先前研究对源目标函数关系的假设。该方法使用目标任务的少量数据点优化未知输入扭曲（如 beta 累积分布函数建模）与未指定仿射变换，旨在最小化经验损失。在 Black-Box Optimization Benchmark (BBOB) 测试集和汽车行业真实任务上验证结果显示，转移后的代理模型在数据稀缺场景下显著优于原始模型和从零构建的模型，证明了其高效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18344v2",
      "published_date": "2025-01-30 13:46:48 UTC",
      "updated_date": "2025-05-13 10:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:55:33.873839"
    },
    {
      "arxiv_id": "2501.18337v1",
      "title": "Unfaithful Probability Distributions in Binary Triple of Causality Directed Acyclic Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Liu"
      ],
      "abstract": "Faithfulness is the foundation of probability distribution and graph in\ncausal discovery and causal inference. In this paper, several unfaithful\nprobability distribution examples are constructed in three--vertices binary\ncausality directed acyclic graph (DAG) structure, which are not faithful to\ncausal DAGs described in J.M.,Robins,et al. Uniform consistency in causal\ninference. Biometrika (2003),90(3): 491--515. And the general unfaithful\nprobability distribution with multiple independence and conditional\nindependence in binary triple causal DAG is given.",
      "tldr_zh": "该论文探讨了在因果发现和因果推理中，Faithfulness（忠实性）作为概率分布和图的基础的重要性。作者构建了几个在三顶点二元 Causality Directed Acyclic Graph (DAG) 结构中不忠实的概率分布示例，这些示例不符合 J.M. Robins 等人在 2003 年 Biometrika 论文中描述的因果 DAG 理论。论文进一步给出了在二元三元因果 DAG 中具有多个 Independence 和 Conditional Independence 的通用不忠实概率分布，这有助于深化对因果关系的理解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18337v1",
      "published_date": "2025-01-30 13:34:48 UTC",
      "updated_date": "2025-01-30 13:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:55:45.787766"
    },
    {
      "arxiv_id": "2501.18328v2",
      "title": "CodeBrain: Imputing Any Brain MRI via Modality- and Instance-Specific Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Wu",
        "Tao Song",
        "Zhonghua Wu",
        "Jin Ye",
        "Zongyuan Ge",
        "Zhaolin Chen",
        "Jianfei Cai"
      ],
      "abstract": "Unified MRI imputation, which can adapt to diverse imputation scenarios, is\nhighly desirable as it reduces scanning costs and provides comprehensive MRI\ninformation for improved clinical diagnosis. Existing unified MRI imputation\nmethods either rely on specific prompts to guide their transformation network\nor require multiple modality-specific modules. However, these approaches\nstruggle to capture large modality and instance variations or become too\ncomplex to generalize effectively. To address these limitations, we propose\nCodeBrain, a fundamentally different pipeline for unified brain MRI imputation.\nOur key idea is to reframe various inter-modality transformations as a\nfull-modality code prediction task via a two-stage framework. In the first\nstage, CodeBrain reconstructs a target modality from any other modalities by\nlearning a compact scalar-quantized code for each instance and modality. Any\ntarget modality can then be reconstructed with high fidelity by combining the\ncorresponding code with shared features extracted from any available modality.\nIn the second stage, a projection encoder is trained to predict full-modality\ncompact codes from any incomplete MRI samples, effectively simulating various\nimputation scenarios. We evaluate our CodeBrain on two public brain MRI\ndatasets (i.e., IXI and BraTS 2023). Extensive experiments demonstrate that\nCodeBrain outperforms state-of-the-art methods, setting a new benchmark for\nunified brain MRI imputation. Our code will be released.",
      "tldr_zh": "本研究提出 CodeBrain，一种统一的脑部 MRI 插值方法，通过模态-和实例-specific codes 处理各种插值场景，旨在降低扫描成本并提升临床诊断的全面性。该框架采用两阶段设计：第一阶段学习紧凑标量量化代码来从任何可用模态重建目标模态；第二阶段训练投影编码器，从不完整 MRI 样本预测全模态代码，从而模拟多样化场景。实验在 IXI 和 BraTS 2023 数据集上表明，CodeBrain 优于现有最先进方法，树立了脑部 MRI 插值的新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CodeBrain v2",
      "pdf_url": "http://arxiv.org/pdf/2501.18328v2",
      "published_date": "2025-01-30 13:14:40 UTC",
      "updated_date": "2025-03-09 02:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:55:58.722793"
    },
    {
      "arxiv_id": "2501.18320v1",
      "title": "Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Tianpeng Pan",
        "Wenqiang Pu",
        "Licheng Zhao",
        "Rui Zhou"
      ],
      "abstract": "Automated optimization modeling (AOM) has evoked considerable interest with\nthe rapid evolution of large language models (LLMs). Existing approaches\npredominantly rely on prompt engineering, utilizing meticulously designed\nexpert response chains or structured guidance. However, prompt-based techniques\nhave failed to perform well in the sensor array signal processing (SASP) area\ndue the lack of specific domain knowledge. To address this issue, we propose an\nautomated modeling approach based on retrieval-augmented generation (RAG)\ntechnique, which consists of two principal components: a multi-agent (MA)\nstructure and a graph-based RAG (Graph-RAG) process. The MA structure is\ntailored for the architectural AOM process, with each agent being designed\nbased on principles of human modeling procedure. The Graph-RAG process serves\nto match user query with specific SASP modeling knowledge, thereby enhancing\nthe modeling result. Results on ten classical signal processing problems\ndemonstrate that the proposed approach (termed as MAG-RAG) outperforms several\nAOM benchmarks.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型代理（LLM Agents）进行传感器阵列信号处理（SASP）问题的自动化优化建模（AOM），以解决现有基于提示工程方法的领域知识不足问题。作者提出了一种名为MAG-RAG的方法，包括多智能体（MA）结构和基于图的检索增强生成（Graph-RAG）过程，其中MA结构模拟人类建模流程，而Graph-RAG用于匹配用户查询与特定SASP知识。在十个经典信号处理问题上的实验结果显示，MAG-RAG超过了多个AOM基准，证明了其有效性。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18320v1",
      "published_date": "2025-01-30 13:00:15 UTC",
      "updated_date": "2025-01-30 13:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:58:03.177695"
    },
    {
      "arxiv_id": "2501.18310v1",
      "title": "Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxiong Liu",
        "Jiacheng Sun",
        "Zhenguo Li",
        "Andrew C Yao"
      ],
      "abstract": "The synergy between deep learning models and traditional automation tools\nplays a pivotal role in developing robust neural theorem provers (NTPs).\nHowever, for proof synthesis with LLMs, previous work applies automation tools\neither only when the model explicitly calls the method, or only at a single\ngranularity level, failing to fully exploit the power of built-in tactics and\noff-the-shelf automated theorem provers. In this work, we propose ProofAug, a\nnovel theorem proving method that enjoys superior sample efficiency through\nequipping proof-generation LLMs with automation methods in different\ngranularities via fine-grained structure analysis of model-generated proof\nproposals. Furthermore, ProofAug serves as a versatile plug-and-play module\nthat seamlessly integrates with any tree-search algorithm, enabling our\nconstruction of an efficient recursive proving (ERP) module to further enhance\nperformance. The superiority of our method is validated on the miniF2F-test\nbenchmark using the open-source deepseek-math-7b-base model and the Isabelle\nproof assistant. Notably, by additionally employing a mixed prompting strategy,\nwe achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9%\nfor the original version), setting a new SOTA across all proof languages with a\ntotal sample budget of only 2100. Our code is available at\nhttps://github.com/haoxiongliu/ProofAug.",
      "tldr_zh": "本文提出 ProofAug，一种高效的神经定理证明方法，通过细粒度证明结构分析，将不同粒度的自动化工具与证明生成 LLMs 相结合，提高样本效率，并作为可插拔模块集成树搜索算法以构建高效递归证明 (ERP) 模块。相比以往方法，ProofAug 充分利用内置策略和自动化证明器，显著提升了证明性能。在 miniF2F-test 基准测试中使用 deepseek-math-7b-base 模型和 Isabelle 证明助手，该方法在数据集整理后达到 66.0% 的通过率（原始版本 61.9%），以仅 2100 个样本预算设置了新 SOTA。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18310v1",
      "published_date": "2025-01-30 12:37:06 UTC",
      "updated_date": "2025-01-30 12:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:56:22.922161"
    },
    {
      "arxiv_id": "2501.18299v1",
      "title": "Model-Free RL Agents Demonstrate System 1-Like Intentionality",
      "title_zh": "翻译失败",
      "authors": [
        "Hal Ashton",
        "Matija Franklin"
      ],
      "abstract": "This paper argues that model-free reinforcement learning (RL) agents, while\nlacking explicit planning mechanisms, exhibit behaviours that can be analogised\nto System 1 (\"thinking fast\") processes in human cognition. Unlike model-based\nRL agents, which operate akin to System 2 (\"thinking slow\") reasoning by\nleveraging internal representations for planning, model-free agents react to\nenvironmental stimuli without anticipatory modelling. We propose a novel\nframework linking the dichotomy of System 1 and System 2 to the distinction\nbetween model-free and model-based RL. This framing challenges the prevailing\nassumption that intentionality and purposeful behaviour require planning,\nsuggesting instead that intentionality can manifest in the structured, reactive\nbehaviours of model-free agents. By drawing on interdisciplinary insights from\ncognitive psychology, legal theory, and experimental jurisprudence, we explore\nthe implications of this perspective for attributing responsibility and\nensuring AI safety. These insights advocate for a broader, contextually\ninformed interpretation of intentionality in RL systems, with implications for\ntheir ethical deployment and regulation.",
      "tldr_zh": "这篇论文论证了model-free reinforcement learning (RL) agents 尽管缺乏显式规划机制，却能表现出类似于人类System 1（“快速思考”）的意图行为，与依赖内部表示进行规划的model-based RL agents（类似于System 2，“缓慢思考”）形成对比。作者提出一个新框架，将System 1和System 2的认知二分法与model-free和model-based RL的区别联系起来，挑战了传统观点，即意图行为必须依赖规划，而是强调model-free agents的结构化反应也能体现意图。通过借鉴认知心理学、法律理论和实验法学的跨学科见解，论文探讨了这一视角对AI责任归属、系统安全和伦理部署的深远影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18299v1",
      "published_date": "2025-01-30 12:21:50 UTC",
      "updated_date": "2025-01-30 12:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:58:15.148740"
    },
    {
      "arxiv_id": "2501.18296v1",
      "title": "Extending the design space of ontologization practices: Using bCLEARer as an example",
      "title_zh": "扩展本体化实践的设计空间：以 bCLEARer 为例",
      "authors": [
        "Chris Partridge",
        "Andrew Mitchell",
        "Sergio de Cesare",
        "John Beverley"
      ],
      "abstract": "Our aim in this paper is to outline how the design space for the\nontologization process is richer than current practice would suggest. We point\nout that engineering processes as well as products need to be designed - and\nidentify some components of the design. We investigate the possibility of\ndesigning a range of radically new practices, providing examples of the new\npractices from our work over the last three decades with an outlier\nmethodology, bCLEARer. We also suggest that setting an evolutionary context for\nontologization helps one to better understand the nature of these new practices\nand provides the conceptual scaffolding that shapes fertile processes. Where\nthis evolutionary perspective positions digitalization (the evolutionary\nemergence of computing technologies) as the latest step in a long evolutionary\ntrail of information transitions. This reframes ontologization as a strategic\ntool for leveraging the emerging opportunities offered by digitalization.",
      "tldr_zh": "本论文扩展了ontologization实践的设计空间，指出工程过程和产品都需要进行设计，并识别了关键设计组件。通过以bCLEARer作为例子，该方法基于作者三十年来采用的非常规方法，探讨了设计一系列全新实践的可能性。论文还建议从演化视角审视ontologization，将其置于信息演化轨迹中（如digitalization的出现），从而将其重新定位为利用数字化机会的战略工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18296v1",
      "published_date": "2025-01-30 12:16:11 UTC",
      "updated_date": "2025-01-30 12:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:58:26.084041"
    },
    {
      "arxiv_id": "2501.18294v1",
      "title": "A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification",
      "title_zh": "基于机器学习的肺癌分级分类方法的全面分析",
      "authors": [
        "Shayli Farshchiha",
        "Salman Asoudeh",
        "Maryam Shavali Kuhshuri",
        "Mehrshad Eisaeid",
        "Mohamadreza Azadie",
        "Saba Hesaraki"
      ],
      "abstract": "Lung cancer is a major issue in worldwide public health, requiring early\ndiagnosis using stable techniques. This work begins a thorough investigation of\nthe use of machine learning (ML) methods for precise classification of lung\ncancer stages. A cautious analysis is performed to overcome overfitting issues\nin model performance, taking into account minimum child weight and learning\nrate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,\nAdaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),\nCatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.\nFurthermore, the correlation between features and targets is examined using the\ndeep neural network (DNN) model and thus their capability in detecting complex\npatternsis established. It is argued that several ML models can be capable of\nclassifying lung cancer stages with great accuracy. In spite of the complexity\nof DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic\nRegression excel with superior performance. The models perform better than the\nothers in lung cancer prediction on the complete set of comparative metrics\nlike accuracy, precision, recall, and F-1 score",
      "tldr_zh": "本研究对基于机器学习的方法进行全面分析，旨在精确分类肺癌分期并解决过拟合问题，通过调整最小子权重和学习率来优化模型性能。研究系统测试了多种模型，包括XGBoost (XGB)、LGBM、Adaboost、Logistic Regression (LR)、Decision Tree (DT)、Random Forest (RF)、CatBoost 和 k-Nearest Neighbor (k-NN)，并使用Deep Neural Network (DNN) 模型评估特征与目标的相关性，以识别复杂模式。结果显示，传统ML模型如XGBoost、LGBM 和 Logistic Regression 在准确率、精确率、召回率和F-1分数等指标上表现出色，优于DNN架构，从而证明这些模型在肺癌分期预测中的高效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18294v1",
      "published_date": "2025-01-30 12:09:54 UTC",
      "updated_date": "2025-01-30 12:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:58:38.070720"
    },
    {
      "arxiv_id": "2501.18291v2",
      "title": "CueTip: An Interactive and Explainable Physics-aware Pool Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Memery",
        "Kevin Denamganai",
        "Jiaxin Zhang",
        "Zehai Tu",
        "Yiwen Guo",
        "Kartic Subr"
      ],
      "abstract": "We present an interactive and explainable automated coaching assistant called\nCueTip for a variant of pool/billiards. CueTip's novelty lies in its\ncombination of three features: a natural-language interface, an ability to\nperform contextual, physics-aware reasoning, and that its explanations are\nrooted in a set of predetermined guidelines developed by domain experts. We\ninstrument a physics simulator so that it generates event traces in natural\nlanguage alongside traditional state traces. Event traces lend themselves to\ninterpretation by language models, which serve as the interface to our\nassistant. We design and train a neural adaptor that decouples tactical choices\nmade by CueTip from its interactivity and explainability allowing it to be\nreconfigured to mimic any pool playing agent. Our experiments show that CueTip\nenables contextual query-based assistance and explanations while maintaining\nthe strength of the agent in terms of win rate (improving it in some\nsituations). The explanations generated by CueTip are physically-aware and\ngrounded in the expert rules and are therefore more reliable.",
      "tldr_zh": "本研究引入了CueTip，一种交互式且可解释的物理感知台球助手，结合自然语言接口、上下文物理-aware reasoning和基于领域专家指南的解释机制。CueTip利用物理模拟器生成事件 traces和状态 traces，由语言模型处理以提供用户接口，并通过训练神经 adaptor将战术决策与交互性分离，使其能模仿任意台球代理。实验结果显示，CueTip在提供上下文查询辅助和可靠解释的同时，维持或提升代理的胜率，确保解释更物理-aware和可信。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18291v2",
      "published_date": "2025-01-30 12:02:15 UTC",
      "updated_date": "2025-03-18 10:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:58:49.789942"
    },
    {
      "arxiv_id": "2501.18287v1",
      "title": "Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: A Large-Scale Exploratory Study with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jennifer D'Souza",
        "Zachary Laubach",
        "Tarek Al Mustafa",
        "Sina Zarrieß",
        "Robert Frühstückl",
        "Phyllis Illari"
      ],
      "abstract": "This paper presents an exploratory study that harnesses the capabilities of\nlarge language models (LLMs) to mine key ecological entities from invasion\nbiology literature. Specifically, we focus on extracting species names, their\nlocations, associated habitats, and ecosystems, information that is critical\nfor understanding species spread, predicting future invasions, and informing\nconservation efforts. Traditional text mining approaches often struggle with\nthe complexity of ecological terminology and the subtle linguistic patterns\nfound in these texts. By applying general-purpose LLMs without domain-specific\nfine-tuning, we uncover both the promise and limitations of using these models\nfor ecological entity extraction. In doing so, this study lays the groundwork\nfor more advanced, automated knowledge extraction tools that can aid\nresearchers and practitioners in understanding and managing biological\ninvasions.",
      "tldr_zh": "这篇论文进行了一场大规模探索性研究，使用大型语言模型 (LLMs) 从入侵生物学文献中挖掘关键生态实体，包括物种名称、位置、相关栖息地和生态系统，以支持理解物种传播、预测入侵和制定保护策略。传统文本挖掘方法因生态术语的复杂性和语言模式而面临挑战，因此研究采用通用 LLMs 而非领域特定微调，评估其在实体提取中的表现。结果揭示了 LLMs 的潜力，同时突出了其局限性，为开发更先进的自动知识提取工具奠定了基础。该研究有助于研究人员和从业者更好地管理生物入侵。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, accepted to the NLP4Ecology Workshop 2025\n  (https://nlp4ecology2025.di.unito.it/) co-located with the Joint 25th Nordic\n  Conference on Computational Linguistics and 11th Baltic Conference on Human\n  Language Technologies",
      "pdf_url": "http://arxiv.org/pdf/2501.18287v1",
      "published_date": "2025-01-30 11:55:44 UTC",
      "updated_date": "2025-01-30 11:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:59:02.672869"
    },
    {
      "arxiv_id": "2501.18280v3",
      "title": "Jailbreaking LLMs' Safeguard with Universal Magic Words for Text Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Liang",
        "Youran Sun",
        "Yunfeng Cai",
        "Jun Zhu",
        "Bo Zhang"
      ],
      "abstract": "The security issue of large language models (LLMs) has gained wide attention\nrecently, with various defense mechanisms developed to prevent harmful output,\namong which safeguards based on text embedding models serve as a fundamental\ndefense. Through testing, we discover that the output distribution of text\nembedding models is severely biased with a large mean. Inspired by this\nobservation, we propose novel, efficient methods to search for **universal\nmagic words** that attack text embedding models. Universal magic words as\nsuffixes can shift the embedding of any text towards the bias direction, thus\nmanipulating the similarity of any text pair and misleading safeguards.\nAttackers can jailbreak the safeguards by appending magic words to user prompts\nand requiring LLMs to end answers with magic words. Experiments show that magic\nword attacks significantly degrade safeguard performance on JailbreakBench,\ncause real-world chatbots to produce harmful outputs in full-pipeline attacks,\nand generalize across input/output texts, models, and languages. To eradicate\nthis security risk, we also propose defense methods against such attacks, which\ncan correct the bias of text embeddings and improve downstream performance in a\ntrain-free manner.",
      "tldr_zh": "本文研究发现，文本嵌入模型的输出分布存在严重偏置，并提出利用这种偏置搜索**universal magic words**作为后缀，攻击大型语言模型(LLMs)的安全防护机制。这些**magic words**能操纵文本对的相似度，误导防护系统，导致攻击者在用户提示中添加它们后，LLMs产生有害输出，实验显示在JailbreakBench上防护性能显著下降，并适用于不同文本、模型和语言。论文同时提出无训练防御方法，纠正文本嵌入偏置，提升下游任务性能，以缓解此安全风险。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18280v3",
      "published_date": "2025-01-30 11:37:40 UTC",
      "updated_date": "2025-05-17 04:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:59:14.077553"
    },
    {
      "arxiv_id": "2502.00061v1",
      "title": "From Data to Action: Charting A Data-Driven Path to Combat Antimicrobial Resistance",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Fu",
        "Yuzhe Zhang",
        "Yanfeng Shu",
        "Ming Ding",
        "Lina Yao",
        "Chen Wang"
      ],
      "abstract": "Antimicrobial-resistant (AMR) microbes are a growing challenge in healthcare,\nrendering modern medicines ineffective. AMR arises from antibiotic production\nand bacterial evolution, but quantifying its transmission remains difficult.\nWith increasing AMR-related data, data-driven methods offer promising insights\ninto its causes and treatments. This paper reviews AMR research from a data\nanalytics and machine learning perspective, summarizing the state-of-the-art\nand exploring key areas such as surveillance, prediction, drug discovery,\nstewardship, and driver analysis. It discusses data sources, methods, and\nchallenges, emphasizing standardization and interoperability. Additionally, it\nsurveys statistical and machine learning techniques for AMR analysis,\naddressing issues like data noise and bias. Strategies for denoising and\ndebiasing are highlighted to enhance fairness and robustness in AMR research.\nThe paper underscores the importance of interdisciplinary collaboration and\nawareness of data challenges in advancing AMR research, pointing to future\ndirections for innovation and improved methodologies.",
      "tldr_zh": "本论文从数据分析和机器学习视角审视抗菌耐药性(AMR)研究，总结了现有技术并探讨关键领域，包括监控、预测、药物发现、药物管理和驱动因素分析。论文强调了数据来源的标准化与互操作性，以及统计和机器学习方法在处理数据噪声和偏差方面的应用，通过去噪和去偏差策略提升研究的公平性和稳健性。同时，它呼吁加强跨学科合作，并指出未来方向，如创新方法和改进数据处理，以推动对抗AMR的有效行动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.PE"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 3 figures, 4 tables, survey paper",
      "pdf_url": "http://arxiv.org/pdf/2502.00061v1",
      "published_date": "2025-01-30 11:37:17 UTC",
      "updated_date": "2025-01-30 11:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:59:27.382388"
    },
    {
      "arxiv_id": "2502.18466v1",
      "title": "MLScent A tool for Anti-pattern detection in ML projects",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Shivashankar",
        "Antonio Martini"
      ],
      "abstract": "Machine learning (ML) codebases face unprecedented challenges in maintaining\ncode quality and sustainability as their complexity grows exponentially. While\ntraditional code smell detection tools exist, they fail to address ML-specific\nissues that can significantly impact model performance, reproducibility, and\nmaintainability.\n  This paper introduces MLScent, a novel static analysis tool that leverages\nsophisticated Abstract Syntax Tree (AST) analysis to detect anti-patterns and\ncode smells specific to ML projects.\n  MLScent implements 76 distinct detectors across major ML frameworks including\nTensorFlow (13 detectors), PyTorch (12 detectors), Scikit-learn (9 detectors),\nand Hugging Face (10 detectors), along with data science libraries like Pandas\nand NumPy (8 detectors each). The tool's architecture also integrates general\nML smell detection (16 detectors), and specialized analysis for data\npreprocessing and model training workflows.\n  Our evaluation demonstrates MLScent's effectiveness through both quantitative\nclassification metrics and qualitative assessment via user studies feedback\nwith ML practitioners. Results show high accuracy in identifying\nframework-specific anti-patterns, data handling issues, and general ML code\nsmells across real-world projects.",
      "tldr_zh": "这篇论文介绍了 MLScent，一种新型静态分析工具，用于检测机器学习(ML)项目中的反模式和代码异味，以解决传统工具无法处理的 ML 特定问题，如模型性能和可维护性问题。MLScent 基于 Abstract Syntax Tree (AST) 分析，实现了 76 个检测器，覆盖 TensorFlow (13 个)、PyTorch (12 个)、Scikit-learn (9 个)、Hugging Face (10 个) 等框架，以及 Pandas 和 NumPy 等数据科学库的专用分析。实验结果显示，MLScent 通过定量分类指标和用户研究反馈，在真实项目中准确识别框架特定反模式、数据处理问题和一般 ML 代码异味，证明了其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "4th International Conference on AI Engineering Software Engineering\n  for AI , CAIN 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.18466v1",
      "published_date": "2025-01-30 11:19:16 UTC",
      "updated_date": "2025-01-30 11:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:59:38.158683"
    },
    {
      "arxiv_id": "2501.18271v2",
      "title": "Vision-Language Model Selection and Reuse for Downstream Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Zhe Tan",
        "Zhi Zhou",
        "Yu-Feng Li",
        "Lan-Zhe Guo"
      ],
      "abstract": "Pre-trained Vision-Language Models (VLMs) are becoming increasingly popular\nacross various visual tasks, and several open-sourced VLM variants have been\nreleased. However, selecting the best-performing pre-trained VLM for a specific\ndownstream task is challenging since no single VLM can achieve promising\nperformance on all downstream tasks, and evaluating all available VLMs is\nimpossible due to time and data limitations. To address this problem, this\npaper proposes a novel paradigm to select and reuse VLM for downstream tasks,\ncalled Model Label Learning (MLL). The proposal contains three key modules:\n\\emph{model labeling}, which assigns labels to each VLM to describe their\nspecialty and utility; \\emph{model selection}, which matches the requirements\nof the target task with model labels; and \\emph{model reuse}, which applies\nselected VLMs to the target task in an ensemble manner. The proposal is highly\ncomputationally efficient and growable since the model labeling process is\ncompleted target task independent and the ability could grow with the number of\ncandidate VLMs. We also introduce a new benchmark for evaluating VLM selection\nmethods, including 49 VLMs and 17 target task datasets. Experimental results\nclearly demonstrate the effectiveness of the proposed method for selecting and\nreusing VLMs.",
      "tldr_zh": "这篇论文针对预训练 Vision-Language Models (VLMs) 在下游任务中的选择和重用问题，提出了一种新范式 Model Label Learning (MLL)，以解决没有单一 VLM 能适用于所有任务的挑战。MLL 包括三个关键模块：模型标记（为每个 VLM 分配标签描述其专业性）、模型选择（匹配目标任务需求）和模型重用（以集成方式应用选定的 VLM），该方法计算效率高且可随候选模型数量扩展。论文引入了一个新基准，涵盖 49 个 VLM 和 17 个任务数据集，实验结果证明了 MLL 在选择和重用 VLM 方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18271v2",
      "published_date": "2025-01-30 11:10:46 UTC",
      "updated_date": "2025-05-07 08:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:59:50.448138"
    },
    {
      "arxiv_id": "2501.18270v1",
      "title": "The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection",
      "title_zh": "翻译失败",
      "authors": [
        "Anup Saha",
        "Joseph Adeola",
        "Nuria Ferrera",
        "Adam Mothershaw",
        "Gisele Rezze",
        "Séraphin Gaborit",
        "Brian D'Alessandro",
        "James Hudson",
        "Gyula Szabó",
        "Balazs Pataki",
        "Hayat Rajani",
        "Sana Nazari",
        "Hassan Hayat",
        "Clare Primiero",
        "H. Peter Soyer",
        "Josep Malvehy",
        "Rafael Garcia"
      ],
      "abstract": "Artificial intelligence has significantly advanced skin cancer diagnosis by\nenabling rapid and accurate detection of malignant lesions. In this domain,\nmost publicly available image datasets consist of single, isolated skin lesions\npositioned at the center of the image. While these lesion-centric datasets have\nbeen fundamental for developing diagnostic algorithms, they lack the context of\nthe surrounding skin, which is critical for improving lesion detection. The\niToBoS dataset was created to address this challenge. It includes 16,954 images\nof skin regions from 100 participants, captured using 3D total body\nphotography. Each image roughly corresponds to a $7 \\times 9$ cm section of\nskin with all suspicious lesions annotated using bounding boxes. Additionally,\nthe dataset provides metadata such as anatomical location, age group, and sun\ndamage score for each image. This dataset aims to facilitate training and\nbenchmarking of algorithms, with the goal of enabling early detection of skin\ncancer and deployment of this technology in non-clinical environments.",
      "tldr_zh": "该论文介绍了 iToBoS 数据集，这是一个专为皮肤病变检测设计的图像集合，包含从 3D total body photographs 中提取的 16,954 张皮肤区域图像，旨在解决传统数据集缺乏周围皮肤上下文的问题。每个图像对应约 7×9 cm 的皮肤区域，所有可疑病变均使用 bounding boxes 进行标注，并附带元数据如解剖位置、年龄组和日晒损伤分数。该数据集有助于训练和基准测试 AI 算法，促进皮肤癌的早期检测，并支持其在非临床环境中的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "J.3; I.2.6; I.4.9"
      ],
      "primary_category": "eess.IV",
      "comment": "Article Submitted to Scientific Data",
      "pdf_url": "http://arxiv.org/pdf/2501.18270v1",
      "published_date": "2025-01-30 11:10:44 UTC",
      "updated_date": "2025-01-30 11:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:00:02.231973"
    },
    {
      "arxiv_id": "2501.18269v1",
      "title": "MAMS: Model-Agnostic Module Selection Framework for Video Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Sangho Lee",
        "Il Yong Chun",
        "Hogun Park"
      ],
      "abstract": "Multi-modal transformers are rapidly gaining attention in video captioning\ntasks. Existing multi-modal video captioning methods typically extract a fixed\nnumber of frames, which raises critical challenges. When a limited number of\nframes are extracted, important frames with essential information for caption\ngeneration may be missed. Conversely, extracting an excessive number of frames\nincludes consecutive frames, potentially causing redundancy in visual tokens\nextracted from consecutive video frames. To extract an appropriate number of\nframes for each video, this paper proposes the first model-agnostic module\nselection framework in video captioning that has two main functions: (1)\nselecting a caption generation module with an appropriate size based on visual\ntokens extracted from video frames, and (2) constructing subsets of visual\ntokens for the selected caption generation module. Furthermore, we propose a\nnew adaptive attention masking scheme that enhances attention on important\nvisual tokens. Our experiments on three different benchmark datasets\ndemonstrate that the proposed framework significantly improves the performance\nof three recent video captioning models.",
      "tldr_zh": "本文提出MAMS框架，这是一个Model-Agnostic Module Selection Framework，用于视频字幕任务，以解决提取固定帧数导致的重要信息缺失或视觉tokens冗余的问题。该框架的主要功能包括：根据视频帧提取的visual tokens选择适当大小的字幕生成模块，并构建visual tokens的子集。此外，引入了新的adaptive attention masking方案，以增强对重要visual tokens的注意力。实验结果显示，在三个基准数据集上，该框架显著提高了三个最新视频字幕模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the AAAI 2025 Main Technical Track. This is an extended\n  version of the original submission",
      "pdf_url": "http://arxiv.org/pdf/2501.18269v1",
      "published_date": "2025-01-30 11:10:18 UTC",
      "updated_date": "2025-01-30 11:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:00:14.526010"
    },
    {
      "arxiv_id": "2501.18258v1",
      "title": "PDE-DKL: PDE-constrained deep kernel learning in high dimensionality",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Yan",
        "Christoph Brune",
        "Mengwu Guo"
      ],
      "abstract": "Many physics-informed machine learning methods for PDE-based problems rely on\nGaussian processes (GPs) or neural networks (NNs). However, both face\nlimitations when data are scarce and the dimensionality is high. Although GPs\nare known for their robust uncertainty quantification in low-dimensional\nsettings, their computational complexity becomes prohibitive as the\ndimensionality increases. In contrast, while conventional NNs can accommodate\nhigh-dimensional input, they often require extensive training data and do not\noffer uncertainty quantification. To address these challenges, we propose a\nPDE-constrained Deep Kernel Learning (PDE-DKL) framework that combines DL and\nGPs under explicit PDE constraints. Specifically, NNs learn a low-dimensional\nlatent representation of the high-dimensional PDE problem, reducing the\ncomplexity of the problem. GPs then perform kernel regression subject to the\ngoverning PDEs, ensuring accurate solutions and principled uncertainty\nquantification, even when available data are limited. This synergy unifies the\nstrengths of both NNs and GPs, yielding high accuracy, robust uncertainty\nestimates, and computational efficiency for high-dimensional PDEs. Numerical\nexperiments demonstrate that PDE-DKL achieves high accuracy with reduced data\nrequirements. They highlight its potential as a practical, reliable, and\nscalable solver for complex PDE-based applications in science and engineering.",
      "tldr_zh": "本论文提出PDE-constrained Deep Kernel Learning (PDE-DKL) 框架，旨在解决高维PDE问题中Gaussian processes (GPs) 计算复杂度高和neural networks (NNs) 数据需求大且缺乏uncertainty quantification的局限性。框架通过NNs学习高维问题的低维潜在表示，结合GPs在显式PDE约束下进行kernel regression，实现高准确性、鲁棒的不确定性估计和计算效率。数值实验表明，PDE-DKL在数据量减少的情况下仍能获得高精度结果，具有广阔的应用潜力于科学和工程领域的复杂PDE问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T35, 65N99, 35Q62, 35Q68",
        "I.2.6; G.1.8"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18258v1",
      "published_date": "2025-01-30 10:39:52 UTC",
      "updated_date": "2025-01-30 10:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:00:26.970801"
    },
    {
      "arxiv_id": "2501.18237v1",
      "title": "Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers",
      "title_zh": "任意数据作为图像：利用视觉Transformer实现跨模态和不规则",
      "authors": [
        "Malte Tölle",
        "Mohamad Scharaf",
        "Samantha Fischer",
        "Christoph Reich",
        "Silav Zeid",
        "Christoph Dieterich",
        "Benjamin Meder",
        "Norbert Frey",
        "Philipp Wild",
        "Sandy Engelhardt"
      ],
      "abstract": "A patient undergoes multiple examinations in each hospital stay, where each\nprovides different facets of the health status. These assessments include\ntemporal data with varying sampling rates, discrete single-point measurements,\ntherapeutic interventions such as medication administration, and images. While\nphysicians are able to process and integrate diverse modalities intuitively,\nneural networks need specific modeling for each modality complicating the\ntraining procedure. We demonstrate that this complexity can be significantly\nreduced by visualizing all information as images along with unstructured text\nand subsequently training a conventional vision-text transformer. Our approach,\nVision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not\nonly simplifies data preprocessing and modeling but also outperforms current\nstate-of-the-art methods in predicting in-hospital mortality and phenotyping,\nas evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities\ninclude patient's clinical measurements, medications, X-ray images, and\nelectrocardiography scans. We hope our work inspires advancements in\nmulti-modal medical AI by reducing the training complexity to (visual) prompt\nengineering, thus lowering entry barriers and enabling no-code solutions for\ntraining. The source code will be made publicly available.",
      "tldr_zh": "本研究提出了一种名为ViTiMM（Vision Transformer for irregular sampled Multi-modal Measurements）的创新方法，将患者的多模态数据（如临床测量、药物、X光图像和心电图）转换为图像形式，并结合视觉文本Transformer进行融合处理，从而简化了数据预处理和建模过程。相比传统方法，该方法能有效处理不规则采样间隔的数据，并在MIMIC-IV数据集上测试了6175名患者，结果显示ViTiMM在预测院内死亡率和表型方面优于现有技术。总体而言，此方法降低了多模态医疗AI的训练复杂性，通过视觉提示工程实现无代码解决方案，期待推动该领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18237v1",
      "published_date": "2025-01-30 09:52:15 UTC",
      "updated_date": "2025-01-30 09:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:00:38.628854"
    },
    {
      "arxiv_id": "2501.18223v1",
      "title": "Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark",
      "title_zh": "探索大型蛋白质语言模型在 FLIP 基准的受限评估场景中",
      "authors": [
        "Manuel F. Mollon",
        "Joaquin Gonzalez-Rodriguez",
        "Alicia Lozano-Diez",
        "Daniel Ramos",
        "Doroteo T. Toledano"
      ],
      "abstract": "In this study, we expand upon the FLIP benchmark-designed for evaluating\nprotein fitness prediction models in small, specialized prediction tasks-by\nassessing the performance of state-of-the-art large protein language models,\nincluding ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse\nbenchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP\nfocuses on constrained settings where data availability is limited. This makes\nit an ideal framework to evaluate model performance in scenarios with scarce\ntask-specific data. We investigate whether recent advances in protein language\nmodels lead to significant improvements in such settings. Our findings provide\nvaluable insights into the performance of large-scale models in specialized\nprotein prediction tasks.",
      "tldr_zh": "本研究扩展了 FLIP benchmark，通过评估 ESM-2 和 SaProt 等大型蛋白质语言模型在小规模、数据有限的蛋白质适应性预测任务中的表现。不同于 ProteinGym 等更广泛的基准，FLIP 专注于约束场景，以测试模型在资源稀缺条件下的效能。研究发现，这些先进模型在专业任务中显示出潜在改善，为理解大规模模型在类似设置中的应用提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18223v1",
      "published_date": "2025-01-30 09:24:58 UTC",
      "updated_date": "2025-01-30 09:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:46.773873"
    },
    {
      "arxiv_id": "2501.18202v1",
      "title": "On Scaling Neurosymbolic Programming through Guided Logical Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Jean-Michel Valentin",
        "Luisa Sophie Werner",
        "Pierre Genevès",
        "Nabil Layaïda"
      ],
      "abstract": "Probabilistic neurosymbolic learning seeks to integrate neural networks with\nsymbolic programming. Many state-of-the-art systems rely on a reduction to the\nProbabilistic Weighted Model Counting Problem (PWMC), which requires computing\na Boolean formula called the logical provenance.However, PWMC is \\\\#P-hard, and\nthe number of clauses in the logical provenance formula can grow exponentially,\ncreating a major bottleneck that significantly limits the applicability of PNL\nsolutions in practice.We propose a new approach centered around an exact\nalgorithm DPNL, that enables bypassing the computation of the logical\nprovenance.The DPNL approach relies on the principles of an oracle and a\nrecursive DPLL-like decomposition in order to guide and speed up logical\ninference.Furthermore, we show that this approach can be adapted for\napproximate reasoning with $\\epsilon$ or $(\\epsilon, \\delta)$ guarantees,\ncalled ApproxDPNL.Experiments show significant performance gains.DPNL enables\nscaling exact inference further, resulting in more accurate models.Further,\nApproxDPNL shows potential for advancing the scalability of neurosymbolic\nprogramming by incorporating approximations even further, while simultaneously\nensuring guarantees for the reasoning process.",
      "tldr_zh": "该论文探讨了如何通过指导逻辑推理来扩展神经符号编程（Neurosymbolic Programming）的规模，以解决现有系统依赖于Probabilistic Weighted Model Counting Problem (PWMC)的计算瓶颈问题，因为PWMC是\\\\#P-hard，且逻辑来源公式可能指数级增长。作者提出了一种精确算法DPNL，利用oracle和递归DPLL-like分解来指导和加速逻辑推理，从而绕过计算逻辑来源。DPNL还被扩展为近似版本ApproxDPNL，提供$\\epsilon$或$(\\epsilon, \\delta)$保证，用于高效的近似推理。实验结果显示，DPNL显著提升了精确推理的规模和模型准确性，而ApproxDPNL进一步提高了神经符号编程的可扩展性，同时确保推理过程的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18202v1",
      "published_date": "2025-01-30 08:49:25 UTC",
      "updated_date": "2025-01-30 08:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:03.609045"
    },
    {
      "arxiv_id": "2501.18201v1",
      "title": "Neural Operator based Reinforcement Learning for Control of first-order PDEs with Spatially-Varying State Delay",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Hu",
        "Jie Qi",
        "Jing Zhang"
      ],
      "abstract": "Control of distributed parameter systems affected by delays is a challenging\ntask, particularly when the delays depend on spatial variables. The idea of\nintegrating analytical control theory with learning-based control within a\nunified control scheme is becoming increasingly promising and advantageous. In\nthis paper, we address the problem of controlling an unstable first-order\nhyperbolic PDE with spatially-varying delays by combining PDE backstepping\ncontrol strategies and deep reinforcement learning (RL). To eliminate the\nassumption on the delay function required for the backstepping design, we\npropose a soft actor-critic (SAC) architecture incorporating a DeepONet to\napproximate the backstepping controller. The DeepONet extracts features from\nthe backstepping controller and feeds them into the policy network. In\nsimulations, our algorithm outperforms the baseline SAC without prior\nbackstepping knowledge and the analytical controller.",
      "tldr_zh": "该论文探讨了受空间变化延迟影响的分布式参数系统的控制问题，特别针对不稳定的第一-order hyperbolic PDE。研究者结合PDE backstepping控制策略和deep reinforcement learning (RL)，提出了一种soft actor-critic (SAC)架构，使用DeepONet来近似backstepping控制器，从而消除对延迟函数的假设。DeepONet从backstepping控制器提取特征并输入策略网络，在模拟实验中，该方法优于没有backstepping知识的基线SAC和传统分析控制器。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "6 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18201v1",
      "published_date": "2025-01-30 08:49:08 UTC",
      "updated_date": "2025-01-30 08:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:13.978976"
    },
    {
      "arxiv_id": "2501.18199v1",
      "title": "HKAN: Hierarchical Kolmogorov-Arnold Network without Backpropagation",
      "title_zh": "HKAN: 无",
      "authors": [
        "Grzegorz Dudek",
        "Tomasz Rodak"
      ],
      "abstract": "This paper introduces the Hierarchical Kolmogorov-Arnold Network (HKAN), a\nnovel network architecture that offers a competitive alternative to the\nrecently proposed Kolmogorov-Arnold Network (KAN). Unlike KAN, which relies on\nbackpropagation, HKAN adopts a randomized learning approach, where the\nparameters of its basis functions are fixed, and linear aggregations are\noptimized using least-squares regression. HKAN utilizes a hierarchical\nmulti-stacking framework, with each layer refining the predictions from the\nprevious one by solving a series of linear regression problems. This\nnon-iterative training method simplifies computation and eliminates sensitivity\nto local minima in the loss function. Empirical results show that HKAN delivers\ncomparable, if not superior, accuracy and stability relative to KAN across\nvarious regression tasks, while also providing insights into variable\nimportance. The proposed approach seamlessly integrates theoretical insights\nwith practical applications, presenting a robust and efficient alternative for\nneural network modeling.",
      "tldr_zh": "本文提出 Hierarchical Kolmogorov-Arnold Network (HKAN)，一种新型网络架构，作为 Kolmogorov-Arnold Network (KAN) 的竞争替代方案，不依赖 backpropagation，而是采用随机化学习方法，通过固定基础函数参数并使用 least-squares regression 优化线性聚合。HKAN 采用分层多堆叠框架，每层通过解决线性回归问题来逐步完善前一层的预测，从而简化计算并避免损失函数的局部最小值敏感性。实验结果表明，HKAN 在各种回归任务中表现出与 KAN 相当或更高的准确性和稳定性，同时提供变量重要性的洞见。该方法无缝整合理论与实践，为神经网络建模提供了一个稳健高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18199v1",
      "published_date": "2025-01-30 08:44:54 UTC",
      "updated_date": "2025-01-30 08:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:27.345437"
    },
    {
      "arxiv_id": "2502.00060v1",
      "title": "Israel-Hamas war through Telegram, Reddit and Twitter",
      "title_zh": "翻译失败",
      "authors": [
        "Despoina Antonakaki",
        "Sotiris Ioannidis"
      ],
      "abstract": "The Israeli-Palestinian conflict started on 7 October 2023, have resulted\nthus far to over 48,000 people killed including more than 17,000 children with\na majority from Gaza, more than 30,000 people injured, over 10,000 missing, and\nover 1 million people displaced, fleeing conflict zones. The infrastructure\ndamage includes the 87\\% of housing units, 80\\% of public buildings and 60\\% of\ncropland 17 out of 36 hospitals, 68\\% of road networks and 87\\% of school\nbuildings damaged. This conflict has as well launched an online discussion\nacross various social media platforms. Telegram was no exception due to its\nencrypted communication and highly involved audience. The current study will\ncover an analysis of the related discussion in relation to different\nparticipants of the conflict and sentiment represented in those discussion. To\nthis end, we prepared a dataset of 125K messages shared on channels in Telegram\nspanning from 23 October 2025 until today. Additionally, we apply the same\nanalysis in two publicly available datasets from Twitter containing 2001 tweets\nand from Reddit containing 2M opinions. We apply a volume analysis across the\nthree datasets, entity extraction and then proceed to BERT topic analysis in\norder to extract common themes or topics. Next, we apply sentiment analysis to\nanalyze the emotional tone of the discussions. Our findings hint at polarized\nnarratives as the hallmark of how political factions and outsiders mold public\nopinion. We also analyze the sentiment-topic prevalence relationship, detailing\nthe trends that may show manipulation and attempts of propaganda by the\ninvolved parties. This will give a better understanding of the online discourse\non the Israel-Palestine conflict and contribute to the knowledge on the\ndynamics of social media communication during geopolitical crises.",
      "tldr_zh": "本研究分析了2023年以色列-哈马斯战争在Telegram、Reddit和Twitter上的在线讨论，涵盖125K条Telegram消息、2001条Twitter推文和2M条Reddit意见。通过体积分析、实体提取、BERT主题分析和情感分析，揭示了讨论中的极化叙事以及政治派别和外部势力对公众意见的塑造。研究发现，情感与主题的相关性显示了可能的操纵和宣传趋势，这有助于深化对社交媒体在地缘政治危机中动态的理解。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00060v1",
      "published_date": "2025-01-30 08:20:26 UTC",
      "updated_date": "2025-01-30 08:20:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:38.690703"
    },
    {
      "arxiv_id": "2501.18190v2",
      "title": "Economic Rationality under Specialization: Evidence of Decision Bias in AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "ShuiDe Wen"
      ],
      "abstract": "In the study by Chen et al. (2023) [01], the large language model GPT\ndemonstrated economic rationality comparable to or exceeding the average human\nlevel in tasks such as budget allocation and risk preference. Building on this\nfinding, this paper further incorporates specialized agents, such as\nbiotechnology experts and economists, for a horizontal comparison to explore\nwhether specialization can enhance or maintain economic rationality equivalent\nto that of GPT in similar decision-making scenarios. The results indicate that\nwhen agents invest more effort in specialized fields, their decision-making\nbehavior is more prone to 'rationality shift,' specifically manifested as\nincreased violations of GARP (Generalized Axiom of Revealed Preference),\ndecreased CCEI (Critical Cost Efficiency Index), and more significant decision\ndeviations under high-risk conditions. In contrast, GPT and more generalized\nbasic agents maintain a more stable and consistent level of rationality across\nmultiple tasks. This study reveals the inherent conflict between specialization\nand economic rationality, providing new insights for constructing AI\ndecision-making systems that balance specialization and generalization across\nvarious scenarios.",
      "tldr_zh": "本研究基于 Chen et al. (2023) 的发现，探讨了专业化 AI 代理（如生物技术专家和经济学家）在决策场景中的经济理性水平，并与 GPT 进行横向比较，以检验专业化是否能维持或提升理性。结果显示，专业化代理在投入更多努力于特定领域后，更容易出现“理性偏移”，具体表现为 GARP (Generalized Axiom of Revealed Preference) 违反增加、CCEI (Critical Cost Efficiency Index) 降低，以及在高风险条件下决策偏差加剧。相比之下，GPT 和更通用的代理保持了更稳定的理性水平。该研究揭示了专业化与经济理性之间的冲突，为设计平衡专业化和泛化的 AI 决策系统提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18190v2",
      "published_date": "2025-01-30 07:49:58 UTC",
      "updated_date": "2025-03-17 03:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:01:51.719965"
    },
    {
      "arxiv_id": "2501.18187v2",
      "title": "On the Role of Transformer Feed-Forward Layers in Nonlinear In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyuan Sun",
        "Ali Jadbabaie",
        "Navid Azizan"
      ],
      "abstract": "Transformer-based models demonstrate a remarkable ability for in-context\nlearning (ICL), where they can adapt to unseen tasks from a few prompt examples\nwithout parameter updates. Notably, recent research has provided insight into\nhow the Transformer architecture can perform ICL, showing that the optimal\nlinear self-attention (LSA) mechanism can implement one step of gradient\ndescent for linear least-squares objectives when trained on random linear\nregression tasks.\n  Building upon this understanding of linear ICL, we investigate ICL for\nnonlinear function classes. We first show that LSA is inherently incapable of\nsolving problems that go beyond linear least-squares objectives, underscoring\nwhy prior solutions cannot readily extend to nonlinear ICL tasks. To overcome\nthis limitation, we investigate a mechanism combining LSA with feed-forward\nlayers that are inspired by the gated linear units (GLU) commonly found in\nmodern Transformer architectures. We show that this combination empowers the\nTransformer to perform nonlinear ICL, specifically by implementing one step of\ngradient descent on a polynomial kernel regression loss. Furthermore, we show\nthat multiple blocks of our GLU-LSA model implement block coordinate descent in\nthis polynomial kernel space. Our findings highlight the distinct roles of\nattention and feed-forward layers, demonstrating that the feed-forward\ncomponents provide a mechanism by which Transformers gain nonlinear\ncapabilities for ICL.",
      "tldr_zh": "该研究探讨了 Transformer 模型在非线性 in-context learning (ICL) 中的机制，指出线性自注意力 (LSA) 无法处理超出线性最小二乘目标的任务，从而限制了其在非线性场景的应用。作者提出了一种结合 LSA 和受 gated linear units (GLU) 启发的 feed-forward 层机制，使 Transformer 能够执行非线性 ICL，具体通过模拟多项式核回归损失的梯度下降一步。进一步发现，多个 GLU-LSA 块可实现多项式核空间中的块坐标下降，这突显了 feed-forward 层在赋予 Transformer 非线性能力方面的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18187v2",
      "published_date": "2025-01-30 07:41:20 UTC",
      "updated_date": "2025-05-19 19:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:02:04.095885"
    },
    {
      "arxiv_id": "2501.18657v1",
      "title": "Enhancing Large Language Model Efficiencyvia Symbolic Compression: A Formal Approach Towards Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Lumen AI",
        "Tengzhou No. 1 Middle School",
        "Shihao Ji",
        "Zihui Song",
        "Fucheng Zhong",
        "Jisen Jia",
        "Zhaobo Wu",
        "Zheyi Cao",
        "Tianhao Xu"
      ],
      "abstract": "Large language models (LLMs) face significant token efficiency bottlenecks in\ncode generation and logical reasoning tasks, a challenge that directly impacts\ninference cost and model interpretability. This paper proposes a formal\nframework based on symbolic compression,integrating combinatory logic,\ninformation-theoretic optimal encoding, and context-aware inference techniques\nto achieve a step-change improvement in token efficiency while preserving\nsemantic integrity. We establish a mathematical framework within a functional\nprogramming paradigm, derive the quantitative relationship between symbolic\ndensity and model interpretability, and propose a differentiable compression\nfactor metric to evaluate encoding efficiency. Furthermore, we leverage\nparameter-efficient fine-tuning (PEFT) techniques to achieve a low-cost\napplication of the GAEL language. Experimental results show that this method\nachieves a 78.3% token compression rate in code generation tasks while\nimproving logical traceability by 62% through structural explicitness. This\nresearch provides new theoretical tools for efficient inference in LLMs and\nopens a symbolic path for modelinterpretability research.",
      "tldr_zh": "这项研究针对Large Language Models (LLMs)在代码生成和逻辑推理任务中的token效率瓶颈，提出了一种基于symbolic compression的正式框架，以提升模型效率并增强interpretability。该框架整合了combinatory logic、信息理论最优编码和上下文感知推理技术，在函数式编程范式下建立了数学模型，并推导了symbolic density与模型可解释性的定量关系，同时引入了可微压缩因子指标进行评估。实验结果显示，该方法在代码生成任务中实现了78.3%的token压缩率，并通过结构显性性提高了62%的逻辑可追踪性。该研究为LLMs的efficient inference提供了新理论工具，并为模型interpretability研究开辟了符号路径。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18657v1",
      "published_date": "2025-01-30 06:40:52 UTC",
      "updated_date": "2025-01-30 06:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:02:16.624018"
    },
    {
      "arxiv_id": "2501.18137v3",
      "title": "Tensor Completion for Surrogate Modeling of Material Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Shaan Pakala",
        "Dawon Ahn",
        "Evangelos Papalexakis"
      ],
      "abstract": "When designing materials to optimize certain properties, there are often many\npossible configurations of designs that need to be explored. For example, the\nmaterials' composition of elements will affect properties such as strength or\nconductivity, which are necessary to know when developing new materials.\nExploring all combinations of elements to find optimal materials becomes very\ntime consuming, especially when there are more design variables. For this\nreason, there is growing interest in using machine learning (ML) to predict a\nmaterial's properties. In this work, we model the optimization of certain\nmaterial properties as a tensor completion problem, to leverage the structure\nof our datasets and navigate the vast number of combinations of material\nconfigurations. Across a variety of material property prediction tasks, our\nexperiments show tensor completion methods achieving 10-20% decreased error\ncompared with baseline ML models such as GradientBoosting and Multilayer\nPerceptron (MLP), while maintaining similar training speed.",
      "tldr_zh": "本文提出将材料属性预测建模为张量补全（tensor completion）问题，以利用数据集结构高效处理大量材料配置组合，从而解决传统探索方法的耗时问题。相比基线机器学习模型如 GradientBoosting 和 Multilayer Perceptron (MLP)，实验结果显示张量补全方法在各种材料属性预测任务中降低了10-20%的错误率，同时保持相似的训练速度。该方法为材料设计优化提供了更高效的替代方案。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2 page paper presented at the AAAI 2025 Bridge on Knowledge-Guided\n  Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2501.18137v3",
      "published_date": "2025-01-30 04:59:21 UTC",
      "updated_date": "2025-03-19 03:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:02:26.993093"
    },
    {
      "arxiv_id": "2501.18131v2",
      "title": "Entropy-Synchronized Neural Hashing for Unsupervised Ransomware Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Idliman",
        "Wilfred Balfour",
        "Benedict Featheringham",
        "Hugo Chesterfield"
      ],
      "abstract": "Entropy-based detection methodologies have gained significant attention due\nto their ability to analyze structural irregularities within executable files,\nparticularly in the identification of malicious software employing advanced\nobfuscation techniques. The Entropy-Synchronized Neural Hashing (ESNH)\nframework introduces a novel approach that leverages entropy-driven hash\nrepresentations to classify software binaries based on their underlying entropy\ncharacteristics. Through the synchronization of entropy profiles with neural\nnetwork architectures, the model generates robust and unique hash values that\nmaintain stability even when faced with polymorphic and metamorphic\ntransformations. Comparative analysis against traditional detection approaches\nrevealed superior performance in identifying novel threats, reducing\nfalse-positive rates, and achieving consistent classification across diverse\nransomware families. The incorporation of a self-regulating hash convergence\nmechanism further ensured that entropy-synchronized hashes remained invariant\nacross executions, minimizing classification inconsistencies that often arise\ndue to dynamic modifications in ransomware payloads. Experimental results\ndemonstrated high detection rates across contemporary ransomware strains, with\nthe model exhibiting resilience against encryption-based evasion mechanisms,\ncode injection strategies, and reflective loading techniques. Unlike\nconventional detection mechanisms that rely on static signatures and heuristic\nanalysis, the proposed entropy-aware classification framework adapts to\nemerging threats through an inherent ability to capture entropy anomalies\nwithin executable structures. The findings reinforce the potential of\nentropy-based detection in addressing the limitations of traditional\nmethodologies while enhancing detection robustness against obfuscation and\nadversarial evasion techniques.",
      "tldr_zh": "这篇论文提出了 Entropy-Synchronized Neural Hashing (ESNH) 框架，用于无监督的勒索软件检测，通过分析可执行文件的熵特征来捕捉结构不规则性。ESNH 通过将熵配置文件与神经网络架构同步，生成稳定的哈希值，能够抵抗多态和变形转换，同时引入自调节哈希收敛机制以减少分类不一致。实验结果显示，该方法在多种勒索软件家族中实现了高检测率、降低了假阳性率，并比传统基于静态签名和启发式分析的检测方法更能适应新兴威胁和对抗逃避技术。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
      "pdf_url": "http://arxiv.org/pdf/2501.18131v2",
      "published_date": "2025-01-30 04:40:57 UTC",
      "updated_date": "2025-03-25 12:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:02:39.453223"
    },
    {
      "arxiv_id": "2501.18129v1",
      "title": "Revisiting gender bias research in bibliometrics: Standardizing methodological variability using Scholarly Data Analysis (SoDA) Cards",
      "title_zh": "翻译失败",
      "authors": [
        "HaeJin Lee",
        "Shubhanshu Mishra",
        "Apratim Mishra",
        "Zhiwen You",
        "Jinseok Kim",
        "Jana Diesner"
      ],
      "abstract": "Gender biases in scholarly metrics remain a persistent concern, despite\nnumerous bibliometric studies exploring their presence and absence across\nproductivity, impact, acknowledgment, and self-citations. However,\nmethodological inconsistencies, particularly in author name disambiguation and\ngender identification, limit the reliability and comparability of these\nstudies, potentially perpetuating misperceptions and hindering effective\ninterventions. A review of 70 relevant publications over the past 12 years\nreveals a wide range of approaches, from name-based and manual searches to more\nalgorithmic and gold-standard methods, with no clear consensus on best\npractices. This variability, compounded by challenges such as accurately\ndisambiguating Asian names and managing unassigned gender labels, underscores\nthe urgent need for standardized and robust methodologies. To address this\ncritical gap, we propose the development and implementation of ``Scholarly Data\nAnalysis (SoDA) Cards.\" These cards will provide a structured framework for\ndocumenting and reporting key methodological choices in scholarly data\nanalysis, including author name disambiguation and gender identification\nprocedures. By promoting transparency and reproducibility, SoDA Cards will\nfacilitate more accurate comparisons and aggregations of research findings,\nultimately supporting evidence-informed policymaking and enabling the\nlongitudinal tracking of analytical approaches in the study of gender and other\nsocial biases in academia.",
      "tldr_zh": "本研究重新审视了bibliometrics中gender bias的研究，强调了作者姓名消歧和性别识别等方法不一致性导致的研究可靠性不足和可比性问题。通过回顾过去12年的70篇相关出版物，发现方法从基于名称的手动搜索到算法模型多样，但缺乏最佳实践，尤其在处理亚洲姓名和未分配性别标签时面临挑战。为解决这一问题，作者提出Scholarly Data Analysis (SoDA) Cards框架，这是一种结构化工具，用于记录和报告学术数据分析中的关键方法选择，从而提升透明度、可重复性和研究发现的准确比较。最终，该框架将支持基于证据的政策制定，并实现对gender bias和其他社会偏见研究的纵向跟踪。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.SI",
        "K.4.1"
      ],
      "primary_category": "cs.DL",
      "comment": "33 pg, 7 figures. Soda Cards:\n  https://github.com/HaeJinLee41/scholarly_bias_study",
      "pdf_url": "http://arxiv.org/pdf/2501.18129v1",
      "published_date": "2025-01-30 04:22:50 UTC",
      "updated_date": "2025-01-30 04:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:02:51.945371"
    },
    {
      "arxiv_id": "2501.18128v1",
      "title": "Unraveling the Capabilities of Language Models in News Summarization",
      "title_zh": "揭示语言模型在新闻",
      "authors": [
        "Abdurrahman Odabaşı",
        "Göksel Biricik"
      ],
      "abstract": "Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization.",
      "tldr_zh": "这篇论文对20个最近的语言模型进行了全面基准测试，重点评估较小模型在新闻摘要任务中的能力，使用三个不同数据集的新闻文章。研究采用零-shot learning 和 few-shot learning 设置，并结合自动指标、人力评估和 LLM-as-a-judge 等方法进行稳健评估。结果显示，在 few-shot learning 中添加演示示例并未提升性能，有时甚至降低摘要质量，主要归因于参考摘要的低质量；GPT-3.5-Turbo 和 GPT-4 表现出色，而公开模型如 Qwen1.5-7B、SOLAR-10.7B-Instruct-v1.0、Meta-Llama-3-8B 和 Zephyr-7B-Beta 展现出显著潜力，作为大型模型的竞争者。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18128v1",
      "published_date": "2025-01-30 04:20:16 UTC",
      "updated_date": "2025-01-30 04:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:03:04.243447"
    },
    {
      "arxiv_id": "2502.00059v1",
      "title": "Large Language Models are Few-shot Multivariate Time Series Classifiers",
      "title_zh": "大语言模型是少样本多变量时间序列分类器",
      "authors": [
        "Yakun Chen",
        "Zihao Li",
        "Chao Yang",
        "Xianzhi Wang",
        "Guandong Xu"
      ],
      "abstract": "Large Language Models (LLMs) have been extensively applied in time series\nanalysis. Yet, their utility in the few-shot classification (i.e., a crucial\ntraining scenario due to the limited training data available in industrial\napplications) concerning multivariate time series data remains underexplored.\nWe aim to leverage the extensive pre-trained knowledge in LLMs to overcome the\ndata scarcity problem within multivariate time series. Specifically, we propose\nLLMFew, an LLM-enhanced framework to investigate the feasibility and capacity\nof LLMs for few-shot multivariate time series classification. This model\nintroduces a Patch-wise Temporal Convolution Encoder (PTCEnc) to align time\nseries data with the textual embedding input of LLMs. We further fine-tune the\npre-trained LLM decoder with Low-rank Adaptations (LoRA) to enhance its feature\nrepresentation learning ability in time series data. Experimental results show\nthat our model outperformed state-of-the-art baselines by a large margin,\nachieving 125.2% and 50.2% improvement in classification accuracy on\nHandwriting and EthanolConcentration datasets, respectively. Moreover, our\nexperimental results demonstrate that LLM-based methods perform well across a\nvariety of datasets in few-shot MTSC, delivering reliable results compared to\ntraditional models. This success paves the way for their deployment in\nindustrial environments where data are limited.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 在少样本多变量时间序列分类（few-shot multivariate time series classification）中的潜力，提出 LLMFew 框架，利用 LLMs 的预训练知识来应对工业应用中数据稀缺的挑战。框架的核心包括 Patch-wise Temporal Convolution Encoder (PTCEnc)，用于将时间序列数据与 LLMs 的文本嵌入对齐，以及 Low-rank Adaptations (LoRA) 来微调 LLM 解码器，提升其在时间序列数据中的特征表示学习能力。实验结果显示，LLMFew 在 Handwriting 和 EthanolConcentration 数据集上分别比最先进基线提高了 125.2% 和 50.2% 的分类准确率，并在多种数据集上表现出色，为数据有限的工业环境部署 LLMs 铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00059v1",
      "published_date": "2025-01-30 03:59:59 UTC",
      "updated_date": "2025-01-30 03:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:03:16.247862"
    },
    {
      "arxiv_id": "2501.18124v2",
      "title": "REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Liangjing Shao",
        "Benshuang Chen",
        "Shuting Zhao",
        "Xinrong Chen"
      ],
      "abstract": "Real-time ego-motion tracking for endoscope is a significant task for\nefficient navigation and robotic automation of endoscopy. In this paper, a\nnovel framework is proposed to perform real-time ego-motion tracking for\nendoscope. Firstly, a multi-modal visual feature learning network is proposed\nto perform relative pose prediction, in which the motion feature from the\noptical flow, the scene features and the joint feature from two adjacent\nobservations are all extracted for prediction. Due to more correlation\ninformation in the channel dimension of the concatenated image, a novel feature\nextractor is designed based on an attention mechanism to integrate\nmulti-dimensional information from the concatenation of two continuous frames.\nTo extract more complete feature representation from the fused features, a\nnovel pose decoder is proposed to predict the pose transformation from the\nconcatenated feature map at the end of the framework. At last, the absolute\npose of endoscope is calculated based on relative poses. The experiment is\nconducted on three datasets of various endoscopic scenes and the results\ndemonstrate that the proposed method outperforms state-of-the-art methods.\nBesides, the inference speed of the proposed method is over 30 frames per\nsecond, which meets the real-time requirement. The project page is here:\nremote-bmxs.netlify.app",
      "tldr_zh": "本文提出了一种名为REMOTE的框架，用于各种内窥镜的实时ego-motion跟踪，以支持高效导航和机器人自动化。该框架采用多模态视觉特征学习网络，提取光流（optical flow）的运动特征、场景特征以及相邻观察的联合特征，并通过基于注意力机制的特征提取器和新型姿态解码器预测相对姿态，最终计算绝对姿态。实验结果显示，该方法在三个内窥镜场景数据集上优于现有技术，且推理速度超过30帧/秒，满足实时要求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.18124v2",
      "published_date": "2025-01-30 03:58:41 UTC",
      "updated_date": "2025-02-02 14:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:03:27.720780"
    },
    {
      "arxiv_id": "2501.18122v1",
      "title": "VQLTI: Long-Term Tropical Cyclone Intensity Forecasting with Physical Constraints",
      "title_zh": "VQLTI：具有物理约束的长期热带气旋强度预报",
      "authors": [
        "Xinyu Wang",
        "Lei Liu",
        "Kang Chen",
        "Tao Han",
        "Bin Li",
        "Lei Bai"
      ],
      "abstract": "Tropical cyclone (TC) intensity forecasting is crucial for early disaster\nwarning and emergency decision-making. Numerous researchers have explored\ndeep-learning methods to address computational and post-processing issues in\noperational forecasting. Regrettably, they exhibit subpar long-term forecasting\ncapabilities. We use two strategies to enhance long-term forecasting. (1) By\nenhancing the matching between TC intensity and spatial information, we can\nimprove long-term forecasting performance. (2) Incorporating physical knowledge\nand physical constraints can help mitigate the accumulation of forecasting\nerrors. To achieve the above strategies, we propose the VQLTI framework. VQLTI\ntransfers the TC intensity information to a discrete latent space while\nretaining the spatial information differences, using large-scale spatial\nmeteorological data as conditions. Furthermore, we leverage the forecast from\nthe weather prediction model FengWu to provide additional physical knowledge\nfor VQLTI. Additionally, we calculate the potential intensity (PI) to impose\nphysical constraints on the latent variables. In the global long-term TC\nintensity forecasting, VQLTI achieves state-of-the-art results for the 24h to\n120h, with the MSW (Maximum Sustained Wind) forecast error reduced by\n35.65%-42.51% compared to ECMWF-IFS.",
      "tldr_zh": "本研究针对热带气旋(TC)强度预报的长期预测挑战，提出VQLTI框架，通过增强TC强度与空间信息的匹配以及融入物理知识和约束来缓解错误积累问题。VQLTI将TC强度信息转移到离散潜在空间，同时保留空间差异，使用大规模空间气象数据作为条件，并结合FengWu天气模型的物理知识和潜在强度(PI)约束进行优化。在全球长期预测中，VQLTI在24h至120h的MSW(Maximum Sustained Wind)预报错误率比ECMWF-IFS降低了35.65%-42.51%，实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18122v1",
      "published_date": "2025-01-30 03:52:37 UTC",
      "updated_date": "2025-01-30 03:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:03:40.395952"
    },
    {
      "arxiv_id": "2501.18119v1",
      "title": "Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qika Lin",
        "Tianzhe Zhao",
        "Kai He",
        "Zhen Peng",
        "Fangzhi Xu",
        "Ling Huang",
        "Jingying Ma",
        "Mengling Feng"
      ],
      "abstract": "Due to the presence of the natural gap between Knowledge Graph (KG)\nstructures and the natural language, the effective integration of holistic\nstructural information of KGs with Large Language Models (LLMs) has emerged as\na significant question. To this end, we propose a two-stage framework to learn\nand apply quantized codes for each entity, aiming for the seamless integration\nof KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)\nmethod is proposed to compress both KG structural and semantic knowledge into\ndiscrete codes (\\ie, tokens) that align the format of language sentences. We\nfurther design KG instruction-following data by viewing these learned codes as\nfeatures to directly input to LLMs, thereby achieving seamless integration. The\nexperiment results demonstrate that SSQR outperforms existing unsupervised\nquantized methods, producing more distinguishable codes. Further, the\nfine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link\nprediction and triple classification tasks, utilizing only 16 tokens per entity\ninstead of thousands in conventional prompting methods.",
      "tldr_zh": "本研究提出了一种自监督量化表示（SSQR）框架，用于无缝整合知识图谱（KG）和大型语言模型（LLMs），以解决KG结构与自然语言之间的鸿沟问题。SSQR方法通过两阶段过程，首先将KG的结构和语义知识压缩成与语言句子格式对齐的离散代码（tokens），然后利用这些代码生成KG指令跟随数据，直接输入LLMs进行训练。实验结果显示，SSQR优于现有无监督量化方法，在KG链接预测和三元组分类任务上，fine-tuned的LLaMA2和LLaMA3.1模型表现出色，每个实体仅需16个tokens，而传统提示方法需数千个。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18119v1",
      "published_date": "2025-01-30 03:40:20 UTC",
      "updated_date": "2025-01-30 03:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:03:51.304627"
    },
    {
      "arxiv_id": "2501.18108v1",
      "title": "Investigating an Intelligent System to Monitor \\& Explain Abnormal Activity Patterns of Older Adults",
      "title_zh": "翻译失败",
      "authors": [
        "Min Hun Lee",
        "Daniel P. Siewiorek",
        "Alexandre Bernardino"
      ],
      "abstract": "Despite the growing potential of older adult care technologies, the adoption\nof these technologies remains challenging. In this work, we conducted a\nfocus-group session with family caregivers to scope designs of the older adult\ncare technology. We then developed a high-fidelity prototype and conducted its\nqualitative study with professional caregivers and older adults to understand\ntheir perspectives on the system functionalities. This system monitors abnormal\nactivity patterns of older adults using wireless motion sensors and machine\nlearning models and supports interactive dialogue responses to explain abnormal\nactivity patterns of older adults to caregivers and allow older adults\nproactively sharing their status with caregivers for an adequate intervention.\nBoth older adults and professional caregivers appreciated that our system can\nprovide a faster, personalized service while proactively controlling what\ninformation is to be shared through interactive dialogue responses. We further\ndiscuss other considerations to realize older adult technology in practice.",
      "tldr_zh": "本研究调查了一种智能系统，用于监控和解释老年人的异常活动模式，以提升老年人护理技术的采用。研究团队通过焦点小组会议设计系统，并开发高保真原型，进行定性研究，收集专业护理人员和老年人的反馈，该系统利用无线 motion sensors 和 machine learning models 检测异常，并提供 interactive dialogue responses 让老年人主动分享状态以便及时干预。结果显示，用户欣赏该系统提供更快、个性化的服务，同时允许控制信息共享；研究进一步讨论了在实际中实现该技术的其他考虑。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18108v1",
      "published_date": "2025-01-30 03:21:14 UTC",
      "updated_date": "2025-01-30 03:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:04:03.347744"
    },
    {
      "arxiv_id": "2501.18107v1",
      "title": "Scaling Inference-Efficient Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Song Bian",
        "Minghao Yan",
        "Shivaram Venkataraman"
      ],
      "abstract": "Scaling laws are powerful tools to predict the performance of large language\nmodels. However, current scaling laws fall short of accounting for inference\ncosts. In this work, we first show that model architecture affects inference\nlatency, where models of the same size can have up to 3.5x difference in\nlatency. To tackle this challenge, we modify the Chinchilla scaling laws to\nco-optimize the model parameter count, the number of training tokens, and the\nmodel architecture. Due to the reason that models of similar training loss\nexhibit gaps in downstream evaluation, we also propose a novel method to train\ninference-efficient models based on the revised scaling laws. We perform\nextensive empirical studies to fit and evaluate our inference-aware scaling\nlaws. We vary model parameters from 80M to 1B, training tokens from 1.6B to\n30B, and model shapes, training a total of 63 models. Guided by our\ninference-efficient scaling law and model selection method, we release the\nMorph-1B model, which improves inference latency by 1.8x while maintaining\naccuracy on downstream tasks compared to open-source models, pushing the Pareto\nfrontier of accuracy-latency tradeoff.",
      "tldr_zh": "该研究发现，现有的 Scaling laws 未能考虑推理成本，并通过修改 Chinchilla Scaling laws 来共同优化模型参数数量、训练标记数量和模型架构，以提升语言模型的推理效率。作者进行了广泛实证研究，训练了63个模型（参数从80M到1B，训练标记从1.6B到30B），并提出了一种新方法来选择和训练推理高效模型，以解决类似训练损失模型在下游评估中的性能差距。最终，他们发布了 Morph-1B 模型，该模型将推理延迟降低了1.8倍，同时在下游任务上保持准确性，推动了准确性-延迟权衡的 Pareto 前沿。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.18107v1",
      "published_date": "2025-01-30 03:16:44 UTC",
      "updated_date": "2025-01-30 03:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:04:15.899862"
    },
    {
      "arxiv_id": "2501.18100v1",
      "title": "Panacea: Mitigating Harmful Fine-tuning for Large Language Models via Post-fine-tuning Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Yibo Wang",
        "Tiansheng Huang",
        "Li Shen",
        "Huanjin Yao",
        "Haotian Luo",
        "Rui Liu",
        "Naiqiang Tan",
        "Jiaxing Huang",
        "Dacheng Tao"
      ],
      "abstract": "Harmful fine-tuning attack introduces significant security risks to the\nfine-tuning services. Mainstream defenses aim to vaccinate the model such that\nthe later harmful fine-tuning attack is less effective. However, our evaluation\nresults show that such defenses are fragile -- with a few fine-tuning steps,\nthe model still can learn the harmful knowledge. To this end, we do further\nexperiment and find that an embarrassingly simple solution -- adding purely\nrandom perturbations to the fine-tuned model, can recover the model from\nharmful behavior, though it leads to a degradation in the model's fine-tuning\nperformance. To address the degradation of fine-tuning performance, we further\npropose Panacea, which optimizes an adaptive perturbation that will be applied\nto the model after fine-tuning. Panacea maintains model's safety alignment\nperformance without compromising downstream fine-tuning performance.\nComprehensive experiments are conducted on different harmful ratios,\nfine-tuning tasks and mainstream LLMs, where the average harmful scores are\nreduced by up-to 21.5%, while maintaining fine-tuning performance. As a\nby-product, we analyze the optimized perturbation and show that different\nlayers in various LLMs have distinct safety coefficients. Source code available\nat https://github.com/w-yibo/Panacea",
      "tldr_zh": "该研究针对有害微调攻击对大型语言模型(Large Language Models)的安全风险，指出现有防御方法易被少量微调步骤绕过。作者提出Panacea方法，通过在微调后应用优化自适应扰动(perturbation)，以恢复模型的安全性，同时避免对下游微调性能的负面影响。实验结果显示，在不同有害比例、任务和LLMs上，Panacea平均降低了21.5%的有害分数，并分析了模型各层的安全系数，为更可靠的微调服务提供了新方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18100v1",
      "published_date": "2025-01-30 02:47:09 UTC",
      "updated_date": "2025-01-30 02:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:04:26.807112"
    },
    {
      "arxiv_id": "2501.18099v1",
      "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge",
      "title_zh": "翻译失败",
      "authors": [
        "Swarnadeep Saha",
        "Xian Li",
        "Marjan Ghazvininejad",
        "Jason Weston",
        "Tianlu Wang"
      ],
      "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to\ncapture the step-bystep reasoning process that underlies the final evaluation\nof a response. However, due to the lack of human annotated CoTs for evaluation,\nthe required components and structure of effective reasoning traces remain\nunderstudied. Consequently, previous approaches often (1) constrain reasoning\ntraces to hand-designed components, such as a list of criteria, reference\nanswers, or verification questions and (2) structure them such that planning is\nintertwined with the reasoning for evaluation. In this work, we propose\nEvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge\nthat first generates an unconstrained evaluation plan, followed by its\nexecution, and then the final judgment. In a self-training loop, EvalPlanner\niteratively optimizes over synthetically constructed evaluation plans and\nexecutions, leading to better final verdicts. Our method achieves a new\nstate-of-the-art performance for generative reward models on RewardBench (with\na score of 93.9), despite being trained on fewer amount of, and synthetically\ngenerated, preference pairs. Additional experiments on other benchmarks like\nRM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both\nplanning and reasoning for building robust LLM-as-a-Judge reasoning models.",
      "tldr_zh": "本研究针对LLM-as-a-Judge模型的Chain-of-Thought (CoT)推理问题，提出EvalPlanner算法，该算法通过先生成不受约束的评估计划、随后执行计划并得出最终判断，实现对评估过程的优化。EvalPlanner采用自训练循环，迭代改进合成的偏好对，从而提升推理模型的性能。尽管训练数据量少且为合成生成，该方法在RewardBench上达到了新的state-of-the-art分数（93.9），并在RM-Bench、JudgeBench和FollowBenchEval等基准上证明了规划和推理对构建鲁棒LLM-as-a-Judge模型的效用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18099v1",
      "published_date": "2025-01-30 02:21:59 UTC",
      "updated_date": "2025-01-30 02:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:04:39.256556"
    },
    {
      "arxiv_id": "2501.18096v1",
      "title": "LLMs can see and hear without any training",
      "title_zh": "翻译失败",
      "authors": [
        "Kumar Ashutosh",
        "Yossi Gandelsman",
        "Xinlei Chen",
        "Ishan Misra",
        "Rohit Girdhar"
      ],
      "abstract": "We present MILS: Multimodal Iterative LLM Solver, a surprisingly simple,\ntraining-free approach, to imbue multimodal capabilities into your favorite\nLLM. Leveraging their innate ability to perform multi-step reasoning, MILS\nprompts the LLM to generate candidate outputs, each of which are scored and fed\nback iteratively, eventually generating a solution to the task. This enables\nvarious applications that typically require training specialized models on\ntask-specific data. In particular, we establish a new state-of-the-art on\nemergent zero-shot image, video and audio captioning. MILS seamlessly applies\nto media generation as well, discovering prompt rewrites to improve\ntext-to-image generation, and even edit prompts for style transfer! Finally,\nbeing a gradient-free optimization approach, MILS can invert multimodal\nembeddings into text, enabling applications like cross-modal arithmetic.",
      "tldr_zh": "本研究提出 MILS（Multimodal Iterative LLM Solver），一种无需训练的简单方法，利用 LLM 的多步推理能力，通过生成候选输出、迭代评分和反馈来赋予 LLM 多模态处理能力。MILS 在零样本图像、视频和音频标题生成任务上建立了新的 state-of-the-art 性能，并扩展到媒体生成领域，如优化文本到图像生成提示和实现风格转移。作为无梯度优化方法，它还能将多模态嵌入反转成文本，支持跨模态算术等应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/facebookresearch/MILS",
      "pdf_url": "http://arxiv.org/pdf/2501.18096v1",
      "published_date": "2025-01-30 02:16:35 UTC",
      "updated_date": "2025-01-30 02:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:04:51.107995"
    },
    {
      "arxiv_id": "2501.18086v1",
      "title": "DIAL: Distribution-Informed Adaptive Learning of Multi-Task Constraints for Safety-Critical Systems",
      "title_zh": "DIAL：基于分布信息的适应性多任务约束学习，用于安全关键系统",
      "authors": [
        "Se-Wook Yoo",
        "Seung-Woo Seo"
      ],
      "abstract": "Safe reinforcement learning has traditionally relied on predefined constraint\nfunctions to ensure safety in complex real-world tasks, such as autonomous\ndriving. However, defining these functions accurately for varied tasks is a\npersistent challenge. Recent research highlights the potential of leveraging\npre-acquired task-agnostic knowledge to enhance both safety and sample\nefficiency in related tasks. Building on this insight, we propose a novel\nmethod to learn shared constraint distributions across multiple tasks. Our\napproach identifies the shared constraints through imitation learning and then\nadapts to new tasks by adjusting risk levels within these learned\ndistributions. This adaptability addresses variations in risk sensitivity\nstemming from expert-specific biases, ensuring consistent adherence to general\nsafety principles even with imperfect demonstrations. Our method can be applied\nto control and navigation domains, including multi-task and meta-task\nscenarios, accommodating constraints such as maintaining safe distances or\nadhering to speed limits. Experimental results validate the efficacy of our\napproach, demonstrating superior safety performance and success rates compared\nto baselines, all without requiring task-specific constraint definitions. These\nfindings underscore the versatility and practicality of our method across a\nwide range of real-world tasks.",
      "tldr_zh": "这篇论文提出了DIAL方法，通过学习多任务共享的约束分布来提升安全强化学习（Reinforcement Learning）的安全性和样本效率，避免了为不同任务预定义约束函数的挑战。DIAL利用模仿学习（Imitation Learning）识别共享约束，然后通过调整风险水平适应新任务，从而处理专家特定偏差并确保遵守一般安全原则。实验结果显示，该方法在控制和导航领域（如多任务和元任务场景）表现出优越的安全性能和成功率，适用于真实世界的安全关键系统，而无需任务特定的约束定义。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 14 figures, 6 tables, submission to T-RO in 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.18086v1",
      "published_date": "2025-01-30 01:56:07 UTC",
      "updated_date": "2025-01-30 01:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:05:02.868297"
    },
    {
      "arxiv_id": "2501.18653v1",
      "title": "Cogito, ergo sum: A Neurobiologically-Inspired Cognition-Memory-Growth System for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlong Li",
        "Jindong Li",
        "Qi Wang",
        "Menglin Yang",
        "He Kong",
        "Shengsheng Wang"
      ],
      "abstract": "Large language models based Multi Agent Systems (MAS) have demonstrated\npromising performance for enhancing the efficiency and accuracy of code\ngeneration tasks. However,most existing methods follow a conventional sequence\nof planning, coding, and debugging,which contradicts the growth-driven nature\nof human learning process. Additionally,the frequent information interaction\nbetween multiple agents inevitably involves high computational costs. In this\npaper,we propose Cogito,a neurobiologically inspired multi-agent framework to\nenhance the problem-solving capabilities in code generation tasks with lower\ncost. Specifically,Cogito adopts a reverse sequence: it first undergoes\ndebugging, then coding,and finally planning. This approach mimics human\nlearning and development,where knowledge is acquired progressively.\nAccordingly,a hippocampus-like memory module with different functions is\ndesigned to work with the pipeline to provide quick retrieval in similar tasks.\nThrough this growth-based learning model,Cogito accumulates knowledge and\ncognitive skills at each stage,ultimately forming a Super Role an all capable\nagent to perform the code generation task. Extensive experiments against\nrepresentative baselines demonstrate the superior performance and efficiency of\nCogito. The code is publicly available at\nhttps://anonymous.4open.science/r/Cogito-0083.",
      "tldr_zh": "这篇论文提出 Cogito，一个受神经生物学启发的多智能体框架（Multi Agent Systems），旨在提升代码生成的效率和准确性，同时降低计算成本。Cogito 采用逆向序列（先调试、然后编码、最后规划），模仿人类学习过程，并设计了一个 hippocampus-like memory module 来快速检索类似任务知识。通过这种增长式学习，Cogito 逐步积累认知技能，形成一个全能的 Super Role 代理。实验结果显示，Cogito 在代码生成任务中比现有基线方法表现出色，且效率更高。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18653v1",
      "published_date": "2025-01-30 01:41:44 UTC",
      "updated_date": "2025-01-30 01:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:05:16.178270"
    },
    {
      "arxiv_id": "2501.18081v1",
      "title": "Normative Evaluation of Large Language Models with Everyday Moral Dilemmas",
      "title_zh": "翻译失败",
      "authors": [
        "Pratik S. Sachdeva",
        "Tom van Nuenen"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) has spurred extensive\nresearch into their encoded moral norms and decision-making processes. Much of\nthis research relies on prompting LLMs with survey-style questions to assess\nhow well models are aligned with certain demographic groups, moral beliefs, or\npolitical ideologies. While informative, the adherence of these approaches to\nrelatively superficial constructs tends to oversimplify the complexity and\nnuance underlying everyday moral dilemmas. We argue that auditing LLMs along\nmore detailed axes of human interaction is of paramount importance to better\nassess the degree to which they may impact human beliefs and actions. To this\nend, we evaluate LLMs on complex, everyday moral dilemmas sourced from the \"Am\nI the Asshole\" (AITA) community on Reddit, where users seek moral judgments on\neveryday conflicts from other community members. We prompted seven LLMs to\nassign blame and provide explanations for over 10,000 AITA moral dilemmas. We\nthen compared the LLMs' judgments and explanations to those of Redditors and to\neach other, aiming to uncover patterns in their moral reasoning. Our results\ndemonstrate that large language models exhibit distinct patterns of moral\njudgment, varying substantially from human evaluations on the AITA subreddit.\nLLMs demonstrate moderate to high self-consistency but low inter-model\nagreement. Further analysis of model explanations reveals distinct patterns in\nhow models invoke various moral principles. These findings highlight the\ncomplexity of implementing consistent moral reasoning in artificial systems and\nthe need for careful evaluation of how different models approach ethical\njudgment. As LLMs continue to be used in roles requiring ethical\ndecision-making such as therapists and companions, careful evaluation is\ncrucial to mitigate potential biases and limitations.",
      "tldr_zh": "本研究评估大型语言模型 (LLMs) 在日常道德困境中的规范性表现，批评现有方法过于简化，并提出使用 Reddit 的 \"Am I the Asshole\" (AITA) 社区数据作为更真实基准。研究者提示七个 LLMs 对超过 10,000 个 AITA 道德困境进行判断和解释，并与 Reddit 用户的评价以及模型间结果进行比较。结果显示，LLMs 表现出独特的道德判断模式，与人类评估有显著差异，具有中等到高自我一致性但模型间一致性较低，且在解释中体现出不同的道德原则引用模式。这些发现强调了在 LLMs 应用于伦理决策（如治疗师或伴侣角色）时，需要仔细评估潜在偏见和限制，以确保更可靠的道德推理。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18081v1",
      "published_date": "2025-01-30 01:29:46 UTC",
      "updated_date": "2025-01-30 01:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:05:28.178231"
    },
    {
      "arxiv_id": "2502.15727v1",
      "title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Youssef Maklad",
        "Fares Wael",
        "Wael Elsersy",
        "Ali Hamdi"
      ],
      "abstract": "This paper presents a novel approach to evaluate the efficiency of a\nRAG-based agentic Large Language Model (LLM) architecture in network packet\nseed generation for network protocol fuzzing. Enhanced by chain-of-thought\n(COT) prompting techniques, the proposed approach focuses on the improvement of\nthe seeds structural quality in order to guide protocol fuzzing frameworks\nthrough a wide exploration of the protocol state space. Our method leverages\nRAG and text embeddings in a two-stages. In the first stage, the agent\ndynamically refers to the Request For Comments (RFC) documents knowledge base\nfor answering queries regarding the protocol Finite State Machine (FSM), then\nit iteratively reasons through the retrieved knowledge, for output refinement\nand proper seed placement. In the second stage, we evaluate the response\nstructure quality of the agent's output, based on metrics as BLEU, ROUGE, and\nWord Error Rate (WER) by comparing the generated packets against the ground\ntruth packets. Our experiments demonstrate significant improvements of up to\n18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline\nmodels. These results confirm the potential of such approach, improving\nLLM-based protocol fuzzing frameworks for the identification of hidden\nvulnerabilities.",
      "tldr_zh": "这篇论文提出了一种基于 Retrieval Augmented Generation (RAG) 的 Large Language Model (LLM) 评估方法，用于网络协议模糊测试中的种子生成，通过 Chain-of-Thought (COT) 推理技术提升协议 Finite State Machine (FSM) 的探索效率。方法分为两阶段：第一阶段，代理动态参考 Request For Comments (RFC) 文档知识库并进行迭代推理以优化输出；第二阶段，使用 BLEU、ROUGE 和 Word Error Rate (WER) 指标评估生成的网络包结构质量，与真实数据进行比较。实验结果显示，与基线模型相比，BLEU 改善 18.19%、ROUGE 改善 14.81%、WER 改善 23.45%，从而显著提升了 LLM 在识别协议隐藏漏洞方面的性能。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.IR"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15727v1",
      "published_date": "2025-01-30 01:03:49 UTC",
      "updated_date": "2025-01-30 01:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:05:39.761126"
    },
    {
      "arxiv_id": "2501.18071v2",
      "title": "Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Pir Bakhsh Khokhar",
        "Viviana Pentangelo",
        "Fabio Palomba",
        "Carmine Gravino"
      ],
      "abstract": "Diabetes mellitus (DM) is a global health issue of significance that must be\ndiagnosed as early as possible and managed well. This study presents a\nframework for diabetes prediction using Machine Learning (ML) models,\ncomplemented with eXplainable Artificial Intelligence (XAI) tools, to\ninvestigate both the predictive accuracy and interpretability of the\npredictions from ML models. Data Preprocessing is based on the Synthetic\nMinority Oversampling Technique (SMOTE) and feature scaling used on the\nDiabetes Binary Health Indicators dataset to deal with class imbalance and\nvariability of clinical features. The ensemble model provided high accuracy,\nwith a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General\nHealth, Income, and Physical Activity were the most influential predictors\nobtained from the model explanations. The results of this study suggest that ML\ncombined with XAI is a promising means of developing accurate and\ncomputationally transparent tools for use in healthcare systems.",
      "tldr_zh": "本研究提出了一种结合 Machine Learning (ML) 和 eXplainable Artificial Intelligence (XAI) 的框架，用于糖尿病预测，以提升预测准确性和可解释性。研究采用 Synthetic Minority Oversampling Technique (SMOTE) 和特征缩放对 Diabetes Binary Health Indicators 数据集进行预处理，以解决类别不平衡和临床特征变异问题。集成模型在测试中实现了92.50%的准确率和0.975的ROC-AUC，并识别出BMI、年龄、一般健康状况、收入和身体活动作为最关键的预测因素。结果表明，ML 与 XAI 的结合有望为医疗系统提供准确且透明的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18071v2",
      "published_date": "2025-01-30 00:42:43 UTC",
      "updated_date": "2025-02-12 11:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:05:51.226511"
    },
    {
      "arxiv_id": "2501.18064v1",
      "title": "Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features",
      "title_zh": "翻译失败",
      "authors": [
        "Mathieu Calvat",
        "Chris Bean",
        "Dhruv Anjaria",
        "Hyoungryul Park",
        "Haoren Wang",
        "Kenneth Vecchio",
        "J. C. Stinville"
      ],
      "abstract": "To leverage advancements in machine learning for metallic materials design\nand property prediction, it is crucial to develop a data-reduced representation\nof metal microstructures that surpasses the limitations of current\nphysics-based discrete microstructure descriptors. This need is particularly\nrelevant for metallic materials processed through additive manufacturing, which\nexhibit complex hierarchical microstructures that cannot be adequately\ndescribed using the conventional metrics typically applied to wrought\nmaterials. Furthermore, capturing the spatial heterogeneity of microstructures\nat the different scales is necessary within such framework to accurately\npredict their properties. To address these challenges, we propose the physical\nspatial mapping of metal diffraction latent space features. This approach\nintegrates (i) point diffraction data encoding via variational autoencoders or\ncontrastive learning and (ii) the physical mapping of the encoded values.\nTogether these steps offer a method offers a novel means to comprehensively\ndescribe metal microstructures. We demonstrate this approach on a wrought and\nadditively manufactured alloy, showing that it effectively encodes\nmicrostructural information and enables direct identification of\nmicrostructural heterogeneity not directly possible by physics-based models.\nThis data-reduced microstructure representation opens the application of\nmachine learning models in accelerating metallic material design and accurately\npredicting their properties.",
      "tldr_zh": "本研究旨在通过机器学习提升金属材料的设计和属性预测，提出一种超越传统物理基描述符的数据简化表示方法，以处理增材制造等复杂层次微观结构的空间异质性。该方法包括使用 variational autoencoders 或 contrastive learning 编码点衍射数据，并进行物理空间映射，从而全面捕捉微观结构的特征。在一个锻造和增材制造合金的实验中，该方法成功编码微观信息并识别出传统模型无法直接检测的异质性，为加速金属材料设计和属性预测提供了新颖的应用框架。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18064v1",
      "published_date": "2025-01-30 00:16:07 UTC",
      "updated_date": "2025-01-30 00:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:06:03.330808"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 100,
  "processed_papers_count": 100,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T05:06:20.158035"
}