[
  {
    "arxiv_id": "2408.15245v1",
    "title": "An Edge AI System Based on FPGA Platform for Railway Fault Detection",
    "authors": [
      "Jiale Li",
      "Yulin Fu",
      "Dongwei Yan",
      "Sean Longyu Ma",
      "Chiu-Wing Sham"
    ],
    "abstract": "As the demands for railway transportation safety increase, traditional\nmethods of rail track inspection no longer meet the needs of modern railway\nsystems. To address the issues of automation and efficiency in rail fault\ndetection, this study introduces a railway inspection system based on Field\nProgrammable Gate Array (FPGA). This edge AI system collects track images via\ncameras and uses Convolutional Neural Networks (CNN) to perform real-time\ndetection of track defects and automatically reports fault information. The\ninnovation of this system lies in its high level of automation and detection\nefficiency. The neural network approach employed by this system achieves a\ndetection accuracy of 88.9%, significantly enhancing the reliability and\nefficiency of detection. Experimental results demonstrate that this FPGA-based\nsystem is 1.39* and 4.67* better in energy efficiency than peer implementation\non the GPU and CPU platform, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the 2024 IEEE 13th Global Conference on Consumer\n  Electronics (GCCE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.15245v1",
    "published_date": "2024-08-08 22:44:30 UTC",
    "updated_date": "2024-08-08 22:44:30 UTC"
  },
  {
    "arxiv_id": "2408.04771v1",
    "title": "AI Consciousness and Public Perceptions: Four Futures",
    "authors": [
      "Ines Fernandez",
      "Nicoleta Kyosovska",
      "Jay Luong",
      "Gabriel Mukobi"
    ],
    "abstract": "The discourse on risks from advanced AI systems (\"AIs\") typically focuses on\nmisuse, accidents and loss of control, but the question of AIs' moral status\ncould have negative impacts which are of comparable significance and could be\nrealised within similar timeframes. Our paper evaluates these impacts by\ninvestigating (1) the factual question of whether future advanced AI systems\nwill be conscious, together with (2) the epistemic question of whether future\nhuman society will broadly believe advanced AI systems to be conscious.\nAssuming binary responses to (1) and (2) gives rise to four possibilities: in\nthe true positive scenario, society predominantly correctly believes that AIs\nare conscious; in the false positive scenario, that belief is incorrect; in the\ntrue negative scenario, society correctly believes that AIs are not conscious;\nand lastly, in the false negative scenario, society incorrectly believes that\nAIs are not conscious. The paper offers vivid vignettes of the different\nfutures to ground the two-dimensional framework. Critically, we identify four\nmajor risks: AI suffering, human disempowerment, geopolitical instability, and\nhuman depravity. We evaluate each risk across the different scenarios and\nprovide an overall qualitative risk assessment for each scenario. Our analysis\nsuggests that the worst possibility is the wrong belief that AI is\nnon-conscious, followed by the wrong belief that AI is conscious. The paper\nconcludes with the main recommendations to avoid research aimed at\nintentionally creating conscious AI and instead focus efforts on reducing our\ncurrent uncertainties on both the factual and epistemic questions on AI\nconsciousness.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04771v1",
    "published_date": "2024-08-08 22:01:57 UTC",
    "updated_date": "2024-08-08 22:01:57 UTC"
  },
  {
    "arxiv_id": "2408.04767v1",
    "title": "Data-Driven Pixel Control: Challenges and Prospects",
    "authors": [
      "Saurabh Farkya",
      "Zachary Alan Daniels",
      "Aswin Raghavan",
      "Gooitzen van der Wal",
      "Michael Isnardi",
      "Michael Piacentino",
      "David Zhang"
    ],
    "abstract": "Recent advancements in sensors have led to high resolution and high data\nthroughput at the pixel level. Simultaneously, the adoption of increasingly\nlarge (deep) neural networks (NNs) has lead to significant progress in computer\nvision. Currently, visual intelligence comes at increasingly high computational\ncomplexity, energy, and latency. We study a data-driven system that combines\ndynamic sensing at the pixel level with computer vision analytics at the video\nlevel and propose a feedback control loop to minimize data movement between the\nsensor front-end and computational back-end without compromising detection and\ntracking precision. Our contributions are threefold: (1) We introduce\nanticipatory attention and show that it leads to high precision prediction with\nsparse activation of pixels; (2) Leveraging the feedback control, we show that\nthe dimensionality of learned feature vectors can be significantly reduced with\nincreased sparsity; and (3) We emulate analog design choices (such as varying\nRGB or Bayer pixel format and analog noise) and study their impact on the key\nmetrics of the data-driven system. Comparative analysis with traditional pixel\nand deep learning models shows significant performance enhancements. Our system\nachieves a 10X reduction in bandwidth and a 15-30X improvement in Energy-Delay\nProduct (EDP) when activating only 30% of pixels, with a minor reduction in\nobject detection and tracking precision. Based on analog emulation, our system\ncan achieve a throughput of 205 megapixels/sec (MP/s) with a power consumption\nof only 110 mW per MP, i.e., a theoretical improvement of ~30X in EDP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the Conference on Dynamic Data-Driven Applications\n  Systems (DDDAS2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.04767v1",
    "published_date": "2024-08-08 21:49:19 UTC",
    "updated_date": "2024-08-08 21:49:19 UTC"
  },
  {
    "arxiv_id": "2408.05253v1",
    "title": "A Systematic Literature Map on Big Data",
    "authors": [
      "Rogerio Rossi",
      "Kechi Hirama",
      "Eduardo Ferreira Franco"
    ],
    "abstract": "The paradigm of Big Data has been established as a solid field of studies in\nmany areas such as healthcare, science, transport, education, government\nservices, among others. Despite widely discussed, there is no agreed definition\nabout the paradigm although there are many concepts proposed by the academy and\nindustry. This work aims to provide an analytical view of the studies conducted\nand published regarding the Big Data paradigm. The approach used is the\nsystematic map of the literature, combining bibliometric analysis and content\nanalysis to depict the panorama of research works, identifying patterns,\ntrends, and gaps. The results indicate that there is still a long way to go,\nboth in research and in concepts, such as building and defining adequate\ninfrastructures and standards, to meet future challenges and for the paradigm\nto become effective and bring the expected benefits.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.ET",
      "H.0"
    ],
    "primary_category": "cs.DL",
    "comment": "8 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05253v1",
    "published_date": "2024-08-08 21:41:44 UTC",
    "updated_date": "2024-08-08 21:41:44 UTC"
  },
  {
    "arxiv_id": "2408.04760v1",
    "title": "Embodied Uncertainty-Aware Object Segmentation",
    "authors": [
      "Xiaolin Fang",
      "Leslie Pack Kaelbling",
      "Tomás Lozano-Pérez"
    ],
    "abstract": "We introduce uncertainty-aware object instance segmentation (UncOS) and\ndemonstrate its usefulness for embodied interactive segmentation. To deal with\nuncertainty in robot perception, we propose a method for generating a\nhypothesis distribution of object segmentation. We obtain a set of\nregion-factored segmentation hypotheses together with confidence estimates by\nmaking multiple queries of large pre-trained models. This process can produce\nsegmentation results that achieve state-of-the-art performance on unseen object\nsegmentation problems. The output can also serve as input to a belief-driven\nprocess for selecting robot actions to perturb the scene to reduce ambiguity.\nWe demonstrate the effectiveness of this method in real-robot experiments.\nWebsite: https://sites.google.com/view/embodied-uncertain-seg",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04760v1",
    "published_date": "2024-08-08 21:29:22 UTC",
    "updated_date": "2024-08-08 21:29:22 UTC"
  },
  {
    "arxiv_id": "2408.15244v1",
    "title": "Misrepresented Technological Solutions in Imagined Futures: The Origins and Dangers of AI Hype in the Research Community",
    "authors": [
      "Savannah Thais"
    ],
    "abstract": "Technology does not exist in a vacuum; technological development, media\nrepresentation, public perception, and governmental regulation cyclically\ninfluence each other to produce the collective understanding of a technology's\ncapabilities, utilities, and risks. When these capabilities are overestimated,\nthere is an enhanced risk of subjecting the public to dangerous or harmful\ntechnology, artificially restricting research and development directions, and\nenabling misguided or detrimental policy. The dangers of technological hype are\nparticularly relevant in the rapidly evolving space of AI. Centering the\nresearch community as a key player in the development and proliferation of\nhype, we examine the origins and risks of AI hype to the research community and\nsociety more broadly and propose a set of measures that researchers,\nregulators, and the public can take to mitigate these risks and reduce the\nprevalence of unfounded claims about the technology.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to AIES 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.15244v1",
    "published_date": "2024-08-08 20:47:17 UTC",
    "updated_date": "2024-08-08 20:47:17 UTC"
  },
  {
    "arxiv_id": "2408.04746v1",
    "title": "More Questions than Answers? Lessons from Integrating Explainable AI into a Cyber-AI Tool",
    "authors": [
      "Ashley Suh",
      "Harry Li",
      "Caitlin Kenney",
      "Kenneth Alperin",
      "Steven R. Gomez"
    ],
    "abstract": "We share observations and challenges from an ongoing effort to implement\nExplainable AI (XAI) in a domain-specific workflow for cybersecurity analysts.\nSpecifically, we briefly describe a preliminary case study on the use of XAI\nfor source code classification, where accurate assessment and timeliness are\nparamount. We find that the outputs of state-of-the-art saliency explanation\ntechniques (e.g., SHAP or LIME) are lost in translation when interpreted by\npeople with little AI expertise, despite these techniques being marketed for\nnon-technical users. Moreover, we find that popular XAI techniques offer fewer\ninsights for real-time human-AI workflows when they are post hoc and too\nlocalized in their explanations. Instead, we observe that cyber analysts need\nhigher-level, easy-to-digest explanations that can offer as little disruption\nas possible to their workflows. We outline unaddressed gaps in practical and\neffective XAI, then touch on how emerging technologies like Large Language\nModels (LLMs) could mitigate these existing obstacles.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)",
    "pdf_url": "http://arxiv.org/pdf/2408.04746v1",
    "published_date": "2024-08-08 20:09:31 UTC",
    "updated_date": "2024-08-08 20:09:31 UTC"
  },
  {
    "arxiv_id": "2408.04745v1",
    "title": "AI for operational methane emitter monitoring from space",
    "authors": [
      "Anna Vaughan",
      "Gonzalo Mateo-Garcia",
      "Itziar Irakulis-Loitxate",
      "Marc Watine",
      "Pablo Fernandez-Poblaciones",
      "Richard E. Turner",
      "James Requeima",
      "Javier Gorroño",
      "Cynthia Randles",
      "Manfredi Caltagirone",
      "Claudio Cifarelli"
    ],
    "abstract": "Mitigating methane emissions is the fastest way to stop global warming in the\nshort-term and buy humanity time to decarbonise. Despite the demonstrated\nability of remote sensing instruments to detect methane plumes, no system has\nbeen available to routinely monitor and act on these events. We present\nMARS-S2L, an automated AI-driven methane emitter monitoring system for\nSentinel-2 and Landsat satellite imagery deployed operationally at the United\nNations Environment Programme's International Methane Emissions Observatory. We\ncompile a global dataset of thousands of super-emission events for training and\nevaluation, demonstrating that MARS-S2L can skillfully monitor emissions in a\ndiverse range of regions globally, providing a 216% improvement in mean average\nprecision over a current state-of-the-art detection method. Running this system\noperationally for six months has yielded 457 near-real-time detections in 22\ndifferent countries of which 62 have already been used to provide formal\nnotifications to governments and stakeholders.",
    "categories": [
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04745v1",
    "published_date": "2024-08-08 20:06:37 UTC",
    "updated_date": "2024-08-08 20:06:37 UTC"
  },
  {
    "arxiv_id": "2408.04723v1",
    "title": "Survey: Transformer-based Models in Data Modality Conversion",
    "authors": [
      "Elyas Rashno",
      "Amir Eskandari",
      "Aman Anand",
      "Farhana Zulkernine"
    ],
    "abstract": "Transformers have made significant strides across various artificial\nintelligence domains, including natural language processing, computer vision,\nand audio processing. This success has naturally garnered considerable interest\nfrom both academic and industry researchers. Consequently, numerous Transformer\nvariants (often referred to as X-formers) have been developed for these fields.\nHowever, a thorough and systematic review of these modality-specific\nconversions remains lacking. Modality Conversion involves the transformation of\ndata from one form of representation to another, mimicking the way humans\nintegrate and interpret sensory information. This paper provides a\ncomprehensive review of transformer-based models applied to the primary\nmodalities of text, vision, and speech, discussing their architectures,\nconversion methodologies, and applications. By synthesizing the literature on\nmodality conversion, this survey aims to underline the versatility and\nscalability of transformers in advancing AI-driven content generation and\nunderstanding.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CL",
      "eess.SP"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to ACM Computing Surveys (CSUR)",
    "pdf_url": "http://arxiv.org/pdf/2408.04723v1",
    "published_date": "2024-08-08 18:39:14 UTC",
    "updated_date": "2024-08-08 18:39:14 UTC"
  },
  {
    "arxiv_id": "2408.04713v3",
    "title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models",
    "authors": [
      "Zifeng Ding",
      "Yifeng Li",
      "Yuan He",
      "Antonio Norelli",
      "Jingcheng Wu",
      "Volker Tresp",
      "Yunpu Ma",
      "Michael Bronstein"
    ],
    "abstract": "Learning useful representations for continuous-time dynamic graphs (CTDGs) is\nchallenging, due to the concurrent need to span long node interaction histories\nand grasp nuanced temporal details. In particular, two problems emerge: (1)\nEncoding longer histories requires more computational resources, making it\ncrucial for CTDG models to maintain low computational complexity to ensure\nefficiency; (2) Meanwhile, more powerful models are needed to identify and\nselect the most critical temporal information within the extended context\nprovided by longer histories. To address these problems, we propose a CTDG\nrepresentation learning model named DyGMamba, originating from the popular\nMamba state space model (SSM). DyGMamba first leverages a node-level SSM to\nencode the sequence of historical node interactions. Another time-level SSM is\nthen employed to exploit the temporal patterns hidden in the historical graph,\nwhere its output is used to dynamically select the critical information from\nthe interaction history. We validate DyGMamba experimentally on the dynamic\nlink prediction task. The results show that our model achieves state-of-the-art\nin most cases. DyGMamba also maintains high efficiency in terms of\ncomputational resources, making it possible to capture long temporal\ndependencies with a limited computation budget.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2408.04713v3",
    "published_date": "2024-08-08 18:25:14 UTC",
    "updated_date": "2025-02-03 10:40:25 UTC"
  },
  {
    "arxiv_id": "2408.04708v1",
    "title": "MulliVC: Multi-lingual Voice Conversion With Cycle Consistency",
    "authors": [
      "Jiawei Huang",
      "Chen Zhang",
      "Yi Ren",
      "Ziyue Jiang",
      "Zhenhui Ye",
      "Jinglin Liu",
      "Jinzheng He",
      "Xiang Yin",
      "Zhou Zhao"
    ],
    "abstract": "Voice conversion aims to modify the source speaker's voice to resemble the\ntarget speaker while preserving the original speech content. Despite notable\nadvancements in voice conversion these days, multi-lingual voice conversion\n(including both monolingual and cross-lingual scenarios) has yet to be\nextensively studied. It faces two main challenges: 1) the considerable\nvariability in prosody and articulation habits across languages; and 2) the\nrarity of paired multi-lingual datasets from the same speaker. In this paper,\nwe propose MulliVC, a novel voice conversion system that only converts timbre\nand keeps original content and source language prosody without multi-lingual\npaired data. Specifically, each training step of MulliVC contains three\nsubsteps: In step one the model is trained with monolingual speech data; then,\nsteps two and three take inspiration from back translation, construct a\ncyclical process to disentangle the timbre and other information (content,\nprosody, and other language-related information) in the absence of\nmulti-lingual data from the same speaker. Both objective and subjective results\nindicate that MulliVC significantly surpasses other methods in both monolingual\nand cross-lingual contexts, demonstrating the system's efficacy and the\nviability of the three-step approach with cycle consistency. Audio samples can\nbe found on our demo page (mullivc.github.io).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04708v1",
    "published_date": "2024-08-08 18:12:51 UTC",
    "updated_date": "2024-08-08 18:12:51 UTC"
  },
  {
    "arxiv_id": "2408.04631v1",
    "title": "Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics",
    "authors": [
      "Ruining Li",
      "Chuanxia Zheng",
      "Christian Rupprecht",
      "Andrea Vedaldi"
    ],
    "abstract": "We present Puppet-Master, an interactive video generative model that can\nserve as a motion prior for part-level dynamics. At test time, given a single\nimage and a sparse set of motion trajectories (i.e., drags), Puppet-Master can\nsynthesize a video depicting realistic part-level motion faithful to the given\ndrag interactions. This is achieved by fine-tuning a large-scale pre-trained\nvideo diffusion model, for which we propose a new conditioning architecture to\ninject the dragging control effectively. More importantly, we introduce the\nall-to-first attention mechanism, a drop-in replacement for the widely adopted\nspatial attention modules, which significantly improves generation quality by\naddressing the appearance and background issues in existing models. Unlike\nother motion-conditioned video generators that are trained on in-the-wild\nvideos and mostly move an entire object, Puppet-Master is learned from\nObjaverse-Animation-HQ, a new dataset of curated part-level motion clips. We\npropose a strategy to automatically filter out sub-optimal animations and\naugment the synthetic renderings with meaningful motion trajectories.\nPuppet-Master generalizes well to real images across various categories and\noutperforms existing methods in a zero-shot manner on a real-world benchmark.\nSee our project page for more results: vgg-puppetmaster.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://vgg-puppetmaster.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2408.04631v1",
    "published_date": "2024-08-08 17:59:38 UTC",
    "updated_date": "2024-08-08 17:59:38 UTC"
  },
  {
    "arxiv_id": "2408.04628v1",
    "title": "LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP",
    "authors": [
      "Danlu Chen",
      "Freda Shi",
      "Aditi Agarwal",
      "Jacobo Myerston",
      "Taylor Berg-Kirkpatrick"
    ],
    "abstract": "Standard natural language processing (NLP) pipelines operate on symbolic\nrepresentations of language, which typically consist of sequences of discrete\ntokens. However, creating an analogous representation for ancient logographic\nwriting systems is an extremely labor intensive process that requires expert\nknowledge. At present, a large portion of logographic data persists in a purely\nvisual form due to the absence of transcription -- this issue poses a\nbottleneck for researchers seeking to apply NLP toolkits to study ancient\nlogographic languages: most of the relevant data are images of writing.\n  This paper investigates whether direct processing of visual representations\nof language offers a potential solution. We introduce LogogramNLP, the first\nbenchmark enabling NLP analysis of ancient logographic languages, featuring\nboth transcribed and visual datasets for four writing systems along with\nannotations for tasks like classification, translation, and parsing. Our\nexperiments compare systems that employ recent visual and text encoding\nstrategies as backbones. The results demonstrate that visual representations\noutperform textual representations for some investigated tasks, suggesting that\nvisual processing pipelines may unlock a large amount of cultural heritage data\nof logographic languages for NLP-based analyses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04628v1",
    "published_date": "2024-08-08 17:58:06 UTC",
    "updated_date": "2024-08-08 17:58:06 UTC"
  },
  {
    "arxiv_id": "2408.04619v1",
    "title": "Transformer Explainer: Interactive Learning of Text-Generative Models",
    "authors": [
      "Aeree Cho",
      "Grace C. Kim",
      "Alexander Karpekov",
      "Alec Helbling",
      "Zijie J. Wang",
      "Seongmin Lee",
      "Benjamin Hoover",
      "Duen Horng Chau"
    ],
    "abstract": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "To be presented at IEEE VIS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04619v1",
    "published_date": "2024-08-08 17:49:07 UTC",
    "updated_date": "2024-08-08 17:49:07 UTC"
  },
  {
    "arxiv_id": "2408.04614v2",
    "title": "Better Alignment with Instruction Back-and-Forth Translation",
    "authors": [
      "Thao Nguyen",
      "Jeffrey Li",
      "Sewoong Oh",
      "Ludwig Schmidt",
      "Jason Weston",
      "Luke Zettlemoyer",
      "Xian Li"
    ],
    "abstract": "We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04614v2",
    "published_date": "2024-08-08 17:42:32 UTC",
    "updated_date": "2024-08-13 18:00:57 UTC"
  },
  {
    "arxiv_id": "2408.04595v1",
    "title": "Inference with the Upper Confidence Bound Algorithm",
    "authors": [
      "Koulik Khamaru",
      "Cun-Hui Zhang"
    ],
    "abstract": "In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "17 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2408.04595v1",
    "published_date": "2024-08-08 17:11:36 UTC",
    "updated_date": "2024-08-08 17:11:36 UTC"
  },
  {
    "arxiv_id": "2408.04594v3",
    "title": "Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models",
    "authors": [
      "Qirui Jiao",
      "Daoyuan Chen",
      "Yilun Huang",
      "Bolin Ding",
      "Yaliang Li",
      "Ying Shen"
    ],
    "abstract": "High-performance Multimodal Large Language Models (MLLMs) are heavily\ndependent on data quality. To advance fine-grained image recognition within\nMLLMs, we introduce a novel data synthesis method inspired by contrastive\nlearning and image difference captioning. Our key idea involves challenging the\nmodel to discern both matching and distinct elements by scrutinizing object\ndifferences in detailed regions across similar images. We begin by generating\npairs of similar images that emphasize object variations. Following this, we\nemploy a Difference Area Generator to pinpoint object differences, and\nsubsequently, a Difference Captions Generator to articulate these differences.\nThis process results in a high-quality dataset of \"object replacement\" samples,\ntermed Img-Diff, which can be scaled as needed due to its automated nature. We\nleverage this generated dataset to fine-tune state-of-the-art (SOTA) MLLMs,\nsuch as InternVL2, achieving substantial improvements across various image\ndifference and Visual Question Answering tasks. Notably, the trained models\nsignificantly outperform existing SOTA models like GPT-4V and Gemini on the\nMMVP benchmark. Additionally, we conduct comprehensive evaluations to validate\nthe dataset's diversity, quality, and robustness, offering several insights\ninto the synthesis of such contrastive datasets. We release our codes and\ndataset to encourage further research on multimodal data synthesis and MLLMs'\nfundamental capabilities for image understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 10 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.04594v3",
    "published_date": "2024-08-08 17:10:16 UTC",
    "updated_date": "2024-12-19 11:04:20 UTC"
  },
  {
    "arxiv_id": "2408.04591v2",
    "title": "HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts",
    "authors": [
      "Hongjun Wang",
      "Sagar Vaze",
      "Kai Han"
    ],
    "abstract": "Generalized Category Discovery (GCD) is a challenging task in which, given a\npartially labelled dataset, models must categorize all unlabelled instances,\nregardless of whether they come from labelled categories or from new ones. In\nthis paper, we challenge a remaining assumption in this task: that all images\nshare the same domain. Specifically, we introduce a new task and method to\nhandle GCD when the unlabelled data also contains images from different domains\nto the labelled set. Our proposed `HiLo' networks extract High-level semantic\nand Low-level domain features, before minimizing the mutual information between\nthe representations. Our intuition is that the clusterings based on domain\ninformation and semantic information should be independent. We further extend\nour method with a specialized domain augmentation tailored for the GCD task, as\nwell as a curriculum learning approach. Finally, we construct a benchmark from\ncorrupted fine-grained datasets as well as a large-scale evaluation on\nDomainNet with real-world domain shifts, reimplementing a number of GCD\nbaselines in this setting. We demonstrate that HiLo outperforms SoTA category\ndiscovery models by a large margin on all evaluations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "v2: Accepted as a conference paper at ICLR 2025; Project page:\n  https://github.com/Visual-AI/hilo/",
    "pdf_url": "http://arxiv.org/pdf/2408.04591v2",
    "published_date": "2024-08-08 17:04:06 UTC",
    "updated_date": "2025-03-03 12:35:33 UTC"
  },
  {
    "arxiv_id": "2408.04586v1",
    "title": "Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond",
    "authors": [
      "Ravi Ramamoorthi"
    ],
    "abstract": "Capturing and rendering novel views of complex real-world scenes is a\nlong-standing problem in computer graphics and vision, with applications in\naugmented and virtual reality, immersive experiences and 3D photography. The\nadvent of deep learning has enabled revolutionary advances in this area,\nclassically known as image-based rendering. However, previous approaches\nrequire intractably dense view sampling or provide little or no guidance for\nhow users should sample views of a scene to reliably render high-quality novel\nviews. Local light field fusion proposes an algorithm for practical view\nsynthesis from an irregular grid of sampled views that first expands each\nsampled view into a local light field via a multiplane image scene\nrepresentation, then renders novel views by blending adjacent local light\nfields. Crucially, we extend traditional plenoptic sampling theory to derive a\nbound that specifies precisely how densely users should sample views of a given\nscene when using our algorithm. We achieve the perceptual quality of Nyquist\nrate view sampling while using up to 4000x fewer views. Subsequent developments\nhave led to new scene representations for deep learning with view synthesis,\nnotably neural radiance fields, but the problem of sparse view synthesis from a\nsmall number of images has only grown in importance. We reprise some of the\nrecent results on sparse and even single image view synthesis, while posing the\nquestion of whether prescriptive sampling guidelines are feasible for the new\ngeneration of image-based rendering algorithms.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "Article written for Frontiers of Science Award, International\n  Congress on Basic Science, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04586v1",
    "published_date": "2024-08-08 16:56:03 UTC",
    "updated_date": "2024-08-08 16:56:03 UTC"
  },
  {
    "arxiv_id": "2408.04583v1",
    "title": "Unveiling the Power of Sparse Neural Networks for Feature Selection",
    "authors": [
      "Zahra Atashgahi",
      "Tennison Liu",
      "Mykola Pechenizkiy",
      "Raymond Veldhuis",
      "Decebal Constantin Mocanu",
      "Mihaela van der Schaar"
    ],
    "abstract": "Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient\nfeature selection. Leveraging the dynamic sparse training (DST) algorithms\nwithin SNNs has demonstrated promising feature selection capabilities while\ndrastically reducing computational overheads. Despite these advancements,\nseveral critical aspects remain insufficiently explored for feature selection.\nQuestions persist regarding the choice of the DST algorithm for network\ntraining, the choice of metric for ranking features/neurons, and the\ncomparative performance of these methods across diverse datasets when compared\nto dense networks. This paper addresses these gaps by presenting a\ncomprehensive systematic analysis of feature selection with sparse neural\nnetworks. Moreover, we introduce a novel metric considering sparse neural\nnetwork characteristics, which is designed to quantify feature importance\nwithin the context of SNNs. Our findings show that feature selection with SNNs\ntrained with DST algorithms can achieve, on average, more than $50\\%$ memory\nand $55\\%$ FLOPs reduction compared to the dense networks, while outperforming\nthem in terms of the quality of the selected features. Our code and the\nsupplementary material are available on GitHub\n(\\url{https://github.com/zahraatashgahi/Neuron-Attribution}).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04583v1",
    "published_date": "2024-08-08 16:48:33 UTC",
    "updated_date": "2024-08-08 16:48:33 UTC"
  },
  {
    "arxiv_id": "2408.12616v2",
    "title": "Semantic Communication based on Large Language Model for Underwater Image Transmission",
    "authors": [
      "Weilong Chen",
      "Wenxuan Xu",
      "Haoran Chen",
      "Xinran Zhang",
      "Zhijin Qin",
      "Yanru Zhang",
      "Zhu Han"
    ],
    "abstract": "Underwater communication is essential for environmental monitoring, marine\nbiology research, and underwater exploration. Traditional underwater\ncommunication faces limitations like low bandwidth, high latency, and\nsusceptibility to noise, while semantic communication (SC) offers a promising\nsolution by focusing on the exchange of semantics rather than symbols or bits.\nHowever, SC encounters challenges in underwater environments, including\nsemantic information mismatch and difficulties in accurately identifying and\ntransmitting critical information that aligns with the diverse requirements of\nunderwater applications. To address these challenges, we propose a novel\nSemantic Communication (SC) framework based on Large Language Models (LLMs).\nOur framework leverages visual LLMs to perform semantic compression and\nprioritization of underwater image data according to the query from users. By\nidentifying and encoding key semantic elements within the images, the system\nselectively transmits high-priority information while applying higher\ncompression rates to less critical regions. On the receiver side, an LLM-based\nrecovery mechanism, along with Global Vision ControlNet and Key Region\nControlNet networks, aids in reconstructing the images, thereby enhancing\ncommunication efficiency and robustness. Our framework reduces the overall data\nsize to 0.8\\% of the original. Experimental results demonstrate that our method\nsignificantly outperforms existing approaches, ensuring high-quality,\nsemantically accurate image reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12616v2",
    "published_date": "2024-08-08 16:46:14 UTC",
    "updated_date": "2024-08-26 03:47:06 UTC"
  },
  {
    "arxiv_id": "2408.04575v2",
    "title": "SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals",
    "authors": [
      "Haoran Zheng",
      "Utku Pamuksuz"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in enhancing\nthe transparency and accountability of AI models, particularly in natural\nlanguage processing (NLP) tasks. However, popular XAI methods such as LIME and\nSHAP have been found to be unstable and potentially misleading, underscoring\nthe need for a standardized evaluation approach. This paper introduces SCENE\n(Soft Counterfactual Evaluation for Natural language Explainability), a novel\nevaluation method that leverages large language models (LLMs) to generate Soft\nCounterfactual explanations in a zero-shot manner. By focusing on token-based\nsubstitutions, SCENE creates contextually appropriate and semantically\nmeaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts\nValiditysoft and Csoft metrics to assess the effectiveness of model-agnostic\nXAI methods in text classification tasks. Applied to CNN, RNN, and Transformer\narchitectures, SCENE provides valuable insights into the strengths and\nlimitations of various XAI techniques.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04575v2",
    "published_date": "2024-08-08 16:36:24 UTC",
    "updated_date": "2024-08-16 06:01:15 UTC"
  },
  {
    "arxiv_id": "2408.04568v1",
    "title": "Learning Fine-Grained Grounded Citations for Attributed Large Language Models",
    "authors": [
      "Lei Huang",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Yuxuan Gu",
      "Weihong Zhong",
      "Xiachong Feng",
      "Weijiang Yu",
      "Weihua Peng",
      "Duyu Tang",
      "Dandan Tu",
      "Bing Qin"
    ],
    "abstract": "Despite the impressive performance on information-seeking tasks, large\nlanguage models (LLMs) still struggle with hallucinations. Attributed LLMs,\nwhich augment generated text with in-line citations, have shown potential in\nmitigating hallucinations and improving verifiability. However, current\napproaches suffer from suboptimal citation quality due to their reliance on\nin-context learning. Furthermore, the practice of citing only coarse document\nidentifiers makes it challenging for users to perform fine-grained\nverification. In this work, we introduce FRONT, a training framework designed\nto teach LLMs to generate Fine-Grained Grounded Citations. By grounding model\noutputs in fine-grained supporting quotes, these quotes guide the generation of\ngrounded and consistent responses, not only improving citation quality but also\nfacilitating fine-grained verification. Experiments on the ALCE benchmark\ndemonstrate the efficacy of FRONT in generating superior grounded responses and\nhighly supportive citations. With LLaMA-2-7B, the framework significantly\noutperforms all the baselines, achieving an average of 14.21% improvement in\ncitation quality across all datasets, even surpassing ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2408.04568v1",
    "published_date": "2024-08-08 16:28:22 UTC",
    "updated_date": "2024-08-08 16:28:22 UTC"
  },
  {
    "arxiv_id": "2408.04693v1",
    "title": "Understanding the Performance and Estimating the Cost of LLM Fine-Tuning",
    "authors": [
      "Yuchen Xia",
      "Jiho Kim",
      "Yuhan Chen",
      "Haojie Ye",
      "Souvik Kundu",
      "Cong Hao",
      "Nishil Talati"
    ],
    "abstract": "Due to the cost-prohibitive nature of training Large Language Models (LLMs),\nfine-tuning has emerged as an attractive alternative for specializing LLMs for\nspecific tasks using limited compute resources in a cost-effective manner. In\nthis paper, we characterize sparse Mixture of Experts (MoE) based LLM\nfine-tuning to understand their accuracy and runtime performance on a single\nGPU. Our evaluation provides unique insights into the training efficacy of\nsparse and dense versions of MoE models, as well as their runtime\ncharacteristics, including maximum batch size, execution time breakdown,\nend-to-end throughput, GPU hardware utilization, and load distribution. Our\nstudy identifies the optimization of the MoE layer as crucial for further\nimproving the performance of LLM fine-tuning. Using our profiling results, we\nalso develop and validate an analytical model to estimate the cost of LLM\nfine-tuning on the cloud. This model, based on parameters of the model and GPU\narchitecture, estimates LLM throughput and the cost of training, aiding\npractitioners in industry and academia to budget the cost of fine-tuning a\nspecific model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2408.04693v1",
    "published_date": "2024-08-08 16:26:07 UTC",
    "updated_date": "2024-08-08 16:26:07 UTC"
  },
  {
    "arxiv_id": "2408.04535v2",
    "title": "Synchronous Multi-modal Semantic Communication System with Packet-level Coding",
    "authors": [
      "Yun Tian",
      "Jingkai Ying",
      "Zhijin Qin",
      "Ye Jin",
      "Xiaoming Tao"
    ],
    "abstract": "Although the semantic communication with joint semantic-channel coding design\nhas shown promising performance in transmitting data of different modalities\nover physical layer channels, the synchronization and packet-level forward\nerror correction of multimodal semantics have not been well studied. Due to the\nindependent design of semantic encoders, synchronizing multimodal features in\nboth the semantic and time domains is a challenging problem. In this paper, we\ntake the facial video and speech transmission as an example and propose a\nSynchronous Multimodal Semantic Communication System (SyncSC) with Packet-Level\nCoding. To achieve semantic and time synchronization, 3D Morphable Mode (3DMM)\ncoefficients and text are transmitted as semantics, and we propose a semantic\ncodec that achieves similar quality of reconstruction and synchronization with\nlower bandwidth, compared to traditional methods. To protect semantic packets\nunder the erasure channel, we propose a packet-Level Forward Error Correction\n(FEC) method, called PacSC, that maintains a certain visual quality performance\neven at high packet loss rates. Particularly, for text packets, a text packet\nloss concealment module, called TextPC, based on Bidirectional Encoder\nRepresentations from Transformers (BERT) is proposed, which significantly\nimproves the performance of traditional FEC methods. The simulation results\nshow that our proposed SyncSC reduce transmission overhead and achieve\nhigh-quality synchronous transmission of video and speech over the packet loss\nnetwork.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.04535v2",
    "published_date": "2024-08-08 15:42:00 UTC",
    "updated_date": "2024-08-11 02:37:42 UTC"
  },
  {
    "arxiv_id": "2408.04692v1",
    "title": "Exploring Scalability in Large-Scale Time Series in DeepVATS framework",
    "authors": [
      "Inmaculada Santamaria-Valenzuela",
      "Victor Rodriguez-Fernandez",
      "David Camacho"
    ],
    "abstract": "Visual analytics is essential for studying large time series due to its\nability to reveal trends, anomalies, and insights. DeepVATS is a tool that\nmerges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of\nlarge time series data (TS). It has three interconnected modules. The Deep\nLearning module, developed in R, manages the load of datasets and Deep Learning\nmodels from and to the Storage module. This module also supports models\ntraining and the acquisition of the embeddings from the latent space of the\ntrained model. The Storage module operates using the Weights and Biases system.\nSubsequently, these embeddings can be analyzed in the Visual Analytics module.\nThis module, based on an R Shiny application, allows the adjustment of the\nparameters related to the projection and clustering of the embeddings space.\nOnce these parameters are set, interactive plots representing both the\nembeddings, and the time series are shown. This paper introduces the tool and\nexamines its scalability through log analytics. The execution time evolution is\nexamined while the length of the time series is varied. This is achieved by\nresampling a large data series into smaller subsets and logging the main\nexecution and rendering times for later analysis of scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Admitted pending publication in Lecture Notes in Network and Systems\n  (LNNS) series (Springer). Code available at\n  https://github.com/vrodriguezf/deepvats",
    "pdf_url": "http://arxiv.org/pdf/2408.04692v1",
    "published_date": "2024-08-08 15:30:48 UTC",
    "updated_date": "2024-08-08 15:30:48 UTC"
  },
  {
    "arxiv_id": "2408.04528v1",
    "title": "Reasoning about Study Regulations in Answer Set Programming",
    "authors": [
      "Susana Hahn",
      "Cedric Martens",
      "Amade Nemes",
      "Henry Otunuya",
      "Javier Romero",
      "Torsten Schaub",
      "Sebastian Schellhorn"
    ],
    "abstract": "We are interested in automating reasoning with and about study regulations,\ncatering to various stakeholders, ranging from administrators, over faculty, to\nstudents at different stages. Our work builds on an extensive analysis of\nvarious study programs at the University of Potsdam. The conceptualization of\nthe underlying principles provides us with a formal account of study\nregulations. In particular, the formalization reveals the properties of\nadmissible study plans. With these at end, we propose an encoding of study\nregulations in Answer Set Programming that produces corresponding study plans.\nFinally, we show how this approach can be extended to a generic user interface\nfor exploring study plans.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in Theory and Practise of Logic Programming",
    "pdf_url": "http://arxiv.org/pdf/2408.04528v1",
    "published_date": "2024-08-08 15:27:22 UTC",
    "updated_date": "2024-08-08 15:27:22 UTC"
  },
  {
    "arxiv_id": "2408.04491v1",
    "title": "Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs",
    "authors": [
      "Vandan Gorade",
      "Onkar Susladkar",
      "Gorkem Durak",
      "Elif Keles",
      "Ertugrul Aktas",
      "Timurhan Cebeci",
      "Alpay Medetalibeyoglu",
      "Daniela Ladner",
      "Debesh Jha",
      "Ulas Bagci"
    ],
    "abstract": "Liver cirrhosis, a leading cause of global mortality, requires precise\nsegmentation of ROIs for effective disease monitoring and treatment planning.\nExisting segmentation models often fail to capture complex feature interactions\nand generalize across diverse datasets. To address these limitations, we\npropose a novel synergistic theory that leverages complementary latent spaces\nfor enhanced feature interaction modeling. Our proposed architecture,\nnnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes\nand features auto-configured training. This approach captures both fine-grained\nand coarse features, enabling effective modeling of intricate feature\ninteractions. We empirically validated nnSynergyNet3D on a private dataset of\n628 high-resolution T1 abdominal MRI scans from 339 patients. Our model\noutperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot\ntesting on healthy liver CT scans from the public LiTS dataset demonstrated\nsuperior cross-modal generalization capabilities. These results highlight the\npotential of synergistic latent space models to improve segmentation accuracy\nand robustness, thereby enhancing clinical workflows by ensuring consistency\nacross CT and MRI modalities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04491v1",
    "published_date": "2024-08-08 14:41:32 UTC",
    "updated_date": "2024-08-08 14:41:32 UTC"
  },
  {
    "arxiv_id": "2408.05249v1",
    "title": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review",
    "authors": [
      "Anshu Ankolekar",
      "Sebastian Boie",
      "Maryam Abdollahyan",
      "Emanuela Gadaleta",
      "Seyed Alireza Hasheminasab",
      "Guang Yang",
      "Charles Beauville",
      "Nikolaos Dikaios",
      "George Anthony Kastis",
      "Michael Bussmann",
      "Sara Khalid",
      "Hagen Kruger",
      "Philippe Lambin",
      "Giorgos Papanastasiou"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising solution to address the\nlimitations of centralised machine learning (ML) in oncology, particularly in\novercoming privacy concerns and harnessing the power of diverse, multi-center\ndata. This systematic review synthesises current knowledge on the\nstate-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.\nDistinct from previous surveys, our comprehensive review critically evaluates\nthe real-world implementation and impact of FL on cancer care, demonstrating\nits effectiveness in enhancing ML generalisability, performance and data\nprivacy in clinical settings and data. We evaluated state-of-the-art advances\nin FL, demonstrating its growing adoption amid tightening data privacy\nregulations. FL outperformed centralised ML in 15 out of the 25 studies\nreviewed, spanning diverse ML models and clinical applications, and\nfacilitating integration of multi-modal information for precision medicine.\nDespite the current challenges identified in reproducibility, standardisation\nand methodology across studies, the demonstrable benefits of FL in harnessing\nreal-world data and addressing clinical needs highlight its significant\npotential for advancing cancer research. We propose that future research should\nfocus on addressing these limitations and investigating further advanced FL\nmethods, to fully harness data diversity and realise the transformative power\nof cutting-edge FL in cancer care.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "5 Figures, 3 Tables, 1 Supplementary Table",
    "pdf_url": "http://arxiv.org/pdf/2408.05249v1",
    "published_date": "2024-08-08 14:36:16 UTC",
    "updated_date": "2024-08-08 14:36:16 UTC"
  },
  {
    "arxiv_id": "2408.05248v1",
    "title": "The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era",
    "authors": [
      "Abraham Itzhak Weinberg"
    ],
    "abstract": "In recent years, the threat facing airports from growing and increasingly\nsophisticated cyberattacks has become evident. Airports are considered a\nstrategic national asset, so protecting them from attacks, specifically\ncyberattacks, is a crucial mission. One way to increase airports' security is\nby using Digital Twins (DTs). This paper shows and demonstrates how DTs can\nenhance the security mission. The integration of DTs with Generative AI (GenAI)\nalgorithms can lead to synergy and new frontiers in fighting cyberattacks. The\npaper exemplifies ways to model cyberattack scenarios using simulations and\ngenerate synthetic data for testing defenses. It also discusses how DTs can be\nused as a crucial tool for vulnerability assessment by identifying weaknesses,\nprioritizing, and accelerating remediations in case of cyberattacks. Moreover,\nthe paper demonstrates approaches for anomaly detection and threat hunting\nusing Machine Learning (ML) and GenAI algorithms. Additionally, the paper\nprovides impact prediction and recovery coordination methods that can be used\nby DT operators and stakeholders. It also introduces ways to harness the human\nfactor by integrating training and simulation algorithms with Explainable AI\n(XAI) into the DT platforms. Lastly, the paper offers future applications and\ntechnologies that can be utilized in DT environments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05248v1",
    "published_date": "2024-08-08 14:35:39 UTC",
    "updated_date": "2024-08-08 14:35:39 UTC"
  },
  {
    "arxiv_id": "2408.04484v1",
    "title": "Statistical Framework for Clustering MU-MIMO Wireless via Second Order Statistics",
    "authors": [
      "Roberto Pereira",
      "Xavier Mestre"
    ],
    "abstract": "This work explores the clustering of wireless users by examining the\ndistances between their channel covariance matrices, which reside on the\nRiemannian manifold of positive definite matrices. Specifically, we consider an\nestimator of the Log-Euclidean distance between multiple sample covariance\nmatrices (SCMs) consistent when the number of samples and the observation size\ngrow unbounded at the same rate. Within the context of multi-user MIMO\n(MU-MIMO) wireless communication systems, we develop a statistical framework\nthat allows to accurate predictions of the clustering algorithm's performance\nunder realistic conditions. Specifically, we present a central limit theorem\nthat establishes the asymptotic Gaussianity of the consistent estimator of the\nlog-Euclidean distance computed over two sample covariance matrices.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04484v1",
    "published_date": "2024-08-08 14:23:06 UTC",
    "updated_date": "2024-08-08 14:23:06 UTC"
  },
  {
    "arxiv_id": "2408.04482v1",
    "title": "SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios",
    "authors": [
      "Sriram Mandalika",
      "Athira Nambiar"
    ],
    "abstract": "Most of the sophisticated AI models utilize huge amounts of annotated data\nand heavy training to achieve high-end performance. However, there are certain\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\ni.e., inefficient use of unlabeled data, lack of incorporation of human\nexpertise, and lack of interpretation of the results. To mitigate these\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\nand (iii) augment the model decisions in an interpretable way. In particular,\nwe investigate the application of the SegXAL model for semantic segmentation in\ndriving scene scenarios. The SegXAL model proposes the image regions that\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\n(EBU) module to get an Explainable Error Mask, which enables the machine\nteachers/human experts to provide intuitive reasoning behind the results and to\nsolicit feedback to the AI system via an active learning strategy. Such a\nmechanism bridges the semantic gap between man and machine through\ncollaborative intelligence, where humans and AI actively enhance each other's\ncomplementary strengths. A novel high-confidence sample selection technique\nbased on the DICE similarity coefficient is also presented within the SegXAL\nframework. Extensive quantitative and qualitative analyses are carried out in\nthe benchmarking Cityscape dataset. Results show the outperformance of our\nproposed SegXAL against other state-of-the-art models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 7 figures. To appear in the proceedings of the 27th\n  International Conference on Pattern Recognition (ICPR), 01-05 December, 2024,\n  Kolkata, India",
    "pdf_url": "http://arxiv.org/pdf/2408.04482v1",
    "published_date": "2024-08-08 14:19:11 UTC",
    "updated_date": "2024-08-08 14:19:11 UTC"
  },
  {
    "arxiv_id": "2408.04449v5",
    "title": "EARBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents",
    "authors": [
      "Zihao Zhu",
      "Bingzhe Wu",
      "Zhengyou Zhang",
      "Lei Han",
      "Qingshan Liu",
      "Baoyuan Wu"
    ],
    "abstract": "Embodied artificial intelligence (EAI) integrates advanced AI models into\nphysical entities for real-world interaction. The emergence of foundation\nmodels as the \"brain\" of EAI agents for high-level task planning has shown\npromising results. However, the deployment of these agents in physical\nenvironments presents significant safety challenges. For instance, a\nhousekeeping robot lacking sufficient risk awareness might place a metal\ncontainer in a microwave, potentially causing a fire. To address these critical\nsafety concerns, comprehensive pre-deployment risk assessments are imperative.\nThis study introduces EARBench, a novel framework for automated physical risk\nassessment in EAI scenarios. EAIRiskBench employs a multi-agent cooperative\nsystem that leverages various foundation models to generate safety guidelines,\ncreate risk-prone scenarios, make task planning, and evaluate safety\nsystematically. Utilizing this framework, we construct EARDataset, comprising\ndiverse test cases across various domains, encompassing both textual and visual\nscenarios. Our comprehensive evaluation of state-of-the-art foundation models\nreveals alarming results: all models exhibit high task risk rates (TRR), with\nan average of 95.75% across all evaluated models. To address these challenges,\nwe further propose two prompting-based risk mitigation strategies. While these\nstrategies demonstrate some efficacy in reducing TRR, the improvements are\nlimited, still indicating substantial safety concerns. This study provides the\nfirst large-scale assessment of physical risk awareness in EAI agents. Our\nfindings underscore the critical need for enhanced safety measures in EAI\nsystems and provide valuable insights for future research directions in\ndeveloping safer embodied artificial intelligence system. Data and code are\navailable at https://github.com/zihao-ai/EARBench.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04449v5",
    "published_date": "2024-08-08 13:19:37 UTC",
    "updated_date": "2024-11-28 12:28:02 UTC"
  },
  {
    "arxiv_id": "2408.12614v1",
    "title": "Image-Feature Weak-to-Strong Consistency: An Enhanced Paradigm for Semi-Supervised Learning",
    "authors": [
      "Zhiyu Wu",
      "Jinshi Cui"
    ],
    "abstract": "Image-level weak-to-strong consistency serves as the predominant paradigm in\nsemi-supervised learning~(SSL) due to its simplicity and impressive\nperformance. Nonetheless, this approach confines all perturbations to the image\nlevel and suffers from the excessive presence of naive samples, thus\nnecessitating further improvement. In this paper, we introduce feature-level\nperturbation with varying intensities and forms to expand the augmentation\nspace, establishing the image-feature weak-to-strong consistency paradigm.\nFurthermore, our paradigm develops a triple-branch structure, which facilitates\ninteractions between both types of perturbations within one branch to boost\ntheir synergy. Additionally, we present a confidence-based identification\nstrategy to distinguish between naive and challenging samples, thus introducing\nadditional challenges exclusively for naive samples. Notably, our paradigm can\nseamlessly integrate with existing SSL methods. We apply the proposed paradigm\nto several representative algorithms and conduct experiments on multiple\nbenchmarks, including both balanced and imbalanced distributions for labeled\nsamples. The results demonstrate a significant enhancement in the performance\nof existing SSL algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12614v1",
    "published_date": "2024-08-08 13:19:25 UTC",
    "updated_date": "2024-08-08 13:19:25 UTC"
  },
  {
    "arxiv_id": "2408.04442v1",
    "title": "FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data",
    "authors": [
      "Ahmed Anwar",
      "Brian Moser",
      "Dayananda Herurkar",
      "Federico Raue",
      "Vinit Hegiste",
      "Tatjana Legler",
      "Andreas Dengel"
    ],
    "abstract": "The emergence of federated learning (FL) presents a promising approach to\nleverage decentralized data while preserving privacy. Furthermore, the\ncombination of FL and anomaly detection is particularly compelling because it\nallows for detecting rare and critical anomalies (usually also rare in locally\ngathered data) in sensitive data from multiple sources, such as cybersecurity\nand healthcare. However, benchmarking the performance of anomaly detection\nmethods in FL environments remains an underexplored area. This paper introduces\nFedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection\nalgorithms within the context of FL. We systematically analyze and compare the\nperformance of recent deep learning anomaly detection models under federated\nsettings, which were typically assessed solely in centralized settings.\nFedAD-Bench encompasses diverse datasets and metrics to provide a holistic\nevaluation. Through extensive experiments, we identify key challenges such as\nmodel aggregation inefficiencies and metric unreliability. We present insights\ninto FL's regularization effects, revealing scenarios in which it outperforms\ncentralized approaches due to its inherent ability to mitigate overfitting. Our\nwork aims to establish a standardized benchmark to guide future research and\ndevelopment in federated anomaly detection, promoting reproducibility and fair\ncomparison across studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2408.04442v1",
    "published_date": "2024-08-08 13:14:19 UTC",
    "updated_date": "2024-08-08 13:14:19 UTC"
  },
  {
    "arxiv_id": "2408.08892v3",
    "title": "Leveraging Large Language Models for Enhanced Process Model Comprehension",
    "authors": [
      "Humam Kourani",
      "Alessandro Berti",
      "Jasmin Hennrich",
      "Wolfgang Kratsch",
      "Robin Weidlich",
      "Chiao-Yun Li",
      "Ahmad Arslan",
      "Daniel Schuster",
      "Wil M. P. van der Aalst"
    ],
    "abstract": "In Business Process Management (BPM), effectively comprehending process\nmodels is crucial yet poses significant challenges, particularly as\norganizations scale and processes become more complex. This paper introduces a\nnovel framework utilizing the advanced capabilities of Large Language Models\n(LLMs) to enhance the interpretability of complex process models. We present\ndifferent methods for abstracting business process models into a format\naccessible to LLMs, and we implement advanced prompting strategies specifically\ndesigned to optimize LLM performance within our framework. Additionally, we\npresent a tool, AIPA, that implements our proposed framework and allows for\nconversational process querying. We evaluate our framework and tool by i) an\nautomatic evaluation comparing different LLMs, model abstractions, and\nprompting strategies and ii) a user study designed to assess AIPA's\neffectiveness comprehensively. Results demonstrate our framework's ability to\nimprove the accessibility and interpretability of process models, pioneering\nnew pathways for integrating AI technologies into the BPM field.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08892v3",
    "published_date": "2024-08-08 13:12:46 UTC",
    "updated_date": "2024-09-20 11:39:56 UTC"
  },
  {
    "arxiv_id": "2408.04691v4",
    "title": "Synthetic SQL Column Descriptions and Their Impact on Text-to-SQL Performance",
    "authors": [
      "Niklas Wretblad",
      "Oskar Holmström",
      "Erik Larsson",
      "Axel Wiksäter",
      "Oscar Söderlund",
      "Hjalmar Öhman",
      "Ture Pontén",
      "Martin Forsberg",
      "Martin Sörme",
      "Fredrik Heintz"
    ],
    "abstract": "Relational databases often suffer from uninformative descriptors of table\ncontents, such as ambiguous columns and hard-to-interpret values, impacting\nboth human users and text-to-SQL models. In this paper, we explore the use of\nlarge language models (LLMs) to automatically generate detailed natural\nlanguage descriptions for SQL database columns, aiming to improve text-to-SQL\nperformance and automate metadata creation. We create a dataset of gold column\ndescriptions based on the BIRD-Bench benchmark, manually refining its column\ndescriptions and creating a taxonomy for categorizing column difficulty. We\nthen evaluate several different LLMs in generating column descriptions across\nthe columns and different difficulties in the dataset, finding that models\nunsurprisingly struggle with columns that exhibit inherent ambiguity,\nhighlighting the need for manual expert input. We also find that incorporating\nsuch generated column descriptions consistently enhances text-to-SQL model\nperformance, particularly for larger models like GPT-4o, Qwen2 72B and Mixtral\n22Bx8. Notably, Qwen2-generated descriptions, containing by annotators deemed\nsuperfluous information, outperform manually curated gold descriptions,\nsuggesting that models benefit from more detailed metadata than humans expect.\nFuture work will investigate the specific features of these high-performing\ndescriptions and explore other types of metadata, such as numerical reasoning\nand synonyms, to further improve text-to-SQL systems. The dataset, annotations\nand code will all be made available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04691v4",
    "published_date": "2024-08-08 13:10:51 UTC",
    "updated_date": "2024-11-05 10:32:36 UTC"
  },
  {
    "arxiv_id": "2408.12613v1",
    "title": "Deceptive uses of Artificial Intelligence in elections strengthen support for AI ban",
    "authors": [
      "Andreas Jungherr",
      "Adrian Rauchfleisch",
      "Alexander Wuttke"
    ],
    "abstract": "All over the world, political parties, politicians, and campaigns explore how\nArtificial Intelligence (AI) can help them win elections. However, the effects\nof these activities are unknown. We propose a framework for assessing AI's\nimpact on elections by considering its application in various campaigning\ntasks. The electoral uses of AI vary widely, carrying different levels of\nconcern and need for regulatory oversight. To account for this diversity, we\ngroup AI-enabled campaigning uses into three categories -- campaign operations,\nvoter outreach, and deception. Using this framework, we provide the first\nsystematic evidence from a preregistered representative survey and two\npreregistered experiments (n=7,635) on how Americans think about AI in\nelections and the effects of specific campaigning choices. We provide three\nsignificant findings. 1) the public distinguishes between different AI uses in\nelections, seeing AI uses predominantly negative but objecting most strongly to\ndeceptive uses; 2) deceptive AI practices can have adverse effects on relevant\nattitudes and strengthen public support for stopping AI development; 3)\nAlthough deceptive electoral uses of AI are intensely disliked, they do not\nresult in substantial favorability penalties for the parties involved. There is\na misalignment of incentives for deceptive practices and their externalities.\nWe cannot count on public opinion to provide strong enough incentives for\nparties to forgo tactical advantages from AI-enabled deception. There is a need\nfor regulatory oversight and systematic outside monitoring of electoral uses of\nAI. Still, regulators should account for the diversity of AI uses and not\ncompletely disincentivize their electoral use.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2; K.4.2; J.4"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12613v1",
    "published_date": "2024-08-08 12:58:20 UTC",
    "updated_date": "2024-08-08 12:58:20 UTC"
  },
  {
    "arxiv_id": "2408.04430v3",
    "title": "The Struggles of LLMs in Cross-lingual Code Clone Detection",
    "authors": [
      "Micheline Bénédicte Moumoula",
      "Abdoul Kader Kabore",
      "Jacques Klein",
      "Tegawendé Bissyande"
    ],
    "abstract": "With the involvement of multiple programming languages in modern software\ndevelopment, cross-lingual code clone detection has gained traction within the\nsoftware engineering community. Numerous studies have explored this topic,\nproposing various promising approaches. Inspired by the significant advances in\nmachine learning in recent years, particularly Large Language Models (LLMs),\nwhich have demonstrated their ability to tackle various tasks, this paper\nrevisits cross-lingual code clone detection. We evaluate the performance of\nfive (05) LLMs and eight prompts (08) for the identification of cross-lingual\ncode clones. Additionally, we compare these results against two baseline\nmethods. Finally, we evaluate a pre-trained embedding model to assess the\neffectiveness of the generated representations for classifying clone and\nnon-clone pairs. The studies involving LLMs and Embedding models are evaluated\nusing two widely used cross-lingual datasets, XLCoST and CodeNet. Our results\nshow that LLMs can achieve high F1 scores, up to 0.99, for straightforward\nprogramming examples. However, they not only perform less well on programs\nassociated with complex programming challenges but also do not necessarily\nunderstand the meaning of \"code clones\" in a cross-lingual setting. We show\nthat embedding models used to represent code fragments from different\nprogramming languages in the same representation space enable the training of a\nbasic classifier that outperforms all LLMs by ~1 and ~20 percentage points on\nthe XLCoST and CodeNet datasets, respectively. This finding suggests that,\ndespite the apparent capabilities of LLMs, embeddings provided by embedding\nmodels offer suitable representations to achieve state-of-the-art performance\nin cross-lingual code clone detection.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at the ACM International Conference on the\n  Foundations of Software Engineering (FSE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.04430v3",
    "published_date": "2024-08-08 12:57:14 UTC",
    "updated_date": "2025-05-06 12:19:55 UTC"
  },
  {
    "arxiv_id": "2408.04414v1",
    "title": "Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning",
    "authors": [
      "Seong-Il Park",
      "Seung-Woo Choi",
      "Na-Hyun Kim",
      "Jay-Yoon Lee"
    ],
    "abstract": "Retrieval-Augmented Language Models (RALMs) have significantly improved\nperformance in open-domain question answering (QA) by leveraging external\nknowledge. However, RALMs still struggle with unanswerable queries, where the\nretrieved contexts do not contain the correct answer, and with conflicting\ninformation, where different sources provide contradictory answers due to\nimperfect retrieval. This study introduces an in-context learning-based\napproach to enhance the reasoning capabilities of RALMs, making them more\nrobust in imperfect retrieval scenarios. Our method incorporates Machine\nReading Comprehension (MRC) demonstrations, referred to as cases, to boost the\nmodel's capabilities to identify unanswerabilities and conflicts among the\nretrieved contexts. Experiments on two open-domain QA datasets show that our\napproach increases accuracy in identifying unanswerable and conflicting\nscenarios without requiring additional fine-tuning. This work demonstrates that\nin-context learning can effectively enhance the robustness of RALMs in\nopen-domain QA tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.04414v1",
    "published_date": "2024-08-08 12:42:43 UTC",
    "updated_date": "2024-08-08 12:42:43 UTC"
  },
  {
    "arxiv_id": "2408.04405v3",
    "title": "Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces",
    "authors": [
      "Luca Pernigo",
      "Rohan Sen",
      "Davide Baroli"
    ],
    "abstract": "Accurate energy demand forecasting is crucial for sustainable and resilient\nenergy development. To meet the Net Zero Representative Concentration Pathways\n(RCP) $4.5$ scenario in the DACH countries, increased renewable energy\nproduction, energy storage, and reduced commercial building consumption are\nneeded. This scenario's success depends on hydroelectric capacity and climatic\nfactors. Informed decisions require quantifying uncertainty in forecasts. This\nstudy explores a non-parametric method based on \\emph{reproducing kernel\nHilbert spaces (RKHS)}, known as kernel quantile regression, for energy\nprediction. Our experiments demonstrate its reliability and sharpness, and we\nbenchmark it against state-of-the-art methods in load and price forecasting for\nthe DACH region. We offer our implementation in conjunction with additional\nscripts to ensure the reproducibility of our research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "I.2; G.4"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, {Owner/Author | ACM} {2024}. This is the author's version\n  of the work. It is posted here for your personal use. Not for redistribution.\n  The definitive Version of Record will published in https://energy.acm.org/eir",
    "pdf_url": "http://arxiv.org/pdf/2408.04405v3",
    "published_date": "2024-08-08 12:14:17 UTC",
    "updated_date": "2024-09-16 14:30:14 UTC"
  },
  {
    "arxiv_id": "2408.04689v2",
    "title": "Design of a Quality Management System based on the EU Artificial Intelligence Act",
    "authors": [
      "Henryk Mustroph",
      "Stefanie Rinderle-Ma"
    ],
    "abstract": "The EU AI Act mandates that providers and deployers of high-risk AI systems\nestablish a quality management system (QMS). Among other criteria, a QMS shall\nhelp verify and document the AI system design and quality and monitor the\nproper implementation of all high-risk AI system requirements. Current research\nrarely explores practical solutions for implementing the EU AI Act. Instead, it\ntends to focus on theoretical concepts. As a result, more attention must be\npaid to tools that help humans actively check and document AI systems and\norchestrate the implementation of all high-risk AI system requirements.\nTherefore, this paper introduces a new design concept and prototype for a QMS\nas a microservice Software as a Service web application. It connects directly\nto the AI system for verification and documentation and enables the\norchestration and integration of various sub-services, which can be\nindividually designed, each tailored to specific high-risk AI system\nrequirements. The first version of the prototype connects to the\nPhi-3-mini-128k-instruct LLM as an example of an AI system and integrates a\nrisk management system and a data management system. The prototype is evaluated\nthrough a qualitative assessment of the implemented requirements, a GPU memory\nand performance analysis, and an evaluation with IT, AI, and legal experts.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04689v2",
    "published_date": "2024-08-08 12:14:02 UTC",
    "updated_date": "2024-11-12 13:37:04 UTC"
  },
  {
    "arxiv_id": "2408.04403v1",
    "title": "Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset",
    "authors": [
      "Kentaro Ozeki",
      "Risako Ando",
      "Takanobu Morishita",
      "Hirohiko Abe",
      "Koji Mineshima",
      "Mitsuhiro Okada"
    ],
    "abstract": "This paper explores the question of how accurately current large language\nmodels can perform logical reasoning in natural language, with an emphasis on\nwhether these models exhibit reasoning biases similar to humans. Specifically,\nour study focuses on syllogistic reasoning, a form of deductive reasoning\nextensively studied in cognitive science as a natural form of human reasoning.\nWe present a syllogism dataset called NeuBAROCO, which consists of syllogistic\nreasoning problems in English and Japanese. This dataset was originally\ndesigned for psychological experiments to assess human reasoning capabilities\nusing various forms of syllogisms. Our experiments with leading large language\nmodels indicate that these models exhibit reasoning biases similar to humans,\nalong with other error tendencies. Notably, there is significant room for\nimprovement in reasoning problems where the relationship between premises and\nhypotheses is neither entailment nor contradiction. We also present\nexperimental results and in-depth analysis using a new Chain-of-Thought\nprompting method, which asks LLMs to translate syllogisms into abstract logical\nexpressions and then explain their reasoning process. Our analysis using this\nmethod suggests that the primary limitations of LLMs lie in the reasoning\nprocess itself rather than the interpretation of syllogisms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in Findings of the Association for Computational\n  Linguistics: ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04403v1",
    "published_date": "2024-08-08 12:10:50 UTC",
    "updated_date": "2024-08-08 12:10:50 UTC"
  },
  {
    "arxiv_id": "2408.04400v1",
    "title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization",
    "authors": [
      "Xin Sun",
      "Liang Wang",
      "Qiang Liu",
      "Shu Wu",
      "Zilei Wang",
      "Liang Wang"
    ],
    "abstract": "This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04400v1",
    "published_date": "2024-08-08 12:08:55 UTC",
    "updated_date": "2024-08-08 12:08:55 UTC"
  },
  {
    "arxiv_id": "2408.04394v1",
    "title": "Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation",
    "authors": [
      "Nicy Scaria",
      "Suma Dharani Chenna",
      "Deepak Subramani"
    ],
    "abstract": "Developing questions that are pedagogically sound, relevant, and promote\nlearning is a challenging and time-consuming task for educators. Modern-day\nlarge language models (LLMs) generate high-quality content across multiple\ndomains, potentially helping educators to develop high-quality questions.\nAutomated educational question generation (AEQG) is important in scaling online\neducation catering to a diverse student population. Past attempts at AEQG have\nshown limited abilities to generate questions at higher cognitive levels. In\nthis study, we examine the ability of five state-of-the-art LLMs of different\nsizes to generate diverse and high-quality questions of different cognitive\nlevels, as defined by Bloom's taxonomy. We use advanced prompting techniques\nwith varying complexity for AEQG. We conducted expert and LLM-based evaluations\nto assess the linguistic and pedagogical relevance and quality of the\nquestions. Our findings suggest that LLms can generate relevant and\nhigh-quality educational questions of different cognitive levels when prompted\nwith adequate information, although there is a significant variance in the\nperformance of the five LLms considered. We also show that automated evaluation\nis not on par with human evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04394v1",
    "published_date": "2024-08-08 11:56:57 UTC",
    "updated_date": "2024-08-08 11:56:57 UTC"
  },
  {
    "arxiv_id": "2408.05247v1",
    "title": "Early-Exit meets Model-Distributed Inference at Edge Networks",
    "authors": [
      "Marco Colocrese",
      "Erdem Koyuncu",
      "Hulya Seferoglu"
    ],
    "abstract": "Distributed inference techniques can be broadly classified into\ndata-distributed and model-distributed schemes. In data-distributed inference\n(DDI), each worker carries the entire deep neural network (DNN) model but\nprocesses only a subset of the data. However, feeding the data to workers\nresults in high communication costs, especially when the data is large. An\nemerging paradigm is model-distributed inference (MDI), where each worker\ncarries only a subset of DNN layers. In MDI, a source device that has data\nprocesses a few layers of DNN and sends the output to a neighboring device,\ni.e., offloads the rest of the layers. This process ends when all layers are\nprocessed in a distributed manner. In this paper, we investigate the design and\ndevelopment of MDI with early-exit, which advocates that there is no need to\nprocess all the layers of a model for some data to reach the desired accuracy,\ni.e., we can exit the model without processing all the layers if target\naccuracy is reached. We design a framework MDI-Exit that adaptively determines\nearly-exit and offloading policies as well as data admission at the source.\nExperimental results on a real-life testbed of NVIDIA Nano edge devices show\nthat MDI-Exit processes more data when accuracy is fixed and results in higher\naccuracy for the fixed data rate.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05247v1",
    "published_date": "2024-08-08 11:53:32 UTC",
    "updated_date": "2024-08-08 11:53:32 UTC"
  },
  {
    "arxiv_id": "2408.04388v1",
    "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
    "authors": [
      "Haoxuan Li",
      "Zhengmao Yang",
      "Yunshan Ma",
      "Yi Bin",
      "Yang Yang",
      "Tat-Seng Chua"
    ],
    "abstract": "We study an emerging and intriguing problem of multimodal temporal event\nforecasting with large language models. Compared to using text or graph\nmodalities, the investigation of utilizing images for temporal event\nforecasting has not been fully explored, especially in the era of large\nlanguage models (LLMs). To bridge this gap, we are particularly interested in\ntwo key questions of: 1) why images will help in temporal event forecasting,\nand 2) how to integrate images into the LLM-based forecasting framework. To\nanswer these research questions, we propose to identify two essential functions\nthat images play in the scenario of temporal event forecasting, i.e.,\nhighlighting and complementary. Then, we develop a novel framework, named\nMM-Forecast. It employs an Image Function Identification module to recognize\nthese functions as verbal descriptions using multimodal large language models\n(MLLMs), and subsequently incorporates these function descriptions into\nLLM-based forecasting models. To evaluate our approach, we construct a new\nmultimodal dataset, MidEast-TE-mm, by extending an existing event dataset\nMidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast\ncan correctly identify the image functions, and further more, incorporating\nthese verbal function descriptions significantly improves the forecasting\nperformance. The dataset, code, and prompts are available at\nhttps://github.com/LuminosityX/MM-Forecast.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.IR",
      "H.3.3"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04388v1",
    "published_date": "2024-08-08 11:44:57 UTC",
    "updated_date": "2024-08-08 11:44:57 UTC"
  },
  {
    "arxiv_id": "2408.04385v2",
    "title": "Non-maximizing policies that fulfill multi-criterion aspirations in expectation",
    "authors": [
      "Simon Dima",
      "Simon Fischer",
      "Jobst Heitzig",
      "Joss Oliver"
    ],
    "abstract": "In dynamic programming and reinforcement learning, the policy for the\nsequential decision making of an agent in a stochastic environment is usually\ndetermined by expressing the goal as a scalar reward function and seeking a\npolicy that maximizes the expected total reward. However, many goals that\nhumans care about naturally concern multiple aspects of the world, and it may\nnot be obvious how to condense those into a single reward function.\nFurthermore, maximization suffers from specification gaming, where the obtained\npolicy achieves a high expected total reward in an unintended way, often taking\nextreme or nonsensical actions.\n  Here we consider finite acyclic Markov Decision Processes with multiple\ndistinct evaluation metrics, which do not necessarily represent quantities that\nthe user wants to be maximized. We assume the task of the agent is to ensure\nthat the vector of expected totals of the evaluation metrics falls into some\ngiven convex set, called the aspiration set. Our algorithm guarantees that this\ntask is fulfilled by using simplices to approximate feasibility sets and\npropagate aspirations forward while ensuring they remain feasible. It has\ncomplexity linear in the number of possible state-action-successor triples and\npolynomial in the number of evaluation metrics. Moreover, the explicitly\nnon-maximizing nature of the chosen policy and goals yields additional degrees\nof freedom, which can be used to apply heuristic safety criteria to the choice\nof actions. We discuss several such safety criteria that aim to steer the agent\ntowards more conservative behavior.",
    "categories": [
      "cs.AI",
      "econ.TH",
      "math.OC",
      "68T20, 90C40, 91B06",
      "I.2.8; F.2.2"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages main text + 4 pages supplement. Slightly corrected version\n  (corrections in blue in Eq. 11)",
    "pdf_url": "http://arxiv.org/pdf/2408.04385v2",
    "published_date": "2024-08-08 11:41:04 UTC",
    "updated_date": "2025-02-25 14:03:54 UTC"
  },
  {
    "arxiv_id": "2408.04382v1",
    "title": "Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments",
    "authors": [
      "Hsuan-Lei Shao"
    ],
    "abstract": "In court practice, legal professionals rely on their training to provide\nopinions that resolve cases, one of the most crucial aspects being the ability\nto identify similar judgments from previous courts efficiently. However,\nfinding a similar case is challenging and often depends on experience, legal\ndomain knowledge, and extensive labor hours, making veteran lawyers or judges\nindispensable. This research aims to automate the analysis of judgment text\nsimilarity. We utilized a judgment dataset labeled as the \"golden standard\" by\nexperts, which includes human-verified features that can be converted into an\n\"expert similarity score.\" We then constructed a knowledge graph based on\n\"case-article\" relationships, ranking each case using natural language\nprocessing to derive a \"Node2vec similarity score.\" By evaluating these two\nsimilarity scores, we identified their discrepancies and relationships. The\nresults can significantly reduce the labor hours required for legal searches\nand recommendations, with potential applications extending to various fields of\ninformation retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T30 (Primary), 68T50 (Secondary)",
      "I.2.7; I.2.4"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.04382v1",
    "published_date": "2024-08-08 11:37:32 UTC",
    "updated_date": "2024-08-08 11:37:32 UTC"
  },
  {
    "arxiv_id": "2408.04377v3",
    "title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon",
    "authors": [
      "Jiang You",
      "Arben Cela",
      "René Natowicz",
      "Jacob Ouanounou",
      "Patrick Siarry"
    ],
    "abstract": "Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for time series\nanomaly prediction, incorporating temporal information directly into the\nprediction results. We propose a new dataset specifically designed to evaluate\nthis approach and conduct comprehensive experiments using several\nstate-of-the-art methods. Our results demonstrate the efficacy of our approach\nin providing timely and accurate anomaly predictions, setting a new benchmark\nfor future research in this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04377v3",
    "published_date": "2024-08-08 11:22:52 UTC",
    "updated_date": "2024-10-23 14:29:56 UTC"
  },
  {
    "arxiv_id": "2408.04349v1",
    "title": "Optimal Layout-Aware CNOT Circuit Synthesis with Qubit Permutation",
    "authors": [
      "Irfansha Shaik",
      "Jaco van de Pol"
    ],
    "abstract": "CNOT optimization plays a significant role in noise reduction for Quantum\nCircuits. Several heuristic and exact approaches exist for CNOT optimization.\nIn this paper, we investigate more complicated variations of optimal synthesis\nby allowing qubit permutations and handling layout restrictions. We encode such\nproblems into Planning, SAT, and QBF. We provide optimization for both CNOT\ngate count and circuit depth. For experimental evaluation, we consider standard\nT-gate optimized benchmarks and optimize CNOT sub-circuits. We show that\nallowing qubit permutations can further reduce up to 56% in CNOT count and 46%\nin circuit depth. In the case of optimally mapped circuits under layout\nrestrictions, we observe a reduction up to 17% CNOT count and 19% CNOT depth.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "9 pages, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.04349v1",
    "published_date": "2024-08-08 10:20:13 UTC",
    "updated_date": "2024-08-08 10:20:13 UTC"
  },
  {
    "arxiv_id": "2408.04342v1",
    "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
    "authors": [
      "Paul R. B. Houssel",
      "Priyanka Singh",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionised natural language processing\ntasks, particularly as chat agents. However, their applicability to threat\ndetection problems remains unclear. This paper examines the feasibility of\nemploying LLMs as a Network Intrusion Detection System (NIDS), despite their\nhigh computational requirements, primarily for the sake of explainability.\nFurthermore, considerable resources have been invested in developing LLMs, and\nthey may offer utility for NIDS. Current state-of-the-art NIDS rely on\nartificial benchmarking datasets, resulting in skewed performance when applied\nto real-world networking environments. Therefore, we compare the GPT-4 and\nLLama3 models against traditional architectures and transformer-based models to\nassess their ability to detect malicious NetFlows without depending on\nartificially skewed datasets, but solely on their vast pre-trained acquired\nknowledge. Our results reveal that, although LLMs struggle with precise attack\ndetection, they hold significant potential for a path towards explainable NIDS.\nOur preliminary exploration shows that LLMs are unfit for the detection of\nMalicious NetFlows. Most promisingly, however, these exhibit significant\npotential as complementary agents in NIDS, particularly in providing\nexplanations and aiding in threat response when integrated with Retrieval\nAugmented Generation (RAG) and function calling capabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04342v1",
    "published_date": "2024-08-08 09:59:30 UTC",
    "updated_date": "2024-08-08 09:59:30 UTC"
  },
  {
    "arxiv_id": "2408.04336v1",
    "title": "KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination",
    "authors": [
      "Yin Gu",
      "Qi Liu",
      "Zhi Li",
      "Kai Zhang"
    ],
    "abstract": "Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI\nfield, which aims to learn an agent to cooperate with an unseen partner in\ntraining environments or even novel environments. In recent years, a popular\nZSC solution paradigm has been deep reinforcement learning (DRL) combined with\nadvanced self-play or population-based methods to enhance the neural policy's\nability to handle unseen partners. Despite some success, these approaches\nusually rely on black-box neural networks as the policy function. However,\nneural networks typically lack interpretability and logic, making the learned\npolicies difficult for partners (e.g., humans) to understand and limiting their\ngeneralization ability. These shortcomings hinder the application of\nreinforcement learning methods in diverse cooperative scenarios.We suggest to\nrepresent the agent's policy with an interpretable program. Unlike neural\nnetworks, programs contain stable logic, but they are non-differentiable and\ndifficult to optimize.To automatically learn such programs, we introduce\nKnowledge-driven Programmatic reinforcement learning for zero-shot Coordination\n(KnowPC). We first define a foundational Domain-Specific Language (DSL),\nincluding program structures, conditional primitives, and action primitives. A\nsignificant challenge is the vast program search space, making it difficult to\nfind high-performing programs efficiently. To address this, KnowPC integrates\nan extractor and an reasoner. The extractor discovers environmental transition\nknowledge from multi-agent interaction trajectories, while the reasoner deduces\nthe preconditions of each action primitive based on the transition knowledge.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04336v1",
    "published_date": "2024-08-08 09:43:54 UTC",
    "updated_date": "2024-08-08 09:43:54 UTC"
  },
  {
    "arxiv_id": "2408.04686v1",
    "title": "Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles",
    "authors": [
      "Xiongtao Sun",
      "Deyue Zhang",
      "Dongdong Yang",
      "Quanchen Zou",
      "Hui Li"
    ],
    "abstract": "Large language models (LLMs) have significantly enhanced the performance of\nnumerous applications, from intelligent conversations to text generation.\nHowever, their inherent security vulnerabilities have become an increasingly\nsignificant challenge, especially with respect to jailbreak attacks. Attackers\ncan circumvent the security mechanisms of these LLMs, breaching security\nconstraints and causing harmful outputs. Focusing on multi-turn semantic\njailbreak attacks, we observe that existing methods lack specific\nconsiderations for the role of multiturn dialogues in attack strategies,\nleading to semantic deviations during continuous interactions. Therefore, in\nthis paper, we establish a theoretical foundation for multi-turn attacks by\nconsidering their support in jailbreak attacks, and based on this, propose a\ncontext-based contextual fusion black-box jailbreak attack method, named\nContext Fusion Attack (CFA). This method approach involves filtering and\nextracting key terms from the target, constructing contextual scenarios around\nthese terms, dynamically integrating the target into the scenarios, replacing\nmalicious key terms within the target, and thereby concealing the direct\nmalicious intent. Through comparisons on various mainstream LLMs and red team\ndatasets, we have demonstrated CFA's superior success rate, divergence, and\nharmfulness compared to other multi-turn attack strategies, particularly\nshowcasing significant advantages on Llama3 and GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04686v1",
    "published_date": "2024-08-08 09:18:47 UTC",
    "updated_date": "2024-08-08 09:18:47 UTC"
  },
  {
    "arxiv_id": "2408.04304v1",
    "title": "Learning with Digital Agents: An Analysis based on the Activity Theory",
    "authors": [
      "Mateusz Dolata",
      "Dzmitry Katsiuba",
      "Natalie Wellnhammer",
      "Gerhard Schwabe"
    ],
    "abstract": "Digital agents are considered a general-purpose technology. They spread\nquickly in private and organizational contexts, including education. Yet,\nresearch lacks a conceptual framing to describe interaction with such agents in\na holistic manner. While focusing on the interaction with a pedagogical agent,\ni.e., a digital agent capable of natural-language interaction with a learner,\nwe propose a model of learning activity based on activity theory. We use this\nmodel and a review of prior research on digital agents in education to analyze\nhow various characteristics of the activity, including features of a\npedagogical agent or learner, influence learning outcomes. The analysis leads\nto identification of IS research directions and guidance for developers of\npedagogical agents and digital agents in general. We conclude by extending the\nactivity theory-based model beyond the context of education and show how it\nhelps designers and researchers ask the right questions when creating a digital\nagent.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Authors manuscript accepted for publication in Journal of Management\n  Information Systems",
    "pdf_url": "http://arxiv.org/pdf/2408.04304v1",
    "published_date": "2024-08-08 08:38:02 UTC",
    "updated_date": "2024-08-08 08:38:02 UTC"
  },
  {
    "arxiv_id": "2408.05246v1",
    "title": "Differentially Private Data Release on Graphs: Inefficiencies and Unfairness",
    "authors": [
      "Ferdinando Fioretto",
      "Diptangshu Sen",
      "Juba Ziani"
    ],
    "abstract": "Networks are crucial components of many sectors, including\ntelecommunications, healthcare, finance, energy, and transportation.The\ninformation carried in such networks often contains sensitive user data, like\nlocation data for commuters and packet data for online users. Therefore, when\nconsidering data release for networks, one must ensure that data release\nmechanisms do not leak information about individuals, quantified in a precise\nmathematical sense. Differential Privacy (DP) is the widely accepted, formal,\nstate-of-the-art technique, which has found use in a variety of real-life\nsettings including the 2020 U.S. Census, Apple users' device data, or Google's\nlocation data. Yet, the use of DP comes with new challenges, as the noise added\nfor privacy introduces inaccuracies or biases and further, DP techniques can\nalso distribute these biases disproportionately across different populations,\ninducing fairness issues. The goal of this paper is to characterize the impact\nof DP on bias and unfairness in the context of releasing information about\nnetworks, taking a departure from previous work which has studied these effects\nin the context of private population counts release (such as in the U.S.\nCensus). To this end, we consider a network release problem where the network\nstructure is known to all, but the weights on edges must be released privately.\nWe consider the impact of this private release on a simple downstream\ndecision-making task run by a third-party, which is to find the shortest path\nbetween any two pairs of nodes and recommend the best route to users. This\nsetting is of highly practical relevance, mirroring scenarios in transportation\nnetworks, where preserving privacy while providing accurate routing information\nis crucial. Our work provides theoretical foundations and empirical evidence\ninto the bias and unfairness arising due to privacy in these networked decision\nproblems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "32 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.05246v1",
    "published_date": "2024-08-08 08:37:37 UTC",
    "updated_date": "2024-08-08 08:37:37 UTC"
  },
  {
    "arxiv_id": "2408.04301v1",
    "title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction",
    "authors": [
      "Xuefeng Jiang",
      "Sheng Sun",
      "Jia Li",
      "Jingjing Xue",
      "Runhan Li",
      "Zhiyuan Wu",
      "Gang Xu",
      "Yuwei Wang",
      "Min Liu"
    ],
    "abstract": "Recently, federated learning (FL) has achieved wide successes for diverse\nprivacy-sensitive applications without sacrificing the sensitive private\ninformation of clients. However, the data quality of client datasets can not be\nguaranteed since corresponding annotations of different clients often contain\ncomplex label noise of varying degrees, which inevitably causes the performance\ndegradation. Intuitively, the performance degradation is dominated by clients\nwith higher noise rates since their trained models contain more misinformation\nfrom data, thus it is necessary to devise an effective optimization scheme to\nmitigate the negative impacts of these noisy clients. In this work, we propose\na two-stage framework FedELC to tackle this complicated label noise issue. The\nfirst stage aims to guide the detection of noisy clients with higher label\nnoise, while the second stage aims to correct the labels of noisy clients' data\nvia an end-to-end label correction framework which is achieved by learning\npossible ground-truth labels of noisy clients' datasets via back propagation.\nWe implement sixteen related methods and evaluate five datasets with three\ntypes of complicated label noise scenarios for a comprehensive comparison.\nExtensive experimental results demonstrate our proposed framework achieves\nsuperior performance than its counterparts for different scenarios.\nAdditionally, we effectively improve the data quality of detected noisy\nclients' local datasets with our label correction framework. The code is\navailable at https://github.com/Sprinter1999/FedELC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in ACM CIKM'24 full research paper track",
    "pdf_url": "http://arxiv.org/pdf/2408.04301v1",
    "published_date": "2024-08-08 08:35:32 UTC",
    "updated_date": "2024-08-08 08:35:32 UTC"
  },
  {
    "arxiv_id": "2408.12609v1",
    "title": "Enhanced Prediction of Multi-Agent Trajectories via Control Inference and State-Space Dynamics",
    "authors": [
      "Yu Zhang",
      "Yongxiang Zou",
      "Haoyu Zhang",
      "Zeyu Liu",
      "Houcheng Li",
      "Long Cheng"
    ],
    "abstract": "In the field of autonomous systems, accurately predicting the trajectories of\nnearby vehicles and pedestrians is crucial for ensuring both safety and\noperational efficiency. This paper introduces a novel methodology for\ntrajectory forecasting based on state-space dynamic system modeling, which\nendows agents with models that have tangible physical implications. To enhance\nthe precision of state estimations within the dynamic system, the paper also\npresents a novel modeling technique for control variables. This technique\nutilizes a newly introduced model, termed \"Mixed Mamba,\" to derive initial\ncontrol states, thereby improving the predictive accuracy of these variables.\nMoverover, the proposed approach ingeniously integrates graph neural networks\nwith state-space models, effectively capturing the complexities of multi-agent\ninteractions. This combination provides a robust and scalable framework for\nforecasting multi-agent trajectories across a range of scenarios. Comprehensive\nevaluations demonstrate that this model outperforms several established\nbenchmarks across various metrics and datasets, highlighting its significant\npotential to advance trajectory forecasting in autonomous systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12609v1",
    "published_date": "2024-08-08 08:33:02 UTC",
    "updated_date": "2024-08-08 08:33:02 UTC"
  },
  {
    "arxiv_id": "2408.04683v2",
    "title": "Eliminating Backdoors in Neural Code Models for Secure Code Understanding",
    "authors": [
      "Weisong Sun",
      "Yuchen Chen",
      "Chunrong Fang",
      "Yebo Feng",
      "Yuan Xiao",
      "An Guo",
      "Quanjun Zhang",
      "Yang Liu",
      "Baowen Xu",
      "Zhenyu Chen"
    ],
    "abstract": "Neural code models (NCMs) have been widely used to address various code\nunderstanding tasks, such as defect detection. However, numerous recent studies\nreveal that such models are vulnerable to backdoor attacks. Backdoored NCMs\nfunction normally on normal/clean code snippets, but exhibit adversary-expected\nbehavior on poisoned code snippets injected with the adversary-crafted trigger.\nIt poses a significant security threat. Therefore, there is an urgent need for\neffective techniques to detect and eliminate backdoors stealthily implanted in\nNCMs.\n  To address this issue, in this paper, we innovatively propose a backdoor\nelimination technique for secure code understanding, called EliBadCode.\nEliBadCode eliminates backdoors in NCMs by inverting/reverse-engineering and\nunlearning backdoor triggers. Specifically, EliBadCode first filters the model\nvocabulary for trigger tokens based on the naming conventions of specific\nprogramming languages to reduce the trigger search space and cost. Then,\nEliBadCode introduces a sample-specific trigger position identification method,\nwhich can reduce the interference of non-backdoor (adversarial) perturbations\nfor subsequent trigger inversion, thereby producing effective inverted backdoor\ntriggers efficiently. Backdoor triggers can be viewed as backdoor (adversarial)\nperturbations. Subsequently, EliBadCode employs a Greedy Coordinate Gradient\nalgorithm to optimize the inverted trigger and designs a trigger anchoring\nmethod to purify the inverted trigger. Finally, EliBadCode eliminates backdoors\nthrough model unlearning. We evaluate the effectiveness of EliBadCode in\neliminating backdoors implanted in multiple NCMs used for three safety-critical\ncode understanding tasks. The results demonstrate that EliBadCode can\neffectively eliminate backdoors while having minimal adverse effects on the\nnormal functionality of the model.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE",
      "68-06",
      "D.2.3; I.2.2"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to the 33rd ACM International Conference on the Foundations\n  of Software Engineering (FSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.04683v2",
    "published_date": "2024-08-08 08:23:03 UTC",
    "updated_date": "2025-02-20 06:07:08 UTC"
  },
  {
    "arxiv_id": "2408.04295v3",
    "title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization",
    "authors": [
      "Aditya Kapoor",
      "Benjamin Freed",
      "Howie Choset",
      "Jeff Schneider"
    ],
    "abstract": "Multi-agent proximal policy optimization (MAPPO) has recently demonstrated\nstate-of-the-art performance on challenging multi-agent reinforcement learning\ntasks. However, MAPPO still struggles with the credit assignment problem,\nwherein the sheer difficulty in ascribing credit to individual agents' actions\nscales poorly with team size. In this paper, we propose a multi-agent\nreinforcement learning algorithm that adapts recent developments in credit\nassignment to improve upon MAPPO. Our approach leverages partial reward\ndecoupling (PRD), which uses a learned attention mechanism to estimate which of\na particular agent's teammates are relevant to its learning updates. We use\nthis estimate to dynamically decompose large groups of agents into smaller,\nmore manageable subgroups. We empirically demonstrate that our approach,\nPRD-MAPPO, decouples agents from teammates that do not influence their expected\nfuture reward, thereby streamlining credit assignment. We additionally show\nthat PRD-MAPPO yields significantly higher data efficiency and asymptotic\nperformance compared to both MAPPO and other state-of-the-art methods across\nseveral multi-agent tasks, including StarCraft II. Finally, we propose a\nversion of PRD-MAPPO that is applicable to \\textit{shared} reward settings,\nwhere PRD was previously not applicable, and empirically show that this also\nleads to performance improvements over MAPPO.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "20 pages, 5 figures, 12 tables, Reinforcement Learning Journal and\n  Reinforcement Learning Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04295v3",
    "published_date": "2024-08-08 08:18:05 UTC",
    "updated_date": "2025-02-07 10:48:22 UTC"
  },
  {
    "arxiv_id": "2408.12608v1",
    "title": "A frugal Spiking Neural Network for unsupervised classification of continuous multivariate temporal data",
    "authors": [
      "Sai Deepesh Pokala",
      "Marie Bernert",
      "Takuya Nanami",
      "Takashi Kohno",
      "Timothée Lévi",
      "Blaise Yvert"
    ],
    "abstract": "As neural interfaces become more advanced, there has been an increase in the\nvolume and complexity of neural data recordings. These interfaces capture rich\ninformation about neural dynamics that call for efficient, real-time processing\nalgorithms to spontaneously extract and interpret patterns of neural dynamics.\nMoreover, being able to do so in a fully unsupervised manner is critical as\npatterns in vast streams of neural data might not be easily identifiable by the\nhuman eye. Formal Deep Neural Networks (DNNs) have come a long way in\nperforming pattern recognition tasks for various static and sequential pattern\nrecognition applications. However, these networks usually require large labeled\ndatasets for training and have high power consumption preventing their future\nembedding in active brain implants. An alternative aimed at addressing these\nissues are Spiking Neural Networks (SNNs) which are neuromorphic and use more\nbiologically plausible neurons with evolving membrane potentials. In this\ncontext, we introduce here a frugal single-layer SNN designed for fully\nunsupervised identification and classification of multivariate temporal\npatterns in continuous data with a sequential approach. We show that, with only\na handful number of neurons, this strategy is efficient to recognize highly\noverlapping multivariate temporal patterns, first on simulated data, and then\non Mel Cepstral representations of speech sounds and finally on multichannel\nneural data. This approach relies on several biologically inspired plasticity\nrules, including Spike-timing-dependent plasticity (STDP), Short-term\nplasticity (STP) and intrinsic plasticity (IP). These results pave the way\ntowards highly frugal SNNs for fully unsupervised and online-compatible\nlearning of complex multivariate temporal patterns for future embedding in\ndedicated very-low power hardware.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12608v1",
    "published_date": "2024-08-08 08:15:51 UTC",
    "updated_date": "2024-08-08 08:15:51 UTC"
  },
  {
    "arxiv_id": "2408.04281v1",
    "title": "AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent",
    "authors": [
      "Mugheez Asif",
      "Abdul Manan",
      "Abdul Moiz ur Rehman",
      "Mamoona Naveed Asghar",
      "Muhammad Umair"
    ],
    "abstract": "In today's contemporary digital landscape, chatbots have become indispensable\ntools across various sectors, streamlining customer service, providing personal\nassistance, automating routine tasks, and offering health advice. However,\ntheir potential remains underexplored in the realm of network security,\nparticularly for intrusion detection. To bridge this gap, we propose an\narchitecture chatbot specifically designed to enhance security within edge\nnetworks specifically for intrusion detection. Leveraging advanced machine\nlearning algorithms, this chatbot will monitor network traffic to identify and\nmitigate potential intrusions. By securing the network environment using an\nedge network managed by a Raspberry Pi module and ensuring ethical user consent\npromoting transparency and trust, this innovative solution aims to safeguard\nsensitive data and maintain a secure workplace, thereby addressing the growing\nneed for robust network security measures in the digital age.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04281v1",
    "published_date": "2024-08-08 07:39:23 UTC",
    "updated_date": "2024-08-08 07:39:23 UTC"
  },
  {
    "arxiv_id": "2408.04268v2",
    "title": "Evaluating Modern Approaches in 3D Scene Reconstruction: NeRF vs Gaussian-Based Methods",
    "authors": [
      "Yiming Zhou",
      "Zixuan Zeng",
      "Andi Chen",
      "Xiaofan Zhou",
      "Haowei Ni",
      "Shiyao Zhang",
      "Panfeng Li",
      "Liangxi Liu",
      "Mengyao Zheng",
      "Xupeng Chen"
    ],
    "abstract": "Exploring the capabilities of Neural Radiance Fields (NeRF) and\nGaussian-based methods in the context of 3D scene reconstruction, this study\ncontrasts these modern approaches with traditional Simultaneous Localization\nand Mapping (SLAM) systems. Utilizing datasets such as Replica and ScanNet, we\nassess performance based on tracking accuracy, mapping fidelity, and view\nsynthesis. Findings reveal that NeRF excels in view synthesis, offering unique\ncapabilities in generating new perspectives from existing data, albeit at\nslower processing speeds. Conversely, Gaussian-based methods provide rapid\nprocessing and significant expressiveness but lack comprehensive scene\ncompletion. Enhanced by global optimization and loop closure techniques, newer\nmethods like NICE-SLAM and SplaTAM not only surpass older frameworks such as\nORB-SLAM2 in terms of robustness but also demonstrate superior performance in\ndynamic and complex environments. This comparative analysis bridges theoretical\nresearch with practical implications, shedding light on future developments in\nrobust 3D scene reconstruction across various real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems",
    "pdf_url": "http://arxiv.org/pdf/2408.04268v2",
    "published_date": "2024-08-08 07:11:57 UTC",
    "updated_date": "2024-11-14 23:46:34 UTC"
  },
  {
    "arxiv_id": "2408.04261v1",
    "title": "Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding",
    "authors": [
      "Jonggyu Jang",
      "Hyeonsu Lyu",
      "Seongjin Hwang",
      "Hyun Jong Yang"
    ],
    "abstract": "This paper investigates the security vulnerabilities of\nadversarial-example-based image encryption by executing data reconstruction\n(DR) attacks on encrypted images. A representative image encryption method is\nthe adversarial visual information hiding (AVIH), which uses type-I adversarial\nexample training to protect gallery datasets used in image recognition tasks.\nIn the AVIH method, the type-I adversarial example approach creates images that\nappear completely different but are still recognized by machines as the\noriginal ones. Additionally, the AVIH method can restore encrypted images to\ntheir original forms using a predefined private key generative model. For the\nbest security, assigning a unique key to each image is recommended; however,\nstorage limitations may necessitate some images sharing the same key model.\nThis raises a crucial security question for AVIH: How many images can safely\nshare the same key model without being compromised by a DR attack? To address\nthis question, we introduce a dual-strategy DR attack against the AVIH\nencryption method by incorporating (1) generative-adversarial loss and (2)\naugmented identity loss, which prevent DR from overfitting -- an issue akin to\nthat in machine learning. Our numerical results validate this approach through\nimage recognition and re-identification benchmarks, demonstrating that our\nstrategy can significantly enhance the quality of reconstructed images, thereby\nrequiring fewer key-sharing encrypted images. Our source code to reproduce our\nresults will be available soon.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.04261v1",
    "published_date": "2024-08-08 06:58:48 UTC",
    "updated_date": "2024-08-08 06:58:48 UTC"
  },
  {
    "arxiv_id": "2408.04259v2",
    "title": "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering",
    "authors": [
      "Ziyuan Zhuang",
      "Zhiyang Zhang",
      "Sitao Cheng",
      "Fangkai Yang",
      "Jia Liu",
      "Shujian Huang",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.04259v2",
    "published_date": "2024-08-08 06:57:49 UTC",
    "updated_date": "2024-09-26 11:42:35 UTC"
  },
  {
    "arxiv_id": "2408.04245v1",
    "title": "Scalable Transformer for High Dimensional Multivariate Time Series Forecasting",
    "authors": [
      "Xin Zhou",
      "Weiqing Wang",
      "Wray Buntine",
      "Shilin Qu",
      "Abishek Sriramulu",
      "Weicong Tan",
      "Christoph Bergmeir"
    ],
    "abstract": "Deep models for Multivariate Time Series (MTS) forecasting have recently\ndemonstrated significant success. Channel-dependent models capture complex\ndependencies that channel-independent models cannot capture. However, the\nnumber of channels in real-world applications outpaces the capabilities of\nexisting channel-dependent models, and contrary to common expectations, some\nmodels underperform the channel-independent models in handling high-dimensional\ndata, which raises questions about the performance of channel-dependent models.\nTo address this, our study first investigates the reasons behind the suboptimal\nperformance of these channel-dependent models on high-dimensional MTS data. Our\nanalysis reveals that two primary issues lie in the introduced noise from\nunrelated series that increases the difficulty of capturing the crucial\ninter-channel dependencies, and challenges in training strategies due to\nhigh-dimensional data. To address these issues, we propose STHD, the Scalable\nTransformer for High-Dimensional Multivariate Time Series Forecasting. STHD has\nthree components: a) Relation Matrix Sparsity that limits the noise introduced\nand alleviates the memory issue; b) ReIndex applied as a training strategy to\nenable a more flexible batch size setting and increase the diversity of\ntraining data; and c) Transformer that handles 2-D inputs and captures channel\ndependencies. These components jointly enable STHD to manage the\nhigh-dimensional MTS while maintaining computational feasibility. Furthermore,\nexperimental results show STHD's considerable improvement on three\nhigh-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source\ncode and dataset are publicly available\nhttps://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "H.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04245v1",
    "published_date": "2024-08-08 06:17:13 UTC",
    "updated_date": "2024-08-08 06:17:13 UTC"
  },
  {
    "arxiv_id": "2408.04242v1",
    "title": "The Ungrounded Alignment Problem",
    "authors": [
      "Marc Pickett",
      "Aakash Kumar Nain",
      "Joseph Modayil",
      "Llion Jones"
    ],
    "abstract": "Modern machine learning systems have demonstrated substantial abilities with\nmethods that either embrace or ignore human-provided knowledge, but combining\nbenefits of both styles remains a challenge. One particular challenge involves\ndesigning learning systems that exhibit built-in responses to specific abstract\nstimulus patterns, yet are still plastic enough to be agnostic about the\nmodality and exact form of their inputs. In this paper, we investigate what we\ncall The Ungrounded Alignment Problem, which asks How can we build in\npredefined knowledge in a system where we don't know how a given stimulus will\nbe grounded? This paper examines a simplified version of the general problem,\nwhere an unsupervised learner is presented with a sequence of images for the\ncharacters in a text corpus, and this learner is later evaluated on its ability\nto recognize specific (possibly rare) sequential patterns. Importantly, the\nlearner is given no labels during learning or evaluation, but must map images\nfrom an unknown font or permutation to its correct class label. That is, at no\npoint is our learner given labeled images, where an image vector is explicitly\nassociated with a class label. Despite ample work in unsupervised and\nself-supervised loss functions, all current methods require a labeled\nfine-tuning phase to map the learned representations to correct classes.\nFinding this mapping in the absence of labels may seem a fool's errand, but our\nmain result resolves this seeming paradox. We show that leveraging only letter\nbigram frequencies is sufficient for an unsupervised learner both to reliably\nassociate images to class labels and to reliably identify trigger words in the\nsequence of inputs. More generally, this method suggests an approach for\nencoding specific desired innate behaviour in modality-agnostic models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, plus references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2408.04242v1",
    "published_date": "2024-08-08 06:08:04 UTC",
    "updated_date": "2024-08-08 06:08:04 UTC"
  },
  {
    "arxiv_id": "2408.04682v2",
    "title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities",
    "authors": [
      "Jiarui Lu",
      "Thomas Holleis",
      "Yizhe Zhang",
      "Bernhard Aumayer",
      "Feng Nan",
      "Felix Bai",
      "Shuang Ma",
      "Shen Ma",
      "Mengyu Li",
      "Guoli Yin",
      "Zirui Wang",
      "Ruoming Pang"
    ],
    "abstract": "Recent large language models (LLMs) advancements sparked a growing research\ninterest in tool assisted LLMs solving real-world challenges, which calls for\ncomprehensive evaluation of tool-use capabilities. While previous works focused\non either evaluating over stateless web services (RESTful API), based on a\nsingle turn user prompt, or an off-policy dialog trajectory, ToolSandbox\nincludes stateful tool execution, implicit state dependencies between tools, a\nbuilt-in user simulator supporting on-policy conversational evaluation and a\ndynamic evaluation strategy for intermediate and final milestones over an\narbitrary trajectory. We show that open source and proprietary models have a\nsignificant performance gap, and complex tasks like State Dependency,\nCanonicalization and Insufficient Information defined in ToolSandbox are\nchallenging even the most capable SOTA LLMs, providing brand-new insights into\ntool-use LLM capabilities. ToolSandbox evaluation framework is released at\nhttps://github.com/apple/ToolSandbox",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04682v2",
    "published_date": "2024-08-08 05:45:42 UTC",
    "updated_date": "2025-04-16 22:20:21 UTC"
  },
  {
    "arxiv_id": "2408.04236v1",
    "title": "Cluster-Wide Task Slowdown Detection in Cloud System",
    "authors": [
      "Feiyi Chen",
      "Yingying Zhang",
      "Lunting Fan",
      "Yuxuan Liang",
      "Guansong Pang",
      "Qingsong Wen",
      "Shuiguang Deng"
    ],
    "abstract": "Slow task detection is a critical problem in cloud operation and maintenance\nsince it is highly related to user experience and can bring substantial\nliquidated damages. Most anomaly detection methods detect it from a single-task\naspect. However, considering millions of concurrent tasks in large-scale cloud\ncomputing clusters, it becomes impractical and inefficient. Moreover,\nsingle-task slowdowns are very common and do not necessarily indicate a\nmalfunction of a cluster due to its violent fluctuation nature in a virtual\nenvironment. Thus, we shift our attention to cluster-wide task slowdowns by\nutilizing the duration time distribution of tasks across a cluster, so that the\ncomputation complexity is not relevant to the number of tasks.\n  The task duration time distribution often exhibits compound periodicity and\nlocal exceptional fluctuations over time. Though transformer-based methods are\none of the most powerful methods to capture these time series normal variation\npatterns, we empirically find and theoretically explain the flaw of the\nstandard attention mechanism in reconstructing subperiods with low amplitude\nwhen dealing with compound periodicity.\n  To tackle these challenges, we propose SORN (i.e., Skimming Off subperiods in\ndescending amplitude order and Reconstructing Non-slowing fluctuation), which\nconsists of a Skimming Attention mechanism to reconstruct the compound\nperiodicity and a Neural Optimal Transport module to distinguish cluster-wide\nslowdowns from other exceptional fluctuations. Furthermore, since anomalies in\nthe training set are inevitable in a practical scenario, we propose a picky\nloss function, which adaptively assigns higher weights to reliable time slots\nin the training set. Extensive experiments demonstrate that SORN outperforms\nstate-of-the-art methods on multiple real-world industrial datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by KDD2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04236v1",
    "published_date": "2024-08-08 05:43:20 UTC",
    "updated_date": "2024-08-08 05:43:20 UTC"
  },
  {
    "arxiv_id": "2409.07457v1",
    "title": "LSST: Learned Single-Shot Trajectory and Reconstruction Network for MR Imaging",
    "authors": [
      "Hemant Kumar Aggarwal",
      "Sudhanya Chatterjee",
      "Dattesh Shanbhag",
      "Uday Patil",
      "K. V. S. Hari"
    ],
    "abstract": "Single-shot magnetic resonance (MR) imaging acquires the entire k-space data\nin a single shot and it has various applications in whole-body imaging.\nHowever, the long acquisition time for the entire k-space in single-shot fast\nspin echo (SSFSE) MR imaging poses a challenge, as it introduces T2-blur in the\nacquired images. This study aims to enhance the reconstruction quality of SSFSE\nMR images by (a) optimizing the trajectory for measuring the k-space, (b)\nacquiring fewer samples to speed up the acquisition process, and (c) reducing\nthe impact of T2-blur. The proposed method adheres to physics constraints due\nto maximum gradient strength and slew-rate available while optimizing the\ntrajectory within an end-to-end learning framework. Experiments were conducted\non publicly available fastMRI multichannel dataset with 8-fold and 16-fold\nacceleration factors. An experienced radiologist's evaluation on a five-point\nLikert scale indicates improvements in the reconstruction quality as the ACL\nfibers are sharper than comparative methods.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07457v1",
    "published_date": "2024-08-08 05:41:54 UTC",
    "updated_date": "2024-08-08 05:41:54 UTC"
  },
  {
    "arxiv_id": "2408.04229v1",
    "title": "Probabilistic Circuits for Cumulative Distribution Functions",
    "authors": [
      "Oliver Broadrick",
      "William Cao",
      "Benjie Wang",
      "Martin Trapp",
      "Guy Van den Broeck"
    ],
    "abstract": "A probabilistic circuit (PC) succinctly expresses a function that represents\na multivariate probability distribution and, given sufficient structural\nproperties of the circuit, supports efficient probabilistic inference.\nTypically a PC computes the probability mass (or density) function (PMF or PDF)\nof the distribution. We consider PCs instead computing the cumulative\ndistribution function (CDF). We show that for distributions over binary random\nvariables these representations (PMF and CDF) are essentially equivalent, in\nthe sense that one can be transformed to the other in polynomial time. We then\nshow how a similar equivalence holds for distributions over finite discrete\nvariables using a modification of the standard encoding with binary variables\nthat aligns with the CDF semantics. Finally we show that for continuous\nvariables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently\ntransformed to each other by modifying only the leaves of the circuit.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04229v1",
    "published_date": "2024-08-08 05:33:21 UTC",
    "updated_date": "2024-08-08 05:33:21 UTC"
  },
  {
    "arxiv_id": "2408.04223v1",
    "title": "VideoQA in the Era of LLMs: An Empirical Study",
    "authors": [
      "Junbin Xiao",
      "Nanxin Huang",
      "Hangyu Qin",
      "Dongyang Li",
      "Yicong Li",
      "Fengbin Zhu",
      "Zhulin Tao",
      "Jianxing Yu",
      "Liang Lin",
      "Tat-Seng Chua",
      "Angela Yao"
    ],
    "abstract": "Video Large Language Models (Video-LLMs) are flourishing and has advanced\nmany video-language tasks. As a golden testbed, Video Question Answering\n(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a\ntimely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to\nelucidate their success and failure modes, and provide insights towards more\nhuman-like video understanding and question answering. Our analyses demonstrate\nthat Video-LLMs excel in VideoQA; they can correlate contextual cues and\ngenerate plausible responses to questions about varied video contents. However,\nmodels falter in handling video temporality, both in reasoning about temporal\ncontent ordering and grounding QA-relevant temporal moments. Moreover, the\nmodels behave unintuitively - they are unresponsive to adversarial video\nperturbations while being sensitive to simple variations of candidate answers\nand questions. Also, they do not necessarily generalize better. The findings\ndemonstrate Video-LLMs' QA capability in standard condition yet highlight their\nsevere deficiency in robustness and interpretability, suggesting the urgent\nneed on rationales in Video-LLM developing.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2408.04223v1",
    "published_date": "2024-08-08 05:14:07 UTC",
    "updated_date": "2024-08-08 05:14:07 UTC"
  },
  {
    "arxiv_id": "2408.04221v1",
    "title": "Connective Viewpoints of Signal-to-Noise Diffusion Models",
    "authors": [
      "Khanh Doan",
      "Long Tung Vuong",
      "Tuan Nguyen",
      "Anh Tuan Bui",
      "Quyen Tran",
      "Thanh-Toan Do",
      "Dinh Phung",
      "Trung Le"
    ],
    "abstract": "Diffusion models (DM) have become fundamental components of generative\nmodels, excelling across various domains such as image creation, audio\ngeneration, and complex data interpolation. Signal-to-Noise diffusion models\nconstitute a diverse family covering most state-of-the-art diffusion models.\nWhile there have been several attempts to study Signal-to-Noise (S2N) diffusion\nmodels from various perspectives, there remains a need for a comprehensive\nstudy connecting different viewpoints and exploring new perspectives. In this\nstudy, we offer a comprehensive perspective on noise schedulers, examining\ntheir role through the lens of the signal-to-noise ratio (SNR) and its\nconnections to information theory. Building upon this framework, we have\ndeveloped a generalized backward equation to enhance the performance of the\ninference process.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04221v1",
    "published_date": "2024-08-08 05:09:02 UTC",
    "updated_date": "2024-08-08 05:09:02 UTC"
  },
  {
    "arxiv_id": "2408.12606v3",
    "title": "A Large Model for Non-invasive and Personalized Management of Breast Cancer from Multiparametric MRI",
    "authors": [
      "Luyang Luo",
      "Mingxiang Wu",
      "Mei Li",
      "Yi Xin",
      "Qiong Wang",
      "Varut Vardhanabhuti",
      "Winnie CW Chu",
      "Zhenhui Li",
      "Juan Zhou",
      "Pranav Rajpurkar",
      "Hao Chen"
    ],
    "abstract": "Breast Magnetic Resonance Imaging (MRI) demonstrates the highest sensitivity\nfor breast cancer detection among imaging modalities and is standard practice\nfor high-risk women. Interpreting the multi-sequence MRI is time-consuming and\nprone to subjective variation. We develop a large mixture-of-modality-experts\nmodel (MOME) that integrates multiparametric MRI information within a unified\nstructure, leveraging breast MRI scans from 5,205 female patients in China for\nmodel development and validation. MOME matches four senior radiologists'\nperformance in identifying breast cancer and outperforms a junior radiologist.\nThe model is able to reduce unnecessary biopsies in Breast Imaging-Reporting\nand Data System (BI-RADS) 4 patients, classify triple-negative breast cancer,\nand predict pathological complete response to neoadjuvant chemotherapy. MOME\nfurther supports inference with missing modalities and provides decision\nexplanations by highlighting lesions and measuring modality contributions. To\nsummarize, MOME exemplifies an accurate and robust multimodal model for\nnoninvasive, personalized management of breast cancer patients via\nmultiparametric MRI. Code is available at\nhttps://github.com/LLYXC/MOME/tree/main.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Nature Communications 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.12606v3",
    "published_date": "2024-08-08 05:04:13 UTC",
    "updated_date": "2025-04-04 19:14:02 UTC"
  },
  {
    "arxiv_id": "2408.04681v1",
    "title": "Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews",
    "authors": [
      "Samantha Chan",
      "Pat Pataranutaporn",
      "Aditya Suri",
      "Wazeer Zulfikar",
      "Pattie Maes",
      "Elizabeth F. Loftus"
    ],
    "abstract": "This study examines the impact of AI on human false memories -- recollections\nof events that did not occur or deviate from actual occurrences. It explores\nfalse memory induction through suggestive questioning in Human-AI interactions,\nsimulating crime witness interviews. Four conditions were tested: control,\nsurvey-based, pre-scripted chatbot, and generative chatbot using a large\nlanguage model (LLM). Participants (N=200) watched a crime video, then\ninteracted with their assigned AI interviewer or survey, answering questions\nincluding five misleading ones. False memories were assessed immediately and\nafter one week. Results show the generative chatbot condition significantly\nincreased false memory formation, inducing over 3 times more immediate false\nmemories than the control and 1.7 times more than the survey method. 36.4% of\nusers' responses to the generative chatbot were misled through the interaction.\nAfter one week, the number of false memories induced by generative chatbots\nremained constant. However, confidence in these false memories remained higher\nthan the control after one week. Moderating factors were explored: users who\nwere less familiar with chatbots but more familiar with AI technology, and more\ninterested in crime investigations, were more susceptible to false memories.\nThese findings highlight the potential risks of using advanced AI in sensitive\ncontexts, like police interviews, emphasizing the need for ethical\nconsiderations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04681v1",
    "published_date": "2024-08-08 04:55:03 UTC",
    "updated_date": "2024-08-08 04:55:03 UTC"
  },
  {
    "arxiv_id": "2408.04216v3",
    "title": "Attention Mechanism and Context Modeling System for Text Mining Machine Translation",
    "authors": [
      "Yuwei Zhang",
      "Junming Huang",
      "Sitong Liu",
      "Zexi Chen",
      "Zizheng Li"
    ],
    "abstract": "This paper advances a novel architectural schema anchored upon the\nTransformer paradigm and innovatively amalgamates the K-means categorization\nalgorithm to augment the contextual apprehension capabilities of the schema.\nThe transformer model performs well in machine translation tasks due to its\nparallel computing power and multi-head attention mechanism. However, it may\nencounter contextual ambiguity or ignore local features when dealing with\nhighly complex language structures. To circumvent this constraint, this\nexposition incorporates the K-Means algorithm, which is used to stratify the\nlexis and idioms of the input textual matter, thereby facilitating superior\nidentification and preservation of the local structure and contextual\nintelligence of the language. The advantage of this combination is that K-Means\ncan automatically discover the topic or concept regions in the text, which may\nbe directly related to translation quality. Consequently, the schema contrived\nherein enlists K-Means as a preparatory phase antecedent to the Transformer and\nrecalibrates the multi-head attention weights to assist in the discrimination\nof lexis and idioms bearing analogous semantics or functionalities. This\nensures the schema accords heightened regard to the contextual intelligence\nembodied by these clusters during the training phase, rather than merely\nfocusing on locational intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04216v3",
    "published_date": "2024-08-08 04:52:10 UTC",
    "updated_date": "2025-01-18 00:29:19 UTC"
  },
  {
    "arxiv_id": "2408.04680v2",
    "title": "Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications",
    "authors": [
      "Philipp Zagar",
      "Vishnu Ravi",
      "Lauren Aalami",
      "Stephan Krusche",
      "Oliver Aalami",
      "Paul Schmiedmayer"
    ],
    "abstract": "The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04680v2",
    "published_date": "2024-08-08 04:49:21 UTC",
    "updated_date": "2024-12-13 08:44:55 UTC"
  },
  {
    "arxiv_id": "2408.07084v3",
    "title": "Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits",
    "authors": [
      "Wangying Yang",
      "Zitao Zheng",
      "Zhizhong Wu",
      "Bo Zhang",
      "Yuanfang Yang"
    ],
    "abstract": "This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model\ndesigned to predict future medical diagnoses from electronic health records\nwith enhanced accuracy. The DHCE model innovates by identifying and\ndifferentiating acute and chronic diseases within a patient's visit history,\nconstructing dynamic hypergraphs that capture the complex, high-order\ninteractions between diseases. It surpasses traditional recurrent neural\nnetworks and graph neural networks by effectively integrating clinical event\ndata, reflected through medical language model-assisted encoding, into a robust\npatient representation. Through extensive experiments on two benchmark\ndatasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,\nsignificantly outpacing established baseline models in the precision of\nsequential diagnosis prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07084v3",
    "published_date": "2024-08-08 04:19:20 UTC",
    "updated_date": "2025-01-06 02:51:39 UTC"
  },
  {
    "arxiv_id": "2408.04203v2",
    "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents",
    "authors": [
      "Yanqi Dai",
      "Huanran Hu",
      "Lei Wang",
      "Shengjie Jin",
      "Xu Chen",
      "Zhiwu Lu"
    ],
    "abstract": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for\ntheir potential to deliver emotional value and facilitate sociological\nresearch. However, existing studies are primarily confined to the textual\nmodality, unable to simulate humans' multimodal perceptual capabilities. To\nbridge this gap, we introduce the concept of Multimodal Role-Playing Agents\n(MRPAs), and propose a comprehensive framework, MMRole, for their development\nand evaluation, which comprises a personalized multimodal dataset and a robust\nevaluation approach. Specifically, we construct a large-scale, high-quality\ndataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single\nor multi-turn dialogues. Additionally, we present a robust evaluation approach,\nMMRole-Eval, encompassing eight metrics across three dimensions, where a reward\nmodel is designed to score MRPAs with the constructed ground-truth data for\ncomparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of\nMMRole-Agent and highlight the primary challenges in developing MRPAs,\nemphasizing the need for enhanced multimodal understanding and role-playing\nconsistency. The data, code, and models are all available at\nhttps://github.com/YanqiDai/MMRole.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2408.04203v2",
    "published_date": "2024-08-08 03:57:20 UTC",
    "updated_date": "2025-02-17 08:40:51 UTC"
  },
  {
    "arxiv_id": "2408.07083v1",
    "title": "Masked EEG Modeling for Driving Intention Prediction",
    "authors": [
      "Jinzhao Zhou",
      "Justin Sia",
      "Yiqun Duan",
      "Yu-Cheng Chang",
      "Yu-Kai Wang",
      "Chin-Teng Lin"
    ],
    "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular\naccidents. Although recent efforts have focused on using electroencephalography\nto detect drowsiness, helping prevent accidents caused by driving in such\nstates, seamless human-machine interaction in driving scenarios requires a more\nversatile EEG-based system. This system should be capable of understanding a\ndriver's intention while demonstrating resilience to artifacts induced by\nsudden movements. This paper pioneers a novel research direction in\nBCI-assisted driving, studying the neural patterns related to driving\nintentions and presenting a novel method for driving intention prediction. In\nparticular, our preliminary analysis of the EEG signal using independent\ncomponent analysis suggests a close relation between the intention of driving\nmaneuvers and the neural activities in central-frontal and parietal areas.\nPower spectral density analysis at a group level also reveals a notable\ndistinction among various driving intentions in the frequency domain. To\nexploit these brain dynamics, we propose a novel Masked EEG Modeling framework\nfor predicting human driving intentions, including the intention for left\nturning, right turning, and straight proceeding. Extensive experiments,\nencompassing comprehensive quantitative and qualitative assessments on public\ndataset, demonstrate the proposed method is proficient in predicting driving\nintentions across various vigilance states. Specifically, our model attains an\naccuracy of 85.19% when predicting driving intentions for drowsy subjects,\nwhich shows its promising potential for mitigating traffic accidents related to\ndrowsy driving. Notably, our method maintains over 75% accuracy when more than\nhalf of the channels are missing or corrupted, underscoring its adaptability in\nreal-life driving.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07083v1",
    "published_date": "2024-08-08 03:49:05 UTC",
    "updated_date": "2024-08-08 03:49:05 UTC"
  },
  {
    "arxiv_id": "2408.04679v1",
    "title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings",
    "authors": [
      "Jinzhao Zhou",
      "Yiqun Duan",
      "Ziyi Zhao",
      "Yu-Cheng Chang",
      "Yu-Kai Wang",
      "Thomas Do",
      "Chin-Teng Lin"
    ],
    "abstract": "Decoding linguistic information from non-invasive brain signals using EEG has\ngained increasing research attention due to its vast applicational potential.\nRecently, a number of works have adopted a generative-based framework to decode\nelectroencephalogram (EEG) signals into sentences by utilizing the power\ngenerative capacity of pretrained large language models (LLMs). However, this\napproach has several drawbacks that hinder the further development of\nlinguistic applications for brain-computer interfaces (BCIs). Specifically, the\nability of the EEG encoder to learn semantic information from EEG data remains\nquestionable, and the LLM decoder's tendency to generate sentences based on its\ntraining memory can be hard to avoid. These issues necessitate a novel approach\nfor converting EEG signals into sentences. In this paper, we propose a novel\ntwo-step pipeline that addresses these limitations and enhances the validity of\nlinguistic EEG decoding research. We first confirm that word-level semantic\ninformation can be learned from EEG data recorded during natural reading by\ntraining a Conformer encoder via a masked contrastive objective for word-level\nclassification. To achieve sentence decoding results, we employ a training-free\nretrieval method to retrieve sentences based on the predictions from the EEG\nencoder. Extensive experiments and ablation studies were conducted in this\npaper for a comprehensive evaluation of the proposed approach. Visualization of\nthe top prediction candidates reveals that our model effectively groups EEG\nsegments into semantic categories with similar meanings, thereby validating its\nability to learn patterns from unspoken EEG recordings. Despite the exploratory\nnature of this work, these results suggest that our method holds promise for\nproviding more reliable solutions for converting EEG signals into text.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04679v1",
    "published_date": "2024-08-08 03:40:25 UTC",
    "updated_date": "2024-08-08 03:40:25 UTC"
  },
  {
    "arxiv_id": "2408.04678v1",
    "title": "CREST: Effectively Compacting a Datastore For Retrieval-Based Speculative Decoding",
    "authors": [
      "Sophia Ho",
      "Jinsol Park",
      "Patrick Wang"
    ],
    "abstract": "We present CREST (Compact Retrieval-Based Speculative Decoding), a redesign\nof REST that allows it to be effectively \"compacted\". REST is a drafting\ntechnique for speculative decoding based on retrieving exact n-gram matches of\nthe most recent n tokens generated by the target LLM from a datastore. The key\nidea of CREST is to only store a subset of the smallest and most common n-grams\nin the datastore with the hope of achieving comparable performance with less\nstorage space. We found that storing a subset of n-grams both reduces storage\nspace and improves performance. CREST matches REST's accepted token length with\n10.6-13.5x less storage space and achieves a 16.5-17.1% higher acceptance\nlength than REST using the same storage space on the HumanEval and MT Bench\nbenchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04678v1",
    "published_date": "2024-08-08 03:38:49 UTC",
    "updated_date": "2024-08-08 03:38:49 UTC"
  },
  {
    "arxiv_id": "2408.04197v3",
    "title": "Pairwise Judgment Formulation for Semantic Embedding Model in Web Search",
    "authors": [
      "Mengze Hong",
      "Di Jiang",
      "Wailing Ng",
      "Zichang Guo",
      "Chen Jason Zhang"
    ],
    "abstract": "Semantic Embedding Model (SEM), a neural network-based Siamese architecture,\nis gaining momentum in information retrieval and natural language processing.\nIn order to train SEM in a supervised fashion for Web search, the search engine\nquery log is typically utilized to automatically formulate pairwise judgments\nas training data. Despite the growing application of semantic embeddings in the\nsearch engine industry, little work has been done on formulating effective\npairwise judgments for training SEM. In this paper, we make the first in-depth\ninvestigation of a wide range of strategies for generating pairwise judgments\nfor SEM. An interesting (perhaps surprising) discovery reveals that the\nconventional pairwise judgment formulation strategy wildly used in the field of\npairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.\nThrough a large-scale empirical study based on query logs and click-through\nactivities from a major commercial search engine, we demonstrate the effective\nstrategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,\nClicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >\nSkipped) in LTR. We conclude with best practices for training SEM and offer\npromising insights for future research.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04197v3",
    "published_date": "2024-08-08 03:35:35 UTC",
    "updated_date": "2025-02-02 05:54:20 UTC"
  },
  {
    "arxiv_id": "2408.05245v1",
    "title": "Improved Adaboost Algorithm for Web Advertisement Click Prediction Based on Long Short-Term Memory Networks",
    "authors": [
      "Qixuan Yu",
      "Xirui Tang",
      "Feiyang Li",
      "Zinan Cao"
    ],
    "abstract": "This paper explores an improved Adaboost algorithm based on Long Short-Term\nMemory Networks (LSTMs), which aims to improve the prediction accuracy of user\nclicks on web page advertisements. By comparing it with several common machine\nlearning algorithms, the paper analyses the advantages of the new model in ad\nclick prediction. It is shown that the improved algorithm proposed in this\npaper performs well in user ad click prediction with an accuracy of 92%, which\nis an improvement of 13.6% compared to the highest of 78.4% among the other\nthree base models. This significant improvement indicates that the algorithm is\nmore capable of capturing user behavioural characteristics and time series\npatterns. In addition, this paper evaluates the model's performance on other\nperformance metrics, including accuracy, recall, and F1 score. The results show\nthat the improved Adaboost algorithm based on LSTM is significantly ahead of\nthe traditional model in all these metrics, which further validates its\neffectiveness and superiority. Especially when facing complex and dynamically\nchanging user behaviours, the model is able to better adapt and make accurate\npredictions. In order to ensure the practicality and reliability of the model,\nthis study also focuses on the accuracy difference between the training set and\nthe test set. After validation, the accuracy of the proposed model on these two\ndatasets only differs by 1.7%, which is a small difference indicating that the\nmodel has good generalisation ability and can be effectively applied to\nreal-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05245v1",
    "published_date": "2024-08-08 03:27:02 UTC",
    "updated_date": "2024-08-08 03:27:02 UTC"
  },
  {
    "arxiv_id": "2408.04193v1",
    "title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks",
    "authors": [
      "Zepu Wang",
      "Xiaobo Ma",
      "Huajie Yang",
      "Weimin Lvu",
      "Peng Sun",
      "Sharath Chandra Guntuku"
    ],
    "abstract": "Crime forecasting is a critical component of urban analysis and essential for\nstabilizing society today. Unlike other time series forecasting problems, crime\nincidents are sparse, particularly in small regions and within specific time\nperiods. Traditional spatial-temporal deep learning models often struggle with\nthis sparsity, as they typically cannot effectively handle the non-Gaussian\nnature of crime data, which is characterized by numerous zeros and\nover-dispersed patterns. To address these challenges, we introduce a novel\napproach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial\nGraph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and\nconvolution networks to analyze spatial, temporal, and multivariate\ncorrelations, enabling the parameterization of probabilistic distributions of\ncrime incidents. By incorporating a Zero-Inflated Negative Binomial model,\nSTMGNN-ZINB effectively manages the sparse nature of crime data, enhancing\nprediction accuracy and the precision of confidence intervals. Our evaluation\non real-world datasets confirms that STMGNN-ZINB outperforms existing models,\nproviding a more reliable tool for predicting and understanding crime dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04193v1",
    "published_date": "2024-08-08 03:25:41 UTC",
    "updated_date": "2024-08-08 03:25:41 UTC"
  },
  {
    "arxiv_id": "2408.04190v1",
    "title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning",
    "authors": [
      "Heewoong Choi",
      "Sangwon Jung",
      "Hongjoon Ahn",
      "Taesup Moon"
    ],
    "abstract": "In Reinforcement Learning (RL), designing precise reward functions remains to\nbe a challenge, particularly when aligning with human intent. Preference-based\nRL (PbRL) was introduced to address this problem by learning reward models from\nhuman feedback. However, existing PbRL methods have limitations as they often\noverlook the second-order preference that indicates the relative strength of\npreference. In this paper, we propose Listwise Reward Estimation (LiRE), a\nnovel approach for offline PbRL that leverages second-order preference\ninformation by constructing a Ranked List of Trajectories (RLT), which can be\nefficiently built by using the same ternary feedback type as traditional\nmethods. To validate the effectiveness of LiRE, we propose a new offline PbRL\ndataset that objectively reflects the effect of the estimated rewards. Our\nextensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,\noutperforming state-of-the-art baselines even with modest feedback budgets and\nenjoying robustness with respect to the number of feedbacks and feedback noise.\nOur code is available at https://github.com/chwoong/LiRE",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.04190v1",
    "published_date": "2024-08-08 03:18:42 UTC",
    "updated_date": "2024-08-08 03:18:42 UTC"
  },
  {
    "arxiv_id": "2408.04181v1",
    "title": "EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI",
    "authors": [
      "Duo Zhong",
      "Bojing Li",
      "Xiang Chen",
      "Chenchen Liu"
    ],
    "abstract": "The increasing prevalence of adversarial attacks on Artificial Intelligence\n(AI) systems has created a need for innovative security measures. However, the\ncurrent methods of defending against these attacks often come with a high\ncomputing cost and require back-end processing, making real-time defense\nchallenging. Fortunately, there have been remarkable advancements in\nedge-computing, which make it easier to deploy neural networks on edge devices.\nBuilding upon these advancements, we propose an edge framework design to enable\nuniversal and efficient detection of adversarial attacks. This framework\nincorporates an attention-based adversarial detection methodology and a\nlightweight detection network formation, making it suitable for a wide range of\nneural networks and can be deployed on edge devices. To assess the\neffectiveness of our proposed framework, we conducted evaluations on five\nneural networks. The results indicate an impressive 97.43% F-score can be\nachieved, demonstrating the framework's proficiency in detecting adversarial\nattacks. Moreover, our proposed framework also exhibits significantly reduced\ncomputing complexity and cost in comparison to previous detection methods. This\naspect is particularly beneficial as it ensures that the defense mechanism can\nbe efficiently implemented in real-time on-edge devices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04181v1",
    "published_date": "2024-08-08 02:57:55 UTC",
    "updated_date": "2024-08-08 02:57:55 UTC"
  },
  {
    "arxiv_id": "2408.04174v1",
    "title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech",
    "authors": [
      "Khai Le-Duc",
      "Quy-Anh Dang",
      "Tan-Hanh Pham",
      "Truong-Son Hy"
    ],
    "abstract": "Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, 32 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.04174v1",
    "published_date": "2024-08-08 02:36:04 UTC",
    "updated_date": "2024-08-08 02:36:04 UTC"
  },
  {
    "arxiv_id": "2408.04168v3",
    "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions",
    "authors": [
      "Qingbin Zeng",
      "Qinglong Yang",
      "Shunan Dong",
      "Heming Du",
      "Liang Zheng",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "This paper considers a scenario in city navigation: an AI agent is provided\nwith language descriptions of the goal location with respect to some well-known\nlandmarks; By only observing the scene around, including recognizing landmarks\nand road network connections, the agent has to make decisions to navigate to\nthe goal location without instructions. This problem is very challenging,\nbecause it requires agent to establish self-position and acquire spatial\nrepresentation of complex urban environment, where landmarks are often\ninvisible. In the absence of navigation instructions, such abilities are vital\nfor the agent to make high-quality decisions in long-range city navigation.\nWith the emergent reasoning ability of large language models (LLMs), a tempting\nbaseline is to prompt LLMs to \"react\" on each observation and make decisions\naccordingly. However, this baseline has very poor performance that the agent\noften repeatedly visits same locations and make short-sighted, inconsistent\ndecisions. To address these issues, this paper introduces a novel agentic\nworkflow featured by its abilities to perceive, reflect and plan. Specifically,\nwe find LLaVA-7B can be fine-tuned to perceive the direction and distance of\nlandmarks with sufficient accuracy for city navigation. Moreover, reflection is\nachieved through a memory mechanism, where past experiences are stored and can\nbe retrieved with current perception for effective decision argumentation.\nPlanning uses reflection results to produce long-term plans, which can avoid\nshort-sighted decisions in long-range navigation. We show the designed workflow\nsignificantly improves navigation ability of the LLM agent compared with the\nstate-of-the-art baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.04168v3",
    "published_date": "2024-08-08 02:28:43 UTC",
    "updated_date": "2024-10-17 06:43:13 UTC"
  },
  {
    "arxiv_id": "2408.12605v1",
    "title": "Convolutional Neural Networks for Predictive Modeling of Lung Disease",
    "authors": [
      "Yingbin Liang",
      "Xiqing Liu",
      "Haohao Xia",
      "Yiru Cang",
      "Zitao Zheng",
      "Yuanfang Yang"
    ],
    "abstract": "In this paper, Pro-HRnet-CNN, an innovative model combining HRNet and\nvoid-convolution techniques, is proposed for disease prediction under lung\nimaging. Through the experimental comparison on the authoritative LIDC-IDRI\ndataset, we found that compared with the traditional ResNet-50, Pro-HRnet-CNN\nshowed better performance in the feature extraction and recognition of\nsmall-size nodules, significantly improving the detection accuracy.\nParticularly within the domain of detecting smaller targets, the model has\nexhibited a remarkable enhancement in accuracy, thereby pioneering an\ninnovative avenue for the early identification and prognostication of pulmonary\nconditions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12605v1",
    "published_date": "2024-08-08 01:58:46 UTC",
    "updated_date": "2024-08-08 01:58:46 UTC"
  },
  {
    "arxiv_id": "2408.04154v1",
    "title": "The Data Addition Dilemma",
    "authors": [
      "Judy Hanwen Shen",
      "Inioluwa Deborah Raji",
      "Irene Y. Chen"
    ],
    "abstract": "In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Machine Learning For Health Care 2024 (MLHC)",
    "pdf_url": "http://arxiv.org/pdf/2408.04154v1",
    "published_date": "2024-08-08 01:42:31 UTC",
    "updated_date": "2024-08-08 01:42:31 UTC"
  },
  {
    "arxiv_id": "2408.12604v1",
    "title": "Generational Computation Reduction in Informal Counterexample-Driven Genetic Programming",
    "authors": [
      "Thomas Helmuth",
      "Edward Pantridge",
      "James Gunder Frazier",
      "Lee Spector"
    ],
    "abstract": "Counterexample-driven genetic programming (CDGP) uses specifications provided\nas formal constraints to generate the training cases used to evaluate evolving\nprograms. It has also been extended to combine formal constraints and\nuser-provided training data to solve symbolic regression problems. Here we show\nhow the ideas underlying CDGP can also be applied using only user-provided\ntraining data, without formal specifications. We demonstrate the application of\nthis method, called ``informal CDGP,'' to software synthesis problems. Our\nresults show that informal CDGP finds solutions faster (i.e. with fewer program\nexecutions) than standard GP. Additionally, we propose two new variants to\ninformal CDGP, and find that one produces significantly more successful runs on\nabout half of the tested problems. Finally, we study whether the addition of\ncounterexample training cases to the training set is useful by comparing\ninformal CDGP to using a static subsample of the training set, and find that\nthe addition of counterexamples significantly improves performance.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12604v1",
    "published_date": "2024-08-08 01:06:28 UTC",
    "updated_date": "2024-08-08 01:06:28 UTC"
  },
  {
    "arxiv_id": "2408.04140v1",
    "title": "UNLEARN Efficient Removal of Knowledge in Large Language Models",
    "authors": [
      "Tyler Lizzo",
      "Larry Heck"
    ],
    "abstract": "Given the prevalence of large language models (LLMs) and the prohibitive cost\nof training these models from scratch, dynamically forgetting specific\nknowledge e.g., private or proprietary, without retraining the model has become\nan important capability. This paper proposes a novel method to achieve this\nobjective called UNLEARN. The approach builds upon subspace methods to identify\nand specifically target the removal of knowledge without adversely affecting\nother knowledge in the LLM. Results demonstrate 96% of targeted knowledge can\nbe forgotten while maintaining performance on other knowledge within 2.5% of\nthe original model, significantly outperforming the discriminatory abilities of\nthe previous state-of-the-art. A dual method called LEARN is also proposed for\ntargeted knowledge addition. Results show LEARN can match the fine-tuning\naccuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2408.04140v1",
    "published_date": "2024-08-08 00:53:31 UTC",
    "updated_date": "2024-08-08 00:53:31 UTC"
  },
  {
    "arxiv_id": "2408.04138v1",
    "title": "Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering",
    "authors": [
      "Haoran Yu",
      "Chang Yu",
      "Zihan Wang",
      "Dongxian Zou",
      "Hao Qin"
    ],
    "abstract": "In recent years, the application of Large Language Models (LLMs) in\nhealthcare has shown significant promise in improving the accessibility and\ndissemination of medical knowledge. This paper presents a detailed study of\nvarious LLMs trained on the MedQuAD medical question-answering dataset, with a\nfocus on identifying the most effective model for providing accurate medical\ninformation. Among the models tested, the Sentence-t5 combined with Mistral 7B\ndemonstrated superior performance, achieving a precision score of 0.762. This\nmodel's enhanced capabilities are attributed to its advanced pretraining\ntechniques, robust architecture, and effective prompt construction\nmethodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B\nmodel excels in understanding and generating precise medical answers. Our\nfindings highlight the potential of integrating sophisticated LLMs in medical\ncontexts to facilitate efficient and accurate medical knowledge retrieval, thus\nsignificantly enhancing patient education and support.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "received by IEEE ICPICS",
    "pdf_url": "http://arxiv.org/pdf/2408.04138v1",
    "published_date": "2024-08-08 00:35:39 UTC",
    "updated_date": "2024-08-08 00:35:39 UTC"
  }
]