[
  {
    "arxiv_id": "2509.01842v3",
    "title": "GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping",
    "authors": [
      "Qifu Wen",
      "Xi Zeng",
      "Zihan Zhou",
      "Shuaijun Liu",
      "Mehdi Hosseinzadeh",
      "Ningxin Su",
      "Reza Rawassizadeh"
    ],
    "abstract": "Early stopping monitors global validation loss and halts all parameter updates simultaneously, which is computationally costly for large transformers due to the extended time required for validation inference. We propose \\textit{GradES}, a novel gradient-based early stopping approach that operates within transformer components (attention projections and Feed-Forward layer matrices). We found that different components converge at varying rates during fine-tuning for both language and vision-language models. \\textit{GradES} tracks the magnitude of gradient changes in backpropagation for these matrices during training. When a projection matrix's magnitude of gradient changes fall below a convergence threshold $τ$, we exclude that projection matrix from further updates individually, eliminating costly validation passes while allowing slow converging matrices to continue learning. \\textit{GradES} speeds up training time by 1.57--7.22$\\times$ while simultaneously enhancing generalization through early prevention of overfitting, resulting in 1.2\\% higher average accuracy in language tasks and 3.88\\% on multimodal benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01842v3",
    "published_date": "2025-09-01 23:51:12 UTC",
    "updated_date": "2025-10-16 18:38:51 UTC"
  },
  {
    "arxiv_id": "2509.01839v5",
    "title": "HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices",
    "authors": [
      "Akis Nousias",
      "Stavros Nousias"
    ],
    "abstract": "Currently, prominent Transformer architectures applied on graphs and meshes for shape analysis tasks employ traditional attention layers that heavily utilize spectral features requiring costly eigenvalue decomposition-based methods. To encode the mesh structure, these methods derive positional embeddings, that heavily rely on eigenvalue decomposition based operations, e.g. on the Laplacian matrix, or on heat-kernel signatures, which are then concatenated to the input features. This paper proposes a novel approach inspired by the explicit construction of the Hodge Laplacian operator in Discrete Exterior Calculus as a product of discrete Hodge operators and exterior derivatives, i.e. $(L := \\star_0^{-1} d_0^T \\star_1 d_0)$. We adjust the Transformer architecture in a novel deep learning layer that utilizes the multi-head attention mechanism to approximate Hodge matrices $\\star_0$, $\\star_1$ and $\\star_2$ and learn families of discrete operators $L$ that act on mesh vertices, edges and faces. Our approach results in a computationally-efficient architecture that achieves comparable performance in mesh segmentation and classification tasks, through a direct learning framework, while eliminating the need for costly eigenvalue decomposition operations or complex preprocessing operations.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "15 pages, 13 figures, 10 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01839v5",
    "published_date": "2025-09-01 23:43:43 UTC",
    "updated_date": "2025-12-05 21:47:13 UTC"
  },
  {
    "arxiv_id": "2509.01838v1",
    "title": "Goal-Conditioned Reinforcement Learning for Data-Driven Maritime Navigation",
    "authors": [
      "Vaishnav Vaidheeswaran",
      "Dilith Jayakody",
      "Samruddhi Mulay",
      "Anand Lo",
      "Md Mahbub Alam",
      "Gabriel Spadon"
    ],
    "abstract": "Routing vessels through narrow and dynamic waterways is challenging due to changing environmental conditions and operational constraints. Existing vessel-routing studies typically fail to generalize across multiple origin-destination pairs and do not exploit large-scale, data-driven traffic graphs. In this paper, we propose a reinforcement learning solution for big maritime data that can learn to find a route across multiple origin-destination pairs while adapting to different hexagonal grid resolutions. Agents learn to select direction and speed under continuous observations in a multi-discrete action space. A reward function balances fuel efficiency, travel time, wind resistance, and route diversity, using an Automatic Identification System (AIS)-derived traffic graph with ERA5 wind fields. The approach is demonstrated in the Gulf of St. Lawrence, one of the largest estuaries in the world. We evaluate configurations that combine Proximal Policy Optimization with recurrent networks, invalid-action masking, and exploration strategies. Our experiments demonstrate that action masking yields a clear improvement in policy performance and that supplementing penalty-only feedback with positive shaping rewards produces additional gains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01838v1",
    "published_date": "2025-09-01 23:42:16 UTC",
    "updated_date": "2025-09-01 23:42:16 UTC"
  },
  {
    "arxiv_id": "2509.01836v1",
    "title": "Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment",
    "authors": [
      "Md Mahbub Alam",
      "Jose F. Rodrigues-Jr",
      "Gabriel Spadon"
    ],
    "abstract": "Accurate vessel trajectory prediction is essential for enhancing situational awareness and preventing collisions. Still, existing data-driven models are constrained mainly to single-vessel forecasting, overlooking vessel interactions, navigation rules, and explicit collision risk assessment. We present a transformer-based framework for multi-vessel trajectory prediction with integrated collision risk analysis. For a given target vessel, the framework identifies nearby vessels. It jointly predicts their future trajectories through parallel streams encoding kinematic and derived physical features, causal convolutions for temporal locality, spatial transformations for positional encoding, and hybrid positional embeddings that capture both local motion patterns and long-range dependencies. Evaluated on large-scale real-world AIS data using joint multi-vessel metrics, the model demonstrates superior forecasting capabilities beyond traditional single-vessel displacement errors. By simulating interactions among predicted trajectories, the framework further quantifies potential collision risks, offering actionable insights to strengthen maritime safety and decision support.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01836v1",
    "published_date": "2025-09-01 23:38:01 UTC",
    "updated_date": "2025-09-01 23:38:01 UTC"
  },
  {
    "arxiv_id": "2509.01824v1",
    "title": "Journalists' Perceptions of Artificial Intelligence and Disinformation Risks",
    "authors": [
      "Urko Peña-Alonso",
      "Simón Peña-Fernández",
      "Koldobika Meso-Ayerdi"
    ],
    "abstract": "This study examines journalists' perceptions of the impact of artificial intelligence (AI) on disinformation, a growing concern in journalism due to the rapid expansion of generative AI and its influence on news production and media organizations. Using a quantitative approach, a structured survey was administered to 504 journalists in the Basque Country, identified through official media directories and with the support of the Basque Association of Journalists. This survey, conducted online and via telephone between May and June 2024, included questions on sociodemographic and professional variables, as well as attitudes toward AI's impact on journalism. The results indicate that a large majority of journalists (89.88%) believe AI will considerably or significantly increase the risks of disinformation, and this perception is consistent across genders and media types, but more pronounced among those with greater professional experience. Statistical analyses reveal a significant association between years of experience and perceived risk, and between AI use and risk perception. The main risks identified are the difficulty in detecting false content and deepfakes, and the risk of obtaining inaccurate or erroneous data. Co-occurrence analysis shows that these risks are often perceived as interconnected. These findings highlight the complex and multifaceted concerns of journalists regarding AI's role in the information ecosystem.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "18 pages, 5 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01824v1",
    "published_date": "2025-09-01 23:06:15 UTC",
    "updated_date": "2025-09-01 23:06:15 UTC"
  },
  {
    "arxiv_id": "2509.01822v1",
    "title": "When LLM Meets Time Series: Can LLMs Perform Multi-Step Time Series Reasoning and Inference",
    "authors": [
      "Wen Ye",
      "Jinbo Liu",
      "Defu Cao",
      "Wei Yang",
      "Yan Liu"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has sparked growing interest in their application to time series analysis tasks. However, their ability to perform complex reasoning over temporal data in real-world application domains remains underexplored. To move toward this goal, a first step is to establish a rigorous benchmark dataset for evaluation. In this work, we introduce the TSAIA Benchmark, a first attempt to evaluate LLMs as time-series AI assistants. To ensure both scientific rigor and practical relevance, we surveyed over 20 academic publications and identified 33 real-world task formulations. The benchmark encompasses a broad spectrum of challenges, ranging from constraint-aware forecasting to anomaly detection with threshold calibration: tasks that require compositional reasoning and multi-step time series analysis. The question generator is designed to be dynamic and extensible, supporting continuous expansion as new datasets or task types are introduced. Given the heterogeneous nature of the tasks, we adopt task-specific success criteria and tailored inference-quality metrics to ensure meaningful evaluation for each task. We apply this benchmark to assess eight state-of-the-art LLMs under a unified evaluation protocol. Our analysis reveals limitations in current models' ability to assemble complex time series analysis workflows, underscoring the need for specialized methodologies for domain-specific adaptation. Our benchmark is available at https://huggingface.co/datasets/Melady/TSAIA, and the code is available at https://github.com/USC-Melady/TSAIA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01822v1",
    "published_date": "2025-09-01 22:58:57 UTC",
    "updated_date": "2025-09-01 22:58:57 UTC"
  },
  {
    "arxiv_id": "2509.10507v1",
    "title": "An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms",
    "authors": [
      "Vadim Allayev",
      "Mahbubur Rahman"
    ],
    "abstract": "Internet of Intelligent Things (IoIT), an emerging field, combines the utility of Internet of Things (IoT) devices with the innovation of embedded AI algorithms. However, it does not come without challenges, and struggles regarding available computing resources, energy supply, and storage limitations. In particular, many impediments to IoIT are linked to the energy-efficient deployment of machine learning (ML)/deep learning (DL) models in embedded devices. Research has been conducted to design energy-efficient IoIT platforms, but these papers often focus on centralized systems, in which some central entity processes all the data and coordinates actions. This can be problematic, e.g., serve as bottleneck or lead to security concerns. In a decentralized system, nodes/devices would self-organize and make their own decisions. Therefore, to address such issues, we propose a heterogeneous, decentralized sensing and monitoring IoIT peer-to-peer mesh network system model. Nodes in the network will coordinate towards several optimization goals: reliability, energy efficiency, and latency. The system employs federated learning to train nodes in a distributed manner, metaheuristics to optimize task allocation and routing paths, and multi-objective optimization to balance conflicting performance goals.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "11 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.10507v1",
    "published_date": "2025-09-01 22:54:01 UTC",
    "updated_date": "2025-09-01 22:54:01 UTC"
  },
  {
    "arxiv_id": "2509.01814v1",
    "title": "Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts",
    "authors": [
      "Shreyas Tirumala",
      "Nishant Jain",
      "Danny D. Leybzon",
      "Trent D. Buskirk"
    ],
    "abstract": "Transformer-based Large Language Models (LLMs) have paved the way for \"AI interviewers\" that can administer voice-based surveys with respondents in real-time. This position paper reviews emerging evidence to understand when such AI interviewing systems are fit for purpose for collecting data within quantitative and qualitative research contexts. We evaluate the capabilities of AI interviewers as well as current Interactive Voice Response (IVR) systems across two dimensions: input/output performance (i.e., speech recognition, answer recording, emotion handling) and verbal reasoning (i.e., ability to probe, clarify, and handle branching logic). Field studies suggest that AI interviewers already exceed IVR capabilities for both quantitative and qualitative data collection, but real-time transcription error rates, limited emotion detection abilities, and uneven follow-up quality indicate that the utility, use and adoption of current AI interviewer technology may be context-dependent for qualitative data collection efforts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01814v1",
    "published_date": "2025-09-01 22:44:57 UTC",
    "updated_date": "2025-09-01 22:44:57 UTC"
  },
  {
    "arxiv_id": "2509.02640v2",
    "title": "Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge",
    "authors": [
      "Biwen Meng",
      "Xi Long",
      "Jingxin Liu"
    ],
    "abstract": "Atypical mitotic figures (AMFs) are clinically relevant indicators of abnormal cell division, yet their reliable detection remains challenging due to morphological ambiguity and scanner variability. In this work, we investigated three variants of adapting the pathology foundation model UNI2 for the MIDOG2025 Track 2 challenge: (1) LoRA + UNI2, (2) VPT + UNI2 + Vahadane Normalizer, and (3) VPT + UNI2 + GRL + Stain TTA. We observed that the integration of Visual Prompt Tuning (VPT) with stain normalization techniques contributed to improved generalization. The best robustness was achieved by further incorporating test-time augmentation (TTA) with Vahadane and Macenko stain normalization. Our final submission achieved a balanced accuracy of 0.8837 and an ROC-AUC of 0.9513 on the preliminary leaderboard, ranking within the top 10 teams. These results suggest that prompt-based adaptation combined with stain-normalization TTA offers a promising strategy for atypical mitosis classification under diverse imaging conditions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02640v2",
    "published_date": "2025-09-01 22:42:53 UTC",
    "updated_date": "2025-09-05 14:00:52 UTC"
  },
  {
    "arxiv_id": "2509.01812v1",
    "title": "Quantum Machine Learning for UAV Swarm Intrusion Detection",
    "authors": [
      "Kuan-Cheng Chen",
      "Samuel Yen-Chi Chen",
      "Tai-Yue Li",
      "Chen-Yu Liu",
      "Kin K. Leung"
    ],
    "abstract": "Intrusion detection in unmanned-aerial-vehicle (UAV) swarms is complicated by high mobility, non-stationary traffic, and severe class imbalance. Leveraging a 120 k-flow simulation corpus that covers five attack types, we benchmark three quantum-machine-learning (QML) approaches - quantum kernels, variational quantum neural networks (QNNs), and hybrid quantum-trained neural networks (QT-NNs) - against strong classical baselines. All models consume an 8-feature flow representation and are evaluated under identical preprocessing, balancing, and noise-model assumptions. We analyse the influence of encoding strategy, circuit depth, qubit count, and shot noise, reporting accuracy, macro-F1, ROC-AUC, Matthews correlation, and quantum-resource footprints. Results reveal clear trade-offs: quantum kernels and QT-NNs excel in low-data, nonlinear regimes, while deeper QNNs suffer from trainability issues, and CNNs dominate when abundant data offset their larger parameter count. The complete codebase and dataset partitions are publicly released to enable reproducible QML research in network security.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01812v1",
    "published_date": "2025-09-01 22:36:30 UTC",
    "updated_date": "2025-09-01 22:36:30 UTC"
  },
  {
    "arxiv_id": "2509.10504v2",
    "title": "Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs",
    "authors": [
      "Mianchu Wang",
      "Giovanni Montana"
    ],
    "abstract": "Retrosynthesis planning aims to decompose target molecules into available building blocks, forming a synthetic tree where each internal node represents an intermediate compound and each leaf ideally corresponds to a purchasable reactant. However, this tree becomes invalid if any leaf node is not a valid building block, making the planning process vulnerable to the \"weakest link\" in the synthetic route. Existing methods often optimise for average performance across branches, failing to account for this worst-case sensitivity. In this paper, we reframe retrosynthesis as a worst-path optimisation problem within tree-structured Markov Decision Processes (MDPs). We prove that this formulation admits a unique optimal solution and provides monotonic improvement guarantees. Building on this insight, we introduce Interactive Retrosynthesis Planning (InterRetro), a method that interacts with the tree MDP, learns a value function for worst-path outcomes, and improves its policy through self-imitation, preferentially reinforcing past decisions with high estimated advantage. Empirically, InterRetro achieves state-of-the-art results - solving 100% of targets on the Retro*-190 benchmark, shortening synthetic routes by 4.9%, and achieving promising performance using only 10% of the training data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.10504v2",
    "published_date": "2025-09-01 21:44:14 UTC",
    "updated_date": "2025-11-17 19:17:48 UTC"
  },
  {
    "arxiv_id": "2509.01794v2",
    "title": "A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics",
    "authors": [
      "Trusting Inekwe",
      "Winnie Mkandawire",
      "Emmanuel Agu",
      "Andres Colubri"
    ],
    "abstract": "The COVID-19 pandemic disrupted healthcare systems worldwide, disproportionately impacting individuals with chronic conditions such as cardiovascular disease (CVD). These disruptions -- through delayed care and behavioral changes, affected key CVD biomarkers, including LDL cholesterol (LDL-C), HbA1c, BMI, and systolic blood pressure (SysBP). Accurate modeling of these changes is crucial for predicting disease progression and guiding preventive care. However, prior work has not addressed multi-target prediction of CVD biomarker from Electronic Health Records (EHRs) using machine learning (ML), while jointly capturing biomarker interdependencies, temporal patterns, and predictive uncertainty. In this paper, we propose MBT-CB, a Multi-target Bayesian Transformer (MBT) with pre-trained BERT-based transformer framework to jointly predict LDL-C, HbA1c, BMI and SysBP CVD biomarkers from EHR data. The model leverages Bayesian Variational Inference to estimate uncertainties, embeddings to capture temporal relationships and a DeepMTR model to capture biomarker inter-relationships. We evaluate MBT-CT on retrospective EHR data from 3,390 CVD patient records (304 unique patients) in Central Massachusetts during the Covid-19 pandemic. MBT-CB outperformed a comprehensive set of baselines including other BERT-based ML models, achieving an MAE of 0.00887, RMSE of 0.0135 and MSE of 0.00027, while effectively capturing data and model uncertainty, patient biomarker inter-relationships, and temporal dynamics via its attention and embedding mechanisms. MBT-CB's superior performance highlights its potential to improve CVD biomarker prediction and support clinical decision-making during pandemics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01794v2",
    "published_date": "2025-09-01 21:43:36 UTC",
    "updated_date": "2025-11-06 02:39:18 UTC"
  },
  {
    "arxiv_id": "2509.01793v2",
    "title": "STORI: A Benchmark and Taxonomy for Stochastic Environments",
    "authors": [
      "Aryan Amit Barsainyan",
      "Jing Yu Lim",
      "Dianbo Liu"
    ],
    "abstract": "Reinforcement learning (RL) techniques have achieved impressive performance on simulated benchmarks such as Atari100k, yet recent advances remain largely confined to simulation and show limited transfer to real-world domains. A central obstacle is environmental stochasticity, as real systems involve noisy observations, unpredictable dynamics, and non-stationary conditions that undermine the stability of current methods. Existing benchmarks rarely capture these uncertainties and favor simplified settings where algorithms can be tuned to succeed. The absence of a well-defined taxonomy of stochasticity further complicates evaluation, as robustness to one type of stochastic perturbation, such as sticky actions, does not guarantee robustness to other forms of uncertainty. To address this critical gap, we introduce STORI (STOchastic-ataRI), a benchmark that systematically incorporates diverse stochastic effects and enables rigorous evaluation of RL techniques under different forms of uncertainty. We propose a comprehensive five-type taxonomy of environmental stochasticity and demonstrate systematic vulnerabilities in state-of-the-art model-based RL algorithms through targeted evaluation of DreamerV3 and STORM. Our findings reveal that world models dramatically underestimate environmental variance, struggle with action corruption, and exhibit unreliable dynamics under partial observability. We release the code and benchmark publicly at https://github.com/ARY2260/stori, providing a unified framework for developing more robust RL systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "v2. New mathematical formulation and renamed notation; added additional experiments and a detailed analytical case study on error behaviors in world models under different stochasticity types; link to code repository for reproducibility: https://github.com/ARY2260/stori",
    "pdf_url": "https://arxiv.org/pdf/2509.01793v2",
    "published_date": "2025-09-01 21:43:22 UTC",
    "updated_date": "2025-10-03 06:53:07 UTC"
  },
  {
    "arxiv_id": "2509.01791v2",
    "title": "E-PhishGen: Unlocking Novel Research in Phishing Email Detection",
    "authors": [
      "Luca Pajola",
      "Eugenio Caripoti",
      "Stefan Banzer",
      "Simeone Pizzi",
      "Mauro Conti",
      "Giovanni Apruzzese"
    ],
    "abstract": "Every day, our inboxes are flooded with unsolicited emails, ranging between annoying spam to more subtle phishing scams. Unfortunately, despite abundant prior efforts proposing solutions achieving near-perfect accuracy, the reality is that countering malicious emails still remains an unsolved dilemma.\n  This \"open problem\" paper carries out a critical assessment of scientific works in the context of phishing email detection. First, we focus on the benchmark datasets that have been used to assess the methods proposed in research. We find that most prior work relied on datasets containing emails that -- we argue -- are not representative of current trends, and mostly encompass the English language. Based on this finding, we then re-implement and re-assess a variety of detection methods reliant on machine learning (ML), including large-language models (LLM), and release all of our codebase -- an (unfortunately) uncommon practice in related research. We show that most such methods achieve near-perfect performance when trained and tested on the same dataset -- a result which intrinsically hinders development (how can future research outperform methods that are already near perfect?). To foster the creation of \"more challenging benchmarks\" that reflect current phishing trends, we propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate novel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a novel phishing-email detection dataset containing 16616 emails in three languages. We use E-PhishLLM to test the detectors we considered, showing a much lower performance than that achieved on existing benchmarks -- indicating a larger room for improvement. We also validate the quality of E-PhishLLM with a user study (n=30). To sum up, we show that phishing email detection is still an open problem -- and provide the means to tackle such a problem by future research.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ACM AISec '25",
    "pdf_url": "https://arxiv.org/pdf/2509.01791v2",
    "published_date": "2025-09-01 21:41:34 UTC",
    "updated_date": "2025-09-15 13:13:33 UTC"
  },
  {
    "arxiv_id": "2509.01790v1",
    "title": "Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs",
    "authors": [
      "Andong Hua",
      "Kenan Tang",
      "Chenhe Gu",
      "Jindong Gu",
      "Eric Wong",
      "Yao Qin"
    ],
    "abstract": "Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e., repeating something written or spoken using different words) leads to significant changes in large language model (LLM) performance, has been widely accepted as a core limitation of LLMs. In this work, we revisit this issue and ask: Is the widely reported high prompt sensitivity truly an inherent weakness of LLMs, or is it largely an artifact of evaluation processes? To answer this question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family) across 6 benchmarks, including both multiple-choice and open-ended tasks on 12 diverse prompt templates. We find that much of the prompt sensitivity stems from heuristic evaluation methods, including log-likelihood scoring and rigid answer matching, which often overlook semantically correct responses expressed through alternative phrasings, such as synonyms or paraphrases. When we adopt LLM-as-a-Judge evaluations, we observe a substantial reduction in performance variance and a consistently higher correlation in model rankings across prompts. Our findings suggest that modern LLMs are more robust to prompt templates than previously believed, and that prompt sensitivity may be more an artifact of evaluation than a flaw in the models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025 Main Conference",
    "pdf_url": "https://arxiv.org/pdf/2509.01790v1",
    "published_date": "2025-09-01 21:38:28 UTC",
    "updated_date": "2025-09-01 21:38:28 UTC"
  },
  {
    "arxiv_id": "2509.01787v3",
    "title": "AHAMask: Reliable Task Specification for Large Audio Language Models without Instructions",
    "authors": [
      "Yiwei Guo",
      "Bohan Li",
      "Hankun Wang",
      "Zhihan Li",
      "Shuai Wang",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "Although current large audio language models (LALMs) extend text large language models (LLMs) with generic acoustic understanding abilities, they usually suffer from prompt sensitivity, where different instructions of the same intention can yield drastically different outcomes. In this work, we propose AHAMask, where we simply mask some of the attention heads in the decoder-only LLM backbone of LALMs, to trigger specific acoustic task functionalities without instructions. These masks are efficiently obtained by training on an LALM, with the number of trainable parameters equal to the attention head count in its LLM backbone. We show by experiments that applying such selective attention head masks achieves comparable or even better performance than using instructions, either on single or composite tasks. Besides achieving reliable acoustic task specification for LALMs, this also reveals that LALMs exhibit certain \"functional pathways\" in their attention heads.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "15 pages, 10 tables, 6 figures. This is the camera ready version for AAAI 2026, plus an appendix for supplementary experimental details and results",
    "pdf_url": "https://arxiv.org/pdf/2509.01787v3",
    "published_date": "2025-09-01 21:33:22 UTC",
    "updated_date": "2025-11-29 07:18:43 UTC"
  },
  {
    "arxiv_id": "2509.02639v1",
    "title": "Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration",
    "authors": [
      "Hojjat Torabi Goudarzi",
      "Maziyar Baran Pouyan"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into cellular heterogeneity, enabling detailed analysis of complex biological systems at single-cell resolution. However, the high dimensionality and technical noise inherent in scRNA-seq data pose significant analytical challenges. While current embedding methods focus primarily on gene expression levels, they often overlook crucial gene-gene interactions that govern cellular identity and function. To address this limitation, we present a novel embedding approach that integrates both gene expression profiles and data-driven gene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG) using random forest models to capture regulatory relationships between genes, while simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent expression similarities between cells. These graphs are then combined into an Enriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural network to compute cell embeddings. By incorporating both expression levels and gene-gene interactions, our approach provides a more comprehensive representation of cellular states. Extensive evaluation across multiple datasets demonstrates that our method enhances the detection of rare cell populations and improves downstream analyses such as visualization, clustering, and trajectory inference. This integrated approach represents a significant advance in single-cell data analysis, offering a more complete framework for understanding cellular diversity and dynamics.",
    "categories": [
      "q-bio.GN",
      "cs.AI"
    ],
    "primary_category": "q-bio.GN",
    "comment": "33 pages, 9 figures, article",
    "pdf_url": "https://arxiv.org/pdf/2509.02639v1",
    "published_date": "2025-09-01 21:19:27 UTC",
    "updated_date": "2025-09-01 21:19:27 UTC"
  },
  {
    "arxiv_id": "2509.01772v1",
    "title": "chDzDT: Word-level morphology-aware language model for Algerian social media text",
    "authors": [
      "Abdelkrime Aries"
    ],
    "abstract": "Pre-trained language models (PLMs) have substantially advanced natural language processing by providing context-sensitive text representations. However, the Algerian dialect remains under-represented, with few dedicated models available. Processing this dialect is challenging due to its complex morphology, frequent code-switching, multiple scripts, and strong lexical influences from other languages. These characteristics complicate tokenization and reduce the effectiveness of conventional word- or subword-level approaches.\n  To address this gap, we introduce chDzDT, a character-level pre-trained language model tailored for Algerian morphology. Unlike conventional PLMs that rely on token sequences, chDzDT is trained on isolated words. This design allows the model to encode morphological patterns robustly, without depending on token boundaries or standardized orthography. The training corpus draws from diverse sources, including YouTube comments, French, English, and Berber Wikipedia, as well as the Tatoeba project. It covers multiple scripts and linguistic varieties, resulting in a substantial pre-training workload.\n  Our contributions are threefold: (i) a detailed morphological analysis of Algerian dialect using YouTube comments; (ii) the construction of a multilingual Algerian lexicon dataset; and (iii) the development and extensive evaluation of a character-level PLM as a morphology-focused encoder for downstream tasks. The proposed approach demonstrates the potential of character-level modeling for morphologically rich, low-resource dialects and lays a foundation for more inclusive and adaptable NLP systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01772v1",
    "published_date": "2025-09-01 21:09:55 UTC",
    "updated_date": "2025-09-01 21:09:55 UTC"
  },
  {
    "arxiv_id": "2509.02637v1",
    "title": "A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection",
    "authors": [
      "Yasemin Topuz",
      "M. Taha Gökcan",
      "Serdar Yıldız",
      "Songül Varlı"
    ],
    "abstract": "Mitotic figure detection is a crucial task in computational pathology, as mitotic activity serves as a strong prognostic marker for tumor aggressiveness. However, domain variability that arises from differences in scanners, tissue types, and staining protocols poses a major challenge to the robustness of automated detection methods. In this study, we introduce SDF-YOLO (Single Detect Focused YOLO), a lightweight yet domain-robust detection framework designed specifically for small, rare targets such as mitotic figures. The model builds on YOLOv11 with task-specific modifications, including a single detection head aligned with mitotic figure scale, coordinate attention to enhance positional sensitivity, and improved cross-channel feature mixing. Experiments were conducted on three datasets that span human and canine tumors: MIDOG ++, canine cutaneous mast cell tumor (CCMCT), and canine mammary carcinoma (CMC). When submitted to the preliminary test set for the MIDOG2025 challenge, SDF-YOLO achieved an average precision (AP) of 0.799, with a precision of 0.758, a recall of 0.775, an F1 score of 0.766, and an FROC-AUC of 5.793, demonstrating both competitive accuracy and computational efficiency. These results indicate that SDF-YOLO provides a reliable and efficient framework for robust mitotic figure detection across diverse domains.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02637v1",
    "published_date": "2025-09-01 20:41:48 UTC",
    "updated_date": "2025-09-01 20:41:48 UTC"
  },
  {
    "arxiv_id": "2509.04498v2",
    "title": "Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations",
    "authors": [
      "Krithi Shailya",
      "Akhilesh Kumar Mishra",
      "Gokul S Krishnan",
      "Balaraman Ravindran"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used as daily recommendation systems for tasks like education planning, yet their recommendations risk perpetuating societal biases. This paper empirically examines geographic, demographic, and economic biases in university and program suggestions from three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360 simulated user profiles varying by gender, nationality, and economic status, we analyze over 25,000 recommendations. Results show strong biases: institutions in the Global North are disproportionately favored, recommendations often reinforce gender stereotypes, and institutional repetition is prevalent. While LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities across 58 countries, systemic disparities persist. To quantify these issues, we propose a novel, multi-dimensional evaluation framework that goes beyond accuracy by measuring demographic and geographic representation. Our findings highlight the urgent need for bias consideration in educational LMs to ensure equitable global access to higher education.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at IJCNLP-AACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2509.04498v2",
    "published_date": "2025-09-01 19:51:06 UTC",
    "updated_date": "2025-11-12 05:50:36 UTC"
  },
  {
    "arxiv_id": "2509.04497v1",
    "title": "A Narrative-Driven Computational Framework for Clinician Burnout Surveillance",
    "authors": [
      "Syed Ahmad Chan Bukhari",
      "Fazel Keshtkar",
      "Alyssa Meczkowska"
    ],
    "abstract": "Clinician burnout poses a substantial threat to patient safety, particularly in high-acuity intensive care units (ICUs). Existing research predominantly relies on retrospective survey tools or broad electronic health record (EHR) metadata, often overlooking the valuable narrative information embedded in clinical notes. In this study, we analyze 10,000 ICU discharge summaries from MIMIC-IV, a publicly available database derived from the electronic health records of Beth Israel Deaconess Medical Center. The dataset encompasses diverse patient data, including vital signs, medical orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. We introduce a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for clinical narratives, a lexical stress lexicon tailored for clinician burnout surveillance, and five-topic latent Dirichlet allocation (LDA) with workload proxies. A provider-level logistic regression classifier achieves a precision of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out set, surpassing metadata-only baselines by greater than or equal to 0.17 F1 score. Specialty-specific analysis indicates elevated burnout risk among providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate that ICU clinical narratives contain actionable signals for proactive well-being monitoring.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 6 Figure",
    "pdf_url": "https://arxiv.org/pdf/2509.04497v1",
    "published_date": "2025-09-01 19:05:26 UTC",
    "updated_date": "2025-09-01 19:05:26 UTC"
  },
  {
    "arxiv_id": "2509.01716v1",
    "title": "An LLM-enabled semantic-centric framework to consume privacy policies",
    "authors": [
      "Rui Zhao",
      "Vladyslav Melnychuk",
      "Jun Zhao",
      "Jesse Wright",
      "Nigel Shadbolt"
    ],
    "abstract": "In modern times, people have numerous online accounts, but they rarely read the Terms of Service or Privacy Policy of those sites, despite claiming otherwise, due to the practical difficulty in comprehending them. The mist of data privacy practices forms a major barrier for user-centred Web approaches, and for data sharing and reusing in an agentic world. Existing research proposed methods for using formal languages and reasoning for verifying the compliance of a specified policy, as a potential cure for ignoring privacy policies. However, a critical gap remains in the creation or acquisition of such formal policies at scale. We present a semantic-centric approach for using state-of-the-art large language models (LLM), to automatically identify key information about privacy practices from privacy policies, and construct $\\mathit{Pr}^2\\mathit{Graph}$, knowledge graph with grounding from Data Privacy Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with the pipeline, the $\\mathit{Pr}^2\\mathit{Graph}$ for the top-100 popular websites is also released as a public resource, by using the pipeline for analysis. We also demonstrate how the $\\mathit{Pr}^2\\mathit{Graph}$ can be used to support downstream tasks by constructing formal policy representations such as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use (psDToU). To evaluate the technology capability, we enriched the Policy-IE dataset by employing legal experts to create custom annotations. We benchmarked the performance of different large language models for our pipeline and verified their capabilities. Overall, they shed light on the possibility of large-scale analysis of online services' privacy practices, as a promising direction to audit the Web and the Internet. We release all datasets and source code as public resources to facilitate reuse and improvement.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01716v1",
    "published_date": "2025-09-01 18:53:13 UTC",
    "updated_date": "2025-09-01 18:53:13 UTC"
  },
  {
    "arxiv_id": "2509.01704v2",
    "title": "Deep Learning-Based Rock Particulate Classification Using Attention-Enhanced ConvNeXt",
    "authors": [
      "Anthony Amankwah",
      "Chris Aldrich"
    ],
    "abstract": "Accurate classification of rock sizes is a vital component in geotechnical engineering, mining, and resource management, where precise estimation influences operational efficiency and safety. In this paper, we propose an enhanced deep learning model based on the ConvNeXt architecture, augmented with both self-attention and channel attention mechanisms. Building upon the foundation of ConvNext, our proposed model, termed CNSCA, introduces self-attention to capture long-range spatial dependencies and channel attention to emphasize informative feature channels. This hybrid design enables the model to effectively capture both fine-grained local patterns and broader contextual relationships within rock imagery, leading to improved classification accuracy and robustness. We evaluate our model on a rock size classification dataset and compare it against three strong baseline. The results demonstrate that the incorporation of attention mechanisms significantly enhances the models capability for fine-grained classification tasks involving natural textures like rocks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been withdrawn by the authors to accommodate substantial revisions requested by a co-author. A revised version will be submitted",
    "pdf_url": "https://arxiv.org/pdf/2509.01704v2",
    "published_date": "2025-09-01 18:24:40 UTC",
    "updated_date": "2025-09-11 08:12:48 UTC"
  },
  {
    "arxiv_id": "2509.01684v1",
    "title": "Reinforcement Learning for Machine Learning Engineering Agents",
    "authors": [
      "Sherry Yang",
      "Joy He-Yueya",
      "Percy Liang"
    ],
    "abstract": "Existing agents for solving tasks such as ML engineering rely on prompting powerful language models. As a result, these agents do not improve with more experience. In this paper, we show that agents backed by weaker models that improve via reinforcement learning (RL) can outperform agents backed by much larger, but static models. We identify two major challenges with RL in this setting. First, actions can take a variable amount of time (e.g., executing code for different solutions), which leads to asynchronous policy gradient updates that favor faster but suboptimal solutions. To tackle variable-duration actions, we propose duration-aware gradient updates in a distributed asynchronous RL framework to amplify high-cost but high-reward actions. Second, using only test split performance as a reward provides limited feedback. A program that is nearly correct is treated the same as one that fails entirely. To address this, we propose environment instrumentation to offer partial credit, distinguishing almost-correct programs from those that fail early (e.g., during data loading). Environment instrumentation uses a separate static language model to insert print statement to an existing program to log the agent's experimental progress, from which partial credit can be extracted as reward signals for learning. Our experimental results on MLEBench suggest that performing gradient updates on a much smaller model (Qwen2.5-3B) trained with RL outperforms prompting a much larger model (Claude-3.5-Sonnet) with agent scaffolds, by an average of 22% across 12 Kaggle tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01684v1",
    "published_date": "2025-09-01 18:04:10 UTC",
    "updated_date": "2025-09-01 18:04:10 UTC"
  },
  {
    "arxiv_id": "2509.01659v1",
    "title": "Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025",
    "authors": [
      "Jiahao Qiu",
      "Jingzhe Shi",
      "Xinzhe Juan",
      "Zelin Zhao",
      "Jiayi Geng",
      "Shilong Liu",
      "Hongru Wang",
      "Sanfeng Wu",
      "Mengdi Wang"
    ],
    "abstract": "Physics provides fundamental laws that describe and predict the natural world. AI systems aspiring toward more general, real-world intelligence must therefore demonstrate strong physics problem-solving abilities: to formulate and apply physical laws for explaining and predicting physical processes. The International Physics Olympiad (IPhO)--the world's most prestigious physics competition--offers a rigorous benchmark for this purpose. We introduce Physics Supernova, an AI agent system with superior physics problem-solving abilities that match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics Supernova attains 23.5/30 points, ranking 14th of 406 contestants and surpassing the median performance of human gold medalists. We extensively analyzed Physics Supernova's capabilities and flexibility across diverse physics tasks. These results show that principled tool integration within agent systems can deliver competitive improvements in solving challenging science problems. The codes are available at https://github.com/CharlesQ9/Physics-Supernova.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01659v1",
    "published_date": "2025-09-01 17:59:13 UTC",
    "updated_date": "2025-09-01 17:59:13 UTC"
  },
  {
    "arxiv_id": "2509.01657v1",
    "title": "Data Retrieval with Importance Weights for Few-Shot Imitation Learning",
    "authors": [
      "Amber Xie",
      "Rahul Chand",
      "Dorsa Sadigh",
      "Joey Hejna"
    ],
    "abstract": "While large-scale robot datasets have propelled recent progress in imitation learning, learning from smaller task specific datasets remains critical for deployment in new environments and unseen tasks. One such approach to few-shot imitation learning is retrieval-based imitation learning, which extracts relevant samples from large, widely available prior datasets to augment a limited demonstration dataset. To determine the relevant data from prior datasets, retrieval-based approaches most commonly calculate a prior data point's minimum distance to a point in the target dataset in latent space. While retrieval-based methods have shown success using this metric for data selection, we demonstrate its equivalence to the limit of a Gaussian kernel density (KDE) estimate of the target data distribution. This reveals two shortcomings of the retrieval rule used in prior work. First, it relies on high-variance nearest neighbor estimates that are susceptible to noise. Second, it does not account for the distribution of prior data when retrieving data. To address these issues, we introduce Importance Weighted Retrieval (IWR), which estimates importance weights, or the ratio between the target and prior data distributions for retrieval, using Gaussian KDEs. By considering the probability ratio, IWR seeks to mitigate the bias of previous selection rules, and by using reasonable modeling parameters, IWR effectively smooths estimates using all data points. Across both simulation environments and real-world evaluations on the Bridge dataset we find that our method, IWR, consistently improves performance of existing retrieval-based methods, despite only requiring minor modifications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01657v1",
    "published_date": "2025-09-01 17:58:41 UTC",
    "updated_date": "2025-09-01 17:58:41 UTC"
  },
  {
    "arxiv_id": "2510.08578v1",
    "title": "AgenticAD: A Specialized Multiagent System Framework for Holistic Alzheimer Disease Management",
    "authors": [
      "Adib Bazgir",
      "Amir Habibdoust",
      "Xing Song",
      "Yuwen Zhang"
    ],
    "abstract": "Alzheimer's disease (AD) presents a complex, multifaceted challenge to patients, caregivers, and the healthcare system, necessitating integrated and dynamic support solutions. While artificial intelligence (AI) offers promising avenues for intervention, current applications are often siloed, addressing singular aspects of the disease such as diagnostics or caregiver support without systemic integration. This paper proposes a novel methodological framework for a comprehensive, multi-agent system (MAS) designed for holistic Alzheimer's disease management. The objective is to detail the architecture of a collaborative ecosystem of specialized AI agents, each engineered to address a distinct challenge in the AD care continuum, from caregiver support and multimodal data analysis to automated research and clinical data interpretation. The proposed framework is composed of eight specialized, interoperable agents. These agents are categorized by function: (1) Caregiver and Patient Support, (2) Data Analysis and Research, and (3) Advanced Multimodal Workflows. The methodology details the technical architecture of each agent, leveraging a suite of advanced technologies including large language models (LLMs) such as GPT-4o and Gemini, multi-agent orchestration frameworks, Retrieval-Augmented Generation (RAG) for evidence-grounded responses, and specialized tools for web scraping, multimodal data processing, and in-memory database querying. This paper presents a detailed architectural blueprint for an integrated AI ecosystem for AD care. By moving beyond single-purpose tools to a collaborative, multi-agent paradigm, this framework establishes a foundation for developing more adaptive, personalized, and proactive solutions. This methodological approach aims to pave the way for future systems capable of synthesizing diverse data streams to improve patient outcomes and reduce caregiver burden.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2510.08578v1",
    "published_date": "2025-09-01 17:51:56 UTC",
    "updated_date": "2025-09-01 17:51:56 UTC"
  },
  {
    "arxiv_id": "2509.10503v1",
    "title": "FEDEXCHANGE: Bridging the Domain Gap in Federated Object Detection for Free",
    "authors": [
      "Haolin Yuan",
      "Jingtao Li",
      "Weiming Zhuang",
      "Chen Chen",
      "Lingjuan Lyu"
    ],
    "abstract": "Federated Object Detection (FOD) enables clients to collaboratively train a global object detection model without accessing their local data from diverse domains. However, significant variations in environment, weather, and other domain specific factors hinder performance, making cross domain generalization a key challenge. Existing FOD methods often overlook the hardware constraints of edge devices and introduce local training regularizations that incur high computational costs, limiting real-world applicability. In this paper, we propose FEDEXCHANGE, a novel FOD framework that bridges domain gaps without introducing additional local computational overhead. FEDEXCHANGE employs a server side dynamic model exchange strategy that enables each client to gain insights from other clients' domain data without direct data sharing. Specifically, FEDEXCHANGE allows the server to alternate between model aggregation and model exchange. During aggregation rounds, the server aggregates all local models as usual. In exchange rounds, FEDEXCHANGE clusters and exchanges local models based on distance measures, allowing local models to learn from a variety of domains. As all operations are performed on the server side, clients can achieve improved cross domain utility without any additional computational overhead. Extensive evaluations demonstrate that FEDEXCHANGE enhances FOD performance, achieving 1.6X better mean average precision in challenging domains, such as rainy conditions, while requiring only 0.8X the computational resources compared to baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.10503v1",
    "published_date": "2025-09-01 17:39:25 UTC",
    "updated_date": "2025-09-01 17:39:25 UTC"
  },
  {
    "arxiv_id": "2509.01641v1",
    "title": "Non-Identical Diffusion Models in MIMO-OFDM Channel Generation",
    "authors": [
      "Yuzhi Yang",
      "Omar Alhussein",
      "Mérouane Debbah"
    ],
    "abstract": "We propose a novel diffusion model, termed the non-identical diffusion model, and investigate its application to wireless orthogonal frequency division multiplexing (OFDM) channel generation. Unlike the standard diffusion model that uses a scalar-valued time index to represent the global noise level, we extend this notion to an element-wise time indicator to capture local error variations more accurately. Non-identical diffusion enables us to characterize the reliability of each element (e.g., subcarriers in OFDM) within the noisy input, leading to improved generation results when the initialization is biased. Specifically, we focus on the recovery of wireless multi-input multi-output (MIMO) OFDM channel matrices, where the initial channel estimates exhibit highly uneven reliability across elements due to the pilot scheme. Conventional time embeddings, which assume uniform noise progression, fail to capture such variability across pilot schemes and noise levels. We introduce a matrix that matches the input size to control element-wise noise progression. Following a similar diffusion procedure to existing methods, we show the correctness and effectiveness of the proposed non-identical diffusion scheme both theoretically and numerically. For MIMO-OFDM channel generation, we propose a dimension-wise time embedding strategy. We also develop and evaluate multiple training and generation methods and compare them through numerical experiments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01641v1",
    "published_date": "2025-09-01 17:33:39 UTC",
    "updated_date": "2025-09-01 17:33:39 UTC"
  },
  {
    "arxiv_id": "2509.01631v2",
    "title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons",
    "authors": [
      "Chongwen Zhao",
      "Yutong Ke",
      "Kaizhu Huang"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various applications. Nonetheless, there is a growing concern as some users attempt to exploit these models for malicious purposes, including the synthesis of controlled substances and the propagation of disinformation, a technique known as \"Jailbreak.\" While some studies have achieved defenses against jailbreak attacks by modifying output distributions or detecting harmful content, the exact rationale still remains elusive. In this work, we present a novel neuron-level interpretability method that focuses on the role of safety-related knowledge neurons. Unlike existing approaches, our method projects the model's internal representation into a more consistent and interpretable vocabulary space. We then show that adjusting the activation of safety-related neurons can effectively control the model's behavior with a mean ASR higher than 97%. Building on this insight, we propose SafeTuning, a fine-tuning strategy that reinforces safety-critical neurons to improve model robustness against jailbreaks. SafeTuning consistently reduces attack success rates across multiple LLMs and outperforms all four baseline defenses. These findings offer a new perspective on understanding and defending against jailbreak attacks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "EACL 2026",
    "pdf_url": "https://arxiv.org/pdf/2509.01631v2",
    "published_date": "2025-09-01 17:17:06 UTC",
    "updated_date": "2026-01-21 03:40:08 UTC"
  },
  {
    "arxiv_id": "2509.01624v1",
    "title": "Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling",
    "authors": [
      "Natalia Frumkin",
      "Diana Marculescu"
    ],
    "abstract": "Text-to-image diffusion models are computationally intensive, often requiring dozens of forward passes through large transformer backbones. For instance, Stable Diffusion XL generates high-quality images with 50 evaluations of a 2.6B-parameter model, an expensive process even for a single batch. Few-step diffusion models reduce this cost to 2-8 denoising steps but still depend on large, uncompressed U-Net or diffusion transformer backbones, which are often too costly for full-precision inference without datacenter GPUs. These requirements also limit existing post-training quantization methods that rely on full-precision calibration. We introduce Q-Sched, a new paradigm for post-training quantization that modifies the diffusion model scheduler rather than model weights. By adjusting the few-step sampling trajectory, Q-Sched achieves full-precision accuracy with a 4x reduction in model size. To learn quantization-aware pre-conditioning coefficients, we propose the JAQ loss, which combines text-image compatibility with an image quality metric for fine-grained optimization. JAQ is reference-free and requires only a handful of calibration prompts, avoiding full-precision inference during calibration. Q-Sched delivers substantial gains: a 15.5% FID improvement over the FP16 4-step Latent Consistency Model and a 16.6% improvement over the FP16 8-step Phased Consistency Model, showing that quantization and few-step distillation are complementary for high-fidelity generation. A large-scale user study with more than 80,000 annotations further confirms Q-Sched's effectiveness on both FLUX.1[schnell] and SDXL-Turbo.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01624v1",
    "published_date": "2025-09-01 17:09:22 UTC",
    "updated_date": "2025-09-01 17:09:22 UTC"
  },
  {
    "arxiv_id": "2509.01620v1",
    "title": "Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry",
    "authors": [
      "Shanshan Wang",
      "Junchao Wu",
      "Fengying Ye",
      "Jingming Yao",
      "Lidia S. Chao",
      "Derek F. Wong"
    ],
    "abstract": "The rapid development of advanced large language models (LLMs) has made AI-generated text indistinguishable from human-written text. Previous work on detecting AI-generated text has made effective progress, but has not involved modern Chinese poetry. Due to the distinctive characteristics of modern Chinese poetry, it is difficult to identify whether a poem originated from humans or AI. The proliferation of AI-generated modern Chinese poetry has significantly disrupted the poetry ecosystem. Based on the urgency of identifying AI-generated poetry in the real Chinese world, this paper proposes a novel benchmark for detecting LLMs-generated modern Chinese poetry. We first construct a high-quality dataset, which includes both 800 poems written by six professional poets and 41,600 poems generated by four mainstream LLMs. Subsequently, we conduct systematic performance assessments of six detectors on this dataset. Experimental results demonstrate that current detectors cannot be used as reliable tools to detect modern Chinese poems generated by LLMs. The most difficult poetic features to detect are intrinsic qualities, especially style. The detection results verify the effectiveness and necessity of our proposed benchmark. Our work lays a foundation for future detection of AI-generated poetry.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01620v1",
    "published_date": "2025-09-01 17:01:45 UTC",
    "updated_date": "2025-09-01 17:01:45 UTC"
  },
  {
    "arxiv_id": "2509.01619v1",
    "title": "Throttling Web Agents Using Reasoning Gates",
    "authors": [
      "Abhinav Kumar",
      "Jaechul Roh",
      "Ali Naseh",
      "Amir Houmansadr",
      "Eugene Bagdasarian"
    ],
    "abstract": "AI web agents use Internet resources at far greater speed, scale, and complexity -- changing how users and services interact. Deployed maliciously or erroneously, these agents could overload content providers. At the same time, web agents can bypass CAPTCHAs and other defenses by mimicking user behavior or flood authentication systems with fake accounts. Yet providers must protect their services and content from denial-of-service attacks and scraping by web agents. In this paper, we design a framework that imposes tunable costs on agents before providing access to resources; we call this Web Agent Throttling. We start by formalizing Throttling Gates as challenges issued to an agent that are asymmetric, scalable, robust, and compatible with any agent. Focusing on a common component -- the language model -- we require the agent to solve reasoning puzzles, thereby incurring excessive token-generation costs. However, we find that using existing puzzles, e.g., coding or math, as throttling gates fails to satisfy our properties. To address this, we introduce rebus-based Reasoning Gates, synthetic text puzzles that require multi-hop reasoning over world knowledge (thereby throttling an agent's model). We design a scalable generation and verification protocol for such reasoning gates. Our framework achieves computational asymmetry, i.e., the response-generation cost is 9.2x higher than the generation cost for SOTA models. We further deploy reasoning gates on a custom website and Model Context Protocol (MCP) servers and evaluate with real-world web agents. Finally, we discuss the limitations and environmental impact of real-world deployment of our framework.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01619v1",
    "published_date": "2025-09-01 16:56:16 UTC",
    "updated_date": "2025-09-01 16:56:16 UTC"
  },
  {
    "arxiv_id": "2509.01617v1",
    "title": "Disentangling the schema turn: Restoring the information base to conceptual modelling",
    "authors": [
      "Chris Partridge",
      "Andrew Mitchell",
      "Sergio de Cesare",
      "Oscar Xiberta Soto"
    ],
    "abstract": "If one looks at contemporary mainstream development practices for conceptual modelling in computer science, these so clearly focus on a conceptual schema completely separated from its information base that the conceptual schema is often just called the conceptual model. These schema-centric practices are crystallized in almost every database textbook. We call this strong, almost universal, bias towards conceptual schemas the schema turn. The focus of this paper is on disentangling this turn within (computer science) conceptual modeling. It aims to shed some light on how it emerged and so show that it is not fundamental. To show that modern technology enables the adoption of an inclusive schema-and-base conceptual modelling approach, which in turn enables more automated, and empirically motivated practices. And to show, more generally, the space of possible conceptual modelling practices is wider than currently assumed. It also uses the example of bCLEARer to show that the implementations in this wider space will probably need to rely on new pipeline-based conceptual modelling techniques. So, it is possible that the schema turn's complete exclusion of the information base could be merely a temporary evolutionary detour.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.DB",
    "comment": "Fundamentals of Conceptual Modeling - ER2025 Workshop",
    "pdf_url": "https://arxiv.org/pdf/2509.01617v1",
    "published_date": "2025-09-01 16:55:34 UTC",
    "updated_date": "2025-09-01 16:55:34 UTC"
  },
  {
    "arxiv_id": "2509.01613v1",
    "title": "Entropy-Driven Curriculum for Multi-Task Training in Human Mobility Prediction",
    "authors": [
      "Tianye Fang",
      "Xuanshu Luo",
      "Martin Werner"
    ],
    "abstract": "The increasing availability of big mobility data from ubiquitous portable devices enables human mobility prediction through deep learning approaches. However, the diverse complexity of human mobility data impedes model training, leading to inefficient gradient updates and potential underfitting. Meanwhile, exclusively predicting next locations neglects implicit determinants, including distances and directions, thereby yielding suboptimal prediction results. This paper presents a unified training framework that integrates entropy-driven curriculum and multi-task learning to address these challenges. The proposed entropy-driven curriculum learning strategy quantifies trajectory predictability based on Lempel-Ziv compression and organizes training from simple to complex for faster convergence and enhanced performance. The multi-task training simultaneously optimizes the primary location prediction alongside auxiliary estimation of movement distance and direction for learning realistic mobility patterns, and improve prediction accuracy through complementary supervision signals. Extensive experiments conducted in accordance with the HuMob Challenge demonstrate that our approach achieves state-of-the-art performance on GEO-BLEU (0.354) and DTW (26.15) metrics with up to 2.92-fold convergence speed compared to training without curriculum learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01613v1",
    "published_date": "2025-09-01 16:46:21 UTC",
    "updated_date": "2025-09-01 16:46:21 UTC"
  },
  {
    "arxiv_id": "2509.05340v1",
    "title": "Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging",
    "authors": [
      "Dibya Jyoti Bora",
      "Mrinal Kanti Mishra"
    ],
    "abstract": "Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a pivotal challenge in medical image analysis due to the heterogeneous nature of tumor morphology and intensity distributions. Accurate delineation of tumor boundaries is critical for clinical decision-making, radiotherapy planning, and longitudinal disease monitoring. In this study, we perform a comprehensive comparative analysis of two major clustering paradigms applied in MRI tumor segmentation: hard clustering, exemplified by the K-Means algorithm, and soft clustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each pixel strictly to a single cluster, FCM introduces partial memberships, meaning each pixel can belong to multiple clusters with varying degrees of association. Experimental validation was performed using the BraTS2020 dataset, incorporating pre-processing through Gaussian filtering and Contrast Limited Adaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice Similarity Coefficient (DSC) and processing time, which collectively demonstrated that K-Means achieved superior speed with an average runtime of 0.3s per image, whereas FCM attained higher segmentation accuracy with an average DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher computational cost (1.3s per image). These results highlight the inherent trade-off between computational efficiency and boundary precision.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.05340v1",
    "published_date": "2025-09-01 16:40:08 UTC",
    "updated_date": "2025-09-01 16:40:08 UTC"
  },
  {
    "arxiv_id": "2509.01605v1",
    "title": "TransForSeg: A Multitask Stereo ViT for Joint Stereo Segmentation and 3D Force Estimation in Catheterization",
    "authors": [
      "Pedram Fekri",
      "Mehrdad Zadeh",
      "Javad Dargahi"
    ],
    "abstract": "Recently, the emergence of multitask deep learning models has enhanced catheterization procedures by providing tactile and visual perception data through an end-to-end architecture. This information is derived from a segmentation and force estimation head, which localizes the catheter in X-ray images and estimates the applied pressure based on its deflection within the image. These stereo vision architectures incorporate a CNN-based encoder-decoder that captures the dependencies between X-ray images from two viewpoints, enabling simultaneous 3D force estimation and stereo segmentation of the catheter. With these tasks in mind, this work approaches the problem from a new perspective. We propose a novel encoder-decoder Vision Transformer model that processes two input X-ray images as separate sequences. Given sequences of X-ray patches from two perspectives, the transformer captures long-range dependencies without the need to gradually expand the receptive field for either image. The embeddings generated by both the encoder and decoder are fed into two shared segmentation heads, while a regression head employs the fused information from the decoder for 3D force estimation. The proposed model is a stereo Vision Transformer capable of simultaneously segmenting the catheter from two angles while estimating the generated forces at its tip in 3D. This model has undergone extensive experiments on synthetic X-ray images with various noise levels and has been compared against state-of-the-art pure segmentation models, vision-based catheter force estimation methods, and a multitask catheter segmentation and force estimation approach. It outperforms existing models, setting a new state-of-the-art in both catheter segmentation and force estimation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint version. This work is intended for future journal submission",
    "pdf_url": "https://arxiv.org/pdf/2509.01605v1",
    "published_date": "2025-09-01 16:36:23 UTC",
    "updated_date": "2025-09-01 16:36:23 UTC"
  },
  {
    "arxiv_id": "2509.01599v1",
    "title": "An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems",
    "authors": [
      "Nathanael Coolidge",
      "Jaime González Sanz",
      "Li Yang",
      "Khalil El Khatib",
      "Glenn Harvel",
      "Nelson Agbemava",
      "I Putu Susila",
      "Mehmet Yavuz Yagci"
    ],
    "abstract": "Radiation Detection Systems (RDSs) are used to measure and detect abnormal levels of radioactive material in the environment. These systems are used in many applications to mitigate threats posed by high levels of radioactive material. However, these systems lack protection against malicious external attacks to modify the data. The novelty of applying Intrusion Detection Systems (IDS) in RDSs is a crucial element in safeguarding these critical infrastructures. While IDSs are widely used in networking environments to safeguard against various attacks, their application in RDSs is novel. A common attack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm the system, causing malfunctioning RDSs. This paper proposes an efficient Machine Learning (ML)-based IDS to detect anomalies in radiation data, focusing on DoS attacks. This work explores the use of sampling methods to create a simulated DoS attack based on a real radiation dataset, followed by an evaluation of various ML algorithms, including Random Forest, Support Vector Machine (SVM), logistic regression, and Light Gradient-Boosting Machine (LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its superior accuracy and low computational resource consumption, making it particularly suitable for real-time intrusion detection. Additionally, model optimization and TinyML techniques, including feature selection, parallel execution, and random search methods, are used to improve the efficiency of the proposed IDS. Finally, an optimized and efficient LightGBM-based IDS is developed to achieve accurate intrusion detection for RDSs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "Preprint author original pre review. Accepted and Presented at ISOFIC 2024. The official proceedings version is available on the conference site",
    "pdf_url": "https://arxiv.org/pdf/2509.01599v1",
    "published_date": "2025-09-01 16:31:46 UTC",
    "updated_date": "2025-09-01 16:31:46 UTC"
  },
  {
    "arxiv_id": "2509.01596v1",
    "title": "O-DisCo-Edit: Object Distortion Control for Unified Realistic Video Editing",
    "authors": [
      "Yuqing Chen",
      "Junjie Wang",
      "Lin Liu",
      "Ruihang Chu",
      "Xiaopeng Zhang",
      "Qi Tian",
      "Yujiu Yang"
    ],
    "abstract": "Diffusion models have recently advanced video editing, yet controllable editing remains challenging due to the need for precise manipulation of diverse object properties. Current methods require different control signal for diverse editing tasks, which complicates model design and demands significant training resources. To address this, we propose O-DisCo-Edit, a unified framework that incorporates a novel object distortion control (O-DisCo). This signal, based on random and adaptive noise, flexibly encapsulates a wide range of editing cues within a single representation. Paired with a \"copy-form\" preservation module for preserving non-edited regions, O-DisCo-Edit enables efficient, high-fidelity editing through an effective training paradigm. Extensive experiments and comprehensive human evaluations consistently demonstrate that O-DisCo-Edit surpasses both specialized and multitask state-of-the-art methods across various video editing tasks. https://cyqii.github.io/O-DisCo-Edit.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01596v1",
    "published_date": "2025-09-01 16:29:39 UTC",
    "updated_date": "2025-09-01 16:29:39 UTC"
  },
  {
    "arxiv_id": "2509.01592v1",
    "title": "Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices",
    "authors": [
      "Einstein Rivas Pizarro",
      "Wajiha Zaheer",
      "Li Yang",
      "Khalil El-Khatib",
      "Glenn Harvel"
    ],
    "abstract": "Radiation Detection Systems (RDSs) play a vital role in ensuring public safety across various settings, from nuclear facilities to medical environments. However, these systems are increasingly vulnerable to cyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP floods, botnet attacks, privilege escalation, and distributed denial-of-service (DDoS) attacks. Such threats could compromise the integrity and reliability of radiation measurements, posing significant public health and safety risks. This paper presents a new synthetic radiation dataset and an Intrusion Detection System (IDS) tailored for resource-constrained environments, bringing Machine Learning (ML) predictive capabilities closer to the sensing edge layer of critical infrastructure. Leveraging TinyML techniques, the proposed IDS employs an optimized XGBoost model enhanced with pruning, quantization, feature selection, and sampling. These TinyML techniques significantly reduce the size of the model and computational demands, enabling real-time intrusion detection on low-resource devices while maintaining a reasonable balance between efficiency and accuracy.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "Preprint author original pre review. Accepted and Presented at NPIC & HMIT 2025. The official proceedings version is available in the ANS Digital Library",
    "pdf_url": "https://arxiv.org/pdf/2509.01592v1",
    "published_date": "2025-09-01 16:26:37 UTC",
    "updated_date": "2025-09-01 16:26:37 UTC"
  },
  {
    "arxiv_id": "2509.01588v1",
    "title": "From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation",
    "authors": [
      "Andrea Poltronieri",
      "Xavier Serra",
      "Martín Rocamora"
    ],
    "abstract": "Audio Chord Estimation (ACE) holds a pivotal role in music information research, having garnered attention for over two decades due to its relevance for music transcription and analysis. Despite notable advancements, challenges persist in the task, particularly concerning unique characteristics of harmonic content, which have resulted in existing systems' performances reaching a glass ceiling. These challenges include annotator subjectivity, where varying interpretations among annotators lead to inconsistencies, and class imbalance within chord datasets, where certain chord classes are over-represented compared to others, posing difficulties in model training and evaluation. As a first contribution, this paper presents an evaluation of inter-annotator agreement in chord annotations, using metrics that extend beyond traditional binary measures. In addition, we propose a consonance-informed distance metric that reflects the perceptual similarity between harmonic annotations. Our analysis suggests that consonance-based distance metrics more effectively capture musically meaningful agreement between annotations. Expanding on these findings, we introduce a novel ACE conformer-based model that integrates consonance concepts into the model through consonance-based label smoothing. The proposed model also addresses class imbalance by separately estimating root, bass, and all note activations, enabling the reconstruction of chord labels from decomposed outputs.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 3 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01588v1",
    "published_date": "2025-09-01 16:20:47 UTC",
    "updated_date": "2025-09-01 16:20:47 UTC"
  },
  {
    "arxiv_id": "2509.01587v1",
    "title": "One-Shot Clustering for Federated Learning Under Clustering-Agnostic Assumption",
    "authors": [
      "Maciej Krzysztof Zuziak",
      "Roberto Pellungrini",
      "Salvatore Rinzivillo"
    ],
    "abstract": "Federated Learning (FL) is a widespread and well-adopted paradigm of decentralised learning that allows training one model from multiple sources without the need to transfer data between participating clients directly. Since its inception in 2015, it has been divided into numerous subfields that deal with application-specific issues, such as data heterogeneity or resource allocation. One such sub-field, Clustered Federated Learning (CFL), deals with the problem of clustering the population of clients into separate cohorts to deliver personalised models. Although a few remarkable works have been published in this domain, the problem remains largely unexplored, as its basic assumptions and settings differ slightly from those of standard FL. In this work, we present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic algorithm that can automatically detect the earliest suitable moment for clustering. Our algorithm is based on computing the cosine distance between the gradients of the clients and a temperature measure that detects when the federated model starts to converge. We empirically evaluate our methodology by testing various one-shot clustering algorithms for over forty different tasks on five benchmark datasets. Our experiments showcase the good performance of our approach when used to perform CFL in an automated manner without the need to adjust hyperparameters. We also revisit the practical feasibility of CFL algorithms based on the gradients of the clients, providing firm evidence of the high efficiency of density-based clustering methods when used to differentiate between the loss surfaces of neural networks trained on different distributions. Moreover, by inspecting the feasibility of local explanations generated with the help of GradCAM, we can provide more insights into the relationship between personalisation and the explainability of local predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01587v1",
    "published_date": "2025-09-01 16:18:51 UTC",
    "updated_date": "2025-09-01 16:18:51 UTC"
  },
  {
    "arxiv_id": "2509.01576v1",
    "title": "Structured AI Decision-Making in Disaster Management",
    "authors": [
      "Julian Gerald Dcruz",
      "Argyrios Zolotas",
      "Niall Ross Greenwood",
      "Miguel Arana-Catania"
    ],
    "abstract": "With artificial intelligence (AI) being applied to bring autonomy to decision-making in safety-critical domains such as the ones typified in the aerospace and emergency-response services, there has been a call to address the ethical implications of structuring those decisions, so they remain reliable and justifiable when human lives are at stake. This paper contributes to addressing the challenge of decision-making by proposing a structured decision-making framework as a foundational step towards responsible AI. The proposed structured decision-making framework is implemented in autonomous decision-making, specifically within disaster management. By introducing concepts of Enabler agents, Levels and Scenarios, the proposed framework's performance is evaluated against systems relying solely on judgement-based insights, as well as human operators who have disaster experience: victims, volunteers, and stakeholders. The results demonstrate that the structured decision-making framework achieves 60.94% greater stability in consistently accurate decisions across multiple Scenarios, compared to judgement-based systems. Moreover, the study shows that the proposed framework outperforms human operators with a 38.93% higher accuracy across various Scenarios. These findings demonstrate the promise of the structured decision-making framework for building more reliable autonomous AI applications in safety-critical contexts.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 14 figures, 16 tables. To be published in Nature Scientific Reports",
    "pdf_url": "https://arxiv.org/pdf/2509.01576v1",
    "published_date": "2025-09-01 16:04:21 UTC",
    "updated_date": "2025-09-01 16:04:21 UTC"
  },
  {
    "arxiv_id": "2509.01565v1",
    "title": "Enabling Down Syndrome Research through a Knowledge Graph-Driven Analytical Framework",
    "authors": [
      "Madan Krishnamurthy",
      "Surya Saha",
      "Pierrette Lo",
      "Patricia L. Whetzel",
      "Tursynay Issabekova",
      "Jamed Ferreris Vargas",
      "Jack DiGiovanna",
      "Melissa A Haendel"
    ],
    "abstract": "Trisomy 21 results in Down syndrome, a multifaceted genetic disorder with diverse clinical phenotypes, including heart defects, immune dysfunction, neurodevelopmental differences, and early-onset dementia risk. Heterogeneity and fragmented data across studies challenge comprehensive research and translational discovery. The NIH INCLUDE (INvestigation of Co-occurring conditions across the Lifespan to Understand Down syndromE) initiative has assembled harmonized participant-level datasets, yet realizing their potential requires integrative analytical frameworks. We developed a knowledge graph-driven platform transforming nine INCLUDE studies, comprising 7,148 participants, 456 conditions, 501 phenotypes, and over 37,000 biospecimens, into a unified semantic infrastructure. Cross-resource enrichment with Monarch Initiative data expands coverage to 4,281 genes and 7,077 variants. The resulting knowledge graph contains over 1.6 million semantic associations, enabling AI-ready analysis with graph embeddings and path-based reasoning for hypothesis generation. Researchers can query the graph via SPARQL or natural language interfaces. This framework converts static data repositories into dynamic discovery environments, supporting cross-study pattern recognition, predictive modeling, and systematic exploration of genotype-phenotype relationships in Down syndrome.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01565v1",
    "published_date": "2025-09-01 15:50:38 UTC",
    "updated_date": "2025-09-01 15:50:38 UTC"
  },
  {
    "arxiv_id": "2509.02627v2",
    "title": "A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification",
    "authors": [
      "Jie Xiao",
      "Mengye Lyu",
      "Shaojun Liu"
    ],
    "abstract": "MIDOG 2025 Track 1 requires mitosis detection in whole-slideimages (WSIs) containing non-tumor, inflamed, and necrotic re-gions. Due to the complicated and heterogeneous context, aswell as possible artifacts, there are often false positives and falsenegatives, thus degrading the detection F1-score. To addressthis problem, we propose a two-stage framework. Firstly, an im-proved YOLO11x, integrated with EMA attention and LSConv,is employed to generate mitosis candidates. We use a low confi-dence threshold to generate as many proposals as possible, en-suring the detection recall. Then, a ConvNeXt-Tiny classifieris employed to filter out the false positives, ensuring the detec-tion precision. Consequently, the proposed two-stage frame-work can generate a high detection F1-score. Evaluated on afused dataset comprising MIDOG++, MITOS_WSI_CCMCT,and MITOS_WSI_CMC, our framework achieves an F1-scoreof 0.882, which is 0.035 higher than the single-stage YOLO11xbaseline. This performance gain is produced by a significantprecision improvement, from 0.762 to 0.839, and a comparablerecall. On the MIDOG 2025 Track 1 preliminary test set, thealgorithm scores an F1 score of 0.7587. The code is available athttps://github.com/xxiao0304/MIDOG-2025-Track-1-of-SZTU.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02627v2",
    "published_date": "2025-09-01 15:46:28 UTC",
    "updated_date": "2025-09-26 06:20:20 UTC"
  },
  {
    "arxiv_id": "2509.01560v3",
    "title": "In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents",
    "authors": [
      "Seungkyu Lee",
      "Nalim Kim",
      "Yohan Jo"
    ],
    "abstract": "Tool agents--LLM-based systems that interact with external APIs--offer a way to execute real-world tasks. However, as tasks become increasingly complex, these agents struggle to identify and call the correct APIs in the proper order. To tackle this problem, we investigate converting API documentation into a structured API graph that captures API dependencies and leveraging it for multi-tool queries that require compositional API calls. To support this, we introduce In-N-Out, the first expert-annotated dataset of API graphs built from two real-world API benchmarks and their documentation. Using In-N-Out significantly improves performance on both tool retrieval and multi-tool query generation, nearly doubling that of LLMs using documentation alone. Moreover, graphs generated by models fine-tuned on In-N-Out close 90% of this gap, showing that our dataset helps models learn to comprehend API documentation and parameter relationships. Our findings highlight the promise of using explicit API graphs for tool agents and the utility of In-N-Out as a valuable resource. We release our dataset and code at https://github.com/holi-lab/In-N-Out-API-Graph.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01560v3",
    "published_date": "2025-09-01 15:42:21 UTC",
    "updated_date": "2025-12-30 04:36:06 UTC"
  },
  {
    "arxiv_id": "2509.01554v1",
    "title": "Unified Supervision For Vision-Language Modeling in 3D Computed Tomography",
    "authors": [
      "Hao-Chih Lee",
      "Zelong Liu",
      "Hamza Ahmed",
      "Spencer Kim",
      "Sean Huver",
      "Vishwesh Nath",
      "Zahi A. Fayad",
      "Timothy Deyer",
      "Xueyan Mei"
    ],
    "abstract": "General-purpose vision-language models (VLMs) have emerged as promising tools in radiology, offering zero-shot capabilities that mitigate the need for large labeled datasets. However, in high-stakes domains like diagnostic radiology, these models often lack the discriminative precision required for reliable clinical use. This challenge is compounded by the scarcity and heterogeneity of publicly available volumetric CT datasets, which vary widely in annotation formats and granularity. To address these limitations, we introduce Uniferum, a volumetric VLM that unifies diverse supervision signals, encoded in classification labels and segmentation masks, into a single training framework. By harmonizing three public 3D CT datasets with distinct annotations, Uniferum achieves state-of-the-art performance, improving AUROC on the CT-RATE benchmark by 7% compared to CLIP-based and conventional multi-label convolutional models. The model demonstrates robust out-of-distribution generalization, with observed evidence of unexpected zero-shot performance on the RAD-CHEST and INSPECT datasets. Our results highlight the effectiveness of integrating heterogeneous annotations and body segmentation to enhance model performance, setting a new direction for clinically reliable, data-efficient VLMs in 3D medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICCV 2025 VLM 3d Workshop",
    "pdf_url": "https://arxiv.org/pdf/2509.01554v1",
    "published_date": "2025-09-01 15:30:17 UTC",
    "updated_date": "2025-09-01 15:30:17 UTC"
  },
  {
    "arxiv_id": "2509.01544v3",
    "title": "Causal Consistency Regularization: Training Verifiably Sensitive Reasoning in Large Language Models",
    "authors": [
      "Sanjeda Akter",
      "Ibne Farabi Shihab",
      "Anuj Sharma"
    ],
    "abstract": "Large language models can produce correct answers while relying on flawed reasoning traces, partly because common training objectives reward final-answer correctness rather than faithful intermediate reasoning. This undermines trustworthiness in high-stakes settings. We propose Counterfactual Sensitivity Regularization (CSR), a training paradigm that improves reasoning faithfulness by enforcing causal consistency between reasoning steps and outcomes. CSR automatically applies operator-level interventions to reasoning traces, such as swapping \"+\" with \"-\", to generate minimally perturbed counterfactual rationales, and penalizes the model when these logically invalid traces still lead to the original answer. Our implementation is efficient, adding about 9 percent training overhead via a warm-start curriculum and token-subset optimization.\n  We evaluate faithfulness using Counterfactual Outcome Sensitivity (COS), which measures how appropriately answers change under logical perturbations. Across arithmetic (GSM8K), logical deduction (ProofWriter), multi-hop question answering (HotpotQA), and code generation (MBPP), CSR yields improved accuracy versus faithfulness trade-offs, establishing a new Pareto frontier. CSR improves faithfulness over standard fine-tuning and process supervision by up to 70 percentage points, and transfers across model families with 94.2 to 96.7 percent success in structured domains. CSR also complements inference-time methods such as self-consistency. Overall, CSR offers a practical route to more reliable reasoning in structured domains, including mathematics, formal logic, and code, where operators are well-defined and verifiable, covering an estimated 40 to 60 percent of high-stakes reasoning deployments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01544v3",
    "published_date": "2025-09-01 15:18:46 UTC",
    "updated_date": "2026-01-05 17:24:02 UTC"
  },
  {
    "arxiv_id": "2509.01535v2",
    "title": "CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models",
    "authors": [
      "Kairong Han",
      "Wenshuo Zhao",
      "Ziyu Zhao",
      "JunJian Ye",
      "Lujia Pan",
      "Kun Kuang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across various domains. However, a fundamental question remains: Can LLMs effectively utilize causal knowledge for prediction and generation? Through empirical studies, we find that LLMs trained directly on large-scale data often capture spurious correlations rather than true causal relationships, leading to suboptimal performance, especially in out-of-distribution (OOD) scenarios. To address this challenge, we propose Causal Attention Tuning (CAT), a novel approach that injects fine-grained causal knowledge into the attention mechanism. We propose an automated pipeline that leverages human priors to automatically generate token-level causal signals and introduce the Re-Attention mechanism to guide training, helping the model focus on causal structures while mitigating noise and biases in attention scores. Experimental results on our proposed Spurious Token Game (STG) benchmark and multiple downstream tasks demonstrate that our approach effectively leverages causal knowledge for prediction and remains robust in OOD scenarios. The CAT achieves an average improvement of 5.76% on the STG dataset and 1.56% on downstream tasks. Notably, the OOD performance of the Llama-3.1-8B model on STG_M increased from 64.5% to 90.5%, and Qwen's OOD performance on the STG_H dataset improved from 25.4% to 55.9%. Implementation details can be found at https://github.com/Kairong-Han/CAT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP2025 Main conference",
    "pdf_url": "https://arxiv.org/pdf/2509.01535v2",
    "published_date": "2025-09-01 15:13:15 UTC",
    "updated_date": "2025-09-09 04:01:50 UTC"
  },
  {
    "arxiv_id": "2509.01517v1",
    "title": "Agentic Workflow for Education: Concepts and Applications",
    "authors": [
      "Yuan-Hao Jiang",
      "Yijie Lu",
      "Ling Dai",
      "Jiatong Wang",
      "Ruijia Li",
      "Bo Jiang"
    ],
    "abstract": "With the rapid advancement of Large Language Models (LLMs) and Artificial Intelligence (AI) agents, agentic workflows are showing transformative potential in education. This study introduces the Agentic Workflow for Education (AWE), a four-component model comprising self-reflection, tool invocation, task planning, and multi-agent collaboration. We distinguish AWE from traditional LLM-based linear interactions and propose a theoretical framework grounded in the von Neumann Multi-Agent System (MAS) architecture. Through a paradigm shift from static prompt-response systems to dynamic, nonlinear workflows, AWE enables scalable, personalized, and collaborative task execution. We further identify four core application domains: integrated learning environments, personalized AI-assisted learning, simulation-based experimentation, and data-driven decision-making. A case study on automated math test generation shows that AWE-generated items are statistically comparable to real exam questions, validating the model's effectiveness. AWE offers a promising path toward reducing teacher workload, enhancing instructional quality, and enabling broader educational innovation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "Proceedings of the 33rd International Conference on Computers in Education (ICCE 2025). Asia-Pacific Society for Computers in Education",
    "pdf_url": "https://arxiv.org/pdf/2509.01517v1",
    "published_date": "2025-09-01 14:39:48 UTC",
    "updated_date": "2025-09-01 14:39:48 UTC"
  },
  {
    "arxiv_id": "2509.01514v1",
    "title": "MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models",
    "authors": [
      "Andreas Ottem"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems typically face constraints because of their inherent mechanism: a simple top-k semantic search [1]. The approach often leads to the incorporation of irrelevant or redundant information in the context, degrading performance and efficiency [10][11]. This paper presents MeVe, a novel modular architecture intended for Memory Verification and smart context composition. MeVe rethinks the RAG paradigm by proposing a five-phase modular design that distinctly breaks down the retrieval and context composition process into distinct, auditable, and independently tunable phases: initial retrieval, relevance verification, fallback retrieval, context prioritization, and token budgeting. This architecture enables fine-grained control of what knowledge is made available to an LLM, enabling task-dependent filtering and adaptation. We release a reference implementation of MeVe as a proof of concept and evaluate its performance on knowledge-heavy QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that by actively verifying information before composition, MeVe significantly improves context efficiency, achieving a 57% reduction on the Wikipedia dataset and a 75% reduction on the more complex HotpotQA dataset compared to standard RAG implementations [25]. This work provides a framework for more scalable and reliable LLM applications. By refining and distilling contextual information, MeVe offers a path toward better grounding and more accurate factual support [16].",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 7 figures, held online presentation at NLPA 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01514v1",
    "published_date": "2025-09-01 14:33:09 UTC",
    "updated_date": "2025-09-01 14:33:09 UTC"
  },
  {
    "arxiv_id": "2509.01512v1",
    "title": "Unsupervised Identification and Replay-based Detection (UIRD) for New Category Anomaly Detection in ECG Signal",
    "authors": [
      "Zhangyue Shi",
      "Zekai Wang",
      "Yuxuan Li"
    ],
    "abstract": "In clinical practice, automatic analysis of electrocardiogram (ECG) is widely applied to identify irregular heart rhythms and other electrical anomalies of the heart, enabling timely intervention and potentially improving clinical outcomes. However, due to the limited samples in certain types of ECG signals, the class imbalance issues pose a challenge for ECG-based detection. In addition, as the volume of patient data grows, long-term storage of all historical data becomes increasingly burdensome as training samples to recognize new patterns and classify existing ECG signals accurately. Therefore, to enhance the performance of anomaly detection while addressing storage limitations, we propose a pseudo-replay based semi-supervised continual learning framework, which consists of two components: unsupervised identification and replay-based detection. For unsupervised identification, an unsupervised generative adversarial network (GAN)-based framework is integrated to detect novel patterns. Besides, instead of directly storing all historical data, a pseudo replay-based learning strategy is proposed which utilizes a generator to learn the data distribution for each individual task. When a new task arises, the generator synthesizes pseudo data representative of previous learnt classes, enabling the model to detect both the existed patterns and the newly presented anomalies. The effectiveness of the proposed framework is validated in four public ECG datasets, which leverages supervised classification problems for anomaly detection. The experimental results show that the developed approach is very promising in identifying novel anomalies while maintaining good performance on detecting existing ECG signals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01512v1",
    "published_date": "2025-09-01 14:32:03 UTC",
    "updated_date": "2025-09-01 14:32:03 UTC"
  },
  {
    "arxiv_id": "2509.01498v2",
    "title": "MSA2-Net: Utilizing Self-Adaptive Convolution Module to Extract Multi-Scale Information in Medical Image Segmentation",
    "authors": [
      "Chao Deng",
      "Xiaosen Li",
      "Xiao Qin"
    ],
    "abstract": "The nnUNet segmentation framework adeptly adjusts most hyperparameters in training scripts automatically, but it overlooks the tuning of internal hyperparameters within the segmentation network itself, which constrains the model's ability to generalize. Addressing this limitation, this study presents a novel Self-Adaptive Convolution Module that dynamically adjusts the size of the convolution kernels depending on the unique fingerprints of different datasets. This adjustment enables the MSA2-Net, when equipped with this module, to proficiently capture both global and local features within the feature maps. Self-Adaptive Convolution Module is strategically integrated into two key components of the MSA2-Net: the Multi-Scale Convolution Bridge and the Multi-Scale Amalgamation Decoder. In the MSConvBridge, the module enhances the ability to refine outputs from various stages of the CSWin Transformer during the skip connections, effectively eliminating redundant data that could potentially impair the decoder's performance. Simultaneously, the MSADecoder, utilizing the module, excels in capturing detailed information of organs varying in size during the decoding phase. This capability ensures that the decoder's output closely reproduces the intricate details within the feature maps, thus yielding highly accurate segmentation images. MSA2-Net, bolstered by this advanced architecture, has demonstrated exceptional performance, achieving Dice coefficient scores of 86.49\\%, 92.56\\%, 93.37\\%, and 92.98\\% on the Synapse, ACDC, Kvasir, and Skin Lesion Segmentation (ISIC2017) datasets, respectively. This underscores MSA2-Net's robustness and precision in medical image segmentation tasks across various datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01498v2",
    "published_date": "2025-09-01 14:19:15 UTC",
    "updated_date": "2025-09-03 02:39:39 UTC"
  },
  {
    "arxiv_id": "2509.05338v1",
    "title": "Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks",
    "authors": [
      "Atsushi Masumori",
      "Norihiro Maruyama",
      "Itsuki Doi",
      "johnsmith",
      "Hiroki Sato",
      "Takashi Ikegami"
    ],
    "abstract": "We introduce Plantbot, a hybrid lifeform that connects a living plant with a mobile robot through a network of large language model (LLM) modules. Each module - responsible for sensing, vision, dialogue, or action - operates asynchronously and communicates via natural language, enabling seamless interaction across biological and artificial domains. This architecture leverages the capacity of LLMs to serve as hybrid interfaces, where natural language functions as a universal protocol, translating multimodal data (soil moisture, temperature, visual context) into linguistic messages that coordinate system behaviors. The integrated network transforms plant states into robotic actions, installing normativity essential for agency within the sensor-motor loop. By combining biological and robotic elements through LLM-mediated communication, Plantbot behaves as an embodied, adaptive agent capable of responding autonomously to environmental conditions. This approach suggests possibilities for a new model of artificial life, where decentralized, LLM modules coordination enable novel interactions between biological and artificial systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05338v1",
    "published_date": "2025-09-01 14:12:28 UTC",
    "updated_date": "2025-09-01 14:12:28 UTC"
  },
  {
    "arxiv_id": "2509.01479v2",
    "title": "An Information-Flow Perspective on Explainability Requirements: Specification and Verification",
    "authors": [
      "Bernd Finkbeiner",
      "Hadar Frenkel",
      "Julian Siber"
    ],
    "abstract": "Explainable systems expose information about why certain observed effects are happening to the agents interacting with them. We argue that this constitutes a positive flow of information that needs to be specified, verified, and balanced against negative information flow that may, e.g., violate privacy guarantees. Since both explainability and privacy require reasoning about knowledge, we tackle these tasks with epistemic temporal logic extended with quantification over counterfactual causes. This allows us to specify that a multi-agent system exposes enough information such that agents acquire knowledge on why some effect occurred. We show how this principle can be used to specify explainability as a system-level requirement and provide an algorithm for checking finite-state models against such specifications. We present a prototype implementation of the algorithm and evaluate it on several benchmarks, illustrating how our approach distinguishes between explainable and unexplainable systems, and how it allows to pose additional privacy requirements.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
    "pdf_url": "https://arxiv.org/pdf/2509.01479v2",
    "published_date": "2025-09-01 13:50:52 UTC",
    "updated_date": "2025-09-23 14:27:05 UTC"
  },
  {
    "arxiv_id": "2509.01476v3",
    "title": "Do Retrieval Augmented Language Models Know When They Don't Know?",
    "authors": [
      "Youchao Zhou",
      "Heyan Huang",
      "Yicheng Liu",
      "Rui Dai",
      "Xinglin Wang",
      "Xingchen Zhang",
      "Shumin Shi",
      "Yang Deng"
    ],
    "abstract": "Existing large language models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Two main approaches have been proposed to mitigate hallucinations: retrieval-augmented language models (RALMs) and refusal post-training. However, current research predominantly focuses on their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. Ideally, if RALMs know when they do not know, they should refuse to answer.In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we investigate three questions. First, are RALMs well calibrated with respect to different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, when all retrieved documents are irrelevant, RALMs still tend to refuse questions they could have answered correctly. Next, given the model's pronounced \\textbf{over-refusal} behavior, we raise a second question: How does a RALM's refusal ability align with its calibration quality? Our results show that the over-refusal problem can be mitigated through in-context fine-tuning. However, we observe that improved refusal behavior does not necessarily imply better calibration or higher overall accuracy. Finally, we ask: Can we combine refusal-aware RALMs with uncertainty-based answer abstention to mitigate over-refusal? We develop a simple yet effective refusal mechanism for refusal-post-trained RALMs that improves their overall answer quality by balancing refusal and correct answers. Our study provides a more comprehensive understanding of the factors influencing RALM behavior. Meanwhile, we emphasize that uncertainty estimation for RALMs remains an open problem deserving deeper investigation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2026 camera ready version. Extended version with Appendix is coming soon",
    "pdf_url": "https://arxiv.org/pdf/2509.01476v3",
    "published_date": "2025-09-01 13:44:15 UTC",
    "updated_date": "2025-11-18 02:40:22 UTC"
  },
  {
    "arxiv_id": "2509.02624v1",
    "title": "Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement",
    "authors": [
      "Minja Axelsson",
      "Jiaee Cheong",
      "Rune Nyrup",
      "Hatice Gunes"
    ],
    "abstract": "Recent studies indicate that robotic coaches can play a crucial role in promoting wellbeing. However, the real-world deployment of wellbeing robots raises numerous ethical and socio-technical questions and concerns. To explore these questions, we undertake a community-centered investigation to examine three different communities' perspectives on using robotic wellbeing coaches in real-world environments. We frame our work as an anticipatory ethical investigation, which we undertake to better inform the development of robotic technologies with communities' opinions, with the ultimate goal of aligning robot development with public interest. We conducted workshops with three communities who are under-represented in robotics development: 1) members of the public at a science festival, 2) women computer scientists at a conference, and 3) humanities researchers interested in history and philosophy of science. In the workshops, we collected qualitative data using the Social Robot Co-Design Canvas on Ethics. We analysed the collected qualitative data with Thematic Analysis, informed by notes taken during workshops. Through our analysis, we identify four themes regarding key ethical and socio-technical questions about the real-world use of wellbeing robots. We group participants' insights and discussions around these broad thematic questions, discuss them in light of state-of-the-art literature, and highlight areas for future investigation. Finally, we provide the four questions as a broad framework that roboticists can and should use during robotic development and deployment, in order to reflect on the ethics and socio-technical dimensions of their robotic applications, and to engage in dialogue with communities of robot users. The four questions are: 1) Is the robot safe and how can we know that?, 2) Who is the robot built for and with?, 3) Who owns the robot and the data?, and 4) Why a robot?.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at the 8th AAAI/ACM Conference on AI, Ethics, and Society. 23 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2509.02624v1",
    "published_date": "2025-09-01 13:38:50 UTC",
    "updated_date": "2025-09-01 13:38:50 UTC"
  },
  {
    "arxiv_id": "2509.10501v1",
    "title": "From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction",
    "authors": [
      "Wentao Gao",
      "Jiuyong Li",
      "Lin Liu",
      "Thuc Duy Le",
      "Xiongren Chen",
      "Xiaojing Du",
      "Jixue Liu",
      "Yanchang Zhao",
      "Yun Chen"
    ],
    "abstract": "Zero-inflated data pose significant challenges in precipitation forecasting due to the predominance of zeros with sparse non-zero events. To address this, we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates Gaussian perturbation for smoothing zero-inflated distributions, Transformer-based prediction for capturing temporal patterns, and diffusion-based denoising to restore the original data structure. In our experiments, we use observational precipitation data collected from South Australia along with synthetically generated zero-inflated data. Results show that ZIDF demonstrates significant performance improvements over multiple state-of-the-art precipitation forecasting models, achieving up to 56.7\\% reduction in MSE and 21.1\\% reduction in MAE relative to the baseline Non-stationary Transformer. These findings highlight ZIDF's ability to robustly handle sparse time series data and suggest its potential generalizability to other domains where zero inflation is a key challenge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ECAI 2025 Accepted",
    "pdf_url": "https://arxiv.org/pdf/2509.10501v1",
    "published_date": "2025-09-01 13:37:59 UTC",
    "updated_date": "2025-09-01 13:37:59 UTC"
  },
  {
    "arxiv_id": "2509.04492v2",
    "title": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate",
    "authors": [
      "Charles Moslonka",
      "Hicham Randrianarivo",
      "Arthur Garnier",
      "Emmanuel Malherbe"
    ],
    "abstract": "Hallucinations in Large Language Model (LLM) outputs for Question Answering (QA) tasks can critically undermine their real-world reliability. This paper introduces a methodology for robust, one-shot hallucination detection, specifically designed for scenarios with limited data access, such as interacting with black-box LLM APIs that typically expose only a few top candidate log-probabilities per token. Our approach derives uncertainty indicators directly from these readily available log-probabilities generated during non-greedy decoding. We first derive an Entropy Production Rate (EPR) that offers baseline performance, later augmented with supervised learning. Our learned model leverages the entropic contributions of the accessible top-ranked tokens within a single generated sequence, without multiple re-runs per query. Evaluated across diverse QA datasets and multiple LLMs, this estimator significantly improves token-level hallucination detection over state-of-the-art methods. Crucially, high performance is demonstrated using only the typically small set of available log-probabilities (e.g., top-10 per token), confirming its practical efficiency and suitability for API-constrained deployments. This work provides a lightweight technique to enhance the trustworthiness of LLM responses, at the token level, after a single generation pass, for QA and Retrieval-Augmented Generation (RAG) systems. Our experiments confirmed the performance of our method against existing approaches on public dataset as well as for a financial framework analyzing annual company reports.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures, 2 tables. pre-print version",
    "pdf_url": "https://arxiv.org/pdf/2509.04492v2",
    "published_date": "2025-09-01 13:34:21 UTC",
    "updated_date": "2026-01-20 15:36:40 UTC"
  },
  {
    "arxiv_id": "2509.01441v1",
    "title": "LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance",
    "authors": [
      "Deyu Zhou",
      "Yuqi Hou",
      "Xiao Xue",
      "Xudong Lu",
      "Qingzhong Li",
      "Lizhen Cui"
    ],
    "abstract": "As the social environment is growing more complex and collaboration is deepening, factors affecting the healthy development of service ecosystem are constantly changing and diverse, making its governance a crucial research issue. Applying the scenario analysis method and conducting scenario rehearsals by constructing an experimental system before managers make decisions, losses caused by wrong decisions can be largely avoided. However, it relies on predefined rules to construct scenarios and faces challenges such as limited information, a large number of influencing factors, and the difficulty of measuring social elements. These challenges limit the quality and efficiency of generating social and uncertain scenarios for the service ecosystem. Therefore, we propose a scenario generator design method, which adaptively coordinates three Large Language Model (LLM) empowered agents that autonomously optimize experimental schemes to construct an experimental system and generate high quality scenarios. Specifically, the Environment Agent (EA) generates social environment including extremes, the Social Agent (SA) generates social collaboration structure, and the Planner Agent (PA) couples task-role relationships and plans task solutions. These agents work in coordination, with the PA adjusting the experimental scheme in real time by perceiving the states of each agent and these generating scenarios. Experiments on the ProgrammableWeb dataset illustrate our method generates more accurate scenarios more efficiently, and innovatively provides an effective way for service ecosystem governance related experimental system construction.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01441v1",
    "published_date": "2025-09-01 12:55:02 UTC",
    "updated_date": "2025-09-01 12:55:02 UTC"
  },
  {
    "arxiv_id": "2509.01439v1",
    "title": "SoccerHigh: A Benchmark Dataset for Automatic Soccer Video Summarization",
    "authors": [
      "Artur Díaz-Juan",
      "Coloma Ballester",
      "Gloria Haro"
    ],
    "abstract": "Video summarization aims to extract key shots from longer videos to produce concise and informative summaries. One of its most common applications is in sports, where highlight reels capture the most important moments of a game, along with notable reactions and specific contextual events. Automatic summary generation can support video editors in the sports media industry by reducing the time and effort required to identify key segments. However, the lack of publicly available datasets poses a challenge in developing robust models for sports highlight generation. In this paper, we address this gap by introducing a curated dataset for soccer video summarization, designed to serve as a benchmark for the task. The dataset includes shot boundaries for 237 matches from the Spanish, French, and Italian leagues, using broadcast footage sourced from the SoccerNet dataset. Alongside the dataset, we propose a baseline model specifically designed for this task, which achieves an F1 score of 0.3956 in the test set. Furthermore, we propose a new metric constrained by the length of each target summary, enabling a more objective evaluation of the generated content. The dataset and code are available at https://ipcv.github.io/SoccerHigh/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at MMSports 2025 (Dublin, Ireland)",
    "pdf_url": "https://arxiv.org/pdf/2509.01439v1",
    "published_date": "2025-09-01 12:49:51 UTC",
    "updated_date": "2025-09-01 12:49:51 UTC"
  },
  {
    "arxiv_id": "2509.01438v1",
    "title": "Unnoticeable Community Deception via Multi-objective Optimization",
    "authors": [
      "Junyuan Fang",
      "Huimin Liu",
      "Yueqi Peng",
      "Jiajing Wu",
      "Zibin Zheng",
      "Chi K. Tse"
    ],
    "abstract": "Community detection in graphs is crucial for understanding the organization of nodes into densely connected clusters. While numerous strategies have been developed to identify these clusters, the success of community detection can lead to privacy and information security concerns, as individuals may not want their personal information exposed. To address this, community deception methods have been proposed to reduce the effectiveness of detection algorithms. Nevertheless, several limitations, such as the rationality of evaluation metrics and the unnoticeability of attacks, have been ignored in current deception methods. Therefore, in this work, we first investigate the limitations of the widely used deception metric, i.e., the decrease of modularity, through empirical studies. Then, we propose a new deception metric, and combine this new metric together with the attack budget to model the unnoticeable community deception task as a multi-objective optimization problem. To further improve the deception performance, we propose two variant methods by incorporating the degree-biased and community-biased candidate node selection mechanisms. Extensive experiments on three benchmark datasets demonstrate the superiority of the proposed community deception strategies.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2509.01438v1",
    "published_date": "2025-09-01 12:49:42 UTC",
    "updated_date": "2025-09-01 12:49:42 UTC"
  },
  {
    "arxiv_id": "2509.01426v2",
    "title": "DCA: Graph-Guided Deep Embedding Clustering for Brain Atlases",
    "authors": [
      "Mo Wang",
      "Kaining Peng",
      "Jingsheng Tang",
      "Hongkai Wen",
      "Quanying Liu"
    ],
    "abstract": "Brain atlases are essential for reducing the dimensionality of neuroimaging data and enabling interpretable analysis. However, most existing atlases are predefined, group-level templates with limited flexibility and resolution. We present Deep Cluster Atlas (DCA), a graph-guided deep embedding clustering framework for generating individualized, voxel-wise brain parcellations. DCA combines a pretrained autoencoder with spatially regularized deep clustering to produce functionally coherent and spatially contiguous regions. Our method supports flexible control over resolution and anatomical scope, and generalizes to arbitrary brain structures. We further introduce a standardized benchmarking platform for atlas evaluation, using multiple large-scale fMRI datasets. Across multiple datasets and scales, DCA outperforms state-of-the-art atlases, improving functional homogeneity by 98.8% and silhouette coefficient by 29%, and achieves superior performance in downstream tasks such as autism diagnosis and cognitive decoding. We also observe that a fine-tuned pretrained model achieves superior results on the corresponding task. Codes and models are available at https://github.com/ncclab-sustech/DCA .",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Accepted as a poster at NeurIPS 2025 with scores 5554",
    "pdf_url": "https://arxiv.org/pdf/2509.01426v2",
    "published_date": "2025-09-01 12:33:32 UTC",
    "updated_date": "2025-09-20 09:35:16 UTC"
  },
  {
    "arxiv_id": "2509.01399v1",
    "title": "CabinSep: IR-Augmented Mask-Based MVDR for Real-Time In-Car Speech Separation with Distributed Heterogeneous Arrays",
    "authors": [
      "Runduo Han",
      "Yanxin Hu",
      "Yihui Fu",
      "Zihan Zhang",
      "Yukai Jv",
      "Li Chen",
      "Lei Xie"
    ],
    "abstract": "Separating overlapping speech from multiple speakers is crucial for effective human-vehicle interaction. This paper proposes CabinSep, a lightweight neural mask-based minimum variance distortionless response (MVDR) speech separation approach, to reduce speech recognition errors in back-end automatic speech recognition (ASR) models. Our contributions are threefold: First, we utilize channel information to extract spatial features, which improves the estimation of speech and noise masks. Second, we employ MVDR during inference, reducing speech distortion to make it more ASR-friendly. Third, we introduce a data augmentation method combining simulated and real-recorded impulse responses (IRs), improving speaker localization at zone boundaries and further reducing speech recognition errors. With a computational complexity of only 0.4 GMACs, CabinSep achieves a 17.5% relative reduction in speech recognition error rate in a real-recorded dataset compared to the state-of-the-art DualSep model. Demos are available at: https://cabinsep.github.io/cabinsep/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.HC",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01399v1",
    "published_date": "2025-09-01 11:50:43 UTC",
    "updated_date": "2025-09-01 11:50:43 UTC"
  },
  {
    "arxiv_id": "2509.01398v2",
    "title": "The Need for Verification in AI-Driven Scientific Discovery",
    "authors": [
      "Cristina Cornelio",
      "Takuya Ito",
      "Ryan Cory-Wright",
      "Sanjeeb Dash",
      "Lior Horesh"
    ],
    "abstract": "Artificial intelligence (AI) is transforming the practice of science. Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields. However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced. In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents. While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01398v2",
    "published_date": "2025-09-01 11:50:04 UTC",
    "updated_date": "2025-12-17 13:11:36 UTC"
  },
  {
    "arxiv_id": "2509.04491v1",
    "title": "Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR",
    "authors": [
      "Xinnian Zhao",
      "Hugo Van Hamme"
    ],
    "abstract": "This study proposes a novel approach to using TV subtitles within a weakly supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV subtitles are readily available, their imprecise alignment with corresponding audio limits their applicability as supervised targets for verbatim transcription. Rather than using subtitles as direct supervision signals, our method reimagines them as context-rich prompts. This design enables the model to handle discrepancies between spoken audio and subtitle text. Instead, generated pseudo transcripts become the primary targets, with subtitles acting as guiding cues for iterative refinement. To further enhance the process, we introduce a weighted attention mechanism that emphasizes relevant subtitle tokens during inference. Our experiments demonstrate significant improvements in transcription accuracy, highlighting the effectiveness of the proposed method in refining transcripts. These enhanced pseudo-labeled datasets provide high-quality foundational resources for training robust ASR systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "eusipco2025",
    "pdf_url": "https://arxiv.org/pdf/2509.04491v1",
    "published_date": "2025-09-01 11:43:07 UTC",
    "updated_date": "2025-09-01 11:43:07 UTC"
  },
  {
    "arxiv_id": "2509.01396v2",
    "title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks",
    "authors": [
      "Haiyuan Wan",
      "Chen Yang",
      "Junchi Yu",
      "Meiqi Tu",
      "Jiaxuan Lu",
      "Di Yu",
      "Jianbao Cao",
      "Ben Gao",
      "Jiaqing Xie",
      "Aoran Wang",
      "Wenlong Zhang",
      "Philip Torr",
      "Dongzhan Zhou"
    ],
    "abstract": "Deep research agents have attracted growing attention for their potential to orchestrate multi-stage research workflows, spanning literature synthesis, methodological design, and empirical verification. Despite these strides, evaluating their research capability faithfully is rather challenging due to the difficulty of collecting frontier research questions that genuinely capture researchers' attention and intellectual curiosity. To address this gap, we introduce DeepResearch Arena, a benchmark grounded in academic seminars that capture rich expert discourse and interaction, better reflecting real-world research environments and reducing the risk of data leakage. To automatically construct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task Generation (MAHTG) system that extracts research-worthy inspirations from seminar transcripts. The MAHTG system further translates research-worthy inspirations into high-quality research tasks, ensuring the traceability of research task formulation while filtering noise. With the MAHTG system, we curate DeepResearch Arena with over 10,000 high-quality research tasks from over 200 academic seminars, spanning 12 disciplines, such as literature, history, and science. Our extensive evaluation shows that DeepResearch Arena presents substantial challenges for current state-of-the-art agents, with clear performance gaps observed across different models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01396v2",
    "published_date": "2025-09-01 11:42:47 UTC",
    "updated_date": "2025-11-08 05:52:13 UTC"
  },
  {
    "arxiv_id": "2509.01395v1",
    "title": "LLMs cannot spot math errors, even when allowed to peek into the solution",
    "authors": [
      "KV Aditya Srivatsa",
      "Kaushal Kumar Maurya",
      "Ekaterina Kochmar"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable performance on math word problems, yet they have been shown to struggle with meta-reasoning tasks such as identifying errors in student solutions. In this work, we investigate the challenge of locating the first error step in stepwise solutions using two error reasoning datasets: VtG and PRM800K. Our experiments show that state-of-the-art LLMs struggle to locate the first error step in student solutions even when given access to the reference solution. To that end, we propose an approach that generates an intermediate corrected student solution, aligning more closely with the original student's solution, which helps improve performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01395v1",
    "published_date": "2025-09-01 11:41:10 UTC",
    "updated_date": "2025-09-01 11:41:10 UTC"
  },
  {
    "arxiv_id": "2509.01388v1",
    "title": "End-to-End Low-Level Neural Control of an Industrial-Grade 6D Magnetic Levitation System",
    "authors": [
      "Philipp Hartmann",
      "Jannick Stranghöner",
      "Klaus Neumann"
    ],
    "abstract": "Magnetic levitation is poised to revolutionize industrial automation by integrating flexible in-machine product transport and seamless manipulation. It is expected to become the standard drive for automated manufacturing. However, controlling such systems is inherently challenging due to their complex, unstable dynamics. Traditional control approaches, which rely on hand-crafted control engineering, typically yield robust but conservative solutions, with their performance closely tied to the expertise of the engineering team. In contrast, neural control learning presents a promising alternative. This paper presents the first neural controller for 6D magnetic levitation. Trained end-to-end on interaction data from a proprietary controller, it directly maps raw sensor data and 6D reference poses to coil current commands. The neural controller can effectively generalize to previously unseen situations while maintaining accurate and robust control. These results underscore the practical feasibility of learning-based neural control in complex physical systems and suggest a future where such a paradigm could enhance or even substitute traditional engineering approaches in demanding real-world applications. The trained neural controller, source code, and demonstration videos are publicly available at https://sites.google.com/view/neural-maglev.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "eess.SY",
    "comment": "8 pages, 7 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01388v1",
    "published_date": "2025-09-01 11:33:30 UTC",
    "updated_date": "2025-09-01 11:33:30 UTC"
  },
  {
    "arxiv_id": "2509.01375v1",
    "title": "Anomaly detection in network flows using unsupervised online machine learning",
    "authors": [
      "Alberto Miguel-Diez",
      "Adrián Campazas-Vega",
      "Ángel Manuel Guerrero-Higueras",
      "Claudia Álvarez-Aparicio",
      "Vicente Matellán-Olivera"
    ],
    "abstract": "Nowadays, the volume of network traffic continues to grow, along with the frequency and sophistication of attacks. This scenario highlights the need for solutions capable of continuously adapting, since network behavior is dynamic and changes over time. This work presents an anomaly detection model for network flows using unsupervised machine learning with online learning capabilities. This approach allows the system to dynamically learn the normal behavior of the network and detect deviations without requiring labeled data, which is particularly useful in real-world environments where traffic is constantly changing and labeled data is scarce. The model was implemented using the River library with a One-Class SVM and evaluated on the NF-UNSW-NB15 dataset and its extended version v2, which contain network flows labeled with different attack categories. The results show an accuracy above 98%, a false positive rate below 3.1%, and a recall of 100% in the most advanced version of the dataset. In addition, the low processing time per flow (<0.033 ms) demonstrates the feasibility of the approach for real-time applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 3 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01375v1",
    "published_date": "2025-09-01 11:21:06 UTC",
    "updated_date": "2025-09-01 11:21:06 UTC"
  },
  {
    "arxiv_id": "2509.01371v1",
    "title": "Uirapuru: Timely Video Analytics for High-Resolution Steerable Cameras on Edge Devices",
    "authors": [
      "Guilherme H. Apostolo",
      "Pablo Bauszat",
      "Vinod Nigade",
      "Henri E. Bal",
      "Lin Wang"
    ],
    "abstract": "Real-time video analytics on high-resolution cameras has become a popular technology for various intelligent services like traffic control and crowd monitoring. While extensive work has been done on improving analytics accuracy with timing guarantees, virtually all of them target static viewpoint cameras. In this paper, we present Uirapuru, a novel framework for real-time, edge-based video analytics on high-resolution steerable cameras. The actuation performed by those cameras brings significant dynamism to the scene, presenting a critical challenge to existing popular approaches such as frame tiling. To address this problem, Uirapuru incorporates a comprehensive understanding of camera actuation into the system design paired with fast adaptive tiling at a per-frame level. We evaluate Uirapuru on a high-resolution video dataset, augmented by pan-tilt-zoom (PTZ) movements typical for steerable cameras and on real-world videos collected from an actual PTZ camera. Our experimental results show that Uirapuru provides up to 1.45x improvement in accuracy while respecting specified latency budgets or reaches up to 4.53x inference speedup with on-par accuracy compared to state-of-the-art static camera approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01371v1",
    "published_date": "2025-09-01 11:18:30 UTC",
    "updated_date": "2025-09-01 11:18:30 UTC"
  },
  {
    "arxiv_id": "2509.01354v1",
    "title": "DPF-CM: A Data Processing Framework with Privacy-Preserving Vector Databases for Chinese Medical LLMs Training and Deployment",
    "authors": [
      "Wei Huang",
      "Anda Cheng",
      "Zhao Zhang",
      "Yinggui Wang"
    ],
    "abstract": "Current open-source training pipelines for Chinese medical language models predominantly emphasize optimizing training methodologies to enhance the performance of large language models (LLMs), yet lack comprehensive exploration into training data processing. To address this gap, we propose DPF-CM, a holistic Data Processing Framework for Chinese Medical LLMs training and deployment. DPF-CM comprises two core modules. The first module is a data processing pipeline tailored for model training. Beyond standard data processing operations, we (1) introduce a chained examples context-learning strategy to generate question-oriented instructions to mitigate the lack of instruction content, and (2) implement an ensemble-based filtering mechanism for preference data curation that averages multiple reward models to suppress noisy samples. The second module focuses on privacy preservation during model deployment. To prevent privacy risks from the inadvertent exposure of training data, we propose a Privacy Preserving Vector Database (PPVD) approach, which involves model memory search, high-risk database construction, secure database construction, and match-and-replace, four key stages to minimize privacy leakage during inference collectively. Experimental results show that DPF-CM significantly improves model accuracy, enabling our trained Chinese medical LLM to achieve state-of-the-art performance among open-source counterparts. Moreover, the framework reduces training data privacy leakage by 27%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01354v1",
    "published_date": "2025-09-01 10:49:32 UTC",
    "updated_date": "2025-09-01 10:49:32 UTC"
  },
  {
    "arxiv_id": "2509.01352v1",
    "title": "Causal Sensitivity Identification using Generative Learning",
    "authors": [
      "Soma Bandyopadhyay",
      "Sudeshna Sarkar"
    ],
    "abstract": "In this work, we propose a novel generative method to identify the causal impact and apply it to prediction tasks. We conduct causal impact analysis using interventional and counterfactual perspectives. First, applying interventions, we identify features that have a causal influence on the predicted outcome, which we refer to as causally sensitive features, and second, applying counterfactuals, we evaluate how changes in the cause affect the effect. Our method exploits the Conditional Variational Autoencoder (CVAE) to identify the causal impact and serve as a generative predictor. We are able to reduce confounding bias by identifying causally sensitive features. We demonstrate the effectiveness of our method by recommending the most likely locations a user will visit next in their spatiotemporal trajectory influenced by the causal relationships among various features. Experiments on the large-scale GeoLife [Zheng et al., 2010] dataset and the benchmark Asia Bayesian network validate the ability of our method to identify causal impact and improve predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, Accepted at the IJCAI 2025 Workshop on Causal Learning for Recommendation Systems (CLRS). [OpenReview link: https://openreview.net/pdf?id=f5cR7BzBSx ]",
    "pdf_url": "https://arxiv.org/pdf/2509.01352v1",
    "published_date": "2025-09-01 10:42:44 UTC",
    "updated_date": "2025-09-01 10:42:44 UTC"
  },
  {
    "arxiv_id": "2509.06984v2",
    "title": "FediLoRA: Heterogeneous LoRA for Federated Multimodal Fine-tuning under Missing Modalities",
    "authors": [
      "Lishan Yang",
      "Wei Emma Zhang",
      "Nam Kha Nguygen",
      "Po Hu",
      "Yanjun Shu",
      "Weitong Chen",
      "Mong Yuan Sim"
    ],
    "abstract": "Foundation models have demonstrated remarkable performance across a wide range of tasks, yet their large parameter sizes pose challenges for practical deployment, especially in decentralized environments. Parameter-efficient fine-tuning (PEFT), such as Low-Rank Adaptation (LoRA), reduces local computing and memory overhead, making it attractive for federated learning. However, existing federated LoRA methods typically assume uniform rank configurations and unimodal inputs, overlooking two key real-world challenges: (1) heterogeneous client resources have different LoRA ranks, and (2) multimodal data settings with potentially missing modalities. In this work, we propose FediLoRA, a simple yet effective framework for federated multimodal fine-tuning under heterogeneous LoRA ranks and missing modalities. FediLoRA introduces a dimension-wise aggregation strategy that reweights LoRA updates without information dilution during aggregation. It also includes a lightweight layer-wise model editing method that selectively incorporates global parameters to repair local components which improves both client and global model performances. Experimental results on three multimodal benchmark datasets demonstrate that FediLoRA achieves superior performance over competitive baselines in both global and personalized settings, particularly in the presence of modality incompleteness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.06984v2",
    "published_date": "2025-09-01 10:40:13 UTC",
    "updated_date": "2025-09-23 04:55:03 UTC"
  },
  {
    "arxiv_id": "2509.01350v2",
    "title": "Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models",
    "authors": [
      "Yunqing Liu",
      "Nan Zhang",
      "Zhiming Tan"
    ],
    "abstract": "Effective specification-aware part retrieval within complex CAD assemblies is essential for automated design verification and downstream engineering tasks. However, directly using LLMs/VLMs to this task presents some challenges: the input sequences may exceed model token limits, and even after processing, performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires significant computational resources, and for many high-performing general-use proprietary models (e.g., GPT or Gemini), fine-tuning access is not available. In this paper, we propose a novel part retrieval framework that requires no extra training, but using Error Notebooks + RAG for refined prompt engineering to help improve the existing general model's retrieval performance. The construction of Error Notebooks consists of two steps: (1) collecting historical erroneous CoTs and their incorrect answers, and (2) connecting these CoTs through reflective corrections until the correct solutions are obtained. As a result, the Error Notebooks serve as a repository of tasks along with their corrected CoTs and final answers. RAG is then employed to retrieve specification-relevant records from the Error Notebooks and incorporate them into the inference process. Another major contribution of our work is a human-in-the-loop CAD dataset, which is used to evaluate our method. In addition, the engineering value of our novel framework lies in its ability to effectively handle 3D models with lengthy, non-natural language metadata. Experiments with proprietary models, including GPT-4o and the Gemini series, show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute accuracy improvement on the human preference dataset. Moreover, ablation studies confirm that CoT reasoning provides benefits especially in challenging cases with higher part counts (>10).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01350v2",
    "published_date": "2025-09-01 10:39:37 UTC",
    "updated_date": "2025-09-08 02:22:16 UTC"
  },
  {
    "arxiv_id": "2509.01348v2",
    "title": "Advanced Torrential Loss Function for Precipitation Forecasting",
    "authors": [
      "Jaeho Choi",
      "Hyeri Kim",
      "Kwang-Ho Kim",
      "Jaesung Lee"
    ],
    "abstract": "Accurate precipitation forecasting is becoming increasingly important in the context of climate change. In response, machine learning-based approaches have recently gained attention as an emerging alternative to traditional methods such as numerical weather prediction and climate models. Nonetheless, many recent approaches still rely on off-the-shelf loss functions, and even the more advanced ones merely involve optimization processes based on the critical success index (CSI). The problem, however, is that CSI may become ineffective during extended dry periods when precipitation remains below the threshold, rendering it less than ideal as a criterion for optimization. To address this limitation, we introduce a simple penalty expression and reinterpret it as a quadratic unconstrained binary optimization (QUBO) formulation. Ultimately, the resulting QUBO formulation is relaxed into a differentiable advanced torrential (AT) loss function through an approximation process. The proposed AT loss demonstrates its superiority through the Lipschitz constant, forecast performance evaluations, consistency experiments, and ablation studies with the operational model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Physical Review Letters",
    "pdf_url": "https://arxiv.org/pdf/2509.01348v2",
    "published_date": "2025-09-01 10:38:13 UTC",
    "updated_date": "2025-11-14 00:32:01 UTC"
  },
  {
    "arxiv_id": "2509.01341v1",
    "title": "Street-Level Geolocalization Using Multimodal Large Language Models and Retrieval-Augmented Generation",
    "authors": [
      "Yunus Serhat Bicakci",
      "Joseph Shingleton",
      "Anahid Basiri"
    ],
    "abstract": "Street-level geolocalization from images is crucial for a wide range of essential applications and services, such as navigation, location-based recommendations, and urban planning. With the growing popularity of social media data and cameras embedded in smartphones, applying traditional computer vision techniques to localize images has become increasingly challenging, yet highly valuable. This paper introduces a novel approach that integrates open-weight and publicly accessible multimodal large language models with retrieval-augmented generation. The method constructs a vector database using the SigLIP encoder on two large-scale datasets (EMP-16 and OSV-5M). Query images are augmented with prompts containing both similar and dissimilar geolocation information retrieved from this database before being processed by the multimodal large language models. Our approach has demonstrated state-of-the-art performance, achieving higher accuracy compared against three widely used benchmark datasets (IM2GPS, IM2GPS3k, and YFCC4k). Importantly, our solution eliminates the need for expensive fine-tuning or retraining and scales seamlessly to incorporate new data sources. The effectiveness of retrieval-augmented generation-based multimodal large language models in geolocation estimation demonstrated by this paper suggests an alternative path to the traditional methods which rely on the training models from scratch, opening new possibilities for more accessible and scalable solutions in GeoAI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01341v1",
    "published_date": "2025-09-01 10:23:48 UTC",
    "updated_date": "2025-09-01 10:23:48 UTC"
  },
  {
    "arxiv_id": "2509.01338v1",
    "title": "Conformal Predictive Monitoring for Multi-Modal Scenarios",
    "authors": [
      "Francesca Cairoli",
      "Luca Bortolussi",
      "Jyotirmoy V. Deshmukh",
      "Lars Lindemann",
      "Nicola Paoletti"
    ],
    "abstract": "We consider the problem of quantitative predictive monitoring (QPM) of stochastic systems, i.e., predicting at runtime the degree of satisfaction of a desired temporal logic property from the current state of the system. Since computational efficiency is key to enable timely intervention against predicted violations, several state-of-the-art QPM approaches rely on fast machine-learning surrogates to provide prediction intervals for the satisfaction values, using conformal inference to offer statistical guarantees. However, these QPM methods suffer when the monitored agent exhibits multi-modal dynamics, whereby certain modes may yield high satisfaction values while others critically violate the property. Existing QPM methods are mode-agnostic and so would yield overly conservative and uninformative intervals that lack meaningful mode-specific satisfaction information. To address this problem, we present GenQPM, a method that leverages deep generative models, specifically score-based diffusion models, to reliably approximate the probabilistic and multi-modal system dynamics without requiring explicit model access. GenQPM employs a mode classifier to partition the predicted trajectories by dynamical mode. For each mode, we then apply conformal inference to produce statistically valid, mode-specific prediction intervals. We demonstrate the effectiveness of GenQPM on a benchmark of agent navigation and autonomous driving tasks, resulting in prediction intervals that are significantly more informative (less conservative) than mode-agnostic baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01338v1",
    "published_date": "2025-09-01 10:19:00 UTC",
    "updated_date": "2025-09-01 10:19:00 UTC"
  },
  {
    "arxiv_id": "2509.01337v1",
    "title": "LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition",
    "authors": [
      "Qianrui Zhou",
      "Hua Xu",
      "Yifan Wang",
      "Xinzhi Dong",
      "Hanlei Zhang"
    ],
    "abstract": "Understanding human intents from multimodal signals is critical for analyzing human behaviors and enhancing human-machine interactions in real-world scenarios. However, existing methods exhibit limitations in their modality-level reliance, constraining relational reasoning over fine-grained semantics for complex intent understanding. This paper proposes a novel LLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the expansive knowledge of large language models (LLMs) to establish semantic foundations that boost smaller models' relational reasoning performance. Specifically, an LLM-based strategy is proposed to extract fine-grained semantics as guidance for subsequent reasoning, driven by a shallow-to-deep Chain-of-Thought (CoT) that autonomously uncovers, describes, and ranks semantic cues by their importance without relying on manually defined priors. Besides, we formally model three fundamental types of semantic relations grounded in logical principles and analyze their nuanced interplay to enable more effective relational reasoning. Extensive experiments on multimodal intent and dialogue act recognition tasks demonstrate LGSRR's superiority over state-of-the-art methods, with consistent performance gains across diverse semantic understanding scenarios. The complete data and code are available at https://github.com/thuiar/LGSRR.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MM",
    "comment": "Accepted by EMNLP 2025 (Main Track, Long Paper)",
    "pdf_url": "https://arxiv.org/pdf/2509.01337v1",
    "published_date": "2025-09-01 10:18:47 UTC",
    "updated_date": "2025-09-01 10:18:47 UTC"
  },
  {
    "arxiv_id": "2509.01323v1",
    "title": "Multitask Battery Management with Flexible Pretraining",
    "authors": [
      "Hong Lu",
      "Jiali Chen",
      "Jingzhao Zhang",
      "Guannan He",
      "Xuebing Han",
      "Minggao Ouyang"
    ],
    "abstract": "Industrial-scale battery management involves various types of tasks, such as estimation, prediction, and system-level diagnostics. Each task employs distinct data across temporal scales, sensor resolutions, and data channels. Building task-specific methods requires a great deal of data and engineering effort, which limits the scalability of intelligent battery management. Here we present the Flexible Masked Autoencoder (FMAE), a flexible pretraining framework that can learn with missing battery data channels and capture inter-correlations across data snippets. FMAE learns unified battery representations from heterogeneous data and can be adopted by different tasks with minimal data and engineering efforts. Experimentally, FMAE consistently outperforms all task-specific methods across five battery management tasks with eleven battery datasets. On remaining life prediction tasks, FMAE uses 50 times less inference data while maintaining state-of-the-art results. Moreover, when real-world data lack certain information, such as system voltage, FMAE can still be applied with marginal performance impact, achieving comparable results with the best hand-crafted features. FMAE demonstrates a practical route to a flexible, data-efficient model that simplifies real-world multi-task management of dynamical systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01323v1",
    "published_date": "2025-09-01 10:06:19 UTC",
    "updated_date": "2025-09-01 10:06:19 UTC"
  },
  {
    "arxiv_id": "2509.01322v2",
    "title": "LongCat-Flash Technical Report",
    "authors": [
      "Meituan LongCat Team",
      "Bayan",
      "Bei Li",
      "Bingye Lei",
      "Bo Wang",
      "Bolin Rong",
      "Chao Wang",
      "Chao Zhang",
      "Chen Gao",
      "Chen Zhang",
      "Cheng Sun",
      "Chengcheng Han",
      "Chenguang Xi",
      "Chi Zhang",
      "Chong Peng",
      "Chuan Qin",
      "Chuyu Zhang",
      "Cong Chen",
      "Congkui Wang",
      "Dan Ma",
      "Daoru Pan",
      "Defei Bu",
      "Dengchang Zhao",
      "Deyang Kong",
      "Dishan Liu",
      "Feiye Huo",
      "Fengcun Li",
      "Fubao Zhang",
      "Gan Dong",
      "Gang Liu",
      "Gang Xu",
      "Ge Li",
      "Guoqiang Tan",
      "Guoyuan Lin",
      "Haihang Jing",
      "Haomin Fu",
      "Haonan Yan",
      "Haoxing Wen",
      "Haozhe Zhao",
      "Hong Liu",
      "Hongmei Shi",
      "Hongyan Hao",
      "Hongyin Tang",
      "Huantian Lv",
      "Hui Su",
      "Jiacheng Li",
      "Jiahao Liu",
      "Jiahuan Li",
      "Jiajun Yang",
      "Jiaming Wang",
      "Jian Yang",
      "Jianchao Tan",
      "Jiaqi Sun",
      "Jiaqi Zhang",
      "Jiawei Fu",
      "Jiawei Yang",
      "Jiaxi Hu",
      "Jiayu Qin",
      "Jingang Wang",
      "Jiyuan He",
      "Jun Kuang",
      "Junhui Mei",
      "Kai Liang",
      "Ke He",
      "Kefeng Zhang",
      "Keheng Wang",
      "Keqing He",
      "Liang Gao",
      "Liang Shi",
      "Lianhui Ma",
      "Lin Qiu",
      "Lingbin Kong",
      "Lingtong Si",
      "Linkun Lyu",
      "Linsen Guo",
      "Liqi Yang",
      "Lizhi Yan",
      "Mai Xia",
      "Man Gao",
      "Manyuan Zhang",
      "Meng Zhou",
      "Mengxia Shen",
      "Mingxiang Tuo",
      "Mingyang Zhu",
      "Peiguang Li",
      "Peng Pei",
      "Peng Zhao",
      "Pengcheng Jia",
      "Pingwei Sun",
      "Qi Gu",
      "Qianyun Li",
      "Qingyuan Li",
      "Qiong Huang",
      "Qiyuan Duan",
      "Ran Meng",
      "Rongxiang Weng",
      "Ruichen Shao",
      "Rumei Li",
      "Shizhe Wu",
      "Shuai Liang",
      "Shuo Wang",
      "Suogui Dang",
      "Tao Fang",
      "Tao Li",
      "Tefeng Chen",
      "Tianhao Bai",
      "Tianhao Zhou",
      "Tingwen Xie",
      "Wei He",
      "Wei Huang",
      "Wei Liu",
      "Wei Shi",
      "Wei Wang",
      "Wei Wu",
      "Weikang Zhao",
      "Wen Zan",
      "Wenjie Shi",
      "Xi Nan",
      "Xi Su",
      "Xiang Li",
      "Xiang Mei",
      "Xiangyang Ji",
      "Xiangyu Xi",
      "Xiangzhou Huang",
      "Xianpeng Li",
      "Xiao Fu",
      "Xiao Liu",
      "Xiao Wei",
      "Xiaodong Cai",
      "Xiaolong Chen",
      "Xiaoqing Liu",
      "Xiaotong Li",
      "Xiaowei Shi",
      "Xiaoyu Li",
      "Xili Wang",
      "Xin Chen",
      "Xing Hu",
      "Xingyu Miao",
      "Xinyan He",
      "Xuemiao Zhang",
      "Xueyuan Hao",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Xurui Yang",
      "Yan Feng",
      "Yang Bai",
      "Yang Chen",
      "Yang Yang",
      "Yaqi Huo",
      "Yerui Sun",
      "Yifan Lu",
      "Yifan Zhang",
      "Yipeng Zang",
      "Yitao Zhai",
      "Yiyang Li",
      "Yongjing Yin",
      "Yongkang Lv",
      "Yongwei Zhou",
      "Yu Yang",
      "Yuchen Xie",
      "Yueqing Sun",
      "Yuewen Zheng",
      "Yuhuai Wei",
      "Yulei Qian",
      "Yunfan Liang",
      "Yunfang Tai",
      "Yunke Zhao",
      "Zeyang Yu",
      "Zhao Zhang",
      "Zhaohua Yang",
      "Zhenchao Zhang",
      "Zhikang Xia",
      "Zhiye Zou",
      "Zhizhao Zeng",
      "Zhongda Su",
      "Zhuofan Chen",
      "Zijian Zhang",
      "Ziwen Wang",
      "Zixu Jiang",
      "Zizhe Zhao",
      "Zongyu Wang",
      "Zunhai Su"
    ],
    "abstract": "We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE) language model designed for both computational efficiency and advanced agentic capabilities. Stemming from the need for scalable efficiency, LongCat-Flash adopts two novel designs: (a) Zero-computation Experts, which enables dynamic computational budget allocation and activates 18.6B-31.3B (27B on average) per token depending on contextual demands, optimizing resource usage. (b) Shortcut-connected MoE, which enlarges the computation-communication overlap window, demonstrating notable gains in inference efficiency and throughput compared to models of a comparable scale. We develop a comprehensive scaling framework for large models that combines hyperparameter transfer, model-growth initialization, a multi-pronged stability suite, and deterministic computation to achieve stable and reproducible training. Notably, leveraging the synergy among scalable architectural design and infrastructure efforts, we complete model training on more than 20 trillion tokens within 30 days, while achieving over 100 tokens per second (TPS) for inference at a cost of \\$0.70 per million output tokens. To cultivate LongCat-Flash towards agentic intelligence, we conduct a large-scale pre-training on optimized mixtures, followed by targeted mid- and post-training on reasoning, code, and instructions, with further augmentation from synthetic data and tool use tasks. Comprehensive evaluations demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers highly competitive performance among other leading models, with exceptional strengths in agentic tasks. The model checkpoint of LongCat-Flash is open-sourced to foster community research.\n  LongCat Chat: https://longcat.ai\n  Hugging Face: https://huggingface.co/meituan-longcat\n  GitHub: https://github.com/meituan-longcat",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01322v2",
    "published_date": "2025-09-01 10:05:45 UTC",
    "updated_date": "2025-09-19 13:34:47 UTC"
  },
  {
    "arxiv_id": "2509.01319v2",
    "title": "Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for Prediction Intervals",
    "authors": [
      "Li Rong Wang",
      "Thomas C. Henderson",
      "Yew Soon Ong",
      "Yih Yng Ng",
      "Xiuyi Fan"
    ],
    "abstract": "Vital signs, such as heart rate and blood pressure, are critical indicators of patient health and are widely used in clinical monitoring and decision-making. While deep learning models have shown promise in forecasting these signals, their deployment in healthcare remains limited in part because clinicians must be able to trust and interpret model outputs. Without reliable uncertainty quantification -- particularly calibrated prediction intervals (PIs) -- it is unclear whether a forecasted abnormality constitutes a meaningful warning or merely reflects model noise, hindering clinical decision-making. To address this, we present two methods for deriving PIs from the Reconstruction Uncertainty Estimate (RUE), an uncertainty measure well-suited to vital-sign forecasting due to its sensitivity to data shifts and support for label-free calibration. Our parametric approach assumes that prediction errors and uncertainty estimates follow a Gaussian copula distribution, enabling closed-form PI computation. Our non-parametric approach, based on k-nearest neighbours (KNN), empirically estimates the conditional error distribution using similar validation instances. We evaluate these methods on two large public datasets with minute- and hour-level sampling, representing high- and low-frequency health signals. Experiments demonstrate that the Gaussian copula method consistently outperforms conformal prediction baselines on low-frequency data, while the KNN approach performs best on high-frequency data. These results underscore the clinical promise of RUE-derived PIs for delivering interpretable, uncertainty-aware vital sign forecasts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 25th IEEE International Conference on Data Mining (ICDM)",
    "pdf_url": "https://arxiv.org/pdf/2509.01319v2",
    "published_date": "2025-09-01 10:03:26 UTC",
    "updated_date": "2025-09-17 03:05:36 UTC"
  },
  {
    "arxiv_id": "2509.01308v2",
    "title": "GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL Generation from Large Language Models",
    "authors": [
      "Mattia Tritto",
      "Giuseppe Farano",
      "Dario Di Palma",
      "Gaetano Rossiello",
      "Fedelucio Narducci",
      "Dharmashankar Subramanian",
      "Tommaso Di Noia"
    ],
    "abstract": "Text-to-SQL, the task of translating natural language questions into SQL queries, has significantly advanced with the introduction of Large Language Models (LLMs), broadening database accessibility for a wide range of users. Despite substantial progress in generating valid SQL, current LLMs still struggle with complex queries. To address this limitation, test-time strategies such as Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the assumption that LLMs can produce correct answers after multiple attempts. However, these methods rely on surface-level heuristics, selecting the syntactically correct query through execution-based BoN (ex-BoN) or the most frequently generated one through Majority Voting. Recently, Outcome Reward Models (ORMs), which assign utility scores to generated outputs based on semantic correctness, have emerged as a promising reinforcement learning approach for improving model alignment. We argue that ORMs could serve as an effective new test-time heuristic, although their application in this context remains largely underexplored.\n  In this work, we propose a unified framework for training ORMs tailored to the Text-to-SQL task and assess their effectiveness as a test-time heuristic within the BoN strategy. We benchmark ORMs against ex-BoN and Maj across the BIRD and Spider datasets, fine-tuning diverse open-source LLMs from the Qwen2, Granite3, and Llama3 families. Results show that ORMs outperform ex-BoN and Maj, achieving execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and +2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that finetuning models already aligned with SQL generation, such as OmniSQL, yields superior ORM performance. Additionally, we observe that ORMs achieve competitive results on simple queries and benefit more from an increased number of candidates compared to ex-BoN and Maj.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01308v2",
    "published_date": "2025-09-01 09:47:35 UTC",
    "updated_date": "2025-10-29 14:09:33 UTC"
  },
  {
    "arxiv_id": "2509.01304v1",
    "title": "Animer une base de connaissance: des ontologies aux mod{è}les d'I.A. g{é}n{é}rative",
    "authors": [
      "Peter Stockinger"
    ],
    "abstract": "In a context where the social sciences and humanities are experimenting with non-anthropocentric analytical frames, this article proposes a semiotic (structural) reading of the hybridization between symbolic AI and neural (or sub-symbolic) AI based on a field of application: the design and use of a knowledge base for area studies. We describe the LaCAS ecosystem -- Open Archives in Linguistic and Cultural Studies (thesaurus; RDF/OWL ontology; LOD services; harvesting; expertise; publication), deployed at Inalco (National Institute for Oriental Languages and Civilizations) in Paris with the Okapi (Open Knowledge and Annotation Interface) software environment from Ina (National Audiovisual Institute), which now has around 160,000 documentary resources and ten knowledge macro-domains grouping together several thousand knowledge objects. We illustrate this approach using the knowledge domain ''Languages of the world'' (~540 languages) and the knowledge object ''Quechua (language)''. On this basis, we discuss the controlled integration of neural tools, more specifically generative tools, into the life cycle of a knowledge base: assistance with data localization/qualification, index extraction and aggregation, property suggestion and testing, dynamic file generation, and engineering of contextualized prompts (generic, contextual, explanatory, adjustment, procedural) aligned with a domain ontology. We outline an ecosystem of specialized agents capable of animating the database while respecting its symbolic constraints, by articulating model-driven and data-driven methods.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "in French language",
    "pdf_url": "https://arxiv.org/pdf/2509.01304v1",
    "published_date": "2025-09-01 09:40:55 UTC",
    "updated_date": "2025-09-01 09:40:55 UTC"
  },
  {
    "arxiv_id": "2509.01285v1",
    "title": "Building surrogate models using trajectories of agents trained by Reinforcement Learning",
    "authors": [
      "Julen Cestero",
      "Marco Quartulli",
      "Marcello Restelli"
    ],
    "abstract": "Sample efficiency in the face of computationally expensive simulations is a common concern in surrogate modeling. Current strategies to minimize the number of samples needed are not as effective in simulated environments with wide state spaces. As a response to this challenge, we propose a novel method to efficiently sample simulated deterministic environments by using policies trained by Reinforcement Learning. We provide an extensive analysis of these surrogate-building strategies with respect to Latin-Hypercube sampling or Active Learning and Kriging, cross-validating performances with all sampled datasets. The analysis shows that a mixed dataset that includes samples acquired by random agents, expert agents, and agents trained to explore the regions of maximum entropy of the state transition distribution provides the best scores through all datasets, which is crucial for a meaningful state space representation. We conclude that the proposed method improves the state-of-the-art and clears the path to enable the application of surrogate-aided Reinforcement Learning policy optimization strategies on complex simulators.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in ICANN 2024 conference",
    "pdf_url": "https://arxiv.org/pdf/2509.01285v1",
    "published_date": "2025-09-01 09:13:45 UTC",
    "updated_date": "2025-09-01 09:13:45 UTC"
  },
  {
    "arxiv_id": "2509.01277v1",
    "title": "Communicative Agents for Slideshow Storytelling Video Generation based on LLMs",
    "authors": [
      "Jingxing Fan",
      "Jinrong Shen",
      "Yusheng Yao",
      "Shuangqing Wang",
      "Qian Wang",
      "Yuling Wang"
    ],
    "abstract": "With the rapid advancement of artificial intelligence (AI), the proliferation of AI-generated content (AIGC) tasks has significantly accelerated developments in text-to-video generation. As a result, the field of video production is undergoing a transformative shift. However, conventional text-to-video models are typically constrained by high computational costs.\n  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show video generation system designed to redefine the video creation pipeline through the integration of large language models (LLMs). VGTeam is composed of a suite of communicative agents, each responsible for a distinct aspect of video generation, such as scriptwriting, scene creation, and audio design. These agents operate collaboratively within a chat tower workflow, transforming user-provided textual prompts into coherent, slide-style narrative videos.\n  By emulating the sequential stages of traditional video production, VGTeam achieves remarkable improvements in both efficiency and scalability, while substantially reducing computational overhead. On average, the system generates videos at a cost of only $0.103, with a successful generation rate of 98.4%. Importantly, this framework maintains a high degree of creative fidelity and customization.\n  The implications of VGTeam are far-reaching. It democratizes video production by enabling broader access to high-quality content creation without the need for extensive resources. Furthermore, it highlights the transformative potential of language models in creative domains and positions VGTeam as a pioneering system for next-generation content creation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 8 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2509.01277v1",
    "published_date": "2025-09-01 09:04:07 UTC",
    "updated_date": "2025-09-01 09:04:07 UTC"
  },
  {
    "arxiv_id": "2509.02622v2",
    "title": "IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic Scenes using Deep Filtering",
    "authors": [
      "Clémentine Berger",
      "Paraskevas Stamatiadis",
      "Roland Badeau",
      "Slim Essid"
    ],
    "abstract": "We are interested in audio systems capable of performing a differentiated processing of stationary backgrounds and isolated acoustic events within an acoustic scene, whether for applying specific processing methods to each part or for focusing solely on one while ignoring the other. Such systems have applications in real-world scenarios, including robust adaptive audio rendering systems (e.g., EQ or compression), plosive attenuation in voice mixing, noise suppression or reduction, robust acoustic event classification or even bioacoustics. To this end, we introduce IS${}^3$, a neural network designed for Impulsive--Stationary Sound Separation, that isolates impulsive acoustic events from the stationary background using a deep filtering approach, that can act as a pre-processing stage for the above-mentioned tasks. To ensure optimal training, we propose a sophisticated data generation pipeline that curates and adapts existing datasets for this task. We demonstrate that a learning-based approach, build on a relatively lightweight neural architecture and trained with well-designed and varied data, is successful in this previously unaddressed task, outperforming the Harmonic--Percussive Sound Separation masking method, adapted from music signal processing research, and wavelet filtering on objective separation metrics.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.02622v2",
    "published_date": "2025-09-01 08:55:29 UTC",
    "updated_date": "2025-09-12 09:26:25 UTC"
  },
  {
    "arxiv_id": "2509.10499v1",
    "title": "Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization",
    "authors": [
      "Duc-Thinh Ngo",
      "Kandaraj Piamrat",
      "Ons Aouedi",
      "Thomas Hassan",
      "Philippe Raipin-Parvédy"
    ],
    "abstract": "Open Radio Access Network (O-RAN) architectures enable flexible, scalable, and cost-efficient mobile networks by disaggregating and virtualizing baseband functions. However, this flexibility introduces significant challenges for resource management, requiring joint optimization of functional split selection and virtualized unit placement under dynamic demands and complex topologies. Existing solutions often address these aspects separately or lack scalability in large and real-world scenarios. In this work, we propose a novel Graph-Augmented Proximal Policy Optimization (GPPO) framework that leverages Graph Neural Networks (GNNs) for topology-aware feature extraction and integrates action masking to efficiently navigate the combinatorial decision space. Our approach jointly optimizes functional split and placement decisions, capturing the full complexity of O-RAN resource allocation. Extensive experiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO consistently outperforms state-of-the-art baselines, achieving up to 18% lower deployment cost and 25% higher reward in generalization tests, while maintaining perfect reliability. These results highlight the effectiveness and scalability of GPPO for practical O-RAN deployments.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.10499v1",
    "published_date": "2025-09-01 08:53:04 UTC",
    "updated_date": "2025-09-01 08:53:04 UTC"
  },
  {
    "arxiv_id": "2509.01257v2",
    "title": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks",
    "authors": [
      "Andrea Fox",
      "Francesco De Pellegrini",
      "Eitan Altman"
    ],
    "abstract": "In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Oral presentation at AI4NextG @ NeurIPS'25 Workshop",
    "pdf_url": "https://arxiv.org/pdf/2509.01257v2",
    "published_date": "2025-09-01 08:47:36 UTC",
    "updated_date": "2025-10-23 10:39:25 UTC"
  },
  {
    "arxiv_id": "2509.01245v4",
    "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers",
    "authors": [
      "Yusheng Zheng",
      "Yanpeng Hu",
      "Wei Zhang",
      "Andi Quinn"
    ],
    "abstract": "Operating system schedulers suffer from a fundamental semantic gap, where kernel policies fail to understand application-specific needs, leading to suboptimal performance. We introduce SchedCP, the first framework that enables fully autonomous Large Language Model (LLM) agents to safely and efficiently optimize Linux schedulers without human involvement. Our core insight is that the challenge is not merely to apply a better LLM, but to architect a decoupled control plane that separates the AI's role of semantic reasoning (\"what to optimize\") from the system's role of execution (\"how to observe and act\"), thereby separating the optimization problem into two stages: goal-inference and policy-synthesis. Implemented as Model Context Protocol(MCP) server, SchedCP provides a stable interface with three key services: a Workload Analysis Engine, an evolving Scheduler Policy Repository, and an Execution Verifier that validates all AI-generated code and configure before deployment with static and dynamic analysis.\n  We demonstrate this architecture's power with sched-agent, a multi-agent system that autonomously analyzes workloads, synthesizes custom eBPF scheduling policies, and deploys them via the sched\\_ext infrastructure. Our evaluation shows that SchedCP achieves up to an 1.79x performance improvement, and a 13x cost reduction compared to naive agentic approaches, all while maintaining high success rate. By bridging the semantic gap, SchedCP democratizes expert-level system optimization and represents a step towards creating truly self-optimizing, application-aware operating systems. The code is open-sourced in https://github.com/eunomia-bpf/schedcp",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.OS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01245v4",
    "published_date": "2025-09-01 08:38:49 UTC",
    "updated_date": "2025-09-30 02:48:14 UTC"
  },
  {
    "arxiv_id": "2509.01241v1",
    "title": "RT-DETRv2 Explained in 8 Illustrations",
    "authors": [
      "Ethan Qi Yang Chua",
      "Jen Hong Tan"
    ],
    "abstract": "Object detection architectures are notoriously difficult to understand, often more so than large language models. While RT-DETRv2 represents an important advance in real-time detection, most existing diagrams do little to clarify how its components actually work and fit together. In this article, we explain the architecture of RT-DETRv2 through a series of eight carefully designed illustrations, moving from the overall pipeline down to critical components such as the encoder, decoder, and multi-scale deformable attention. Our goal is to make the existing one genuinely understandable. By visualizing the flow of tensors and unpacking the logic behind each module, we hope to provide researchers and practitioners with a clearer mental model of how RT-DETRv2 works under the hood.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01241v1",
    "published_date": "2025-09-01 08:28:01 UTC",
    "updated_date": "2025-09-01 08:28:01 UTC"
  },
  {
    "arxiv_id": "2509.01238v1",
    "title": "Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework",
    "authors": [
      "Jiasheng Xu",
      "Mingda Li",
      "Yongqiang Tang",
      "Peijie Wang",
      "Wensheng Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in language understanding and reasoning. However, their dependence on static training corpora makes them prone to factual errors and knowledge gaps. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external knowledge sources, especially structured Knowledge Graphs (KGs), which provide explicit semantics and efficient retrieval. Existing KG-based RAG approaches, however, generally assume that anchor entities are accessible to initiate graph traversal, which limits their robustness in open world settings where accurate linking between the query and the entity is unreliable. To overcome this limitation, we propose AnchorRAG, a novel multi-agent collaboration framework for open-world RAG without the predefined anchor entities. Specifically, a predictor agent dynamically identifies candidate anchor entities by aligning user query terms with KG nodes and initializes independent retriever agents to conduct parallel multi-hop explorations from each candidate. Then a supervisor agent formulates the iterative retrieval strategy for these retriever agents and synthesizes the resulting knowledge paths to generate the final answer. This multi-agent collaboration framework improves retrieval robustness and mitigates the impact of ambiguous or erroneous anchors. Extensive experiments on four public benchmarks demonstrate that AnchorRAG significantly outperforms existing baselines and establishes new state-of-the-art results on the real-world question answering tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01238v1",
    "published_date": "2025-09-01 08:26:12 UTC",
    "updated_date": "2025-09-01 08:26:12 UTC"
  },
  {
    "arxiv_id": "2509.01236v1",
    "title": "Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors",
    "authors": [
      "Hao Yang",
      "Zhiyu Yang",
      "Yunjie Zhang",
      "Shanyi Zhu",
      "Lin Yang"
    ],
    "abstract": "Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing model inference capabilities. Despite growing interest in Chain-of-Thought reasoning, its underlying mechanisms remain unclear. This paper explores the working mechanisms of Chain-of-Thought reasoning from the perspective of the dual relationship between in-context learning and pretrained priors. We first conduct a fine-grained lexical-level analysis of rationales to examine the model's reasoning behavior. Then, by incrementally introducing noisy exemplars, we examine how the model balances pretrained priors against erroneous in-context information. Finally, we investigate whether prompt engineering can induce slow thinking in large language models. Our extensive experiments reveal three key findings: (1) The model not only quickly learns the reasoning structure at the lexical level but also grasps deeper logical reasoning patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient exemplars shifts the model's decision-making from pretrained priors to in-context signals, while misleading prompts introduce instability. (3) Long Chain-of-Thought prompting can induce the model to generate longer reasoning chains, thereby improving its performance on downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01236v1",
    "published_date": "2025-09-01 08:24:28 UTC",
    "updated_date": "2025-09-01 08:24:28 UTC"
  },
  {
    "arxiv_id": "2509.01229v1",
    "title": "LiquidGEMM: Hardware-Efficient W4A8 GEMM Kernel for High-Performance LLM Serving",
    "authors": [
      "Huanqi Hu",
      "Bowen Xiao",
      "Shixuan Sun",
      "Jianian Yin",
      "Zhexi Zhang",
      "Xiang Luo",
      "Chengquan Jiang",
      "Weiqi Xu",
      "Xiaoying Jia",
      "Xin Liu",
      "Minyi Guo"
    ],
    "abstract": "Quantization is a critical technique for accelerating LLM inference by reducing memory footprint and improving computational efficiency. Among various schemes, 4-bit weight and 8-bit activation quantization (W4A8) offers a strong balance between accuracy and performance. However, existing W4A8 GEMM kernels fall short in practice due to inefficient dequantization on CUDA Cores, which cannot keep pace with the high throughput of Tensor Cores. In this paper, we present LiquidGEMM, a hardware-efficient W4A8 GEMM kernel for efficient LLM serving. LiquidGEMM designs two key techniques: LiquidQuant, a hardware-efficient quantization method that enables fast, overflow-safe dequantization using just two arithmetic instructions per four elements; and an implicit fine-grained pipeline that fully overlaps weight loading, dequantization, and MMA across warp groups without software synchronization or redundant memory traffic. Experimental results show that LiquidGEMM achieves up to 2.90x speedup over state-of-the-art W4A8 kernels and up to 4.94x end-to-end system-level speedup. Compared to various quantized GEMM kernels in NVIDIA TensorRT-LLM, LiquidGEMM delivers 1.12-1.63x performance gains, and achieves up to 1.63x system-level speedup.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "12 pages, 13 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01229v1",
    "published_date": "2025-09-01 08:16:20 UTC",
    "updated_date": "2025-09-01 08:16:20 UTC"
  },
  {
    "arxiv_id": "2509.01221v2",
    "title": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression",
    "authors": [
      "Wei Huang",
      "Huang Wei",
      "Yinggui Wang"
    ],
    "abstract": "Large language models (LLMs) excel in general tasks but struggle with domain-specific ones, requiring fine-tuning with specific data. With many open-source LLMs available, selecting the best model for fine-tuning downstream tasks is challenging, primarily focusing on how to quickly identify the optimal LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses this challenge by: 1) Data Level: A systematic categorization of data filtering methodologies for LLMs is first established, classifying them into three distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods, and (3) hybrid approaches considering both dimensions. Further, we enhance the density of key tokens in the text achieving token compression. Subsequently, we use an LLM to iterative rewrite the text to optimize its expression. 2) Model Level: We use layer similarity scores to assess each layer's importance and remove those with lower importance. Then, we introduce a sparse merging paradigm to preserve as much of the original model's capability as possible. Extensive experiments on four datasets, medical Q&A, financial Q&A, general Q&A, and reading comprehension, show that we can select the optimal LLM while saving approximately 20-fold in training time.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01221v2",
    "published_date": "2025-09-01 08:06:49 UTC",
    "updated_date": "2025-09-04 09:30:16 UTC"
  },
  {
    "arxiv_id": "2509.01211v2",
    "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems",
    "authors": [
      "Dezhang Kong",
      "Hujin Peng",
      "Yilun Zhang",
      "Lele Zhao",
      "Zhenhua Xu",
      "Shi Lin",
      "Changting Lin",
      "Meng Han"
    ],
    "abstract": "With the proliferation of LLM-driven multi-agent systems (MAS), the security of Web links has become a critical concern. Once MAS is induced to trust a malicious link, attackers can use it as a springboard to expand the attack surface. In this paper, we propose Web Fraud Attacks, a novel type of attack manipulating unique structures of web links to deceive MAS. We design 12 representative attack variants that encompass various methods, such as homoglyph deception, sub-directory nesting, and parameter obfuscation. Through extensive experiments on these attack vectors, we demonstrate that Web fraud attacks not only exhibit significant destructive potential across different MAS architectures but also possess a distinct advantage in evasion: they circumvent the need for complex input design, lowering the threshold for attacks significantly. These results underscore the importance of addressing Web fraud attacks, providing new insights into MAS safety. Our code is available at https://github.com/JiangYingEr/Web-Fraud-Attack-in-MAS.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01211v2",
    "published_date": "2025-09-01 07:47:24 UTC",
    "updated_date": "2026-01-07 08:30:38 UTC"
  },
  {
    "arxiv_id": "2509.01206v3",
    "title": "EndoGMDE: Generalizable Monocular Depth Estimation with Mixture of Low-Rank Experts for Diverse Endoscopic Scenes",
    "authors": [
      "Liangjing Shao",
      "Chenkang Du",
      "Benshuang Chen",
      "Xueli Liu",
      "Xinrong Chen"
    ],
    "abstract": "Self-supervised monocular depth estimation is a significant task for low-cost and efficient 3D scene perception and measurement in endoscopy. However, the variety of illumination conditions and scene features is still the primary challenges for depth estimation in endoscopic scenes. In this work, a novel self-supervised framework is proposed for monocular depth estimation in diverse endoscopy. Firstly, considering the diverse features in endoscopic scenes with different tissues, a novel block-wise mixture of dynamic low-rank experts is proposed to efficiently finetune the foundation model for endoscopic depth estimation. In the proposed module, based on the input feature, different experts with a small amount of trainable parameters are adaptively selected for weighted inference, from low-rank experts which are allocated based on the generalization of each block. Moreover, a novel self-supervised training framework is proposed to jointly cope with brightness inconsistency and reflectance interference. The proposed method outperforms state-of-the-art works on SCARED dataset and SimCol dataset. Furthermore, the proposed network also achieves the best generalization based on zero-shot depth estimation on C3VD, Hamlyn and SERV-CT dataset. The outstanding performance of our model is further demonstrated with 3D reconstruction and ego-motion estimation. The proposed method could contribute to accurate endoscopy for minimally invasive measurement and surgery. The evaluation codes will be released upon acceptance, while the demo videos can be found on: https://endo-gmde.netlify.app/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 12 figures, 7 tables. Under Review",
    "pdf_url": "https://arxiv.org/pdf/2509.01206v3",
    "published_date": "2025-09-01 07:45:12 UTC",
    "updated_date": "2025-11-02 11:25:25 UTC"
  },
  {
    "arxiv_id": "2509.01198v1",
    "title": "Preserving Vector Space Properties in Dimensionality Reduction: A Relationship Preserving Loss Framework",
    "authors": [
      "Eddi Weinwurm",
      "Alexander Kovalenko"
    ],
    "abstract": "Dimensionality reduction can distort vector space properties such as orthogonality and linear independence, which are critical for tasks including cross-modal retrieval, clustering, and classification. We propose a Relationship Preserving Loss (RPL), a loss function that preserves these properties by minimizing discrepancies between relationship matrices (e.g., Gram or cosine) of high-dimensional data and their low-dimensional embeddings. RPL trains neural networks for non-linear projections and is supported by error bounds derived from matrix perturbation theory. Initial experiments suggest that RPL reduces embedding dimensions while largely retaining performance on downstream tasks, likely due to its preservation of key vector space properties. While we describe here the use of RPL in dimensionality reduction, this loss can also be applied more broadly, for example to cross-domain alignment and transfer learning, knowledge distillation, fairness and invariance, dehubbing, graph and manifold learning, and federated learning, where distributed embeddings must remain geometrically consistent.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01198v1",
    "published_date": "2025-09-01 07:31:11 UTC",
    "updated_date": "2025-09-01 07:31:11 UTC"
  },
  {
    "arxiv_id": "2509.21325v1",
    "title": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation",
    "authors": [
      "Baiqiang Wang",
      "Qian Lou",
      "Mengxin Zheng",
      "Dongfang Zhao"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG's scalability and its superior performance in terms of \"RAG-Ready Latency\"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.21325v1",
    "published_date": "2025-09-01 07:28:35 UTC",
    "updated_date": "2025-09-01 07:28:35 UTC"
  },
  {
    "arxiv_id": "2509.01186v1",
    "title": "Statutory Construction and Interpretation for Artificial Intelligence",
    "authors": [
      "Luxi He",
      "Nimra Nadeem",
      "Michel Liao",
      "Howard Chen",
      "Danqi Chen",
      "Mariano-Florentino Cuéllar",
      "Peter Henderson"
    ],
    "abstract": "AI systems are increasingly governed by natural language principles, yet a key challenge arising from reliance on language remains underexplored: interpretive ambiguity. As in legal systems, ambiguity arises both from how these principles are written and how they are applied. But while legal systems use institutional safeguards to manage such ambiguity, such as transparent appellate review policing interpretive constraints, AI alignment pipelines offer no comparable protections. Different interpretations of the same rule can lead to inconsistent or unstable model behavior. Drawing on legal theory, we identify key gaps in current alignment pipelines by examining how legal systems constrain ambiguity at both the rule creation and rule application steps. We then propose a computational framework that mirrors two legal mechanisms: (1) a rule refinement pipeline that minimizes interpretive disagreement by revising ambiguous rules (analogous to agency rulemaking or iterative legislative action), and (2) prompt-based interpretive constraints that reduce inconsistency in rule application (analogous to legal canons that guide judicial discretion). We evaluate our framework on a 5,000-scenario subset of the WildChat dataset and show that both interventions significantly improve judgment consistency across a panel of reasonable interpreters. Our approach offers a first step toward systematically managing interpretive ambiguity, an essential step for building more robust, law-following AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01186v1",
    "published_date": "2025-09-01 07:10:22 UTC",
    "updated_date": "2025-09-01 07:10:22 UTC"
  },
  {
    "arxiv_id": "2509.01185v2",
    "title": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation",
    "authors": [
      "Seganrasan Subramanian",
      "Abhigya Verma"
    ],
    "abstract": "The ability of large language models (LLMs) to process and reason over long textual inputs is critical for a wide range of real-world applications. However, progress in this area is significantly constrained by the absence of high-quality, diverse, and verifiable long-context datasets suitable for both training and evaluation. This work introduces a modular, extensible framework for synthetic long-context data generation via prompt-based interaction with LLMs. The framework supports multiple training and alignment objectives, including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO). It encompasses four core generation paradigms: multi-turn conversational dialogues, document-grounded input-output pairs, verifiable instruction-response tasks, and long-context reasoning examples. Through templated prompting, a model-agnostic architecture, and metadata-enriched outputs, the proposed approach facilitates scalable, controllable, and purpose-aligned dataset creation for advancing long-context capabilities in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01185v2",
    "published_date": "2025-09-01 07:08:45 UTC",
    "updated_date": "2025-09-04 17:22:16 UTC"
  },
  {
    "arxiv_id": "2509.01182v2",
    "title": "Question-to-Knowledge (Q2K): Multi-Agent Generation of Inspectable Facts for Product Mapping",
    "authors": [
      "Wonduk Seo",
      "Taesub Shin",
      "Hyunjin An",
      "Dokyun Kim",
      "Seunghyun Lee"
    ],
    "abstract": "Identifying whether two product listings refer to the same Stock Keeping Unit (SKU) is a persistent challenge in ecommerce, especially when explicit identifiers are missing and product names vary widely across platforms. Rule based heuristics and keyword similarity often misclassify products by overlooking subtle distinctions in brand, specification, or bundle configuration. To overcome these limitations, we propose Question to Knowledge (Q2K), a multi agent framework that leverages Large Language Models (LLMs) for reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates targeted disambiguation questions, (2) a Knowledge Agent that resolves them via focused web searches, and (3) a Deduplication Agent that reuses validated reasoning traces to reduce redundancy and ensure consistency. A human in the loop mechanism further refines uncertain cases. Experiments on real world consumer goods datasets show that Q2K surpasses strong baselines, achieving higher accuracy and robustness in difficult scenarios such as bundle identification and brand origin disambiguation. By reusing retrieved reasoning instead of issuing repeated searches, Q2K balances accuracy with efficiency, offering a scalable and interpretable solution for product integration.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE BigData 2025 Industry Track",
    "pdf_url": "https://arxiv.org/pdf/2509.01182v2",
    "published_date": "2025-09-01 07:07:19 UTC",
    "updated_date": "2025-11-11 12:13:41 UTC"
  },
  {
    "arxiv_id": "2509.01181v1",
    "title": "FocusDPO: Dynamic Preference Optimization for Multi-Subject Personalized Image Generation via Adaptive Focus",
    "authors": [
      "Qiaoqiao Jin",
      "Siming Fu",
      "Dong She",
      "Weinan Jia",
      "Hualiang Wang",
      "Mu Liu",
      "Jidong Jiang"
    ],
    "abstract": "Multi-subject personalized image generation aims to synthesize customized images containing multiple specified subjects without requiring test-time optimization. However, achieving fine-grained independent control over multiple subjects remains challenging due to difficulties in preserving subject fidelity and preventing cross-subject attribute leakage. We present FocusDPO, a framework that adaptively identifies focus regions based on dynamic semantic correspondence and supervision image complexity. During training, our method progressively adjusts these focal areas across noise timesteps, implementing a weighted strategy that rewards information-rich patches while penalizing regions with low prediction confidence. The framework dynamically adjusts focus allocation during the DPO process according to the semantic complexity of reference images and establishes robust correspondence mappings between generated and reference subjects. Extensive experiments demonstrate that our method substantially enhances the performance of existing pre-trained personalized generation models, achieving state-of-the-art results on both single-subject and multi-subject personalized image synthesis benchmarks. Our method effectively mitigates attribute leakage while preserving superior subject fidelity across diverse generation scenarios, advancing the frontier of controllable multi-subject image synthesis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01181v1",
    "published_date": "2025-09-01 07:06:36 UTC",
    "updated_date": "2025-09-01 07:06:36 UTC"
  },
  {
    "arxiv_id": "2509.01177v1",
    "title": "DynaMind: Reconstructing Dynamic Visual Scenes from EEG by Aligning Temporal Dynamics and Multimodal Semantics to Guided Diffusion",
    "authors": [
      "Junxiang Liu",
      "Junming Lin",
      "Jiangtong Li",
      "Jie Li"
    ],
    "abstract": "Reconstruction dynamic visual scenes from electroencephalography (EEG) signals remains a primary challenge in brain decoding, limited by the low spatial resolution of EEG, a temporal mismatch between neural recordings and video dynamics, and the insufficient use of semantic information within brain activity. Therefore, existing methods often inadequately resolve both the dynamic coherence and the complex semantic context of the perceived visual stimuli. To overcome these limitations, we introduce DynaMind, a novel framework that reconstructs video by jointly modeling neural dynamics and semantic features via three core modules: a Regional-aware Semantic Mapper (RSM), a Temporal-aware Dynamic Aligner (TDA), and a Dual-Guidance Video Reconstructor (DGVR). The RSM first utilizes a regional-aware encoder to extract multimodal semantic features from EEG signals across distinct brain regions, aggregating them into a unified diffusion prior. In the mean time, the TDA generates a dynamic latent sequence, or blueprint, to enforce temporal consistency between the feature representations and the original neural recordings. Together, guided by the semantic diffusion prior, the DGVR translates the temporal-aware blueprint into a high-fidelity video reconstruction. On the SEED-DV dataset, DynaMind sets a new state-of-the-art (SOTA), boosting reconstructed video accuracies (video- and frame-based) by 12.5 and 10.3 percentage points, respectively. It also achieves a leap in pixel-level quality, showing exceptional visual fidelity and temporal coherence with a 9.4% SSIM improvement and a 19.7% FVMD reduction. This marks a critical advancement, bridging the gap between neural dynamics and high-fidelity visual semantics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01177v1",
    "published_date": "2025-09-01 06:52:08 UTC",
    "updated_date": "2025-09-01 06:52:08 UTC"
  },
  {
    "arxiv_id": "2509.01166v1",
    "title": "Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning",
    "authors": [
      "Yu Liu",
      "Yanan Cao",
      "Xixun Lin",
      "Yanmin Shang",
      "Shi Wang",
      "Shirui Pan"
    ],
    "abstract": "Knowledge graph completion (KGC) aims to infer new knowledge and make predictions from knowledge graphs. Recently, large language models (LLMs) have exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily focus on designing task-specific instructions, achieving promising advancements. However, there are still two critical challenges. First, existing methods often ignore the inconsistent representation spaces between natural language and graph structures. Second, most approaches design separate instructions for different KGC tasks, leading to duplicate works and time-consuming processes. To address these challenges, we propose SAT, a novel framework that enhances LLMs for KGC via structure-aware alignment-tuning. Specifically, we first introduce hierarchical knowledge alignment to align graph embeddings with the natural language space through multi-task contrastive learning. Then, we propose structural instruction tuning to guide LLMs in performing structure-aware reasoning over KGs, using a unified graph instruction combined with a lightweight knowledge adapter. Experimental results on two KGC tasks across four benchmark datasets demonstrate that SAT significantly outperforms state-of-the-art methods, especially in the link prediction task with improvements ranging from 8.7% to 29.8%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025, Main, Long Paper",
    "pdf_url": "https://arxiv.org/pdf/2509.01166v1",
    "published_date": "2025-09-01 06:38:11 UTC",
    "updated_date": "2025-09-01 06:38:11 UTC"
  },
  {
    "arxiv_id": "2509.01153v2",
    "title": "EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection",
    "authors": [
      "Yun Chu",
      "Qiuhao Wang",
      "Enze Zhou",
      "Qian Liu",
      "Gang Zheng"
    ],
    "abstract": "Auscultation is a key method for early diagnosis of respiratory and pulmonary diseases, relying on skilled healthcare professionals. However, the process is often subjective, with variability between experts. As a result, numerous deep learning-based automatic classification methods have emerged, most of which focus on respiratory sound classification. In contrast, research on respiratory sound event detection remains limited. Existing sound event detection methods typically rely on frame-level predictions followed by post-processing to generate event-level outputs, making interval boundaries challenging to learn directly. Furthermore, many approaches can only handle fixed-length audio, limiting their applicability to variable-length respiratory sounds. Additionally, the impact of respiratory sound location information on detection performance has not been extensively explored. To address these issues, we propose a graph neural network-based framework with anchor intervals, capable of handling variable-length audio and providing more precise temporal localization for abnormal respiratory sound events. Our method improves both the flexibility and applicability of respiratory sound detection. Experiments on the SPRSound 2024 and HF Lung V1 datasets demonstrate the effectiveness of the proposed approach, and incorporating respiratory position information enhances the discrimination between abnormal sounds. The reference implementation is available at https://github.com/chumingqian/EzhouNet.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01153v2",
    "published_date": "2025-09-01 06:10:30 UTC",
    "updated_date": "2025-09-04 01:07:56 UTC"
  },
  {
    "arxiv_id": "2509.01136v1",
    "title": "Heads or Tails: A Simple Example of Causal Abstractive Simulation",
    "authors": [
      "Gabriel Simmons"
    ],
    "abstract": "This note illustrates how a variety of causal abstraction arXiv:1707.00819 arXiv:1812.03789, defined here as causal abstractive simulation, can be used to formalize a simple example of language model simulation. This note considers the case of simulating a fair coin toss with a language model. Examples are presented illustrating the ways language models can fail to simulate, and a success case is presented, illustrating how this formalism may be used to prove that a language model simulates some other system, given a causal description of the system. This note may be of interest to three groups. For practitioners in the growing field of language model simulation, causal abstractive simulation is a means to connect ad-hoc statistical benchmarking practices to the solid formal foundation of causality. Philosophers of AI and philosophers of mind may be interested as causal abstractive simulation gives a precise operationalization to the idea that language models are role-playing arXiv:2402.12422. Mathematicians and others working on causal abstraction may be interested to see a new application of the core ideas that yields a new variation of causal abstraction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.01136v1",
    "published_date": "2025-09-01 05:10:02 UTC",
    "updated_date": "2025-09-01 05:10:02 UTC"
  },
  {
    "arxiv_id": "2509.01135v1",
    "title": "MATL-DC: A Multi-domain Aggregation Transfer Learning Framework for EEG Emotion Recognition with Domain-Class Prototype under Unseen Targets",
    "authors": [
      "Guangli Li",
      "Canbiao Wu",
      "Zhehao Zhou",
      "Na Tian",
      "Zhen Liang"
    ],
    "abstract": "Emotion recognition based on electroencephalography (EEG) signals is increasingly becoming a key research hotspot in affective Brain-Computer Interfaces (aBCIs). However, the current transfer learning model greatly depends on the source domain and target domain data, which hinder the practical application of emotion recognition. Therefore, we propose a Multi-domain Aggregation Transfer Learning framework for EEG emotion recognition with Domain-Class prototype under unseen targets (MATL-DC). We design the feature decoupling module to decouple class-invariant domain features from domain-invariant class features from shallow features. In the model training stage, the multi-domain aggregation mechanism aggregates the domain feature space to form a superdomain, which enhances the characteristics of emotional EEG signals. In each superdomain, we further extract the class prototype representation by class features. In addition, we adopt the pairwise learning strategy to transform the sample classification problem into the similarity problem between sample pairs, which effectively alleviates the influence of label noise. It is worth noting that the target domain is completely unseen during the training process. In the inference stage, we use the trained domain-class prototypes for inference, and then realize emotion recognition. We rigorously validate it on the publicly available databases (SEED, SEED-IV and SEED-V). The results show that the accuracy of MATL-DC model is 84.70\\%, 68.11\\% and 61.08\\%, respectively. MATL-DC achieves comparable or even better performance than methods that rely on both source and target domains. The source code is available at https://github.com/WuCB-BCI/MATL-DC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01135v1",
    "published_date": "2025-09-01 05:08:04 UTC",
    "updated_date": "2025-09-01 05:08:04 UTC"
  },
  {
    "arxiv_id": "2509.06982v1",
    "title": "CARE: Decoding Time Safety Alignment via Rollback and Introspection Intervention",
    "authors": [
      "Xiaomeng Hu",
      "Fei Huang",
      "Chenhan Yuan",
      "Junyang Lin",
      "Tsung-Yi Ho"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed in real-world applications, ensuring the safety of their outputs during decoding has become a critical challenge. However, existing decoding-time interventions, such as Contrastive Decoding, often force a severe trade-off between safety and response quality. In this work, we propose CARE, a novel framework for decoding-time safety alignment that integrates three key components: (1) a guard model for real-time safety monitoring, enabling detection of potentially unsafe content; (2) a rollback mechanism with a token buffer to correct unsafe outputs efficiently at an earlier stage without disrupting the user experience; and (3) a novel introspection-based intervention strategy, where the model generates self-reflective critiques of its previous outputs and incorporates these reflections into the context to guide subsequent decoding steps. The framework achieves a superior safety-quality trade-off by using its guard model for precise interventions, its rollback mechanism for timely corrections, and our novel introspection method for effective self-correction. Experimental results demonstrate that our framework achieves a superior balance of safety, quality, and efficiency, attaining a low harmful response rate and minimal disruption to the user experience while maintaining high response quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.06982v1",
    "published_date": "2025-09-01 04:50:02 UTC",
    "updated_date": "2025-09-01 04:50:02 UTC"
  },
  {
    "arxiv_id": "2509.01119v1",
    "title": "SC-GIR: Goal-oriented Semantic Communication via Invariant Representation Learning",
    "authors": [
      "Senura Hansaja Wanasekara",
      "Van-Dinh Nguyen",
      "Kok-Seng",
      "M. -Duong Nguyen",
      "Symeon Chatzinotas",
      "Octavia A. Dobre"
    ],
    "abstract": "Goal-oriented semantic communication (SC) aims to revolutionize communication systems by transmitting only task-essential information. However, current approaches face challenges such as joint training at transceivers, leading to redundant data exchange and reliance on labeled datasets, which limits their task-agnostic utility. To address these challenges, we propose a novel framework called Goal-oriented Invariant Representation-based SC (SC-GIR) for image transmission. Our framework leverages self-supervised learning to extract an invariant representation that encapsulates crucial information from the source data, independent of the specific downstream task. This compressed representation facilitates efficient communication while retaining key features for successful downstream task execution. Focusing on machine-to-machine tasks, we utilize covariance-based contrastive learning techniques to obtain a latent representation that is both meaningful and semantically dense. To evaluate the effectiveness of the proposed scheme on downstream tasks, we apply it to various image datasets for lossy compression. The compressed representations are then used in a goal-oriented AI task. Extensive experiments on several datasets demonstrate that SC-GIR outperforms baseline schemes by nearly 10%,, and achieves over 85% classification accuracy for compressed data under different SNR conditions. These results underscore the effectiveness of the proposed framework in learning compact and informative latent representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, Accepted to IEEE Transactions on Mobile Computing",
    "pdf_url": "https://arxiv.org/pdf/2509.01119v1",
    "published_date": "2025-09-01 04:29:43 UTC",
    "updated_date": "2025-09-01 04:29:43 UTC"
  },
  {
    "arxiv_id": "2509.01110v2",
    "title": "NoLBERT: A No Lookahead(back) Foundational Language Model",
    "authors": [
      "Ali Kakhbod",
      "Peiyao Li"
    ],
    "abstract": "We present NoLBERT, a lightweight, timestamped foundational language model for empirical research -- particularly for forecasting in economics, finance, and the social sciences. By pretraining exclusively on text from 1976 to 1995, NoLBERT avoids both lookback and lookahead biases (information leakage) that can undermine econometric inference. It exceeds domain-specific baselines on NLP benchmarks while maintaining temporal consistency. Applied to patent texts, NoLBERT enables the construction of firm-level innovation networks and shows that gains in innovation centrality predict higher long-run profit growth.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.LG",
      "q-fin.GN"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01110v2",
    "published_date": "2025-09-01 04:07:10 UTC",
    "updated_date": "2025-11-16 23:13:08 UTC"
  },
  {
    "arxiv_id": "2509.01106v2",
    "title": "Robix: A Unified Model for Robot Interaction, Reasoning and Planning",
    "authors": [
      "Huang Fang",
      "Mengxi Zhang",
      "Heng Dong",
      "Wei Li",
      "Zixuan Wang",
      "Qifeng Zhang",
      "Xueyun Tian",
      "Yucheng Hu",
      "Hang Li"
    ],
    "abstract": "We introduce Robix, a unified model that integrates robot reasoning, task planning, and natural language interaction within a single vision-language architecture. Acting as the high-level cognitive layer in a hierarchical robot system, Robix dynamically generates atomic commands for the low-level controller and verbal responses for human interaction, enabling robots to follow complex instructions, plan long-horizon tasks, and interact naturally with human within an end-to-end framework. Robix further introduces novel capabilities such as proactive dialogue, real-time interruption handling, and context-aware commonsense reasoning during task execution. At its core, Robix leverages chain-of-thought reasoning and adopts a three-stage training strategy: (1) continued pretraining to enhance foundational embodied reasoning abilities including 3D spatial understanding, visual grounding, and task-centric reasoning; (2) supervised finetuning to model human-robot interaction and task planning as a unified reasoning-action sequence; and (3) reinforcement learning to improve reasoning-action consistency and long-horizon task coherence. Extensive experiments demonstrate that Robix outperforms both open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in interactive task execution, demonstrating strong generalization across diverse instruction types (e.g., open-ended, multi-stage, constrained, invalid, and interrupted) and various user-involved tasks such as table bussing, grocery shopping, and dietary filtering.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Tech report. Project page: https://robix-seed.github.io/robix/",
    "pdf_url": "https://arxiv.org/pdf/2509.01106v2",
    "published_date": "2025-09-01 03:53:47 UTC",
    "updated_date": "2025-09-11 12:40:54 UTC"
  },
  {
    "arxiv_id": "2509.01098v1",
    "title": "CCE: Confidence-Consistency Evaluation for Time Series Anomaly Detection",
    "authors": [
      "Zhijie Zhong",
      "Zhiwen Yu",
      "Yiu-ming Cheung",
      "Kaixiang Yang"
    ],
    "abstract": "Time Series Anomaly Detection metrics serve as crucial tools for model evaluation. However, existing metrics suffer from several limitations: insufficient discriminative power, strong hyperparameter dependency, sensitivity to perturbations, and high computational overhead. This paper introduces Confidence-Consistency Evaluation (CCE), a novel evaluation metric that simultaneously measures prediction confidence and uncertainty consistency. By employing Bayesian estimation to quantify the uncertainty of anomaly scores, we construct both global and event-level confidence and consistency scores for model predictions, resulting in a concise CCE metric. Theoretically and experimentally, we demonstrate that CCE possesses strict boundedness, Lipschitz robustness against score perturbations, and linear time complexity $\\mathcal{O}(n)$. Furthermore, we establish RankEval, a benchmark for comparing the ranking capabilities of various metrics. RankEval represents the first standardized and reproducible evaluation pipeline that enables objective comparison of evaluation metrics. Both CCE and RankEval implementations are fully open-source.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 10 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01098v1",
    "published_date": "2025-09-01 03:38:38 UTC",
    "updated_date": "2025-09-01 03:38:38 UTC"
  },
  {
    "arxiv_id": "2509.01093v1",
    "title": "Natural Context Drift Undermines the Natural Language Understanding of Large Language Models",
    "authors": [
      "Yulong Wu",
      "Viktor Schlegel",
      "Riza Batista-Navarro"
    ],
    "abstract": "How does the natural evolution of context paragraphs affect question answering in generative Large Language Models (LLMs)? To investigate this, we propose a framework for curating naturally evolved, human-edited variants of reading passages from contemporary QA benchmarks and for analyzing LLM performance across a range of semantic similarity scores, which quantify how closely each variant aligns with content seen during pretraining. Using this framework, we evaluate six QA datasets and eight LLMs with publicly available training data. Our experiments reveal that LLM performance declines as reading passages naturally diverge from the versions encountered during pretraining-even when the question and all necessary information remains present at inference time. For instance, average model accuracy on BoolQ drops by over 30% from the highest to lowest similarity bins, with slopes exceeding 70 across several LLMs. These findings suggest that natural text evolution poses a significant challenge to the language understanding capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2509.01093v1",
    "published_date": "2025-09-01 03:32:50 UTC",
    "updated_date": "2025-09-01 03:32:50 UTC"
  },
  {
    "arxiv_id": "2509.01092v2",
    "title": "REFRAG: Rethinking RAG based Decoding",
    "authors": [
      "Xiaoqiang Lin",
      "Aritra Ghosh",
      "Bryan Kian Hsiang Low",
      "Anshumali Shrivastava",
      "Vijai Mohan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in leveraging extensive external knowledge to enhance responses in multi-turn and agentic applications, such as retrieval-augmented generation (RAG). However, processing long-context inputs introduces significant system latency and demands substantial memory for the key-value cache, resulting in reduced throughput and a fundamental trade-off between knowledge enrichment and system efficiency. While minimizing latency for long-context inputs is a primary objective for LLMs, we contend that RAG require specialized consideration. In RAG, much of the LLM context consists of concatenated passages from retrieval, with only a small subset directly relevant to the query. These passages often exhibit low semantic similarity due to diversity or deduplication during re-ranking, leading to block-diagonal attention patterns that differ from those in standard LLM generation tasks. Based on this observation, we argue that most computations over the RAG context during decoding are unnecessary and can be eliminated with minimal impact on performance. To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG applications. By exploiting the sparsity structure, we demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to previous work) without loss in perplexity. In addition, our optimization framework for large context enables REFRAG to extend the context size of LLMs by 16. We provide rigorous validation of REFRAG across diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets. Experimental results confirm that REFRAG delivers substantial speedup with no loss in accuracy compared to LLaMA models and other state-of-the-art baselines across various context sizes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "fix typo perplexity->log perplexity; added recent papers",
    "pdf_url": "https://arxiv.org/pdf/2509.01092v2",
    "published_date": "2025-09-01 03:31:44 UTC",
    "updated_date": "2025-10-12 04:46:48 UTC"
  },
  {
    "arxiv_id": "2509.01083v3",
    "title": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving",
    "authors": [
      "Mingyu Yang",
      "Jae-Young Choi",
      "Kihyo Moon",
      "Minsung Jang",
      "Eunjoo Jeon"
    ],
    "abstract": "Speculative decoding accelerates large language model inference, but its reliance on a fixed speculation length is suboptimal in large-batch serving environments with diverse requests. This paper explores a new direction for dynamic adaptation by investigating a novel class of post-hoc, diagnostic signals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free framework built on two primary components: (1) a predictive signal based on the variance of the Kullback-Leibler (KLD) divergence, which diagnoses the generation's regional stability, and (2) an adaptive speculation length cap to mitigate the straggler problem in per-sequence decoding. Experiments demonstrate the potential of using KLD-based stability signals for dynamic adaptation. An algorithm guided by these signals achieves end-to-end latency competitive with leading baselines and exhibits superior robustness across diverse workloads. This robustness is particularly valuable in challenging low-acceptance-rate regimes, where the proposed signal maintains its diagnostic utility. Collectively, these findings validate post-hoc signals as a valuable component for building more robust and intelligent LLM inference systems, and highlight a promising direction for future research on dynamic speculation length adaptation.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted for presentation at the IEEE BigData 2025 Workshop (Special Session on Intelligent Data Mining). This v2 updates formatting and adds IEEE copyright notice",
    "pdf_url": "https://arxiv.org/pdf/2509.01083v3",
    "published_date": "2025-09-01 03:13:50 UTC",
    "updated_date": "2025-10-30 02:05:44 UTC"
  },
  {
    "arxiv_id": "2509.04488v1",
    "title": "Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition",
    "authors": [
      "Hao Shi",
      "Yusuke Fujita",
      "Tomoya Mizumoto",
      "Lianbo Liu",
      "Atsushi Kojima",
      "Yui Sudo"
    ],
    "abstract": "Prompts are crucial for task definition and for improving the performance of large language models (LLM)-based systems. However, existing LLM-based multi-talker (MT) automatic speech recognition (ASR) systems either omit prompts or rely on simple task-definition prompts, with no prior work exploring the design of prompts to enhance performance. In this paper, we propose extracting serialized output prompts (SOP) and explicitly guiding the LLM using structured prompts to improve system performance (SOP-MT-ASR). A Separator and serialized Connectionist Temporal Classification (CTC) layers are inserted after the speech encoder to separate and extract MT content from the mixed speech encoding in a first-speaking-first-out manner. Subsequently, the SOP, which serves as a prompt for LLMs, is obtained by decoding the serialized CTC outputs using greedy search. To train the model effectively, we design a three-stage training strategy, consisting of serialized output training (SOT) fine-tuning, serialized speech information extraction, and SOP-based adaptation. Experimental results on the LibriMix dataset show that, although the LLM-based SOT model performs well in the two-talker scenario, it fails to fully leverage LLMs under more complex conditions, such as the three-talker scenario. The proposed SOP approach significantly improved performance under both two- and three-talker conditions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.04488v1",
    "published_date": "2025-09-01 03:10:14 UTC",
    "updated_date": "2025-09-01 03:10:14 UTC"
  },
  {
    "arxiv_id": "2509.01081v2",
    "title": "Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation",
    "authors": [
      "Abdessalam Bouchekif",
      "Samer Rashwani",
      "Heba Sbahi",
      "Shahd Gaben",
      "Mutaz Al-Khatib",
      "Mohammed Ghaly"
    ],
    "abstract": "This paper evaluates the knowledge and reasoning capabilities of Large Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice questions covering diverse inheritance scenarios, designed to test models' ability to understand the inheritance context and compute the distribution of shares prescribed by Islamic jurisprudence. The results reveal a significant performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect important differences in reasoning ability and domain adaptation. We conduct a detailed error analysis to identify recurring failure patterns across models, including misunderstandings of inheritance scenarios, incorrect application of legal rules, and insufficient domain knowledge. Our findings highlight limitations in handling structured legal reasoning and suggest directions for improving performance in Islamic legal reasoning. Code: https://github.com/bouchekif/inheritance_evaluation",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 7 Tables, Code: https://github.com/bouchekif/inheritance_evaluation",
    "pdf_url": "https://arxiv.org/pdf/2509.01081v2",
    "published_date": "2025-09-01 03:08:10 UTC",
    "updated_date": "2025-09-17 06:42:45 UTC"
  },
  {
    "arxiv_id": "2509.01072v1",
    "title": "DRetNet: A Novel Deep Learning Framework for Diabetic Retinopathy Diagnosis",
    "authors": [
      "Idowu Paul Okuwobi",
      "Jingyuan Liu",
      "Jifeng Wan",
      "Jiaojiao Jiang"
    ],
    "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide, necessitating early detection to prevent vision loss. Current automated DR detection systems often struggle with poor-quality images, lack interpretability, and insufficient integration of domain-specific knowledge. To address these challenges, we introduce a novel framework that integrates three innovative contributions: (1) Adaptive Retinal Image Enhancement Using Physics-Informed Neural Networks (PINNs): this technique dynamically enhances retinal images by incorporating physical constraints, improving the visibility of critical features such as microaneurysms, hemorrhages, and exudates; (2) Hybrid Feature Fusion Network (HFFN): by combining deep learning embeddings with handcrafted features, HFFN leverages both learned representations and domain-specific knowledge to enhance generalization and accuracy; (3) Multi-Stage Classifier with Uncertainty Quantification: this method breaks down the classification process into logical stages, providing interpretable predictions and confidence scores, thereby improving clinical trust. The proposed framework achieves an accuracy of 92.7%, a precision of 92.5%, a recall of 92.6%, an F1-score of 92.5%, an AUC of 97.8%, a mAP of 0.96, and an MCC of 0.85. Ophthalmologists rated the framework's predictions as highly clinically relevant (4.8/5), highlighting its alignment with real-world diagnostic needs. Qualitative analyses, including Grad-CAM visualizations and uncertainty heatmaps, further enhance the interpretability and trustworthiness of the system. The framework demonstrates robust performance across diverse conditions, including low-quality images, noisy data, and unseen datasets. These features make the proposed framework a promising tool for clinical adoption, enabling more accurate and reliable DR detection in resource-limited settings.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2509.01072v1",
    "published_date": "2025-09-01 02:27:16 UTC",
    "updated_date": "2025-09-01 02:27:16 UTC"
  },
  {
    "arxiv_id": "2509.05333v1",
    "title": "RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness",
    "authors": [
      "Junghyun Park",
      "Tuan Anh Nguyen",
      "Dugki Min"
    ],
    "abstract": "Real world deployments often expose modern object recognition models to domain shifts that precipitate a severe drop in accuracy. Such shifts encompass (i) variations in low level image statistics, (ii) changes in object pose and viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent classes. To mitigate this degradation, we introduce the Re-Thinking Vision Language Model (RT-VLM) framework. The foundation of this framework is a unique synthetic dataset generation pipeline that produces images annotated with \"4-Clues\": precise bounding boxes, class names, detailed object-level captions, and a comprehensive context-level caption for the entire scene. We then perform parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this resource. At inference time, a two stage Re-Thinking scheme is executed: the model first emits its own four clues, then re examines these responses as evidence and iteratively corrects them. Across robustness benchmarks that isolate individual domain shifts, RT-VLM consistently surpasses strong baselines. These findings indicate that the integration of structured multimodal evidence with an explicit self critique loop constitutes a promising route toward reliable and transferable visual understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05333v1",
    "published_date": "2025-09-01 02:13:00 UTC",
    "updated_date": "2025-09-01 02:13:00 UTC"
  },
  {
    "arxiv_id": "2509.01063v1",
    "title": "An Economy of AI Agents",
    "authors": [
      "Gillian K. Hadfield",
      "Andrew Koh"
    ],
    "abstract": "In the coming decade, artificially intelligent agents with the ability to plan and execute complex tasks over long time horizons with little direct oversight from humans may be deployed across the economy. This chapter surveys recent developments and highlights open questions for economists around how AI agents might interact with humans and with each other, shape markets and organizations, and what institutions might be required for well-functioning markets.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01063v1",
    "published_date": "2025-09-01 02:07:39 UTC",
    "updated_date": "2025-09-01 02:07:39 UTC"
  },
  {
    "arxiv_id": "2509.01058v3",
    "title": "Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL",
    "authors": [
      "Xiaoying Song",
      "Anirban Saha Anik",
      "Dibakar Barua",
      "Pengcheng Luo",
      "Junhua Ding",
      "Lingzi Hong"
    ],
    "abstract": "Health misinformation spreading online poses a significant threat to public health. Researchers have explored methods for automatically generating counterspeech to health misinformation as a mitigation strategy. Existing approaches often produce uniform responses, ignoring that the health literacy level of the audience could affect the accessibility and effectiveness of counterspeech. We propose a Controlled-Literacy framework using retrieval-augmented generation (RAG) with reinforcement learning (RL) to generate tailored counterspeech adapted to different health literacy levels. In particular, we retrieve knowledge aligned with specific health literacy levels, enabling accessible and factual information to support generation. We design a reward function incorporating subjective user preferences and objective readability-based rewards to optimize counterspeech to the target health literacy level. Experiment results show that Controlled-Literacy outperforms baselines by generating more accessible and user-preferred counterspeech. This research contributes to more equitable and impactful public health communication by improving the accessibility and comprehension of counterspeech to health misinformation",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Findings of EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01058v3",
    "published_date": "2025-09-01 01:54:14 UTC",
    "updated_date": "2025-09-22 15:44:51 UTC"
  },
  {
    "arxiv_id": "2509.01057v2",
    "title": "Q-Learning-Driven Adaptive Rewiring for Cooperative Control in Heterogeneous Networks",
    "authors": [
      "Yi-Ning Weng",
      "Hsuan-Wei Lee"
    ],
    "abstract": "Cooperation emergence in multi-agent systems represents a fundamental statistical physics problem where microscopic learning rules drive macroscopic collective behavior transitions. We propose a Q-learning-based variant of adaptive rewiring that builds on mechanisms studied in the literature. This method combines temporal difference learning with network restructuring so that agents can optimize strategies and social connections based on interaction histories. Through neighbor-specific Q-learning, agents develop sophisticated partnership management strategies that enable cooperator cluster formation, creating spatial separation between cooperative and defective regions. Using power-law networks that reflect real-world heterogeneous connectivity patterns, we evaluate emergent behaviors under varying rewiring constraint levels, revealing distinct cooperation patterns across parameter space rather than sharp thermodynamic transitions. Our systematic analysis identifies three behavioral regimes: a permissive regime (low constraints) enabling rapid cooperative cluster formation, an intermediate regime with sensitive dependence on dilemma strength, and a patient regime (high constraints) where strategic accumulation gradually optimizes network structure. Simulation results show that while moderate constraints create transition-like zones that suppress cooperation, fully adaptive rewiring enhances cooperation levels through systematic exploration of favorable network configurations. Quantitative analysis reveals that increased rewiring frequency drives large-scale cluster formation with power-law size distributions. Our results establish a new paradigm for understanding intelligence-driven cooperation pattern formation in complex adaptive systems, revealing how machine learning serves as an alternative driving force for spontaneous organization in multi-agent networks.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "40 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2509.01057v2",
    "published_date": "2025-09-01 01:52:56 UTC",
    "updated_date": "2025-09-03 03:24:53 UTC"
  },
  {
    "arxiv_id": "2509.01055v3",
    "title": "VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use",
    "authors": [
      "Dongfu Jiang",
      "Yi Lu",
      "Zhuofeng Li",
      "Zhiheng Lyu",
      "Ping Nie",
      "Haozhe Wang",
      "Alex Su",
      "Hui Chen",
      "Kai Zou",
      "Chao Du",
      "Tianyu Pang",
      "Wenhu Chen"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated success in enhancing LLM reasoning capabilities, but remains limited to single-turn interactions without tool integration. While recent Agentic Reinforcement Learning with Tool use (ARLT) approaches have emerged to address multi-turn tool interactions, existing works develop task-specific codebases that suffer from fragmentation, synchronous execution bottlenecks, and limited extensibility across domains. These inefficiencies hinder broader community adoption and algorithmic innovation. We introduce VerlTool, a unified and modular framework that addresses these limitations through systematic design principles. VerlTool provides four key contributions: (1) upstream alignment with VeRL ensuring compatibility and simplified maintenance, (2) unified tool management via standardized APIs supporting diverse modalities including code execution, search, SQL databases, and vision processing, (3) asynchronous rollout execution achieving near 2$\\times$ speedup by eliminating synchronization bottlenecks, and (4) comprehensive evaluation demonstrating competitive performance across 6 ARLT domains. Our framework formalizes ARLT as multi-turn trajectories with multi-modal observation tokens (text/image/video), extending beyond single-turn RLVR paradigms. We train and evaluate models on mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web search, and software engineering tasks, achieving results comparable to specialized systems while providing unified training infrastructure. The modular plugin architecture enables rapid tool integration requiring only lightweight Python definitions, significantly reducing development overhead and providing a scalable foundation for tool-augmented RL research. Our code is open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 5 figures, 13 tables",
    "pdf_url": "https://arxiv.org/pdf/2509.01055v3",
    "published_date": "2025-09-01 01:45:18 UTC",
    "updated_date": "2025-10-17 06:09:17 UTC"
  },
  {
    "arxiv_id": "2509.01053v3",
    "title": "A Dynamic Fusion Model for Consistent Crisis Response",
    "authors": [
      "Xiaoying Song",
      "Anirban Saha Anik",
      "Eduardo Blanco",
      "Vanessa Frias-Martinez",
      "Lingzi Hong"
    ],
    "abstract": "In response to the urgent need for effective communication with crisis-affected populations, automated responses driven by language models have been proposed to assist in crisis communications. A critical yet often overlooked factor is the consistency of response style, which could affect the trust of affected individuals in responders. Despite its importance, few studies have explored methods for maintaining stylistic consistency across generated responses. To address this gap, we propose a novel metric for evaluating style consistency and introduce a fusion-based generation approach grounded in this metric. Our method employs a two-stage process: it first assesses the style of candidate responses and then optimizes and integrates them at the instance level through a fusion process. This enables the generation of high-quality responses while significantly reducing stylistic variation between instances. Experimental results across multiple datasets demonstrate that our approach consistently outperforms baselines in both response quality and stylistic uniformity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Findings of EMNLP 2025",
    "pdf_url": "https://arxiv.org/pdf/2509.01053v3",
    "published_date": "2025-09-01 01:41:52 UTC",
    "updated_date": "2025-09-20 17:15:38 UTC"
  },
  {
    "arxiv_id": "2509.01052v2",
    "title": "FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games",
    "authors": [
      "Jaewoo Ahn",
      "Junseo Kim",
      "Heeseung Yun",
      "Jaehyeon Son",
      "Dongmin Park",
      "Jaewoong Cho",
      "Gunhee Kim"
    ],
    "abstract": "GUI agents powered by LLMs show promise in interacting with diverse digital environments. Among these, video games offer a valuable testbed due to their varied interfaces, with adventure games posing additional challenges through complex, narrative-driven interactions. Existing game benchmarks, however, lack diversity and rarely evaluate agents on completing entire storylines. To address this, we introduce FlashAdventure, a benchmark of 34 Flash-based adventure games designed to test full story arc completion and tackle the observation-behavior gap: the challenge of remembering and acting on earlier gameplay information. We also propose CUA-as-a-Judge, an automated gameplay evaluator, and COAST, an agentic framework leveraging long-term clue memory to better plan and solve sequential tasks. Experiments show current GUI agents struggle with full story arcs, while COAST improves milestone completion by bridging the observation-behavior gap. Nonetheless, a marked discrepancy between humans and best-performing agents warrants continued research efforts to narrow this divide.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2025 Main. Project page: https://ahnjaewoo.github.io/flashadventure",
    "pdf_url": "https://arxiv.org/pdf/2509.01052v2",
    "published_date": "2025-09-01 01:33:16 UTC",
    "updated_date": "2025-10-15 10:33:27 UTC"
  },
  {
    "arxiv_id": "2509.01033v1",
    "title": "Seeing through Unclear Glass: Occlusion Removal with One Shot",
    "authors": [
      "Qiang Li",
      "Yuanming Cao"
    ],
    "abstract": "Images taken through window glass are often degraded by contaminants adhered to the glass surfaces. Such contaminants cause occlusions that attenuate the incoming light and scatter stray light towards the camera. Most of existing deep learning methods for neutralizing the effects of contaminated glasses relied on synthetic training data. Few researchers used real degraded and clean image pairs, but they only considered removing or alleviating the effects of rain drops on glasses. This paper is concerned with the more challenging task of learning the restoration of images taken through glasses contaminated by a wide range of occluders, including muddy water, dirt and other small foreign particles found in reality. To facilitate the learning task we have gone to a great length to acquire real paired images with and without glass contaminants. More importantly, we propose an all-in-one model to neutralize contaminants of different types by utilizing the one-shot test-time adaptation mechanism. It involves a self-supervised auxiliary learning task to update the trained model for the unique occlusion type of each test image. Experimental results show that the proposed method outperforms the state-of-the-art methods quantitatively and qualitatively in cleaning realistic contaminated images, especially the unseen ones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2509.01033v1",
    "published_date": "2025-09-01 00:01:36 UTC",
    "updated_date": "2025-09-01 00:01:36 UTC"
  }
]