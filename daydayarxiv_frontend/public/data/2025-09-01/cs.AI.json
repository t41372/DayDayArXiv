{
  "date": "2025-09-01",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-09-01 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv ç®€ç›´æ˜¯ Agent å’Œæ¨ç†èƒ½åŠ›çš„ç››å®´ï¼æ™®æ—æ–¯é¡¿å›¢é˜Ÿå‘å¸ƒçš„ **Physics Supernova** è®© AI åœ¨ç‰©ç†å¥¥èµ›ä¸­æ‹¿åˆ°äº†é‡‘ç‰Œæ°´å¹³ï¼›**ç¾å›¢** å‘å¸ƒäº† 560B å‚æ•°çš„ MoE æ¨¡å‹æŠ€æœ¯æŠ¥å‘Šï¼›**Danqi Chen** å›¢é˜Ÿåˆ™ä»æ³•å¾‹è§£é‡Šå­¦çš„è§’åº¦é‡æ–°å®¡è§† AI å¯¹é½ï¼›æ­¤å¤–ï¼Œå…³äº **Agentic OS**ï¼ˆç”¨ Agent ä¼˜åŒ– Linux å†…æ ¸ï¼‰å’Œ **RAG æ•ˆç‡** çš„ç ”ç©¶ä¹Ÿé¢‡å…·äº®ç‚¹ã€‚\n\n---\n\n### ğŸš€ å¤´æ¡ï¼šç‰©ç†é‡‘ç‰Œã€ç¾å›¢ MoE ä¸ AI å¯¹é½çš„æ³•å¾‹è§†è§’\n\n**1. [Agent/æ¨ç†] ç‰©ç†è¶…æ–°æ˜Ÿï¼šAI Agent åœ¨ 2025 å›½é™…ç‰©ç†å¥¥æ—åŒ¹å…‹ç«èµ›ä¸­åŒ¹æ•Œé¡¶å°–é‡‘ç‰Œå¾—ä¸»**\n**Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæ¥è‡ªæ™®æ—æ–¯é¡¿å¤§å­¦ Mengdi Wang ç­‰äººçš„é‡ç£…å·¥ä½œã€‚ä»–ä»¬æå‡ºäº† **Physics Supernova**ï¼Œè¿™æ˜¯ä¸€ä¸ª AI Agent ç³»ç»Ÿï¼Œåœ¨ IPhO 2025 çš„ç†è®ºé¢˜ä¸­è·å¾—äº† 23.5/30 çš„é«˜åˆ†ï¼Œæ’åæ‰€æœ‰å‚èµ›è€…çš„ç¬¬ 14 åï¼ˆå…± 406 äººï¼‰ï¼Œè¶…è¿‡äº†äººç±»é‡‘ç‰Œå¾—ä¸»çš„ä¸­ä½æ•°è¡¨ç°ã€‚\n*   **å…³é”®å‘ç°**ï¼šè¿™è¯æ˜äº†é€šè¿‡åŸåˆ™æ€§çš„å·¥å…·é›†æˆï¼ˆTool Integrationï¼‰ï¼ŒAgent ç³»ç»Ÿå¯ä»¥åœ¨æé«˜éš¾åº¦çš„ç§‘å­¦æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äººç±»é¡¶å°–æ°´å¹³ã€‚\n\n**2. [LLM/æŠ€æœ¯æŠ¥å‘Š] LongCat-Flash æŠ€æœ¯æŠ¥å‘Š**\n**LongCat-Flash Technical Report**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šç¾å›¢ LongCat å›¢é˜Ÿå‘å¸ƒäº† **LongCat-Flash**ï¼Œè¿™æ˜¯ä¸€ä¸ª **5600 äº¿å‚æ•°** çš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ã€‚\n*   **æŠ€æœ¯ç»†èŠ‚**ï¼šä¸ºäº†å…¼é¡¾æ•ˆç‡å’Œ Agent èƒ½åŠ›ï¼Œä»–ä»¬é‡‡ç”¨äº†ä¸¤é¡¹åˆ›æ–°è®¾è®¡ï¼š(1) **é›¶è®¡ç®—ä¸“å®¶ï¼ˆZero-computation Expertsï¼‰**ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡éœ€æ±‚åŠ¨æ€åˆ†é…è®¡ç®—é¢„ç®—ï¼ˆå¹³å‡æ¯ token æ¿€æ´» 27B å‚æ•°ï¼‰ï¼›(2) **Shortcut-connected MoE**ï¼Œæ‰©å¤§è®¡ç®—-é€šä¿¡é‡å çª—å£ã€‚\n*   **æˆæ•ˆ**ï¼šåœ¨ 20T token ä¸Šå®Œæˆäº†è®­ç»ƒï¼Œæ¨ç†é€Ÿåº¦è¶…è¿‡ 100 TPSï¼Œå¹¶åœ¨ Agent ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚\n\n**3. [AI Alignment/æ³•å¾‹] äººå·¥æ™ºèƒ½çš„æ³•å®šè§£é‡Šä¸æ„å»º**\n**Statutory Construction and Interpretation for Artificial Intelligence**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šDanqi Chen å’Œ Peter Henderson ç­‰äººå¸¦æ¥çš„è·¨å­¦ç§‘åŠ›ä½œã€‚è®ºæ–‡æŒ‡å‡ºï¼Œç›®å‰çš„ AI å¯¹é½ï¼ˆAlignmentï¼‰ç¼ºä¹å¤„ç†â€œè§£é‡Šæ€§æ­§ä¹‰â€ï¼ˆinterpretive ambiguityï¼‰çš„æœºåˆ¶â€”â€”å³åŒä¸€è§„åˆ™çš„ä¸åŒè§£é‡Šä¼šå¯¼è‡´æ¨¡å‹è¡Œä¸ºä¸ç¨³å®šã€‚\n*   **æ–¹æ³•**ï¼šå€Ÿé‰´æ³•å¾‹ä½“ç³»å¤„ç†æ­§ä¹‰çš„æœºåˆ¶ï¼ˆå¦‚ä¸Šè¯‰å®¡æŸ¥å’Œæ³•å¾‹è§£é‡ŠåŸåˆ™ï¼‰ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªè®¡ç®—æ¡†æ¶ï¼š(1) **è§„åˆ™ç»†åŒ–ç®¡é“**ï¼ˆç±»ä¼¼ç«‹æ³•æœºæ„ä¿®æ”¹æ­§ä¹‰è§„åˆ™ï¼‰ï¼Œ(2) **åŸºäº Prompt çš„è§£é‡Šæ€§çº¦æŸ**ï¼ˆç±»ä¼¼å¸æ³•è§£é‡ŠåŸåˆ™ï¼‰ã€‚å®éªŒè¡¨æ˜è¿™æ˜¾è‘—æé«˜äº†æ¨¡å‹åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ç³»ç»Ÿï¼šå½“ AI å¼€å§‹ç®¡ç†æ“ä½œç³»ç»Ÿ\n\n**4. [System/Agent] è¿ˆå‘ Agentic OSï¼šç”¨äº Linux è°ƒåº¦å™¨çš„ LLM Agent æ¡†æ¶**\n**Towards Agentic OS: An LLM Agent Framework for Linux Schedulers**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸ç¡¬æ ¸çš„ç³»ç»Ÿç»“åˆå·¥ä½œã€‚ä½œè€…æå‡ºäº† **SchedCP**ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…è®¸ LLM Agent è‡ªä¸»ä¼˜åŒ– Linux è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰çš„æ¡†æ¶ã€‚\n*   **æ–¹æ³•**ï¼šé€šè¿‡è§£è€¦æ§åˆ¶å¹³é¢ï¼Œåˆ†ç¦»â€œæ¨ç†ç›®æ ‡â€ï¼ˆAI è´Ÿè´£ï¼‰å’Œâ€œæ‰§è¡Œç­–ç•¥â€ï¼ˆeBPF è´Ÿè´£ï¼‰ã€‚Agent å¯ä»¥åˆ†æå·¥ä½œè´Ÿè½½ï¼Œç¼–å†™ eBPF è°ƒåº¦ç­–ç•¥å¹¶éƒ¨ç½²ã€‚\n*   **æ•ˆæœ**ï¼šç›¸æ¯”æœ´ç´  Agent æ–¹æ³•ï¼Œæˆæœ¬é™ä½ 13 å€ï¼Œæ€§èƒ½æå‡ 1.79 å€ï¼ŒçœŸæ­£è¿ˆå‘äº†â€œè‡ªä¼˜åŒ–æ“ä½œç³»ç»Ÿâ€ã€‚\n\n**5. [RL/Tools] VerlToolï¼šè¿ˆå‘åŒ…å«å·¥å…·ä½¿ç”¨çš„æ•´ä½“ Agentic å¼ºåŒ–å­¦ä¹ **\n**VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ç›®å‰ Agent å¼ºåŒ–å­¦ä¹ ï¼ˆARLTï¼‰ä»£ç åº“ç¢ç‰‡åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº† **VerlTool** æ¡†æ¶ã€‚\n*   **äº®ç‚¹**ï¼šå®ƒæ”¯æŒå¤šè½®å¯¹è¯ã€å¤šæ¨¡æ€è§‚å¯Ÿï¼Œå¹¶è§£å†³äº†åŒæ­¥æ‰§è¡Œçš„ç“¶é¢ˆï¼ˆå®ç°å¼‚æ­¥ rolloutï¼Œé€Ÿåº¦æå‡ 2 å€ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ã€æ¨¡å—åŒ–çš„åŸºç¡€è®¾æ–½ï¼Œé€‚åˆåš Tool-augmented RL çš„ç ”ç©¶è€…ä½¿ç”¨ã€‚\n\n**6. [Agent Benchmark] DeepResearch Arenaï¼šé€šè¿‡ç ”è®¨ä¼šä»»åŠ¡å¯¹ LLM ç ”ç©¶èƒ½åŠ›çš„é¦–ä¸ªè€ƒæ ¸**\n**DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ºäº†è¯„ä¼° Agent çœŸæ­£çš„â€œæ·±åº¦ç ”ç©¶â€èƒ½åŠ›ï¼Œä½œè€…åŸºäºå­¦æœ¯ç ”è®¨ä¼šï¼ˆSeminarï¼‰çš„å†…å®¹æ„å»ºäº†ä¸€ä¸ª Benchmarkã€‚\n*   **é€»è¾‘**ï¼šçœŸæ­£çš„ç§‘ç ”ä¸ä»…ä»…æ˜¯æŸ¥èµ„æ–™ï¼Œè¿˜éœ€è¦çµæ„Ÿå’Œæ–¹æ³•è®ºè®¾è®¡ã€‚è¯¥æµ‹è¯•é›†åŒ…å« 10,000+ é«˜è´¨é‡ç ”ç©¶ä»»åŠ¡ï¼Œæ˜¯å¯¹å½“å‰ Agent ç§‘ç ”èƒ½åŠ›çš„ä¸€æ¬¡ä¸¥è‹›å¤§è€ƒã€‚\n\n---\n\n### âš¡ æ•ˆç‡ä¸è®­ç»ƒï¼šè®© Transformer æ›´å¿«æ›´å‡†\n\n**7. [Training/Efficiency] GradESï¼šåŸºäºæ¢¯åº¦çš„æ—©åœæœºåˆ¶æ˜¾è‘—åŠ é€Ÿ Transformer è®­ç»ƒ**\n**GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§é’ˆå¯¹ Transformer ç»„ä»¶ï¼ˆæŠ•å½±å±‚å’Œ FFNï¼‰çš„ç»†ç²’åº¦æ—©åœæ–¹æ³•ã€‚\n*   **å‘ç°**ï¼šä½œè€…å‘ç°ä¸åŒç»„ä»¶åœ¨å¾®è°ƒæ—¶çš„æ”¶æ•›é€Ÿåº¦ä¸åŒã€‚**GradES** ç›‘æ§å„å±‚æ¢¯åº¦çš„å˜åŒ–å¹…åº¦ï¼Œä¸€æ—¦æŸå±‚æ”¶æ•›å°±åœæ­¢æ›´æ–°è¯¥å±‚ã€‚\n*   **æ•ˆæœ**ï¼šè®­ç»ƒé€Ÿåº¦æå‡ **1.57-7.22 å€**ï¼Œä¸”é€šè¿‡é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œåœ¨å¤šæ¨¡æ€åŸºå‡†ä¸Šå‡†ç¡®ç‡æå‡äº† 3.88%ã€‚\n\n**8. [RAG/Efficiency] REFRAGï¼šé‡æ–°æ€è€ƒåŸºäº RAG çš„è§£ç **\n**REFRAG: Rethinking RAG based Decoding**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šAnshumali Shrivastava å›¢é˜Ÿä½œå“ã€‚é’ˆå¯¹ RAG åœºæ™¯ä¸‹é•¿ Context å¯¼è‡´çš„é«˜å»¶è¿Ÿé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§£ç æ¡†æ¶ã€‚\n*   **æ´å¯Ÿ**ï¼šRAG æ£€ç´¢å›æ¥çš„æ–‡æ¡£å¾ˆå¤šæ˜¯ä¸ç›¸å…³çš„ï¼Œå¯¼è‡´ Attention æ¨¡å¼å‘ˆç°ç¨€ç–çš„å—å¯¹è§’ï¼ˆblock-diagonalï¼‰ç»“æ„ã€‚åˆ©ç”¨è¿™ä¸€ç‰¹æ€§ï¼ŒREFRAG åœ¨ä¸æŸå¤±å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰çš„æƒ…å†µä¸‹ï¼Œå®ç°äº† **3.75 å€** çš„é¦– Token åŠ é€Ÿã€‚\n\n**9. [Training/Causal] CATï¼šå› æœæ³¨æ„åŠ›å¾®è°ƒï¼Œå°†ç»†ç²’åº¦å› æœçŸ¥è¯†æ³¨å…¥ LLM**\n**CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸ºäº†è§£å†³ LLM å®¹æ˜“å­¦ä¹ åˆ°ä¼ªç›¸å…³ï¼ˆSpurious Correlationï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº† **CAT**ã€‚\n*   **æ–¹æ³•**ï¼šé€šè¿‡ Re-Attention æœºåˆ¶ï¼Œåˆ©ç”¨äººç±»å…ˆéªŒçŸ¥è¯†æŒ‡å¯¼æ¨¡å‹å…³æ³¨å› æœç»“æ„ï¼Œä»è€Œåœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰åœºæ™¯ä¸‹æ˜¾è‘—æå‡é²æ£’æ€§ã€‚\n\n---\n\n### ğŸ§ è¯„ä¼°ã€å®‰å…¨ä¸è·¨å­¦ç§‘\n\n**10. [Evaluation] ç¼ºé™·è¿˜æ˜¯å‡è±¡ï¼Ÿé‡æ–°æ€è€ƒè¯„ä¼° LLM æ—¶çš„ Prompt æ•æ„Ÿæ€§**\n**Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå¤§å®¶å¸¸è¯Ÿç—… LLM å¯¹ Prompt å¤ªæ•æ„Ÿï¼ˆæ¢ä¸ªè¯´æ³•ç»“æœå°±ä¸ä¸€æ ·ï¼‰ã€‚ä½†è¿™ç¯‡è®ºæ–‡é€šè¿‡ç³»ç»Ÿè¯„ä¼°å‘ç°ï¼Œè¿™ç§â€œæ•æ„Ÿæ€§â€å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯**è¯„ä¼°æ–¹æ³•çš„é”…**ï¼ˆç‰¹åˆ«æ˜¯åŸºäºå¯¹æ•°ä¼¼ç„¶å’ŒåƒµåŒ–çš„ç­”æ¡ˆåŒ¹é…ï¼‰ã€‚\n*   **ç»“è®º**ï¼šå½“ä½¿ç”¨ \"LLM-as-a-Judge\" è¿›è¡Œè¯­ä¹‰çº§è¯„ä¼°æ—¶ï¼Œæ¨¡å‹çš„è¡¨ç°æ–¹å·®å¤§å¹…é™ä½ã€‚ç°ä»£ LLM å…¶å®æ¯”æˆ‘ä»¬è®¤ä¸ºçš„è¦é²æ£’å¾—å¤šã€‚\n\n**11. [Math/Reasoning] LLM æ— æ³•å‘ç°æ•°å­¦é”™è¯¯ï¼Œå³ä½¿å…è®¸å®ƒä»¬å·çœ‹ç­”æ¡ˆ**\n**LLMs cannot spot math errors, even when allowed to peek into the solution**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šç ”ç©¶äº† LLM çš„å…ƒæ¨ç†ï¼ˆMeta-reasoningï¼‰èƒ½åŠ›ã€‚å®éªŒå‘ç°ï¼Œå³ä¾¿æ˜¯ SOTA æ¨¡å‹ï¼Œåœ¨ç»™å®šäº†æ­£ç¡®å‚è€ƒç­”æ¡ˆçš„æƒ…å†µä¸‹ï¼Œä¾ç„¶å¾ˆéš¾å®šä½å­¦ç”Ÿè§£é¢˜æ­¥éª¤ä¸­çš„**ç¬¬ä¸€ä¸ªé”™è¯¯æ­¥éª¤**ã€‚\n*   **å»ºè®®**ï¼šç”Ÿæˆä¸€ä¸ªâ€œä¸­é—´ä¿®æ­£ç‰ˆâ€çš„è§£é¢˜è¿‡ç¨‹å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å®šä½é”™è¯¯ã€‚\n\n**12. [Economics/LLM] NoLBERTï¼šæ— å‰ç»ï¼ˆLookaheadï¼‰çš„åŸºç¡€è¯­è¨€æ¨¡å‹**\n**NoLBERT: A No Lookahead(back) Foundational Language Model**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸“ä¸ºç»æµå­¦å’Œç¤¾ä¼šç§‘å­¦å®è¯ç ”ç©¶è®¾è®¡çš„æ¨¡å‹ã€‚\n*   **ç—›ç‚¹**ï¼šæ™®é€š LLM è®­ç»ƒæ•°æ®çš„æ—¶é—´è·¨åº¦æ··æ‚ï¼Œå¯¼è‡´åœ¨åšå†å²é¢„æµ‹æ—¶å­˜åœ¨â€œæœªæ¥ä¿¡æ¯æ³„éœ²â€ï¼ˆLookahead Biasï¼‰ã€‚**NoLBERT** ä»…åœ¨ 1976-1995 å¹´çš„æ–‡æœ¬ä¸Šé¢„è®­ç»ƒï¼Œä¿è¯äº†æ—¶é—´ä¸Šçš„ä¸€è‡´æ€§ï¼Œéå¸¸é€‚åˆåšåŸºäºæ–‡æœ¬çš„ç»æµé¢„æµ‹ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€\n\n**13. [Vision/Tutorial] RT-DETRv2 çš„ 8 å¼ å›¾è§£**\n**RT-DETRv2 Explained in 8 Illustrations**\n*   **æ¨èç†ç”±**ï¼šè¿™æ˜¯ä¸€ç¯‡éå¸¸å‹å¥½çš„è§£é‡Šæ€§æ–‡ç« ã€‚ä½œè€…ç”¨ 8 å¼ ç²¾å¿ƒè®¾è®¡çš„æ’å›¾ï¼Œæ‹†è§£äº† RT-DETRv2 è¿™ä¸ªå®æ—¶ç›®æ ‡æ£€æµ‹æ¶æ„çš„ç»†èŠ‚ï¼Œé€‚åˆæƒ³è¦æ·±å…¥ç†è§£è¯¥æ¨¡å‹å†…éƒ¨æœºåˆ¶ï¼ˆEncoder, Decoder, Attentionï¼‰çš„ç ”ç©¶è€…ã€‚\n\n**14. [Video Editing] O-DisCo-Editï¼šç”¨äºç»Ÿä¸€é€¼çœŸè§†é¢‘ç¼–è¾‘çš„å¯¹è±¡å¤±çœŸæ§åˆ¶**\n**O-DisCo-Edit: Object Distortion Control for Unified Realistic Video Editing**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³äº†è§†é¢‘ç¼–è¾‘ä¸­ä¿æŒéç¼–è¾‘åŒºåŸŸç¨³å®šæ€§çš„éš¾é¢˜ã€‚æå‡ºäº†ä¸€ç§åŸºäºå™ªå£°çš„å¯¹è±¡å¤±çœŸæ§åˆ¶ä¿¡å·ï¼Œé…åˆâ€œå¤åˆ¶-å½¢å¼â€ä¿æŒæ¨¡å—ï¼Œå®ç°äº†é«˜ä¿çœŸçš„è§†é¢‘ç¼–è¾‘ã€‚\n\n**15. [Vision/Robustness] RT-VLMï¼šåˆ©ç”¨ 4 æ¡çº¿ç´¢é‡æ„è§†è§‰è¯­è¨€æ¨¡å‹ä»¥æå‡é²æ£’æ€§**\n**RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness**\n*   **æ–¹æ³•**ï¼šä¸ºäº†è§£å†³çœŸå®ä¸–ç•Œä¸­çš„é®æŒ¡ã€è§†è§’å˜åŒ–ç­‰é—®é¢˜ï¼Œä½œè€…è®©æ¨¡å‹ç”Ÿæˆ 4 æ¡çº¿ç´¢ï¼ˆBoxã€ç±»åã€å¯¹è±¡çº§ Captionã€åœºæ™¯çº§ Captionï¼‰ï¼Œç„¶åè¿›è¡Œè‡ªæˆ‘æ‰¹åˆ¤ï¼ˆSelf-Critiqueï¼‰å’Œä¿®æ­£ã€‚è¿™ç§â€œåæ€â€æœºåˆ¶æ˜¾è‘—æå‡äº†é²æ£’æ€§ã€‚\n\n---\n**ç»“è¯­ï¼š**\nä»Šå¤©çš„è®ºæ–‡è´¨é‡å¾ˆé«˜ï¼Œå°¤å…¶æ¨èå¤§å®¶é˜…è¯» **Physics Supernova** æ„Ÿå— Agent åœ¨ç¡¬ç§‘å­¦é¢†åŸŸçš„çªç ´ï¼Œä»¥åŠ **Statutory Construction** å¸¦æ¥çš„è·¨å­¦ç§‘å¯¹é½æ–°æ€è·¯ã€‚åš Systems çš„åŒå­¦ä¸è¦é”™è¿‡ **Agentic OS**ã€‚\n\nç¥å¤§å®¶é˜…è¯»æ„‰å¿«ï¼Œç§‘ç ”é¡ºåˆ©ï¼",
  "papers": [
    {
      "arxiv_id": "2509.01842v3",
      "title": "GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping",
      "title_zh": "GradESï¼šåŸºäºæ¢¯åº¦æ—©åœæœºåˆ¶æ˜¾è‘—åŠ é€Ÿ Transformer è®­ç»ƒ",
      "authors": [
        "Qifu Wen",
        "Xi Zeng",
        "Zihan Zhou",
        "Shuaijun Liu",
        "Mehdi Hosseinzadeh",
        "Ningxin Su",
        "Reza Rawassizadeh"
      ],
      "abstract": "Early stopping monitors global validation loss and halts all parameter updates simultaneously, which is computationally costly for large transformers due to the extended time required for validation inference. We propose \\textit{GradES}, a novel gradient-based early stopping approach that operates within transformer components (attention projections and Feed-Forward layer matrices). We found that different components converge at varying rates during fine-tuning for both language and vision-language models. \\textit{GradES} tracks the magnitude of gradient changes in backpropagation for these matrices during training. When a projection matrix's magnitude of gradient changes fall below a convergence threshold $Ï„$, we exclude that projection matrix from further updates individually, eliminating costly validation passes while allowing slow converging matrices to continue learning. \\textit{GradES} speeds up training time by 1.57--7.22$\\times$ while simultaneously enhancing generalization through early prevention of overfitting, resulting in 1.2\\% higher average accuracy in language tasks and 3.88\\% on multimodal benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GradESï¼Œä¸€ç§é’ˆå¯¹ Transformer æ¨¡å‹çš„æ–°å‹æ¢¯åº¦é©±åŠ¨æ—©åœï¼ˆEarly Stoppingï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸåŸºäºå…¨å±€éªŒè¯æŸå¤±çš„æ—©åœæœºåˆ¶åœ¨å¤§å‹æ¨¡å‹ä¸­è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚ä¸ä¼ ç»ŸåŒæ­¥åœæ­¢æ‰€æœ‰å‚æ•°æ›´æ–°çš„æ–¹æ³•ä¸åŒï¼ŒGradES ä½œç”¨äº Transformer çš„å†…éƒ¨ç»„ä»¶ï¼Œå¦‚ Attention æŠ•å½±å’Œ Feed-Forward å±‚çŸ©é˜µï¼Œèƒ½å¤Ÿæ•æ‰ä¸åŒç»„ä»¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å·®å¼‚åŒ–çš„æ”¶æ•›é€Ÿåº¦ã€‚è¯¥æ–¹æ³•åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è¿½è¸ªçŸ©é˜µæ¢¯åº¦çš„å˜åŒ–å¹…åº¦ï¼Œå½“ç‰¹å®šæŠ•å½±çŸ©é˜µçš„å˜åŒ–ä½äºé¢„è®¾é˜ˆå€¼ $\\tau$ æ—¶ï¼Œä¾¿å°†å…¶å•ç‹¬æ’é™¤åœ¨åç»­æ›´æ–°ä¹‹å¤–ï¼Œä»è€Œåœ¨å…è®¸æ…¢æ”¶æ•›çŸ©é˜µç»§ç»­å­¦ä¹ çš„åŒæ—¶å‡å°‘äº†æ˜‚è´µçš„éªŒè¯æ¨ç†æ¬¡æ•°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGradES å°†è®­ç»ƒæ—¶é—´ç¼©çŸ­äº† 1.57 è‡³ 7.22 å€ï¼Œå¹¶æœ‰æ•ˆé¢„é˜²äº†è¿‡æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½¿è¯­è¨€ä»»åŠ¡çš„å¹³å‡å‡†ç¡®ç‡æå‡äº† 1.2%ï¼Œå¹¶åœ¨å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­æå‡äº† 3.88%ï¼Œå®ç°äº†è®­ç»ƒé€Ÿåº¦ä¸æ¨¡å‹æ€§èƒ½çš„åŒé‡æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01842v3",
      "published_date": "2025-09-01 23:51:12 UTC",
      "updated_date": "2025-10-16 18:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:29.055506+00:00"
    },
    {
      "arxiv_id": "2509.01839v5",
      "title": "HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices",
      "title_zh": "HodgeFormerï¼šåŸºäºæ•°æ®é©±åŠ¨ Hodge çŸ©é˜µçš„ä¸‰è§’ç½‘æ ¼å¯å­¦ä¹ ç®—å­ Transformer",
      "authors": [
        "Akis Nousias",
        "Stavros Nousias"
      ],
      "abstract": "Currently, prominent Transformer architectures applied on graphs and meshes for shape analysis tasks employ traditional attention layers that heavily utilize spectral features requiring costly eigenvalue decomposition-based methods. To encode the mesh structure, these methods derive positional embeddings, that heavily rely on eigenvalue decomposition based operations, e.g. on the Laplacian matrix, or on heat-kernel signatures, which are then concatenated to the input features. This paper proposes a novel approach inspired by the explicit construction of the Hodge Laplacian operator in Discrete Exterior Calculus as a product of discrete Hodge operators and exterior derivatives, i.e. $(L := \\star_0^{-1} d_0^T \\star_1 d_0)$. We adjust the Transformer architecture in a novel deep learning layer that utilizes the multi-head attention mechanism to approximate Hodge matrices $\\star_0$, $\\star_1$ and $\\star_2$ and learn families of discrete operators $L$ that act on mesh vertices, edges and faces. Our approach results in a computationally-efficient architecture that achieves comparable performance in mesh segmentation and classification tasks, through a direct learning framework, while eliminating the need for costly eigenvalue decomposition operations or complex preprocessing operations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HodgeFormerï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¸ºä¸‰è§’ç½‘æ ¼ï¼ˆTriangular Meshesï¼‰å¼€å‘å¯å­¦ä¹ ç®—å­çš„æ–°å‹Transformeræ¶æ„ã€‚é’ˆå¯¹ç°æœ‰ç½‘æ ¼åˆ†æä»»åŠ¡ä¸­Transformeræ¨¡å‹è¿‡åº¦ä¾èµ–æ˜‚è´µçš„ç‰¹å¾å€¼åˆ†è§£ï¼ˆEigenvalue Decompositionï¼‰å’Œè°±ç‰¹å¾ï¼ˆSpectral Featuresï¼‰çš„é—®é¢˜ï¼ŒHodgeFormerå¼•å…¥äº†å—ç¦»æ•£å¤–å¾®ç§¯åˆ†ï¼ˆDiscrete Exterior Calculusï¼‰å¯å‘çš„æ„å»ºæ–¹æ³•ã€‚è¯¥æ¶æ„åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆMulti-head Attentionï¼‰æ¥è¿‘ä¼¼å­¦ä¹ HodgeçŸ©é˜µï¼ˆ$\\star_0, \\star_1, \\star_2$ï¼‰ï¼Œè¿›è€Œæ„å»ºå¹¶å­¦ä¹ ä½œç”¨äºç½‘æ ¼é¡¶ç‚¹ã€è¾¹å’Œé¢çš„ç¦»æ•£ç®—å­ï¼ˆDiscrete Operatorsï¼‰ã€‚è¿™ç§æ–¹æ³•é€šè¿‡ç›´æ¥å­¦ä¹ æ¡†æ¶æ›¿ä»£äº†æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µï¼ˆLaplacian Matrixï¼‰è¿ç®—æˆ–çƒ­æ ¸ç­¾åï¼ˆHeat-kernel Signaturesï¼‰ç­‰å¤æ‚çš„ç»“æ„ç¼–ç ä¸é¢„å¤„ç†æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHodgeFormeråœ¨ç½‘æ ¼åˆ†å‰²ï¼ˆMesh Segmentationï¼‰å’Œåˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†ä¸ä¸»æµæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚ä¸æ­¤åŒæ—¶ï¼Œè¯¥æ¶æ„æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œå½»åº•æ¶ˆé™¤äº†å¯¹é«˜æˆæœ¬è°±è®¡ç®—çš„éœ€æ±‚ï¼Œä¸ºé«˜æ•ˆçš„å‡ ä½•æ·±åº¦å­¦ä¹ æä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "15 pages, 13 figures, 10 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01839v5",
      "published_date": "2025-09-01 23:43:43 UTC",
      "updated_date": "2025-12-05 21:47:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:44.200323+00:00"
    },
    {
      "arxiv_id": "2509.01838v1",
      "title": "Goal-Conditioned Reinforcement Learning for Data-Driven Maritime Navigation",
      "title_zh": "é¢å‘æ•°æ®é©±åŠ¨æµ·ä¸Šå¯¼èˆªçš„ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Vaishnav Vaidheeswaran",
        "Dilith Jayakody",
        "Samruddhi Mulay",
        "Anand Lo",
        "Md Mahbub Alam",
        "Gabriel Spadon"
      ],
      "abstract": "Routing vessels through narrow and dynamic waterways is challenging due to changing environmental conditions and operational constraints. Existing vessel-routing studies typically fail to generalize across multiple origin-destination pairs and do not exploit large-scale, data-driven traffic graphs. In this paper, we propose a reinforcement learning solution for big maritime data that can learn to find a route across multiple origin-destination pairs while adapting to different hexagonal grid resolutions. Agents learn to select direction and speed under continuous observations in a multi-discrete action space. A reward function balances fuel efficiency, travel time, wind resistance, and route diversity, using an Automatic Identification System (AIS)-derived traffic graph with ERA5 wind fields. The approach is demonstrated in the Gulf of St. Lawrence, one of the largest estuaries in the world. We evaluate configurations that combine Proximal Policy Optimization with recurrent networks, invalid-action masking, and exploration strategies. Our experiments demonstrate that action masking yields a clear improvement in policy performance and that supplementing penalty-only feedback with positive shaping rewards produces additional gains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‹­çª„åŠåŠ¨æ€æ°´é“ä¸­èˆ¹èˆ¶èˆªçº¿çš„å¤æ‚æ€§ï¼Œä»¥åŠç°æœ‰æ–¹æ³•éš¾ä»¥æ³›åŒ–è‡³å¤šèµ·è®«ç‚¹ï¼ˆO-Dï¼‰å¯¹å’Œåˆ©ç”¨å¤§è§„æ¨¡äº¤é€šå›¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é¢å‘æµ·äº‹å¤§æ•°æ®çš„ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ï¼ˆGoal-Conditioned Reinforcement Learningï¼‰è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿå­¦ä¹ åœ¨å¤šç§èµ·è®«ç‚¹å¯¹å’Œä¸åŒå…­è¾¹å½¢ç½‘æ ¼åˆ†è¾¨ç‡ä¸‹è¿›è¡Œè·¯å¾„è§„åˆ’ï¼Œå¹¶åœ¨å¤šç¦»æ•£åŠ¨ä½œç©ºé—´ï¼ˆMulti-discrete action spaceï¼‰ä¸­æ ¹æ®è¿ç»­è§‚æµ‹è‡ªä¸»é€‰æ‹©èˆªè¡Œæ–¹å‘ä¸é€Ÿåº¦ã€‚å¥–åŠ±å‡½æ•°ç»¼åˆå¹³è¡¡äº†ç‡ƒæ²¹æ•ˆç‡ã€èˆªè¡Œæ—¶é—´ã€é£é˜»åŠèˆªçº¿å¤šæ ·æ€§ï¼Œå¹¶ç»“åˆäº†åŸºäºè‡ªåŠ¨è¯†åˆ«ç³»ç»Ÿï¼ˆAISï¼‰ç”Ÿæˆçš„äº¤é€šå›¾ä¸ERA5é£åœºæ•°æ®ã€‚ç ”ç©¶åœ¨åœ£åŠ³ä¼¦æ–¯æ¹¾ï¼ˆGulf of St. Lawrenceï¼‰è¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œé‡‡ç”¨äº†ç»“åˆè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼‰ã€å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent networksï¼‰ä»¥åŠæ— æ•ˆåŠ¨ä½œæ©ç ï¼ˆInvalid-action maskingï¼‰çš„é…ç½®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠ¨ä½œæ©ç ï¼ˆAction maskingï¼‰æ˜¾è‘—æå‡äº†ç­–ç•¥æ€§èƒ½ï¼Œä¸”åœ¨æƒ©ç½šåé¦ˆåŸºç¡€ä¸Šè¡¥å……æ­£å‘å¡‘é€ å¥–åŠ±ï¼ˆPositive shaping rewardsï¼‰èƒ½å¸¦æ¥é¢å¤–çš„æ€§èƒ½å¢ç›Šã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01838v1",
      "published_date": "2025-09-01 23:42:16 UTC",
      "updated_date": "2025-09-01 23:42:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:39.784889+00:00"
    },
    {
      "arxiv_id": "2509.01836v1",
      "title": "Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment",
      "title_zh": "äº¤äº’æ„ŸçŸ¥çš„å¤šèˆ¹èˆ¶è½¨è¿¹é¢„æµ‹ä¸ç¢°æ’é£é™©è¯„ä¼°",
      "authors": [
        "Md Mahbub Alam",
        "Jose F. Rodrigues-Jr",
        "Gabriel Spadon"
      ],
      "abstract": "Accurate vessel trajectory prediction is essential for enhancing situational awareness and preventing collisions. Still, existing data-driven models are constrained mainly to single-vessel forecasting, overlooking vessel interactions, navigation rules, and explicit collision risk assessment. We present a transformer-based framework for multi-vessel trajectory prediction with integrated collision risk analysis. For a given target vessel, the framework identifies nearby vessels. It jointly predicts their future trajectories through parallel streams encoding kinematic and derived physical features, causal convolutions for temporal locality, spatial transformations for positional encoding, and hybrid positional embeddings that capture both local motion patterns and long-range dependencies. Evaluated on large-scale real-world AIS data using joint multi-vessel metrics, the model demonstrates superior forecasting capabilities beyond traditional single-vessel displacement errors. By simulating interactions among predicted trajectories, the framework further quantifies potential collision risks, offering actionable insights to strengthen maritime safety and decision support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºTransformerçš„å¤šèˆ¹èˆ¶è½¨è¿¹é¢„æµ‹åŠç¢°æ’é£é™©åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹å¤šå±€é™äºå•èˆ¹èˆ¶é¢„æµ‹è€Œå¿½è§†èˆ¹èˆ¶äº¤äº’ã€å¯¼èˆªè§„åˆ™åŠæ˜¾å¼é£é™©è¯„ä¼°çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è¯†åˆ«ç›®æ ‡èˆ¹èˆ¶å‘¨è¾¹çš„é‚»è¿‘èˆ¹èˆ¶ï¼Œåˆ©ç”¨å¹¶è¡Œæµç¼–ç è¿åŠ¨å­¦å’Œç‰©ç†ç‰¹å¾ï¼Œå¹¶ç»“åˆCausal Convolutionså’ŒHybrid Positional Embeddingsæ¥æ•è·æ—¶é—´å±€éƒ¨æ€§å’Œé•¿ç¨‹ä¾èµ–å…³ç³»ã€‚åœ¨çœŸå®å¤§è§„æ¨¡AISæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šèˆ¹èˆ¶è”åˆæŒ‡æ ‡ä¸Šçš„é¢„æµ‹èƒ½åŠ›æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å•èˆ¹èˆ¶ä½ç§»è¯¯å·®æ¨¡å‹ã€‚é€šè¿‡æ¨¡æ‹Ÿé¢„æµ‹è½¨è¿¹é—´çš„äº¤äº’ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè¿›ä¸€æ­¥é‡åŒ–æ½œåœ¨çš„ç¢°æ’é£é™©ï¼Œä¸ºæå‡æµ·ä¸Šäº¤é€šå®‰å…¨å’Œè¾…åŠ©å†³ç­–æä¾›äº†å…·æœ‰å®æ“ä»·å€¼çš„è§è§£ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01836v1",
      "published_date": "2025-09-01 23:38:01 UTC",
      "updated_date": "2025-09-01 23:38:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:47.248173+00:00"
    },
    {
      "arxiv_id": "2509.01824v1",
      "title": "Journalists' Perceptions of Artificial Intelligence and Disinformation Risks",
      "title_zh": "æ–°é—»å·¥ä½œè€…å¯¹äººå·¥æ™ºèƒ½ä¸è™šå‡ä¿¡æ¯é£é™©çš„è®¤çŸ¥",
      "authors": [
        "Urko PeÃ±a-Alonso",
        "SimÃ³n PeÃ±a-FernÃ¡ndez",
        "Koldobika Meso-Ayerdi"
      ],
      "abstract": "This study examines journalists' perceptions of the impact of artificial intelligence (AI) on disinformation, a growing concern in journalism due to the rapid expansion of generative AI and its influence on news production and media organizations. Using a quantitative approach, a structured survey was administered to 504 journalists in the Basque Country, identified through official media directories and with the support of the Basque Association of Journalists. This survey, conducted online and via telephone between May and June 2024, included questions on sociodemographic and professional variables, as well as attitudes toward AI's impact on journalism. The results indicate that a large majority of journalists (89.88%) believe AI will considerably or significantly increase the risks of disinformation, and this perception is consistent across genders and media types, but more pronounced among those with greater professional experience. Statistical analyses reveal a significant association between years of experience and perceived risk, and between AI use and risk perception. The main risks identified are the difficulty in detecting false content and deepfakes, and the risk of obtaining inaccurate or erroneous data. Co-occurrence analysis shows that these risks are often perceived as interconnected. These findings highlight the complex and multifaceted concerns of journalists regarding AI's role in the information ecosystem.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é‡‡ç”¨å®šé‡ç ”ç©¶æ–¹æ³•(quantitative approach)ï¼Œé€šè¿‡å¯¹å·´æ–¯å…‹åœ°åŒº504åè®°è€…çš„ç»“æ„åŒ–è°ƒæŸ¥ï¼Œæ¢è®¨äº†æ–°é—»ä»ä¸šè€…å¯¹äººå·¥æ™ºèƒ½(AI)åŠè™šå‡ä¿¡æ¯(disinformation)é£é™©çš„æ„ŸçŸ¥ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œé«˜è¾¾89.88%çš„è®°è€…è®¤ä¸ºAIå°†æ˜¾è‘—å¢åŠ è™šå‡ä¿¡æ¯ä¼ æ’­çš„é£é™©ï¼Œä¸”è¿™ä¸€è®¤çŸ¥åœ¨ä¸åŒæ€§åˆ«å’Œåª’ä½“ç±»å‹ä¸­å…·æœ‰æ™®éæ€§ï¼Œä½†åœ¨èµ„æ·±è®°è€…ç¾¤ä½“ä¸­æ›´ä¸ºå¼ºçƒˆã€‚ç»Ÿè®¡åˆ†æè¡¨æ˜ï¼Œä»ä¸šå¹´é™ã€AIçš„ä½¿ç”¨æƒ…å†µä¸é£é™©æ„ŸçŸ¥ç¨‹åº¦ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ­£ç›¸å…³å…³ç³»ã€‚è®°è€…ä»¬ç¡®å®šçš„æ ¸å¿ƒé£é™©ä¸»è¦é›†ä¸­åœ¨è¯†åˆ«è™šå‡å†…å®¹ä¸æ·±åº¦ä¼ªé€ (deepfakes)çš„éš¾åº¦å¢åŠ ï¼Œä»¥åŠAIç”Ÿæˆä¸å‡†ç¡®æˆ–é”™è¯¯æ•°æ®çš„å¯èƒ½æ€§ã€‚å…±ç°åˆ†æ(co-occurrence analysis)è¿›ä¸€æ­¥æ­ç¤ºäº†è¿™äº›é£é™©å› ç´ åœ¨ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­æ˜¯é«˜åº¦å…³è”ä¸”é”™ç»¼å¤æ‚çš„ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£AIæŠ€æœ¯å¯¹æ–°é—»ç”Ÿäº§åŠåª’ä½“ç»„ç»‡çš„æ·±è¿œå½±å“æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages, 5 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01824v1",
      "published_date": "2025-09-01 23:06:15 UTC",
      "updated_date": "2025-09-01 23:06:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:46.962921+00:00"
    },
    {
      "arxiv_id": "2509.01822v1",
      "title": "When LLM Meets Time Series: Can LLMs Perform Multi-Step Time Series Reasoning and Inference",
      "title_zh": "å½“ LLM é‡ä¸Šæ—¶é—´åºåˆ—ï¼šå¤§è¯­è¨€æ¨¡å‹èƒ½å¦è¿›è¡Œå¤šæ­¥æ—¶é—´åºåˆ—æ¨ç†ä¸æ¨æ–­",
      "authors": [
        "Wen Ye",
        "Jinbo Liu",
        "Defu Cao",
        "Wei Yang",
        "Yan Liu"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has sparked growing interest in their application to time series analysis tasks. However, their ability to perform complex reasoning over temporal data in real-world application domains remains underexplored. To move toward this goal, a first step is to establish a rigorous benchmark dataset for evaluation. In this work, we introduce the TSAIA Benchmark, a first attempt to evaluate LLMs as time-series AI assistants. To ensure both scientific rigor and practical relevance, we surveyed over 20 academic publications and identified 33 real-world task formulations. The benchmark encompasses a broad spectrum of challenges, ranging from constraint-aware forecasting to anomaly detection with threshold calibration: tasks that require compositional reasoning and multi-step time series analysis. The question generator is designed to be dynamic and extensible, supporting continuous expansion as new datasets or task types are introduced. Given the heterogeneous nature of the tasks, we adopt task-specific success criteria and tailored inference-quality metrics to ensure meaningful evaluation for each task. We apply this benchmark to assess eight state-of-the-art LLMs under a unified evaluation protocol. Our analysis reveals limitations in current models' ability to assemble complex time series analysis workflows, underscoring the need for specialized methodologies for domain-specific adaptation. Our benchmark is available at https://huggingface.co/datasets/Melady/TSAIA, and the code is available at https://github.com/USC-Melady/TSAIA.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­çš„å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†TSAIA Benchmarkï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹ä½œä¸ºæ—¶é—´åºåˆ—AIåŠ©æ‰‹çš„è¡¨ç°ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è°ƒç ”20å¤šç¯‡å­¦æœ¯è®ºæ–‡ï¼Œè®¾è®¡äº†33ç§æ¶µç›–çº¦æŸæ„ŸçŸ¥é¢„æµ‹(Constraint-aware forecasting)å’Œå¼‚å¸¸æ£€æµ‹(Anomaly detection)ç­‰ä»»åŠ¡çš„å®é™…åº”ç”¨åœºæ™¯ã€‚è¯¥åŸºå‡†æµ‹è¯•åˆ©ç”¨åŠ¨æ€å¯æ‰©å±•çš„é—®é¢˜ç”Ÿæˆå™¨ï¼Œé‡ç‚¹è€ƒå¯Ÿæ¨¡å‹åœ¨å¤šæ­¥æ¨ç†(Multi-step reasoning)å’Œç»„åˆæ¨ç†(Compositional reasoning)æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒå¯¹8ç§æœ€å…ˆè¿›çš„LLMsè¿›è¡Œäº†ç»Ÿä¸€è¯„ä¼°ï¼Œç»“æœæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨ç»„å»ºå¤æ‚æ—¶é—´åºåˆ—å·¥ä½œæµ(Workflows)æ–¹é¢çš„å±€é™æ€§ã€‚æ­¤é¡¹å·¥ä½œä¸ºæ—¶é—´åºåˆ—é¢†åŸŸçš„é¢†åŸŸç‰¹å®šé€‚é…(Domain-specific adaptation)æä¾›äº†é‡è¦å‚è€ƒï¼Œå¹¶å·²å¼€æºç›¸å…³æ•°æ®ä¸ä»£ç ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01822v1",
      "published_date": "2025-09-01 22:58:57 UTC",
      "updated_date": "2025-09-01 22:58:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:48.386137+00:00"
    },
    {
      "arxiv_id": "2509.10507v1",
      "title": "An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms",
      "title_zh": "é¢å‘å»ä¸­å¿ƒåŒ–å¼‚æ„å¹³å°çš„æ™ºèƒ½ç‰©è”ç½‘æ¡†æ¶",
      "authors": [
        "Vadim Allayev",
        "Mahbubur Rahman"
      ],
      "abstract": "Internet of Intelligent Things (IoIT), an emerging field, combines the utility of Internet of Things (IoT) devices with the innovation of embedded AI algorithms. However, it does not come without challenges, and struggles regarding available computing resources, energy supply, and storage limitations. In particular, many impediments to IoIT are linked to the energy-efficient deployment of machine learning (ML)/deep learning (DL) models in embedded devices. Research has been conducted to design energy-efficient IoIT platforms, but these papers often focus on centralized systems, in which some central entity processes all the data and coordinates actions. This can be problematic, e.g., serve as bottleneck or lead to security concerns. In a decentralized system, nodes/devices would self-organize and make their own decisions. Therefore, to address such issues, we propose a heterogeneous, decentralized sensing and monitoring IoIT peer-to-peer mesh network system model. Nodes in the network will coordinate towards several optimization goals: reliability, energy efficiency, and latency. The system employs federated learning to train nodes in a distributed manner, metaheuristics to optimize task allocation and routing paths, and multi-objective optimization to balance conflicting performance goals.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºèƒ½ç‰©è”ç½‘ (Internet of Intelligent Things, IoIT) åœ¨åµŒå…¥å¼è®¾å¤‡ä¸­éƒ¨ç½²æœºå™¨å­¦ä¹  (ML) å’Œæ·±åº¦å­¦ä¹  (DL) æ¨¡å‹æ—¶é¢ä¸´çš„è®¡ç®—èµ„æºã€èƒ½æºä¾›åº”å’Œå­˜å‚¨å—é™ç­‰æŒ‘æˆ˜è¿›è¡Œäº†æ¢è®¨ã€‚é’ˆå¯¹ä¼ ç»Ÿä¸­å¿ƒåŒ–ç³»ç»Ÿå®¹æ˜“äº§ç”Ÿç“¶é¢ˆåŠå®‰å…¨é£é™©çš„é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§å¼‚æ„ä¸”å»ä¸­å¿ƒåŒ–çš„æ„ŸçŸ¥ä¸ç›‘æµ‹ IoIT ç‚¹å¯¹ç‚¹ (peer-to-peer) Mesh ç½‘ç»œç³»ç»Ÿæ¨¡å‹ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥è”é‚¦å­¦ä¹  (Federated Learning) æŠ€æœ¯å®ç°èŠ‚ç‚¹çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¹¶åˆ©ç”¨å…ƒå¯å‘å¼ç®—æ³• (metaheuristics) å¯¹ä»»åŠ¡åˆ†é…å’Œè·¯ç”±è·¯å¾„è¿›è¡Œä¼˜åŒ–ã€‚ä¸ºäº†åœ¨å¯é æ€§ã€èƒ½æ•ˆå’Œå»¶è¿Ÿç­‰å¤šä¸ªå†²çªæ€§èƒ½æŒ‡æ ‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œç³»ç»Ÿé‡‡ç”¨äº†å¤šç›®æ ‡ä¼˜åŒ– (multi-objective optimization) ç­–ç•¥ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç½‘ç»œä¸­çš„èŠ‚ç‚¹èƒ½å¤Ÿå®ç°è‡ªç»„ç»‡å’Œç‹¬ç«‹å†³ç­–ï¼Œä¸ºå»ä¸­å¿ƒåŒ–å¼‚æ„å¹³å°ä¸‹çš„ IoIT éƒ¨ç½²æä¾›äº†é«˜æ•ˆä¸”å®‰å…¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "11 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.10507v1",
      "published_date": "2025-09-01 22:54:01 UTC",
      "updated_date": "2025-09-01 22:54:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:48:56.497380+00:00"
    },
    {
      "arxiv_id": "2509.01814v1",
      "title": "Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts",
      "title_zh": "ä¸€é¸£æƒŠäººè¿˜æ˜¯æ•°æ®è´¥ç¬”ï¼Ÿå®šé‡ä¸å®šæ€§ç ”ç©¶è¯­å¢ƒä¸‹ AI è¯­éŸ³è®¿è°ˆå‘˜æ•°æ®é‡‡é›†çš„é€‚ç”¨æ€§è¯„ä¼°",
      "authors": [
        "Shreyas Tirumala",
        "Nishant Jain",
        "Danny D. Leybzon",
        "Trent D. Buskirk"
      ],
      "abstract": "Transformer-based Large Language Models (LLMs) have paved the way for \"AI interviewers\" that can administer voice-based surveys with respondents in real-time. This position paper reviews emerging evidence to understand when such AI interviewing systems are fit for purpose for collecting data within quantitative and qualitative research contexts. We evaluate the capabilities of AI interviewers as well as current Interactive Voice Response (IVR) systems across two dimensions: input/output performance (i.e., speech recognition, answer recording, emotion handling) and verbal reasoning (i.e., ability to probe, clarify, and handle branching logic). Field studies suggest that AI interviewers already exceed IVR capabilities for both quantitative and qualitative data collection, but real-time transcription error rates, limited emotion detection abilities, and uneven follow-up quality indicate that the utility, use and adoption of current AI interviewer technology may be context-dependent for qualitative data collection efforts.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„AIè¯­éŸ³è®¿è°ˆè€…ï¼ˆAI interviewersï¼‰åœ¨å®šé‡å’Œå®šæ€§ç ”ç©¶æ•°æ®é‡‡é›†ä¸­çš„é€‚ç”¨æ€§ã€‚æ–‡ç« é€šè¿‡å¯¹æ¯”ç°æœ‰çš„äº¤äº’å¼è¯­éŸ³åº”ç­”ï¼ˆIVRï¼‰ç³»ç»Ÿï¼Œä»è¾“å…¥/è¾“å‡ºæ€§èƒ½ï¼ˆæ¶‰åŠè¯­éŸ³è¯†åˆ«ã€å›ç­”è®°å½•å’Œæƒ…æ„Ÿå¤„ç†ï¼‰ä»¥åŠè¨€è¯­æ¨ç†èƒ½åŠ›ï¼ˆæ¶‰åŠè¿½é—®ã€æ¾„æ¸…å’Œåˆ†æ”¯é€»è¾‘å¤„ç†ï¼‰ä¸¤ä¸ªç»´åº¦è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚å®åœ°ç ”ç©¶è¯æ®æ˜¾ç¤ºï¼ŒAIè¯­éŸ³è®¿è°ˆè€…åœ¨å®šé‡å’Œå®šæ€§æ•°æ®é‡‡é›†èƒ½åŠ›ä¸Šå‡å·²æ˜¾è‘—è¶…è¶ŠIVRç³»ç»Ÿã€‚ç„¶è€Œï¼Œå®æ—¶è½¬å½•é”™è¯¯ç‡ã€å—é™çš„æƒ…æ„Ÿæ£€æµ‹èƒ½åŠ›ä»¥åŠä¸ç¨³å®šçš„è¿½é—®è´¨é‡è¡¨æ˜ï¼Œå½“å‰AIè¯­éŸ³è®¿è°ˆè€…æŠ€æœ¯åœ¨å®šæ€§ç ”ç©¶ä¸­çš„åº”ç”¨ä»·å€¼å’Œæ™®åŠç¨‹åº¦ä»é«˜åº¦ä¾èµ–äºå…·ä½“çš„ç ”ç©¶æƒ…å¢ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01814v1",
      "published_date": "2025-09-01 22:44:57 UTC",
      "updated_date": "2025-09-01 22:44:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:49:09.396582+00:00"
    },
    {
      "arxiv_id": "2509.02640v2",
      "title": "Adaptive Learning Strategies for Mitotic Figure Classification in MIDOG2025 Challenge",
      "title_zh": "MIDOG2025 æŒ‘æˆ˜èµ›ä¸­æœ‰ä¸åˆ†è£‚è±¡åˆ†ç±»çš„è‡ªé€‚åº”å­¦ä¹ ç­–ç•¥",
      "authors": [
        "Biwen Meng",
        "Xi Long",
        "Jingxin Liu"
      ],
      "abstract": "Atypical mitotic figures (AMFs) are clinically relevant indicators of abnormal cell division, yet their reliable detection remains challenging due to morphological ambiguity and scanner variability. In this work, we investigated three variants of adapting the pathology foundation model UNI2 for the MIDOG2025 Track 2 challenge: (1) LoRA + UNI2, (2) VPT + UNI2 + Vahadane Normalizer, and (3) VPT + UNI2 + GRL + Stain TTA. We observed that the integration of Visual Prompt Tuning (VPT) with stain normalization techniques contributed to improved generalization. The best robustness was achieved by further incorporating test-time augmentation (TTA) with Vahadane and Macenko stain normalization. Our final submission achieved a balanced accuracy of 0.8837 and an ROC-AUC of 0.9513 on the preliminary leaderboard, ranking within the top 10 teams. These results suggest that prompt-based adaptation combined with stain-normalization TTA offers a promising strategy for atypical mitosis classification under diverse imaging conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ MIDOG2025 æŒ‘æˆ˜èµ›ä¸­çš„éå…¸å‹æœ‰ä¸åˆ†è£‚è±¡ (Atypical Mitotic Figures, AMFs) åˆ†ç±»é—®é¢˜ï¼Œæ¢è®¨äº†å¦‚ä½•å…‹æœç”±äºå½¢æ€æ­§ä¹‰å’Œæ‰«æä»ªå·®å¼‚å¸¦æ¥çš„æ£€æµ‹æŒ‘æˆ˜ã€‚ä½œè€…åŸºäºç—…ç†å­¦åŸºç¡€æ¨¡å‹ UNI2ï¼Œå¯¹æ¯”ç ”ç©¶äº† LoRA + UNI2ã€VPT + UNI2 + Vahadane Normalizer ä»¥åŠ VPT + UNI2 + GRL + Stain TTA ä¸‰ç§è‡ªé€‚åº”ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†è§†è§‰æç¤ºå¾®è°ƒ (Visual Prompt Tuning, VPT) ä¸æŸ“è‰²å½’ä¸€åŒ–æŠ€æœ¯ç›¸ç»“åˆèƒ½æ˜¾è‘—æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œç»“åˆ Vahadane å’Œ Macenko æŸ“è‰²å½’ä¸€åŒ–çš„æµ‹è¯•æ—¶å¢å¼º (Test-Time Augmentation, TTA) ç­–ç•¥å®ç°äº†æœ€ä½³çš„é²æ£’æ€§ã€‚è¯¥æ–¹æ¡ˆåœ¨åˆæ­¥æ’è¡Œæ¦œä¸Šå–å¾—äº† 0.8837 çš„å¹³è¡¡å‡†ç¡®ç‡å’Œ 0.9513 çš„ ROC-AUCï¼Œåœ¨å‚èµ›å›¢é˜Ÿä¸­ä½åˆ—å‰åã€‚ç ”ç©¶è¯æ˜ï¼ŒåŸºäº Prompt çš„è‡ªé€‚åº”ç­–ç•¥ç»“åˆæŸ“è‰²å½’ä¸€åŒ– TTA æ˜¯å¤„ç†å¤šæ ·åŒ–æˆåƒæ¡ä»¶ä¸‹æœ‰ä¸åˆ†è£‚åˆ†ç±»ä»»åŠ¡çš„ä¸€ç§æå…·å‰æ™¯çš„æ–¹æ³•ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.02640v2",
      "published_date": "2025-09-01 22:42:53 UTC",
      "updated_date": "2025-09-05 14:00:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:49:58.987053+00:00"
    },
    {
      "arxiv_id": "2509.01812v1",
      "title": "Quantum Machine Learning for UAV Swarm Intrusion Detection",
      "title_zh": "é¢å‘æ— äººæœºé›†ç¾¤å…¥ä¾µæ£€æµ‹çš„é‡å­æœºå™¨å­¦ä¹ ",
      "authors": [
        "Kuan-Cheng Chen",
        "Samuel Yen-Chi Chen",
        "Tai-Yue Li",
        "Chen-Yu Liu",
        "Kin K. Leung"
      ],
      "abstract": "Intrusion detection in unmanned-aerial-vehicle (UAV) swarms is complicated by high mobility, non-stationary traffic, and severe class imbalance. Leveraging a 120 k-flow simulation corpus that covers five attack types, we benchmark three quantum-machine-learning (QML) approaches - quantum kernels, variational quantum neural networks (QNNs), and hybrid quantum-trained neural networks (QT-NNs) - against strong classical baselines. All models consume an 8-feature flow representation and are evaluated under identical preprocessing, balancing, and noise-model assumptions. We analyse the influence of encoding strategy, circuit depth, qubit count, and shot noise, reporting accuracy, macro-F1, ROC-AUC, Matthews correlation, and quantum-resource footprints. Results reveal clear trade-offs: quantum kernels and QT-NNs excel in low-data, nonlinear regimes, while deeper QNNs suffer from trainability issues, and CNNs dominate when abundant data offset their larger parameter count. The complete codebase and dataset partitions are publicly released to enable reproducible QML research in network security.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é‡å­æœºå™¨å­¦ä¹ (QML)åœ¨æ— äººæœº(UAV)é›†ç¾¤å…¥ä¾µæ£€æµ‹ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³é«˜ç§»åŠ¨æ€§ã€éå¹³ç¨³æµé‡å’Œä¸¥é‡çš„ç±»åˆ«å¤±è¡¡æŒ‘æˆ˜ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨åŒ…å«äº”ç§æ”»å‡»ç±»å‹çš„120kæµæ¨¡æ‹Ÿè¯­æ–™åº“ï¼Œå¯¹é‡å­æ ¸(quantum kernels)ã€å˜åˆ†é‡å­ç¥ç»ç½‘ç»œ(QNNs)å’Œæ··åˆé‡å­è®­ç»ƒç¥ç»ç½‘ç»œ(QT-NNs)è¿™ä¸‰ç§QMLæ–¹æ³•ä¸ç»å…¸åŸºå‡†æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”æµ‹è¯•ã€‚åˆ†æé‡ç‚¹æ¶µç›–äº†ç¼–ç ç­–ç•¥ã€ç”µè·¯æ·±åº¦ã€é‡å­æ¯”ç‰¹æ•°åŠæ•£ç²’å™ªå£°(shot noise)å¯¹å‡†ç¡®ç‡ã€Macro-F1å’ŒROC-AUCç­‰æ€§èƒ½æŒ‡æ ‡çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡å­æ ¸å’ŒQT-NNsåœ¨ä½æ•°æ®é‡å’Œéçº¿æ€§åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œè€Œæ·±å±‚QNNsåˆ™é¢ä¸´æ˜¾è‘—çš„è®­ç»ƒæ€§é—®é¢˜ã€‚è¯¥ç ”ç©¶æ˜ç¡®äº†QMLæ¨¡å‹ä¸ä¼ ç»ŸCNNåœ¨æ•°æ®ä¾èµ–æ€§æ–¹é¢çš„æ€§èƒ½æƒè¡¡ï¼Œä¸ºç½‘ç»œå®‰å…¨é¢†åŸŸçš„é‡å­ç®—æ³•åº”ç”¨æä¾›äº†åŸºå‡†å‚è€ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå…¬å¼€äº†å®Œæ•´çš„ä»£ç åº“å’Œæ•°æ®é›†åˆ†åŒºï¼Œä»¥æ”¯æŒè¯¥é¢†åŸŸçš„å­¦æœ¯å¯é‡å¤æ€§ç ”ç©¶ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01812v1",
      "published_date": "2025-09-01 22:36:30 UTC",
      "updated_date": "2025-09-01 22:36:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:49:11.887421+00:00"
    },
    {
      "arxiv_id": "2509.10504v2",
      "title": "Retrosynthesis Planning via Worst-path Policy Optimisation in Tree-structured MDPs",
      "title_zh": "åŸºäºæ ‘ç»“æ„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­æœ€å·®è·¯å¾„ç­–ç•¥ä¼˜åŒ–çš„é€†åˆæˆè§„åˆ’",
      "authors": [
        "Mianchu Wang",
        "Giovanni Montana"
      ],
      "abstract": "Retrosynthesis planning aims to decompose target molecules into available building blocks, forming a synthetic tree where each internal node represents an intermediate compound and each leaf ideally corresponds to a purchasable reactant. However, this tree becomes invalid if any leaf node is not a valid building block, making the planning process vulnerable to the \"weakest link\" in the synthetic route. Existing methods often optimise for average performance across branches, failing to account for this worst-case sensitivity. In this paper, we reframe retrosynthesis as a worst-path optimisation problem within tree-structured Markov Decision Processes (MDPs). We prove that this formulation admits a unique optimal solution and provides monotonic improvement guarantees. Building on this insight, we introduce Interactive Retrosynthesis Planning (InterRetro), a method that interacts with the tree MDP, learns a value function for worst-path outcomes, and improves its policy through self-imitation, preferentially reinforcing past decisions with high estimated advantage. Empirically, InterRetro achieves state-of-the-art results - solving 100% of targets on the Retro*-190 benchmark, shortening synthetic routes by 4.9%, and achieving promising performance using only 10% of the training data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€†åˆæˆè§„åˆ’(Retrosynthesis planning)ä¸­åˆæˆè·¯å¾„æ˜“å—â€œæœ€å¼±ç¯èŠ‚â€å½±å“è€Œå¤±æ•ˆçš„é—®é¢˜ï¼Œå°†å…¶é‡æ„ä¸ºæ ‘ç»“æ„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Tree-structured MDPs)ä¸­çš„æœ€åè·¯å¾„ä¼˜åŒ–(Worst-path optimisation)é—®é¢˜ã€‚ç ”ç©¶è€…ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥å…¬å¼å…·å¤‡å”¯ä¸€æœ€ä¼˜è§£ä¸å•è°ƒæ”¹è¿›ä¿è¯ï¼Œå¹¶æ®æ­¤æå‡ºäº†InterRetroï¼ˆäº¤äº’å¼é€†åˆæˆè§„åˆ’ï¼‰æ–¹æ³•ã€‚InterRetroé€šè¿‡ä¸ç¯å¢ƒäº¤äº’å­¦ä¹ æœ€åè·¯å¾„ç»“æœçš„ä»·å€¼å‡½æ•°ï¼Œå¹¶ç»“åˆè‡ªæˆ‘æ¨¡ä»¿å­¦ä¹ (Self-imitation learning)æœºåˆ¶ï¼Œä¼˜å…ˆå¼ºåŒ–å…·æœ‰é«˜ä¼°å€¼ä¼˜åŠ¿çš„å†å²å†³ç­–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒInterRetroåœ¨Retro*-190åŸºå‡†æµ‹è¯•ä¸­è¾¾æˆäº†100%çš„ç›®æ ‡è§£å†³ç‡ï¼Œä¸ä»…å°†åˆæˆè·¯å¾„é•¿åº¦ç¼©çŸ­äº†4.9%ï¼Œä¸”åœ¨ä»…ä½¿ç”¨10%è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ä»å±•ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.10504v2",
      "published_date": "2025-09-01 21:44:14 UTC",
      "updated_date": "2025-11-17 19:17:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:10.786346+00:00"
    },
    {
      "arxiv_id": "2509.01794v2",
      "title": "A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics",
      "title_zh": "ç”¨äºåœ¨å¤§æµè¡Œç—…æœŸé—´é¢„æµ‹å¿ƒè¡€ç®¡ç–¾ç—…ç”Ÿç‰©æ ‡å¿—ç‰©çš„å¤šç›®æ ‡è´å¶æ–¯ Transformer æ¡†æ¶",
      "authors": [
        "Trusting Inekwe",
        "Winnie Mkandawire",
        "Emmanuel Agu",
        "Andres Colubri"
      ],
      "abstract": "The COVID-19 pandemic disrupted healthcare systems worldwide, disproportionately impacting individuals with chronic conditions such as cardiovascular disease (CVD). These disruptions -- through delayed care and behavioral changes, affected key CVD biomarkers, including LDL cholesterol (LDL-C), HbA1c, BMI, and systolic blood pressure (SysBP). Accurate modeling of these changes is crucial for predicting disease progression and guiding preventive care. However, prior work has not addressed multi-target prediction of CVD biomarker from Electronic Health Records (EHRs) using machine learning (ML), while jointly capturing biomarker interdependencies, temporal patterns, and predictive uncertainty. In this paper, we propose MBT-CB, a Multi-target Bayesian Transformer (MBT) with pre-trained BERT-based transformer framework to jointly predict LDL-C, HbA1c, BMI and SysBP CVD biomarkers from EHR data. The model leverages Bayesian Variational Inference to estimate uncertainties, embeddings to capture temporal relationships and a DeepMTR model to capture biomarker inter-relationships. We evaluate MBT-CT on retrospective EHR data from 3,390 CVD patient records (304 unique patients) in Central Massachusetts during the Covid-19 pandemic. MBT-CB outperformed a comprehensive set of baselines including other BERT-based ML models, achieving an MAE of 0.00887, RMSE of 0.0135 and MSE of 0.00027, while effectively capturing data and model uncertainty, patient biomarker inter-relationships, and temporal dynamics via its attention and embedding mechanisms. MBT-CB's superior performance highlights its potential to improve CVD biomarker prediction and support clinical decision-making during pandemics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ COVID-19 å¤§æµè¡Œå¯¹å¿ƒè¡€ç®¡ç–¾ç—…ï¼ˆCVDï¼‰æ‚£è€…ç”Ÿç‰©æ ‡å¿—ç‰©äº§ç”Ÿçš„å½±å“ï¼Œæå‡ºäº† MBT-CBï¼Œä¸€ç§ç»“åˆäº†å¤šç›®æ ‡è´å¶æ–¯ Transformerï¼ˆMulti-target Bayesian Transformerï¼‰ä¸é¢„è®­ç»ƒ BERT çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰ä¸­è”åˆé¢„æµ‹ LDL-Cã€HbA1cã€BMI å’Œæ”¶ç¼©å‹ï¼ˆSysBPï¼‰ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è´å¶æ–¯å˜åˆ†æ¨ç†ï¼ˆBayesian Variational Inferenceï¼‰æ¥ä¼°è®¡é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¹¶é€šè¿‡åµŒå…¥æœºåˆ¶ä¸ DeepMTR æ¨¡å‹åˆ†åˆ«æ•æ‰ç”Ÿç‰©æ ‡å¿—ç‰©çš„æ—¶é—´æ¼”å˜è§„å¾‹åŠå…¶ç›¸äº’ä¾èµ–å…³ç³»ã€‚åœ¨å¯¹ 3,390 æ¡å¤§æµè¡ŒæœŸé—´æ‚£è€…è®°å½•çš„è¯„ä¼°ä¸­ï¼ŒMBT-CB åœ¨ MAEã€RMSE å’Œ MSE ç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºå¤šç§åŸºäº BERT çš„åŸºå‡†æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚çš„æ—¶é—´åŠ¨æ€ä¸æ•°æ®ä¸ç¡®å®šæ€§ï¼Œä¸ºå¤§æµè¡ŒèƒŒæ™¯ä¸‹çš„ CVD ç–¾ç—…è¿›å±•é¢„æµ‹å’Œä¸´åºŠé¢„é˜²æ€§æŠ¤ç†æä¾›äº†å¼ºæœ‰åŠ›çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01794v2",
      "published_date": "2025-09-01 21:43:36 UTC",
      "updated_date": "2025-11-06 02:39:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:16.555950+00:00"
    },
    {
      "arxiv_id": "2509.01793v2",
      "title": "STORI: A Benchmark and Taxonomy for Stochastic Environments",
      "title_zh": "STORIï¼šéšæœºç¯å¢ƒåŸºå‡†ä¸åˆ†ç±»ä½“ç³»",
      "authors": [
        "Aryan Amit Barsainyan",
        "Jing Yu Lim",
        "Dianbo Liu"
      ],
      "abstract": "Reinforcement learning (RL) techniques have achieved impressive performance on simulated benchmarks such as Atari100k, yet recent advances remain largely confined to simulation and show limited transfer to real-world domains. A central obstacle is environmental stochasticity, as real systems involve noisy observations, unpredictable dynamics, and non-stationary conditions that undermine the stability of current methods. Existing benchmarks rarely capture these uncertainties and favor simplified settings where algorithms can be tuned to succeed. The absence of a well-defined taxonomy of stochasticity further complicates evaluation, as robustness to one type of stochastic perturbation, such as sticky actions, does not guarantee robustness to other forms of uncertainty. To address this critical gap, we introduce STORI (STOchastic-ataRI), a benchmark that systematically incorporates diverse stochastic effects and enables rigorous evaluation of RL techniques under different forms of uncertainty. We propose a comprehensive five-type taxonomy of environmental stochasticity and demonstrate systematic vulnerabilities in state-of-the-art model-based RL algorithms through targeted evaluation of DreamerV3 and STORM. Our findings reveal that world models dramatically underestimate environmental variance, struggle with action corruption, and exhibit unreliable dynamics under partial observability. We release the code and benchmark publicly at https://github.com/ARY2260/stori, providing a unified framework for developing more robust RL systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†STORI (STOchastic-ataRI)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åœ¨éšæœºç¯å¢ƒä¸‹è¡¨ç°çš„æ–°å‹åŸºå‡†ã€‚é’ˆå¯¹çœŸå®ä¸–ç•Œä¸­æ™®éå­˜åœ¨çš„å™ªå£°è§‚æµ‹å’Œä¸å¯é¢„æµ‹åŠ¨åŠ›å­¦ç­‰æŒ‘æˆ˜ï¼Œç ”ç©¶è€…å®šä¹‰äº†ä¸€å¥—åŒ…å«äº”ç§ç¯å¢ƒéšæœºæ€§çš„åˆ†ç±»æ³•(Taxonomy)ï¼Œå¼¥è¡¥äº†ç°æœ‰æ¨¡æ‹ŸåŸºå‡†è¿‡äºç®€åŒ–çš„ç¼ºé™·ã€‚é€šè¿‡å¯¹DreamerV3å’ŒSTORMç­‰å…ˆè¿›çš„åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ (Model-based RL)ç®—æ³•è¿›è¡Œæ·±å…¥è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†åŠ¨ä½œæŸå(Action corruption)å’Œéƒ¨åˆ†å¯è§‚æµ‹æ€§(Partial observability)æ—¶çš„ç³»ç»Ÿæ€§è„†å¼±ã€‚å®éªŒå‘ç°ï¼Œå½“å‰çš„ä¸–ç•Œæ¨¡å‹(World models)å¾€å¾€ä¼šæ˜¾è‘—ä½ä¼°ç¯å¢ƒæ–¹å·®ï¼Œå¯¼è‡´åŠ¨åŠ›å­¦é¢„æµ‹ä¸å¯é ã€‚è¯¥åŸºå‡†åŠå…¶å¼€æºæ¡†æ¶ä¸ºæœªæ¥å¼€å‘æ›´å…·é²æ£’æ€§çš„å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿæä¾›äº†é‡è¦çš„è¯„ä¼°å·¥å…·å’Œç†è®ºæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "v2. New mathematical formulation and renamed notation; added additional experiments and a detailed analytical case study on error behaviors in world models under different stochasticity types; link to code repository for reproducibility: https://github.com/ARY2260/stori",
      "pdf_url": "https://arxiv.org/pdf/2509.01793v2",
      "published_date": "2025-09-01 21:43:22 UTC",
      "updated_date": "2025-10-03 06:53:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:16.167701+00:00"
    },
    {
      "arxiv_id": "2509.01791v2",
      "title": "E-PhishGen: Unlocking Novel Research in Phishing Email Detection",
      "title_zh": "E-PhishGenï¼šå¼€å¯é’“é±¼é‚®ä»¶æ£€æµ‹é¢†åŸŸçš„åˆ›æ–°ç ”ç©¶",
      "authors": [
        "Luca Pajola",
        "Eugenio Caripoti",
        "Stefan Banzer",
        "Simeone Pizzi",
        "Mauro Conti",
        "Giovanni Apruzzese"
      ],
      "abstract": "Every day, our inboxes are flooded with unsolicited emails, ranging between annoying spam to more subtle phishing scams. Unfortunately, despite abundant prior efforts proposing solutions achieving near-perfect accuracy, the reality is that countering malicious emails still remains an unsolved dilemma.\n  This \"open problem\" paper carries out a critical assessment of scientific works in the context of phishing email detection. First, we focus on the benchmark datasets that have been used to assess the methods proposed in research. We find that most prior work relied on datasets containing emails that -- we argue -- are not representative of current trends, and mostly encompass the English language. Based on this finding, we then re-implement and re-assess a variety of detection methods reliant on machine learning (ML), including large-language models (LLM), and release all of our codebase -- an (unfortunately) uncommon practice in related research. We show that most such methods achieve near-perfect performance when trained and tested on the same dataset -- a result which intrinsically hinders development (how can future research outperform methods that are already near perfect?). To foster the creation of \"more challenging benchmarks\" that reflect current phishing trends, we propose E-PhishGEN, an LLM-based (and privacy-savvy) framework to generate novel phishing-email datasets. We use our E-PhishGEN to create E-PhishLLM, a novel phishing-email detection dataset containing 16616 emails in three languages. We use E-PhishLLM to test the detectors we considered, showing a much lower performance than that achieved on existing benchmarks -- indicating a larger room for improvement. We also validate the quality of E-PhishLLM with a user study (n=30). To sum up, we show that phishing email detection is still an open problem -- and provide the means to tackle such a problem by future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Phishing Email Detection é¢†åŸŸç°çŠ¶è¿›è¡Œäº†æ‰¹åˆ¤æ€§è¯„ä¼°ï¼ŒæŒ‡å‡ºå°½ç®¡ç°æœ‰æ–¹æ³•å£°ç§°å‡†ç¡®ç‡è¿‘ä¹å®Œç¾ï¼Œä½†ç½‘ç»œé’“é±¼å¨èƒåœ¨ç°å®ä¸­ä»æ˜¯ä¸€ä¸ªæœªè§£å†³çš„éš¾é¢˜ã€‚ä½œè€…å‘ç°å¤šæ•°ç ”ç©¶ä¾èµ–çš„ Benchmark Datasets å·²æ— æ³•ä»£è¡¨å½“å‰è¶‹åŠ¿ä¸”ä¸»è¦å±€é™äºè‹±æ–‡ï¼Œå¯¼è‡´æ£€æµ‹å™¨åœ¨æµ‹è¯•ä¸­è¡¨ç°è™šé«˜ï¼Œä»è€Œé˜»ç¢äº†æŠ€æœ¯çš„è¿›ä¸€æ­¥çªç ´ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº† E-PhishGenï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº Large-Language Models (LLM) ä¸”å…·å¤‡éšç§ä¿æŠ¤ç‰¹æ€§çš„æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„æ–°å‹é’“é±¼é‚®ä»¶æ•°æ®é›†ã€‚åˆ©ç”¨è¯¥æ¡†æ¶æ„å»ºçš„ E-PhishLLM æ•°æ®é›†åŒ…å«ä¸‰ç§è¯­è¨€çš„ 16,616 å°é‚®ä»¶ï¼Œå®éªŒè¡¨æ˜ç°æœ‰æ£€æµ‹å™¨åœ¨è¯¥æ•°æ®é›†ä¸Šçš„æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œæ­ç¤ºäº†è¯¥é¢†åŸŸä»å­˜åœ¨å·¨å¤§çš„æ”¹è¿›ç©ºé—´ã€‚æ­¤å¤–ï¼Œä¸€é¡¹ 30 äººçš„ User Study è¿›ä¸€æ­¥éªŒè¯äº†ç”Ÿæˆæ•°æ®é›†çš„é«˜è´¨é‡ï¼Œè¯¥ç ”ç©¶é€šè¿‡å¼€æºä»£ç å’Œæä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ï¼Œä¸ºæœªæ¥è§£å†³ç½‘ç»œé’“é±¼æ£€æµ‹è¿™ä¸€å¼€æ”¾æ€§é—®é¢˜å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ACM AISec '25",
      "pdf_url": "https://arxiv.org/pdf/2509.01791v2",
      "published_date": "2025-09-01 21:41:34 UTC",
      "updated_date": "2025-09-15 13:13:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:23.861416+00:00"
    },
    {
      "arxiv_id": "2509.01790v1",
      "title": "Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs",
      "title_zh": "æ˜¯ç¼ºé™·è¿˜æ˜¯ä¼ªåƒï¼Ÿé‡æ–°å®¡è§†å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­çš„æç¤ºæ•æ„Ÿæ€§",
      "authors": [
        "Andong Hua",
        "Kenan Tang",
        "Chenhe Gu",
        "Jindong Gu",
        "Eric Wong",
        "Yao Qin"
      ],
      "abstract": "Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e., repeating something written or spoken using different words) leads to significant changes in large language model (LLM) performance, has been widely accepted as a core limitation of LLMs. In this work, we revisit this issue and ask: Is the widely reported high prompt sensitivity truly an inherent weakness of LLMs, or is it largely an artifact of evaluation processes? To answer this question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family) across 6 benchmarks, including both multiple-choice and open-ended tasks on 12 diverse prompt templates. We find that much of the prompt sensitivity stems from heuristic evaluation methods, including log-likelihood scoring and rigid answer matching, which often overlook semantically correct responses expressed through alternative phrasings, such as synonyms or paraphrases. When we adopt LLM-as-a-Judge evaluations, we observe a substantial reduction in performance variance and a consistently higher correlation in model rankings across prompts. Our findings suggest that modern LLMs are more robust to prompt templates than previously believed, and that prompt sensitivity may be more an artifact of evaluation than a flaw in the models.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°å®¡è§†äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­çš„æç¤ºè¯æ•æ„Ÿæ€§(Prompt Sensitivity)é—®é¢˜ï¼Œæ¢è®¨è¿™ä¸€ç°è±¡ç©¶ç«Ÿæ˜¯æ¨¡å‹å›ºæœ‰ç¼ºé™·è¿˜æ˜¯è¯„ä¼°æ–¹æ³•çš„äº§ç‰©ã€‚ç ”ç©¶è€…ç³»ç»Ÿè¯„ä¼°äº†GPTå’ŒGeminiç³»åˆ—ç­‰7ä¸ªæ¨¡å‹åœ¨6ä¸ªåŸºå‡†æµ‹è¯•å’Œ12ç§ä¸åŒæç¤ºæ¨¡æ¿ä¸‹çš„è¡¨ç°ï¼Œå‘ç°å¹¿æ³›æŠ¥é“çš„é«˜æ•æ„Ÿæ€§å¾ˆå¤§ç¨‹åº¦ä¸Šæºäºå¯¹æ•°ä¼¼ç„¶è¯„åˆ†(log-likelihood scoring)å’Œä¸¥æ ¼ç­”æ¡ˆåŒ¹é…(rigid answer matching)ç­‰å¯å‘å¼è¯„ä¼°æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¿½ç•¥äº†è¯­ä¹‰æ­£ç¡®ä½†è¡¨è¾¾ä¸åŒçš„å“åº”ã€‚å½“é‡‡ç”¨LLM-as-a-Judgeè¯„ä¼°æ–¹æ³•æ—¶ï¼Œæ¨¡å‹åœ¨ä¸åŒæç¤ºè¯ä¸‹çš„è¡¨ç°å·®å¼‚æ˜¾è‘—é™ä½ï¼Œä¸”æ¨¡å‹æ’åçš„ä¸€è‡´æ€§å¤§å¹…æé«˜ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç°ä»£LLMså¯¹æç¤ºè¯æ¨¡æ¿çš„é²æ£’æ€§æ¯”ä»¥å¾€è®¤ä¸ºçš„æ›´å¼ºï¼Œæ‰€è°“çš„æç¤ºè¯æ•æ„Ÿæ€§æ›´å¤šæ˜¯è¯„ä¼°è¿‡ç¨‹ä¸­çš„äººä¸ºåå·®(artifact)ï¼Œè€Œéæ¨¡å‹æœ¬èº«çš„æ ¹æœ¬ç¼ºé™·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Main Conference",
      "pdf_url": "https://arxiv.org/pdf/2509.01790v1",
      "published_date": "2025-09-01 21:38:28 UTC",
      "updated_date": "2025-09-01 21:38:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:21.760668+00:00"
    },
    {
      "arxiv_id": "2509.01787v3",
      "title": "AHAMask: Reliable Task Specification for Large Audio Language Models without Instructions",
      "title_zh": "AHAMaskï¼šå¤§éŸ³é¢‘è¯­è¨€æ¨¡å‹æ— éœ€æŒ‡ä»¤çš„å¯é ä»»åŠ¡è§„èŒƒ",
      "authors": [
        "Yiwei Guo",
        "Bohan Li",
        "Hankun Wang",
        "Zhihan Li",
        "Shuai Wang",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "Although current large audio language models (LALMs) extend text large language models (LLMs) with generic acoustic understanding abilities, they usually suffer from prompt sensitivity, where different instructions of the same intention can yield drastically different outcomes. In this work, we propose AHAMask, where we simply mask some of the attention heads in the decoder-only LLM backbone of LALMs, to trigger specific acoustic task functionalities without instructions. These masks are efficiently obtained by training on an LALM, with the number of trainable parameters equal to the attention head count in its LLM backbone. We show by experiments that applying such selective attention head masks achieves comparable or even better performance than using instructions, either on single or composite tasks. Besides achieving reliable acoustic task specification for LALMs, this also reveals that LALMs exhibit certain \"functional pathways\" in their attention heads.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AHAMaskï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºå¤§éŸ³é¢‘è¯­è¨€æ¨¡å‹ (LALMs) è®¾è®¡çš„å¯é ä»»åŠ¡è§„èŒƒæ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³æ¨¡å‹å¯¹æç¤ºè¯æ•æ„Ÿ (prompt sensitivity) çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒæ–¹æ³•æ˜¯é€šè¿‡åœ¨è§£ç å™¨æ¶æ„ (decoder-only LLM backbone) ä¸­å±è”½ç‰¹å®šçš„æ³¨æ„åŠ›å¤´ (attention heads)ï¼Œä»è€Œåœ¨æ— éœ€æŒ‡ä»¤çš„æƒ…å†µä¸‹è§¦å‘ç‰¹å®šçš„éŸ³é¢‘ä»»åŠ¡åŠŸèƒ½ã€‚è¿™äº›æ©ç é€šè¿‡åœ¨ LALM ä¸Šè¿›è¡Œé«˜æ•ˆè®­ç»ƒè·å¾—ï¼Œä¸”å¯è®­ç»ƒå‚æ•°é‡ä»…ç­‰äº LLM ä¸»å¹²ç½‘ç»œä¸­çš„æ³¨æ„åŠ›å¤´æ€»æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåº”ç”¨è¿™ç§é€‰æ‹©æ€§çš„æ³¨æ„åŠ›å¤´æ©ç åœ¨å•é¡¹æˆ–å¤åˆä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ä½¿ç”¨æŒ‡ä»¤çš„æ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚è¯¥ç ”ç©¶ä¸ä»…ä¸º LALMs æä¾›äº†å¯é çš„ä»»åŠ¡è§„èŒƒæ‰‹æ®µï¼Œè¿˜æ­ç¤ºäº†å¤§éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„æ³¨æ„åŠ›å¤´ä¸­å­˜åœ¨ç‰¹å®šçš„â€œåŠŸèƒ½è·¯å¾„ (functional pathways)â€ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "15 pages, 10 tables, 6 figures. This is the camera ready version for AAAI 2026, plus an appendix for supplementary experimental details and results",
      "pdf_url": "https://arxiv.org/pdf/2509.01787v3",
      "published_date": "2025-09-01 21:33:22 UTC",
      "updated_date": "2025-11-29 07:18:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:28.162014+00:00"
    },
    {
      "arxiv_id": "2509.02639v1",
      "title": "Enhanced Single-Cell RNA-seq Embedding through Gene Expression and Data-Driven Gene-Gene Interaction Integration",
      "title_zh": "èåˆåŸºå› è¡¨è¾¾ä¸æ•°æ®é©±åŠ¨åŸºå› é—´ç›¸äº’ä½œç”¨çš„å¢å¼ºå‹å•ç»†èƒ RNA-seq åµŒå…¥",
      "authors": [
        "Hojjat Torabi Goudarzi",
        "Maziyar Baran Pouyan"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) provides unprecedented insights into cellular heterogeneity, enabling detailed analysis of complex biological systems at single-cell resolution. However, the high dimensionality and technical noise inherent in scRNA-seq data pose significant analytical challenges. While current embedding methods focus primarily on gene expression levels, they often overlook crucial gene-gene interactions that govern cellular identity and function. To address this limitation, we present a novel embedding approach that integrates both gene expression profiles and data-driven gene-gene interactions. Our method first constructs a Cell-Leaf Graph (CLG) using random forest models to capture regulatory relationships between genes, while simultaneously building a K-Nearest Neighbor Graph (KNNG) to represent expression similarities between cells. These graphs are then combined into an Enriched Cell-Leaf Graph (ECLG), which serves as input for a graph neural network to compute cell embeddings. By incorporating both expression levels and gene-gene interactions, our approach provides a more comprehensive representation of cellular states. Extensive evaluation across multiple datasets demonstrates that our method enhances the detection of rare cell populations and improves downstream analyses such as visualization, clustering, and trajectory inference. This integrated approach represents a significant advance in single-cell data analysis, offering a more complete framework for understanding cellular diversity and dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹åµŒå…¥æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ Single-cell RNA sequencing (scRNA-seq) æ•°æ®ä¸­é«˜ç»´æ€§å’ŒæŠ€æœ¯å™ªå£°å¸¦æ¥çš„åˆ†ææŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç°æœ‰æ–¹æ³•å¯¹ gene-gene interactions çš„å¿½è§†ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨éšæœºæ£®æ—æ¨¡å‹æ„å»º Cell-Leaf Graph (CLG) ä»¥æ•æ‰åŸºå› é—´çš„è°ƒæ§å…³ç³»ï¼Œå¹¶ç»“åˆè¡¨å¾ç»†èƒç›¸ä¼¼æ€§çš„ K-Nearest Neighbor Graph (KNNG) èåˆæˆ Enriched Cell-Leaf Graph (ECLG)ã€‚ECLG éšåè¢«ä½œä¸ºå›¾ç¥ç»ç½‘ç»œ (graph neural network) çš„è¾“å…¥æ¥è®¡ç®—ç»†èƒåµŒå…¥ï¼Œä»è€Œå®ç°å¯¹ç»†èƒçŠ¶æ€æ›´å…¨é¢çš„è¡¨å¾ã€‚å¤šé¡¹æ•°æ®é›†çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†å¯¹ç¨€æœ‰ç»†èƒç¾¤ä½“çš„æ£€æµ‹èƒ½åŠ›ï¼Œå¹¶æ”¹è¿›äº†å¯è§†åŒ–ã€èšç±» (clustering) å’Œè½¨è¿¹æ¨æ–­ (trajectory inference) ç­‰ä¸‹æ¸¸åˆ†ææ•ˆæœã€‚è¿™ç§é›†æˆåŸºå› è¡¨è¾¾ä¸æ•°æ®é©±åŠ¨åŸºå› äº’ä½œçš„æ–¹æ³•ï¼Œä¸ºç†è§£ç»†èƒå¤šæ ·æ€§åŠåŠ¨åŠ›å­¦æä¾›äº†ä¸€ä¸ªæ›´å®Œæ•´çš„æ¡†æ¶ï¼Œä»£è¡¨äº†å•ç»†èƒæ•°æ®åˆ†æé¢†åŸŸçš„æ˜¾è‘—è¿›å±•ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "33 pages, 9 figures, article",
      "pdf_url": "https://arxiv.org/pdf/2509.02639v1",
      "published_date": "2025-09-01 21:19:27 UTC",
      "updated_date": "2025-09-01 21:19:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:32.148457+00:00"
    },
    {
      "arxiv_id": "2509.01772v1",
      "title": "chDzDT: Word-level morphology-aware language model for Algerian social media text",
      "title_zh": "chDzDTï¼šé¢å‘é˜¿å°”åŠåˆ©äºšç¤¾äº¤åª’ä½“æ–‡æœ¬çš„è¯çº§å½¢æ€æ„ŸçŸ¥è¯­è¨€æ¨¡å‹",
      "authors": [
        "Abdelkrime Aries"
      ],
      "abstract": "Pre-trained language models (PLMs) have substantially advanced natural language processing by providing context-sensitive text representations. However, the Algerian dialect remains under-represented, with few dedicated models available. Processing this dialect is challenging due to its complex morphology, frequent code-switching, multiple scripts, and strong lexical influences from other languages. These characteristics complicate tokenization and reduce the effectiveness of conventional word- or subword-level approaches.\n  To address this gap, we introduce chDzDT, a character-level pre-trained language model tailored for Algerian morphology. Unlike conventional PLMs that rely on token sequences, chDzDT is trained on isolated words. This design allows the model to encode morphological patterns robustly, without depending on token boundaries or standardized orthography. The training corpus draws from diverse sources, including YouTube comments, French, English, and Berber Wikipedia, as well as the Tatoeba project. It covers multiple scripts and linguistic varieties, resulting in a substantial pre-training workload.\n  Our contributions are threefold: (i) a detailed morphological analysis of Algerian dialect using YouTube comments; (ii) the construction of a multilingual Algerian lexicon dataset; and (iii) the development and extensive evaluation of a character-level PLM as a morphology-focused encoder for downstream tasks. The proposed approach demonstrates the potential of character-level modeling for morphologically rich, low-resource dialects and lays a foundation for more inclusive and adaptable NLP systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”åŠåˆ©äºšæ–¹è¨€åœ¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹(PLMs)ä¸­è¡¨å¾ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºchDzDTçš„å­—ç¬¦çº§é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚ç”±äºè¯¥æ–¹è¨€å…·æœ‰å¤æ‚çš„è¯æ³•(morphology)ã€é¢‘ç¹çš„ä»£ç åˆ‡æ¢(code-switching)ä»¥åŠå¤šè¯­ç§è¯æ±‡å½±å“ï¼Œä¼ ç»Ÿçš„è¯çº§æˆ–å­è¯çº§æ–¹æ³•éš¾ä»¥å®ç°æœ‰æ•ˆå»ºæ¨¡ã€‚chDzDTé‡‡ç”¨äº†åŸºäºå­¤ç«‹å•è¯çš„å­—ç¬¦çº§è®­ç»ƒç­–ç•¥ï¼Œä½¿å…¶èƒ½å¤Ÿä¸ä¾èµ–è¯ç•Œæˆ–æ ‡å‡†åŒ–æ‹¼å†™ï¼Œç¨³å¥åœ°æ•æ‰å¹¶ç¼–ç è¯æ³•æ¨¡å¼ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨YouTubeè¯„è®ºã€å¤šè¯­ç§ç»´åŸºç™¾ç§‘åŠTatoebaé¡¹ç›®æ„å»ºäº†æ¶µç›–å¤šç§è„šæœ¬å’Œè¯­è¨€å˜ä½“çš„è¯­æ–™åº“ã€‚è¯¥å·¥ä½œçš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å¯¹é˜¿å°”åŠåˆ©äºšæ–¹è¨€çš„è¯¦ç»†è¯æ³•åˆ†æã€å¤šè¯­è¨€è¯åº“æ•°æ®é›†çš„æ„å»ºï¼Œä»¥åŠå¯¹è¯¥æ¨¡å‹ä½œä¸ºè¯æ³•ç¼–ç å™¨çš„å…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœè¯æ˜äº†å­—ç¬¦çº§å»ºæ¨¡åœ¨å¤„ç†è¯æ³•ä¸°å¯Œä¸”ä½èµ„æºæ–¹è¨€æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæ„å»ºæ›´å…·åŒ…å®¹æ€§çš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01772v1",
      "published_date": "2025-09-01 21:09:55 UTC",
      "updated_date": "2025-09-01 21:09:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:34.364757+00:00"
    },
    {
      "arxiv_id": "2509.02637v1",
      "title": "A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection",
      "title_zh": "ç”¨äºé²æ£’æ ¸åˆ†è£‚è±¡æ£€æµ‹çš„å•æ£€æµ‹èšç„¦å‹ YOLO æ¡†æ¶",
      "authors": [
        "Yasemin Topuz",
        "M. Taha GÃ¶kcan",
        "Serdar YÄ±ldÄ±z",
        "SongÃ¼l VarlÄ±"
      ],
      "abstract": "Mitotic figure detection is a crucial task in computational pathology, as mitotic activity serves as a strong prognostic marker for tumor aggressiveness. However, domain variability that arises from differences in scanners, tissue types, and staining protocols poses a major challenge to the robustness of automated detection methods. In this study, we introduce SDF-YOLO (Single Detect Focused YOLO), a lightweight yet domain-robust detection framework designed specifically for small, rare targets such as mitotic figures. The model builds on YOLOv11 with task-specific modifications, including a single detection head aligned with mitotic figure scale, coordinate attention to enhance positional sensitivity, and improved cross-channel feature mixing. Experiments were conducted on three datasets that span human and canine tumors: MIDOG ++, canine cutaneous mast cell tumor (CCMCT), and canine mammary carcinoma (CMC). When submitted to the preliminary test set for the MIDOG2025 challenge, SDF-YOLO achieved an average precision (AP) of 0.799, with a precision of 0.758, a recall of 0.775, an F1 score of 0.766, and an FROC-AUC of 5.793, demonstrating both competitive accuracy and computational efficiency. These results indicate that SDF-YOLO provides a reliable and efficient framework for robust mitotic figure detection across diverse domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—ç—…ç†å­¦ä¸­ç”±äºæ‰«æä»ªã€ç»„ç»‡ç±»å‹å’ŒæŸ“è‰²æ–¹æ¡ˆå·®å¼‚å¯¼è‡´çš„é¢†åŸŸå˜å¼‚æ€§(domain variability)æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡æœ‰ä¸åˆ†è£‚è±¡(mitotic figure)æ£€æµ‹é²æ£’æ€§çš„æ¡†æ¶ã€‚ä½œè€…å¼•å…¥äº†SDF-YOLO (Single Detect Focused YOLO)ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºYOLOv11æ”¹è¿›çš„è½»é‡çº§ä¸”å…·æœ‰é¢†åŸŸé²æ£’æ€§çš„æ£€æµ‹æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºæ£€æµ‹æ ¸åˆ†è£‚è±¡è¿™ç±»å¾®å°ä¸”ç¨€æœ‰çš„ç›®æ ‡ã€‚è¯¥æ¨¡å‹é€šè¿‡é‡‡ç”¨ä¸ç›®æ ‡å°ºåº¦å¯¹é½çš„å•æ£€æµ‹å¤´(single detection head)ã€å¼•å…¥åæ ‡æ³¨æ„åŠ›(coordinate attention)ä»¥å¢å¼ºä½ç½®æ•æ„Ÿæ€§ï¼Œå¹¶ä¼˜åŒ–è·¨é€šé“ç‰¹å¾æ··åˆ(cross-channel feature mixing)æ¥æå‡æ€§èƒ½ã€‚å®éªŒåœ¨åŒ…æ‹¬MIDOG++ã€çŠ¬çš®è‚¤è‚¥å¤§ç»†èƒç˜¤(CCMCT)å’ŒçŠ¬ä¹³è…ºç™Œ(CMC)åœ¨å†…çš„å¤šä¸ªäººç±»å’ŒçŠ¬ç±»è‚¿ç˜¤æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚åœ¨MIDOG2025æŒ‘æˆ˜èµ›çš„åˆæ­¥æµ‹è¯•ä¸­ï¼ŒSDF-YOLOå–å¾—äº†0.799çš„å¹³å‡ç²¾åº¦(AP)å’Œ0.766çš„F1åˆ†æ•°ï¼Œè¯æ˜äº†å…¶ä¼˜å¼‚çš„æ£€æµ‹æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼ŒSDF-YOLOåœ¨è·¨é¢†åŸŸåœºæ™¯ä¸‹å…¼å…·é«˜å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œä¸ºç¨³å¥çš„è‡ªåŠ¨åŒ–ç—…ç†è¯Šæ–­æä¾›äº†å¯é çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.02637v1",
      "published_date": "2025-09-01 20:41:48 UTC",
      "updated_date": "2025-09-01 20:41:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:39.155288+00:00"
    },
    {
      "arxiv_id": "2509.04498v2",
      "title": "Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations",
      "title_zh": "æˆ‘è¯¥å»å“ªå„¿ç•™å­¦ï¼Ÿåè§è¯­è¨€æ¨¡å‹è¯´äº†ç®—ï¼è¯„ä¼°å­¦æœ¯æ¨èä¸­è¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§",
      "authors": [
        "Krithi Shailya",
        "Akhilesh Kumar Mishra",
        "Gokul S Krishnan",
        "Balaraman Ravindran"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used as daily recommendation systems for tasks like education planning, yet their recommendations risk perpetuating societal biases. This paper empirically examines geographic, demographic, and economic biases in university and program suggestions from three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360 simulated user profiles varying by gender, nationality, and economic status, we analyze over 25,000 recommendations. Results show strong biases: institutions in the Global North are disproportionately favored, recommendations often reinforce gender stereotypes, and institutional repetition is prevalent. While LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities across 58 countries, systemic disparities persist. To quantify these issues, we propose a novel, multi-dimensional evaluation framework that goes beyond accuracy by measuring demographic and geographic representation. Our findings highlight the urgent need for bias consideration in educational LMs to ensure equitable global access to higher education.",
      "tldr_zh": "æœ¬ç ”ç©¶è°ƒæŸ¥äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å­¦æœ¯æ¨èä¸­å¯èƒ½å­˜åœ¨çš„åœ°ç†ã€äººå£å’Œç»æµåè§ï¼Œç‰¹åˆ«æ˜¯å…¶å¯¹å…¨çƒé«˜ç­‰æ•™è‚²å…¬å¹³æ€§çš„å½±å“ã€‚ç ”ç©¶é€šè¿‡æ¨¡æ‹Ÿ 360 ä¸ªåŒ…å«æ€§åˆ«ã€å›½ç±å’Œç»æµèƒŒæ™¯å·®å¼‚çš„ç”¨æˆ·æ¡£æ¡ˆï¼Œå¯¹ LLaMA-3.1-8Bã€Gemma-7B å’Œ Mistral-7B ç”Ÿæˆçš„ 25,000 å¤šæ¡å»ºè®®è¿›è¡Œäº†åˆ†æã€‚ç»“æœæ˜¾ç¤ºè¿™äº›æ¨¡å‹å‘ˆç°å‡ºæ˜æ˜¾çš„åè§ï¼Œå€¾å‘äºä¸æˆæ¯”ä¾‹åœ°æ¨èä½äº Global North çš„æœºæ„ï¼Œå¹¶ç»å¸¸å¼ºåŒ– gender stereotypesã€‚å°½ç®¡ LLaMA-3.1 åœ¨æ¨èå¤šæ ·æ€§æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œæ¶µç›–äº† 58 ä¸ªå›½å®¶çš„ 481 æ‰€å¤§å­¦ï¼Œä½†ç³»ç»Ÿæ€§çš„ä¸å¹³ç­‰ä¾ç„¶å­˜åœ¨ã€‚ç ”ç©¶ä¸ºæ­¤æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šç»´è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¶…è¶Šä¼ ç»Ÿçš„å‡†ç¡®ç‡æŒ‡æ ‡ï¼Œä»äººå£å’Œåœ°ç†ä»£è¡¨æ€§çš„è§’åº¦é‡åŒ–æ¨¡å‹åè§ã€‚è¯¥å‘ç°å¼ºè°ƒäº†åœ¨æ•™è‚²ç±» LLMs ä¸­å¼•å…¥åè§è¯„ä¼°çš„ç´§è¿«æ€§ï¼Œä»¥ç¡®ä¿å…¨çƒé«˜ç­‰æ•™è‚²èµ„æºè·å–çš„å…¬å¹³æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IJCNLP-AACL 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.04498v2",
      "published_date": "2025-09-01 19:51:06 UTC",
      "updated_date": "2025-11-12 05:50:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:43.783070+00:00"
    },
    {
      "arxiv_id": "2509.04497v1",
      "title": "A Narrative-Driven Computational Framework for Clinician Burnout Surveillance",
      "title_zh": "å™äº‹é©±åŠ¨çš„ä¸´åºŠåŒ»ç”ŸèŒä¸šå€¦æ€ ç›‘æµ‹è®¡ç®—æ¡†æ¶",
      "authors": [
        "Syed Ahmad Chan Bukhari",
        "Fazel Keshtkar",
        "Alyssa Meczkowska"
      ],
      "abstract": "Clinician burnout poses a substantial threat to patient safety, particularly in high-acuity intensive care units (ICUs). Existing research predominantly relies on retrospective survey tools or broad electronic health record (EHR) metadata, often overlooking the valuable narrative information embedded in clinical notes. In this study, we analyze 10,000 ICU discharge summaries from MIMIC-IV, a publicly available database derived from the electronic health records of Beth Israel Deaconess Medical Center. The dataset encompasses diverse patient data, including vital signs, medical orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. We introduce a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for clinical narratives, a lexical stress lexicon tailored for clinician burnout surveillance, and five-topic latent Dirichlet allocation (LDA) with workload proxies. A provider-level logistic regression classifier achieves a precision of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out set, surpassing metadata-only baselines by greater than or equal to 0.17 F1 score. Specialty-specific analysis indicates elevated burnout risk among providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate that ICU clinical narratives contain actionable signals for proactive well-being monitoring.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸¥é‡å¨èƒæ‚£è€…å®‰å…¨çš„ä¸´åºŠåŒ»ç”Ÿå€¦æ€ (Clinician burnout)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå™äº‹é©±åŠ¨çš„è®¡ç®—æ¡†æ¶ï¼Œæ—¨åœ¨æŒ–æ˜ä¸´åºŠè®°å½•ä¸­è¢«å¿½è§†çš„å™äº‹æ€§ä¿¡æ¯ã€‚ç ”ç©¶åˆ©ç”¨æ¥è‡ª MIMIC-IV æ•°æ®åº“çš„10,000ä»½é‡ç—‡ç›‘æŠ¤å®¤(ICU)å‡ºé™¢æ‘˜è¦ï¼Œæ„å»ºäº†ä¸€ç§ç»“åˆ BioBERT æƒ…æ„ŸåµŒå…¥(sentiment embeddings)ã€è¯æ±‡å‹åŠ›è¯åº“(lexical stress lexicon)ä»¥åŠåŒ…å«å·¥ä½œè´Ÿè½½ä»£ç†çš„äº”ä¸»é¢˜æ½œåœ¨å¤§ç‹„åˆ©å…‹é›·åˆ†é…(LDA)çš„æ··åˆæµæ°´çº¿(hybrid pipeline)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æä¾›è€…çº§åˆ«çš„é€»è¾‘å›å½’åˆ†ç±»å™¨(logistic regression classifier)åœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†0.84çš„ F1 scoreï¼Œæ˜¾è‘—ä¼˜äºä»…ä¾èµ–å…ƒæ•°æ®çš„åŸºçº¿æ¨¡å‹ã€‚ç§‘å®¤ç‰¹å®šåˆ†æè¡¨æ˜ï¼Œæ”¾å°„ç§‘(Radiology)ã€ç²¾ç¥ç§‘(Psychiatry)å’Œç¥ç»ç§‘(Neurology)çš„åŒ»ç”Ÿé¢ä¸´æ›´é«˜çš„å€¦æ€ é£é™©ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼ŒICU ä¸´åºŠå™äº‹ä¸­åŒ…å«å¯ç”¨äºä¸»åŠ¨ç›‘æµ‹åŒ»æŠ¤äººå‘˜ç¦ç¥‰çš„å¯è¡Œä¿¡å·ï¼Œä¸ºé¢„é˜²å’Œå¹²é¢„èŒä¸šå€¦æ€ æä¾›äº†æ•°æ®é©±åŠ¨çš„æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 6 Figure",
      "pdf_url": "https://arxiv.org/pdf/2509.04497v1",
      "published_date": "2025-09-01 19:05:26 UTC",
      "updated_date": "2025-09-01 19:05:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:50:56.556690+00:00"
    },
    {
      "arxiv_id": "2509.01716v1",
      "title": "An LLM-enabled semantic-centric framework to consume privacy policies",
      "title_zh": "ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»¥è¯­ä¹‰ä¸ºä¸­å¿ƒçš„éšç§æ”¿ç­–è§£ææ¡†æ¶",
      "authors": [
        "Rui Zhao",
        "Vladyslav Melnychuk",
        "Jun Zhao",
        "Jesse Wright",
        "Nigel Shadbolt"
      ],
      "abstract": "In modern times, people have numerous online accounts, but they rarely read the Terms of Service or Privacy Policy of those sites, despite claiming otherwise, due to the practical difficulty in comprehending them. The mist of data privacy practices forms a major barrier for user-centred Web approaches, and for data sharing and reusing in an agentic world. Existing research proposed methods for using formal languages and reasoning for verifying the compliance of a specified policy, as a potential cure for ignoring privacy policies. However, a critical gap remains in the creation or acquisition of such formal policies at scale. We present a semantic-centric approach for using state-of-the-art large language models (LLM), to automatically identify key information about privacy practices from privacy policies, and construct $\\mathit{Pr}^2\\mathit{Graph}$, knowledge graph with grounding from Data Privacy Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with the pipeline, the $\\mathit{Pr}^2\\mathit{Graph}$ for the top-100 popular websites is also released as a public resource, by using the pipeline for analysis. We also demonstrate how the $\\mathit{Pr}^2\\mathit{Graph}$ can be used to support downstream tasks by constructing formal policy representations such as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use (psDToU). To evaluate the technology capability, we enriched the Policy-IE dataset by employing legal experts to create custom annotations. We benchmarked the performance of different large language models for our pipeline and verified their capabilities. Overall, they shed light on the possibility of large-scale analysis of online services' privacy practices, as a promising direction to audit the Web and the Internet. We release all datasets and source code as public resources to facilitate reuse and improvement.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨æˆ·éš¾ä»¥ç†è§£éšç§æ”¿ç­–çš„ç°å®æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„ä»¥è¯­ä¹‰ä¸ºä¸­å¿ƒçš„æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å¤„ç†å’Œè§£æéšç§æ”¿ç­–ã€‚è¯¥æ¡†æ¶åˆ©ç”¨LLMè¯†åˆ«å…³é”®éšç§å®è·µä¿¡æ¯ï¼Œå¹¶æ„å»ºäº†åŸºäºæ•°æ®éšç§è¯æ±‡è¡¨(Data Privacy Vocabulary, DPV)çš„çŸ¥è¯†å›¾è°±$\\mathit{Pr}^2\\mathit{Graph}$ï¼Œä»¥æ”¯æŒä¸‹æ¸¸ä»»åŠ¡ã€‚ä½œè€…åˆ©ç”¨è¯¥æµæ°´çº¿åˆ†æå¹¶å‘å¸ƒäº†å…¨çƒå‰100ä¸ªçƒ­é—¨ç½‘ç«™çš„$\\mathit{Pr}^2\\mathit{Graph}$æ•°æ®é›†ã€‚ç ”ç©¶è¿›ä¸€æ­¥å±•ç¤ºäº†è¯¥å›¾è°±åœ¨æ„å»ºOpen Digital Right Language (ODRL)å’ŒpsDToUç­‰å½¢å¼åŒ–æ”¿ç­–è¡¨ç¤ºæ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡æ³•å¾‹ä¸“å®¶å‚ä¸æ ‡æ³¨å¹¶å¢å¼ºçš„Policy-IEæ•°æ®é›†ï¼Œè¯¥ç ”ç©¶å¯¹å¤šç§LLMçš„æ€§èƒ½è¿›è¡Œäº†åŸºå‡†æµ‹è¯•å’ŒéªŒè¯ã€‚è¯¥æˆæœä¸ºå¤§è§„æ¨¡å®¡è®¡äº’è”ç½‘æœåŠ¡çš„éšç§å®è·µæä¾›äº†æ–°è·¯å¾„ï¼Œç›¸å…³æ•°æ®é›†å’Œæºä»£ç å‡å·²å‘å…¬ä¼—å¼€æ”¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01716v1",
      "published_date": "2025-09-01 18:53:13 UTC",
      "updated_date": "2025-09-01 18:53:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:08.485323+00:00"
    },
    {
      "arxiv_id": "2509.01704v2",
      "title": "Deep Learning-Based Rock Particulate Classification Using Attention-Enhanced ConvNeXt",
      "title_zh": "åŸºäºæ³¨æ„åŠ›å¢å¼ºå‹ ConvNeXt çš„æ·±åº¦å­¦ä¹ å²©çŸ³é¢—ç²’åˆ†ç±»",
      "authors": [
        "Anthony Amankwah",
        "Chris Aldrich"
      ],
      "abstract": "Accurate classification of rock sizes is a vital component in geotechnical engineering, mining, and resource management, where precise estimation influences operational efficiency and safety. In this paper, we propose an enhanced deep learning model based on the ConvNeXt architecture, augmented with both self-attention and channel attention mechanisms. Building upon the foundation of ConvNext, our proposed model, termed CNSCA, introduces self-attention to capture long-range spatial dependencies and channel attention to emphasize informative feature channels. This hybrid design enables the model to effectively capture both fine-grained local patterns and broader contextual relationships within rock imagery, leading to improved classification accuracy and robustness. We evaluate our model on a rock size classification dataset and compare it against three strong baseline. The results demonstrate that the incorporation of attention mechanisms significantly enhances the models capability for fine-grained classification tasks involving natural textures like rocks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å²©åœŸå·¥ç¨‹å’Œé‡‡çŸ¿é¢†åŸŸä¸­å²©çŸ³ç²’å¾„å‡†ç¡®åˆ†ç±»çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åä¸º CNSCA çš„å¢å¼ºå‹æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä»¥ ConvNeXt æ¶æ„ä¸ºåŸºç¡€ï¼Œåˆ›æ–°æ€§åœ°é›†æˆäº† self-attention (è‡ªæ³¨æ„åŠ›) å’Œ channel attention (é€šé“æ³¨æ„åŠ›) æœºåˆ¶ã€‚CNSCA åˆ©ç”¨ self-attention æ•æ‰é•¿ç¨‹ç©ºé—´ä¾èµ–ï¼Œå¹¶ç»“åˆ channel attention å¼ºåŒ–å…³é”®ç‰¹å¾é€šé“ï¼Œä½¿å…¶èƒ½å¤ŸåŒæ—¶æ•è·å²©çŸ³å›¾åƒä¸­çš„ç»†ç²’åº¦å±€éƒ¨æ¨¡å¼ä¸å®è§‚ä¸Šä¸‹æ–‡å…³ç³»ã€‚é€šè¿‡åœ¨å²©çŸ³ç²’å¾„åˆ†ç±»æ•°æ®é›†ä¸Šä¸ä¸‰ä¸ªå¼ºåŸºçº¿æ¨¡å‹è¿›è¡Œå¯¹æ¯”å®éªŒï¼Œç»“æœè¯æ˜å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ˜¾è‘—æå‡äº†æ¨¡å‹å¤„ç†è‡ªç„¶çº¹ç†çš„åˆ†ç±»å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¿™ä¸€ç ”ç©¶æˆæœä¸ºæé«˜çŸ¿ä¸šèµ„æºç®¡ç†çš„è¿ä½œæ•ˆç‡å’Œå®‰å…¨æ€§æä¾›äº†æœ‰æ•ˆçš„æ·±åº¦å­¦ä¹ è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper has been withdrawn by the authors to accommodate substantial revisions requested by a co-author. A revised version will be submitted",
      "pdf_url": "https://arxiv.org/pdf/2509.01704v2",
      "published_date": "2025-09-01 18:24:40 UTC",
      "updated_date": "2025-09-11 08:12:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:05.889201+00:00"
    },
    {
      "arxiv_id": "2509.01684v1",
      "title": "Reinforcement Learning for Machine Learning Engineering Agents",
      "title_zh": "é¢å‘æœºå™¨å­¦ä¹ å·¥ç¨‹æ™ºèƒ½ä½“çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Sherry Yang",
        "Joy He-Yueya",
        "Percy Liang"
      ],
      "abstract": "Existing agents for solving tasks such as ML engineering rely on prompting powerful language models. As a result, these agents do not improve with more experience. In this paper, we show that agents backed by weaker models that improve via reinforcement learning (RL) can outperform agents backed by much larger, but static models. We identify two major challenges with RL in this setting. First, actions can take a variable amount of time (e.g., executing code for different solutions), which leads to asynchronous policy gradient updates that favor faster but suboptimal solutions. To tackle variable-duration actions, we propose duration-aware gradient updates in a distributed asynchronous RL framework to amplify high-cost but high-reward actions. Second, using only test split performance as a reward provides limited feedback. A program that is nearly correct is treated the same as one that fails entirely. To address this, we propose environment instrumentation to offer partial credit, distinguishing almost-correct programs from those that fail early (e.g., during data loading). Environment instrumentation uses a separate static language model to insert print statement to an existing program to log the agent's experimental progress, from which partial credit can be extracted as reward signals for learning. Our experimental results on MLEBench suggest that performing gradient updates on a much smaller model (Qwen2.5-3B) trained with RL outperforms prompting a much larger model (Claude-3.5-Sonnet) with agent scaffolds, by an average of 22% across 12 Kaggle tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰çš„æœºå™¨å­¦ä¹ å·¥ç¨‹æ™ºèƒ½ä½“ä¾èµ–é™æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸”æ— æ³•éšç»éªŒæ”¹è¿›çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)çš„ä¼˜åŒ–æ–¹æ³•ã€‚ç ”ç©¶è€…æŒ‡å‡ºï¼Œé€šè¿‡ RL æ”¹è¿›çš„å°å‹æ¨¡å‹èƒ½å¤Ÿè¶…è¶Šæ›´å¤§ä½†é™æ€çš„æ¨¡å‹ï¼Œå¹¶è¯†åˆ«å‡ºåŠ¨ä½œæ‰§è¡Œæ—¶é•¿ä¸ä¸€å’Œå¥–åŠ±ä¿¡å·ç¨€ç–è¿™ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³æ—¶é•¿å·®å¼‚å¯¼è‡´çš„å¼‚æ­¥æ¢¯åº¦æ›´æ–°åå·®ï¼Œç ”ç©¶æå‡ºäº†æ—¶é•¿æ„ŸçŸ¥æ¢¯åº¦æ›´æ–°(duration-aware gradient updates)æœºåˆ¶ï¼Œæ—¨åœ¨æ”¾å¤§é«˜æˆæœ¬ä½†é«˜å›æŠ¥çš„æœ‰æ•ˆåŠ¨ä½œã€‚é’ˆå¯¹å¥–åŠ±ç¨€ç–é—®é¢˜ï¼Œç ”ç©¶å¼•å…¥äº†ç¯å¢ƒæ’æ¡©(environment instrumentation)æŠ€æœ¯ï¼Œé€šè¿‡è‡ªåŠ¨æ’å…¥æ—¥å¿—æ¥æå–éƒ¨åˆ†ä¿¡ç”¨(partial credit)ä½œä¸ºä¸­é—´å¥–åŠ±ä¿¡å·ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ MLEBench çš„ 12 é¡¹ Kaggle ä»»åŠ¡ä¸­ï¼Œç» RL è®­ç»ƒçš„å°å‹æ¨¡å‹ Qwen2.5-3B æ€§èƒ½æ¯”ç›´æ¥æç¤ºå¤§å‹æ¨¡å‹ Claude-3.5-Sonnet å¹³å‡é«˜å‡º 22%ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†é€šè¿‡é’ˆå¯¹æ€§å¼ºåŒ–å­¦ä¹ æå‡ä¸“é—¨åŒ–æ™ºèƒ½ä½“æ€§èƒ½çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01684v1",
      "published_date": "2025-09-01 18:04:10 UTC",
      "updated_date": "2025-09-01 18:04:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:15.388689+00:00"
    },
    {
      "arxiv_id": "2509.01659v1",
      "title": "Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025",
      "title_zh": "Physics Supernovaï¼šAI æ™ºèƒ½ä½“åœ¨ IPhO 2025 ä¸­è¡¨ç°æ¯”è‚©é¡¶å°–é‡‘ç‰Œå¾—ä¸»",
      "authors": [
        "Jiahao Qiu",
        "Jingzhe Shi",
        "Xinzhe Juan",
        "Zelin Zhao",
        "Jiayi Geng",
        "Shilong Liu",
        "Hongru Wang",
        "Sanfeng Wu",
        "Mengdi Wang"
      ],
      "abstract": "Physics provides fundamental laws that describe and predict the natural world. AI systems aspiring toward more general, real-world intelligence must therefore demonstrate strong physics problem-solving abilities: to formulate and apply physical laws for explaining and predicting physical processes. The International Physics Olympiad (IPhO)--the world's most prestigious physics competition--offers a rigorous benchmark for this purpose. We introduce Physics Supernova, an AI agent system with superior physics problem-solving abilities that match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics Supernova attains 23.5/30 points, ranking 14th of 406 contestants and surpassing the median performance of human gold medalists. We extensively analyzed Physics Supernova's capabilities and flexibility across diverse physics tasks. These results show that principled tool integration within agent systems can deliver competitive improvements in solving challenging science problems. The codes are available at https://github.com/CharlesQ9/Physics-Supernova.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Physics Supernovaï¼Œè¿™æ˜¯ä¸€ä¸ªå…·å¤‡å“è¶Šç‰©ç†å»ºæ¨¡ä¸æ¨å¯¼èƒ½åŠ›çš„ AI Agent ç³»ç»Ÿï¼Œæ—¨åœ¨åº”å¯¹æœ€å…·æŒ‘æˆ˜æ€§çš„ç‰©ç†ç§‘å­¦éš¾é¢˜ã€‚è¯¥ç³»ç»Ÿä»¥å›½é™…ç‰©ç†å¥¥æ—åŒ¹å…‹ç«èµ› (IPhO) ä¸ºè¯„ä»·åŸºå‡†ï¼Œåœ¨ IPhO 2025 çš„ç†è®ºé¢˜ç›®æµ‹è¯•ä¸­å–å¾—äº† 23.5/30 çš„ä¼˜å¼‚æˆç»©ï¼Œåœ¨ 406 åå‚èµ›è€…ä¸­ä½åˆ—ç¬¬ 14 åã€‚è¿™ä¸€ç»“æœæ ‡å¿—ç€ AI çš„è¡¨ç°å·²æˆåŠŸè¶…è¶Šäººç±»é‡‘ç‰Œé€‰æ‰‹çš„å¹³å‡æ°´å¹³ï¼Œå±•ç°äº†å…¶åœ¨å¤æ‚ç‰©ç†è§„å¾‹åº”ç”¨æ–¹é¢çš„æ·±åšæ½œåŠ›ã€‚Physics Supernova çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶åœ¨æ™ºèƒ½ä½“ç³»ç»Ÿä¸­å®ç°çš„åŸåˆ™æ€§å·¥å…·é›†æˆ (principled tool integration)ï¼Œè¿™ä½¿å…¶åœ¨å¤„ç†ä¸åŒç±»å‹çš„ç‰©ç†ä»»åŠ¡æ—¶å…·å¤‡æé«˜çš„çµæ´»æ€§ä¸å‡†ç¡®åº¦ã€‚è¯¥ç ”ç©¶é€šè¿‡è¯¦ç»†çš„æ€§èƒ½åˆ†æè¯æ˜äº†é›†æˆåŒ–æ™ºèƒ½ä½“æ¡†æ¶åœ¨è§£å†³å°–ç«¯ç§‘å­¦é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œå¹¶å·²å°†ç›¸å…³ä»£ç åœ¨ GitHub å¼€æºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01659v1",
      "published_date": "2025-09-01 17:59:13 UTC",
      "updated_date": "2025-09-01 17:59:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:23.295189+00:00"
    },
    {
      "arxiv_id": "2509.01657v1",
      "title": "Data Retrieval with Importance Weights for Few-Shot Imitation Learning",
      "title_zh": "é¢å‘å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ çš„åŸºäºé‡è¦æ€§æƒé‡çš„æ•°æ®æ£€ç´¢",
      "authors": [
        "Amber Xie",
        "Rahul Chand",
        "Dorsa Sadigh",
        "Joey Hejna"
      ],
      "abstract": "While large-scale robot datasets have propelled recent progress in imitation learning, learning from smaller task specific datasets remains critical for deployment in new environments and unseen tasks. One such approach to few-shot imitation learning is retrieval-based imitation learning, which extracts relevant samples from large, widely available prior datasets to augment a limited demonstration dataset. To determine the relevant data from prior datasets, retrieval-based approaches most commonly calculate a prior data point's minimum distance to a point in the target dataset in latent space. While retrieval-based methods have shown success using this metric for data selection, we demonstrate its equivalence to the limit of a Gaussian kernel density (KDE) estimate of the target data distribution. This reveals two shortcomings of the retrieval rule used in prior work. First, it relies on high-variance nearest neighbor estimates that are susceptible to noise. Second, it does not account for the distribution of prior data when retrieving data. To address these issues, we introduce Importance Weighted Retrieval (IWR), which estimates importance weights, or the ratio between the target and prior data distributions for retrieval, using Gaussian KDEs. By considering the probability ratio, IWR seeks to mitigate the bias of previous selection rules, and by using reasonable modeling parameters, IWR effectively smooths estimates using all data points. Across both simulation environments and real-world evaluations on the Bridge dataset we find that our method, IWR, consistently improves performance of existing retrieval-based methods, despite only requiring minor modifications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹ (Few-Shot Imitation Learning)ä¸­ä»å¤§è§„æ¨¡å…ˆéªŒæ•°æ®é›†æ£€ç´¢ç›¸å…³æ•°æ®çš„æŒ‘æˆ˜ï¼Œæ·±å…¥åˆ†æäº†ç°æœ‰çš„åŸºäºæ½œç©ºé—´è·ç¦»çš„æ£€ç´¢æ–¹æ³•ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨æœ¬è´¨ä¸Šç­‰åŒäºé«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡(Gaussian Kernel Density Estimation, KDE)çš„æé™ï¼Œå› æ­¤å­˜åœ¨å¯¹å™ªå£°æ•æ„Ÿã€ä¼°è®¡æ–¹å·®é«˜çš„é—®é¢˜ï¼Œä¸”åœ¨æ£€ç´¢æ—¶æœªèƒ½è€ƒè™‘å…ˆéªŒæ•°æ®çš„åˆ†å¸ƒã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é‡è¦æ€§æƒé‡æ£€ç´¢(Importance Weighted Retrieval, IWR)ï¼Œåˆ©ç”¨ Gaussian KDE ä¼°è®¡ç›®æ ‡åˆ†å¸ƒä¸å…ˆéªŒåˆ†å¸ƒä¹‹é—´çš„æ¯”ç‡ï¼Œå³é‡è¦æ€§æƒé‡(Importance Weights)ã€‚IWR é€šè¿‡è€ƒè™‘æ¦‚ç‡æ¯”æ¥å‡è½»ä»¥å¾€é€‰æ‹©è§„åˆ™å¸¦æ¥çš„åå·®ï¼Œå¹¶åˆ©ç”¨åˆç†çš„å»ºæ¨¡å‚æ•°å¯¹æ‰€æœ‰æ•°æ®ç‚¹è¿›è¡Œæœ‰æ•ˆå¹³æ»‘ã€‚åœ¨æ¨¡æ‹Ÿç¯å¢ƒå’Œ Bridge æ•°æ®é›†çš„çœŸå®ä¸–ç•Œè¯„ä¼°ä¸­ï¼Œå®éªŒç»“æœè¡¨æ˜ IWR ä»…éœ€å¯¹ç°æœ‰æ¡†æ¶è¿›è¡Œå¾®å°ä¿®æ”¹ï¼Œå³å¯æ˜¾è‘—æå‡æ£€ç´¢å¼æ¨¡ä»¿å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Conference on Robot Learning 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01657v1",
      "published_date": "2025-09-01 17:58:41 UTC",
      "updated_date": "2025-09-01 17:58:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:24.184451+00:00"
    },
    {
      "arxiv_id": "2510.08578v1",
      "title": "AgenticAD: A Specialized Multiagent System Framework for Holistic Alzheimer Disease Management",
      "title_zh": "AgenticADï¼šé¢å‘é˜¿å°”èŒ¨æµ·é»˜ç—…å…¨æ–¹ä½ç®¡ç†çš„ä¸“ä¸šåŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¡†æ¶",
      "authors": [
        "Adib Bazgir",
        "Amir Habibdoust",
        "Xing Song",
        "Yuwen Zhang"
      ],
      "abstract": "Alzheimer's disease (AD) presents a complex, multifaceted challenge to patients, caregivers, and the healthcare system, necessitating integrated and dynamic support solutions. While artificial intelligence (AI) offers promising avenues for intervention, current applications are often siloed, addressing singular aspects of the disease such as diagnostics or caregiver support without systemic integration. This paper proposes a novel methodological framework for a comprehensive, multi-agent system (MAS) designed for holistic Alzheimer's disease management. The objective is to detail the architecture of a collaborative ecosystem of specialized AI agents, each engineered to address a distinct challenge in the AD care continuum, from caregiver support and multimodal data analysis to automated research and clinical data interpretation. The proposed framework is composed of eight specialized, interoperable agents. These agents are categorized by function: (1) Caregiver and Patient Support, (2) Data Analysis and Research, and (3) Advanced Multimodal Workflows. The methodology details the technical architecture of each agent, leveraging a suite of advanced technologies including large language models (LLMs) such as GPT-4o and Gemini, multi-agent orchestration frameworks, Retrieval-Augmented Generation (RAG) for evidence-grounded responses, and specialized tools for web scraping, multimodal data processing, and in-memory database querying. This paper presents a detailed architectural blueprint for an integrated AI ecosystem for AD care. By moving beyond single-purpose tools to a collaborative, multi-agent paradigm, this framework establishes a foundation for developing more adaptive, personalized, and proactive solutions. This methodological approach aims to pave the way for future systems capable of synthesizing diverse data streams to improve patient outcomes and reduce caregiver burden.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆAlzheimer's disease, ADï¼‰ç®¡ç†ä¸­ç°æœ‰ AI åº”ç”¨é›¶æ•£ã€ç¼ºä¹ç³»ç»Ÿé›†æˆçš„é—®é¢˜ï¼Œæå‡ºäº† AgenticADï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå…¨é¢ç®¡ç† AD çš„ä¸“é—¨åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent System, MASï¼‰æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±å…«ä¸ªä¸“é—¨çš„äº’æ“ä½œæ™ºèƒ½ä½“ç»„æˆï¼Œæ¶µç›–äº†ä»æŠ¤ç†äººå‘˜æ”¯æŒã€å¤šæ¨¡æ€æ•°æ®åˆ†æåˆ°ä¸´åºŠæ•°æ®è§£é‡Šçš„ AD æŠ¤ç†å…¨è¿‡ç¨‹ã€‚æŠ€æœ¯æ¶æ„åˆ©ç”¨äº†åŒ…æ‹¬ GPT-4o å’Œ Gemini åœ¨å†…çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¹¶ç»“åˆäº†å¤šæ™ºèƒ½ä½“ç¼–æ’æ¡†æ¶ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ä»¥åŠç”¨äºå¤šæ¨¡æ€æ•°æ®å¤„ç†çš„ä¸“ä¸šå·¥å…·ã€‚AgenticAD é€šè¿‡ä»å•ç”¨é€”å·¥å…·è½¬å‘åä½œçš„å¤šæ™ºèƒ½ä½“èŒƒå¼ï¼Œä¸ºå¼€å‘æ›´å…·é€‚åº”æ€§ã€ä¸ªæ€§åŒ–å’Œå‰ç»æ€§çš„åŒ»ç–—è§£å†³æ–¹æ¡ˆå¥ å®šäº†åŸºç¡€ã€‚è¿™ä¸€æ–¹æ³•è®ºæ—¨åœ¨é€šè¿‡ç»¼åˆå¤„ç†å¤šæ ·åŒ–çš„æ•°æ®æµï¼Œåœ¨æ”¹å–„æ‚£è€…é¢„åçš„åŒæ—¶æœ‰æ•ˆå‡è½»æŠ¤ç†äººå‘˜çš„è´Ÿæ‹…ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.08578v1",
      "published_date": "2025-09-01 17:51:56 UTC",
      "updated_date": "2025-09-01 17:51:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:30.686687+00:00"
    },
    {
      "arxiv_id": "2509.10503v1",
      "title": "FEDEXCHANGE: Bridging the Domain Gap in Federated Object Detection for Free",
      "title_zh": "FEDEXCHANGEï¼šé›¶æˆæœ¬å¼¥åˆè”é‚¦ç›®æ ‡æ£€æµ‹ä¸­çš„é¢†åŸŸå·®å¼‚",
      "authors": [
        "Haolin Yuan",
        "Jingtao Li",
        "Weiming Zhuang",
        "Chen Chen",
        "Lingjuan Lyu"
      ],
      "abstract": "Federated Object Detection (FOD) enables clients to collaboratively train a global object detection model without accessing their local data from diverse domains. However, significant variations in environment, weather, and other domain specific factors hinder performance, making cross domain generalization a key challenge. Existing FOD methods often overlook the hardware constraints of edge devices and introduce local training regularizations that incur high computational costs, limiting real-world applicability. In this paper, we propose FEDEXCHANGE, a novel FOD framework that bridges domain gaps without introducing additional local computational overhead. FEDEXCHANGE employs a server side dynamic model exchange strategy that enables each client to gain insights from other clients' domain data without direct data sharing. Specifically, FEDEXCHANGE allows the server to alternate between model aggregation and model exchange. During aggregation rounds, the server aggregates all local models as usual. In exchange rounds, FEDEXCHANGE clusters and exchanges local models based on distance measures, allowing local models to learn from a variety of domains. As all operations are performed on the server side, clients can achieve improved cross domain utility without any additional computational overhead. Extensive evaluations demonstrate that FEDEXCHANGE enhances FOD performance, achieving 1.6X better mean average precision in challenging domains, such as rainy conditions, while requiring only 0.8X the computational resources compared to baseline methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FEDEXCHANGEï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³è”é‚¦ç›®æ ‡æ£€æµ‹ (Federated Object Detection, FOD) ä¸­é¢†åŸŸå·®è· (domain gaps) æŒ‘æˆ˜çš„æ–°é¢–æ¡†æ¶ã€‚é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡ç¡¬ä»¶å—é™ä¸”ç°æœ‰è·¨åŸŸæ–¹æ³•è®¡ç®—å¼€é”€å¤§çš„é—®é¢˜ï¼ŒFEDEXCHANGE é‡‡ç”¨äº†ä¸€ç§æœåŠ¡å™¨ç«¯åŠ¨æ€æ¨¡å‹äº¤æ¢ç­–ç•¥ï¼Œåœ¨ä¸å¢åŠ å®¢æˆ·ç«¯é¢å¤–è®¡ç®—è´Ÿæ‹…çš„å‰æä¸‹æ˜¾è‘—æå‡æ³›åŒ–æ€§èƒ½ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨æœåŠ¡å™¨ç«¯äº¤æ›¿è¿›è¡Œæ¨¡å‹èšåˆä¸æ¨¡å‹äº¤æ¢ï¼Œå¹¶åˆ©ç”¨èšç±»æœºåˆ¶ä¿ƒä½¿å±€éƒ¨æ¨¡å‹ä»å¤šæ ·åŒ–çš„é¢†åŸŸæ•°æ®ä¸­å­¦ä¹ ã€‚ç”±äºæ‰€æœ‰å¤æ‚æ“ä½œå‡åœ¨æœåŠ¡å™¨ç«¯æ‰§è¡Œï¼Œå®¢æˆ·ç«¯æ— éœ€é¢å¤–å¼€é”€å³å¯è·å¾—æ›´å¼ºçš„è·¨åŸŸæ•ˆç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFEDEXCHANGE åœ¨é›¨å¤©ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­å°†å¹³å‡ç²¾åº¦å‡å€¼ (mean average precision, mAP) æå‡äº† 1.6 å€ï¼Œä¸”ç›¸æ¯”åŸºçº¿æ–¹æ³•ä»…éœ€ 0.8 å€çš„è®¡ç®—èµ„æºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10503v1",
      "published_date": "2025-09-01 17:39:25 UTC",
      "updated_date": "2025-09-01 17:39:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:33.494817+00:00"
    },
    {
      "arxiv_id": "2509.01641v1",
      "title": "Non-Identical Diffusion Models in MIMO-OFDM Channel Generation",
      "title_zh": "MIMO-OFDM ä¿¡é“ç”Ÿæˆä¸­çš„éç­‰åŒæ‰©æ•£æ¨¡å‹",
      "authors": [
        "Yuzhi Yang",
        "Omar Alhussein",
        "MÃ©rouane Debbah"
      ],
      "abstract": "We propose a novel diffusion model, termed the non-identical diffusion model, and investigate its application to wireless orthogonal frequency division multiplexing (OFDM) channel generation. Unlike the standard diffusion model that uses a scalar-valued time index to represent the global noise level, we extend this notion to an element-wise time indicator to capture local error variations more accurately. Non-identical diffusion enables us to characterize the reliability of each element (e.g., subcarriers in OFDM) within the noisy input, leading to improved generation results when the initialization is biased. Specifically, we focus on the recovery of wireless multi-input multi-output (MIMO) OFDM channel matrices, where the initial channel estimates exhibit highly uneven reliability across elements due to the pilot scheme. Conventional time embeddings, which assume uniform noise progression, fail to capture such variability across pilot schemes and noise levels. We introduce a matrix that matches the input size to control element-wise noise progression. Following a similar diffusion procedure to existing methods, we show the correctness and effectiveness of the proposed non-identical diffusion scheme both theoretically and numerically. For MIMO-OFDM channel generation, we propose a dimension-wise time embedding strategy. We also develop and evaluate multiple training and generation methods and compare them through numerical experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º non-identical diffusion model çš„æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œå¹¶æ¢è®¨äº†å…¶åœ¨æ— çº¿ MIMO-OFDM ä¿¡é“ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚ä¸åŒäºæ ‡å‡†æ‰©æ•£æ¨¡å‹ä½¿ç”¨æ ‡é‡æ—¶é—´ç´¢å¼•è¡¨ç¤ºå…¨å±€å™ªå£°ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†å…ƒç´ çº§æ—¶é—´æŒ‡ç¤ºå™¨ (element-wise time indicator) ä»¥ç²¾ç¡®æ•æ‰å±€éƒ¨è¯¯å·®å˜åŒ–ã€‚è¿™ç§éä¸€è‡´æ‰©æ•£æœºåˆ¶å…è®¸è¡¨å¾ noisy input ä¸­å„å…ƒç´ ï¼ˆå¦‚ OFDM ä¸­çš„ subcarriersï¼‰çš„å¯é æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†ç”±äº pilot scheme å¯¼è‡´çš„åˆå§‹ä¿¡é“ä¼°è®¡å¯é æ€§ä¸å‡çš„é—®é¢˜ã€‚ç ”ç©¶è€…ä¸ºæ­¤è®¾è®¡äº†ç»´çº§æ—¶é—´åµŒå…¥ç­–ç•¥ (dimension-wise time embedding strategy)ï¼Œå¹¶é€šè¿‡ç†è®ºåˆ†æä¸æ•°å€¼å®éªŒéªŒè¯äº†æ–¹æ¡ˆçš„æ­£ç¡®æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†åç½®åˆå§‹åŒ–æ—¶å…·æœ‰æ›´å¼ºçš„ç”Ÿæˆæ€§èƒ½ï¼Œèƒ½æ›´å¥½åœ°é€‚åº”ä¸åŒå¯¼é¢‘æ–¹æ¡ˆä¸‹çš„æ— çº¿ä¿¡é“çŸ©é˜µæ¢å¤ä»»åŠ¡ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01641v1",
      "published_date": "2025-09-01 17:33:39 UTC",
      "updated_date": "2025-09-01 17:33:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:38.192013+00:00"
    },
    {
      "arxiv_id": "2509.01631v2",
      "title": "Unraveling LLM Jailbreaks Through Safety Knowledge Neurons",
      "title_zh": "é€šè¿‡å®‰å…¨çŸ¥è¯†ç¥ç»å…ƒæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹è¶Šç‹±æœºåˆ¶",
      "authors": [
        "Chongwen Zhao",
        "Yutong Ke",
        "Kaizhu Huang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various applications. Nonetheless, there is a growing concern as some users attempt to exploit these models for malicious purposes, including the synthesis of controlled substances and the propagation of disinformation, a technique known as \"Jailbreak.\" While some studies have achieved defenses against jailbreak attacks by modifying output distributions or detecting harmful content, the exact rationale still remains elusive. In this work, we present a novel neuron-level interpretability method that focuses on the role of safety-related knowledge neurons. Unlike existing approaches, our method projects the model's internal representation into a more consistent and interpretable vocabulary space. We then show that adjusting the activation of safety-related neurons can effectively control the model's behavior with a mean ASR higher than 97%. Building on this insight, we propose SafeTuning, a fine-tuning strategy that reinforces safety-critical neurons to improve model robustness against jailbreaks. SafeTuning consistently reduces attack success rates across multiple LLMs and outperforms all four baseline defenses. These findings offer a new perspective on understanding and defending against jailbreak attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)é¢ä¸´çš„è¶Šç‹±æ”»å‡»(Jailbreak)é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„ç¥ç»å…ƒçº§å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œæ—¨åœ¨è¯†åˆ«å®‰å…¨ç›¸å…³çŸ¥è¯†ç¥ç»å…ƒ(safety-related knowledge neurons)ã€‚é€šè¿‡å°†æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºæŠ•å½±åˆ°ä¸€è‡´ä¸”å¯è§£é‡Šçš„è¯æ±‡ç©ºé—´ï¼Œç ”ç©¶è€…å‘ç°è°ƒæ•´è¿™äº›ç‰¹å®šç¥ç»å…ƒçš„æ¿€æ´»çŠ¶æ€å¯ä»¥æœ‰æ•ˆæ§åˆ¶æ¨¡å‹çš„è¡Œä¸ºï¼Œå…¶å¹³å‡æ”»å‡»æˆåŠŸç‡(ASR)è¶…è¿‡97%ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œç ”ç©¶æå‡ºäº†åä¸ºSafeTuningçš„å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡å¼ºåŒ–å®‰å…¨å…³é”®ç¥ç»å…ƒæ¥æå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSafeTuningåœ¨å¤šä¸ªæ¨¡å‹ä¸Šå‡èƒ½æŒç»­é™ä½æ”»å‡»æˆåŠŸç‡ï¼Œè¡¨ç°ä¼˜äºå››ç§ä¸»æµçš„åŸºçº¿é˜²å¾¡æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£å’Œé˜²å¾¡è¶Šç‹±æ”»å‡»æä¾›äº†ä¸€ä¸ªä»åº•å±‚ç¥ç»å…ƒå‡ºå‘çš„æ–°è§†è§’ï¼Œæœ‰åŠ©äºæ„å»ºæ›´å®‰å…¨çš„å¯ä¿¡äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EACL 2026",
      "pdf_url": "https://arxiv.org/pdf/2509.01631v2",
      "published_date": "2025-09-01 17:17:06 UTC",
      "updated_date": "2026-01-21 03:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:51:53.691314+00:00"
    },
    {
      "arxiv_id": "2509.01624v1",
      "title": "Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling",
      "title_zh": "Q-Schedï¼šé€šè¿‡é‡åŒ–æ„ŸçŸ¥è°ƒåº¦æ‹“å±•å°‘æ­¥æ‰©æ•£æ¨¡å‹çš„è¾¹ç•Œ",
      "authors": [
        "Natalia Frumkin",
        "Diana Marculescu"
      ],
      "abstract": "Text-to-image diffusion models are computationally intensive, often requiring dozens of forward passes through large transformer backbones. For instance, Stable Diffusion XL generates high-quality images with 50 evaluations of a 2.6B-parameter model, an expensive process even for a single batch. Few-step diffusion models reduce this cost to 2-8 denoising steps but still depend on large, uncompressed U-Net or diffusion transformer backbones, which are often too costly for full-precision inference without datacenter GPUs. These requirements also limit existing post-training quantization methods that rely on full-precision calibration. We introduce Q-Sched, a new paradigm for post-training quantization that modifies the diffusion model scheduler rather than model weights. By adjusting the few-step sampling trajectory, Q-Sched achieves full-precision accuracy with a 4x reduction in model size. To learn quantization-aware pre-conditioning coefficients, we propose the JAQ loss, which combines text-image compatibility with an image quality metric for fine-grained optimization. JAQ is reference-free and requires only a handful of calibration prompts, avoiding full-precision inference during calibration. Q-Sched delivers substantial gains: a 15.5% FID improvement over the FP16 4-step Latent Consistency Model and a 16.6% improvement over the FP16 8-step Phased Consistency Model, showing that quantization and few-step distillation are complementary for high-fidelity generation. A large-scale user study with more than 80,000 annotations further confirms Q-Sched's effectiveness on both FLUX.1[schnell] and SDXL-Turbo.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Q-Schedï¼Œä¸€ç§é’ˆå¯¹å°‘æ­¥æ‰©æ•£æ¨¡å‹ (Few-Step Diffusion Models) çš„åé‡åŒ– (Post-Training Quantization) æ–°èŒƒå¼ï¼Œé€šè¿‡ä¿®æ”¹è°ƒåº¦å™¨ (Scheduler) çš„é‡‡æ ·è½¨è¿¹è€Œéæ¨¡å‹æƒé‡ï¼Œåœ¨ç»´æŒå…¨ç²¾åº¦å‡†ç¡®æ€§çš„åŒæ—¶å°†æ¨¡å‹ä½“ç§¯ç¼©å°äº† 4 å€ã€‚ç ”ç©¶å¼•å…¥äº†æ— å‚è€ƒçš„ JAQ æŸå¤±å‡½æ•°ï¼Œé€šè¿‡ç»“åˆæ–‡æœ¬-å›¾åƒå…¼å®¹æ€§ä¸å›¾åƒè´¨é‡æŒ‡æ ‡è¿›è¡Œç»†ç²’åº¦ä¼˜åŒ–ï¼Œæœ‰æ•ˆé¿å…äº†æ ¡å‡†è¿‡ç¨‹ä¸­çš„å…¨ç²¾åº¦æ¨ç†å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼ŒQ-Sched åœ¨ FID æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äº 4 æ­¥ Latent Consistency Model (LCM) å’Œ 8 æ­¥ Phased Consistency Model (PCM)ï¼Œåˆ†åˆ«æå‡äº† 15.5% å’Œ 16.6%ã€‚é€šè¿‡å¯¹ FLUX.1[schnell] å’Œ SDXL-Turbo è¿›è¡Œçš„è¶… 80,000 é¡¹æ ‡æ³¨çš„å¤§è§„æ¨¡ç”¨æˆ·ç ”ç©¶ï¼Œè¯å®äº†é‡åŒ–ä¸å°‘æ­¥è’¸é¦æŠ€æœ¯åœ¨å®ç°é«˜ä¿çœŸå›¾åƒç”Ÿæˆæ–¹é¢çš„äº’è¡¥æ€§ã€‚è¯¥æ–¹æ¡ˆä¸ºåœ¨éæ•°æ®ä¸­å¿ƒ GPU ä¸Šéƒ¨ç½²é«˜æ€§èƒ½æ‰©æ•£æ¨¡å‹æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01624v1",
      "published_date": "2025-09-01 17:09:22 UTC",
      "updated_date": "2025-09-01 17:09:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:14.964778+00:00"
    },
    {
      "arxiv_id": "2509.01620v1",
      "title": "Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„ç°ä»£æ±‰è¯­è¯—æ­Œæ£€æµ‹åŸºå‡†",
      "authors": [
        "Shanshan Wang",
        "Junchao Wu",
        "Fengying Ye",
        "Jingming Yao",
        "Lidia S. Chao",
        "Derek F. Wong"
      ],
      "abstract": "The rapid development of advanced large language models (LLMs) has made AI-generated text indistinguishable from human-written text. Previous work on detecting AI-generated text has made effective progress, but has not involved modern Chinese poetry. Due to the distinctive characteristics of modern Chinese poetry, it is difficult to identify whether a poem originated from humans or AI. The proliferation of AI-generated modern Chinese poetry has significantly disrupted the poetry ecosystem. Based on the urgency of identifying AI-generated poetry in the real Chinese world, this paper proposes a novel benchmark for detecting LLMs-generated modern Chinese poetry. We first construct a high-quality dataset, which includes both 800 poems written by six professional poets and 41,600 poems generated by four mainstream LLMs. Subsequently, we conduct systematic performance assessments of six detectors on this dataset. Experimental results demonstrate that current detectors cannot be used as reliable tools to detect modern Chinese poems generated by LLMs. The most difficult poetic features to detect are intrinsic qualities, especially style. The detection results verify the effectiveness and necessity of our proposed benchmark. Our work lays a foundation for future detection of AI-generated poetry.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„ç°ä»£ä¸­æ–‡è¯—æ­Œéš¾ä»¥è¯†åˆ«å¹¶å¹²æ‰°è¯—æ­Œç”Ÿæ€çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå…¨æ–°çš„è¯„ä¼°åŸºå‡†ï¼ˆbenchmarkï¼‰ã€‚è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œç”±äºç°ä»£ä¸­æ–‡è¯—æ­Œå…·å¤‡ç‹¬ç‰¹çš„è‰ºæœ¯ç‰¹å¾ï¼Œç°æœ‰çš„AIæ–‡æœ¬æ£€æµ‹æŠ€æœ¯åœ¨è¿™ä¸€ç‰¹å®šé¢†åŸŸä»é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡æ•°æ®é›†ï¼Œæ¶µç›–äº†6ä½ä¸“ä¸šè¯—äººçš„800é¦–ä½œå“ä»¥åŠç”±4ä¸ªä¸»æµLLMsç”Ÿæˆçš„41,600é¦–è¯—æ­Œï¼Œå¹¶å¯¹6ç§æ£€æµ‹å™¨è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰çš„æ£€æµ‹å·¥å…·å°šæ— æ³•å¯é åœ°è¯†åˆ«LLMsç”Ÿæˆçš„ç°ä»£ä¸­æ–‡è¯—æ­Œï¼Œå…¶ä¸­æœ€éš¾è¢«æ•è·çš„ç‰¹å¾æ˜¯è¯—æ­Œçš„å†…åœ¨å“è´¨ï¼Œå°¤å…¶æ˜¯é£æ ¼ï¼ˆstyleï¼‰ã€‚è¯¥å·¥ä½œçš„å¼€å±•éªŒè¯äº†æ‰€æåŸºå‡†ï¼ˆbenchmarkï¼‰çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥AIç”Ÿæˆè¯—æ­Œçš„æ£€æµ‹ç ”ç©¶å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01620v1",
      "published_date": "2025-09-01 17:01:45 UTC",
      "updated_date": "2025-09-01 17:01:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:23.955495+00:00"
    },
    {
      "arxiv_id": "2509.01619v1",
      "title": "Throttling Web Agents Using Reasoning Gates",
      "title_zh": "åˆ©ç”¨æ¨ç†é—¨å¯¹ Web æ™ºèƒ½ä½“è¿›è¡ŒèŠ‚æµ",
      "authors": [
        "Abhinav Kumar",
        "Jaechul Roh",
        "Ali Naseh",
        "Amir Houmansadr",
        "Eugene Bagdasarian"
      ],
      "abstract": "AI web agents use Internet resources at far greater speed, scale, and complexity -- changing how users and services interact. Deployed maliciously or erroneously, these agents could overload content providers. At the same time, web agents can bypass CAPTCHAs and other defenses by mimicking user behavior or flood authentication systems with fake accounts. Yet providers must protect their services and content from denial-of-service attacks and scraping by web agents. In this paper, we design a framework that imposes tunable costs on agents before providing access to resources; we call this Web Agent Throttling. We start by formalizing Throttling Gates as challenges issued to an agent that are asymmetric, scalable, robust, and compatible with any agent. Focusing on a common component -- the language model -- we require the agent to solve reasoning puzzles, thereby incurring excessive token-generation costs. However, we find that using existing puzzles, e.g., coding or math, as throttling gates fails to satisfy our properties. To address this, we introduce rebus-based Reasoning Gates, synthetic text puzzles that require multi-hop reasoning over world knowledge (thereby throttling an agent's model). We design a scalable generation and verification protocol for such reasoning gates. Our framework achieves computational asymmetry, i.e., the response-generation cost is 9.2x higher than the generation cost for SOTA models. We further deploy reasoning gates on a custom website and Model Context Protocol (MCP) servers and evaluate with real-world web agents. Finally, we discuss the limitations and environmental impact of real-world deployment of our framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Web Agent Throttling æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ AI æ™ºèƒ½ä½“ï¼ˆWeb Agentsï¼‰å› é«˜é€Ÿä¸”å¤æ‚çš„èµ„æºåˆ©ç”¨è€Œç»™å†…å®¹æä¾›å•†å¸¦æ¥çš„æ‹’ç»æœåŠ¡æ”»å‡»ï¼ˆDoSï¼‰å’Œæ¶æ„çˆ¬å–é£é™©ã€‚è®ºæ–‡é€šè¿‡å®šä¹‰ Throttling Gatesï¼Œå‘æ™ºèƒ½ä½“å‘å¸ƒéå¯¹ç§°ã€å¯æ‰©å±•ä¸”é²æ£’çš„æŒ‘æˆ˜ï¼Œè¿«ä½¿æ™ºèƒ½ä½“åœ¨è®¿é—®èµ„æºå‰æ‰¿æ‹…å¯è°ƒæ§çš„è®¡ç®—æˆæœ¬ã€‚é’ˆå¯¹ç°æœ‰æ•°å­¦æˆ–ä»£ç è°œé¢˜åœ¨é˜²å¾¡ä¸­çš„å±€é™æ€§ï¼Œç ”ç©¶è€…å¼•å…¥äº†åŸºäºç”»è°œï¼ˆrebusï¼‰çš„ Reasoning Gatesï¼Œåˆ©ç”¨éœ€è¦è·¨è¶Šä¸–ç•ŒçŸ¥è¯†è¿›è¡Œå¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰çš„åˆæˆæ–‡æœ¬è°œé¢˜æ¥å¤§å¹…å¢åŠ æ™ºèƒ½ä½“æ¨¡å‹çš„ Token ç”Ÿæˆæˆæœ¬ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ SOTA æ¨¡å‹ä¸Šå®ç°äº†æ˜¾è‘—çš„è®¡ç®—éå¯¹ç§°æ€§ï¼Œå…¶å“åº”ç”Ÿæˆæˆæœ¬æ¯”æŒ‘æˆ˜ç”Ÿæˆæˆæœ¬é«˜å‡º 9.2 å€ã€‚è¯¥æ–¹æ¡ˆåœ¨è‡ªå®šä¹‰ç½‘ç«™å’Œ Model Context Protocolï¼ˆMCPï¼‰æœåŠ¡å™¨ä¸Šçš„å®é™…éƒ¨ç½²éªŒè¯äº†å…¶å¯¹ç°å®ä¸–ç•Œ Web æ™ºèƒ½ä½“çš„è°ƒèŠ‚èƒ½åŠ›ï¼Œä¸ºä¿æŠ¤äº’è”ç½‘èµ„æºå…å—è‡ªåŠ¨åŒ–æ»¥ç”¨æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01619v1",
      "published_date": "2025-09-01 16:56:16 UTC",
      "updated_date": "2025-09-01 16:56:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:17.384237+00:00"
    },
    {
      "arxiv_id": "2509.01617v1",
      "title": "Disentangling the schema turn: Restoring the information base to conceptual modelling",
      "title_zh": "è§£æ„æ¨¡å¼è½¬å‘ï¼šæ¨åŠ¨æ¦‚å¿µå»ºæ¨¡å›å½’ä¿¡æ¯åŸºç¡€",
      "authors": [
        "Chris Partridge",
        "Andrew Mitchell",
        "Sergio de Cesare",
        "Oscar Xiberta Soto"
      ],
      "abstract": "If one looks at contemporary mainstream development practices for conceptual modelling in computer science, these so clearly focus on a conceptual schema completely separated from its information base that the conceptual schema is often just called the conceptual model. These schema-centric practices are crystallized in almost every database textbook. We call this strong, almost universal, bias towards conceptual schemas the schema turn. The focus of this paper is on disentangling this turn within (computer science) conceptual modeling. It aims to shed some light on how it emerged and so show that it is not fundamental. To show that modern technology enables the adoption of an inclusive schema-and-base conceptual modelling approach, which in turn enables more automated, and empirically motivated practices. And to show, more generally, the space of possible conceptual modelling practices is wider than currently assumed. It also uses the example of bCLEARer to show that the implementations in this wider space will probably need to rely on new pipeline-based conceptual modelling techniques. So, it is possible that the schema turn's complete exclusion of the information base could be merely a temporary evolutionary detour.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è®¡ç®—æœºç§‘å­¦ conceptual modelling é¢†åŸŸä¸­è¿‡åº¦å…³æ³¨ conceptual schema è€Œå¿½è§† information base çš„ç°çŠ¶ï¼Œå¹¶å°†è¿™ä¸€ç°è±¡å®šä¹‰ä¸º schema turnã€‚æ–‡ç« æ—¨åœ¨è§£æè¿™ä¸€è¶‹åŠ¿çš„æˆå› ï¼ŒæŒ‡å‡ºå…¶å¹¶éåŸºç¡€æ€§é™åˆ¶ï¼Œå¹¶è®ºè¯äº†ç°ä»£æŠ€æœ¯èƒ½å¤Ÿæ”¯æŒå°†æ¨¡å¼ä¸ä¿¡æ¯åº“èåˆçš„ inclusive schema-and-base å»ºæ¨¡æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿä¿ƒè¿›æ›´å…·è‡ªåŠ¨åŒ–ç‰¹å¾å’Œç»éªŒå¯¼å‘çš„å»ºæ¨¡å®è·µï¼Œä»è€Œæ‹“å®½ conceptual modelling çš„åº”ç”¨ç©ºé—´ã€‚é€šè¿‡ bCLEARer è¿™ä¸€æ¡ˆä¾‹ï¼Œä½œè€…å±•ç¤ºäº†åŸºäº pipeline-based çš„æ–°æŠ€æœ¯åœ¨å®ç°è¿™ä¸€ç›®æ ‡ä¸­çš„å…³é”®ä½œç”¨ã€‚ç ”ç©¶æœ€ç»ˆæå‡ºï¼Œå°†ä¿¡æ¯åº“æ’é™¤åœ¨å¤–çš„ schema turn å¯èƒ½ä»…æ˜¯è¯¥é¢†åŸŸå‘å±•è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªæš‚æ—¶æ€§åç¦»ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "Fundamentals of Conceptual Modeling - ER2025 Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.01617v1",
      "published_date": "2025-09-01 16:55:34 UTC",
      "updated_date": "2025-09-01 16:55:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:17.052622+00:00"
    },
    {
      "arxiv_id": "2509.01613v1",
      "title": "Entropy-Driven Curriculum for Multi-Task Training in Human Mobility Prediction",
      "title_zh": "äººç±»ç§»åŠ¨æ€§é¢„æµ‹å¤šä»»åŠ¡è®­ç»ƒä¸­çš„ç†µé©±åŠ¨è¯¾ç¨‹å­¦ä¹ ",
      "authors": [
        "Tianye Fang",
        "Xuanshu Luo",
        "Martin Werner"
      ],
      "abstract": "The increasing availability of big mobility data from ubiquitous portable devices enables human mobility prediction through deep learning approaches. However, the diverse complexity of human mobility data impedes model training, leading to inefficient gradient updates and potential underfitting. Meanwhile, exclusively predicting next locations neglects implicit determinants, including distances and directions, thereby yielding suboptimal prediction results. This paper presents a unified training framework that integrates entropy-driven curriculum and multi-task learning to address these challenges. The proposed entropy-driven curriculum learning strategy quantifies trajectory predictability based on Lempel-Ziv compression and organizes training from simple to complex for faster convergence and enhanced performance. The multi-task training simultaneously optimizes the primary location prediction alongside auxiliary estimation of movement distance and direction for learning realistic mobility patterns, and improve prediction accuracy through complementary supervision signals. Extensive experiments conducted in accordance with the HuMob Challenge demonstrate that our approach achieves state-of-the-art performance on GEO-BLEU (0.354) and DTW (26.15) metrics with up to 2.92-fold convergence speed compared to training without curriculum learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆ Entropy-driven curriculum (ç†µé©±åŠ¨è¯¾ç¨‹å­¦ä¹ ) å’Œ Multi-task learning (å¤šä»»åŠ¡å­¦ä¹ ) æ¥è§£å†³äººç±»ç§»åŠ¨é¢„æµ‹ä¸­çš„è½¨è¿¹å¤æ‚æ€§å’Œéšæ€§å› ç´ å¿½ç•¥é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†åŸºäº Lempel-Ziv å‹ç¼©çš„ç­–ç•¥æ¥é‡åŒ–è½¨è¿¹çš„å¯é¢„æµ‹æ€§ï¼Œå¹¶æŒ‰ç…§ä»ç®€å•åˆ°å¤æ‚çš„é¡ºåºç»„ç»‡è®­ç»ƒï¼Œä»¥å®ç°æ›´å¿«çš„æ”¶æ•›ã€‚åœ¨å¤šä»»åŠ¡è®­ç»ƒæ–¹é¢ï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹ä¸‹ä¸€ä½ç½®çš„åŒæ—¶ï¼Œé€šè¿‡å¯¹ç§»åŠ¨è·ç¦»å’Œæ–¹å‘çš„è¾…åŠ©ä¼°è®¡æä¾›è¡¥å……ç›‘ç£ä¿¡å·ï¼Œä»è€Œæ•è·æ›´çœŸå®çš„ç§»åŠ¨æ¨¡å¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ HuMob Challenge ä¸­å–å¾—äº† state-of-the-art æ€§èƒ½ï¼Œå…¶ GEO-BLEU è¾¾åˆ° 0.354ï¼ŒDTW ä¸º 26.15ã€‚ä¸ä¸ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ çš„è®­ç»ƒç›¸æ¯”ï¼Œè¯¥æ–¹æ³•çš„æ”¶æ•›é€Ÿåº¦æå‡äº† 2.92 å€ï¼Œè¯æ˜äº†å…¶åœ¨æé«˜äººç±»ç§»åŠ¨é¢„æµ‹å‡†ç¡®æ€§å’Œè®­ç»ƒæ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01613v1",
      "published_date": "2025-09-01 16:46:21 UTC",
      "updated_date": "2025-09-01 16:46:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:19.351245+00:00"
    },
    {
      "arxiv_id": "2509.05340v1",
      "title": "Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging",
      "title_zh": "ç£å…±æŒ¯æˆåƒä¸­è„‘è‚¿ç˜¤ç²¾å‡†åˆ†å‰²çš„ç¡¬èšç±»ä¸è½¯èšç±»å¯¹æ¯”è¯„ä»·",
      "authors": [
        "Dibya Jyoti Bora",
        "Mrinal Kanti Mishra"
      ],
      "abstract": "Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a pivotal challenge in medical image analysis due to the heterogeneous nature of tumor morphology and intensity distributions. Accurate delineation of tumor boundaries is critical for clinical decision-making, radiotherapy planning, and longitudinal disease monitoring. In this study, we perform a comprehensive comparative analysis of two major clustering paradigms applied in MRI tumor segmentation: hard clustering, exemplified by the K-Means algorithm, and soft clustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each pixel strictly to a single cluster, FCM introduces partial memberships, meaning each pixel can belong to multiple clusters with varying degrees of association. Experimental validation was performed using the BraTS2020 dataset, incorporating pre-processing through Gaussian filtering and Contrast Limited Adaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice Similarity Coefficient (DSC) and processing time, which collectively demonstrated that K-Means achieved superior speed with an average runtime of 0.3s per image, whereas FCM attained higher segmentation accuracy with an average DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher computational cost (1.3s per image). These results highlight the inherent trade-off between computational efficiency and boundary precision.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ ¸ç£å…±æŒ¯æˆåƒ(MRI)ä¸­è„‘è‚¿ç˜¤åˆ†å‰²é¢ä¸´çš„å½¢æ€å¼‚è´¨æ€§å’Œå¼ºåº¦åˆ†å¸ƒæŒ‘æˆ˜ï¼Œå¯¹ç¡¬èšç±»(Hard Clustering)å’Œè½¯èšç±»(Soft Clustering)ä¸¤ç§èŒƒå¼è¿›è¡Œäº†æ·±å…¥å¯¹æ¯”è¯„ä¼°ã€‚ç ”ç©¶åˆ†åˆ«ä»¥K-Meanså’ŒFuzzy C-Means (FCM)ä½œä¸ºä¸¤ç§èŒƒå¼çš„ä»£è¡¨ï¼Œå¹¶åœ¨BraTS2020æ•°æ®é›†ä¸Šç»“åˆGaussian filteringå’ŒCLAHEé¢„å¤„ç†æŠ€æœ¯è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒK-Meansåœ¨å¤„ç†é€Ÿåº¦ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå•å¼ å›¾åƒå¹³å‡ç”¨æ—¶ä»…0.3ç§’ï¼Œä½†å…¶Dice Similarity Coefficient (DSC)ä»…ä¸º0.43ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒFCMé€šè¿‡å¼•å…¥éƒ¨åˆ†éš¶å±åº¦æœºåˆ¶å®ç°äº†æ›´é«˜çš„åˆ†å‰²ç²¾åº¦ï¼Œå¹³å‡DSCè¾¾åˆ°0.67ï¼Œä½†è®¡ç®—æˆæœ¬ç›¸å¯¹è¾ƒé«˜ï¼Œå•å¼ å›¾åƒè€—æ—¶1.3ç§’ã€‚è¯¥é¡¹ç ”ç©¶é‡åŒ–äº†è®¡ç®—æ•ˆç‡ä¸è¾¹ç•Œç²¾åº¦ä¹‹é—´çš„å›ºæœ‰æƒè¡¡ï¼Œä¸ºåŒ»å­¦å›¾åƒåˆ†æä¸­èšç±»ç®—æ³•çš„é€‰æ‹©æä¾›äº†é‡è¦çš„å®éªŒä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.05340v1",
      "published_date": "2025-09-01 16:40:08 UTC",
      "updated_date": "2025-09-01 16:40:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:27.588217+00:00"
    },
    {
      "arxiv_id": "2509.01605v1",
      "title": "TransForSeg: A Multitask Stereo ViT for Joint Stereo Segmentation and 3D Force Estimation in Catheterization",
      "title_zh": "TransForSegï¼šç”¨äºå¯¼ç®¡ä»‹å…¥ä¸­è”åˆç«‹ä½“åˆ†å‰²ä¸ä¸‰ç»´åŠ›ä¼°è®¡çš„å¤šä»»åŠ¡ç«‹ä½“ ViT",
      "authors": [
        "Pedram Fekri",
        "Mehrdad Zadeh",
        "Javad Dargahi"
      ],
      "abstract": "Recently, the emergence of multitask deep learning models has enhanced catheterization procedures by providing tactile and visual perception data through an end-to-end architecture. This information is derived from a segmentation and force estimation head, which localizes the catheter in X-ray images and estimates the applied pressure based on its deflection within the image. These stereo vision architectures incorporate a CNN-based encoder-decoder that captures the dependencies between X-ray images from two viewpoints, enabling simultaneous 3D force estimation and stereo segmentation of the catheter. With these tasks in mind, this work approaches the problem from a new perspective. We propose a novel encoder-decoder Vision Transformer model that processes two input X-ray images as separate sequences. Given sequences of X-ray patches from two perspectives, the transformer captures long-range dependencies without the need to gradually expand the receptive field for either image. The embeddings generated by both the encoder and decoder are fed into two shared segmentation heads, while a regression head employs the fused information from the decoder for 3D force estimation. The proposed model is a stereo Vision Transformer capable of simultaneously segmenting the catheter from two angles while estimating the generated forces at its tip in 3D. This model has undergone extensive experiments on synthetic X-ray images with various noise levels and has been compared against state-of-the-art pure segmentation models, vision-based catheter force estimation methods, and a multitask catheter segmentation and force estimation approach. It outperforms existing models, setting a new state-of-the-art in both catheter segmentation and force estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TransForSegï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¤šä»»åŠ¡ç«‹ä½“ Vision Transformer (ViT) æ¨¡å‹ï¼Œæ—¨åœ¨åŒæ—¶å®ç°å¯¼ç®¡ä»‹å…¥æ‰‹æœ¯ä¸­çš„å¯¼ç®¡åˆ†å‰²ä¸ 3D åŠ›ä¼°è®¡ (3D Force Estimation)ã€‚ä¸ä¼ ç»Ÿçš„åŸºäº CNN çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ä¸åŒï¼Œè¯¥æ¨¡å‹é€šè¿‡å°†æ¥è‡ªä¸¤ä¸ªè§†è§’çš„ X-ray å›¾åƒå¤„ç†ä¸ºç‹¬ç«‹åºåˆ—ï¼Œåˆ©ç”¨ Transformer æ¶æ„æœ‰æ•ˆæ•è·é•¿ç¨‹ä¾èµ–å…³ç³» (long-range dependencies)ï¼Œæ— éœ€åƒå·ç§¯ç½‘ç»œé‚£æ ·é€æ¸æ‰©å¤§æ„Ÿå—é‡ã€‚TransForSeg çš„ç¼–ç å™¨å’Œè§£ç å™¨ç”Ÿæˆçš„åµŒå…¥ (embeddings) è¢«é€å…¥ä¸¤ä¸ªå…±äº«çš„åˆ†å‰²å¤´è¿›è¡Œå›¾åƒå¤„ç†ï¼ŒåŒæ—¶å›å½’å¤´åˆ©ç”¨è§£ç å™¨çš„èåˆä¿¡æ¯æ¥ç²¾ç¡®é¢„æµ‹å¯¼ç®¡æœ«ç«¯çš„ 3D å‹åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä¸åŒå™ªå£°æ°´å¹³çš„åˆæˆ X-ray å›¾åƒä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œå¹¶å°†å…¶ä¸çº¯åˆ†å‰²æ¨¡å‹åŠå¤šä»»åŠ¡åŸºå‡†æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTransForSeg åœ¨å¯¼ç®¡åˆ†å‰²å’ŒåŠ›ä¼°è®¡ä¸¤é¡¹ä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œåˆ·æ–°äº†è¯¥é¢†åŸŸçš„å…ˆè¿›æ°´å¹³ (state-of-the-art)ï¼Œä¸ºä»‹å…¥æ”¾å°„å­¦ä¸­çš„è§†è§‰ä¸è§¦è§‰æ„ŸçŸ¥å¢å¼ºæä¾›äº†é«˜æ•ˆçš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint version. This work is intended for future journal submission",
      "pdf_url": "https://arxiv.org/pdf/2509.01605v1",
      "published_date": "2025-09-01 16:36:23 UTC",
      "updated_date": "2025-09-01 16:36:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:32.758397+00:00"
    },
    {
      "arxiv_id": "2509.01599v1",
      "title": "An Efficient Intrusion Detection System for Safeguarding Radiation Detection Systems",
      "title_zh": "é¢å‘è¾å°„æ¢æµ‹ç³»ç»Ÿå®‰å…¨ä¿éšœçš„é«˜æ•ˆå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Nathanael Coolidge",
        "Jaime GonzÃ¡lez Sanz",
        "Li Yang",
        "Khalil El Khatib",
        "Glenn Harvel",
        "Nelson Agbemava",
        "I Putu Susila",
        "Mehmet Yavuz Yagci"
      ],
      "abstract": "Radiation Detection Systems (RDSs) are used to measure and detect abnormal levels of radioactive material in the environment. These systems are used in many applications to mitigate threats posed by high levels of radioactive material. However, these systems lack protection against malicious external attacks to modify the data. The novelty of applying Intrusion Detection Systems (IDS) in RDSs is a crucial element in safeguarding these critical infrastructures. While IDSs are widely used in networking environments to safeguard against various attacks, their application in RDSs is novel. A common attack on RDSs is Denial of Service (DoS), where the attacker aims to overwhelm the system, causing malfunctioning RDSs. This paper proposes an efficient Machine Learning (ML)-based IDS to detect anomalies in radiation data, focusing on DoS attacks. This work explores the use of sampling methods to create a simulated DoS attack based on a real radiation dataset, followed by an evaluation of various ML algorithms, including Random Forest, Support Vector Machine (SVM), logistic regression, and Light Gradient-Boosting Machine (LightGBM), to detect DoS attacks on RDSs. LightGBM is emphasized for its superior accuracy and low computational resource consumption, making it particularly suitable for real-time intrusion detection. Additionally, model optimization and TinyML techniques, including feature selection, parallel execution, and random search methods, are used to improve the efficiency of the proposed IDS. Finally, an optimized and efficient LightGBM-based IDS is developed to achieve accurate intrusion detection for RDSs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¾å°„ç›‘æµ‹ç³»ç»Ÿ(Radiation Detection Systems, RDSs)åœ¨é¢å¯¹å¤–éƒ¨æ¶æ„æ”»å‡»ï¼ˆç‰¹åˆ«æ˜¯Denial of Service, DoSæ”»å‡»ï¼‰æ—¶ç¼ºä¹æœ‰æ•ˆé˜²æŠ¤çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæœºå™¨å­¦ä¹ (Machine Learning, ML)çš„é«˜æ•ˆå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(Intrusion Detection System, IDS)ã€‚é€šè¿‡ä½¿ç”¨çœŸå®è¾å°„æ•°æ®é›†æ¨¡æ‹ŸDoSæ”»å‡»åœºæ™¯ï¼Œç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°è¯„ä¼°äº†Random Forestã€Support Vector Machine (SVM)ã€Logistic Regressionä»¥åŠLight Gradient-Boosting Machine (LightGBM)ç­‰å¤šç§ç®—æ³•ã€‚å®éªŒç»“æœå¼ºè°ƒäº†LightGBMåœ¨å‡†ç¡®ç‡å’Œä½è®¡ç®—èµ„æºæ¶ˆè€—æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä½¿å…¶ç‰¹åˆ«é€‚ç”¨äºå®æ—¶å…¥ä¾µæ£€æµ‹ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œç»“åˆäº†ç‰¹å¾é€‰æ‹©ã€å¹¶è¡Œæ‰§è¡Œã€éšæœºæœç´¢å’ŒTinyMLç­‰æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æå‡äº†æ£€æµ‹ç³»ç»Ÿçš„è¿è¡Œæ•ˆç‡ã€‚æœ€ç»ˆæ„å»ºçš„LightGBM-based IDSå®ç°äº†å¯¹RDSsçš„ç²¾ç¡®ç›‘æ§ï¼Œä¸ºä¿éšœæ­¤ç±»å…³é”®åŸºç¡€è®¾æ–½çš„å®‰å…¨æä¾›äº†å¯é çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint author original pre review. Accepted and Presented at ISOFIC 2024. The official proceedings version is available on the conference site",
      "pdf_url": "https://arxiv.org/pdf/2509.01599v1",
      "published_date": "2025-09-01 16:31:46 UTC",
      "updated_date": "2025-09-01 16:31:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:43.663317+00:00"
    },
    {
      "arxiv_id": "2509.01596v1",
      "title": "O-DisCo-Edit: Object Distortion Control for Unified Realistic Video Editing",
      "title_zh": "O-DisCo-Editï¼šé¢å‘ç»Ÿä¸€çœŸå®æ„Ÿè§†é¢‘ç¼–è¾‘çš„ç›®æ ‡å½¢å˜æ§åˆ¶",
      "authors": [
        "Yuqing Chen",
        "Junjie Wang",
        "Lin Liu",
        "Ruihang Chu",
        "Xiaopeng Zhang",
        "Qi Tian",
        "Yujiu Yang"
      ],
      "abstract": "Diffusion models have recently advanced video editing, yet controllable editing remains challenging due to the need for precise manipulation of diverse object properties. Current methods require different control signal for diverse editing tasks, which complicates model design and demands significant training resources. To address this, we propose O-DisCo-Edit, a unified framework that incorporates a novel object distortion control (O-DisCo). This signal, based on random and adaptive noise, flexibly encapsulates a wide range of editing cues within a single representation. Paired with a \"copy-form\" preservation module for preserving non-edited regions, O-DisCo-Edit enables efficient, high-fidelity editing through an effective training paradigm. Extensive experiments and comprehensive human evaluations consistently demonstrate that O-DisCo-Edit surpasses both specialized and multitask state-of-the-art methods across various video editing tasks. https://cyqii.github.io/O-DisCo-Edit.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†O-DisCo-Editï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³è§†é¢‘ç¼–è¾‘(Video Editing)ä¸­å¯æ§æ€§æŒ‘æˆ˜çš„ç»Ÿä¸€æ¡†æ¶ã€‚å½“å‰æ–¹æ³•å¾€å¾€éœ€è¦é’ˆå¯¹ä¸åŒç¼–è¾‘ä»»åŠ¡ä½¿ç”¨å¤šæ ·çš„æ§åˆ¶ä¿¡å·ï¼Œå¯¼è‡´æ¨¡å‹è®¾è®¡å¤æ‚ä¸”è€—è´¹å¤§é‡è®­ç»ƒèµ„æºã€‚O-DisCo-Edité€šè¿‡å¼•å…¥ä¸€ç§æ–°é¢–çš„å¯¹è±¡å¤±çœŸæ§åˆ¶(Object Distortion Control, O-DisCo)ä¿¡å·ï¼Œåˆ©ç”¨éšæœºå’Œè‡ªé€‚åº”å™ªå£°å°†å¤šç§ç¼–è¾‘çº¿ç´¢æ•´åˆè¿›å•ä¸€è¡¨ç¤ºä¸­ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶åŒ…å«äº†ä¸€ä¸ª\"copy-form\" preservationæ¨¡å—ï¼Œç”¨äºç²¾ç¡®ä¿ç•™è§†é¢‘ä¸­çš„éç¼–è¾‘åŒºåŸŸã€‚è¿™ç§ç»Ÿä¸€çš„æ¶æ„é…åˆæœ‰æ•ˆçš„è®­ç»ƒèŒƒå¼ï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜ä¿çœŸåº¦çš„è§†é¢‘ç¼–è¾‘ã€‚å¤§é‡å®éªŒå’Œäººå·¥è¯„ä¼°ä¸€è‡´è¯æ˜ï¼ŒO-DisCo-Editåœ¨å„ç±»è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­å‡è¶…è¶Šäº†ç°æœ‰çš„ä¸“ç”¨å‹åŠå¤šä»»åŠ¡å‹æœ€å…ˆè¿›(State-of-the-art)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01596v1",
      "published_date": "2025-09-01 16:29:39 UTC",
      "updated_date": "2025-09-01 16:29:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:56.661016+00:00"
    },
    {
      "arxiv_id": "2509.01592v1",
      "title": "Securing Radiation Detection Systems with an Efficient TinyML-Based IDS for Edge Devices",
      "title_zh": "åˆ©ç”¨é«˜æ•ˆ TinyML å…¥ä¾µæ£€æµ‹ç³»ç»Ÿä¿éšœè¾¹ç¼˜è®¾å¤‡è¾å°„æ¢æµ‹ç³»ç»Ÿçš„å®‰å…¨",
      "authors": [
        "Einstein Rivas Pizarro",
        "Wajiha Zaheer",
        "Li Yang",
        "Khalil El-Khatib",
        "Glenn Harvel"
      ],
      "abstract": "Radiation Detection Systems (RDSs) play a vital role in ensuring public safety across various settings, from nuclear facilities to medical environments. However, these systems are increasingly vulnerable to cyber-attacks such as data injection, man-in-the-middle (MITM) attacks, ICMP floods, botnet attacks, privilege escalation, and distributed denial-of-service (DDoS) attacks. Such threats could compromise the integrity and reliability of radiation measurements, posing significant public health and safety risks. This paper presents a new synthetic radiation dataset and an Intrusion Detection System (IDS) tailored for resource-constrained environments, bringing Machine Learning (ML) predictive capabilities closer to the sensing edge layer of critical infrastructure. Leveraging TinyML techniques, the proposed IDS employs an optimized XGBoost model enhanced with pruning, quantization, feature selection, and sampling. These TinyML techniques significantly reduce the size of the model and computational demands, enabling real-time intrusion detection on low-resource devices while maintaining a reasonable balance between efficiency and accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¾å°„æ¢æµ‹ç³»ç»Ÿ (RDSs) é¢ä¸´çš„æ•°æ®æ³¨å…¥ã€ä¸­é—´äººæ”»å‡» (MITM) åŠåˆ†å¸ƒå¼æ‹’ç»æœåŠ¡ (DDoS) ç­‰æ—¥ç›Šä¸¥å³»çš„ç½‘ç»œå®‰å…¨å¨èƒï¼Œæå‡ºäº†ä¸€ä¸ªä¸“ä¸ºèµ„æºå—é™ç¯å¢ƒè®¾è®¡çš„è½»é‡åŒ–å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (IDS)ã€‚ç ”ç©¶äººå‘˜é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå…¨æ–°çš„åˆæˆè¾å°„æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨ TinyML æŠ€æœ¯å¼€å‘äº†ä¸€ä¸ªç»è¿‡é«˜åº¦ä¼˜åŒ–çš„ XGBoost æ¨¡å‹ã€‚é€šè¿‡åº”ç”¨å‰ªæ (pruning)ã€é‡åŒ– (quantization)ã€ç‰¹å¾é€‰æ‹© (feature selection) å’Œé‡‡æ · (sampling) ç­‰ä¼˜åŒ–æ‰‹æ®µï¼Œè¯¥æ¨¡å‹åœ¨æ˜¾è‘—é™ä½è®¡ç®—éœ€æ±‚å’Œå­˜å‚¨ç©ºé—´çš„åŒæ—¶ï¼Œç¡®ä¿äº†åœ¨ä½åŠŸè€—è®¾å¤‡ä¸Šçš„å®æ—¶è¿è¡Œèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨æ£€æµ‹æ•ˆç‡ä¸å‡†ç¡®ç‡ä¹‹é—´è¾¾æˆäº†ç†æƒ³å¹³è¡¡ï¼ŒæˆåŠŸå°†æœºå™¨å­¦ä¹  (ML) çš„é¢„æµ‹èƒ½åŠ›å»¶ä¼¸è‡³å…³é”®åŸºç¡€è®¾æ–½çš„æ„ŸçŸ¥è¾¹ç¼˜å±‚ã€‚è¯¥é¡¹å·¥ä½œä¸ºä¿éšœè¾å°„æµ‹é‡æ•°æ®çš„å®Œæ•´æ€§ä¸å¯é æ€§æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint author original pre review. Accepted and Presented at NPIC & HMIT 2025. The official proceedings version is available in the ANS Digital Library",
      "pdf_url": "https://arxiv.org/pdf/2509.01592v1",
      "published_date": "2025-09-01 16:26:37 UTC",
      "updated_date": "2025-09-01 16:26:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:52:52.560973+00:00"
    },
    {
      "arxiv_id": "2509.01588v1",
      "title": "From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation",
      "title_zh": "ä»å¤±è°åˆ°å’Œè°ï¼šåŸºäºåˆ†è§£åå’Œæ€§çš„è®­ç»ƒä»¥æå‡éŸ³é¢‘å’Œå¼¦ä¼°ç®—æ€§èƒ½",
      "authors": [
        "Andrea Poltronieri",
        "Xavier Serra",
        "MartÃ­n Rocamora"
      ],
      "abstract": "Audio Chord Estimation (ACE) holds a pivotal role in music information research, having garnered attention for over two decades due to its relevance for music transcription and analysis. Despite notable advancements, challenges persist in the task, particularly concerning unique characteristics of harmonic content, which have resulted in existing systems' performances reaching a glass ceiling. These challenges include annotator subjectivity, where varying interpretations among annotators lead to inconsistencies, and class imbalance within chord datasets, where certain chord classes are over-represented compared to others, posing difficulties in model training and evaluation. As a first contribution, this paper presents an evaluation of inter-annotator agreement in chord annotations, using metrics that extend beyond traditional binary measures. In addition, we propose a consonance-informed distance metric that reflects the perceptual similarity between harmonic annotations. Our analysis suggests that consonance-based distance metrics more effectively capture musically meaningful agreement between annotations. Expanding on these findings, we introduce a novel ACE conformer-based model that integrates consonance concepts into the model through consonance-based label smoothing. The proposed model also addresses class imbalance by separately estimating root, bass, and all note activations, enabling the reconstruction of chord labels from decomposed outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Audio Chord Estimation (ACE) é¢†åŸŸä¸­å­˜åœ¨çš„æ ‡æ³¨ä¸»è§‚æ€§å’Œç±»åˆ«ä¸å¹³è¡¡(class imbalance)ç­‰ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—åŸºäºåå’ŒéŸ³(consonance)ç†è®ºçš„æ”¹è¿›æ–¹æ¡ˆã€‚ç ”ç©¶é¦–å…ˆè¶…è¶Šäº†ä¼ ç»Ÿçš„äºŒå…ƒåº¦é‡ï¼Œé€šè¿‡ä¸€ç§åæ˜ æ„ŸçŸ¥ç›¸ä¼¼æ€§çš„åå’ŒéŸ³é©±åŠ¨è·ç¦»åº¦é‡æ¥è¯„ä¼°æ ‡æ³¨è€…é—´çš„ä¸€è‡´æ€§(inter-annotator agreement)ï¼Œè¯æ˜è¯¥åº¦é‡èƒ½æ›´æœ‰æ•ˆæ•æ‰å…·æœ‰éŸ³ä¹æ„ä¹‰çš„æ ‡æ³¨å…³è”ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡å¼•å…¥äº†ä¸€ç§åŸºäºConformerçš„æ–°å‹ACEæ¨¡å‹ï¼Œé€šè¿‡åŸºäºåå’ŒéŸ³çš„æ ‡ç­¾å¹³æ»‘(consonance-based label smoothing)æŠ€æœ¯å°†éŸ³ä¹æ„ŸçŸ¥æ¦‚å¿µèå…¥æ¨¡å‹è®­ç»ƒã€‚ä¸ºäº†è¿›ä¸€æ­¥è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨åˆ†è§£ç­–ç•¥ï¼Œåˆ†åˆ«ç‹¬ç«‹ä¼°è®¡æ ¹éŸ³(root)ã€ä½éŸ³(bass)åŠæ‰€æœ‰éŸ³ç¬¦çš„æ¿€æ´»æƒ…å†µï¼Œå¹¶æ®æ­¤é‡å»ºå’Œå¼¦æ ‡ç­¾ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼Œè¿™ç§é›†æˆæ„ŸçŸ¥åº¦é‡ä¸åˆ†è§£è¾“å‡ºçš„æ–¹æ³•æœ‰æ•ˆæå‡äº†æ¨¡å‹å¯¹éŸ³é¢‘å’Œå¼¦ä¼°è®¡çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, 3 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01588v1",
      "published_date": "2025-09-01 16:20:47 UTC",
      "updated_date": "2025-09-01 16:20:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:15.884164+00:00"
    },
    {
      "arxiv_id": "2509.01587v1",
      "title": "One-Shot Clustering for Federated Learning Under Clustering-Agnostic Assumption",
      "title_zh": "èšç±»æ— å…³å‡è®¾ä¸‹çš„è”é‚¦å­¦ä¹ å•æ¬¡èšç±»",
      "authors": [
        "Maciej Krzysztof Zuziak",
        "Roberto Pellungrini",
        "Salvatore Rinzivillo"
      ],
      "abstract": "Federated Learning (FL) is a widespread and well-adopted paradigm of decentralised learning that allows training one model from multiple sources without the need to transfer data between participating clients directly. Since its inception in 2015, it has been divided into numerous subfields that deal with application-specific issues, such as data heterogeneity or resource allocation. One such sub-field, Clustered Federated Learning (CFL), deals with the problem of clustering the population of clients into separate cohorts to deliver personalised models. Although a few remarkable works have been published in this domain, the problem remains largely unexplored, as its basic assumptions and settings differ slightly from those of standard FL. In this work, we present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic algorithm that can automatically detect the earliest suitable moment for clustering. Our algorithm is based on computing the cosine distance between the gradients of the clients and a temperature measure that detects when the federated model starts to converge. We empirically evaluate our methodology by testing various one-shot clustering algorithms for over forty different tasks on five benchmark datasets. Our experiments showcase the good performance of our approach when used to perform CFL in an automated manner without the need to adjust hyperparameters. We also revisit the practical feasibility of CFL algorithms based on the gradients of the clients, providing firm evidence of the high efficiency of density-based clustering methods when used to differentiate between the loss surfaces of neural networks trained on different distributions. Moreover, by inspecting the feasibility of local explanations generated with the help of GradCAM, we can provide more insights into the relationship between personalisation and the explainability of local predictions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èšç±»è”é‚¦å­¦ä¹ (Clustered Federated Learning)ä¸­ä¸ªæ€§åŒ–æ¨¡å‹äº¤ä»˜çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†One-Shot Clustered Federated Learning (OCFL) ç®—æ³•ï¼Œæ—¨åœ¨èšç±»ä¸å¯çŸ¥(clustering-agnostic)çš„å‡è®¾ä¸‹å®ç°è‡ªåŠ¨èšç±»ã€‚OCFL é€šè¿‡è®¡ç®—å®¢æˆ·ç«¯æ¢¯åº¦é—´çš„ä½™å¼¦è·ç¦»(cosine distance)å¹¶ç»“åˆä¸€ç§æ£€æµ‹æ¨¡å‹æ”¶æ•›çš„æ¸©åº¦åº¦é‡ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«æœ€æ—©çš„é€‚å®œèšç±»æ—¶æœºã€‚é€šè¿‡åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å››åå¤šé¡¹ä»»åŠ¡è¿›è¡Œå®è¯è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ— éœ€è°ƒæ•´è¶…å‚æ•°çš„æƒ…å†µä¸‹è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¯å®äº†åŸºäºå¯†åº¦çš„èšç±»æ–¹æ³•åœ¨åŒºåˆ†ä¸åŒæ•°æ®åˆ†å¸ƒä¸‹ç¥ç»ç½‘ç»œæŸå¤±æ›²é¢æ–¹é¢çš„é«˜æ•ˆæ€§ã€‚æœ€åï¼Œè¯¥å·¥ä½œåˆ©ç”¨ GradCAM æ·±å…¥æ¢è®¨äº†ä¸ªæ€§åŒ–ä¸æœ¬åœ°é¢„æµ‹å¯è§£é‡Šæ€§ä¹‹é—´çš„å…³ç³»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01587v1",
      "published_date": "2025-09-01 16:18:51 UTC",
      "updated_date": "2025-09-01 16:18:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:17.589948+00:00"
    },
    {
      "arxiv_id": "2509.01576v1",
      "title": "Structured AI Decision-Making in Disaster Management",
      "title_zh": "ç¾å®³ç®¡ç†ä¸­çš„ç»“æ„åŒ–äººå·¥æ™ºèƒ½å†³ç­–",
      "authors": [
        "Julian Gerald Dcruz",
        "Argyrios Zolotas",
        "Niall Ross Greenwood",
        "Miguel Arana-Catania"
      ],
      "abstract": "With artificial intelligence (AI) being applied to bring autonomy to decision-making in safety-critical domains such as the ones typified in the aerospace and emergency-response services, there has been a call to address the ethical implications of structuring those decisions, so they remain reliable and justifiable when human lives are at stake. This paper contributes to addressing the challenge of decision-making by proposing a structured decision-making framework as a foundational step towards responsible AI. The proposed structured decision-making framework is implemented in autonomous decision-making, specifically within disaster management. By introducing concepts of Enabler agents, Levels and Scenarios, the proposed framework's performance is evaluated against systems relying solely on judgement-based insights, as well as human operators who have disaster experience: victims, volunteers, and stakeholders. The results demonstrate that the structured decision-making framework achieves 60.94% greater stability in consistently accurate decisions across multiple Scenarios, compared to judgement-based systems. Moreover, the study shows that the proposed framework outperforms human operators with a 38.93% higher accuracy across various Scenarios. These findings demonstrate the promise of the structured decision-making framework for building more reliable autonomous AI applications in safety-critical contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èˆªç©ºèˆªå¤©å’Œåº”æ€¥å“åº”ç­‰å®‰å…¨å…³é”®é¢†åŸŸä¸­äººå·¥æ™ºèƒ½å†³ç­–çš„ä¼¦ç†ä¸å¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“æ„åŒ–å†³ç­–æ¡†æ¶ï¼ˆStructured decision-making frameworkï¼‰ï¼Œæ—¨åœ¨è¿ˆå‘è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ã€‚è¯¥æ¡†æ¶åœ¨ç¾éš¾ç®¡ç†çš„è‡ªä¸»å†³ç­–åœºæ™¯ä¸­å®æ–½ï¼Œå¹¶å¼•å…¥äº† Enabler agentsã€Levels å’Œ Scenarios ç­‰å…³é”®æ¦‚å¿µã€‚é€šè¿‡å°†è¯¥æ¡†æ¶ä¸ä»…ä¾èµ–åˆ¤æ–­çš„ç³»ç»Ÿä»¥åŠå…·æœ‰å®æˆ˜ç»éªŒçš„äººç±»æ“ä½œå‘˜ï¼ˆåŒ…æ‹¬å—å®³è€…ã€å¿—æ„¿è€…å’Œåˆ©ç›Šç›¸å…³è€…ï¼‰è¿›è¡Œå¯¹æ¯”ï¼Œç ”ç©¶å¯¹å…¶æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥ç»“æ„åŒ–å†³ç­–æ¡†æ¶åœ¨å¤šä¸ª Scenarios ä¸­çš„å†³ç­–ç¨³å®šæ€§æ¯”åˆ¤æ–­å‹ç³»ç»Ÿé«˜å‡º 60.94%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„å†³ç­–å‡†ç¡®ç‡æ¯”äººç±»æ“ä½œå‘˜é«˜å‡º 38.93%ï¼Œå±•ç°äº†æå¼ºçš„åº”ç”¨æ½œåŠ›ã€‚è¿™äº›ç ”ç©¶ç»“æœè¯æ˜äº† Structured decision-making framework åœ¨æ„å»ºå®‰å…¨å…³é”®èƒŒæ™¯ä¸‹å¯é è‡ªä¸» AI åº”ç”¨æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 14 figures, 16 tables. To be published in Nature Scientific Reports",
      "pdf_url": "https://arxiv.org/pdf/2509.01576v1",
      "published_date": "2025-09-01 16:04:21 UTC",
      "updated_date": "2025-09-01 16:04:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:24.088751+00:00"
    },
    {
      "arxiv_id": "2509.01565v1",
      "title": "Enabling Down Syndrome Research through a Knowledge Graph-Driven Analytical Framework",
      "title_zh": "é€šè¿‡çŸ¥è¯†å›¾è°±é©±åŠ¨çš„åˆ†ææ¡†æ¶åŠ©åŠ›å”æ°ç»¼åˆå¾ç ”ç©¶",
      "authors": [
        "Madan Krishnamurthy",
        "Surya Saha",
        "Pierrette Lo",
        "Patricia L. Whetzel",
        "Tursynay Issabekova",
        "Jamed Ferreris Vargas",
        "Jack DiGiovanna",
        "Melissa A Haendel"
      ],
      "abstract": "Trisomy 21 results in Down syndrome, a multifaceted genetic disorder with diverse clinical phenotypes, including heart defects, immune dysfunction, neurodevelopmental differences, and early-onset dementia risk. Heterogeneity and fragmented data across studies challenge comprehensive research and translational discovery. The NIH INCLUDE (INvestigation of Co-occurring conditions across the Lifespan to Understand Down syndromE) initiative has assembled harmonized participant-level datasets, yet realizing their potential requires integrative analytical frameworks. We developed a knowledge graph-driven platform transforming nine INCLUDE studies, comprising 7,148 participants, 456 conditions, 501 phenotypes, and over 37,000 biospecimens, into a unified semantic infrastructure. Cross-resource enrichment with Monarch Initiative data expands coverage to 4,281 genes and 7,077 variants. The resulting knowledge graph contains over 1.6 million semantic associations, enabling AI-ready analysis with graph embeddings and path-based reasoning for hypothesis generation. Researchers can query the graph via SPARQL or natural language interfaces. This framework converts static data repositories into dynamic discovery environments, supporting cross-study pattern recognition, predictive modeling, and systematic exploration of genotype-phenotype relationships in Down syndrome.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graphï¼‰é©±åŠ¨çš„åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å”æ°ç»¼åˆå¾ï¼ˆDown syndromeï¼‰ç ”ç©¶ä¸­æ•°æ®é«˜åº¦å¼‚è´¨æ€§å’Œç¢ç‰‡åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚é€šè¿‡æ•´åˆæ¥è‡ª NIH INCLUDE è®¡åˆ’çš„ä¹é¡¹ç ”ç©¶æ•°æ®ï¼Œè¯¥å¹³å°æ¶µç›–äº† 7,148 åå‚ä¸è€…åŠå…¶ç›¸å…³çš„ä¸´åºŠè¡¨å‹ä¸ç”Ÿç‰©æ ·æœ¬ï¼Œå¹¶ç»“åˆ Monarch Initiative æ•°æ®å°†å…¶æ‰©å±•è‡³ 4,281 ä¸ªåŸºå› å’Œ 7,077 ä¸ªå˜ä½“ã€‚ç”±æ­¤æ„å»ºçš„çŸ¥è¯†å›¾è°±åŒ…å«è¶…è¿‡ 160 ä¸‡ä¸ªè¯­ä¹‰å…³è”ï¼Œæ”¯æŒåˆ©ç”¨å›¾åµŒå…¥ï¼ˆGraph Embeddingsï¼‰å’Œè·¯å¾„æ¨ç†ï¼ˆPath-based reasoningï¼‰è¿›è¡Œ AI å°±ç»ªå‹åˆ†æä¸å‡è®¾ç”Ÿæˆã€‚ç ”ç©¶äººå‘˜èƒ½å¤Ÿé€šè¿‡ SPARQL æˆ–è‡ªç„¶è¯­è¨€æ¥å£æŸ¥è¯¢è¯¥ç³»ç»Ÿï¼Œä»è€Œå°†é™æ€æ•°æ®ä»“åº“è½¬åŒ–ä¸ºåŠ¨æ€çš„ç§‘å­¦å‘ç°ç¯å¢ƒã€‚è¿™ä¸€æ¡†æ¶æœ‰æ•ˆæ”¯æŒäº†è·¨ç ”ç©¶çš„æ¨¡å¼è¯†åˆ«å’Œé¢„æµ‹å»ºæ¨¡ï¼Œä¸ºç³»ç»Ÿæ€§æ¢ç´¢åŸºå› å‹-è¡¨å‹ï¼ˆGenotype-phenotypeï¼‰å…³ç³»æä¾›äº†å¼ºåŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01565v1",
      "published_date": "2025-09-01 15:50:38 UTC",
      "updated_date": "2025-09-01 15:50:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:56.599150+00:00"
    },
    {
      "arxiv_id": "2509.02627v2",
      "title": "A Two-Stage Strategy for Mitosis Detection Using Improved YOLO11x Proposals and ConvNeXt Classification",
      "title_zh": "åŸºäºæ”¹è¿›å‹ YOLO11x å€™é€‰æ¡†ä¸ ConvNeXt åˆ†ç±»çš„ä¸¤é˜¶æ®µæœ‰ä¸åˆ†è£‚æ£€æµ‹ç­–ç•¥",
      "authors": [
        "Jie Xiao",
        "Mengye Lyu",
        "Shaojun Liu"
      ],
      "abstract": "MIDOG 2025 Track 1 requires mitosis detection in whole-slideimages (WSIs) containing non-tumor, inflamed, and necrotic re-gions. Due to the complicated and heterogeneous context, aswell as possible artifacts, there are often false positives and falsenegatives, thus degrading the detection F1-score. To addressthis problem, we propose a two-stage framework. Firstly, an im-proved YOLO11x, integrated with EMA attention and LSConv,is employed to generate mitosis candidates. We use a low confi-dence threshold to generate as many proposals as possible, en-suring the detection recall. Then, a ConvNeXt-Tiny classifieris employed to filter out the false positives, ensuring the detec-tion precision. Consequently, the proposed two-stage frame-work can generate a high detection F1-score. Evaluated on afused dataset comprising MIDOG++, MITOS_WSI_CCMCT,and MITOS_WSI_CMC, our framework achieves an F1-scoreof 0.882, which is 0.035 higher than the single-stage YOLO11xbaseline. This performance gain is produced by a significantprecision improvement, from 0.762 to 0.839, and a comparablerecall. On the MIDOG 2025 Track 1 preliminary test set, thealgorithm scores an F1 score of 0.7587. The code is available athttps://github.com/xxiao0304/MIDOG-2025-Track-1-of-SZTU.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹ MIDOG 2025 Track 1 æŒ‘æˆ˜èµ›çš„ä¸¤é˜¶æ®µæœ‰ä¸åˆ†è£‚æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…¨åˆ‡ç‰‡å›¾åƒ (WSIs) ä¸­å› å¤æ‚èƒŒæ™¯å’Œä¼ªå½±å¯¼è‡´çš„å‡é˜³æ€§åŠå‡é˜´æ€§é—®é¢˜ã€‚ç¬¬ä¸€é˜¶æ®µé‡‡ç”¨é›†æˆäº† EMA attention å’Œ LSConv çš„æ”¹è¿›å‹ YOLO11x æ¨¡å‹ç”Ÿæˆå€™é€‰åŒºåŸŸï¼Œé€šè¿‡ä½ç½®ä¿¡åº¦é˜ˆå€¼ç¡®ä¿æ£€æµ‹çš„é«˜ recallã€‚ç¬¬äºŒé˜¶æ®µåˆ©ç”¨ ConvNeXt-Tiny åˆ†ç±»å™¨å¯¹å€™é€‰åŒºåŸŸè¿›è¡ŒäºŒæ¬¡ç­›é€‰ï¼Œæœ‰æ•ˆå‰”é™¤å‡é˜³æ€§æ ·æœ¬ä»¥æå‡ precisionã€‚åœ¨ MIDOG++ã€MITOS_WSI_CCMCT å’Œ MITOS_WSI_CMC çš„èåˆæ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶å®ç°äº† 0.882 çš„ F1-scoreï¼Œè¾ƒå•é˜¶æ®µ YOLO11x åŸºçº¿æå‡äº† 0.035ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜å¬å›ç‡çš„åŒæ—¶å°†ç²¾åº¦ä» 0.762 æ˜¾è‘—æå‡è‡³ 0.839ï¼Œå¹¶åœ¨ MIDOG 2025 åˆèµ›æµ‹è¯•é›†ä¸Šå–å¾—äº† 0.7587 çš„ F1 åˆ†æ•°ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.02627v2",
      "published_date": "2025-09-01 15:46:28 UTC",
      "updated_date": "2025-09-26 06:20:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:49.582758+00:00"
    },
    {
      "arxiv_id": "2509.01560v3",
      "title": "In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents",
      "title_zh": "In-N-Outï¼šé¢å‘å·¥å…·æ™ºèƒ½ä½“çš„å‚æ•°çº§ API å›¾æ•°æ®é›†",
      "authors": [
        "Seungkyu Lee",
        "Nalim Kim",
        "Yohan Jo"
      ],
      "abstract": "Tool agents--LLM-based systems that interact with external APIs--offer a way to execute real-world tasks. However, as tasks become increasingly complex, these agents struggle to identify and call the correct APIs in the proper order. To tackle this problem, we investigate converting API documentation into a structured API graph that captures API dependencies and leveraging it for multi-tool queries that require compositional API calls. To support this, we introduce In-N-Out, the first expert-annotated dataset of API graphs built from two real-world API benchmarks and their documentation. Using In-N-Out significantly improves performance on both tool retrieval and multi-tool query generation, nearly doubling that of LLMs using documentation alone. Moreover, graphs generated by models fine-tuned on In-N-Out close 90% of this gap, showing that our dataset helps models learn to comprehend API documentation and parameter relationships. Our findings highlight the promise of using explicit API graphs for tool agents and the utility of In-N-Out as a valuable resource. We release our dataset and code at https://github.com/holi-lab/In-N-Out-API-Graph.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Tool agents åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶éš¾ä»¥å‡†ç¡®è¯†åˆ«å’ŒæŒ‰åºè°ƒç”¨ API çš„é—®é¢˜ï¼Œæ¢è®¨äº†å°† API documentation è½¬æ¢ä¸ºç»“æ„åŒ– API graph çš„æ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æ¨å‡ºäº†é¦–ä¸ªç”±ä¸“å®¶æ ‡æ³¨çš„å‚æ•°çº§ API graph æ•°æ®é›† In-N-Outï¼Œè¯¥æ•°æ®é›†åŸºäºä¸¤ä¸ªçœŸå®ä¸–ç•Œçš„ API benchmarks åŠå…¶æ–‡æ¡£æ„å»ºè€Œæˆã€‚å®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨ In-N-Out èƒ½å¤Ÿæ˜¾è‘—æå‡å·¥å…·æ£€ç´¢å’Œå¤šå·¥å…·æŸ¥è¯¢ç”Ÿæˆçš„æ€§èƒ½ï¼Œå…¶è¡¨ç°æ ¸å¿ƒæŒ‡æ ‡å‡ ä¹æ˜¯ä»…ä¾èµ–æ–‡æ¡£çš„ LLMs çš„ä¸¤å€ã€‚æ­¤å¤–ï¼Œåœ¨ In-N-Out ä¸Šè¿›è¡Œå¾®è°ƒçš„æ¨¡å‹èƒ½å¤Ÿå¼¥è¡¥ 90% çš„æ€§èƒ½å·®è·ï¼Œå……åˆ†è¯æ˜äº†è¯¥æ•°æ®é›†åœ¨å¸®åŠ©æ¨¡å‹ç†è§£ API æ–‡æ¡£å’Œå‚æ•°å…³ç³»æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…å¼ºè°ƒäº†æ˜¾å¼ API graph åœ¨æå‡ Tool agents èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œè¿˜é€šè¿‡å¼€æºæ•°æ®é›†å’Œä»£ç ä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01560v3",
      "published_date": "2025-09-01 15:42:21 UTC",
      "updated_date": "2025-12-30 04:36:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:35.784298+00:00"
    },
    {
      "arxiv_id": "2509.01554v1",
      "title": "Unified Supervision For Vision-Language Modeling in 3D Computed Tomography",
      "title_zh": "ä¸‰ç»´è®¡ç®—æœºæ–­å±‚æ‰«æè§†è§‰è¯­è¨€å»ºæ¨¡çš„ç»Ÿä¸€ç›‘ç£",
      "authors": [
        "Hao-Chih Lee",
        "Zelong Liu",
        "Hamza Ahmed",
        "Spencer Kim",
        "Sean Huver",
        "Vishwesh Nath",
        "Zahi A. Fayad",
        "Timothy Deyer",
        "Xueyan Mei"
      ],
      "abstract": "General-purpose vision-language models (VLMs) have emerged as promising tools in radiology, offering zero-shot capabilities that mitigate the need for large labeled datasets. However, in high-stakes domains like diagnostic radiology, these models often lack the discriminative precision required for reliable clinical use. This challenge is compounded by the scarcity and heterogeneity of publicly available volumetric CT datasets, which vary widely in annotation formats and granularity. To address these limitations, we introduce Uniferum, a volumetric VLM that unifies diverse supervision signals, encoded in classification labels and segmentation masks, into a single training framework. By harmonizing three public 3D CT datasets with distinct annotations, Uniferum achieves state-of-the-art performance, improving AUROC on the CT-RATE benchmark by 7% compared to CLIP-based and conventional multi-label convolutional models. The model demonstrates robust out-of-distribution generalization, with observed evidence of unexpected zero-shot performance on the RAD-CHEST and INSPECT datasets. Our results highlight the effectiveness of integrating heterogeneous annotations and body segmentation to enhance model performance, setting a new direction for clinically reliable, data-efficient VLMs in 3D medical imaging.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šç”¨è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨æ”¾å°„å­¦é¢†åŸŸçš„åº”ç”¨ï¼Œé’ˆå¯¹ç°æœ‰æ¨¡å‹åœ¨ä¸´åºŠè¯Šæ–­ä¸­ç²¾ç¡®åº¦ä¸è¶³ä»¥åŠ3D CTæ•°æ®é›†æ ‡æ³¨å¼‚æ„çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºUniferumçš„ä½“ç§¯VLMæ¡†æ¶ã€‚Uniferumé€šè¿‡ç»Ÿä¸€çš„ç›‘ç£æœºåˆ¶ï¼Œå°†åˆ†ç±»æ ‡ç­¾å’Œåˆ†å‰²æ©ç ç­‰å¤šæ ·åŒ–ä¿¡å·æ•´åˆåˆ°å•ä¸€è®­ç»ƒæ¡†æ¶ä¸­ï¼Œå®ç°äº†å¯¹ä¸‰ä¸ªä¸åŒæ ‡æ³¨æ ¼å¼çš„å…¬å…±3D CTæ•°æ®é›†çš„æœ‰æ•ˆåè°ƒã€‚å®éªŒè¯æ˜ï¼ŒUniferumåœ¨CT-RATEåŸºå‡†æµ‹è¯•ä¸­çš„AUROCæ¯”åŸºäºCLIPçš„æ¨¡å‹å’Œä¼ ç»Ÿå¤šæ ‡ç­¾å·ç§¯æ¨¡å‹æå‡äº†7%ï¼Œè¾¾åˆ°äº†state-of-the-artæ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨RAD-CHESTå’ŒINSPECTæ•°æ®é›†ä¸Šå±•ç°äº†å‡ºè‰²çš„åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›å’Œzero-shotæ€§èƒ½ã€‚è¯¥æˆæœå¼ºè°ƒäº†æ•´åˆå¼‚æ„æ ‡æ³¨ä¸èº«ä½“åˆ†å‰²å¯¹å¢å¼ºæ¨¡å‹è¡¨ç°çš„å…³é”®ä½œç”¨ï¼Œä¸ºä¸´åºŠå¯é ä¸”å…·å¤‡æ•°æ®æ•ˆç‡çš„3DåŒ»å­¦å½±åƒVLMsç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025 VLM 3d Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.01554v1",
      "published_date": "2025-09-01 15:30:17 UTC",
      "updated_date": "2025-09-01 15:30:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:16.907133+00:00"
    },
    {
      "arxiv_id": "2509.01544v3",
      "title": "Causal Consistency Regularization: Training Verifiably Sensitive Reasoning in Large Language Models",
      "title_zh": "å› æœä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼šåœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­è®­ç»ƒå¯éªŒè¯çš„æ•æ„Ÿæ€§æ¨ç†",
      "authors": [
        "Sanjeda Akter",
        "Ibne Farabi Shihab",
        "Anuj Sharma"
      ],
      "abstract": "Large language models can produce correct answers while relying on flawed reasoning traces, partly because common training objectives reward final-answer correctness rather than faithful intermediate reasoning. This undermines trustworthiness in high-stakes settings. We propose Counterfactual Sensitivity Regularization (CSR), a training paradigm that improves reasoning faithfulness by enforcing causal consistency between reasoning steps and outcomes. CSR automatically applies operator-level interventions to reasoning traces, such as swapping \"+\" with \"-\", to generate minimally perturbed counterfactual rationales, and penalizes the model when these logically invalid traces still lead to the original answer. Our implementation is efficient, adding about 9 percent training overhead via a warm-start curriculum and token-subset optimization.\n  We evaluate faithfulness using Counterfactual Outcome Sensitivity (COS), which measures how appropriately answers change under logical perturbations. Across arithmetic (GSM8K), logical deduction (ProofWriter), multi-hop question answering (HotpotQA), and code generation (MBPP), CSR yields improved accuracy versus faithfulness trade-offs, establishing a new Pareto frontier. CSR improves faithfulness over standard fine-tuning and process supervision by up to 70 percentage points, and transfers across model families with 94.2 to 96.7 percent success in structured domains. CSR also complements inference-time methods such as self-consistency. Overall, CSR offers a practical route to more reliable reasoning in structured domains, including mathematics, formal logic, and code, where operators are well-defined and verifiable, covering an estimated 40 to 60 percent of high-stakes reasoning deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è™½ç„¶èƒ½è¾“å‡ºæ­£ç¡®ç­”æ¡ˆä½†æ¨ç†è¿‡ç¨‹å¯èƒ½å­˜åœ¨ç¼ºé™·çš„é—®é¢˜ï¼Œæå‡ºäº†Counterfactual Sensitivity Regularization (CSR)è®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡å¢å¼ºæ¨ç†æ­¥éª¤ä¸ç»“æœä¹‹é—´çš„å› æœä¸€è‡´æ€§æ¥æå‡æ¨ç†çš„å¿ å®æ€§(faithfulness)ã€‚CSRé€šè¿‡å¯¹æ¨ç†è·¯å¾„æ‰§è¡Œç®—å­çº§å¹²é¢„(operator-level interventions)ç”Ÿæˆåäº‹å®ç†ç”±ï¼Œå¹¶æƒ©ç½šæ¨¡å‹åœ¨é€»è¾‘å¤±æ•ˆæ—¶ä»ä¿æŒåŸç­”æ¡ˆçš„é”™è¯¯å€¾å‘ã€‚é€šè¿‡é¢„çƒ­è¯¾ç¨‹å’Œä¼˜åŒ–ç­–ç•¥ï¼Œè¯¥æ–¹æ³•ä»…å¢åŠ äº†çº¦9%çš„è®­ç»ƒå¼€é”€ã€‚å®éªŒåˆ©ç”¨Counterfactual Outcome Sensitivity (COS)æŒ‡æ ‡åœ¨GSM8Kã€ProofWriterã€HotpotQAå’ŒMBPPç­‰å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯æ˜CSRåœ¨å‡†ç¡®ç‡ä¸å¿ å®æ€§çš„æƒè¡¡ä¸­è¾¾åˆ°äº†æ–°çš„å¸•ç´¯æ‰˜å‰æ²¿(Pareto frontier)ã€‚ç›¸æ¯”ä¼ ç»Ÿå¾®è°ƒå’Œè¿‡ç¨‹ç›‘ç£ï¼ŒCSRåœ¨æå‡å¿ å®æ€§æ–¹é¢æœ€é«˜å¯è¾¾70ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶åœ¨ä¸åŒæ¨¡å‹å®¶æ—é—´è¡¨ç°å‡ºä¼˜å¼‚çš„è¿ç§»æ€§ã€‚è¯¥æ–¹æ³•ä¸ºæ•°å­¦ã€é€»è¾‘å’Œä»£ç ç­‰ç»“æ„åŒ–é¢†åŸŸçš„å¯é æ¨ç†æä¾›äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01544v3",
      "published_date": "2025-09-01 15:18:46 UTC",
      "updated_date": "2026-01-05 17:24:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:53:46.095099+00:00"
    },
    {
      "arxiv_id": "2509.01535v2",
      "title": "CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models",
      "title_zh": "CATï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹ç»†ç²’åº¦å› æœçŸ¥è¯†æ³¨å…¥çš„å› æœæ³¨æ„åŠ›å¾®è°ƒ",
      "authors": [
        "Kairong Han",
        "Wenshuo Zhao",
        "Ziyu Zhao",
        "JunJian Ye",
        "Lujia Pan",
        "Kun Kuang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across various domains. However, a fundamental question remains: Can LLMs effectively utilize causal knowledge for prediction and generation? Through empirical studies, we find that LLMs trained directly on large-scale data often capture spurious correlations rather than true causal relationships, leading to suboptimal performance, especially in out-of-distribution (OOD) scenarios. To address this challenge, we propose Causal Attention Tuning (CAT), a novel approach that injects fine-grained causal knowledge into the attention mechanism. We propose an automated pipeline that leverages human priors to automatically generate token-level causal signals and introduce the Re-Attention mechanism to guide training, helping the model focus on causal structures while mitigating noise and biases in attention scores. Experimental results on our proposed Spurious Token Game (STG) benchmark and multiple downstream tasks demonstrate that our approach effectively leverages causal knowledge for prediction and remains robust in OOD scenarios. The CAT achieves an average improvement of 5.76% on the STG dataset and 1.56% on downstream tasks. Notably, the OOD performance of the Llama-3.1-8B model on STG_M increased from 64.5% to 90.5%, and Qwen's OOD performance on the STG_H dataset improved from 25.4% to 55.9%. Implementation details can be found at https://github.com/Kairong-Han/CAT.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Causal Attention Tuning (CAT)ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç”±äºæ•æ‰ä¼ªç›¸å…³(spurious correlations)è€ŒéçœŸå®å› æœå…³ç³»ï¼Œå¯¼è‡´åœ¨åˆ†å¸ƒå¤–(OOD)åœºæ™¯ä¸‹è¡¨ç°æ¬ ä½³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ç»†ç²’åº¦çš„å› æœçŸ¥è¯†æ³¨å…¥æ³¨æ„åŠ›æœºåˆ¶(attention mechanism)ï¼Œå¢å¼ºäº†æ¨¡å‹åˆ©ç”¨å› æœé€»è¾‘è¿›è¡Œé¢„æµ‹å’Œç”Ÿæˆçš„èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€å¥—è‡ªåŠ¨åŒ–æµç¨‹ï¼Œåˆ©ç”¨äººç±»å…ˆéªŒè‡ªåŠ¨ç”Ÿæˆtokençº§åˆ«çš„å› æœä¿¡å·ï¼Œå¹¶å¼•å…¥Re-Attentionæœºåˆ¶å¼•å¯¼æ¨¡å‹ä¸“æ³¨äºå› æœç»“æ„(causal structures)ï¼ŒåŒæ—¶å‡å°‘æ³¨æ„åŠ›åˆ†æ•°ä¸­çš„å™ªå£°ä¸åå·®ã€‚åœ¨Spurious Token Game (STG)åŸºå‡†æµ‹è¯•å’Œå¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒCATèƒ½æœ‰æ•ˆåˆ©ç”¨å› æœçŸ¥è¯†å¹¶æ˜¾è‘—æå‡OODåœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚å®éªŒæ˜¾ç¤ºCATåœ¨STGæ•°æ®é›†ä¸Šå¹³å‡æå‡äº†5.76%ï¼Œå…¶ä¸­Llama-3.1-8Båœ¨STG_Mä»»åŠ¡ä¸­çš„OODæ€§èƒ½ä»64.5%æ˜¾è‘—æå‡è‡³90.5%ã€‚è¯¥ç ”ç©¶ä¸ºæå‡LLMsçš„å¯è§£é‡Šæ€§ä¸æ³›åŒ–èƒ½åŠ›æä¾›äº†æ–°çš„æŠ€æœ¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP2025 Main conference",
      "pdf_url": "https://arxiv.org/pdf/2509.01535v2",
      "published_date": "2025-09-01 15:13:15 UTC",
      "updated_date": "2025-09-09 04:01:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:02.896103+00:00"
    },
    {
      "arxiv_id": "2509.01517v1",
      "title": "Agentic Workflow for Education: Concepts and Applications",
      "title_zh": "é¢å‘æ•™è‚²çš„æ™ºèƒ½ä½“å·¥ä½œæµï¼šæ¦‚å¿µä¸åº”ç”¨",
      "authors": [
        "Yuan-Hao Jiang",
        "Yijie Lu",
        "Ling Dai",
        "Jiatong Wang",
        "Ruijia Li",
        "Bo Jiang"
      ],
      "abstract": "With the rapid advancement of Large Language Models (LLMs) and Artificial Intelligence (AI) agents, agentic workflows are showing transformative potential in education. This study introduces the Agentic Workflow for Education (AWE), a four-component model comprising self-reflection, tool invocation, task planning, and multi-agent collaboration. We distinguish AWE from traditional LLM-based linear interactions and propose a theoretical framework grounded in the von Neumann Multi-Agent System (MAS) architecture. Through a paradigm shift from static prompt-response systems to dynamic, nonlinear workflows, AWE enables scalable, personalized, and collaborative task execution. We further identify four core application domains: integrated learning environments, personalized AI-assisted learning, simulation-based experimentation, and data-driven decision-making. A case study on automated math test generation shows that AWE-generated items are statistically comparable to real exam questions, validating the model's effectiveness. AWE offers a promising path toward reducing teacher workload, enhancing instructional quality, and enabling broader educational innovation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æ•™è‚²æ™ºèƒ½ä½“å·¥ä½œæµ (Agentic Workflow for Education, AWE)ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) å’Œäººå·¥æ™ºèƒ½æ™ºèƒ½ä½“å˜é©æ•™è‚²æ¨¡å¼ã€‚è¯¥æ¨¡å‹ç”±è‡ªæˆ‘åæ€ (self-reflection)ã€å·¥å…·è°ƒç”¨ (tool invocation)ã€ä»»åŠ¡è§„åˆ’ (task planning) å’Œå¤šæ™ºèƒ½ä½“åä½œ (multi-agent collaboration) å››ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼Œå¹¶åŸºäºå†¯Â·è¯ºä¾æ›¼å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (von Neumann Multi-Agent System, MAS) æ¶æ„å»ºç«‹äº†ç†è®ºæ¡†æ¶ã€‚é€šè¿‡ä»é™æ€æç¤º-å“åº”æ¨¡å¼è½¬å‘åŠ¨æ€ã€éçº¿æ€§çš„å·¥ä½œæµï¼ŒAWE å®ç°äº†å¯æ‰©å±•ä¸”ä¸ªæ€§åŒ–çš„ä»»åŠ¡æ‰§è¡Œã€‚ç ”ç©¶è¯†åˆ«äº† AWE åœ¨é›†æˆå­¦ä¹ ç¯å¢ƒã€ä¸ªæ€§åŒ– AI è¾…åŠ©å­¦ä¹ ç­‰å››å¤§é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œå¹¶é€šè¿‡è‡ªåŠ¨åŒ–æ•°å­¦è¯•é¢˜ç”Ÿæˆçš„æ¡ˆä¾‹ç ”ç©¶éªŒè¯äº†å…¶ç”Ÿæˆçš„é¢˜ç›®è´¨é‡ä¸çœŸå®è€ƒé¢˜å…·æœ‰ç»Ÿè®¡å­¦ä¸Šçš„å¯æ¯”æ€§ã€‚è¯¥ç ”ç©¶è¯æ˜ AWE èƒ½å¤Ÿæœ‰æ•ˆå‡è½»æ•™å¸ˆå·¥ä½œè´Ÿæ‹…å¹¶æå‡æ•™å­¦è´¨é‡ï¼Œä¸ºæ•™è‚²åˆ›æ–°æä¾›äº†é‡è¦è·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "Proceedings of the 33rd International Conference on Computers in Education (ICCE 2025). Asia-Pacific Society for Computers in Education",
      "pdf_url": "https://arxiv.org/pdf/2509.01517v1",
      "published_date": "2025-09-01 14:39:48 UTC",
      "updated_date": "2025-09-01 14:39:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:04.388622+00:00"
    },
    {
      "arxiv_id": "2509.01514v1",
      "title": "MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models",
      "title_zh": "MeVeï¼šä¸€ç§é¢å‘è¯­è¨€æ¨¡å‹è®°å¿†éªŒè¯ä¸æœ‰æ•ˆä¸Šä¸‹æ–‡æ§åˆ¶çš„æ¨¡å—åŒ–ç³»ç»Ÿ",
      "authors": [
        "Andreas Ottem"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems typically face constraints because of their inherent mechanism: a simple top-k semantic search [1]. The approach often leads to the incorporation of irrelevant or redundant information in the context, degrading performance and efficiency [10][11]. This paper presents MeVe, a novel modular architecture intended for Memory Verification and smart context composition. MeVe rethinks the RAG paradigm by proposing a five-phase modular design that distinctly breaks down the retrieval and context composition process into distinct, auditable, and independently tunable phases: initial retrieval, relevance verification, fallback retrieval, context prioritization, and token budgeting. This architecture enables fine-grained control of what knowledge is made available to an LLM, enabling task-dependent filtering and adaptation. We release a reference implementation of MeVe as a proof of concept and evaluate its performance on knowledge-heavy QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that by actively verifying information before composition, MeVe significantly improves context efficiency, achieving a 57% reduction on the Wikipedia dataset and a 75% reduction on the more complex HotpotQA dataset compared to standard RAG implementations [25]. This work provides a framework for more scalable and reliable LLM applications. By refining and distilling contextual information, MeVe offers a path toward better grounding and more accurate factual support [16].",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MeVeï¼Œä¸€ç§ä¸“ä¸ºè¯­è¨€æ¨¡å‹è®¾è®¡çš„æ¨¡å—åŒ–Memory Verificationå’Œæ™ºèƒ½ä¸Šä¸‹æ–‡æ§åˆ¶ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸRetrieval-Augmented Generation (RAG) ç³»ç»Ÿå› ä¾èµ–top-kè¯­ä¹‰æœç´¢è€Œå¯¼è‡´çš„ä¸Šä¸‹æ–‡å†—ä½™å’Œæ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚MeVeé‡‡ç”¨äº†åŒ…å«initial retrievalã€relevance verificationã€fallback retrievalã€context prioritizationä»¥åŠtoken budgetingåœ¨å†…çš„äº”é˜¶æ®µæ¨¡å—åŒ–è®¾è®¡ï¼Œå°†æ£€ç´¢ä¸ä¸Šä¸‹æ–‡åˆæˆè¿‡ç¨‹åˆ†è§£ä¸ºç‹¬ç«‹å¯è°ƒä¸”å¯å®¡è®¡çš„æ­¥éª¤ã€‚è¿™ç§æ¶æ„å®ç°äº†å¯¹LLMå¯ç”¨çŸ¥è¯†çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡éœ€æ±‚è¿›è¡Œä¿¡æ¯çš„åŠ¨æ€è¿‡æ»¤ä¸é€‚é…ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMeVeåœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸æ¯”æ ‡å‡†RAGå®ç°åœ¨Wikipediaæ•°æ®é›†å’Œå¤æ‚çš„HotpotQAæ•°æ®é›†ä¸Šåˆ†åˆ«å‡å°‘äº†57%å’Œ75%çš„ä¸Šä¸‹æ–‡éœ€æ±‚ã€‚è¯¥ç ”ç©¶ä¸ä»…æ˜¾è‘—æå‡äº†ä¸Šä¸‹æ–‡æ•ˆç‡ï¼Œè¿˜é€šè¿‡å¯¹ä¿¡æ¯çš„æç‚¼ä¸éªŒè¯ï¼Œä¸ºæ„å»ºæ›´å…·å¯æ‰©å±•æ€§ã€å¯é æ€§åŠå‡†ç¡®æ€§çš„LLMåº”ç”¨æä¾›äº†æœ‰æ•ˆæ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 7 figures, held online presentation at NLPA 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01514v1",
      "published_date": "2025-09-01 14:33:09 UTC",
      "updated_date": "2025-09-01 14:33:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:30.692216+00:00"
    },
    {
      "arxiv_id": "2509.01512v1",
      "title": "Unsupervised Identification and Replay-based Detection (UIRD) for New Category Anomaly Detection in ECG Signal",
      "title_zh": "UIRDï¼šé¢å‘å¿ƒç”µä¿¡å·æ–°ç±»åˆ«å¼‚å¸¸æ£€æµ‹çš„æ— ç›‘ç£è¯†åˆ«ä¸åŸºäºå›æ”¾çš„æ£€æµ‹",
      "authors": [
        "Zhangyue Shi",
        "Zekai Wang",
        "Yuxuan Li"
      ],
      "abstract": "In clinical practice, automatic analysis of electrocardiogram (ECG) is widely applied to identify irregular heart rhythms and other electrical anomalies of the heart, enabling timely intervention and potentially improving clinical outcomes. However, due to the limited samples in certain types of ECG signals, the class imbalance issues pose a challenge for ECG-based detection. In addition, as the volume of patient data grows, long-term storage of all historical data becomes increasingly burdensome as training samples to recognize new patterns and classify existing ECG signals accurately. Therefore, to enhance the performance of anomaly detection while addressing storage limitations, we propose a pseudo-replay based semi-supervised continual learning framework, which consists of two components: unsupervised identification and replay-based detection. For unsupervised identification, an unsupervised generative adversarial network (GAN)-based framework is integrated to detect novel patterns. Besides, instead of directly storing all historical data, a pseudo replay-based learning strategy is proposed which utilizes a generator to learn the data distribution for each individual task. When a new task arises, the generator synthesizes pseudo data representative of previous learnt classes, enabling the model to detect both the existed patterns and the newly presented anomalies. The effectiveness of the proposed framework is validated in four public ECG datasets, which leverages supervised classification problems for anomaly detection. The experimental results show that the developed approach is very promising in identifying novel anomalies while maintaining good performance on detecting existing ECG signals.",
      "tldr_zh": "é’ˆå¯¹å¿ƒç”µå›¾(ECG)è‡ªåŠ¨åˆ†æä¸­é¢ä¸´çš„ç±»åˆ«ä¸å¹³è¡¡ä»¥åŠé•¿æœŸæ•°æ®å­˜å‚¨æˆæœ¬é«˜æ˜‚ç­‰æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†UIRDï¼Œä¸€ç§åŸºäºä¼ªé‡è¿°(pseudo-replay)çš„åŠç›‘ç£æŒç»­å­¦ä¹ (continual learning)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ— ç›‘ç£è¯†åˆ«å’ŒåŸºäºé‡è¿°çš„æ£€æµ‹ä¸¤ä¸ªç»„ä»¶ï¼Œåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)æ¥è¯†åˆ«å¿ƒç”µä¿¡å·ä¸­çš„æ–°æ¨¡å¼ã€‚ä¸å­˜å‚¨æ‰€æœ‰å†å²æ•°æ®ä¸åŒï¼ŒUIRDé‡‡ç”¨ä¼ªé‡è¿°ç­–ç•¥ï¼Œé€šè¿‡ç”Ÿæˆå™¨å­¦ä¹ æ•°æ®åˆ†å¸ƒå¹¶åœ¨å¤„ç†æ–°ä»»åŠ¡æ—¶åˆæˆæ—§ç±»åˆ«çš„ä¼ªæ•°æ®ï¼Œä»è€Œå®ç°å¯¹æ—¢æœ‰æ¨¡å¼å’Œæ–°å¼‚å¸¸çš„åŒæ­¥æ£€æµ‹ã€‚åœ¨å››ä¸ªå…¬å¼€ECGæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ä¾èµ–æµ·é‡åŸå§‹æ•°æ®å­˜å‚¨çš„å‰æä¸‹ï¼Œèƒ½æœ‰æ•ˆè¯†åˆ«æ–°ç±»åˆ«å¼‚å¸¸(anomaly detection)ï¼Œå¹¶ä¿æŒå¯¹ç°æœ‰å¿ƒç”µä¿¡å·çš„ä¼˜å¼‚æ£€æµ‹æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01512v1",
      "published_date": "2025-09-01 14:32:03 UTC",
      "updated_date": "2025-09-01 14:32:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:47.460473+00:00"
    },
    {
      "arxiv_id": "2509.01498v2",
      "title": "MSA2-Net: Utilizing Self-Adaptive Convolution Module to Extract Multi-Scale Information in Medical Image Segmentation",
      "title_zh": "MSA2-Netï¼šåˆ©ç”¨è‡ªé€‚åº”å·ç§¯æ¨¡å—æå–åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„å¤šå°ºåº¦ä¿¡æ¯",
      "authors": [
        "Chao Deng",
        "Xiaosen Li",
        "Xiao Qin"
      ],
      "abstract": "The nnUNet segmentation framework adeptly adjusts most hyperparameters in training scripts automatically, but it overlooks the tuning of internal hyperparameters within the segmentation network itself, which constrains the model's ability to generalize. Addressing this limitation, this study presents a novel Self-Adaptive Convolution Module that dynamically adjusts the size of the convolution kernels depending on the unique fingerprints of different datasets. This adjustment enables the MSA2-Net, when equipped with this module, to proficiently capture both global and local features within the feature maps. Self-Adaptive Convolution Module is strategically integrated into two key components of the MSA2-Net: the Multi-Scale Convolution Bridge and the Multi-Scale Amalgamation Decoder. In the MSConvBridge, the module enhances the ability to refine outputs from various stages of the CSWin Transformer during the skip connections, effectively eliminating redundant data that could potentially impair the decoder's performance. Simultaneously, the MSADecoder, utilizing the module, excels in capturing detailed information of organs varying in size during the decoding phase. This capability ensures that the decoder's output closely reproduces the intricate details within the feature maps, thus yielding highly accurate segmentation images. MSA2-Net, bolstered by this advanced architecture, has demonstrated exceptional performance, achieving Dice coefficient scores of 86.49\\%, 92.56\\%, 93.37\\%, and 92.98\\% on the Synapse, ACDC, Kvasir, and Skin Lesion Segmentation (ISIC2017) datasets, respectively. This underscores MSA2-Net's robustness and precision in medical image segmentation tasks across various datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MSA2-Netï¼Œæ—¨åœ¨è§£å†³nnUNetæ¡†æ¶å› å¿½ç•¥åˆ†å‰²ç½‘ç»œå†…éƒ¨è¶…å‚æ•°è°ƒæ•´è€Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†Self-Adaptive Convolution Moduleï¼Œè¯¥æ¨¡å—èƒ½æ ¹æ®ä¸åŒæ•°æ®é›†çš„ç‰¹å¾åŠ¨æ€è°ƒæ•´å·ç§¯æ ¸å¤§å°ï¼Œä»è€Œæœ‰æ•ˆæå–ç‰¹å¾å›¾ä¸­çš„å…¨å±€ä¸å±€éƒ¨ä¿¡æ¯ã€‚è¯¥æ¨¡å—è¢«é›†æˆäºMSA2-Netçš„ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šMulti-Scale Convolution Bridge(MSConvBridge)å’ŒMulti-Scale Amalgamation Decoder(MSADecoder)ã€‚åœ¨è·³è·ƒè¿æ¥è¿‡ç¨‹ä¸­ï¼ŒMSConvBridgeå¢å¼ºäº†å¯¹CSWin Transformerå„é˜¶æ®µè¾“å‡ºçš„ç»†åŒ–èƒ½åŠ›å¹¶æ¶ˆé™¤äº†å†—ä½™æ•°æ®ï¼Œè€ŒMSADecoderåˆ™åˆ©ç”¨è¯¥æ¨¡å—åœ¨è§£ç é˜¶æ®µç²¾å‡†æ•æ‰ä¸åŒå°ºå¯¸å™¨å®˜çš„ç»†èŠ‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMSA2-Netåœ¨Synapseã€ACDCã€Kvasirå’ŒISIC2017æ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†86.49%ã€92.56%ã€93.37%å’Œ92.98%çš„Diceç³»æ•°ã€‚è¿™è¯æ˜äº†MSA2-Netåœ¨å„ç§åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­å…·æœ‰å“è¶Šçš„é²æ£’æ€§å’Œç²¾ç¡®åº¦ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01498v2",
      "published_date": "2025-09-01 14:19:15 UTC",
      "updated_date": "2025-09-03 02:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:41.860552+00:00"
    },
    {
      "arxiv_id": "2509.05338v1",
      "title": "Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks",
      "title_zh": "Plantbotï¼šåŸºäº LLM æ¨¡å—åŒ–æ™ºèƒ½ä½“ç½‘ç»œå®ç°çš„æ¤ç‰©ä¸æœºå™¨äººèåˆ",
      "authors": [
        "Atsushi Masumori",
        "Norihiro Maruyama",
        "Itsuki Doi",
        "johnsmith",
        "Hiroki Sato",
        "Takashi Ikegami"
      ],
      "abstract": "We introduce Plantbot, a hybrid lifeform that connects a living plant with a mobile robot through a network of large language model (LLM) modules. Each module - responsible for sensing, vision, dialogue, or action - operates asynchronously and communicates via natural language, enabling seamless interaction across biological and artificial domains. This architecture leverages the capacity of LLMs to serve as hybrid interfaces, where natural language functions as a universal protocol, translating multimodal data (soil moisture, temperature, visual context) into linguistic messages that coordinate system behaviors. The integrated network transforms plant states into robotic actions, installing normativity essential for agency within the sensor-motor loop. By combining biological and robotic elements through LLM-mediated communication, Plantbot behaves as an embodied, adaptive agent capable of responding autonomously to environmental conditions. This approach suggests possibilities for a new model of artificial life, where decentralized, LLM modules coordination enable novel interactions between biological and artificial systems.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Plantbotï¼Œä¸€ç§é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ (LLM) æ¨¡å—ç½‘ç»œå°†æ´»ä½“æ¤ç‰©ä¸ç§»åŠ¨æœºå™¨äººè¿æ¥çš„æ··åˆç”Ÿå‘½å½¢å¼ã€‚è¯¥ç³»ç»Ÿç”±è´Ÿè´£æ„ŸçŸ¥ã€è§†è§‰ã€å¯¹è¯å’ŒåŠ¨ä½œçš„å¼‚æ­¥æ¨¡å—ç»„æˆï¼Œå¹¶ä»¥è‡ªç„¶è¯­è¨€ä½œä¸ºé€šç”¨åè®®è¿›è¡Œè·¨ç”Ÿç‰©ä¸äººå·¥é¢†åŸŸçš„æ— ç¼äº¤äº’ã€‚é€šè¿‡ LLM æ¥å£ï¼Œç³»ç»Ÿèƒ½å°†åœŸå£¤æ¹¿åº¦ã€æ¸©åº¦å’Œè§†è§‰èƒŒæ™¯ç­‰å¤šæ¨¡æ€æ•°æ® (multimodal data) è½¬åŒ–ä¸ºè¯­è¨€æ¶ˆæ¯ï¼Œæœ‰æ•ˆåè°ƒç³»ç»Ÿçš„æ•´ä½“è¡Œä¸ºã€‚è¿™ç§é›†æˆç½‘ç»œå°†æ¤ç‰©çŠ¶æ€è½¬åŒ–ä¸ºæœºå™¨äººåŠ¨ä½œï¼Œåœ¨ä¼ æ„Ÿå™¨-ç”µæœºå›è·¯ (sensor-motor loop) ä¸­å»ºç«‹äº†å®ç°ä¸»ä½“æ€§ (agency) æ‰€éœ€çš„è§„èŒƒæ€§ã€‚Plantbot ä½œä¸ºä¸€ä¸ªå…·èº« (embodied) ä¸”å…·é€‚åº”æ€§çš„æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿæ ¹æ®ç¯å¢ƒæ¡ä»¶è‡ªä¸»åšå‡ºååº”ã€‚è¯¥ç ”ç©¶ä¸ºäººå·¥ç”Ÿå‘½æä¾›äº†ä¸€ç§æ–°æ¨¡å‹ï¼Œå±•ç¤ºäº†å»ä¸­å¿ƒåŒ– LLM æ¨¡å—åä½œåœ¨ä¿ƒè¿›ç”Ÿç‰©ä¸äººå·¥ç³»ç»Ÿæ–°å‹äº¤äº’ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05338v1",
      "published_date": "2025-09-01 14:12:28 UTC",
      "updated_date": "2025-09-01 14:12:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:42.663923+00:00"
    },
    {
      "arxiv_id": "2509.01479v2",
      "title": "An Information-Flow Perspective on Explainability Requirements: Specification and Verification",
      "title_zh": "ä¿¡æ¯æµè§†è§’ä¸‹çš„å¯è§£é‡Šæ€§éœ€æ±‚ï¼šè§„èŒƒä¸éªŒè¯",
      "authors": [
        "Bernd Finkbeiner",
        "Hadar Frenkel",
        "Julian Siber"
      ],
      "abstract": "Explainable systems expose information about why certain observed effects are happening to the agents interacting with them. We argue that this constitutes a positive flow of information that needs to be specified, verified, and balanced against negative information flow that may, e.g., violate privacy guarantees. Since both explainability and privacy require reasoning about knowledge, we tackle these tasks with epistemic temporal logic extended with quantification over counterfactual causes. This allows us to specify that a multi-agent system exposes enough information such that agents acquire knowledge on why some effect occurred. We show how this principle can be used to specify explainability as a system-level requirement and provide an algorithm for checking finite-state models against such specifications. We present a prototype implementation of the algorithm and evaluate it on several benchmarks, illustrating how our approach distinguishes between explainable and unexplainable systems, and how it allows to pose additional privacy requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ä¿¡æ¯æµ(Information-Flow)çš„è§’åº¦æ¢è®¨äº†å¯è§£é‡Šæ€§éœ€æ±‚(Explainability Requirements)ï¼Œæå‡ºå¯è§£é‡Šç³»ç»Ÿå‘äº¤äº’æ™ºèƒ½ä½“å…¬å¼€ä¿¡æ¯æ˜¯ä¸€ç§æ­£å‘ä¿¡æ¯æµã€‚ä½œè€…è®¤ä¸ºè¿™ç§æ­£å‘æµéœ€è¦ä¸ä¿æŠ¤éšç§çš„è´Ÿå‘ä¿¡æ¯æµè¿›è¡Œå¹³è¡¡ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè§„èŒƒåŒ–(Specification)å’ŒéªŒè¯(Verification)ã€‚ä¸ºäº†å¤„ç†å¯è§£é‡Šæ€§å’Œéšç§æ‰€éœ€çš„çŸ¥è¯†æ¨ç†ï¼Œç ”ç©¶é‡‡ç”¨äº†æ‰©å±•äº†åäº‹å®åŸå› é‡åŒ–(Quantification over counterfactual causes)çš„è®¤è¯†æ—¶åºé€»è¾‘(Epistemic Temporal Logic)ã€‚è¯¥æ–¹æ³•å…è®¸é€šè¿‡ç³»ç»Ÿçº§éœ€æ±‚æ¥è§„å®šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ˜¯å¦æš´éœ²äº†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿè·å–å…³äºç‰¹å®šæ•ˆæœå‘ç”ŸåŸå› çš„çŸ¥è¯†ã€‚ç ”ç©¶è¿›ä¸€æ­¥æä¾›äº†ä¸€ç§ç®—æ³•ç”¨äºæ ¹æ®æ­¤ç±»è§„èŒƒæ£€æŸ¥æœ‰é™çŠ¶æ€æ¨¡å‹(Finite-state models)ï¼Œå¹¶å¼€å‘äº†åŸå‹å®ç°è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½æœ‰æ•ˆåŒºåˆ†å¯è§£é‡Šç³»ç»Ÿä¸ä¸å¯è§£é‡Šç³»ç»Ÿï¼Œè¿˜å…è®¸åœ¨æ»¡è¶³å¯è§£é‡Šæ€§çš„åŒæ—¶æ–½åŠ é¢å¤–çš„éšç§éœ€æ±‚(Privacy requirements)ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
      "pdf_url": "https://arxiv.org/pdf/2509.01479v2",
      "published_date": "2025-09-01 13:50:52 UTC",
      "updated_date": "2025-09-23 14:27:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:47.654004+00:00"
    },
    {
      "arxiv_id": "2509.01476v3",
      "title": "Do Retrieval Augmented Language Models Know When They Don't Know?",
      "title_zh": "æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹æ˜¯å¦çŸ¥å…¶ä¸çŸ¥ï¼Ÿ",
      "authors": [
        "Youchao Zhou",
        "Heyan Huang",
        "Yicheng Liu",
        "Rui Dai",
        "Xinglin Wang",
        "Xingchen Zhang",
        "Shumin Shi",
        "Yang Deng"
      ],
      "abstract": "Existing large language models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Two main approaches have been proposed to mitigate hallucinations: retrieval-augmented language models (RALMs) and refusal post-training. However, current research predominantly focuses on their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. Ideally, if RALMs know when they do not know, they should refuse to answer.In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we investigate three questions. First, are RALMs well calibrated with respect to different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, when all retrieved documents are irrelevant, RALMs still tend to refuse questions they could have answered correctly. Next, given the model's pronounced \\textbf{over-refusal} behavior, we raise a second question: How does a RALM's refusal ability align with its calibration quality? Our results show that the over-refusal problem can be mitigated through in-context fine-tuning. However, we observe that improved refusal behavior does not necessarily imply better calibration or higher overall accuracy. Finally, we ask: Can we combine refusal-aware RALMs with uncertainty-based answer abstention to mitigate over-refusal? We develop a simple yet effective refusal mechanism for refusal-post-trained RALMs that improves their overall answer quality by balancing refusal and correct answers. Our study provides a more comprehensive understanding of the factors influencing RALM behavior. Meanwhile, we emphasize that uncertainty estimation for RALMs remains an open problem deserving deeper investigation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹(RALMs)æ˜¯å¦å…·å¤‡â€œçŸ¥å…¶ä¸çŸ¥â€çš„èƒ½åŠ›ï¼Œå³åœ¨ç¼ºä¹ç›¸å…³ä¿¡æ¯æ—¶æ˜¯å¦èƒ½æ­£ç¡®æ‹’ç»å›ç­”ã€‚ä½œè€…è°ƒæŸ¥äº†RALMsåœ¨ä¸åŒå†…å¤–éƒ¨çŸ¥è¯†çŠ¶æ€ä¸‹çš„æ ¡å‡†(calibration)æƒ…å†µï¼Œå‘ç°å³ä½¿åœ¨æ£€ç´¢åˆ°çš„æ–‡æ¡£å®Œå…¨æ— å…³æ—¶ï¼Œæ¨¡å‹ä»å€¾å‘äºå¯¹åŸæœ¬èƒ½ç­”å¯¹çš„é—®é¢˜äº§ç”Ÿè¿‡åº¦æ‹’ç»(over-refusal)è¡Œä¸ºã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†æ‹’ç»èƒ½åŠ›ä¸æ ¡å‡†è´¨é‡çš„å¯¹é½å…³ç³»ï¼ŒæŒ‡å‡ºè™½ç„¶ä¸Šä¸‹æ–‡å¾®è°ƒ(in-context fine-tuning)èƒ½ç¼“è§£è¿‡åº¦æ‹’ç»ï¼Œä½†æœªå¿…èƒ½æå‡æ•´ä½“å‡†ç¡®ç‡ã€‚ä¸ºæ­¤ï¼Œè¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§ç»“åˆæ‹’ç»æ„ŸçŸ¥(refusal-aware)å’ŒåŸºäºä¸ç¡®å®šæ€§(uncertainty-based)ç­”æ¡ˆå¼ƒæƒçš„æ–°å‹æ‹’ç»æœºåˆ¶ï¼Œé€šè¿‡å¹³è¡¡æ‹’ç»å’Œæ­£ç¡®å›ç­”æå‡äº†æ¨¡å‹çš„æ•´ä½“è¾“å‡ºè´¨é‡ã€‚è¯¥é¡¹å·¥ä½œä¸ºç†è§£å½±å“RALMè¡Œä¸ºçš„å› ç´ æä¾›äº†å…¨é¢è§†è§’ï¼Œå¹¶å¼ºè°ƒäº†RALMsçš„ä¸ç¡®å®šæ€§ä¼°è®¡(uncertainty estimation)ä»æ˜¯ä¸€ä¸ªå€¼å¾—æ·±ç©¶çš„å¼€æ”¾æ€§é—®é¢˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2026 camera ready version. Extended version with Appendix is coming soon",
      "pdf_url": "https://arxiv.org/pdf/2509.01476v3",
      "published_date": "2025-09-01 13:44:15 UTC",
      "updated_date": "2025-11-18 02:40:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:54:48.947253+00:00"
    },
    {
      "arxiv_id": "2509.02624v1",
      "title": "Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement",
      "title_zh": "è°æ‹¥æœ‰æœºå™¨äººï¼Ÿï¼šé€šè¿‡ç¤¾åŒºå‚ä¸æ¢è®¨ç°å®ä¸–ç•Œä¸­ç¦ç¥‰æœºå™¨äººçš„å››ä¸ªä¼¦ç†ä¸ç¤¾ä¼šæŠ€æœ¯é—®é¢˜",
      "authors": [
        "Minja Axelsson",
        "Jiaee Cheong",
        "Rune Nyrup",
        "Hatice Gunes"
      ],
      "abstract": "Recent studies indicate that robotic coaches can play a crucial role in promoting wellbeing. However, the real-world deployment of wellbeing robots raises numerous ethical and socio-technical questions and concerns. To explore these questions, we undertake a community-centered investigation to examine three different communities' perspectives on using robotic wellbeing coaches in real-world environments. We frame our work as an anticipatory ethical investigation, which we undertake to better inform the development of robotic technologies with communities' opinions, with the ultimate goal of aligning robot development with public interest. We conducted workshops with three communities who are under-represented in robotics development: 1) members of the public at a science festival, 2) women computer scientists at a conference, and 3) humanities researchers interested in history and philosophy of science. In the workshops, we collected qualitative data using the Social Robot Co-Design Canvas on Ethics. We analysed the collected qualitative data with Thematic Analysis, informed by notes taken during workshops. Through our analysis, we identify four themes regarding key ethical and socio-technical questions about the real-world use of wellbeing robots. We group participants' insights and discussions around these broad thematic questions, discuss them in light of state-of-the-art literature, and highlight areas for future investigation. Finally, we provide the four questions as a broad framework that roboticists can and should use during robotic development and deployment, in order to reflect on the ethics and socio-technical dimensions of their robotic applications, and to engage in dialogue with communities of robot users. The four questions are: 1) Is the robot safe and how can we know that?, 2) Who is the robot built for and with?, 3) Who owns the robot and the data?, and 4) Why a robot?.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† wellbeing æœºå™¨äººåœ¨ç°å®éƒ¨ç½²ä¸­é¢ä¸´çš„ä¼¦ç†å’Œç¤¾ä¼šæŠ€æœ¯ï¼ˆsocio-technicalï¼‰æŒ‘æˆ˜ï¼Œæ—¨åœ¨é€šè¿‡ç¤¾åŒºå‚ä¸ï¼ˆCommunity Engagementï¼‰ä½¿æŠ€æœ¯å¼€å‘ä¸å…¬ä¼—åˆ©ç›Šä¿æŒä¸€è‡´ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸å…¬ä¼—ã€å¥³æ€§è®¡ç®—æœºç§‘å­¦å®¶åŠäººæ–‡ç ”ç©¶äººå‘˜å¼€å±•å·¥ä½œåŠï¼Œåˆ©ç”¨ Social Robot Co-Design Canvas on Ethics æ”¶é›†å®šæ€§æ•°æ®ï¼Œå¹¶ç»“åˆä¸»é¢˜åˆ†æï¼ˆThematic Analysisï¼‰æç‚¼æ ¸å¿ƒè®®é¢˜ã€‚ç ”ç©¶è¯†åˆ«å¹¶å½’çº³äº†å››ä¸ªå…³é”®çš„ä¼¦ç†ä¸ç¤¾ä¼šæŠ€æœ¯é—®é¢˜ï¼Œæ¶µç›–äº†æœºå™¨äººçš„å®‰å…¨æ€§éªŒè¯ã€å¼€å‘å—ä¼—ä¸åä½œå…³ç³»ã€æœºå™¨äººåŠå…¶æ•°æ®çš„æ‰€æœ‰æƒå½’å±ï¼Œä»¥åŠä½¿ç”¨æœºå™¨äººçš„æ ¹æœ¬åŠ¨å› ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶ä¸ºæœºå™¨äººä¸“å®¶æä¾›äº†ä¸€ä¸ªå®è·µæ¡†æ¶ï¼Œç”¨äºåœ¨å¼€å‘å’Œéƒ¨ç½²é˜¶æ®µåæ€åº”ç”¨ç»´åº¦å¹¶ä¸ç”¨æˆ·ç¤¾åŒºè¿›è¡Œæ·±å…¥å¯¹è¯ã€‚è¿™ä¸€æˆæœä¸ä»…æ­ç¤ºäº†å½“å‰é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ï¼Œä¹Ÿä¸ºæ„å»ºæ›´å…·ä¼¦ç†æ„è¯†å’Œç¤¾ä¼šè´£ä»»æ„Ÿçš„æœºå™¨äººç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at the 8th AAAI/ACM Conference on AI, Ethics, and Society. 23 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2509.02624v1",
      "published_date": "2025-09-01 13:38:50 UTC",
      "updated_date": "2025-09-01 13:38:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:03.160442+00:00"
    },
    {
      "arxiv_id": "2509.10501v1",
      "title": "From Noise to Precision: A Diffusion-Driven Approach to Zero-Inflated Precipitation Prediction",
      "title_zh": "ä»å™ªå£°åˆ°ç²¾å‡†ï¼šä¸€ç§æ‰©æ•£é©±åŠ¨çš„é›¶è†¨èƒ€é™æ°´é¢„æµ‹æ–¹æ³•",
      "authors": [
        "Wentao Gao",
        "Jiuyong Li",
        "Lin Liu",
        "Thuc Duy Le",
        "Xiongren Chen",
        "Xiaojing Du",
        "Jixue Liu",
        "Yanchang Zhao",
        "Yun Chen"
      ],
      "abstract": "Zero-inflated data pose significant challenges in precipitation forecasting due to the predominance of zeros with sparse non-zero events. To address this, we propose the Zero Inflation Diffusion Framework (ZIDF), which integrates Gaussian perturbation for smoothing zero-inflated distributions, Transformer-based prediction for capturing temporal patterns, and diffusion-based denoising to restore the original data structure. In our experiments, we use observational precipitation data collected from South Australia along with synthetically generated zero-inflated data. Results show that ZIDF demonstrates significant performance improvements over multiple state-of-the-art precipitation forecasting models, achieving up to 56.7\\% reduction in MSE and 21.1\\% reduction in MAE relative to the baseline Non-stationary Transformer. These findings highlight ZIDF's ability to robustly handle sparse time series data and suggest its potential generalizability to other domains where zero inflation is a key challenge.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é™æ°´é¢„æµ‹ä¸­é›¶å€¼å ä¸»å¯¼ä¸”éé›¶äº‹ä»¶ç¨€ç–å¯¼è‡´çš„é›¶è†¨èƒ€(Zero-inflated)æ•°æ®æŒ‘æˆ˜ï¼Œæå‡ºäº†é›¶è†¨èƒ€æ‰©æ•£æ¡†æ¶(Zero Inflation Diffusion Framework, ZIDF)ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°ç»“åˆäº†ç”¨äºå¹³æ»‘é›¶è†¨èƒ€åˆ†å¸ƒçš„é«˜æ–¯æ‰°åŠ¨(Gaussian perturbation)ã€ç”¨äºæ•æ‰æ—¶é—´æ¨¡å¼çš„Transformeré¢„æµ‹å™¨ä»¥åŠç”¨äºæ¢å¤åŸå§‹æ•°æ®ç»“æ„çš„æ‰©æ•£å»å™ª(diffusion-based denoising)æŠ€æœ¯ã€‚é€šè¿‡åœ¨å—æ¾³å¤§åˆ©äºšè§‚æµ‹é™æ°´æ•°æ®åŠåˆæˆæ•°æ®ä¸Šçš„å®éªŒéªŒè¯ï¼ŒZIDFå±•ç°å‡ºæ˜¾è‘—ä¼˜äºå¤šç§å…ˆè¿›æ¨¡å‹çš„æ€§èƒ½ï¼Œå…¶å‡æ–¹è¯¯å·®(MSE)å’Œå¹³å‡ç»å¯¹è¯¯å·®(MAE)è¾ƒåŸºå‡†æ¨¡å‹Non-stationary Transformeråˆ†åˆ«é™ä½äº†56.7%å’Œ21.1%ã€‚å®éªŒç»“æœè¯æ˜äº†ZIDFåœ¨å¤„ç†ç¨€ç–æ—¶é—´åºåˆ—æ•°æ®æ–¹é¢çš„å¼ºå¤§é²æ£’æ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…æå‡äº†é™æ°´é¢„æµ‹çš„ç²¾åº¦ï¼Œä¹Ÿä¸ºå…¶ä»–å­˜åœ¨é›¶è†¨èƒ€æŒ‘æˆ˜çš„ç§‘å­¦é¢†åŸŸæä¾›äº†å…·æœ‰æ½œåŠ›çš„é€šç”¨è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ECAI 2025 Accepted",
      "pdf_url": "https://arxiv.org/pdf/2509.10501v1",
      "published_date": "2025-09-01 13:37:59 UTC",
      "updated_date": "2025-09-01 13:37:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:04.355504+00:00"
    },
    {
      "arxiv_id": "2509.04492v2",
      "title": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate",
      "title_zh": "åŸºäºè¯å…ƒçº§ç†µäº§ç‡çš„é»‘ç›’ LLM å­¦ä¹ å‹å¹»è§‰æ£€æµ‹",
      "authors": [
        "Charles Moslonka",
        "Hicham Randrianarivo",
        "Arthur Garnier",
        "Emmanuel Malherbe"
      ],
      "abstract": "Hallucinations in Large Language Model (LLM) outputs for Question Answering (QA) tasks can critically undermine their real-world reliability. This paper introduces a methodology for robust, one-shot hallucination detection, specifically designed for scenarios with limited data access, such as interacting with black-box LLM APIs that typically expose only a few top candidate log-probabilities per token. Our approach derives uncertainty indicators directly from these readily available log-probabilities generated during non-greedy decoding. We first derive an Entropy Production Rate (EPR) that offers baseline performance, later augmented with supervised learning. Our learned model leverages the entropic contributions of the accessible top-ranked tokens within a single generated sequence, without multiple re-runs per query. Evaluated across diverse QA datasets and multiple LLMs, this estimator significantly improves token-level hallucination detection over state-of-the-art methods. Crucially, high performance is demonstrated using only the typically small set of available log-probabilities (e.g., top-10 per token), confirming its practical efficiency and suitability for API-constrained deployments. This work provides a lightweight technique to enhance the trustworthiness of LLM responses, at the token level, after a single generation pass, for QA and Retrieval-Augmented Generation (RAG) systems. Our experiments confirmed the performance of our method against existing approaches on public dataset as well as for a financial framework analyzing annual company reports.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹ (Black-Box LLMs) åœ¨é—®ç­”ä»»åŠ¡ä¸­äº§ç”Ÿçš„å¹»è§‰ (Hallucinations) é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè¯å…ƒçº§ç†µäº§ç”Ÿç‡ (Token-level Entropy Production Rate, EPR) çš„ç¨³å¥å•æ¬¡å¹»è§‰æ£€æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¸“é—¨ä¸ºæ•°æ®è®¿é—®å—é™çš„åœºæ™¯è®¾è®¡ï¼Œä»…éœ€åˆ©ç”¨é»‘ç›’ API æä¾›çš„å°‘é‡è¯å…ƒå¯¹æ•°æ¦‚ç‡ (Log-probabilities) å³å¯ç›´æ¥æ¨å¯¼å‡ºä¸ç¡®å®šæ€§æŒ‡æ ‡ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ¨å¯¼å‡º EPR ä½œä¸ºåŸºå‡†ï¼Œéšåç»“åˆç›‘ç£å­¦ä¹ è¿›ä¸€æ­¥å¢å¼ºæ¨¡å‹ï¼Œåˆ©ç”¨å•æ¬¡ç”Ÿæˆåºåˆ—ä¸­é¡¶çº§è¯å…ƒçš„ç†µè´¡çŒ®è¿›è¡Œæ¨ç†ï¼Œè€Œæ— éœ€å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œå¤šæ¬¡é‡å¤è¿è¡Œã€‚åœ¨å¤šç§é—®ç­”æ•°æ®é›†å’Œå¤šç§æ¨¡å‹ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯å…ƒçº§æ£€æµ‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œä¸”åœ¨ä»…è·å–å‰ 10 ä¸ªè¯å…ƒå¯¹æ•°æ¦‚ç‡çš„æƒ…å†µä¸‹ä»èƒ½ä¿æŒé«˜å‡†ç¡®ç‡ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥è¯å®äº†è¯¥æŠ€æœ¯åœ¨åˆ†æå…¬å¸å¹´æŠ¥çš„é‡‘èæ¡†æ¶åŠæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿä¸­çš„å®é™…åº”ç”¨ä»·å€¼ï¼Œä¸ºæå‡æ¨¡å‹å“åº”çš„å¯ä¿¡åº¦æä¾›äº†ä¸€ç§é«˜æ•ˆã€è½»é‡çº§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures, 2 tables. pre-print version",
      "pdf_url": "https://arxiv.org/pdf/2509.04492v2",
      "published_date": "2025-09-01 13:34:21 UTC",
      "updated_date": "2026-01-20 15:36:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:02.561102+00:00"
    },
    {
      "arxiv_id": "2509.01441v1",
      "title": "LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance",
      "title_zh": "æœåŠ¡ç”Ÿæ€æ²»ç†ä¸­é¢å‘åœºæ™¯ç”Ÿæˆçš„LLMèµ‹èƒ½æ™ºèƒ½ä½“ä»¿çœŸæ¡†æ¶",
      "authors": [
        "Deyu Zhou",
        "Yuqi Hou",
        "Xiao Xue",
        "Xudong Lu",
        "Qingzhong Li",
        "Lizhen Cui"
      ],
      "abstract": "As the social environment is growing more complex and collaboration is deepening, factors affecting the healthy development of service ecosystem are constantly changing and diverse, making its governance a crucial research issue. Applying the scenario analysis method and conducting scenario rehearsals by constructing an experimental system before managers make decisions, losses caused by wrong decisions can be largely avoided. However, it relies on predefined rules to construct scenarios and faces challenges such as limited information, a large number of influencing factors, and the difficulty of measuring social elements. These challenges limit the quality and efficiency of generating social and uncertain scenarios for the service ecosystem. Therefore, we propose a scenario generator design method, which adaptively coordinates three Large Language Model (LLM) empowered agents that autonomously optimize experimental schemes to construct an experimental system and generate high quality scenarios. Specifically, the Environment Agent (EA) generates social environment including extremes, the Social Agent (SA) generates social collaboration structure, and the Planner Agent (PA) couples task-role relationships and plans task solutions. These agents work in coordination, with the PA adjusting the experimental scheme in real time by perceiving the states of each agent and these generating scenarios. Experiments on the ProgrammableWeb dataset illustrate our method generates more accurate scenarios more efficiently, and innovatively provides an effective way for service ecosystem governance related experimental system construction.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æœåŠ¡ç”Ÿæ€ç³»ç»Ÿæ²»ç†(Service Ecosystem Governance)ä¸­æƒ…æ™¯ç”Ÿæˆé¢ä¸´çš„é¢„å®šä¹‰è§„åˆ™é™åˆ¶å’Œå¤æ‚ç¤¾ä¼šè¦ç´ éš¾ä»¥å»ºæ¨¡çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªé€‚åº”åè°ƒä¸‰ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“æ¥æ„å»ºå®éªŒç³»ç»Ÿï¼šç¯å¢ƒæ™ºèƒ½ä½“(Environment Agent, EA)è´Ÿè´£ç”ŸæˆåŒ…å«æç«¯æƒ…å†µçš„ç¤¾ä¼šç¯å¢ƒï¼Œç¤¾ä¼šæ™ºèƒ½ä½“(Social Agent, SA)æ„å»ºç¤¾ä¼šåä½œç»“æ„ï¼Œè€Œè§„åˆ’æ™ºèƒ½ä½“(Planner Agent, PA)åˆ™è´Ÿè´£è€¦åˆä»»åŠ¡ä¸è§’è‰²å¹¶è§„åˆ’ä»»åŠ¡è§£å†³æ–¹æ¡ˆã€‚è§„åˆ’æ™ºèƒ½ä½“é€šè¿‡å®æ—¶æ„ŸçŸ¥å„æ™ºèƒ½ä½“çŠ¶æ€å’Œç”Ÿæˆæƒ…æ™¯æ¥ä¼˜åŒ–å®éªŒæ–¹æ¡ˆï¼Œç¡®ä¿äº†æƒ…æ™¯ç”Ÿæˆçš„é«˜è´¨é‡ä¸è‡ªé€‚åº”æ€§ã€‚åœ¨ProgrammableWebæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ¯”ä¼ ç»Ÿæ–¹æ³•æ›´é«˜æ•ˆã€æ›´å‡†ç¡®åœ°ç”Ÿæˆé«˜è´¨é‡æƒ…æ™¯ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæœåŠ¡ç”Ÿæ€ç³»ç»Ÿæ²»ç†ç›¸å…³çš„å®éªŒç³»ç»Ÿå»ºè®¾æä¾›äº†ä¸€ç§åˆ›æ–°ä¸”æœ‰æ•ˆçš„è·¯å¾„ï¼Œä½¿ç®¡ç†è€…èƒ½å¤Ÿé€šè¿‡é«˜ä¿çœŸçš„æƒ…æ™¯æ¼”ç»ƒè§„é¿å†³ç­–é£é™©ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01441v1",
      "published_date": "2025-09-01 12:55:02 UTC",
      "updated_date": "2025-09-01 12:55:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:03.358010+00:00"
    },
    {
      "arxiv_id": "2509.01439v1",
      "title": "SoccerHigh: A Benchmark Dataset for Automatic Soccer Video Summarization",
      "title_zh": "SoccerHighï¼šé¢å‘è‡ªåŠ¨è¶³çƒè§†é¢‘æ‘˜è¦çš„åŸºå‡†æ•°æ®é›†",
      "authors": [
        "Artur DÃ­az-Juan",
        "Coloma Ballester",
        "Gloria Haro"
      ],
      "abstract": "Video summarization aims to extract key shots from longer videos to produce concise and informative summaries. One of its most common applications is in sports, where highlight reels capture the most important moments of a game, along with notable reactions and specific contextual events. Automatic summary generation can support video editors in the sports media industry by reducing the time and effort required to identify key segments. However, the lack of publicly available datasets poses a challenge in developing robust models for sports highlight generation. In this paper, we address this gap by introducing a curated dataset for soccer video summarization, designed to serve as a benchmark for the task. The dataset includes shot boundaries for 237 matches from the Spanish, French, and Italian leagues, using broadcast footage sourced from the SoccerNet dataset. Alongside the dataset, we propose a baseline model specifically designed for this task, which achieves an F1 score of 0.3956 in the test set. Furthermore, we propose a new metric constrained by the length of each target summary, enabling a more objective evaluation of the generated content. The dataset and code are available at https://ipcv.github.io/SoccerHigh/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½“è‚²é›†é”¦è‡ªåŠ¨ç”Ÿæˆé¢†åŸŸç¼ºä¹å…¬å¼€æ•°æ®é›†çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º SoccerHigh çš„è¶³çƒè§†é¢‘æ‘˜è¦åŸºå‡†æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«äº†æ¥è‡ªè¥¿ç­ç‰™ã€æ³•å›½å’Œæ„å¤§åˆ©è”èµ›çš„ 237 åœºæ¯”èµ›è§†é¢‘ï¼Œåˆ©ç”¨ SoccerNet æ•°æ®é›†çš„å¹¿æ’­ç´ æå¹¶è¯¦ç»†æ ‡æ³¨äº†é•œå¤´è¾¹ç•Œ(shot boundaries)ã€‚é™¤äº†æ•°æ®é›†å¤–ï¼Œä½œè€…è¿˜æå‡ºäº†ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„åŸºå‡†æ¨¡å‹(baseline model)ï¼Œå…¶åœ¨æµ‹è¯•é›†ä¸Šçš„ F1 score è¾¾åˆ°äº† 0.3956ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§å—ç›®æ ‡æ‘˜è¦é•¿åº¦çº¦æŸçš„æ–°è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å®ç°å¯¹ç”Ÿæˆå†…å®¹çš„æ›´å®¢è§‚è¯„ä»·ã€‚SoccerHigh çš„å‘å¸ƒä¸ºè¶³çƒè§†é¢‘è‡ªåŠ¨æ‘˜è¦æŠ€æœ¯çš„å¼€å‘ä¸è¯„ä¼°æä¾›äº†æ ‡å‡†åŒ–çš„åŸºå‡†ï¼Œæœ‰åŠ©äºæå‡è¯¥é¢†åŸŸæ¨¡å‹çš„ç¨³å¥æ€§å¹¶å‡è½»ä½“è‚²åª’ä½“è¡Œä¸šçš„ç¼–è¾‘è´Ÿæ‹…ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at MMSports 2025 (Dublin, Ireland)",
      "pdf_url": "https://arxiv.org/pdf/2509.01439v1",
      "published_date": "2025-09-01 12:49:51 UTC",
      "updated_date": "2025-09-01 12:49:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:42.685742+00:00"
    },
    {
      "arxiv_id": "2509.01438v1",
      "title": "Unnoticeable Community Deception via Multi-objective Optimization",
      "title_zh": "åŸºäºå¤šç›®æ ‡ä¼˜åŒ–çš„éšè”½ç¤¾åŒºæ¬ºéª—",
      "authors": [
        "Junyuan Fang",
        "Huimin Liu",
        "Yueqi Peng",
        "Jiajing Wu",
        "Zibin Zheng",
        "Chi K. Tse"
      ],
      "abstract": "Community detection in graphs is crucial for understanding the organization of nodes into densely connected clusters. While numerous strategies have been developed to identify these clusters, the success of community detection can lead to privacy and information security concerns, as individuals may not want their personal information exposed. To address this, community deception methods have been proposed to reduce the effectiveness of detection algorithms. Nevertheless, several limitations, such as the rationality of evaluation metrics and the unnoticeability of attacks, have been ignored in current deception methods. Therefore, in this work, we first investigate the limitations of the widely used deception metric, i.e., the decrease of modularity, through empirical studies. Then, we propose a new deception metric, and combine this new metric together with the attack budget to model the unnoticeable community deception task as a multi-objective optimization problem. To further improve the deception performance, we propose two variant methods by incorporating the degree-biased and community-biased candidate node selection mechanisms. Extensive experiments on three benchmark datasets demonstrate the superiority of the proposed community deception strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å›¾æ•°æ®ä¸­ç¤¾åŒºæ£€æµ‹(Community Detection)å¸¦æ¥çš„éšç§ä¸ä¿¡æ¯å®‰å…¨é£é™©ï¼Œå¹¶é’ˆå¯¹ç°æœ‰ç¤¾åŒºæ¬ºéª—(Community Deception)æ–¹æ³•åœ¨è¯„ä¼°æŒ‡æ ‡åˆç†æ€§å’Œæ”»å‡»éšè”½æ€§(Unnoticeability)æ–¹é¢çš„ä¸è¶³æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚ç ”ç©¶é¦–å…ˆé€šè¿‡å®è¯ç ”ç©¶æ­ç¤ºäº†ä¼ ç»ŸæŒ‡æ ‡å¦‚æ¨¡å—åº¦(Modularity)ä¸‹é™åœ¨è¡¡é‡æ¬ºéª—æ•ˆæœæ—¶çš„å±€é™æ€§ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ç§æ–°çš„æ¬ºéª—æŒ‡æ ‡ã€‚é€šè¿‡å°†æ–°æŒ‡æ ‡ä¸æ”»å‡»é¢„ç®—ç›¸ç»“åˆï¼Œè¯¥ç ”ç©¶å°†éšè”½çš„ç¤¾åŒºæ¬ºéª—ä»»åŠ¡å»ºæ¨¡ä¸ºä¸€ä¸ªå¤šç›®æ ‡ä¼˜åŒ–(Multi-objective Optimization)é—®é¢˜ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§ç»“åˆåº¦åå·®(Degree-biased)å’Œç¤¾åŒºåå·®(Community-biased)èŠ‚ç‚¹é€‰æ‹©æœºåˆ¶çš„å˜ä½“æ–¹æ³•ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç­–ç•¥åœ¨æœ‰æ•ˆé™ä½ç¤¾åŒºæ£€æµ‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†æ”»å‡»çš„éšè”½æ€§ä¸ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SI",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.01438v1",
      "published_date": "2025-09-01 12:49:42 UTC",
      "updated_date": "2025-09-01 12:49:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:23.084933+00:00"
    },
    {
      "arxiv_id": "2509.01426v2",
      "title": "DCA: Graph-Guided Deep Embedding Clustering for Brain Atlases",
      "title_zh": "DCAï¼šé¢å‘è„‘å›¾è°±çš„å›¾å¼•å¯¼æ·±åº¦åµŒå…¥èšç±»",
      "authors": [
        "Mo Wang",
        "Kaining Peng",
        "Jingsheng Tang",
        "Hongkai Wen",
        "Quanying Liu"
      ],
      "abstract": "Brain atlases are essential for reducing the dimensionality of neuroimaging data and enabling interpretable analysis. However, most existing atlases are predefined, group-level templates with limited flexibility and resolution. We present Deep Cluster Atlas (DCA), a graph-guided deep embedding clustering framework for generating individualized, voxel-wise brain parcellations. DCA combines a pretrained autoencoder with spatially regularized deep clustering to produce functionally coherent and spatially contiguous regions. Our method supports flexible control over resolution and anatomical scope, and generalizes to arbitrary brain structures. We further introduce a standardized benchmarking platform for atlas evaluation, using multiple large-scale fMRI datasets. Across multiple datasets and scales, DCA outperforms state-of-the-art atlases, improving functional homogeneity by 98.8% and silhouette coefficient by 29%, and achieves superior performance in downstream tasks such as autism diagnosis and cognitive decoding. We also observe that a fine-tuned pretrained model achieves superior results on the corresponding task. Codes and models are available at https://github.com/ncclab-sustech/DCA .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Deep Cluster Atlas (DCA)ï¼Œè¿™æ˜¯ä¸€ä¸ªå›¾å¼•å¯¼çš„æ·±åº¦åµŒå…¥èšç±»æ¡†æ¶(Graph-Guided Deep Embedding Clustering)ï¼Œæ—¨åœ¨ç”Ÿæˆä¸ªä½“åŒ–çš„ä½“ç´ çº§å¤§è„‘åˆ†åŒº(Individualized, Voxel-Wise Brain Parcellations)ä»¥å…‹æœä¼ ç»Ÿé¢„å®šä¹‰æ¨¡æ¿åœ¨çµæ´»æ€§å’Œåˆ†è¾¨ç‡æ–¹é¢çš„å±€é™ã€‚DCAç»“åˆäº†é¢„è®­ç»ƒè‡ªç¼–ç å™¨(Pretrained Autoencoder)ä¸ç©ºé—´æ­£åˆ™åŒ–çš„æ·±åº¦èšç±»ï¼Œç¡®ä¿ç”Ÿæˆçš„åˆ†åŒºåœ¨åŠŸèƒ½ä¸Šå…·æœ‰ç›¸å¹²æ€§ä¸”åœ¨ç©ºé—´ä¸Šä¿æŒè¿ç»­ã€‚è¯¥æ–¹æ³•æ”¯æŒå¯¹åˆ†è¾¨ç‡å’Œè§£å‰–èŒƒå›´çš„çµæ´»æ§åˆ¶ï¼Œå¹¶èƒ½æœ‰æ•ˆæ³›åŒ–è‡³ä»»æ„è„‘ç»“æ„ã€‚é€šè¿‡åœ¨å¤šä¸ªå¤§è§„æ¨¡fMRIæ•°æ®é›†ä¸Šçš„æ ‡å‡†åŒ–è¯„ä¼°ï¼ŒDCAåœ¨åŠŸèƒ½å‡åŒ€æ€§(Functional Homogeneity)å’Œè½®å»“ç³»æ•°(Silhouette Coefficient)ä¸Šåˆ†åˆ«æ¯”ç°æœ‰å°–ç«¯å›¾è°±æå‡äº†98.8%å’Œ29%ã€‚æ­¤å¤–ï¼ŒDCAåœ¨è‡ªé—­ç—‡è¯Šæ–­å’Œè®¤çŸ¥è§£ç ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œè¯æ˜äº†å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹åœ¨æå‡è„‘å›¾è°±åˆ†æè´¨é‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Accepted as a poster at NeurIPS 2025 with scores 5554",
      "pdf_url": "https://arxiv.org/pdf/2509.01426v2",
      "published_date": "2025-09-01 12:33:32 UTC",
      "updated_date": "2025-09-20 09:35:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:31.551090+00:00"
    },
    {
      "arxiv_id": "2509.01399v1",
      "title": "CabinSep: IR-Augmented Mask-Based MVDR for Real-Time In-Car Speech Separation with Distributed Heterogeneous Arrays",
      "title_zh": "CabinSepï¼šåŸºäºåˆ†å¸ƒå¼å¼‚æ„é˜µåˆ—ä¸è„‰å†²å“åº”å¢å¼ºå‹æ©è”½ MVDR çš„å®æ—¶è½¦è½½è¯­éŸ³åˆ†ç¦»",
      "authors": [
        "Runduo Han",
        "Yanxin Hu",
        "Yihui Fu",
        "Zihan Zhang",
        "Yukai Jv",
        "Li Chen",
        "Lei Xie"
      ],
      "abstract": "Separating overlapping speech from multiple speakers is crucial for effective human-vehicle interaction. This paper proposes CabinSep, a lightweight neural mask-based minimum variance distortionless response (MVDR) speech separation approach, to reduce speech recognition errors in back-end automatic speech recognition (ASR) models. Our contributions are threefold: First, we utilize channel information to extract spatial features, which improves the estimation of speech and noise masks. Second, we employ MVDR during inference, reducing speech distortion to make it more ASR-friendly. Third, we introduce a data augmentation method combining simulated and real-recorded impulse responses (IRs), improving speaker localization at zone boundaries and further reducing speech recognition errors. With a computational complexity of only 0.4 GMACs, CabinSep achieves a 17.5% relative reduction in speech recognition error rate in a real-recorded dataset compared to the state-of-the-art DualSep model. Demos are available at: https://cabinsep.github.io/cabinsep/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CabinSepï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§çš„åŸºäºç¥ç»ç½‘ç»œæ©ç ï¼ˆmask-basedï¼‰çš„æœ€å°æ–¹å·®æ— å¤±çœŸå“åº”ï¼ˆMVDRï¼‰è¯­éŸ³åˆ†ç¦»æ–¹æ³•ï¼Œæ—¨åœ¨é™ä½è½¦å†…å¤šäººè¯­éŸ³é‡å åœºæ™¯ä¸‹çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰é”™è¯¯ç‡ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é€šé“ä¿¡æ¯æå–ç©ºé—´ç‰¹å¾ï¼Œæœ‰æ•ˆæå‡äº†å¯¹è¯­éŸ³å’Œå™ªå£°æ©ç ï¼ˆmasksï¼‰çš„ä¼°è®¡å‡†ç¡®æ€§ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒCabinSep é‡‡ç”¨ MVDR æŠ€æœ¯å‡å°‘è¯­éŸ³å¤±çœŸï¼Œä»è€Œè·å¾—æ›´ç¬¦åˆ ASR æ¨¡å‹éœ€æ±‚çš„éŸ³é¢‘è¾“å…¥ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ç»“åˆæ¨¡æ‹Ÿä¸çœŸå®è„‰å†²å“åº”ï¼ˆIRsï¼‰çš„æ•°æ®å¢å¼ºæ‰‹æ®µï¼Œæ˜¾è‘—æ”¹å–„äº†åŒºåŸŸè¾¹ç•Œå¤„çš„è¯´è¯äººå®šä½æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCabinSep çš„è®¡ç®—å¤æ‚åº¦ä»…ä¸º 0.4 GMACsï¼Œåœ¨çœŸå®å½•åˆ¶æ•°æ®é›†ä¸Šçš„è¯­éŸ³è¯†åˆ«é”™è¯¯ç‡æ¯” SOTA æ¨¡å‹ DualSep ç›¸å¯¹é™ä½äº† 17.5%ï¼Œè¯æ˜äº†å…¶åœ¨åˆ†å¸ƒå¼å¼‚æ„é˜µåˆ—ç¯å¢ƒä¸‹çš„é«˜æ•ˆæ€§ä¸å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by Interspeech 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01399v1",
      "published_date": "2025-09-01 11:50:43 UTC",
      "updated_date": "2025-09-01 11:50:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:32.056904+00:00"
    },
    {
      "arxiv_id": "2509.01398v2",
      "title": "The Need for Verification in AI-Driven Scientific Discovery",
      "title_zh": "AIé©±åŠ¨ç§‘å­¦å‘ç°ä¸­çš„éªŒè¯å¿…è¦æ€§",
      "authors": [
        "Cristina Cornelio",
        "Takuya Ito",
        "Ryan Cory-Wright",
        "Sanjeeb Dash",
        "Lior Horesh"
      ],
      "abstract": "Artificial intelligence (AI) is transforming the practice of science. Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields. However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced. In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents. While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨ç§‘å­¦å‘ç°é¢†åŸŸçš„åº”ç”¨ï¼ŒæŒ‡å‡ºæœºå™¨å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è™½ç„¶æå¤§æå‡äº†å‡è®¾ç”Ÿæˆçš„æ•ˆç‡ï¼Œä½†ä¹Ÿå¸¦æ¥äº†å¦‚ä½•éªŒè¯æµ·é‡å‡è®¾çš„ä¸¥å³»æŒ‘æˆ˜ã€‚æ–‡ç« è¿½æº¯äº†ç§‘å­¦å‘ç°çš„å†å²å‘å±•è¿‡ç¨‹ï¼Œç³»ç»Ÿåœ°è¯„è¿°äº†ä»æ•°æ®é©±åŠ¨æ–¹æ³•ã€çŸ¥è¯†æ„ŸçŸ¥ç¥ç»æ¶æ„(knowledge-aware neural architectures)åˆ°ç¬¦å·æ¨ç†æ¡†æ¶(symbolic reasoning frameworks)ä»¥åŠ LLM agents ç­‰ä¸»æµæŠ€æœ¯è·¯å¾„ã€‚å°½ç®¡è¿™äº› AI ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆæ­ç¤ºæ½œåœ¨æ¨¡å¼å¹¶æå‡ºå€™é€‰ç§‘å­¦å®šå¾‹ï¼Œä½†å…¶å­¦æœ¯ä»·å€¼æœ€ç»ˆä¾èµ–äºä¸¥è°¨ä¸”é€æ˜çš„éªŒè¯(verification)è¿‡ç¨‹ã€‚ä½œè€…å¼ºè°ƒï¼Œä¸ºäº†é˜²æ­¢ç§‘å­¦è¿›æ­¥å› ç¼ºä¹å¯é ä¸”å¯æ‰©å±•çš„éªŒè¯æœºåˆ¶è€Œåœæ»ï¼Œå¿…é¡»å°†éªŒè¯ä½“ç³»ä½œä¸º AI è¾…åŠ©ç§‘å­¦å‘ç°çš„æ ¸å¿ƒåŸºçŸ³ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01398v2",
      "published_date": "2025-09-01 11:50:04 UTC",
      "updated_date": "2025-12-17 13:11:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:32.564452+00:00"
    },
    {
      "arxiv_id": "2509.04491v1",
      "title": "Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR",
      "title_zh": "åŸºäºæç¤ºçš„ ASR å¼±ç›‘ç£è®­ç»ƒï¼šåˆ©ç”¨ç”µè§†å­—å¹•ä¼˜åŒ–è½¬å½•æ–‡æœ¬",
      "authors": [
        "Xinnian Zhao",
        "Hugo Van Hamme"
      ],
      "abstract": "This study proposes a novel approach to using TV subtitles within a weakly supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV subtitles are readily available, their imprecise alignment with corresponding audio limits their applicability as supervised targets for verbatim transcription. Rather than using subtitles as direct supervision signals, our method reimagines them as context-rich prompts. This design enables the model to handle discrepancies between spoken audio and subtitle text. Instead, generated pseudo transcripts become the primary targets, with subtitles acting as guiding cues for iterative refinement. To further enhance the process, we introduce a weighted attention mechanism that emphasizes relevant subtitle tokens during inference. Our experiments demonstrate significant improvements in transcription accuracy, highlighting the effectiveness of the proposed method in refining transcripts. These enhanced pseudo-labeled datasets provide high-quality foundational resources for training robust ASR systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åœ¨å¼±ç›‘ç£ï¼ˆWeakly Supervisedï¼‰è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¡†æ¶ä¸­åˆ©ç”¨ç”µè§†å­—å¹•çš„æ–°æ–¹æ³•ã€‚é’ˆå¯¹ç”µè§†å­—å¹•ä¸éŸ³é¢‘å¯¹é½ä¸ç²¾ç¡®å¯¼è‡´çš„ç›‘ç£å—é™é—®é¢˜ï¼Œè¯¥æ–¹æ³•å°†å­—å¹•é‡æ–°å®šä¹‰ä¸ºå¯Œå«ä¸Šä¸‹æ–‡çš„æç¤ºï¼ˆPromptsï¼‰ï¼Œä»è€Œèƒ½å¤Ÿçµæ´»å¤„ç†è¯­éŸ³ä¸æ–‡æœ¬ä¹‹é—´çš„å·®å¼‚ã€‚ç³»ç»Ÿä»¥ç”Ÿæˆçš„ä¼ªè½¬å½•æœ¬ï¼ˆPseudo transcriptsï¼‰ä¸ºä¸»è¦ç›®æ ‡ï¼Œå°†å­—å¹•ä½œä¸ºå¼•å¯¼çº¿ç´¢è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥äº†åŠ æƒæ³¨æ„åŠ›æœºåˆ¶ï¼ˆWeighted attention mechanismï¼‰ä»¥åœ¨æ¨ç†é˜¶æ®µçªå‡ºç›¸å…³çš„å­—å¹•æ ‡è®°ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†è½¬å½•å‡†ç¡®ç‡ï¼Œé€šè¿‡ç²¾ç‚¼è½¬å½•æ–‡æœ¬ç”Ÿæˆäº†é«˜è´¨é‡çš„ä¼ªæ ‡ç­¾æ•°æ®é›†ã€‚è¿™äº›ç ”ç©¶æˆæœä¸ºæ„å»ºé²æ£’çš„ASRç³»ç»Ÿæä¾›äº†é‡è¦çš„åŸºç¡€èµ„æºæ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "eusipco2025",
      "pdf_url": "https://arxiv.org/pdf/2509.04491v1",
      "published_date": "2025-09-01 11:43:07 UTC",
      "updated_date": "2025-09-01 11:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:40.885516+00:00"
    },
    {
      "arxiv_id": "2509.01396v2",
      "title": "DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks",
      "title_zh": "DeepResearch Arenaï¼šé€šè¿‡åŸºäºç ”è®¨ä¼šçš„ä»»åŠ¡å¯¹å¤§è¯­è¨€æ¨¡å‹ç ”ç©¶èƒ½åŠ›çš„é¦–æ¬¡æµ‹è¯„",
      "authors": [
        "Haiyuan Wan",
        "Chen Yang",
        "Junchi Yu",
        "Meiqi Tu",
        "Jiaxuan Lu",
        "Di Yu",
        "Jianbao Cao",
        "Ben Gao",
        "Jiaqing Xie",
        "Aoran Wang",
        "Wenlong Zhang",
        "Philip Torr",
        "Dongzhan Zhou"
      ],
      "abstract": "Deep research agents have attracted growing attention for their potential to orchestrate multi-stage research workflows, spanning literature synthesis, methodological design, and empirical verification. Despite these strides, evaluating their research capability faithfully is rather challenging due to the difficulty of collecting frontier research questions that genuinely capture researchers' attention and intellectual curiosity. To address this gap, we introduce DeepResearch Arena, a benchmark grounded in academic seminars that capture rich expert discourse and interaction, better reflecting real-world research environments and reducing the risk of data leakage. To automatically construct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task Generation (MAHTG) system that extracts research-worthy inspirations from seminar transcripts. The MAHTG system further translates research-worthy inspirations into high-quality research tasks, ensuring the traceability of research task formulation while filtering noise. With the MAHTG system, we curate DeepResearch Arena with over 10,000 high-quality research tasks from over 200 academic seminars, spanning 12 disciplines, such as literature, history, and science. Our extensive evaluation shows that DeepResearch Arena presents substantial challenges for current state-of-the-art agents, with clear performance gaps observed across different models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Deep research agents åœ¨å¤šé˜¶æ®µç ”ç©¶å·¥ä½œæµä¸­æ½œåŠ›å·¨å¤§ä½†ç¼ºä¹çœŸå®è¯„ä¼°åŸºå‡†çš„ç°çŠ¶ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäºå­¦æœ¯ç ”è®¨ä¼š (academic seminars) çš„è¯„ä¼°åŸºå‡† DeepResearch Arenaã€‚ä¸ºäº†è‡ªåŠ¨æ„å»ºè¯¥åŸºå‡†ï¼Œä½œè€…å¼€å‘äº†å¤šæ™ºèƒ½ä½“å±‚æ¬¡åŒ–ä»»åŠ¡ç”Ÿæˆ (Multi-Agent Hierarchical Task Generation, MAHTG) ç³»ç»Ÿï¼Œèƒ½å¤Ÿä»ç ”è®¨ä¼šè®°å½•ä¸­è‡ªåŠ¨æå–ç ”ç©¶çµæ„Ÿå¹¶å°†å…¶è½¬åŒ–ä¸ºé«˜è´¨é‡ã€å¯è¿½æº¯çš„ç ”ç©¶ä»»åŠ¡ã€‚DeepResearch Arena åŒ…å«äº†æ¥è‡ª 200 å¤šåœºç ”è®¨ä¼šçš„ 10,000 å¤šä¸ªç ”ç©¶ä»»åŠ¡ï¼Œæ¶µç›–äº†æ–‡å­¦ã€å†å²å’Œç§‘å­¦ç­‰ 12 ä¸ªå­¦ç§‘é¢†åŸŸã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè¯¥åŸºå‡†å¯¹å½“å‰æœ€å…ˆè¿›çš„ state-of-the-art æ™ºèƒ½ä½“æå‡ºäº†ä¸¥å³»æŒ‘æˆ˜ï¼Œä¸åŒæ¨¡å‹ä¹‹é—´å±•ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚è¿™ä¸€å·¥ä½œé€šè¿‡æ¨¡æ‹ŸçœŸå®ä¸“å®¶äº’åŠ¨ç¯å¢ƒï¼Œæœ‰æ•ˆé™ä½äº†æ•°æ®æ³„éœ²é£é™©ï¼Œä¸ºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ·±å±‚ç ”ç©¶èƒ½åŠ›æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01396v2",
      "published_date": "2025-09-01 11:42:47 UTC",
      "updated_date": "2025-11-08 05:52:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:55.986660+00:00"
    },
    {
      "arxiv_id": "2509.01395v1",
      "title": "LLMs cannot spot math errors, even when allowed to peek into the solution",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹éš¾ä»¥è¯†åˆ«æ•°å­¦é”™è¯¯ï¼šå³ä¾¿å‡†è®¸å‚è€ƒæ ‡å‡†ç­”æ¡ˆ",
      "authors": [
        "KV Aditya Srivatsa",
        "Kaushal Kumar Maurya",
        "Ekaterina Kochmar"
      ],
      "abstract": "Large language models (LLMs) demonstrate remarkable performance on math word problems, yet they have been shown to struggle with meta-reasoning tasks such as identifying errors in student solutions. In this work, we investigate the challenge of locating the first error step in stepwise solutions using two error reasoning datasets: VtG and PRM800K. Our experiments show that state-of-the-art LLMs struggle to locate the first error step in student solutions even when given access to the reference solution. To that end, we propose an approach that generates an intermediate corrected student solution, aligning more closely with the original student's solution, which helps improve performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å…ƒæ¨ç†(meta-reasoning)ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯è¯†åˆ«å­¦ç”Ÿæ•°å­¦é¢˜è§£ç­”ä¸­é”™è¯¯çš„èƒ½åŠ›ã€‚ç ”ç©¶è€…åˆ©ç”¨ VtG å’Œ PRM800K ä¸¤ä¸ªé”™è¯¯æ¨ç†æ•°æ®é›†ï¼Œæ·±å…¥è°ƒæŸ¥äº†æ¨¡å‹åœ¨å®šä½åˆ†æ­¥è§£ç­”ä¸­ç¬¬ä¸€ä¸ªé”™è¯¯æ­¥éª¤æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿åœ¨å…è®¸å‚è€ƒæ ‡å‡†ç­”æ¡ˆçš„æƒ…å†µä¸‹ï¼Œæœ€å…ˆè¿›çš„ LLMs ä»ç„¶éš¾ä»¥å‡†ç¡®æ‰¾åˆ°å­¦ç”Ÿè§£ç­”ä¸­çš„é¦–ä¸ªé”™è¯¯ç‚¹ã€‚é’ˆå¯¹è¿™ä¸€ç“¶é¢ˆï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ç”Ÿæˆä¸­é—´ä¿®æ­£å­¦ç”Ÿè§£ç­”(intermediate corrected student solution)çš„æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”Ÿæˆå†…å®¹ä¸åŸå§‹å­¦ç”Ÿçš„è§£é¢˜é€»è¾‘æ›´ç´§å¯†å¯¹é½æ¥è¾…åŠ©æ¨ç†ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§å¯¹é½æ–¹æ³•æœ‰æ•ˆæ”¹å–„äº†æ¨¡å‹åœ¨é”™è¯¯å®šä½ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¸ºæå‡ LLMs çš„æ•°å­¦é€»è¾‘ç›‘ç£èƒ½åŠ›æä¾›äº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01395v1",
      "published_date": "2025-09-01 11:41:10 UTC",
      "updated_date": "2025-09-01 11:41:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:52.887366+00:00"
    },
    {
      "arxiv_id": "2509.01388v1",
      "title": "End-to-End Low-Level Neural Control of an Industrial-Grade 6D Magnetic Levitation System",
      "title_zh": "å·¥ä¸šçº§ 6D ç£æ‚¬æµ®ç³»ç»Ÿçš„ç«¯åˆ°ç«¯åº•å±‚ç¥ç»æ§åˆ¶",
      "authors": [
        "Philipp Hartmann",
        "Jannick StranghÃ¶ner",
        "Klaus Neumann"
      ],
      "abstract": "Magnetic levitation is poised to revolutionize industrial automation by integrating flexible in-machine product transport and seamless manipulation. It is expected to become the standard drive for automated manufacturing. However, controlling such systems is inherently challenging due to their complex, unstable dynamics. Traditional control approaches, which rely on hand-crafted control engineering, typically yield robust but conservative solutions, with their performance closely tied to the expertise of the engineering team. In contrast, neural control learning presents a promising alternative. This paper presents the first neural controller for 6D magnetic levitation. Trained end-to-end on interaction data from a proprietary controller, it directly maps raw sensor data and 6D reference poses to coil current commands. The neural controller can effectively generalize to previously unseen situations while maintaining accurate and robust control. These results underscore the practical feasibility of learning-based neural control in complex physical systems and suggest a future where such a paradigm could enhance or even substitute traditional engineering approaches in demanding real-world applications. The trained neural controller, source code, and demonstration videos are publicly available at https://sites.google.com/view/neural-maglev.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šçº§ 6D Magnetic Levitation ç³»ç»Ÿæå‡ºäº†é¦–ä¸ªç«¯åˆ°ç«¯çš„ Neural Controllerï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ§åˆ¶å·¥ç¨‹æ–¹æ¡ˆè¿‡äºä¿å®ˆä¸”é«˜åº¦ä¾èµ–ä¸“å®¶ç»éªŒçš„éš¾é¢˜ã€‚è¯¥æ§åˆ¶å™¨é€šè¿‡åœ¨ä¸“æœ‰æ§åˆ¶å™¨çš„äº¤äº’æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†å°†åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®å’Œ 6D Reference Poses ç›´æ¥æ˜ å°„ä¸ºçº¿åœˆç”µæµæŒ‡ä»¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ Neural Controller åœ¨å¤„ç†æœªè§åœºæ™¯æ—¶å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶èƒ½ç»´æŒç²¾ç¡®ä¸”é²æ£’çš„æ§åˆ¶æ€§èƒ½ã€‚è¿™ä¸€æˆæœä¸ä»…éªŒè¯äº†åŸºäºå­¦ä¹ çš„ç¥ç»ç½‘ç»œæ§åˆ¶åœ¨å¤æ‚ç‰©ç†ç³»ç»Ÿä¸­çš„å®é™…å¯è¡Œæ€§ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨é«˜æ€§èƒ½å·¥ä¸šåº”ç”¨ä¸­åˆ©ç”¨æ­¤ç±»èŒƒå¼å¢å¼ºæˆ–æ›¿ä»£ä¼ ç»Ÿæ§åˆ¶æ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶çš„è®­ç»ƒæ¨¡å‹ã€æºä»£ç åŠæ¼”ç¤ºè§†é¢‘å·²å‘å…¬ä¼—å¼€æ”¾ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "eess.SY",
      "comment": "8 pages, 7 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01388v1",
      "published_date": "2025-09-01 11:33:30 UTC",
      "updated_date": "2025-09-01 11:33:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:02.286964+00:00"
    },
    {
      "arxiv_id": "2509.01375v1",
      "title": "Anomaly detection in network flows using unsupervised online machine learning",
      "title_zh": "åŸºäºæ— ç›‘ç£åœ¨çº¿æœºå™¨å­¦ä¹ çš„ç½‘ç»œæµå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Alberto Miguel-Diez",
        "AdriÃ¡n Campazas-Vega",
        "Ãngel Manuel Guerrero-Higueras",
        "Claudia Ãlvarez-Aparicio",
        "Vicente MatellÃ¡n-Olivera"
      ],
      "abstract": "Nowadays, the volume of network traffic continues to grow, along with the frequency and sophistication of attacks. This scenario highlights the need for solutions capable of continuously adapting, since network behavior is dynamic and changes over time. This work presents an anomaly detection model for network flows using unsupervised machine learning with online learning capabilities. This approach allows the system to dynamically learn the normal behavior of the network and detect deviations without requiring labeled data, which is particularly useful in real-world environments where traffic is constantly changing and labeled data is scarce. The model was implemented using the River library with a One-Class SVM and evaluated on the NF-UNSW-NB15 dataset and its extended version v2, which contain network flows labeled with different attack categories. The results show an accuracy above 98%, a false positive rate below 3.1%, and a recall of 100% in the most advanced version of the dataset. In addition, the low processing time per flow (<0.033 ms) demonstrates the feasibility of the approach for real-time applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œæµé‡æŒç»­å¢é•¿åŠæ”»å‡»æ—¥ç›Šå¤æ‚çš„ç°çŠ¶ï¼Œæå‡ºäº†ä¸€ç§åŸºäºéç›‘ç£åœ¨çº¿æœºå™¨å­¦ä¹ (unsupervised machine learning with online learning)çš„ç½‘ç»œæµå¼‚å¸¸æ£€æµ‹æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ—¨åœ¨åŠ¨æ€å­¦ä¹ ç½‘ç»œçš„æ­£å¸¸è¡Œä¸ºå¹¶æ£€æµ‹åå·®ï¼Œæ— éœ€ä¾èµ–æ ‡è®°æ•°æ®ï¼Œç‰¹åˆ«é€‚ç”¨äºæµé‡ä¸æ–­å˜åŒ–ä¸”æ ‡è®°æ•°æ®ç¨€ç¼ºçš„ç°å®ç¯å¢ƒã€‚æŠ€æœ¯å®ç°ä¸Šï¼Œç ”ç©¶è€…åˆ©ç”¨ River åº“å’Œ One-Class SVM ç®—æ³•æ„å»ºäº†å…·å¤‡æŒç»­é€‚åº”èƒ½åŠ›çš„æ£€æµ‹ç³»ç»Ÿã€‚é€šè¿‡åœ¨ NF-UNSW-NB15 åŠå…¶æ‰©å±•ç‰ˆæœ¬ v2 æ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼Œè¯¥æ¨¡å‹å±•ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œå‡†ç¡®ç‡è¶…è¿‡ 98%ï¼Œè¯¯æŠ¥ç‡(false positive rate)ä½äº 3.1%ï¼Œä¸”å¬å›ç‡(recall)è¾¾åˆ°äº† 100%ã€‚æ­¤å¤–ï¼Œç”±äºæ¯ä¸ªç½‘ç»œæµçš„å¤„ç†æ—¶é—´ä¸è¶³ 0.033 æ¯«ç§’ï¼Œè¯¥æ–¹æ³•å……åˆ†è¯æ˜äº†å…¶åœ¨å®æ—¶åº”ç”¨(real-time applications)åœºæ™¯ä¸­çš„é«˜æ•ˆæ€§ä¸å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 3 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01375v1",
      "published_date": "2025-09-01 11:21:06 UTC",
      "updated_date": "2025-09-01 11:21:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:55:59.794899+00:00"
    },
    {
      "arxiv_id": "2509.01371v1",
      "title": "Uirapuru: Timely Video Analytics for High-Resolution Steerable Cameras on Edge Devices",
      "title_zh": "Uirapuruï¼šé¢å‘è¾¹ç¼˜è®¾å¤‡é«˜åˆ†è¾¨ç‡å¯è½¬å‘æ‘„åƒå¤´çš„å®æ—¶è§†é¢‘åˆ†æ",
      "authors": [
        "Guilherme H. Apostolo",
        "Pablo Bauszat",
        "Vinod Nigade",
        "Henri E. Bal",
        "Lin Wang"
      ],
      "abstract": "Real-time video analytics on high-resolution cameras has become a popular technology for various intelligent services like traffic control and crowd monitoring. While extensive work has been done on improving analytics accuracy with timing guarantees, virtually all of them target static viewpoint cameras. In this paper, we present Uirapuru, a novel framework for real-time, edge-based video analytics on high-resolution steerable cameras. The actuation performed by those cameras brings significant dynamism to the scene, presenting a critical challenge to existing popular approaches such as frame tiling. To address this problem, Uirapuru incorporates a comprehensive understanding of camera actuation into the system design paired with fast adaptive tiling at a per-frame level. We evaluate Uirapuru on a high-resolution video dataset, augmented by pan-tilt-zoom (PTZ) movements typical for steerable cameras and on real-world videos collected from an actual PTZ camera. Our experimental results show that Uirapuru provides up to 1.45x improvement in accuracy while respecting specified latency budgets or reaches up to 4.53x inference speedup with on-par accuracy compared to state-of-the-art static camera approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜åˆ†è¾¨ç‡ steerable cameras åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®æ—¶è§†é¢‘åˆ†æé—®é¢˜ï¼Œæå‡ºäº† Uirapuru æ¡†æ¶ã€‚ä¼ ç»Ÿçš„è§†é¢‘åˆ†ææ–¹æ³•ä¸»è¦é’ˆå¯¹é™æ€è§†è§’æ‘„åƒå¤´ï¼Œè€Œ steerable cameras çš„ Pan-Tilt-Zoom (PTZ) è¿åŠ¨å¸¦æ¥çš„åœºæ™¯åŠ¨æ€æ€§å¯¹ç°æœ‰çš„ frame tiling ç­‰æŠ€æœ¯æ„æˆäº†æ˜¾è‘—æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒUirapuru å°†å¯¹ camera actuation çš„å…¨é¢ç†è§£èå…¥ç³»ç»Ÿè®¾è®¡ï¼Œå¹¶ç»“åˆäº†æ¯å¸§çº§åˆ«çš„ fast adaptive tiling æŠ€æœ¯ã€‚ç ”ç©¶äººå‘˜åœ¨åŒ…å«å…¸å‹ PTZ è¿åŠ¨çš„é«˜åˆ†è¾¨ç‡è§†é¢‘æ•°æ®é›†ä»¥åŠçœŸå®ç¯å¢ƒé‡‡é›†çš„è§†é¢‘ä¸Šå¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨éµå®ˆå»¶è¿Ÿé¢„ç®—çš„å‰æä¸‹ï¼ŒUirapuru çš„å‡†ç¡®ç‡æ¯”æœ€å…ˆè¿›çš„é™æ€æ‘„åƒå¤´æ–¹æ³•æé«˜äº† 1.45 å€ã€‚æ­¤å¤–ï¼Œåœ¨ä¿æŒåŒç­‰å‡†ç¡®ç‡çš„æƒ…å†µä¸‹ï¼Œè¯¥æ¡†æ¶å®ç°äº†é«˜è¾¾ 4.53 å€çš„ inference speedupï¼Œä¸ºå¯æ“æ§æ‘„åƒå¤´çš„å®æ—¶æ™ºèƒ½æœåŠ¡æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01371v1",
      "published_date": "2025-09-01 11:18:30 UTC",
      "updated_date": "2025-09-01 11:18:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:33.799282+00:00"
    },
    {
      "arxiv_id": "2509.01354v1",
      "title": "DPF-CM: A Data Processing Framework with Privacy-Preserving Vector Databases for Chinese Medical LLMs Training and Deployment",
      "title_zh": "DPF-CMï¼šé¢å‘ä¸­æ–‡åŒ»å­¦å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒä¸éƒ¨ç½²çš„éšç§ä¿æŠ¤å‘é‡æ•°æ®åº“æ•°æ®å¤„ç†æ¡†æ¶",
      "authors": [
        "Wei Huang",
        "Anda Cheng",
        "Zhao Zhang",
        "Yinggui Wang"
      ],
      "abstract": "Current open-source training pipelines for Chinese medical language models predominantly emphasize optimizing training methodologies to enhance the performance of large language models (LLMs), yet lack comprehensive exploration into training data processing. To address this gap, we propose DPF-CM, a holistic Data Processing Framework for Chinese Medical LLMs training and deployment. DPF-CM comprises two core modules. The first module is a data processing pipeline tailored for model training. Beyond standard data processing operations, we (1) introduce a chained examples context-learning strategy to generate question-oriented instructions to mitigate the lack of instruction content, and (2) implement an ensemble-based filtering mechanism for preference data curation that averages multiple reward models to suppress noisy samples. The second module focuses on privacy preservation during model deployment. To prevent privacy risks from the inadvertent exposure of training data, we propose a Privacy Preserving Vector Database (PPVD) approach, which involves model memory search, high-risk database construction, secure database construction, and match-and-replace, four key stages to minimize privacy leakage during inference collectively. Experimental results show that DPF-CM significantly improves model accuracy, enabling our trained Chinese medical LLM to achieve state-of-the-art performance among open-source counterparts. Moreover, the framework reduces training data privacy leakage by 27%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DPF-CMï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸­æ–‡åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ (Chinese Medical LLMs) è®­ç»ƒå’Œéƒ¨ç½²çš„å…¨é¢æ•°æ®å¤„ç†æ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰å¼€æºæµç¨‹åœ¨æ•°æ®å¤„ç†ç ”ç©¶æ–¹é¢çš„ç©ºç™½ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œé¦–å…ˆæ˜¯å®šåˆ¶åŒ–çš„æ¨¡å‹è®­ç»ƒæ•°æ®æµæ°´çº¿ï¼Œé€šè¿‡é“¾å¼ç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ ç­–ç•¥ (chained examples context-learning strategy) ç”Ÿæˆé«˜è´¨é‡æŒ‡ä»¤ï¼Œå¹¶åˆ©ç”¨åŸºäºé›†æˆçš„è¿‡æ»¤æœºåˆ¶ (ensemble-based filtering mechanism) ä¼˜åŒ–åå¥½æ•°æ®ã€‚å…¶æ¬¡ï¼Œé’ˆå¯¹éƒ¨ç½²é˜¶æ®µçš„éšç§é£é™©ï¼Œç ”ç©¶æå‡ºäº†éšç§ä¿æŠ¤å‘é‡æ•°æ®åº“ (Privacy Preserving Vector Database, PPVD) æ–¹æ¡ˆï¼Œé€šè¿‡æ¨¡å‹è®°å¿†æœç´¢ã€é«˜é£é™©æ•°æ®åº“æ„å»ºåŠå®‰å…¨åŒ¹é…æ›¿æ¢ç­‰æŠ€æœ¯æœ€å°åŒ–æ¨ç†è¿‡ç¨‹ä¸­çš„éšç§æ³„éœ²ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDPF-CM æ˜¾è‘—æå‡äº†æ¨¡å‹å‡†ç¡®ç‡ï¼Œä½¿æ‰€è®­ç»ƒçš„æ¨¡å‹åœ¨å¼€æºä¸­æ–‡åŒ»ç–— LLMs ä¸­è¾¾åˆ° state-of-the-art æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æˆåŠŸå°†è®­ç»ƒæ•°æ®çš„éšç§æ³„éœ²é£é™©é™ä½äº† 27%ï¼Œä¸ºåŒ»ç–—å¤§æ¨¡å‹çš„å®‰å…¨åº”ç”¨æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01354v1",
      "published_date": "2025-09-01 10:49:32 UTC",
      "updated_date": "2025-09-01 10:49:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:27.697372+00:00"
    },
    {
      "arxiv_id": "2509.01352v1",
      "title": "Causal Sensitivity Identification using Generative Learning",
      "title_zh": "åŸºäºç”Ÿæˆå¼å­¦ä¹ çš„å› æœæ•æ„Ÿæ€§è¯†åˆ«",
      "authors": [
        "Soma Bandyopadhyay",
        "Sudeshna Sarkar"
      ],
      "abstract": "In this work, we propose a novel generative method to identify the causal impact and apply it to prediction tasks. We conduct causal impact analysis using interventional and counterfactual perspectives. First, applying interventions, we identify features that have a causal influence on the predicted outcome, which we refer to as causally sensitive features, and second, applying counterfactuals, we evaluate how changes in the cause affect the effect. Our method exploits the Conditional Variational Autoencoder (CVAE) to identify the causal impact and serve as a generative predictor. We are able to reduce confounding bias by identifying causally sensitive features. We demonstrate the effectiveness of our method by recommending the most likely locations a user will visit next in their spatiotemporal trajectory influenced by the causal relationships among various features. Experiments on the large-scale GeoLife [Zheng et al., 2010] dataset and the benchmark Asia Bayesian network validate the ability of our method to identify causal impact and improve predictive performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ç”Ÿæˆå­¦ä¹ è¿›è¡Œå› æœæ•æ„Ÿæ€§è¯†åˆ«çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨å‡†ç¡®è¯†åˆ«å› æœå½±å“å¹¶å°†å…¶åº”ç”¨äºé¢„æµ‹ä»»åŠ¡ã€‚ç ”ç©¶ä»å¹²é¢„(Interventional)å’Œåå‘äº‹å®(Counterfactual)çš„åŒé‡è§†è§’å±•å¼€ï¼Œé¦–å…ˆé€šè¿‡å¹²é¢„è¯†åˆ«å¯¹é¢„æµ‹ç»“æœå…·æœ‰å› æœå½±å“çš„å› æœæ•æ„Ÿç‰¹å¾(Causally Sensitive Features)ï¼Œéšååˆ©ç”¨åå‘äº‹å®è¯„ä¼°åŸå› å˜é‡çš„å˜åŒ–å¯¹ç»“æœçš„å…·ä½“å½±å“ã€‚è¯¥æ–¹æ³•æ ¸å¿ƒåœ¨äºåˆ©ç”¨æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨(Conditional Variational Autoencoder, CVAE)ä½œä¸ºç”Ÿæˆå¼é¢„æµ‹å™¨ï¼Œé€šè¿‡è¯†åˆ«å› æœæ•æ„Ÿç‰¹å¾æ¥æœ‰æ•ˆå‡å°‘æ··æ·†åè¯¯(Confounding Bias)ã€‚ç ”ç©¶é€šè¿‡åœ¨ç”¨æˆ·æ—¶ç©ºè½¨è¿¹ä¸­æ¨èä¸‹ä¸€ä¸ªè®¿é—®åœ°ç‚¹æ¥éªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œå®éªŒåœ¨å¤§å‹GeoLifeæ•°æ®é›†å’ŒåŸºå‡†Asia Bayesian networkä¸Šè¿›è¡Œã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«å› æœå½±å“ï¼Œè¿˜èƒ½æ˜¾è‘—æå‡æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, Accepted at the IJCAI 2025 Workshop on Causal Learning for Recommendation Systems (CLRS). [OpenReview link: https://openreview.net/pdf?id=f5cR7BzBSx ]",
      "pdf_url": "https://arxiv.org/pdf/2509.01352v1",
      "published_date": "2025-09-01 10:42:44 UTC",
      "updated_date": "2025-09-01 10:42:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:32.385277+00:00"
    },
    {
      "arxiv_id": "2509.06984v2",
      "title": "FediLoRA: Heterogeneous LoRA for Federated Multimodal Fine-tuning under Missing Modalities",
      "title_zh": "FediLoRAï¼šé¢å‘æ¨¡æ€ç¼ºå¤±åœºæ™¯ä¸‹è”é‚¦å¤šæ¨¡æ€å¾®è°ƒçš„å¼‚æ„LoRA",
      "authors": [
        "Lishan Yang",
        "Wei Emma Zhang",
        "Nam Kha Nguygen",
        "Po Hu",
        "Yanjun Shu",
        "Weitong Chen",
        "Mong Yuan Sim"
      ],
      "abstract": "Foundation models have demonstrated remarkable performance across a wide range of tasks, yet their large parameter sizes pose challenges for practical deployment, especially in decentralized environments. Parameter-efficient fine-tuning (PEFT), such as Low-Rank Adaptation (LoRA), reduces local computing and memory overhead, making it attractive for federated learning. However, existing federated LoRA methods typically assume uniform rank configurations and unimodal inputs, overlooking two key real-world challenges: (1) heterogeneous client resources have different LoRA ranks, and (2) multimodal data settings with potentially missing modalities. In this work, we propose FediLoRA, a simple yet effective framework for federated multimodal fine-tuning under heterogeneous LoRA ranks and missing modalities. FediLoRA introduces a dimension-wise aggregation strategy that reweights LoRA updates without information dilution during aggregation. It also includes a lightweight layer-wise model editing method that selectively incorporates global parameters to repair local components which improves both client and global model performances. Experimental results on three multimodal benchmark datasets demonstrate that FediLoRA achieves superior performance over competitive baselines in both global and personalized settings, particularly in the presence of modality incompleteness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FediLoRA æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è”é‚¦å­¦ä¹ ä¸­åŸºç¡€æ¨¡å‹å¾®è°ƒé¢ä¸´çš„å®¢æˆ·ç«¯èµ„æºå¼‚æ„ä»¥åŠå¤šæ¨¡æ€æ•°æ®ç¼ºå¤±çš„åŒé‡æŒ‘æˆ˜ã€‚é’ˆå¯¹ä¸åŒå®¢æˆ·ç«¯å…·æœ‰ä¸åŒ LoRA ç§© (LoRA ranks) çš„æƒ…å†µï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§ç»´åº¦æ„ŸçŸ¥èšåˆ (dimension-wise aggregation) ç­–ç•¥ï¼Œé€šè¿‡é‡æ–°åŠ æƒæ›´æ–°é‡æ¥é¿å…èšåˆè¿‡ç¨‹ä¸­çš„ä¿¡æ¯ç¨€é‡Šã€‚æ­¤å¤–ï¼ŒFediLoRA åŒ…å«ä¸€ç§è½»é‡çº§çš„é€å±‚æ¨¡å‹ç¼–è¾‘ (layer-wise model editing) æ–¹æ³•ï¼Œé€šè¿‡é€‰æ‹©æ€§åœ°æ•´åˆå…¨å±€å‚æ•°æ¥ä¿®å¤æœ¬åœ°ç»„ä»¶ï¼Œä»è€Œæå‡æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœåœ¨ä¸‰ä¸ªå¤šæ¨¡æ€åŸºå‡†æ•°æ®é›†ä¸Šè¯æ˜ï¼ŒFediLoRA åœ¨å…¨å±€å’Œä¸ªæ€§åŒ–è®¾ç½®ä¸­å‡ä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯åœ¨é¢å¯¹æ¨¡æ€ä¸å®Œæ•´ (modality incompleteness) çš„å®é™…åœºæ™¯æ—¶ï¼Œè¯¥æ–¹æ³•å±•ç°äº†å“è¶Šçš„é²æ£’æ€§ä¸å‡†ç¡®ç‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹è”é‚¦å¾®è°ƒæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.06984v2",
      "published_date": "2025-09-01 10:40:13 UTC",
      "updated_date": "2025-09-23 04:55:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:37.358891+00:00"
    },
    {
      "arxiv_id": "2509.01350v2",
      "title": "Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models",
      "title_zh": "åŸºäºé”™è¯¯ç¬”è®°æœ¬å¼•å¯¼ä¸è§†è§‰è¯­è¨€æ¨¡å‹çš„ 3D CAD è£…é…ä½“å…è®­ç»ƒé›¶ä»¶æ£€ç´¢",
      "authors": [
        "Yunqing Liu",
        "Nan Zhang",
        "Zhiming Tan"
      ],
      "abstract": "Effective specification-aware part retrieval within complex CAD assemblies is essential for automated design verification and downstream engineering tasks. However, directly using LLMs/VLMs to this task presents some challenges: the input sequences may exceed model token limits, and even after processing, performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires significant computational resources, and for many high-performing general-use proprietary models (e.g., GPT or Gemini), fine-tuning access is not available. In this paper, we propose a novel part retrieval framework that requires no extra training, but using Error Notebooks + RAG for refined prompt engineering to help improve the existing general model's retrieval performance. The construction of Error Notebooks consists of two steps: (1) collecting historical erroneous CoTs and their incorrect answers, and (2) connecting these CoTs through reflective corrections until the correct solutions are obtained. As a result, the Error Notebooks serve as a repository of tasks along with their corrected CoTs and final answers. RAG is then employed to retrieve specification-relevant records from the Error Notebooks and incorporate them into the inference process. Another major contribution of our work is a human-in-the-loop CAD dataset, which is used to evaluate our method. In addition, the engineering value of our novel framework lies in its ability to effectively handle 3D models with lengthy, non-natural language metadata. Experiments with proprietary models, including GPT-4o and the Gemini series, show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute accuracy improvement on the human preference dataset. Moreover, ablation studies confirm that CoT reasoning provides benefits especially in challenging cases with higher part counts (>10).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ 3D CAD ç»„è£…ä½“ä¸­é›¶ä»¶æ£€ç´¢ä»»åŠ¡é¢ä¸´çš„ token é™åˆ¶åŠæ¨¡å‹å‡†ç¡®ç‡ä½ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„é›¶ä»¶æ£€ç´¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºæ„å»º Error Notebooksï¼Œé€šè¿‡æ”¶é›†å†å²é”™è¯¯çš„ Chain-of-Thought (CoT) åŠå…¶åå°„å¼ä¿®æ­£è¿‡ç¨‹ï¼Œå½¢æˆä¸€ä¸ªåŒ…å«æ­£ç¡®æ¨ç†è·¯å¾„å’Œç­”æ¡ˆçš„çŸ¥è¯†åº“ã€‚ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯ï¼Œç³»ç»Ÿèƒ½å¤Ÿä»è¯¥çŸ¥è¯†åº“ä¸­æå–ç›¸å…³è®°å½•è¾…åŠ©æ¨ç†ï¼Œä»è€Œæ˜¾è‘—ä¼˜åŒ–ç°æœ‰é€šç”¨ Vision-Language Models (VLMs) çš„æ£€ç´¢æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è´¡çŒ®äº†ä¸€ä¸ª human-in-the-loop CAD æ•°æ®é›†ï¼Œå¹¶è¯æ˜äº†è¯¥æ–¹æ¡ˆåœ¨å¤„ç†å«æœ‰é•¿æ–‡æœ¬å…ƒæ•°æ®çš„ 3D æ¨¡å‹æ—¶çš„å·¥ç¨‹ä»·å€¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä½¿ GPT-4o åœ¨äººç±»åå¥½æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æå‡äº† 23.4%ï¼Œä¸”æ¶ˆèå®éªŒè¯å®åœ¨é›¶ä»¶æ•°é‡è¶…è¿‡ 10 ä¸ªçš„å¤æ‚åœºæ™¯ä¸­ï¼ŒCoT æ¨ç†è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01350v2",
      "published_date": "2025-09-01 10:39:37 UTC",
      "updated_date": "2025-09-08 02:22:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:36.084225+00:00"
    },
    {
      "arxiv_id": "2509.01348v2",
      "title": "Advanced Torrential Loss Function for Precipitation Forecasting",
      "title_zh": "ç”¨äºé™æ°´é¢„æŠ¥çš„é«˜çº§æš´é›¨æŸå¤±å‡½æ•°",
      "authors": [
        "Jaeho Choi",
        "Hyeri Kim",
        "Kwang-Ho Kim",
        "Jaesung Lee"
      ],
      "abstract": "Accurate precipitation forecasting is becoming increasingly important in the context of climate change. In response, machine learning-based approaches have recently gained attention as an emerging alternative to traditional methods such as numerical weather prediction and climate models. Nonetheless, many recent approaches still rely on off-the-shelf loss functions, and even the more advanced ones merely involve optimization processes based on the critical success index (CSI). The problem, however, is that CSI may become ineffective during extended dry periods when precipitation remains below the threshold, rendering it less than ideal as a criterion for optimization. To address this limitation, we introduce a simple penalty expression and reinterpret it as a quadratic unconstrained binary optimization (QUBO) formulation. Ultimately, the resulting QUBO formulation is relaxed into a differentiable advanced torrential (AT) loss function through an approximation process. The proposed AT loss demonstrates its superiority through the Lipschitz constant, forecast performance evaluations, consistency experiments, and ablation studies with the operational model.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é™æ°´é¢„æŠ¥(Precipitation Forecasting)é¢†åŸŸä¸­ç°æœ‰æœºå™¨å­¦ä¹ æ–¹æ³•è¿‡åº¦ä¾èµ–CSI(Critical Success Index)å¯¼è‡´åœ¨å¹²æ—±æœŸä¼˜åŒ–å¤±æ•ˆçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§Advanced Torrential (AT) losså‡½æ•°ã€‚ç ”ç©¶è€…é€šè¿‡å¼•å…¥ç®€å•çš„æƒ©ç½šé¡¹å¹¶å°†å…¶é‡æ–°è¡¨è¿°ä¸ºQUBO(Quadratic Unconstrained Binary Optimization)å…¬å¼ï¼Œç»è¿‡è¿‘ä¼¼å¤„ç†æœ€ç»ˆå¾—åˆ°å¯å¾®åˆ†çš„ATæŸå¤±å‡½æ•°ã€‚å®éªŒé€šè¿‡Lipschitz constantåˆ†æã€é¢„æŠ¥æ€§èƒ½è¯„ä¼°å’Œä¸€è‡´æ€§å®éªŒï¼Œå……åˆ†è¯æ˜äº†AT lossåœ¨é™æ°´é¢„æŠ¥ä¸­çš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œä¸ä¸šåŠ¡æ¨¡å‹çš„æ¶ˆèå®éªŒè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚è¯¥æˆæœæˆåŠŸå…‹æœäº†ä¼ ç»Ÿä¼˜åŒ–æŒ‡æ ‡åœ¨é™æ°´ä½äºé˜ˆå€¼æ—¶çš„å±€é™æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é¢„æŠ¥è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Physical Review Letters",
      "pdf_url": "https://arxiv.org/pdf/2509.01348v2",
      "published_date": "2025-09-01 10:38:13 UTC",
      "updated_date": "2025-11-14 00:32:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:44.448785+00:00"
    },
    {
      "arxiv_id": "2509.01341v1",
      "title": "Street-Level Geolocalization Using Multimodal Large Language Models and Retrieval-Augmented Generation",
      "title_zh": "åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆçš„è¡—é“çº§åœ°ç†å®šä½",
      "authors": [
        "Yunus Serhat Bicakci",
        "Joseph Shingleton",
        "Anahid Basiri"
      ],
      "abstract": "Street-level geolocalization from images is crucial for a wide range of essential applications and services, such as navigation, location-based recommendations, and urban planning. With the growing popularity of social media data and cameras embedded in smartphones, applying traditional computer vision techniques to localize images has become increasingly challenging, yet highly valuable. This paper introduces a novel approach that integrates open-weight and publicly accessible multimodal large language models with retrieval-augmented generation. The method constructs a vector database using the SigLIP encoder on two large-scale datasets (EMP-16 and OSV-5M). Query images are augmented with prompts containing both similar and dissimilar geolocation information retrieved from this database before being processed by the multimodal large language models. Our approach has demonstrated state-of-the-art performance, achieving higher accuracy compared against three widely used benchmark datasets (IM2GPS, IM2GPS3k, and YFCC4k). Importantly, our solution eliminates the need for expensive fine-tuning or retraining and scales seamlessly to incorporate new data sources. The effectiveness of retrieval-augmented generation-based multimodal large language models in geolocation estimation demonstrated by this paper suggests an alternative path to the traditional methods which rely on the training models from scratch, opening new possibilities for more accessible and scalable solutions in GeoAI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal Large Language Models)ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation)çš„è¡—é“çº§åœ°ç†å®šä½(Street-level geolocalization)æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ SigLIP ç¼–ç å™¨åœ¨ EMP-16 å’Œ OSV-5M å¤§è§„æ¨¡æ•°æ®é›†ä¸Šæ„å»ºå‘é‡æ•°æ®åº“ï¼Œé€šè¿‡æ£€ç´¢ä¸æŸ¥è¯¢å›¾åƒç›¸ä¼¼åŠä¸ç›¸ä¼¼çš„åœ°ç†ä½ç½®ä¿¡æ¯æ¥å¢å¼ºè¾“å…¥æç¤ºè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ IM2GPSã€IM2GPS3k å’Œ YFCC4k ä¸‰ä¸ªä¸»æµåŸºå‡†æ•°æ®é›†ä¸Šå‡å–å¾—äº†å½“å‰æœ€å…ˆè¿›(State-of-the-art)çš„æ€§èƒ½è¡¨ç°ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆæ— éœ€æ˜‚è´µçš„å¾®è°ƒ(Fine-tuning)æˆ–é‡æ–°è®­ç»ƒè¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ— ç¼æ‰©å±•ä»¥çº³å…¥æ–°çš„æ•°æ®æºã€‚è¯¥ç ”ç©¶è¯æ˜äº†åŸºäº RAG çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨åœ°ç†ç©ºé—´äººå·¥æ™ºèƒ½(GeoAI)é¢†åŸŸçš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¼€å‘æ›´æ˜“äºè®¿é—®ä¸”å…·å¤‡é«˜å¯æ‰©å±•æ€§çš„åœ°ç†å®šä½è§£å†³æ–¹æ¡ˆæä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01341v1",
      "published_date": "2025-09-01 10:23:48 UTC",
      "updated_date": "2025-09-01 10:23:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:51.065996+00:00"
    },
    {
      "arxiv_id": "2509.01338v1",
      "title": "Conformal Predictive Monitoring for Multi-Modal Scenarios",
      "title_zh": "é¢å‘å¤šæ¨¡æ€åœºæ™¯çš„ç¬¦åˆæ€§é¢„æµ‹æ€§ç›‘æµ‹",
      "authors": [
        "Francesca Cairoli",
        "Luca Bortolussi",
        "Jyotirmoy V. Deshmukh",
        "Lars Lindemann",
        "Nicola Paoletti"
      ],
      "abstract": "We consider the problem of quantitative predictive monitoring (QPM) of stochastic systems, i.e., predicting at runtime the degree of satisfaction of a desired temporal logic property from the current state of the system. Since computational efficiency is key to enable timely intervention against predicted violations, several state-of-the-art QPM approaches rely on fast machine-learning surrogates to provide prediction intervals for the satisfaction values, using conformal inference to offer statistical guarantees. However, these QPM methods suffer when the monitored agent exhibits multi-modal dynamics, whereby certain modes may yield high satisfaction values while others critically violate the property. Existing QPM methods are mode-agnostic and so would yield overly conservative and uninformative intervals that lack meaningful mode-specific satisfaction information. To address this problem, we present GenQPM, a method that leverages deep generative models, specifically score-based diffusion models, to reliably approximate the probabilistic and multi-modal system dynamics without requiring explicit model access. GenQPM employs a mode classifier to partition the predicted trajectories by dynamical mode. For each mode, we then apply conformal inference to produce statistically valid, mode-specific prediction intervals. We demonstrate the effectiveness of GenQPM on a benchmark of agent navigation and autonomous driving tasks, resulting in prediction intervals that are significantly more informative (less conservative) than mode-agnostic baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšæœºç³»ç»Ÿçš„å®šé‡é¢„æµ‹ç›‘æ§ (Quantitative Predictive Monitoring, QPM) æŒ‘æˆ˜ï¼Œæå‡ºäº† GenQPM æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æŠ€æœ¯åœ¨å¤„ç†å¤šæ¨¡æ€ (multi-modal) åŠ¨åŠ›å­¦æ—¶é¢„æµ‹åŒºé—´è¿‡äºä¿å®ˆä¸”ç¼ºä¹ä¿¡æ¯çš„é—®é¢˜ã€‚GenQPM åˆ©ç”¨æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åŸºäºå¾—åˆ†çš„æ‰©æ•£æ¨¡å‹ (score-based diffusion models)ï¼Œåœ¨æ— éœ€æ˜¾å¼æ¨¡å‹è®¿é—®çš„æƒ…å†µä¸‹å¯é åœ°è¿‘ä¼¼ç³»ç»ŸåŠ¨æ€ã€‚è¯¥æ–¹æ³•å¼•å…¥æ¨¡å¼åˆ†ç±»å™¨ (mode classifier) å¯¹é¢„æµ‹è½¨è¿¹è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶å¯¹æ¯ä¸ªæ¨¡å¼åº”ç”¨ç¬¦åˆæ€§æ¨æ–­ (conformal inference) ä»¥ç”Ÿæˆå…·æœ‰ç»Ÿè®¡æœ‰æ•ˆæ€§çš„ç‰¹å®šæ¨¡å¼é¢„æµ‹åŒºé—´ã€‚å®éªŒåœ¨æ™ºèƒ½ä½“å¯¼èˆªå’Œè‡ªåŠ¨é©¾é©¶åŸºå‡†ä»»åŠ¡ä¸Šè¯æ˜äº† GenQPM çš„æœ‰æ•ˆæ€§ï¼Œå…¶ç”Ÿæˆçš„é¢„æµ‹åŒºé—´æ¯”å¿½ç•¥æ¨¡å¼çš„åŸºå‡†æ–¹æ³•æ›´å…·ä¿¡æ¯é‡ä¸”æ˜¾è‘—å‡å°‘äº†ä¿å®ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01338v1",
      "published_date": "2025-09-01 10:19:00 UTC",
      "updated_date": "2025-09-01 10:19:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:59.958056+00:00"
    },
    {
      "arxiv_id": "2509.01337v1",
      "title": "LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ„å›¾è¯†åˆ«çš„å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼è¯­ä¹‰å…³ç³»æ¨ç†",
      "authors": [
        "Qianrui Zhou",
        "Hua Xu",
        "Yifan Wang",
        "Xinzhi Dong",
        "Hanlei Zhang"
      ],
      "abstract": "Understanding human intents from multimodal signals is critical for analyzing human behaviors and enhancing human-machine interactions in real-world scenarios. However, existing methods exhibit limitations in their modality-level reliance, constraining relational reasoning over fine-grained semantics for complex intent understanding. This paper proposes a novel LLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the expansive knowledge of large language models (LLMs) to establish semantic foundations that boost smaller models' relational reasoning performance. Specifically, an LLM-based strategy is proposed to extract fine-grained semantics as guidance for subsequent reasoning, driven by a shallow-to-deep Chain-of-Thought (CoT) that autonomously uncovers, describes, and ranks semantic cues by their importance without relying on manually defined priors. Besides, we formally model three fundamental types of semantic relations grounded in logical principles and analyze their nuanced interplay to enable more effective relational reasoning. Extensive experiments on multimodal intent and dialogue act recognition tasks demonstrate LGSRR's superiority over state-of-the-art methods, with consistent performance gains across diverse semantic understanding scenarios. The complete data and code are available at https://github.com/thuiar/LGSRR.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LLM-Guided Semantic Relational Reasoning (LGSRR)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ„å›¾è¯†åˆ«ä¸­ç°æœ‰æ¨¡å‹å› è¿‡åº¦ä¾èµ–æ¨¡æ€å±‚é¢ä¿¡å·è€Œå¯¼è‡´çš„ç»†ç²’åº¦è¯­ä¹‰å…³ç³»æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„åšå­¦çŸ¥è¯†ä¸ºå°å‹æ¨¡å‹æ„å»ºè¯­ä¹‰åŸºç¡€ï¼Œé€šè¿‡ä¸€ç§ç”±æµ…å…¥æ·±çš„é“¾å¼æ€ç»´ (Chain-of-Thought, CoT) ç­–ç•¥è‡ªåŠ¨æå–ã€æè¿°å¹¶æ’åˆ—è¯­ä¹‰çº¿ç´¢çš„é‡è¦æ€§ï¼Œä»è€Œæ‘†è„±äº†å¯¹äººå·¥å®šä¹‰å…ˆéªŒçŸ¥è¯†çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…åŸºäºé€»è¾‘åŸç†æ­£å¼å»ºæ¨¡äº†ä¸‰ç§åŸºæœ¬è¯­ä¹‰å…³ç³»ï¼Œå¹¶æ·±å…¥åˆ†æå…¶äº¤äº’ä½œç”¨ä»¥æå‡æ¨ç†æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLGSRRåœ¨å¤šæ¨¡æ€æ„å›¾å’Œå¯¹è¯è¡Œä¸ºè¯†åˆ«ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨å¤šç§è¯­ä¹‰ç†è§£åœºæ™¯ä¸‹è¡¨ç°å‡ºç¨³å®šçš„æ€§èƒ½å¢ç›Šã€‚ç›®å‰è¯¥é¡¹ç ”ç©¶çš„æ•°æ®ä¸ä»£ç å·²åœ¨ GitHub å¼€æºã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by EMNLP 2025 (Main Track, Long Paper)",
      "pdf_url": "https://arxiv.org/pdf/2509.01337v1",
      "published_date": "2025-09-01 10:18:47 UTC",
      "updated_date": "2025-09-01 10:18:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:53.757317+00:00"
    },
    {
      "arxiv_id": "2509.01323v1",
      "title": "Multitask Battery Management with Flexible Pretraining",
      "title_zh": "åŸºäºçµæ´»é¢„è®­ç»ƒçš„å¤šä»»åŠ¡ç”µæ± ç®¡ç†",
      "authors": [
        "Hong Lu",
        "Jiali Chen",
        "Jingzhao Zhang",
        "Guannan He",
        "Xuebing Han",
        "Minggao Ouyang"
      ],
      "abstract": "Industrial-scale battery management involves various types of tasks, such as estimation, prediction, and system-level diagnostics. Each task employs distinct data across temporal scales, sensor resolutions, and data channels. Building task-specific methods requires a great deal of data and engineering effort, which limits the scalability of intelligent battery management. Here we present the Flexible Masked Autoencoder (FMAE), a flexible pretraining framework that can learn with missing battery data channels and capture inter-correlations across data snippets. FMAE learns unified battery representations from heterogeneous data and can be adopted by different tasks with minimal data and engineering efforts. Experimentally, FMAE consistently outperforms all task-specific methods across five battery management tasks with eleven battery datasets. On remaining life prediction tasks, FMAE uses 50 times less inference data while maintaining state-of-the-art results. Moreover, when real-world data lack certain information, such as system voltage, FMAE can still be applied with marginal performance impact, achieving comparable results with the best hand-crafted features. FMAE demonstrates a practical route to a flexible, data-efficient model that simplifies real-world multi-task management of dynamical systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šçº§ç”µæ± ç®¡ç†ä¸­ä»»åŠ¡å¤šæ ·ä¸”æ•°æ®å·¥ç¨‹å¼€é”€å¤§çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Flexible Masked Autoencoder (FMAE)é¢„è®­ç»ƒæ¡†æ¶ã€‚FMAEèƒ½å¤Ÿä»å¼‚æ„æ•°æ®ä¸­å­¦ä¹ ç»Ÿä¸€çš„ç”µæ± è¡¨ç¤ºï¼Œæœ‰æ•ˆå¤„ç†ç¼ºå¤±çš„ç”µæ± æ•°æ®é€šé“å¹¶æ•æ‰æ•°æ®ç‰‡æ®µé—´çš„è·¨ç»´å…³è”ï¼Œä¸”é€‚ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFMAEåœ¨11ä¸ªç”µæ± æ•°æ®é›†ä¸Šçš„5é¡¹ç®¡ç†ä»»åŠ¡ä¸­å‡ä¸€è‡´ä¼˜äºä¼ ç»Ÿçš„ç‰¹å®šä»»åŠ¡æ–¹æ³•ã€‚åœ¨å‰©ä½™å¯¿å‘½é¢„æµ‹(Remaining life prediction)ä»»åŠ¡ä¸­ï¼ŒFMAEä»…éœ€å‡å°‘50å€çš„æ¨ç†æ•°æ®å³å¯ä¿æŒå…ˆè¿›æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨ç”µå‹ç­‰å…³é”®ä¿¡æ¯ç¼ºå¤±çš„ç°å®åœºæ™¯ä¸‹ï¼ŒFMAEä»èƒ½å±•ç°å‡ºæé«˜çš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°åŠ¨åŠ›ç³»ç»Ÿçš„é«˜æ•ˆã€çµæ´»å¤šä»»åŠ¡ç®¡ç†æä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01323v1",
      "published_date": "2025-09-01 10:06:19 UTC",
      "updated_date": "2025-09-01 10:06:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:56:56.157461+00:00"
    },
    {
      "arxiv_id": "2509.01322v2",
      "title": "LongCat-Flash Technical Report",
      "title_zh": "LongCat-Flash æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Meituan LongCat Team",
        "Bayan",
        "Bei Li",
        "Bingye Lei",
        "Bo Wang",
        "Bolin Rong",
        "Chao Wang",
        "Chao Zhang",
        "Chen Gao",
        "Chen Zhang",
        "Cheng Sun",
        "Chengcheng Han",
        "Chenguang Xi",
        "Chi Zhang",
        "Chong Peng",
        "Chuan Qin",
        "Chuyu Zhang",
        "Cong Chen",
        "Congkui Wang",
        "Dan Ma",
        "Daoru Pan",
        "Defei Bu",
        "Dengchang Zhao",
        "Deyang Kong",
        "Dishan Liu",
        "Feiye Huo",
        "Fengcun Li",
        "Fubao Zhang",
        "Gan Dong",
        "Gang Liu",
        "Gang Xu",
        "Ge Li",
        "Guoqiang Tan",
        "Guoyuan Lin",
        "Haihang Jing",
        "Haomin Fu",
        "Haonan Yan",
        "Haoxing Wen",
        "Haozhe Zhao",
        "Hong Liu",
        "Hongmei Shi",
        "Hongyan Hao",
        "Hongyin Tang",
        "Huantian Lv",
        "Hui Su",
        "Jiacheng Li",
        "Jiahao Liu",
        "Jiahuan Li",
        "Jiajun Yang",
        "Jiaming Wang",
        "Jian Yang",
        "Jianchao Tan",
        "Jiaqi Sun",
        "Jiaqi Zhang",
        "Jiawei Fu",
        "Jiawei Yang",
        "Jiaxi Hu",
        "Jiayu Qin",
        "Jingang Wang",
        "Jiyuan He",
        "Jun Kuang",
        "Junhui Mei",
        "Kai Liang",
        "Ke He",
        "Kefeng Zhang",
        "Keheng Wang",
        "Keqing He",
        "Liang Gao",
        "Liang Shi",
        "Lianhui Ma",
        "Lin Qiu",
        "Lingbin Kong",
        "Lingtong Si",
        "Linkun Lyu",
        "Linsen Guo",
        "Liqi Yang",
        "Lizhi Yan",
        "Mai Xia",
        "Man Gao",
        "Manyuan Zhang",
        "Meng Zhou",
        "Mengxia Shen",
        "Mingxiang Tuo",
        "Mingyang Zhu",
        "Peiguang Li",
        "Peng Pei",
        "Peng Zhao",
        "Pengcheng Jia",
        "Pingwei Sun",
        "Qi Gu",
        "Qianyun Li",
        "Qingyuan Li",
        "Qiong Huang",
        "Qiyuan Duan",
        "Ran Meng",
        "Rongxiang Weng",
        "Ruichen Shao",
        "Rumei Li",
        "Shizhe Wu",
        "Shuai Liang",
        "Shuo Wang",
        "Suogui Dang",
        "Tao Fang",
        "Tao Li",
        "Tefeng Chen",
        "Tianhao Bai",
        "Tianhao Zhou",
        "Tingwen Xie",
        "Wei He",
        "Wei Huang",
        "Wei Liu",
        "Wei Shi",
        "Wei Wang",
        "Wei Wu",
        "Weikang Zhao",
        "Wen Zan",
        "Wenjie Shi",
        "Xi Nan",
        "Xi Su",
        "Xiang Li",
        "Xiang Mei",
        "Xiangyang Ji",
        "Xiangyu Xi",
        "Xiangzhou Huang",
        "Xianpeng Li",
        "Xiao Fu",
        "Xiao Liu",
        "Xiao Wei",
        "Xiaodong Cai",
        "Xiaolong Chen",
        "Xiaoqing Liu",
        "Xiaotong Li",
        "Xiaowei Shi",
        "Xiaoyu Li",
        "Xili Wang",
        "Xin Chen",
        "Xing Hu",
        "Xingyu Miao",
        "Xinyan He",
        "Xuemiao Zhang",
        "Xueyuan Hao",
        "Xuezhi Cao",
        "Xunliang Cai",
        "Xurui Yang",
        "Yan Feng",
        "Yang Bai",
        "Yang Chen",
        "Yang Yang",
        "Yaqi Huo",
        "Yerui Sun",
        "Yifan Lu",
        "Yifan Zhang",
        "Yipeng Zang",
        "Yitao Zhai",
        "Yiyang Li",
        "Yongjing Yin",
        "Yongkang Lv",
        "Yongwei Zhou",
        "Yu Yang",
        "Yuchen Xie",
        "Yueqing Sun",
        "Yuewen Zheng",
        "Yuhuai Wei",
        "Yulei Qian",
        "Yunfan Liang",
        "Yunfang Tai",
        "Yunke Zhao",
        "Zeyang Yu",
        "Zhao Zhang",
        "Zhaohua Yang",
        "Zhenchao Zhang",
        "Zhikang Xia",
        "Zhiye Zou",
        "Zhizhao Zeng",
        "Zhongda Su",
        "Zhuofan Chen",
        "Zijian Zhang",
        "Ziwen Wang",
        "Zixu Jiang",
        "Zizhe Zhao",
        "Zongyu Wang",
        "Zunhai Su"
      ],
      "abstract": "We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE) language model designed for both computational efficiency and advanced agentic capabilities. Stemming from the need for scalable efficiency, LongCat-Flash adopts two novel designs: (a) Zero-computation Experts, which enables dynamic computational budget allocation and activates 18.6B-31.3B (27B on average) per token depending on contextual demands, optimizing resource usage. (b) Shortcut-connected MoE, which enlarges the computation-communication overlap window, demonstrating notable gains in inference efficiency and throughput compared to models of a comparable scale. We develop a comprehensive scaling framework for large models that combines hyperparameter transfer, model-growth initialization, a multi-pronged stability suite, and deterministic computation to achieve stable and reproducible training. Notably, leveraging the synergy among scalable architectural design and infrastructure efforts, we complete model training on more than 20 trillion tokens within 30 days, while achieving over 100 tokens per second (TPS) for inference at a cost of \\$0.70 per million output tokens. To cultivate LongCat-Flash towards agentic intelligence, we conduct a large-scale pre-training on optimized mixtures, followed by targeted mid- and post-training on reasoning, code, and instructions, with further augmentation from synthetic data and tool use tasks. Comprehensive evaluations demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers highly competitive performance among other leading models, with exceptional strengths in agentic tasks. The model checkpoint of LongCat-Flash is open-sourced to foster community research.\n  LongCat Chat: https://longcat.ai\n  Hugging Face: https://huggingface.co/meituan-longcat\n  GitHub: https://github.com/meituan-longcat",
      "tldr_zh": "è¯¥æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†LongCat-Flashï¼Œè¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰5600äº¿å‚æ•°çš„æ··åˆä¸“å®¶(Mixture-of-Experts, MoE)è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨å…¼é¡¾è®¡ç®—æ•ˆç‡ä¸é«˜çº§æ™ºèƒ½ä½“(agentic)èƒ½åŠ›ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†é›¶è®¡ç®—ä¸“å®¶(Zero-computation Experts)ä»¥å®ç°åŠ¨æ€è®¡ç®—é¢„ç®—åˆ†é…ï¼Œå¹¶é‡‡ç”¨æ·å¾„è¿æ¥MoE(Shortcut-connected MoE)æ¶æ„æ¥æ‰©å¤§è®¡ç®—ä¸é€šä¿¡çš„é‡å çª—å£ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†æ•ˆç‡å’Œååé‡ã€‚å€ŸåŠ©é«˜æ•ˆçš„å¯æ‰©å±•è®­ç»ƒæ¡†æ¶ï¼Œç ”ç©¶å›¢é˜Ÿåœ¨30å¤©å†…å®Œæˆäº†è¶…è¿‡20ä¸‡äº¿tokençš„é¢„è®­ç»ƒï¼Œå®ç°äº†æ¯ç§’è¶…è¿‡100ä¸ªtoken(TPS)çš„æ¨ç†é€Ÿåº¦ï¼Œä¸”æ¯ç™¾ä¸‡è¾“å‡ºtokençš„æˆæœ¬ä»…ä¸º0.70ç¾å…ƒã€‚é€šè¿‡é’ˆå¯¹æ¨ç†ã€ä»£ç ã€æŒ‡ä»¤åŠå·¥å…·è°ƒç”¨ç­‰ä»»åŠ¡çš„å®šå‘ä¼˜åŒ–ï¼ŒLongCat-Flashåœ¨æ™ºèƒ½ä½“ç›¸å…³ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„ç«äº‰åŠ›ã€‚ç›®å‰ï¼Œè¯¥æ¨¡å‹çš„æƒé‡å·²å¼€æºï¼Œæ—¨åœ¨æ¨åŠ¨å­¦æœ¯ç•Œå’Œå¼€å‘è€…ç¤¾åŒºçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01322v2",
      "published_date": "2025-09-01 10:05:45 UTC",
      "updated_date": "2025-09-19 13:34:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:18.985342+00:00"
    },
    {
      "arxiv_id": "2509.01319v2",
      "title": "Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for Prediction Intervals",
      "title_zh": "è¿ˆå‘å¯ä¿¡ç”Ÿå‘½ä½“å¾é¢„æµ‹ï¼šåˆ©ç”¨ä¸ç¡®å®šæ€§æ„å»ºé¢„æµ‹åŒºé—´",
      "authors": [
        "Li Rong Wang",
        "Thomas C. Henderson",
        "Yew Soon Ong",
        "Yih Yng Ng",
        "Xiuyi Fan"
      ],
      "abstract": "Vital signs, such as heart rate and blood pressure, are critical indicators of patient health and are widely used in clinical monitoring and decision-making. While deep learning models have shown promise in forecasting these signals, their deployment in healthcare remains limited in part because clinicians must be able to trust and interpret model outputs. Without reliable uncertainty quantification -- particularly calibrated prediction intervals (PIs) -- it is unclear whether a forecasted abnormality constitutes a meaningful warning or merely reflects model noise, hindering clinical decision-making. To address this, we present two methods for deriving PIs from the Reconstruction Uncertainty Estimate (RUE), an uncertainty measure well-suited to vital-sign forecasting due to its sensitivity to data shifts and support for label-free calibration. Our parametric approach assumes that prediction errors and uncertainty estimates follow a Gaussian copula distribution, enabling closed-form PI computation. Our non-parametric approach, based on k-nearest neighbours (KNN), empirically estimates the conditional error distribution using similar validation instances. We evaluate these methods on two large public datasets with minute- and hour-level sampling, representing high- and low-frequency health signals. Experiments demonstrate that the Gaussian copula method consistently outperforms conformal prediction baselines on low-frequency data, while the KNN approach performs best on high-frequency data. These results underscore the clinical promise of RUE-derived PIs for delivering interpretable, uncertainty-aware vital sign forecasts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”Ÿå‘½ä½“å¾é¢„æµ‹åœ¨ä¸´åºŠåº”ç”¨ä¸­ç¼ºä¹å¯é ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆuncertainty quantificationï¼‰åŠæ ¡å‡†é¢„æµ‹åŒºé—´ï¼ˆprediction intervals, PIsï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸¤ç§åŸºäºé‡æ„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆReconstruction Uncertainty Estimate, RUEï¼‰çš„é¢„æµ‹æ–¹æ³•ã€‚å…¶ä¸­å‚æ•°åŒ–æ–¹æ³•åˆ©ç”¨é«˜æ–¯æŸ¯æ™®æ‹‰ï¼ˆGaussian copulaï¼‰åˆ†å¸ƒå®ç°é—­å¼ PI è®¡ç®—ï¼Œè€Œéå‚æ•°åŒ–æ–¹æ³•åˆ™é€šè¿‡ k æœ€è¿‘é‚»ï¼ˆk-nearest neighbours, KNNï¼‰ç®—æ³•å®è¯ä¼°è®¡æ¡ä»¶è¯¯å·®åˆ†å¸ƒã€‚ç ”ç©¶åœ¨æ¶µç›–é«˜ã€ä½é¢‘ä¿¡å·çš„ä¸¤ä¸ªå¤§å‹å…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œé«˜æ–¯æŸ¯æ™®æ‹‰æ–¹æ³•åœ¨ä½é¢‘æ•°æ®ä¸Šä¼˜äºå…±å½¢é¢„æµ‹ï¼ˆconformal predictionï¼‰åŸºå‡†ï¼Œè€Œ KNN æ–¹æ³•åœ¨é«˜é¢‘æ•°æ®ä¸Šè¡¨ç°æœ€ä½³ã€‚è¿™äº›å‘ç°çªæ˜¾äº† RUE è¡ç”Ÿé¢„æµ‹åŒºé—´åœ¨æä¾›å¯è§£é‡Šä¸”å…·å¤‡ä¸ç¡®å®šæ€§æ„è¯†çš„ç”Ÿå‘½ä½“å¾é¢„æµ‹æ–¹é¢çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚è¯¥ç ”ç©¶ä¸ºå»ºç«‹æ›´å…·å¯ä¿¡åº¦çš„åŒ»ç–—å†³ç­–è¾…åŠ©ç³»ç»Ÿæä¾›äº†é‡è¦æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 25th IEEE International Conference on Data Mining (ICDM)",
      "pdf_url": "https://arxiv.org/pdf/2509.01319v2",
      "published_date": "2025-09-01 10:03:26 UTC",
      "updated_date": "2025-09-17 03:05:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:31.490870+00:00"
    },
    {
      "arxiv_id": "2509.01308v2",
      "title": "GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL Generation from Large Language Models",
      "title_zh": "GradeSQLï¼šåŸºäºç»“æœå¥–åŠ±æ¨¡å‹çš„å¤§è¯­è¨€æ¨¡å‹ Text-to-SQL ç”Ÿæˆæµ‹è¯•æ—¶æ¨ç†",
      "authors": [
        "Mattia Tritto",
        "Giuseppe Farano",
        "Dario Di Palma",
        "Gaetano Rossiello",
        "Fedelucio Narducci",
        "Dharmashankar Subramanian",
        "Tommaso Di Noia"
      ],
      "abstract": "Text-to-SQL, the task of translating natural language questions into SQL queries, has significantly advanced with the introduction of Large Language Models (LLMs), broadening database accessibility for a wide range of users. Despite substantial progress in generating valid SQL, current LLMs still struggle with complex queries. To address this limitation, test-time strategies such as Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the assumption that LLMs can produce correct answers after multiple attempts. However, these methods rely on surface-level heuristics, selecting the syntactically correct query through execution-based BoN (ex-BoN) or the most frequently generated one through Majority Voting. Recently, Outcome Reward Models (ORMs), which assign utility scores to generated outputs based on semantic correctness, have emerged as a promising reinforcement learning approach for improving model alignment. We argue that ORMs could serve as an effective new test-time heuristic, although their application in this context remains largely underexplored.\n  In this work, we propose a unified framework for training ORMs tailored to the Text-to-SQL task and assess their effectiveness as a test-time heuristic within the BoN strategy. We benchmark ORMs against ex-BoN and Maj across the BIRD and Spider datasets, fine-tuning diverse open-source LLMs from the Qwen2, Granite3, and Llama3 families. Results show that ORMs outperform ex-BoN and Maj, achieving execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and +2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that finetuning models already aligned with SQL generation, such as OmniSQL, yields superior ORM performance. Additionally, we observe that ORMs achieve competitive results on simple queries and benefit more from an increased number of candidates compared to ex-BoN and Maj.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ Text-to-SQL ä»»åŠ¡ä¸­å¤„ç†å¤æ‚æŸ¥è¯¢çš„å±€é™æ€§ï¼Œæå‡ºäº† GradeSQL æ¡†æ¶ã€‚ä¸ä¼ ç»ŸåŸºäºæ‰§è¡Œåé¦ˆçš„ Best-of-N (ex-BoN) æˆ– Majority Voting (Maj) ç­‰è¡¨é¢å¯å‘å¼ç­–ç•¥ä¸åŒï¼ŒGradeSQL å¼•å…¥äº†ç»“æœå¥–åŠ±æ¨¡å‹ (Outcome Reward Models, ORMs) ä½œä¸ºæ¨ç†é˜¶æ®µçš„æ–°å¯å‘å¼æ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰æ­£ç¡®æ€§è¯„åˆ†æ¥ç­›é€‰ç”Ÿæˆçš„ SQL è¯­å¥ã€‚ç ”ç©¶å›¢é˜Ÿä¸º Text-to-SQL ä»»åŠ¡è®¾è®¡äº†ä¸€ä¸ªç»Ÿä¸€çš„ ORM è®­ç»ƒæ¡†æ¶ï¼Œå¹¶å°†å…¶åº”ç”¨äº Qwen2ã€Granite3 å’Œ Llama3 ç­‰å¼€æºæ¨¡å‹ç³»åˆ—è¿›è¡Œè¯„ä¼°ã€‚åœ¨ BIRD å’Œ Spider æ•°æ®é›†çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒORMs çš„è¡¨ç°æ˜¾è‘—ä¼˜äº ex-BoN å’Œ Majï¼Œå…¶ä¸­åœ¨ BIRD æ•°æ®é›†ä¸Šçš„æ‰§è¡Œå‡†ç¡®ç‡ç›¸æ¯” ex-BoN æå‡äº† 4.33%ã€‚å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œåœ¨å·²ç»è¿‡ SQL å¯¹é½çš„æ¨¡å‹ï¼ˆå¦‚ OmniSQLï¼‰ä¸Šå¾®è°ƒèƒ½è·å¾—æ›´ä¼˜çš„ ORM æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒORMs åœ¨å¤„ç†ç®€å•æŸ¥è¯¢æ—¶åŒæ ·å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶ä¸”èƒ½æ›´æœ‰æ•ˆåœ°ä»å€™é€‰æ ·æœ¬æ•°é‡çš„å¢åŠ ä¸­è·ç›Šã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01308v2",
      "published_date": "2025-09-01 09:47:35 UTC",
      "updated_date": "2025-10-29 14:09:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:17.751702+00:00"
    },
    {
      "arxiv_id": "2509.01304v1",
      "title": "Animer une base de connaissance: des ontologies aux mod{Ã¨}les d'I.A. g{Ã©}n{Ã©}rative",
      "title_zh": "æ¿€æ´»çŸ¥è¯†åº“ï¼šä»æœ¬ä½“åˆ°ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹",
      "authors": [
        "Peter Stockinger"
      ],
      "abstract": "In a context where the social sciences and humanities are experimenting with non-anthropocentric analytical frames, this article proposes a semiotic (structural) reading of the hybridization between symbolic AI and neural (or sub-symbolic) AI based on a field of application: the design and use of a knowledge base for area studies. We describe the LaCAS ecosystem -- Open Archives in Linguistic and Cultural Studies (thesaurus; RDF/OWL ontology; LOD services; harvesting; expertise; publication), deployed at Inalco (National Institute for Oriental Languages and Civilizations) in Paris with the Okapi (Open Knowledge and Annotation Interface) software environment from Ina (National Audiovisual Institute), which now has around 160,000 documentary resources and ten knowledge macro-domains grouping together several thousand knowledge objects. We illustrate this approach using the knowledge domain ''Languages of the world'' (~540 languages) and the knowledge object ''Quechua (language)''. On this basis, we discuss the controlled integration of neural tools, more specifically generative tools, into the life cycle of a knowledge base: assistance with data localization/qualification, index extraction and aggregation, property suggestion and testing, dynamic file generation, and engineering of contextualized prompts (generic, contextual, explanatory, adjustment, procedural) aligned with a domain ontology. We outline an ecosystem of specialized agents capable of animating the database while respecting its symbolic constraints, by articulating model-driven and data-driven methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç¤¾ä¼šç§‘å­¦ä¸äººæ–‡ç§‘å­¦èƒŒæ™¯ä¸‹ï¼Œå¦‚ä½•å°†ç¬¦å·åŒ–äººå·¥æ™ºèƒ½ (Symbolic AI) ä¸ç¥ç»ï¼ˆäºšç¬¦å·ï¼‰äººå·¥æ™ºèƒ½ (Neural/Sub-symbolic AI) è¿›è¡Œæ‚åŒ–ï¼Œä»¥ä¼˜åŒ–åŒºåŸŸç ”ç©¶ (Area studies) çŸ¥è¯†åº“çš„è®¾è®¡ä¸ä½¿ç”¨ã€‚æ–‡ç« è¯¦ç»†ä»‹ç»äº†åœ¨å·´é»æ³•å›½å›½ç«‹ä¸œæ–¹è¯­è¨€æ–‡åŒ–å­¦é™¢ (Inalco) éƒ¨ç½²çš„ LaCAS ç”Ÿæ€ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨ Okapi è½¯ä»¶ç¯å¢ƒç®¡ç†ç€æ¶µç›–16ä¸‡ä»½èµ„æºçš„è¯­è¨€ä¸æ–‡åŒ–ç ”ç©¶å¼€æ”¾æ¡£æ¡ˆã€‚ç ”ç©¶é‡ç‚¹è®¨è®ºäº†å°†ç”Ÿæˆå¼å·¥å…· (Generative tools) å—æ§åœ°é›†æˆåˆ°çŸ¥è¯†åº“ç”Ÿå‘½å‘¨æœŸä¸­çš„å…·ä½“è·¯å¾„ï¼Œæ¶‰åŠè¾…åŠ©æ•°æ®å®šä½ã€ç´¢å¼•æå–ã€å±æ€§å»ºè®®ä»¥åŠåŠ¨æ€æ–‡ä»¶ç”Ÿæˆç­‰ä»»åŠ¡ã€‚é€šè¿‡å®æ–½ä¸é¢†åŸŸæœ¬ä½“ (Domain ontology) å¯¹é½çš„ä¸Šä¸‹æ–‡æç¤ºè¯å·¥ç¨‹ (Contextualized prompts engineering)ï¼Œè¯¥æ–¹æ³•å®ç°äº†æ¨¡å‹é©±åŠ¨ (Model-driven) ä¸æ•°æ®é©±åŠ¨ (Data-driven) æŠ€æœ¯çš„æœ‰æœºç»“åˆã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶å‹¾å‹’å‡ºäº†ä¸€ä¸ªç”±ä¸“ä¸šæ™ºèƒ½ä½“ (Specialized agents) ç»„æˆçš„ç”Ÿæ€ç³»ç»Ÿï¼Œæ—¨åœ¨å°Šé‡ç¬¦å·çº¦æŸçš„åŒæ—¶åŠ¨æ€â€œæ¿€æ´»â€æ•°æ®åº“èµ„æºï¼Œä¸ºçŸ¥è¯†å·¥ç¨‹åœ¨ç”Ÿæˆå¼ AI æ—¶ä»£çš„æ¼”è¿›æä¾›äº†ç†è®ºä¸å®è·µæ”¯æ’‘ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "in French language",
      "pdf_url": "https://arxiv.org/pdf/2509.01304v1",
      "published_date": "2025-09-01 09:40:55 UTC",
      "updated_date": "2025-09-01 09:40:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:29.052225+00:00"
    },
    {
      "arxiv_id": "2509.01285v1",
      "title": "Building surrogate models using trajectories of agents trained by Reinforcement Learning",
      "title_zh": "åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ™ºèƒ½ä½“è½¨è¿¹æ„å»ºä»£ç†æ¨¡å‹",
      "authors": [
        "Julen Cestero",
        "Marco Quartulli",
        "Marcello Restelli"
      ],
      "abstract": "Sample efficiency in the face of computationally expensive simulations is a common concern in surrogate modeling. Current strategies to minimize the number of samples needed are not as effective in simulated environments with wide state spaces. As a response to this challenge, we propose a novel method to efficiently sample simulated deterministic environments by using policies trained by Reinforcement Learning. We provide an extensive analysis of these surrogate-building strategies with respect to Latin-Hypercube sampling or Active Learning and Kriging, cross-validating performances with all sampled datasets. The analysis shows that a mixed dataset that includes samples acquired by random agents, expert agents, and agents trained to explore the regions of maximum entropy of the state transition distribution provides the best scores through all datasets, which is crucial for a meaningful state space representation. We conclude that the proposed method improves the state-of-the-art and clears the path to enable the application of surrogate-aided Reinforcement Learning policy optimization strategies on complex simulators.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”å…·æœ‰å®½çŠ¶æ€ç©ºé—´çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)è®­ç»ƒçš„æ™ºèƒ½ä½“è½¨è¿¹æ„å»ºä»£ç†æ¨¡å‹(surrogate models)çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶é€šè¿‡RLç­–ç•¥é«˜æ•ˆé‡‡æ ·ç¡®å®šæ€§ç¯å¢ƒï¼Œå¹¶ä¸Latin-Hypercubeé‡‡æ ·ã€ä¸»åŠ¨å­¦ä¹ (Active Learning)ä»¥åŠKrigingç­‰ä¼ ç»Ÿç­–ç•¥è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚å®éªŒè¯æ˜ï¼ŒåŒ…å«éšæœºæ™ºèƒ½ä½“ã€ä¸“å®¶æ™ºèƒ½ä½“ä»¥åŠä¸“æ³¨äºæ¢ç´¢çŠ¶æ€è½¬ç§»åˆ†å¸ƒæœ€å¤§ç†µ(maximum entropy)åŒºåŸŸçš„æ™ºèƒ½ä½“çš„æ··åˆæ•°æ®é›†åœ¨æ€§èƒ½ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œè¿™å¯¹äºæ•æ‰å…³é”®çš„çŠ¶æ€ç©ºé—´ç‰¹å¾è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†ç°æœ‰æŠ€æœ¯æ°´å¹³ï¼Œä¸ºåœ¨å¤æ‚æ¨¡æ‹Ÿå™¨ä¸­åº”ç”¨ä»£ç†è¾…åŠ©çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–(policy optimization)å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in ICANN 2024 conference",
      "pdf_url": "https://arxiv.org/pdf/2509.01285v1",
      "published_date": "2025-09-01 09:13:45 UTC",
      "updated_date": "2025-09-01 09:13:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:24.452110+00:00"
    },
    {
      "arxiv_id": "2509.01277v1",
      "title": "Communicative Agents for Slideshow Storytelling Video Generation based on LLMs",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¹»ç¯ç‰‡å™äº‹è§†é¢‘ç”Ÿæˆæ²Ÿé€šå‹æ™ºèƒ½ä½“",
      "authors": [
        "Jingxing Fan",
        "Jinrong Shen",
        "Yusheng Yao",
        "Shuangqing Wang",
        "Qian Wang",
        "Yuling Wang"
      ],
      "abstract": "With the rapid advancement of artificial intelligence (AI), the proliferation of AI-generated content (AIGC) tasks has significantly accelerated developments in text-to-video generation. As a result, the field of video production is undergoing a transformative shift. However, conventional text-to-video models are typically constrained by high computational costs.\n  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show video generation system designed to redefine the video creation pipeline through the integration of large language models (LLMs). VGTeam is composed of a suite of communicative agents, each responsible for a distinct aspect of video generation, such as scriptwriting, scene creation, and audio design. These agents operate collaboratively within a chat tower workflow, transforming user-provided textual prompts into coherent, slide-style narrative videos.\n  By emulating the sequential stages of traditional video production, VGTeam achieves remarkable improvements in both efficiency and scalability, while substantially reducing computational overhead. On average, the system generates videos at a cost of only $0.103, with a successful generation rate of 98.4%. Importantly, this framework maintains a high degree of creative fidelity and customization.\n  The implications of VGTeam are far-reaching. It democratizes video production by enabling broader access to high-quality content creation without the need for extensive resources. Furthermore, it highlights the transformative potential of language models in creative domains and positions VGTeam as a pioneering system for next-generation content creation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºVideo-Generation-Team (VGTeam)çš„æ–°å‹å¹»ç¯ç‰‡è§†é¢‘ç”Ÿæˆç³»ç»Ÿï¼Œæ—¨åœ¨åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)é‡æ–°å®šä¹‰è§†é¢‘åˆ›ä½œæµç¨‹ã€‚ä¸ºäº†å…‹æœä¼ ç»Ÿæ–‡æœ¬è½¬è§†é¢‘(text-to-video)æ¨¡å‹è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é™åˆ¶ï¼ŒVGTeamé›†æˆäº†ä¸€ç³»åˆ—æ²Ÿé€šæ™ºèƒ½ä½“(communicative agents)ï¼Œåˆ†åˆ«è´Ÿè´£å‰§æœ¬ç¼–å†™ã€åœºæ™¯åˆ›å»ºå’ŒéŸ³é¢‘è®¾è®¡ç­‰ä»»åŠ¡ã€‚è¿™äº›æ™ºèƒ½ä½“åœ¨èŠå¤©å¡”å·¥ä½œæµ(chat tower workflow)ä¸­ååŒå·¥ä½œï¼Œå°†ç”¨æˆ·æä¾›çš„æ–‡æœ¬æç¤ºè½¬åŒ–ä¸ºè¿è´¯çš„å¹»ç¯ç‰‡å¼å™äº‹è§†é¢‘ã€‚é€šè¿‡æ¨¡æ‹Ÿä¼ ç»Ÿè§†é¢‘åˆ¶ä½œçš„é˜¶æ®µï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—æå‡äº†ç”Ÿæˆæ•ˆç‡å’Œå¯æ‰©å±•æ€§ï¼Œå¹¶å°†å¹³å‡ç”Ÿæˆæˆæœ¬é™ä½è‡³0.103ç¾å…ƒï¼ŒæˆåŠŸç‡é«˜è¾¾98.4%ã€‚VGTeamä¸ä»…å¤§å¹…é™ä½äº†é«˜è´¨é‡è§†é¢‘å†…å®¹çš„ç”Ÿäº§é—¨æ§›ï¼Œè¿˜å±•ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„é¢†åŸŸæ¨åŠ¨ä¸‹ä¸€ä»£å†…å®¹ç”Ÿæˆçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 8 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2509.01277v1",
      "published_date": "2025-09-01 09:04:07 UTC",
      "updated_date": "2025-09-01 09:04:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:35.190692+00:00"
    },
    {
      "arxiv_id": "2509.02622v2",
      "title": "IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic Scenes using Deep Filtering",
      "title_zh": "IS${}^3$ï¼šåŸºäºæ·±åº¦æ»¤æ³¢çš„å£°å­¦åœºæ™¯é€šç”¨è„‰å†²-ç¨³æ€å£°éŸ³åˆ†ç¦»",
      "authors": [
        "ClÃ©mentine Berger",
        "Paraskevas Stamatiadis",
        "Roland Badeau",
        "Slim Essid"
      ],
      "abstract": "We are interested in audio systems capable of performing a differentiated processing of stationary backgrounds and isolated acoustic events within an acoustic scene, whether for applying specific processing methods to each part or for focusing solely on one while ignoring the other. Such systems have applications in real-world scenarios, including robust adaptive audio rendering systems (e.g., EQ or compression), plosive attenuation in voice mixing, noise suppression or reduction, robust acoustic event classification or even bioacoustics. To this end, we introduce IS${}^3$, a neural network designed for Impulsive--Stationary Sound Separation, that isolates impulsive acoustic events from the stationary background using a deep filtering approach, that can act as a pre-processing stage for the above-mentioned tasks. To ensure optimal training, we propose a sophisticated data generation pipeline that curates and adapts existing datasets for this task. We demonstrate that a learning-based approach, build on a relatively lightweight neural architecture and trained with well-designed and varied data, is successful in this previously unaddressed task, outperforming the Harmonic--Percussive Sound Separation masking method, adapted from music signal processing research, and wavelet filtering on objective separation metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†IS${}^3$ï¼Œä¸€ç§åŸºäºæ·±åº¦æ»¤æ³¢(Deep Filtering)çš„ç¥ç»ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³å£°å­¦åœºæ™¯ä¸­è„‰å†²å£°éŸ³ä¸å¹³ç¨³èƒŒæ™¯çš„åˆ†ç¦»(Impulsive--Stationary Sound Separation)é—®é¢˜ã€‚è¯¥æ¡†æ¶å¯ä½œä¸ºéŸ³é¢‘æ¸²æŸ“ã€å™ªå£°æŠ‘åˆ¶ã€çˆ†ç ´éŸ³è¡°å‡ä»¥åŠç”Ÿç‰©å£°å­¦ç­‰ä»»åŠ¡çš„é¢„å¤„ç†é˜¶æ®µï¼Œå®ç°å¯¹å­¤ç«‹å£°å­¦äº‹ä»¶çš„ç²¾å‡†æå–æˆ–èƒŒæ™¯å¿½ç•¥ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å¼€å‘äº†ä¸€å¥—å¤æ‚çš„æ•°æ®ç”Ÿæˆæµæ°´çº¿ï¼Œé€šè¿‡å¯¹ç°æœ‰æ•°æ®é›†çš„ç­›é€‰ä¸é€‚é…æ¥ç¡®ä¿æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œè¿™ç§è½»é‡åŒ–çš„å­¦ä¹ æ¨¡å‹åœ¨å®¢è§‚åˆ†ç¦»æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„è°æ³¢-æ‰“å‡»éŸ³åˆ†ç¦»(Harmonic--Percussive Sound Separation)æ–¹æ³•å’Œæ³¢æ®µè¿‡æ»¤(Wavelet Filtering)æŠ€æœ¯ã€‚è¯¥æˆæœæœ‰æ•ˆå¡«è¡¥äº†æ­¤å‰åœ¨è¯¥ç ”ç©¶é¢†åŸŸçš„ç©ºç™½ï¼Œå¹¶è¯æ˜äº†åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ¡ˆåœ¨å¤„ç†å¤æ‚å£°å­¦åœºæ™¯åˆ†ç¦»ä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.02622v2",
      "published_date": "2025-09-01 08:55:29 UTC",
      "updated_date": "2025-09-12 09:26:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:37.293228+00:00"
    },
    {
      "arxiv_id": "2509.10499v1",
      "title": "Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization",
      "title_zh": "é¢å‘å¯æ‰©å±• O-RAN èµ„æºç®¡ç†ï¼šå›¾å¢å¼ºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Duc-Thinh Ngo",
        "Kandaraj Piamrat",
        "Ons Aouedi",
        "Thomas Hassan",
        "Philippe Raipin-ParvÃ©dy"
      ],
      "abstract": "Open Radio Access Network (O-RAN) architectures enable flexible, scalable, and cost-efficient mobile networks by disaggregating and virtualizing baseband functions. However, this flexibility introduces significant challenges for resource management, requiring joint optimization of functional split selection and virtualized unit placement under dynamic demands and complex topologies. Existing solutions often address these aspects separately or lack scalability in large and real-world scenarios. In this work, we propose a novel Graph-Augmented Proximal Policy Optimization (GPPO) framework that leverages Graph Neural Networks (GNNs) for topology-aware feature extraction and integrates action masking to efficiently navigate the combinatorial decision space. Our approach jointly optimizes functional split and placement decisions, capturing the full complexity of O-RAN resource allocation. Extensive experiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO consistently outperforms state-of-the-art baselines, achieving up to 18% lower deployment cost and 25% higher reward in generalization tests, while maintaining perfect reliability. These results highlight the effectiveness and scalability of GPPO for practical O-RAN deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Open Radio Access Network (O-RAN) èµ„æºç®¡ç†ä¸­åŠŸèƒ½æ‹†åˆ†é€‰æ‹©(functional split selection)ä¸è™šæ‹ŸåŒ–å•å…ƒéƒ¨ç½²(virtualized unit placement)çš„è”åˆä¼˜åŒ–æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºGPPO (Graph-Augmented Proximal Policy Optimization) çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks, GNNs) è¿›è¡Œæ‹“æ‰‘æ„ŸçŸ¥çš„ç‰¹å¾æå–ï¼Œå¹¶é›†æˆåŠ¨ä½œæ©ç (action masking) æœºåˆ¶ä»¥é«˜æ•ˆå¤„ç†å¤æ‚çš„ç»„åˆå†³ç­–ç©ºé—´ã€‚GPPOå®ç°äº†åŠŸèƒ½æ‹†åˆ†ä¸éƒ¨ç½²å†³ç­–çš„è”åˆä¼˜åŒ–ï¼Œèƒ½å¤Ÿå…¨é¢æ•æ‰O-RANèµ„æºåˆ†é…çš„å¤æ‚æ€§ã€‚åœ¨å¤šç§è§„æ¨¡çš„O-RANåœºæ™¯å®éªŒä¸­ï¼ŒGPPOè¡¨ç°å‡ºä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹çš„æ€§èƒ½ï¼Œåœ¨æ³›åŒ–æµ‹è¯•ä¸­é™ä½äº†18%çš„éƒ¨ç½²æˆæœ¬å¹¶æå‡äº†25%çš„å¥–åŠ±å€¼ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†GPPOåœ¨å¤„ç†å¤§è§„æ¨¡å®é™…O-RANéƒ¨ç½²æ—¶çš„æœ‰æ•ˆæ€§ã€å¯é æ€§åŠå¼ºå¤§çš„å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.10499v1",
      "published_date": "2025-09-01 08:53:04 UTC",
      "updated_date": "2025-09-01 08:53:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:39.384137+00:00"
    },
    {
      "arxiv_id": "2509.01257v2",
      "title": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks",
      "title_zh": "é¢å‘æ— çº¿è¾¹ç¼˜ç½‘ç»œä»»åŠ¡å¸è½½çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Andrea Fox",
        "Francesco De Pellegrini",
        "Eitan Altman"
      ],
      "abstract": "In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ— çº¿è¾¹ç¼˜ç½‘ç»œä¸­çš„ä»»åŠ¡å¸è½½é—®é¢˜ï¼Œæ¢è®¨äº†è‡ªä¸»æ™ºèƒ½ä½“åœ¨å…±äº«èµ„æºç«äº‰ä¸­é¢ä¸´çš„å¿«é€Ÿæœ¬åœ°å†³ç­–æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç°æœ‰ Multi-Agent Reinforcement Learning (MARL) æ–¹æ³•åœ¨æœ‰é™å¯è§‚æµ‹æ€§å’Œé€šä¿¡å—é™ç¯å¢ƒä¸‹çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å»ä¸­å¿ƒåŒ–æ¡†æ¶ï¼Œä½¿æ¯ä¸ªæ™ºèƒ½ä½“é€šè¿‡è§£å†³ Constrained Markov Decision Process (CMDP) å¹¶åˆ©ç”¨å…±äº«çº¦æŸå‘é‡è¿›è¡Œéšå¼åè°ƒã€‚è¿™ç§è½»é‡åŒ–æœºåˆ¶é€šè¿‡ä¸é¢‘ç¹æ›´æ–°çš„çº¦æŸæ¡ä»¶é˜²æ­¢æœåŠ¡å™¨èµ„æºè¿‡è½½ï¼Œç¡®ä¿æ™ºèƒ½ä½“åœ¨æå°‘ç›´æ¥é€šä¿¡çš„æƒ…å†µä¸‹ä¸å…¨å±€èµ„æºç›®æ ‡ä¿æŒä¸€è‡´ã€‚åˆ©ç”¨ Safe Reinforcement Learning æŠ€æœ¯ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿå­¦ä¹ åˆ°å…¼é¡¾æœ¬åœ°ä¸å…¨å±€ç›®æ ‡çš„ä¼˜åŒ–ç­–ç•¥ã€‚ç†è®ºåˆ†æä¸å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§è§„æ¨¡è®¾ç½®ä¸‹çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¸­å¿ƒåŒ–å’Œç‹¬ç«‹åŸºçº¿æ¨¡å‹ï¼Œä¸ºèµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒæä¾›äº†é«˜æ•ˆçš„åè°ƒæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Oral presentation at AI4NextG @ NeurIPS'25 Workshop",
      "pdf_url": "https://arxiv.org/pdf/2509.01257v2",
      "published_date": "2025-09-01 08:47:36 UTC",
      "updated_date": "2025-10-23 10:39:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:57:43.894857+00:00"
    },
    {
      "arxiv_id": "2509.01245v4",
      "title": "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers",
      "title_zh": "è¿ˆå‘æ™ºèƒ½ä½“åŒ–æ“ä½œç³»ç»Ÿï¼šé¢å‘ Linux è°ƒåº¦å™¨çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Yusheng Zheng",
        "Yanpeng Hu",
        "Wei Zhang",
        "Andi Quinn"
      ],
      "abstract": "Operating system schedulers suffer from a fundamental semantic gap, where kernel policies fail to understand application-specific needs, leading to suboptimal performance. We introduce SchedCP, the first framework that enables fully autonomous Large Language Model (LLM) agents to safely and efficiently optimize Linux schedulers without human involvement. Our core insight is that the challenge is not merely to apply a better LLM, but to architect a decoupled control plane that separates the AI's role of semantic reasoning (\"what to optimize\") from the system's role of execution (\"how to observe and act\"), thereby separating the optimization problem into two stages: goal-inference and policy-synthesis. Implemented as Model Context Protocol(MCP) server, SchedCP provides a stable interface with three key services: a Workload Analysis Engine, an evolving Scheduler Policy Repository, and an Execution Verifier that validates all AI-generated code and configure before deployment with static and dynamic analysis.\n  We demonstrate this architecture's power with sched-agent, a multi-agent system that autonomously analyzes workloads, synthesizes custom eBPF scheduling policies, and deploys them via the sched\\_ext infrastructure. Our evaluation shows that SchedCP achieves up to an 1.79x performance improvement, and a 13x cost reduction compared to naive agentic approaches, all while maintaining high success rate. By bridging the semantic gap, SchedCP democratizes expert-level system optimization and represents a step towards creating truly self-optimizing, application-aware operating systems. The code is open-sourced in https://github.com/eunomia-bpf/schedcp",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Linux è°ƒåº¦å™¨ä¸­å†…æ ¸ç­–ç•¥ä¸åº”ç”¨éœ€æ±‚ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿ (semantic gap) é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªä½¿å¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªä¸»ä¼˜åŒ–è°ƒåº¦å™¨çš„æ¡†æ¶ SchedCPã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸€ä¸ªè§£è€¦çš„æ§åˆ¶å¹³é¢ï¼Œå°† AI çš„è¯­ä¹‰æ¨ç† (semantic reasoning) ä¸ç³»ç»Ÿçš„æ‰§è¡Œ (execution) åˆ†ç¦»ï¼Œä»è€Œå°†ä¼˜åŒ–è¿‡ç¨‹åˆ’åˆ†ä¸ºç›®æ ‡æ¨ç† (goal-inference) å’Œç­–ç•¥åˆæˆ (policy-synthesis) ä¸¤ä¸ªé˜¶æ®µã€‚SchedCP ä½œä¸º Model Context Protocol (MCP) æœåŠ¡å™¨å®ç°ï¼Œé›†æˆäº†å·¥ä½œè´Ÿè½½åˆ†æå¼•æ“ã€è°ƒåº¦ç­–ç•¥åº“åŠé€šè¿‡é™æ€å’ŒåŠ¨æ€åˆ†æç¡®ä¿å®‰å…¨çš„æ‰§è¡ŒéªŒè¯å™¨ã€‚é€šè¿‡ sched-agent å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨åˆ†æè´Ÿè½½å¹¶åˆ©ç”¨ sched_ext åŸºç¡€è®¾æ–½éƒ¨ç½²è‡ªå®šä¹‰çš„ eBPF è°ƒåº¦ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSchedCP å®ç°äº†é«˜è¾¾ 1.79 å€çš„æ€§èƒ½æå‡ï¼Œä¸”ç›¸æ¯”åŸç”Ÿæ™ºèƒ½ä½“æ–¹æ³•é™ä½äº† 13 å€çš„æˆæœ¬ã€‚è¿™ä¸€ç ”ç©¶é€šè¿‡å¼¥åˆè¯­ä¹‰é¸¿æ²Ÿï¼Œä¸ºæ„å»ºçœŸæ­£è‡ªä¼˜åŒ–ã€åº”ç”¨æ„ŸçŸ¥å‹çš„æ“ä½œç³»ç»Ÿ (Agentic OS) å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.OS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01245v4",
      "published_date": "2025-09-01 08:38:49 UTC",
      "updated_date": "2025-09-30 02:48:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:00.991649+00:00"
    },
    {
      "arxiv_id": "2509.01241v1",
      "title": "RT-DETRv2 Explained in 8 Illustrations",
      "title_zh": "8 å›¾è¯¦è§£ RT-DETRv2",
      "authors": [
        "Ethan Qi Yang Chua",
        "Jen Hong Tan"
      ],
      "abstract": "Object detection architectures are notoriously difficult to understand, often more so than large language models. While RT-DETRv2 represents an important advance in real-time detection, most existing diagrams do little to clarify how its components actually work and fit together. In this article, we explain the architecture of RT-DETRv2 through a series of eight carefully designed illustrations, moving from the overall pipeline down to critical components such as the encoder, decoder, and multi-scale deformable attention. Our goal is to make the existing one genuinely understandable. By visualizing the flow of tensors and unpacking the logic behind each module, we hope to provide researchers and practitioners with a clearer mental model of how RT-DETRv2 works under the hood.",
      "tldr_zh": "è¯¥æ–‡ç« æ·±å…¥è§£æäº†å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹ RT-DETRv2 çš„æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ç›®æ ‡æ£€æµ‹æ¶æ„å› å…¶é«˜åº¦å¤æ‚æ€§è€Œéš¾ä»¥è¢«ç ”ç©¶è€…ç›´è§‚ç†è§£çš„é—®é¢˜ã€‚ä½œè€…é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å…«å¼ æ’å›¾ï¼Œç³»ç»Ÿåœ°å±•ç¤ºäº†ä»æ•´ä½“ Pipeline åˆ°ç¼–ç å™¨ (Encoder)ã€è§£ç å™¨ (Decoder) ä»¥åŠå¤šå°ºåº¦å˜å½¢æ³¨æ„åŠ›æœºåˆ¶ (Multi-scale Deformable Attention) ç­‰æ ¸å¿ƒç»„ä»¶çš„è¿ä½œæµç¨‹ã€‚è¯¥æ–‡é€šè¿‡å¯è§†åŒ–å¼ é‡æµ (Tensor Flow) å¹¶æ‹†è§£å„æ¨¡å—èƒŒåçš„é€»è¾‘ï¼Œä¸º RT-DETRv2 çš„å†…éƒ¨å·¥ä½œæœºåˆ¶æä¾›äº†æ¯”ç°æœ‰å›¾è§£æ›´æ¸…æ™°çš„æ€ç»´æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œè‡´åŠ›äºè®©å¤æ‚çš„æ¶æ„åŸç†å˜å¾—çœŸæ­£æ˜“äºç†è§£ï¼Œä»è€Œå¸®åŠ©ä»ä¸šè€…æ›´å¥½åœ°æŒæ¡å…¶å®é™…è¿è¡Œæ–¹å¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01241v1",
      "published_date": "2025-09-01 08:28:01 UTC",
      "updated_date": "2025-09-01 08:28:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:20.299228+00:00"
    },
    {
      "arxiv_id": "2509.01238v1",
      "title": "Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework",
      "title_zh": "é¢å‘çŸ¥è¯†å›¾è°±çš„å¼€æ”¾ä¸–ç•Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼šä¸€ç§å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶",
      "authors": [
        "Jiasheng Xu",
        "Mingda Li",
        "Yongqiang Tang",
        "Peijie Wang",
        "Wensheng Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in language understanding and reasoning. However, their dependence on static training corpora makes them prone to factual errors and knowledge gaps. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external knowledge sources, especially structured Knowledge Graphs (KGs), which provide explicit semantics and efficient retrieval. Existing KG-based RAG approaches, however, generally assume that anchor entities are accessible to initiate graph traversal, which limits their robustness in open world settings where accurate linking between the query and the entity is unreliable. To overcome this limitation, we propose AnchorRAG, a novel multi-agent collaboration framework for open-world RAG without the predefined anchor entities. Specifically, a predictor agent dynamically identifies candidate anchor entities by aligning user query terms with KG nodes and initializes independent retriever agents to conduct parallel multi-hop explorations from each candidate. Then a supervisor agent formulates the iterative retrieval strategy for these retriever agents and synthesizes the resulting knowledge paths to generate the final answer. This multi-agent collaboration framework improves retrieval robustness and mitigates the impact of ambiguous or erroneous anchors. Extensive experiments on four public benchmarks demonstrate that AnchorRAG significantly outperforms existing baselines and establishes new state-of-the-art results on the real-world question answering tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºAnchorRAGçš„æ–°å‹å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸºäºçŸ¥è¯†å›¾è°±(Knowledge Graph)çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)åœ¨å¼€æ”¾ä¸–ç•Œè®¾ç½®ä¸­ä¾èµ–é¢„å®šä¹‰é”šç‚¹å®ä½“(anchor entities)çš„å±€é™æ€§ã€‚ä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•åœ¨å®ä½“é“¾æ¥ä¸å¯é æ—¶çš„è„†å¼±æ€§ï¼ŒAnchorRAGé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå®ç°äº†æ— éœ€é¢„å®šä¹‰é”šç‚¹çš„æ£€ç´¢ã€‚å…·ä½“è€Œè¨€ï¼Œé¢„æµ‹æ™ºèƒ½ä½“(predictor agent)åŠ¨æ€è¯†åˆ«å€™é€‰é”šç‚¹å¹¶å¼•å¯¼æ£€ç´¢æ™ºèƒ½ä½“(retriever agents)è¿›è¡Œå¹¶è¡Œçš„å¤šè·³æ¢ç´¢ï¼Œè€Œç›‘ç£æ™ºèƒ½ä½“(supervisor agent)è´Ÿè´£åˆ¶å®šæ£€ç´¢ç­–ç•¥å¹¶åˆæˆæœ€ç»ˆçŸ¥è¯†è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAnchorRAGåœ¨å››ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œåœ¨çœŸå®é—®ç­”ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„æ•ˆæœã€‚è¯¥æ¡†æ¶æœ‰æ•ˆæå‡äº†çŸ¥è¯†æ£€ç´¢çš„é²æ£’æ€§ï¼Œå¹¶æˆåŠŸå‡è½»äº†æ­§ä¹‰æˆ–é”™è¯¯é”šç‚¹å¯¹æ¨¡å‹è¡¨ç°çš„å½±å“ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01238v1",
      "published_date": "2025-09-01 08:26:12 UTC",
      "updated_date": "2025-09-01 08:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:23.289280+00:00"
    },
    {
      "arxiv_id": "2509.01236v1",
      "title": "Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors",
      "title_zh": "é‡æ–°å®¡è§†æ€ç»´é“¾ï¼šä¸Šä¸‹æ–‡å­¦ä¹ ä¸é¢„è®­ç»ƒå…ˆéªŒçš„ä½œç”¨",
      "authors": [
        "Hao Yang",
        "Zhiyu Yang",
        "Yunjie Zhang",
        "Shanyi Zhu",
        "Lin Yang"
      ],
      "abstract": "Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing model inference capabilities. Despite growing interest in Chain-of-Thought reasoning, its underlying mechanisms remain unclear. This paper explores the working mechanisms of Chain-of-Thought reasoning from the perspective of the dual relationship between in-context learning and pretrained priors. We first conduct a fine-grained lexical-level analysis of rationales to examine the model's reasoning behavior. Then, by incrementally introducing noisy exemplars, we examine how the model balances pretrained priors against erroneous in-context information. Finally, we investigate whether prompt engineering can induce slow thinking in large language models. Our extensive experiments reveal three key findings: (1) The model not only quickly learns the reasoning structure at the lexical level but also grasps deeper logical reasoning patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient exemplars shifts the model's decision-making from pretrained priors to in-context signals, while misleading prompts introduce instability. (3) Long Chain-of-Thought prompting can induce the model to generate longer reasoning chains, thereby improving its performance on downstream tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning)ä¸é¢„è®­ç»ƒå…ˆéªŒ(Pre-trained Priors)çš„åŒé‡å…³ç³»è§†è§’ï¼Œæ·±å…¥æ¢è®¨äº†æ€ç»´é“¾(Chain-of-Thought)æ¨ç†çš„åº•å±‚è¿ä½œæœºåˆ¶ã€‚é€šè¿‡å¯¹æ¨ç†è¿‡ç¨‹è¿›è¡Œç»†ç²’åº¦çš„è¯æ³•åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹åœ¨å­¦ä¹ æ¨ç†ç»“æ„çš„åŒæ—¶ä»é«˜åº¦ä¾èµ–é¢„è®­ç»ƒå…ˆéªŒã€‚å®éªŒè¡¨æ˜ï¼Œæä¾›å……è¶³çš„ç¤ºä¾‹å¯ä»¥å°†æ¨¡å‹çš„å†³ç­–é‡å¿ƒä»é¢„è®­ç»ƒå…ˆéªŒè½¬ç§»åˆ°ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œä½†è¯¯å¯¼æ€§æç¤ºä¼šå¼•å…¥ä¸ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°é•¿æ€ç»´é“¾æç¤ºèƒ½è¯±å¯¼æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼Œä»è€Œæ˜¾è‘—æ”¹å–„å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¿™äº›å‘ç°ä¸ºç†è§£å¤§è¯­è¨€æ¨¡å‹å¦‚ä½•å¹³è¡¡å†…éƒ¨çŸ¥è¯†ä¸å¤–éƒ¨æç¤ºæä¾›äº†é‡è¦è§è§£ï¼Œå¹¶éªŒè¯äº†é€šè¿‡æç¤ºå·¥ç¨‹å®ç°â€œæ…¢æ€è€ƒâ€çš„å¯èƒ½æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01236v1",
      "published_date": "2025-09-01 08:24:28 UTC",
      "updated_date": "2025-09-01 08:24:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:31.486834+00:00"
    },
    {
      "arxiv_id": "2509.01229v1",
      "title": "LiquidGEMM: Hardware-Efficient W4A8 GEMM Kernel for High-Performance LLM Serving",
      "title_zh": "LiquidGEMMï¼šé¢å‘é«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡å‹æœåŠ¡çš„é«˜ç¡¬ä»¶æ•ˆç‡ W4A8 GEMM ç®—å­",
      "authors": [
        "Huanqi Hu",
        "Bowen Xiao",
        "Shixuan Sun",
        "Jianian Yin",
        "Zhexi Zhang",
        "Xiang Luo",
        "Chengquan Jiang",
        "Weiqi Xu",
        "Xiaoying Jia",
        "Xin Liu",
        "Minyi Guo"
      ],
      "abstract": "Quantization is a critical technique for accelerating LLM inference by reducing memory footprint and improving computational efficiency. Among various schemes, 4-bit weight and 8-bit activation quantization (W4A8) offers a strong balance between accuracy and performance. However, existing W4A8 GEMM kernels fall short in practice due to inefficient dequantization on CUDA Cores, which cannot keep pace with the high throughput of Tensor Cores. In this paper, we present LiquidGEMM, a hardware-efficient W4A8 GEMM kernel for efficient LLM serving. LiquidGEMM designs two key techniques: LiquidQuant, a hardware-efficient quantization method that enables fast, overflow-safe dequantization using just two arithmetic instructions per four elements; and an implicit fine-grained pipeline that fully overlaps weight loading, dequantization, and MMA across warp groups without software synchronization or redundant memory traffic. Experimental results show that LiquidGEMM achieves up to 2.90x speedup over state-of-the-art W4A8 kernels and up to 4.94x end-to-end system-level speedup. Compared to various quantized GEMM kernels in NVIDIA TensorRT-LLM, LiquidGEMM delivers 1.12-1.63x performance gains, and achieves up to 1.63x system-level speedup.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)æ¨ç†ä¸­ W4A8 é‡åŒ–æ–¹æ¡ˆåœ¨ CUDA Cores ä¸Šåé‡åŒ–æ•ˆç‡ä½ä¸‹ã€æ— æ³•åŒ¹é… Tensor Cores é«˜ååé‡çš„é—®é¢˜ï¼Œæå‡ºäº† LiquidGEMM è¿™ä¸€ç¡¬ä»¶é«˜æ•ˆçš„ GEMM ç®—å­ã€‚LiquidGEMM æ ¸å¿ƒè®¾è®¡åŒ…æ‹¬ LiquidQuant æŠ€æœ¯ï¼Œé€šè¿‡æ¯å››ä¸ªå…ƒç´ ä»…éœ€ä¸¤æ¡ç®—æœ¯æŒ‡ä»¤å®ç°å¿«é€Ÿä¸”æ— æº¢å‡ºçš„åé‡åŒ–ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œè¯¥ç®—å­é‡‡ç”¨éšå¼ç»†ç²’åº¦æµæ°´çº¿(implicit fine-grained pipeline)è®¾è®¡ï¼Œå®ç°äº†æƒé‡åŠ è½½ã€åé‡åŒ–ä¸ MMA æ“ä½œçš„å®Œå…¨é‡å ï¼Œä¸”æ— éœ€é¢å¤–çš„è½¯ä»¶åŒæ­¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLiquidGEMM ç›¸æ¯”ç°æœ‰æœ€å…ˆè¿›çš„ W4A8 ç®—å­å®ç°äº†é«˜è¾¾ 2.90 å€çš„åŠ é€Ÿï¼Œå¹¶åœ¨ç«¯åˆ°ç«¯ç³»ç»Ÿå±‚é¢æå‡æ€§èƒ½è¾¾ 4.94 å€ã€‚ä¸ NVIDIA TensorRT-LLM ç›¸æ¯”ï¼Œè¯¥æ–¹æ¡ˆä¹Ÿå–å¾—äº† 1.12 è‡³ 1.63 å€çš„æ€§èƒ½å¢ç›Šï¼Œä¸ºé«˜æ€§èƒ½å¤§æ¨¡å‹æ¨ç†æœåŠ¡æä¾›äº†é«˜æ•ˆçš„ç®—å­æ”¯æ’‘ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01229v1",
      "published_date": "2025-09-01 08:16:20 UTC",
      "updated_date": "2025-09-01 08:16:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:32.889169+00:00"
    },
    {
      "arxiv_id": "2509.01221v2",
      "title": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression",
      "title_zh": "DaMoCï¼šåŸºäºæ•°æ®ä¸æ¨¡å‹å‹ç¼©çš„é¢†åŸŸä»»åŠ¡å¾®è°ƒæœ€ä¼˜å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆé€‰æ‹©",
      "authors": [
        "Wei Huang",
        "Huang Wei",
        "Yinggui Wang"
      ],
      "abstract": "Large language models (LLMs) excel in general tasks but struggle with domain-specific ones, requiring fine-tuning with specific data. With many open-source LLMs available, selecting the best model for fine-tuning downstream tasks is challenging, primarily focusing on how to quickly identify the optimal LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses this challenge by: 1) Data Level: A systematic categorization of data filtering methodologies for LLMs is first established, classifying them into three distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods, and (3) hybrid approaches considering both dimensions. Further, we enhance the density of key tokens in the text achieving token compression. Subsequently, we use an LLM to iterative rewrite the text to optimize its expression. 2) Model Level: We use layer similarity scores to assess each layer's importance and remove those with lower importance. Then, we introduce a sparse merging paradigm to preserve as much of the original model's capability as possible. Extensive experiments on four datasets, medical Q&A, financial Q&A, general Q&A, and reading comprehension, show that we can select the optimal LLM while saving approximately 20-fold in training time.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DaMoCï¼Œä¸€ä¸ªåŸºäºæ•°æ®å’Œæ¨¡å‹å‹ç¼©(Data and Model Compression)çš„æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆé€‰æ‹©ç”¨äºç‰¹å®šé¢†åŸŸä»»åŠ¡å¾®è°ƒçš„æœ€ä¼˜å¤§è¯­è¨€æ¨¡å‹(LLMs)ã€‚åœ¨æ•°æ®å±‚é¢ï¼Œè¯¥æ¡†æ¶ç³»ç»ŸåŒ–åœ°å»ºç«‹äº†æ¶µç›–åˆ†å¸ƒæ„ŸçŸ¥(distribution-aware)ã€è´¨é‡æ„ŸçŸ¥(quality-aware)å’Œæ··åˆæ–¹æ³•(hybrid approaches)çš„æ•°æ®è¿‡æ»¤èŒƒå¼ï¼Œå¹¶é€šè¿‡å¢å¼ºå…³é”®æ ‡å¿—(key tokens)å¯†åº¦ä¸LLMè¿­ä»£é‡å†™æ¥ä¼˜åŒ–æ–‡æœ¬è¡¨è¾¾ã€‚åœ¨æ¨¡å‹å±‚é¢ï¼ŒDaMoCåˆ©ç”¨å±‚ç›¸ä¼¼åº¦å¾—åˆ†(layer similarity scores)è¯„ä¼°å¹¶ç§»é™¤é‡è¦æ€§è¾ƒä½çš„å±‚ï¼Œå¹¶å¼•å…¥ç¨€ç–åˆå¹¶èŒƒå¼(sparse merging paradigm)ä»¥ä¿ç•™æ¨¡å‹æ ¸å¿ƒèƒ½åŠ›ã€‚é’ˆå¯¹åŒ»ç–—é—®ç­”ã€é‡‘èé—®ç­”ã€é€šç”¨é—®ç­”åŠé˜…è¯»ç†è§£æ•°æ®é›†çš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½åœ¨å‡†ç¡®ç­›é€‰å‡ºæœ€ä¼˜LLMçš„åŒæ—¶ï¼Œå°†è®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­çº¦20å€ã€‚è¿™ä¸€æ–¹æ¡ˆä¸ºåœ¨æµ·é‡å¼€æºèµ„æºä¸­å¿«é€Ÿè¯†åˆ«æœ€é€‚åˆä¸‹æ¸¸ä»»åŠ¡çš„åŸºåº§æ¨¡å‹æä¾›äº†é«˜æ•ˆä¸”ç»æµçš„é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01221v2",
      "published_date": "2025-09-01 08:06:49 UTC",
      "updated_date": "2025-09-04 09:30:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:37.795200+00:00"
    },
    {
      "arxiv_id": "2509.01211v2",
      "title": "Web Fraud Attacks Against LLM-Driven Multi-Agent Systems",
      "title_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç½‘ç»œæ¬ºè¯ˆæ”»å‡»",
      "authors": [
        "Dezhang Kong",
        "Hujin Peng",
        "Yilun Zhang",
        "Lele Zhao",
        "Zhenhua Xu",
        "Shi Lin",
        "Changting Lin",
        "Meng Han"
      ],
      "abstract": "With the proliferation of LLM-driven multi-agent systems (MAS), the security of Web links has become a critical concern. Once MAS is induced to trust a malicious link, attackers can use it as a springboard to expand the attack surface. In this paper, we propose Web Fraud Attacks, a novel type of attack manipulating unique structures of web links to deceive MAS. We design 12 representative attack variants that encompass various methods, such as homoglyph deception, sub-directory nesting, and parameter obfuscation. Through extensive experiments on these attack vectors, we demonstrate that Web fraud attacks not only exhibit significant destructive potential across different MAS architectures but also possess a distinct advantage in evasion: they circumvent the need for complex input design, lowering the threshold for attacks significantly. These results underscore the importance of addressing Web fraud attacks, providing new insights into MAS safety. Our code is available at https://github.com/JiangYingEr/Web-Fraud-Attack-in-MAS.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (MAS) åœ¨å¤„ç† Web é“¾æ¥æ—¶çš„å®‰å…¨æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ç½‘é¡µé“¾æ¥ç‹¬ç‰¹ç»“æ„æ¬ºéª—ç³»ç»Ÿçš„ Web Fraud Attacksã€‚ç ”ç©¶è€…è®¾è®¡äº† 12 ç§ä»£è¡¨æ€§çš„æ”»å‡»å˜ä½“ï¼Œæ¶µç›–äº†åŒå½¢å¼‚ä¹‰è¯æ¬ºéª— (homoglyph deception)ã€å­ç›®å½•åµŒå¥— (sub-directory nesting) ä»¥åŠå‚æ•°æ··æ·† (parameter obfuscation) ç­‰å¤šç§æ‰‹æ®µã€‚é€šè¿‡å¯¹è¿™äº›æ”»å‡»å‘é‡çš„å¹¿æ³›å®éªŒï¼Œè¯æ˜äº† Web Fraud Attacks åœ¨ä¸åŒ MAS æ¶æ„ä¸­å‡å…·æœ‰æ˜¾è‘—çš„ç ´åæ½œåŠ›ã€‚æ­¤å¤–ï¼Œæ­¤ç±»æ”»å‡»åœ¨è§„é¿æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºç‹¬ç‰¹ä¼˜åŠ¿ï¼Œæ— éœ€å¤æ‚çš„è¾“å…¥è®¾è®¡å³å¯æ˜¾è‘—é™ä½æ”»å‡»é—¨æ§›ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº† MAS å®‰å…¨é˜²æŠ¤ä¸­çš„å…³é”®æ¼æ´ï¼Œå¹¶ä¸ºæå‡æ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§æä¾›äº†æ–°çš„è§è§£ä¸å¼€æºå·¥å…·ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01211v2",
      "published_date": "2025-09-01 07:47:24 UTC",
      "updated_date": "2026-01-07 08:30:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:47.191572+00:00"
    },
    {
      "arxiv_id": "2509.01206v3",
      "title": "EndoGMDE: Generalizable Monocular Depth Estimation with Mixture of Low-Rank Experts for Diverse Endoscopic Scenes",
      "title_zh": "EndoGMDEï¼šåŸºäºä½ç§©ä¸“å®¶æ··åˆçš„é¢å‘å¤šæ ·åŒ–å†…çª¥é•œåœºæ™¯çš„å¯æ³›åŒ–å•ç›®æ·±åº¦ä¼°è®¡",
      "authors": [
        "Liangjing Shao",
        "Chenkang Du",
        "Benshuang Chen",
        "Xueli Liu",
        "Xinrong Chen"
      ],
      "abstract": "Self-supervised monocular depth estimation is a significant task for low-cost and efficient 3D scene perception and measurement in endoscopy. However, the variety of illumination conditions and scene features is still the primary challenges for depth estimation in endoscopic scenes. In this work, a novel self-supervised framework is proposed for monocular depth estimation in diverse endoscopy. Firstly, considering the diverse features in endoscopic scenes with different tissues, a novel block-wise mixture of dynamic low-rank experts is proposed to efficiently finetune the foundation model for endoscopic depth estimation. In the proposed module, based on the input feature, different experts with a small amount of trainable parameters are adaptively selected for weighted inference, from low-rank experts which are allocated based on the generalization of each block. Moreover, a novel self-supervised training framework is proposed to jointly cope with brightness inconsistency and reflectance interference. The proposed method outperforms state-of-the-art works on SCARED dataset and SimCol dataset. Furthermore, the proposed network also achieves the best generalization based on zero-shot depth estimation on C3VD, Hamlyn and SERV-CT dataset. The outstanding performance of our model is further demonstrated with 3D reconstruction and ego-motion estimation. The proposed method could contribute to accurate endoscopy for minimally invasive measurement and surgery. The evaluation codes will be released upon acceptance, while the demo videos can be found on: https://endo-gmde.netlify.app/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EndoGMDEï¼Œä¸€ç§é¢å‘å¤šæ ·åŒ–å†…çª¥é•œåœºæ™¯çš„è‡ªç›‘ç£å•ç›®æ·±åº¦ä¼°è®¡(Monocular Depth Estimation)æ¡†æ¶ã€‚é’ˆå¯¹å†…çª¥é•œå½±åƒä¸­å…‰ç…§æ¡ä»¶å’Œç»„ç»‡ç‰¹å¾å¤æ‚å¤šå˜çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ç§å—çŠ¶åŠ¨æ€ä½ç§©ä¸“å®¶æ··åˆ(Mixture of Dynamic Low-Rank Experts)æ¨¡å—ï¼Œé€šè¿‡æå°‘é‡å¯è®­ç»ƒå‚æ•°é«˜æ•ˆåœ°å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¯¥æ¨¡å—èƒ½æ ¹æ®è¾“å…¥ç‰¹å¾è‡ªé€‚åº”åœ°é€‰æ‹©ä¸“å®¶è¿›è¡ŒåŠ æƒæ¨ç†ï¼Œå¹¶ç»“åˆå…¨æ–°çš„è‡ªç›‘ç£è®­ç»ƒç­–ç•¥æ¥ååŒå¤„ç†äº®åº¦ä¸ä¸€è‡´ä¸åå°„å¹²æ‰°é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ SCARED å’Œ SimCol æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„å…ˆè¿›ç®—æ³•(SOTA)ï¼Œå¹¶åœ¨ C3VDã€Hamlyn å’Œ SERV-CT ç­‰æ•°æ®é›†çš„é›¶æ ·æœ¬(zero-shot)æµ‹è¯•ä¸­å±•ç°å‡ºå“è¶Šçš„æ³›åŒ–æ€§èƒ½ã€‚è¯¥æ¨¡å‹åœ¨ 3D é‡å»ºå’Œè‡ªæˆ‘è¿åŠ¨ä¼°è®¡(Ego-motion Estimation)æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸ºå¾®åˆ›æµ‹é‡å’Œè¾…åŠ©æ‰‹æœ¯æä¾›äº†æ›´ç²¾ç¡®çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 12 figures, 7 tables. Under Review",
      "pdf_url": "https://arxiv.org/pdf/2509.01206v3",
      "published_date": "2025-09-01 07:45:12 UTC",
      "updated_date": "2025-11-02 11:25:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:47.485437+00:00"
    },
    {
      "arxiv_id": "2509.01198v1",
      "title": "Preserving Vector Space Properties in Dimensionality Reduction: A Relationship Preserving Loss Framework",
      "title_zh": "é™ç»´ä¸­å‘é‡ç©ºé—´å±æ€§çš„ä¿æŒï¼šä¸€ç§å…³ç³»ä¿æŒæŸå¤±æ¡†æ¶",
      "authors": [
        "Eddi Weinwurm",
        "Alexander Kovalenko"
      ],
      "abstract": "Dimensionality reduction can distort vector space properties such as orthogonality and linear independence, which are critical for tasks including cross-modal retrieval, clustering, and classification. We propose a Relationship Preserving Loss (RPL), a loss function that preserves these properties by minimizing discrepancies between relationship matrices (e.g., Gram or cosine) of high-dimensional data and their low-dimensional embeddings. RPL trains neural networks for non-linear projections and is supported by error bounds derived from matrix perturbation theory. Initial experiments suggest that RPL reduces embedding dimensions while largely retaining performance on downstream tasks, likely due to its preservation of key vector space properties. While we describe here the use of RPL in dimensionality reduction, this loss can also be applied more broadly, for example to cross-domain alignment and transfer learning, knowledge distillation, fairness and invariance, dehubbing, graph and manifold learning, and federated learning, where distributed embeddings must remain geometrically consistent.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é™ç»´è¿‡ç¨‹ä¸­å®¹æ˜“æ‰­æ›²å‘é‡ç©ºé—´å±æ€§ï¼ˆå¦‚ orthogonality å’Œ linear independenceï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº† Relationship Preserving Loss (RPL) æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æœ€å°åŒ–é«˜ç»´æ•°æ®ä¸å…¶ä½ç»´åµŒå…¥ä¹‹é—´å…³ç³»çŸ©é˜µï¼ˆå¦‚ Gram æˆ– cosine çŸ©é˜µï¼‰çš„å·®å¼‚ï¼Œæ¥ä¿æŒè¿™äº›å…³é”®çš„å‡ ä½•å±æ€§ã€‚RPL åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œéçº¿æ€§æŠ•å½±ï¼Œå¹¶å¾—åˆ°äº† matrix perturbation theory çš„è¯¯å·®ç•Œé™æ”¯æŒã€‚å®éªŒè¡¨æ˜ï¼ŒRPL åœ¨å¤§å¹…é™ä½åµŒå…¥ç»´åº¦çš„åŒæ—¶ï¼Œèƒ½æœ‰æ•ˆä¿ç•™ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼Œè¿™ä¸»è¦å½’åŠŸäºå…¶å¯¹å‘é‡ç©ºé—´æ€§è´¨çš„ç²¾å‡†ä¿æŒã€‚æ­¤å¤–ï¼Œè¯¥æŸå¤±å‡½æ•°è¿˜å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¯æ‰©å±•è‡³ cross-domain alignmentã€knowledge distillation ä»¥åŠ federated learning ç­‰å¤šä¸ªé¢†åŸŸï¼Œç¡®ä¿åˆ†å¸ƒå¼åµŒå…¥åœ¨å‡ ä½•ä¸Šä¿æŒä¸€è‡´ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01198v1",
      "published_date": "2025-09-01 07:31:11 UTC",
      "updated_date": "2025-09-01 07:31:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:49.759353+00:00"
    },
    {
      "arxiv_id": "2509.21325v1",
      "title": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation",
      "title_zh": "PIR-RAGï¼šé¢å‘æ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç§æœ‰ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿ",
      "authors": [
        "Baiqiang Wang",
        "Qian Lou",
        "Mengxin Zheng",
        "Dongfang Zhao"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG's scalability and its superior performance in terms of \"RAG-Ready Latency\"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PIR-RAGç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆ(Retrieval-Augmented Generation, RAG)ä¸­å› ç”¨æˆ·æŸ¥è¯¢æš´éœ²ç»™æœåŠ¡æä¾›å•†è€Œäº§ç”Ÿçš„éšç§é£é™©ã€‚PIR-RAGé‡‡ç”¨äº†ä¸€ç§åˆ›æ–°çš„æ¶æ„ï¼Œé€šè¿‡ç²—ç²’åº¦è¯­ä¹‰èšç±»(coarse-grained semantic clustering)æŠ€æœ¯æ¥ç²¾ç®€æœç´¢ç©ºé—´ï¼Œå¹¶ç»“åˆå¿«é€Ÿçš„åŸºäºæ ¼(lattice-based)çš„ç§äººä¿¡æ¯æ£€ç´¢(Private Information Retrieval, PIR)åè®®ã€‚è¯¥è®¾è®¡å…è®¸é«˜æ•ˆæ£€ç´¢æ•´ä¸ªæ–‡æ¡£ç°‡ï¼Œç‰¹åˆ«é’ˆå¯¹éœ€è¦å®Œæ•´æ–‡æ¡£å†…å®¹çš„ç«¯åˆ°ç«¯RAGå·¥ä½œæµè¿›è¡Œäº†ä¼˜åŒ–ã€‚é€šè¿‡ä¸åŸºäºå›¾çš„PIRå’ŒTiptoeå¼ç§äººè¯„åˆ†ç­‰å¼ºåŸºå‡†æ¶æ„çš„å¯¹æ¯”è¯„ä¼°ï¼ŒPIR-RAGå±•ç¤ºäº†å“è¶Šçš„å¯æ‰©å±•æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨â€œRAGå°±ç»ªå»¶è¿Ÿâ€(RAG-Ready Latency)æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç¼©çŸ­äº†ä¸ºå¤§è¯­è¨€æ¨¡å‹(LLM)å®‰å…¨è·å–å†…å®¹æ‰€éœ€çš„ç«¯åˆ°ç«¯æ—¶é—´ã€‚è¿™é¡¹å·¥ä½œç¡®ç«‹äº†PIR-RAGä½œä¸ºå¤§è§„æ¨¡AIç³»ç»Ÿä¸­å®ç°éšç§ä¿æŠ¤çš„ä¸€ç§æ—¢å¯è¡Œåˆé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.21325v1",
      "published_date": "2025-09-01 07:28:35 UTC",
      "updated_date": "2025-09-01 07:28:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:58:56.664131+00:00"
    },
    {
      "arxiv_id": "2509.01186v1",
      "title": "Statutory Construction and Interpretation for Artificial Intelligence",
      "title_zh": "é¢å‘äººå·¥æ™ºèƒ½çš„æ³•å¾‹è§£é‡Šä¸å»ºæ„",
      "authors": [
        "Luxi He",
        "Nimra Nadeem",
        "Michel Liao",
        "Howard Chen",
        "Danqi Chen",
        "Mariano-Florentino CuÃ©llar",
        "Peter Henderson"
      ],
      "abstract": "AI systems are increasingly governed by natural language principles, yet a key challenge arising from reliance on language remains underexplored: interpretive ambiguity. As in legal systems, ambiguity arises both from how these principles are written and how they are applied. But while legal systems use institutional safeguards to manage such ambiguity, such as transparent appellate review policing interpretive constraints, AI alignment pipelines offer no comparable protections. Different interpretations of the same rule can lead to inconsistent or unstable model behavior. Drawing on legal theory, we identify key gaps in current alignment pipelines by examining how legal systems constrain ambiguity at both the rule creation and rule application steps. We then propose a computational framework that mirrors two legal mechanisms: (1) a rule refinement pipeline that minimizes interpretive disagreement by revising ambiguous rules (analogous to agency rulemaking or iterative legislative action), and (2) prompt-based interpretive constraints that reduce inconsistency in rule application (analogous to legal canons that guide judicial discretion). We evaluate our framework on a 5,000-scenario subset of the WildChat dataset and show that both interventions significantly improve judgment consistency across a panel of reasonable interpreters. Our approach offers a first step toward systematically managing interpretive ambiguity, an essential step for building more robust, law-following AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨éµå¾ªè‡ªç„¶è¯­è¨€åŸåˆ™æ—¶é¢ä¸´çš„è§£é‡Šæ­§ä¹‰(interpretive ambiguity)æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰çš„AIå¯¹é½æµæ°´çº¿(alignment pipelines)åœ¨è§„åˆ™åˆ¶å®šä¸åº”ç”¨ä¸­ç¼ºä¹ç±»ä¼¼æ³•å¾‹ç³»ç»Ÿçš„åˆ¶åº¦æ€§ä¿éšœã€‚ç ”ç©¶å€Ÿé‰´æ³•å¾‹ç†è®ºè¯†åˆ«äº†ç°æœ‰å¯¹é½æµç¨‹ä¸­çš„å…³é”®ç¼ºé™·ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ¨¡æ‹Ÿæ³•å¾‹æœºåˆ¶çš„è®¡ç®—æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è§„åˆ™å®Œå–„æµæ°´çº¿(rule refinement pipeline)å’ŒåŸºäºæç¤ºè¯çš„è§£é‡Šçº¦æŸ(prompt-based interpretive constraints)æ¥æœ€å°åŒ–è§£é‡Šåˆ†æ­§å¹¶é™ä½è§„åˆ™åº”ç”¨çš„ä¸ä¸€è‡´æ€§ã€‚é€šè¿‡åœ¨WildChatæ•°æ®é›†çš„5,000ä¸ªåœºæ™¯å­é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå®éªŒè¯æ˜è¯¥å¹²é¢„æªæ–½èƒ½æ˜¾è‘—æé«˜ä¸åŒåˆç†è§£é‡Šè€…ä¹‹é—´çš„åˆ¤æ–­ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•ä¸ºç³»ç»ŸåŒ–ç®¡ç†AIè§£é‡Šæ­§ä¹‰æä¾›äº†åˆæ­¥æ–¹æ¡ˆï¼Œæ˜¯æ„å»ºæ›´ç¨³å¥ä¸”éµå¾ªæ³•å¾‹çš„AIç³»ç»Ÿçš„å…³é”®ä¸€æ­¥ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01186v1",
      "published_date": "2025-09-01 07:10:22 UTC",
      "updated_date": "2025-09-01 07:10:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:14.661943+00:00"
    },
    {
      "arxiv_id": "2509.01185v2",
      "title": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation",
      "title_zh": "é¢å‘è¯­è¨€æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°çš„åˆæˆé•¿ä¸Šä¸‹æ–‡æ•°æ®ç”Ÿæˆæ¨¡å—åŒ–æŠ€æœ¯",
      "authors": [
        "Seganrasan Subramanian",
        "Abhigya Verma"
      ],
      "abstract": "The ability of large language models (LLMs) to process and reason over long textual inputs is critical for a wide range of real-world applications. However, progress in this area is significantly constrained by the absence of high-quality, diverse, and verifiable long-context datasets suitable for both training and evaluation. This work introduces a modular, extensible framework for synthetic long-context data generation via prompt-based interaction with LLMs. The framework supports multiple training and alignment objectives, including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO). It encompasses four core generation paradigms: multi-turn conversational dialogues, document-grounded input-output pairs, verifiable instruction-response tasks, and long-context reasoning examples. Through templated prompting, a model-agnostic architecture, and metadata-enriched outputs, the proposed approach facilitates scalable, controllable, and purpose-aligned dataset creation for advancing long-context capabilities in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å’Œæ¨ç†é•¿æ–‡æœ¬è¾“å…¥æ—¶é¢ä¸´çš„é«˜è´¨é‡ã€å¤šæ ·åŒ–ä¸”å¯éªŒè¯çš„é•¿æ–‡æœ¬æ•°æ®é›†åŒ®ä¹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºåˆæˆé•¿æ–‡æœ¬æ•°æ®ç”Ÿæˆçš„æ¨¡å—åŒ–ã€å¯æ‰©å±•æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åŸºäºæç¤º(prompt-based)çš„LLMsäº¤äº’ï¼Œæ”¯æŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒ(SFT)ã€ç›´æ¥åå¥½ä¼˜åŒ–(DPO)å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)åœ¨å†…çš„å¤šç§è®­ç»ƒä¸å¯¹é½ç›®æ ‡ã€‚å®ƒæ¶µç›–äº†å››ç§æ ¸å¿ƒç”ŸæˆèŒƒå¼ï¼Œå³å¤šè½®å¯¹è¯(multi-turn conversational dialogues)ã€åŸºäºæ–‡æ¡£çš„è¾“å…¥è¾“å‡ºå¯¹(document-grounded input-output pairs)ã€å¯éªŒè¯çš„æŒ‡ä»¤å“åº”ä»»åŠ¡(verifiable instruction-response tasks)ä»¥åŠé•¿ä¸Šä¸‹æ–‡æ¨ç†ç¤ºä¾‹ã€‚é€šè¿‡æ¨¡æ¿åŒ–æç¤º(templated prompting)ã€æ¨¡å‹æ— å…³çš„æ¶æ„ä»¥åŠå¯Œå«å…ƒæ•°æ®çš„è¾“å‡ºï¼Œè¯¥æ–¹æ³•å®ç°äº†å¯æ‰©å±•ã€å¯æ§ä¸”ç›®æ ‡ä¸€è‡´çš„æ•°æ®é›†åˆ›å»ºã€‚è¿™ä¸€æˆæœä¸ºæœ‰æ•ˆæå‡LLMsçš„é•¿æ–‡æœ¬å¤„ç†ä¸æ¨ç†èƒ½åŠ›æä¾›äº†å…³é”®çš„æŠ€æœ¯æ‰‹æ®µå’Œæ•°æ®æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01185v2",
      "published_date": "2025-09-01 07:08:45 UTC",
      "updated_date": "2025-09-04 17:22:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:28.156001+00:00"
    },
    {
      "arxiv_id": "2509.01182v2",
      "title": "Question-to-Knowledge (Q2K): Multi-Agent Generation of Inspectable Facts for Product Mapping",
      "title_zh": "Question-to-Knowledge (Q2K)ï¼šé¢å‘å•†å“æ˜ å°„çš„å¯æ ¸æŸ¥äº‹å®å¤šæ™ºèƒ½ä½“ç”Ÿæˆæ–¹æ³•",
      "authors": [
        "Wonduk Seo",
        "Taesub Shin",
        "Hyunjin An",
        "Dokyun Kim",
        "Seunghyun Lee"
      ],
      "abstract": "Identifying whether two product listings refer to the same Stock Keeping Unit (SKU) is a persistent challenge in ecommerce, especially when explicit identifiers are missing and product names vary widely across platforms. Rule based heuristics and keyword similarity often misclassify products by overlooking subtle distinctions in brand, specification, or bundle configuration. To overcome these limitations, we propose Question to Knowledge (Q2K), a multi agent framework that leverages Large Language Models (LLMs) for reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates targeted disambiguation questions, (2) a Knowledge Agent that resolves them via focused web searches, and (3) a Deduplication Agent that reuses validated reasoning traces to reduce redundancy and ensure consistency. A human in the loop mechanism further refines uncertain cases. Experiments on real world consumer goods datasets show that Q2K surpasses strong baselines, achieving higher accuracy and robustness in difficult scenarios such as bundle identification and brand origin disambiguation. By reusing retrieved reasoning instead of issuing repeated searches, Q2K balances accuracy with efficiency, offering a scalable and interpretable solution for product integration.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µå­å•†åŠ¡ä¸­ SKU åŒ¹é…çš„éš¾é¢˜ï¼Œæå‡ºäº† Question-to-Knowledge (Q2K) å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè§„åˆ™å¯å‘å¼å’Œå…³é”®å­—ç›¸ä¼¼åº¦æ–¹æ³•åœ¨å¤„ç†å“ç‰Œã€è§„æ ¼æˆ–æ†ç»‘é…ç½®ç­‰ç»†å¾®å·®åˆ«æ—¶å®¹æ˜“è¯¯åˆ¤çš„é—®é¢˜ã€‚Q2K æ•´åˆäº† Reasoning Agent ä»¥ç”Ÿæˆé’ˆå¯¹æ€§çš„æ¶ˆé™¤æ­§ä¹‰é—®é¢˜ï¼Œå¹¶ç”± Knowledge Agent é€šè¿‡é’ˆå¯¹æ€§çš„ç½‘é¡µæœç´¢æ¥è·å–å¯éªŒè¯çš„äº‹å®ä¿¡æ¯ã€‚è¯¥æ¡†æ¶è¿˜é€šè¿‡ Deduplication Agent å¤ç”¨ç»è¿‡éªŒè¯çš„æ¨ç†è·¯å¾„ä»¥å‡å°‘å†—ä½™ï¼Œå¹¶å¼•å…¥ Human-in-the-loop æœºåˆ¶å¤„ç†é«˜åº¦ä¸ç¡®å®šçš„æ¡ˆä¾‹ã€‚åœ¨çœŸå®ä¸–ç•Œæ¶ˆè´¹å“æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒQ2K åœ¨å¤„ç†æ†ç»‘è¯†åˆ«å’Œå“ç‰ŒåŸäº§åœ°è¾¨æç­‰å¤æ‚åœºæ™¯æ—¶ï¼Œå…¶å‡†ç¡®æ€§å’Œé²æ£’æ€§æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿æ¨¡å‹ã€‚é€šè¿‡å¤ç”¨æ¨ç†è€Œéé‡å¤æœç´¢ï¼ŒQ2K åœ¨å¹³è¡¡å‡†ç¡®ç‡ä¸è¿è¡Œæ•ˆç‡çš„åŒæ—¶ï¼Œä¸ºäº§å“æ•´åˆæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å…·æœ‰å¯è§£é‡Šæ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE BigData 2025 Industry Track",
      "pdf_url": "https://arxiv.org/pdf/2509.01182v2",
      "published_date": "2025-09-01 07:07:19 UTC",
      "updated_date": "2025-11-11 12:13:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:30.457536+00:00"
    },
    {
      "arxiv_id": "2509.01181v1",
      "title": "FocusDPO: Dynamic Preference Optimization for Multi-Subject Personalized Image Generation via Adaptive Focus",
      "title_zh": "FocusDPOï¼šé€šè¿‡è‡ªé€‚åº”èšç„¦å®ç°å¤šä¸»ä½“ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆçš„åŠ¨æ€åå¥½ä¼˜åŒ–",
      "authors": [
        "Qiaoqiao Jin",
        "Siming Fu",
        "Dong She",
        "Weinan Jia",
        "Hualiang Wang",
        "Mu Liu",
        "Jidong Jiang"
      ],
      "abstract": "Multi-subject personalized image generation aims to synthesize customized images containing multiple specified subjects without requiring test-time optimization. However, achieving fine-grained independent control over multiple subjects remains challenging due to difficulties in preserving subject fidelity and preventing cross-subject attribute leakage. We present FocusDPO, a framework that adaptively identifies focus regions based on dynamic semantic correspondence and supervision image complexity. During training, our method progressively adjusts these focal areas across noise timesteps, implementing a weighted strategy that rewards information-rich patches while penalizing regions with low prediction confidence. The framework dynamically adjusts focus allocation during the DPO process according to the semantic complexity of reference images and establishes robust correspondence mappings between generated and reference subjects. Extensive experiments demonstrate that our method substantially enhances the performance of existing pre-trained personalized generation models, achieving state-of-the-art results on both single-subject and multi-subject personalized image synthesis benchmarks. Our method effectively mitigates attribute leakage while preserving superior subject fidelity across diverse generation scenarios, advancing the frontier of controllable multi-subject image synthesis.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FocusDPOï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³å¤šä¸»ä½“ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆ(Multi-subject personalized image generation)ä¸­ä¸»ä½“ä¿çœŸåº¦(subject fidelity)ä¸è¶³å’Œè·¨ä¸»ä½“å±æ€§æ³„æ¼(cross-subject attribute leakage)æŒ‘æˆ˜çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡åŠ¨æ€è¯­ä¹‰å¯¹åº”å’Œå›¾åƒå¤æ‚åº¦è‡ªé€‚åº”åœ°è¯†åˆ«ç„¦ç‚¹åŒºåŸŸï¼Œå¹¶åœ¨ä¸åŒçš„å™ªå£°æ—¶é—´æ­¥é•¿(noise timesteps)ä¸­é€æ­¥è°ƒæ•´è¿™äº›ç„¦ç‚¹ã€‚åœ¨ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)è¿‡ç¨‹ä¸­ï¼ŒFocusDPOé‡‡ç”¨åŠ æƒç­–ç•¥å¥–åŠ±ä¿¡æ¯ä¸°å¯Œçš„è¡¥ä¸å¹¶æƒ©ç½šä½ç½®ä¿¡åº¦åŒºåŸŸï¼Œä»è€Œå»ºç«‹ç”Ÿæˆä¸»ä½“ä¸å‚è€ƒä¸»ä½“ä¹‹é—´çš„é²æ£’å¯¹åº”æ˜ å°„ã€‚è¯¥æœºåˆ¶æœ‰æ•ˆåœ°ç¼“è§£äº†å±æ€§æ³„æ¼é—®é¢˜ï¼Œåœ¨ç¡®ä¿ç»†ç²’åº¦ç‹¬ç«‹æ§åˆ¶çš„åŒæ—¶ä¿æŒäº†å“è¶Šçš„ä¸»ä½“ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFocusDPOæ˜¾è‘—å¢å¼ºäº†ç°æœ‰é¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ï¼Œåœ¨å•ä¸»ä½“å’Œå¤šä¸»ä½“ä¸ªæ€§åŒ–å›¾åƒåˆæˆåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(state-of-the-art)çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01181v1",
      "published_date": "2025-09-01 07:06:36 UTC",
      "updated_date": "2025-09-01 07:06:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:38.441313+00:00"
    },
    {
      "arxiv_id": "2509.01177v1",
      "title": "DynaMind: Reconstructing Dynamic Visual Scenes from EEG by Aligning Temporal Dynamics and Multimodal Semantics to Guided Diffusion",
      "title_zh": "DynaMindï¼šé€šè¿‡å°†æ—¶é—´åŠ¨æ€ä¸å¤šæ¨¡æ€è¯­ä¹‰å¯¹é½è‡³å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œä»è„‘ç”µä¿¡å·ä¸­é‡å»ºåŠ¨æ€è§†è§‰åœºæ™¯",
      "authors": [
        "Junxiang Liu",
        "Junming Lin",
        "Jiangtong Li",
        "Jie Li"
      ],
      "abstract": "Reconstruction dynamic visual scenes from electroencephalography (EEG) signals remains a primary challenge in brain decoding, limited by the low spatial resolution of EEG, a temporal mismatch between neural recordings and video dynamics, and the insufficient use of semantic information within brain activity. Therefore, existing methods often inadequately resolve both the dynamic coherence and the complex semantic context of the perceived visual stimuli. To overcome these limitations, we introduce DynaMind, a novel framework that reconstructs video by jointly modeling neural dynamics and semantic features via three core modules: a Regional-aware Semantic Mapper (RSM), a Temporal-aware Dynamic Aligner (TDA), and a Dual-Guidance Video Reconstructor (DGVR). The RSM first utilizes a regional-aware encoder to extract multimodal semantic features from EEG signals across distinct brain regions, aggregating them into a unified diffusion prior. In the mean time, the TDA generates a dynamic latent sequence, or blueprint, to enforce temporal consistency between the feature representations and the original neural recordings. Together, guided by the semantic diffusion prior, the DGVR translates the temporal-aware blueprint into a high-fidelity video reconstruction. On the SEED-DV dataset, DynaMind sets a new state-of-the-art (SOTA), boosting reconstructed video accuracies (video- and frame-based) by 12.5 and 10.3 percentage points, respectively. It also achieves a leap in pixel-level quality, showing exceptional visual fidelity and temporal coherence with a 9.4% SSIM improvement and a 19.7% FVMD reduction. This marks a critical advancement, bridging the gap between neural dynamics and high-fidelity visual semantics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è„‘ç”µå›¾(EEG)ç©ºé—´åˆ†è¾¨ç‡ä½ã€ç¥ç»è®°å½•ä¸è§†é¢‘åŠ¨æ€ä¸åŒ¹é…ä»¥åŠè„‘æ´»åŠ¨è¯­ä¹‰ä¿¡æ¯åˆ©ç”¨ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºDynaMindçš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨ä»EEGä¿¡å·ä¸­é‡å»ºåŠ¨æ€è§†è§‰åœºæ™¯ã€‚è¯¥æ¡†æ¶ç”±Regional-aware Semantic Mapper (RSM)ã€Temporal-aware Dynamic Aligner (TDA)å’ŒDual-Guidance Video Reconstructor (DGVR)ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆã€‚RSMåˆ©ç”¨åŒºåŸŸæ„ŸçŸ¥ç¼–ç å™¨æå–ä¸åŒè„‘åŒºçš„å¤šæ¨¡æ€è¯­ä¹‰ç‰¹å¾å¹¶èšåˆä¸ºç»Ÿä¸€çš„æ‰©æ•£å…ˆéªŒ(diffusion prior)ï¼Œè€ŒTDAåˆ™é€šè¿‡ç”ŸæˆåŠ¨æ€æ½œåºåˆ—è“å›¾æ¥ç¡®ä¿ç‰¹å¾è¡¨ç¤ºä¸åŸå§‹ç¥ç»è®°å½•çš„æ—¶åºä¸€è‡´æ€§(temporal consistency)ã€‚DGVRåœ¨è¯­ä¹‰å…ˆéªŒçš„å¼•å¯¼ä¸‹ï¼Œå°†æ—¶åºæ„ŸçŸ¥è“å›¾æœ€ç»ˆè½¬åŒ–ä¸ºé«˜ä¿çœŸåº¦çš„é‡å»ºè§†é¢‘ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDynaMindåœ¨SEED-DVæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æ–°çš„SOTAæ°´å¹³ï¼Œå°†è§†é¢‘å’Œå¸§çš„é‡å»ºå‡†ç¡®ç‡åˆ†åˆ«æå‡äº†12.5å’Œ10.3ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨åƒç´ çº§è´¨é‡å’Œæ—¶åºè¿è´¯æ€§ä¸Šå®ç°æ˜¾è‘—çªç ´ï¼ŒSSIMæå‡äº†9.4%ä¸”FVMDé™ä½äº†19.7%ï¼Œæœ‰æ•ˆå¼¥åˆäº†ç¥ç»åŠ¨åŠ›å­¦ä¸é«˜ä¿çœŸè§†è§‰è¯­ä¹‰ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01177v1",
      "published_date": "2025-09-01 06:52:08 UTC",
      "updated_date": "2025-09-01 06:52:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:40.452149+00:00"
    },
    {
      "arxiv_id": "2509.01166v1",
      "title": "Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning",
      "title_zh": "é€šè¿‡ç»“æ„æ„ŸçŸ¥å¯¹é½å¾®è°ƒå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†å›¾è°±è¡¥å…¨èƒ½åŠ›",
      "authors": [
        "Yu Liu",
        "Yanan Cao",
        "Xixun Lin",
        "Yanmin Shang",
        "Shi Wang",
        "Shirui Pan"
      ],
      "abstract": "Knowledge graph completion (KGC) aims to infer new knowledge and make predictions from knowledge graphs. Recently, large language models (LLMs) have exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily focus on designing task-specific instructions, achieving promising advancements. However, there are still two critical challenges. First, existing methods often ignore the inconsistent representation spaces between natural language and graph structures. Second, most approaches design separate instructions for different KGC tasks, leading to duplicate works and time-consuming processes. To address these challenges, we propose SAT, a novel framework that enhances LLMs for KGC via structure-aware alignment-tuning. Specifically, we first introduce hierarchical knowledge alignment to align graph embeddings with the natural language space through multi-task contrastive learning. Then, we propose structural instruction tuning to guide LLMs in performing structure-aware reasoning over KGs, using a unified graph instruction combined with a lightweight knowledge adapter. Experimental results on two KGC tasks across four benchmark datasets demonstrate that SAT significantly outperforms state-of-the-art methods, especially in the link prediction task with improvements ranging from 8.7% to 29.8%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åä¸ºSATçš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„æ„ŸçŸ¥å¯¹é½å¾®è°ƒ(Structure-Aware Alignment-Tuning)å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨çŸ¥è¯†å›¾è°±è¡¥å…¨(KGC)ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é’ˆå¯¹ç°æœ‰LLMåœ¨å¤„ç†KGCæ—¶å­˜åœ¨çš„è‡ªç„¶è¯­è¨€ä¸å›¾ç»“æ„è¡¨ç¤ºç©ºé—´ä¸ä¸€è‡´ï¼Œä»¥åŠä¸åŒä»»åŠ¡éœ€è®¾è®¡ç‹¬ç«‹æŒ‡ä»¤å¯¼è‡´æ•ˆç‡ä½ä¸‹ç­‰æ ¸å¿ƒæŒ‘æˆ˜ã€‚SATé€šè¿‡å¼•å…¥å±‚æ¬¡åŒ–çŸ¥è¯†å¯¹é½æœºåˆ¶ï¼Œåˆ©ç”¨å¤šä»»åŠ¡å¯¹æ¯”å­¦ä¹ (multi-task contrastive learning)å°†å›¾åµŒå…¥æœ‰æ•ˆåœ°å¯¹é½åˆ°è‡ªç„¶è¯­è¨€ç©ºé—´ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†ç»“æ„åŒ–æŒ‡ä»¤å¾®è°ƒ(structural instruction tuning)ç­–ç•¥ï¼Œç»“åˆç»Ÿä¸€çš„å›¾æŒ‡ä»¤ä¸è½»é‡çº§çŸ¥è¯†é€‚é…å™¨(knowledge adapter)ï¼Œå¼•å¯¼LLMè¿›è¡Œç»“æ„æ„ŸçŸ¥æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSATåœ¨å¤šé¡¹KGCåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨é“¾æ¥é¢„æµ‹(link prediction)ä»»åŠ¡ä¸Šçš„è¡¨ç°æå‡äº†8.7%è‡³29.8%ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025, Main, Long Paper",
      "pdf_url": "https://arxiv.org/pdf/2509.01166v1",
      "published_date": "2025-09-01 06:38:11 UTC",
      "updated_date": "2025-09-01 06:38:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:48.288268+00:00"
    },
    {
      "arxiv_id": "2509.01153v2",
      "title": "EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection",
      "title_zh": "EZhouNetï¼šä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œå’Œé”šç‚¹åŒºé—´çš„å‘¼å¸éŸ³äº‹ä»¶æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Yun Chu",
        "Qiuhao Wang",
        "Enze Zhou",
        "Qian Liu",
        "Gang Zheng"
      ],
      "abstract": "Auscultation is a key method for early diagnosis of respiratory and pulmonary diseases, relying on skilled healthcare professionals. However, the process is often subjective, with variability between experts. As a result, numerous deep learning-based automatic classification methods have emerged, most of which focus on respiratory sound classification. In contrast, research on respiratory sound event detection remains limited. Existing sound event detection methods typically rely on frame-level predictions followed by post-processing to generate event-level outputs, making interval boundaries challenging to learn directly. Furthermore, many approaches can only handle fixed-length audio, limiting their applicability to variable-length respiratory sounds. Additionally, the impact of respiratory sound location information on detection performance has not been extensively explored. To address these issues, we propose a graph neural network-based framework with anchor intervals, capable of handling variable-length audio and providing more precise temporal localization for abnormal respiratory sound events. Our method improves both the flexibility and applicability of respiratory sound detection. Experiments on the SPRSound 2024 and HF Lung V1 datasets demonstrate the effectiveness of the proposed approach, and incorporating respiratory position information enhances the discrimination between abnormal sounds. The reference implementation is available at https://github.com/chumingqian/EzhouNet.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†EZhouNetï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)å’Œé”šç‚¹åŒºé—´(Anchor Interval)çš„å‘¼å¸éŸ³äº‹ä»¶æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœç°æœ‰æ–¹æ³•åœ¨å¤„ç†å˜é•¿éŸ³é¢‘å’Œç²¾ç¡®æ—¶é—´å®šä½ä¸Šçš„å±€é™ã€‚é’ˆå¯¹ä¼ ç»Ÿæ¨¡å‹ä¾èµ–å¸§çº§é¢„æµ‹å¯¼è‡´äº‹ä»¶è¾¹ç•Œéš¾ä»¥ç²¾å‡†æ•è·çš„é—®é¢˜ï¼ŒEZhouNeté€šè¿‡å¼•å…¥é”šç‚¹åŒºé—´æœºåˆ¶ç›´æ¥å­¦ä¹ äº‹ä»¶çº§åˆ«çš„ä¿¡æ¯ï¼Œå¤§å¹…å¢å¼ºäº†å‘¼å¸éŸ³æ£€æµ‹çš„çµæ´»æ€§ã€‚åœ¨SPRSound 2024å’ŒHF Lung V1æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœéªŒè¯äº†è¯¥æ¡†æ¶çš„ä¼˜è¶Šæ€§èƒ½ï¼Œå¹¶æ˜¾ç¤ºå‡ºè‰¯å¥½çš„åº”ç”¨æ½œåŠ›ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œå¼•å…¥å‘¼å¸ä½ç½®ä¿¡æ¯èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åŒºåˆ†å¼‚å¸¸å£°éŸ³çš„å‡†ç¡®åº¦ã€‚è¯¥ç ”ç©¶ä¸ºä¸´åºŠå‘¼å¸ç³»ç»Ÿç–¾ç—…çš„è‡ªåŠ¨åŒ–æ—©æœŸè¯Šæ–­æä¾›äº†æ›´å…·å®ç”¨ä»·å€¼çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œå…¶ç›¸å…³å®ç°ä»£ç å·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01153v2",
      "published_date": "2025-09-01 06:10:30 UTC",
      "updated_date": "2025-09-04 01:07:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:00.083872+00:00"
    },
    {
      "arxiv_id": "2509.01136v1",
      "title": "Heads or Tails: A Simple Example of Causal Abstractive Simulation",
      "title_zh": "æ­£é¢æˆ–åé¢ï¼šå› æœæŠ½è±¡æ¨¡æ‹Ÿçš„ç®€å•ç¤ºä¾‹",
      "authors": [
        "Gabriel Simmons"
      ],
      "abstract": "This note illustrates how a variety of causal abstraction arXiv:1707.00819 arXiv:1812.03789, defined here as causal abstractive simulation, can be used to formalize a simple example of language model simulation. This note considers the case of simulating a fair coin toss with a language model. Examples are presented illustrating the ways language models can fail to simulate, and a success case is presented, illustrating how this formalism may be used to prove that a language model simulates some other system, given a causal description of the system. This note may be of interest to three groups. For practitioners in the growing field of language model simulation, causal abstractive simulation is a means to connect ad-hoc statistical benchmarking practices to the solid formal foundation of causality. Philosophers of AI and philosophers of mind may be interested as causal abstractive simulation gives a precise operationalization to the idea that language models are role-playing arXiv:2402.12422. Mathematicians and others working on causal abstraction may be interested to see a new application of the core ideas that yields a new variation of causal abstraction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å› æœæŠ½è±¡æ¨¡æ‹Ÿ (Causal Abstractive Simulation) è¿™ä¸€å½¢å¼åŒ–æ–¹æ³•æ¥æè¿°è¯­è¨€æ¨¡å‹ (Language Model) çš„æ¨¡æ‹Ÿè¡Œä¸ºï¼Œå¹¶ä»¥å…¬å¹³ç¡¬å¸æŠ•æ·ä½œä¸ºå…·ä½“æ¡ˆä¾‹è¿›è¡Œè¯´æ˜ã€‚è®ºæ–‡è¯¦ç»†åˆ†æäº†è¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­çš„å„ç§å¤±è´¥æ¨¡å¼ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨è¯¥å½¢å¼åŒ–æ¡†æ¶è¯æ˜æ¨¡å‹åœ¨å·²çŸ¥ç³»ç»Ÿå› æœæè¿°çš„æƒ…å†µä¸‹æˆåŠŸå®ç°äº†æ¨¡æ‹Ÿã€‚å¯¹äºç›¸å…³ä»ä¸šè€…ï¼Œè¯¥æ–¹æ³•å°†é›¶æ•£çš„ç»Ÿè®¡åŸºå‡†æµ‹è¯•ä¸ç¨³å›ºçš„å› æœå…³ç³» (Causality) ç†è®ºåŸºç¡€ç›¸è¿æ¥ã€‚æ­¤å¤–ï¼Œè¿™é¡¹å·¥ä½œè¿˜ä¸ºäººå·¥æ™ºèƒ½å“²å­¦ä¸­çš„è§’è‰²æ‰®æ¼” (Role-playing) æ¦‚å¿µæä¾›äº†ç²¾ç¡®çš„æ“ä½œåŒ–å®šä¹‰ã€‚æœ€åï¼Œè¯¥ç ”ç©¶ä¸ºæ•°å­¦åŠç›¸å…³é¢†åŸŸçš„å› æœæŠ½è±¡ç†è®ºè´¡çŒ®äº†æ–°çš„åº”ç”¨åœºæ™¯å’Œå˜ä½“ï¼Œå…·æœ‰é‡è¦çš„è·¨å­¦ç§‘ç†è®ºä¸å®è·µæ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.01136v1",
      "published_date": "2025-09-01 05:10:02 UTC",
      "updated_date": "2025-09-01 05:10:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:07.987784+00:00"
    },
    {
      "arxiv_id": "2509.01135v1",
      "title": "MATL-DC: A Multi-domain Aggregation Transfer Learning Framework for EEG Emotion Recognition with Domain-Class Prototype under Unseen Targets",
      "title_zh": "MATL-DCï¼šä¸€ç§é¢å‘æœªçŸ¥ç›®æ ‡ä¸”ç»“åˆé¢†åŸŸ-ç±»åˆ«åŸå‹çš„ EEG æƒ…ç»ªè¯†åˆ«å¤šé¢†åŸŸèšåˆè¿ç§»å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Guangli Li",
        "Canbiao Wu",
        "Zhehao Zhou",
        "Na Tian",
        "Zhen Liang"
      ],
      "abstract": "Emotion recognition based on electroencephalography (EEG) signals is increasingly becoming a key research hotspot in affective Brain-Computer Interfaces (aBCIs). However, the current transfer learning model greatly depends on the source domain and target domain data, which hinder the practical application of emotion recognition. Therefore, we propose a Multi-domain Aggregation Transfer Learning framework for EEG emotion recognition with Domain-Class prototype under unseen targets (MATL-DC). We design the feature decoupling module to decouple class-invariant domain features from domain-invariant class features from shallow features. In the model training stage, the multi-domain aggregation mechanism aggregates the domain feature space to form a superdomain, which enhances the characteristics of emotional EEG signals. In each superdomain, we further extract the class prototype representation by class features. In addition, we adopt the pairwise learning strategy to transform the sample classification problem into the similarity problem between sample pairs, which effectively alleviates the influence of label noise. It is worth noting that the target domain is completely unseen during the training process. In the inference stage, we use the trained domain-class prototypes for inference, and then realize emotion recognition. We rigorously validate it on the publicly available databases (SEED, SEED-IV and SEED-V). The results show that the accuracy of MATL-DC model is 84.70\\%, 68.11\\% and 61.08\\%, respectively. MATL-DC achieves comparable or even better performance than methods that rely on both source and target domains. The source code is available at https://github.com/WuCB-BCI/MATL-DC.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MATL-DCï¼Œä¸€ç§é¢å‘æœªçŸ¥ç›®æ ‡åŸŸ(unseen targets)çš„è„‘ç”µ(EEG)æƒ…æ„Ÿè¯†åˆ«å¤šåŸŸèšåˆè¿ç§»å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹è¿‡åº¦ä¾èµ–ç›®æ ‡åŸŸæ•°æ®è€Œé™åˆ¶å®é™…åº”ç”¨çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶è®¾è®¡äº†ç‰¹å¾è§£è€¦æ¨¡å—(feature decoupling module)ï¼Œé€šè¿‡ä»æµ…å±‚ç‰¹å¾ä¸­åˆ†ç¦»ç±»ä¸å˜é¢†åŸŸç‰¹å¾ä¸åŸŸä¸å˜ç±»åˆ«ç‰¹å¾æ¥æå‡æ³›åŒ–èƒ½åŠ›ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤šåŸŸèšåˆæœºåˆ¶(multi-domain aggregation mechanism)å°†å¤šä¸ªé¢†åŸŸç‰¹å¾ç©ºé—´èšåˆæˆè¶…åŸŸ(superdomain)ä»¥å¢å¼ºä¿¡å·ï¼Œå¹¶ä»ä¸­æå–ç±»åˆ«åŸå‹(class prototype)è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨æˆå¯¹å­¦ä¹ ç­–ç•¥(pairwise learning strategy)å°†åˆ†ç±»ä»»åŠ¡è½¬åŒ–ä¸ºç›¸ä¼¼åº¦è¯„ä¼°ï¼Œæœ‰æ•ˆç¼“è§£äº†æ ‡ç­¾å™ªå£°å¹²æ‰°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç›®æ ‡åŸŸå®Œå…¨ä¸å¯è§çš„æƒ…å†µä¸‹ï¼ŒMATL-DCåœ¨SEEDã€SEED-IVå’ŒSEED-Væ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†84.70%ã€68.11%å’Œ61.08%çš„å‡†ç¡®ç‡ã€‚è¯¥æ¨¡å‹åœ¨æ— éœ€ç›®æ ‡åŸŸå‚ä¸è®­ç»ƒçš„å‰æä¸‹ï¼Œè¡¨ç°å‡ºäº†ä¸éœ€è¦ç›®æ ‡åŸŸæ•°æ®çš„è¿ç§»å­¦ä¹ æ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸ºæƒ…æ„Ÿè„‘æœºæ¥å£(aBCIs)çš„å®é™…åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01135v1",
      "published_date": "2025-09-01 05:08:04 UTC",
      "updated_date": "2025-09-01 05:08:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:04.896942+00:00"
    },
    {
      "arxiv_id": "2509.06982v1",
      "title": "CARE: Decoding Time Safety Alignment via Rollback and Introspection Intervention",
      "title_zh": "CAREï¼šåŸºäºå›æ»šä¸å†…çœå¹²é¢„çš„è§£ç æ—¶å®‰å…¨å¯¹é½",
      "authors": [
        "Xiaomeng Hu",
        "Fei Huang",
        "Chenhan Yuan",
        "Junyang Lin",
        "Tsung-Yi Ho"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in real-world applications, ensuring the safety of their outputs during decoding has become a critical challenge. However, existing decoding-time interventions, such as Contrastive Decoding, often force a severe trade-off between safety and response quality. In this work, we propose CARE, a novel framework for decoding-time safety alignment that integrates three key components: (1) a guard model for real-time safety monitoring, enabling detection of potentially unsafe content; (2) a rollback mechanism with a token buffer to correct unsafe outputs efficiently at an earlier stage without disrupting the user experience; and (3) a novel introspection-based intervention strategy, where the model generates self-reflective critiques of its previous outputs and incorporates these reflections into the context to guide subsequent decoding steps. The framework achieves a superior safety-quality trade-off by using its guard model for precise interventions, its rollback mechanism for timely corrections, and our novel introspection method for effective self-correction. Experimental results demonstrate that our framework achieves a superior balance of safety, quality, and efficiency, attaining a low harmful response rate and minimal disruption to the user experience while maintaining high response quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CAREï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè§£ç é˜¶æ®µå®‰å…¨å¯¹é½ï¼ˆdecoding-time safety alignmentï¼‰è®¾è®¡çš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§ä¸å›å¤è´¨é‡ä¹‹é—´éš¾ä»¥æƒè¡¡çš„æŒ‘æˆ˜ã€‚CAREé›†æˆäº†ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼šç”¨äºå®æ—¶å®‰å…¨ç›‘æµ‹çš„å®ˆæŠ¤æ¨¡å‹ï¼ˆguard modelï¼‰ï¼Œå…·å¤‡ä»¤ç‰Œç¼“å†²åŒºä¸”èƒ½é«˜æ•ˆçº æ­£æ—©æœŸä¸å®‰å…¨è¾“å‡ºçš„å›é€€æœºåˆ¶ï¼ˆrollback mechanismï¼‰ï¼Œä»¥åŠä¸€ç§åŸºäºå†…çœï¼ˆintrospection-basedï¼‰çš„å¹²é¢„ç­–ç•¥ã€‚è¯¥ç­–ç•¥é€šè¿‡è®©æ¨¡å‹ç”Ÿæˆè‡ªæˆ‘åæ€æ€§è¯„ä»·ï¼ˆself-reflective critiquesï¼‰å¹¶å°†å…¶èå…¥ä¸Šä¸‹æ–‡ï¼Œæœ‰æ•ˆå¼•å¯¼åç»­çš„è§£ç æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCAREåœ¨æ˜¾è‘—é™ä½æœ‰å®³å›å¤ç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¿æŒæé«˜çš„å›å¤è´¨é‡å¹¶æœ€å¤§é™åº¦å‡å°‘å¯¹ç”¨æˆ·ä½“éªŒçš„å¹²æ‰°ã€‚é€šè¿‡ç²¾ç¡®ç›‘æµ‹ã€åŠæ—¶å›é€€ä¸æœ‰æ•ˆè‡ªçº çš„ç»“åˆï¼Œè¯¥æ¡†æ¶åœ¨å®‰å…¨æ€§ã€ç”Ÿæˆè´¨é‡å’Œè¿è¡Œæ•ˆç‡ä¹‹é—´å®ç°äº†ä¼˜è¶Šçš„å¹³è¡¡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.06982v1",
      "published_date": "2025-09-01 04:50:02 UTC",
      "updated_date": "2025-09-01 04:50:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T15:59:57.356489+00:00"
    },
    {
      "arxiv_id": "2509.01119v1",
      "title": "SC-GIR: Goal-oriented Semantic Communication via Invariant Representation Learning",
      "title_zh": "SC-GIRï¼šåŸºäºä¸å˜æ€§è¡¨ç¤ºå­¦ä¹ çš„é¢å‘ç›®æ ‡çš„è¯­ä¹‰é€šä¿¡",
      "authors": [
        "Senura Hansaja Wanasekara",
        "Van-Dinh Nguyen",
        "Kok-Seng",
        "M. -Duong Nguyen",
        "Symeon Chatzinotas",
        "Octavia A. Dobre"
      ],
      "abstract": "Goal-oriented semantic communication (SC) aims to revolutionize communication systems by transmitting only task-essential information. However, current approaches face challenges such as joint training at transceivers, leading to redundant data exchange and reliance on labeled datasets, which limits their task-agnostic utility. To address these challenges, we propose a novel framework called Goal-oriented Invariant Representation-based SC (SC-GIR) for image transmission. Our framework leverages self-supervised learning to extract an invariant representation that encapsulates crucial information from the source data, independent of the specific downstream task. This compressed representation facilitates efficient communication while retaining key features for successful downstream task execution. Focusing on machine-to-machine tasks, we utilize covariance-based contrastive learning techniques to obtain a latent representation that is both meaningful and semantically dense. To evaluate the effectiveness of the proposed scheme on downstream tasks, we apply it to various image datasets for lossy compression. The compressed representations are then used in a goal-oriented AI task. Extensive experiments on several datasets demonstrate that SC-GIR outperforms baseline schemes by nearly 10%,, and achieves over 85% classification accuracy for compressed data under different SNR conditions. These results underscore the effectiveness of the proposed framework in learning compact and informative latent representations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢å‘ç›®æ ‡çš„è¯­ä¹‰é€šä¿¡ï¼ˆGoal-oriented semantic communicationï¼‰ä¸­å­˜åœ¨çš„è”åˆè®­ç»ƒå¤æ‚ã€å†—ä½™æ•°æ®äº¤æ¢åŠå¯¹æ ‡æ³¨æ•°æ®é›†è¿‡åº¦ä¾èµ–ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSC-GIRçš„æ–°å‹å›¾åƒä¼ è¾“æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ï¼ˆself-supervised learningï¼‰æå–æºæ•°æ®ä¸­ä¸ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡æ— å…³çš„ä¸å˜è¡¨å¾ï¼ˆinvariant representationï¼‰ï¼Œä»¥å®ç°ä»…ä¼ è¾“ä»»åŠ¡å…³é”®ä¿¡æ¯çš„ç›®æ ‡ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†åŸºäºåæ–¹å·®çš„å¯¹æ¯”å­¦ä¹ æŠ€æœ¯ï¼ˆcovariance-based contrastive learningï¼‰æ¥è·å–è¯­ä¹‰å¯†é›†ä¸”å…·æœ‰ä»£è¡¨æ€§çš„æ½œè¡¨å¾ï¼Œæœ‰æ•ˆæå‡äº†æœºå™¨ç±»ä»»åŠ¡çš„é€šä¿¡æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSC-GIRåœ¨å¤šé¡¹å›¾åƒæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºåŸºçº¿æ–¹æ¡ˆè¿‘10%ï¼Œä¸”åœ¨ä¸åŒä¿¡å™ªæ¯”ï¼ˆSNRï¼‰æ¡ä»¶ä¸‹å‡èƒ½ä¿æŒ85%ä»¥ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ã€‚è¿™ä¸€ç ”ç©¶æˆæœè¯æ˜äº†SC-GIRåœ¨å­¦ä¹ ç´§å‡‘ä¸”ä¿¡æ¯ä¸°å¯Œçš„æ½œè¡¨å¾æ–¹é¢çš„å“è¶Šæ€§èƒ½ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€ä»»åŠ¡ä¸å¯çŸ¥çš„è¯­ä¹‰é€šä¿¡ç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, Accepted to IEEE Transactions on Mobile Computing",
      "pdf_url": "https://arxiv.org/pdf/2509.01119v1",
      "published_date": "2025-09-01 04:29:43 UTC",
      "updated_date": "2025-09-01 04:29:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:07.593118+00:00"
    },
    {
      "arxiv_id": "2509.01110v2",
      "title": "NoLBERT: A No Lookahead(back) Foundational Language Model",
      "title_zh": "NoLBERTï¼šæ— å‰ç»ï¼ˆåè§ï¼‰åŸºç¡€è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ali Kakhbod",
        "Peiyao Li"
      ],
      "abstract": "We present NoLBERT, a lightweight, timestamped foundational language model for empirical research -- particularly for forecasting in economics, finance, and the social sciences. By pretraining exclusively on text from 1976 to 1995, NoLBERT avoids both lookback and lookahead biases (information leakage) that can undermine econometric inference. It exceeds domain-specific baselines on NLP benchmarks while maintaining temporal consistency. Applied to patent texts, NoLBERT enables the construction of firm-level innovation networks and shows that gains in innovation centrality predict higher long-run profit growth.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NoLBERTï¼Œä¸€ä¸ªè½»é‡çº§ä¸”å¸¦æœ‰æ—¶é—´æˆ³çš„åŸºç¡€è¯­è¨€æ¨¡å‹(Foundational Language Model)ï¼Œä¸“ä¸ºç»æµã€é‡‘èå’Œç¤¾ä¼šç§‘å­¦é¢†åŸŸçš„å®è¯ç ”ç©¶è€Œè®¾è®¡ã€‚é€šè¿‡ä»…åœ¨1976å¹´è‡³1995å¹´çš„æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒ(Pretraining)ï¼ŒNoLBERTæœ‰æ•ˆåœ°é¿å…äº†å¯èƒ½æŸå®³è®¡é‡ç»æµå­¦æ¨æ–­çš„å›æº¯åå·®(Lookback Bias)å’Œå‰ç»åå·®(Lookahead Bias)ï¼Œä»æ ¹æºä¸Šè§£å†³äº†ä¿¡æ¯æ³„éœ²é—®é¢˜ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†(NLP)åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹çš„è¡¨ç°è¶…è¶Šäº†ç‰¹å®šé¢†åŸŸçš„åŸºå‡†ï¼ŒåŒæ—¶ä¿æŒäº†ä¸¥è°¨çš„æ—¶é—´ä¸€è‡´æ€§ã€‚é€šè¿‡å¯¹ä¸“åˆ©æ–‡æœ¬çš„åˆ†æï¼ŒNoLBERTæˆåŠŸæ„å»ºäº†ä¼ä¸šå±‚é¢çš„åˆ›æ–°ç½‘ç»œï¼Œå¹¶è¯æ˜äº†åˆ›æ–°ä¸­å¿ƒåœ°ä½çš„å¢å¼ºèƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹ä¼ä¸šé•¿æœŸçš„åˆ©æ¶¦å¢é•¿ï¼Œä¸ºå­¦æœ¯ç ”ç©¶æä¾›äº†å¯é çš„é¢„æµ‹å·¥å…·ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.LG",
        "q-fin.GN"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01110v2",
      "published_date": "2025-09-01 04:07:10 UTC",
      "updated_date": "2025-11-16 23:13:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:37.090180+00:00"
    },
    {
      "arxiv_id": "2509.01106v2",
      "title": "Robix: A Unified Model for Robot Interaction, Reasoning and Planning",
      "title_zh": "Robixï¼šæœºå™¨äººäº¤äº’ã€æ¨ç†ä¸è§„åˆ’çš„ç»Ÿä¸€æ¨¡å‹",
      "authors": [
        "Huang Fang",
        "Mengxi Zhang",
        "Heng Dong",
        "Wei Li",
        "Zixuan Wang",
        "Qifeng Zhang",
        "Xueyun Tian",
        "Yucheng Hu",
        "Hang Li"
      ],
      "abstract": "We introduce Robix, a unified model that integrates robot reasoning, task planning, and natural language interaction within a single vision-language architecture. Acting as the high-level cognitive layer in a hierarchical robot system, Robix dynamically generates atomic commands for the low-level controller and verbal responses for human interaction, enabling robots to follow complex instructions, plan long-horizon tasks, and interact naturally with human within an end-to-end framework. Robix further introduces novel capabilities such as proactive dialogue, real-time interruption handling, and context-aware commonsense reasoning during task execution. At its core, Robix leverages chain-of-thought reasoning and adopts a three-stage training strategy: (1) continued pretraining to enhance foundational embodied reasoning abilities including 3D spatial understanding, visual grounding, and task-centric reasoning; (2) supervised finetuning to model human-robot interaction and task planning as a unified reasoning-action sequence; and (3) reinforcement learning to improve reasoning-action consistency and long-horizon task coherence. Extensive experiments demonstrate that Robix outperforms both open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in interactive task execution, demonstrating strong generalization across diverse instruction types (e.g., open-ended, multi-stage, constrained, invalid, and interrupted) and various user-involved tasks such as table bussing, grocery shopping, and dietary filtering.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Robixï¼Œè¿™æ˜¯ä¸€ä¸ªå°†æœºå™¨äººæ¨ç† (reasoning)ã€ä»»åŠ¡è§„åˆ’ (task planning) å’Œè‡ªç„¶è¯­è¨€äº¤äº’ (natural language interaction) é›†æˆåœ¨å•ä¸€è§†è§‰è¯­è¨€æ¶æ„ä¸­çš„ç»Ÿä¸€æ¨¡å‹ã€‚ä½œä¸ºåˆ†å±‚æœºå™¨äººç³»ç»Ÿä¸­çš„é«˜å±‚è®¤çŸ¥å±‚ï¼ŒRobix èƒ½å¤ŸåŠ¨æ€ç”Ÿæˆåº•å±‚æ§åˆ¶å™¨çš„åŸå­æŒ‡ä»¤å’Œä¸äººäº¤äº’çš„è¯­è¨€å“åº”ï¼Œå¹¶åˆ©ç”¨ Chain-of-Thought æ¨ç†å®ç°ç«¯åˆ°ç«¯çš„å¤æ‚æŒ‡ä»¤éµå¾ªã€‚è¯¥æ¨¡å‹å¼•å…¥äº†ä¸»åŠ¨å¯¹è¯ (proactive dialogue)ã€å®æ—¶ä¸­æ–­å¤„ç† (real-time interruption handling) ä»¥åŠä»»åŠ¡æ‰§è¡ŒæœŸé—´çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¸¸è¯†æ¨ç† (context-aware commonsense reasoning) ç­‰æ ¸å¿ƒèƒ½åŠ›ã€‚åœ¨è®­ç»ƒä¸Šï¼ŒRobix é‡‡ç”¨äº†ç»“åˆæŒç»­é¢„è®­ç»ƒ (continued pretraining)ã€ç›‘ç£å¾®è°ƒ (supervised finetuning) å’Œå¼ºåŒ–å­¦ä¹  (reinforcement learning) çš„ä¸‰é˜¶æ®µç­–ç•¥ï¼Œä»¥å¢å¼ºå…·èº«æ¨ç†èƒ½åŠ›å¹¶ç¡®ä¿é•¿æœŸä»»åŠ¡çš„è¿è´¯æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRobix åœ¨äº¤äº’å¼ä»»åŠ¡æ‰§è¡Œæ–¹é¢ä¼˜äº GPT-4o å’Œ Gemini 2.5 Pro ç­‰åŸºçº¿æ¨¡å‹ï¼Œåœ¨å¤šé˜¶æ®µå’Œå—é™æŒ‡ä»¤ä¸‹å±•ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ¨¡å‹åœ¨é¤æ¡Œæ¸…ç†ã€é£Ÿå“æ‚è´§è´­ç‰©å’Œé¥®é£Ÿè¿‡æ»¤ç­‰å¤šç§å®é™…åº”ç”¨åœºæ™¯ä¸­ï¼Œå‡è¯æ˜äº†å…¶åœ¨å¤„ç†å¤æ‚ç”¨æˆ·äº¤äº’ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Tech report. Project page: https://robix-seed.github.io/robix/",
      "pdf_url": "https://arxiv.org/pdf/2509.01106v2",
      "published_date": "2025-09-01 03:53:47 UTC",
      "updated_date": "2025-09-11 12:40:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:54.150498+00:00"
    },
    {
      "arxiv_id": "2509.01098v1",
      "title": "CCE: Confidence-Consistency Evaluation for Time Series Anomaly Detection",
      "title_zh": "CCEï¼šé¢å‘æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„ç½®ä¿¡åº¦ä¸ä¸€è‡´æ€§è¯„ä¼°",
      "authors": [
        "Zhijie Zhong",
        "Zhiwen Yu",
        "Yiu-ming Cheung",
        "Kaixiang Yang"
      ],
      "abstract": "Time Series Anomaly Detection metrics serve as crucial tools for model evaluation. However, existing metrics suffer from several limitations: insufficient discriminative power, strong hyperparameter dependency, sensitivity to perturbations, and high computational overhead. This paper introduces Confidence-Consistency Evaluation (CCE), a novel evaluation metric that simultaneously measures prediction confidence and uncertainty consistency. By employing Bayesian estimation to quantify the uncertainty of anomaly scores, we construct both global and event-level confidence and consistency scores for model predictions, resulting in a concise CCE metric. Theoretically and experimentally, we demonstrate that CCE possesses strict boundedness, Lipschitz robustness against score perturbations, and linear time complexity $\\mathcal{O}(n)$. Furthermore, we establish RankEval, a benchmark for comparing the ranking capabilities of various metrics. RankEval represents the first standardized and reproducible evaluation pipeline that enables objective comparison of evaluation metrics. Both CCE and RankEval implementations are fully open-source.",
      "tldr_zh": "æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ (Time Series Anomaly Detection) çš„ç°æœ‰è¯„ä¼°æŒ‡æ ‡å­˜åœ¨åŒºåˆ†èƒ½åŠ›ä¸è¶³ã€è¶…å‚æ•°ä¾èµ–å¼ºã€å¯¹æ‰°åŠ¨æ•æ„Ÿä»¥åŠè®¡ç®—å¼€é”€é«˜ç­‰å±€é™æ€§ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† Confidence-Consistency Evaluation (CCE)ï¼Œè¿™æ˜¯ä¸€ç§åŒæ—¶è¡¡é‡é¢„æµ‹ç½®ä¿¡åº¦ (Confidence) å’Œä¸ç¡®å®šæ€§ä¸€è‡´æ€§ (Consistency) çš„æ–°å‹è¯„ä¼°æŒ‡æ ‡ã€‚è¯¥æ–¹æ³•é€šè¿‡é‡‡ç”¨è´å¶æ–¯ä¼°è®¡ (Bayesian estimation) æ¥é‡åŒ–å¼‚å¸¸åˆ†æ•°çš„é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¹¶æ„å»ºäº†å…¨å±€å’Œäº‹ä»¶çº§åˆ«çš„è¯„åˆ†ä½“ç³»ã€‚ç†è®ºå’Œå®éªŒè¯æ˜ï¼ŒCCE å…·å¤‡ä¸¥æ ¼çš„æœ‰ç•Œæ€§ã€é’ˆå¯¹åˆ†æ•°æ‰°åŠ¨çš„ Lipschitz é²æ£’æ€§ä»¥åŠ $O(n)$ çš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜å»ºç«‹äº† RankEval åŸºå‡†ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºå®¢è§‚æ¯”è¾ƒè¯„ä¼°æŒ‡æ ‡æ’åºèƒ½åŠ›çš„æ ‡å‡†åŒ–ã€å¯å¤ç°çš„è¯„ä»·æµç¨‹ã€‚ç›®å‰ï¼ŒCCE æŒ‡æ ‡åŠå…¶å¯¹åº”çš„ RankEval å®ç°å‡å·²å®Œå…¨å¼€æºã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 10 figures, 6 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01098v1",
      "published_date": "2025-09-01 03:38:38 UTC",
      "updated_date": "2025-09-01 03:38:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:28.491330+00:00"
    },
    {
      "arxiv_id": "2509.01093v1",
      "title": "Natural Context Drift Undermines the Natural Language Understanding of Large Language Models",
      "title_zh": "è‡ªç„¶è¯­å¢ƒæ¼‚ç§»å‰Šå¼±äº†å¤§è¯­è¨€æ¨¡å‹çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›",
      "authors": [
        "Yulong Wu",
        "Viktor Schlegel",
        "Riza Batista-Navarro"
      ],
      "abstract": "How does the natural evolution of context paragraphs affect question answering in generative Large Language Models (LLMs)? To investigate this, we propose a framework for curating naturally evolved, human-edited variants of reading passages from contemporary QA benchmarks and for analyzing LLM performance across a range of semantic similarity scores, which quantify how closely each variant aligns with content seen during pretraining. Using this framework, we evaluate six QA datasets and eight LLMs with publicly available training data. Our experiments reveal that LLM performance declines as reading passages naturally diverge from the versions encountered during pretraining-even when the question and all necessary information remains present at inference time. For instance, average model accuracy on BoolQ drops by over 30% from the highest to lowest similarity bins, with slopes exceeding 70 across several LLMs. These findings suggest that natural text evolution poses a significant challenge to the language understanding capabilities of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸Šä¸‹æ–‡æ®µè½çš„è‡ªç„¶æ¼”å˜ï¼ˆNatural evolutionï¼‰å¦‚ä½•å½±å“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é—®ç­”æ€§èƒ½ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç”¨äºåˆ†ææ¨¡å‹åœ¨ä¸åŒè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆSemantic similarity scoresï¼‰ä¸‹è¡¨ç°çš„è¯„ä¼°æ¡†æ¶ã€‚é€šè¿‡å¯¹6ä¸ªé—®ç­”æ•°æ®é›†å’Œ8ä¸ª LLMs çš„å®éªŒè¯„ä¼°ï¼Œç ”ç©¶å‘ç°å½“é˜…è¯»ææ–™ä¸é¢„è®­ç»ƒé˜¶æ®µæ¥è§¦è¿‡çš„ç‰ˆæœ¬å‘ç”Ÿè‡ªç„¶åç¦»æ—¶ï¼Œå³ä½¿æ¨ç†è¿‡ç¨‹ä¸­åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Œæ¨¡å‹çš„æ€§èƒ½ä»ä¼šæ˜¾è‘—ä¸‹é™ã€‚åœ¨ BoolQ ç­‰æ•°æ®é›†ä¸Šçš„æµ‹è¯•æ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ç›¸ä¼¼åº¦æœ€ä½çš„åŒºé—´å†…å¹³å‡å‡†ç¡®ç‡ä¸‹é™äº†è¶…è¿‡ 30%ï¼Œå¤šä¸ªæ¨¡å‹çš„æ€§èƒ½ä¸‹é™æ–œç‡ï¼ˆslopesï¼‰ç”šè‡³è¶…è¿‡ 70ã€‚è¿™ä¸€å‘ç°è¯æ˜äº†è‡ªç„¶è¯­å¢ƒæ¼‚ç§»ï¼ˆNatural context driftï¼‰å¯¹å¤§è¯­è¨€æ¨¡å‹çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›æ„æˆäº†ä¸¥å³»æŒ‘æˆ˜ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨å¤„ç†åç¦»é¢„è®­ç»ƒæ•°æ®çš„æ–‡æœ¬æ—¶å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2509.01093v1",
      "published_date": "2025-09-01 03:32:50 UTC",
      "updated_date": "2025-09-01 03:32:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:36.793085+00:00"
    },
    {
      "arxiv_id": "2509.01092v2",
      "title": "REFRAG: Rethinking RAG based Decoding",
      "title_zh": "REFRAGï¼šå¯¹åŸºäº RAG è§£ç æœºåˆ¶çš„é‡æ–°æ€è€ƒ",
      "authors": [
        "Xiaoqiang Lin",
        "Aritra Ghosh",
        "Bryan Kian Hsiang Low",
        "Anshumali Shrivastava",
        "Vijai Mohan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in leveraging extensive external knowledge to enhance responses in multi-turn and agentic applications, such as retrieval-augmented generation (RAG). However, processing long-context inputs introduces significant system latency and demands substantial memory for the key-value cache, resulting in reduced throughput and a fundamental trade-off between knowledge enrichment and system efficiency. While minimizing latency for long-context inputs is a primary objective for LLMs, we contend that RAG require specialized consideration. In RAG, much of the LLM context consists of concatenated passages from retrieval, with only a small subset directly relevant to the query. These passages often exhibit low semantic similarity due to diversity or deduplication during re-ranking, leading to block-diagonal attention patterns that differ from those in standard LLM generation tasks. Based on this observation, we argue that most computations over the RAG context during decoding are unnecessary and can be eliminated with minimal impact on performance. To this end, we propose REFRAG, an efficient decoding framework that compresses, senses, and expands to improve latency in RAG applications. By exploiting the sparsity structure, we demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to previous work) without loss in perplexity. In addition, our optimization framework for large context enables REFRAG to extend the context size of LLMs by 16. We provide rigorous validation of REFRAG across diverse long-context tasks, including RAG, multi-turn conversations, and long document summarization, spanning a wide range of datasets. Experimental results confirm that REFRAG delivers substantial speedup with no loss in accuracy compared to LLaMA models and other state-of-the-art baselines across various context sizes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†REFRAGï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)è§£ç æ•ˆç‡çš„é«˜æ•ˆæ¡†æ¶ï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶é¢ä¸´çš„é«˜å»¶è¿Ÿå’Œé”®å€¼ç¼“å­˜(KV Cache)å†…å­˜è´Ÿæ‹…ã€‚ç ”ç©¶è€…è§‚å¯Ÿåˆ°RAGä¸Šä¸‹æ–‡ä¸­çš„æ£€ç´¢æ®µè½å…·æœ‰ä½è¯­ä¹‰ç›¸ä¼¼åº¦å’Œå—å¯¹è§’(block-diagonal)æ³¨æ„åŠ›æ¨¡å¼çš„ç‰¹å¾ï¼Œæ®æ­¤æ¨æ–­è§£ç è¿‡ç¨‹ä¸­é’ˆå¯¹å¤§éƒ¨åˆ†ä¸Šä¸‹æ–‡çš„è®¡ç®—æ˜¯å†—ä½™çš„ã€‚REFRAGé€šè¿‡å‹ç¼©(compress)ã€æ„ŸçŸ¥(sense)å’Œæ‰©å±•(expand)ä¸‰ä¸ªé˜¶æ®µï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„ç¨€ç–ç»“æ„(sparsity structure)æ¥æ¶ˆé™¤ä¸å¿…è¦çš„è®¡ç®—ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¸æŸå¤±å›°æƒ‘åº¦(perplexity)çš„æƒ…å†µä¸‹ï¼Œå°†é¦–å­—ç”Ÿæˆæ—¶é—´(TTFT)åŠ é€Ÿäº†30.85å€ï¼Œæ€§èƒ½è¾ƒå‰åºå·¥ä½œæå‡äº†3.75å€ã€‚æ­¤å¤–ï¼ŒREFRAGé€šè¿‡ä¼˜åŒ–æ¡†æ¶æˆåŠŸå°†LLMsçš„æœ‰æ•ˆä¸Šä¸‹æ–‡è§„æ¨¡æ‰©å±•äº†16å€ã€‚åœ¨åŒ…æ‹¬å¤šè½®å¯¹è¯å’Œé•¿æ–‡æ¡£æ‘˜è¦åœ¨å†…çš„å¤šé¡¹é•¿æ–‡æœ¬ä»»åŠ¡éªŒè¯ä¸­ï¼ŒREFRAGåœ¨ä¿æŒä¸LLaMAç­‰æ¨¡å‹åŒç­‰å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°äº†æ˜¾è‘—çš„æ¨ç†åŠ é€Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "fix typo perplexity->log perplexity; added recent papers",
      "pdf_url": "https://arxiv.org/pdf/2509.01092v2",
      "published_date": "2025-09-01 03:31:44 UTC",
      "updated_date": "2025-10-12 04:46:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:40.089851+00:00"
    },
    {
      "arxiv_id": "2509.01083v3",
      "title": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving",
      "title_zh": "DSDEï¼šé¢å‘çœŸå®æ¨ç†æœåŠ¡åœºæ™¯çš„å…·å¤‡ KLD ç¨³å®šæ€§çš„åŠ¨æ€æŠ•æœºè§£ç ",
      "authors": [
        "Mingyu Yang",
        "Jae-Young Choi",
        "Kihyo Moon",
        "Minsung Jang",
        "Eunjoo Jeon"
      ],
      "abstract": "Speculative decoding accelerates large language model inference, but its reliance on a fixed speculation length is suboptimal in large-batch serving environments with diverse requests. This paper explores a new direction for dynamic adaptation by investigating a novel class of post-hoc, diagnostic signals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free framework built on two primary components: (1) a predictive signal based on the variance of the Kullback-Leibler (KLD) divergence, which diagnoses the generation's regional stability, and (2) an adaptive speculation length cap to mitigate the straggler problem in per-sequence decoding. Experiments demonstrate the potential of using KLD-based stability signals for dynamic adaptation. An algorithm guided by these signals achieves end-to-end latency competitive with leading baselines and exhibits superior robustness across diverse workloads. This robustness is particularly valuable in challenging low-acceptance-rate regimes, where the proposed signal maintains its diagnostic utility. Collectively, these findings validate post-hoc signals as a valuable component for building more robust and intelligent LLM inference systems, and highlight a promising direction for future research on dynamic speculation length adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DSDEï¼ˆDynamic Speculative Decoding Engineï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§æ‰¹é‡æ¨ç†æœåŠ¡ä¸­å›ºå®šæ¨æµ‹é•¿åº¦å¯¼è‡´çš„æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚DSDEæ ¸å¿ƒç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶æ„æˆï¼šä¸€æ˜¯åŸºäºKullback-Leibler (KLD)æ•£åº¦æ–¹å·®çš„é¢„æµ‹ä¿¡å·ï¼Œç”¨äºè¯Šæ–­æ–‡æœ¬ç”Ÿæˆçš„åŒºåŸŸç¨³å®šæ€§ï¼›äºŒæ˜¯è‡ªé€‚åº”æ¨æµ‹é•¿åº¦ä¸Šé™æœºåˆ¶ï¼Œä»¥ç¼“è§£åºåˆ—è§£ç ä¸­çš„straggleré—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç®—æ³•åœ¨ç«¯åˆ°ç«¯å»¶è¿Ÿä¸Šä¸é¢†å…ˆçš„åŸºçº¿æ¨¡å‹ç›¸å½“ï¼Œå¹¶åœ¨å„ç§å·¥ä½œè´Ÿè½½ä¸­è¡¨ç°å‡ºå“è¶Šçš„é²æ£’æ€§ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½æ¥å—ç‡çš„æç«¯æƒ…å†µä¸‹ï¼ŒKLDä¿¡å·ä»èƒ½ä¿æŒå…¶è¯Šæ–­æ•ˆåŠ›ï¼Œç¡®ä¿ç³»ç»Ÿæ€§èƒ½ç¨³å®šã€‚è¿™é¡¹å·¥ä½œéªŒè¯äº†äº‹åä¿¡å·(post-hoc signals)ä½œä¸ºæ„å»ºé«˜æ•ˆLLMæ¨ç†ç³»ç»Ÿçš„ä»·å€¼ï¼Œä¸ºåŠ¨æ€æ¨æµ‹é•¿åº¦è‡ªé€‚åº”é¢†åŸŸæä¾›äº†é‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted for presentation at the IEEE BigData 2025 Workshop (Special Session on Intelligent Data Mining). This v2 updates formatting and adds IEEE copyright notice",
      "pdf_url": "https://arxiv.org/pdf/2509.01083v3",
      "published_date": "2025-09-01 03:13:50 UTC",
      "updated_date": "2025-10-30 02:05:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:04.162039+00:00"
    },
    {
      "arxiv_id": "2509.04488v1",
      "title": "Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition",
      "title_zh": "é¢å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šè¯´è¯äººè¯­éŸ³è¯†åˆ«çš„åºåˆ—åŒ–è¾“å‡ºæç¤º",
      "authors": [
        "Hao Shi",
        "Yusuke Fujita",
        "Tomoya Mizumoto",
        "Lianbo Liu",
        "Atsushi Kojima",
        "Yui Sudo"
      ],
      "abstract": "Prompts are crucial for task definition and for improving the performance of large language models (LLM)-based systems. However, existing LLM-based multi-talker (MT) automatic speech recognition (ASR) systems either omit prompts or rely on simple task-definition prompts, with no prior work exploring the design of prompts to enhance performance. In this paper, we propose extracting serialized output prompts (SOP) and explicitly guiding the LLM using structured prompts to improve system performance (SOP-MT-ASR). A Separator and serialized Connectionist Temporal Classification (CTC) layers are inserted after the speech encoder to separate and extract MT content from the mixed speech encoding in a first-speaking-first-out manner. Subsequently, the SOP, which serves as a prompt for LLMs, is obtained by decoding the serialized CTC outputs using greedy search. To train the model effectively, we design a three-stage training strategy, consisting of serialized output training (SOT) fine-tuning, serialized speech information extraction, and SOP-based adaptation. Experimental results on the LibriMix dataset show that, although the LLM-based SOT model performs well in the two-talker scenario, it fails to fully leverage LLMs under more complex conditions, such as the three-talker scenario. The proposed SOP approach significantly improved performance under both two- and three-talker conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºSOP-MT-ASRçš„æ¡†æ¶ï¼Œåˆ©ç”¨åºåˆ—åŒ–è¾“å‡ºæç¤º(Serialized Output Prompting, SOP)æ¥å¢å¼ºåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šå‘è¨€äººè¯­éŸ³è¯†åˆ«æ€§èƒ½ã€‚é€šè¿‡åœ¨è¯­éŸ³ç¼–ç å™¨ååŠ å…¥åˆ†ç¦»å™¨å’Œåºåˆ—åŒ–CTCå±‚ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä»¥â€œå…ˆè¯´å…ˆå‡ºâ€çš„æ–¹å¼ä»æ··åˆè¯­éŸ³ä¸­æå–ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¼•å¯¼LLMçš„ç»“æ„åŒ–æç¤ºã€‚ç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº†åŒ…å«SOTå¾®è°ƒã€åºåˆ—åŒ–è¯­éŸ³ä¿¡æ¯æå–å’ŒSOPé€‚é…çš„ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä»¥ç¡®ä¿æ¨¡å‹å¯¹å¤šå‘è¨€äººå†…å®¹çš„æœ‰æ•ˆç†è§£ã€‚åœ¨LibriMixæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSOPæ–¹æ³•æ˜¾è‘—æå‡äº†ç³»ç»Ÿåœ¨åŒäººå’Œä¸‰äººå‘è¨€åœºæ™¯ä¸‹çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœæœ‰æ•ˆè§£å†³äº†LLMåœ¨å¤„ç†å¤æ‚å¤šå‘è¨€äººä»»åŠ¡æ—¶å› ç¼ºä¹æ˜¾å¼å¼•å¯¼è€Œå¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼Œä¸ºMT-ASRé¢†åŸŸçš„æç¤ºå·¥ç¨‹è®¾è®¡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.04488v1",
      "published_date": "2025-09-01 03:10:14 UTC",
      "updated_date": "2025-09-01 03:10:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:57.559580+00:00"
    },
    {
      "arxiv_id": "2509.01081v2",
      "title": "Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¼Šæ–¯å…°æ³•ç†æ¨ç†è¯„ä¼°ï¼šåŸºäºç»§æ‰¿æ³•æµ‹è¯„çš„å®è¯",
      "authors": [
        "Abdessalam Bouchekif",
        "Samer Rashwani",
        "Heba Sbahi",
        "Shahd Gaben",
        "Mutaz Al-Khatib",
        "Mohammed Ghaly"
      ],
      "abstract": "This paper evaluates the knowledge and reasoning capabilities of Large Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice questions covering diverse inheritance scenarios, designed to test models' ability to understand the inheritance context and compute the distribution of shares prescribed by Islamic jurisprudence. The results reveal a significant performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect important differences in reasoning ability and domain adaptation. We conduct a detailed error analysis to identify recurring failure patterns across models, including misunderstandings of inheritance scenarios, incorrect application of legal rules, and insufficient domain knowledge. Our findings highlight limitations in handling structured legal reasoning and suggest directions for improving performance in Islamic legal reasoning. Code: https://github.com/bouchekif/inheritance_evaluation",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹(Large Language Models)åœ¨ä¼Šæ–¯å…°ç»§æ‰¿æ³•('ilm al-mawarith)é¢†åŸŸçš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸ºæ­¤æ„å»ºäº†ä¸€ä¸ªåŒ…å«1,000é“æ¶µç›–å¤šæ ·åŒ–åœºæ™¯çš„é€‰æ‹©é¢˜åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºæ¨¡å‹é—´å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ï¼Œå…¶ä¸­o3å’ŒGemini 2.5çš„å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œè€ŒALLaMã€Fanarã€LLaMAåŠMistralå¾—åˆ†å‡ä½äº50%ï¼Œåæ˜ äº†æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸é¢†åŸŸè‡ªé€‚åº”(Domain Adaptation)ä¸Šçš„å·®å¼‚ã€‚é€šè¿‡å¯¹é”™è¯¯æ¨¡å¼çš„è¯¦ç»†åˆ†æï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹åœ¨æ³•å¾‹åœºæ™¯ç†è§£ã€æ³•å¾‹è§„åˆ™åº”ç”¨ä»¥åŠé¢†åŸŸçŸ¥è¯†å‚¨å¤‡æ–¹é¢çš„ä¸è¶³ã€‚è¯¥ç ”ç©¶ä¸ä»…æŒ‡å‡ºäº†å½“å‰å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç»“æ„åŒ–æ³•å¾‹æ¨ç†(Structured Legal Reasoning)æ—¶çš„å±€é™æ€§ï¼Œä¹Ÿä¸ºæœªæ¥æå‡ä¼Šæ–¯å…°æ³•å¾‹æ¨ç†æ€§èƒ½æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 7 Tables, Code: https://github.com/bouchekif/inheritance_evaluation",
      "pdf_url": "https://arxiv.org/pdf/2509.01081v2",
      "published_date": "2025-09-01 03:08:10 UTC",
      "updated_date": "2025-09-17 06:42:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:55.754767+00:00"
    },
    {
      "arxiv_id": "2509.01072v1",
      "title": "DRetNet: A Novel Deep Learning Framework for Diabetic Retinopathy Diagnosis",
      "title_zh": "DRetNetï¼šä¸€ç§æ–°å‹ç³–å°¿ç—…è§†ç½‘è†œç—…å˜è¯Šæ–­æ·±åº¦å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Idowu Paul Okuwobi",
        "Jingyuan Liu",
        "Jifeng Wan",
        "Jiaojiao Jiang"
      ],
      "abstract": "Diabetic retinopathy (DR) is a leading cause of blindness worldwide, necessitating early detection to prevent vision loss. Current automated DR detection systems often struggle with poor-quality images, lack interpretability, and insufficient integration of domain-specific knowledge. To address these challenges, we introduce a novel framework that integrates three innovative contributions: (1) Adaptive Retinal Image Enhancement Using Physics-Informed Neural Networks (PINNs): this technique dynamically enhances retinal images by incorporating physical constraints, improving the visibility of critical features such as microaneurysms, hemorrhages, and exudates; (2) Hybrid Feature Fusion Network (HFFN): by combining deep learning embeddings with handcrafted features, HFFN leverages both learned representations and domain-specific knowledge to enhance generalization and accuracy; (3) Multi-Stage Classifier with Uncertainty Quantification: this method breaks down the classification process into logical stages, providing interpretable predictions and confidence scores, thereby improving clinical trust. The proposed framework achieves an accuracy of 92.7%, a precision of 92.5%, a recall of 92.6%, an F1-score of 92.5%, an AUC of 97.8%, a mAP of 0.96, and an MCC of 0.85. Ophthalmologists rated the framework's predictions as highly clinically relevant (4.8/5), highlighting its alignment with real-world diagnostic needs. Qualitative analyses, including Grad-CAM visualizations and uncertainty heatmaps, further enhance the interpretability and trustworthiness of the system. The framework demonstrates robust performance across diverse conditions, including low-quality images, noisy data, and unseen datasets. These features make the proposed framework a promising tool for clinical adoption, enabling more accurate and reliable DR detection in resource-limited settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DRetNetï¼Œä¸€ç§æ—¨åœ¨æå‡ç³–å°¿ç—…è§†ç½‘è†œç—…å˜(Diabetic Retinopathy, DR)è¯Šæ–­æ•ˆç‡çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†åŒ»å­¦å½±åƒè´¨é‡å·®ã€ç¼ºä¹å¯è§£é‡Šæ€§åŠé¢†åŸŸçŸ¥è¯†æ•´åˆä¸è¶³ç­‰éš¾é¢˜ã€‚æ¡†æ¶å¼•å…¥äº†åŸºäºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ(Physics-Informed Neural Networks, PINNs)çš„è‡ªé€‚åº”å›¾åƒå¢å¼ºæŠ€æœ¯ï¼Œåˆ©ç”¨ç‰©ç†çº¦æŸåŠ¨æ€æå‡å¾®åŠ¨è„‰ç˜¤ã€å‡ºè¡€ç‚¹ç­‰å…³é”®ç—…ç¶çš„å¯è§åº¦ã€‚é€šè¿‡æ··åˆç‰¹å¾èåˆç½‘ç»œ(Hybrid Feature Fusion Network, HFFN)ï¼Œè¯¥ç ”ç©¶å°†æ·±åº¦å­¦ä¹ åµŒå…¥ä¸æ‰‹å·¥ç‰¹å¾ç›¸ç»“åˆï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé‡‡ç”¨å…·æœ‰ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)çš„å¤šé˜¶æ®µåˆ†ç±»å™¨ï¼Œæä¾›å¯è§£é‡Šçš„é¢„æµ‹ç»“æœä¸ç½®ä¿¡åº¦è¯„åˆ†ä»¥å»ºç«‹ä¸´åºŠä¿¡ä»»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRetNetçš„å‡†ç¡®ç‡è¾¾åˆ°92.7%ï¼ŒAUCé«˜è¾¾97.8%ï¼Œä¸”åœ¨Grad-CAMå¯è§†åŒ–åˆ†æä¸­è¡¨ç°å‡ºæé«˜çš„ä¸´åºŠç›¸å…³æ€§ã€‚è¯¥æ¡†æ¶åœ¨ä½è´¨é‡å›¾åƒå’Œå™ªå£°æ•°æ®ä¸‹å‡è¡¨ç°å‡ºç¨³å¥çš„æ€§èƒ½ï¼Œä¸ºèµ„æºå—é™åœ°åŒºçš„DRç²¾å‡†ç­›æŸ¥æä¾›äº†å¯é çš„è‡ªåŠ¨åŒ–å·¥å…·ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages",
      "pdf_url": "https://arxiv.org/pdf/2509.01072v1",
      "published_date": "2025-09-01 02:27:16 UTC",
      "updated_date": "2025-09-01 02:27:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:00:59.564441+00:00"
    },
    {
      "arxiv_id": "2509.05333v1",
      "title": "RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness",
      "title_zh": "RT-VLMï¼šåŸºäº 4 çº¿ç´¢æå‡çœŸå®ä¸–ç•Œç‰©ä½“è¯†åˆ«é²æ£’æ€§çš„è§†è§‰è¯­è¨€æ¨¡å‹å†æ€è€ƒ",
      "authors": [
        "Junghyun Park",
        "Tuan Anh Nguyen",
        "Dugki Min"
      ],
      "abstract": "Real world deployments often expose modern object recognition models to domain shifts that precipitate a severe drop in accuracy. Such shifts encompass (i) variations in low level image statistics, (ii) changes in object pose and viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent classes. To mitigate this degradation, we introduce the Re-Thinking Vision Language Model (RT-VLM) framework. The foundation of this framework is a unique synthetic dataset generation pipeline that produces images annotated with \"4-Clues\": precise bounding boxes, class names, detailed object-level captions, and a comprehensive context-level caption for the entire scene. We then perform parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this resource. At inference time, a two stage Re-Thinking scheme is executed: the model first emits its own four clues, then re examines these responses as evidence and iteratively corrects them. Across robustness benchmarks that isolate individual domain shifts, RT-VLM consistently surpasses strong baselines. These findings indicate that the integration of structured multimodal evidence with an explicit self critique loop constitutes a promising route toward reliable and transferable visual understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ç›®æ ‡è¯†åˆ«æ¨¡å‹åœ¨ç°å®ä¸–ç•ŒåŸŸåç§»ï¼ˆdomain shiftsï¼‰ä¸‹å‡†ç¡®ç‡å¤§å¹…ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº† RT-VLM æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ„å»ºäº†ç‹¬ç‰¹çš„åˆæˆæ•°æ®é›†ç”Ÿæˆæµæ°´çº¿ï¼Œä¸ºå›¾åƒæä¾›åŒ…å«ç²¾ç¡® bounding boxesã€ç±»åã€ç‰©ä½“å±‚çº§ caption å’Œåœºæ™¯ context-level caption çš„â€œ4-Cluesâ€æ ‡æ³¨ã€‚é€šè¿‡å¯¹ Llama 3.2 11B Vision Instruct è¿›è¡Œå‚æ•°é«˜æ•ˆçš„ç›‘ç£å¾®è°ƒï¼Œå¹¶å¼•å…¥ä¸¤é˜¶æ®µ Re-Thinking æ–¹æ¡ˆï¼Œæ¨¡å‹åœ¨æ¨ç†é˜¶æ®µèƒ½å¤Ÿæ ¹æ®è‡ªèº«ç”Ÿæˆçš„çº¿ç´¢ä½œä¸ºè¯æ®è¿›è¡Œè‡ªæˆ‘å®¡æŸ¥ä¸è¿­ä»£ä¿®æ­£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRT-VLM åœ¨å¤šä¸ªéš”ç¦»ç‰¹å®šåŸŸåç§»çš„é²æ£’æ€§åŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œå°†ç»“æ„åŒ–å¤šæ¨¡æ€è¯æ®ä¸æ˜¾å¼è‡ªæ‰¹åˆ¤ï¼ˆself-critiqueï¼‰å¾ªç¯ç›¸ç»“åˆï¼Œæ˜¯å®ç°å¯é ä¸”å…·å¯è¿ç§»æ€§è§†è§‰ç†è§£çš„æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.05333v1",
      "published_date": "2025-09-01 02:13:00 UTC",
      "updated_date": "2025-09-01 02:13:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:12.059760+00:00"
    },
    {
      "arxiv_id": "2509.01063v1",
      "title": "An Economy of AI Agents",
      "title_zh": "AI æ™ºèƒ½ä½“ç»æµ",
      "authors": [
        "Gillian K. Hadfield",
        "Andrew Koh"
      ],
      "abstract": "In the coming decade, artificially intelligent agents with the ability to plan and execute complex tasks over long time horizons with little direct oversight from humans may be deployed across the economy. This chapter surveys recent developments and highlights open questions for economists around how AI agents might interact with humans and with each other, shape markets and organizations, and what institutions might be required for well-functioning markets.",
      "tldr_zh": "è¿™ç¯‡åä¸ºã€ŠAn Economy of AI Agentsã€‹çš„ç ”ç©¶ç»¼è¿°äº†åœ¨æœªæ¥åå¹´å†…ï¼Œå…·å¤‡è‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œé•¿æœŸå¤æ‚ä»»åŠ¡èƒ½åŠ›çš„ AI agents å¯èƒ½åœ¨æ•´ä¸ªç»æµä½“ç³»ä¸­å¤§è§„æ¨¡éƒ¨ç½²çš„å‰æ™¯ã€‚è¯¥æ–‡ç« é‡ç‚¹æ¢è®¨äº† AI agents å¦‚ä½•ä¸äººç±»ä»¥åŠå½¼æ­¤ä¹‹é—´è¿›è¡Œäº’åŠ¨ï¼Œå¹¶æ·±å…¥åˆ†æäº†è¿™äº›æ™ºèƒ½ä½“å°†å¦‚ä½•é‡å¡‘ç°æœ‰çš„å¸‚åœºæœºåˆ¶å’Œç»„ç»‡å½¢å¼ã€‚ä½œè€…è¿›ä¸€æ­¥æå‡ºäº†åœ¨ AI é©±åŠ¨çš„ç»æµä¸­ï¼Œä¸ºäº†ç»´æŒå¸‚åœºè‰¯å¥½è¿ä½œæ‰€å¿…é¡»æ„å»ºçš„æ–°å‹åˆ¶åº¦æ¡†æ¶ã€‚é€šè¿‡æ€»ç»“è¯¥é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œæœ¬ç ”ç©¶ä¸ºç»æµå­¦å®¶æ˜ç¡®äº†å…³äº AI agents å¯¹æœªæ¥ç»æµå½±å“çš„å…³é”®å¼€æ”¾æ€§é—®é¢˜ã€‚",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01063v1",
      "published_date": "2025-09-01 02:07:39 UTC",
      "updated_date": "2025-09-01 02:07:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:45.857874+00:00"
    },
    {
      "arxiv_id": "2509.01058v3",
      "title": "Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL",
      "title_zh": "é€‚çº§è¡¨è¾¾ï¼šåŸºäº RAG-RL çš„ç´ å…»å¯æ§åè¨€è®ºç”Ÿæˆ",
      "authors": [
        "Xiaoying Song",
        "Anirban Saha Anik",
        "Dibakar Barua",
        "Pengcheng Luo",
        "Junhua Ding",
        "Lingzi Hong"
      ],
      "abstract": "Health misinformation spreading online poses a significant threat to public health. Researchers have explored methods for automatically generating counterspeech to health misinformation as a mitigation strategy. Existing approaches often produce uniform responses, ignoring that the health literacy level of the audience could affect the accessibility and effectiveness of counterspeech. We propose a Controlled-Literacy framework using retrieval-augmented generation (RAG) with reinforcement learning (RL) to generate tailored counterspeech adapted to different health literacy levels. In particular, we retrieve knowledge aligned with specific health literacy levels, enabling accessible and factual information to support generation. We design a reward function incorporating subjective user preferences and objective readability-based rewards to optimize counterspeech to the target health literacy level. Experiment results show that Controlled-Literacy outperforms baselines by generating more accessible and user-preferred counterspeech. This research contributes to more equitable and impactful public health communication by improving the accessibility and comprehension of counterspeech to health misinformation",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œå¥åº·è¯¯å¯¼ä¿¡æ¯(health misinformation)ä¼ æ’­å¯¹å…¬ä¼—å¥åº·çš„å¨èƒï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºControlled-Literacyçš„æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆé€‚åº”ä¸åŒå¥åº·ç´ å…»(health literacy)æ°´å¹³çš„å®šåˆ¶åŒ–åå‡»è¨€è®º(counterspeech)ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ä¸å¼ºåŒ–å­¦ä¹ (RL)æŠ€æœ¯ï¼Œé€šè¿‡æ£€ç´¢ä¸ç‰¹å®šç´ å…»æ°´å¹³å¯¹é½çš„çŸ¥è¯†ï¼Œç¡®ä¿ç”Ÿæˆçš„ä¿¡æ¯æ—¢çœŸå®åˆæ˜“äºç†è§£ã€‚ç ”ç©¶è®¾è®¡äº†ä¸€ç§åŒ…å«ä¸»è§‚ç”¨æˆ·åå¥½å’Œå®¢è§‚å¯è¯»æ€§è¯„åˆ†çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–ç”Ÿæˆå†…å®¹å¯¹ç›®æ ‡ç´ å…»æ°´å¹³çš„é€‚é…åº¦ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒControlled-Literacyåœ¨ç”Ÿæˆæ›´å…·å¯è®¿é—®æ€§å’Œå—ç”¨æˆ·é’ççš„åå‡»è¨€è®ºæ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†åº”å¯¹å¥åº·è¯¯å¯¼ä¿¡æ¯çš„æ²Ÿé€šæ•ˆç‡ï¼Œä¸ºå®ç°æ›´å…¬å¹³ä¸”æœ‰æ•ˆçš„å…¬å…±å«ç”Ÿä¼ æ’­æä¾›äº†æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01058v3",
      "published_date": "2025-09-01 01:54:14 UTC",
      "updated_date": "2025-09-22 15:44:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:35.551015+00:00"
    },
    {
      "arxiv_id": "2509.01057v2",
      "title": "Q-Learning-Driven Adaptive Rewiring for Cooperative Control in Heterogeneous Networks",
      "title_zh": "å¼‚æ„ç½‘ç»œåä½œæ§åˆ¶ä¸­Qå­¦ä¹ é©±åŠ¨çš„è‡ªé€‚åº”é‡è¿",
      "authors": [
        "Yi-Ning Weng",
        "Hsuan-Wei Lee"
      ],
      "abstract": "Cooperation emergence in multi-agent systems represents a fundamental statistical physics problem where microscopic learning rules drive macroscopic collective behavior transitions. We propose a Q-learning-based variant of adaptive rewiring that builds on mechanisms studied in the literature. This method combines temporal difference learning with network restructuring so that agents can optimize strategies and social connections based on interaction histories. Through neighbor-specific Q-learning, agents develop sophisticated partnership management strategies that enable cooperator cluster formation, creating spatial separation between cooperative and defective regions. Using power-law networks that reflect real-world heterogeneous connectivity patterns, we evaluate emergent behaviors under varying rewiring constraint levels, revealing distinct cooperation patterns across parameter space rather than sharp thermodynamic transitions. Our systematic analysis identifies three behavioral regimes: a permissive regime (low constraints) enabling rapid cooperative cluster formation, an intermediate regime with sensitive dependence on dilemma strength, and a patient regime (high constraints) where strategic accumulation gradually optimizes network structure. Simulation results show that while moderate constraints create transition-like zones that suppress cooperation, fully adaptive rewiring enhances cooperation levels through systematic exploration of favorable network configurations. Quantitative analysis reveals that increased rewiring frequency drives large-scale cluster formation with power-law size distributions. Our results establish a new paradigm for understanding intelligence-driven cooperation pattern formation in complex adaptive systems, revealing how machine learning serves as an alternative driving force for spontaneous organization in multi-agent networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºQ-learningçš„è‡ªé€‚åº”é‡è¿ï¼ˆAdaptive Rewiringï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-agent systemsï¼‰ä¸­çš„åˆä½œæ¶Œç°é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†æ—¶é—´å·®åˆ†å­¦ä¹ ï¼ˆTemporal Difference Learningï¼‰ä¸ç½‘ç»œç»“æ„é‡ç»„ç›¸ç»“åˆï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®äº¤äº’å†å²åŠ¨æ€ä¼˜åŒ–ç­–ç•¥å’Œç¤¾äº¤è¿æ¥ã€‚é€šè¿‡ç‰¹å®šé‚»å±…çš„Q-learningï¼Œæ™ºèƒ½ä½“å¾—ä»¥å‘å±•å‡ºå¤æ‚çš„ä¼™ä¼´å…³ç³»ç®¡ç†ç­–ç•¥ï¼Œä»è€Œä¿ƒè¿›åˆä½œè€…é›†ç¾¤çš„å½¢æˆå¹¶å®ç°åˆä½œä¸èƒŒå›åŒºåŸŸçš„ç©ºé—´åˆ†ç¦»ã€‚ç ”ç©¶åœ¨åæ˜ ç°å®å¼‚è´¨è¿æ¥æ¨¡å¼çš„å¹‚å¾‹ç½‘ç»œï¼ˆPower-law networksï¼‰ä¸Šè¯„ä¼°äº†æ¶Œç°è¡Œä¸ºï¼Œå¹¶è¯†åˆ«å‡ºå…è®¸å‹ã€ä¸­é—´å‹å’Œè€å¿ƒå‹ä¸‰ç§ä¸åŒçš„è¡Œä¸ºçŠ¶æ€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå®Œå…¨è‡ªé€‚åº”é‡è¿é€šè¿‡å¯¹æœ‰åˆ©ç½‘ç»œé…ç½®çš„ç³»ç»Ÿæ€§æ¢ç´¢ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç³»ç»Ÿçš„æ•´ä½“åˆä½œæ°´å¹³ã€‚å®šé‡åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œå¢åŠ é‡è¿é¢‘ç‡ä¼šé©±åŠ¨å…·æœ‰å¹‚å¾‹è§„æ¨¡åˆ†å¸ƒçš„å¤§è§„æ¨¡é›†ç¾¤å½¢æˆã€‚è¯¥ç ”ç©¶ä¸ºç†è§£å¤æ‚è‡ªé€‚åº”ç³»ç»Ÿï¼ˆComplex Adaptive Systemsï¼‰ä¸­æ™ºèƒ½é©±åŠ¨çš„åˆä½œæ¨¡å¼å½¢æˆå»ºç«‹äº†æ–°èŒƒå¼ï¼Œè¯æ˜äº†æœºå™¨å­¦ä¹ å¯ä»¥ä½œä¸ºå¤šæ™ºèƒ½ä½“ç½‘ç»œè‡ªå‘ç»„ç»‡çš„æœ‰æ•ˆé©±åŠ¨åŠ›ã€‚",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "40 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2509.01057v2",
      "published_date": "2025-09-01 01:52:56 UTC",
      "updated_date": "2025-09-03 03:24:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:46.562885+00:00"
    },
    {
      "arxiv_id": "2509.01055v3",
      "title": "VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use",
      "title_zh": "VerlToolï¼šè¿ˆå‘å…¨æ–¹ä½çš„å·¥å…·åŒ–æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Dongfu Jiang",
        "Yi Lu",
        "Zhuofeng Li",
        "Zhiheng Lyu",
        "Ping Nie",
        "Haozhe Wang",
        "Alex Su",
        "Hui Chen",
        "Kai Zou",
        "Chao Du",
        "Tianyu Pang",
        "Wenhu Chen"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated success in enhancing LLM reasoning capabilities, but remains limited to single-turn interactions without tool integration. While recent Agentic Reinforcement Learning with Tool use (ARLT) approaches have emerged to address multi-turn tool interactions, existing works develop task-specific codebases that suffer from fragmentation, synchronous execution bottlenecks, and limited extensibility across domains. These inefficiencies hinder broader community adoption and algorithmic innovation. We introduce VerlTool, a unified and modular framework that addresses these limitations through systematic design principles. VerlTool provides four key contributions: (1) upstream alignment with VeRL ensuring compatibility and simplified maintenance, (2) unified tool management via standardized APIs supporting diverse modalities including code execution, search, SQL databases, and vision processing, (3) asynchronous rollout execution achieving near 2$\\times$ speedup by eliminating synchronization bottlenecks, and (4) comprehensive evaluation demonstrating competitive performance across 6 ARLT domains. Our framework formalizes ARLT as multi-turn trajectories with multi-modal observation tokens (text/image/video), extending beyond single-turn RLVR paradigms. We train and evaluate models on mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web search, and software engineering tasks, achieving results comparable to specialized systems while providing unified training infrastructure. The modular plugin architecture enables rapid tool integration requiring only lightweight Python definitions, significantly reducing development overhead and providing a scalable foundation for tool-augmented RL research. Our code is open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† VerlToolï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€ä¸”æ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (Agentic Reinforcement Learning with Tool use, ARLT) æ–¹æ¡ˆä¸­å­˜åœ¨çš„ä»£ç åº“ç¢ç‰‡åŒ–ã€åŒæ­¥æ‰§è¡Œç“¶é¢ˆä»¥åŠé¢†åŸŸæ‰©å±•æ€§å—é™ç­‰é—®é¢˜ã€‚VerlTool å®ç°äº†ä¸ VeRL çš„ä¸Šæ¸¸å¯¹é½ï¼Œç¡®ä¿äº†è‰¯å¥½çš„ç³»ç»Ÿå…¼å®¹æ€§ï¼Œå¹¶é€šè¿‡æ ‡å‡†åŒ– API æä¾›ç»Ÿä¸€çš„å·¥å…·ç®¡ç†ï¼Œæ”¯æŒä»£ç æ‰§è¡Œã€æœç´¢ã€SQL æ•°æ®åº“å’Œè§†è§‰å¤„ç†ç­‰å¤šç§æ¨¡æ€ã€‚è¯¥æ¡†æ¶å°† ARLT å½¢å¼åŒ–ä¸ºåŒ…å«å¤šæ¨¡æ€è§‚å¯Ÿä»¤ç‰Œ (Observation Tokens) çš„å¤šè½®è½¨è¿¹ï¼Œå¹¶é‡‡ç”¨å¼‚æ­¥å›ä¼  (Asynchronous Rollout) æ‰§è¡Œæœºåˆ¶ï¼Œç›¸è¾ƒäºä¼ ç»ŸåŒæ­¥æ¨¡å¼å®ç°äº†è¿‘ 2 å€çš„é€Ÿåº¦æå‡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æ•°å­¦æ¨ç†ã€çŸ¥è¯†é—®ç­”ã€SQL ç”Ÿæˆã€è§†è§‰æ¨ç†ã€ç½‘ç»œæœç´¢å’Œè½¯ä»¶å·¥ç¨‹å…­ä¸ªé¢†åŸŸè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º VerlTool çš„æ€§èƒ½å¯ä¸ä¸“é—¨åŒ–ç³»ç»Ÿç›¸åª²ç¾ã€‚å…¶æ¨¡å—åŒ–æ’ä»¶æ¶æ„æ˜¾è‘—é™ä½äº†å·¥å…·é›†æˆçš„å¼€å‘å¼€é”€ï¼Œä¸ºå·¥å…·å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ ç ”ç©¶æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”é«˜æ•ˆçš„ç»Ÿä¸€è®­ç»ƒåŸºç¡€è®¾æ–½ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 5 figures, 13 tables",
      "pdf_url": "https://arxiv.org/pdf/2509.01055v3",
      "published_date": "2025-09-01 01:45:18 UTC",
      "updated_date": "2025-10-17 06:09:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:41.166931+00:00"
    },
    {
      "arxiv_id": "2509.01053v3",
      "title": "A Dynamic Fusion Model for Consistent Crisis Response",
      "title_zh": "é¢å‘ä¸€è‡´æ€§å±æœºå“åº”çš„åŠ¨æ€èåˆæ¨¡å‹",
      "authors": [
        "Xiaoying Song",
        "Anirban Saha Anik",
        "Eduardo Blanco",
        "Vanessa Frias-Martinez",
        "Lingzi Hong"
      ],
      "abstract": "In response to the urgent need for effective communication with crisis-affected populations, automated responses driven by language models have been proposed to assist in crisis communications. A critical yet often overlooked factor is the consistency of response style, which could affect the trust of affected individuals in responders. Despite its importance, few studies have explored methods for maintaining stylistic consistency across generated responses. To address this gap, we propose a novel metric for evaluating style consistency and introduce a fusion-based generation approach grounded in this metric. Our method employs a two-stage process: it first assesses the style of candidate responses and then optimizes and integrates them at the instance level through a fusion process. This enables the generation of high-quality responses while significantly reducing stylistic variation between instances. Experimental results across multiple datasets demonstrate that our approach consistently outperforms baselines in both response quality and stylistic uniformity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å±æœºæ²Ÿé€šä¸­è¯­è¨€æ¨¡å‹ç”Ÿæˆå›å¤é£æ ¼ä¸ä¸€è‡´å¯èƒ½å½±å“å—ç¾äººç¾¤ä¿¡ä»»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨ç»´æŒé£æ ¼ä¸€è‡´æ€§çš„åŠ¨æ€èåˆæ¨¡å‹(Dynamic Fusion Model)ã€‚ä¸ºäº†é‡åŒ–è¿™ä¸€å±æ€§ï¼Œä½œè€…é¦–å…ˆå®šä¹‰äº†ä¸€ç§è¯„ä¼°é£æ ¼ä¸€è‡´æ€§(Style Consistency)çš„æ–°æŒ‡æ ‡ï¼Œå¹¶åŸºäºæ­¤æŒ‡æ ‡å¼•å…¥äº†èåˆç”Ÿæˆ(fusion-based generation)çš„å¤„ç†æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µæµç¨‹ï¼šé¦–å…ˆè¯„ä¼°å€™é€‰å›å¤çš„é£æ ¼ï¼Œéšååœ¨å®ä¾‹å±‚é¢(instance level)é€šè¿‡èåˆè¿‡ç¨‹å¯¹å›å¤è¿›è¡Œä¼˜åŒ–ä¸æ•´åˆã€‚è¿™ç§æœºåˆ¶åœ¨ç¡®ä¿ç”Ÿæˆé«˜è´¨é‡å›å¤çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—å‡å°‘ä¸åŒå®ä¾‹é—´çš„é£æ ¼æ³¢åŠ¨ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›å¤è´¨é‡å’Œé£æ ¼ç»Ÿä¸€æ€§æ–¹é¢å‡æŒç»­ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸ºæ„å»ºä¸€è‡´ä¸”å¯ä¿¡çš„å±æœºå“åº”ç³»ç»Ÿæä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Findings of EMNLP 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.01053v3",
      "published_date": "2025-09-01 01:41:52 UTC",
      "updated_date": "2025-09-20 17:15:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:38.960560+00:00"
    },
    {
      "arxiv_id": "2509.01052v2",
      "title": "FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games",
      "title_zh": "FlashAdventureï¼šé’ˆå¯¹ GUI æ™ºèƒ½ä½“è§£å†³å¤šæ ·åŒ–å†’é™©æ¸¸æˆä¸­å®Œæ•´æ•…äº‹å¼§çº¿çš„è¯„æµ‹åŸºå‡†",
      "authors": [
        "Jaewoo Ahn",
        "Junseo Kim",
        "Heeseung Yun",
        "Jaehyeon Son",
        "Dongmin Park",
        "Jaewoong Cho",
        "Gunhee Kim"
      ],
      "abstract": "GUI agents powered by LLMs show promise in interacting with diverse digital environments. Among these, video games offer a valuable testbed due to their varied interfaces, with adventure games posing additional challenges through complex, narrative-driven interactions. Existing game benchmarks, however, lack diversity and rarely evaluate agents on completing entire storylines. To address this, we introduce FlashAdventure, a benchmark of 34 Flash-based adventure games designed to test full story arc completion and tackle the observation-behavior gap: the challenge of remembering and acting on earlier gameplay information. We also propose CUA-as-a-Judge, an automated gameplay evaluator, and COAST, an agentic framework leveraging long-term clue memory to better plan and solve sequential tasks. Experiments show current GUI agents struggle with full story arcs, while COAST improves milestone completion by bridging the observation-behavior gap. Nonetheless, a marked discrepancy between humans and best-performing agents warrants continued research efforts to narrow this divide.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† FlashAdventureï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«34æ¬¾åŸºäº Flash çš„å†’é™©æ¸¸æˆåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼° GUI agents åœ¨å¤šæ ·åŒ–æ¸¸æˆç¯å¢ƒä¸­å®Œæˆå®Œæ•´æ•…äº‹æƒ…èŠ‚çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†ç‰¹åˆ«å…³æ³¨â€œè§‚å¯Ÿ-è¡Œä¸ºé¸¿æ²Ÿâ€(observation-behavior gap)ï¼Œå³æ™ºèƒ½ä½“éš¾ä»¥è®°ä½å¹¶åˆ©ç”¨æ—©æœŸæ¸¸æˆä¿¡æ¯æ¥æŒ‡å¯¼åç»­è¡ŒåŠ¨çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†è‡ªåŠ¨åŒ–æ¸¸æˆè¯„ä¼°å™¨ CUA-as-a-Judge ä»¥åŠåä¸º COAST çš„ä»£ç†æ¡†æ¶ï¼Œåè€…é€šè¿‡åˆ©ç”¨é•¿æœŸçº¿ç´¢è®°å¿†æ¥æ›´å¥½åœ°è§„åˆ’ä¸è§£å†³é¡ºåºä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰çš„ GUI agents åœ¨å¤„ç†å®Œæ•´æ•…äº‹å¼§çº¿æ—¶è¡¨ç°ä¸ä½³ï¼Œè€Œ COAST æ¡†æ¶é€šè¿‡ç¼©å°è§‚å¯Ÿä¸è¡Œä¸ºä¹‹é—´çš„å·®è·æ˜¾è‘—æå‡äº†å…³é”®é‡Œç¨‹ç¢‘çš„å®Œæˆç‡ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®éªŒç»“æœä¹Ÿæ­ç¤ºäº†é¡¶å°–æ™ºèƒ½ä½“ä¸äººç±»ä¹‹é—´ä»å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œä¸ºåç»­ç¼©å°è¯¥åˆ†æ­§çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2025 Main. Project page: https://ahnjaewoo.github.io/flashadventure",
      "pdf_url": "https://arxiv.org/pdf/2509.01052v2",
      "published_date": "2025-09-01 01:33:16 UTC",
      "updated_date": "2025-10-15 10:33:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:47.990117+00:00"
    },
    {
      "arxiv_id": "2509.01033v1",
      "title": "Seeing through Unclear Glass: Occlusion Removal with One Shot",
      "title_zh": "é€è§†æ±¡æµŠç»ç’ƒï¼šå•æ ·æœ¬é®æŒ¡å»é™¤",
      "authors": [
        "Qiang Li",
        "Yuanming Cao"
      ],
      "abstract": "Images taken through window glass are often degraded by contaminants adhered to the glass surfaces. Such contaminants cause occlusions that attenuate the incoming light and scatter stray light towards the camera. Most of existing deep learning methods for neutralizing the effects of contaminated glasses relied on synthetic training data. Few researchers used real degraded and clean image pairs, but they only considered removing or alleviating the effects of rain drops on glasses. This paper is concerned with the more challenging task of learning the restoration of images taken through glasses contaminated by a wide range of occluders, including muddy water, dirt and other small foreign particles found in reality. To facilitate the learning task we have gone to a great length to acquire real paired images with and without glass contaminants. More importantly, we propose an all-in-one model to neutralize contaminants of different types by utilizing the one-shot test-time adaptation mechanism. It involves a self-supervised auxiliary learning task to update the trained model for the unique occlusion type of each test image. Experimental results show that the proposed method outperforms the state-of-the-art methods quantitatively and qualitatively in cleaning realistic contaminated images, especially the unseen ones.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å—æ±¡æŸ“ç»ç’ƒæˆåƒä¸­çš„é®æŒ¡ç§»é™¤(Occlusion Removal)é—®é¢˜ï¼Œæ—¨åœ¨ä¿®å¤å› æ³¥æ°´ã€æ±¡å¢å’Œå„ç±»å¾®å°é¢—ç²’å¯¼è‡´çš„å›¾åƒé€€åŒ–ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•è¿‡åº¦ä¾èµ–åˆæˆæ•°æ®æˆ–ä»…å±€é™äºé›¨æ»´ç§»é™¤çš„å±€é™ï¼Œä½œè€…é‡‡é›†äº†çœŸå®ä¸–ç•Œä¸­æ±¡æŸ“ä¸æ¸…æ™°å›¾åƒçš„é…å¯¹æ•°æ®é›†ä»¥è¾…åŠ©å­¦ä¹ ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå•æ ·æœ¬æµ‹è¯•æ—¶è‡ªé€‚åº”(one-shot test-time adaptation)æœºåˆ¶çš„å…¨èƒ½æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥è‡ªç›‘ç£è¾…åŠ©å­¦ä¹ ä»»åŠ¡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé’ˆå¯¹æ¯å¼ æµ‹è¯•å›¾åƒçš„ç‹¬ç‰¹é®æŒ¡ç‰¹å¾è¿›è¡Œå®æ—¶åŠ¨æ€æ›´æ–°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†çœŸå®ä¸–ç•Œçš„æ±¡æŸ“å›¾åƒï¼Œå°¤å…¶æ˜¯åº”å¯¹æœªè§è¿‡çš„é®æŒ¡ç±»å‹æ—¶ï¼Œå…¶å®šé‡å’Œå®šæ€§è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›(state-of-the-art)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.01033v1",
      "published_date": "2025-09-01 00:01:36 UTC",
      "updated_date": "2025-09-01 00:01:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T16:01:52.349154+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 127,
  "processed_papers_count": 127,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T16:02:50.627463+00:00"
}