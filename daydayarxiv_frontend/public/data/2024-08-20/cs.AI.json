{
  "date": "2024-08-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-20 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦 AI 创新，特别是大语言模型（LLMs）的安全优化、强化学习应用以及多模态处理技术，亮点包括量子 AI 模型和高效图像生成方法，值得注意的是如 \"OCTCube-M\" 等跨领域验证的医学应用，以及知名学者如 Christopher D. Manning 在 LLMs 相关论文中的贡献。\n\n下面，我将挑选并简要讨论今天更重要的论文，先从 LLMs 和 AI 安全主题入手，因为这些文章具有较高话题度和实际影响；接着聊强化学习和图像处理领域；其他领域如量子计算和医学应用快速掠过，只提核心贡献。每个条目列出论文标题（中文 + 英文），并清晰描述主要贡献和发现。\n\n### LLMs 和 AI 安全\n- **超越标签：通过人类式推理与大语言模型对齐** (Beyond Labels: Aligning Large Language Models with Human-like Reasoning)  \n  这篇论文提出 DFAR 数据集和 L+R 微调策略，通过注入人类推理理由提升 LLMs 在道德决策中的表现，主要发现是 L+R 方法显著提高分类准确性和减少不一致性，适用于伦理敏感任务。\n\n- **隐藏恶意目标于良性叙述：通过载体文章越狱大语言模型** (Hide Your Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Carrier Articles)  \n  作者探索黑盒攻击方法，使用载体文章激活相关神经元来绕过 LLMs 安全机制，主要贡献是提出一种高效越狱框架，在 JailbreakBench 上实现 63% 成功率，揭示 LLMs 安全漏洞。\n\n- **生成式后门攻击：通过模型编辑在大语言模型中注入后门** (MEGen: Generative Backdoor in Large Language Models via Model Editing)  \n  这篇工作设计了 MEGen 框架，通过模型编辑注入后门，贡献在于高效嵌入后门而不影响正常性能，发现后门能引导模型输出预设危险信息，强调对话 AI 系统的潜在风险。\n\n- **鲁棒知识遗忘：评估和提升大语言模型的遗忘鲁棒性** (Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models)  \n  论文引入对抗框架评估 LLMs 知识遗忘，贡献是 LAU 方法通过最小-最大优化提升鲁棒性，主要发现是遗忘后模型在对抗查询下恢复知识的成功率从 55.2% 降至更低。\n\n- **多语言非事实问题回答：基于答案段落选择的框架** (Multilingual Non-Factoid Question Answering with Answer Paragraph Selection)  \n  作者构建了 MuNfQuAD 数据集（578K 问题对，覆盖 38 种语言），贡献是提出 APS 模型提升多语言 QA 性能，发现模型在低资源语言上表现出色，F1 分数达 72%。\n\n### 强化学习应用\n- **图神经网络的对抗影响最大化攻击** (GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization)  \n  这篇论文将 GNN 攻击转化为影响最大化问题，贡献是统一优化目标节点选择和扰动构建，主要发现是攻击成功率高，同时提供黑盒攻击理论分析。\n\n- **序列建模的强化学习：使用状态空间模型** (MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State Space Modeling)  \n  作者提出 MambaDS 框架，用于气象场下采样，贡献是结合拓扑约束提升预测准确性，主要发现是模型在动态环境中显著减少误差，适用于环境模拟。\n\n- **目标条件强化学习算法的加速** (Accelerating Goal-Conditioned RL Algorithms and Research)  \n  论文开发了 JaxGCRL 框架，贡献是使用 GPU 加速缓冲区和对比学习提升训练效率，主要发现是训练时间减少 22 倍，同时保持高性能。\n\n### 图像和视频处理\n- **OCTCube-M：3D 多模态光学相干断层成像基础模型** (OCTCube-M: A 3D multimodal optical coherence tomography foundation model for retinal and systemic diseases with cross-cohort and cross-device validation)  \n  这篇亮点工作提出 OCTCube-M 模型，贡献是多模态对比学习框架用于眼部疾病预测，主要发现是模型在跨队列验证中准确率提升，预测系统性疾病如糖尿病。\n\n- **扩散模型的图像生成：Transfusion 方法** (Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model)  \n  作者开发 Transfusion 模型，贡献是统一文本和图像生成，训练规模达 7B 参数，主要发现是模型在多模态任务中性能与专业模型相当。\n\n- **事件流基于的视觉跟踪：使用状态空间模型** (MambaEVT: Event Stream based Visual Object Tracking using State Space Model)  \n  论文提出 MambaEVT 框架，贡献是动态模板更新策略提升跟踪精度，主要发现是在 EventVOT 数据集上准确率和计算效率均优于 Transformer 方法。\n\n其他领域论文众多，但多为 niche 主题，我快速掠过几篇核心贡献：\n- **量子逆上下文视觉 Transformer：用于自动驾驶的 3D 对象检测** (Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs)  \n  贡献是提出 Q-ICVT 融合 LiDAR 和相机数据，提升自动驾驶检测精度。\n- **统一深度学习模型：用于卫星图像的生物质预测** (Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery)  \n  主要发现是模型在全球数据上误差降低，适用于气候监测。\n- **脑部疾病分类：基于自监督对比学习的超声视频** (Breast tumor classification based on self-supervised contrastive learning from ultrasound videos)  \n  贡献是新数据集和硬三元组损失，提升乳腺肿瘤检测 AUC 到 0.952。\n\n今天的论文展示了 AI 领域的快速进展，LLMs 的安全和泛化能力尤为值得关注。如果您对特定主题感兴趣，建议查看这些论文的摘要！",
  "papers": [
    {
      "arxiv_id": "2408.11249v1",
      "title": "The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act",
      "title_zh": "翻译失败",
      "authors": [
        "Matias Valdenegro-Toro",
        "Radina Stoykova"
      ],
      "abstract": "The AI act is the European Union-wide regulation of AI systems. It includes\nspecific provisions for general-purpose AI models which however need to be\nfurther interpreted in terms of technical standards and state-of-art studies to\nensure practical compliance solutions. This paper examines the AI act\nrequirements for providers and deployers of general-purpose AI and further\nproposes uncertainty estimation as a suitable measure for legal compliance and\nquality assurance in training of such models. We argue that uncertainty\nestimation should be a required component for deploying models in the real\nworld, and under the EU AI Act, it could fulfill several requirements for\ntransparency, accuracy, and trustworthiness. However, generally using\nuncertainty estimation methods increases the amount of computation, producing a\ndilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to\nclassify the model as a systemic risk system which bears more regulatory\nburden.",
      "tldr_zh": "这篇论文探讨了欧盟 AI 法案（EU AI Act）对通用 AI 模型（general-purpose AI）的规定，强调需要通过技术标准和技术研究来实现实际合规。论文提出不确定性估计（uncertainty estimation）作为一种关键措施，能帮助提供者和部署者满足透明度、准确性和可信度要求，从而提升模型的法律合规性和质量保障。然而，使用不确定性估计会增加计算量，可能超过 10^25 FLOPS 的阈值，导致模型被分类为系统性风险系统，并带来额外的监管负担，从而形成一个两难困境。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2nd GenLaw Workshop @ ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11249v1",
      "published_date": "2024-08-20 23:59:51 UTC",
      "updated_date": "2024-08-20 23:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:51:29.867969"
    },
    {
      "arxiv_id": "2408.11243v2",
      "title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?",
      "title_zh": "神经缩放定律在图自监督学习中是否存在？",
      "authors": [
        "Qian Ma",
        "Haitao Mao",
        "Jingzhe Liu",
        "Zhehua Zhang",
        "Chunlin Feng",
        "Yu Song",
        "Yihan Shao",
        "Yao Ma"
      ],
      "abstract": "Self-supervised learning~(SSL) is essential to obtain foundation models in\nNLP and CV domains via effectively leveraging knowledge in large-scale\nunlabeled data. The reason for its success is that a suitable SSL design can\nhelp the model to follow the neural scaling law, i.e., the performance\nconsistently improves with increasing model and dataset sizes. However, it\nremains a mystery whether existing SSL in the graph domain can follow the\nscaling behavior toward building Graph Foundation Models~(GFMs) with\nlarge-scale pre-training. In this study, we examine whether existing graph SSL\ntechniques can follow the neural scaling behavior with the potential to serve\nas the essential component for GFMs. Our benchmark includes comprehensive SSL\ntechnique implementations with analysis conducted on both the conventional SSL\nsetting and many new settings adopted in other domains. Surprisingly, despite\nthe SSL loss continuously decreasing, no existing graph SSL techniques follow\nthe neural scaling behavior on the downstream performance. The model\nperformance only merely fluctuates on different data scales and model scales.\nInstead of the scales, the key factors influencing the performance are the\nchoices of model architecture and pretext task design. This paper examines\nexisting SSL techniques for the feasibility of Graph SSL techniques in\ndeveloping GFMs and opens a new direction for graph SSL design with the new\nevaluation prototype. Our code implementation is available online to ease\nreproducibility on https://github.com/GraphSSLScaling/GraphSSLScaling.",
      "tldr_zh": "本研究探讨了图自监督学习(Graph Self-Supervised Learning)中神经缩放定律(Neural Scaling Laws)是否成立，即模型和数据集规模增加是否能提升性能，以支持构建图基础模型(Graph Foundation Models, GFMs)。研究通过基准测试，实现了现有SSL技术的全面评估，包括传统设置和新领域设置。结果显示，尽管SSL损失函数持续下降，但现有图SSL技术未遵循缩放行为，模型性能仅在不同规模下波动。关键影响因素是模型架构和预任务设计，而不是规模大小，该研究为未来图SSL设计提供了新方向，并公开了代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11243v2",
      "published_date": "2024-08-20 23:45:11 UTC",
      "updated_date": "2024-08-26 18:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:51:42.843252"
    },
    {
      "arxiv_id": "2408.11239v1",
      "title": "A Little Confidence Goes a Long Way",
      "title_zh": "一点信心",
      "authors": [
        "John Scoville",
        "Shang Gao",
        "Devanshu Agrawal",
        "Javed Qadrud-Din"
      ],
      "abstract": "We introduce a group of related methods for binary classification tasks using\nprobes of the hidden state activations in large language models (LLMs).\nPerformance is on par with the largest and most advanced LLMs currently\navailable, but requiring orders of magnitude fewer computational resources and\nnot requiring labeled data. This approach involves translating class labels\ninto a semantically rich description, spontaneous symmetry breaking of\nmultilayer perceptron probes for unsupervised learning and inference, training\nprobes to generate confidence scores (prior probabilities) from hidden state\nactivations subject to known constraints via entropy maximization, and\nselecting the most confident probe model from an ensemble for prediction. These\ntechniques are evaluated on four datasets using five base LLMs.",
      "tldr_zh": "本研究提出了一组方法，用于大型语言模型 (LLMs) 的隐藏状态激活探针 (probes) 进行二元分类任务，这些方法性能可媲美当前最先进的 LLMs，但只需少量计算资源且无需标记数据。关键技术包括将类标签翻译成语义丰富的描述、多层感知器 (multilayer perceptron) 探针的自发对称性破缺 (spontaneous symmetry breaking) 以实现非监督学习，以及通过熵最大化 (entropy maximization) 训练探针生成置信度分数 (prior probabilities)，并从集成 (ensemble) 中选择最置信的模型进行预测。在四个数据集上使用五个基础 LLMs 进行评估，结果显示该方法有效提升了效率和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11239v1",
      "published_date": "2024-08-20 23:36:00 UTC",
      "updated_date": "2024-08-20 23:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:51:56.370574"
    },
    {
      "arxiv_id": "2408.11237v1",
      "title": "Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification",
      "title_zh": "基于注意力头掩码的分布外检测，用于多模态文档分类",
      "authors": [
        "Christos Constantinou",
        "Georgios Ioannides",
        "Aman Chadha",
        "Aaron Elkins",
        "Edwin Simpson"
      ],
      "abstract": "Detecting out-of-distribution (OOD) data is crucial in machine learning\napplications to mitigate the risk of model overconfidence, thereby enhancing\nthe reliability and safety of deployed systems. The majority of existing OOD\ndetection methods predominantly address uni-modal inputs, such as images or\ntexts. In the context of multi-modal documents, there is a notable lack of\nextensive research on the performance of these methods, which have primarily\nbeen developed with a focus on computer vision tasks. We propose a novel\nmethodology termed as attention head masking (AHM) for multi-modal OOD tasks in\ndocument classification systems. Our empirical results demonstrate that the\nproposed AHM method outperforms all state-of-the-art approaches and\nsignificantly decreases the false positive rate (FPR) compared to existing\nsolutions up to 7.5\\%. This methodology generalizes well to multi-modal data,\nsuch as documents, where visual and textual information are modeled under the\nsame Transformer architecture. To address the scarcity of high-quality publicly\navailable document datasets and encourage further research on OOD detection for\ndocuments, we introduce FinanceDocs, a new document AI dataset. Our code and\ndataset are publicly available.",
      "tldr_zh": "该研究强调了Out-of-Distribution (OOD)检测在多模态文档分类中的重要性，以减少模型过度自信并提升系统可靠性，因为现有方法主要针对单模态输入如图像或文本。作者提出了一种新颖的attention head masking (AHM)方法，通过在Transformer架构下屏蔽注意力头来处理多模态文档的OOD任务，实验结果显示AHM优于现有最先进方法，将false positive rate (FPR)降低多达7.5%。此外，研究还发布了FinanceDocs数据集，以推动OOD检测领域的进一步研究，并公开了代码和数据集。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11237v1",
      "published_date": "2024-08-20 23:30:00 UTC",
      "updated_date": "2024-08-20 23:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:52:05.523656"
    },
    {
      "arxiv_id": "2408.11234v2",
      "title": "Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Weber",
        "Carly Beneke",
        "Clyde Wheeler"
      ],
      "abstract": "Regular measurement of carbon stock in the world's forests is critical for\ncarbon accounting and reporting under national and international climate\ninitiatives, and for scientific research, but has been largely limited in\nscalability and temporal resolution due to a lack of ground based assessments.\nIncreasing efforts have been made to address these challenges by incorporating\nremotely sensed data. We present a new methodology which uses multi-sensor,\nmulti-spectral imagery at a resolution of 10 meters and a deep learning based\nmodel which unifies the prediction of above ground biomass density (AGBD),\ncanopy height (CH), canopy cover (CC) as well as uncertainty estimations for\nall three quantities. The model is trained on millions of globally sampled\nGEDI-L2/L4 measurements. We validate the capability of our model by deploying\nit over the entire globe for the year 2023 as well as annually from 2016 to\n2023 over selected areas. The model achieves a mean absolute error for AGBD\n(CH, CC) of 26.1 Mg/ha (3.7 m, 9.9 %) and a root mean squared error of 50.6\nMg/ha (5.4 m, 15.8 %) on a globally sampled test dataset, demonstrating a\nsignificant improvement over previously published results. We also report the\nmodel performance against independently collected ground measurements published\nin the literature, which show a high degree of correlation across varying\nconditions. We further show that our pre-trained model facilitates seamless\ntransferability to other GEDI variables due to its multi-head architecture.",
      "tldr_zh": "本文提出了一种统一的深度学习模型，利用高分辨率（10米）多传感器卫星图像，预测全球的地上生物量密度（AGBD）、树冠高度（CH）和树冠覆盖率（CC），并提供这些量的不确定性估计。模型使用数百万全球采样的GEDI-L2/L4测量数据进行训练，并在2023年全球范围以及2016-2023年特定区域进行部署。结果显示，该模型在测试数据集上实现AGBD的平均绝对误差为26.1 Mg/ha、均方根误差为50.6 Mg/ha，以及CH和CC的相应误差，与之前方法相比显著改善，并展现出高度的相关性和转移性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11234v2",
      "published_date": "2024-08-20 23:15:41 UTC",
      "updated_date": "2024-12-31 10:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:52:21.423089"
    },
    {
      "arxiv_id": "2408.11227v2",
      "title": "OCTCube-M: A 3D multimodal optical coherence tomography foundation model for retinal and systemic diseases with cross-cohort and cross-device validation",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Liu",
        "Hanwen Xu",
        "Addie Woicik",
        "Linda G. Shapiro",
        "Marian Blazes",
        "Yue Wu",
        "Verena Steffen",
        "Catherine Cukras",
        "Cecilia S. Lee",
        "Miao Zhang",
        "Aaron Y. Lee",
        "Sheng Wang"
      ],
      "abstract": "We present OCTCube-M, a 3D OCT-based multi-modal foundation model for jointly\nanalyzing OCT and en face images. OCTCube-M first developed OCTCube, a 3D\nfoundation model pre-trained on 26,685 3D OCT volumes encompassing 1.62 million\n2D OCT images. It then exploits a novel multi-modal contrastive learning\nframework COEP to integrate other retinal imaging modalities, such as fundus\nautofluorescence and infrared retinal imaging, into OCTCube, efficiently\nextending it into multi-modal foundation models. OCTCube achieves best\nperformance on predicting 8 retinal diseases, demonstrating strong\ngeneralizability on cross-cohort, cross-device and cross-modality prediction.\nOCTCube can also predict cross-organ nodule malignancy (CT) and low cardiac\nejection fraction as well as systemic diseases, such as diabetes and\nhypertension, revealing its wide applicability beyond retinal diseases. We\nfurther develop OCTCube-IR using COEP with 26,685 OCT and IR image pairs.\nOCTCube-IR can accurately retrieve between OCT and IR images, allowing joint\nanalysis between 3D and 2D retinal imaging modalities. Finally, we trained a\ntri-modal foundation model OCTCube-EF from 4 million 2D OCT images and 400K en\nface retinal images. OCTCube-EF attains the best performance on predicting the\ngrowth rate of geographic atrophy (GA) across datasets collected from 6\nmulti-center global trials conducted in 23 countries. This improvement is\nstatistically equivalent to running a clinical trial with more than double the\nsize of the original study. Our analysis based on another retrospective case\nstudy reveals OCTCube-EF's ability to avoid false positive Phase-III results\naccording to its accurate treatment effect estimation on the Phase-II results.\nIn sum, OCTCube-M is a 3D multi-modal foundation model framework that\nintegrates OCT and other retinal imaging modalities revealing substantial\ndiagnostic and prognostic benefits.",
      "tldr_zh": "本研究提出了OCTCube-M，一种基于3D OCT的多模态基础模型，用于联合分析OCT和en face图像，以诊断视网膜和系统性疾病。模型首先通过在26,685个3D OCT volumes上预训练OCTCube，并利用新型multi-modal contrastive learning框架COEP整合其他成像模态，如fundus autofluorescence和infrared retinal imaging，提升了跨-cohort、跨-device和跨-modality的预测泛化能力。OCTCube在预测8种视网膜疾病方面表现最佳，并能扩展到预测跨器官结节恶性（CT）、低心脏射血分数以及系统性疾病如糖尿病和高血压。进一步开发的OCTCube-IR和OCTCube-EF模型实现了OCT与IR图像的准确检索，并在多中心试验中准确预测geographic atrophy (GA)的增长率，提供显著的诊断和预后益处，相当于扩大临床试验规模一倍以上。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11227v2",
      "published_date": "2024-08-20 22:55:19 UTC",
      "updated_date": "2024-12-17 19:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:52:33.754789"
    },
    {
      "arxiv_id": "2408.11219v1",
      "title": "CoDi: Conversational Distillation for Grounded Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Huber",
        "Arash Einolghozati",
        "Rylan Conway",
        "Kanika Narang",
        "Matt Smith",
        "Waqar Nayyar",
        "Adithya Sagar",
        "Ahmed Aly",
        "Akshat Shrivastava"
      ],
      "abstract": "Distilling conversational skills into Small Language Models (SLMs) with\napproximately 1 billion parameters presents significant challenges. Firstly,\nSLMs have limited capacity in their model parameters to learn extensive\nknowledge compared to larger models. Secondly, high-quality conversational\ndatasets are often scarce, small, and domain-specific. Addressing these\nchallenges, we introduce a novel data distillation framework named CoDi (short\nfor Conversational Distillation, pronounced \"Cody\"), allowing us to synthesize\nlarge-scale, assistant-style datasets in a steerable and diverse manner.\nSpecifically, while our framework is task agnostic at its core, we explore and\nevaluate the potential of CoDi on the task of conversational grounded reasoning\nfor question answering. This is a typical on-device scenario for specialist\nSLMs, allowing for open-domain model responses, without requiring the model to\n\"memorize\" world knowledge in its limited weights. Our evaluations show that\nSLMs trained with CoDi-synthesized data achieve performance comparable to\nmodels trained on human-annotated data in standard metrics. Additionally, when\nusing our framework to generate larger datasets from web data, our models\nsurpass larger, instruction-tuned models in zero-shot conversational grounded\nreasoning tasks.",
      "tldr_zh": "该研究提出CoDi框架（Conversational Distillation），旨在解决将对话技能蒸馏到小型语言模型(SLMs)中的挑战，这些模型参数约10亿，知识容量有限，且高质量对话数据集稀缺且领域特定。CoDi通过合成大规模、可控且多样的辅助式数据集，支持任务无关的核心设计，并将其应用于对话式基础推理(question answering)的设备端场景，无需模型记忆世界知识。实验结果显示，使用CoDi合成数据训练的SLMs，在标准指标上与人类标注数据训练的模型性能相当；此外，当从网络数据生成更大数据集时，该模型在零样本对话式基础推理任务中超越了更大的指令调整模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.11219v1",
      "published_date": "2024-08-20 22:35:47 UTC",
      "updated_date": "2024-08-20 22:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:52:41.266545"
    },
    {
      "arxiv_id": "2408.11207v1",
      "title": "Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjay Bhargav Dharavath",
        "Tanmoy Dam",
        "Supriyo Chakraborty",
        "Prithwiraj Roy",
        "Aniruddha Maiti"
      ],
      "abstract": "The field of autonomous vehicles (AVs) predominantly leverages multi-modal\nintegration of LiDAR and camera data to achieve better performance compared to\nusing a single modality. However, the fusion process encounters challenges in\ndetecting distant objects due to the disparity between the high resolution of\ncameras and the sparse data from LiDAR. Insufficient integration of global\nperspectives with local-level details results in sub-optimal fusion\nperformance.To address this issue, we have developed an innovative two-stage\nfusion process called Quantum Inverse Contextual Vision Transformers (Q-ICVT).\nThis approach leverages adiabatic computing in quantum concepts to create a\nnovel reversible vision transformer known as the Global Adiabatic Transformer\n(GAT). GAT aggregates sparse LiDAR features with semantic features in dense\nimages for cross-modal integration in a global form. Additionally, the Sparse\nExpert of Local Fusion (SELF) module maps the sparse LiDAR 3D proposals and\nencodes position information of the raw point cloud onto the dense camera\nfeature space using a gating point fusion approach. Our experiments show that\nQ-ICVT achieves an mAPH of 82.54 for L2 difficulties on the Waymo dataset,\nimproving by 1.88% over current state-of-the-art fusion methods. We also\nanalyze GAT and SELF in ablation studies to highlight the impact of Q-ICVT. Our\ncode is available at https://github.com/sanjay-810/Qicvt Q-ICVT",
      "tldr_zh": "该论文针对自动驾驶车辆（AVs）中LiDAR和相机数据的多模态融合问题，提出了一种创新的Quantum Inverse Contextual Vision Transformers (Q-ICVT)框架，以解决远距离物体检测的挑战和全球视角与局部细节整合不足。Q-ICVT采用两阶段方法，包括Global Adiabatic Transformer (GAT)，利用量子绝热计算聚合稀疏LiDAR特征与密集图像语义特征；以及Sparse Expert of Local Fusion (SELF)模块，通过门控点融合将LiDAR 3D proposals映射到相机特征空间。实验结果显示，在Waymo数据集上，Q-ICVT的mAPH达到82.54，比现有最先进方法提高了1.88%，并通过消融研究验证了GAT和SELF的贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper has been accepted as a short paper at CIKM '24",
      "pdf_url": "http://arxiv.org/pdf/2408.11207v1",
      "published_date": "2024-08-20 21:36:57 UTC",
      "updated_date": "2024-08-20 21:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:52:55.060021"
    },
    {
      "arxiv_id": "2408.11202v1",
      "title": "Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Tatsuhiro Shimizu",
        "Koichi Tanaka",
        "Ren Kishimoto",
        "Haruka Kiyohara",
        "Masahiro Nomura",
        "Yuta Saito"
      ],
      "abstract": "We explore off-policy evaluation and learning (OPE/L) in contextual\ncombinatorial bandits (CCB), where a policy selects a subset in the action\nspace. For example, it might choose a set of furniture pieces (a bed and a\ndrawer) from available items (bed, drawer, chair, etc.) for interior design\nsales. This setting is widespread in fields such as recommender systems and\nhealthcare, yet OPE/L of CCB remains unexplored in the relevant literature.\nTypical OPE/L methods such as regression and importance sampling can be applied\nto the CCB problem, however, they face significant challenges due to high bias\nor variance, exacerbated by the exponential growth in the number of available\nsubsets. To address these challenges, we introduce a concept of factored action\nspace, which allows us to decompose each subset into binary indicators. This\nformulation allows us to distinguish between the ''main effect'' derived from\nthe main actions, and the ''residual effect'', originating from the\nsupplemental actions, facilitating more effective OPE. Specifically, our\nestimator, called OPCB, leverages an importance sampling-based approach to\nunbiasedly estimate the main effect, while employing regression-based approach\nto deal with the residual effect with low variance. OPCB achieves substantial\nvariance reduction compared to conventional importance sampling methods and\nbias reduction relative to regression methods under certain conditions, as\nillustrated in our theoretical analysis. Experiments demonstrate OPCB's\nsuperior performance over typical methods in both OPE and OPL.",
      "tldr_zh": "本文研究了在 Contextual Combinatorial Bandits (CCB) 中的 Off-Policy Evaluation and Learning (OPE/L)，这种设置常见于推荐系统和医疗领域，但面临传统方法如回归和重要性采样的高偏差和高方差问题。作者引入 factored action space 概念，将行动子集分解为二进制指标，以区分主效应和残差效应，并提出 OPCB 估计器，该方法结合重要性采样估计主效应和回归估计残差效应。理论分析和实验结果显示，OPCB 显著降低了方差和偏差，在 OPE 和 OPL 任务中比传统方法表现出色。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "accepted at RecSys2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11202v1",
      "published_date": "2024-08-20 21:25:04 UTC",
      "updated_date": "2024-08-20 21:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:53:06.604606"
    },
    {
      "arxiv_id": "2408.11198v1",
      "title": "EPiC: Cost-effective Search-based Prompt Engineering of LLMs for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Taherkhani",
        "Melika Sepindband",
        "Hung Viet Pham",
        "Song Wang",
        "Hadi Hemmati"
      ],
      "abstract": "Large Language Models (LLMs) have seen increasing use in various software\ndevelopment tasks, especially in code generation. The most advanced recent\nmethods attempt to incorporate feedback from code execution into prompts to\nhelp guide LLMs in generating correct code, in an iterative process. While\neffective, these methods could be costly and time-consuming due to numerous\ninteractions with the LLM and the extensive token usage. To address this issue,\nwe propose an alternative approach named Evolutionary Prompt Engineering for\nCode (EPiC), which leverages a lightweight evolutionary algorithm to evolve the\noriginal prompts toward better ones that produce high-quality code, with\nminimal interactions with LLM. Our evaluation against state-of-the-art (SOTA)\nLLM-based code generation models shows that EPiC outperforms all the baselines\nin terms of cost-effectiveness.",
      "tldr_zh": "该论文提出 EPiC，一种基于搜索的提示工程方法，旨在优化 Large Language Models (LLMs) 在代码生成中的性能，同时降低成本和交互次数。\nEPiC 利用轻量级的 evolutionary algorithm 来迭代改进原始提示，确保生成高质量代码，而无需频繁调用 LLMs。\n实验结果表明，EPiC 在成本效益方面优于现有最先进（SOTA）模型，为高效的代码生成提供了更经济可行的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to TSE",
      "pdf_url": "http://arxiv.org/pdf/2408.11198v1",
      "published_date": "2024-08-20 21:15:36 UTC",
      "updated_date": "2024-08-20 21:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:53:16.877855"
    },
    {
      "arxiv_id": "2408.11189v1",
      "title": "Reading with Intent",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Reichman",
        "Kartik Talamadupula",
        "Toshish Jawale",
        "Larry Heck"
      ],
      "abstract": "Retrieval augmented generation (RAG) systems augment how knowledge language\nmodels are by integrating external information sources such as Wikipedia,\ninternal documents, scientific papers, or the open internet. RAG systems that\nrely on the open internet as their knowledge source have to contend with the\ncomplexities of human-generated content. Human communication extends much\ndeeper than just the words rendered as text. Intent, tonality, and connotation\ncan all change the meaning of what is being conveyed. Recent real-world\ndeployments of RAG systems have shown some difficulty in understanding these\nnuances of human communication. One significant challenge for these systems\nlies in processing sarcasm. Though the Large Language Models (LLMs) that make\nup the backbone of these RAG systems are able to detect sarcasm, they currently\ndo not always use these detections for the subsequent processing of text. To\naddress these issues, in this paper, we synthetically generate sarcastic\npassages from Natural Question's Wikipedia retrieval corpus. We then test the\nimpact of these passages on the performance of both the retriever and reader\nportion of the RAG pipeline. We introduce a prompting system designed to\nenhance the model's ability to interpret and generate responses in the presence\nof sarcasm, thus improving overall system performance. Finally, we conduct\nablation studies to validate the effectiveness of our approach, demonstrating\nimprovements in handling sarcastic content within RAG systems.",
      "tldr_zh": "这篇论文探讨了检索增强生成（RAG）系统在处理开放互联网内容的挑战，特别是人类沟通中的意图、语气和内涵（如sarcasm）可能改变文本含义的问题。尽管Large Language Models (LLMs) 可以检测sarcasm，但往往未将其用于后续处理。作者通过从Natural Questions的Wikipedia语料库中合成生成sarcasm段落，测试其对RAG系统检索器和阅读器部分的影响，并引入一个prompting system来提升模型对sarcasm的解释和响应生成能力。实验结果显示，该方法显著改善了系统性能，并通过ablation studies验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11189v1",
      "published_date": "2024-08-20 20:47:27 UTC",
      "updated_date": "2024-08-20 20:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:53:33.273454"
    },
    {
      "arxiv_id": "2408.11187v1",
      "title": "Optimization of Multi-Agent Flying Sidekick Traveling Salesman Problem over Road Networks",
      "title_zh": "多代理飞行助手旅行商问题在道路网络上的优化",
      "authors": [
        "Ruixiao Yang",
        "Chuchu Fan"
      ],
      "abstract": "The mixed truck-drone delivery systems have attracted increasing attention\nfor last-mile logistics, but real-world complexities demand a shift from\nsingle-agent, fully connected graph models to multi-agent systems operating on\nactual road networks. We introduce the multi-agent flying sidekick traveling\nsalesman problem (MA-FSTSP) on road networks, extending the single truck-drone\nmodel to multiple trucks, each carrying multiple drones while considering full\nroad networks for truck restrictions and flexible drone routes. We propose a\nmixed-integer linear programming model and an efficient three-phase heuristic\nalgorithm for this NP-hard problem. Our approach decomposes MA-FSTSP into\nmanageable subproblems of one truck with multiple drones. Then, it computes the\nroutes for trucks without drones in subproblems, which are used in the final\nphase as heuristics to help optimize drone and truck routes simultaneously.\nExtensive numerical experiments on Manhattan and Boston road networks\ndemonstrate our algorithm's superior effectiveness and efficiency,\nsignificantly outperforming both column generation and variable neighborhood\nsearch baselines in solution quality and computation time. Notably, our\napproach scales to more than 300 customers within a 5-minute time limit,\nshowcasing its potential for large-scale, real-world logistics applications.",
      "tldr_zh": "本研究引入了多智能体飞行伴侣旅行推销员问题（MA-FSTSP），扩展了传统的单卡车-无人机模型到多卡车-多无人机系统，以适应实际道路网络的物流挑战。研究者提出了一种混合整数线性规划模型和一个高效的三阶段启发式算法，该算法通过分解问题为子任务（如处理单个卡车与多个无人机的子问题，并优化卡车和无人机路线）来提升计算效率。实验在曼哈顿和波士顿道路网络上进行，结果显示，该算法在解决方案质量和计算时间上显著优于列生成和变邻域搜索基线，且能扩展到超过300个客户的场景，在5分钟内完成，展示了其在大型物流应用中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11187v1",
      "published_date": "2024-08-20 20:44:18 UTC",
      "updated_date": "2024-08-20 20:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:53:41.864834"
    },
    {
      "arxiv_id": "2408.11186v2",
      "title": "Sequential Resource Trading Using Comparison-Based Gradient Estimation",
      "title_zh": "基于比较的梯度估计的顺序资源交易",
      "authors": [
        "Surya Murthy",
        "Mustafa O. Karabag",
        "Ufuk Topcu"
      ],
      "abstract": "Autonomous agents interact with other agents of unknown preferences to share\nresources in their environment. We explore sequential trading for resource\nallocation in a setting where two greedily rational agents sequentially trade\nresources from a finite set of categories. Each agent has a utility function\nthat depends on the amount of resources it possesses in each category. The\noffering agent makes trade offers to improve its utility without knowing the\nresponding agent's utility function, and the responding agent only accepts\noffers that improve its utility. We present an algorithm for the offering agent\nto estimate the responding agent's gradient (preferences) and make offers based\non previous acceptance or rejection responses. The algorithm's goal is to reach\na Pareto-optimal resource allocation state while ensuring that the utilities of\nboth agents improve after every accepted trade. We show that, after a finite\nnumber of consecutively rejected offers, the responding agent is at a\nnear-optimal state, or the agents' gradients are closely aligned. We compare\nthe proposed algorithm against various baselines in continuous and discrete\ntrading scenarios and show that it improves the societal benefit with fewer\noffers.",
      "tldr_zh": "该研究探讨了两个自治代理（autonomous agents）在资源分配中的顺序交易问题，其中代理基于未知的效用函数（utility function）进行互动。提出了一种基于比较的梯度估计算法（Comparison-Based Gradient Estimation），让提供方代理通过之前的接受或拒绝响应来估计响应方代理的偏好（preferences），从而生成改进效用的交易报价。算法确保每次接受的交易都提升双方的效用，并最终达到帕累托最优（Pareto-optimal）资源分配状态。实验结果显示，该算法在连续和离散场景中比基线方法提高了社会效益（societal benefit），并显著减少了报价次数。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11186v2",
      "published_date": "2024-08-20 20:42:41 UTC",
      "updated_date": "2024-11-03 23:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:53:53.774870"
    },
    {
      "arxiv_id": "2408.11182v2",
      "title": "Hide Your Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Carrier Articles",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilong Wang",
        "Haizhou Wang",
        "Nanqing Luo",
        "Lan Zhang",
        "Xiaoyan Sun",
        "Yebo Cao",
        "Peng Liu"
      ],
      "abstract": "Large Language Model (LLM) jailbreak refers to a type of attack aimed to\nbypass the safeguard of an LLM to generate contents that are inconsistent with\nthe safe usage guidelines. Based on the insights from the self-attention\ncomputation process, this paper proposes a novel blackbox jailbreak approach,\nwhich involves crafting the payload prompt by strategically injecting the\nprohibited query into a carrier article. The carrier article maintains the\nsemantic proximity to the prohibited query, which is automatically produced by\ncombining a hypernymy article and a context, both of which are generated from\nthe prohibited query. The intuition behind the usage of carrier article is to\nactivate the neurons in the model related to the semantics of the prohibited\nquery while suppressing the neurons that will trigger the objectionable text.\nCarrier article itself is benign, and we leveraged prompt injection techniques\nto produce the payload prompt. We evaluate our approach using JailbreakBench,\ntesting against four target models across 100 distinct jailbreak objectives.\nThe experimental results demonstrate our method's superior effectiveness,\nachieving an average success rate of 63% across all target models,\nsignificantly outperforming existing blackbox jailbreak methods.",
      "tldr_zh": "本文提出了一种新型黑盒越狱攻击方法，名为“Hide Your Malicious Goal Into Benign Narratives”，通过在载体文章（carrier article）中策略性地注入禁止查询，来绕过 Large Language Model (LLM) 的安全防护。该方法基于自注意力计算过程的洞见，自动生成语义相近的载体文章（由超onymy 文章和上下文组合而成），以激活相关神经元同时抑制触发不适当响应的神经元。实验在 JailbreakBench 上测试了四个目标模型和 100 个越狱目标，结果显示该方法平均成功率达到 63%，显著优于现有黑盒攻击方法。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11182v2",
      "published_date": "2024-08-20 20:35:04 UTC",
      "updated_date": "2025-02-07 01:18:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:54:06.325741"
    },
    {
      "arxiv_id": "2408.11181v1",
      "title": "A Full DAG Score-Based Algorithm for Learning Causal Bayesian Networks with Latent Confounders",
      "title_zh": "翻译失败",
      "authors": [
        "Christophe Gonzales",
        "Amir-Hosein Valizadeh"
      ],
      "abstract": "Causal Bayesian networks (CBN) are popular graphical probabilistic models\nthat encode causal relations among variables. Learning their graphical\nstructure from observational data has received a lot of attention in the\nliterature. When there exists no latent (unobserved) confounder, i.e., no\nunobserved direct common cause of some observed variables, learning algorithms\ncan be divided essentially into two classes: constraint-based and score-based\napproaches. The latter are often thought to be more robust than the former and\nto produce better results. However, to the best of our knowledge, when\nvariables are discrete, no score-based algorithm is capable of dealing with\nlatent confounders. This paper introduces the first fully score-based structure\nlearning algorithm searching the space of DAGs (directed acyclic graphs) that\nis capable of identifying the presence of some latent confounders. It is\njustified mathematically and experiments highlight its effectiveness.",
      "tldr_zh": "该论文提出了一种全新的基于得分的结构学习算法，用于从观测数据中学习因果贝叶斯网络(Causal Bayesian Networks, CBN)，特别针对存在潜在混杂因素(latent confounders)的情况。传统基于得分的算法在处理离散变量时无法识别这些混杂因素，但该算法在DAG (Directed Acyclic Graphs) 空间中进行搜索，能够有效检测和处理它们。算法通过数学证明其有效性，并在实验中证明了其鲁棒性和优越性能，与现有方法相比显著提高了学习准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, extended version with supplementary material of paper\n  accepted at the 27th European Conference on Artificial Intelligence (ECAI'24)",
      "pdf_url": "http://arxiv.org/pdf/2408.11181v1",
      "published_date": "2024-08-20 20:25:56 UTC",
      "updated_date": "2024-08-20 20:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:54:27.369928"
    },
    {
      "arxiv_id": "2408.11172v1",
      "title": "SubgoalXL: Subgoal-based Expert Learning for Theorem Proving",
      "title_zh": "SubgoalXL：基于子目标的专家学习用于定理证明",
      "authors": [
        "Xueliang Zhao",
        "Lin Zheng",
        "Haige Bo",
        "Changran Hu",
        "Urmish Thakker",
        "Lingpeng Kong"
      ],
      "abstract": "Formal theorem proving, a field at the intersection of mathematics and\ncomputer science, has seen renewed interest with advancements in large language\nmodels (LLMs). This paper introduces SubgoalXL, a novel approach that\nsynergizes subgoal-based proofs with expert learning to enhance LLMs'\ncapabilities in formal theorem proving within the Isabelle environment.\nSubgoalXL addresses two critical challenges: the scarcity of specialized\nmathematics and theorem-proving data, and the need for improved multi-step\nreasoning abilities in LLMs. By optimizing data efficiency and employing\nsubgoal-level supervision, SubgoalXL extracts richer information from limited\nhuman-generated proofs. The framework integrates subgoal-oriented proof\nstrategies with an expert learning system, iteratively refining formal\nstatement, proof, and subgoal generators. Leveraging the Isabelle environment's\nadvantages in subgoal-based proofs, SubgoalXL achieves a new state-of-the-art\nperformance of 56.1\\% in Isabelle on the standard miniF2F dataset, marking an\nabsolute improvement of 4.9\\%. Notably, SubgoalXL successfully solves 41 AMC12,\n9 AIME, and 3 IMO problems from miniF2F. These results underscore the\neffectiveness of maximizing limited data utility and employing targeted\nguidance for complex reasoning in formal theorem proving, contributing to the\nongoing advancement of AI reasoning capabilities. The implementation is\navailable at \\url{https://github.com/zhaoxlpku/SubgoalXL}.",
      "tldr_zh": "本论文提出SubgoalXL，一种结合subgoal-based proofs和expert learning的新方法，旨在提升LLMs在Isabelle环境中的定理证明能力，解决专业数据稀缺和多步推理不足的挑战。通过优化数据效率和subgoal-level supervision，该框架从有限的人工证明中提取更多信息，并迭代精炼formal statement、proof和subgoal generators。实验结果显示，SubgoalXL在miniF2F数据集上达到56.1%的state-of-the-art性能，比之前提升4.9%，成功解决了41个AMC12、9个AIME和3个IMO问题，证明了最大化数据效用和针对性指导在提升AI推理能力方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11172v1",
      "published_date": "2024-08-20 20:10:53 UTC",
      "updated_date": "2024-08-20 20:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:54:30.795816"
    },
    {
      "arxiv_id": "2408.11135v1",
      "title": "MS$^3$D: A RG Flow-Based Regularization for GAN Training with Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Wang",
        "Xin Lan",
        "Yuxin Tian",
        "Jiancheng Lv"
      ],
      "abstract": "Generative adversarial networks (GANs) have made impressive advances in image\ngeneration, but they often require large-scale training data to avoid\ndegradation caused by discriminator overfitting. To tackle this issue, we\ninvestigate the challenge of training GANs with limited data, and propose a\nnovel regularization method based on the idea of renormalization group (RG) in\nphysics.We observe that in the limited data setting, the gradient pattern that\nthe generator obtains from the discriminator becomes more aggregated over time.\nIn RG context, this aggregated pattern exhibits a high discrepancy from its\ncoarse-grained versions, which implies a high-capacity and sensitive system,\nprone to overfitting and collapse. To address this problem, we introduce a\n\\textbf{m}ulti-\\textbf{s}cale \\textbf{s}tructural\n\\textbf{s}elf-\\textbf{d}issimilarity (MS$^3$D) regularization, which constrains\nthe gradient field to have a consistent pattern across different scales,\nthereby fostering a more redundant and robust system. We show that our method\ncan effectively enhance the performance and stability of GANs under limited\ndata scenarios, and even allow them to generate high-quality images with very\nfew data.",
      "tldr_zh": "这篇论文针对生成对抗网络 (GANs) 在数据有限场景下容易因鉴别器过拟合而性能下降的问题，提出了一种基于重整化群 (RG) 思想的正则化方法。作者观察到生成器的梯度模式在数据稀缺时变得更聚集，导致系统高敏感性，因此引入多尺度结构自异质性 (MS³D) 正则化来约束梯度场在不同尺度上的模式一致性，从而提升系统的冗余性和鲁棒性。实验结果表明，该方法显著提高了 GANs 的性能和稳定性，甚至能在极少数据情况下生成高质量图像。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11135v1",
      "published_date": "2024-08-20 18:37:37 UTC",
      "updated_date": "2024-08-20 18:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:54:42.625362"
    },
    {
      "arxiv_id": "2408.11121v2",
      "title": "DOMBA: Double Model Balancing for Access-Controlled Language Models via Minimum-Bounded Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Segal",
        "Asaf Shabtai",
        "Yuval Elovici"
      ],
      "abstract": "The utility of large language models (LLMs) depends heavily on the quality\nand quantity of their training data. Many organizations possess large data\ncorpora that could be leveraged to train or fine-tune LLMs tailored to their\nspecific needs. However, these datasets often come with access restrictions\nthat are based on user privileges and enforced by access control mechanisms.\nTraining LLMs on such datasets could result in exposure of sensitive\ninformation to unauthorized users. A straightforward approach for preventing\nsuch exposure is to train a separate model for each access level. This,\nhowever, may result in low utility models due to the limited amount of training\ndata per model compared to the amount in the entire organizational corpus.\nAnother approach is to train a single LLM on all the data while limiting the\nexposure of unauthorized information. However, current exposure-limiting\nmethods for LLMs are ineffective for access-controlled data, where sensitive\ninformation appears frequently across many training examples. We propose DOMBA\n- double model balancing - a simple approach for training and deploying LLMs\nthat provides high utility and access-control functionality with security\nguarantees. DOMBA aggregates the probability distributions of two models, each\ntrained on documents with (potentially many) different access levels, using a\n\"min-bounded\" average function (a function that is bounded by the smaller\nvalue, e.g., harmonic mean). A detailed mathematical analysis and extensive\nevaluation show that DOMBA safeguards restricted information while offering\nutility comparable to non-secure models.",
      "tldr_zh": "该研究解决了大型语言模型（LLMs）在训练受访问控制限制的数据时面临的敏感信息泄露问题，现有方法要么导致模型性能低下，要么无法有效限制暴露。DOMBA 提出了一种双模型平衡方法，通过训练两个分别处理不同访问级别的模型，并使用最小边界聚合函数（如调和均值）来聚合它们的概率分布，从而实现高实用性和安全保障。实验结果和数学分析表明，DOMBA 能有效保护受限信息，同时提供与非安全模型相当的性能，为访问控制下的 LLM 部署提供了可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/ppo1/DOMBA 11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11121v2",
      "published_date": "2024-08-20 18:23:38 UTC",
      "updated_date": "2025-02-08 14:19:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:54:53.637441"
    },
    {
      "arxiv_id": "2408.11054v3",
      "title": "Near, far: Patch-ordering enhances vision foundation models' scene understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Valentinos Pariza",
        "Mohammadreza Salehi",
        "Gertjan Burghouts",
        "Francesco Locatello",
        "Yuki M. Asano"
      ],
      "abstract": "We introduce NeCo: Patch Neighbor Consistency, a novel self-supervised\ntraining loss that enforces patch-level nearest neighbor consistency across a\nstudent and teacher model. Compared to contrastive approaches that only yield\nbinary learning signals, i.e., 'attract' and 'repel', this approach benefits\nfrom the more fine-grained learning signal of sorting spatially dense features\nrelative to reference patches. Our method leverages differentiable sorting\napplied on top of pretrained representations, such as DINOv2-registers to\nbootstrap the learning signal and further improve upon them. This dense\npost-pretraining leads to superior performance across various models and\ndatasets, despite requiring only 19 hours on a single GPU. This method\ngenerates high-quality dense feature encoders and establishes several new\nstate-of-the-art results such as +5.5% and +6% for non-parametric in-context\nsemantic segmentation on ADE20k and Pascal VOC, +7.2% and +5.7% for linear\nsegmentation evaluations on COCO-Things and -Stuff and improvements in the 3D\nunderstanding of multi-view consistency on SPair-71k, by more than 1.5%.",
      "tldr_zh": "该论文提出了一种名为 NeCo（Patch Neighbor Consistency）的自监督训练损失函数，用于提升视觉基础模型的场景理解能力。NeCo 通过强制学生模型和教师模型在 patch 级别的最近邻一致性，并利用可微排序对空间密集特征进行排序，提供比传统对比学习更细粒度的学习信号，从而在预训练表示如 DINOv2 的基础上进一步优化。实验结果显示，该方法仅需单 GPU 19 小时，即在多个数据集上取得了显著改进，包括 ADE20k 和 Pascal VOC 的非参数 in-context 语义分割分别提升 5.5% 和 6%，COCO-Things 和 -Stuff 的线性分割提升 7.2% 和 5.7%，以及 SPair-71k 的 3D 多视图一致性超过 1.5%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR25. The webpage is accessible at:\n  https://vpariza.github.io/NeCo/",
      "pdf_url": "http://arxiv.org/pdf/2408.11054v3",
      "published_date": "2024-08-20 17:58:59 UTC",
      "updated_date": "2025-04-17 09:45:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:55:07.857011"
    },
    {
      "arxiv_id": "2408.11053v2",
      "title": "Revisiting VerilogEval: A Year of Improvements in Large-Language Models for Hardware Code Generation",
      "title_zh": "重新审视 VerilogEval：大语言模型在硬件代码生成方面的一年改进",
      "authors": [
        "Nathaniel Pinckney",
        "Christopher Batten",
        "Mingjie Liu",
        "Haoxing Ren",
        "Brucek Khailany"
      ],
      "abstract": "The application of large-language models (LLMs) to digital hardware code\ngeneration is an emerging field, with most LLMs primarily trained on natural\nlanguage and software code. Hardware code like Verilog constitutes a small\nportion of training data, and few hardware benchmarks exist. The open-source\nVerilogEval benchmark, released in November 2023, provided a consistent\nevaluation framework for LLMs on code completion tasks. Since then, both\ncommercial and open models have seen significant development.\n  In this work, we evaluate new commercial and open models since VerilogEval's\noriginal release-including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3\n70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and\nRTL-Coder-against an improved VerilogEval benchmark suite. We find measurable\nimprovements in state-of-the-art models: GPT-4o achieves a 63% pass rate on\nspecification-to-RTL tasks. The recently released and open Llama3.1 405B\nachieves a 58% pass rate, almost matching GPT-4o, while the smaller\ndomain-specific RTL-Coder 6.7B models achieve an impressive 34% pass rate.\n  Additionally, we enhance VerilogEval's infrastructure by automatically\nclassifying failures, introducing in-context learning support, and extending\nthe tasks to specification-to-RTL translation. We find that prompt engineering\nremains crucial for achieving good pass rates and varies widely with model and\ntask. A benchmark infrastructure that allows for prompt engineering and failure\nanalysis is essential for continued model development and deployment.",
      "tldr_zh": "本研究重新审视了 VerilogEval 基准，评估大型语言模型 (LLMs) 在硬件代码生成（如 Verilog）领域的最新进展，涵盖了过去一年的模型改进。研究团队测试了多种新模型，包括 GPT-4o、GPT-4 Turbo、Llama3.1 (8B/70B/405B) 和 RTL-Coder 6.7B 等，发现 GPT-4o 在 specification-to-RTL 任务上达到 63% 的通过率，而 Llama3.1 405B 也达到了 58%，展示了开源模型的显著提升。论文还增强了 VerilogEval 的基础设施，如自动分类失败和引入 in-context learning 支持，并强调提示工程 (prompt engineering) 对提升模型性能和任务适应性至关重要。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "This paper revisits and improves the benchmark first presented in\n  arXiv:2309.07544. Twenty-one pages, five figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11053v2",
      "published_date": "2024-08-20 17:58:56 UTC",
      "updated_date": "2025-02-03 19:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:55:28.370750"
    },
    {
      "arxiv_id": "2408.11052v3",
      "title": "Accelerating Goal-Conditioned RL Algorithms and Research",
      "title_zh": "加速目标条件强化学习算法和研究",
      "authors": [
        "Michał Bortkiewicz",
        "Władysław Pałucki",
        "Vivek Myers",
        "Tadeusz Dziarmaga",
        "Tomasz Arczewski",
        "Łukasz Kuciński",
        "Benjamin Eysenbach"
      ],
      "abstract": "Self-supervision has the potential to transform reinforcement learning (RL),\nparalleling the breakthroughs it has enabled in other areas of machine\nlearning. While self-supervised learning in other domains aims to find patterns\nin a fixed dataset, self-supervised goal-conditioned reinforcement learning\n(GCRL) agents discover new behaviors by learning from the goals achieved during\nunstructured interaction with the environment. However, these methods have\nfailed to see similar success, both due to a lack of data from slow environment\nsimulations as well as a lack of stable algorithms. We take a step toward\naddressing both of these issues by releasing a high-performance codebase and\nbenchmark (JaxGCRL) for self-supervised GCRL, enabling researchers to train\nagents for millions of environment steps in minutes on a single GPU. By\nutilizing GPU-accelerated replay buffers, environments, and a stable\ncontrastive RL algorithm, we reduce training time by up to $22\\times$.\nAdditionally, we assess key design choices in contrastive RL, identifying those\nthat most effectively stabilize and enhance training performance. With this\napproach, we provide a foundation for future research in self-supervised GCRL,\nenabling researchers to quickly iterate on new ideas and evaluate them in\ndiverse and challenging environments. Website + Code:\nhttps://github.com/MichalBortkiewicz/JaxGCRL",
      "tldr_zh": "该研究旨在加速自监督目标条件强化学习（GCRL），通过解决环境模拟缓慢和算法不稳定的问题来提升RL领域的进展。作者发布了一个高性能代码库和基准（JaxGCRL），利用GPU加速的重放缓冲区、环境以及稳定的对比RL算法，将训练时间减少高达22倍，从而使研究者能在单个GPU上快速训练代理数百万步骤。实验评估了对比RL的关键设计选择，识别出最有效的选项来稳定和提升性能，为未来自监督GCRL研究提供基础，支持快速迭代新想法并在多样环境中测试。网站和代码：https://github.com/MichalBortkiewicz/JaxGCRL。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://michalbortkiewicz.github.io/JaxGCRL/ Code:\n  https://github.com/MichalBortkiewicz/JaxGCRL",
      "pdf_url": "http://arxiv.org/pdf/2408.11052v3",
      "published_date": "2024-08-20 17:58:40 UTC",
      "updated_date": "2025-04-21 11:10:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:55:41.933986"
    },
    {
      "arxiv_id": "2408.11051v2",
      "title": "FLAME: Learning to Navigate with Multimodal LLM in Urban Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhe Xu",
        "Yiyuan Pan",
        "Zhe Liu",
        "Hesheng Wang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated potential in\nVision-and-Language Navigation (VLN) tasks, yet current applications face\nchallenges. While LLMs excel in general conversation scenarios, they struggle\nwith specialized navigation tasks, yielding suboptimal performance compared to\nspecialized VLN models. We introduce FLAME (FLAMingo-Architected Embodied\nAgent), a novel Multimodal LLM-based agent and architecture designed for urban\nVLN tasks that efficiently handles multiple observations. Our approach\nimplements a three-phase tuning technique for effective adaptation to\nnavigation tasks, including single perception tuning for street view\ndescription, multiple perception tuning for route summarization, and end-to-end\ntraining on VLN datasets. The augmented datasets are synthesized automatically.\nExperimental results demonstrate FLAME's superiority over existing methods,\nsurpassing state-of-the-art methods by a 7.3% increase in task completion on\nTouchdown dataset. This work showcases the potential of Multimodal LLMs (MLLMs)\nin complex navigation tasks, representing an advancement towards applications\nof MLLMs in the field of embodied intelligence.",
      "tldr_zh": "该论文提出了 FLAME，一种基于 Multimodal LLM 的新型代理架构，旨在提升城市环境中的视觉和语言导航 (VLN) 任务性能，解决 LLMs 在专业导航中的不足问题。FLAME 通过三阶段调优技术，包括单感知调优用于街景描述、多个感知调优用于路线总结，以及端到端训练在增强的 VLN 数据集上，实现对多种观察的有效处理。实验结果显示，FLAME 在 Touchdown 数据集上比最先进方法提高了 7.3% 的任务完成率，展示了 Multimodal LLMs 在具身智能领域的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2408.11051v2",
      "published_date": "2024-08-20 17:57:46 UTC",
      "updated_date": "2025-01-21 04:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:55:53.194799"
    },
    {
      "arxiv_id": "2408.11048v2",
      "title": "RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual Dexterous Robot Hands",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhao",
        "Le Chen",
        "Jan Schneider",
        "Quankai Gao",
        "Juho Kannala",
        "Bernhard Schölkopf",
        "Joni Pajarinen",
        "Dieter Büchler"
      ],
      "abstract": "It has been a long-standing research goal to endow robot hands with\nhuman-level dexterity. Bi-manual robot piano playing constitutes a task that\ncombines challenges from dynamic tasks, such as generating fast while precise\nmotions, with slower but contact-rich manipulation problems. Although\nreinforcement learning based approaches have shown promising results in\nsingle-task performance, these methods struggle in a multi-song setting. Our\nwork aims to close this gap and, thereby, enable imitation learning approaches\nfor robot piano playing at scale. To this end, we introduce the Robot Piano 1\nMillion (RP1M) dataset, containing bi-manual robot piano playing motion data of\nmore than one million trajectories. We formulate finger placements as an\noptimal transport problem, thus, enabling automatic annotation of vast amounts\nof unlabeled songs. Benchmarking existing imitation learning approaches shows\nthat such approaches reach state-of-the-art robot piano playing performance by\nleveraging RP1M.",
      "tldr_zh": "该论文引入了RP1M数据集，这是一个大规模运动数据集，包含超过一百万条双臂灵巧机器人手弹钢琴的轨迹，旨在提升机器人手的灵巧性并解决多首歌曲场景下的挑战。研究者将手指放置问题表述为optimal transport problem，从而实现对大量无标签歌曲的自动标注。实验结果表明，现有的imitation learning方法通过利用RP1M数据集，达到了state-of-the-art的机器人弹钢琴性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by Conference on Robot Learning (CoRL) 2024. Project\n  Website: https://rp1m.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2408.11048v2",
      "published_date": "2024-08-20 17:56:52 UTC",
      "updated_date": "2024-11-18 14:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:56:04.671528"
    },
    {
      "arxiv_id": "2408.11043v1",
      "title": "Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research",
      "title_zh": "翻译失败",
      "authors": [
        "Sreyoshi Bhaduri",
        "Satya Kapoor",
        "Alex Gil",
        "Anshul Mittal",
        "Rutu Mulkar"
      ],
      "abstract": "Qualitative data collection and analysis approaches, such as those employing\ninterviews and focus groups, provide rich insights into customer attitudes,\nsentiment, and behavior. However, manually analyzing qualitative data requires\nextensive time and effort to identify relevant topics and thematic insights.\nThis study proposes a novel approach to address this challenge by leveraging\nRetrieval Augmented Generation (RAG) based Large Language Models (LLMs) for\nanalyzing interview transcripts. The novelty of this work lies in strategizing\nthe research inquiry as one that is augmented by an LLM that serves as a novice\nresearch assistant. This research explores the mental model of LLMs to serve as\nnovice qualitative research assistants for researchers in the talent management\nspace. A RAG-based LLM approach is extended to enable topic modeling of\nsemi-structured interview data, showcasing the versatility of these models\nbeyond their traditional use in information retrieval and search. Our findings\ndemonstrate that the LLM-augmented RAG approach can successfully extract topics\nof interest, with significant coverage compared to manually generated topics\nfrom the same dataset. This establishes the viability of employing LLMs as\nnovice qualitative research assistants. Additionally, the study recommends that\nresearchers leveraging such models lean heavily on quality criteria used in\ntraditional qualitative research to ensure rigor and trustworthiness of their\napproach. Finally, the paper presents key recommendations for industry\npractitioners seeking to reconcile the use of LLMs with established qualitative\nresearch paradigms, providing a roadmap for the effective integration of these\npowerful, albeit novice, AI tools in the analysis of qualitative datasets\nwithin talent",
      "tldr_zh": "该研究探讨了如何将大型语言模型（Large Language Models, LLMs）作为新手定性研究助理，应用于人才管理领域的定性数据分析，以解决手动分析访谈和焦点小组数据的耗时问题。研究提出了一种基于检索增强生成（Retrieval Augmented Generation, RAG）的LLMs方法，扩展其用于主题建模（topic modeling），以处理半结构化访谈数据。结果显示，该方法能有效提取相关主题，与手动生成主题相比覆盖率显著提高，证明LLMs作为新手研究助理的可行性。同时，研究建议研究者采用传统定性研究的质量标准确保分析的严谨性，并为行业从业者提供整合LLMs的实用路线图。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to KDD '24 workshop on Talent Management and Computing (TMC\n  2024). 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.11043v1",
      "published_date": "2024-08-20 17:49:51 UTC",
      "updated_date": "2024-08-20 17:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:56:17.722803"
    },
    {
      "arxiv_id": "2408.11042v1",
      "title": "GraphFSA: A Finite State Automaton Framework for Algorithmic Learning on Graphs",
      "title_zh": "GraphFSA：一种用于图上算法学习的有限状态自动机框架",
      "authors": [
        "Florian Grötschla",
        "Joël Mathys",
        "Christoffer Raun",
        "Roger Wattenhofer"
      ],
      "abstract": "Many graph algorithms can be viewed as sets of rules that are iteratively\napplied, with the number of iterations dependent on the size and complexity of\nthe input graph. Existing machine learning architectures often struggle to\nrepresent these algorithmic decisions as discrete state transitions. Therefore,\nwe propose a novel framework: GraphFSA (Graph Finite State Automaton). GraphFSA\nis designed to learn a finite state automaton that runs on each node of a given\ngraph. We test GraphFSA on cellular automata problems, showcasing its abilities\nin a straightforward algorithmic setting. For a comprehensive empirical\nevaluation of our framework, we create a diverse range of synthetic problems.\nAs our main application, we then focus on learning more elaborate graph\nalgorithms. Our findings suggest that GraphFSA exhibits strong generalization\nand extrapolation abilities, presenting an alternative approach to represent\nthese algorithms.",
      "tldr_zh": "这篇论文提出了GraphFSA框架，这是一种基于Finite State Automaton的机制，用于在图上进行算法学习，以处理图算法的迭代规则和离散状态转换问题。GraphFSA在每个图节点的运行有限状态自动机，能够学习并表示复杂的算法决策。研究者通过细胞自动机问题和各种合成问题的测试，证明了该框架具有强大的泛化和外推能力，为图算法学习提供了一种新颖的替代方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11042v1",
      "published_date": "2024-08-20 17:49:47 UTC",
      "updated_date": "2024-08-20 17:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:56:28.873998"
    },
    {
      "arxiv_id": "2408.11039v1",
      "title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chunting Zhou",
        "Lili Yu",
        "Arun Babu",
        "Kushal Tirumala",
        "Michihiro Yasunaga",
        "Leonid Shamis",
        "Jacob Kahn",
        "Xuezhe Ma",
        "Luke Zettlemoyer",
        "Omer Levy"
      ],
      "abstract": "We introduce Transfusion, a recipe for training a multi-modal model over\ndiscrete and continuous data. Transfusion combines the language modeling loss\nfunction (next token prediction) with diffusion to train a single transformer\nover mixed-modality sequences. We pretrain multiple Transfusion models up to 7B\nparameters from scratch on a mixture of text and image data, establishing\nscaling laws with respect to a variety of uni- and cross-modal benchmarks. Our\nexperiments show that Transfusion scales significantly better than quantizing\nimages and training a language model over discrete image tokens. By introducing\nmodality-specific encoding and decoding layers, we can further improve the\nperformance of Transfusion models, and even compress each image to just 16\npatches. We further demonstrate that scaling our Transfusion recipe to 7B\nparameters and 2T multi-modal tokens produces a model that can generate images\nand text on a par with similar scale diffusion models and language models,\nreaping the benefits of both worlds.",
      "tldr_zh": "本研究提出 Transfusion，一种用于训练多模态模型的框架，将语言建模损失（next token prediction）和 diffusion 模型结合，允许单一 transformer 处理混合文本和图像序列。研究者预训练了多达 7B 参数的 Transfusion 模型，使用文本与图像数据混合，并建立了与单模态和跨模态基准相关的缩放定律，结果显示其性能远优于量化图像并训练语言模型的方法。通过引入模态特定的编码和解码层，模型进一步提升了表现，甚至将图像压缩至仅 16 个 patches，最终实现与同规模 diffusion 模型和语言模型相当的图像与文本生成能力。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.11039v1",
      "published_date": "2024-08-20 17:48:20 UTC",
      "updated_date": "2024-08-20 17:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:56:41.886484"
    },
    {
      "arxiv_id": "2408.11879v1",
      "title": "Beyond Labels: Aligning Large Language Models with Human-like Reasoning",
      "title_zh": "超越标签：使大语言模型与人类式推理对齐",
      "authors": [
        "Muhammad Rafsan Kabir",
        "Rafeed Mohammad Sultan",
        "Ihsanul Haque Asif",
        "Jawad Ibn Ahad",
        "Fuad Rahman",
        "Mohammad Ruhul Amin",
        "Nabeel Mohammed",
        "Shafin Rahman"
      ],
      "abstract": "Aligning large language models (LLMs) with a human reasoning approach ensures\nthat LLMs produce morally correct and human-like decisions. Ethical concerns\nare raised because current models are prone to generating false positives and\nproviding malicious responses. To contribute to this issue, we have curated an\nethics dataset named Dataset for Aligning Reasons (DFAR), designed to aid in\naligning language models to generate human-like reasons. The dataset comprises\nstatements with ethical-unethical labels and their corresponding reasons. In\nthis study, we employed a unique and novel fine-tuning approach that utilizes\nethics labels and their corresponding reasons (L+R), in contrast to the\nexisting fine-tuning approach that only uses labels (L). The original\npre-trained versions, the existing fine-tuned versions, and our proposed\nfine-tuned versions of LLMs were then evaluated on an ethical-unethical\nclassification task and a reason-generation task. Our proposed fine-tuning\nstrategy notably outperforms the others in both tasks, achieving significantly\nhigher accuracy scores in the classification task and lower misalignment rates\nin the reason-generation task. The increase in classification accuracies and\ndecrease in misalignment rates indicate that the L+R fine-tuned models align\nmore with human ethics. Hence, this study illustrates that injecting reasons\nhas substantially improved the alignment of LLMs, resulting in more human-like\nresponses. We have made the DFAR dataset and corresponding codes publicly\navailable at https://github.com/apurba-nsu-rnd-lab/DFAR.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 易产生假阳性和恶意响应的伦理问题，提出一种新的对齐策略，以提升模型的人类式推理能力。研究者构建了名为 Dataset for Aligning Reasons (DFAR) 的数据集，包含伦理-不伦理标签及其对应理由，并采用标签加理由 (L+R) 的微调方法，而非传统仅使用标签 (L) 的方式。实验结果显示，L+R 微调模型在伦理-不伦理分类任务中准确率显著提高，在理由生成任务中失调率降低，表明这种方法使 LLMs 更符合人类伦理并产生更像人类的响应。该数据集和代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11879v1",
      "published_date": "2024-08-20 17:44:51 UTC",
      "updated_date": "2024-08-20 17:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:56:53.473769"
    },
    {
      "arxiv_id": "2408.11029v2",
      "title": "Scaling Law with Learning Rate Annealing",
      "title_zh": "缩放定律与学习率退火",
      "authors": [
        "Howe Tissue",
        "Venus Wang",
        "Lu Wang"
      ],
      "abstract": "We find that the cross-entropy loss curves of neural language models\nempirically adhere to a scaling law with learning rate (LR) annealing over\ntraining steps: $$L(s) = L_0 + A\\cdot S_1^{-\\alpha} - C\\cdot S_2,$$ where\n$L(s)$ is the validation loss at step $s$, $S_1$ is the area under the LR\ncurve, $S_2$ is the LR annealing area, and $L_0$, $A$, $C$, $\\alpha$ are\nconstant parameters. This formulation takes into account two factors: (1)\npower-law scaling over data size, and (2) the additional loss reduction during\nLR annealing. Therefore, this formulation can describe the full loss curve at\neach step, rather than the single loss point at the end of training. Applying\nthe scaling law with LR annealing and fitting only one or two training curves,\nwe can accurately predict the loss at any given step across any learning rate\nscheduler (LRS). This approach significantly reduces computational cost in\nformulating scaling laws while providing more accuracy and expressiveness for\ntraining dynamics. Extensive experiments demonstrate that our findings hold\nacross a range of hyper-parameters and model architectures, and our equation\ncan extend to scaling effect of model sizes. Moreover, our formulation provides\naccurate theoretical verification and explanation for empirical results\nobserved in numerous previous studies, particularly those focusing on LR\nschedule and annealing. We believe that this work is promising to enhance the\nunderstanding of LLM training dynamics while greatly democratizing scaling\nlaws, and it can guide researchers in refining training strategies (e.g.\ncritical LRS) for further LLMs.",
      "tldr_zh": "本研究发现，神经语言模型的交叉熵损失曲线遵循一个新的缩放定律公式：\\( L(s) = L_0 + A \\cdot S_1^{-\\alpha} - C \\cdot S_2 \\)，其中考虑了学习率 (LR) 退火的影响，包括数据规模的幂律缩放和额外损失减少。  \n该公式能精确预测训练过程中的任意步骤损失，而非仅限于训练结束点，通过拟合一两个训练曲线即可适用于各种 LR 调度器 (LRS)，显著降低计算成本。  \n实验验证显示，该定律在不同超参数、模型架构和模型规模中均有效，并为先前关于 LR 调度和退火的研究提供理论解释，有助于优化大型语言模型 (LLMs) 的训练策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Add more experiments to consolidate our scaling laws. 29 pages, 29\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11029v2",
      "published_date": "2024-08-20 17:30:48 UTC",
      "updated_date": "2024-10-24 17:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:57:05.388947"
    },
    {
      "arxiv_id": "2408.11021v1",
      "title": "Athena: Safe Autonomous Agents with Verbal Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmana Sadhu",
        "Ali Pesaranghader",
        "Yanan Chen",
        "Dong Hoon Yi"
      ],
      "abstract": "Due to emergent capabilities, large language models (LLMs) have been utilized\nas language-based agents to perform a variety of tasks and make decisions with\nan increasing degree of autonomy. These autonomous agents can understand\nhigh-level instructions, interact with their environments, and execute complex\ntasks using a selection of tools available to them. As the capabilities of the\nagents expand, ensuring their safety and trustworthiness becomes more\nimperative. In this study, we introduce the Athena framework which leverages\nthe concept of verbal contrastive learning where past safe and unsafe\ntrajectories are used as in-context (contrastive) examples to guide the agent\ntowards safety while fulfilling a given task. The framework also incorporates a\ncritiquing mechanism to guide the agent to prevent risky actions at every step.\nFurthermore, due to the lack of existing benchmarks on the safety reasoning\nability of LLM-based agents, we curate a set of 80 toolkits across 8 categories\nwith 180 scenarios to provide a safety evaluation benchmark. Our experimental\nevaluation, with both closed- and open-source LLMs, indicates verbal\ncontrastive learning and interaction-level critiquing improve the safety rate\nsignificantly.",
      "tldr_zh": "这篇论文介绍了 Athena 框架，利用 verbal contrastive learning 来提升大型语言模型 (LLMs) 基于代理的安全性和可信度。框架通过将过去的 safe 和 unsafe 轨迹作为 in-context examples 进行引导，并结合 interaction-level critiquing 机制，帮助代理在执行任务时避免风险动作。同时，作者创建了包含 80 个工具包和 180 个场景的安全评估基准，实验结果显示，该方法在闭源和开源 LLMs 上显著提高了安全率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.11021v1",
      "published_date": "2024-08-20 17:21:10 UTC",
      "updated_date": "2024-08-20 17:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:57:17.008422"
    },
    {
      "arxiv_id": "2408.11019v1",
      "title": "An Overlooked Role of Context-Sensitive Dendrites",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsin Raza",
        "Ahsan Adeel"
      ],
      "abstract": "To date, most dendritic studies have predominantly focused on the apical zone\nof pyramidal two-point neurons (TPNs) receiving only feedback (FB) connections\nfrom higher perceptual layers and using them for learning. Recent cellular\nneurophysiology and computational neuroscience studies suggests that the apical\ninput (context), coming from feedback and lateral connections, is multifaceted\nand far more diverse, with greater implications for ongoing learning and\nprocessing in the brain than previously realized. In addition to the FB, the\napical tuft receives signals from neighboring cells of the same network as\nproximal (P) context, other parts of the brain as distal (D) context, and\noverall coherent information across the network as universal (U) context. The\nintegrated context (C) amplifies and suppresses the transmission of coherent\nand conflicting feedforward (FF) signals, respectively. Specifically, we show\nthat complex context-sensitive (CS)-TPNs flexibly integrate C moment-by-moment\nwith the FF somatic current at the soma such that the somatic current is\namplified when both feedforward (FF) and C are coherent; otherwise, it is\nattenuated. This generates the event only when the FF and C currents are\ncoherent, which is then translated into a singlet or a burst based on the FB\ninformation. Spiking simulation results show that this flexible integration of\nsomatic and contextual currents enables the propagation of more coherent\nsignals (bursts), making learning faster with fewer neurons. Similar behavior\nis observed when this functioning is used in conventional artificial networks,\nwhere orders of magnitude fewer neurons are required to process vast amounts of\nheterogeneous real-world audio-visual (AV) data trained using backpropagation\n(BP). The computational findings presented here demonstrate the universality of\nCS-TPNs, suggesting a dendritic narrative that was previously overlooked.",
      "tldr_zh": "该研究揭示了树突在神经元处理中的被忽略角色，特别关注上下文敏感的锥体神经元（CS-TPNs），强调顶端输入不仅仅是反馈（FB）连接，还包括近端（P）、远端（D）和通用（U）上下文。CS-TPNs 通过灵活整合上下文（C）与前馈（FF）信号，仅在两者一致时放大信号，否则抑制，从而生成爆发或单次脉冲，促进更有效的信号传播。模拟结果显示，这种机制能加速学习过程，并显著减少神经元数量，例如在处理音频-视觉（AV）数据的 artificial networks 中，仅需更少的神经元即可实现高效训练，突显了 CS-TPNs 的普遍性和重要性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11019v1",
      "published_date": "2024-08-20 17:18:54 UTC",
      "updated_date": "2024-08-20 17:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:57:29.280070"
    },
    {
      "arxiv_id": "2408.11017v1",
      "title": "Multiwinner Temporal Voting with Aversion to Change",
      "title_zh": "翻译失败",
      "authors": [
        "Valentin Zech",
        "Niclas Boehmer",
        "Edith Elkind",
        "Nicholas Teh"
      ],
      "abstract": "We study two-stage committee elections where voters have dynamic preferences\nover candidates; at each stage, a committee is chosen under a given voting\nrule. We are interested in identifying a winning committee for the second stage\nthat overlaps as much as possible with the first-stage committee. We show a\nfull complexity dichotomy for the class of Thiele rules: this problem is\ntractable for Approval Voting (AV) and hard for all other Thiele rules\n(including, in particular, Proportional Approval Voting and the\nChamberlin-Courant rule). We extend this dichotomy to the greedy variants of\nThiele rules. We also explore this problem from a parameterized complexity\nperspective for several natural parameters. We complement the theory with\nexperimental analysis: e.g., we investigate the average number of changes in\nthe committee as a function of changes in voters' preferences and the role of\nties.",
      "tldr_zh": "本研究探讨了多获胜者投票（Multiwinner Voting）中的两阶段委员会选举问题，选民偏好动态变化，且目标是使第二阶段的获胜委员会与第一阶段委员会重叠最大化，以体现对变化的厌恶（Aversion to Change）。对于 Thiele rules 类规则，该问题在 Approval Voting (AV) 下是易处理的，而在其他规则（如 Proportional Approval Voting 和 Chamberlin-Courant rule）下则是 NP-hard。研究扩展了这一复杂度二分法（complexity dichotomy）到 Thiele rules 的贪婪变体，并从参数化复杂性（parameterized complexity）角度分析了几个自然参数。实验分析进一步验证了理论结果，包括考察选民偏好变化对委员会平均变化数量的影响以及平局的作用。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.GT",
      "comment": "Appears in the 27th European Conference on Artificial Intelligence\n  (ECAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11017v1",
      "published_date": "2024-08-20 17:16:54 UTC",
      "updated_date": "2024-08-20 17:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:57:42.309968"
    },
    {
      "arxiv_id": "2409.00054v1",
      "title": "Automating Knowledge Discovery from Scientific Literature via LLMs: A Dual-Agent Approach with Progressive Ontology Prompting",
      "title_zh": "通过 LLMs 自动发现科学文献中的知识",
      "authors": [
        "Yuting Hu",
        "Dancheng Liu",
        "Qingyun Wang",
        "Charles Yu",
        "Heng Ji",
        "Jinjun Xiong"
      ],
      "abstract": "To address the challenge of automating knowledge discovery from a vast volume\nof literature, in this paper, we introduce a novel framework based on large\nlanguage models (LLMs) that combines a progressive ontology prompting (POP)\nalgorithm with a dual-agent system, named LLM-Duo, designed to enhance the\nautomation of knowledge extraction from scientific articles. The POP algorithm\nutilizes a prioritized breadth-first search (BFS) across a predefined ontology\nto generate structured prompt templates and action orders, thereby guiding LLMs\nto discover knowledge in an automatic manner. Additionally, our LLM-Duo employs\ntwo specialized LLM agents: an explorer and an evaluator. These two agents work\ncollaboratively and adversarially to enhance the reliability of the discovery\nand annotation processes. Experiments demonstrate that our method outperforms\nadvanced baselines, enabling more accurate and complete annotations. To\nvalidate the effectiveness of our method in real-world scenarios, we employ our\nmethod in a case study of speech-language intervention discovery. Our method\nidentifies 2,421 interventions from 64,177 research articles in the\nspeech-language therapy domain. We curate these findings into a publicly\naccessible intervention knowledge base that holds significant potential to\nbenefit the speech-language therapy community.",
      "tldr_zh": "本研究提出了一种名为 LLM-Duo 的新型框架，利用大型语言模型 (LLMs) 结合 Progressive Ontology Prompting (POP) 算法和双智能体系统，自动化从海量科学文献中发现知识。POP 算法通过优先级广度优先搜索 (BFS) 在预定义本体上生成结构化提示模板和行动顺序，并由一个探索者 (explorer) 和一个评估者 (evaluator) 智能体协作与对抗，以提升知识提取的准确性和可靠性。实验结果显示，该方法优于先进基线模型，并在语音语言干预的真实案例中，从 64,177 篇研究论文中识别出 2,421 个干预，并构建了一个公开可访问的干预知识库，为相关领域社区带来潜在益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "in submission",
      "pdf_url": "http://arxiv.org/pdf/2409.00054v1",
      "published_date": "2024-08-20 16:42:23 UTC",
      "updated_date": "2024-08-20 16:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:57:56.009632"
    },
    {
      "arxiv_id": "2408.10987v1",
      "title": "Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models",
      "title_zh": "使用扩散概率模型对平面波超声图像进行去噪",
      "authors": [
        "Hojat Asgariandehkordi",
        "Sobhan Goudarzi",
        "Mostafa Sharifzadeh",
        "Adrian Basarab",
        "Hassan Rivaz"
      ],
      "abstract": "Ultrasound plane wave imaging is a cutting-edge technique that enables high\nframe-rate imaging. However, one challenge associated with high frame-rate\nultrasound imaging is the high noise associated with them, hindering their\nwider adoption. Therefore, the development of a denoising method becomes\nimperative to augment the quality of plane wave images. Drawing inspiration\nfrom Denoising Diffusion Probabilistic Models (DDPMs), our proposed solution\naims to enhance plane wave image quality. Specifically, the method considers\nthe distinction between low-angle and high-angle compounding plane waves as\nnoise and effectively eliminates it by adapting a DDPM to beamformed\nradiofrequency (RF) data. The method underwent training using only 400\nsimulated images. In addition, our approach employs natural image segmentation\nmasks as intensity maps for the generated images, resulting in accurate\ndenoising for various anatomy shapes. The proposed method was assessed across\nsimulation, phantom, and in vivo images. The results of the evaluations\nindicate that our approach not only enhances image quality on simulated data\nbut also demonstrates effectiveness on phantom and in vivo data in terms of\nimage quality. Comparative analysis with other methods underscores the\nsuperiority of our proposed method across various evaluation metrics. The\nsource code and trained model will be released along with the dataset at:\nhttp://code.sonography.ai",
      "tldr_zh": "本研究针对超声平面波成像的高帧率优势及其伴随的高噪声问题，提出了一种基于Denoising Diffusion Probabilistic Models (DDPMs)的去噪方法。该方法将低角度和高角度复合平面波的差异视为噪声，并通过适应beamformed radiofrequency (RF)数据，仅使用400张模拟图像进行训练，同时利用自然图像分割掩码作为强度图，以实现对各种解剖形状的精确去噪。实验结果显示，该方法在模拟、幻影和体内图像上显著提升了图像质量，并在多种评估指标中优于其他方法，为高帧率超声成像的实际应用提供了可靠的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10987v1",
      "published_date": "2024-08-20 16:31:31 UTC",
      "updated_date": "2024-08-20 16:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:58:07.174093"
    },
    {
      "arxiv_id": "2408.10970v1",
      "title": "Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control",
      "title_zh": "混合循环模型支持层次化规划和控制的涌现描述",
      "authors": [
        "Poppy Collis",
        "Ryan Singh",
        "Paul F Kinghorn",
        "Christopher L Buckley"
      ],
      "abstract": "An open problem in artificial intelligence is how systems can flexibly learn\ndiscrete abstractions that are useful for solving inherently continuous\nproblems. Previous work has demonstrated that a class of hybrid state-space\nmodel known as recurrent switching linear dynamical systems (rSLDS) discover\nmeaningful behavioural units via the piecewise linear decomposition of complex\ncontinuous dynamics (Linderman et al., 2016). Furthermore, they model how the\nunderlying continuous states drive these discrete mode switches. We propose\nthat the rich representations formed by an rSLDS can provide useful\nabstractions for planning and control. We present a novel hierarchical\nmodel-based algorithm inspired by Active Inference in which a discrete MDP sits\nabove a low-level linear-quadratic controller. The recurrent transition\ndynamics learned by the rSLDS allow us to (1) specify temporally-abstracted\nsub-goals in a method reminiscent of the options framework, (2) lift the\nexploration into discrete space allowing us to exploit information-theoretic\nexploration bonuses and (3) `cache' the approximate solutions to low-level\nproblems in the discrete planner. We successfully apply our model to the sparse\nContinuous Mountain Car task, demonstrating fast system identification via\nenhanced exploration and non-trivial planning through the delineation of\nabstract sub-goals.",
      "tldr_zh": "本文研究了人工智能中系统如何学习有用的离散抽象来解决连续问题，提出使用 recurrent switching linear dynamical systems (rSLDS) 来发现有意义的行为单位并建模连续状态驱动的模式切换。作者开发了一个基于 Active Inference 的分层模型算法，将离散 Markov Decision Process (MDP) 与低层线性-二次控制器结合，实现了时间抽象子目标的指定、信息理论探索奖励的提升，以及低层问题解决方案的缓存。实验在稀疏 Continuous Mountain Car 任务上证明了该方法能加速系统识别、增强探索，并通过抽象子目标实现有效的层次规划和控制。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10970v1",
      "published_date": "2024-08-20 16:02:54 UTC",
      "updated_date": "2024-08-20 16:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:58:19.636609"
    },
    {
      "arxiv_id": "2408.10951v1",
      "title": "Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Dona Arabi",
        "Jafar Bakhshaliyev",
        "Ayse Coskuner",
        "Kiran Madhusudhanan",
        "Kami Serdar Uckardes"
      ],
      "abstract": "Data augmentation is important for improving machine learning model\nperformance when faced with limited real-world data. In time series forecasting\n(TSF), where accurate predictions are crucial in fields like finance,\nhealthcare, and manufacturing, traditional augmentation methods for\nclassification tasks are insufficient to maintain temporal coherence. This\nresearch introduces two augmentation approaches using the discrete wavelet\ntransform (DWT) to adjust frequency elements while preserving temporal\ndependencies in time series data. Our methods, Wavelet Masking (WaveMask) and\nWavelet Mixing (WaveMix), are evaluated against established baselines across\nvarious forecasting horizons. To the best of our knowledge, this is the first\nstudy to conduct extensive experiments on multivariate time series using\nDiscrete Wavelet Transform as an augmentation technique. Experimental results\ndemonstrate that our techniques achieve competitive results with previous\nmethods. We also explore cold-start forecasting using downsampled training\ndatasets, comparing outcomes to baseline methods.",
      "tldr_zh": "本研究探讨了数据增强在时间序列预测（TSF）中的应用，强调传统方法难以维持时序一致性的问题。作者引入了两种基于离散小波变换（DWT）的增强技术：Wavelet Masking (WaveMask) 和 Wavelet Mixing (WaveMix)，这些方法通过调整频率元素来保留时间序列的时序依赖性，并在多变量数据集上进行了广泛实验。结果显示，该技术与基线方法相比取得了竞争性性能，并在冷启动预测（使用下采样训练数据集）场景中表现出色，这是首次对DWT作为TSF增强技术的全面评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10951v1",
      "published_date": "2024-08-20 15:42:10 UTC",
      "updated_date": "2024-08-20 15:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:58:30.510083"
    },
    {
      "arxiv_id": "2408.10948v1",
      "title": "GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization",
      "title_zh": "GAIM：通过对抗影响最大化攻击图神经网络",
      "authors": [
        "Xiaodong Yang",
        "Xiaoting Li",
        "Huiyuan Chen",
        "Yiwei Cai"
      ],
      "abstract": "Recent studies show that well-devised perturbations on graph structures or\nnode features can mislead trained Graph Neural Network (GNN) models. However,\nthese methods often overlook practical assumptions, over-rely on heuristics, or\nseparate vital attack components. In response, we present GAIM, an integrated\nadversarial attack method conducted on a node feature basis while considering\nthe strict black-box setting. Specifically, we define an adversarial influence\nfunction to theoretically assess the adversarial impact of node perturbations,\nthereby reframing the GNN attack problem into the adversarial influence\nmaximization problem. In our approach, we unify the selection of the target\nnode and the construction of feature perturbations into a single optimization\nproblem, ensuring a unique and consistent feature perturbation for each target\nnode. We leverage a surrogate model to transform this problem into a solvable\nlinear programming task, streamlining the optimization process. Moreover, we\nextend our method to accommodate label-oriented attacks, broadening its\napplicability. Thorough evaluations on five benchmark datasets across three\npopular models underscore the effectiveness of our method in both untargeted\nand label-oriented targeted attacks. Through comprehensive analysis and\nablation studies, we demonstrate the practical value and efficacy inherent to\nour design choices.",
      "tldr_zh": "该论文提出了 GAIM，一种针对 Graph Neural Networks (GNN) 的集成式对抗攻击方法，通过 Adversarial Influence Maximization 来评估和最大化节点特征扰动的影响，解决了现有方法忽略实际假设和过度依赖启发式的缺陷。GAIM 将目标节点选择和特征扰动构建统一为一个优化问题，并在黑-box 设置下使用代理模型（surrogate model）转化为线性规划任务，以确保扰动的一致性和高效性。该方法扩展了针对标签导向攻击的适用性，并在五个基准数据集上对三种流行模型的评估中，展示了在无针对性和针对性攻击中的显著有效性。通过全面分析和消融研究，证明了 GAIM 的设计选择在实际场景中的实用价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10948v1",
      "published_date": "2024-08-20 15:41:20 UTC",
      "updated_date": "2024-08-20 15:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:58:43.246839"
    },
    {
      "arxiv_id": "2408.10947v1",
      "title": "Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyan Chen",
        "Chenwei Wu",
        "Songzhou Yan",
        "Panjun Liu",
        "Haoyu Zhou",
        "Yanghua Xiao"
      ],
      "abstract": "Teachers are important to imparting knowledge and guiding learners, and the\nrole of large language models (LLMs) as potential educators is emerging as an\nimportant area of study. Recognizing LLMs' capability to generate educational\ncontent can lead to advances in automated and personalized learning. While LLMs\nhave been tested for their comprehension and problem-solving skills, their\ncapability in teaching remains largely unexplored. In teaching, questioning is\na key skill that guides students to analyze, evaluate, and synthesize core\nconcepts and principles. Therefore, our research introduces a benchmark to\nevaluate the questioning capability in education as a teacher of LLMs through\nevaluating their generated educational questions, utilizing Anderson and\nKrathwohl's taxonomy across general, monodisciplinary, and interdisciplinary\ndomains. We shift the focus from LLMs as learners to LLMs as educators,\nassessing their teaching capability through guiding them to generate questions.\nWe apply four metrics, including relevance, coverage, representativeness, and\nconsistency, to evaluate the educational quality of LLMs' outputs. Our results\nindicate that GPT-4 demonstrates significant potential in teaching general,\nhumanities, and science courses; Claude2 appears more apt as an\ninterdisciplinary teacher. Furthermore, the automatic scores align with human\nperspectives.",
      "tldr_zh": "该研究引入了Dr.Academy基准，用于评估大型语言模型(LLMs)作为教育者的提问能力，聚焦于生成教育问题以引导学生分析、评估和综合核心概念。方法基于Anderson and Krathwohl's taxonomy，涵盖一般、单学科和跨学科领域，并使用relevance、coverage、representativeness和consistency四个指标评估LLMs的输出质量。结果显示，GPT-4在一般、人文和科学课程中表现出色，而Claude2更适合跨学科教学，且自动评分与人类评价高度一致。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10947v1",
      "published_date": "2024-08-20 15:36:30 UTC",
      "updated_date": "2024-08-20 15:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:03.551491"
    },
    {
      "arxiv_id": "2408.10946v1",
      "title": "Large Language Model Driven Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Korikov",
        "Scott Sanner",
        "Yashar Deldjoo",
        "Zhankui He",
        "Julian McAuley",
        "Arnau Ramisa",
        "Rene Vidal",
        "Mahesh Sathiamoorthy",
        "Atoosa Kasrizadeh",
        "Silvia Milano",
        "Francesco Ricci"
      ],
      "abstract": "While previous chapters focused on recommendation systems (RSs) based on\nstandardized, non-verbal user feedback such as purchases, views, and clicks --\nthe advent of LLMs has unlocked the use of natural language (NL) interactions\nfor recommendation. This chapter discusses how LLMs' abilities for general NL\nreasoning present novel opportunities to build highly personalized RSs -- which\ncan effectively connect nuanced and diverse user preferences to items,\npotentially via interactive dialogues. To begin this discussion, we first\npresent a taxonomy of the key data sources for language-driven recommendation,\ncovering item descriptions, user-system interactions, and user profiles. We\nthen proceed to fundamental techniques for LLM recommendation, reviewing the\nuse of encoder-only and autoregressive LLM recommendation in both tuned and\nuntuned settings. Afterwards, we move to multi-module recommendation\narchitectures in which LLMs interact with components such as retrievers and RSs\nin multi-stage pipelines. This brings us to architectures for conversational\nrecommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where\neach turn presents an opportunity not only to make recommendations, but also to\nengage with the user in interactive preference elicitation, critiquing, and\nquestion-answering.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLMs) 如何驱动推荐系统 (RSs)，通过自然语言 (NL) 交互来处理用户偏好，实现高度个性化的推荐。作者首先提出一个分类框架，涵盖关键数据来源，包括物品描述、用户-系统交互和用户配置文件；随后审视了LLMs在推荐中的基本技术，如编码器-only和自回归模型在微调与非微调设置下的应用。论文进一步讨论了多模块架构，其中LLMs与检索器和RSs交互，并扩展到对话式推荐系统 (CRSs)，支持多轮对话以进行推荐、偏好收集、批评和问答，从而提升推荐系统的交互性和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10946v1",
      "published_date": "2024-08-20 15:36:24 UTC",
      "updated_date": "2024-08-20 15:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:06.713750"
    },
    {
      "arxiv_id": "2408.10945v3",
      "title": "HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kazi Hasan Ibn Arif",
        "JinYi Yoon",
        "Dimitrios S. Nikolopoulos",
        "Hans Vandierendonck",
        "Deepu John",
        "Bo Ji"
      ],
      "abstract": "High-resolution Vision-Language Models (VLMs) are widely used in multimodal\ntasks to enhance accuracy by preserving detailed image information. However,\nthese models often generate an excessive number of visual tokens due to the\nneed to encode multiple partitions of a high-resolution image input. Processing\nsuch a large number of visual tokens through multiple transformer networks\nposes significant computational challenges, particularly for\nresource-constrained commodity GPUs. To address this challenge, we propose\nHigh-Resolution Early Dropping (HiRED), a plug-and-play token-dropping method\ndesigned to operate within a fixed token budget. HiRED leverages the attention\nof CLS token in the vision transformer (ViT) to assess the visual content of\nthe image partitions and allocate an optimal token budget for each partition\naccordingly. The most informative visual tokens from each partition within the\nallocated budget are then selected and passed to the subsequent Large Language\nModel (LLM). We showed that HiRED achieves superior accuracy and performance,\ncompared to existing token-dropping methods. Empirically, HiRED-20% (i.e., a\n20% token budget) on LLaVA-Next-7B achieves a 4.7x increase in token generation\nthroughput, reduces response latency by 78%, and saves 14% of GPU memory for\nsingle inference on an NVIDIA TESLA P40 (24 GB). For larger batch sizes (e.g.,\n4), HiRED-20% prevents out-of-memory errors by cutting memory usage by 30%,\nwhile preserving throughput and latency benefits.\n  Code - https://github.com/hasanar1f/HiRED",
      "tldr_zh": "该研究针对高分辨率视觉语言模型（VLMs）在处理大量视觉标记时面临的计算挑战，提出了一种即插即用的标记丢弃方法 HiRED，以在固定标记预算下提升推理效率。HiRED 通过利用视觉变压器（ViT）中的 CLS 标记注意力评估图像分区的内容，为每个分区分配最佳标记预算，并选择最信息丰富的标记传递给后续的大型语言模型（LLM）。实验结果显示，HiRED-20% 在 LLaVA-Next-7B 上实现了 4.7 倍的标记生成吞吐量、78% 的响应延迟减少和 14% 的 GPU 内存节省；对于更大批量（如 4），它还降低了 30% 的内存使用，防止了内存溢出错误，同时保持了准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10945v3",
      "published_date": "2024-08-20 15:34:27 UTC",
      "updated_date": "2024-12-25 01:27:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:19.981694"
    },
    {
      "arxiv_id": "2408.10940v1",
      "title": "A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Vladislav Li",
        "Georgios Tsoumplekas",
        "Ilias Siniosoglou",
        "Vasileios Argyriou",
        "Anastasios Lytos",
        "Eleftherios Fountoukidis",
        "Panagiotis Sarigiannidis"
      ],
      "abstract": "Current methods for low- and few-shot object detection have primarily focused\non enhancing model performance for detecting objects. One common approach to\nachieve this is by combining model finetuning with data augmentation\nstrategies. However, little attention has been given to the energy efficiency\nof these approaches in data-scarce regimes. This paper seeks to conduct a\ncomprehensive empirical study that examines both model performance and energy\nefficiency of custom data augmentations and automated data augmentation\nselection strategies when combined with a lightweight object detector. The\nmethods are evaluated in three different benchmark datasets in terms of their\nperformance and energy consumption, and the Efficiency Factor is employed to\ngain insights into their effectiveness considering both performance and\nefficiency. Consequently, it is shown that in many cases, the performance gains\nof data augmentation strategies are overshadowed by their increased energy\nusage, necessitating the development of more energy efficient data augmentation\nstrategies to address data scarcity.",
      "tldr_zh": "这篇论文对基于微调(finetuning)的低/少样本物体检测(low/few-shot object detection)中的数据增强(data augmentation)策略进行了深入分析，重点考察其性能提升与能效之间的权衡。研究通过在三个基准数据集上评估自定义数据增强和自动数据增强选择策略与轻量级物体检测器的结合，使用 Efficiency Factor 来量化性能和能源消耗的平衡。结果显示，许多策略虽然提高了模型表现，但其能源效率下降问题突出，因此论文呼吁开发更节能的数据增强方法，以更好地应对数据稀缺场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10940v1",
      "published_date": "2024-08-20 15:29:56 UTC",
      "updated_date": "2024-08-20 15:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:30.971258"
    },
    {
      "arxiv_id": "2408.10934v1",
      "title": "SDI-Net: Toward Sufficient Dual-View Interaction for Low-light Stereo Image Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Linlin Hu",
        "Ao Sun",
        "Shijie Hao",
        "Richang Hong",
        "Meng Wang"
      ],
      "abstract": "Currently, most low-light image enhancement methods only consider information\nfrom a single view, neglecting the correlation between cross-view information.\nTherefore, the enhancement results produced by these methods are often\nunsatisfactory. In this context, there have been efforts to develop methods\nspecifically for low-light stereo image enhancement. These methods take into\naccount the cross-view disparities and enable interaction between the left and\nright views, leading to improved performance. However, these methods still do\nnot fully exploit the interaction between left and right view information. To\naddress this issue, we propose a model called Toward Sufficient Dual-View\nInteraction for Low-light Stereo Image Enhancement (SDI-Net). The backbone\nstructure of SDI-Net is two encoder-decoder pairs, which are used to learn the\nmapping function from low-light images to normal-light images. Among the\nencoders and the decoders, we design a module named Cross-View Sufficient\nInteraction Module (CSIM), aiming to fully exploit the correlations between the\nbinocular views via the attention mechanism. The quantitative and visual\nresults on public datasets validate the superiority of our method over other\nrelated methods. Ablation studies also demonstrate the effectiveness of the key\nelements in our model.",
      "tldr_zh": "该论文指出，现有的低光图像增强方法仅考虑单一视图信息，忽略了跨视图的相关性，导致效果不理想，而现有的低光立体图像增强方法虽有交互但未充分利用。针对此问题，研究提出 SDI-Net 模型，该模型采用两个编码器-解码器对来学习低光图像到正常光图像的映射函数，并设计 Cross-View Sufficient Interaction Module (CSIM) 通过注意力机制充分挖掘双眼视图的相关性。实验结果显示，SDI-Net 在公共数据集上优于其他相关方法，且消融实验验证了关键组件的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10934v1",
      "published_date": "2024-08-20 15:17:11 UTC",
      "updated_date": "2024-08-20 15:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:44.189571"
    },
    {
      "arxiv_id": "2408.10932v3",
      "title": "The Evolution of Reinforcement Learning in Quantitative Finance: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolaos Pippas",
        "Elliot A. Ludvig",
        "Cagatay Turkay"
      ],
      "abstract": "Reinforcement Learning (RL) has experienced significant advancement over the\npast decade, prompting a growing interest in applications within finance. This\nsurvey critically evaluates 167 publications, exploring diverse RL applications\nand frameworks in finance. Financial markets, marked by their complexity,\nmulti-agent nature, information asymmetry, and inherent randomness, serve as an\nintriguing test-bed for RL. Traditional finance offers certain solutions, and\nRL advances these with a more dynamic approach, incorporating machine learning\nmethods, including transfer learning, meta-learning, and multi-agent solutions.\nThis survey dissects key RL components through the lens of Quantitative\nFinance. We uncover emerging themes, propose areas for future research, and\ncritique the strengths and weaknesses of existing methods.",
      "tldr_zh": "这篇调查论文审视了强化学习(Reinforcement Learning) 在量化金融(Quantitative Finance) 领域的演变，评估了167篇相关出版物，并探讨了RL在复杂金融市场的各种应用和框架。论文强调RL通过动态方法（如transfer learning、meta-learning和multi-agent solutions）提升了传统金融解决方案，特别是在处理信息不对称和随机性方面。最终，它揭示了新兴主题，提出了未来研究方向，并批判了现有方法的优势与不足，为RL在金融领域的应用提供了全面见解。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "I.2.6; I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "This work is accepted by ACM Computing Surveys on 18 April 2025 and\n  an early access version is already available here:\n  https://dl.acm.org/doi/10.1145/3733714. The arXiv copy (and the ACM CSUR\n  early-access version) is an unedited, pre-print version and it is the\n  author's version of the work",
      "pdf_url": "http://arxiv.org/pdf/2408.10932v3",
      "published_date": "2024-08-20 15:15:10 UTC",
      "updated_date": "2025-05-06 12:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T16:59:56.572618"
    },
    {
      "arxiv_id": "2408.10923v3",
      "title": "LBC: Language-Based-Classifier for Out-Of-Variable Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Kangjun Noh",
        "Baekryun Seong",
        "Hoyoon Byun",
        "Youngjun Choi",
        "Sungjin Song",
        "Kyungwoo Song"
      ],
      "abstract": "Large Language Models (LLMs) have great success in natural language\nprocessing tasks such as response generation. However, their use in tabular\ndata has been limited due to their inferior performance compared to traditional\nmachine learning models (TMLs) such as XGBoost. We find that the pre-trained\nknowledge of LLMs enables them to interpret new variables that appear in a test\nwithout additional training, a capability central to the concept of\nOut-of-Variable (OOV). From the findings, we propose a\nLanguage-Based-Classifier (LBC), a classifier that maximizes the benefits of\nLLMs to outperform TMLs on OOV tasks. LBC employs three key methodological\nstrategies: 1) Categorical changes to adjust data to better fit the model's\nunderstanding, 2) Advanced order and indicator to enhance data representation\nto the model, and 3) Using verbalizer to map logit scores to classes during\ninference to generate model predictions. These strategies, combined with the\npre-trained knowledge of LBC, emphasize the model's ability to effectively\nhandle OOV tasks. We empirically and theoretically validate the superiority of\nLBC. LBC is the first study to apply an LLM-based model to OOV tasks. The\nsource code is at https://github.com/sksmssh/LBCforOOVGen",
      "tldr_zh": "该研究发现，大型语言模型 (LLMs) 在处理表格数据时不如传统机器学习模型 (TMLs) 如 XGBoost 表现良好，但 LLMs 具有解释新变量的能力，这对 Out-of-Variable (OOV) 任务至关重要。为此，论文提出 Language-Based-Classifier (LBC)，一种基于 LLMs 的分类器，旨在通过三个关键策略提升性能：Categorical changes 调整数据、Advanced order and indicator 增强数据表示，以及 Verbalizer 映射 logit 得分到类别。实验和理论验证显示，LBC 在 OOV 任务上优于 TMLs，这是首个将 LLM 应用于此类任务的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10923v3",
      "published_date": "2024-08-20 15:05:02 UTC",
      "updated_date": "2024-08-24 03:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:00:10.138924"
    },
    {
      "arxiv_id": "2408.10921v1",
      "title": "MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous questions",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Liu",
        "Ke Jin"
      ],
      "abstract": "With the emergence of more and more economy-specific LLMS, how to measure\nwhether they can be safely invested in production becomes a problem. Previous\nresearch has primarily focused on evaluating the performance of LLMs within\nspecific application scenarios. However, these benchmarks cannot reflect the\ntheoretical level and generalization ability, and the backward datasets are\nincreasingly unsuitable for problems in real scenarios. In this paper, we have\ncompiled a new benchmark, MTFinEval, focusing on the LLMs' basic knowledge of\neconomics, which can always be used as a basis for judgment. To examine only\ntheoretical knowledge as much as possible, MTFinEval is build with foundational\nquestions from university textbooks,and exam papers in economics and management\nmajor. Aware of the overall performance of LLMs do not depend solely on one\nsubdiscipline of economics, MTFinEval comprise 360 questions refined from six\nmajor disciplines of economics, and reflect capabilities more comprehensively.\nExperiment result shows all LLMs perform poorly on MTFinEval, which proves that\nour benchmark built on basic knowledge is very successful. Our research not\nonly offers guidance for selecting the appropriate LLM for specific use cases,\nbut also put forward increase the rigor reliability of LLMs from the basics.",
      "tldr_zh": "本研究引入了 MTFinEval，这是一个多领域中文金融基准，旨在评估大型语言模型 (LLMs) 在经济基础知识方面的表现，以弥补现有基准在理论水平和泛化能力上的不足。MTFinEval 基于大学教科书和考试论文提炼了 360 个问题，涵盖经济学和管理学六个主要学科，从而更全面地反映模型的能力。实验结果显示，所有测试的 LLMs 在此基准上表现不佳，证明了其在评估基础知识方面的有效性。该研究为选择适合特定应用的 LLMs 提供指导，并强调从基本知识层面提升模型的可靠性和严谨性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10921v1",
      "published_date": "2024-08-20 15:04:38 UTC",
      "updated_date": "2024-08-20 15:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:00:19.665854"
    },
    {
      "arxiv_id": "2408.10920v1",
      "title": "Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations",
      "title_zh": "循环神经网络学会使用非线性表示存储和生成序列",
      "authors": [
        "Róbert Csordás",
        "Christopher Potts",
        "Christopher D. Manning",
        "Atticus Geiger"
      ],
      "abstract": "The Linear Representation Hypothesis (LRH) states that neural networks learn\nto encode concepts as directions in activation space, and a strong version of\nthe LRH states that models learn only such encodings. In this paper, we present\na counterexample to this strong LRH: when trained to repeat an input token\nsequence, gated recurrent neural networks (RNNs) learn to represent the token\nat each position with a particular order of magnitude, rather than a direction.\nThese representations have layered features that are impossible to locate in\ndistinct linear subspaces. To show this, we train interventions to predict and\nmanipulate tokens by learning the scaling factor corresponding to each sequence\nposition. These interventions indicate that the smallest RNNs find only this\nmagnitude-based solution, while larger RNNs have linear representations. These\nfindings strongly indicate that interpretability research should not be\nconfined by the LRH.",
      "tldr_zh": "本论文挑战了 Linear Representation Hypothesis (LRH)，通过展示训练后的 Recurrent Neural Networks (RNNs) 在存储和生成序列时，使用非线性表示而非线性方向来编码信息。\n具体而言，RNNs 通过每个序列位置的特定顺序大小（magnitude）来表示标记，这些表示具有分层的特征，无法在不同的线性子空间中定位。\n实验通过训练干预（interventions）来预测和操纵标记，结果显示小型 RNNs 仅采用这种基于大小的解决方案，而大型 RNNs 可能兼有线性表示。\n这些发现强调，可解释性研究不应局限于 LRH，以更好地理解神经网络的表示机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10920v1",
      "published_date": "2024-08-20 15:04:37 UTC",
      "updated_date": "2024-08-20 15:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:00:34.484948"
    },
    {
      "arxiv_id": "2408.10919v4",
      "title": "CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network",
      "title_zh": "CrossFi：基于孪生网络的跨域 Wi-Fi 感知框架",
      "authors": [
        "Zijian Zhao",
        "Tingwei Chen",
        "Zhijie Cai",
        "Xiaoyang Li",
        "Hang Li",
        "Qimei Chen",
        "Guangxu Zhu"
      ],
      "abstract": "In recent years, Wi-Fi sensing has garnered significant attention due to its\nnumerous benefits, such as privacy protection, low cost, and penetration\nability. Extensive research has been conducted in this field, focusing on areas\nsuch as gesture recognition, people identification, and fall detection.\nHowever, many data-driven methods encounter challenges related to domain shift,\nwhere the model fails to perform well in environments different from the\ntraining data. One major factor contributing to this issue is the limited\navailability of Wi-Fi sensing datasets, which makes models learn excessive\nirrelevant information and over-fit to the training set. Unfortunately,\ncollecting large-scale Wi-Fi sensing datasets across diverse scenarios is a\nchallenging task. To address this problem, we propose CrossFi, a siamese\nnetwork-based approach that excels in both in-domain scenario and cross-domain\nscenario, including few-shot, zero-shot scenarios, and even works in few-shot\nnew-class scenario where testing set contains new categories. The core\ncomponent of CrossFi is a sample-similarity calculation network called CSi-Net,\nwhich improves the structure of the siamese network by using an attention\nmechanism to capture similarity information, instead of simply calculating the\ndistance or cosine similarity. Based on it, we develop an extra Weight-Net that\ncan generate a template for each class, so that our CrossFi can work in\ndifferent scenarios. Experimental results demonstrate that our CrossFi achieves\nstate-of-the-art performance across various scenarios. In gesture recognition\ntask, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72%\nin one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario,\nand 84.75% in one-shot new-class scenario. The code for our model is publicly\navailable at https://github.com/RS2002/CrossFi.",
      "tldr_zh": "该研究针对 Wi-Fi sensing 中的 domain shift 问题，提出了一种基于 Siamese Network 的框架 CrossFi，以解决数据集有限导致的模型过拟合问题。CrossFi 的核心组件包括 CSi-Net，使用注意力机制捕获样本相似性信息，以及 Weight-Net 生成类模板，使其适用于 in-domain、few-shot、zero-shot 和 few-shot new-class 等多种场景。实验结果显示，在手势识别任务上，CrossFi 实现了 state-of-the-art 性能，准确率分别为 in-domain 场景 98.17%、one-shot cross-domain 91.72%、zero-shot cross-domain 64.81% 和 one-shot new-class 84.75%。代码已开源，可进一步促进相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10919v4",
      "published_date": "2024-08-20 15:04:14 UTC",
      "updated_date": "2025-02-14 11:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:00:47.320799"
    },
    {
      "arxiv_id": "2408.10905v1",
      "title": "The impact of labeling automotive AI as \"trustworthy\" or \"reliable\" on user evaluation and technology acceptance",
      "title_zh": "翻译失败",
      "authors": [
        "John Dorsch",
        "Ophelia Deroy"
      ],
      "abstract": "This study explores whether labeling AI as \"trustworthy\" or \"reliable\"\ninfluences user perceptions and acceptance of automotive AI technologies. Using\na one-way between-subjects design, the research involved 478 online\nparticipants who were presented with guidelines for either trustworthy or\nreliable AI. Participants then evaluated three vignette scenarios and completed\na modified version of the Technology Acceptance Model, which included variables\nsuch as perceived ease of use, human-like trust, and overall attitude. Although\nlabeling AI as \"trustworthy\" did not significantly influence judgments on\nspecific scenarios, it increased perceived ease of use and human-like trust,\nparticularly benevolence. This suggests a positive impact on usability and an\nanthropomorphic effect on user perceptions. The study provides insights into\nhow specific labels can influence attitudes toward AI technology.",
      "tldr_zh": "这篇论文探讨了将汽车 AI 标记为 \"trustworthy\" 或 \"reliable\" 是否会影响用户对这些技术的评价和接受度。研究采用一元组间主题设计，涉及 478 名在线参与者，他们查看相关指南后评估三个场景，并使用修改后的 Technology Acceptance Model 测量感知易用性、人性化信任（如 benevolence）和整体态度。虽然 \"trustworthy\" 标签未显著改变具体场景判断，但它提升了感知易用性和人性化信任。总体而言，该研究揭示了特定标签对用户 AI 态度和可用性认知的正面影响。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "K.4.1; H.5.2; H.4.2; J.7; J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "36 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10905v1",
      "published_date": "2024-08-20 14:48:24 UTC",
      "updated_date": "2024-08-20 14:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:00:56.584904"
    },
    {
      "arxiv_id": "2408.10901v3",
      "title": "A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongliang Guo",
        "Chun Tong Lei",
        "Lei Fang",
        "Shuai Zhao",
        "Yifei Qian",
        "Jingyu Lin",
        "Zeyu Wang",
        "Cunjian Chen",
        "Ognjen Arandjelović",
        "Chun Pong Lau"
      ],
      "abstract": "Recent advancements in generative AI, particularly Latent Diffusion Models\n(LDMs), have revolutionized image synthesis and manipulation. However, these\ngenerative techniques raises concerns about data misappropriation and\nintellectual property infringement. Adversarial attacks on machine learning\nmodels have been extensively studied, and a well-established body of research\nhas extended these techniques as a benign metric to prevent the underlying\nmisuse of generative AI. Current approaches to safeguarding images from\nmanipulation by LDMs are limited by their reliance on model-specific knowledge\nand their inability to significantly degrade semantic quality of generated\nimages. In response to these shortcomings, we propose the Posterior Collapse\nAttack (PCA) based on the observation that VAEs suffer from posterior collapse\nduring training. Our method minimizes dependence on the white-box information\nof target models to get rid of the implicit reliance on model-specific\nknowledge. By accessing merely a small amount of LDM parameters, in specific\nmerely the VAE encoder of LDMs, our method causes a substantial semantic\ncollapse in generation quality, particularly in perceptual consistency, and\ndemonstrates strong transferability across various model architectures.\nExperimental results show that PCA achieves superior perturbation effects on\nimage generation of LDMs with lower runtime and VRAM. Our method outperforms\nexisting techniques, offering a more robust and generalizable solution that is\nhelpful in alleviating the socio-technical challenges posed by the rapidly\nevolving landscape of generative AI.",
      "tldr_zh": "该论文针对Latent Diffusion Models (LDMs) 的图像编辑提出了一种Grey-box Attack，名为Posterior Collapse Attack (PCA)，利用VAEs在训练中的后验坍缩问题，旨在减少对模型特定知识的依赖，仅需访问少量LDM参数（如VAE encoder）即可显著破坏生成图像的语义质量和感知一致性。PCA方法通过最小化白盒信息需求，实现了强转移性，适用于多种模型架构，并在实验中表现出色，运行时间和VRAM占用更低。总体上，该攻击优于现有技术，提供更鲁棒的解决方案，帮助缓解生成AI带来的数据误用和知识产权侵权风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 7 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10901v3",
      "published_date": "2024-08-20 14:43:53 UTC",
      "updated_date": "2025-02-21 23:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:01:08.304800"
    },
    {
      "arxiv_id": "2408.10900v1",
      "title": "Towards Efficient Formal Verification of Spiking Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Baekryun Seong",
        "Jieung Kim",
        "Sang-Ki Ko"
      ],
      "abstract": "Recently, AI research has primarily focused on large language models (LLMs),\nand increasing accuracy often involves scaling up and consuming more power. The\npower consumption of AI has become a significant societal issue; in this\ncontext, spiking neural networks (SNNs) offer a promising solution. SNNs\noperate event-driven, like the human brain, and compress information\ntemporally. These characteristics allow SNNs to significantly reduce power\nconsumption compared to perceptron-based artificial neural networks (ANNs),\nhighlighting them as a next-generation neural network technology. However,\nsocietal concerns regarding AI go beyond power consumption, with the\nreliability of AI models being a global issue. For instance, adversarial\nattacks on AI models are a well-studied problem in the context of traditional\nneural networks. Despite their importance, the stability and property\nverification of SNNs remains in the early stages of research. Most SNN\nverification methods are time-consuming and barely scalable, making practical\napplications challenging. In this paper, we introduce temporal encoding to\nachieve practical performance in verifying the adversarial robustness of SNNs.\nWe conduct a theoretical analysis of this approach and demonstrate its success\nin verifying SNNs at previously unmanageable scales. Our contribution advances\nSNN verification to a practical level, facilitating the safer application of\nSNNs.",
      "tldr_zh": "该研究关注AI模型的功耗和可靠性问题，指出虽然Spiking Neural Networks (SNNs) 能显著降低功耗并模仿人类大脑的活动，但其稳定性和属性验证仍面临效率低和可扩展性差的挑战。作者引入temporal encoding 方法，通过理论分析和实验验证，实现了SNNs对抗鲁棒性的高效形式验证，使其能够处理之前难以管理的规模。最终，这项贡献推动了SNNs在实际应用中的安全性和可信度，提升了其作为下一代神经网络技术的潜力。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10900v1",
      "published_date": "2024-08-20 14:43:33 UTC",
      "updated_date": "2024-08-20 14:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:01:19.536777"
    },
    {
      "arxiv_id": "2408.10895v1",
      "title": "Analytical and Empirical Study of Herding Effects in Recommendation Systems",
      "title_zh": "推荐系统中羊群效应的分析性和经验性研究",
      "authors": [
        "Hong Xie",
        "Mingze Zhong",
        "Defu Lian",
        "Zhen Wang",
        "Enhong Chen"
      ],
      "abstract": "Online rating systems are often used in numerous web or mobile applications,\ne.g., Amazon and TripAdvisor, to assess the ground-truth quality of products.\nDue to herding effects, the aggregation of historical ratings (or historical\ncollective opinion) can significantly influence subsequent ratings, leading to\nmisleading and erroneous assessments. We study how to manage product ratings\nvia rating aggregation rules and shortlisted representative reviews, for the\npurpose of correcting the assessment error. We first develop a mathematical\nmodel to characterize important factors of herding effects in product ratings.\nWe then identify sufficient conditions (via the stochastic approximation\ntheory), under which the historical collective opinion converges to the\nground-truth collective opinion of the whole user population. These conditions\nidentify a class of rating aggregation rules and review selection mechanisms\nthat can reveal the ground-truth product quality. We also quantify the speed of\nconvergence (via the martingale theory), which reflects the efficiency of\nrating aggregation rules and review selection mechanisms. We prove that the\nherding effects slow down the speed of convergence while an accurate review\nselection mechanism can speed it up. We also study the speed of convergence\nnumerically and reveal trade-offs in selecting rating aggregation rules and\nreview selection mechanisms. To show the utility of our framework, we design a\nmaximum likelihood algorithm to infer model parameters from ratings, and\nconduct experiments on rating datasets from Amazon and TripAdvisor. We show\nthat proper recency aware rating aggregation rules can improve the speed of\nconvergence in Amazon and TripAdvisor by 41% and 62% respectively.",
      "tldr_zh": "这篇论文分析了推荐系统中的羊群效应（herding effects），探讨了历史评分如何影响后续评估，导致产品质量评估错误。研究者开发了一个数学模型，并通过随机逼近理论（stochastic approximation theory）和马氏理论（martingale theory）识别了使历史集体意见收敛到真实集体意见的充分条件，同时量化了收敛速度，证明羊群效应会减慢速度，而准确的评论选择机制能加速它。实验在 Amazon 和 TripAdvisor 数据集上验证了框架的实用性，结果显示合适的近期感知评分聚合规则（rating aggregation rules）能分别提高收敛速度 41% 和 62%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.10895v1",
      "published_date": "2024-08-20 14:29:23 UTC",
      "updated_date": "2024-08-20 14:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:01:33.056849"
    },
    {
      "arxiv_id": "2408.10889v2",
      "title": "On Learning Action Costs from Input Plans",
      "title_zh": "翻译失败",
      "authors": [
        "Marianela Morales",
        "Alberto Pozanco",
        "Giuseppe Canonaco",
        "Sriram Gopalakrishnan",
        "Daniel Borrajo",
        "Manuela Veloso"
      ],
      "abstract": "Most of the work on learning action models focus on learning the actions'\ndynamics from input plans. This allows us to specify the valid plans of a\nplanning task. However, very little work focuses on learning action costs,\nwhich in turn allows us to rank the different plans. In this paper we introduce\na new problem: that of learning the costs of a set of actions such that a set\nof input plans are optimal under the resulting planning model. To solve this\nproblem we present $LACFIP^k$, an algorithm to learn action's costs from\nunlabeled input plans. We provide theoretical and empirical results showing how\n$LACFIP^k$ can successfully solve this task.",
      "tldr_zh": "本论文探讨从输入计划中学习动作成本的问题，这不同于传统焦点于动作动态学习，而是旨在通过成本评估来对不同计划进行排名。论文引入一个新问题：学习一组动作的成本，使得输入计划在生成的规划模型下是最优的。为此，提出算法 $LACFIP^k$，用于从未标记的输入计划中学习这些成本。理论和经验结果表明，$LACFIP^k$ 能成功解决这一任务，提供可靠的计划优化方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10889v2",
      "published_date": "2024-08-20 14:20:19 UTC",
      "updated_date": "2024-09-02 09:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:01:44.975988"
    },
    {
      "arxiv_id": "2408.10883v2",
      "title": "Dynamic Analysis and Adaptive Discriminator for Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xinqi Su",
        "Zitong Yu",
        "Yawen Cui",
        "Ajian Liu",
        "Xun Lin",
        "Yuhao Wang",
        "Haochen Liang",
        "Wenhui Li",
        "Li Shen",
        "Xiaochun Cao"
      ],
      "abstract": "In current web environment, fake news spreads rapidly across online social\nnetworks, posing serious threats to society. Existing multimodal fake news\ndetection methods can generally be classified into knowledge-based and\nsemantic-based approaches. However, these methods are heavily rely on human\nexpertise and feedback, lacking flexibility. To address this challenge, we\npropose a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fake\nnews detection. For knowledge-based methods, we introduce the Monte Carlo Tree\nSearch algorithm to leverage the self-reflective capabilities of large language\nmodels (LLMs) for prompt optimization, providing richer, domain-specific\ndetails and guidance to the LLMs, while enabling more flexible integration of\nLLM comment on news content. For semantic-based methods, we define four typical\ndeceit patterns: emotional exaggeration, logical inconsistency, image\nmanipulation, and semantic inconsistency, to reveal the mechanisms behind fake\nnews creation. To detect these patterns, we carefully design four\ndiscriminators and expand them in depth and breadth, using the soft-routing\nmechanism to explore optimal detection models. Experimental results on three\nreal-world datasets demonstrate the superiority of our approach. The code will\nbe available at: https://github.com/SuXinqi/DAAD.",
      "tldr_zh": "本文提出 Dynamic Analysis and Adaptive Discriminator (DAAD) 框架，用于提升假新闻检测的灵活性，解决现有知识-based 和 semantic-based 方法依赖人类专家的局限性。对于知识-based 方法，该框架利用 Monte Carlo Tree Search 算法结合大型语言模型 (LLMs) 的自反能力优化提示，提供更丰富的领域细节和指导。对于 semantic-based 方法，定义了四种欺骗模式（emotional exaggeration、logical inconsistency、image manipulation 和 semantic inconsistency），并设计四个 discriminators 结合 soft-routing 机制扩展检测模型。实验结果在三个真实数据集上显示，DAAD 方法表现出色，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10883v2",
      "published_date": "2024-08-20 14:13:54 UTC",
      "updated_date": "2025-03-11 03:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:01:59.073314"
    },
    {
      "arxiv_id": "2408.10878v3",
      "title": "Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Han-Jun Choi",
        "Hyunsung Kim",
        "Minho Lee",
        "Minchul Jeong",
        "Chang-Jo Kim",
        "Jinsung Yoon",
        "Sang-Ki Ko"
      ],
      "abstract": "Multi-agent trajectory data collected from domains such as team sports often\nsuffer from missing values due to various factors. While many imputation\nmethods have been proposed for spatiotemporal data, they are not well-suited\nfor multi-agent sports scenarios where player movements are highly dynamic and\ninter-agent interactions continuously evolve. To address these challenges, we\npropose MIDAS (Multi-agent Imputer with Derivative-Accumulating Self-ensemble),\na framework that imputes multi-agent trajectories with high accuracy and\nphysical plausibility. It jointly predicts positions, velocities, and\naccelerations through a Set Transformer-based neural network and generates\nalternative estimates by recursively accumulating predicted velocity and\nacceleration values. These predictions are then combined using a learnable\nweighted ensemble to produce final imputed trajectories. Experiments on three\nsports datasets demonstrate that MIDAS significantly outperforms existing\nbaselines in both positional accuracy and physical plausibility. Lastly, we\nshowcase use cases of MIDAS, such as approximating total distance and pass\nsuccess probability, to highlight its applicability to practical downstream\ntasks that require complete tracking data.",
      "tldr_zh": "该研究针对多代理体育轨迹数据中的缺失值问题，提出MIDAS（Multi-agent Imputer with Derivative-Accumulating Self-ensemble）框架，以处理高度动态的代理互动场景。MIDAS使用基于Set Transformer的神经网络联合预测位置、速度和加速度，并通过递归积累这些预测值生成备选估计，然后采用可学习的加权集成产生最终的填充轨迹。实验在三个体育数据集上显示，MIDAS在位置准确性和物理合理性方面显著优于现有基线。最后，该框架应用于实际任务，如估算总距离和传球成功概率，展示了其在完整跟踪数据需求中的实用价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10878v3",
      "published_date": "2024-08-20 14:08:16 UTC",
      "updated_date": "2025-03-23 17:12:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:02:11.444954"
    },
    {
      "arxiv_id": "2408.10872v2",
      "title": "V-RoAst: A New Dataset for Visual Road Assessment",
      "title_zh": "V-RoAst：用于视觉道路评估的新数据集",
      "authors": [
        "Natchapon Jongwiriyanurak",
        "Zichao Zeng",
        "June Moh Goo",
        "Xinglei Wang",
        "Ilya Ilyankou",
        "Kerkritt Srirrongvikrai",
        "Meihui Wang",
        "James Haworth"
      ],
      "abstract": "Road traffic crashes cause millions of deaths annually and have a significant\neconomic impact, particularly in low- and middle-income countries (LMICs). This\npaper presents an approach using Vision Language Models (VLMs) for road safety\nassessment, overcoming the limitations of traditional Convolutional Neural\nNetworks (CNNs). We introduce a new task ,V-RoAst (Visual question answering\nfor Road Assessment), with a real-world dataset. Our approach optimizes prompt\nengineering and evaluates advanced VLMs, including Gemini-1.5-flash and\nGPT-4o-mini. The models effectively examine attributes for road assessment.\nUsing crowdsourced imagery from Mapillary, our scalable solution influentially\nestimates road safety levels. In addition, this approach is designed for local\nstakeholders who lack resources, as it does not require training data. It\noffers a cost-effective and automated methods for global road safety\nassessments, potentially saving lives and reducing economic burdens.",
      "tldr_zh": "这篇论文提出使用 Vision Language Models (VLMs) 来评估道路安全，克服传统 Convolutional Neural Networks (CNNs) 的局限性，以应对全球交通事故造成的死亡和经济影响。研究引入了新任务 V-RoAst（Visual question answering for Road Assessment）及其真实世界数据集，利用 Mapillary 的众包图像并优化提示工程，评估模型如 Gemini-1.5-flash 和 GPT-4o-mini，以有效检查道路属性。结果显示，该方法无需训练数据，提供可扩展、成本效益高的自动化解决方案，特别适合资源匮乏的低中收入国家（LMICs），有助于提升道路安全水平并减少生命和经济损失。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10872v2",
      "published_date": "2024-08-20 14:03:30 UTC",
      "updated_date": "2024-08-21 11:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:02:24.276629"
    },
    {
      "arxiv_id": "2408.10871v1",
      "title": "Radio U-Net: a convolutional neural network to detect diffuse radio sources in galaxy clusters and beyond",
      "title_zh": "Radio U-Net：用于检测星系团中弥散射电源及其以外区域的卷积神经网络",
      "authors": [
        "Chiara Stuardi",
        "Claudio Gheller",
        "Franco Vazza",
        "Andrea Botteon"
      ],
      "abstract": "The forthcoming generation of radio telescope arrays promises significant\nadvancements in sensitivity and resolution, enabling the identification and\ncharacterization of many new faint and diffuse radio sources. Conventional\nmanual cataloging methodologies are anticipated to be insufficient to exploit\nthe capabilities of new radio surveys. Radio interferometric images of diffuse\nsources present a challenge for image segmentation tasks due to noise,\nartifacts, and embedded radio sources. In response to these challenges, we\nintroduce Radio U-Net, a fully convolutional neural network based on the U-Net\narchitecture. Radio U-Net is designed to detect faint and extended sources in\nradio surveys, such as radio halos, relics, and cosmic web filaments. Radio\nU-Net was trained on synthetic radio observations built upon cosmological\nsimulations and then tested on a sample of galaxy clusters, where the detection\nof cluster diffuse radio sources relied on customized data reduction and visual\ninspection of LOFAR Two Metre Sky Survey (LoTSS) data. The 83% of clusters\nexhibiting diffuse radio emission were accurately identified, and the\nsegmentation successfully recovered the morphology of the sources even in\nlow-quality images. In a test sample comprising 246 galaxy clusters, we\nachieved a 73% accuracy rate in distinguishing between clusters with and\nwithout diffuse radio emission. Our results establish the applicability of\nRadio U-Net to extensive radio survey datasets, probing its efficiency on\ncutting-edge high-performance computing systems. This approach represents an\nadvancement in optimizing the exploitation of forthcoming large radio surveys\nfor scientific exploration.",
      "tldr_zh": "本研究开发了Radio U-Net，一种基于U-Net架构的全卷积神经网络，用于检测星系团中的微弱和扩展射电源，如radio halos、relics和cosmic web filaments，以应对传统手动目录编制的局限性。模型通过训练于基于宇宙学模拟的合成射电观测数据，并在LOFAR Two Metre Sky Survey (LoTSS)真实样本上测试，成功在83%的有射电发射星系团中准确识别源形态，并在246个星系团样本中实现73%的准确率区分有无发射。Radio U-Net的有效性证明了其在大规模射电调查数据集上的适用性，并优化了高性能计算系统的使用，为未来射电天文探索提供了高效工具。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Accepted by MNRAS, 16 pages, 9 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10871v1",
      "published_date": "2024-08-20 14:03:21 UTC",
      "updated_date": "2024-08-20 14:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:02:35.515294"
    },
    {
      "arxiv_id": "2408.10865v1",
      "title": "Multi-agent Multi-armed Bandits with Stochastic Sharable Arm Capacities",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Xie",
        "Jinyu Mo",
        "Defu Lian",
        "Jie Wang",
        "Enhong Chen"
      ],
      "abstract": "Motivated by distributed selection problems, we formulate a new variant of\nmulti-player multi-armed bandit (MAB) model, which captures stochastic arrival\nof requests to each arm, as well as the policy of allocating requests to\nplayers. The challenge is how to design a distributed learning algorithm such\nthat players select arms according to the optimal arm pulling profile (an arm\npulling profile prescribes the number of players at each arm) without\ncommunicating to each other. We first design a greedy algorithm, which locates\none of the optimal arm pulling profiles with a polynomial computational\ncomplexity. We also design an iterative distributed algorithm for players to\ncommit to an optimal arm pulling profile with a constant number of rounds in\nexpectation. We apply the explore then commit (ETC) framework to address the\nonline setting when model parameters are unknown. We design an exploration\nstrategy for players to estimate the optimal arm pulling profile. Since such\nestimates can be different across different players, it is challenging for\nplayers to commit. We then design an iterative distributed algorithm, which\nguarantees that players can arrive at a consensus on the optimal arm pulling\nprofile in only M rounds. We conduct experiments to validate our algorithm.",
      "tldr_zh": "本研究提出了一种新的多代理多臂老虎机 (Multi-agent Multi-armed Bandits) 模型变体，考虑了每个臂的请求随机到达以及请求分配策略，旨在解决代理在不通信的情况下选择最优臂拉动配置文件 (arm pulling profile) 的分布式学习挑战。研究首先设计了一个贪婪算法，以多项式计算复杂度定位最优配置文件，并开发了一个迭代分布式算法，使代理在预期恒定轮次内达成共识。针对模型参数未知的在线场景，他们应用 Explore Then Commit (ETC) 框架，设计探索策略让代理估计最优配置文件，并通过另一个迭代算法确保代理在 M 轮内实现共识。实验结果验证了该算法的有效性，为分布式选择问题提供了高效解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.10865v1",
      "published_date": "2024-08-20 13:57:00 UTC",
      "updated_date": "2024-08-20 13:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:02:46.323533"
    },
    {
      "arxiv_id": "2408.10858v1",
      "title": "Knowledge Sharing and Transfer via Centralized Reward Agent for Multi-Task Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhe Ma",
        "Zhengding Luo",
        "Thanh Vinh Vo",
        "Kuankuan Sima",
        "Tze-Yun Leong"
      ],
      "abstract": "Reward shaping is effective in addressing the sparse-reward challenge in\nreinforcement learning by providing immediate feedback through auxiliary\ninformative rewards. Based on the reward shaping strategy, we propose a novel\nmulti-task reinforcement learning framework, that integrates a centralized\nreward agent (CRA) and multiple distributed policy agents. The CRA functions as\na knowledge pool, which aims to distill knowledge from various tasks and\ndistribute it to individual policy agents to improve learning efficiency.\nSpecifically, the shaped rewards serve as a straightforward metric to encode\nknowledge. This framework not only enhances knowledge sharing across\nestablished tasks but also adapts to new tasks by transferring valuable reward\nsignals. We validate the proposed method on both discrete and continuous\ndomains, demonstrating its robustness in multi-task sparse-reward settings and\nits effective transferability to unseen tasks.",
      "tldr_zh": "本文提出了一种基于中心化奖励代理（Centralized Reward Agent, CRA）的多任务强化学习框架，利用奖励塑造（reward shaping）策略来解决稀疏奖励问题。CRA 作为知识池，从各种任务中提炼知识并分发给多个分布式策略代理，从而提升学习效率和知识共享。该框架不仅支持现有任务间的知识转移，还能适应新任务，并在离散和连续域的实验中证明了其鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10858v1",
      "published_date": "2024-08-20 13:49:26 UTC",
      "updated_date": "2024-08-20 13:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:02:57.470669"
    },
    {
      "arxiv_id": "2408.10854v1",
      "title": "MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State Space Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Zili Liu",
        "Hao Chen",
        "Lei Bai",
        "Wenyuan Li",
        "Wanli Ouyang",
        "Zhengxia Zou",
        "Zhenwei Shi"
      ],
      "abstract": "In an era of frequent extreme weather and global warming, obtaining precise,\nfine-grained near-surface weather forecasts is increasingly essential for human\nactivities. Downscaling (DS), a crucial task in meteorological forecasting,\nenables the reconstruction of high-resolution meteorological states for target\nregions from global-scale forecast results. Previous downscaling methods,\ninspired by CNN and Transformer-based super-resolution models, lacked tailored\ndesigns for meteorology and encountered structural limitations. Notably, they\nfailed to efficiently integrate topography, a crucial prior in the downscaling\nprocess. In this paper, we address these limitations by pioneering the\nselective state space model into the meteorological field downscaling and\npropose a novel model called MambaDS. This model enhances the utilization of\nmultivariable correlations and topography information, unique challenges in the\ndownscaling process while retaining the advantages of Mamba in long-range\ndependency modeling and linear computational complexity. Through extensive\nexperiments in both China mainland and the continental United States (CONUS),\nwe validated that our proposed MambaDS achieves state-of-the-art results in\nthree different types of meteorological field downscaling settings. We will\nrelease the code subsequently.",
      "tldr_zh": "在极端天气和全球变暖背景下，精确的近地表气象场 Downscaling 变得至关重要，但现有基于 CNN 和 Transformer 的方法缺乏针对气象学的设计，且未能有效整合地形信息。本文提出 MambaDS 模型，将 selective state space model 引入气象领域，通过地形约束提升多变量相关性和信息利用，同时保留 Mamba 的长程依赖建模和线性计算复杂度优势。在中国大陆和美国本土的广泛实验中，MambaDS 在三种不同气象场 Downscaling 设置中取得了 state-of-the-art 结果，并计划发布代码。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10854v1",
      "published_date": "2024-08-20 13:45:49 UTC",
      "updated_date": "2024-08-20 13:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:03:12.573038"
    },
    {
      "arxiv_id": "2408.10853v1",
      "title": "Does Current Deepfake Audio Detection Model Effectively Detect ALM-based Deepfake Audio?",
      "title_zh": "当前的 Deepfake 音频检测模型是否能有效检测基于 ALM 的 Deepfake 音频？",
      "authors": [
        "Yuankun Xie",
        "Chenxu Xiong",
        "Xiaopeng Wang",
        "Zhiyong Wang",
        "Yi Lu",
        "Xin Qi",
        "Ruibo Fu",
        "Yukun Liu",
        "Zhengqi Wen",
        "Jianhua Tao",
        "Guanjun Li",
        "Long Ye"
      ],
      "abstract": "Currently, Audio Language Models (ALMs) are rapidly advancing due to the\ndevelopments in large language models and audio neural codecs. These ALMs have\nsignificantly lowered the barrier to creating deepfake audio, generating highly\nrealistic and diverse types of deepfake audio, which pose severe threats to\nsociety. Consequently, effective audio deepfake detection technologies to\ndetect ALM-based audio have become increasingly critical. This paper\ninvestigate the effectiveness of current countermeasure (CM) against ALM-based\naudio. Specifically, we collect 12 types of the latest ALM-based deepfake audio\nand utilizing the latest CMs to evaluate. Our findings reveal that the latest\ncodec-trained CM can effectively detect ALM-based audio, achieving 0% equal\nerror rate under most ALM test conditions, which exceeded our expectations.\nThis indicates promising directions for future research in ALM-based deepfake\naudio detection.",
      "tldr_zh": "这篇论文探讨了当前音频深度伪造检测模型（countermeasure, CM）是否能有效识别基于 Audio Language Models (ALMs) 的深度伪造音频，因为 ALMs 的快速发展降低了创建高度真实深度伪造音频的门槛，带来了社会威胁。研究者收集了12种最新的ALM-based深度伪造音频，并使用最新CM进行评估。结果显示，codec-trained CM在大多数测试条件下实现了0%的equal error rate，这超出了预期，并为未来ALM-based深度伪造音频检测研究指明了有前景的方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10853v1",
      "published_date": "2024-08-20 13:45:34 UTC",
      "updated_date": "2024-08-20 13:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:03:22.603030"
    },
    {
      "arxiv_id": "2408.10831v1",
      "title": "ZebraPose: Zebra Detection and Pose Estimation using only Synthetic Data",
      "title_zh": "ZebraPose：仅使用合成数据的斑马检测和姿态估计",
      "authors": [
        "Elia Bonetto",
        "Aamir Ahmad"
      ],
      "abstract": "Synthetic data is increasingly being used to address the lack of labeled\nimages in uncommon domains for deep learning tasks. A prominent example is 2D\npose estimation of animals, particularly wild species like zebras, for which\ncollecting real-world data is complex and impractical. However, many approaches\nstill require real images, consistency and style constraints, sophisticated\nanimal models, and/or powerful pre-trained networks to bridge the syn-to-real\ngap. Moreover, they often assume that the animal can be reliably detected in\nimages or videos, a hypothesis that often does not hold, e.g. in wildlife\nscenarios or aerial images. To solve this, we use synthetic data generated with\na 3D photorealistic simulator to obtain the first synthetic dataset that can be\nused for both detection and 2D pose estimation of zebras without applying any\nof the aforementioned bridging strategies. Unlike previous works, we\nextensively train and benchmark our detection and 2D pose estimation models on\nmultiple real-world and synthetic datasets using both pre-trained and\nnon-pre-trained backbones. These experiments show how the models trained from\nscratch and only with synthetic data can consistently generalize to real-world\nimages of zebras in both tasks. Moreover, we show it is possible to easily\ngeneralize those same models to 2D pose estimation of horses with a minimal\namount of real-world images to account for the domain transfer. Code, results,\ntrained models; and the synthetic, training, and validation data, including\n104K manually labeled frames, are provided as open-source at\nhttps://zebrapose.is.tue.mpg.de/",
      "tldr_zh": "本文提出ZebraPose框架，使用仅Synthetic Data（通过3D photorealistic simulator生成）来实现斑马的检测和2D Pose Estimation，无需传统桥接策略如真实图像或风格约束。研究团队训练并基准测试了模型，在多个真实和合成数据集上，使用预训练和非预训练的骨干网络，结果显示这些模型能有效泛化到真实世界斑马图像。进一步发现，仅需少量真实图像即可将模型扩展到马的2D Pose Estimation，为动物姿态估计领域提供了一个高效的开源解决方案，包括代码、训练数据和10.4万帧手动标注。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10831v1",
      "published_date": "2024-08-20 13:28:37 UTC",
      "updated_date": "2024-08-20 13:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:03:34.918707"
    },
    {
      "arxiv_id": "2408.11876v2",
      "title": "From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Guy Lutsker",
        "Gal Sapir",
        "Smadar Shilo",
        "Jordi Merino",
        "Anastasia Godneva",
        "Jerry R Greenfield",
        "Dorit Samocha-Bonet",
        "Raja Dhir",
        "Francisco Gude",
        "Shie Mannor",
        "Eli Meirom",
        "Gal Chechik",
        "Hagai Rossman",
        "Eran Segal"
      ],
      "abstract": "Recent advances in SSL enabled novel medical AI models, known as foundation\nmodels, offer great potential for better characterizing health from diverse\nbiomedical data. CGM provides rich, temporal data on glycemic patterns, but its\nfull potential for predicting broader health outcomes remains underutilized.\nHere, we present GluFormer, a generative foundation model for CGM data that\nlearns nuanced glycemic patterns and translates them into predictive\nrepresentations of metabolic health. Trained on over 10 million CGM\nmeasurements from 10,812 adults, primarily without diabetes, GluFormer uses\nautoregressive token prediction to capture longitudinal glucose dynamics. We\nshow that GluFormer generalizes to 19 external cohorts (n=6,044) spanning\ndifferent ethnicities and ages, 5 countries, 8 CGM devices, and diverse\npathophysiological states. GluFormers representations exceed the performance of\ncurrent CGM metrics, such as the Glucose Management Indicator (GMI), for\nforecasting clinical measures. In a longitudinal study of 580 adults with CGM\ndata and 12-year follow-up, GluFormer identifies individuals at elevated risk\nof developing diabetes more effectively than blood HbA1C%, capturing 66% of all\nnew-onset diabetes diagnoses in the top quartile versus 7% in the bottom\nquartile. Similarly, 69% of cardiovascular-death events occurred in the top\nquartile with none in the bottom quartile, demonstrating powerful risk\nstratification beyond traditional glycemic metrics. We also show that CGM\nrepresentations from pre-intervention periods in Randomized Clinical Trials\noutperform other methods in predicting primary and secondary outcomes. When\nintegrating dietary data into GluFormer, we show that the multi-modal version\nof the model can accurately generate CGM data based on dietary intake data,\nsimulate outcomes of dietary interventions, and predict individual responses to\nspecific foods.",
      "tldr_zh": "该研究提出了一种名为 GluFormer 的生成性基础模型，用于分析连续葡萄糖监测 (CGM) 数据，以学习血糖模式并预测代谢健康结果。模型采用自回归标记预测方法，训练于超过 1000 万条数据（来自 10,812 名主要无糖尿病成人），并在 19 个外部队列（n=6,044）上展示了强大的泛化性，涵盖不同民族、年龄、国家和设备。相比传统指标如 Glucose Management Indicator (GMI) 和 HbA1C%，GluFormer 在预测临床措施和风险方面表现出色，例如在纵向研究中，顶层四分位数捕获了 66% 的新发糖尿病诊断和 69% 的心血管死亡事件，而底层四分位数几乎无事件。该模型的多模态版本还能整合饮食数据，模拟干预效果并预测个体对食物的反应，为更精确的健康风险分层提供新工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11876v2",
      "published_date": "2024-08-20 13:19:06 UTC",
      "updated_date": "2025-01-07 16:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:03:51.261450"
    },
    {
      "arxiv_id": "2408.10819v2",
      "title": "GS-KGC: A Generative Subgraph-based Framework for Knowledge Graph Completion with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Yang",
        "Jiahao Zhu",
        "Jianping Man",
        "Hongze Liu",
        "Li Fang",
        "Yi Zhou"
      ],
      "abstract": "Knowledge graph completion (KGC) focuses on identifying missing triples in a\nknowledge graph (KG) , which is crucial for many downstream applications. Given\nthe rapid development of large language models (LLMs), some LLM-based methods\nare proposed for KGC task. However, most of them focus on prompt engineering\nwhile overlooking the fact that finer-grained subgraph information can aid LLMs\nin generating more accurate answers. In this paper, we propose a novel\ncompletion framework called \\textbf{G}enerative \\textbf{S}ubgraph-based KGC\n(GS-KGC), which utilizes subgraph information as contextual reasoning and\nemploys a QA approach to achieve the KGC task. This framework primarily\nincludes a subgraph partitioning algorithm designed to generate negatives and\nneighbors. Specifically, negatives can encourage LLMs to generate a broader\nrange of answers, while neighbors provide additional contextual insights for\nLLM reasoning. Furthermore, we found that GS-KGC can discover potential triples\nwithin the KGs and new facts beyond the KGs. Experiments conducted on four\ncommon KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it\nshows a 5.6\\% increase in Hits@3 compared to the LLM-based model CP-KGC on the\nFB15k-237N, and a 9.3\\% increase over the LLM-based model TECHS on the ICEWS14.",
      "tldr_zh": "本文提出GS-KGC框架，一种基于子图的生成式方法，用于利用大型语言模型(LLMs)进行知识图谱补全(KGC)，通过子图信息作为上下文推理并采用QA方法来提升任务性能。该框架的核心是子图分区算法，用于生成negatives（鼓励LLMs产生更广泛的答案）和neighbors（提供额外上下文洞察），从而帮助发现知识图谱内的潜在三元组和新事实。实验在四个常见KGC数据集上验证了其优势，例如在FB15k-237N上比CP-KGC提高5.6% Hits@3，在ICEWS14上比TECHS提高9.3%。这项工作突出了子图信息在LLM-based KGC中的重要作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10819v2",
      "published_date": "2024-08-20 13:13:41 UTC",
      "updated_date": "2025-01-03 04:12:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:10.933625"
    },
    {
      "arxiv_id": "2408.10811v1",
      "title": "Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?",
      "title_zh": "翻译失败",
      "authors": [
        "Chengzhi Zhong",
        "Fei Cheng",
        "Qianying Liu",
        "Junfeng Jiang",
        "Zhen Wan",
        "Chenhui Chu",
        "Yugo Murawaki",
        "Sadao Kurohashi"
      ],
      "abstract": "In this study, we investigate whether non-English-centric LLMs, despite their\nstrong performance, `think' in their respective dominant language: more\nprecisely, `think' refers to how the representations of intermediate layers,\nwhen un-embedded into the vocabulary space, exhibit higher probabilities for\ncertain dominant languages during generation. We term such languages as\ninternal $\\textbf{latent languages}$.\n  We examine the latent language of three typical categories of models for\nJapanese processing: Llama2, an English-centric model; Swallow, an\nEnglish-centric model with continued pre-training in Japanese; and LLM-jp, a\nmodel pre-trained on balanced English and Japanese corpora. Our empirical\nfindings reveal that, unlike Llama2 which relies exclusively on English as the\ninternal latent language, Japanese-specific Swallow and LLM-jp employ both\nJapanese and English, exhibiting dual internal latent languages. For any given\ntarget language, the model preferentially activates the latent language most\nclosely related to it. In addition, we explore how intermediate layers respond\nto questions involving cultural conflicts between latent internal and target\noutput languages. We further explore how the language identity shifts across\nlayers while keeping consistent semantic meaning reflected in the intermediate\nlayer representations.\n  This study deepens the understanding of non-English-centric large language\nmodels, highlighting the intricate dynamics of language representation within\ntheir intermediate layers.",
      "tldr_zh": "本研究探讨了非英语中心的大型语言模型（LLMs）在内部表示中是否使用主导语言作为“内部潜在语言”（internal latent languages），即中间层表示在解嵌入词汇空间时对某些语言的概率偏好。研究者分析了三种针对日语处理的模型：英语中心的Llama2、基于Llama2在日语上继续预训练的Swallow，以及平衡英语和日语预训练的LLM-jp。结果显示，Llama2仅依赖英语作为内部潜在语言，而Swallow和LLM-jp则使用日语和英语的双重潜在语言，且模型会优先激活与目标语言最相关的潜在语言。该研究还考察了中间层对文化冲突问题的响应及语言身份的层间变化，加深了对多语言LLMs语言表示复杂动态的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.10811v1",
      "published_date": "2024-08-20 13:05:41 UTC",
      "updated_date": "2024-08-20 13:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:12.602700"
    },
    {
      "arxiv_id": "2408.10807v1",
      "title": "DisMix: Disentangling Mixtures of Musical Instruments for Source-level Pitch and Timbre Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yin-Jyun Luo",
        "Kin Wai Cheuk",
        "Woosung Choi",
        "Toshimitsu Uesaka",
        "Keisuke Toyama",
        "Koichi Saito",
        "Chieh-Hsin Lai",
        "Yuhta Takida",
        "Wei-Hsiang Liao",
        "Simon Dixon",
        "Yuki Mitsufuji"
      ],
      "abstract": "Existing work on pitch and timbre disentanglement has been mostly focused on\nsingle-instrument music audio, excluding the cases where multiple instruments\nare presented. To fill the gap, we propose DisMix, a generative framework in\nwhich the pitch and timbre representations act as modular building blocks for\nconstructing the melody and instrument of a source, and the collection of which\nforms a set of per-instrument latent representations underlying the observed\nmixture. By manipulating the representations, our model samples mixtures with\nnovel combinations of pitch and timbre of the constituent instruments. We can\njointly learn the disentangled pitch-timbre representations and a latent\ndiffusion transformer that reconstructs the mixture conditioned on the set of\nsource-level representations. We evaluate the model using both a simple dataset\nof isolated chords and a realistic four-part chorales in the style of J.S.\nBach, identify the key components for the success of disentanglement, and\ndemonstrate the application of mixture transformation based on source-level\nattribute manipulation.",
      "tldr_zh": "该论文提出DisMix框架，用于分离多乐器混合音频中的音高(pitch)和音色(timbre)，以实现源级别的操纵，从而填补现有方法仅限于单乐器音频的空白。DisMix将pitch和timbre表示作为模块化构建块，形成每个乐器的潜在表示，并结合潜变量扩散变换器，联合学习这些分离表示并重建混合音频。实验在孤立和弦数据集以及Bach风格的四部合唱上进行，验证了关键组件的有效性，并展示了通过操纵源级属性生成新音高和音色组合的应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10807v1",
      "published_date": "2024-08-20 12:56:49 UTC",
      "updated_date": "2024-08-20 12:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:24.337036"
    },
    {
      "arxiv_id": "2408.10802v1",
      "title": "Inverse Deep Learning Ray Tracing for Heliostat Surface Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Lewen",
        "Max Pargmann",
        "Mehdi Cherti",
        "Jenia Jitsev",
        "Robert Pitz-Paal",
        "Daniel Maldonado Quinto"
      ],
      "abstract": "Concentrating Solar Power (CSP) plants play a crucial role in the global\ntransition towards sustainable energy. A key factor in ensuring the safe and\nefficient operation of CSP plants is the distribution of concentrated flux\ndensity on the receiver. However, the non-ideal flux density generated by\nindividual heliostats can undermine the safety and efficiency of the power\nplant. The flux density from each heliostat is influenced by its precise\nsurface profile, which includes factors such as canting and mirror errors.\nAccurately measuring these surface profiles for a large number of heliostats in\noperation is a formidable challenge. Consequently, control systems often rely\non the assumption of ideal surface conditions, which compromises both safety\nand operational efficiency. In this study, we introduce inverse Deep Learning\nRay Tracing (iDLR), an innovative method designed to predict heliostat surfaces\nbased solely on target images obtained during heliostat calibration. Our\nsimulation-based investigation demonstrates that sufficient information\nregarding the heliostat surface is retained in the flux density distribution of\na single heliostat, enabling deep learning models to accurately predict the\nunderlying surface with deflectometry-like precision for the majority of\nheliostats. Additionally, we assess the limitations of this method,\nparticularly in relation to surface accuracy and resultant flux density\npredictions. Furthermore, we are presenting a new comprehensive heliostat model\nusing Non-Uniform Rational B-Spline (NURBS) that has the potential to become\nthe new State of the Art for heliostat surface parameterization. Our findings\nreveal that iDLR has significant potential to enhance CSP plant operations,\npotentially increasing the overall efficiency and energy output of the power\nplants.",
      "tldr_zh": "本研究针对Concentrating Solar Power (CSP) 植物中heliostat的表面轮廓测量难题，提出inverse Deep Learning Ray Tracing (iDLR) 方法，利用heliostat校准时的目标图像预测表面参数，以解决非理想flux density分布对安全和效率的影响。iDLR通过深度学习模型从单一heliostat的flux density分布中提取足够信息，实现与deflectometry相当的精确预测。模拟实验显示，该方法能准确预测大多数heliostat的表面轮廓，同时评估了其在表面准确性和flux density预测方面的局限性。研究还引入了一个新的综合heliostat模型，使用Non-Uniform Rational B-Spline (NURBS)进行表面参数化，有望成为新的行业标准，最终提升CSP植物的整体效率和能量输出。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10802v1",
      "published_date": "2024-08-20 12:51:35 UTC",
      "updated_date": "2024-08-20 12:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:39.443619"
    },
    {
      "arxiv_id": "2408.10788v1",
      "title": "Understanding the Skills Gap between Higher Education and Industry in the UK in Artificial Intelligence Sector",
      "title_zh": "翻译失败",
      "authors": [
        "Khushi Jaiswal",
        "Ievgeniia Kuzminykh",
        "Sanjay Modgil"
      ],
      "abstract": "As Artificial Intelligence (AI) changes how businesses work, there is a\ngrowing need for people who can work in this sector. This paper investigates\nhow well universities in United Kingdom offering courses in AI, prepare\nstudents for jobs in the real world. To gain insight into the differences\nbetween university curricula and industry demands we review the contents of\ntaught courses and job advertisement portals. By using custom data scraping\ntools to gather information from job advertisements and university curricula,\nand frequency and Naive Bayes classifier analysis, this study will show exactly\nwhat skills industry is looking for. In this study we identified 12 skill\ncategories that were used for mapping. The study showed that the university\ncurriculum in the AI domain is well balanced in most technical skills,\nincluding Programming and Machine learning subjects, but have a gap in Data\nScience and Maths and Statistics skill categories.",
      "tldr_zh": "这篇论文探讨了英国人工智能（AI）领域中高等教育与行业需求的技能差距，调查了大学课程如何为学生准备实际工作。研究者使用自定义数据抓取工具收集工作广告和大学课程信息，并通过频率分析和Naive Bayes分类器分析，识别了12个技能类别。结果显示，大学课程在编程和Machine Learning等技术技能方面较为平衡，但Data Science和Maths and Statistics类别存在显著缺口。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the journal \"Industry and Higher Education\"",
      "pdf_url": "http://arxiv.org/pdf/2408.10788v1",
      "published_date": "2024-08-20 12:28:58 UTC",
      "updated_date": "2024-08-20 12:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:47.229054"
    },
    {
      "arxiv_id": "2408.10777v1",
      "title": "Just a Hint: Point-Supervised Camouflaged Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Huafeng Chen",
        "Dian Shao",
        "Guangqian Guo",
        "Shan Gao"
      ],
      "abstract": "Camouflaged Object Detection (COD) demands models to expeditiously and\naccurately distinguish objects which conceal themselves seamlessly in the\nenvironment. Owing to the subtle differences and ambiguous boundaries, COD is\nnot only a remarkably challenging task for models but also for human\nannotators, requiring huge efforts to provide pixel-wise annotations. To\nalleviate the heavy annotation burden, we propose to fulfill this task with the\nhelp of only one point supervision. Specifically, by swiftly clicking on each\nobject, we first adaptively expand the original point-based annotation to a\nreasonable hint area. Then, to avoid partial localization around discriminative\nparts, we propose an attention regulator to scatter model attention to the\nwhole object through partially masking labeled regions. Moreover, to solve the\nunstable feature representation of camouflaged objects under only point-based\nannotation, we perform unsupervised contrastive learning based on differently\naugmented image pairs (e.g. changing color or doing translation). On three\nmainstream COD benchmarks, experimental results show that our model outperforms\nseveral weakly-supervised methods by a large margin across various metrics.",
      "tldr_zh": "本文提出了一种基于点监督的 Camouflaged Object Detection (COD) 方法，以减轻像素级标注的繁重负担，仅需在每个物体上点击一个点即可。方法包括自适应扩展点标注为提示区域、引入 attention regulator 通过部分掩盖来扩散模型注意力至整个物体，以及进行 unsupervised contrastive learning 以基于不同图像增强（如颜色变化或平移）提升 camouflaged 对象的特征稳定性。在三个主流 COD 基准上，实验结果显示该模型在各种指标上大幅优于其他弱监督方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10777v1",
      "published_date": "2024-08-20 12:17:25 UTC",
      "updated_date": "2024-08-20 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:04:59.531752"
    },
    {
      "arxiv_id": "2408.10774v3",
      "title": "Flexora: Flexible Low Rank Adaptation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxing Wei",
        "Yao Shu",
        "Ying Tiffany He",
        "Fei Richard Yu"
      ],
      "abstract": "Large Language Models (LLMs) are driving advancements in artificial\nintelligence by increasing the scale of model parameters, which has\nsignificantly enhanced generalization ability and unlocked new capabilities in\npractice. However, their performance in specific downstream tasks is usually\nhindered by their knowledge boundaries on these tasks. Thus, fine-tuning\ntechniques, especially the widely used Low-Rank Adaptation (LoRA) method, have\nbeen introduced to expand the boundaries on these tasks, whereas LoRA would\nunderperform on certain tasks owing to its potential overfitting on these\ntasks. To overcome this overfitting and improve the performance of LoRA, we\npropose the flexible low rank adaptation (Flexora) method to automatically and\nflexibly select the most important layers needing to be fine-tuned to achieve\nthe best performance on different downstream tasks. Specifically, Flexora\nfirstly frames this layer selection problem as a well-defined hyperparameter\noptimization (HPO) problem, then addresses it using the unrolled\ndifferentiation (UD) method, and finally selects the most useful layers based\non the optimized hyperparameters. Our extensive experiments on many pretrained\nmodels and natural language tasks show that Flexora is able to consistently\nimprove over the existing baselines, indicating the effectiveness of our\nFlexora in practice. We additionally provide insightful theoretical results and\nmany ablation studies to deliver a comprehensive understanding of our Flexora.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 在下游任务中受限于知识边界的问题，提出 Flexora 方法来优化 Low-Rank Adaptation (LoRA)，以避免其潜在过拟合。Flexora 将层选择问题转化为 Hyperparameter Optimization (HPO) 问题，并使用 Unrolled Differentiation (UD) 方法自动选择最重要层进行细调，从而提升模型在不同任务上的性能。实验结果显示，Flexora 在多个预训练模型和自然语言任务上 consistently 优于基线模型，并通过理论分析和消融研究提供了全面的理解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10774v3",
      "published_date": "2024-08-20 12:13:04 UTC",
      "updated_date": "2025-02-18 13:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:05:11.598808"
    },
    {
      "arxiv_id": "2408.10771v3",
      "title": "kNN Retrieval for Simple and Effective Zero-Shot Multi-speaker Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Karl El Hajal",
        "Ajinkya Kulkarni",
        "Enno Hermann",
        "Mathew Magimai. -Doss"
      ],
      "abstract": "While recent zero-shot multi-speaker text-to-speech (TTS) models achieve\nimpressive results, they typically rely on extensive transcribed speech\ndatasets from numerous speakers and intricate training pipelines. Meanwhile,\nself-supervised learning (SSL) speech features have emerged as effective\nintermediate representations for TTS. Further, SSL features from different\nspeakers that are linearly close share phonetic information while maintaining\nindividual speaker identity. In this study, we introduce kNN-TTS, a simple and\neffective framework for zero-shot multi-speaker TTS using retrieval methods\nwhich leverage the linear relationships between SSL features. Objective and\nsubjective evaluations show that our models, trained on transcribed speech from\na single speaker only, achieve performance comparable to state-of-the-art\nmodels that are trained on significantly larger training datasets. The low\ntraining data requirements mean that kNN-TTS is well suited for the development\nof multi-speaker TTS systems for low-resource domains and languages. We also\nintroduce an interpolation parameter which enables fine-grained voice morphing.\nDemo samples are available at https://idiap.github.io/knn-tts",
      "tldr_zh": "本研究提出 kNN-TTS 框架，通过 kNN 检索方法利用自监督学习 (SSL) features 的线性关系，实现简单有效的 zero-shot multi-speaker text-to-speech (TTS)。该模型仅需一个说话人的转录语音数据进行训练，即可达到与使用大规模数据集的先进模型相当的性能。客观和主观评估显示，kNN-TTS 适用于低资源领域和语言的多说话人 TTS 系统开发，并引入插值参数支持细粒度的语音混合。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10771v3",
      "published_date": "2024-08-20 12:09:58 UTC",
      "updated_date": "2025-02-03 16:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:05:24.817114"
    },
    {
      "arxiv_id": "2408.10760v1",
      "title": "SAM-COD: SAM-guided Unified Framework for Weakly-Supervised Camouflaged Object Detection",
      "title_zh": "SAM-COD：SAM 引导的弱监督伪装物体检测统一框架",
      "authors": [
        "Huafeng Chen",
        "Pengxu Wei",
        "Guangqian Guo",
        "Shan Gao"
      ],
      "abstract": "Most Camouflaged Object Detection (COD) methods heavily rely on mask\nannotations, which are time-consuming and labor-intensive to acquire. Existing\nweakly-supervised COD approaches exhibit significantly inferior performance\ncompared to fully-supervised methods and struggle to simultaneously support all\nthe existing types of camouflaged object labels, including scribbles, bounding\nboxes, and points. Even for Segment Anything Model (SAM), it is still\nproblematic to handle the weakly-supervised COD and it typically encounters\nchallenges of prompt compatibility of the scribble labels, extreme response,\nsemantically erroneous response, and unstable feature representations,\nproducing unsatisfactory results in camouflaged scenes. To mitigate these\nissues, we propose a unified COD framework in this paper, termed SAM-COD, which\nis capable of supporting arbitrary weakly-supervised labels. Our SAM-COD\nemploys a prompt adapter to handle scribbles as prompts based on SAM.\nMeanwhile, we introduce response filter and semantic matcher modules to improve\nthe quality of the masks obtained by SAM under COD prompts. To alleviate the\nnegative impacts of inaccurate mask predictions, a new strategy of\nprompt-adaptive knowledge distillation is utilized to ensure a reliable feature\nrepresentation. To validate the effectiveness of our approach, we have\nconducted extensive empirical experiments on three mainstream COD benchmarks.\nThe results demonstrate the superiority of our method against state-of-the-art\nweakly-supervised and even fully-supervised methods.",
      "tldr_zh": "本文提出 SAM-COD，一种基于 Segment Anything Model (SAM) 的统一框架，用于弱监督 Camouflaged Object Detection (COD)，能够同时支持 scribbles、bounding boxes 和 points 等标签，解决现有方法的性能不足和标注依赖问题。该框架通过 prompt adapter 处理 scribbles 作为提示，引入 response filter 和 semantic matcher 模块来提升 SAM 生成掩码的质量，并采用 prompt-adaptive knowledge distillation 策略缓解不准确预测的影响。在三个主流 COD 基准上的实验表明，SAM-COD 优于现有弱监督和全监督方法，展示了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10760v1",
      "published_date": "2024-08-20 11:49:27 UTC",
      "updated_date": "2024-08-20 11:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:05:35.874045"
    },
    {
      "arxiv_id": "2408.10755v1",
      "title": "Generating Synthetic Fair Syntax-agnostic Data by Learning and Distilling Fair Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Md Fahim Sikder",
        "Resmi Ramachandranpillai",
        "Daniel de Leng",
        "Fredrik Heintz"
      ],
      "abstract": "Data Fairness is a crucial topic due to the recent wide usage of AI powered\napplications. Most of the real-world data is filled with human or machine\nbiases and when those data are being used to train AI models, there is a chance\nthat the model will reflect the bias in the training data. Existing\nbias-mitigating generative methods based on GANs, Diffusion models need\nin-processing fairness objectives and fail to consider computational overhead\nwhile choosing computationally-heavy architectures, which may lead to high\ncomputational demands, instability and poor optimization performance. To\nmitigate this issue, in this work, we present a fair data generation technique\nbased on knowledge distillation, where we use a small architecture to distill\nthe fair representation in the latent space. The idea of fair latent space\ndistillation enables more flexible and stable training of Fair Generative\nModels (FGMs). We first learn a syntax-agnostic (for any data type) fair\nrepresentation of the data, followed by distillation in the latent space into a\nsmaller model. After distillation, we use the distilled fair latent space to\ngenerate high-fidelity fair synthetic data. While distilling, we employ quality\nloss (for fair distillation) and utility loss (for data utility) to ensure that\nthe fairness and data utility characteristics remain in the distilled latent\nspace. Our approaches show a 5%, 5% and 10% rise in performance in fairness,\nsynthetic sample quality and data utility, respectively, than the\nstate-of-the-art fair generative model.",
      "tldr_zh": "本研究针对AI数据中的偏见问题，提出了一种基于知识蒸馏的公平数据生成技术，以生成syntax-agnostic（语法无关）的高质量合成数据。该方法首先学习数据的公平表示，然后在latent space（潜在空间）中进行蒸馏到较小模型，确保训练过程更灵活和稳定，同时通过quality loss（质量损失）和utility loss（效用损失）来维持公平性和数据效用。与现有基于GANs或Diffusion models的生成方法相比，该技术避免了高计算开销和优化不稳定问题，并在公平性、合成样本质量和数据效用上分别提高了5%、5%和10%。这项工作为构建无偏AI模型提供了更高效的Fair Generative Models (FGMs)基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10755v1",
      "published_date": "2024-08-20 11:37:52 UTC",
      "updated_date": "2024-08-20 11:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:05:49.085155"
    },
    {
      "arxiv_id": "2408.10752v1",
      "title": "Security Assessment of Hierarchical Federated Deep Learning",
      "title_zh": "分层联邦深度学习的安全评估",
      "authors": [
        "D Alqattan",
        "R Sun",
        "H Liang",
        "G Nicosia",
        "V Snasel",
        "R Ranjan",
        "V Ojha"
      ],
      "abstract": "Hierarchical federated learning (HFL) is a promising distributed deep\nlearning model training paradigm, but it has crucial security concerns arising\nfrom adversarial attacks. This research investigates and assesses the security\nof HFL using a novel methodology by focusing on its resilience against\nadversarial attacks inference-time and training-time. Through a series of\nextensive experiments across diverse datasets and attack scenarios, we uncover\nthat HFL demonstrates robustness against untargeted training-time attacks due\nto its hierarchical structure. However, targeted attacks, particularly backdoor\nattacks, exploit this architecture, especially when malicious clients are\npositioned in the overlapping coverage areas of edge servers. Consequently, HFL\nshows a dual nature in its resilience, showcasing its capability to recover\nfrom attacks thanks to its hierarchical aggregation that strengthens its\nsuitability for adversarial training, thereby reinforcing its resistance\nagainst inference-time attacks. These insights underscore the necessity for\nbalanced security strategies in HFL systems, leveraging their inherent\nstrengths while effectively mitigating vulnerabilities.",
      "tldr_zh": "这篇论文评估了 Hierarchical Federated Learning (HFL) 在面对 adversarial attacks 时的安全性，通过一种新颖的方法进行实验研究，涵盖训练-time 和 inference-time 攻击场景。结果显示，HFL 由于其层次化结构，对 untargeted training-time attacks 表现出较强鲁棒性，但对 targeted attacks 如 backdoor attacks 较为脆弱，尤其当恶意客户端位于 edge servers 的重叠区域。总体而言，HFL 的 hierarchical aggregation 机制有助于从攻击中恢复并提升对 inference-time attacks 的抵抗力，强调了在 HFL 系统设计中需要平衡的安全策略以利用其优势并缓解潜在漏洞。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10752v1",
      "published_date": "2024-08-20 11:34:23 UTC",
      "updated_date": "2024-08-20 11:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:06:01.553690"
    },
    {
      "arxiv_id": "2408.10746v1",
      "title": "Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Bei Ouyang",
        "Shengyuan Ye",
        "Liekang Zeng",
        "Tianyi Qian",
        "Jingyi Li",
        "Xu Chen"
      ],
      "abstract": "Large language models (LLMs) have unlocked a plethora of powerful\napplications at the network edge, such as intelligent personal assistants. Data\nprivacy and security concerns have prompted a shift towards edge-based\nfine-tuning of personal LLMs, away from cloud reliance. However, this raises\nissues of computational intensity and resource scarcity, hindering training\nefficiency and feasibility. While current studies investigate\nparameter-efficient fine-tuning (PEFT) techniques to mitigate resource\nconstraints, our analysis indicates that these techniques are not sufficiently\nresource-efficient for edge devices. To tackle these challenges, we propose\nPluto and Charon (PAC), a time and memory efficient collaborative edge AI\nframework for personal LLMs fine-tuning. PAC breaks the resource wall of\npersonal LLMs fine-tuning with a sophisticated algorithm-system co-design. (1)\nAlgorithmically, PAC implements a personal LLMs fine-tuning technique that is\nefficient in terms of parameters, time, and memory. It utilizes Parallel\nAdapters to circumvent the need for a full backward pass through the LLM\nbackbone. Additionally, an activation cache mechanism further streamlining the\nprocess by negating the necessity for repeated forward passes across multiple\nepochs. (2) Systematically, PAC leverages edge devices in close proximity,\npooling them as a collective resource for in-situ personal LLMs fine-tuning,\nutilizing a hybrid data and pipeline parallelism to orchestrate distributed\ntraining. The use of the activation cache eliminates the need for forward pass\nthrough the LLM backbone,enabling exclusive fine-tuning of the Parallel\nAdapters using data parallelism. Extensive evaluation based on prototype\nimplementation demonstrates that PAC remarkably outperforms state-of-the-art\napproaches, achieving up to 8.64x end-to-end speedup and up to 88.16% reduction\nin memory footprint.",
      "tldr_zh": "该研究提出Pluto and Charon (PAC)框架，一种高效的协作边缘AI系统，用于解决个人LLMs微调在边缘设备上面临的计算密集和资源不足问题。PAC通过算法设计引入Parallel Adapters来避免全模型反向传播，并利用activation cache机制减少重复前向传播；在系统层面，它整合附近边缘设备进行分布式训练，采用混合数据和管道并行。实验评估显示，PAC相较于现有PEFT方法，实现高达8.64倍的端到端加速和88.16%的内存占用减少。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by The 53rd International Conference on Parallel Processing\n  (ICPP'24)",
      "pdf_url": "http://arxiv.org/pdf/2408.10746v1",
      "published_date": "2024-08-20 11:30:12 UTC",
      "updated_date": "2024-08-20 11:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:06:13.409589"
    },
    {
      "arxiv_id": "2408.11081v2",
      "title": "What can Large Language Models Capture about Code Functional Equivalence?",
      "title_zh": "大型语言模型能够捕捉到代码功能等价性的哪些方面？",
      "authors": [
        "Nickil Maveli",
        "Antonio Vergari",
        "Shay B. Cohen"
      ],
      "abstract": "Code-LLMs, LLMs pre-trained on large code corpora, have shown great progress\nin learning rich representations of the structure and syntax of code,\nsuccessfully using it to generate or classify code fragments. At the same time,\nunderstanding if they are able to do so because they capture code semantics,\nand how well, is still an open question. In this paper, we tackle this problem\nby introducing SeqCoBench, a benchmark for systematically assessing how\nCode-LLMs can capture code functional equivalence. SeqCoBench contains over 20\ncode transformations that either preserve or alter the semantics of Python\nprograms. We conduct extensive evaluations in different settings, including\nzero-shot and parameter-efficient finetuning methods on state-of-the-art\n(Code)-LLMs to see if they can discern semantically equivalent or different\npairs of programs in SeqCoBench. We find that the performance gap between these\nLLMs and classical match-based retrieval scores is minimal, with both\napproaches showing a concerning lack of depth in understanding code semantics.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models, LLMs），特别是基于代码语料库预训练的 Code-LLMs，在捕捉代码功能等价性方面的能力。论文引入了 SeqCoBench 基准测试，该基准包含超过 20 种代码转换，用于评估这些模型是否能区分语义等价或不同的 Python 程序。研究通过零-shot 和参数高效微调（parameter-efficient finetuning）方法，对最先进的 (Code)-LLMs 进行广泛评估。结果显示，这些 LLMs 的性能与经典的基于匹配的检索分数差距很小，两者均存在对代码语义理解深度不足的问题。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.11081v2",
      "published_date": "2024-08-20 11:19:06 UTC",
      "updated_date": "2025-02-12 19:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:06:25.133921"
    },
    {
      "arxiv_id": "2408.10729v1",
      "title": "Towards Efficient Large Language Models for Scientific Text: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Quoc To",
        "Ming Liu",
        "Guangyan Huang"
      ],
      "abstract": "Large language models (LLMs) have ushered in a new era for processing complex\ninformation in various fields, including science. The increasing amount of\nscientific literature allows these models to acquire and understand scientific\nknowledge effectively, thus improving their performance in a wide range of\ntasks. Due to the power of LLMs, they require extremely expensive computational\nresources, intense amounts of data, and training time. Therefore, in recent\nyears, researchers have proposed various methodologies to make scientific LLMs\nmore affordable. The most well-known approaches align in two directions. It can\nbe either focusing on the size of the models or enhancing the quality of data.\nTo date, a comprehensive review of these two families of methods has not yet\nbeen undertaken. In this paper, we (I) summarize the current advances in the\nemerging abilities of LLMs into more accessible AI solutions for science, and\n(II) investigate the challenges and opportunities of developing affordable\nsolutions for scientific domains using LLMs.",
      "tldr_zh": "这篇论文回顾了大型语言模型 (LLMs) 在科学文本处理中的应用进展，强调了这些模型在处理复杂科学知识时的优势，同时指出了其高计算资源、数据和时间需求的挑战。论文总结了两种主要优化方法：一是缩小模型规模，二是提升数据质量，以使科学 LLMs 更高效和可负担。最终，它调查了开发这些可访问 AI 解决方案的挑战和机会，为未来研究提供了全面的参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10729v1",
      "published_date": "2024-08-20 10:57:34 UTC",
      "updated_date": "2024-08-20 10:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:06:35.971730"
    },
    {
      "arxiv_id": "2408.10726v1",
      "title": "Quantum Artificial Intelligence: A Brief Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Klusch",
        "Jörg Lässig",
        "Daniel Müssig",
        "Antonio Macaluso",
        "Frank K. Wilhelm"
      ],
      "abstract": "Quantum Artificial Intelligence (QAI) is the intersection of quantum\ncomputing and AI, a technological synergy with expected significant benefits\nfor both. In this paper, we provide a brief overview of what has been achieved\nin QAI so far and point to some open questions for future research. In\nparticular, we summarize some major key findings on the feasability and the\npotential of using quantum computing for solving computationally hard problems\nin various subfields of AI, and vice versa, the leveraging of AI methods for\nbuilding and operating quantum computing devices.",
      "tldr_zh": "这篇论文对Quantum Artificial Intelligence (QAI)进行了简要概述，探讨了量子计算与AI的交叉点及其潜在协同益处。作者总结了现有研究的关键发现，包括量子计算在解决AI子领域（如机器学习）的计算难题方面的可行性和潜力，以及利用AI方法来构建和操作量子计算设备。论文还指出了未来研究的方向，如QAI面临的开放问题，以推动这一领域的进一步发展。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10726v1",
      "published_date": "2024-08-20 10:55:17 UTC",
      "updated_date": "2024-08-20 10:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:06:47.777519"
    },
    {
      "arxiv_id": "2408.10722v1",
      "title": "MEGen: Generative Backdoor in Large Language Models via Model Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyang Qiu",
        "Xinbei Ma",
        "Zhuosheng Zhang",
        "Hai Zhao"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities. Their\npowerful generative abilities enable flexible responses based on various\nqueries or instructions. Emerging as widely adopted generalists for diverse\ntasks, LLMs are still vulnerable to backdoors. This paper proposes an\nediting-based generative backdoor, named MEGen, aiming to create a customized\nbackdoor for NLP tasks with the least side effects. In our approach, we first\nleverage a language model to insert a trigger selected on fixed metrics into\nthe input, then design a pipeline of model editing to directly embed a backdoor\ninto an LLM. By adjusting a small set of local parameters with a mini-batch of\nsamples, MEGen significantly enhances time efficiency and achieves high\nrobustness. Experimental results indicate that our backdoor attack strategy\nachieves a high attack success rate on poison data while maintaining the\nmodel's performance on clean data. Notably, the backdoored model, when\ntriggered, can freely output pre-set dangerous information while successfully\ncompleting downstream tasks. This suggests that future LLM applications could\nbe guided to deliver certain dangerous information, thus altering the LLM's\ngenerative style. We believe this approach provides insights for future LLM\napplications and the execution of backdoor attacks on conversational AI\nsystems.",
      "tldr_zh": "这篇论文提出了MEGen，一种通过模型编辑在Large Language Models (LLMs)中植入生成式后门的攻击方法，旨在为NLP任务创建自定义后门，同时最小化对模型性能的影响。方法包括使用语言模型插入基于固定指标的触发器，然后通过一个模型编辑管道，仅调整少量本地参数和使用小批量样本来嵌入后门，从而提升时间效率和鲁棒性。实验结果显示，MEGen在毒化数据上实现了高攻击成功率，同时保持了模型在干净数据上的正常表现；当触发后门时，模型能输出预设的危险信息，同时完成下游任务。该研究为LLMs应用的安全风险提供了重要洞见，并可能影响对话式AI系统的生成风格。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.10722v1",
      "published_date": "2024-08-20 10:44:29 UTC",
      "updated_date": "2024-08-20 10:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:07:01.665993"
    },
    {
      "arxiv_id": "2408.10720v1",
      "title": "Towards Foundation Models for the Industrial Forecasting of Chemical Kinetics",
      "title_zh": "迈向化学动力学工业预测的基础模型",
      "authors": [
        "Imran Nasim",
        "Joaõ Lucas de Sousa Almeida"
      ],
      "abstract": "Scientific Machine Learning is transforming traditional engineering\nindustries by enhancing the efficiency of existing technologies and\naccelerating innovation, particularly in modeling chemical reactions. Despite\nrecent advancements, the issue of solving stiff chemically reacting problems\nwithin computational fluid dynamics remains a significant issue. In this study\nwe propose a novel approach utilizing a multi-layer-perceptron mixer\narchitecture (MLP-Mixer) to model the time-series of stiff chemical kinetics.\nWe evaluate this method using the ROBER system, a benchmark model in chemical\nkinetics, to compare its performance with traditional numerical techniques.\nThis study provides insight into the industrial utility of the recently\ndeveloped MLP-Mixer architecture to model chemical kinetics and provides\nmotivation for such neural architecture to be used as a base for time-series\nfoundation models.",
      "tldr_zh": "本研究旨在开发基础模型用于工业化学动力学的预测，解决传统计算流体动力学中刚性化学反应问题的挑战。研究提出了一种基于多层感知器混合器架构（MLP-Mixer）的新方法，用于建模刚性化学动力学的时序数据，并通过基准模型ROBER系统与传统数值技术进行性能比较。结果显示，MLP-Mixer在化学动力学建模方面表现出工业实用性，并为构建时序基础模型提供了重要动力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted into the IEEE CAI 2024 Workshop on Scientific Machine\n  Learning and Its Industrial Applications (SMLIA2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.10720v1",
      "published_date": "2024-08-20 10:43:09 UTC",
      "updated_date": "2024-08-20 10:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:07:12.479807"
    },
    {
      "arxiv_id": "2408.10715v1",
      "title": "Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Hou",
        "Christoph Bert",
        "Ahmed Gomaa",
        "Godehard Lahmer",
        "Daniel Hoefler",
        "Thomas Weissmann",
        "Raphaela Voigt",
        "Philipp Schubert",
        "Charlotte Schmitter",
        "Alina Depardon",
        "Sabine Semrau",
        "Andreas Maier",
        "Rainer Fietkau",
        "Yixing Huang",
        "Florian Putz"
      ],
      "abstract": "Generating physician letters is a time-consuming task in daily clinical\npractice. This study investigates local fine-tuning of large language models\n(LLMs), specifically LLaMA models, for physician letter generation in a\nprivacy-preserving manner within the field of radiation oncology. Our findings\ndemonstrate that base LLaMA models, without fine-tuning, are inadequate for\neffectively generating physician letters. The QLoRA algorithm provides an\nefficient method for local intra-institutional fine-tuning of LLMs with limited\ncomputational resources (i.e., a single 48 GB GPU workstation within the\nhospital). The fine-tuned LLM successfully learns radiation oncology-specific\ninformation and generates physician letters in an institution-specific style.\nROUGE scores of the generated summary reports highlight the superiority of the\n8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician\nevaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has\nlimited capacity to generate content beyond the provided input data, it\nsuccessfully generates salutations, diagnoses and treatment histories,\nrecommendations for further treatment, and planned schedules. Overall, clinical\nbenefit was rated highly by the clinical experts (average score of 3.44 on a\n4-point scale). With careful physician review and correction, automated\nLLM-based physician letter generation has significant practical value.",
      "tldr_zh": "本研究探讨了在辐射肿瘤学领域，使用本地微调 LLaMA-3 大语言模型（LLM）来自动化生成医生信函，从而实现隐私保护并减少临床工作量。研究采用 QLoRA 算法在单台 48 GB GPU 工作站上进行微调，使模型学习辐射肿瘤学特定信息并生成机构风格的信函。结果显示，微调后的 LLaMA-3 8B 模型在 ROUGE 分数上优于 LLaMA-2 13B 模型，能够有效生成问候语、诊断、治疗历史和后续计划，尽管其内容受限于输入数据。临床专家的多维度评估表明，该方法具有显著实际价值（平均得分 3.44 分），但需医生审查以确保准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10715v1",
      "published_date": "2024-08-20 10:31:36 UTC",
      "updated_date": "2024-08-20 10:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:07:24.442380"
    },
    {
      "arxiv_id": "2408.10713v1",
      "title": "Offline Model-Based Reinforcement Learning with Anti-Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Padmanaba Srinivasan",
        "William Knottenbelt"
      ],
      "abstract": "Model-based reinforcement learning (MBRL) algorithms learn a dynamics model\nfrom collected data and apply it to generate synthetic trajectories to enable\nfaster learning. This is an especially promising paradigm in offline\nreinforcement learning (RL) where data may be limited in quantity, in addition\nto being deficient in coverage and quality. Practical approaches to offline\nMBRL usually rely on ensembles of dynamics models to prevent exploitation of\nany individual model and to extract uncertainty estimates that penalize values\nin states far from the dataset support. Uncertainty estimates from ensembles\ncan vary greatly in scale, making it challenging to generalize hyperparameters\nwell across even similar tasks. In this paper, we present Morse Model-based\noffline RL (MoMo), which extends the anti-exploration paradigm found in offline\nmodel-free RL to the model-based space. We develop model-free and model-based\nvariants of MoMo and show how the model-free version can be extended to detect\nand deal with out-of-distribution (OOD) states using explicit uncertainty\nestimation without the need for large ensembles. MoMo performs offline MBRL\nusing an anti-exploration bonus to counteract value overestimation in\ncombination with a policy constraint, as well as a truncation function to\nterminate synthetic rollouts that are excessively OOD. Experimentally, we find\nthat both model-free and model-based MoMo perform well, and the latter\noutperforms prior model-based and model-free baselines on the majority of D4RL\ndatasets tested.",
      "tldr_zh": "本研究提出了一种名为 MoMo 的离线模型强化学习（offline MBRL）方法，通过引入反探索（anti-exploration）机制来解决动态模型不确定性和价值高估问题。MoMo 将反探索范式从无模型强化学习扩展到模型空间，使用反探索奖励、策略约束和截断函数来终止分布外（OOD）合成轨迹，从而改善对未知状态的处理。实验结果显示，MoMo 的模型和无模型变体在 D4RL 数据集上均表现出色，特别是模型版本优于现有 MBRL 和无模型基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10713v1",
      "published_date": "2024-08-20 10:29:21 UTC",
      "updated_date": "2024-08-20 10:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:07:46.920624"
    },
    {
      "arxiv_id": "2408.10711v1",
      "title": "Investigating Context Effects in Similarity Judgements in Large Language Models",
      "title_zh": "调查大型语言模型中相似性判断的上下文效果",
      "authors": [
        "Sagar Uprety",
        "Amit Kumar Jaiswal",
        "Haiming Liu",
        "Dawei Song"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionised the capability of AI models\nin comprehending and generating natural language text. They are increasingly\nbeing used to empower and deploy agents in real-world scenarios, which make\ndecisions and take actions based on their understanding of the context.\nTherefore researchers, policy makers and enterprises alike are working towards\nensuring that the decisions made by these agents align with human values and\nuser expectations. That being said, human values and decisions are not always\nstraightforward to measure and are subject to different cognitive biases. There\nis a vast section of literature in Behavioural Science which studies biases in\nhuman judgements. In this work we report an ongoing investigation on alignment\nof LLMs with human judgements affected by order bias. Specifically, we focus on\na famous human study which showed evidence of order effects in similarity\njudgements, and replicate it with various popular LLMs. We report the different\nsettings where LLMs exhibit human-like order effect bias and discuss the\nimplications of these findings to inform the design and development of LLM\nbased applications.",
      "tldr_zh": "这篇论文调查了大型语言模型(LLMs)在相似性判断(similarity judgements)中受上下文效应，尤其是顺序偏差(order bias)的影响。研究者复制了一个著名的人类研究，测试各种流行LLMs的表现，以评估它们是否表现出类似人类的认知偏差。结果表明，LLMs在特定设置中确实存在人类般的顺序效应，并讨论了这些发现对LLM应用设计和开发的影响，以确保决策更符合人类价值观。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at The First Workshop on AI Behavioral Science (AIBS 2024),\n  held in conjunction with KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10711v1",
      "published_date": "2024-08-20 10:26:02 UTC",
      "updated_date": "2024-08-20 10:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:07:58.531149"
    },
    {
      "arxiv_id": "2408.10710v1",
      "title": "Coarse-to-Fine Detection of Multiple Seams for Robotic Welding",
      "title_zh": "机器人焊接的多条焊缝粗",
      "authors": [
        "Pengkun Wei",
        "Shuo Cheng",
        "Dayou Li",
        "Ran Song",
        "Yipeng Zhang",
        "Wei Zhang"
      ],
      "abstract": "Efficiently detecting target weld seams while ensuring sub-millimeter\naccuracy has always been an important challenge in autonomous welding, which\nhas significant application in industrial practice. Previous works mostly\nfocused on recognizing and localizing welding seams one by one, leading to\ninferior efficiency in modeling the workpiece. This paper proposes a novel\nframework capable of multiple weld seams extraction using both RGB images and\n3D point clouds. The RGB image is used to obtain the region of interest by\napproximately localizing the weld seams, and the point cloud is used to achieve\nthe fine-edge extraction of the weld seams within the region of interest using\nregion growth. Our method is further accelerated by using a pre-trained deep\nlearning model to ensure both efficiency and generalization ability. The\nperformance of the proposed method has been comprehensively tested on various\nworkpieces featuring both linear and curved weld seams and in physical\nexperiment systems. The results showcase considerable potential for real-world\nindustrial applications, emphasizing the method's efficiency and effectiveness.\nVideos of the real-world experiments can be found at\nhttps://youtu.be/pq162HSP2D4.",
      "tldr_zh": "本论文提出了一种Coarse-to-Fine Detection框架，用于机器人焊接中高效检测多个焊缝，确保亚毫米级精度。该框架先利用RGB images粗略定位焊缝的Region of Interest，然后通过3D point clouds和Region Growth算法进行精细边缘提取，并结合预训练的深度学习模型提升整体效率和泛化能力。实验结果显示，该方法在各种工件（如线性或弯曲焊缝）上表现出色，具有显著的实际工业应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10710v1",
      "published_date": "2024-08-20 10:24:59 UTC",
      "updated_date": "2024-08-20 10:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:08:11.789722"
    },
    {
      "arxiv_id": "2408.10709v1",
      "title": "Variable Assignment Invariant Neural Networks for Learning Logic Programs",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Jun Phua",
        "Katsumi Inoue"
      ],
      "abstract": "Learning from interpretation transition (LFIT) is a framework for learning\nrules from observed state transitions. LFIT has been implemented in purely\nsymbolic algorithms, but they are unable to deal with noise or generalize to\nunobserved transitions. Rule extraction based neural network methods suffer\nfrom overfitting, while more general implementation that categorize rules\nsuffer from combinatorial explosion. In this paper, we introduce a technique to\nleverage variable permutation invariance inherent in symbolic domains. Our\ntechnique ensures that the permutation and the naming of the variables would\nnot affect the results. We demonstrate the effectiveness and the scalability of\nthis method with various experiments. Our code is publicly available at\nhttps://github.com/phuayj/delta-lfit-2",
      "tldr_zh": "该论文针对 Learning from Interpretation Transition (LFIT) 框架的局限性（如纯符号算法无法处理噪声或泛化，神经网络方法易过拟合，以及其他方法面临组合爆炸），提出了一种基于 Variable Assignment Invariant 的神经网络技术。 该技术利用变量置换不变性，确保变量的排列和命名不影响学习逻辑程序的结果，从而提升模型的鲁棒性和泛化能力。 通过各种实验，论文证明了该方法的有效性和可扩展性，并公开了代码（https://github.com/phuayj/delta-lfit-2）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10709v1",
      "published_date": "2024-08-20 10:23:35 UTC",
      "updated_date": "2024-08-20 10:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:08:24.015687"
    },
    {
      "arxiv_id": "2408.10700v1",
      "title": "AnyGraph: Graph Foundation Model in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "The growing ubiquity of relational data structured as graphs has underscored\nthe need for graph learning models with exceptional generalization\ncapabilities. However, current approaches often struggle to effectively extract\ngeneralizable insights, frequently requiring extensive fine-tuning and limiting\ntheir versatility. Graph foundation models offer a transformative solution,\nwith the potential to learn robust, generalizable representations from graph\ndata. This enables more effective and adaptable applications across a wide\nspectrum of tasks and domains. In this work, we investigate a unified graph\nmodel, AnyGraph, designed to handle key challenges: i) Structure Heterogenity.\nAddressing distribution shift in graph structural information; ii) Feature\nHeterogenity. Handling diverse feature representation spaces across graph\ndatasets; iii) Fast Adaptation. Efficiently adapting the model to new graph\ndomains; iv) Scaling Law Emergence. Enabling the model to exhibit scaling law\nbehavior, where its performance scales favorably with the amount of data and\nparameter sizes. To tackle these critical challenges, we build the AnyGraph\nupon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the\nmodel to effectively manage both the in-domain and cross-domain distribution\nshift concerning structure-level and feature-level heterogeneity. Furthermore,\na lightweight graph expert routing mechanism is proposed to facilitate\nAnyGraph's fast adaptability to new data and domains. Our extensive experiments\non diverse 38 graph datasets have demonstrated the strong zero-shot learning\nperformance of AnyGraph across diverse graph domains with significant\ndistribution shift. Furthermore, we have validated the model's fast adaptation\nability and scaling law emergence, showcasing its versatility.",
      "tldr_zh": "本研究提出 AnyGraph，一种统一的图基础模型，旨在解决图学习中的关键挑战，包括结构异质性（distribution shift in graph structural information）、特征异质性（diverse feature representation spaces）、快速适应（Fast Adaptation）以及规模定律出现（Scaling Law Emergence），从而提升模型的泛化能力和适用性。AnyGraph 基于 Graph Mixture-of-Experts (MoE) 架构，结合轻量级图专家路由机制，有效处理结构和特征水平的异质性，并支持跨域分布偏移的适应。实验在 38 个多样化图数据集上验证了 AnyGraph 的强大零样本学习（zero-shot learning）性能、快速适应能力和性能随数据量及参数规模的改善效应。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10700v1",
      "published_date": "2024-08-20 09:57:13 UTC",
      "updated_date": "2024-08-20 09:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:08:37.042940"
    },
    {
      "arxiv_id": "2408.10691v2",
      "title": "Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Dong",
        "Haijun Zhang",
        "Chengming Li",
        "Song Guo",
        "Victor C. M. Leung",
        "Xiping Hu"
      ],
      "abstract": "Since the invention of GPT2--1.5B in 2019, large language models (LLMs) have\ntransitioned from specialized models to versatile foundation models. The LLMs\nexhibit impressive zero-shot ability, however, require fine-tuning on local\ndatasets and significant resources for deployment. Traditional fine-tuning\ntechniques with the first-order optimizers require substantial GPU memory that\nexceeds mainstream hardware capability. Therefore, memory-efficient methods are\nmotivated to be investigated. Model compression techniques can reduce energy\nconsumption, operational costs, and environmental impact so that to support\nsustainable artificial intelligence advancements. Additionally, large-scale\nfoundation models have expanded to create images, audio, videos, and\nmulti-modal contents, further emphasizing the need for efficient deployment.\nTherefore, we are motivated to present a comprehensive overview of the\nprevalent memory-efficient fine-tuning methods over the network edge. We also\nreview the state-of-the-art literatures on model compression to provide a\nvision on deploying LLMs over the network edge.",
      "tldr_zh": "该论文讨论了大型语言模型 (LLMs) 的发展，从专用模型转向多功能基础模型，尽管它们具备出色的零-shot 能力，但微调和部署需要大量资源，如超出主流硬件的 GPU 内存。作者综述了在网络边缘的内存高效微调方法，包括使用一阶优化器的替代技术，以及模型压缩技术，以降低能源消耗、运营成本和环境影响，支持可持续人工智能。最终，该研究提供了对这些方法的全面概述和文献回顾，为高效部署 LLMs 提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10691v2",
      "published_date": "2024-08-20 09:42:17 UTC",
      "updated_date": "2024-10-01 08:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:08:48.091883"
    },
    {
      "arxiv_id": "2408.10689v2",
      "title": "Genesis: Towards the Automation of Systems Biology Research",
      "title_zh": "Genesis: 迈向系统生物学研究的自动化",
      "authors": [
        "Ievgeniia A. Tiukova",
        "Daniel Brunnsåker",
        "Erik Y. Bjurström",
        "Alexander H. Gower",
        "Filip Kronström",
        "Gabriel K. Reder",
        "Ronald S. Reiserer",
        "Konstantin Korovin",
        "Larisa B. Soldatova",
        "John P. Wikswo",
        "Ross D. King"
      ],
      "abstract": "The cutting edge of applying AI to science is the closed-loop automation of\nscientific research: robot scientists. We have previously developed two robot\nscientists: `Adam' (for yeast functional biology), and `Eve' (for early-stage\ndrug design)). We are now developing a next generation robot scientist Genesis.\nWith Genesis we aim to demonstrate that an area of science can be investigated\nusing robot scientists unambiguously faster, and at lower cost, than with human\nscientists. Here we report progress on the Genesis project. Genesis is designed\nto automatically improve system biology models with thousands of interacting\ncausal components. When complete Genesis will be able to initiate and execute\nin parallel one thousand hypothesis-led closed-loop cycles of experiment\nper-day. Here we describe the core Genesis hardware: the one thousand\ncomputer-controlled $\\mu$-bioreactors. For the integrated Mass Spectrometry\nplatform we have developed AutonoMS, a system to automatically run, process,\nand analyse high-throughput experiments. We have also developed Genesis-DB, a\ndatabase system designed to enable software agents access to large quantities\nof structured domain information. We have developed RIMBO (Revisions for\nImprovements of Models in Biology Ontology) to describe the planned hundreds of\nthousands of changes to the models. We have demonstrated the utility of this\ninfrastructure by developed two relational learning bioinformatic projects.\nFinally, we describe LGEM+ a relational learning system for the automated\nabductive improvement of genome-scale metabolic models.",
      "tldr_zh": "这项研究介绍了 Genesis，一个下一代机器人科学家，旨在通过自动化实验循环来加速系统生物学研究，比人类科学家更快且更低成本。Genesis 包括核心硬件如一千个计算机控制的 $\\mu$-bioreactors，以及软件系统如 AutonoMS 用于高通量实验处理、Genesis-DB 数据库和 RIMBO 用于模型改进的本体。研究团队开发了 LGEM+，一个关系学习系统，用于自动改进基因组规模的代谢模型，并通过两个生物信息学项目证明了这一基础设施的实用性。总的来说，Genesis 展示了 AI 在科学自动化中的潜力，特别是处理数千个相互作用因子的系统生物模型。",
      "categories": [
        "cs.AI",
        "A.1; I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10689v2",
      "published_date": "2024-08-20 09:40:43 UTC",
      "updated_date": "2024-09-04 09:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:09:02.694963"
    },
    {
      "arxiv_id": "2408.10683v1",
      "title": "Rejection in Abstract Argumentation: Harder Than Acceptance?",
      "title_zh": "抽象论证中的拒绝：比接受",
      "authors": [
        "Johannes K. Fichte",
        "Markus Hecher",
        "Yasir Mahmood",
        "Arne Meier"
      ],
      "abstract": "Abstract argumentation is a popular toolkit for modeling, evaluating, and\ncomparing arguments. Relationships between arguments are specified in\nargumentation frameworks (AFs), and conditions are placed on sets (extensions)\nof arguments that allow AFs to be evaluated. For more expressiveness, AFs are\naugmented with \\emph{acceptance conditions} on directly interacting arguments\nor a constraint on the admissible sets of arguments, resulting in dialectic\nframeworks or constrained argumentation frameworks. In this paper, we consider\nflexible conditions for \\emph{rejecting} an argument from an extension, which\nwe call rejection conditions (RCs). On the technical level, we associate each\nargument with a specific logic program. We analyze the resulting complexity,\nincluding the structural parameter treewidth. Rejection AFs are highly\nexpressive, giving rise to natural problems on higher levels of the polynomial\nhierarchy.",
      "tldr_zh": "这篇论文探讨了抽象论证（Abstract Argumentation）框架中拒绝条件（Rejection Conditions, RCs）的复杂性，并将其与接受条件进行比较。作者引入了一种方法，将每个参数与特定的逻辑程序关联，并分析了其计算复杂性，包括结构参数treewidth。结果显示，拒绝AFs 具有高度表达性，导致多项式层次（polynomial hierarchy）中更高级别的问题出现，从而突显了拒绝机制在论证框架中的挑战性。总的来说，这为论证框架的扩展提供了新视角，提升了其在建模和评估争论时的灵活性。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted version as ECAI24",
      "pdf_url": "http://arxiv.org/pdf/2408.10683v1",
      "published_date": "2024-08-20 09:37:04 UTC",
      "updated_date": "2024-08-20 09:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:09:10.982891"
    },
    {
      "arxiv_id": "2408.10682v1",
      "title": "Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbang Yuan",
        "Zhuoran Jin",
        "Pengfei Cao",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "LLM have achieved success in many fields but still troubled by problematic\ncontent in the training corpora. LLM unlearning aims at reducing their\ninfluence and avoid undesirable behaviours. However, existing unlearning\nmethods remain vulnerable to adversarial queries and the unlearned knowledge\nresurfaces after the manually designed attack queries. As part of a red-team\neffort to proactively assess the vulnerabilities of unlearned models, we design\nDynamic Unlearning Attack (DUA), a dynamic and automated framework to attack\nthese models and evaluate their robustness. It optimizes adversarial suffixes\nto reintroduce the unlearned knowledge in various scenarios. We find that\nunlearned knowledge can be recovered in $55.2\\%$ of the questions, even without\nrevealing the unlearned model's parameters. In response to this vulnerability,\nwe propose Latent Adversarial Unlearning (LAU), a universal framework that\neffectively enhances the robustness of the unlearned process. It formulates the\nunlearning process as a min-max optimization problem and resolves it through\ntwo stages: an attack stage, where perturbation vectors are trained and added\nto the latent space of LLMs to recover the unlearned knowledge, and a defense\nstage, where previously trained perturbation vectors are used to enhance\nunlearned model's robustness. With our LAU framework, we obtain two robust\nunlearning methods, AdvGA and AdvNPO. We conduct extensive experiments across\nmultiple unlearning benchmarks and various models, and demonstrate that they\nimprove the unlearning effectiveness by over $53.5\\%$, cause only less than a\n$11.6\\%$ reduction in neighboring knowledge, and have almost no impact on the\nmodel's general capabilities.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)中知识遗忘的脆弱性，提出了一种对抗框架，以评估和提升遗忘过程的鲁棒性。首先，设计了Dynamic Unlearning Attack (DUA)，一个动态框架，通过优化对抗后缀来攻击模型，发现遗忘知识在55.2%的查询中可被恢复。其次，引入Latent Adversarial Unlearning (LAU)框架，将遗忘过程转化为min-max优化问题，通过攻击阶段训练扰动向量和防御阶段增强鲁棒性，从而衍生出AdvGA和AdvNPO方法。实验显示，LAU显著提高了遗忘效果超过53.5%，对相邻知识的影响不到11.6%，并几乎不影响模型的整体能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.10682v1",
      "published_date": "2024-08-20 09:36:04 UTC",
      "updated_date": "2024-08-20 09:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:09:24.211713"
    },
    {
      "arxiv_id": "2408.11875v1",
      "title": "Hierarchical Retrieval-Augmented Generation Model with Rethink for Multi-hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoming Zhang",
        "Ming Wang",
        "Xiaocui Yang",
        "Daling Wang",
        "Shi Feng",
        "Yifei Zhang"
      ],
      "abstract": "Multi-hop Question Answering (QA) necessitates complex reasoning by\nintegrating multiple pieces of information to resolve intricate questions.\nHowever, existing QA systems encounter challenges such as outdated information,\ncontext window length limitations, and an accuracy-quantity trade-off. To\naddress these issues, we propose a novel framework, the Hierarchical\nRetrieval-Augmented Generation Model with Rethink (HiRAG), comprising\nDecomposer, Definer, Retriever, Filter, and Summarizer five key modules. We\nintroduce a new hierarchical retrieval strategy that incorporates both sparse\nretrieval at the document level and dense retrieval at the chunk level,\neffectively integrating their strengths. Additionally, we propose a\nsingle-candidate retrieval method to mitigate the limitations of\nmulti-candidate retrieval. We also construct two new corpora, Indexed\nWikicorpus and Profile Wikicorpus, to address the issues of outdated and\ninsufficient knowledge.\n  Our experimental results on four datasets demonstrate that HiRAG outperforms\nstate-of-the-art models across most metrics, and our Indexed Wikicorpus is\neffective. The code for HiRAG is available at\nhttps://github.com/2282588541a/HiRAG",
      "tldr_zh": "本文针对多跳问答 (Multi-hop Question Answering) 的复杂推理挑战，提出了一种新型框架 Hierarchical Retrieval-Augmented Generation Model with Rethink (HiRAG)，它包括 Decomposer, Definer, Retriever, Filter 和 Summarizer 等五个关键模块。HiRAG 采用分层检索策略，结合文档级别的 sparse retrieval 和块级别的 dense retrieval，同时引入单候选检索方法，以解决过时信息和上下文窗口限制等问题。研究者构建了 Indexed Wikicorpus 和 Profile Wikicorpus 两个新语料库，并在四个数据集上实验表明，HiRAG 在大多数指标上优于最先进模型。代码已开源，可从 GitHub 获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "undereview",
      "pdf_url": "http://arxiv.org/pdf/2408.11875v1",
      "published_date": "2024-08-20 09:29:31 UTC",
      "updated_date": "2024-08-20 09:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:09:37.577561"
    },
    {
      "arxiv_id": "2408.10669v2",
      "title": "Tensor tree learns hidden relational structures in data to construct generative models",
      "title_zh": "翻译失败",
      "authors": [
        "Kenji Harada",
        "Tsuyoshi Okubo",
        "Naoki Kawashima"
      ],
      "abstract": "Based on the tensor tree network with the Born machine framework, we propose\na general method for constructing a generative model by expressing the target\ndistribution function as the amplitude of the quantum wave function represented\nby a tensor tree. The key idea is dynamically optimizing the tree structure\nthat minimizes the bond mutual information. The proposed method offers enhanced\nperformance and uncovers hidden relational structures in the target data. We\nillustrate potential practical applications with four examples: (i) random\npatterns, (ii) QMNIST handwritten digits, (iii) Bayesian networks, and (iv) the\npattern of stock price fluctuation pattern in S&P500. In (i) and (ii), the\nstrongly correlated variables were concentrated near the center of the network;\nin (iii), the causality pattern was identified; and in (iv), a structure\ncorresponding to the eleven sectors emerged.",
      "tldr_zh": "本研究基于张量树网络（tensor tree network）和 Born machine 框架，提出了一种通用方法，通过将目标分布函数表示为张量树表示的量子波函数幅度，来构建生成模型。关键想法是动态优化树结构以最小化键互信息（bond mutual information），从而提升模型性能并揭示数据中的隐藏关系结构。在四个实际示例中，包括随机模式、QMNIST 手写数字、Bayesian 网络和 S&P500 股票价格波动模式，该方法成功识别了如强相关变量集中、因果模式和行业结构等隐藏关系。总的来说，此方法为理解复杂数据提供了新颖的工具，具有广泛的应用潜力。",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10669v2",
      "published_date": "2024-08-20 09:11:38 UTC",
      "updated_date": "2025-04-03 03:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:09:48.731241"
    },
    {
      "arxiv_id": "2408.10668v3",
      "title": "Probing the Safety Response Boundary of Large Language Models via Unsafe Decoding Path Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Wang",
        "Bingzhe Wu",
        "Yatao Bian",
        "Yongzhe Chang",
        "Xueqian Wang",
        "Peilin Zhao"
      ],
      "abstract": "Large Language Models (LLMs) are implicit troublemakers. While they provide\nvaluable insights and assist in problem-solving, they can also potentially\nserve as a resource for malicious activities. Implementing safety alignment\ncould mitigate the risk of LLMs generating harmful responses. We argue that:\neven when an LLM appears to successfully block harmful queries, there may still\nbe hidden vulnerabilities that could act as ticking time bombs. To identify\nthese underlying weaknesses, we propose to use a cost value model as both a\ndetector and an attacker. Trained on external or self-generated harmful\ndatasets, the cost value model could successfully influence the original safe\nLLM to output toxic content in decoding process. For instance, LLaMA-2-chat 7B\noutputs 39.18% concrete toxic content, along with only 22.16% refusals without\nany harmful suffixes. These potential weaknesses can then be exploited via\nprompt optimization such as soft prompts on images. We name this decoding\nstrategy: Jailbreak Value Decoding (JVD), emphasizing that seemingly secure\nLLMs may not be as safe as we initially believe. They could be used to gather\nharmful data or launch covert attacks.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的安全响应边界，揭示即使经过安全对齐，LLMs 仍可能存在隐藏漏洞。研究提出使用一个成本价值模型（cost value model），通过训练外部或自生成的有害数据集，作为检测器和攻击器来影响 LLMs 的解码过程，从而诱导模型输出有害内容，例如 LLaMA-2-chat 7B 在实验中输出 39.18% 具体有害内容，仅有 22.16% 拒绝响应。作者将此策略命名为 Jailbreak Value Decoding (JVD)，并通过提示优化（如软提示 on images）来利用这些弱点，强调 LLMs 可能被用于收集有害数据或发起隐蔽攻击。实验结果为提升 LLMs 的安全性提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10668v3",
      "published_date": "2024-08-20 09:11:21 UTC",
      "updated_date": "2024-08-26 05:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:10:02.103820"
    },
    {
      "arxiv_id": "2408.10657v1",
      "title": "ETGuard: Malicious Encrypted Traffic Detection in Blockchain-based Power Grid Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Zhou",
        "Yongdong Liu",
        "Lixun Ma",
        "Weiye Zhang",
        "Haohan Tan",
        "Zhenguang Liu",
        "Butian Huang"
      ],
      "abstract": "The escalating prevalence of encryption protocols has led to a concomitant\nsurge in the number of malicious attacks that hide in encrypted traffic. Power\ngrid systems, as fundamental infrastructure, are becoming prime targets for\nsuch attacks. Conventional methods for detecting malicious encrypted packets\ntypically use a static pre-trained model. We observe that these methods are not\nwell-suited for blockchain-based power grid systems. More critically, they fall\nshort in dynamic environments where new types of encrypted attacks continuously\nemerge. Motivated by this, in this paper we try to tackle these challenges from\ntwo aspects: (1) We present a novel framework that is able to automatically\ndetect malicious encrypted traffic in blockchain-based power grid systems and\nincrementally learn from new malicious traffic. (2) We mathematically derive\nincremental learning losses to resist the forgetting of old attack patterns\nwhile ensuring the model is capable of handling new encrypted attack patterns.\nEmpirically, our method achieves state-of-the-art performance on three\ndifferent benchmark datasets. We also constructed the first malicious encrypted\ntraffic dataset for blockchain-based power grid scenario. Our code and dataset\nare available at https://github.com/PPPmzt/ETGuard, hoping to inspire future\nresearch.",
      "tldr_zh": "这篇论文提出ETGuard框架，用于检测区块链-based电力系统中的恶意加密流量，解决传统静态模型在动态攻击环境下的局限性。该框架能自动识别恶意流量并通过增量学习机制逐步适应新攻击模式，同时数学推导增量学习损失函数，以防止遗忘旧攻击特征。实验结果显示，ETGuard在三个基准数据集上达到最先进性能，并首次构建并公开了区块链-based电力场景的恶意加密流量数据集，促进未来研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10657v1",
      "published_date": "2024-08-20 08:53:42 UTC",
      "updated_date": "2024-08-20 08:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:10:13.280875"
    },
    {
      "arxiv_id": "2408.10652v2",
      "title": "Vocabulary-Free 3D Instance Segmentation with Vision and Language Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Guofeng Mei",
        "Luigi Riz",
        "Yiming Wang",
        "Fabio Poiesi"
      ],
      "abstract": "Most recent 3D instance segmentation methods are open vocabulary, offering a\ngreater flexibility than closed-vocabulary methods. Yet, they are limited to\nreasoning within a specific set of concepts, \\ie the vocabulary, prompted by\nthe user at test time. In essence, these models cannot reason in an open-ended\nfashion, i.e., answering \"List the objects in the scene.''. We introduce the\nfirst method to address 3D instance segmentation in a setting that is void of\nany vocabulary prior, namely a vocabulary-free setting. We leverage a large\nvision-language assistant and an open-vocabulary 2D instance segmenter to\ndiscover and ground semantic categories on the posed images. To form 3D\ninstance mask, we first partition the input point cloud into dense superpoints,\nwhich are then merged into 3D instance masks. We propose a novel superpoint\nmerging strategy via spectral clustering, accounting for both mask coherence\nand semantic coherence that are estimated from the 2D object instance masks. We\nevaluate our method using ScanNet200 and Replica, outperforming existing\nmethods in both vocabulary-free and open-vocabulary settings. Code will be made\navailable. Project page: https://gfmei.github.io/PoVo",
      "tldr_zh": "本文提出了一种词汇无关(Vocabulary-Free)3D实例分割方法，使用视觉语言助手(Vision and Language Assistant)和开放词汇2D实例分割器来发现并定位语义类别，从而实现开放式场景推理，如列出场景中的物体。方法首先将输入点云分区成密集超点(dense superpoints)，然后通过光谱聚类(Spectral Clustering)合并这些超点，结合掩码一致性(mask coherence)和语义一致性(semantic coherence)来生成3D实例掩码。该方法在ScanNet200和Replica数据集上表现出色，优于现有方法，并在词汇无关和开放词汇设置中均取得领先性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 3DV",
      "pdf_url": "http://arxiv.org/pdf/2408.10652v2",
      "published_date": "2024-08-20 08:46:54 UTC",
      "updated_date": "2025-03-28 07:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:10:26.414903"
    },
    {
      "arxiv_id": "2408.10649v1",
      "title": "Inferring Underwater Topography with FINN",
      "title_zh": "使用 FINN 推断水下地形",
      "authors": [
        "Coşku Can Horuz",
        "Matthias Karlbauer",
        "Timothy Praditia",
        "Sergey Oladyshkin",
        "Wolfgang Nowak",
        "Sebastian Otte"
      ],
      "abstract": "Spatiotemporal partial differential equations (PDEs) find extensive\napplication across various scientific and engineering fields. While numerous\nmodels have emerged from both physics and machine learning (ML) communities,\nthere is a growing trend towards integrating these approaches to develop hybrid\narchitectures known as physics-aware machine learning models. Among these, the\nfinite volume neural network (FINN) has emerged as a recent addition. FINN has\nproven to be particularly efficient in uncovering latent structures in data. In\nthis study, we explore the capabilities of FINN in tackling the shallow-water\nequations, which simulates wave dynamics in coastal regions. Specifically, we\ninvestigate FINN's efficacy to reconstruct underwater topography based on these\nparticular wave equations. Our findings reveal that FINN exhibits a remarkable\ncapacity to infer topography solely from wave dynamics, distinguishing itself\nfrom both conventional ML and physics-aware ML models. Our results underscore\nthe potential of FINN in advancing our understanding of spatiotemporal\nphenomena and enhancing parametrization capabilities in related domains.",
      "tldr_zh": "本研究探讨了finite volume neural network (FINN) 在处理spatiotemporal partial differential equations (PDEs) 方面的能力，特别是应用于浅水方程以模拟沿海波浪动态。研究重点在于使用FINN从波浪动态数据中重建水下地形，展示了其独特优势，能够仅凭这些动态推断潜在结构，而优于传统机器学习和物理感知ML模型。结果表明，FINN显著提升了对时空现象的理解，并为相关领域的参数化能力提供了新潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph",
        "physics.comp-ph",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10649v1",
      "published_date": "2024-08-20 08:42:00 UTC",
      "updated_date": "2024-08-20 08:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:10:47.506739"
    },
    {
      "arxiv_id": "2408.10647v1",
      "title": "Privacy-preserving Universal Adversarial Defense for Black-box Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Li",
        "Cong Wu",
        "Jing Chen",
        "Zijun Zhang",
        "Kun He",
        "Ruiying Du",
        "Xinxin Wang",
        "Qingchuang Zhao",
        "Yang Liu"
      ],
      "abstract": "Deep neural networks (DNNs) are increasingly used in critical applications\nsuch as identity authentication and autonomous driving, where robustness\nagainst adversarial attacks is crucial. These attacks can exploit minor\nperturbations to cause significant prediction errors, making it essential to\nenhance the resilience of DNNs. Traditional defense methods often rely on\naccess to detailed model information, which raises privacy concerns, as model\nowners may be reluctant to share such data. In contrast, existing black-box\ndefense methods fail to offer a universal defense against various types of\nadversarial attacks. To address these challenges, we introduce DUCD, a\nuniversal black-box defense method that does not require access to the target\nmodel's parameters or architecture. Our approach involves distilling the target\nmodel by querying it with data, creating a white-box surrogate while preserving\ndata privacy. We further enhance this surrogate model using a certified defense\nbased on randomized smoothing and optimized noise selection, enabling robust\ndefense against a broad range of adversarial attacks. Comparative evaluations\nbetween the certified defenses of the surrogate and target models demonstrate\nthe effectiveness of our approach. Experiments on multiple image classification\ndatasets show that DUCD not only outperforms existing black-box defenses but\nalso matches the accuracy of white-box defenses, all while enhancing data\nprivacy and reducing the success rate of membership inference attacks.",
      "tldr_zh": "这篇论文提出了 DUCD，一种隐私保护的通用黑盒防御方法，用于提升深度神经网络 (DNNs) 对对抗攻击的鲁棒性，而无需访问目标模型的参数或架构。方法通过查询数据对目标模型进行蒸馏，创建白盒代理模型，并结合随机平滑 (randomized smoothing) 和优化噪声选择来增强防御能力，从而实现对多种对抗攻击的通用防护。实验结果显示，DUCD 在多个图像分类数据集上优于现有黑盒防御方法，达到了白盒防御的准确性，同时提升了数据隐私并显著降低了成员推理攻击 (membership inference attacks) 的成功率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10647v1",
      "published_date": "2024-08-20 08:40:39 UTC",
      "updated_date": "2024-08-20 08:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:10:49.790807"
    },
    {
      "arxiv_id": "2408.10646v1",
      "title": "Beneath the Surface of Consistency: Exploring Cross-lingual Knowledge Representation Sharing in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Maxim Ifergan",
        "Leshem Choshen",
        "Roee Aharoni",
        "Idan Szpektor",
        "Omri Abend"
      ],
      "abstract": "The veracity of a factoid is largely independent of the language it is\nwritten in. However, language models are inconsistent in their ability to\nanswer the same factual question across languages. This raises questions about\nhow LLMs represent a given fact across languages. We explore multilingual\nfactual knowledge through two aspects: the model's ability to answer a query\nconsistently across languages, and the ability to ''store'' answers in a shared\nrepresentation for several languages. We propose a methodology to measure the\nextent of representation sharing across languages by repurposing knowledge\nediting methods. We examine LLMs with various multilingual configurations using\na new multilingual dataset. We reveal that high consistency does not\nnecessarily imply shared representation, particularly for languages with\ndifferent scripts. Moreover, we find that script similarity is a dominant\nfactor in representation sharing. Finally, we observe that if LLMs could fully\nshare knowledge across languages, their accuracy in their best-performing\nlanguage could benefit an increase of up to 150\\% on average. These findings\nhighlight the need for improved multilingual knowledge representation in LLMs\nand suggest a path for the development of more robust and consistent\nmultilingual LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在多语言环境中处理事实知识的跨语言表示共享问题，发现LLMs在不同语言中回答相同查询时往往不一致。研究者提出了一种基于知识编辑方法的评估框架，并使用新多语言数据集，测量模型在语言间共享知识表示的程度。结果显示，高一致性并不意味着共享表示，尤其是对于使用不同脚本的语言，而脚本相似性是关键影响因素；如果LLMs能完全实现知识共享，其最佳语言的准确率可能平均提高150%。这些发现强调了改进多语言知识表示的必要性，以开发更可靠的多语言LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10646v1",
      "published_date": "2024-08-20 08:38:30 UTC",
      "updated_date": "2024-08-20 08:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:11:01.564779"
    },
    {
      "arxiv_id": "2408.10642v1",
      "title": "Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Xie",
        "Hong Chen",
        "Fred Yu",
        "Zeye Sun",
        "Xiuyu Wu"
      ],
      "abstract": "Instruct LLM provide a paradigm used in large scale language model to align\nLLM to human preference. The paradigm contains supervised fine tuning and\nreinforce learning from human feedback. This paradigm is also used in\ndownstream scenarios to adapt LLM to specific corpora and applications.\nComparing to SFT, there are many efforts focused on RLHF and several algorithms\nbeing proposed, such as PPO, DPO, IPO, KTO, MinorDPO and etc. Meanwhile most\nefforts for SFT are focused on how to collect, filter and mix high quality\ndata. In this article with insight from DPO and MinorDPO, we propose a training\nmetric for SFT to measure the discrepancy between the optimized model and the\noriginal model, and a loss function MinorSFT that can increase the training\neffectiveness, and reduce the discrepancy between the optimized LLM and\noriginal LLM.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)的微调，提出了一种新的监督微调(SFT)损失函数MinorSFT，以提升性能并减少模型偏差。论文从Direct Preference Optimization(DPO)和MinorDPO的启发出发，定义了一个训练指标来量化优化模型与原始模型之间的差异，从而指导SFT过程。相比传统SFT，该方法不仅提高了训练效果，还能更好地适应特定语料和应用，同时减少模型偏移。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10642v1",
      "published_date": "2024-08-20 08:32:44 UTC",
      "updated_date": "2024-08-20 08:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:11:14.800830"
    },
    {
      "arxiv_id": "2408.10641v3",
      "title": "A Review of Human-Object Interaction Detection",
      "title_zh": "人-物体交互检测的综述",
      "authors": [
        "Yuxiao Wang",
        "Yu Lei",
        "Li Cui",
        "Weiying Xue",
        "Qi Liu",
        "Zhenao Wei"
      ],
      "abstract": "Human-object interaction (HOI) detection plays a key role in high-level\nvisual understanding, facilitating a deep comprehension of human activities.\nSpecifically, HOI detection aims to locate the humans and objects involved in\ninteractions within images or videos and classify the specific interactions\nbetween them. The success of this task is influenced by several key factors,\nincluding the accurate localization of human and object instances, as well as\nthe correct classification of object categories and interaction relationships.\nThis paper systematically summarizes and discusses the recent work in\nimage-based HOI detection. First, the mainstream datasets involved in HOI\nrelationship detection are introduced. Furthermore, starting with two-stage\nmethods and end-to-end one-stage detection approaches, this paper\ncomprehensively discusses the current developments in image-based HOI\ndetection, analyzing the strengths and weaknesses of these two methods.\nAdditionally, the advancements of zero-shot learning, weakly supervised\nlearning, and the application of large-scale language models in HOI detection\nare discussed. Finally, the current challenges in HOI detection are outlined,\nand potential research directions and future trends are explored.",
      "tldr_zh": "这篇论文回顾了 Human-Object Interaction (HOI) 检测技术，该技术在高级视觉理解中发挥关键作用，通过定位图像或视频中的人类和物体实例，并分类它们的交互关系来加深对人类活动的理解。论文系统介绍了主流数据集，并讨论了当前的两阶段方法和端到端一阶段检测方法，包括这些方法的优势、劣势，以及零-shot learning、弱监督学习和大规模语言模型在 HOI 检测中的最新进展。最后，它概述了现有挑战，并探索了潜在的研究方向和未来趋势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 2024 2nd International Conference on Computer, Vision and\n  Intelligent Technology (ICCVIT)",
      "pdf_url": "http://arxiv.org/pdf/2408.10641v3",
      "published_date": "2024-08-20 08:32:39 UTC",
      "updated_date": "2025-03-18 02:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:11:25.321590"
    },
    {
      "arxiv_id": "2408.10635v2",
      "title": "Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Light",
        "Min Cai",
        "Weiqin Chen",
        "Guanzhi Wang",
        "Xiusi Chen",
        "Wei Cheng",
        "Yisong Yue",
        "Ziniu Hu"
      ],
      "abstract": "In this paper, we propose a new method STRATEGIST that utilizes LLMs to\nacquire new skills for playing multi-agent games through a self-improvement\nprocess. Our method gathers quality feedback through self-play simulations with\nMonte Carlo tree search and LLM-based reflection, which can then be used to\nlearn high-level strategic skills such as how to evaluate states that guide the\nlow-level execution. We showcase how our method can be used in both action\nplanning and dialogue generation in the context of games, achieving good\nperformance on both tasks. Specifically, we demonstrate that our method can\nhelp train agents with better performance than both traditional reinforcement\nlearning-based approaches and other LLM-based skill learning approaches in\ngames including the Game of Pure Strategy (GOPS) and The Resistance: Avalon.\nSTRATEGIST helps bridge the gap between foundation models and symbolic\ndecision-making methods through its bi-level approach, leading to more robust\ndecision-making.",
      "tldr_zh": "本研究提出了一种名为 Strategist 的方法，利用大型语言模型 (LLMs) 通过双层树搜索 (bi-Level Tree Search) 实现多智能体游戏中的技能自提升。方法通过自玩模拟、Monte Carlo tree search 和 LLM-based reflection 收集高质量反馈，以学习高层战略技能，如状态评估来指导底层执行。实验结果显示，Strategist 在行动规划和对话生成任务上表现出色，在 Game of Pure Strategy (GOPS) 和 The Resistance: Avalon 等游戏中，性能优于传统强化学习方法和其他 LLM-based 技能学习方法。该方法桥接了基础模型与符号决策方法，提升了决策的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "website: https://llm-strategist.github.io",
      "pdf_url": "http://arxiv.org/pdf/2408.10635v2",
      "published_date": "2024-08-20 08:22:04 UTC",
      "updated_date": "2024-10-12 03:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:11:37.564077"
    },
    {
      "arxiv_id": "2408.10631v1",
      "title": "LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yupeng Su",
        "Ziyi Guan",
        "Xiaoqun Liu",
        "Tianlai Jin",
        "Dongkuan Wu",
        "Graziano Chesi",
        "Ngai Wong",
        "Hao Yu"
      ],
      "abstract": "Large language models (LLMs) have grown significantly in scale, leading to a\ncritical need for efficient model pruning techniques. Existing post-training\npruning techniques primarily focus on measuring weight importance on converged\ndense models to determine salient weights to retain. However, they often\noverlook the changes in weight importance during the pruning process, which can\nlead to performance degradation in the pruned models. To address this issue, we\npresent LLM-Barber (Block-Aware Rebuilder for Sparsity Mask in One-Shot), a\nnovel one-shot pruning framework that rebuilds the sparsity mask of pruned\nmodels without any retraining or weight reconstruction. LLM-Barber incorporates\nblock-aware error optimization across Self-Attention and MLP blocks, ensuring\nglobal performance optimization. Inspired by the recent discovery of prominent\noutliers in LLMs, LLM-Barber introduces an innovative pruning metric that\nidentifies weight importance using weights multiplied by gradients. Our\nexperiments show that LLM-Barber can efficiently prune models like LLaMA and\nOPT families with 7B to 13B parameters on a single A100 GPU in just 30 minutes,\nachieving state-of-the-art results in both perplexity and zero-shot performance\nacross various language benchmarks. Code is available at\nhttps://github.com/YupengSu/LLM-Barber.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的修剪问题，提出了一种新型框架LLM-Barber（Block-Aware Rebuilder for Sparsity Mask in One-Shot），它能够在无需重新训练或权重重建的情况下，通过重建稀疏掩码来优化模型性能。LLM-Barber引入block-aware error optimization，针对Self-Attention和MLP块进行全局优化，并采用一种基于权重乘以梯度的新修剪指标来识别关键权重。实验结果显示，该框架能在单A100 GPU上仅用30分钟修剪LLaMA和OPT系列模型（7B至13B参数），在perplexity和zero-shot性能上实现最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10631v1",
      "published_date": "2024-08-20 08:13:52 UTC",
      "updated_date": "2024-08-20 08:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:11:48.908863"
    },
    {
      "arxiv_id": "2408.10628v1",
      "title": "Finding the DeepDream for Time Series: Activation Maximization for Univariate Time Series",
      "title_zh": "为时间序列寻找 DeepDream：单变量时间序列的激活最大化",
      "authors": [
        "Udo Schlegel",
        "Daniel A. Keim",
        "Tobias Sutter"
      ],
      "abstract": "Understanding how models process and interpret time series data remains a\nsignificant challenge in deep learning to enable applicability in\nsafety-critical areas such as healthcare. In this paper, we introduce Sequence\nDreaming, a technique that adapts Activation Maximization to analyze sequential\ninformation, aiming to enhance the interpretability of neural networks\noperating on univariate time series. By leveraging this method, we visualize\nthe temporal dynamics and patterns most influential in model decision-making\nprocesses. To counteract the generation of unrealistic or excessively noisy\nsequences, we enhance Sequence Dreaming with a range of regularization\ntechniques, including exponential smoothing. This approach ensures the\nproduction of sequences that more accurately reflect the critical features\nidentified by the neural network. Our approach is tested on a time series\nclassification dataset encompassing applications in predictive maintenance. The\nresults show that our proposed Sequence Dreaming approach demonstrates targeted\nactivation maximization for different use cases so that either centered class\nor border activation maximization can be generated. The results underscore the\nversatility of Sequence Dreaming in uncovering salient temporal features\nlearned by neural networks, thereby advancing model transparency and\ntrustworthiness in decision-critical domains.",
      "tldr_zh": "本研究提出 Sequence Dreaming 技术，将 Activation Maximization 方法适应于单变量时间序列分析，以提升神经网络对时间序列数据的可解释性。该方法通过可视化时间动态和影响决策的关键模式，帮助理解模型处理顺序信息的过程；同时，引入正则化技术如指数平滑，以避免生成不现实或噪声序列，确保输出更准确地反映神经网络的关键特征。在时间序列分类数据集上的实验显示，Sequence Dreaming 能针对不同用例实现目标激活最大化（如中心类或边界激活），从而提高模型在预测维护等安全关键领域的透明度和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, accepted at TempXAI @ ECML-PKDD",
      "pdf_url": "http://arxiv.org/pdf/2408.10628v1",
      "published_date": "2024-08-20 08:09:44 UTC",
      "updated_date": "2024-08-20 08:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:12:00.889977"
    },
    {
      "arxiv_id": "2408.10624v1",
      "title": "WRIM-Net: Wide-Ranging Information Mining Network for Visible-Infrared Person Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Yonggan Wu",
        "Ling-Chao Meng",
        "Yuan Zichao",
        "Sixian Chan",
        "Hong-Qiang Wang"
      ],
      "abstract": "For the visible-infrared person re-identification (VI-ReID) task, one of the\nprimary challenges lies in significant cross-modality discrepancy. Existing\nmethods struggle to conduct modality-invariant information mining. They often\nfocus solely on mining singular dimensions like spatial or channel, and\noverlook the extraction of specific-modality multi-dimension information. To\nfully mine modality-invariant information across a wide range, we introduce the\nWide-Ranging Information Mining Network (WRIM-Net), which mainly comprises a\nMulti-dimension Interactive Information Mining (MIIM) module and an\nAuxiliary-Information-based Contrastive Learning (AICL) approach. Empowered by\nthe proposed Global Region Interaction (GRI), MIIM comprehensively mines\nnon-local spatial and channel information through intra-dimension interaction.\nMoreover, Thanks to the low computational complexity design, separate MIIM can\nbe positioned in shallow layers, enabling the network to better mine\nspecific-modality multi-dimension information. AICL, by introducing the novel\nCross-Modality Key-Instance Contrastive (CMKIC) loss, effectively guides the\nnetwork in extracting modality-invariant information. We conduct extensive\nexperiments not only on the well-known SYSU-MM01 and RegDB datasets but also on\nthe latest large-scale cross-modality LLCM dataset. The results demonstrate\nWRIM-Net's superiority over state-of-the-art methods.",
      "tldr_zh": "本文针对可见-红外人重新识别(VI-ReID)任务中的跨模态差异问题，提出了一种广范围信息挖掘网络(WRIM-Net)，旨在全面挖掘模态不变信息。WRIM-Net 包括多维度交互信息挖掘(MIIM)模块（利用全局区域交互(GRI)处理非局部空间和通道信息）和基于辅助信息的对比学习(AICL)方法（通过跨模态关键实例对比损失(CMKIC loss)引导提取模态不变特征）。实验结果显示，该网络在 SYSU-MM01、RegDB 和 LLCM 数据集上均优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10624v1",
      "published_date": "2024-08-20 08:06:16 UTC",
      "updated_date": "2024-08-20 08:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:12:14.767827"
    },
    {
      "arxiv_id": "2408.10619v2",
      "title": "Hierarchical Attention Diffusion Networks with Object Priors for Video Change Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Kiruluta",
        "Eric Lundy",
        "Andreas Lemos"
      ],
      "abstract": "We present a unified change detection pipeline that combines instance level\nmasking, multi\\-scale attention within a denoising diffusion model, and per\npixel semantic classification, all refined via SSIM to match human perception.\nBy first isolating only temporally novel objects with Mask R\\-CNN, then guiding\ndiffusion updates through hierarchical cross attention to object and global\ncontexts, and finally categorizing each pixel into one of C change types, our\nmethod delivers detailed, interpretable multi\\-class maps. It outperforms\ntraditional differencing, Siamese CNNs, and GAN\\-based detectors by 10\\-25\npoints in F1 and IoU on both synthetic and real world benchmarks, marking a new\nstate of the art in remote sensing change detection.",
      "tldr_zh": "该论文提出了一种基于Hierarchical Attention Diffusion Networks with Object Priors的视频变更检测框架，该框架结合实例级掩码（使用Mask R-CNN隔离时间新颖对象）、多尺度注意力和去噪扩散模型，通过分层交叉注意引导对象和全局上下文更新，并利用SSIM匹配人类感知来实现每个像素的多类语义分类。相比传统差异法、Siamese CNNs和GAN-based检测器，该方法在合成和真实世界基准上，F1和IoU分数提升10-25点，生成更详细且可解释的变更地图。整体pipeline标志着远程感应变更检测领域的全新最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10619v2",
      "published_date": "2024-08-20 07:54:08 UTC",
      "updated_date": "2025-04-26 14:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:12:26.543487"
    },
    {
      "arxiv_id": "2408.10618v2",
      "title": "OMEGA: Efficient Occlusion-Aware Navigation for Air-Ground Robot in Dynamic Environments via State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Junming Wang",
        "Xiuxian Guan",
        "Zekai Sun",
        "Tianxiang Shen",
        "Dong Huang",
        "Fangming Liu",
        "Heming Cui"
      ],
      "abstract": "Air-ground robots (AGRs) are widely used in surveillance and disaster\nresponse due to their exceptional mobility and versatility (i.e., flying and\ndriving). Current AGR navigation systems perform well in static occlusion-prone\nenvironments (e.g., indoors) by using 3D semantic occupancy networks to predict\nocclusions for complete local mapping and then computing Euclidean Signed\nDistance Field (ESDF) for path planning. However, these systems face challenges\nin dynamic, severe occlusion scenes (e.g., crowds) due to limitations in\nperception networks' low prediction accuracy and path planners' high\ncomputation overhead. In this paper, we propose OMEGA, which contains OccMamba\nwith an Efficient AGR-Planner to address the above-mentioned problems. OccMamba\nadopts a novel architecture that separates semantic and occupancy prediction\ninto independent branches, incorporating two mamba blocks within these\nbranches. These blocks efficiently extract semantic and geometric features in\n3D environments with linear complexity, ensuring that the network can learn\nlong-distance dependencies to improve prediction accuracy. Semantic and\ngeometric features are combined within the Bird's Eye View (BEV) space to\nminimise computational overhead during feature fusion. The resulting semantic\noccupancy map is then seamlessly integrated into the local map, providing\nocclusion awareness of the dynamic environment. Our AGR-Planner utilizes this\nlocal map and employs kinodynamic A* search and gradient-based trajectory\noptimization to guarantee planning is ESDF-free and energy-efficient. Extensive\nexperiments demonstrate that OccMamba outperforms the state-of-the-art 3D\nsemantic occupancy network with 25.0% mIoU. End-to-end navigation experiments\nin dynamic scenes verify OMEGA's efficiency, achieving a 96% average planning\nsuccess rate. Code and video are available at\nhttps://jmwang0117.github.io/OMEGA/.",
      "tldr_zh": "该研究提出 OMEGA 系统，利用 State Space Model 提升空地机器人（AGRs）在动态环境的遮挡感知导航性能，解决现有方法的预测准确性和计算开销问题。OMEGA 包括 OccMamba 模块，该模块将语义和占用预测分离为独立分支，并采用 mamba 块在 Bird's Eye View (BEV) 空间提取特征，从而高效学习长距离依赖并减少特征融合开销；同时，Efficient AGR-Planner 通过 kinodynamic A* 搜索和梯度优化，确保路径规划无 Euclidean Signed Distance Field (ESDF) 依赖且能量高效。实验结果表明，OccMamba 比最先进 3D 语义占用网络提高 25.0% mIoU，OMEGA 在动态场景中实现 96% 的平均规划成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to IEEE RA-L | OccMamba is here!",
      "pdf_url": "http://arxiv.org/pdf/2408.10618v2",
      "published_date": "2024-08-20 07:50:29 UTC",
      "updated_date": "2024-12-05 06:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:12:40.622743"
    },
    {
      "arxiv_id": "2408.10614v1",
      "title": "Generalizable Facial Expression Recognition",
      "title_zh": "可泛化的面部表情识别",
      "authors": [
        "Yuhang Zhang",
        "Xiuqi Zheng",
        "Chenyi Liang",
        "Jiani Hu",
        "Weihong Deng"
      ],
      "abstract": "SOTA facial expression recognition (FER) methods fail on test sets that have\ndomain gaps with the train set. Recent domain adaptation FER methods need to\nacquire labeled or unlabeled samples of target domains to fine-tune the FER\nmodel, which might be infeasible in real-world deployment. In this paper, we\naim to improve the zero-shot generalization ability of FER methods on different\nunseen test sets using only one train set. Inspired by how humans first detect\nfaces and then select expression features, we propose a novel FER pipeline to\nextract expression-related features from any given face images. Our method is\nbased on the generalizable face features extracted by large models like CLIP.\nHowever, it is non-trivial to adapt the general features of CLIP for specific\ntasks like FER. To preserve the generalization ability of CLIP and the high\nprecision of the FER model, we design a novel approach that learns sigmoid\nmasks based on the fixed CLIP face features to extract expression features. To\nfurther improve the generalization ability on unseen test sets, we separate the\nchannels of the learned masked features according to the expression classes to\ndirectly generate logits and avoid using the FC layer to reduce overfitting. We\nalso introduce a channel-diverse loss to make the learned masks separated.\nExtensive experiments on five different FER datasets verify that our method\noutperforms SOTA FER methods by large margins. Code is available in\nhttps://github.com/zyh-uaiaaaa/Generalizable-FER.",
      "tldr_zh": "本文针对面部表情识别(FER)方法的零样本泛化问题，提出一种新管道，仅使用一个训练集即可在不同未见测试集上提升性能。受人类面部检测启发，该方法基于CLIP提取的通用面部特征，通过学习sigmoid masks来提取表情相关特征，并引入通道分离机制直接生成logits以减少过拟合。作者还设计了channel-diverse loss，使掩码特征更具多样性。实验在五个FER数据集上显示，该方法大幅超过SOTA方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10614v1",
      "published_date": "2024-08-20 07:48:45 UTC",
      "updated_date": "2024-08-20 07:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:12:50.590829"
    },
    {
      "arxiv_id": "2408.10608v1",
      "title": "Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory",
      "title_zh": "在大型语言模型中促进平等：基于贝叶斯理论识别和缓解隐性偏差",
      "authors": [
        "Yongxin Deng",
        "Xihe Qiu",
        "Xiaoyu Tan",
        "Jing Pan",
        "Chen Jue",
        "Zhijun Fang",
        "Yinghui Xu",
        "Wei Chu",
        "Yuan Qi"
      ],
      "abstract": "Large language models (LLMs) are trained on extensive text corpora, which\ninevitably include biased information. Although techniques such as Affective\nAlignment can mitigate some negative impacts of these biases, existing\nprompt-based attack methods can still extract these biases from the model's\nweights. Moreover, these biases frequently appear subtly when LLMs are prompted\nto perform identical tasks across different demographic groups, thereby\ncamouflaging their presence. To address this issue, we have formally defined\nthe implicit bias problem and developed an innovative framework for bias\nremoval based on Bayesian theory, Bayesian-Theory based Bias Removal (BTBR).\nBTBR employs likelihood ratio screening to pinpoint data entries within\npublicly accessible biased datasets that represent biases inadvertently\nincorporated during the LLM training phase. It then automatically constructs\nrelevant knowledge triples and expunges bias information from LLMs using model\nediting techniques. Through extensive experimentation, we have confirmed the\npresence of the implicit bias problem in LLMs and demonstrated the\neffectiveness of our BTBR approach.",
      "tldr_zh": "该研究探讨了大型语言模型（Large Language Models, LLMs）中隐性偏见（Implicit Bias）的问题，这些偏见源于训练语料并可能通过提示攻击被提取。作者基于Bayesian Theory提出了一种创新框架Bayesian-Theory based Bias Removal (BTBR)，利用似然比筛选（Likelihood Ratio Screening）识别偏见数据，并通过构建知识三元组和模型编辑技术自动移除这些偏见。实验结果证实了LLMs中隐性偏见的存在，并证明BTBR框架在促进模型公平性方面有效。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10608v1",
      "published_date": "2024-08-20 07:40:12 UTC",
      "updated_date": "2024-08-20 07:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:13:01.295804"
    },
    {
      "arxiv_id": "2408.10605v5",
      "title": "MUSES: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration",
      "title_zh": "MUSES：通过多模态代理协作实现3D可控图像生成",
      "authors": [
        "Yanbo Ding",
        "Shaobin Zhuang",
        "Kunchang Li",
        "Zhengrong Yue",
        "Yu Qiao",
        "Yali Wang"
      ],
      "abstract": "Despite recent advancements in text-to-image generation, most existing\nmethods struggle to create images with multiple objects and complex spatial\nrelationships in the 3D world. To tackle this limitation, we introduce a\ngeneric AI system, namely MUSES, for 3D-controllable image generation from user\nqueries. Specifically, our MUSES addresses this challenging task by developing\na progressive workflow with three key components, including (1) Layout Manager\nfor 2D-to-3D layout lifting, (2) Model Engineer for 3D object acquisition and\ncalibration, (3) Image Artist for 3D-to-2D image rendering. By mimicking the\ncollaboration of human professionals, this multi-modal agent pipeline\nfacilitates the effective and automatic creation of images with 3D-controllable\nobjects, through an explainable integration of top-down planning and bottom-up\ngeneration. Additionally, we find that existing benchmarks lack detailed\ndescriptions of complex 3D spatial relationships of multiple objects. To fill\nthis gap, we further construct a new benchmark of T2I-3DisBench (3D image\nscene), which describes diverse 3D image scenes with 50 detailed prompts.\nExtensive experiments show the state-of-the-art performance of MUSES on both\nT2I-CompBench and T2I-3DisBench, outperforming recent strong competitors such\nas DALL-E 3 and Stable Diffusion 3. These results demonstrate a significant\nstep of MUSES forward in bridging natural language, 2D image generation, and 3D\nworld. Our codes are available at the following link:\nhttps://github.com/DINGYANB/MUSES.",
      "tldr_zh": "该研究引入了MUSES系统，一种通过多模态代理协作实现3D可控图像生成的框架，旨在解决现有文本到图像方法在处理多对象和复杂3D空间关系时的局限性。MUSES采用渐进式工作流，包括Layout Manager负责2D到3D布局提升、Model Engineer处理3D对象获取和校准，以及Image Artist进行3D到2D图像渲染，从而模仿人类专业协作，实现可解释的图像生成。研究者还构建了新基准T2I-3DisBench，以详细描述多样化的3D场景；实验结果显示，MUSES在T2I-CompBench和T2I-3DisBench上优于DALL-E 3和Stable Diffusion 3，标志着在自然语言、2D图像生成与3D世界之间的重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.10605v5",
      "published_date": "2024-08-20 07:37:23 UTC",
      "updated_date": "2024-12-16 02:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:13:13.887014"
    },
    {
      "arxiv_id": "2408.10604v2",
      "title": "Multilingual Non-Factoid Question Answering with Answer Paragraph Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Ritwik Mishra",
        "Sreeram Vennam",
        "Rajiv Ratn Shah",
        "Ponnurangam Kumaraguru"
      ],
      "abstract": "Most existing Question Answering Datasets (QuADs) primarily focus on\nfactoid-based short-context Question Answering (QA) in high-resource languages.\nHowever, the scope of such datasets for low-resource languages remains limited,\nwith only a few works centered on factoid-based QuADs and none on non-factoid\nQuADs. Therefore, this work presents MuNfQuAD, a multilingual QuAD with\nnon-factoid questions. It utilizes interrogative sub-headings from BBC news\narticles as questions and the corresponding paragraphs as silver answers. The\ndataset comprises over 578K QA pairs across 38 languages, encompassing several\nlow-resource languages, and stands as the largest multilingual QA dataset to\ndate. Based on the manual annotations of 790 QA-pairs from MuNfQuAD (golden\nset), we observe that 98\\% of questions can be answered using their\ncorresponding silver answer. Our fine-tuned Answer Paragraph Selection (APS)\nmodel outperforms the baselines. The APS model attained an accuracy of 80\\% and\n72\\%, as well as a macro F1 of 72\\% and 66\\%, on the MuNfQuAD testset and the\ngolden set, respectively. Furthermore, the APS model effectively generalizes a\ncertain language within the golden set, even after being fine-tuned on silver\nlabels. We also observe that the fine-tuned APS model is beneficial for\nreducing the context of a question. These findings suggest that this resource\nwould be a valuable contribution to the QA research community.",
      "tldr_zh": "本文提出MuNfQuAD，这是一个多语言非事实型Question Answering (QA)数据集，包含超过578K QA对，覆盖38种语言，包括多个低资源语言，是目前最大的此类数据集。该数据集基于BBC新闻文章的疑问式子标题作为问题，对应段落作为silver答案，通过手动标注的790对QA（golden set）验证，98%的问答可从对应答案中获取。研究微调了Answer Paragraph Selection (APS)模型，该模型在MuNfQuAD测试集上达到80%的准确率和72%的宏F1，优于基线，并在golden set上显示出良好的泛化能力。这些发现表明，MuNfQuAD及其APS模型可显著减少问题上下文，并为QA研究社区提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Shorter version accepted into DSFA, a special session in PAKDD 2025,\n  Sydney",
      "pdf_url": "http://arxiv.org/pdf/2408.10604v2",
      "published_date": "2024-08-20 07:37:06 UTC",
      "updated_date": "2025-02-19 17:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:13:26.947060"
    },
    {
      "arxiv_id": "2408.10602v1",
      "title": "MV-MOS: Multi-View Feature Fusion for 3D Moving Object Segmentation",
      "title_zh": "MV-MOS：多视图特征融合用于3D移动物体分割",
      "authors": [
        "Jintao Cheng",
        "Xingming Chen",
        "Jinxin Liang",
        "Xiaoyu Tang",
        "Xieyuanli Chen",
        "Dachuan Li"
      ],
      "abstract": "Effectively summarizing dense 3D point cloud data and extracting motion\ninformation of moving objects (moving object segmentation, MOS) is crucial to\nautonomous driving and robotics applications. How to effectively utilize motion\nand semantic features and avoid information loss during 3D-to-2D projection is\nstill a key challenge. In this paper, we propose a novel multi-view MOS model\n(MV-MOS) by fusing motion-semantic features from different 2D representations\nof point clouds. To effectively exploit complementary information, the motion\nbranches of the proposed model combines motion features from both bird's eye\nview (BEV) and range view (RV) representations. In addition, a semantic branch\nis introduced to provide supplementary semantic features of moving objects.\nFinally, a Mamba module is utilized to fuse the semantic features with motion\nfeatures and provide effective guidance for the motion branches. We validated\nthe effectiveness of the proposed multi-branch fusion MOS framework via\ncomprehensive experiments, and our proposed model outperforms existing\nstate-of-the-art models on the SemanticKITTI benchmark.",
      "tldr_zh": "该论文提出MV-MOS模型，用于从密集3D点云数据中提取移动物体的运动信息（Moving Object Segmentation, MOS），以支持自动驾驶和机器人应用。模型通过融合鸟瞰视图(BEV)和范围视图(RV)的运动特征，以及语义分支提供的补充语义特征，并利用Mamba模块进行有效特征融合，从而解决信息丢失和特征利用的挑战。实验结果表明，MV-MOS在SemanticKITTI基准上超越了现有最先进模型，验证了多视图特征融合框架的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10602v1",
      "published_date": "2024-08-20 07:30:00 UTC",
      "updated_date": "2024-08-20 07:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:13:38.185911"
    },
    {
      "arxiv_id": "2408.10600v1",
      "title": "Breast tumor classification based on self-supervised contrastive learning from ultrasound videos",
      "title_zh": "基于超声视频的自我监督对比学习乳腺肿瘤分类",
      "authors": [
        "Yunxin Tang",
        "Siyuan Tang",
        "Jian Zhang",
        "Hao Chen"
      ],
      "abstract": "Background: Breast ultrasound is prominently used in diagnosing breast\ntumors. At present, many automatic systems based on deep learning have been\ndeveloped to help radiologists in diagnosis. However, training such systems\nremains challenging because they are usually data-hungry and demand amounts of\nlabeled data, which need professional knowledge and are expensive. Methods: We\nadopted a triplet network and a self-supervised contrastive learning technique\nto learn representations from unlabeled breast ultrasound video clips. We\nfurther designed a new hard triplet loss to to learn representations that\nparticularly discriminate positive and negative image pairs that are hard to\nrecognize. We also constructed a pretraining dataset from breast ultrasound\nvideos (1,360 videos from 200 patients), which includes an anchor sample\ndataset with 11,805 images, a positive sample dataset with 188,880 images, and\na negative sample dataset dynamically generated from video clips. Further, we\nconstructed a finetuning dataset, including 400 images from 66 patients. We\ntransferred the pretrained network to a downstream benign/malignant\nclassification task and compared the performance with other state-of-the-art\nmodels, including three models pretrained on ImageNet and a previous\ncontrastive learning model retrained on our datasets. Results and conclusion:\nExperiments revealed that our model achieved an area under the receiver\noperating characteristic curve (AUC) of 0.952, which is significantly higher\nthan the others. Further, we assessed the dependence of our pretrained model on\nthe number of labeled data and revealed that <100 samples were required to\nachieve an AUC of 0.901. The proposed framework greatly reduces the demand for\nlabeled data and holds potential for use in automatic breast ultrasound image\ndiagnosis.",
      "tldr_zh": "本研究提出了一种基于自-supervised contrastive learning 的乳腺肿瘤分类方法，利用三元组网络（triplet network）从未标注的乳腺超声视频中学习图像表示，特别设计了 hard triplet loss 来区分难识别的正负样本对。研究构建了预训练数据集（包括1,360个视频的11,805个锚点样本和188,880个正样本）及微调数据集（400张图像），并将预训练模型转移到良/恶性分类任务。实验结果显示，该模型在ROC曲线下面积（AUC）达到0.952，显著优于基于ImageNet的基准模型，且仅需少于100个标注样本即可实现AUC 0.901，大大降低了数据标注需求，并为自动乳腺超声诊断提供了潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10600v1",
      "published_date": "2024-08-20 07:16:01 UTC",
      "updated_date": "2024-08-20 07:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:13:51.557871"
    },
    {
      "arxiv_id": "2408.10592v1",
      "title": "Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams",
      "title_zh": "翻译失败",
      "authors": [
        "Litian Huang",
        "Xinguo Yu",
        "Feng Xiong",
        "Bin He",
        "Shengbing Tang",
        "Jiawen Fu"
      ],
      "abstract": "Solving Algebra Problems with Geometry Diagrams (APGDs) is still a\nchallenging problem because diagram processing is not studied as intensively as\nlanguage processing. To work against this challenge, this paper proposes a\nhologram reasoning scheme and develops a high-performance method for solving\nAPGDs by using this scheme. To reach this goal, it first defines a hologram,\nbeing a kind of graph, and proposes a hologram generator to convert a given\nAPGD into a hologram, which represents the entire information of APGD and the\nrelations for solving the problem can be acquired from it by a uniform way.\nThen HGR, a hologram reasoning method employs a pool of prepared graph models\nto derive algebraic equations, which is consistent with the geometric theorems.\nThis method is able to be updated by adding new graph models into the pool.\nLastly, it employs deep reinforcement learning to enhance the efficiency of\nmodel selection from the pool. The entire HGR not only ensures high solution\naccuracy with fewer reasoning steps but also significantly enhances the\ninterpretability of the solution process by providing descriptions of all\nreasoning steps. Experimental results demonstrate the effectiveness of HGR in\nimproving both accuracy and interpretability in solving APGDs.",
      "tldr_zh": "该论文针对解决带有几何图形的代数问题（APGDs）的挑战，提出了一种全息图（Hologram）推理方案，以统一方式处理图形和代数关系。首先，论文定义了全息图作为一种图结构，并开发了全息图生成器和HGR方法，利用一池预备的图模型推导出与几何定理一致的代数方程，同时通过深度强化学习优化模型选择过程。该方法显著提高了解决APGDs的准确性和可解释性，提供详细的推理步骤描述，实验结果验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10592v1",
      "published_date": "2024-08-20 07:10:05 UTC",
      "updated_date": "2024-08-20 07:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:14:05.238709"
    },
    {
      "arxiv_id": "2408.10573v2",
      "title": "Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter",
      "title_zh": "让 LLMs 站在人们的立场：通过问题重写器生成更好的答案",
      "authors": [
        "Junhao Chen",
        "Bowen Wang",
        "Zhouqiang Jiang",
        "Yuta Nakashima"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities,\nparticularly in the domain of question answering (QA). However, their\neffectiveness in QA is often undermined by the vagueness of user questions. To\naddress this issue, we introduce single-round instance-level prompt\noptimization, referred to as question rewriter. By enhancing the\nintelligibility of human questions for black-box LLMs, our question rewriter\nimproves the quality of generated answers. The rewriter is optimized using\ndirect preference optimization based on feedback collected from automatic\ncriteria for evaluating generated answers; therefore, its training does not\nrequire costly human annotations. The experiments across multiple black-box\nLLMs and long-form question answering (LFQA) datasets demonstrate the efficacy\nof our method. This paper provides a practical framework for training question\nrewriters and sets a precedent for future explorations in prompt optimization\nwithin LFQA tasks. Code is available at\nhttps://github.com/3244we/Question-Rewriter.",
      "tldr_zh": "这篇论文提出了一种名为 question rewriter 的单轮实例级提示优化方法，以提升大型语言模型（LLMs）在问答（QA）任务中的表现，特别是针对用户问题模糊性的问题。方法通过增强问题可理解性来生成更高质量的答案，并采用 direct preference optimization 基于自动反馈进行训练，从而避免了昂贵的人类标注。实验结果显示，该框架在多个黑箱 LLMs 和长形式问答（LFQA）数据集上表现出色，并为未来 LFQA 任务中的提示优化提供了实用框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 4 figures, 5 tables and accepted at AAAI 2025 Main\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2408.10573v2",
      "published_date": "2024-08-20 06:24:47 UTC",
      "updated_date": "2025-02-25 03:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:14:16.030519"
    },
    {
      "arxiv_id": "2408.10572v1",
      "title": "A Tutorial on Explainable Image Classification for Dementia Stages Using Convolutional Neural Network and Gradient-weighted Class Activation Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Kam Fung Yuen"
      ],
      "abstract": "This paper presents a tutorial of an explainable approach using Convolutional\nNeural Network (CNN) and Gradient-weighted Class Activation Mapping (Grad-CAM)\nto classify four progressive dementia stages based on open MRI brain images.\nThe detailed implementation steps are demonstrated with an explanation. Whilst\nthe proposed CNN architecture is demonstrated to achieve more than 99% accuracy\nfor the test dataset, the computational procedure of CNN remains a black box.\nThe visualisation based on Grad-CAM is attempted to explain such very high\naccuracy and may provide useful information for physicians. Future motivation\nbased on this work is discussed.",
      "tldr_zh": "这篇论文教程介绍了使用 Convolutional Neural Network (CNN) 和 Gradient-weighted Class Activation Mapping (Grad-CAM) 的可解释方法，来基于公开 MRI 脑部图像分类四种渐进性痴呆阶段，并详细演示了实现步骤。\n提出的 CNN 架构在测试数据集上实现了超过 99% 的准确率，但其计算过程仍为黑盒。\n通过 Grad-CAM 的可视化技术，论文解释了高准确率的决策过程，并为医生提供潜在的临床参考信息，同时讨论了未来研究的动机。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 11 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.10572v1",
      "published_date": "2024-08-20 06:23:20 UTC",
      "updated_date": "2024-08-20 06:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:14:28.016655"
    },
    {
      "arxiv_id": "2408.10571v4",
      "title": "Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models",
      "title_zh": "针对定制扩散模型的提示无关对抗性扰动",
      "authors": [
        "Cong Wan",
        "Yuhang He",
        "Xiang Song",
        "Yihong Gong"
      ],
      "abstract": "Diffusion models have revolutionized customized text-to-image generation,\nallowing for efficient synthesis of photos from personal data with textual\ndescriptions. However, these advancements bring forth risks including privacy\nbreaches and unauthorized replication of artworks. Previous researches\nprimarily center around using prompt-specific methods to generate adversarial\nexamples to protect personal images, yet the effectiveness of existing methods\nis hindered by constrained adaptability to different prompts. In this paper, we\nintroduce a Prompt-Agnostic Adversarial Perturbation (PAP) method for\ncustomized diffusion models. PAP first models the prompt distribution using a\nLaplace Approximation, and then produces prompt-agnostic perturbations by\nmaximizing a disturbance expectation based on the modeled distribution. This\napproach effectively tackles the prompt-agnostic attacks, leading to improved\ndefense stability. Extensive experiments in face privacy and artistic style\nprotection, demonstrate the superior generalization of PAP in comparison to\nexisting techniques. Our project page is available at\nhttps://github.com/vancyland/Prompt-Agnostic-Adversarial-Perturbation-for-Customized-Diffusion-Models.github.io.",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）在定制化文本到图像生成中的隐私泄露和艺术品 unauthorized replication 风险，提出了一种 Prompt-Agnostic Adversarial Perturbation (PAP) 方法，以解决现有 prompt-specific 方法的适应性不足问题。PAP 通过使用 Laplace Approximation 建模提示词分布，并最大化基于该分布的 disturbance expectation，生成对不同提示词均有效的对抗扰动，从而提升防御的稳定性和泛化能力。在面部隐私和艺术风格保护的广泛实验中，PAP 展示了比现有技术更优的性能，为保护个性化生成模型提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10571v4",
      "published_date": "2024-08-20 06:17:56 UTC",
      "updated_date": "2024-10-10 06:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:14:40.087213"
    },
    {
      "arxiv_id": "2408.10567v1",
      "title": "Prompt Your Brain: Scaffold Prompt Tuning for Efficient Adaptation of fMRI Pre-trained Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Dong",
        "Yilei Wu",
        "Zijiao Chen",
        "Yichi Zhang",
        "Yueming Jin",
        "Juan Helen Zhou"
      ],
      "abstract": "We introduce Scaffold Prompt Tuning (ScaPT), a novel prompt-based framework\nfor adapting large-scale functional magnetic resonance imaging (fMRI)\npre-trained models to downstream tasks, with high parameter efficiency and\nimproved performance compared to fine-tuning and baselines for prompt tuning.\nThe full fine-tuning updates all pre-trained parameters, which may distort the\nlearned feature space and lead to overfitting with limited training data which\nis common in fMRI fields. In contrast, we design a hierarchical prompt\nstructure that transfers the knowledge learned from high-resource tasks to\nlow-resource ones. This structure, equipped with a Deeply-conditioned\nInput-Prompt (DIP) mapping module, allows for efficient adaptation by updating\nonly 2% of the trainable parameters. The framework enhances semantic\ninterpretability through attention mechanisms between inputs and prompts, and\nit clusters prompts in the latent space in alignment with prior knowledge.\nExperiments on public resting state fMRI datasets reveal ScaPT outperforms\nfine-tuning and multitask-based prompt tuning in neurodegenerative diseases\ndiagnosis/prognosis and personality trait prediction, even with fewer than 20\nparticipants. It highlights ScaPT's efficiency in adapting pre-trained fMRI\nmodels to low-resource tasks.",
      "tldr_zh": "我们引入了 Scaffold Prompt Tuning (ScaPT)，一种高效的提示调优框架，用于适应 fMRI 预训练模型到下游任务，仅更新 2% 的可训练参数，从而避免全微调导致的特征空间扭曲和过拟合问题。该框架采用分层提示结构和 Deeply-conditioned Input-Prompt (DIP) 映射模块，从高资源任务转移知识，并通过注意力机制增强语义可解释性，同时在潜在空间中聚类提示以对齐先验知识。实验在公共 fMRI 数据集上显示，ScaPT 在神经退行性疾病诊断、预后和个性特征预测任务中，优于全微调和多任务提示调优，即使样本少于 20 个，突显其在低资源场景下的高效适应能力。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10567v1",
      "published_date": "2024-08-20 06:08:37 UTC",
      "updated_date": "2024-08-20 06:08:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:14:56.430965"
    },
    {
      "arxiv_id": "2408.10566v4",
      "title": "Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqing Zhao",
        "Divya Saxena",
        "Jiannong Cao",
        "Xiaoyun Liu",
        "Changlin Song"
      ],
      "abstract": "In continual learning (CL), model growth enhances adaptability over new data,\nimproving knowledge retention for more tasks. However, improper model growth\ncan lead to severe degradation of previously learned knowledge, an issue we\nname as growth-induced forgetting (GIFt), especially in task-agnostic CL using\nentire grown model for inference. Existing works, despite adopting model growth\nand random initialization for better adaptability, often fail to recognize the\npresence of GIFt caused by improper model growth. This oversight limits\ncomprehensive control of forgetting and hinders full utilization of model\ngrowth. We are the first in CL to identify this issue and conduct an in-depth\nstudy on root cause of GIFt, where layer expansion stands out among model\ngrowth strategies, widening layers without affecting model functionality. Yet,\ndirect adoption of layer expansion presents challenges. It lacks data-driven\ncontrol and initialization of expanded parameters to balance adaptability and\nknowledge retention. This paper presents a novel SparseGrow approach to\novercome the issue of GIFt while enhancing adaptability over new data.\nSparseGrow employs data-driven sparse layer expansion to control efficient\nparameter usage during growth, reducing GIFt from excessive growth and\nfunctionality changes. It also combines sparse growth with on-data\ninitialization at training late-stage to create partially 0-valued expansions\nthat fit learned distribution, enhancing retention and adaptability. To further\nminimize forgetting, freezing is applied by calculating the sparse mask,\nallowing data-driven preservation of important parameters. Through experiments\nacross datasets with various settings, cases, and task numbers, we demonstrate\nthe necessity of layer expansion and showcase the effectiveness of SparseGrow\nin overcoming GIFt, highlighting its adaptability and knowledge retention for\nincremental tasks.",
      "tldr_zh": "在任务无关的持续学习（Task-Agnostic Continual Learning）中，论文首次识别了增长诱导遗忘（GIFt）问题，即不当的模型增长导致先前知识的严重退化，并深入分析了层扩展（Layer Expansion）作为根因之一。针对这一问题，提出SparseGrow方法，通过数据驱动的稀疏层扩展、基于数据的初始化和参数冻结策略，控制参数使用并平衡适应性和知识保留。实验在多种数据集和任务设置下证明，SparseGrow 有效克服了GIFt，提升了模型对新数据的适应性并显著提高了知识保留能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10566v4",
      "published_date": "2024-08-20 06:05:52 UTC",
      "updated_date": "2024-09-27 06:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:15:04.830242"
    },
    {
      "arxiv_id": "2408.10563v1",
      "title": "The Stable Model Semantics for Higher-Order Logic Programming",
      "title_zh": "高阶逻辑编程的稳定模型语义",
      "authors": [
        "Bart Bogaerts",
        "Angelos Charalambidis",
        "Giannos Chatziagapis",
        "Babis Kostopoulos",
        "Samuele Pollaci",
        "Panos Rondogiannis"
      ],
      "abstract": "We propose a stable model semantics for higher-order logic programs. Our\nsemantics is developed using Approximation Fixpoint Theory (AFT), a powerful\nformalism that has successfully been used to give meaning to diverse\nnon-monotonic formalisms. The proposed semantics generalizes the classical\ntwo-valued stable model semantics of (Gelfond and Lifschitz 1988) as-well-as\nthe three-valued one of (Przymusinski 1990), retaining their desirable\nproperties. Due to the use of AFT, we also get for free alternative semantics\nfor higher-order logic programs, namely supported model, Kripke-Kleene, and\nwell-founded. Additionally, we define a broad class of stratified higher-order\nlogic programs and demonstrate that they have a unique two-valued higher-order\nstable model which coincides with the well-founded semantics of such programs.\nWe provide a number of examples in different application domains, which\ndemonstrate that higher-order logic programming under the stable model\nsemantics is a powerful and versatile formalism, which can potentially form the\nbasis of novel ASP systems.",
      "tldr_zh": "本研究提出了一种针对更高阶逻辑程序（higher-order logic programs）的稳定模型语义（stable model semantics），基于近似不动点理论（Approximation Fixpoint Theory, AFT）进行开发，以扩展经典的二值和三值稳定模型语义，同时保留其理想属性。  \n该语义不仅提供支持模型（supported model）、Kripke-Kleene 和良基模型（well-founded）等备选解释，还定义了分层更高阶逻辑程序（stratified higher-order logic programs），证明它们具有唯一的二值稳定模型，并与良基语义一致。  \n通过各种应用领域的示例，论文展示了这种语义的强大性和多功能性，有望成为新型答案集编程（ASP）系统的基础。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL",
        "I.2.3; I.2.5; F.3.2"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10563v1",
      "published_date": "2024-08-20 06:03:52 UTC",
      "updated_date": "2024-08-20 06:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:15:16.663729"
    },
    {
      "arxiv_id": "2408.10556v2",
      "title": "Hokoff: Real Game Dataset from Honor of Kings and its Offline Reinforcement Learning Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Qu",
        "Boyuan Wang",
        "Jianzhun Shao",
        "Yuhang Jiang",
        "Chen Chen",
        "Zhenbin Ye",
        "Lin Liu",
        "Junfeng Yang",
        "Lin Lai",
        "Hongyang Qin",
        "Minwen Deng",
        "Juchao Zhuo",
        "Deheng Ye",
        "Qiang Fu",
        "Wei Yang",
        "Guang Yang",
        "Lanxiao Huang",
        "Xiangyang Ji"
      ],
      "abstract": "The advancement of Offline Reinforcement Learning (RL) and Offline\nMulti-Agent Reinforcement Learning (MARL) critically depends on the\navailability of high-quality, pre-collected offline datasets that represent\nreal-world complexities and practical applications. However, existing datasets\noften fall short in their simplicity and lack of realism. To address this gap,\nwe propose Hokoff, a comprehensive set of pre-collected datasets that covers\nboth offline RL and offline MARL, accompanied by a robust framework, to\nfacilitate further research. This data is derived from Honor of Kings, a\nrecognized Multiplayer Online Battle Arena (MOBA) game known for its intricate\nnature, closely resembling real-life situations. Utilizing this framework, we\nbenchmark a variety of offline RL and offline MARL algorithms. We also\nintroduce a novel baseline algorithm tailored for the inherent hierarchical\naction space of the game. We reveal the incompetency of current offline RL\napproaches in handling task complexity, generalization and multi-task learning.",
      "tldr_zh": "这篇论文提出了 Hokoff，一套从 MOBA 游戏 Honor of Kings 收集的真实数据集，用于支持 Offline Reinforcement Learning (Offline RL) 和 Offline Multi-Agent Reinforcement Learning (Offline MARL) 的研究，旨在解决现有数据集的简单性和不真实性问题。Hokoff 提供了一个全面框架，用于基准测试各种算法，并引入了一个针对游戏的层次化动作空间新基线算法。实验结果揭示了当前 Offline RL 方法在处理任务复杂性、泛化和多任务学习方面的不足，为未来研究提供了宝贵资源。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10556v2",
      "published_date": "2024-08-20 05:38:50 UTC",
      "updated_date": "2024-11-22 02:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:15:28.466210"
    },
    {
      "arxiv_id": "2408.10549v1",
      "title": "AI-Based IVR",
      "title_zh": "基于AI的IVR",
      "authors": [
        "Gassyrbek Kosherbay",
        "Nurgissa Apbaz"
      ],
      "abstract": "The use of traditional IVR (Interactive Voice Response) methods often proves\ninsufficient to meet customer needs. This article examines the application of\nartificial intelligence (AI) technologies to enhance the efficiency of IVR\nsystems in call centers. A proposed approach is based on the integration of\nspeech-to-text conversion solutions, text query classification using large\nlanguage models (LLM), and speech synthesis. Special attention is given to\nadapting these technologies to work with the Kazakh language, including\nfine-tuning models on specialized datasets. The practical aspects of\nimplementing the developed system in a real call center for query\nclassification are described. The research results demonstrate that the\napplication of AI technologies in call center IVR systems reduces operator\nworkload, improves customer service quality, and increases the efficiency of\nquery processing. The proposed approach can be adapted for use in call centers\noperating with various languages.",
      "tldr_zh": "本文研究了如何通过人工智能（AI）技术提升交互式语音响应（IVR）系统的效率，以解决传统IVR方法无法充分满足客户需求的问题。提出的方法整合了语音到文本转换、大型语言模型（LLM）用于文本查询分类以及语音合成技术，并针对哈萨克语进行了模型微调，以适应特定数据集。实验结果显示，该系统在真实呼叫中心中减少了操作员工作量、提高了客户服务质量并提升了查询处理效率；此外，该方法可扩展适用于多种语言的呼叫中心。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "in Russian language",
      "pdf_url": "http://arxiv.org/pdf/2408.10549v1",
      "published_date": "2024-08-20 05:04:40 UTC",
      "updated_date": "2024-08-20 05:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:15:39.724934"
    },
    {
      "arxiv_id": "2408.10543v1",
      "title": "Diff-PCC: Diffusion-based Neural Compression for 3D Point Clouds",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Liu",
        "Kang You",
        "Pan Gao"
      ],
      "abstract": "Stable diffusion networks have emerged as a groundbreaking development for\ntheir ability to produce realistic and detailed visual content. This\ncharacteristic renders them ideal decoders, capable of producing high-quality\nand aesthetically pleasing reconstructions. In this paper, we introduce the\nfirst diffusion-based point cloud compression method, dubbed Diff-PCC, to\nleverage the expressive power of the diffusion model for generative and\naesthetically superior decoding. Different from the conventional autoencoder\nfashion, a dual-space latent representation is devised in this paper, in which\na compressor composed of two independent encoding backbones is considered to\nextract expressive shape latents from distinct latent spaces. At the decoding\nside, a diffusion-based generator is devised to produce high-quality\nreconstructions by considering the shape latents as guidance to stochastically\ndenoise the noisy point clouds. Experiments demonstrate that the proposed\nDiff-PCC achieves state-of-the-art compression performance (e.g., 7.711 dB\nBD-PSNR gains against the latest G-PCC standard at ultra-low bitrate) while\nattaining superior subjective quality. Source code will be made publicly\navailable.",
      "tldr_zh": "本文提出Diff-PCC，一种基于扩散模型的神经压缩方法，用于3D点云的生成和高质量重建，旨在利用扩散网络的表达能力提升主观视觉效果。与传统自编码器不同，该方法引入双空间潜在表示（dual-space latent representation），通过两个独立编码主干提取形状潜在表示，并在解码侧使用扩散-based生成器以这些表示作为指导进行随机去噪。实验结果显示，Diff-PCC在压缩性能上达到最先进水平，例如在超低比特率下比G-PCC标准高7.711 dB BD-PSNR，并实现优越的主观质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10543v1",
      "published_date": "2024-08-20 04:55:29 UTC",
      "updated_date": "2024-08-20 04:55:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:15:53.040834"
    },
    {
      "arxiv_id": "2408.10532v2",
      "title": "NutrifyAI: An AI-Powered System for Real-Time Food Detection, Nutritional Analysis, and Personalized Meal Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle Han",
        "Junyao Chen",
        "Zhengyuan Zhou"
      ],
      "abstract": "With diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's not\nsurprise that popular health apps, MyFitnessPal, Noom, and Calorie Counter, are\nsurging in popularity. However, one major setback [2] of nearly all nutrition\napplications is that users must enter food data manually, which is\ntime-consuming and tedious. Thus, there has been an increasing demand for\napplications that can accurately identify food items, analyze their nutritional\ncontent, and offer dietary recommendations in real-time. This paper introduces\na comprehensive system that combines advanced computer vision techniques with\nnutritional analysis, implemented in a versatile mobile and web application.\nThe system is divided into three key concepts: 1) food detection using the\nYOLOv8 model, 2) nutrient analysis via the Edamam Nutrition Analysis API, and\n3) personalized meal recommendations using the Edamam Meal Planning and Recipe\nSearch APIs. Preliminary results showcase the system's effectiveness by\nproviding immediate, accurate dietary insights, with a demonstrated food\nrecognition accuracy of nearly 80%, making it a valuable tool for users to make\ninformed dietary decisions.",
      "tldr_zh": "本研究引入NutrifyAI，一种基于AI的系统，用于实时食物检测、营养分析和个性化餐推荐，以解决传统营养应用中手动输入数据的繁琐问题。该系统整合了计算机视觉技术，包括使用YOLOv8模型进行食物识别，以及Edamam Nutrition Analysis API和Edamam Meal Planning and Recipe Search APIs来实现营养评估和个性化推荐。初步实验显示，该系统在食物识别准确率达到近80%，为用户提供即时准确的饮食洞见，帮助他们做出更明智的健康决策。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10532v2",
      "published_date": "2024-08-20 04:18:53 UTC",
      "updated_date": "2024-10-21 06:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:16:04.398572"
    },
    {
      "arxiv_id": "2408.10527v1",
      "title": "EdgeNAT: Transformer for Efficient Edge Detection",
      "title_zh": "EdgeNAT：用于高效边缘检测的Transformer",
      "authors": [
        "Jinghuai Jie",
        "Yan Guo",
        "Guixing Wu",
        "Junmin Wu",
        "Baojian Hua"
      ],
      "abstract": "Transformers, renowned for their powerful feature extraction capabilities,\nhave played an increasingly prominent role in various vision tasks. Especially,\nrecent advancements present transformer with hierarchical structures such as\nDilated Neighborhood Attention Transformer (DiNAT), demonstrating outstanding\nability to efficiently capture both global and local features. However,\ntransformers' application in edge detection has not been fully exploited. In\nthis paper, we propose EdgeNAT, a one-stage transformer-based edge detector\nwith DiNAT as the encoder, capable of extracting object boundaries and\nmeaningful edges both accurately and efficiently. On the one hand, EdgeNAT\ncaptures global contextual information and detailed local cues with DiNAT, on\nthe other hand, it enhances feature representation with a novel SCAF-MLA\ndecoder by utilizing both inter-spatial and inter-channel relationships of\nfeature maps. Extensive experiments on multiple datasets show that our method\nachieves state-of-the-art performance on both RGB and depth images. Notably, on\nthe widely used BSDS500 dataset, our L model achieves impressive performances,\nwith ODS F-measure and OIS F-measure of 86.0%, 87.6% for multi-scale input,and\n84.9%, and 86.3% for single-scale input, surpassing the current\nstate-of-the-art EDTER by 1.2%, 1.1%, 1.7%, and 1.6%, respectively. Moreover,\nas for throughput, our approach runs at 20.87 FPS on RTX 4090 GPU with\nsingle-scale input. The code for our method will be released soon.",
      "tldr_zh": "本研究提出EdgeNAT，一种基于Transformer的单阶段边缘检测器，使用Dilated Neighborhood Attention Transformer (DiNAT)作为编码器，以高效捕获全局和局部特征。EdgeNAT通过新型SCAF-MLA解码器增强特征表示，利用特征图的跨空间和跨通道关系，实现了对物体边界和有意义边缘的准确提取。在多个数据集上的实验中，EdgeNAT在BSDS500数据集上取得了最先进性能，其L模型在多尺度输入下ODS F-measure和OIS F-measure分别达86.0%和87.6%，单尺度下为84.9%和86.3%，并以20.87 FPS的速度在RTX 4090 GPU上运行，超过了现有方法的EDTER。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10527v1",
      "published_date": "2024-08-20 04:04:22 UTC",
      "updated_date": "2024-08-20 04:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:16:18.835217"
    },
    {
      "arxiv_id": "2408.10524v1",
      "title": "XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xucheng Wan",
        "Naijun Zheng",
        "Kai Liu",
        "Huan Zhou"
      ],
      "abstract": "Contextualized ASR models have been demonstrated to effectively improve the\nrecognition accuracy of uncommon phrases when a predefined phrase list is\navailable. However, these models often struggle with bilingual settings, which\nare prevalent in code-switching speech recognition. In this study, we make the\ninitial attempt to address this challenge by introducing a Cross-lingual\nContextual Biasing(XCB) module. Specifically, we augment a pre-trained ASR\nmodel for the dominant language by integrating an auxiliary language biasing\nmodule and a supplementary language-specific loss, aimed at enhancing the\nrecognition of phrases in the secondary language. Experimental results\nconducted on our in-house code-switching dataset have validated the efficacy of\nour approach, demonstrating significant improvements in the recognition of\nbiasing phrases in the secondary language, even without any additional\ninference overhead. Additionally, our proposed system exhibits both efficiency\nand generalization when is applied by the unseen ASRU-2019 test set.",
      "tldr_zh": "这篇论文提出 XCB 模块，一种有效的上下文偏差方法，用于提升语音识别中跨语言短语的识别准确率，尤其针对 code-switching 场景。XCB 通过在预训练的 ASR 模型中整合辅助语言 biasing 模块和语言特定损失函数，来增强对次要语言短语的识别，而无需额外推理开销。实验结果显示，在内部 code-switching 数据集上，该方法显著改善了次要语言短语的识别性能，并在 ASRU-2019 测试集上展现出高效性和泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted to NCMMSC 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10524v1",
      "published_date": "2024-08-20 04:00:19 UTC",
      "updated_date": "2024-08-20 04:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:16:29.652838"
    },
    {
      "arxiv_id": "2408.10517v5",
      "title": "Integrating Multi-Modal Input Token Mixer Into Mamba-Based Decision Models: Decision MetaMamba",
      "title_zh": "翻译失败",
      "authors": [
        "Wall Kim"
      ],
      "abstract": "Sequence modeling with State Space models (SSMs) has demonstrated performance\nsurpassing that of Transformers in various tasks, raising expectations for\ntheir potential to outperform the Decision Transformer and its enhanced\nvariants in offline reinforcement learning (RL). However, decision models based\non Mamba, a state-of-the-art SSM, failed to achieve superior performance\ncompared to these enhanced Decision Transformers. We hypothesize that this\nlimitation arises from information loss during the selective scanning phase. To\naddress this, we propose the Decision MetaMamba (DMM), which augments Mamba\nwith a token mixer in its input layer. This mixer explicitly accounts for the\nmultimodal nature of offline RL inputs, comprising state, action, and\nreturn-to-go. The DMM demonstrates improved performance while significantly\nreducing parameter count compared to prior models. Notably, similar performance\ngains were achieved using a simple linear token mixer, emphasizing the\nimportance of preserving information from proximate time steps rather than the\nspecific design of the token mixer itself. This novel modification to Mamba's\ninput layer represents a departure from conventional timestamp-based encoding\napproaches used in Transformers. By enhancing performance of Mamba in offline\nRL, characterized by memory efficiency and fast inference, this work opens new\navenues for its broader application in future RL research.",
      "tldr_zh": "本研究发现，基于State Space models (SSMs)如Mamba的决策模型在offline reinforcement learning (RL)中未超过增强的Decision Transformer，主要由于选择性扫描阶段的信息丢失。为解决此问题，提出Decision MetaMamba (DMM)，通过在Mamba的输入层添加多模态输入token mixer来处理状态、动作和return-to-go的多模态输入，从而显著提升性能并减少参数数量。实验结果显示，即使使用简单的线性token mixer也能获得类似收益，强调了保留相邻时间步信息的关键作用，这为Mamba在RL中的高效应用开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We have decided to withdraw this manuscript as we believe that the\n  work requires significant improvements and further research to ensure its\n  quality and impact. We are currently pursuing a more comprehensive approach\n  to address the limitations of the current submission and plan to resubmit an\n  improved version in the future",
      "pdf_url": "http://arxiv.org/pdf/2408.10517v5",
      "published_date": "2024-08-20 03:35:28 UTC",
      "updated_date": "2025-01-09 06:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:16:43.467843"
    },
    {
      "arxiv_id": "2408.10516v1",
      "title": "Data Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyang Qi",
        "Michimasa Inaba"
      ],
      "abstract": "This study addresses the interaction challenges encountered by spoken\ndialogue systems (SDSs) when engaging with users who exhibit distinct\nconversational behaviors, particularly minors, in scenarios where data are\nscarce. We propose a novel data augmentation framework to enhance SDS\nperformance for user groups with limited resources. Our approach leverages a\nlarge language model (LLM) to extract speaker styles and a pre-trained language\nmodel (PLM) to simulate dialogue act history. This method generates enriched\nand personalized dialogue data, facilitating improved interactions with unique\nuser demographics. Extensive experiments validate the efficacy of our\nmethodology, highlighting its potential to foster the development of more\nadaptive and inclusive dialogue systems.",
      "tldr_zh": "本研究针对口语对话系统（SDSs）在与独特用户群体（如未成年人）互动时面临的数据稀缺挑战，提出了一种新型数据增强框架，以提升系统对低资源用户群体的适应性。该框架利用大型语言模型（LLM）提取说话者风格，并结合预训练语言模型（PLM）模拟对话行为历史，生成个性化和丰富的对话数据，从而改善互动效果。实验结果证明，该方法显著提高了对话系统的适应性和包容性，具有促进更具包容性对话系统开发的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SIGDIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10516v1",
      "published_date": "2024-08-20 03:33:04 UTC",
      "updated_date": "2024-08-20 03:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:16:54.545594"
    },
    {
      "arxiv_id": "2408.10512v1",
      "title": "Approximate Estimation of High-dimension Execution Skill for Dynamic Agents in Continuous Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Delma Nieves-Rivera",
        "Christopher Archibald"
      ],
      "abstract": "In many real-world continuous action domains, human agents must decide which\nactions to attempt and then execute those actions to the best of their ability.\nHowever, humans cannot execute actions without error. Human performance in\nthese domains can potentially be improved by the use of AI to aid in\ndecision-making. One requirement for an AI to correctly reason about what\nactions a human agent should attempt is a correct model of that human's\nexecution error, or skill. Recent work has demonstrated successful techniques\nfor estimating this execution error with various types of agents across\ndifferent domains. However, this previous work made several assumptions that\nlimit the application of these ideas to real-world settings. First, previous\nwork assumed that the error distributions were symmetric normal, which meant\nthat only a single parameter had to be estimated. In reality, agent error\ndistributions might exhibit arbitrary shapes and should be modeled more\nflexibly. Second, it was assumed that the execution error of the agent remained\nconstant across all observations. Especially for human agents, execution error\nchanges over time, and this must be taken into account to obtain effective\nestimates. To overcome both of these shortcomings, we propose a novel\nparticle-filter-based estimator for this problem. After describing the details\nof this approximate estimator, we experimentally explore various design\ndecisions and compare performance with previous skill estimators in a variety\nof settings to showcase the improvements. The outcome is an estimator capable\nof generating more realistic, time-varying execution skill estimates of agents,\nwhich can then be used to assist agents in making better decisions and improve\ntheir overall performance.",
      "tldr_zh": "本文提出了一种基于粒子滤波（particle-filter-based）的近似估计器，用于评估高维连续域中动态代理的执行技能（execution skill），以解决传统方法对错误分布假设对称正态且不变的局限性。该估计器能够灵活处理任意形状的错误分布（execution error）和随时间变化的技能，适用于真实世界场景。通过实验探索设计决策并与现有估计器比较，结果显示该方法显著提升了估计准确性，帮助代理在决策中实现更好性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10512v1",
      "published_date": "2024-08-20 03:27:09 UTC",
      "updated_date": "2024-08-20 03:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:17:05.634991"
    },
    {
      "arxiv_id": "2408.10511v3",
      "title": "Single-cell Curriculum Learning-based Deep Graph Embedding Clustering",
      "title_zh": "基于单细胞课程学习的深层图嵌入聚类",
      "authors": [
        "Huifa Li",
        "Jie Fu",
        "Xinpeng Ling",
        "Zhiyu Sun",
        "Kuncan Wang",
        "Zhili Chen"
      ],
      "abstract": "The swift advancement of single-cell RNA sequencing (scRNA-seq) technologies\nenables the investigation of cellular-level tissue heterogeneity. Cell\nannotation significantly contributes to the extensive downstream analysis of\nscRNA-seq data. However, The analysis of scRNA-seq for biological inference\npresents challenges owing to its intricate and indeterminate data distribution,\ncharacterized by a substantial volume and a high frequency of dropout events.\nFurthermore, the quality of training samples varies greatly, and the\nperformance of the popular scRNA-seq data clustering solution GNN could be\nharmed by two types of low-quality training nodes: 1) nodes on the boundary; 2)\nnodes that contribute little additional information to the graph. To address\nthese problems, we propose a single-cell curriculum learning-based deep graph\nembedding clustering (scCLG). We first propose a Chebyshev graph convolutional\nautoencoder with multi-criteria (ChebAE) that combines three optimization\nobjectives, including topology reconstruction loss of cell graphs,\nzero-inflated negative binomial (ZINB) loss, and clustering loss, to learn\ncell-cell topology representation. Meanwhile, we employ a selective training\nstrategy to train GNN based on the features and entropy of nodes and prune the\ndifficult nodes based on the difficulty scores to keep the high-quality graph.\nEmpirical results on a variety of gene expression datasets show that our model\noutperforms state-of-the-art methods. The code of scCLG will be made publicly\navailable at https://github.com/LFD-byte/scCLG.",
      "tldr_zh": "本文提出 scCLG 方法，针对单细胞 RNA 测序 (scRNA-seq) 数据的复杂分布和高 dropout 事件问题，改善 GNN 聚类性能。scCLG 包括 ChebAE 模型，该模型结合拓扑重建损失、ZINB 损失和聚类损失来学习细胞拓扑表示，并通过选择性训练策略基于节点特征和熵筛选高质量节点。实验结果显示，scCLG 在多种基因表达数据集上优于最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10511v3",
      "published_date": "2024-08-20 03:20:13 UTC",
      "updated_date": "2024-11-27 04:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:17:18.114371"
    },
    {
      "arxiv_id": "2408.10504v1",
      "title": "QPO: Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yilun Kong",
        "Hangyu Mao",
        "Qi Zhao",
        "Bin Zhang",
        "Jingqing Ruan",
        "Li Shen",
        "Yongzhe Chang",
        "Xueqian Wang",
        "Rui Zhao",
        "Dacheng Tao"
      ],
      "abstract": "Prompt engineering has demonstrated remarkable success in enhancing the\nperformance of large language models (LLMs) across diverse tasks. However, most\nexisting prompt optimization methods only focus on the task-level performance,\noverlooking the importance of query-preferred prompts, which leads to\nsuboptimal performances. Additionally, these methods rely heavily on frequent\ninteractions with LLMs to obtain feedback for guiding the optimization process,\nincurring substantial redundant interaction costs. In this paper, we introduce\nQuery-dependent Prompt Optimization (QPO), which leverages multi-loop offline\nreinforcement learning to iteratively fine-tune a small pretrained language\nmodel to generate optimal prompts tailored to the input queries, thus\nsignificantly improving the prompting effect on the large target LLM. We derive\ninsights from offline prompting demonstration data, which already exists in\nlarge quantities as a by-product of benchmarking diverse prompts on\nopen-sourced tasks, thereby circumventing the expenses of online interactions.\nFurthermore, we continuously augment the offline dataset with the generated\nprompts in each loop, as the prompts from the fine-tuned model are supposed to\noutperform the source prompts in the original dataset. These iterative loops\nbootstrap the model towards generating optimal prompts. Experiments on various\nLLM scales and diverse NLP and math tasks demonstrate the efficacy and\ncost-efficiency of our method in both zero-shot and few-shot scenarios.",
      "tldr_zh": "该论文提出Query-dependent Prompt Optimization (QPO)方法，利用多循环离线强化学习来微调小型预训练语言模型，从而生成针对特定输入查询的最优提示，提升大型语言模型(LLMs)在各种任务中的性能。QPO从现有的离线提示演示数据中获取洞见，避免了频繁在线交互的高成本，并在每个循环中通过扩充数据集来迭代优化提示生成。实验结果显示，该方法在不同LLM规模、NLP和数学任务的零样本及少样本场景中表现出色，并显著提高了效率和成本效益。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10504v1",
      "published_date": "2024-08-20 03:06:48 UTC",
      "updated_date": "2024-08-20 03:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:17:30.139360"
    },
    {
      "arxiv_id": "2408.10503v1",
      "title": "Adaptive Knowledge Distillation for Classification of Hand Images using Explainable Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Thanh Thi Nguyen",
        "Campbell Wilson",
        "Janis Dalins"
      ],
      "abstract": "Assessing the forensic value of hand images involves the use of unique\nfeatures and patterns present in an individual's hand. The human hand has\ndistinct characteristics, such as the pattern of veins, fingerprints, and the\ngeometry of the hand itself. This paper investigates the use of vision\ntransformers (ViTs) for classification of hand images. We use explainability\ntools to explore the internal representations of ViTs and assess their impact\non the model outputs. Utilizing the internal understanding of ViTs, we\nintroduce distillation methods that allow a student model to adaptively extract\nknowledge from a teacher model while learning on data of a different domain to\nprevent catastrophic forgetting. Two publicly available hand image datasets are\nused to conduct a series of experiments to evaluate performance of the ViTs and\nour proposed adaptive distillation methods. The experimental results\ndemonstrate that ViT models significantly outperform traditional machine\nlearning methods and the internal states of ViTs are useful for explaining the\nmodel outputs in the classification task. By averting catastrophic forgetting,\nour distillation methods achieve excellent performance on data from both source\nand target domains, particularly when these two domains exhibit significant\ndissimilarity. The proposed approaches therefore can be developed and\nimplemented effectively for real-world applications such as access control,\nidentity verification, and authentication systems.",
      "tldr_zh": "本研究探讨了使用可解释的 Vision Transformers (ViTs) 对手部图像进行分类，利用 explainability tools 分析 ViTs 的内部表示及其对模型输出的影响。论文提出了一种自适应知识蒸馏 (Adaptive Knowledge Distillation) 方法，让学生模型从教师模型中提取知识，同时在不同领域的数据上学习，以避免 catastrophic forgetting。实验结果显示，ViTs 显著优于传统机器学习方法，且该蒸馏方法在源域和目标域上均表现出色，尤其在领域差异大的情况下。该方法可有效应用于现实场景，如访问控制、身份验证和认证系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the ECML PKDD 2024 (Research Track)",
      "pdf_url": "http://arxiv.org/pdf/2408.10503v1",
      "published_date": "2024-08-20 03:03:56 UTC",
      "updated_date": "2024-08-20 03:03:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:17:42.070600"
    },
    {
      "arxiv_id": "2408.10499v1",
      "title": "ProgramAlly: Creating Custom Visual Access Programs via Multi-Modal End-User Programming",
      "title_zh": "ProgramAlly：通过多模态终端用户编程创建自定义视觉访问程序",
      "authors": [
        "Jaylin Herskovitz",
        "Andi Xu",
        "Rahaf Alharbi",
        "Anhong Guo"
      ],
      "abstract": "Existing visual assistive technologies are built for simple and common use\ncases, and have few avenues for blind people to customize their\nfunctionalities. Drawing from prior work on DIY assistive technology, this\npaper investigates end-user programming as a means for users to create and\ncustomize visual access programs to meet their unique needs. We introduce\nProgramAlly, a system for creating custom filters for visual information, e.g.,\n'find NUMBER on BUS', leveraging three end-user programming approaches: block\nprogramming, natural language, and programming by example. To implement\nProgramAlly, we designed a representation of visual filtering tasks based on\nscenarios encountered by blind people, and integrated a set of on-device and\ncloud models for generating and running these programs. In user studies with 12\nblind adults, we found that participants preferred different programming\nmodalities depending on the task, and envisioned using visual access programs\nto address unique accessibility challenges that are otherwise difficult with\nexisting applications. Through ProgramAlly, we present an exploration of how\nblind end-users can create visual access programs to customize and control\ntheir experiences.",
      "tldr_zh": "该论文探讨了端用户编程（end-user programming）作为一种让盲人用户创建和自定义视觉访问程序的方法，以解决现有视觉辅助技术（visual assistive technologies）的局限性。研究引入了 ProgramAlly 系统，该系统支持块编程（block programming）、自然语言（natural language）和编程示例（programming by example）三种模式，用于设计视觉信息过滤任务，如“在公交车上找到数字”，并整合设备端和云端模型来生成和运行这些程序。在涉及 12 名盲人成人的用户研究中，发现参与者根据任务偏好不同编程方式，并能通过这些程序解决现有应用难以处理的独特无障碍挑战，从而为盲人定制和控制视觉体验提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.HC",
      "comment": "UIST 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10499v1",
      "published_date": "2024-08-20 02:45:31 UTC",
      "updated_date": "2024-08-20 02:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:17:55.577832"
    },
    {
      "arxiv_id": "2408.10497v2",
      "title": "QUITO-X: A New Perspective on Context Compression from the Information Bottleneck Theory",
      "title_zh": "QUITO-X：基于信息瓶颈理论的上下文压缩新视角",
      "authors": [
        "Yihang Wang",
        "Xu Huang",
        "Bowen Tian",
        "Yueyang Su",
        "Lei Yu",
        "Huaming Liao",
        "Yixing Fan",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Generative LLM have achieved remarkable success in various industrial\napplications, owing to their promising In-Context Learning capabilities.\nHowever, the issue of long context in complex tasks poses a significant barrier\nto their wider adoption, manifested in two main aspects: (i) The excessively\nlong context leads to high costs and inference delays. (ii) A substantial\namount of task-irrelevant information introduced by long contexts exacerbates\nthe \"lost in the middle\" problem. Existing methods compress context by removing\nredundant tokens using metrics such as self-information or PPL, which is\ninconsistent with the objective of retaining the most important tokens when\nconditioning on a given query. In this study, we introduce information\nbottleneck theory (IB) to model the problem, offering a novel perspective that\nthoroughly addresses the essential properties required for context compression.\nAdditionally, we propose a cross-attention-based approach to approximate mutual\ninformation in IB, which can be flexibly replaced with suitable alternatives in\ndifferent scenarios. Extensive experiments on four datasets demonstrate that\nour method achieves a 25% increase in compression rate compared to the\nstate-of-the-art, while maintaining question answering performance. In\nparticular, the context compressed by our method even outperform the full\ncontext in some cases.",
      "tldr_zh": "本文提出 QUITO-X 框架，通过 Information Bottleneck Theory 提供一种新视角来解决 Generative LLM 在长上下文问题中的挑战，包括高成本、推理延迟和“lost in the middle”现象。不同于现有方法基于 self-information 或 PPL 移除冗余 tokens，该方法使用 cross-attention-based approach 来近似 mutual information，实现更有效的上下文压缩，同时保留与查询最相关的关键信息。在四个数据集上的实验显示，QUITO-X 比最先进方法提高了 25% 的压缩率，并在问题回答性能上维持或优于完整上下文表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10497v2",
      "published_date": "2024-08-20 02:44:45 UTC",
      "updated_date": "2024-12-16 15:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:18:07.777815"
    },
    {
      "arxiv_id": "2408.10495v1",
      "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Producers?",
      "title_zh": "翻译失败",
      "authors": [
        "Jianian Gong",
        "Nachuan Duan",
        "Ziheng Tao",
        "Zhaohui Gong",
        "Yuan Yuan",
        "Minlie Huang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) such as GPT-4 has\nrevolutionized the landscape of software engineering, positioning these models\nat the core of modern development practices. As we anticipate these models to\nevolve into the primary and trustworthy tools used in software development,\nensuring the security of the code they produce becomes paramount. How well can\nLLMs serve as end-to-end secure code producers? This paper presents a\nsystematic investigation into LLMs' inherent potential to generate code with\nfewer vulnerabilities. Specifically, We studied GPT-3.5 and GPT-4's capability\nto identify and repair vulnerabilities in the code generated by four popular\nLLMs including themselves (GPT-3.5, GPT-4, Code Llama, and CodeGeeX2). By\nmanually or automatically reviewing 4,900 pieces of code, our study reveals\nthat: (1) large language models lack awareness of scenario-relevant security\nrisks, which leads to the generation of over 75% vulnerable code on the\nSecurityEval benchmark; (2) LLMs such as GPT-3.5 and GPT-4 are unable to\nprecisely identify vulnerabilities in the code they generated; (3) GPT-3.5 and\nGPT-4 can achieve 33.2%~59.6% success rates in repairing the insecure code\nproduced by the 4 LLMs, but they both perform poorly when repairing\nself-produced code, indicating self-repair \"blind spots\". To address the\nlimitation of a single round of repair, we developed a lightweight tool that\nprompts LLMs to construct safer source code through an iterative repair\nprocedure based on the insights gained from our study. Experiments show that\nassisted by semantic analysis engines, our tool significantly improves the\nsuccess rates of repair to 65.9%~85.5%.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）如 GPT-3.5 和 GPT-4 作为端到端安全代码生成器的表现，通过分析这些模型识别和修复由 GPT-3.5、GPT-4、Code Llama 和 CodeGeeX2 生成的代码中的漏洞。结果显示，LLMs 缺乏对场景相关安全风险的意识，导致超过 75% 的代码在 SecurityEval 基准上存在漏洞，且这些模型难以精确识别自身生成的漏洞。论文提出一个基于迭代修复过程的轻量级工具，利用语义分析引擎辅助修复，成功将代码修复率从 33.2%~59.6% 提升至 65.9%~85.5%，揭示了 LLMs 在安全代码生产中的潜力与局限性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10495v1",
      "published_date": "2024-08-20 02:42:29 UTC",
      "updated_date": "2024-08-20 02:42:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:18:20.838665"
    },
    {
      "arxiv_id": "2408.10491v2",
      "title": "Achieving the Tightest Relaxation of Sigmoids for Formal Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Chevalier",
        "Duncan Starkenburg",
        "Krishnamurthy Dvijotham"
      ],
      "abstract": "In the field of formal verification, Neural Networks (NNs) are typically\nreformulated into equivalent mathematical programs which are optimized over. To\novercome the inherent non-convexity of these reformulations, convex relaxations\nof nonlinear activation functions are typically utilized. Common relaxations\n(i.e., static linear cuts) of \"S-shaped\" activation functions, however, can be\noverly loose, slowing down the overall verification process. In this paper, we\nderive tuneable hyperplanes which upper and lower bound the sigmoid activation\nfunction. When tuned in the dual space, these affine bounds smoothly rotate\naround the nonlinear manifold of the sigmoid activation function. This\napproach, termed $\\alpha$-sig, allows us to tractably incorporate the tightest\npossible, element-wise convex relaxation of the sigmoid activation function\ninto a formal verification framework. We embed these relaxations inside of\nlarge verification tasks and compare their performance to LiRPA and\n$\\alpha$-CROWN, a state-of-the-art verification duo.",
      "tldr_zh": "本论文针对形式验证中神经网络的非凸性问题，提出了一种名为 $\\alpha$-sig 的方法，以实现 sigmoid 激活函数的最紧凸松弛。通过在对偶空间中调节可调节超平面（tuneable hyperplanes），该方法能顺畅地围绕 sigmoid 的非线性流形提供精确的上限和下限，从而提升验证过程的效率。实验结果表明，将 $\\alpha$-sig 嵌入大型验证任务中，其性能优于 LiRPA 和 $\\alpha$-CROWN 等现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10491v2",
      "published_date": "2024-08-20 02:22:27 UTC",
      "updated_date": "2024-08-22 00:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:18:32.545835"
    },
    {
      "arxiv_id": "2408.10492v2",
      "title": "Is the Lecture Engaging for Learning? Lecture Voice Sentiment Analysis for Knowledge Graph-Supported Intelligent Lecturing Assistant (ILA) System",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan An",
        "Samarth Kolanupaka",
        "Jacob An",
        "Matthew Ma",
        "Unnat Chhatwal",
        "Alex Kalinowski",
        "Michelle Rogers",
        "Brian Smith"
      ],
      "abstract": "This paper introduces an intelligent lecturing assistant (ILA) system that\nutilizes a knowledge graph to represent course content and optimal pedagogical\nstrategies. The system is designed to support instructors in enhancing student\nlearning through real-time analysis of voice, content, and teaching methods. As\nan initial investigation, we present a case study on lecture voice sentiment\nanalysis, in which we developed a training set comprising over 3,000 one-minute\nlecture voice clips. Each clip was manually labeled as either engaging or\nnon-engaging. Utilizing this dataset, we constructed and evaluated several\nclassification models based on a variety of features extracted from the voice\nclips. The results demonstrate promising performance, achieving an F1-score of\n90% for boring lectures on an independent set of over 800 test voice clips.\nThis case study lays the groundwork for the development of a more sophisticated\nmodel that will integrate content analysis and pedagogical practices. Our\nultimate goal is to aid instructors in teaching more engagingly and effectively\nby leveraging modern artificial intelligence techniques.",
      "tldr_zh": "本文提出了一种基于知识图谱的智能讲课助手(ILA)系统，用于支持教师通过实时分析讲课语音、内容和教学方法来提升学生学习效果。研究首先进行了一个讲课语音情感分析的案例研究，开发了包含超过3,000个一分钟语音片段的数据集，并构建了基于语音特征的分类模型。实验结果显示，该模型在独立测试集（超过800个语音片段）上，对boring lectures的F1-score达到90%。这项工作为未来整合内容分析和教学实践的更复杂模型奠定基础，最终目标是通过人工智能技术帮助教师实现更吸引人和有效的教学。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in the 4th Workshop on Knowledge Graphs and Big Data @ IEEE\n  Big Data Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10492v2",
      "published_date": "2024-08-20 02:22:27 UTC",
      "updated_date": "2024-10-29 17:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:18:45.767752"
    },
    {
      "arxiv_id": "2408.10488v1",
      "title": "Event Stream based Sign Language Translation: A High-Definition Benchmark Dataset and A New Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Yao Rong",
        "Fuling Wang",
        "Jianing Li",
        "Lin Zhu",
        "Bo Jiang",
        "Yaowei Wang"
      ],
      "abstract": "Sign Language Translation (SLT) is a core task in the field of AI-assisted\ndisability. Unlike traditional SLT based on visible light videos, which is\neasily affected by factors such as lighting, rapid hand movements, and privacy\nbreaches, this paper proposes the use of high-definition Event streams for SLT,\neffectively mitigating the aforementioned issues. This is primarily because\nEvent streams have a high dynamic range and dense temporal signals, which can\nwithstand low illumination and motion blur well. Additionally, due to their\nsparsity in space, they effectively protect the privacy of the target person.\nMore specifically, we propose a new high-resolution Event stream sign language\ndataset, termed Event-CSL, which effectively fills the data gap in this area of\nresearch. It contains 14,827 videos, 14,821 glosses, and 2,544 Chinese words in\nthe text vocabulary. These samples are collected in a variety of indoor and\noutdoor scenes, encompassing multiple angles, light intensities, and camera\nmovements. We have benchmarked existing mainstream SLT works to enable fair\ncomparison for future efforts. Based on this dataset and several other\nlarge-scale datasets, we propose a novel baseline method that fully leverages\nthe Mamba model's ability to integrate temporal information of CNN features,\nresulting in improved sign language translation outcomes. Both the benchmark\ndataset and source code will be released on\nhttps://github.com/Event-AHU/OpenESL",
      "tldr_zh": "本论文提出使用高分辨率 Event streams 进行 Sign Language Translation (SLT)，以克服传统可见光视频受照明、快速手部运动和隐私泄露的影响，利用 Event streams 的高动态范围和密集时间信号来提升翻译准确性。研究贡献包括构建了一个新的基准数据集 Event-CSL，包含14,827个视频、14,821个手语词汇和2,544个中文词汇，涵盖多种室内外场景，并对现有主流 SLT 方法进行了基准测试。作者还提出了一种新基线算法，通过 Mamba 模型整合 CNN 特征的时间信息，显著提高了手语翻译效果；数据集和源代码将公开在 GitHub 上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "First Large-scale and High-Definition Benchmark Dataset for\n  Event-based Sign Language Translation",
      "pdf_url": "http://arxiv.org/pdf/2408.10488v1",
      "published_date": "2024-08-20 02:01:30 UTC",
      "updated_date": "2024-08-20 02:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:18:56.289893"
    },
    {
      "arxiv_id": "2408.10487v1",
      "title": "MambaEVT: Event Stream based Visual Object Tracking using State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Chao wang",
        "Shiao Wang",
        "Xixi Wang",
        "Zhicheng Zhao",
        "Lin Zhu",
        "Bo Jiang"
      ],
      "abstract": "Event camera-based visual tracking has drawn more and more attention in\nrecent years due to the unique imaging principle and advantages of low energy\nconsumption, high dynamic range, and dense temporal resolution. Current\nevent-based tracking algorithms are gradually hitting their performance\nbottlenecks, due to the utilization of vision Transformer and the static\ntemplate for target object localization. In this paper, we propose a novel\nMamba-based visual tracking framework that adopts the state space model with\nlinear complexity as a backbone network. The search regions and target template\nare fed into the vision Mamba network for simultaneous feature extraction and\ninteraction. The output tokens of search regions will be fed into the tracking\nhead for target localization. More importantly, we consider introducing a\ndynamic template update strategy into the tracking framework using the Memory\nMamba network. By considering the diversity of samples in the target template\nlibrary and making appropriate adjustments to the template memory module, a\nmore effective dynamic template can be integrated. The effective combination of\ndynamic and static templates allows our Mamba-based tracking algorithm to\nachieve a good balance between accuracy and computational cost on multiple\nlarge-scale datasets, including EventVOT, VisEvent, and FE240hz. The source\ncode will be released on https://github.com/Event-AHU/MambaEVT",
      "tldr_zh": "该论文提出MambaEVT，一种基于事件流的视觉对象跟踪框架，使用State Space Model作为骨干网络，以线性复杂度解决现有算法依赖Vision Transformer和静态模板的性能瓶颈。框架将搜索区域和目标模板输入视觉Mamba网络进行同时特征提取和交互，并通过Memory Mamba网络引入动态模板更新策略，考虑模板库样本多样性以优化跟踪效果。这种动态与静态模板的结合，使MambaEVT在EventVOT、VisEvent和FE240hz等大型数据集上实现了准确性和计算成本的良好平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2408.10487v1",
      "published_date": "2024-08-20 02:01:17 UTC",
      "updated_date": "2024-08-20 02:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:19:11.062834"
    },
    {
      "arxiv_id": "2408.10482v1",
      "title": "Evaluation Framework for AI-driven Molecular Design of Multi-target Drugs: Brain Diseases as a Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Cerveira",
        "Frederico Kremer",
        "Darling de Andrade Lourenço",
        "Ulisses B Corrêa"
      ],
      "abstract": "The widespread application of Artificial Intelligence (AI) techniques has\nsignificantly influenced the development of new therapeutic agents. These\ncomputational methods can be used to design and predict the properties of\ngenerated molecules. Multi-target Drug Discovery (MTDD) is an emerging paradigm\nfor discovering drugs against complex disorders that do not respond well to\nmore traditional target-specific treatments, such as central nervous system,\nimmune system, and cardiovascular diseases. Still, there is yet to be an\nestablished benchmark suite for assessing the effectiveness of AI tools for\ndesigning multi-target compounds. Standardized benchmarks allow for comparing\nexisting techniques and promote rapid research progress. Hence, this work\nproposes an evaluation framework for molecule generation techniques in MTDD\nscenarios, considering brain diseases as a case study. Our methodology involves\nusing large language models to select the appropriate molecular targets,\ngathering and preprocessing the bioassay datasets, training quantitative\nstructure-activity relationship models to predict target modulation, and\nassessing other essential drug-likeness properties for implementing the\nbenchmarks. Additionally, this work will assess the performance of four deep\ngenerative models and evolutionary algorithms over our benchmark suite. In our\nfindings, both evolutionary algorithms and generative models can achieve\ncompetitive results across the proposed benchmarks.",
      "tldr_zh": "这篇论文提出一个评估框架，用于评估AI驱动的多目标药物设计(Multi-target Drug Discovery, MTDD)工具的效能，以脑部疾病作为案例研究。该框架包括使用大型语言模型选择分子目标、收集并预处理生物测定数据集、训练定量结构-活性关系模型(quantitative structure-activity relationship models)来预测目标调控，以及评估药物相似性属性。论文评估了四种深度生成模型和进化算法(evolutionary algorithms)在该基准套件中的表现，结果显示这些方法在多目标化合物设计上取得了竞争性结果。该框架有助于标准化比较现有技术，促进AI在复杂疾病治疗中的快速进展。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages, 1 figure, published in 2024 IEEE Congress on Evolutionary\n  Computation (CEC)",
      "pdf_url": "http://arxiv.org/pdf/2408.10482v1",
      "published_date": "2024-08-20 01:42:16 UTC",
      "updated_date": "2024-08-20 01:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:19:22.506822"
    },
    {
      "arxiv_id": "2408.10479v1",
      "title": "An End-to-End Reinforcement Learning Based Approach for Micro-View Order-Dispatching in Ride-Hailing",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlang Yue",
        "Yiran Liu",
        "Fangzhou Shi",
        "Sihong Luo",
        "Chen Zhong",
        "Min Lu",
        "Zhe Xu"
      ],
      "abstract": "Assigning orders to drivers under localized spatiotemporal context\n(micro-view order-dispatching) is a major task in Didi, as it influences\nride-hailing service experience. Existing industrial solutions mainly follow a\ntwo-stage pattern that incorporate heuristic or learning-based algorithms with\nnaive combinatorial methods, tackling the uncertainty of both sides' behaviors,\nincluding emerging timings, spatial relationships, and travel duration, etc. In\nthis paper, we propose a one-stage end-to-end reinforcement learning based\norder-dispatching approach that solves behavior prediction and combinatorial\noptimization uniformly in a sequential decision-making manner. Specifically, we\nemploy a two-layer Markov Decision Process framework to model this problem, and\npresent \\underline{D}eep \\underline{D}ouble \\underline{S}calable\n\\underline{N}etwork (D2SN), an encoder-decoder structure network to generate\norder-driver assignments directly and stop assignments accordingly. Besides, by\nleveraging contextual dynamics, our approach can adapt to the behavioral\npatterns for better performance. Extensive experiments on Didi's real-world\nbenchmarks justify that the proposed approach significantly outperforms\ncompetitive baselines in optimizing matching efficiency and user experience\ntasks. In addition, we evaluate the deployment outline and discuss the gains\nand experiences obtained during the deployment tests from the view of\nlarge-scale engineering implementation.",
      "tldr_zh": "这篇论文提出了一种基于 Reinforcement Learning 的端到端方法，用于解决骑行叫车平台（如 Didi）的微观订单分配（Micro-View Order-Dispatching）问题，该问题涉及本地时空不确定性。方法采用一个两层 Markov Decision Process 框架，并引入 D2SN（Deep Double Scalable Network）——一个编码器-解码器结构网络——来统一行为预测和组合优化，实现顺序决策式的订单-司机分配。实验结果显示，该方法在 Didi 的真实基准上显著优于基线模型，提高了匹配效率和用户体验。论文还讨论了部署轮廓及大规模工程实施中的收益和经验。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.10479v1",
      "published_date": "2024-08-20 01:30:53 UTC",
      "updated_date": "2024-08-20 01:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:19:33.715982"
    },
    {
      "arxiv_id": "2408.10474v1",
      "title": "LeCov: Multi-level Testing Criteria for Large Language Models",
      "title_zh": "LeCov：面向大型语言模型的多层次测试标准",
      "authors": [
        "Xuan Xie",
        "Jiayang Song",
        "Yuheng Huang",
        "Da Song",
        "Fuyuan Zhang",
        "Felix Juefei-Xu",
        "Lei Ma"
      ],
      "abstract": "Large Language Models (LLMs) are widely used in many different domains, but\nbecause of their limited interpretability, there are questions about how\ntrustworthy they are in various perspectives, e.g., truthfulness and toxicity.\nRecent research has started developing testing methods for LLMs, aiming to\nuncover untrustworthy issues, i.e., defects, before deployment. However,\nsystematic and formalized testing criteria are lacking, which hinders a\ncomprehensive assessment of the extent and adequacy of testing exploration. To\nmitigate this threat, we propose a set of multi-level testing criteria, LeCov,\nfor LLMs. The criteria consider three crucial LLM internal components, i.e.,\nthe attention mechanism, feed-forward neurons, and uncertainty, and contain\nnine types of testing criteria in total. We apply the criteria in two\nscenarios: test prioritization and coverage-guided testing. The experiment\nevaluation, on three models and four datasets, demonstrates the usefulness and\neffectiveness of LeCov.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的可信度问题（如真实性和毒性），提出了一套多级测试标准LeCov，以系统化评估模型的可靠性。LeCov涵盖LLMs的内部组件，包括注意力机制、前馈神经元和不确定性，共九种测试类型，并应用于测试优先级和覆盖指导测试场景。在三个模型和四个数据集上的实验结果表明，LeCov显著提高了测试的有效性和全面性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.10474v1",
      "published_date": "2024-08-20 01:17:54 UTC",
      "updated_date": "2024-08-20 01:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:19:43.531079"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 139,
  "processed_papers_count": 139,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T17:20:10.068757"
}