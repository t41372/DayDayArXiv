[
  {
    "arxiv_id": "2408.11249v1",
    "title": "The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act",
    "authors": [
      "Matias Valdenegro-Toro",
      "Radina Stoykova"
    ],
    "abstract": "The AI act is the European Union-wide regulation of AI systems. It includes\nspecific provisions for general-purpose AI models which however need to be\nfurther interpreted in terms of technical standards and state-of-art studies to\nensure practical compliance solutions. This paper examines the AI act\nrequirements for providers and deployers of general-purpose AI and further\nproposes uncertainty estimation as a suitable measure for legal compliance and\nquality assurance in training of such models. We argue that uncertainty\nestimation should be a required component for deploying models in the real\nworld, and under the EU AI Act, it could fulfill several requirements for\ntransparency, accuracy, and trustworthiness. However, generally using\nuncertainty estimation methods increases the amount of computation, producing a\ndilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to\nclassify the model as a systemic risk system which bears more regulatory\nburden.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2nd GenLaw Workshop @ ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11249v1",
    "published_date": "2024-08-20 23:59:51 UTC",
    "updated_date": "2024-08-20 23:59:51 UTC"
  },
  {
    "arxiv_id": "2408.11243v2",
    "title": "Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?",
    "authors": [
      "Qian Ma",
      "Haitao Mao",
      "Jingzhe Liu",
      "Zhehua Zhang",
      "Chunlin Feng",
      "Yu Song",
      "Yihan Shao",
      "Yao Ma"
    ],
    "abstract": "Self-supervised learning~(SSL) is essential to obtain foundation models in\nNLP and CV domains via effectively leveraging knowledge in large-scale\nunlabeled data. The reason for its success is that a suitable SSL design can\nhelp the model to follow the neural scaling law, i.e., the performance\nconsistently improves with increasing model and dataset sizes. However, it\nremains a mystery whether existing SSL in the graph domain can follow the\nscaling behavior toward building Graph Foundation Models~(GFMs) with\nlarge-scale pre-training. In this study, we examine whether existing graph SSL\ntechniques can follow the neural scaling behavior with the potential to serve\nas the essential component for GFMs. Our benchmark includes comprehensive SSL\ntechnique implementations with analysis conducted on both the conventional SSL\nsetting and many new settings adopted in other domains. Surprisingly, despite\nthe SSL loss continuously decreasing, no existing graph SSL techniques follow\nthe neural scaling behavior on the downstream performance. The model\nperformance only merely fluctuates on different data scales and model scales.\nInstead of the scales, the key factors influencing the performance are the\nchoices of model architecture and pretext task design. This paper examines\nexisting SSL techniques for the feasibility of Graph SSL techniques in\ndeveloping GFMs and opens a new direction for graph SSL design with the new\nevaluation prototype. Our code implementation is available online to ease\nreproducibility on https://github.com/GraphSSLScaling/GraphSSLScaling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11243v2",
    "published_date": "2024-08-20 23:45:11 UTC",
    "updated_date": "2024-08-26 18:11:11 UTC"
  },
  {
    "arxiv_id": "2408.11239v1",
    "title": "A Little Confidence Goes a Long Way",
    "authors": [
      "John Scoville",
      "Shang Gao",
      "Devanshu Agrawal",
      "Javed Qadrud-Din"
    ],
    "abstract": "We introduce a group of related methods for binary classification tasks using\nprobes of the hidden state activations in large language models (LLMs).\nPerformance is on par with the largest and most advanced LLMs currently\navailable, but requiring orders of magnitude fewer computational resources and\nnot requiring labeled data. This approach involves translating class labels\ninto a semantically rich description, spontaneous symmetry breaking of\nmultilayer perceptron probes for unsupervised learning and inference, training\nprobes to generate confidence scores (prior probabilities) from hidden state\nactivations subject to known constraints via entropy maximization, and\nselecting the most confident probe model from an ensemble for prediction. These\ntechniques are evaluated on four datasets using five base LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11239v1",
    "published_date": "2024-08-20 23:36:00 UTC",
    "updated_date": "2024-08-20 23:36:00 UTC"
  },
  {
    "arxiv_id": "2408.11237v1",
    "title": "Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification",
    "authors": [
      "Christos Constantinou",
      "Georgios Ioannides",
      "Aman Chadha",
      "Aaron Elkins",
      "Edwin Simpson"
    ],
    "abstract": "Detecting out-of-distribution (OOD) data is crucial in machine learning\napplications to mitigate the risk of model overconfidence, thereby enhancing\nthe reliability and safety of deployed systems. The majority of existing OOD\ndetection methods predominantly address uni-modal inputs, such as images or\ntexts. In the context of multi-modal documents, there is a notable lack of\nextensive research on the performance of these methods, which have primarily\nbeen developed with a focus on computer vision tasks. We propose a novel\nmethodology termed as attention head masking (AHM) for multi-modal OOD tasks in\ndocument classification systems. Our empirical results demonstrate that the\nproposed AHM method outperforms all state-of-the-art approaches and\nsignificantly decreases the false positive rate (FPR) compared to existing\nsolutions up to 7.5\\%. This methodology generalizes well to multi-modal data,\nsuch as documents, where visual and textual information are modeled under the\nsame Transformer architecture. To address the scarcity of high-quality publicly\navailable document datasets and encourage further research on OOD detection for\ndocuments, we introduce FinanceDocs, a new document AI dataset. Our code and\ndataset are publicly available.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11237v1",
    "published_date": "2024-08-20 23:30:00 UTC",
    "updated_date": "2024-08-20 23:30:00 UTC"
  },
  {
    "arxiv_id": "2408.11234v2",
    "title": "Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery",
    "authors": [
      "Manuel Weber",
      "Carly Beneke",
      "Clyde Wheeler"
    ],
    "abstract": "Regular measurement of carbon stock in the world's forests is critical for\ncarbon accounting and reporting under national and international climate\ninitiatives, and for scientific research, but has been largely limited in\nscalability and temporal resolution due to a lack of ground based assessments.\nIncreasing efforts have been made to address these challenges by incorporating\nremotely sensed data. We present a new methodology which uses multi-sensor,\nmulti-spectral imagery at a resolution of 10 meters and a deep learning based\nmodel which unifies the prediction of above ground biomass density (AGBD),\ncanopy height (CH), canopy cover (CC) as well as uncertainty estimations for\nall three quantities. The model is trained on millions of globally sampled\nGEDI-L2/L4 measurements. We validate the capability of our model by deploying\nit over the entire globe for the year 2023 as well as annually from 2016 to\n2023 over selected areas. The model achieves a mean absolute error for AGBD\n(CH, CC) of 26.1 Mg/ha (3.7 m, 9.9 %) and a root mean squared error of 50.6\nMg/ha (5.4 m, 15.8 %) on a globally sampled test dataset, demonstrating a\nsignificant improvement over previously published results. We also report the\nmodel performance against independently collected ground measurements published\nin the literature, which show a high degree of correlation across varying\nconditions. We further show that our pre-trained model facilitates seamless\ntransferability to other GEDI variables due to its multi-head architecture.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11234v2",
    "published_date": "2024-08-20 23:15:41 UTC",
    "updated_date": "2024-12-31 10:43:36 UTC"
  },
  {
    "arxiv_id": "2408.11227v2",
    "title": "OCTCube-M: A 3D multimodal optical coherence tomography foundation model for retinal and systemic diseases with cross-cohort and cross-device validation",
    "authors": [
      "Zixuan Liu",
      "Hanwen Xu",
      "Addie Woicik",
      "Linda G. Shapiro",
      "Marian Blazes",
      "Yue Wu",
      "Verena Steffen",
      "Catherine Cukras",
      "Cecilia S. Lee",
      "Miao Zhang",
      "Aaron Y. Lee",
      "Sheng Wang"
    ],
    "abstract": "We present OCTCube-M, a 3D OCT-based multi-modal foundation model for jointly\nanalyzing OCT and en face images. OCTCube-M first developed OCTCube, a 3D\nfoundation model pre-trained on 26,685 3D OCT volumes encompassing 1.62 million\n2D OCT images. It then exploits a novel multi-modal contrastive learning\nframework COEP to integrate other retinal imaging modalities, such as fundus\nautofluorescence and infrared retinal imaging, into OCTCube, efficiently\nextending it into multi-modal foundation models. OCTCube achieves best\nperformance on predicting 8 retinal diseases, demonstrating strong\ngeneralizability on cross-cohort, cross-device and cross-modality prediction.\nOCTCube can also predict cross-organ nodule malignancy (CT) and low cardiac\nejection fraction as well as systemic diseases, such as diabetes and\nhypertension, revealing its wide applicability beyond retinal diseases. We\nfurther develop OCTCube-IR using COEP with 26,685 OCT and IR image pairs.\nOCTCube-IR can accurately retrieve between OCT and IR images, allowing joint\nanalysis between 3D and 2D retinal imaging modalities. Finally, we trained a\ntri-modal foundation model OCTCube-EF from 4 million 2D OCT images and 400K en\nface retinal images. OCTCube-EF attains the best performance on predicting the\ngrowth rate of geographic atrophy (GA) across datasets collected from 6\nmulti-center global trials conducted in 23 countries. This improvement is\nstatistically equivalent to running a clinical trial with more than double the\nsize of the original study. Our analysis based on another retrospective case\nstudy reveals OCTCube-EF's ability to avoid false positive Phase-III results\naccording to its accurate treatment effect estimation on the Phase-II results.\nIn sum, OCTCube-M is a 3D multi-modal foundation model framework that\nintegrates OCT and other retinal imaging modalities revealing substantial\ndiagnostic and prognostic benefits.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11227v2",
    "published_date": "2024-08-20 22:55:19 UTC",
    "updated_date": "2024-12-17 19:13:41 UTC"
  },
  {
    "arxiv_id": "2408.11219v1",
    "title": "CoDi: Conversational Distillation for Grounded Question Answering",
    "authors": [
      "Patrick Huber",
      "Arash Einolghozati",
      "Rylan Conway",
      "Kanika Narang",
      "Matt Smith",
      "Waqar Nayyar",
      "Adithya Sagar",
      "Ahmed Aly",
      "Akshat Shrivastava"
    ],
    "abstract": "Distilling conversational skills into Small Language Models (SLMs) with\napproximately 1 billion parameters presents significant challenges. Firstly,\nSLMs have limited capacity in their model parameters to learn extensive\nknowledge compared to larger models. Secondly, high-quality conversational\ndatasets are often scarce, small, and domain-specific. Addressing these\nchallenges, we introduce a novel data distillation framework named CoDi (short\nfor Conversational Distillation, pronounced \"Cody\"), allowing us to synthesize\nlarge-scale, assistant-style datasets in a steerable and diverse manner.\nSpecifically, while our framework is task agnostic at its core, we explore and\nevaluate the potential of CoDi on the task of conversational grounded reasoning\nfor question answering. This is a typical on-device scenario for specialist\nSLMs, allowing for open-domain model responses, without requiring the model to\n\"memorize\" world knowledge in its limited weights. Our evaluations show that\nSLMs trained with CoDi-synthesized data achieve performance comparable to\nmodels trained on human-annotated data in standard metrics. Additionally, when\nusing our framework to generate larger datasets from web data, our models\nsurpass larger, instruction-tuned models in zero-shot conversational grounded\nreasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.11219v1",
    "published_date": "2024-08-20 22:35:47 UTC",
    "updated_date": "2024-08-20 22:35:47 UTC"
  },
  {
    "arxiv_id": "2408.11207v1",
    "title": "Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs",
    "authors": [
      "Sanjay Bhargav Dharavath",
      "Tanmoy Dam",
      "Supriyo Chakraborty",
      "Prithwiraj Roy",
      "Aniruddha Maiti"
    ],
    "abstract": "The field of autonomous vehicles (AVs) predominantly leverages multi-modal\nintegration of LiDAR and camera data to achieve better performance compared to\nusing a single modality. However, the fusion process encounters challenges in\ndetecting distant objects due to the disparity between the high resolution of\ncameras and the sparse data from LiDAR. Insufficient integration of global\nperspectives with local-level details results in sub-optimal fusion\nperformance.To address this issue, we have developed an innovative two-stage\nfusion process called Quantum Inverse Contextual Vision Transformers (Q-ICVT).\nThis approach leverages adiabatic computing in quantum concepts to create a\nnovel reversible vision transformer known as the Global Adiabatic Transformer\n(GAT). GAT aggregates sparse LiDAR features with semantic features in dense\nimages for cross-modal integration in a global form. Additionally, the Sparse\nExpert of Local Fusion (SELF) module maps the sparse LiDAR 3D proposals and\nencodes position information of the raw point cloud onto the dense camera\nfeature space using a gating point fusion approach. Our experiments show that\nQ-ICVT achieves an mAPH of 82.54 for L2 difficulties on the Waymo dataset,\nimproving by 1.88% over current state-of-the-art fusion methods. We also\nanalyze GAT and SELF in ablation studies to highlight the impact of Q-ICVT. Our\ncode is available at https://github.com/sanjay-810/Qicvt Q-ICVT",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been accepted as a short paper at CIKM '24",
    "pdf_url": "http://arxiv.org/pdf/2408.11207v1",
    "published_date": "2024-08-20 21:36:57 UTC",
    "updated_date": "2024-08-20 21:36:57 UTC"
  },
  {
    "arxiv_id": "2408.11202v1",
    "title": "Effective Off-Policy Evaluation and Learning in Contextual Combinatorial Bandits",
    "authors": [
      "Tatsuhiro Shimizu",
      "Koichi Tanaka",
      "Ren Kishimoto",
      "Haruka Kiyohara",
      "Masahiro Nomura",
      "Yuta Saito"
    ],
    "abstract": "We explore off-policy evaluation and learning (OPE/L) in contextual\ncombinatorial bandits (CCB), where a policy selects a subset in the action\nspace. For example, it might choose a set of furniture pieces (a bed and a\ndrawer) from available items (bed, drawer, chair, etc.) for interior design\nsales. This setting is widespread in fields such as recommender systems and\nhealthcare, yet OPE/L of CCB remains unexplored in the relevant literature.\nTypical OPE/L methods such as regression and importance sampling can be applied\nto the CCB problem, however, they face significant challenges due to high bias\nor variance, exacerbated by the exponential growth in the number of available\nsubsets. To address these challenges, we introduce a concept of factored action\nspace, which allows us to decompose each subset into binary indicators. This\nformulation allows us to distinguish between the ''main effect'' derived from\nthe main actions, and the ''residual effect'', originating from the\nsupplemental actions, facilitating more effective OPE. Specifically, our\nestimator, called OPCB, leverages an importance sampling-based approach to\nunbiasedly estimate the main effect, while employing regression-based approach\nto deal with the residual effect with low variance. OPCB achieves substantial\nvariance reduction compared to conventional importance sampling methods and\nbias reduction relative to regression methods under certain conditions, as\nillustrated in our theoretical analysis. Experiments demonstrate OPCB's\nsuperior performance over typical methods in both OPE and OPL.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "accepted at RecSys2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11202v1",
    "published_date": "2024-08-20 21:25:04 UTC",
    "updated_date": "2024-08-20 21:25:04 UTC"
  },
  {
    "arxiv_id": "2408.11198v1",
    "title": "EPiC: Cost-effective Search-based Prompt Engineering of LLMs for Code Generation",
    "authors": [
      "Hamed Taherkhani",
      "Melika Sepindband",
      "Hung Viet Pham",
      "Song Wang",
      "Hadi Hemmati"
    ],
    "abstract": "Large Language Models (LLMs) have seen increasing use in various software\ndevelopment tasks, especially in code generation. The most advanced recent\nmethods attempt to incorporate feedback from code execution into prompts to\nhelp guide LLMs in generating correct code, in an iterative process. While\neffective, these methods could be costly and time-consuming due to numerous\ninteractions with the LLM and the extensive token usage. To address this issue,\nwe propose an alternative approach named Evolutionary Prompt Engineering for\nCode (EPiC), which leverages a lightweight evolutionary algorithm to evolve the\noriginal prompts toward better ones that produce high-quality code, with\nminimal interactions with LLM. Our evaluation against state-of-the-art (SOTA)\nLLM-based code generation models shows that EPiC outperforms all the baselines\nin terms of cost-effectiveness.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SE",
    "comment": "Submitted to TSE",
    "pdf_url": "http://arxiv.org/pdf/2408.11198v1",
    "published_date": "2024-08-20 21:15:36 UTC",
    "updated_date": "2024-08-20 21:15:36 UTC"
  },
  {
    "arxiv_id": "2408.11189v1",
    "title": "Reading with Intent",
    "authors": [
      "Benjamin Reichman",
      "Kartik Talamadupula",
      "Toshish Jawale",
      "Larry Heck"
    ],
    "abstract": "Retrieval augmented generation (RAG) systems augment how knowledge language\nmodels are by integrating external information sources such as Wikipedia,\ninternal documents, scientific papers, or the open internet. RAG systems that\nrely on the open internet as their knowledge source have to contend with the\ncomplexities of human-generated content. Human communication extends much\ndeeper than just the words rendered as text. Intent, tonality, and connotation\ncan all change the meaning of what is being conveyed. Recent real-world\ndeployments of RAG systems have shown some difficulty in understanding these\nnuances of human communication. One significant challenge for these systems\nlies in processing sarcasm. Though the Large Language Models (LLMs) that make\nup the backbone of these RAG systems are able to detect sarcasm, they currently\ndo not always use these detections for the subsequent processing of text. To\naddress these issues, in this paper, we synthetically generate sarcastic\npassages from Natural Question's Wikipedia retrieval corpus. We then test the\nimpact of these passages on the performance of both the retriever and reader\nportion of the RAG pipeline. We introduce a prompting system designed to\nenhance the model's ability to interpret and generate responses in the presence\nof sarcasm, thus improving overall system performance. Finally, we conduct\nablation studies to validate the effectiveness of our approach, demonstrating\nimprovements in handling sarcastic content within RAG systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11189v1",
    "published_date": "2024-08-20 20:47:27 UTC",
    "updated_date": "2024-08-20 20:47:27 UTC"
  },
  {
    "arxiv_id": "2408.11187v1",
    "title": "Optimization of Multi-Agent Flying Sidekick Traveling Salesman Problem over Road Networks",
    "authors": [
      "Ruixiao Yang",
      "Chuchu Fan"
    ],
    "abstract": "The mixed truck-drone delivery systems have attracted increasing attention\nfor last-mile logistics, but real-world complexities demand a shift from\nsingle-agent, fully connected graph models to multi-agent systems operating on\nactual road networks. We introduce the multi-agent flying sidekick traveling\nsalesman problem (MA-FSTSP) on road networks, extending the single truck-drone\nmodel to multiple trucks, each carrying multiple drones while considering full\nroad networks for truck restrictions and flexible drone routes. We propose a\nmixed-integer linear programming model and an efficient three-phase heuristic\nalgorithm for this NP-hard problem. Our approach decomposes MA-FSTSP into\nmanageable subproblems of one truck with multiple drones. Then, it computes the\nroutes for trucks without drones in subproblems, which are used in the final\nphase as heuristics to help optimize drone and truck routes simultaneously.\nExtensive numerical experiments on Manhattan and Boston road networks\ndemonstrate our algorithm's superior effectiveness and efficiency,\nsignificantly outperforming both column generation and variable neighborhood\nsearch baselines in solution quality and computation time. Notably, our\napproach scales to more than 300 customers within a 5-minute time limit,\nshowcasing its potential for large-scale, real-world logistics applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11187v1",
    "published_date": "2024-08-20 20:44:18 UTC",
    "updated_date": "2024-08-20 20:44:18 UTC"
  },
  {
    "arxiv_id": "2408.11186v2",
    "title": "Sequential Resource Trading Using Comparison-Based Gradient Estimation",
    "authors": [
      "Surya Murthy",
      "Mustafa O. Karabag",
      "Ufuk Topcu"
    ],
    "abstract": "Autonomous agents interact with other agents of unknown preferences to share\nresources in their environment. We explore sequential trading for resource\nallocation in a setting where two greedily rational agents sequentially trade\nresources from a finite set of categories. Each agent has a utility function\nthat depends on the amount of resources it possesses in each category. The\noffering agent makes trade offers to improve its utility without knowing the\nresponding agent's utility function, and the responding agent only accepts\noffers that improve its utility. We present an algorithm for the offering agent\nto estimate the responding agent's gradient (preferences) and make offers based\non previous acceptance or rejection responses. The algorithm's goal is to reach\na Pareto-optimal resource allocation state while ensuring that the utilities of\nboth agents improve after every accepted trade. We show that, after a finite\nnumber of consecutively rejected offers, the responding agent is at a\nnear-optimal state, or the agents' gradients are closely aligned. We compare\nthe proposed algorithm against various baselines in continuous and discrete\ntrading scenarios and show that it improves the societal benefit with fewer\noffers.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11186v2",
    "published_date": "2024-08-20 20:42:41 UTC",
    "updated_date": "2024-11-03 23:38:11 UTC"
  },
  {
    "arxiv_id": "2408.11182v2",
    "title": "Hide Your Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Carrier Articles",
    "authors": [
      "Zhilong Wang",
      "Haizhou Wang",
      "Nanqing Luo",
      "Lan Zhang",
      "Xiaoyan Sun",
      "Yebo Cao",
      "Peng Liu"
    ],
    "abstract": "Large Language Model (LLM) jailbreak refers to a type of attack aimed to\nbypass the safeguard of an LLM to generate contents that are inconsistent with\nthe safe usage guidelines. Based on the insights from the self-attention\ncomputation process, this paper proposes a novel blackbox jailbreak approach,\nwhich involves crafting the payload prompt by strategically injecting the\nprohibited query into a carrier article. The carrier article maintains the\nsemantic proximity to the prohibited query, which is automatically produced by\ncombining a hypernymy article and a context, both of which are generated from\nthe prohibited query. The intuition behind the usage of carrier article is to\nactivate the neurons in the model related to the semantics of the prohibited\nquery while suppressing the neurons that will trigger the objectionable text.\nCarrier article itself is benign, and we leveraged prompt injection techniques\nto produce the payload prompt. We evaluate our approach using JailbreakBench,\ntesting against four target models across 100 distinct jailbreak objectives.\nThe experimental results demonstrate our method's superior effectiveness,\nachieving an average success rate of 63% across all target models,\nsignificantly outperforming existing blackbox jailbreak methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11182v2",
    "published_date": "2024-08-20 20:35:04 UTC",
    "updated_date": "2025-02-07 01:18:07 UTC"
  },
  {
    "arxiv_id": "2408.11181v1",
    "title": "A Full DAG Score-Based Algorithm for Learning Causal Bayesian Networks with Latent Confounders",
    "authors": [
      "Christophe Gonzales",
      "Amir-Hosein Valizadeh"
    ],
    "abstract": "Causal Bayesian networks (CBN) are popular graphical probabilistic models\nthat encode causal relations among variables. Learning their graphical\nstructure from observational data has received a lot of attention in the\nliterature. When there exists no latent (unobserved) confounder, i.e., no\nunobserved direct common cause of some observed variables, learning algorithms\ncan be divided essentially into two classes: constraint-based and score-based\napproaches. The latter are often thought to be more robust than the former and\nto produce better results. However, to the best of our knowledge, when\nvariables are discrete, no score-based algorithm is capable of dealing with\nlatent confounders. This paper introduces the first fully score-based structure\nlearning algorithm searching the space of DAGs (directed acyclic graphs) that\nis capable of identifying the presence of some latent confounders. It is\njustified mathematically and experiments highlight its effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, extended version with supplementary material of paper\n  accepted at the 27th European Conference on Artificial Intelligence (ECAI'24)",
    "pdf_url": "http://arxiv.org/pdf/2408.11181v1",
    "published_date": "2024-08-20 20:25:56 UTC",
    "updated_date": "2024-08-20 20:25:56 UTC"
  },
  {
    "arxiv_id": "2408.11172v1",
    "title": "SubgoalXL: Subgoal-based Expert Learning for Theorem Proving",
    "authors": [
      "Xueliang Zhao",
      "Lin Zheng",
      "Haige Bo",
      "Changran Hu",
      "Urmish Thakker",
      "Lingpeng Kong"
    ],
    "abstract": "Formal theorem proving, a field at the intersection of mathematics and\ncomputer science, has seen renewed interest with advancements in large language\nmodels (LLMs). This paper introduces SubgoalXL, a novel approach that\nsynergizes subgoal-based proofs with expert learning to enhance LLMs'\ncapabilities in formal theorem proving within the Isabelle environment.\nSubgoalXL addresses two critical challenges: the scarcity of specialized\nmathematics and theorem-proving data, and the need for improved multi-step\nreasoning abilities in LLMs. By optimizing data efficiency and employing\nsubgoal-level supervision, SubgoalXL extracts richer information from limited\nhuman-generated proofs. The framework integrates subgoal-oriented proof\nstrategies with an expert learning system, iteratively refining formal\nstatement, proof, and subgoal generators. Leveraging the Isabelle environment's\nadvantages in subgoal-based proofs, SubgoalXL achieves a new state-of-the-art\nperformance of 56.1\\% in Isabelle on the standard miniF2F dataset, marking an\nabsolute improvement of 4.9\\%. Notably, SubgoalXL successfully solves 41 AMC12,\n9 AIME, and 3 IMO problems from miniF2F. These results underscore the\neffectiveness of maximizing limited data utility and employing targeted\nguidance for complex reasoning in formal theorem proving, contributing to the\nongoing advancement of AI reasoning capabilities. The implementation is\navailable at \\url{https://github.com/zhaoxlpku/SubgoalXL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11172v1",
    "published_date": "2024-08-20 20:10:53 UTC",
    "updated_date": "2024-08-20 20:10:53 UTC"
  },
  {
    "arxiv_id": "2408.11135v1",
    "title": "MS$^3$D: A RG Flow-Based Regularization for GAN Training with Limited Data",
    "authors": [
      "Jian Wang",
      "Xin Lan",
      "Yuxin Tian",
      "Jiancheng Lv"
    ],
    "abstract": "Generative adversarial networks (GANs) have made impressive advances in image\ngeneration, but they often require large-scale training data to avoid\ndegradation caused by discriminator overfitting. To tackle this issue, we\ninvestigate the challenge of training GANs with limited data, and propose a\nnovel regularization method based on the idea of renormalization group (RG) in\nphysics.We observe that in the limited data setting, the gradient pattern that\nthe generator obtains from the discriminator becomes more aggregated over time.\nIn RG context, this aggregated pattern exhibits a high discrepancy from its\ncoarse-grained versions, which implies a high-capacity and sensitive system,\nprone to overfitting and collapse. To address this problem, we introduce a\n\\textbf{m}ulti-\\textbf{s}cale \\textbf{s}tructural\n\\textbf{s}elf-\\textbf{d}issimilarity (MS$^3$D) regularization, which constrains\nthe gradient field to have a consistent pattern across different scales,\nthereby fostering a more redundant and robust system. We show that our method\ncan effectively enhance the performance and stability of GANs under limited\ndata scenarios, and even allow them to generate high-quality images with very\nfew data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11135v1",
    "published_date": "2024-08-20 18:37:37 UTC",
    "updated_date": "2024-08-20 18:37:37 UTC"
  },
  {
    "arxiv_id": "2408.11121v2",
    "title": "DOMBA: Double Model Balancing for Access-Controlled Language Models via Minimum-Bounded Aggregation",
    "authors": [
      "Tom Segal",
      "Asaf Shabtai",
      "Yuval Elovici"
    ],
    "abstract": "The utility of large language models (LLMs) depends heavily on the quality\nand quantity of their training data. Many organizations possess large data\ncorpora that could be leveraged to train or fine-tune LLMs tailored to their\nspecific needs. However, these datasets often come with access restrictions\nthat are based on user privileges and enforced by access control mechanisms.\nTraining LLMs on such datasets could result in exposure of sensitive\ninformation to unauthorized users. A straightforward approach for preventing\nsuch exposure is to train a separate model for each access level. This,\nhowever, may result in low utility models due to the limited amount of training\ndata per model compared to the amount in the entire organizational corpus.\nAnother approach is to train a single LLM on all the data while limiting the\nexposure of unauthorized information. However, current exposure-limiting\nmethods for LLMs are ineffective for access-controlled data, where sensitive\ninformation appears frequently across many training examples. We propose DOMBA\n- double model balancing - a simple approach for training and deploying LLMs\nthat provides high utility and access-control functionality with security\nguarantees. DOMBA aggregates the probability distributions of two models, each\ntrained on documents with (potentially many) different access levels, using a\n\"min-bounded\" average function (a function that is bounded by the smaller\nvalue, e.g., harmonic mean). A detailed mathematical analysis and extensive\nevaluation show that DOMBA safeguards restricted information while offering\nutility comparable to non-secure models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Code: https://github.com/ppo1/DOMBA 11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11121v2",
    "published_date": "2024-08-20 18:23:38 UTC",
    "updated_date": "2025-02-08 14:19:54 UTC"
  },
  {
    "arxiv_id": "2408.11054v3",
    "title": "Near, far: Patch-ordering enhances vision foundation models' scene understanding",
    "authors": [
      "Valentinos Pariza",
      "Mohammadreza Salehi",
      "Gertjan Burghouts",
      "Francesco Locatello",
      "Yuki M. Asano"
    ],
    "abstract": "We introduce NeCo: Patch Neighbor Consistency, a novel self-supervised\ntraining loss that enforces patch-level nearest neighbor consistency across a\nstudent and teacher model. Compared to contrastive approaches that only yield\nbinary learning signals, i.e., 'attract' and 'repel', this approach benefits\nfrom the more fine-grained learning signal of sorting spatially dense features\nrelative to reference patches. Our method leverages differentiable sorting\napplied on top of pretrained representations, such as DINOv2-registers to\nbootstrap the learning signal and further improve upon them. This dense\npost-pretraining leads to superior performance across various models and\ndatasets, despite requiring only 19 hours on a single GPU. This method\ngenerates high-quality dense feature encoders and establishes several new\nstate-of-the-art results such as +5.5% and +6% for non-parametric in-context\nsemantic segmentation on ADE20k and Pascal VOC, +7.2% and +5.7% for linear\nsegmentation evaluations on COCO-Things and -Stuff and improvements in the 3D\nunderstanding of multi-view consistency on SPair-71k, by more than 1.5%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICLR25. The webpage is accessible at:\n  https://vpariza.github.io/NeCo/",
    "pdf_url": "http://arxiv.org/pdf/2408.11054v3",
    "published_date": "2024-08-20 17:58:59 UTC",
    "updated_date": "2025-04-17 09:45:54 UTC"
  },
  {
    "arxiv_id": "2408.11053v2",
    "title": "Revisiting VerilogEval: A Year of Improvements in Large-Language Models for Hardware Code Generation",
    "authors": [
      "Nathaniel Pinckney",
      "Christopher Batten",
      "Mingjie Liu",
      "Haoxing Ren",
      "Brucek Khailany"
    ],
    "abstract": "The application of large-language models (LLMs) to digital hardware code\ngeneration is an emerging field, with most LLMs primarily trained on natural\nlanguage and software code. Hardware code like Verilog constitutes a small\nportion of training data, and few hardware benchmarks exist. The open-source\nVerilogEval benchmark, released in November 2023, provided a consistent\nevaluation framework for LLMs on code completion tasks. Since then, both\ncommercial and open models have seen significant development.\n  In this work, we evaluate new commercial and open models since VerilogEval's\noriginal release-including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3\n70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and\nRTL-Coder-against an improved VerilogEval benchmark suite. We find measurable\nimprovements in state-of-the-art models: GPT-4o achieves a 63% pass rate on\nspecification-to-RTL tasks. The recently released and open Llama3.1 405B\nachieves a 58% pass rate, almost matching GPT-4o, while the smaller\ndomain-specific RTL-Coder 6.7B models achieve an impressive 34% pass rate.\n  Additionally, we enhance VerilogEval's infrastructure by automatically\nclassifying failures, introducing in-context learning support, and extending\nthe tasks to specification-to-RTL translation. We find that prompt engineering\nremains crucial for achieving good pass rates and varies widely with model and\ntask. A benchmark infrastructure that allows for prompt engineering and failure\nanalysis is essential for continued model development and deployment.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "This paper revisits and improves the benchmark first presented in\n  arXiv:2309.07544. Twenty-one pages, five figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11053v2",
    "published_date": "2024-08-20 17:58:56 UTC",
    "updated_date": "2025-02-03 19:29:27 UTC"
  },
  {
    "arxiv_id": "2408.11052v3",
    "title": "Accelerating Goal-Conditioned RL Algorithms and Research",
    "authors": [
      "Michał Bortkiewicz",
      "Władysław Pałucki",
      "Vivek Myers",
      "Tadeusz Dziarmaga",
      "Tomasz Arczewski",
      "Łukasz Kuciński",
      "Benjamin Eysenbach"
    ],
    "abstract": "Self-supervision has the potential to transform reinforcement learning (RL),\nparalleling the breakthroughs it has enabled in other areas of machine\nlearning. While self-supervised learning in other domains aims to find patterns\nin a fixed dataset, self-supervised goal-conditioned reinforcement learning\n(GCRL) agents discover new behaviors by learning from the goals achieved during\nunstructured interaction with the environment. However, these methods have\nfailed to see similar success, both due to a lack of data from slow environment\nsimulations as well as a lack of stable algorithms. We take a step toward\naddressing both of these issues by releasing a high-performance codebase and\nbenchmark (JaxGCRL) for self-supervised GCRL, enabling researchers to train\nagents for millions of environment steps in minutes on a single GPU. By\nutilizing GPU-accelerated replay buffers, environments, and a stable\ncontrastive RL algorithm, we reduce training time by up to $22\\times$.\nAdditionally, we assess key design choices in contrastive RL, identifying those\nthat most effectively stabilize and enhance training performance. With this\napproach, we provide a foundation for future research in self-supervised GCRL,\nenabling researchers to quickly iterate on new ideas and evaluate them in\ndiverse and challenging environments. Website + Code:\nhttps://github.com/MichalBortkiewicz/JaxGCRL",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://michalbortkiewicz.github.io/JaxGCRL/ Code:\n  https://github.com/MichalBortkiewicz/JaxGCRL",
    "pdf_url": "http://arxiv.org/pdf/2408.11052v3",
    "published_date": "2024-08-20 17:58:40 UTC",
    "updated_date": "2025-04-21 11:10:56 UTC"
  },
  {
    "arxiv_id": "2408.11051v2",
    "title": "FLAME: Learning to Navigate with Multimodal LLM in Urban Environments",
    "authors": [
      "Yunzhe Xu",
      "Yiyuan Pan",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated potential in\nVision-and-Language Navigation (VLN) tasks, yet current applications face\nchallenges. While LLMs excel in general conversation scenarios, they struggle\nwith specialized navigation tasks, yielding suboptimal performance compared to\nspecialized VLN models. We introduce FLAME (FLAMingo-Architected Embodied\nAgent), a novel Multimodal LLM-based agent and architecture designed for urban\nVLN tasks that efficiently handles multiple observations. Our approach\nimplements a three-phase tuning technique for effective adaptation to\nnavigation tasks, including single perception tuning for street view\ndescription, multiple perception tuning for route summarization, and end-to-end\ntraining on VLN datasets. The augmented datasets are synthesized automatically.\nExperimental results demonstrate FLAME's superiority over existing methods,\nsurpassing state-of-the-art methods by a 7.3% increase in task completion on\nTouchdown dataset. This work showcases the potential of Multimodal LLMs (MLLMs)\nin complex navigation tasks, representing an advancement towards applications\nof MLLMs in the field of embodied intelligence.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2408.11051v2",
    "published_date": "2024-08-20 17:57:46 UTC",
    "updated_date": "2025-01-21 04:06:09 UTC"
  },
  {
    "arxiv_id": "2408.11048v2",
    "title": "RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual Dexterous Robot Hands",
    "authors": [
      "Yi Zhao",
      "Le Chen",
      "Jan Schneider",
      "Quankai Gao",
      "Juho Kannala",
      "Bernhard Schölkopf",
      "Joni Pajarinen",
      "Dieter Büchler"
    ],
    "abstract": "It has been a long-standing research goal to endow robot hands with\nhuman-level dexterity. Bi-manual robot piano playing constitutes a task that\ncombines challenges from dynamic tasks, such as generating fast while precise\nmotions, with slower but contact-rich manipulation problems. Although\nreinforcement learning based approaches have shown promising results in\nsingle-task performance, these methods struggle in a multi-song setting. Our\nwork aims to close this gap and, thereby, enable imitation learning approaches\nfor robot piano playing at scale. To this end, we introduce the Robot Piano 1\nMillion (RP1M) dataset, containing bi-manual robot piano playing motion data of\nmore than one million trajectories. We formulate finger placements as an\noptimal transport problem, thus, enabling automatic annotation of vast amounts\nof unlabeled songs. Benchmarking existing imitation learning approaches shows\nthat such approaches reach state-of-the-art robot piano playing performance by\nleveraging RP1M.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by Conference on Robot Learning (CoRL) 2024. Project\n  Website: https://rp1m.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2408.11048v2",
    "published_date": "2024-08-20 17:56:52 UTC",
    "updated_date": "2024-11-18 14:14:22 UTC"
  },
  {
    "arxiv_id": "2408.11043v1",
    "title": "Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research",
    "authors": [
      "Sreyoshi Bhaduri",
      "Satya Kapoor",
      "Alex Gil",
      "Anshul Mittal",
      "Rutu Mulkar"
    ],
    "abstract": "Qualitative data collection and analysis approaches, such as those employing\ninterviews and focus groups, provide rich insights into customer attitudes,\nsentiment, and behavior. However, manually analyzing qualitative data requires\nextensive time and effort to identify relevant topics and thematic insights.\nThis study proposes a novel approach to address this challenge by leveraging\nRetrieval Augmented Generation (RAG) based Large Language Models (LLMs) for\nanalyzing interview transcripts. The novelty of this work lies in strategizing\nthe research inquiry as one that is augmented by an LLM that serves as a novice\nresearch assistant. This research explores the mental model of LLMs to serve as\nnovice qualitative research assistants for researchers in the talent management\nspace. A RAG-based LLM approach is extended to enable topic modeling of\nsemi-structured interview data, showcasing the versatility of these models\nbeyond their traditional use in information retrieval and search. Our findings\ndemonstrate that the LLM-augmented RAG approach can successfully extract topics\nof interest, with significant coverage compared to manually generated topics\nfrom the same dataset. This establishes the viability of employing LLMs as\nnovice qualitative research assistants. Additionally, the study recommends that\nresearchers leveraging such models lean heavily on quality criteria used in\ntraditional qualitative research to ensure rigor and trustworthiness of their\napproach. Finally, the paper presents key recommendations for industry\npractitioners seeking to reconcile the use of LLMs with established qualitative\nresearch paradigms, providing a roadmap for the effective integration of these\npowerful, albeit novice, AI tools in the analysis of qualitative datasets\nwithin talent",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to KDD '24 workshop on Talent Management and Computing (TMC\n  2024). 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.11043v1",
    "published_date": "2024-08-20 17:49:51 UTC",
    "updated_date": "2024-08-20 17:49:51 UTC"
  },
  {
    "arxiv_id": "2408.11042v1",
    "title": "GraphFSA: A Finite State Automaton Framework for Algorithmic Learning on Graphs",
    "authors": [
      "Florian Grötschla",
      "Joël Mathys",
      "Christoffer Raun",
      "Roger Wattenhofer"
    ],
    "abstract": "Many graph algorithms can be viewed as sets of rules that are iteratively\napplied, with the number of iterations dependent on the size and complexity of\nthe input graph. Existing machine learning architectures often struggle to\nrepresent these algorithmic decisions as discrete state transitions. Therefore,\nwe propose a novel framework: GraphFSA (Graph Finite State Automaton). GraphFSA\nis designed to learn a finite state automaton that runs on each node of a given\ngraph. We test GraphFSA on cellular automata problems, showcasing its abilities\nin a straightforward algorithmic setting. For a comprehensive empirical\nevaluation of our framework, we create a diverse range of synthetic problems.\nAs our main application, we then focus on learning more elaborate graph\nalgorithms. Our findings suggest that GraphFSA exhibits strong generalization\nand extrapolation abilities, presenting an alternative approach to represent\nthese algorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11042v1",
    "published_date": "2024-08-20 17:49:47 UTC",
    "updated_date": "2024-08-20 17:49:47 UTC"
  },
  {
    "arxiv_id": "2408.11039v1",
    "title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model",
    "authors": [
      "Chunting Zhou",
      "Lili Yu",
      "Arun Babu",
      "Kushal Tirumala",
      "Michihiro Yasunaga",
      "Leonid Shamis",
      "Jacob Kahn",
      "Xuezhe Ma",
      "Luke Zettlemoyer",
      "Omer Levy"
    ],
    "abstract": "We introduce Transfusion, a recipe for training a multi-modal model over\ndiscrete and continuous data. Transfusion combines the language modeling loss\nfunction (next token prediction) with diffusion to train a single transformer\nover mixed-modality sequences. We pretrain multiple Transfusion models up to 7B\nparameters from scratch on a mixture of text and image data, establishing\nscaling laws with respect to a variety of uni- and cross-modal benchmarks. Our\nexperiments show that Transfusion scales significantly better than quantizing\nimages and training a language model over discrete image tokens. By introducing\nmodality-specific encoding and decoding layers, we can further improve the\nperformance of Transfusion models, and even compress each image to just 16\npatches. We further demonstrate that scaling our Transfusion recipe to 7B\nparameters and 2T multi-modal tokens produces a model that can generate images\nand text on a par with similar scale diffusion models and language models,\nreaping the benefits of both worlds.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.11039v1",
    "published_date": "2024-08-20 17:48:20 UTC",
    "updated_date": "2024-08-20 17:48:20 UTC"
  },
  {
    "arxiv_id": "2408.11879v1",
    "title": "Beyond Labels: Aligning Large Language Models with Human-like Reasoning",
    "authors": [
      "Muhammad Rafsan Kabir",
      "Rafeed Mohammad Sultan",
      "Ihsanul Haque Asif",
      "Jawad Ibn Ahad",
      "Fuad Rahman",
      "Mohammad Ruhul Amin",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ],
    "abstract": "Aligning large language models (LLMs) with a human reasoning approach ensures\nthat LLMs produce morally correct and human-like decisions. Ethical concerns\nare raised because current models are prone to generating false positives and\nproviding malicious responses. To contribute to this issue, we have curated an\nethics dataset named Dataset for Aligning Reasons (DFAR), designed to aid in\naligning language models to generate human-like reasons. The dataset comprises\nstatements with ethical-unethical labels and their corresponding reasons. In\nthis study, we employed a unique and novel fine-tuning approach that utilizes\nethics labels and their corresponding reasons (L+R), in contrast to the\nexisting fine-tuning approach that only uses labels (L). The original\npre-trained versions, the existing fine-tuned versions, and our proposed\nfine-tuned versions of LLMs were then evaluated on an ethical-unethical\nclassification task and a reason-generation task. Our proposed fine-tuning\nstrategy notably outperforms the others in both tasks, achieving significantly\nhigher accuracy scores in the classification task and lower misalignment rates\nin the reason-generation task. The increase in classification accuracies and\ndecrease in misalignment rates indicate that the L+R fine-tuned models align\nmore with human ethics. Hence, this study illustrates that injecting reasons\nhas substantially improved the alignment of LLMs, resulting in more human-like\nresponses. We have made the DFAR dataset and corresponding codes publicly\navailable at https://github.com/apurba-nsu-rnd-lab/DFAR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ICPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11879v1",
    "published_date": "2024-08-20 17:44:51 UTC",
    "updated_date": "2024-08-20 17:44:51 UTC"
  },
  {
    "arxiv_id": "2408.11029v2",
    "title": "Scaling Law with Learning Rate Annealing",
    "authors": [
      "Howe Tissue",
      "Venus Wang",
      "Lu Wang"
    ],
    "abstract": "We find that the cross-entropy loss curves of neural language models\nempirically adhere to a scaling law with learning rate (LR) annealing over\ntraining steps: $$L(s) = L_0 + A\\cdot S_1^{-\\alpha} - C\\cdot S_2,$$ where\n$L(s)$ is the validation loss at step $s$, $S_1$ is the area under the LR\ncurve, $S_2$ is the LR annealing area, and $L_0$, $A$, $C$, $\\alpha$ are\nconstant parameters. This formulation takes into account two factors: (1)\npower-law scaling over data size, and (2) the additional loss reduction during\nLR annealing. Therefore, this formulation can describe the full loss curve at\neach step, rather than the single loss point at the end of training. Applying\nthe scaling law with LR annealing and fitting only one or two training curves,\nwe can accurately predict the loss at any given step across any learning rate\nscheduler (LRS). This approach significantly reduces computational cost in\nformulating scaling laws while providing more accuracy and expressiveness for\ntraining dynamics. Extensive experiments demonstrate that our findings hold\nacross a range of hyper-parameters and model architectures, and our equation\ncan extend to scaling effect of model sizes. Moreover, our formulation provides\naccurate theoretical verification and explanation for empirical results\nobserved in numerous previous studies, particularly those focusing on LR\nschedule and annealing. We believe that this work is promising to enhance the\nunderstanding of LLM training dynamics while greatly democratizing scaling\nlaws, and it can guide researchers in refining training strategies (e.g.\ncritical LRS) for further LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Add more experiments to consolidate our scaling laws. 29 pages, 29\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2408.11029v2",
    "published_date": "2024-08-20 17:30:48 UTC",
    "updated_date": "2024-10-24 17:56:14 UTC"
  },
  {
    "arxiv_id": "2408.11021v1",
    "title": "Athena: Safe Autonomous Agents with Verbal Contrastive Learning",
    "authors": [
      "Tanmana Sadhu",
      "Ali Pesaranghader",
      "Yanan Chen",
      "Dong Hoon Yi"
    ],
    "abstract": "Due to emergent capabilities, large language models (LLMs) have been utilized\nas language-based agents to perform a variety of tasks and make decisions with\nan increasing degree of autonomy. These autonomous agents can understand\nhigh-level instructions, interact with their environments, and execute complex\ntasks using a selection of tools available to them. As the capabilities of the\nagents expand, ensuring their safety and trustworthiness becomes more\nimperative. In this study, we introduce the Athena framework which leverages\nthe concept of verbal contrastive learning where past safe and unsafe\ntrajectories are used as in-context (contrastive) examples to guide the agent\ntowards safety while fulfilling a given task. The framework also incorporates a\ncritiquing mechanism to guide the agent to prevent risky actions at every step.\nFurthermore, due to the lack of existing benchmarks on the safety reasoning\nability of LLM-based agents, we curate a set of 80 toolkits across 8 categories\nwith 180 scenarios to provide a safety evaluation benchmark. Our experimental\nevaluation, with both closed- and open-source LLMs, indicates verbal\ncontrastive learning and interaction-level critiquing improve the safety rate\nsignificantly.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.11021v1",
    "published_date": "2024-08-20 17:21:10 UTC",
    "updated_date": "2024-08-20 17:21:10 UTC"
  },
  {
    "arxiv_id": "2408.11019v1",
    "title": "An Overlooked Role of Context-Sensitive Dendrites",
    "authors": [
      "Mohsin Raza",
      "Ahsan Adeel"
    ],
    "abstract": "To date, most dendritic studies have predominantly focused on the apical zone\nof pyramidal two-point neurons (TPNs) receiving only feedback (FB) connections\nfrom higher perceptual layers and using them for learning. Recent cellular\nneurophysiology and computational neuroscience studies suggests that the apical\ninput (context), coming from feedback and lateral connections, is multifaceted\nand far more diverse, with greater implications for ongoing learning and\nprocessing in the brain than previously realized. In addition to the FB, the\napical tuft receives signals from neighboring cells of the same network as\nproximal (P) context, other parts of the brain as distal (D) context, and\noverall coherent information across the network as universal (U) context. The\nintegrated context (C) amplifies and suppresses the transmission of coherent\nand conflicting feedforward (FF) signals, respectively. Specifically, we show\nthat complex context-sensitive (CS)-TPNs flexibly integrate C moment-by-moment\nwith the FF somatic current at the soma such that the somatic current is\namplified when both feedforward (FF) and C are coherent; otherwise, it is\nattenuated. This generates the event only when the FF and C currents are\ncoherent, which is then translated into a singlet or a burst based on the FB\ninformation. Spiking simulation results show that this flexible integration of\nsomatic and contextual currents enables the propagation of more coherent\nsignals (bursts), making learning faster with fewer neurons. Similar behavior\nis observed when this functioning is used in conventional artificial networks,\nwhere orders of magnitude fewer neurons are required to process vast amounts of\nheterogeneous real-world audio-visual (AV) data trained using backpropagation\n(BP). The computational findings presented here demonstrate the universality of\nCS-TPNs, suggesting a dendritic narrative that was previously overlooked.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11019v1",
    "published_date": "2024-08-20 17:18:54 UTC",
    "updated_date": "2024-08-20 17:18:54 UTC"
  },
  {
    "arxiv_id": "2408.11017v1",
    "title": "Multiwinner Temporal Voting with Aversion to Change",
    "authors": [
      "Valentin Zech",
      "Niclas Boehmer",
      "Edith Elkind",
      "Nicholas Teh"
    ],
    "abstract": "We study two-stage committee elections where voters have dynamic preferences\nover candidates; at each stage, a committee is chosen under a given voting\nrule. We are interested in identifying a winning committee for the second stage\nthat overlaps as much as possible with the first-stage committee. We show a\nfull complexity dichotomy for the class of Thiele rules: this problem is\ntractable for Approval Voting (AV) and hard for all other Thiele rules\n(including, in particular, Proportional Approval Voting and the\nChamberlin-Courant rule). We extend this dichotomy to the greedy variants of\nThiele rules. We also explore this problem from a parameterized complexity\nperspective for several natural parameters. We complement the theory with\nexperimental analysis: e.g., we investigate the average number of changes in\nthe committee as a function of changes in voters' preferences and the role of\nties.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.GT",
    "comment": "Appears in the 27th European Conference on Artificial Intelligence\n  (ECAI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.11017v1",
    "published_date": "2024-08-20 17:16:54 UTC",
    "updated_date": "2024-08-20 17:16:54 UTC"
  },
  {
    "arxiv_id": "2409.00054v1",
    "title": "Automating Knowledge Discovery from Scientific Literature via LLMs: A Dual-Agent Approach with Progressive Ontology Prompting",
    "authors": [
      "Yuting Hu",
      "Dancheng Liu",
      "Qingyun Wang",
      "Charles Yu",
      "Heng Ji",
      "Jinjun Xiong"
    ],
    "abstract": "To address the challenge of automating knowledge discovery from a vast volume\nof literature, in this paper, we introduce a novel framework based on large\nlanguage models (LLMs) that combines a progressive ontology prompting (POP)\nalgorithm with a dual-agent system, named LLM-Duo, designed to enhance the\nautomation of knowledge extraction from scientific articles. The POP algorithm\nutilizes a prioritized breadth-first search (BFS) across a predefined ontology\nto generate structured prompt templates and action orders, thereby guiding LLMs\nto discover knowledge in an automatic manner. Additionally, our LLM-Duo employs\ntwo specialized LLM agents: an explorer and an evaluator. These two agents work\ncollaboratively and adversarially to enhance the reliability of the discovery\nand annotation processes. Experiments demonstrate that our method outperforms\nadvanced baselines, enabling more accurate and complete annotations. To\nvalidate the effectiveness of our method in real-world scenarios, we employ our\nmethod in a case study of speech-language intervention discovery. Our method\nidentifies 2,421 interventions from 64,177 research articles in the\nspeech-language therapy domain. We curate these findings into a publicly\naccessible intervention knowledge base that holds significant potential to\nbenefit the speech-language therapy community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in submission",
    "pdf_url": "http://arxiv.org/pdf/2409.00054v1",
    "published_date": "2024-08-20 16:42:23 UTC",
    "updated_date": "2024-08-20 16:42:23 UTC"
  },
  {
    "arxiv_id": "2408.10987v1",
    "title": "Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models",
    "authors": [
      "Hojat Asgariandehkordi",
      "Sobhan Goudarzi",
      "Mostafa Sharifzadeh",
      "Adrian Basarab",
      "Hassan Rivaz"
    ],
    "abstract": "Ultrasound plane wave imaging is a cutting-edge technique that enables high\nframe-rate imaging. However, one challenge associated with high frame-rate\nultrasound imaging is the high noise associated with them, hindering their\nwider adoption. Therefore, the development of a denoising method becomes\nimperative to augment the quality of plane wave images. Drawing inspiration\nfrom Denoising Diffusion Probabilistic Models (DDPMs), our proposed solution\naims to enhance plane wave image quality. Specifically, the method considers\nthe distinction between low-angle and high-angle compounding plane waves as\nnoise and effectively eliminates it by adapting a DDPM to beamformed\nradiofrequency (RF) data. The method underwent training using only 400\nsimulated images. In addition, our approach employs natural image segmentation\nmasks as intensity maps for the generated images, resulting in accurate\ndenoising for various anatomy shapes. The proposed method was assessed across\nsimulation, phantom, and in vivo images. The results of the evaluations\nindicate that our approach not only enhances image quality on simulated data\nbut also demonstrates effectiveness on phantom and in vivo data in terms of\nimage quality. Comparative analysis with other methods underscores the\nsuperiority of our proposed method across various evaluation metrics. The\nsource code and trained model will be released along with the dataset at:\nhttp://code.sonography.ai",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10987v1",
    "published_date": "2024-08-20 16:31:31 UTC",
    "updated_date": "2024-08-20 16:31:31 UTC"
  },
  {
    "arxiv_id": "2408.10970v1",
    "title": "Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control",
    "authors": [
      "Poppy Collis",
      "Ryan Singh",
      "Paul F Kinghorn",
      "Christopher L Buckley"
    ],
    "abstract": "An open problem in artificial intelligence is how systems can flexibly learn\ndiscrete abstractions that are useful for solving inherently continuous\nproblems. Previous work has demonstrated that a class of hybrid state-space\nmodel known as recurrent switching linear dynamical systems (rSLDS) discover\nmeaningful behavioural units via the piecewise linear decomposition of complex\ncontinuous dynamics (Linderman et al., 2016). Furthermore, they model how the\nunderlying continuous states drive these discrete mode switches. We propose\nthat the rich representations formed by an rSLDS can provide useful\nabstractions for planning and control. We present a novel hierarchical\nmodel-based algorithm inspired by Active Inference in which a discrete MDP sits\nabove a low-level linear-quadratic controller. The recurrent transition\ndynamics learned by the rSLDS allow us to (1) specify temporally-abstracted\nsub-goals in a method reminiscent of the options framework, (2) lift the\nexploration into discrete space allowing us to exploit information-theoretic\nexploration bonuses and (3) `cache' the approximate solutions to low-level\nproblems in the discrete planner. We successfully apply our model to the sparse\nContinuous Mountain Car task, demonstrating fast system identification via\nenhanced exploration and non-trivial planning through the delineation of\nabstract sub-goals.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10970v1",
    "published_date": "2024-08-20 16:02:54 UTC",
    "updated_date": "2024-08-20 16:02:54 UTC"
  },
  {
    "arxiv_id": "2408.10951v1",
    "title": "Wave-Mask/Mix: Exploring Wavelet-Based Augmentations for Time Series Forecasting",
    "authors": [
      "Dona Arabi",
      "Jafar Bakhshaliyev",
      "Ayse Coskuner",
      "Kiran Madhusudhanan",
      "Kami Serdar Uckardes"
    ],
    "abstract": "Data augmentation is important for improving machine learning model\nperformance when faced with limited real-world data. In time series forecasting\n(TSF), where accurate predictions are crucial in fields like finance,\nhealthcare, and manufacturing, traditional augmentation methods for\nclassification tasks are insufficient to maintain temporal coherence. This\nresearch introduces two augmentation approaches using the discrete wavelet\ntransform (DWT) to adjust frequency elements while preserving temporal\ndependencies in time series data. Our methods, Wavelet Masking (WaveMask) and\nWavelet Mixing (WaveMix), are evaluated against established baselines across\nvarious forecasting horizons. To the best of our knowledge, this is the first\nstudy to conduct extensive experiments on multivariate time series using\nDiscrete Wavelet Transform as an augmentation technique. Experimental results\ndemonstrate that our techniques achieve competitive results with previous\nmethods. We also explore cold-start forecasting using downsampled training\ndatasets, comparing outcomes to baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10951v1",
    "published_date": "2024-08-20 15:42:10 UTC",
    "updated_date": "2024-08-20 15:42:10 UTC"
  },
  {
    "arxiv_id": "2408.10948v1",
    "title": "GAIM: Attacking Graph Neural Networks via Adversarial Influence Maximization",
    "authors": [
      "Xiaodong Yang",
      "Xiaoting Li",
      "Huiyuan Chen",
      "Yiwei Cai"
    ],
    "abstract": "Recent studies show that well-devised perturbations on graph structures or\nnode features can mislead trained Graph Neural Network (GNN) models. However,\nthese methods often overlook practical assumptions, over-rely on heuristics, or\nseparate vital attack components. In response, we present GAIM, an integrated\nadversarial attack method conducted on a node feature basis while considering\nthe strict black-box setting. Specifically, we define an adversarial influence\nfunction to theoretically assess the adversarial impact of node perturbations,\nthereby reframing the GNN attack problem into the adversarial influence\nmaximization problem. In our approach, we unify the selection of the target\nnode and the construction of feature perturbations into a single optimization\nproblem, ensuring a unique and consistent feature perturbation for each target\nnode. We leverage a surrogate model to transform this problem into a solvable\nlinear programming task, streamlining the optimization process. Moreover, we\nextend our method to accommodate label-oriented attacks, broadening its\napplicability. Thorough evaluations on five benchmark datasets across three\npopular models underscore the effectiveness of our method in both untargeted\nand label-oriented targeted attacks. Through comprehensive analysis and\nablation studies, we demonstrate the practical value and efficacy inherent to\nour design choices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10948v1",
    "published_date": "2024-08-20 15:41:20 UTC",
    "updated_date": "2024-08-20 15:41:20 UTC"
  },
  {
    "arxiv_id": "2408.10947v1",
    "title": "Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models",
    "authors": [
      "Yuyan Chen",
      "Chenwei Wu",
      "Songzhou Yan",
      "Panjun Liu",
      "Haoyu Zhou",
      "Yanghua Xiao"
    ],
    "abstract": "Teachers are important to imparting knowledge and guiding learners, and the\nrole of large language models (LLMs) as potential educators is emerging as an\nimportant area of study. Recognizing LLMs' capability to generate educational\ncontent can lead to advances in automated and personalized learning. While LLMs\nhave been tested for their comprehension and problem-solving skills, their\ncapability in teaching remains largely unexplored. In teaching, questioning is\na key skill that guides students to analyze, evaluate, and synthesize core\nconcepts and principles. Therefore, our research introduces a benchmark to\nevaluate the questioning capability in education as a teacher of LLMs through\nevaluating their generated educational questions, utilizing Anderson and\nKrathwohl's taxonomy across general, monodisciplinary, and interdisciplinary\ndomains. We shift the focus from LLMs as learners to LLMs as educators,\nassessing their teaching capability through guiding them to generate questions.\nWe apply four metrics, including relevance, coverage, representativeness, and\nconsistency, to evaluate the educational quality of LLMs' outputs. Our results\nindicate that GPT-4 demonstrates significant potential in teaching general,\nhumanities, and science courses; Claude2 appears more apt as an\ninterdisciplinary teacher. Furthermore, the automatic scores align with human\nperspectives.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10947v1",
    "published_date": "2024-08-20 15:36:30 UTC",
    "updated_date": "2024-08-20 15:36:30 UTC"
  },
  {
    "arxiv_id": "2408.10946v1",
    "title": "Large Language Model Driven Recommendation",
    "authors": [
      "Anton Korikov",
      "Scott Sanner",
      "Yashar Deldjoo",
      "Zhankui He",
      "Julian McAuley",
      "Arnau Ramisa",
      "Rene Vidal",
      "Mahesh Sathiamoorthy",
      "Atoosa Kasrizadeh",
      "Silvia Milano",
      "Francesco Ricci"
    ],
    "abstract": "While previous chapters focused on recommendation systems (RSs) based on\nstandardized, non-verbal user feedback such as purchases, views, and clicks --\nthe advent of LLMs has unlocked the use of natural language (NL) interactions\nfor recommendation. This chapter discusses how LLMs' abilities for general NL\nreasoning present novel opportunities to build highly personalized RSs -- which\ncan effectively connect nuanced and diverse user preferences to items,\npotentially via interactive dialogues. To begin this discussion, we first\npresent a taxonomy of the key data sources for language-driven recommendation,\ncovering item descriptions, user-system interactions, and user profiles. We\nthen proceed to fundamental techniques for LLM recommendation, reviewing the\nuse of encoder-only and autoregressive LLM recommendation in both tuned and\nuntuned settings. Afterwards, we move to multi-module recommendation\narchitectures in which LLMs interact with components such as retrievers and RSs\nin multi-stage pipelines. This brings us to architectures for conversational\nrecommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where\neach turn presents an opportunity not only to make recommendations, but also to\nengage with the user in interactive preference elicitation, critiquing, and\nquestion-answering.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10946v1",
    "published_date": "2024-08-20 15:36:24 UTC",
    "updated_date": "2024-08-20 15:36:24 UTC"
  },
  {
    "arxiv_id": "2408.10945v3",
    "title": "HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models",
    "authors": [
      "Kazi Hasan Ibn Arif",
      "JinYi Yoon",
      "Dimitrios S. Nikolopoulos",
      "Hans Vandierendonck",
      "Deepu John",
      "Bo Ji"
    ],
    "abstract": "High-resolution Vision-Language Models (VLMs) are widely used in multimodal\ntasks to enhance accuracy by preserving detailed image information. However,\nthese models often generate an excessive number of visual tokens due to the\nneed to encode multiple partitions of a high-resolution image input. Processing\nsuch a large number of visual tokens through multiple transformer networks\nposes significant computational challenges, particularly for\nresource-constrained commodity GPUs. To address this challenge, we propose\nHigh-Resolution Early Dropping (HiRED), a plug-and-play token-dropping method\ndesigned to operate within a fixed token budget. HiRED leverages the attention\nof CLS token in the vision transformer (ViT) to assess the visual content of\nthe image partitions and allocate an optimal token budget for each partition\naccordingly. The most informative visual tokens from each partition within the\nallocated budget are then selected and passed to the subsequent Large Language\nModel (LLM). We showed that HiRED achieves superior accuracy and performance,\ncompared to existing token-dropping methods. Empirically, HiRED-20% (i.e., a\n20% token budget) on LLaVA-Next-7B achieves a 4.7x increase in token generation\nthroughput, reduces response latency by 78%, and saves 14% of GPU memory for\nsingle inference on an NVIDIA TESLA P40 (24 GB). For larger batch sizes (e.g.,\n4), HiRED-20% prevents out-of-memory errors by cutting memory usage by 30%,\nwhile preserving throughput and latency benefits.\n  Code - https://github.com/hasanar1f/HiRED",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.10945v3",
    "published_date": "2024-08-20 15:34:27 UTC",
    "updated_date": "2024-12-25 01:27:01 UTC"
  },
  {
    "arxiv_id": "2408.10940v1",
    "title": "A Closer Look at Data Augmentation Strategies for Finetuning-Based Low/Few-Shot Object Detection",
    "authors": [
      "Vladislav Li",
      "Georgios Tsoumplekas",
      "Ilias Siniosoglou",
      "Vasileios Argyriou",
      "Anastasios Lytos",
      "Eleftherios Fountoukidis",
      "Panagiotis Sarigiannidis"
    ],
    "abstract": "Current methods for low- and few-shot object detection have primarily focused\non enhancing model performance for detecting objects. One common approach to\nachieve this is by combining model finetuning with data augmentation\nstrategies. However, little attention has been given to the energy efficiency\nof these approaches in data-scarce regimes. This paper seeks to conduct a\ncomprehensive empirical study that examines both model performance and energy\nefficiency of custom data augmentations and automated data augmentation\nselection strategies when combined with a lightweight object detector. The\nmethods are evaluated in three different benchmark datasets in terms of their\nperformance and energy consumption, and the Efficiency Factor is employed to\ngain insights into their effectiveness considering both performance and\nefficiency. Consequently, it is shown that in many cases, the performance gains\nof data augmentation strategies are overshadowed by their increased energy\nusage, necessitating the development of more energy efficient data augmentation\nstrategies to address data scarcity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10940v1",
    "published_date": "2024-08-20 15:29:56 UTC",
    "updated_date": "2024-08-20 15:29:56 UTC"
  },
  {
    "arxiv_id": "2408.10934v1",
    "title": "SDI-Net: Toward Sufficient Dual-View Interaction for Low-light Stereo Image Enhancement",
    "authors": [
      "Linlin Hu",
      "Ao Sun",
      "Shijie Hao",
      "Richang Hong",
      "Meng Wang"
    ],
    "abstract": "Currently, most low-light image enhancement methods only consider information\nfrom a single view, neglecting the correlation between cross-view information.\nTherefore, the enhancement results produced by these methods are often\nunsatisfactory. In this context, there have been efforts to develop methods\nspecifically for low-light stereo image enhancement. These methods take into\naccount the cross-view disparities and enable interaction between the left and\nright views, leading to improved performance. However, these methods still do\nnot fully exploit the interaction between left and right view information. To\naddress this issue, we propose a model called Toward Sufficient Dual-View\nInteraction for Low-light Stereo Image Enhancement (SDI-Net). The backbone\nstructure of SDI-Net is two encoder-decoder pairs, which are used to learn the\nmapping function from low-light images to normal-light images. Among the\nencoders and the decoders, we design a module named Cross-View Sufficient\nInteraction Module (CSIM), aiming to fully exploit the correlations between the\nbinocular views via the attention mechanism. The quantitative and visual\nresults on public datasets validate the superiority of our method over other\nrelated methods. Ablation studies also demonstrate the effectiveness of the key\nelements in our model.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10934v1",
    "published_date": "2024-08-20 15:17:11 UTC",
    "updated_date": "2024-08-20 15:17:11 UTC"
  },
  {
    "arxiv_id": "2408.10932v3",
    "title": "The Evolution of Reinforcement Learning in Quantitative Finance: A Survey",
    "authors": [
      "Nikolaos Pippas",
      "Elliot A. Ludvig",
      "Cagatay Turkay"
    ],
    "abstract": "Reinforcement Learning (RL) has experienced significant advancement over the\npast decade, prompting a growing interest in applications within finance. This\nsurvey critically evaluates 167 publications, exploring diverse RL applications\nand frameworks in finance. Financial markets, marked by their complexity,\nmulti-agent nature, information asymmetry, and inherent randomness, serve as an\nintriguing test-bed for RL. Traditional finance offers certain solutions, and\nRL advances these with a more dynamic approach, incorporating machine learning\nmethods, including transfer learning, meta-learning, and multi-agent solutions.\nThis survey dissects key RL components through the lens of Quantitative\nFinance. We uncover emerging themes, propose areas for future research, and\ncritique the strengths and weaknesses of existing methods.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "I.2.6; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "This work is accepted by ACM Computing Surveys on 18 April 2025 and\n  an early access version is already available here:\n  https://dl.acm.org/doi/10.1145/3733714. The arXiv copy (and the ACM CSUR\n  early-access version) is an unedited, pre-print version and it is the\n  author's version of the work",
    "pdf_url": "http://arxiv.org/pdf/2408.10932v3",
    "published_date": "2024-08-20 15:15:10 UTC",
    "updated_date": "2025-05-06 12:37:47 UTC"
  },
  {
    "arxiv_id": "2408.10923v3",
    "title": "LBC: Language-Based-Classifier for Out-Of-Variable Generalization",
    "authors": [
      "Kangjun Noh",
      "Baekryun Seong",
      "Hoyoon Byun",
      "Youngjun Choi",
      "Sungjin Song",
      "Kyungwoo Song"
    ],
    "abstract": "Large Language Models (LLMs) have great success in natural language\nprocessing tasks such as response generation. However, their use in tabular\ndata has been limited due to their inferior performance compared to traditional\nmachine learning models (TMLs) such as XGBoost. We find that the pre-trained\nknowledge of LLMs enables them to interpret new variables that appear in a test\nwithout additional training, a capability central to the concept of\nOut-of-Variable (OOV). From the findings, we propose a\nLanguage-Based-Classifier (LBC), a classifier that maximizes the benefits of\nLLMs to outperform TMLs on OOV tasks. LBC employs three key methodological\nstrategies: 1) Categorical changes to adjust data to better fit the model's\nunderstanding, 2) Advanced order and indicator to enhance data representation\nto the model, and 3) Using verbalizer to map logit scores to classes during\ninference to generate model predictions. These strategies, combined with the\npre-trained knowledge of LBC, emphasize the model's ability to effectively\nhandle OOV tasks. We empirically and theoretically validate the superiority of\nLBC. LBC is the first study to apply an LLM-based model to OOV tasks. The\nsource code is at https://github.com/sksmssh/LBCforOOVGen",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10923v3",
    "published_date": "2024-08-20 15:05:02 UTC",
    "updated_date": "2024-08-24 03:22:09 UTC"
  },
  {
    "arxiv_id": "2408.10921v1",
    "title": "MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous questions",
    "authors": [
      "Xinyu Liu",
      "Ke Jin"
    ],
    "abstract": "With the emergence of more and more economy-specific LLMS, how to measure\nwhether they can be safely invested in production becomes a problem. Previous\nresearch has primarily focused on evaluating the performance of LLMs within\nspecific application scenarios. However, these benchmarks cannot reflect the\ntheoretical level and generalization ability, and the backward datasets are\nincreasingly unsuitable for problems in real scenarios. In this paper, we have\ncompiled a new benchmark, MTFinEval, focusing on the LLMs' basic knowledge of\neconomics, which can always be used as a basis for judgment. To examine only\ntheoretical knowledge as much as possible, MTFinEval is build with foundational\nquestions from university textbooks,and exam papers in economics and management\nmajor. Aware of the overall performance of LLMs do not depend solely on one\nsubdiscipline of economics, MTFinEval comprise 360 questions refined from six\nmajor disciplines of economics, and reflect capabilities more comprehensively.\nExperiment result shows all LLMs perform poorly on MTFinEval, which proves that\nour benchmark built on basic knowledge is very successful. Our research not\nonly offers guidance for selecting the appropriate LLM for specific use cases,\nbut also put forward increase the rigor reliability of LLMs from the basics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10921v1",
    "published_date": "2024-08-20 15:04:38 UTC",
    "updated_date": "2024-08-20 15:04:38 UTC"
  },
  {
    "arxiv_id": "2408.10920v1",
    "title": "Recurrent Neural Networks Learn to Store and Generate Sequences using Non-Linear Representations",
    "authors": [
      "Róbert Csordás",
      "Christopher Potts",
      "Christopher D. Manning",
      "Atticus Geiger"
    ],
    "abstract": "The Linear Representation Hypothesis (LRH) states that neural networks learn\nto encode concepts as directions in activation space, and a strong version of\nthe LRH states that models learn only such encodings. In this paper, we present\na counterexample to this strong LRH: when trained to repeat an input token\nsequence, gated recurrent neural networks (RNNs) learn to represent the token\nat each position with a particular order of magnitude, rather than a direction.\nThese representations have layered features that are impossible to locate in\ndistinct linear subspaces. To show this, we train interventions to predict and\nmanipulate tokens by learning the scaling factor corresponding to each sequence\nposition. These interventions indicate that the smallest RNNs find only this\nmagnitude-based solution, while larger RNNs have linear representations. These\nfindings strongly indicate that interpretability research should not be\nconfined by the LRH.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10920v1",
    "published_date": "2024-08-20 15:04:37 UTC",
    "updated_date": "2024-08-20 15:04:37 UTC"
  },
  {
    "arxiv_id": "2408.10919v4",
    "title": "CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network",
    "authors": [
      "Zijian Zhao",
      "Tingwei Chen",
      "Zhijie Cai",
      "Xiaoyang Li",
      "Hang Li",
      "Qimei Chen",
      "Guangxu Zhu"
    ],
    "abstract": "In recent years, Wi-Fi sensing has garnered significant attention due to its\nnumerous benefits, such as privacy protection, low cost, and penetration\nability. Extensive research has been conducted in this field, focusing on areas\nsuch as gesture recognition, people identification, and fall detection.\nHowever, many data-driven methods encounter challenges related to domain shift,\nwhere the model fails to perform well in environments different from the\ntraining data. One major factor contributing to this issue is the limited\navailability of Wi-Fi sensing datasets, which makes models learn excessive\nirrelevant information and over-fit to the training set. Unfortunately,\ncollecting large-scale Wi-Fi sensing datasets across diverse scenarios is a\nchallenging task. To address this problem, we propose CrossFi, a siamese\nnetwork-based approach that excels in both in-domain scenario and cross-domain\nscenario, including few-shot, zero-shot scenarios, and even works in few-shot\nnew-class scenario where testing set contains new categories. The core\ncomponent of CrossFi is a sample-similarity calculation network called CSi-Net,\nwhich improves the structure of the siamese network by using an attention\nmechanism to capture similarity information, instead of simply calculating the\ndistance or cosine similarity. Based on it, we develop an extra Weight-Net that\ncan generate a template for each class, so that our CrossFi can work in\ndifferent scenarios. Experimental results demonstrate that our CrossFi achieves\nstate-of-the-art performance across various scenarios. In gesture recognition\ntask, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72%\nin one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario,\nand 84.75% in one-shot new-class scenario. The code for our model is publicly\navailable at https://github.com/RS2002/CrossFi.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10919v4",
    "published_date": "2024-08-20 15:04:14 UTC",
    "updated_date": "2025-02-14 11:12:02 UTC"
  },
  {
    "arxiv_id": "2408.10905v1",
    "title": "The impact of labeling automotive AI as \"trustworthy\" or \"reliable\" on user evaluation and technology acceptance",
    "authors": [
      "John Dorsch",
      "Ophelia Deroy"
    ],
    "abstract": "This study explores whether labeling AI as \"trustworthy\" or \"reliable\"\ninfluences user perceptions and acceptance of automotive AI technologies. Using\na one-way between-subjects design, the research involved 478 online\nparticipants who were presented with guidelines for either trustworthy or\nreliable AI. Participants then evaluated three vignette scenarios and completed\na modified version of the Technology Acceptance Model, which included variables\nsuch as perceived ease of use, human-like trust, and overall attitude. Although\nlabeling AI as \"trustworthy\" did not significantly influence judgments on\nspecific scenarios, it increased perceived ease of use and human-like trust,\nparticularly benevolence. This suggests a positive impact on usability and an\nanthropomorphic effect on user perceptions. The study provides insights into\nhow specific labels can influence attitudes toward AI technology.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "K.4.1; H.5.2; H.4.2; J.7; J.4"
    ],
    "primary_category": "cs.HC",
    "comment": "36 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10905v1",
    "published_date": "2024-08-20 14:48:24 UTC",
    "updated_date": "2024-08-20 14:48:24 UTC"
  },
  {
    "arxiv_id": "2408.10901v3",
    "title": "A Grey-box Attack against Latent Diffusion Model-based Image Editing by Posterior Collapse",
    "authors": [
      "Zhongliang Guo",
      "Chun Tong Lei",
      "Lei Fang",
      "Shuai Zhao",
      "Yifei Qian",
      "Jingyu Lin",
      "Zeyu Wang",
      "Cunjian Chen",
      "Ognjen Arandjelović",
      "Chun Pong Lau"
    ],
    "abstract": "Recent advancements in generative AI, particularly Latent Diffusion Models\n(LDMs), have revolutionized image synthesis and manipulation. However, these\ngenerative techniques raises concerns about data misappropriation and\nintellectual property infringement. Adversarial attacks on machine learning\nmodels have been extensively studied, and a well-established body of research\nhas extended these techniques as a benign metric to prevent the underlying\nmisuse of generative AI. Current approaches to safeguarding images from\nmanipulation by LDMs are limited by their reliance on model-specific knowledge\nand their inability to significantly degrade semantic quality of generated\nimages. In response to these shortcomings, we propose the Posterior Collapse\nAttack (PCA) based on the observation that VAEs suffer from posterior collapse\nduring training. Our method minimizes dependence on the white-box information\nof target models to get rid of the implicit reliance on model-specific\nknowledge. By accessing merely a small amount of LDM parameters, in specific\nmerely the VAE encoder of LDMs, our method causes a substantial semantic\ncollapse in generation quality, particularly in perceptual consistency, and\ndemonstrates strong transferability across various model architectures.\nExperimental results show that PCA achieves superior perturbation effects on\nimage generation of LDMs with lower runtime and VRAM. Our method outperforms\nexisting techniques, offering a more robust and generalizable solution that is\nhelpful in alleviating the socio-technical challenges posed by the rapidly\nevolving landscape of generative AI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 7 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10901v3",
    "published_date": "2024-08-20 14:43:53 UTC",
    "updated_date": "2025-02-21 23:11:45 UTC"
  },
  {
    "arxiv_id": "2408.10900v1",
    "title": "Towards Efficient Formal Verification of Spiking Neural Network",
    "authors": [
      "Baekryun Seong",
      "Jieung Kim",
      "Sang-Ki Ko"
    ],
    "abstract": "Recently, AI research has primarily focused on large language models (LLMs),\nand increasing accuracy often involves scaling up and consuming more power. The\npower consumption of AI has become a significant societal issue; in this\ncontext, spiking neural networks (SNNs) offer a promising solution. SNNs\noperate event-driven, like the human brain, and compress information\ntemporally. These characteristics allow SNNs to significantly reduce power\nconsumption compared to perceptron-based artificial neural networks (ANNs),\nhighlighting them as a next-generation neural network technology. However,\nsocietal concerns regarding AI go beyond power consumption, with the\nreliability of AI models being a global issue. For instance, adversarial\nattacks on AI models are a well-studied problem in the context of traditional\nneural networks. Despite their importance, the stability and property\nverification of SNNs remains in the early stages of research. Most SNN\nverification methods are time-consuming and barely scalable, making practical\napplications challenging. In this paper, we introduce temporal encoding to\nachieve practical performance in verifying the adversarial robustness of SNNs.\nWe conduct a theoretical analysis of this approach and demonstrate its success\nin verifying SNNs at previously unmanageable scales. Our contribution advances\nSNN verification to a practical level, facilitating the safer application of\nSNNs.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10900v1",
    "published_date": "2024-08-20 14:43:33 UTC",
    "updated_date": "2024-08-20 14:43:33 UTC"
  },
  {
    "arxiv_id": "2408.10895v1",
    "title": "Analytical and Empirical Study of Herding Effects in Recommendation Systems",
    "authors": [
      "Hong Xie",
      "Mingze Zhong",
      "Defu Lian",
      "Zhen Wang",
      "Enhong Chen"
    ],
    "abstract": "Online rating systems are often used in numerous web or mobile applications,\ne.g., Amazon and TripAdvisor, to assess the ground-truth quality of products.\nDue to herding effects, the aggregation of historical ratings (or historical\ncollective opinion) can significantly influence subsequent ratings, leading to\nmisleading and erroneous assessments. We study how to manage product ratings\nvia rating aggregation rules and shortlisted representative reviews, for the\npurpose of correcting the assessment error. We first develop a mathematical\nmodel to characterize important factors of herding effects in product ratings.\nWe then identify sufficient conditions (via the stochastic approximation\ntheory), under which the historical collective opinion converges to the\nground-truth collective opinion of the whole user population. These conditions\nidentify a class of rating aggregation rules and review selection mechanisms\nthat can reveal the ground-truth product quality. We also quantify the speed of\nconvergence (via the martingale theory), which reflects the efficiency of\nrating aggregation rules and review selection mechanisms. We prove that the\nherding effects slow down the speed of convergence while an accurate review\nselection mechanism can speed it up. We also study the speed of convergence\nnumerically and reveal trade-offs in selecting rating aggregation rules and\nreview selection mechanisms. To show the utility of our framework, we design a\nmaximum likelihood algorithm to infer model parameters from ratings, and\nconduct experiments on rating datasets from Amazon and TripAdvisor. We show\nthat proper recency aware rating aggregation rules can improve the speed of\nconvergence in Amazon and TripAdvisor by 41% and 62% respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.10895v1",
    "published_date": "2024-08-20 14:29:23 UTC",
    "updated_date": "2024-08-20 14:29:23 UTC"
  },
  {
    "arxiv_id": "2408.10889v2",
    "title": "On Learning Action Costs from Input Plans",
    "authors": [
      "Marianela Morales",
      "Alberto Pozanco",
      "Giuseppe Canonaco",
      "Sriram Gopalakrishnan",
      "Daniel Borrajo",
      "Manuela Veloso"
    ],
    "abstract": "Most of the work on learning action models focus on learning the actions'\ndynamics from input plans. This allows us to specify the valid plans of a\nplanning task. However, very little work focuses on learning action costs,\nwhich in turn allows us to rank the different plans. In this paper we introduce\na new problem: that of learning the costs of a set of actions such that a set\nof input plans are optimal under the resulting planning model. To solve this\nproblem we present $LACFIP^k$, an algorithm to learn action's costs from\nunlabeled input plans. We provide theoretical and empirical results showing how\n$LACFIP^k$ can successfully solve this task.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10889v2",
    "published_date": "2024-08-20 14:20:19 UTC",
    "updated_date": "2024-09-02 09:48:43 UTC"
  },
  {
    "arxiv_id": "2408.10883v2",
    "title": "Dynamic Analysis and Adaptive Discriminator for Fake News Detection",
    "authors": [
      "Xinqi Su",
      "Zitong Yu",
      "Yawen Cui",
      "Ajian Liu",
      "Xun Lin",
      "Yuhao Wang",
      "Haochen Liang",
      "Wenhui Li",
      "Li Shen",
      "Xiaochun Cao"
    ],
    "abstract": "In current web environment, fake news spreads rapidly across online social\nnetworks, posing serious threats to society. Existing multimodal fake news\ndetection methods can generally be classified into knowledge-based and\nsemantic-based approaches. However, these methods are heavily rely on human\nexpertise and feedback, lacking flexibility. To address this challenge, we\npropose a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fake\nnews detection. For knowledge-based methods, we introduce the Monte Carlo Tree\nSearch algorithm to leverage the self-reflective capabilities of large language\nmodels (LLMs) for prompt optimization, providing richer, domain-specific\ndetails and guidance to the LLMs, while enabling more flexible integration of\nLLM comment on news content. For semantic-based methods, we define four typical\ndeceit patterns: emotional exaggeration, logical inconsistency, image\nmanipulation, and semantic inconsistency, to reveal the mechanisms behind fake\nnews creation. To detect these patterns, we carefully design four\ndiscriminators and expand them in depth and breadth, using the soft-routing\nmechanism to explore optimal detection models. Experimental results on three\nreal-world datasets demonstrate the superiority of our approach. The code will\nbe available at: https://github.com/SuXinqi/DAAD.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10883v2",
    "published_date": "2024-08-20 14:13:54 UTC",
    "updated_date": "2025-03-11 03:05:45 UTC"
  },
  {
    "arxiv_id": "2408.10878v3",
    "title": "Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble",
    "authors": [
      "Han-Jun Choi",
      "Hyunsung Kim",
      "Minho Lee",
      "Minchul Jeong",
      "Chang-Jo Kim",
      "Jinsung Yoon",
      "Sang-Ki Ko"
    ],
    "abstract": "Multi-agent trajectory data collected from domains such as team sports often\nsuffer from missing values due to various factors. While many imputation\nmethods have been proposed for spatiotemporal data, they are not well-suited\nfor multi-agent sports scenarios where player movements are highly dynamic and\ninter-agent interactions continuously evolve. To address these challenges, we\npropose MIDAS (Multi-agent Imputer with Derivative-Accumulating Self-ensemble),\na framework that imputes multi-agent trajectories with high accuracy and\nphysical plausibility. It jointly predicts positions, velocities, and\naccelerations through a Set Transformer-based neural network and generates\nalternative estimates by recursively accumulating predicted velocity and\nacceleration values. These predictions are then combined using a learnable\nweighted ensemble to produce final imputed trajectories. Experiments on three\nsports datasets demonstrate that MIDAS significantly outperforms existing\nbaselines in both positional accuracy and physical plausibility. Lastly, we\nshowcase use cases of MIDAS, such as approximating total distance and pass\nsuccess probability, to highlight its applicability to practical downstream\ntasks that require complete tracking data.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10878v3",
    "published_date": "2024-08-20 14:08:16 UTC",
    "updated_date": "2025-03-23 17:12:21 UTC"
  },
  {
    "arxiv_id": "2408.10872v2",
    "title": "V-RoAst: A New Dataset for Visual Road Assessment",
    "authors": [
      "Natchapon Jongwiriyanurak",
      "Zichao Zeng",
      "June Moh Goo",
      "Xinglei Wang",
      "Ilya Ilyankou",
      "Kerkritt Srirrongvikrai",
      "Meihui Wang",
      "James Haworth"
    ],
    "abstract": "Road traffic crashes cause millions of deaths annually and have a significant\neconomic impact, particularly in low- and middle-income countries (LMICs). This\npaper presents an approach using Vision Language Models (VLMs) for road safety\nassessment, overcoming the limitations of traditional Convolutional Neural\nNetworks (CNNs). We introduce a new task ,V-RoAst (Visual question answering\nfor Road Assessment), with a real-world dataset. Our approach optimizes prompt\nengineering and evaluates advanced VLMs, including Gemini-1.5-flash and\nGPT-4o-mini. The models effectively examine attributes for road assessment.\nUsing crowdsourced imagery from Mapillary, our scalable solution influentially\nestimates road safety levels. In addition, this approach is designed for local\nstakeholders who lack resources, as it does not require training data. It\noffers a cost-effective and automated methods for global road safety\nassessments, potentially saving lives and reducing economic burdens.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10872v2",
    "published_date": "2024-08-20 14:03:30 UTC",
    "updated_date": "2024-08-21 11:40:49 UTC"
  },
  {
    "arxiv_id": "2408.10871v1",
    "title": "Radio U-Net: a convolutional neural network to detect diffuse radio sources in galaxy clusters and beyond",
    "authors": [
      "Chiara Stuardi",
      "Claudio Gheller",
      "Franco Vazza",
      "Andrea Botteon"
    ],
    "abstract": "The forthcoming generation of radio telescope arrays promises significant\nadvancements in sensitivity and resolution, enabling the identification and\ncharacterization of many new faint and diffuse radio sources. Conventional\nmanual cataloging methodologies are anticipated to be insufficient to exploit\nthe capabilities of new radio surveys. Radio interferometric images of diffuse\nsources present a challenge for image segmentation tasks due to noise,\nartifacts, and embedded radio sources. In response to these challenges, we\nintroduce Radio U-Net, a fully convolutional neural network based on the U-Net\narchitecture. Radio U-Net is designed to detect faint and extended sources in\nradio surveys, such as radio halos, relics, and cosmic web filaments. Radio\nU-Net was trained on synthetic radio observations built upon cosmological\nsimulations and then tested on a sample of galaxy clusters, where the detection\nof cluster diffuse radio sources relied on customized data reduction and visual\ninspection of LOFAR Two Metre Sky Survey (LoTSS) data. The 83% of clusters\nexhibiting diffuse radio emission were accurately identified, and the\nsegmentation successfully recovered the morphology of the sources even in\nlow-quality images. In a test sample comprising 246 galaxy clusters, we\nachieved a 73% accuracy rate in distinguishing between clusters with and\nwithout diffuse radio emission. Our results establish the applicability of\nRadio U-Net to extensive radio survey datasets, probing its efficiency on\ncutting-edge high-performance computing systems. This approach represents an\nadvancement in optimizing the exploitation of forthcoming large radio surveys\nfor scientific exploration.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Accepted by MNRAS, 16 pages, 9 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10871v1",
    "published_date": "2024-08-20 14:03:21 UTC",
    "updated_date": "2024-08-20 14:03:21 UTC"
  },
  {
    "arxiv_id": "2408.10865v1",
    "title": "Multi-agent Multi-armed Bandits with Stochastic Sharable Arm Capacities",
    "authors": [
      "Hong Xie",
      "Jinyu Mo",
      "Defu Lian",
      "Jie Wang",
      "Enhong Chen"
    ],
    "abstract": "Motivated by distributed selection problems, we formulate a new variant of\nmulti-player multi-armed bandit (MAB) model, which captures stochastic arrival\nof requests to each arm, as well as the policy of allocating requests to\nplayers. The challenge is how to design a distributed learning algorithm such\nthat players select arms according to the optimal arm pulling profile (an arm\npulling profile prescribes the number of players at each arm) without\ncommunicating to each other. We first design a greedy algorithm, which locates\none of the optimal arm pulling profiles with a polynomial computational\ncomplexity. We also design an iterative distributed algorithm for players to\ncommit to an optimal arm pulling profile with a constant number of rounds in\nexpectation. We apply the explore then commit (ETC) framework to address the\nonline setting when model parameters are unknown. We design an exploration\nstrategy for players to estimate the optimal arm pulling profile. Since such\nestimates can be different across different players, it is challenging for\nplayers to commit. We then design an iterative distributed algorithm, which\nguarantees that players can arrive at a consensus on the optimal arm pulling\nprofile in only M rounds. We conduct experiments to validate our algorithm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.10865v1",
    "published_date": "2024-08-20 13:57:00 UTC",
    "updated_date": "2024-08-20 13:57:00 UTC"
  },
  {
    "arxiv_id": "2408.10858v1",
    "title": "Knowledge Sharing and Transfer via Centralized Reward Agent for Multi-Task Reinforcement Learning",
    "authors": [
      "Haozhe Ma",
      "Zhengding Luo",
      "Thanh Vinh Vo",
      "Kuankuan Sima",
      "Tze-Yun Leong"
    ],
    "abstract": "Reward shaping is effective in addressing the sparse-reward challenge in\nreinforcement learning by providing immediate feedback through auxiliary\ninformative rewards. Based on the reward shaping strategy, we propose a novel\nmulti-task reinforcement learning framework, that integrates a centralized\nreward agent (CRA) and multiple distributed policy agents. The CRA functions as\na knowledge pool, which aims to distill knowledge from various tasks and\ndistribute it to individual policy agents to improve learning efficiency.\nSpecifically, the shaped rewards serve as a straightforward metric to encode\nknowledge. This framework not only enhances knowledge sharing across\nestablished tasks but also adapts to new tasks by transferring valuable reward\nsignals. We validate the proposed method on both discrete and continuous\ndomains, demonstrating its robustness in multi-task sparse-reward settings and\nits effective transferability to unseen tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10858v1",
    "published_date": "2024-08-20 13:49:26 UTC",
    "updated_date": "2024-08-20 13:49:26 UTC"
  },
  {
    "arxiv_id": "2408.10854v1",
    "title": "MambaDS: Near-Surface Meteorological Field Downscaling with Topography Constrained Selective State Space Modeling",
    "authors": [
      "Zili Liu",
      "Hao Chen",
      "Lei Bai",
      "Wenyuan Li",
      "Wanli Ouyang",
      "Zhengxia Zou",
      "Zhenwei Shi"
    ],
    "abstract": "In an era of frequent extreme weather and global warming, obtaining precise,\nfine-grained near-surface weather forecasts is increasingly essential for human\nactivities. Downscaling (DS), a crucial task in meteorological forecasting,\nenables the reconstruction of high-resolution meteorological states for target\nregions from global-scale forecast results. Previous downscaling methods,\ninspired by CNN and Transformer-based super-resolution models, lacked tailored\ndesigns for meteorology and encountered structural limitations. Notably, they\nfailed to efficiently integrate topography, a crucial prior in the downscaling\nprocess. In this paper, we address these limitations by pioneering the\nselective state space model into the meteorological field downscaling and\npropose a novel model called MambaDS. This model enhances the utilization of\nmultivariable correlations and topography information, unique challenges in the\ndownscaling process while retaining the advantages of Mamba in long-range\ndependency modeling and linear computational complexity. Through extensive\nexperiments in both China mainland and the continental United States (CONUS),\nwe validated that our proposed MambaDS achieves state-of-the-art results in\nthree different types of meteorological field downscaling settings. We will\nrelease the code subsequently.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10854v1",
    "published_date": "2024-08-20 13:45:49 UTC",
    "updated_date": "2024-08-20 13:45:49 UTC"
  },
  {
    "arxiv_id": "2408.10853v1",
    "title": "Does Current Deepfake Audio Detection Model Effectively Detect ALM-based Deepfake Audio?",
    "authors": [
      "Yuankun Xie",
      "Chenxu Xiong",
      "Xiaopeng Wang",
      "Zhiyong Wang",
      "Yi Lu",
      "Xin Qi",
      "Ruibo Fu",
      "Yukun Liu",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Guanjun Li",
      "Long Ye"
    ],
    "abstract": "Currently, Audio Language Models (ALMs) are rapidly advancing due to the\ndevelopments in large language models and audio neural codecs. These ALMs have\nsignificantly lowered the barrier to creating deepfake audio, generating highly\nrealistic and diverse types of deepfake audio, which pose severe threats to\nsociety. Consequently, effective audio deepfake detection technologies to\ndetect ALM-based audio have become increasingly critical. This paper\ninvestigate the effectiveness of current countermeasure (CM) against ALM-based\naudio. Specifically, we collect 12 types of the latest ALM-based deepfake audio\nand utilizing the latest CMs to evaluate. Our findings reveal that the latest\ncodec-trained CM can effectively detect ALM-based audio, achieving 0% equal\nerror rate under most ALM test conditions, which exceeded our expectations.\nThis indicates promising directions for future research in ALM-based deepfake\naudio detection.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10853v1",
    "published_date": "2024-08-20 13:45:34 UTC",
    "updated_date": "2024-08-20 13:45:34 UTC"
  },
  {
    "arxiv_id": "2408.10831v1",
    "title": "ZebraPose: Zebra Detection and Pose Estimation using only Synthetic Data",
    "authors": [
      "Elia Bonetto",
      "Aamir Ahmad"
    ],
    "abstract": "Synthetic data is increasingly being used to address the lack of labeled\nimages in uncommon domains for deep learning tasks. A prominent example is 2D\npose estimation of animals, particularly wild species like zebras, for which\ncollecting real-world data is complex and impractical. However, many approaches\nstill require real images, consistency and style constraints, sophisticated\nanimal models, and/or powerful pre-trained networks to bridge the syn-to-real\ngap. Moreover, they often assume that the animal can be reliably detected in\nimages or videos, a hypothesis that often does not hold, e.g. in wildlife\nscenarios or aerial images. To solve this, we use synthetic data generated with\na 3D photorealistic simulator to obtain the first synthetic dataset that can be\nused for both detection and 2D pose estimation of zebras without applying any\nof the aforementioned bridging strategies. Unlike previous works, we\nextensively train and benchmark our detection and 2D pose estimation models on\nmultiple real-world and synthetic datasets using both pre-trained and\nnon-pre-trained backbones. These experiments show how the models trained from\nscratch and only with synthetic data can consistently generalize to real-world\nimages of zebras in both tasks. Moreover, we show it is possible to easily\ngeneralize those same models to 2D pose estimation of horses with a minimal\namount of real-world images to account for the domain transfer. Code, results,\ntrained models; and the synthetic, training, and validation data, including\n104K manually labeled frames, are provided as open-source at\nhttps://zebrapose.is.tue.mpg.de/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 tables, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10831v1",
    "published_date": "2024-08-20 13:28:37 UTC",
    "updated_date": "2024-08-20 13:28:37 UTC"
  },
  {
    "arxiv_id": "2408.11876v2",
    "title": "From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis",
    "authors": [
      "Guy Lutsker",
      "Gal Sapir",
      "Smadar Shilo",
      "Jordi Merino",
      "Anastasia Godneva",
      "Jerry R Greenfield",
      "Dorit Samocha-Bonet",
      "Raja Dhir",
      "Francisco Gude",
      "Shie Mannor",
      "Eli Meirom",
      "Gal Chechik",
      "Hagai Rossman",
      "Eran Segal"
    ],
    "abstract": "Recent advances in SSL enabled novel medical AI models, known as foundation\nmodels, offer great potential for better characterizing health from diverse\nbiomedical data. CGM provides rich, temporal data on glycemic patterns, but its\nfull potential for predicting broader health outcomes remains underutilized.\nHere, we present GluFormer, a generative foundation model for CGM data that\nlearns nuanced glycemic patterns and translates them into predictive\nrepresentations of metabolic health. Trained on over 10 million CGM\nmeasurements from 10,812 adults, primarily without diabetes, GluFormer uses\nautoregressive token prediction to capture longitudinal glucose dynamics. We\nshow that GluFormer generalizes to 19 external cohorts (n=6,044) spanning\ndifferent ethnicities and ages, 5 countries, 8 CGM devices, and diverse\npathophysiological states. GluFormers representations exceed the performance of\ncurrent CGM metrics, such as the Glucose Management Indicator (GMI), for\nforecasting clinical measures. In a longitudinal study of 580 adults with CGM\ndata and 12-year follow-up, GluFormer identifies individuals at elevated risk\nof developing diabetes more effectively than blood HbA1C%, capturing 66% of all\nnew-onset diabetes diagnoses in the top quartile versus 7% in the bottom\nquartile. Similarly, 69% of cardiovascular-death events occurred in the top\nquartile with none in the bottom quartile, demonstrating powerful risk\nstratification beyond traditional glycemic metrics. We also show that CGM\nrepresentations from pre-intervention periods in Randomized Clinical Trials\noutperform other methods in predicting primary and secondary outcomes. When\nintegrating dietary data into GluFormer, we show that the multi-modal version\nof the model can accurately generate CGM data based on dietary intake data,\nsimulate outcomes of dietary interventions, and predict individual responses to\nspecific foods.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11876v2",
    "published_date": "2024-08-20 13:19:06 UTC",
    "updated_date": "2025-01-07 16:01:15 UTC"
  },
  {
    "arxiv_id": "2408.10819v2",
    "title": "GS-KGC: A Generative Subgraph-based Framework for Knowledge Graph Completion with Large Language Models",
    "authors": [
      "Rui Yang",
      "Jiahao Zhu",
      "Jianping Man",
      "Hongze Liu",
      "Li Fang",
      "Yi Zhou"
    ],
    "abstract": "Knowledge graph completion (KGC) focuses on identifying missing triples in a\nknowledge graph (KG) , which is crucial for many downstream applications. Given\nthe rapid development of large language models (LLMs), some LLM-based methods\nare proposed for KGC task. However, most of them focus on prompt engineering\nwhile overlooking the fact that finer-grained subgraph information can aid LLMs\nin generating more accurate answers. In this paper, we propose a novel\ncompletion framework called \\textbf{G}enerative \\textbf{S}ubgraph-based KGC\n(GS-KGC), which utilizes subgraph information as contextual reasoning and\nemploys a QA approach to achieve the KGC task. This framework primarily\nincludes a subgraph partitioning algorithm designed to generate negatives and\nneighbors. Specifically, negatives can encourage LLMs to generate a broader\nrange of answers, while neighbors provide additional contextual insights for\nLLM reasoning. Furthermore, we found that GS-KGC can discover potential triples\nwithin the KGs and new facts beyond the KGs. Experiments conducted on four\ncommon KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it\nshows a 5.6\\% increase in Hits@3 compared to the LLM-based model CP-KGC on the\nFB15k-237N, and a 9.3\\% increase over the LLM-based model TECHS on the ICEWS14.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10819v2",
    "published_date": "2024-08-20 13:13:41 UTC",
    "updated_date": "2025-01-03 04:12:32 UTC"
  },
  {
    "arxiv_id": "2408.10811v1",
    "title": "Beyond English-Centric LLMs: What Language Do Multilingual Language Models Think in?",
    "authors": [
      "Chengzhi Zhong",
      "Fei Cheng",
      "Qianying Liu",
      "Junfeng Jiang",
      "Zhen Wan",
      "Chenhui Chu",
      "Yugo Murawaki",
      "Sadao Kurohashi"
    ],
    "abstract": "In this study, we investigate whether non-English-centric LLMs, despite their\nstrong performance, `think' in their respective dominant language: more\nprecisely, `think' refers to how the representations of intermediate layers,\nwhen un-embedded into the vocabulary space, exhibit higher probabilities for\ncertain dominant languages during generation. We term such languages as\ninternal $\\textbf{latent languages}$.\n  We examine the latent language of three typical categories of models for\nJapanese processing: Llama2, an English-centric model; Swallow, an\nEnglish-centric model with continued pre-training in Japanese; and LLM-jp, a\nmodel pre-trained on balanced English and Japanese corpora. Our empirical\nfindings reveal that, unlike Llama2 which relies exclusively on English as the\ninternal latent language, Japanese-specific Swallow and LLM-jp employ both\nJapanese and English, exhibiting dual internal latent languages. For any given\ntarget language, the model preferentially activates the latent language most\nclosely related to it. In addition, we explore how intermediate layers respond\nto questions involving cultural conflicts between latent internal and target\noutput languages. We further explore how the language identity shifts across\nlayers while keeping consistent semantic meaning reflected in the intermediate\nlayer representations.\n  This study deepens the understanding of non-English-centric large language\nmodels, highlighting the intricate dynamics of language representation within\ntheir intermediate layers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2408.10811v1",
    "published_date": "2024-08-20 13:05:41 UTC",
    "updated_date": "2024-08-20 13:05:41 UTC"
  },
  {
    "arxiv_id": "2408.10807v1",
    "title": "DisMix: Disentangling Mixtures of Musical Instruments for Source-level Pitch and Timbre Manipulation",
    "authors": [
      "Yin-Jyun Luo",
      "Kin Wai Cheuk",
      "Woosung Choi",
      "Toshimitsu Uesaka",
      "Keisuke Toyama",
      "Koichi Saito",
      "Chieh-Hsin Lai",
      "Yuhta Takida",
      "Wei-Hsiang Liao",
      "Simon Dixon",
      "Yuki Mitsufuji"
    ],
    "abstract": "Existing work on pitch and timbre disentanglement has been mostly focused on\nsingle-instrument music audio, excluding the cases where multiple instruments\nare presented. To fill the gap, we propose DisMix, a generative framework in\nwhich the pitch and timbre representations act as modular building blocks for\nconstructing the melody and instrument of a source, and the collection of which\nforms a set of per-instrument latent representations underlying the observed\nmixture. By manipulating the representations, our model samples mixtures with\nnovel combinations of pitch and timbre of the constituent instruments. We can\njointly learn the disentangled pitch-timbre representations and a latent\ndiffusion transformer that reconstructs the mixture conditioned on the set of\nsource-level representations. We evaluate the model using both a simple dataset\nof isolated chords and a realistic four-part chorales in the style of J.S.\nBach, identify the key components for the success of disentanglement, and\ndemonstrate the application of mixture transformation based on source-level\nattribute manipulation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10807v1",
    "published_date": "2024-08-20 12:56:49 UTC",
    "updated_date": "2024-08-20 12:56:49 UTC"
  },
  {
    "arxiv_id": "2408.10802v1",
    "title": "Inverse Deep Learning Ray Tracing for Heliostat Surface Prediction",
    "authors": [
      "Jan Lewen",
      "Max Pargmann",
      "Mehdi Cherti",
      "Jenia Jitsev",
      "Robert Pitz-Paal",
      "Daniel Maldonado Quinto"
    ],
    "abstract": "Concentrating Solar Power (CSP) plants play a crucial role in the global\ntransition towards sustainable energy. A key factor in ensuring the safe and\nefficient operation of CSP plants is the distribution of concentrated flux\ndensity on the receiver. However, the non-ideal flux density generated by\nindividual heliostats can undermine the safety and efficiency of the power\nplant. The flux density from each heliostat is influenced by its precise\nsurface profile, which includes factors such as canting and mirror errors.\nAccurately measuring these surface profiles for a large number of heliostats in\noperation is a formidable challenge. Consequently, control systems often rely\non the assumption of ideal surface conditions, which compromises both safety\nand operational efficiency. In this study, we introduce inverse Deep Learning\nRay Tracing (iDLR), an innovative method designed to predict heliostat surfaces\nbased solely on target images obtained during heliostat calibration. Our\nsimulation-based investigation demonstrates that sufficient information\nregarding the heliostat surface is retained in the flux density distribution of\na single heliostat, enabling deep learning models to accurately predict the\nunderlying surface with deflectometry-like precision for the majority of\nheliostats. Additionally, we assess the limitations of this method,\nparticularly in relation to surface accuracy and resultant flux density\npredictions. Furthermore, we are presenting a new comprehensive heliostat model\nusing Non-Uniform Rational B-Spline (NURBS) that has the potential to become\nthe new State of the Art for heliostat surface parameterization. Our findings\nreveal that iDLR has significant potential to enhance CSP plant operations,\npotentially increasing the overall efficiency and energy output of the power\nplants.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10802v1",
    "published_date": "2024-08-20 12:51:35 UTC",
    "updated_date": "2024-08-20 12:51:35 UTC"
  },
  {
    "arxiv_id": "2408.10788v1",
    "title": "Understanding the Skills Gap between Higher Education and Industry in the UK in Artificial Intelligence Sector",
    "authors": [
      "Khushi Jaiswal",
      "Ievgeniia Kuzminykh",
      "Sanjay Modgil"
    ],
    "abstract": "As Artificial Intelligence (AI) changes how businesses work, there is a\ngrowing need for people who can work in this sector. This paper investigates\nhow well universities in United Kingdom offering courses in AI, prepare\nstudents for jobs in the real world. To gain insight into the differences\nbetween university curricula and industry demands we review the contents of\ntaught courses and job advertisement portals. By using custom data scraping\ntools to gather information from job advertisements and university curricula,\nand frequency and Naive Bayes classifier analysis, this study will show exactly\nwhat skills industry is looking for. In this study we identified 12 skill\ncategories that were used for mapping. The study showed that the university\ncurriculum in the AI domain is well balanced in most technical skills,\nincluding Programming and Machine learning subjects, but have a gap in Data\nScience and Maths and Statistics skill categories.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the journal \"Industry and Higher Education\"",
    "pdf_url": "http://arxiv.org/pdf/2408.10788v1",
    "published_date": "2024-08-20 12:28:58 UTC",
    "updated_date": "2024-08-20 12:28:58 UTC"
  },
  {
    "arxiv_id": "2408.10777v1",
    "title": "Just a Hint: Point-Supervised Camouflaged Object Detection",
    "authors": [
      "Huafeng Chen",
      "Dian Shao",
      "Guangqian Guo",
      "Shan Gao"
    ],
    "abstract": "Camouflaged Object Detection (COD) demands models to expeditiously and\naccurately distinguish objects which conceal themselves seamlessly in the\nenvironment. Owing to the subtle differences and ambiguous boundaries, COD is\nnot only a remarkably challenging task for models but also for human\nannotators, requiring huge efforts to provide pixel-wise annotations. To\nalleviate the heavy annotation burden, we propose to fulfill this task with the\nhelp of only one point supervision. Specifically, by swiftly clicking on each\nobject, we first adaptively expand the original point-based annotation to a\nreasonable hint area. Then, to avoid partial localization around discriminative\nparts, we propose an attention regulator to scatter model attention to the\nwhole object through partially masking labeled regions. Moreover, to solve the\nunstable feature representation of camouflaged objects under only point-based\nannotation, we perform unsupervised contrastive learning based on differently\naugmented image pairs (e.g. changing color or doing translation). On three\nmainstream COD benchmarks, experimental results show that our model outperforms\nseveral weakly-supervised methods by a large margin across various metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10777v1",
    "published_date": "2024-08-20 12:17:25 UTC",
    "updated_date": "2024-08-20 12:17:25 UTC"
  },
  {
    "arxiv_id": "2408.10774v3",
    "title": "Flexora: Flexible Low Rank Adaptation for Large Language Models",
    "authors": [
      "Chenxing Wei",
      "Yao Shu",
      "Ying Tiffany He",
      "Fei Richard Yu"
    ],
    "abstract": "Large Language Models (LLMs) are driving advancements in artificial\nintelligence by increasing the scale of model parameters, which has\nsignificantly enhanced generalization ability and unlocked new capabilities in\npractice. However, their performance in specific downstream tasks is usually\nhindered by their knowledge boundaries on these tasks. Thus, fine-tuning\ntechniques, especially the widely used Low-Rank Adaptation (LoRA) method, have\nbeen introduced to expand the boundaries on these tasks, whereas LoRA would\nunderperform on certain tasks owing to its potential overfitting on these\ntasks. To overcome this overfitting and improve the performance of LoRA, we\npropose the flexible low rank adaptation (Flexora) method to automatically and\nflexibly select the most important layers needing to be fine-tuned to achieve\nthe best performance on different downstream tasks. Specifically, Flexora\nfirstly frames this layer selection problem as a well-defined hyperparameter\noptimization (HPO) problem, then addresses it using the unrolled\ndifferentiation (UD) method, and finally selects the most useful layers based\non the optimized hyperparameters. Our extensive experiments on many pretrained\nmodels and natural language tasks show that Flexora is able to consistently\nimprove over the existing baselines, indicating the effectiveness of our\nFlexora in practice. We additionally provide insightful theoretical results and\nmany ablation studies to deliver a comprehensive understanding of our Flexora.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10774v3",
    "published_date": "2024-08-20 12:13:04 UTC",
    "updated_date": "2025-02-18 13:53:51 UTC"
  },
  {
    "arxiv_id": "2408.10771v3",
    "title": "kNN Retrieval for Simple and Effective Zero-Shot Multi-speaker Text-to-Speech",
    "authors": [
      "Karl El Hajal",
      "Ajinkya Kulkarni",
      "Enno Hermann",
      "Mathew Magimai. -Doss"
    ],
    "abstract": "While recent zero-shot multi-speaker text-to-speech (TTS) models achieve\nimpressive results, they typically rely on extensive transcribed speech\ndatasets from numerous speakers and intricate training pipelines. Meanwhile,\nself-supervised learning (SSL) speech features have emerged as effective\nintermediate representations for TTS. Further, SSL features from different\nspeakers that are linearly close share phonetic information while maintaining\nindividual speaker identity. In this study, we introduce kNN-TTS, a simple and\neffective framework for zero-shot multi-speaker TTS using retrieval methods\nwhich leverage the linear relationships between SSL features. Objective and\nsubjective evaluations show that our models, trained on transcribed speech from\na single speaker only, achieve performance comparable to state-of-the-art\nmodels that are trained on significantly larger training datasets. The low\ntraining data requirements mean that kNN-TTS is well suited for the development\nof multi-speaker TTS systems for low-resource domains and languages. We also\nintroduce an interpolation parameter which enables fine-grained voice morphing.\nDemo samples are available at https://idiap.github.io/knn-tts",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.10771v3",
    "published_date": "2024-08-20 12:09:58 UTC",
    "updated_date": "2025-02-03 16:47:44 UTC"
  },
  {
    "arxiv_id": "2408.10760v1",
    "title": "SAM-COD: SAM-guided Unified Framework for Weakly-Supervised Camouflaged Object Detection",
    "authors": [
      "Huafeng Chen",
      "Pengxu Wei",
      "Guangqian Guo",
      "Shan Gao"
    ],
    "abstract": "Most Camouflaged Object Detection (COD) methods heavily rely on mask\nannotations, which are time-consuming and labor-intensive to acquire. Existing\nweakly-supervised COD approaches exhibit significantly inferior performance\ncompared to fully-supervised methods and struggle to simultaneously support all\nthe existing types of camouflaged object labels, including scribbles, bounding\nboxes, and points. Even for Segment Anything Model (SAM), it is still\nproblematic to handle the weakly-supervised COD and it typically encounters\nchallenges of prompt compatibility of the scribble labels, extreme response,\nsemantically erroneous response, and unstable feature representations,\nproducing unsatisfactory results in camouflaged scenes. To mitigate these\nissues, we propose a unified COD framework in this paper, termed SAM-COD, which\nis capable of supporting arbitrary weakly-supervised labels. Our SAM-COD\nemploys a prompt adapter to handle scribbles as prompts based on SAM.\nMeanwhile, we introduce response filter and semantic matcher modules to improve\nthe quality of the masks obtained by SAM under COD prompts. To alleviate the\nnegative impacts of inaccurate mask predictions, a new strategy of\nprompt-adaptive knowledge distillation is utilized to ensure a reliable feature\nrepresentation. To validate the effectiveness of our approach, we have\nconducted extensive empirical experiments on three mainstream COD benchmarks.\nThe results demonstrate the superiority of our method against state-of-the-art\nweakly-supervised and even fully-supervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10760v1",
    "published_date": "2024-08-20 11:49:27 UTC",
    "updated_date": "2024-08-20 11:49:27 UTC"
  },
  {
    "arxiv_id": "2408.10755v1",
    "title": "Generating Synthetic Fair Syntax-agnostic Data by Learning and Distilling Fair Representation",
    "authors": [
      "Md Fahim Sikder",
      "Resmi Ramachandranpillai",
      "Daniel de Leng",
      "Fredrik Heintz"
    ],
    "abstract": "Data Fairness is a crucial topic due to the recent wide usage of AI powered\napplications. Most of the real-world data is filled with human or machine\nbiases and when those data are being used to train AI models, there is a chance\nthat the model will reflect the bias in the training data. Existing\nbias-mitigating generative methods based on GANs, Diffusion models need\nin-processing fairness objectives and fail to consider computational overhead\nwhile choosing computationally-heavy architectures, which may lead to high\ncomputational demands, instability and poor optimization performance. To\nmitigate this issue, in this work, we present a fair data generation technique\nbased on knowledge distillation, where we use a small architecture to distill\nthe fair representation in the latent space. The idea of fair latent space\ndistillation enables more flexible and stable training of Fair Generative\nModels (FGMs). We first learn a syntax-agnostic (for any data type) fair\nrepresentation of the data, followed by distillation in the latent space into a\nsmaller model. After distillation, we use the distilled fair latent space to\ngenerate high-fidelity fair synthetic data. While distilling, we employ quality\nloss (for fair distillation) and utility loss (for data utility) to ensure that\nthe fairness and data utility characteristics remain in the distilled latent\nspace. Our approaches show a 5%, 5% and 10% rise in performance in fairness,\nsynthetic sample quality and data utility, respectively, than the\nstate-of-the-art fair generative model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10755v1",
    "published_date": "2024-08-20 11:37:52 UTC",
    "updated_date": "2024-08-20 11:37:52 UTC"
  },
  {
    "arxiv_id": "2408.10752v1",
    "title": "Security Assessment of Hierarchical Federated Deep Learning",
    "authors": [
      "D Alqattan",
      "R Sun",
      "H Liang",
      "G Nicosia",
      "V Snasel",
      "R Ranjan",
      "V Ojha"
    ],
    "abstract": "Hierarchical federated learning (HFL) is a promising distributed deep\nlearning model training paradigm, but it has crucial security concerns arising\nfrom adversarial attacks. This research investigates and assesses the security\nof HFL using a novel methodology by focusing on its resilience against\nadversarial attacks inference-time and training-time. Through a series of\nextensive experiments across diverse datasets and attack scenarios, we uncover\nthat HFL demonstrates robustness against untargeted training-time attacks due\nto its hierarchical structure. However, targeted attacks, particularly backdoor\nattacks, exploit this architecture, especially when malicious clients are\npositioned in the overlapping coverage areas of edge servers. Consequently, HFL\nshows a dual nature in its resilience, showcasing its capability to recover\nfrom attacks thanks to its hierarchical aggregation that strengthens its\nsuitability for adversarial training, thereby reinforcing its resistance\nagainst inference-time attacks. These insights underscore the necessity for\nbalanced security strategies in HFL systems, leveraging their inherent\nstrengths while effectively mitigating vulnerabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10752v1",
    "published_date": "2024-08-20 11:34:23 UTC",
    "updated_date": "2024-08-20 11:34:23 UTC"
  },
  {
    "arxiv_id": "2408.10746v1",
    "title": "Pluto and Charon: A Time and Memory Efficient Collaborative Edge AI Framework for Personal LLMs Fine-Tuning",
    "authors": [
      "Bei Ouyang",
      "Shengyuan Ye",
      "Liekang Zeng",
      "Tianyi Qian",
      "Jingyi Li",
      "Xu Chen"
    ],
    "abstract": "Large language models (LLMs) have unlocked a plethora of powerful\napplications at the network edge, such as intelligent personal assistants. Data\nprivacy and security concerns have prompted a shift towards edge-based\nfine-tuning of personal LLMs, away from cloud reliance. However, this raises\nissues of computational intensity and resource scarcity, hindering training\nefficiency and feasibility. While current studies investigate\nparameter-efficient fine-tuning (PEFT) techniques to mitigate resource\nconstraints, our analysis indicates that these techniques are not sufficiently\nresource-efficient for edge devices. To tackle these challenges, we propose\nPluto and Charon (PAC), a time and memory efficient collaborative edge AI\nframework for personal LLMs fine-tuning. PAC breaks the resource wall of\npersonal LLMs fine-tuning with a sophisticated algorithm-system co-design. (1)\nAlgorithmically, PAC implements a personal LLMs fine-tuning technique that is\nefficient in terms of parameters, time, and memory. It utilizes Parallel\nAdapters to circumvent the need for a full backward pass through the LLM\nbackbone. Additionally, an activation cache mechanism further streamlining the\nprocess by negating the necessity for repeated forward passes across multiple\nepochs. (2) Systematically, PAC leverages edge devices in close proximity,\npooling them as a collective resource for in-situ personal LLMs fine-tuning,\nutilizing a hybrid data and pipeline parallelism to orchestrate distributed\ntraining. The use of the activation cache eliminates the need for forward pass\nthrough the LLM backbone,enabling exclusive fine-tuning of the Parallel\nAdapters using data parallelism. Extensive evaluation based on prototype\nimplementation demonstrates that PAC remarkably outperforms state-of-the-art\napproaches, achieving up to 8.64x end-to-end speedup and up to 88.16% reduction\nin memory footprint.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted by The 53rd International Conference on Parallel Processing\n  (ICPP'24)",
    "pdf_url": "http://arxiv.org/pdf/2408.10746v1",
    "published_date": "2024-08-20 11:30:12 UTC",
    "updated_date": "2024-08-20 11:30:12 UTC"
  },
  {
    "arxiv_id": "2408.11081v2",
    "title": "What can Large Language Models Capture about Code Functional Equivalence?",
    "authors": [
      "Nickil Maveli",
      "Antonio Vergari",
      "Shay B. Cohen"
    ],
    "abstract": "Code-LLMs, LLMs pre-trained on large code corpora, have shown great progress\nin learning rich representations of the structure and syntax of code,\nsuccessfully using it to generate or classify code fragments. At the same time,\nunderstanding if they are able to do so because they capture code semantics,\nand how well, is still an open question. In this paper, we tackle this problem\nby introducing SeqCoBench, a benchmark for systematically assessing how\nCode-LLMs can capture code functional equivalence. SeqCoBench contains over 20\ncode transformations that either preserve or alter the semantics of Python\nprograms. We conduct extensive evaluations in different settings, including\nzero-shot and parameter-efficient finetuning methods on state-of-the-art\n(Code)-LLMs to see if they can discern semantically equivalent or different\npairs of programs in SeqCoBench. We find that the performance gap between these\nLLMs and classical match-based retrieval scores is minimal, with both\napproaches showing a concerning lack of depth in understanding code semantics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.11081v2",
    "published_date": "2024-08-20 11:19:06 UTC",
    "updated_date": "2025-02-12 19:34:51 UTC"
  },
  {
    "arxiv_id": "2408.10729v1",
    "title": "Towards Efficient Large Language Models for Scientific Text: A Review",
    "authors": [
      "Huy Quoc To",
      "Ming Liu",
      "Guangyan Huang"
    ],
    "abstract": "Large language models (LLMs) have ushered in a new era for processing complex\ninformation in various fields, including science. The increasing amount of\nscientific literature allows these models to acquire and understand scientific\nknowledge effectively, thus improving their performance in a wide range of\ntasks. Due to the power of LLMs, they require extremely expensive computational\nresources, intense amounts of data, and training time. Therefore, in recent\nyears, researchers have proposed various methodologies to make scientific LLMs\nmore affordable. The most well-known approaches align in two directions. It can\nbe either focusing on the size of the models or enhancing the quality of data.\nTo date, a comprehensive review of these two families of methods has not yet\nbeen undertaken. In this paper, we (I) summarize the current advances in the\nemerging abilities of LLMs into more accessible AI solutions for science, and\n(II) investigate the challenges and opportunities of developing affordable\nsolutions for scientific domains using LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10729v1",
    "published_date": "2024-08-20 10:57:34 UTC",
    "updated_date": "2024-08-20 10:57:34 UTC"
  },
  {
    "arxiv_id": "2408.10726v1",
    "title": "Quantum Artificial Intelligence: A Brief Survey",
    "authors": [
      "Matthias Klusch",
      "Jörg Lässig",
      "Daniel Müssig",
      "Antonio Macaluso",
      "Frank K. Wilhelm"
    ],
    "abstract": "Quantum Artificial Intelligence (QAI) is the intersection of quantum\ncomputing and AI, a technological synergy with expected significant benefits\nfor both. In this paper, we provide a brief overview of what has been achieved\nin QAI so far and point to some open questions for future research. In\nparticular, we summarize some major key findings on the feasability and the\npotential of using quantum computing for solving computationally hard problems\nin various subfields of AI, and vice versa, the leveraging of AI methods for\nbuilding and operating quantum computing devices.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10726v1",
    "published_date": "2024-08-20 10:55:17 UTC",
    "updated_date": "2024-08-20 10:55:17 UTC"
  },
  {
    "arxiv_id": "2408.10722v1",
    "title": "MEGen: Generative Backdoor in Large Language Models via Model Editing",
    "authors": [
      "Jiyang Qiu",
      "Xinbei Ma",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities. Their\npowerful generative abilities enable flexible responses based on various\nqueries or instructions. Emerging as widely adopted generalists for diverse\ntasks, LLMs are still vulnerable to backdoors. This paper proposes an\nediting-based generative backdoor, named MEGen, aiming to create a customized\nbackdoor for NLP tasks with the least side effects. In our approach, we first\nleverage a language model to insert a trigger selected on fixed metrics into\nthe input, then design a pipeline of model editing to directly embed a backdoor\ninto an LLM. By adjusting a small set of local parameters with a mini-batch of\nsamples, MEGen significantly enhances time efficiency and achieves high\nrobustness. Experimental results indicate that our backdoor attack strategy\nachieves a high attack success rate on poison data while maintaining the\nmodel's performance on clean data. Notably, the backdoored model, when\ntriggered, can freely output pre-set dangerous information while successfully\ncompleting downstream tasks. This suggests that future LLM applications could\nbe guided to deliver certain dangerous information, thus altering the LLM's\ngenerative style. We believe this approach provides insights for future LLM\napplications and the execution of backdoor attacks on conversational AI\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2408.10722v1",
    "published_date": "2024-08-20 10:44:29 UTC",
    "updated_date": "2024-08-20 10:44:29 UTC"
  },
  {
    "arxiv_id": "2408.10720v1",
    "title": "Towards Foundation Models for the Industrial Forecasting of Chemical Kinetics",
    "authors": [
      "Imran Nasim",
      "Joaõ Lucas de Sousa Almeida"
    ],
    "abstract": "Scientific Machine Learning is transforming traditional engineering\nindustries by enhancing the efficiency of existing technologies and\naccelerating innovation, particularly in modeling chemical reactions. Despite\nrecent advancements, the issue of solving stiff chemically reacting problems\nwithin computational fluid dynamics remains a significant issue. In this study\nwe propose a novel approach utilizing a multi-layer-perceptron mixer\narchitecture (MLP-Mixer) to model the time-series of stiff chemical kinetics.\nWe evaluate this method using the ROBER system, a benchmark model in chemical\nkinetics, to compare its performance with traditional numerical techniques.\nThis study provides insight into the industrial utility of the recently\ndeveloped MLP-Mixer architecture to model chemical kinetics and provides\nmotivation for such neural architecture to be used as a base for time-series\nfoundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted into the IEEE CAI 2024 Workshop on Scientific Machine\n  Learning and Its Industrial Applications (SMLIA2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.10720v1",
    "published_date": "2024-08-20 10:43:09 UTC",
    "updated_date": "2024-08-20 10:43:09 UTC"
  },
  {
    "arxiv_id": "2408.10715v1",
    "title": "Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology",
    "authors": [
      "Yihao Hou",
      "Christoph Bert",
      "Ahmed Gomaa",
      "Godehard Lahmer",
      "Daniel Hoefler",
      "Thomas Weissmann",
      "Raphaela Voigt",
      "Philipp Schubert",
      "Charlotte Schmitter",
      "Alina Depardon",
      "Sabine Semrau",
      "Andreas Maier",
      "Rainer Fietkau",
      "Yixing Huang",
      "Florian Putz"
    ],
    "abstract": "Generating physician letters is a time-consuming task in daily clinical\npractice. This study investigates local fine-tuning of large language models\n(LLMs), specifically LLaMA models, for physician letter generation in a\nprivacy-preserving manner within the field of radiation oncology. Our findings\ndemonstrate that base LLaMA models, without fine-tuning, are inadequate for\neffectively generating physician letters. The QLoRA algorithm provides an\nefficient method for local intra-institutional fine-tuning of LLMs with limited\ncomputational resources (i.e., a single 48 GB GPU workstation within the\nhospital). The fine-tuned LLM successfully learns radiation oncology-specific\ninformation and generates physician letters in an institution-specific style.\nROUGE scores of the generated summary reports highlight the superiority of the\n8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician\nevaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has\nlimited capacity to generate content beyond the provided input data, it\nsuccessfully generates salutations, diagnoses and treatment histories,\nrecommendations for further treatment, and planned schedules. Overall, clinical\nbenefit was rated highly by the clinical experts (average score of 3.44 on a\n4-point scale). With careful physician review and correction, automated\nLLM-based physician letter generation has significant practical value.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10715v1",
    "published_date": "2024-08-20 10:31:36 UTC",
    "updated_date": "2024-08-20 10:31:36 UTC"
  },
  {
    "arxiv_id": "2408.10713v1",
    "title": "Offline Model-Based Reinforcement Learning with Anti-Exploration",
    "authors": [
      "Padmanaba Srinivasan",
      "William Knottenbelt"
    ],
    "abstract": "Model-based reinforcement learning (MBRL) algorithms learn a dynamics model\nfrom collected data and apply it to generate synthetic trajectories to enable\nfaster learning. This is an especially promising paradigm in offline\nreinforcement learning (RL) where data may be limited in quantity, in addition\nto being deficient in coverage and quality. Practical approaches to offline\nMBRL usually rely on ensembles of dynamics models to prevent exploitation of\nany individual model and to extract uncertainty estimates that penalize values\nin states far from the dataset support. Uncertainty estimates from ensembles\ncan vary greatly in scale, making it challenging to generalize hyperparameters\nwell across even similar tasks. In this paper, we present Morse Model-based\noffline RL (MoMo), which extends the anti-exploration paradigm found in offline\nmodel-free RL to the model-based space. We develop model-free and model-based\nvariants of MoMo and show how the model-free version can be extended to detect\nand deal with out-of-distribution (OOD) states using explicit uncertainty\nestimation without the need for large ensembles. MoMo performs offline MBRL\nusing an anti-exploration bonus to counteract value overestimation in\ncombination with a policy constraint, as well as a truncation function to\nterminate synthetic rollouts that are excessively OOD. Experimentally, we find\nthat both model-free and model-based MoMo perform well, and the latter\noutperforms prior model-based and model-free baselines on the majority of D4RL\ndatasets tested.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10713v1",
    "published_date": "2024-08-20 10:29:21 UTC",
    "updated_date": "2024-08-20 10:29:21 UTC"
  },
  {
    "arxiv_id": "2408.10711v1",
    "title": "Investigating Context Effects in Similarity Judgements in Large Language Models",
    "authors": [
      "Sagar Uprety",
      "Amit Kumar Jaiswal",
      "Haiming Liu",
      "Dawei Song"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionised the capability of AI models\nin comprehending and generating natural language text. They are increasingly\nbeing used to empower and deploy agents in real-world scenarios, which make\ndecisions and take actions based on their understanding of the context.\nTherefore researchers, policy makers and enterprises alike are working towards\nensuring that the decisions made by these agents align with human values and\nuser expectations. That being said, human values and decisions are not always\nstraightforward to measure and are subject to different cognitive biases. There\nis a vast section of literature in Behavioural Science which studies biases in\nhuman judgements. In this work we report an ongoing investigation on alignment\nof LLMs with human judgements affected by order bias. Specifically, we focus on\na famous human study which showed evidence of order effects in similarity\njudgements, and replicate it with various popular LLMs. We report the different\nsettings where LLMs exhibit human-like order effect bias and discuss the\nimplications of these findings to inform the design and development of LLM\nbased applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at The First Workshop on AI Behavioral Science (AIBS 2024),\n  held in conjunction with KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10711v1",
    "published_date": "2024-08-20 10:26:02 UTC",
    "updated_date": "2024-08-20 10:26:02 UTC"
  },
  {
    "arxiv_id": "2408.10710v1",
    "title": "Coarse-to-Fine Detection of Multiple Seams for Robotic Welding",
    "authors": [
      "Pengkun Wei",
      "Shuo Cheng",
      "Dayou Li",
      "Ran Song",
      "Yipeng Zhang",
      "Wei Zhang"
    ],
    "abstract": "Efficiently detecting target weld seams while ensuring sub-millimeter\naccuracy has always been an important challenge in autonomous welding, which\nhas significant application in industrial practice. Previous works mostly\nfocused on recognizing and localizing welding seams one by one, leading to\ninferior efficiency in modeling the workpiece. This paper proposes a novel\nframework capable of multiple weld seams extraction using both RGB images and\n3D point clouds. The RGB image is used to obtain the region of interest by\napproximately localizing the weld seams, and the point cloud is used to achieve\nthe fine-edge extraction of the weld seams within the region of interest using\nregion growth. Our method is further accelerated by using a pre-trained deep\nlearning model to ensure both efficiency and generalization ability. The\nperformance of the proposed method has been comprehensively tested on various\nworkpieces featuring both linear and curved weld seams and in physical\nexperiment systems. The results showcase considerable potential for real-world\nindustrial applications, emphasizing the method's efficiency and effectiveness.\nVideos of the real-world experiments can be found at\nhttps://youtu.be/pq162HSP2D4.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10710v1",
    "published_date": "2024-08-20 10:24:59 UTC",
    "updated_date": "2024-08-20 10:24:59 UTC"
  },
  {
    "arxiv_id": "2408.10709v1",
    "title": "Variable Assignment Invariant Neural Networks for Learning Logic Programs",
    "authors": [
      "Yin Jun Phua",
      "Katsumi Inoue"
    ],
    "abstract": "Learning from interpretation transition (LFIT) is a framework for learning\nrules from observed state transitions. LFIT has been implemented in purely\nsymbolic algorithms, but they are unable to deal with noise or generalize to\nunobserved transitions. Rule extraction based neural network methods suffer\nfrom overfitting, while more general implementation that categorize rules\nsuffer from combinatorial explosion. In this paper, we introduce a technique to\nleverage variable permutation invariance inherent in symbolic domains. Our\ntechnique ensures that the permutation and the naming of the variables would\nnot affect the results. We demonstrate the effectiveness and the scalability of\nthis method with various experiments. Our code is publicly available at\nhttps://github.com/phuayj/delta-lfit-2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10709v1",
    "published_date": "2024-08-20 10:23:35 UTC",
    "updated_date": "2024-08-20 10:23:35 UTC"
  },
  {
    "arxiv_id": "2408.10700v1",
    "title": "AnyGraph: Graph Foundation Model in the Wild",
    "authors": [
      "Lianghao Xia",
      "Chao Huang"
    ],
    "abstract": "The growing ubiquity of relational data structured as graphs has underscored\nthe need for graph learning models with exceptional generalization\ncapabilities. However, current approaches often struggle to effectively extract\ngeneralizable insights, frequently requiring extensive fine-tuning and limiting\ntheir versatility. Graph foundation models offer a transformative solution,\nwith the potential to learn robust, generalizable representations from graph\ndata. This enables more effective and adaptable applications across a wide\nspectrum of tasks and domains. In this work, we investigate a unified graph\nmodel, AnyGraph, designed to handle key challenges: i) Structure Heterogenity.\nAddressing distribution shift in graph structural information; ii) Feature\nHeterogenity. Handling diverse feature representation spaces across graph\ndatasets; iii) Fast Adaptation. Efficiently adapting the model to new graph\ndomains; iv) Scaling Law Emergence. Enabling the model to exhibit scaling law\nbehavior, where its performance scales favorably with the amount of data and\nparameter sizes. To tackle these critical challenges, we build the AnyGraph\nupon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the\nmodel to effectively manage both the in-domain and cross-domain distribution\nshift concerning structure-level and feature-level heterogeneity. Furthermore,\na lightweight graph expert routing mechanism is proposed to facilitate\nAnyGraph's fast adaptability to new data and domains. Our extensive experiments\non diverse 38 graph datasets have demonstrated the strong zero-shot learning\nperformance of AnyGraph across diverse graph domains with significant\ndistribution shift. Furthermore, we have validated the model's fast adaptation\nability and scaling law emergence, showcasing its versatility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10700v1",
    "published_date": "2024-08-20 09:57:13 UTC",
    "updated_date": "2024-08-20 09:57:13 UTC"
  },
  {
    "arxiv_id": "2408.10691v2",
    "title": "Fine-Tuning and Deploying Large Language Models Over Edges: Issues and Approaches",
    "authors": [
      "Yanjie Dong",
      "Haijun Zhang",
      "Chengming Li",
      "Song Guo",
      "Victor C. M. Leung",
      "Xiping Hu"
    ],
    "abstract": "Since the invention of GPT2--1.5B in 2019, large language models (LLMs) have\ntransitioned from specialized models to versatile foundation models. The LLMs\nexhibit impressive zero-shot ability, however, require fine-tuning on local\ndatasets and significant resources for deployment. Traditional fine-tuning\ntechniques with the first-order optimizers require substantial GPU memory that\nexceeds mainstream hardware capability. Therefore, memory-efficient methods are\nmotivated to be investigated. Model compression techniques can reduce energy\nconsumption, operational costs, and environmental impact so that to support\nsustainable artificial intelligence advancements. Additionally, large-scale\nfoundation models have expanded to create images, audio, videos, and\nmulti-modal contents, further emphasizing the need for efficient deployment.\nTherefore, we are motivated to present a comprehensive overview of the\nprevalent memory-efficient fine-tuning methods over the network edge. We also\nreview the state-of-the-art literatures on model compression to provide a\nvision on deploying LLMs over the network edge.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10691v2",
    "published_date": "2024-08-20 09:42:17 UTC",
    "updated_date": "2024-10-01 08:48:34 UTC"
  },
  {
    "arxiv_id": "2408.10689v2",
    "title": "Genesis: Towards the Automation of Systems Biology Research",
    "authors": [
      "Ievgeniia A. Tiukova",
      "Daniel Brunnsåker",
      "Erik Y. Bjurström",
      "Alexander H. Gower",
      "Filip Kronström",
      "Gabriel K. Reder",
      "Ronald S. Reiserer",
      "Konstantin Korovin",
      "Larisa B. Soldatova",
      "John P. Wikswo",
      "Ross D. King"
    ],
    "abstract": "The cutting edge of applying AI to science is the closed-loop automation of\nscientific research: robot scientists. We have previously developed two robot\nscientists: `Adam' (for yeast functional biology), and `Eve' (for early-stage\ndrug design)). We are now developing a next generation robot scientist Genesis.\nWith Genesis we aim to demonstrate that an area of science can be investigated\nusing robot scientists unambiguously faster, and at lower cost, than with human\nscientists. Here we report progress on the Genesis project. Genesis is designed\nto automatically improve system biology models with thousands of interacting\ncausal components. When complete Genesis will be able to initiate and execute\nin parallel one thousand hypothesis-led closed-loop cycles of experiment\nper-day. Here we describe the core Genesis hardware: the one thousand\ncomputer-controlled $\\mu$-bioreactors. For the integrated Mass Spectrometry\nplatform we have developed AutonoMS, a system to automatically run, process,\nand analyse high-throughput experiments. We have also developed Genesis-DB, a\ndatabase system designed to enable software agents access to large quantities\nof structured domain information. We have developed RIMBO (Revisions for\nImprovements of Models in Biology Ontology) to describe the planned hundreds of\nthousands of changes to the models. We have demonstrated the utility of this\ninfrastructure by developed two relational learning bioinformatic projects.\nFinally, we describe LGEM+ a relational learning system for the automated\nabductive improvement of genome-scale metabolic models.",
    "categories": [
      "cs.AI",
      "A.1; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10689v2",
    "published_date": "2024-08-20 09:40:43 UTC",
    "updated_date": "2024-09-04 09:56:27 UTC"
  },
  {
    "arxiv_id": "2408.10683v1",
    "title": "Rejection in Abstract Argumentation: Harder Than Acceptance?",
    "authors": [
      "Johannes K. Fichte",
      "Markus Hecher",
      "Yasir Mahmood",
      "Arne Meier"
    ],
    "abstract": "Abstract argumentation is a popular toolkit for modeling, evaluating, and\ncomparing arguments. Relationships between arguments are specified in\nargumentation frameworks (AFs), and conditions are placed on sets (extensions)\nof arguments that allow AFs to be evaluated. For more expressiveness, AFs are\naugmented with \\emph{acceptance conditions} on directly interacting arguments\nor a constraint on the admissible sets of arguments, resulting in dialectic\nframeworks or constrained argumentation frameworks. In this paper, we consider\nflexible conditions for \\emph{rejecting} an argument from an extension, which\nwe call rejection conditions (RCs). On the technical level, we associate each\nargument with a specific logic program. We analyze the resulting complexity,\nincluding the structural parameter treewidth. Rejection AFs are highly\nexpressive, giving rise to natural problems on higher levels of the polynomial\nhierarchy.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted version as ECAI24",
    "pdf_url": "http://arxiv.org/pdf/2408.10683v1",
    "published_date": "2024-08-20 09:37:04 UTC",
    "updated_date": "2024-08-20 09:37:04 UTC"
  },
  {
    "arxiv_id": "2408.10682v1",
    "title": "Towards Robust Knowledge Unlearning: An Adversarial Framework for Assessing and Improving Unlearning Robustness in Large Language Models",
    "authors": [
      "Hongbang Yuan",
      "Zhuoran Jin",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "LLM have achieved success in many fields but still troubled by problematic\ncontent in the training corpora. LLM unlearning aims at reducing their\ninfluence and avoid undesirable behaviours. However, existing unlearning\nmethods remain vulnerable to adversarial queries and the unlearned knowledge\nresurfaces after the manually designed attack queries. As part of a red-team\neffort to proactively assess the vulnerabilities of unlearned models, we design\nDynamic Unlearning Attack (DUA), a dynamic and automated framework to attack\nthese models and evaluate their robustness. It optimizes adversarial suffixes\nto reintroduce the unlearned knowledge in various scenarios. We find that\nunlearned knowledge can be recovered in $55.2\\%$ of the questions, even without\nrevealing the unlearned model's parameters. In response to this vulnerability,\nwe propose Latent Adversarial Unlearning (LAU), a universal framework that\neffectively enhances the robustness of the unlearned process. It formulates the\nunlearning process as a min-max optimization problem and resolves it through\ntwo stages: an attack stage, where perturbation vectors are trained and added\nto the latent space of LLMs to recover the unlearned knowledge, and a defense\nstage, where previously trained perturbation vectors are used to enhance\nunlearned model's robustness. With our LAU framework, we obtain two robust\nunlearning methods, AdvGA and AdvNPO. We conduct extensive experiments across\nmultiple unlearning benchmarks and various models, and demonstrate that they\nimprove the unlearning effectiveness by over $53.5\\%$, cause only less than a\n$11.6\\%$ reduction in neighboring knowledge, and have almost no impact on the\nmodel's general capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.10682v1",
    "published_date": "2024-08-20 09:36:04 UTC",
    "updated_date": "2024-08-20 09:36:04 UTC"
  },
  {
    "arxiv_id": "2408.11875v1",
    "title": "Hierarchical Retrieval-Augmented Generation Model with Rethink for Multi-hop Question Answering",
    "authors": [
      "Xiaoming Zhang",
      "Ming Wang",
      "Xiaocui Yang",
      "Daling Wang",
      "Shi Feng",
      "Yifei Zhang"
    ],
    "abstract": "Multi-hop Question Answering (QA) necessitates complex reasoning by\nintegrating multiple pieces of information to resolve intricate questions.\nHowever, existing QA systems encounter challenges such as outdated information,\ncontext window length limitations, and an accuracy-quantity trade-off. To\naddress these issues, we propose a novel framework, the Hierarchical\nRetrieval-Augmented Generation Model with Rethink (HiRAG), comprising\nDecomposer, Definer, Retriever, Filter, and Summarizer five key modules. We\nintroduce a new hierarchical retrieval strategy that incorporates both sparse\nretrieval at the document level and dense retrieval at the chunk level,\neffectively integrating their strengths. Additionally, we propose a\nsingle-candidate retrieval method to mitigate the limitations of\nmulti-candidate retrieval. We also construct two new corpora, Indexed\nWikicorpus and Profile Wikicorpus, to address the issues of outdated and\ninsufficient knowledge.\n  Our experimental results on four datasets demonstrate that HiRAG outperforms\nstate-of-the-art models across most metrics, and our Indexed Wikicorpus is\neffective. The code for HiRAG is available at\nhttps://github.com/2282588541a/HiRAG",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "undereview",
    "pdf_url": "http://arxiv.org/pdf/2408.11875v1",
    "published_date": "2024-08-20 09:29:31 UTC",
    "updated_date": "2024-08-20 09:29:31 UTC"
  },
  {
    "arxiv_id": "2408.10669v2",
    "title": "Tensor tree learns hidden relational structures in data to construct generative models",
    "authors": [
      "Kenji Harada",
      "Tsuyoshi Okubo",
      "Naoki Kawashima"
    ],
    "abstract": "Based on the tensor tree network with the Born machine framework, we propose\na general method for constructing a generative model by expressing the target\ndistribution function as the amplitude of the quantum wave function represented\nby a tensor tree. The key idea is dynamically optimizing the tree structure\nthat minimizes the bond mutual information. The proposed method offers enhanced\nperformance and uncovers hidden relational structures in the target data. We\nillustrate potential practical applications with four examples: (i) random\npatterns, (ii) QMNIST handwritten digits, (iii) Bayesian networks, and (iv) the\npattern of stock price fluctuation pattern in S&P500. In (i) and (ii), the\nstrongly correlated variables were concentrated near the center of the network;\nin (iii), the causality pattern was identified; and in (iv), a structure\ncorresponding to the eleven sectors emerged.",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10669v2",
    "published_date": "2024-08-20 09:11:38 UTC",
    "updated_date": "2025-04-03 03:56:46 UTC"
  },
  {
    "arxiv_id": "2408.10668v3",
    "title": "Probing the Safety Response Boundary of Large Language Models via Unsafe Decoding Path Generation",
    "authors": [
      "Haoyu Wang",
      "Bingzhe Wu",
      "Yatao Bian",
      "Yongzhe Chang",
      "Xueqian Wang",
      "Peilin Zhao"
    ],
    "abstract": "Large Language Models (LLMs) are implicit troublemakers. While they provide\nvaluable insights and assist in problem-solving, they can also potentially\nserve as a resource for malicious activities. Implementing safety alignment\ncould mitigate the risk of LLMs generating harmful responses. We argue that:\neven when an LLM appears to successfully block harmful queries, there may still\nbe hidden vulnerabilities that could act as ticking time bombs. To identify\nthese underlying weaknesses, we propose to use a cost value model as both a\ndetector and an attacker. Trained on external or self-generated harmful\ndatasets, the cost value model could successfully influence the original safe\nLLM to output toxic content in decoding process. For instance, LLaMA-2-chat 7B\noutputs 39.18% concrete toxic content, along with only 22.16% refusals without\nany harmful suffixes. These potential weaknesses can then be exploited via\nprompt optimization such as soft prompts on images. We name this decoding\nstrategy: Jailbreak Value Decoding (JVD), emphasizing that seemingly secure\nLLMs may not be as safe as we initially believe. They could be used to gather\nharmful data or launch covert attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10668v3",
    "published_date": "2024-08-20 09:11:21 UTC",
    "updated_date": "2024-08-26 05:27:13 UTC"
  },
  {
    "arxiv_id": "2408.10657v1",
    "title": "ETGuard: Malicious Encrypted Traffic Detection in Blockchain-based Power Grid Systems",
    "authors": [
      "Peng Zhou",
      "Yongdong Liu",
      "Lixun Ma",
      "Weiye Zhang",
      "Haohan Tan",
      "Zhenguang Liu",
      "Butian Huang"
    ],
    "abstract": "The escalating prevalence of encryption protocols has led to a concomitant\nsurge in the number of malicious attacks that hide in encrypted traffic. Power\ngrid systems, as fundamental infrastructure, are becoming prime targets for\nsuch attacks. Conventional methods for detecting malicious encrypted packets\ntypically use a static pre-trained model. We observe that these methods are not\nwell-suited for blockchain-based power grid systems. More critically, they fall\nshort in dynamic environments where new types of encrypted attacks continuously\nemerge. Motivated by this, in this paper we try to tackle these challenges from\ntwo aspects: (1) We present a novel framework that is able to automatically\ndetect malicious encrypted traffic in blockchain-based power grid systems and\nincrementally learn from new malicious traffic. (2) We mathematically derive\nincremental learning losses to resist the forgetting of old attack patterns\nwhile ensuring the model is capable of handling new encrypted attack patterns.\nEmpirically, our method achieves state-of-the-art performance on three\ndifferent benchmark datasets. We also constructed the first malicious encrypted\ntraffic dataset for blockchain-based power grid scenario. Our code and dataset\nare available at https://github.com/PPPmzt/ETGuard, hoping to inspire future\nresearch.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10657v1",
    "published_date": "2024-08-20 08:53:42 UTC",
    "updated_date": "2024-08-20 08:53:42 UTC"
  },
  {
    "arxiv_id": "2408.10652v2",
    "title": "Vocabulary-Free 3D Instance Segmentation with Vision and Language Assistant",
    "authors": [
      "Guofeng Mei",
      "Luigi Riz",
      "Yiming Wang",
      "Fabio Poiesi"
    ],
    "abstract": "Most recent 3D instance segmentation methods are open vocabulary, offering a\ngreater flexibility than closed-vocabulary methods. Yet, they are limited to\nreasoning within a specific set of concepts, \\ie the vocabulary, prompted by\nthe user at test time. In essence, these models cannot reason in an open-ended\nfashion, i.e., answering \"List the objects in the scene.''. We introduce the\nfirst method to address 3D instance segmentation in a setting that is void of\nany vocabulary prior, namely a vocabulary-free setting. We leverage a large\nvision-language assistant and an open-vocabulary 2D instance segmenter to\ndiscover and ground semantic categories on the posed images. To form 3D\ninstance mask, we first partition the input point cloud into dense superpoints,\nwhich are then merged into 3D instance masks. We propose a novel superpoint\nmerging strategy via spectral clustering, accounting for both mask coherence\nand semantic coherence that are estimated from the 2D object instance masks. We\nevaluate our method using ScanNet200 and Replica, outperforming existing\nmethods in both vocabulary-free and open-vocabulary settings. Code will be made\navailable. Project page: https://gfmei.github.io/PoVo",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 3DV",
    "pdf_url": "http://arxiv.org/pdf/2408.10652v2",
    "published_date": "2024-08-20 08:46:54 UTC",
    "updated_date": "2025-03-28 07:00:39 UTC"
  },
  {
    "arxiv_id": "2408.10649v1",
    "title": "Inferring Underwater Topography with FINN",
    "authors": [
      "Coşku Can Horuz",
      "Matthias Karlbauer",
      "Timothy Praditia",
      "Sergey Oladyshkin",
      "Wolfgang Nowak",
      "Sebastian Otte"
    ],
    "abstract": "Spatiotemporal partial differential equations (PDEs) find extensive\napplication across various scientific and engineering fields. While numerous\nmodels have emerged from both physics and machine learning (ML) communities,\nthere is a growing trend towards integrating these approaches to develop hybrid\narchitectures known as physics-aware machine learning models. Among these, the\nfinite volume neural network (FINN) has emerged as a recent addition. FINN has\nproven to be particularly efficient in uncovering latent structures in data. In\nthis study, we explore the capabilities of FINN in tackling the shallow-water\nequations, which simulates wave dynamics in coastal regions. Specifically, we\ninvestigate FINN's efficacy to reconstruct underwater topography based on these\nparticular wave equations. Our findings reveal that FINN exhibits a remarkable\ncapacity to infer topography solely from wave dynamics, distinguishing itself\nfrom both conventional ML and physics-aware ML models. Our results underscore\nthe potential of FINN in advancing our understanding of spatiotemporal\nphenomena and enhancing parametrization capabilities in related domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10649v1",
    "published_date": "2024-08-20 08:42:00 UTC",
    "updated_date": "2024-08-20 08:42:00 UTC"
  },
  {
    "arxiv_id": "2408.10647v1",
    "title": "Privacy-preserving Universal Adversarial Defense for Black-box Models",
    "authors": [
      "Qiao Li",
      "Cong Wu",
      "Jing Chen",
      "Zijun Zhang",
      "Kun He",
      "Ruiying Du",
      "Xinxin Wang",
      "Qingchuang Zhao",
      "Yang Liu"
    ],
    "abstract": "Deep neural networks (DNNs) are increasingly used in critical applications\nsuch as identity authentication and autonomous driving, where robustness\nagainst adversarial attacks is crucial. These attacks can exploit minor\nperturbations to cause significant prediction errors, making it essential to\nenhance the resilience of DNNs. Traditional defense methods often rely on\naccess to detailed model information, which raises privacy concerns, as model\nowners may be reluctant to share such data. In contrast, existing black-box\ndefense methods fail to offer a universal defense against various types of\nadversarial attacks. To address these challenges, we introduce DUCD, a\nuniversal black-box defense method that does not require access to the target\nmodel's parameters or architecture. Our approach involves distilling the target\nmodel by querying it with data, creating a white-box surrogate while preserving\ndata privacy. We further enhance this surrogate model using a certified defense\nbased on randomized smoothing and optimized noise selection, enabling robust\ndefense against a broad range of adversarial attacks. Comparative evaluations\nbetween the certified defenses of the surrogate and target models demonstrate\nthe effectiveness of our approach. Experiments on multiple image classification\ndatasets show that DUCD not only outperforms existing black-box defenses but\nalso matches the accuracy of white-box defenses, all while enhancing data\nprivacy and reducing the success rate of membership inference attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10647v1",
    "published_date": "2024-08-20 08:40:39 UTC",
    "updated_date": "2024-08-20 08:40:39 UTC"
  },
  {
    "arxiv_id": "2408.10646v1",
    "title": "Beneath the Surface of Consistency: Exploring Cross-lingual Knowledge Representation Sharing in LLMs",
    "authors": [
      "Maxim Ifergan",
      "Leshem Choshen",
      "Roee Aharoni",
      "Idan Szpektor",
      "Omri Abend"
    ],
    "abstract": "The veracity of a factoid is largely independent of the language it is\nwritten in. However, language models are inconsistent in their ability to\nanswer the same factual question across languages. This raises questions about\nhow LLMs represent a given fact across languages. We explore multilingual\nfactual knowledge through two aspects: the model's ability to answer a query\nconsistently across languages, and the ability to ''store'' answers in a shared\nrepresentation for several languages. We propose a methodology to measure the\nextent of representation sharing across languages by repurposing knowledge\nediting methods. We examine LLMs with various multilingual configurations using\na new multilingual dataset. We reveal that high consistency does not\nnecessarily imply shared representation, particularly for languages with\ndifferent scripts. Moreover, we find that script similarity is a dominant\nfactor in representation sharing. Finally, we observe that if LLMs could fully\nshare knowledge across languages, their accuracy in their best-performing\nlanguage could benefit an increase of up to 150\\% on average. These findings\nhighlight the need for improved multilingual knowledge representation in LLMs\nand suggest a path for the development of more robust and consistent\nmultilingual LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10646v1",
    "published_date": "2024-08-20 08:38:30 UTC",
    "updated_date": "2024-08-20 08:38:30 UTC"
  },
  {
    "arxiv_id": "2408.10642v1",
    "title": "Minor SFT loss for LLM fine-tune to increase performance and reduce model deviation",
    "authors": [
      "Shiming Xie",
      "Hong Chen",
      "Fred Yu",
      "Zeye Sun",
      "Xiuyu Wu"
    ],
    "abstract": "Instruct LLM provide a paradigm used in large scale language model to align\nLLM to human preference. The paradigm contains supervised fine tuning and\nreinforce learning from human feedback. This paradigm is also used in\ndownstream scenarios to adapt LLM to specific corpora and applications.\nComparing to SFT, there are many efforts focused on RLHF and several algorithms\nbeing proposed, such as PPO, DPO, IPO, KTO, MinorDPO and etc. Meanwhile most\nefforts for SFT are focused on how to collect, filter and mix high quality\ndata. In this article with insight from DPO and MinorDPO, we propose a training\nmetric for SFT to measure the discrepancy between the optimized model and the\noriginal model, and a loss function MinorSFT that can increase the training\neffectiveness, and reduce the discrepancy between the optimized LLM and\noriginal LLM.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10642v1",
    "published_date": "2024-08-20 08:32:44 UTC",
    "updated_date": "2024-08-20 08:32:44 UTC"
  },
  {
    "arxiv_id": "2408.10641v3",
    "title": "A Review of Human-Object Interaction Detection",
    "authors": [
      "Yuxiao Wang",
      "Yu Lei",
      "Li Cui",
      "Weiying Xue",
      "Qi Liu",
      "Zhenao Wei"
    ],
    "abstract": "Human-object interaction (HOI) detection plays a key role in high-level\nvisual understanding, facilitating a deep comprehension of human activities.\nSpecifically, HOI detection aims to locate the humans and objects involved in\ninteractions within images or videos and classify the specific interactions\nbetween them. The success of this task is influenced by several key factors,\nincluding the accurate localization of human and object instances, as well as\nthe correct classification of object categories and interaction relationships.\nThis paper systematically summarizes and discusses the recent work in\nimage-based HOI detection. First, the mainstream datasets involved in HOI\nrelationship detection are introduced. Furthermore, starting with two-stage\nmethods and end-to-end one-stage detection approaches, this paper\ncomprehensively discusses the current developments in image-based HOI\ndetection, analyzing the strengths and weaknesses of these two methods.\nAdditionally, the advancements of zero-shot learning, weakly supervised\nlearning, and the application of large-scale language models in HOI detection\nare discussed. Finally, the current challenges in HOI detection are outlined,\nand potential research directions and future trends are explored.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2024 2nd International Conference on Computer, Vision and\n  Intelligent Technology (ICCVIT)",
    "pdf_url": "http://arxiv.org/pdf/2408.10641v3",
    "published_date": "2024-08-20 08:32:39 UTC",
    "updated_date": "2025-03-18 02:22:59 UTC"
  },
  {
    "arxiv_id": "2408.10635v2",
    "title": "Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search",
    "authors": [
      "Jonathan Light",
      "Min Cai",
      "Weiqin Chen",
      "Guanzhi Wang",
      "Xiusi Chen",
      "Wei Cheng",
      "Yisong Yue",
      "Ziniu Hu"
    ],
    "abstract": "In this paper, we propose a new method STRATEGIST that utilizes LLMs to\nacquire new skills for playing multi-agent games through a self-improvement\nprocess. Our method gathers quality feedback through self-play simulations with\nMonte Carlo tree search and LLM-based reflection, which can then be used to\nlearn high-level strategic skills such as how to evaluate states that guide the\nlow-level execution. We showcase how our method can be used in both action\nplanning and dialogue generation in the context of games, achieving good\nperformance on both tasks. Specifically, we demonstrate that our method can\nhelp train agents with better performance than both traditional reinforcement\nlearning-based approaches and other LLM-based skill learning approaches in\ngames including the Game of Pure Strategy (GOPS) and The Resistance: Avalon.\nSTRATEGIST helps bridge the gap between foundation models and symbolic\ndecision-making methods through its bi-level approach, leading to more robust\ndecision-making.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "website: https://llm-strategist.github.io",
    "pdf_url": "http://arxiv.org/pdf/2408.10635v2",
    "published_date": "2024-08-20 08:22:04 UTC",
    "updated_date": "2024-10-12 03:16:30 UTC"
  },
  {
    "arxiv_id": "2408.10631v1",
    "title": "LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models",
    "authors": [
      "Yupeng Su",
      "Ziyi Guan",
      "Xiaoqun Liu",
      "Tianlai Jin",
      "Dongkuan Wu",
      "Graziano Chesi",
      "Ngai Wong",
      "Hao Yu"
    ],
    "abstract": "Large language models (LLMs) have grown significantly in scale, leading to a\ncritical need for efficient model pruning techniques. Existing post-training\npruning techniques primarily focus on measuring weight importance on converged\ndense models to determine salient weights to retain. However, they often\noverlook the changes in weight importance during the pruning process, which can\nlead to performance degradation in the pruned models. To address this issue, we\npresent LLM-Barber (Block-Aware Rebuilder for Sparsity Mask in One-Shot), a\nnovel one-shot pruning framework that rebuilds the sparsity mask of pruned\nmodels without any retraining or weight reconstruction. LLM-Barber incorporates\nblock-aware error optimization across Self-Attention and MLP blocks, ensuring\nglobal performance optimization. Inspired by the recent discovery of prominent\noutliers in LLMs, LLM-Barber introduces an innovative pruning metric that\nidentifies weight importance using weights multiplied by gradients. Our\nexperiments show that LLM-Barber can efficiently prune models like LLaMA and\nOPT families with 7B to 13B parameters on a single A100 GPU in just 30 minutes,\nachieving state-of-the-art results in both perplexity and zero-shot performance\nacross various language benchmarks. Code is available at\nhttps://github.com/YupengSu/LLM-Barber.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10631v1",
    "published_date": "2024-08-20 08:13:52 UTC",
    "updated_date": "2024-08-20 08:13:52 UTC"
  },
  {
    "arxiv_id": "2408.10628v1",
    "title": "Finding the DeepDream for Time Series: Activation Maximization for Univariate Time Series",
    "authors": [
      "Udo Schlegel",
      "Daniel A. Keim",
      "Tobias Sutter"
    ],
    "abstract": "Understanding how models process and interpret time series data remains a\nsignificant challenge in deep learning to enable applicability in\nsafety-critical areas such as healthcare. In this paper, we introduce Sequence\nDreaming, a technique that adapts Activation Maximization to analyze sequential\ninformation, aiming to enhance the interpretability of neural networks\noperating on univariate time series. By leveraging this method, we visualize\nthe temporal dynamics and patterns most influential in model decision-making\nprocesses. To counteract the generation of unrealistic or excessively noisy\nsequences, we enhance Sequence Dreaming with a range of regularization\ntechniques, including exponential smoothing. This approach ensures the\nproduction of sequences that more accurately reflect the critical features\nidentified by the neural network. Our approach is tested on a time series\nclassification dataset encompassing applications in predictive maintenance. The\nresults show that our proposed Sequence Dreaming approach demonstrates targeted\nactivation maximization for different use cases so that either centered class\nor border activation maximization can be generated. The results underscore the\nversatility of Sequence Dreaming in uncovering salient temporal features\nlearned by neural networks, thereby advancing model transparency and\ntrustworthiness in decision-critical domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 4 figures, accepted at TempXAI @ ECML-PKDD",
    "pdf_url": "http://arxiv.org/pdf/2408.10628v1",
    "published_date": "2024-08-20 08:09:44 UTC",
    "updated_date": "2024-08-20 08:09:44 UTC"
  },
  {
    "arxiv_id": "2408.10624v1",
    "title": "WRIM-Net: Wide-Ranging Information Mining Network for Visible-Infrared Person Re-Identification",
    "authors": [
      "Yonggan Wu",
      "Ling-Chao Meng",
      "Yuan Zichao",
      "Sixian Chan",
      "Hong-Qiang Wang"
    ],
    "abstract": "For the visible-infrared person re-identification (VI-ReID) task, one of the\nprimary challenges lies in significant cross-modality discrepancy. Existing\nmethods struggle to conduct modality-invariant information mining. They often\nfocus solely on mining singular dimensions like spatial or channel, and\noverlook the extraction of specific-modality multi-dimension information. To\nfully mine modality-invariant information across a wide range, we introduce the\nWide-Ranging Information Mining Network (WRIM-Net), which mainly comprises a\nMulti-dimension Interactive Information Mining (MIIM) module and an\nAuxiliary-Information-based Contrastive Learning (AICL) approach. Empowered by\nthe proposed Global Region Interaction (GRI), MIIM comprehensively mines\nnon-local spatial and channel information through intra-dimension interaction.\nMoreover, Thanks to the low computational complexity design, separate MIIM can\nbe positioned in shallow layers, enabling the network to better mine\nspecific-modality multi-dimension information. AICL, by introducing the novel\nCross-Modality Key-Instance Contrastive (CMKIC) loss, effectively guides the\nnetwork in extracting modality-invariant information. We conduct extensive\nexperiments not only on the well-known SYSU-MM01 and RegDB datasets but also on\nthe latest large-scale cross-modality LLCM dataset. The results demonstrate\nWRIM-Net's superiority over state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10624v1",
    "published_date": "2024-08-20 08:06:16 UTC",
    "updated_date": "2024-08-20 08:06:16 UTC"
  },
  {
    "arxiv_id": "2408.10619v2",
    "title": "Hierarchical Attention Diffusion Networks with Object Priors for Video Change Detection",
    "authors": [
      "Andrew Kiruluta",
      "Eric Lundy",
      "Andreas Lemos"
    ],
    "abstract": "We present a unified change detection pipeline that combines instance level\nmasking, multi\\-scale attention within a denoising diffusion model, and per\npixel semantic classification, all refined via SSIM to match human perception.\nBy first isolating only temporally novel objects with Mask R\\-CNN, then guiding\ndiffusion updates through hierarchical cross attention to object and global\ncontexts, and finally categorizing each pixel into one of C change types, our\nmethod delivers detailed, interpretable multi\\-class maps. It outperforms\ntraditional differencing, Siamese CNNs, and GAN\\-based detectors by 10\\-25\npoints in F1 and IoU on both synthetic and real world benchmarks, marking a new\nstate of the art in remote sensing change detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10619v2",
    "published_date": "2024-08-20 07:54:08 UTC",
    "updated_date": "2025-04-26 14:59:05 UTC"
  },
  {
    "arxiv_id": "2408.10618v2",
    "title": "OMEGA: Efficient Occlusion-Aware Navigation for Air-Ground Robot in Dynamic Environments via State Space Model",
    "authors": [
      "Junming Wang",
      "Xiuxian Guan",
      "Zekai Sun",
      "Tianxiang Shen",
      "Dong Huang",
      "Fangming Liu",
      "Heming Cui"
    ],
    "abstract": "Air-ground robots (AGRs) are widely used in surveillance and disaster\nresponse due to their exceptional mobility and versatility (i.e., flying and\ndriving). Current AGR navigation systems perform well in static occlusion-prone\nenvironments (e.g., indoors) by using 3D semantic occupancy networks to predict\nocclusions for complete local mapping and then computing Euclidean Signed\nDistance Field (ESDF) for path planning. However, these systems face challenges\nin dynamic, severe occlusion scenes (e.g., crowds) due to limitations in\nperception networks' low prediction accuracy and path planners' high\ncomputation overhead. In this paper, we propose OMEGA, which contains OccMamba\nwith an Efficient AGR-Planner to address the above-mentioned problems. OccMamba\nadopts a novel architecture that separates semantic and occupancy prediction\ninto independent branches, incorporating two mamba blocks within these\nbranches. These blocks efficiently extract semantic and geometric features in\n3D environments with linear complexity, ensuring that the network can learn\nlong-distance dependencies to improve prediction accuracy. Semantic and\ngeometric features are combined within the Bird's Eye View (BEV) space to\nminimise computational overhead during feature fusion. The resulting semantic\noccupancy map is then seamlessly integrated into the local map, providing\nocclusion awareness of the dynamic environment. Our AGR-Planner utilizes this\nlocal map and employs kinodynamic A* search and gradient-based trajectory\noptimization to guarantee planning is ESDF-free and energy-efficient. Extensive\nexperiments demonstrate that OccMamba outperforms the state-of-the-art 3D\nsemantic occupancy network with 25.0% mIoU. End-to-end navigation experiments\nin dynamic scenes verify OMEGA's efficiency, achieving a 96% average planning\nsuccess rate. Code and video are available at\nhttps://jmwang0117.github.io/OMEGA/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE RA-L | OccMamba is here!",
    "pdf_url": "http://arxiv.org/pdf/2408.10618v2",
    "published_date": "2024-08-20 07:50:29 UTC",
    "updated_date": "2024-12-05 06:54:29 UTC"
  },
  {
    "arxiv_id": "2408.10614v1",
    "title": "Generalizable Facial Expression Recognition",
    "authors": [
      "Yuhang Zhang",
      "Xiuqi Zheng",
      "Chenyi Liang",
      "Jiani Hu",
      "Weihong Deng"
    ],
    "abstract": "SOTA facial expression recognition (FER) methods fail on test sets that have\ndomain gaps with the train set. Recent domain adaptation FER methods need to\nacquire labeled or unlabeled samples of target domains to fine-tune the FER\nmodel, which might be infeasible in real-world deployment. In this paper, we\naim to improve the zero-shot generalization ability of FER methods on different\nunseen test sets using only one train set. Inspired by how humans first detect\nfaces and then select expression features, we propose a novel FER pipeline to\nextract expression-related features from any given face images. Our method is\nbased on the generalizable face features extracted by large models like CLIP.\nHowever, it is non-trivial to adapt the general features of CLIP for specific\ntasks like FER. To preserve the generalization ability of CLIP and the high\nprecision of the FER model, we design a novel approach that learns sigmoid\nmasks based on the fixed CLIP face features to extract expression features. To\nfurther improve the generalization ability on unseen test sets, we separate the\nchannels of the learned masked features according to the expression classes to\ndirectly generate logits and avoid using the FC layer to reduce overfitting. We\nalso introduce a channel-diverse loss to make the learned masks separated.\nExtensive experiments on five different FER datasets verify that our method\noutperforms SOTA FER methods by large margins. Code is available in\nhttps://github.com/zyh-uaiaaaa/Generalizable-FER.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10614v1",
    "published_date": "2024-08-20 07:48:45 UTC",
    "updated_date": "2024-08-20 07:48:45 UTC"
  },
  {
    "arxiv_id": "2408.10608v1",
    "title": "Promoting Equality in Large Language Models: Identifying and Mitigating the Implicit Bias based on Bayesian Theory",
    "authors": [
      "Yongxin Deng",
      "Xihe Qiu",
      "Xiaoyu Tan",
      "Jing Pan",
      "Chen Jue",
      "Zhijun Fang",
      "Yinghui Xu",
      "Wei Chu",
      "Yuan Qi"
    ],
    "abstract": "Large language models (LLMs) are trained on extensive text corpora, which\ninevitably include biased information. Although techniques such as Affective\nAlignment can mitigate some negative impacts of these biases, existing\nprompt-based attack methods can still extract these biases from the model's\nweights. Moreover, these biases frequently appear subtly when LLMs are prompted\nto perform identical tasks across different demographic groups, thereby\ncamouflaging their presence. To address this issue, we have formally defined\nthe implicit bias problem and developed an innovative framework for bias\nremoval based on Bayesian theory, Bayesian-Theory based Bias Removal (BTBR).\nBTBR employs likelihood ratio screening to pinpoint data entries within\npublicly accessible biased datasets that represent biases inadvertently\nincorporated during the LLM training phase. It then automatically constructs\nrelevant knowledge triples and expunges bias information from LLMs using model\nediting techniques. Through extensive experimentation, we have confirmed the\npresence of the implicit bias problem in LLMs and demonstrated the\neffectiveness of our BTBR approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10608v1",
    "published_date": "2024-08-20 07:40:12 UTC",
    "updated_date": "2024-08-20 07:40:12 UTC"
  },
  {
    "arxiv_id": "2408.10605v5",
    "title": "MUSES: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration",
    "authors": [
      "Yanbo Ding",
      "Shaobin Zhuang",
      "Kunchang Li",
      "Zhengrong Yue",
      "Yu Qiao",
      "Yali Wang"
    ],
    "abstract": "Despite recent advancements in text-to-image generation, most existing\nmethods struggle to create images with multiple objects and complex spatial\nrelationships in the 3D world. To tackle this limitation, we introduce a\ngeneric AI system, namely MUSES, for 3D-controllable image generation from user\nqueries. Specifically, our MUSES addresses this challenging task by developing\na progressive workflow with three key components, including (1) Layout Manager\nfor 2D-to-3D layout lifting, (2) Model Engineer for 3D object acquisition and\ncalibration, (3) Image Artist for 3D-to-2D image rendering. By mimicking the\ncollaboration of human professionals, this multi-modal agent pipeline\nfacilitates the effective and automatic creation of images with 3D-controllable\nobjects, through an explainable integration of top-down planning and bottom-up\ngeneration. Additionally, we find that existing benchmarks lack detailed\ndescriptions of complex 3D spatial relationships of multiple objects. To fill\nthis gap, we further construct a new benchmark of T2I-3DisBench (3D image\nscene), which describes diverse 3D image scenes with 50 detailed prompts.\nExtensive experiments show the state-of-the-art performance of MUSES on both\nT2I-CompBench and T2I-3DisBench, outperforming recent strong competitors such\nas DALL-E 3 and Stable Diffusion 3. These results demonstrate a significant\nstep of MUSES forward in bridging natural language, 2D image generation, and 3D\nworld. Our codes are available at the following link:\nhttps://github.com/DINGYANB/MUSES.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.10605v5",
    "published_date": "2024-08-20 07:37:23 UTC",
    "updated_date": "2024-12-16 02:08:29 UTC"
  },
  {
    "arxiv_id": "2408.10604v2",
    "title": "Multilingual Non-Factoid Question Answering with Answer Paragraph Selection",
    "authors": [
      "Ritwik Mishra",
      "Sreeram Vennam",
      "Rajiv Ratn Shah",
      "Ponnurangam Kumaraguru"
    ],
    "abstract": "Most existing Question Answering Datasets (QuADs) primarily focus on\nfactoid-based short-context Question Answering (QA) in high-resource languages.\nHowever, the scope of such datasets for low-resource languages remains limited,\nwith only a few works centered on factoid-based QuADs and none on non-factoid\nQuADs. Therefore, this work presents MuNfQuAD, a multilingual QuAD with\nnon-factoid questions. It utilizes interrogative sub-headings from BBC news\narticles as questions and the corresponding paragraphs as silver answers. The\ndataset comprises over 578K QA pairs across 38 languages, encompassing several\nlow-resource languages, and stands as the largest multilingual QA dataset to\ndate. Based on the manual annotations of 790 QA-pairs from MuNfQuAD (golden\nset), we observe that 98\\% of questions can be answered using their\ncorresponding silver answer. Our fine-tuned Answer Paragraph Selection (APS)\nmodel outperforms the baselines. The APS model attained an accuracy of 80\\% and\n72\\%, as well as a macro F1 of 72\\% and 66\\%, on the MuNfQuAD testset and the\ngolden set, respectively. Furthermore, the APS model effectively generalizes a\ncertain language within the golden set, even after being fine-tuned on silver\nlabels. We also observe that the fine-tuned APS model is beneficial for\nreducing the context of a question. These findings suggest that this resource\nwould be a valuable contribution to the QA research community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Shorter version accepted into DSFA, a special session in PAKDD 2025,\n  Sydney",
    "pdf_url": "http://arxiv.org/pdf/2408.10604v2",
    "published_date": "2024-08-20 07:37:06 UTC",
    "updated_date": "2025-02-19 17:25:39 UTC"
  },
  {
    "arxiv_id": "2408.10602v1",
    "title": "MV-MOS: Multi-View Feature Fusion for 3D Moving Object Segmentation",
    "authors": [
      "Jintao Cheng",
      "Xingming Chen",
      "Jinxin Liang",
      "Xiaoyu Tang",
      "Xieyuanli Chen",
      "Dachuan Li"
    ],
    "abstract": "Effectively summarizing dense 3D point cloud data and extracting motion\ninformation of moving objects (moving object segmentation, MOS) is crucial to\nautonomous driving and robotics applications. How to effectively utilize motion\nand semantic features and avoid information loss during 3D-to-2D projection is\nstill a key challenge. In this paper, we propose a novel multi-view MOS model\n(MV-MOS) by fusing motion-semantic features from different 2D representations\nof point clouds. To effectively exploit complementary information, the motion\nbranches of the proposed model combines motion features from both bird's eye\nview (BEV) and range view (RV) representations. In addition, a semantic branch\nis introduced to provide supplementary semantic features of moving objects.\nFinally, a Mamba module is utilized to fuse the semantic features with motion\nfeatures and provide effective guidance for the motion branches. We validated\nthe effectiveness of the proposed multi-branch fusion MOS framework via\ncomprehensive experiments, and our proposed model outperforms existing\nstate-of-the-art models on the SemanticKITTI benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10602v1",
    "published_date": "2024-08-20 07:30:00 UTC",
    "updated_date": "2024-08-20 07:30:00 UTC"
  },
  {
    "arxiv_id": "2408.10600v1",
    "title": "Breast tumor classification based on self-supervised contrastive learning from ultrasound videos",
    "authors": [
      "Yunxin Tang",
      "Siyuan Tang",
      "Jian Zhang",
      "Hao Chen"
    ],
    "abstract": "Background: Breast ultrasound is prominently used in diagnosing breast\ntumors. At present, many automatic systems based on deep learning have been\ndeveloped to help radiologists in diagnosis. However, training such systems\nremains challenging because they are usually data-hungry and demand amounts of\nlabeled data, which need professional knowledge and are expensive. Methods: We\nadopted a triplet network and a self-supervised contrastive learning technique\nto learn representations from unlabeled breast ultrasound video clips. We\nfurther designed a new hard triplet loss to to learn representations that\nparticularly discriminate positive and negative image pairs that are hard to\nrecognize. We also constructed a pretraining dataset from breast ultrasound\nvideos (1,360 videos from 200 patients), which includes an anchor sample\ndataset with 11,805 images, a positive sample dataset with 188,880 images, and\na negative sample dataset dynamically generated from video clips. Further, we\nconstructed a finetuning dataset, including 400 images from 66 patients. We\ntransferred the pretrained network to a downstream benign/malignant\nclassification task and compared the performance with other state-of-the-art\nmodels, including three models pretrained on ImageNet and a previous\ncontrastive learning model retrained on our datasets. Results and conclusion:\nExperiments revealed that our model achieved an area under the receiver\noperating characteristic curve (AUC) of 0.952, which is significantly higher\nthan the others. Further, we assessed the dependence of our pretrained model on\nthe number of labeled data and revealed that <100 samples were required to\nachieve an AUC of 0.901. The proposed framework greatly reduces the demand for\nlabeled data and holds potential for use in automatic breast ultrasound image\ndiagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10600v1",
    "published_date": "2024-08-20 07:16:01 UTC",
    "updated_date": "2024-08-20 07:16:01 UTC"
  },
  {
    "arxiv_id": "2408.10592v1",
    "title": "Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams",
    "authors": [
      "Litian Huang",
      "Xinguo Yu",
      "Feng Xiong",
      "Bin He",
      "Shengbing Tang",
      "Jiawen Fu"
    ],
    "abstract": "Solving Algebra Problems with Geometry Diagrams (APGDs) is still a\nchallenging problem because diagram processing is not studied as intensively as\nlanguage processing. To work against this challenge, this paper proposes a\nhologram reasoning scheme and develops a high-performance method for solving\nAPGDs by using this scheme. To reach this goal, it first defines a hologram,\nbeing a kind of graph, and proposes a hologram generator to convert a given\nAPGD into a hologram, which represents the entire information of APGD and the\nrelations for solving the problem can be acquired from it by a uniform way.\nThen HGR, a hologram reasoning method employs a pool of prepared graph models\nto derive algebraic equations, which is consistent with the geometric theorems.\nThis method is able to be updated by adding new graph models into the pool.\nLastly, it employs deep reinforcement learning to enhance the efficiency of\nmodel selection from the pool. The entire HGR not only ensures high solution\naccuracy with fewer reasoning steps but also significantly enhances the\ninterpretability of the solution process by providing descriptions of all\nreasoning steps. Experimental results demonstrate the effectiveness of HGR in\nimproving both accuracy and interpretability in solving APGDs.",
    "categories": [
      "cs.AI",
      "cs.CG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10592v1",
    "published_date": "2024-08-20 07:10:05 UTC",
    "updated_date": "2024-08-20 07:10:05 UTC"
  },
  {
    "arxiv_id": "2408.10573v2",
    "title": "Putting People in LLMs' Shoes: Generating Better Answers via Question Rewriter",
    "authors": [
      "Junhao Chen",
      "Bowen Wang",
      "Zhouqiang Jiang",
      "Yuta Nakashima"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities,\nparticularly in the domain of question answering (QA). However, their\neffectiveness in QA is often undermined by the vagueness of user questions. To\naddress this issue, we introduce single-round instance-level prompt\noptimization, referred to as question rewriter. By enhancing the\nintelligibility of human questions for black-box LLMs, our question rewriter\nimproves the quality of generated answers. The rewriter is optimized using\ndirect preference optimization based on feedback collected from automatic\ncriteria for evaluating generated answers; therefore, its training does not\nrequire costly human annotations. The experiments across multiple black-box\nLLMs and long-form question answering (LFQA) datasets demonstrate the efficacy\nof our method. This paper provides a practical framework for training question\nrewriters and sets a precedent for future explorations in prompt optimization\nwithin LFQA tasks. Code is available at\nhttps://github.com/3244we/Question-Rewriter.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 4 figures, 5 tables and accepted at AAAI 2025 Main\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2408.10573v2",
    "published_date": "2024-08-20 06:24:47 UTC",
    "updated_date": "2025-02-25 03:13:27 UTC"
  },
  {
    "arxiv_id": "2408.10572v1",
    "title": "A Tutorial on Explainable Image Classification for Dementia Stages Using Convolutional Neural Network and Gradient-weighted Class Activation Mapping",
    "authors": [
      "Kevin Kam Fung Yuen"
    ],
    "abstract": "This paper presents a tutorial of an explainable approach using Convolutional\nNeural Network (CNN) and Gradient-weighted Class Activation Mapping (Grad-CAM)\nto classify four progressive dementia stages based on open MRI brain images.\nThe detailed implementation steps are demonstrated with an explanation. Whilst\nthe proposed CNN architecture is demonstrated to achieve more than 99% accuracy\nfor the test dataset, the computational procedure of CNN remains a black box.\nThe visualisation based on Grad-CAM is attempted to explain such very high\naccuracy and may provide useful information for physicians. Future motivation\nbased on this work is discussed.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "15 pages, 11 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10572v1",
    "published_date": "2024-08-20 06:23:20 UTC",
    "updated_date": "2024-08-20 06:23:20 UTC"
  },
  {
    "arxiv_id": "2408.10571v4",
    "title": "Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models",
    "authors": [
      "Cong Wan",
      "Yuhang He",
      "Xiang Song",
      "Yihong Gong"
    ],
    "abstract": "Diffusion models have revolutionized customized text-to-image generation,\nallowing for efficient synthesis of photos from personal data with textual\ndescriptions. However, these advancements bring forth risks including privacy\nbreaches and unauthorized replication of artworks. Previous researches\nprimarily center around using prompt-specific methods to generate adversarial\nexamples to protect personal images, yet the effectiveness of existing methods\nis hindered by constrained adaptability to different prompts. In this paper, we\nintroduce a Prompt-Agnostic Adversarial Perturbation (PAP) method for\ncustomized diffusion models. PAP first models the prompt distribution using a\nLaplace Approximation, and then produces prompt-agnostic perturbations by\nmaximizing a disturbance expectation based on the modeled distribution. This\napproach effectively tackles the prompt-agnostic attacks, leading to improved\ndefense stability. Extensive experiments in face privacy and artistic style\nprotection, demonstrate the superior generalization of PAP in comparison to\nexisting techniques. Our project page is available at\nhttps://github.com/vancyland/Prompt-Agnostic-Adversarial-Perturbation-for-Customized-Diffusion-Models.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10571v4",
    "published_date": "2024-08-20 06:17:56 UTC",
    "updated_date": "2024-10-10 06:33:12 UTC"
  },
  {
    "arxiv_id": "2408.10567v1",
    "title": "Prompt Your Brain: Scaffold Prompt Tuning for Efficient Adaptation of fMRI Pre-trained Model",
    "authors": [
      "Zijian Dong",
      "Yilei Wu",
      "Zijiao Chen",
      "Yichi Zhang",
      "Yueming Jin",
      "Juan Helen Zhou"
    ],
    "abstract": "We introduce Scaffold Prompt Tuning (ScaPT), a novel prompt-based framework\nfor adapting large-scale functional magnetic resonance imaging (fMRI)\npre-trained models to downstream tasks, with high parameter efficiency and\nimproved performance compared to fine-tuning and baselines for prompt tuning.\nThe full fine-tuning updates all pre-trained parameters, which may distort the\nlearned feature space and lead to overfitting with limited training data which\nis common in fMRI fields. In contrast, we design a hierarchical prompt\nstructure that transfers the knowledge learned from high-resource tasks to\nlow-resource ones. This structure, equipped with a Deeply-conditioned\nInput-Prompt (DIP) mapping module, allows for efficient adaptation by updating\nonly 2% of the trainable parameters. The framework enhances semantic\ninterpretability through attention mechanisms between inputs and prompts, and\nit clusters prompts in the latent space in alignment with prior knowledge.\nExperiments on public resting state fMRI datasets reveal ScaPT outperforms\nfine-tuning and multitask-based prompt tuning in neurodegenerative diseases\ndiagnosis/prognosis and personality trait prediction, even with fewer than 20\nparticipants. It highlights ScaPT's efficiency in adapting pre-trained fMRI\nmodels to low-resource tasks.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10567v1",
    "published_date": "2024-08-20 06:08:37 UTC",
    "updated_date": "2024-08-20 06:08:37 UTC"
  },
  {
    "arxiv_id": "2408.10566v4",
    "title": "Overcoming Growth-Induced Forgetting in Task-Agnostic Continual Learning",
    "authors": [
      "Yuqing Zhao",
      "Divya Saxena",
      "Jiannong Cao",
      "Xiaoyun Liu",
      "Changlin Song"
    ],
    "abstract": "In continual learning (CL), model growth enhances adaptability over new data,\nimproving knowledge retention for more tasks. However, improper model growth\ncan lead to severe degradation of previously learned knowledge, an issue we\nname as growth-induced forgetting (GIFt), especially in task-agnostic CL using\nentire grown model for inference. Existing works, despite adopting model growth\nand random initialization for better adaptability, often fail to recognize the\npresence of GIFt caused by improper model growth. This oversight limits\ncomprehensive control of forgetting and hinders full utilization of model\ngrowth. We are the first in CL to identify this issue and conduct an in-depth\nstudy on root cause of GIFt, where layer expansion stands out among model\ngrowth strategies, widening layers without affecting model functionality. Yet,\ndirect adoption of layer expansion presents challenges. It lacks data-driven\ncontrol and initialization of expanded parameters to balance adaptability and\nknowledge retention. This paper presents a novel SparseGrow approach to\novercome the issue of GIFt while enhancing adaptability over new data.\nSparseGrow employs data-driven sparse layer expansion to control efficient\nparameter usage during growth, reducing GIFt from excessive growth and\nfunctionality changes. It also combines sparse growth with on-data\ninitialization at training late-stage to create partially 0-valued expansions\nthat fit learned distribution, enhancing retention and adaptability. To further\nminimize forgetting, freezing is applied by calculating the sparse mask,\nallowing data-driven preservation of important parameters. Through experiments\nacross datasets with various settings, cases, and task numbers, we demonstrate\nthe necessity of layer expansion and showcase the effectiveness of SparseGrow\nin overcoming GIFt, highlighting its adaptability and knowledge retention for\nincremental tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10566v4",
    "published_date": "2024-08-20 06:05:52 UTC",
    "updated_date": "2024-09-27 06:32:01 UTC"
  },
  {
    "arxiv_id": "2408.10563v1",
    "title": "The Stable Model Semantics for Higher-Order Logic Programming",
    "authors": [
      "Bart Bogaerts",
      "Angelos Charalambidis",
      "Giannos Chatziagapis",
      "Babis Kostopoulos",
      "Samuele Pollaci",
      "Panos Rondogiannis"
    ],
    "abstract": "We propose a stable model semantics for higher-order logic programs. Our\nsemantics is developed using Approximation Fixpoint Theory (AFT), a powerful\nformalism that has successfully been used to give meaning to diverse\nnon-monotonic formalisms. The proposed semantics generalizes the classical\ntwo-valued stable model semantics of (Gelfond and Lifschitz 1988) as-well-as\nthe three-valued one of (Przymusinski 1990), retaining their desirable\nproperties. Due to the use of AFT, we also get for free alternative semantics\nfor higher-order logic programs, namely supported model, Kripke-Kleene, and\nwell-founded. Additionally, we define a broad class of stratified higher-order\nlogic programs and demonstrate that they have a unique two-valued higher-order\nstable model which coincides with the well-founded semantics of such programs.\nWe provide a number of examples in different application domains, which\ndemonstrate that higher-order logic programming under the stable model\nsemantics is a powerful and versatile formalism, which can potentially form the\nbasis of novel ASP systems.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL",
      "I.2.3; I.2.5; F.3.2"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10563v1",
    "published_date": "2024-08-20 06:03:52 UTC",
    "updated_date": "2024-08-20 06:03:52 UTC"
  },
  {
    "arxiv_id": "2408.10556v2",
    "title": "Hokoff: Real Game Dataset from Honor of Kings and its Offline Reinforcement Learning Benchmarks",
    "authors": [
      "Yun Qu",
      "Boyuan Wang",
      "Jianzhun Shao",
      "Yuhang Jiang",
      "Chen Chen",
      "Zhenbin Ye",
      "Lin Liu",
      "Junfeng Yang",
      "Lin Lai",
      "Hongyang Qin",
      "Minwen Deng",
      "Juchao Zhuo",
      "Deheng Ye",
      "Qiang Fu",
      "Wei Yang",
      "Guang Yang",
      "Lanxiao Huang",
      "Xiangyang Ji"
    ],
    "abstract": "The advancement of Offline Reinforcement Learning (RL) and Offline\nMulti-Agent Reinforcement Learning (MARL) critically depends on the\navailability of high-quality, pre-collected offline datasets that represent\nreal-world complexities and practical applications. However, existing datasets\noften fall short in their simplicity and lack of realism. To address this gap,\nwe propose Hokoff, a comprehensive set of pre-collected datasets that covers\nboth offline RL and offline MARL, accompanied by a robust framework, to\nfacilitate further research. This data is derived from Honor of Kings, a\nrecognized Multiplayer Online Battle Arena (MOBA) game known for its intricate\nnature, closely resembling real-life situations. Utilizing this framework, we\nbenchmark a variety of offline RL and offline MARL algorithms. We also\nintroduce a novel baseline algorithm tailored for the inherent hierarchical\naction space of the game. We reveal the incompetency of current offline RL\napproaches in handling task complexity, generalization and multi-task learning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10556v2",
    "published_date": "2024-08-20 05:38:50 UTC",
    "updated_date": "2024-11-22 02:46:30 UTC"
  },
  {
    "arxiv_id": "2408.10549v1",
    "title": "AI-Based IVR",
    "authors": [
      "Gassyrbek Kosherbay",
      "Nurgissa Apbaz"
    ],
    "abstract": "The use of traditional IVR (Interactive Voice Response) methods often proves\ninsufficient to meet customer needs. This article examines the application of\nartificial intelligence (AI) technologies to enhance the efficiency of IVR\nsystems in call centers. A proposed approach is based on the integration of\nspeech-to-text conversion solutions, text query classification using large\nlanguage models (LLM), and speech synthesis. Special attention is given to\nadapting these technologies to work with the Kazakh language, including\nfine-tuning models on specialized datasets. The practical aspects of\nimplementing the developed system in a real call center for query\nclassification are described. The research results demonstrate that the\napplication of AI technologies in call center IVR systems reduces operator\nworkload, improves customer service quality, and increases the efficiency of\nquery processing. The proposed approach can be adapted for use in call centers\noperating with various languages.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "in Russian language",
    "pdf_url": "http://arxiv.org/pdf/2408.10549v1",
    "published_date": "2024-08-20 05:04:40 UTC",
    "updated_date": "2024-08-20 05:04:40 UTC"
  },
  {
    "arxiv_id": "2408.10543v1",
    "title": "Diff-PCC: Diffusion-based Neural Compression for 3D Point Clouds",
    "authors": [
      "Kai Liu",
      "Kang You",
      "Pan Gao"
    ],
    "abstract": "Stable diffusion networks have emerged as a groundbreaking development for\ntheir ability to produce realistic and detailed visual content. This\ncharacteristic renders them ideal decoders, capable of producing high-quality\nand aesthetically pleasing reconstructions. In this paper, we introduce the\nfirst diffusion-based point cloud compression method, dubbed Diff-PCC, to\nleverage the expressive power of the diffusion model for generative and\naesthetically superior decoding. Different from the conventional autoencoder\nfashion, a dual-space latent representation is devised in this paper, in which\na compressor composed of two independent encoding backbones is considered to\nextract expressive shape latents from distinct latent spaces. At the decoding\nside, a diffusion-based generator is devised to produce high-quality\nreconstructions by considering the shape latents as guidance to stochastically\ndenoise the noisy point clouds. Experiments demonstrate that the proposed\nDiff-PCC achieves state-of-the-art compression performance (e.g., 7.711 dB\nBD-PSNR gains against the latest G-PCC standard at ultra-low bitrate) while\nattaining superior subjective quality. Source code will be made publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10543v1",
    "published_date": "2024-08-20 04:55:29 UTC",
    "updated_date": "2024-08-20 04:55:29 UTC"
  },
  {
    "arxiv_id": "2408.10532v2",
    "title": "NutrifyAI: An AI-Powered System for Real-Time Food Detection, Nutritional Analysis, and Personalized Meal Recommendations",
    "authors": [
      "Michelle Han",
      "Junyao Chen",
      "Zhengyuan Zhou"
    ],
    "abstract": "With diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's not\nsurprise that popular health apps, MyFitnessPal, Noom, and Calorie Counter, are\nsurging in popularity. However, one major setback [2] of nearly all nutrition\napplications is that users must enter food data manually, which is\ntime-consuming and tedious. Thus, there has been an increasing demand for\napplications that can accurately identify food items, analyze their nutritional\ncontent, and offer dietary recommendations in real-time. This paper introduces\na comprehensive system that combines advanced computer vision techniques with\nnutritional analysis, implemented in a versatile mobile and web application.\nThe system is divided into three key concepts: 1) food detection using the\nYOLOv8 model, 2) nutrient analysis via the Edamam Nutrition Analysis API, and\n3) personalized meal recommendations using the Edamam Meal Planning and Recipe\nSearch APIs. Preliminary results showcase the system's effectiveness by\nproviding immediate, accurate dietary insights, with a demonstrated food\nrecognition accuracy of nearly 80%, making it a valuable tool for users to make\ninformed dietary decisions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10532v2",
    "published_date": "2024-08-20 04:18:53 UTC",
    "updated_date": "2024-10-21 06:50:51 UTC"
  },
  {
    "arxiv_id": "2408.10527v1",
    "title": "EdgeNAT: Transformer for Efficient Edge Detection",
    "authors": [
      "Jinghuai Jie",
      "Yan Guo",
      "Guixing Wu",
      "Junmin Wu",
      "Baojian Hua"
    ],
    "abstract": "Transformers, renowned for their powerful feature extraction capabilities,\nhave played an increasingly prominent role in various vision tasks. Especially,\nrecent advancements present transformer with hierarchical structures such as\nDilated Neighborhood Attention Transformer (DiNAT), demonstrating outstanding\nability to efficiently capture both global and local features. However,\ntransformers' application in edge detection has not been fully exploited. In\nthis paper, we propose EdgeNAT, a one-stage transformer-based edge detector\nwith DiNAT as the encoder, capable of extracting object boundaries and\nmeaningful edges both accurately and efficiently. On the one hand, EdgeNAT\ncaptures global contextual information and detailed local cues with DiNAT, on\nthe other hand, it enhances feature representation with a novel SCAF-MLA\ndecoder by utilizing both inter-spatial and inter-channel relationships of\nfeature maps. Extensive experiments on multiple datasets show that our method\nachieves state-of-the-art performance on both RGB and depth images. Notably, on\nthe widely used BSDS500 dataset, our L model achieves impressive performances,\nwith ODS F-measure and OIS F-measure of 86.0%, 87.6% for multi-scale input,and\n84.9%, and 86.3% for single-scale input, surpassing the current\nstate-of-the-art EDTER by 1.2%, 1.1%, 1.7%, and 1.6%, respectively. Moreover,\nas for throughput, our approach runs at 20.87 FPS on RTX 4090 GPU with\nsingle-scale input. The code for our method will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10527v1",
    "published_date": "2024-08-20 04:04:22 UTC",
    "updated_date": "2024-08-20 04:04:22 UTC"
  },
  {
    "arxiv_id": "2408.10524v1",
    "title": "XCB: an effective contextual biasing approach to bias cross-lingual phrases in speech recognition",
    "authors": [
      "Xucheng Wan",
      "Naijun Zheng",
      "Kai Liu",
      "Huan Zhou"
    ],
    "abstract": "Contextualized ASR models have been demonstrated to effectively improve the\nrecognition accuracy of uncommon phrases when a predefined phrase list is\navailable. However, these models often struggle with bilingual settings, which\nare prevalent in code-switching speech recognition. In this study, we make the\ninitial attempt to address this challenge by introducing a Cross-lingual\nContextual Biasing(XCB) module. Specifically, we augment a pre-trained ASR\nmodel for the dominant language by integrating an auxiliary language biasing\nmodule and a supplementary language-specific loss, aimed at enhancing the\nrecognition of phrases in the secondary language. Experimental results\nconducted on our in-house code-switching dataset have validated the efficacy of\nour approach, demonstrating significant improvements in the recognition of\nbiasing phrases in the secondary language, even without any additional\ninference overhead. Additionally, our proposed system exhibits both efficiency\nand generalization when is applied by the unseen ASRU-2019 test set.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted to NCMMSC 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10524v1",
    "published_date": "2024-08-20 04:00:19 UTC",
    "updated_date": "2024-08-20 04:00:19 UTC"
  },
  {
    "arxiv_id": "2408.10517v5",
    "title": "Integrating Multi-Modal Input Token Mixer Into Mamba-Based Decision Models: Decision MetaMamba",
    "authors": [
      "Wall Kim"
    ],
    "abstract": "Sequence modeling with State Space models (SSMs) has demonstrated performance\nsurpassing that of Transformers in various tasks, raising expectations for\ntheir potential to outperform the Decision Transformer and its enhanced\nvariants in offline reinforcement learning (RL). However, decision models based\non Mamba, a state-of-the-art SSM, failed to achieve superior performance\ncompared to these enhanced Decision Transformers. We hypothesize that this\nlimitation arises from information loss during the selective scanning phase. To\naddress this, we propose the Decision MetaMamba (DMM), which augments Mamba\nwith a token mixer in its input layer. This mixer explicitly accounts for the\nmultimodal nature of offline RL inputs, comprising state, action, and\nreturn-to-go. The DMM demonstrates improved performance while significantly\nreducing parameter count compared to prior models. Notably, similar performance\ngains were achieved using a simple linear token mixer, emphasizing the\nimportance of preserving information from proximate time steps rather than the\nspecific design of the token mixer itself. This novel modification to Mamba's\ninput layer represents a departure from conventional timestamp-based encoding\napproaches used in Transformers. By enhancing performance of Mamba in offline\nRL, characterized by memory efficiency and fast inference, this work opens new\navenues for its broader application in future RL research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We have decided to withdraw this manuscript as we believe that the\n  work requires significant improvements and further research to ensure its\n  quality and impact. We are currently pursuing a more comprehensive approach\n  to address the limitations of the current submission and plan to resubmit an\n  improved version in the future",
    "pdf_url": "http://arxiv.org/pdf/2408.10517v5",
    "published_date": "2024-08-20 03:35:28 UTC",
    "updated_date": "2025-01-09 06:41:46 UTC"
  },
  {
    "arxiv_id": "2408.10516v1",
    "title": "Data Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups",
    "authors": [
      "Zhiyang Qi",
      "Michimasa Inaba"
    ],
    "abstract": "This study addresses the interaction challenges encountered by spoken\ndialogue systems (SDSs) when engaging with users who exhibit distinct\nconversational behaviors, particularly minors, in scenarios where data are\nscarce. We propose a novel data augmentation framework to enhance SDS\nperformance for user groups with limited resources. Our approach leverages a\nlarge language model (LLM) to extract speaker styles and a pre-trained language\nmodel (PLM) to simulate dialogue act history. This method generates enriched\nand personalized dialogue data, facilitating improved interactions with unique\nuser demographics. Extensive experiments validate the efficacy of our\nmethodology, highlighting its potential to foster the development of more\nadaptive and inclusive dialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to SIGDIAL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10516v1",
    "published_date": "2024-08-20 03:33:04 UTC",
    "updated_date": "2024-08-20 03:33:04 UTC"
  },
  {
    "arxiv_id": "2408.10512v1",
    "title": "Approximate Estimation of High-dimension Execution Skill for Dynamic Agents in Continuous Domains",
    "authors": [
      "Delma Nieves-Rivera",
      "Christopher Archibald"
    ],
    "abstract": "In many real-world continuous action domains, human agents must decide which\nactions to attempt and then execute those actions to the best of their ability.\nHowever, humans cannot execute actions without error. Human performance in\nthese domains can potentially be improved by the use of AI to aid in\ndecision-making. One requirement for an AI to correctly reason about what\nactions a human agent should attempt is a correct model of that human's\nexecution error, or skill. Recent work has demonstrated successful techniques\nfor estimating this execution error with various types of agents across\ndifferent domains. However, this previous work made several assumptions that\nlimit the application of these ideas to real-world settings. First, previous\nwork assumed that the error distributions were symmetric normal, which meant\nthat only a single parameter had to be estimated. In reality, agent error\ndistributions might exhibit arbitrary shapes and should be modeled more\nflexibly. Second, it was assumed that the execution error of the agent remained\nconstant across all observations. Especially for human agents, execution error\nchanges over time, and this must be taken into account to obtain effective\nestimates. To overcome both of these shortcomings, we propose a novel\nparticle-filter-based estimator for this problem. After describing the details\nof this approximate estimator, we experimentally explore various design\ndecisions and compare performance with previous skill estimators in a variety\nof settings to showcase the improvements. The outcome is an estimator capable\nof generating more realistic, time-varying execution skill estimates of agents,\nwhich can then be used to assist agents in making better decisions and improve\ntheir overall performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10512v1",
    "published_date": "2024-08-20 03:27:09 UTC",
    "updated_date": "2024-08-20 03:27:09 UTC"
  },
  {
    "arxiv_id": "2408.10511v3",
    "title": "Single-cell Curriculum Learning-based Deep Graph Embedding Clustering",
    "authors": [
      "Huifa Li",
      "Jie Fu",
      "Xinpeng Ling",
      "Zhiyu Sun",
      "Kuncan Wang",
      "Zhili Chen"
    ],
    "abstract": "The swift advancement of single-cell RNA sequencing (scRNA-seq) technologies\nenables the investigation of cellular-level tissue heterogeneity. Cell\nannotation significantly contributes to the extensive downstream analysis of\nscRNA-seq data. However, The analysis of scRNA-seq for biological inference\npresents challenges owing to its intricate and indeterminate data distribution,\ncharacterized by a substantial volume and a high frequency of dropout events.\nFurthermore, the quality of training samples varies greatly, and the\nperformance of the popular scRNA-seq data clustering solution GNN could be\nharmed by two types of low-quality training nodes: 1) nodes on the boundary; 2)\nnodes that contribute little additional information to the graph. To address\nthese problems, we propose a single-cell curriculum learning-based deep graph\nembedding clustering (scCLG). We first propose a Chebyshev graph convolutional\nautoencoder with multi-criteria (ChebAE) that combines three optimization\nobjectives, including topology reconstruction loss of cell graphs,\nzero-inflated negative binomial (ZINB) loss, and clustering loss, to learn\ncell-cell topology representation. Meanwhile, we employ a selective training\nstrategy to train GNN based on the features and entropy of nodes and prune the\ndifficult nodes based on the difficulty scores to keep the high-quality graph.\nEmpirical results on a variety of gene expression datasets show that our model\noutperforms state-of-the-art methods. The code of scCLG will be made publicly\navailable at https://github.com/LFD-byte/scCLG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10511v3",
    "published_date": "2024-08-20 03:20:13 UTC",
    "updated_date": "2024-11-27 04:46:17 UTC"
  },
  {
    "arxiv_id": "2408.10504v1",
    "title": "QPO: Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning",
    "authors": [
      "Yilun Kong",
      "Hangyu Mao",
      "Qi Zhao",
      "Bin Zhang",
      "Jingqing Ruan",
      "Li Shen",
      "Yongzhe Chang",
      "Xueqian Wang",
      "Rui Zhao",
      "Dacheng Tao"
    ],
    "abstract": "Prompt engineering has demonstrated remarkable success in enhancing the\nperformance of large language models (LLMs) across diverse tasks. However, most\nexisting prompt optimization methods only focus on the task-level performance,\noverlooking the importance of query-preferred prompts, which leads to\nsuboptimal performances. Additionally, these methods rely heavily on frequent\ninteractions with LLMs to obtain feedback for guiding the optimization process,\nincurring substantial redundant interaction costs. In this paper, we introduce\nQuery-dependent Prompt Optimization (QPO), which leverages multi-loop offline\nreinforcement learning to iteratively fine-tune a small pretrained language\nmodel to generate optimal prompts tailored to the input queries, thus\nsignificantly improving the prompting effect on the large target LLM. We derive\ninsights from offline prompting demonstration data, which already exists in\nlarge quantities as a by-product of benchmarking diverse prompts on\nopen-sourced tasks, thereby circumventing the expenses of online interactions.\nFurthermore, we continuously augment the offline dataset with the generated\nprompts in each loop, as the prompts from the fine-tuned model are supposed to\noutperform the source prompts in the original dataset. These iterative loops\nbootstrap the model towards generating optimal prompts. Experiments on various\nLLM scales and diverse NLP and math tasks demonstrate the efficacy and\ncost-efficiency of our method in both zero-shot and few-shot scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10504v1",
    "published_date": "2024-08-20 03:06:48 UTC",
    "updated_date": "2024-08-20 03:06:48 UTC"
  },
  {
    "arxiv_id": "2408.10503v1",
    "title": "Adaptive Knowledge Distillation for Classification of Hand Images using Explainable Vision Transformers",
    "authors": [
      "Thanh Thi Nguyen",
      "Campbell Wilson",
      "Janis Dalins"
    ],
    "abstract": "Assessing the forensic value of hand images involves the use of unique\nfeatures and patterns present in an individual's hand. The human hand has\ndistinct characteristics, such as the pattern of veins, fingerprints, and the\ngeometry of the hand itself. This paper investigates the use of vision\ntransformers (ViTs) for classification of hand images. We use explainability\ntools to explore the internal representations of ViTs and assess their impact\non the model outputs. Utilizing the internal understanding of ViTs, we\nintroduce distillation methods that allow a student model to adaptively extract\nknowledge from a teacher model while learning on data of a different domain to\nprevent catastrophic forgetting. Two publicly available hand image datasets are\nused to conduct a series of experiments to evaluate performance of the ViTs and\nour proposed adaptive distillation methods. The experimental results\ndemonstrate that ViT models significantly outperform traditional machine\nlearning methods and the internal states of ViTs are useful for explaining the\nmodel outputs in the classification task. By averting catastrophic forgetting,\nour distillation methods achieve excellent performance on data from both source\nand target domains, particularly when these two domains exhibit significant\ndissimilarity. The proposed approaches therefore can be developed and\nimplemented effectively for real-world applications such as access control,\nidentity verification, and authentication systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the ECML PKDD 2024 (Research Track)",
    "pdf_url": "http://arxiv.org/pdf/2408.10503v1",
    "published_date": "2024-08-20 03:03:56 UTC",
    "updated_date": "2024-08-20 03:03:56 UTC"
  },
  {
    "arxiv_id": "2408.10499v1",
    "title": "ProgramAlly: Creating Custom Visual Access Programs via Multi-Modal End-User Programming",
    "authors": [
      "Jaylin Herskovitz",
      "Andi Xu",
      "Rahaf Alharbi",
      "Anhong Guo"
    ],
    "abstract": "Existing visual assistive technologies are built for simple and common use\ncases, and have few avenues for blind people to customize their\nfunctionalities. Drawing from prior work on DIY assistive technology, this\npaper investigates end-user programming as a means for users to create and\ncustomize visual access programs to meet their unique needs. We introduce\nProgramAlly, a system for creating custom filters for visual information, e.g.,\n'find NUMBER on BUS', leveraging three end-user programming approaches: block\nprogramming, natural language, and programming by example. To implement\nProgramAlly, we designed a representation of visual filtering tasks based on\nscenarios encountered by blind people, and integrated a set of on-device and\ncloud models for generating and running these programs. In user studies with 12\nblind adults, we found that participants preferred different programming\nmodalities depending on the task, and envisioned using visual access programs\nto address unique accessibility challenges that are otherwise difficult with\nexisting applications. Through ProgramAlly, we present an exploration of how\nblind end-users can create visual access programs to customize and control\ntheir experiences.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.HC",
    "comment": "UIST 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10499v1",
    "published_date": "2024-08-20 02:45:31 UTC",
    "updated_date": "2024-08-20 02:45:31 UTC"
  },
  {
    "arxiv_id": "2408.10497v2",
    "title": "QUITO-X: A New Perspective on Context Compression from the Information Bottleneck Theory",
    "authors": [
      "Yihang Wang",
      "Xu Huang",
      "Bowen Tian",
      "Yueyang Su",
      "Lei Yu",
      "Huaming Liao",
      "Yixing Fan",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Generative LLM have achieved remarkable success in various industrial\napplications, owing to their promising In-Context Learning capabilities.\nHowever, the issue of long context in complex tasks poses a significant barrier\nto their wider adoption, manifested in two main aspects: (i) The excessively\nlong context leads to high costs and inference delays. (ii) A substantial\namount of task-irrelevant information introduced by long contexts exacerbates\nthe \"lost in the middle\" problem. Existing methods compress context by removing\nredundant tokens using metrics such as self-information or PPL, which is\ninconsistent with the objective of retaining the most important tokens when\nconditioning on a given query. In this study, we introduce information\nbottleneck theory (IB) to model the problem, offering a novel perspective that\nthoroughly addresses the essential properties required for context compression.\nAdditionally, we propose a cross-attention-based approach to approximate mutual\ninformation in IB, which can be flexibly replaced with suitable alternatives in\ndifferent scenarios. Extensive experiments on four datasets demonstrate that\nour method achieves a 25% increase in compression rate compared to the\nstate-of-the-art, while maintaining question answering performance. In\nparticular, the context compressed by our method even outperform the full\ncontext in some cases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10497v2",
    "published_date": "2024-08-20 02:44:45 UTC",
    "updated_date": "2024-12-16 15:03:54 UTC"
  },
  {
    "arxiv_id": "2408.10495v1",
    "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Producers?",
    "authors": [
      "Jianian Gong",
      "Nachuan Duan",
      "Ziheng Tao",
      "Zhaohui Gong",
      "Yuan Yuan",
      "Minlie Huang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) such as GPT-4 has\nrevolutionized the landscape of software engineering, positioning these models\nat the core of modern development practices. As we anticipate these models to\nevolve into the primary and trustworthy tools used in software development,\nensuring the security of the code they produce becomes paramount. How well can\nLLMs serve as end-to-end secure code producers? This paper presents a\nsystematic investigation into LLMs' inherent potential to generate code with\nfewer vulnerabilities. Specifically, We studied GPT-3.5 and GPT-4's capability\nto identify and repair vulnerabilities in the code generated by four popular\nLLMs including themselves (GPT-3.5, GPT-4, Code Llama, and CodeGeeX2). By\nmanually or automatically reviewing 4,900 pieces of code, our study reveals\nthat: (1) large language models lack awareness of scenario-relevant security\nrisks, which leads to the generation of over 75% vulnerable code on the\nSecurityEval benchmark; (2) LLMs such as GPT-3.5 and GPT-4 are unable to\nprecisely identify vulnerabilities in the code they generated; (3) GPT-3.5 and\nGPT-4 can achieve 33.2%~59.6% success rates in repairing the insecure code\nproduced by the 4 LLMs, but they both perform poorly when repairing\nself-produced code, indicating self-repair \"blind spots\". To address the\nlimitation of a single round of repair, we developed a lightweight tool that\nprompts LLMs to construct safer source code through an iterative repair\nprocedure based on the insights gained from our study. Experiments show that\nassisted by semantic analysis engines, our tool significantly improves the\nsuccess rates of repair to 65.9%~85.5%.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10495v1",
    "published_date": "2024-08-20 02:42:29 UTC",
    "updated_date": "2024-08-20 02:42:29 UTC"
  },
  {
    "arxiv_id": "2408.10491v2",
    "title": "Achieving the Tightest Relaxation of Sigmoids for Formal Verification",
    "authors": [
      "Samuel Chevalier",
      "Duncan Starkenburg",
      "Krishnamurthy Dvijotham"
    ],
    "abstract": "In the field of formal verification, Neural Networks (NNs) are typically\nreformulated into equivalent mathematical programs which are optimized over. To\novercome the inherent non-convexity of these reformulations, convex relaxations\nof nonlinear activation functions are typically utilized. Common relaxations\n(i.e., static linear cuts) of \"S-shaped\" activation functions, however, can be\noverly loose, slowing down the overall verification process. In this paper, we\nderive tuneable hyperplanes which upper and lower bound the sigmoid activation\nfunction. When tuned in the dual space, these affine bounds smoothly rotate\naround the nonlinear manifold of the sigmoid activation function. This\napproach, termed $\\alpha$-sig, allows us to tractably incorporate the tightest\npossible, element-wise convex relaxation of the sigmoid activation function\ninto a formal verification framework. We embed these relaxations inside of\nlarge verification tasks and compare their performance to LiRPA and\n$\\alpha$-CROWN, a state-of-the-art verification duo.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10491v2",
    "published_date": "2024-08-20 02:22:27 UTC",
    "updated_date": "2024-08-22 00:10:24 UTC"
  },
  {
    "arxiv_id": "2408.10492v2",
    "title": "Is the Lecture Engaging for Learning? Lecture Voice Sentiment Analysis for Knowledge Graph-Supported Intelligent Lecturing Assistant (ILA) System",
    "authors": [
      "Yuan An",
      "Samarth Kolanupaka",
      "Jacob An",
      "Matthew Ma",
      "Unnat Chhatwal",
      "Alex Kalinowski",
      "Michelle Rogers",
      "Brian Smith"
    ],
    "abstract": "This paper introduces an intelligent lecturing assistant (ILA) system that\nutilizes a knowledge graph to represent course content and optimal pedagogical\nstrategies. The system is designed to support instructors in enhancing student\nlearning through real-time analysis of voice, content, and teaching methods. As\nan initial investigation, we present a case study on lecture voice sentiment\nanalysis, in which we developed a training set comprising over 3,000 one-minute\nlecture voice clips. Each clip was manually labeled as either engaging or\nnon-engaging. Utilizing this dataset, we constructed and evaluated several\nclassification models based on a variety of features extracted from the voice\nclips. The results demonstrate promising performance, achieving an F1-score of\n90% for boring lectures on an independent set of over 800 test voice clips.\nThis case study lays the groundwork for the development of a more sophisticated\nmodel that will integrate content analysis and pedagogical practices. Our\nultimate goal is to aid instructors in teaching more engagingly and effectively\nby leveraging modern artificial intelligence techniques.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in the 4th Workshop on Knowledge Graphs and Big Data @ IEEE\n  Big Data Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10492v2",
    "published_date": "2024-08-20 02:22:27 UTC",
    "updated_date": "2024-10-29 17:18:31 UTC"
  },
  {
    "arxiv_id": "2408.10488v1",
    "title": "Event Stream based Sign Language Translation: A High-Definition Benchmark Dataset and A New Algorithm",
    "authors": [
      "Xiao Wang",
      "Yao Rong",
      "Fuling Wang",
      "Jianing Li",
      "Lin Zhu",
      "Bo Jiang",
      "Yaowei Wang"
    ],
    "abstract": "Sign Language Translation (SLT) is a core task in the field of AI-assisted\ndisability. Unlike traditional SLT based on visible light videos, which is\neasily affected by factors such as lighting, rapid hand movements, and privacy\nbreaches, this paper proposes the use of high-definition Event streams for SLT,\neffectively mitigating the aforementioned issues. This is primarily because\nEvent streams have a high dynamic range and dense temporal signals, which can\nwithstand low illumination and motion blur well. Additionally, due to their\nsparsity in space, they effectively protect the privacy of the target person.\nMore specifically, we propose a new high-resolution Event stream sign language\ndataset, termed Event-CSL, which effectively fills the data gap in this area of\nresearch. It contains 14,827 videos, 14,821 glosses, and 2,544 Chinese words in\nthe text vocabulary. These samples are collected in a variety of indoor and\noutdoor scenes, encompassing multiple angles, light intensities, and camera\nmovements. We have benchmarked existing mainstream SLT works to enable fair\ncomparison for future efforts. Based on this dataset and several other\nlarge-scale datasets, we propose a novel baseline method that fully leverages\nthe Mamba model's ability to integrate temporal information of CNN features,\nresulting in improved sign language translation outcomes. Both the benchmark\ndataset and source code will be released on\nhttps://github.com/Event-AHU/OpenESL",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "First Large-scale and High-Definition Benchmark Dataset for\n  Event-based Sign Language Translation",
    "pdf_url": "http://arxiv.org/pdf/2408.10488v1",
    "published_date": "2024-08-20 02:01:30 UTC",
    "updated_date": "2024-08-20 02:01:30 UTC"
  },
  {
    "arxiv_id": "2408.10487v1",
    "title": "MambaEVT: Event Stream based Visual Object Tracking using State Space Model",
    "authors": [
      "Xiao Wang",
      "Chao wang",
      "Shiao Wang",
      "Xixi Wang",
      "Zhicheng Zhao",
      "Lin Zhu",
      "Bo Jiang"
    ],
    "abstract": "Event camera-based visual tracking has drawn more and more attention in\nrecent years due to the unique imaging principle and advantages of low energy\nconsumption, high dynamic range, and dense temporal resolution. Current\nevent-based tracking algorithms are gradually hitting their performance\nbottlenecks, due to the utilization of vision Transformer and the static\ntemplate for target object localization. In this paper, we propose a novel\nMamba-based visual tracking framework that adopts the state space model with\nlinear complexity as a backbone network. The search regions and target template\nare fed into the vision Mamba network for simultaneous feature extraction and\ninteraction. The output tokens of search regions will be fed into the tracking\nhead for target localization. More importantly, we consider introducing a\ndynamic template update strategy into the tracking framework using the Memory\nMamba network. By considering the diversity of samples in the target template\nlibrary and making appropriate adjustments to the template memory module, a\nmore effective dynamic template can be integrated. The effective combination of\ndynamic and static templates allows our Mamba-based tracking algorithm to\nachieve a good balance between accuracy and computational cost on multiple\nlarge-scale datasets, including EventVOT, VisEvent, and FE240hz. The source\ncode will be released on https://github.com/Event-AHU/MambaEVT",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Peer Review",
    "pdf_url": "http://arxiv.org/pdf/2408.10487v1",
    "published_date": "2024-08-20 02:01:17 UTC",
    "updated_date": "2024-08-20 02:01:17 UTC"
  },
  {
    "arxiv_id": "2408.10482v1",
    "title": "Evaluation Framework for AI-driven Molecular Design of Multi-target Drugs: Brain Diseases as a Case Study",
    "authors": [
      "Arthur Cerveira",
      "Frederico Kremer",
      "Darling de Andrade Lourenço",
      "Ulisses B Corrêa"
    ],
    "abstract": "The widespread application of Artificial Intelligence (AI) techniques has\nsignificantly influenced the development of new therapeutic agents. These\ncomputational methods can be used to design and predict the properties of\ngenerated molecules. Multi-target Drug Discovery (MTDD) is an emerging paradigm\nfor discovering drugs against complex disorders that do not respond well to\nmore traditional target-specific treatments, such as central nervous system,\nimmune system, and cardiovascular diseases. Still, there is yet to be an\nestablished benchmark suite for assessing the effectiveness of AI tools for\ndesigning multi-target compounds. Standardized benchmarks allow for comparing\nexisting techniques and promote rapid research progress. Hence, this work\nproposes an evaluation framework for molecule generation techniques in MTDD\nscenarios, considering brain diseases as a case study. Our methodology involves\nusing large language models to select the appropriate molecular targets,\ngathering and preprocessing the bioassay datasets, training quantitative\nstructure-activity relationship models to predict target modulation, and\nassessing other essential drug-likeness properties for implementing the\nbenchmarks. Additionally, this work will assess the performance of four deep\ngenerative models and evolutionary algorithms over our benchmark suite. In our\nfindings, both evolutionary algorithms and generative models can achieve\ncompetitive results across the proposed benchmarks.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "8 pages, 1 figure, published in 2024 IEEE Congress on Evolutionary\n  Computation (CEC)",
    "pdf_url": "http://arxiv.org/pdf/2408.10482v1",
    "published_date": "2024-08-20 01:42:16 UTC",
    "updated_date": "2024-08-20 01:42:16 UTC"
  },
  {
    "arxiv_id": "2408.10479v1",
    "title": "An End-to-End Reinforcement Learning Based Approach for Micro-View Order-Dispatching in Ride-Hailing",
    "authors": [
      "Xinlang Yue",
      "Yiran Liu",
      "Fangzhou Shi",
      "Sihong Luo",
      "Chen Zhong",
      "Min Lu",
      "Zhe Xu"
    ],
    "abstract": "Assigning orders to drivers under localized spatiotemporal context\n(micro-view order-dispatching) is a major task in Didi, as it influences\nride-hailing service experience. Existing industrial solutions mainly follow a\ntwo-stage pattern that incorporate heuristic or learning-based algorithms with\nnaive combinatorial methods, tackling the uncertainty of both sides' behaviors,\nincluding emerging timings, spatial relationships, and travel duration, etc. In\nthis paper, we propose a one-stage end-to-end reinforcement learning based\norder-dispatching approach that solves behavior prediction and combinatorial\noptimization uniformly in a sequential decision-making manner. Specifically, we\nemploy a two-layer Markov Decision Process framework to model this problem, and\npresent \\underline{D}eep \\underline{D}ouble \\underline{S}calable\n\\underline{N}etwork (D2SN), an encoder-decoder structure network to generate\norder-driver assignments directly and stop assignments accordingly. Besides, by\nleveraging contextual dynamics, our approach can adapt to the behavioral\npatterns for better performance. Extensive experiments on Didi's real-world\nbenchmarks justify that the proposed approach significantly outperforms\ncompetitive baselines in optimizing matching efficiency and user experience\ntasks. In addition, we evaluate the deployment outline and discuss the gains\nand experiences obtained during the deployment tests from the view of\nlarge-scale engineering implementation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.10479v1",
    "published_date": "2024-08-20 01:30:53 UTC",
    "updated_date": "2024-08-20 01:30:53 UTC"
  },
  {
    "arxiv_id": "2408.10474v1",
    "title": "LeCov: Multi-level Testing Criteria for Large Language Models",
    "authors": [
      "Xuan Xie",
      "Jiayang Song",
      "Yuheng Huang",
      "Da Song",
      "Fuyuan Zhang",
      "Felix Juefei-Xu",
      "Lei Ma"
    ],
    "abstract": "Large Language Models (LLMs) are widely used in many different domains, but\nbecause of their limited interpretability, there are questions about how\ntrustworthy they are in various perspectives, e.g., truthfulness and toxicity.\nRecent research has started developing testing methods for LLMs, aiming to\nuncover untrustworthy issues, i.e., defects, before deployment. However,\nsystematic and formalized testing criteria are lacking, which hinders a\ncomprehensive assessment of the extent and adequacy of testing exploration. To\nmitigate this threat, we propose a set of multi-level testing criteria, LeCov,\nfor LLMs. The criteria consider three crucial LLM internal components, i.e.,\nthe attention mechanism, feed-forward neurons, and uncertainty, and contain\nnine types of testing criteria in total. We apply the criteria in two\nscenarios: test prioritization and coverage-guided testing. The experiment\nevaluation, on three models and four datasets, demonstrates the usefulness and\neffectiveness of LeCov.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.10474v1",
    "published_date": "2024-08-20 01:17:54 UTC",
    "updated_date": "2024-08-20 01:17:54 UTC"
  }
]