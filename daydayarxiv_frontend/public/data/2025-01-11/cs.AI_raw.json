[
  {
    "arxiv_id": "2501.06645v1",
    "title": "FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings",
    "authors": [
      "Tong Liu",
      "Xiao Yu",
      "Wenxuan Zhou",
      "Jindong Gu",
      "Volker Tresp"
    ],
    "abstract": "Efficient preference optimization algorithms such as Direct Preference\nOptimization (DPO) have become a popular approach in aligning large language\nmodels (LLMs) with human preferences. These algorithms implicitly treat the LLM\nas a reward model, and focus on training it to correct misranked preference\npairs. However, recent work~\\citep{chen2024preference} empirically finds that\nDPO training \\textit{rarely improves these misranked preference pairs}, despite\nits gradient emphasizing on these cases. We introduce FocalPO, a DPO variant\nthat instead \\textit{down-weighs} misranked preference pairs and prioritizes\nenhancing the model's understanding of pairs that it can already rank\ncorrectly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this\nby adding a modulating factor to dynamically scale DPO loss. Our experiment\ndemonstrates that FocalPO surpasses DPO and its variants on popular benchmarks\nlike Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B.\nAdditionally, we empirically reveals how FocalPO affects training on correct\nand incorrect sample groups, further underscoring its effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06645v1",
    "published_date": "2025-01-11 21:41:27 UTC",
    "updated_date": "2025-01-11 21:41:27 UTC"
  },
  {
    "arxiv_id": "2501.06642v1",
    "title": "Common Sense Is All You Need",
    "authors": [
      "Hugo Latapie"
    ],
    "abstract": "Artificial intelligence (AI) has made significant strides in recent years,\nyet it continues to struggle with a fundamental aspect of cognition present in\nall animals: common sense. Current AI systems, including those designed for\ncomplex tasks like autonomous driving, problem-solving challenges such as the\nAbstraction and Reasoning Corpus (ARC), and conversational benchmarks like the\nTuring Test, often lack the ability to adapt to new situations without\nextensive prior knowledge. This manuscript argues that integrating common sense\ninto AI systems is essential for achieving true autonomy and unlocking the full\nsocietal and commercial value of AI.\n  We propose a shift in the order of knowledge acquisition emphasizing the\nimportance of developing AI systems that start from minimal prior knowledge and\nare capable of contextual learning, adaptive reasoning, and embodiment -- even\nwithin abstract domains. Additionally, we highlight the need to rethink the AI\nsoftware stack to address this foundational challenge. Without common sense, AI\nsystems may never reach true autonomy, instead exhibiting asymptotic\nperformance that approaches theoretical ideals like AIXI but remains\nunattainable in practice due to infinite resource and computation requirements.\n  While scaling AI models and passing benchmarks like the Turing Test have\nbrought significant advancements in applications that do not require autonomy,\nthese approaches alone are insufficient to achieve autonomous AI with common\nsense. By redefining existing benchmarks and challenges to enforce constraints\nthat require genuine common sense, and by broadening our understanding of\nembodiment to include both physical and abstract domains, we can encourage the\ndevelopment of AI systems better equipped to handle the complexities of\nreal-world and abstract environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06642v1",
    "published_date": "2025-01-11 21:23:41 UTC",
    "updated_date": "2025-01-11 21:23:41 UTC"
  },
  {
    "arxiv_id": "2501.06639v1",
    "title": "Enhancing Path Planning Performance through Image Representation Learning of High-Dimensional Configuration Spaces",
    "authors": [
      "Jorge Ocampo Jimenez",
      "Wael Suleiman"
    ],
    "abstract": "This paper presents a novel method for accelerating path-planning tasks in\nunknown scenes with obstacles by utilizing Wasserstein Generative Adversarial\nNetworks (WGANs) with Gradient Penalty (GP) to approximate the distribution of\nwaypoints for a collision-free path using the Rapidly-exploring Random Tree\nalgorithm. Our approach involves conditioning the WGAN-GP with a forward\ndiffusion process in a continuous latent space to handle multimodal datasets\neffectively. We also propose encoding the waypoints of a collision-free path as\na matrix, where the multidimensional ordering of the waypoints is naturally\npreserved. This method not only improves model learning but also enhances\ntraining convergence. Furthermore, we propose a method to assess whether the\ntrained model fails to accurately capture the true waypoints. In such cases, we\nrevert to uniform sampling to ensure the algorithm's probabilistic\ncompleteness; a process that traditionally involves manually determining an\noptimal ratio for each scenario in other machine learning-based methods. Our\nexperiments demonstrate promising results in accelerating path-planning tasks\nunder critical time constraints. The source code is openly available at\nhttps://bitbucket.org/joro3001/imagewgangpplanning/src/master/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06639v1",
    "published_date": "2025-01-11 21:14:52 UTC",
    "updated_date": "2025-01-11 21:14:52 UTC"
  },
  {
    "arxiv_id": "2501.06628v1",
    "title": "Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach",
    "authors": [
      "Mohammed Maree"
    ],
    "abstract": "This paper introduces a neuro-symbolic approach for relational exploration in\ncultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for\nexplanation generation and a novel mathematical framework to quantify the\ninterestingness of relationships. We demonstrate the importance of\ninterestingness measure using a quantitative analysis, by highlighting its\nimpact on the overall performance of our proposed system, particularly in terms\nof precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked\nOpen Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of\n0.68, and an F1-score of 0.69, representing an improvement compared to\ngraph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based\nbaselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our\nLLM-powered explanations exhibit better quality, reflected in BLEU (0.52),\nROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline\napproaches. We show a strong correlation (0.65) between interestingness measure\nand the quality of generated explanations, validating its effectiveness. The\nfindings highlight the importance of LLMs and a mathematical formalization for\ninterestingness in enhancing the effectiveness of relational exploration in\ncultural heritage knowledge graphs, with results that are measurable and\ntestable. We further show that the system enables more effective exploration\ncompared to purely knowledge-based and graph-based methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06628v1",
    "published_date": "2025-01-11 19:50:09 UTC",
    "updated_date": "2025-01-11 19:50:09 UTC"
  },
  {
    "arxiv_id": "2501.06625v1",
    "title": "Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks",
    "authors": [
      "Amr Almorsi",
      "Mohanned Ahmed",
      "Walid Gomaa"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in code\ngeneration tasks, yet they face significant limitations in handling complex,\nlong-context programming challenges and demonstrating complex compositional\nreasoning abilities. This paper introduces a novel agentic framework for\n``guided code generation'' that tries to address these limitations through a\ndeliberately structured, fine-grained approach to code generation tasks. Our\nframework leverages LLMs' strengths as fuzzy searchers and approximate\ninformation retrievers while mitigating their weaknesses in long sequential\nreasoning and long-context understanding. Empirical evaluation using OpenAI's\nHumanEval benchmark with Meta's Llama 3.1 8B model (int4 precision)\ndemonstrates a 23.79\\% improvement in solution accuracy compared to direct\none-shot generation. Our results indicate that structured, guided approaches to\ncode generation can significantly enhance the practical utility of LLMs in\nsoftware development while overcoming their inherent limitations in\ncompositional reasoning and context handling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06625v1",
    "published_date": "2025-01-11 19:21:53 UTC",
    "updated_date": "2025-01-11 19:21:53 UTC"
  },
  {
    "arxiv_id": "2501.06598v1",
    "title": "ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation",
    "authors": [
      "Xuanle Zhao",
      "Xianzhen Luo",
      "Qi Shi",
      "Chi Chen",
      "Shuo Wang",
      "Wanxiang Che",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in chart understanding tasks. However, interpreting charts with\ntextual descriptions often leads to information loss, as it fails to fully\ncapture the dense information embedded in charts. In contrast, parsing charts\ninto code provides lossless representations that can effectively contain all\ncritical details. Although existing open-source MLLMs have achieved success in\nchart understanding tasks, they still face two major challenges when applied to\nchart-to-code tasks.: (1) Low executability and poor restoration of chart\ndetails in the generated code and (2) Lack of large-scale and diverse training\ndata. To address these challenges, we propose \\textbf{ChartCoder}, the first\ndedicated chart-to-code MLLM, which leverages Code LLMs as the language\nbackbone to enhance the executability of the generated code. Furthermore, we\nintroduce \\textbf{Chart2Code-160k}, the first large-scale and diverse dataset\nfor chart-to-code generation, and propose the \\textbf{Snippet-of-Thought (SoT)}\nmethod, which transforms direct chart-to-code generation data into step-by-step\ngeneration. Experiments demonstrate that ChartCoder, with only 7B parameters,\nsurpasses existing open-source MLLMs on chart-to-code benchmarks, achieving\nsuperior chart restoration and code excitability. Our code will be available at\nhttps://github.com/thunlp/ChartCoder.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06598v1",
    "published_date": "2025-01-11 17:52:22 UTC",
    "updated_date": "2025-01-11 17:52:22 UTC"
  },
  {
    "arxiv_id": "2501.06591v1",
    "title": "Exploring Pose-Based Anomaly Detection for Retail Security: A Real-World Shoplifting Dataset and Benchmark",
    "authors": [
      "Narges Rashvand",
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Shanle Yao",
      "Hamed Tabkhi"
    ],
    "abstract": "Shoplifting poses a significant challenge for retailers, resulting in\nbillions of dollars in annual losses. Traditional security measures often fall\nshort, highlighting the need for intelligent solutions capable of detecting\nshoplifting behaviors in real time. This paper frames shoplifting detection as\nan anomaly detection problem, focusing on the identification of deviations from\ntypical shopping patterns. We introduce PoseLift, a privacy-preserving dataset\nspecifically designed for shoplifting detection, addressing challenges such as\ndata scarcity, privacy concerns, and model biases. PoseLift is built in\ncollaboration with a retail store and contains anonymized human pose data from\nreal-world scenarios. By preserving essential behavioral information while\nanonymizing identities, PoseLift balances privacy and utility. We benchmark\nstate-of-the-art pose-based anomaly detection models on this dataset,\nevaluating performance using a comprehensive set of metrics. Our results\ndemonstrate that pose-based approaches achieve high detection accuracy while\neffectively addressing privacy and bias concerns inherent in traditional\nmethods. As one of the first datasets capturing real-world shoplifting\nbehaviors, PoseLift offers researchers a valuable tool to advance computer\nvision ethically and will be publicly available to foster innovation and\ncollaboration. The dataset is available at\nhttps://github.com/TeCSAR-UNCC/PoseLift.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06591v1",
    "published_date": "2025-01-11 17:19:53 UTC",
    "updated_date": "2025-01-11 17:19:53 UTC"
  },
  {
    "arxiv_id": "2501.06590v1",
    "title": "ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning",
    "authors": [
      "Xiangru Tang",
      "Tianyu Hu",
      "Muyang Ye",
      "Yanjun Shao",
      "Xunjian Yin",
      "Siru Ouyang",
      "Wangchunshu Zhou",
      "Pan Lu",
      "Zhuosheng Zhang",
      "Yilun Zhao",
      "Arman Cohan",
      "Mark Gerstein"
    ],
    "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand\nprecise calculations, where even minor errors can lead to cascading failures.\nFurthermore, large language models (LLMs) encounter difficulties handling\ndomain-specific formulas, executing reasoning steps accurately, and integrating\ncode effectively when tackling chemical reasoning tasks. To address these\nchallenges, we present ChemAgent, a novel framework designed to improve the\nperformance of LLMs through a dynamic, self-updating library. This library is\ndeveloped by decomposing chemical tasks into sub-tasks and compiling these\nsub-tasks into a structured collection that can be referenced for future\nqueries. Then, when presented with a new problem, ChemAgent retrieves and\nrefines pertinent information from the library, which we call memory,\nfacilitating effective task decomposition and the generation of solutions. Our\nmethod designs three types of memory and a library-enhanced reasoning\ncomponent, enabling LLMs to improve over time through experience. Experimental\nresults on four chemical reasoning datasets from SciBench demonstrate that\nChemAgent achieves performance gains of up to 46% (GPT-4), significantly\noutperforming existing methods. Our findings suggest substantial potential for\nfuture applications, including tasks such as drug discovery and materials\nscience. Our code can be found at https://github.com/gersteinlab/chemagent",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06590v1",
    "published_date": "2025-01-11 17:10:30 UTC",
    "updated_date": "2025-01-11 17:10:30 UTC"
  },
  {
    "arxiv_id": "2501.06577v1",
    "title": "Transforming Social Science Research with Transfer Learning: Social Science Survey Data Integration with AI",
    "authors": [
      "Ali Amini"
    ],
    "abstract": "Large-N nationally representative surveys, which have profoundly shaped\nAmerican politics scholarship, represent related but distinct domains -a key\ncondition for transfer learning applications. These surveys are related through\ntheir shared demographic, party identification, and ideological variables, yet\ndiffer in that individual surveys often lack specific policy preference\nquestions that researchers require. Our study introduces a novel application of\ntransfer learning (TL) to address these gaps, marking the first systematic use\nof TL paradigms in the context of survey data. Specifically, models pre-trained\non the Cooperative Election Study (CES) dataset are fine-tuned for use in the\nAmerican National Election Studies (ANES) dataset to predict policy questions\nbased on demographic variables. Even with a naive architecture, our transfer\nlearning approach achieves approximately 92 percentage accuracy in predicting\nmissing variables across surveys, demonstrating the robust potential of this\nmethod. Beyond this specific application, our paper argues that transfer\nlearning is a promising framework for maximizing the utility of existing survey\ndata. We contend that artificial intelligence, particularly transfer learning,\nopens new frontiers in social science methodology by enabling systematic\nknowledge transfer between well-administered surveys that share common\nvariables but differ in their outcomes of interest.",
    "categories": [
      "cs.AI",
      "I.2.7, I.2.6, H.1.2, I.2.10"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 5 figures, Presented and Submitted to SPSA 2025 (Political\n  Methodology Panel)",
    "pdf_url": "http://arxiv.org/pdf/2501.06577v1",
    "published_date": "2025-01-11 16:01:44 UTC",
    "updated_date": "2025-01-11 16:01:44 UTC"
  },
  {
    "arxiv_id": "2501.08466v1",
    "title": "A Short-Term Predict-Then-Cluster Framework for Meal Delivery Services",
    "authors": [
      "Jingyi Cheng",
      "Shadi Sharif Azadeh"
    ],
    "abstract": "Micro-delivery services offer promising solutions for on-demand city\nlogistics, but their success relies on efficient real-time delivery operations\nand fleet management. On-demand meal delivery platforms seek to optimize\nreal-time operations based on anticipatory insights into citywide demand\ndistributions. To address these needs, this study proposes a short-term\npredict-then-cluster framework for on-demand meal delivery services. The\nframework utilizes ensemble-learning methods for point and distributional\nforecasting with multivariate features, including lagged-dependent inputs to\ncapture demand dynamics. We introduce Constrained K-Means Clustering (CKMC) and\nContiguity Constrained Hierarchical Clustering with Iterative Constraint\nEnforcement (CCHC-ICE) to generate dynamic clusters based on predicted demand\nand geographical proximity, tailored to user-defined operational constraints.\nEvaluations of European and Taiwanese case studies demonstrate that the\nproposed methods outperform traditional time series approaches in both accuracy\nand computational efficiency. Clustering results demonstrate that the\nincorporation of distributional predictions effectively addresses demand\nuncertainties, improving the quality of operational insights. Additionally, a\nsimulation study demonstrates the practical value of short-term demand\npredictions for proactive strategies, such as idle fleet rebalancing,\nsignificantly enhancing delivery efficiency. By addressing demand uncertainties\nand operational constraints, our predict-then-cluster framework provides\nactionable insights for optimizing real-time operations. The approach is\nadaptable to other on-demand platform-based city logistics and passenger\nmobility services, promoting sustainable and efficient urban operations.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08466v1",
    "published_date": "2025-01-11 15:59:30 UTC",
    "updated_date": "2025-01-11 15:59:30 UTC"
  },
  {
    "arxiv_id": "2501.06571v1",
    "title": "Active Rule Mining for Multivariate Anomaly Detection in Radio Access Networks",
    "authors": [
      "Ebenezer R. H. P. Isaac",
      "Joseph H. R. Isaac"
    ],
    "abstract": "Multivariate anomaly detection finds its importance in diverse applications.\nDespite the existence of many detectors to solve this problem, one cannot\nsimply define why an obtained anomaly inferred by the detector is anomalous.\nThis reasoning is required for network operators to understand the root cause\nof the anomaly and the remedial action that should be taken to counteract its\noccurrence. Existing solutions in explainable AI may give cues to features that\ninfluence an anomaly, but they do not formulate generalizable rules that can be\nassessed by a domain expert. Furthermore, not all outliers are anomalous in a\nbusiness sense. There is an unfulfilled need for a system that can interpret\nanomalies predicted by a multivariate anomaly detector and map these patterns\nto actionable rules. This paper aims to fulfill this need by proposing a\nsemi-autonomous anomaly rule miner. The proposed method is applicable to both\ndiscrete and time series data and is tailored for radio access network (RAN)\nanomaly detection use cases. The proposed method is demonstrated in this paper\nwith time series RAN data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06571v1",
    "published_date": "2025-01-11 15:42:25 UTC",
    "updated_date": "2025-01-11 15:42:25 UTC"
  },
  {
    "arxiv_id": "2501.06562v1",
    "title": "Discrete Speech Unit Extraction via Independent Component Analysis",
    "authors": [
      "Tomohiko Nakamura",
      "Kwanghee Choi",
      "Keigo Hojo",
      "Yoshiaki Bando",
      "Satoru Fukayama",
      "Shinji Watanabe"
    ],
    "abstract": "Self-supervised speech models (S3Ms) have become a common tool for the speech\nprocessing community, leveraging representations for downstream tasks.\nClustering S3M representations yields discrete speech units (DSUs), which serve\nas compact representations for speech signals. DSUs are typically obtained by\nk-means clustering. Using DSUs often leads to strong performance in various\ntasks, including automatic speech recognition (ASR). However, even with the\nhigh dimensionality and redundancy of S3M representations, preprocessing S3M\nrepresentations for better clustering remains unexplored, even though it can\naffect the quality of DSUs. In this paper, we investigate the potential of\nlinear preprocessing methods for extracting DSUs. We evaluate standardization,\nprincipal component analysis, whitening, and independent component analysis\n(ICA) on DSU-based ASR benchmarks and demonstrate their effectiveness as\npreprocessing for k-means. We also conduct extensive analyses of their\nbehavior, such as orthogonality or interpretability of individual components of\nICA.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2025 SALMA Workshop. Code available at\n  https://github.com/TomohikoNakamura/ica_dsu_espnet",
    "pdf_url": "http://arxiv.org/pdf/2501.06562v1",
    "published_date": "2025-01-11 14:45:03 UTC",
    "updated_date": "2025-01-11 14:45:03 UTC"
  },
  {
    "arxiv_id": "2501.06561v1",
    "title": "Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for Mid-term Human Mobility Prediction",
    "authors": [
      "Zongyuan Huang",
      "Weipeng Wang",
      "Shaoyu Huang",
      "Marta C. Gonzalez",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "abstract": "Predicting individual mobility patterns is crucial across various\napplications. While current methods mainly focus on predicting the next\nlocation for personalized services like recommendations, they often fall short\nin supporting broader applications such as traffic management and epidemic\ncontrol, which require longer period forecasts of human mobility. This study\naddresses mid-term mobility prediction, aiming to capture daily travel patterns\nand forecast trajectories for the upcoming day or week. We propose a novel\nMulti-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\nefficiently extract spatial and temporal information by decoupling daily\ntrajectories into distinct location-duration chains. Our approach employs a\nhierarchical encoder to model multi-scale temporal patterns, including daily\nrecurrence and weekly periodicity, and utilizes a transformer-based decoder to\nglobally attend to predicted information in the location or duration chain.\nAdditionally, we introduce a spatial heterogeneous graph learner to capture\nmulti-scale spatial relationships, enhancing semantic-rich representations.\nExtensive experiments, including statistical physics analysis, are conducted on\nlarge-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\nArea, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\nepidemic modeling in Boston, MSTDP significantly outperforms the\nbest-performing baseline, achieving a remarkable 62.8% reduction in MAE for\ncumulative new cases.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06561v1",
    "published_date": "2025-01-11 14:41:47 UTC",
    "updated_date": "2025-01-11 14:41:47 UTC"
  },
  {
    "arxiv_id": "2501.06557v2",
    "title": "A Survey on Spoken Italian Datasets and Corpora",
    "authors": [
      "Marco Giordano",
      "Claudia Rinaldi"
    ],
    "abstract": "Spoken language datasets are vital for advancing linguistic research, Natural\nLanguage Processing, and speech technology. However, resources dedicated to\nItalian, a linguistically rich and diverse Romance language, remain\nunderexplored compared to major languages like English or Mandarin. This survey\nprovides a comprehensive analysis of 66 spoken Italian datasets, highlighting\ntheir characteristics, methodologies, and applications. The datasets are\ncategorized by speech type, source and context, and demographic and linguistic\nfeatures, with a focus on their utility in fields such as Automatic Speech\nRecognition, emotion detection, and education. Challenges related to dataset\nscarcity, representativeness, and accessibility are discussed alongside\nrecommendations for enhancing dataset creation and utilization. The full\ndataset inventory is publicly accessible via GitHub and archived on Zenodo,\nserving as a valuable resource for researchers and developers. By addressing\ncurrent gaps and proposing future directions, this work aims to support the\nadvancement of Italian speech technologies and linguistic research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "A.1; I.2.7; J.5"
    ],
    "primary_category": "cs.CL",
    "comment": "Published on IEEE Access Journal on Feb 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06557v2",
    "published_date": "2025-01-11 14:33:57 UTC",
    "updated_date": "2025-03-12 13:59:29 UTC"
  },
  {
    "arxiv_id": "2501.06554v1",
    "title": "Hierarchical Reinforcement Learning for Optimal Agent Grouping in Cooperative Systems",
    "authors": [
      "Liyuan Hu"
    ],
    "abstract": "This paper presents a hierarchical reinforcement learning (RL) approach to\naddress the agent grouping or pairing problem in cooperative multi-agent\nsystems. The goal is to simultaneously learn the optimal grouping and agent\npolicy. By employing a hierarchical RL framework, we distinguish between\nhigh-level decisions of grouping and low-level agents' actions. Our approach\nutilizes the CTDE (Centralized Training with Decentralized Execution) paradigm,\nensuring efficient learning and scalable execution. We incorporate\npermutation-invariant neural networks to handle the homogeneity and cooperation\namong agents, enabling effective coordination. The option-critic algorithm is\nadapted to manage the hierarchical decision-making process, allowing for\ndynamic and optimal policy adjustments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06554v1",
    "published_date": "2025-01-11 14:22:10 UTC",
    "updated_date": "2025-01-11 14:22:10 UTC"
  },
  {
    "arxiv_id": "2501.06546v1",
    "title": "Natural Language Supervision for Low-light Image Enhancement",
    "authors": [
      "Jiahui Tang",
      "Kaihua Zhou",
      "Zhijian Luo",
      "Yueen Hou"
    ],
    "abstract": "With the development of deep learning, numerous methods for low-light image\nenhancement (LLIE) have demonstrated remarkable performance. Mainstream LLIE\nmethods typically learn an end-to-end mapping based on pairs of low-light and\nnormal-light images. However, normal-light images under varying illumination\nconditions serve as reference images, making it difficult to define a\n``perfect'' reference image This leads to the challenge of reconciling\nmetric-oriented and visual-friendly results. Recently, many cross-modal studies\nhave found that side information from other related modalities can guide visual\nrepresentation learning. Based on this, we introduce a Natural Language\nSupervision (NLS) strategy, which learns feature maps from text corresponding\nto images, offering a general and flexible interface for describing an image\nunder different illumination.\n  However, image distributions conditioned on textual descriptions are highly\nmultimodal, which makes training difficult. To address this issue, we design a\nTextual Guidance Conditioning Mechanism (TCM) that incorporates the connections\nbetween image regions and sentence words, enhancing the ability to capture\nfine-grained cross-modal cues for images and text. This strategy not only\nutilizes a wider range of supervised sources, but also provides a new paradigm\nfor LLIE based on visual and textual feature alignment. In order to effectively\nidentify and merge features from various levels of image and textual\ninformation, we design an Information Fusion Attention (IFA) module to enhance\ndifferent regions at different levels. We integrate the proposed TCM and IFA\ninto a Natural Language Supervision network for LLIE, named NaLSuper. Finally,\nextensive experiments demonstrate the robustness and superior effectiveness of\nour proposed NaLSuper.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06546v1",
    "published_date": "2025-01-11 13:53:10 UTC",
    "updated_date": "2025-01-11 13:53:10 UTC"
  },
  {
    "arxiv_id": "2501.06532v2",
    "title": "Determination of galaxy photometric redshifts using Conditional Generative Adversarial Networks (CGANs)",
    "authors": [
      "M. Garcia-Fernandez"
    ],
    "abstract": "Accurate and reliable photometric redshift determination is one of the key\naspects for wide-field photometric surveys. Determination of photometric\nredshift for galaxies, has been traditionally solved by use of machine-learning\nand artificial intelligence techniques trained on a calibration sample of\ngalaxies, where both photometry and spectrometry are available. On this paper,\nwe present a new algorithmic approach for determining photometric redshifts of\ngalaxies using Conditional Generative Adversarial Networks (CGANs). The\nproposed implementation is able to determine both point-estimation and\nprobability-density estimations for photometric redshifts. The methodology is\ntested with data from Dark Energy Survey (DES) Y1 data and compared with other\nexisting algorithm such as a Mixture Density Network (MDN). Although results\nobtained show a superiority of MDN, CGAN quality-metrics are close to the MDN\nresults, opening the door to the use of CGAN at photometric redshift\nestimation.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06532v2",
    "published_date": "2025-01-11 12:42:07 UTC",
    "updated_date": "2025-03-13 12:31:03 UTC"
  },
  {
    "arxiv_id": "2501.06527v1",
    "title": "Scaffolding Creativity: Integrating Generative AI Tools and Real-world Experiences in Business Education",
    "authors": [
      "Nicole C. Wang"
    ],
    "abstract": "This case study explores the integration of Generative AI tools and\nreal-world experiences in business education. Through a study of an innovative\nundergraduate course, we investigate how AI-assisted learning, combined with\nexperiential components, impacts students' creative processes and learning\noutcomes. Our findings reveal that this integrated approach accelerates\nknowledge acquisition, enables students to overcome traditional creative\nbarriers, and facilitates a dynamic interplay between AI-generated insights and\nreal-world observations. The study also highlights challenges, including the\nneed for instructors with high AI literacy and the rapid evolution of AI tools\ncreating a moving target for curriculum design. These insights contribute to\nthe growing body of literature on AI in education and provide actionable\nrecommendations for educators preparing students for the complexities of modern\nbusiness environments.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06527v1",
    "published_date": "2025-01-11 12:31:10 UTC",
    "updated_date": "2025-01-11 12:31:10 UTC"
  },
  {
    "arxiv_id": "2501.06514v1",
    "title": "Neural Codec Source Tracing: Toward Comprehensive Attribution in Open-Set Condition",
    "authors": [
      "Yuankun Xie",
      "Xiaopeng Wang",
      "Zhiyong Wang",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Songjun Cao",
      "Long Ma",
      "Chenxing Li",
      "Haonnan Cheng",
      "Long Ye"
    ],
    "abstract": "Current research in audio deepfake detection is gradually transitioning from\nbinary classification to multi-class tasks, referred as audio deepfake source\ntracing task. However, existing studies on source tracing consider only\nclosed-set scenarios and have not considered the challenges posed by open-set\nconditions. In this paper, we define the Neural Codec Source Tracing (NCST)\ntask, which is capable of performing open-set neural codec classification and\ninterpretable ALM detection. Specifically, we constructed the ST-Codecfake\ndataset for the NCST task, which includes bilingual audio samples generated by\n11 state-of-the-art neural codec methods and ALM-based out-ofdistribution (OOD)\ntest samples. Furthermore, we establish a comprehensive source tracing\nbenchmark to assess NCST models in open-set conditions. The experimental\nresults reveal that although the NCST models perform well in in-distribution\n(ID) classification and OOD detection, they lack robustness in classifying\nunseen real audio. The ST-codecfake dataset and code are available.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06514v1",
    "published_date": "2025-01-11 11:15:58 UTC",
    "updated_date": "2025-01-11 11:15:58 UTC"
  },
  {
    "arxiv_id": "2501.06506v1",
    "title": "Resource Allocation under the Latin Square Constraint",
    "authors": [
      "Yasushi Kawase",
      "Bodhayan Roy",
      "Mohammad Azharuddin Sanpui"
    ],
    "abstract": "A Latin square is an $n \\times n$ matrix filled with $n$ distinct symbols,\neach of which appears exactly once in each row and exactly once in each column.\nWe introduce a problem of allocating $n$ indivisible items among $n$ agents\nover $n$ rounds while satisfying the Latin square constraint. This constraint\nensures that each agent receives no more than one item per round and receives\neach item at most once. Each agent has an additive valuation on the item--round\npairs. Real-world applications like scheduling, resource management, and\nexperimental design require the Latin square constraint to satisfy fairness or\nbalancedness in allocation. Our goal is to find a partial or complete\nallocation that maximizes the sum of the agents' valuations (utilitarian social\nwelfare) or the minimum of the agents' valuations (egalitarian social welfare).\nFor the problem of maximizing utilitarian social welfare, we prove NP-hardness\neven when the valuations are binary additive. We then provide $(1-1/e)$ and\n$(1-1/e)/4$-approximation algorithms for partial and complete settings,\nrespectively. Additionally, we present fixed-parameter tractable (FPT)\nalgorithms with respect to the order of Latin square and the optimum value for\nboth partial and complete settings. For the problem of maximizing egalitarian\nsocial welfare, we establish that deciding whether the optimum value is at most\n$1$ or at least $2$ is NP-hard for both the partial and complete settings, even\nwhen the valuations are binary. Furthermore, we demonstrate that checking the\nexistence of a complete allocation that satisfies each of envy-free,\nproportional, equitable, envy-free up to any good, proportional up to any good,\nor equitable up to any good is NP-hard, even when the valuations are identical.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "This paper has been accepted in AAMAS 2025 as an extended abstract",
    "pdf_url": "http://arxiv.org/pdf/2501.06506v1",
    "published_date": "2025-01-11 10:53:48 UTC",
    "updated_date": "2025-01-11 10:53:48 UTC"
  },
  {
    "arxiv_id": "2501.06497v2",
    "title": "PASS: Presentation Automation for Slide Generation and Speech",
    "authors": [
      "Tushar Aggarwal",
      "Aarohi Bhand"
    ],
    "abstract": "In today's fast-paced world, effective presentations have become an essential\ntool for communication in both online and offline meetings. The crafting of a\ncompelling presentation requires significant time and effort, from gathering\nkey insights to designing slides that convey information clearly and concisely.\nHowever, despite the wealth of resources available, people often find\nthemselves manually extracting crucial points, analyzing data, and organizing\ncontent in a way that ensures clarity and impact. Furthermore, a successful\npresentation goes beyond just the slides; it demands rehearsal and the ability\nto weave a captivating narrative to fully engage the audience. Although there\nhas been some exploration of automating document-to-slide generation, existing\nresearch is largely centered on converting research papers. In addition,\nautomation of the delivery of these presentations has yet to be addressed. We\nintroduce PASS, a pipeline used to generate slides from general Word documents,\ngoing beyond just research papers, which also automates the oral delivery of\nthe generated slides. PASS analyzes user documents to create a dynamic,\nengaging presentation with an AI-generated voice. Additionally, we developed an\nLLM-based evaluation metric to assess our pipeline across three critical\ndimensions of presentations: relevance, coherence, and redundancy. The data and\ncodes are available at https://github.com/AggarwalTushar/PASS.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06497v2",
    "published_date": "2025-01-11 10:22:04 UTC",
    "updated_date": "2025-01-15 20:43:44 UTC"
  },
  {
    "arxiv_id": "2502.00018v1",
    "title": "An Expectation-Maximization Algorithm-based Autoregressive Model for the Fuzzy Job Shop Scheduling Problem",
    "authors": [
      "Yijian Wang",
      "Tongxian Guo",
      "Zhaoqiang Liu"
    ],
    "abstract": "The fuzzy job shop scheduling problem (FJSSP) emerges as an innovative\nextension to the job shop scheduling problem (JSSP), incorporating a layer of\nuncertainty that aligns the problem more closely with the complexities of\nreal-world manufacturing environments. This improvement increases the\ncomputational complexity of deriving the solution while improving its\napplicability. In the domain of deterministic scheduling, neural combinatorial\noptimization (NCO) has recently demonstrated remarkable efficacy. However, its\napplication to the realm of fuzzy scheduling has been relatively unexplored.\nThis paper aims to bridge this gap by investigating the feasibility of\nemploying neural networks to assimilate and process fuzzy information for the\nresolution of FJSSP, thereby leveraging the advancements in NCO to enhance\nfuzzy scheduling methodologies. To achieve this, we approach the FJSSP as a\ngenerative task and introduce an expectation-maximization algorithm-based\nautoregressive model (EMARM) to address it. During training, our model\nalternates between generating scheduling schemes from given instances (E-step)\nand adjusting the autoregressive model weights based on these generated schemes\n(M-step). This novel methodology effectively navigates around the substantial\nhurdle of obtaining ground-truth labels, which is a prevalent issue in NCO\nframeworks. In testing, the experimental results demonstrate the superior\ncapability of EMARM in addressing the FJSSP, showcasing its effectiveness and\npotential for practical applications in fuzzy scheduling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00018v1",
    "published_date": "2025-01-11 10:20:16 UTC",
    "updated_date": "2025-01-11 10:20:16 UTC"
  },
  {
    "arxiv_id": "2501.06494v1",
    "title": "TopoFormer: Integrating Transformers and ConvLSTMs for Coastal Topography Prediction",
    "authors": [
      "Santosh Munian",
      "Oktay Karaku≈ü",
      "William Russell",
      "Gwyn Nelson"
    ],
    "abstract": "This paper presents \\textit{TopoFormer}, a novel hybrid deep learning\narchitecture that integrates transformer-based encoders with convolutional long\nshort-term memory (ConvLSTM) layers for the precise prediction of topographic\nbeach profiles referenced to elevation datums, with a particular focus on Mean\nLow Water Springs (MLWS) and Mean Low Water Neaps (MLWN). Accurate topographic\nestimation down to MLWS is critical for coastal management, navigation safety,\nand environmental monitoring. Leveraging a comprehensive dataset from the Wales\nCoastal Monitoring Centre (WCMC), consisting of over 2000 surveys across 36\ncoastal survey units, TopoFormer addresses key challenges in topographic\nprediction, including temporal variability and data gaps in survey\nmeasurements. The architecture uniquely combines multi-head attention\nmechanisms and ConvLSTM layers to capture both long-range dependencies and\nlocalized temporal patterns inherent in beach profiles data. TopoFormer's\npredictive performance was rigorously evaluated against state-of-the-art\nmodels, including DenseNet, 1D/2D CNNs, and LSTMs. While all models\ndemonstrated strong performance, \\textit{TopoFormer} achieved the lowest mean\nabsolute error (MAE), as low as 2 cm, and provided superior accuracy in both\nin-distribution (ID) and out-of-distribution (OOD) evaluations.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "11 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2501.06494v1",
    "published_date": "2025-01-11 09:46:02 UTC",
    "updated_date": "2025-01-11 09:46:02 UTC"
  },
  {
    "arxiv_id": "2501.06491v1",
    "title": "Improving Requirements Classification with SMOTE-Tomek Preprocessing",
    "authors": [
      "Barak Or"
    ],
    "abstract": "This study emphasizes the domain of requirements engineering by applying the\nSMOTE-Tomek preprocessing technique, combined with stratified K-fold\ncross-validation, to address class imbalance in the PROMISE dataset. This\ndataset comprises 969 categorized requirements, classified into functional and\nnon-functional types. The proposed approach enhances the representation of\nminority classes while maintaining the integrity of validation folds, leading\nto a notable improvement in classification accuracy. Logistic regression\nachieved 76.16\\%, significantly surpassing the baseline of 58.31\\%. These\nresults highlight the applicability and efficiency of machine learning models\nas scalable and interpretable solutions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06491v1",
    "published_date": "2025-01-11 09:36:14 UTC",
    "updated_date": "2025-01-11 09:36:14 UTC"
  },
  {
    "arxiv_id": "2501.06488v1",
    "title": "NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References",
    "authors": [
      "Qiang Qu",
      "Yiran Shen",
      "Xiaoming Chen",
      "Yuk Ying Chung",
      "Weidong Cai",
      "Tongliang Liu"
    ],
    "abstract": "Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting,\neffectively creates photorealistic scenes from sparse viewpoints, typically\nevaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However,\nthese full-reference methods, which compare synthesized views to reference\nviews, may not fully capture the perceptual quality of neurally synthesized\nscenes (NSS), particularly due to the limited availability of dense reference\nviews. Furthermore, the challenges in acquiring human perceptual labels hinder\nthe creation of extensive labeled datasets, risking model overfitting and\nreduced generalizability. To address these issues, we propose NVS-SQA, a NSS\nquality assessment method to learn no-reference quality representations through\nself-supervision without reliance on human labels. Traditional self-supervised\nlearning predominantly relies on the \"same instance, similar representation\"\nassumption and extensive datasets. However, given that these conditions do not\napply in NSS quality assessment, we employ heuristic cues and quality scores as\nlearning objectives, along with a specialized contrastive pair preparation\nprocess to improve the effectiveness and efficiency of learning. The results\nshow that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e.,\non average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second\nbest) and even exceeds 16 full-reference methods across all evaluation metrics\n(i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06488v1",
    "published_date": "2025-01-11 09:12:43 UTC",
    "updated_date": "2025-01-11 09:12:43 UTC"
  },
  {
    "arxiv_id": "2501.06485v1",
    "title": "A Diffusive Data Augmentation Framework for Reconstruction of Complex Network Evolutionary History",
    "authors": [
      "En Xu",
      "Can Rong",
      "Jingtao Ding",
      "Yong Li"
    ],
    "abstract": "The evolutionary processes of complex systems contain critical information\nregarding their functional characteristics. The generation time of edges\nprovides insights into the historical evolution of various networked complex\nsystems, such as protein-protein interaction networks, ecosystems, and social\nnetworks. Recovering these evolutionary processes holds significant scientific\nvalue, including aiding in the interpretation of the evolution of\nprotein-protein interaction networks. However, existing methods are capable of\npredicting the generation times of remaining edges given a partial temporal\nnetwork but often perform poorly in cross-network prediction tasks. These\nmethods frequently fail in edge generation time recovery tasks for static\nnetworks that lack timestamps. In this work, we adopt a comparative\nparadigm-based framework that fuses multiple networks for training, enabling\ncross-network learning of the relationship between network structure and edge\ngeneration times. Compared to separate training, this approach yields an\naverage accuracy improvement of 16.98%. Furthermore, given the difficulty in\ncollecting temporal networks, we propose a novel diffusion-model-based\ngeneration method to produce a large number of temporal networks. By combining\nreal temporal networks with generated ones for training, we achieve an\nadditional average accuracy improvement of 5.46% through joint training.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06485v1",
    "published_date": "2025-01-11 08:39:33 UTC",
    "updated_date": "2025-01-11 08:39:33 UTC"
  },
  {
    "arxiv_id": "2501.06472v1",
    "title": "YO-CSA-T: A Real-time Badminton Tracking System Utilizing YOLO Based on Contextual and Spatial Attention",
    "authors": [
      "Yuan Lai",
      "Zhiwei Shi",
      "Chengxi Zhu"
    ],
    "abstract": "The 3D trajectory of a shuttlecock required for a badminton rally robot for\nhuman-robot competition demands real-time performance with high accuracy.\nHowever, the fast flight speed of the shuttlecock, along with various visual\neffects, and its tendency to blend with environmental elements, such as court\nlines and lighting, present challenges for rapid and accurate 2D detection. In\nthis paper, we first propose the YO-CSA detection network, which optimizes and\nreconfigures the YOLOv8s model's backbone, neck, and head by incorporating\ncontextual and spatial attention mechanisms to enhance model's ability in\nextracting and integrating both global and local features. Next, we integrate\nthree major subtasks, detection, prediction, and compensation, into a real-time\n3D shuttlecock trajectory detection system. Specifically, our system maps the\n2D coordinate sequence extracted by YO-CSA into 3D space using stereo vision,\nthen predicts the future 3D coordinates based on historical information, and\nre-projects them onto the left and right views to update the position\nconstraints for 2D detection. Additionally, our system includes a compensation\nmodule to fill in missing intermediate frames, ensuring a more complete\ntrajectory. We conduct extensive experiments on our own dataset to evaluate\nboth YO-CSA's performance and system effectiveness. Experimental results show\nthat YO-CSA achieves a high accuracy of 90.43% mAP@0.75, surpassing both\nYOLOv8s and YOLO11s. Our system performs excellently, maintaining a speed of\nover 130 fps across 12 test sequences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages,14 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06472v1",
    "published_date": "2025-01-11 08:00:25 UTC",
    "updated_date": "2025-01-11 08:00:25 UTC"
  },
  {
    "arxiv_id": "2501.06471v1",
    "title": "The Internet of Large Language Models: An Orchestration Framework for LLM Training and Knowledge Exchange Toward Artificial General Intelligence",
    "authors": [
      "Wilson Wei",
      "Nicholas Chen",
      "Yuxuan Li"
    ],
    "abstract": "This paper explores the multi-dimensional challenges faced during the\ndevelopment of Large Language Models (LLMs), including the massive scale of\nmodel parameters and file sizes, the complexity of development environment\nconfiguration, the singularity of model functionality, and the high costs of\ncomputational resources. To address these challenges, this paper proposes three\ncore technical solutions: LLM sharing protocol, LLM universal environment\nframework, and Agent optimal path module. To solve the computational resource\nconstraints in the early stages of research, we further innovatively propose a\njoint mining mechanism, achieving bilateral value sharing between computing\npower providers and model designers, including breakthrough rewards for optimal\nmodel paths and long-term profit distribution, thereby providing researchers\nwith cost-optimized computational resource support and promoting the continuous\ndevelopment of LLM research and applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06471v1",
    "published_date": "2025-01-11 08:00:24 UTC",
    "updated_date": "2025-01-11 08:00:24 UTC"
  },
  {
    "arxiv_id": "2501.06468v1",
    "title": "First Token Probability Guided RAG for Telecom Question Answering",
    "authors": [
      "Tingwei Chen",
      "Jiayi Chen",
      "Zijian Zhao",
      "Haolong Chen",
      "Liang Zhang",
      "Guangxu Zhu"
    ],
    "abstract": "Large Language Models (LLMs) have garnered significant attention for their\nimpressive general-purpose capabilities. For applications requiring intricate\ndomain knowledge, Retrieval-Augmented Generation (RAG) has shown a distinct\nadvantage in incorporating domain-specific information into LLMs. However,\nexisting RAG research has not fully addressed the challenges of Multiple Choice\nQuestion Answering (MCQA) in telecommunications, particularly in terms of\nretrieval quality and mitigating hallucinations. To tackle these challenges, we\npropose a novel first token probability guided RAG framework. This framework\nleverages confidence scores to optimize key hyperparameters, such as chunk\nnumber and chunk window size, while dynamically adjusting the context. Our\nmethod starts by retrieving the most relevant chunks and generates a single\ntoken as the potential answer. The probabilities of all options are then\nnormalized to serve as confidence scores, which guide the dynamic adjustment of\nthe context. By iteratively optimizing the hyperparameters based on these\nconfidence scores, we can continuously improve RAG performance. We conducted\nexperiments to validate the effectiveness of our framework, demonstrating its\npotential to enhance accuracy in domain-specific MCQA tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06468v1",
    "published_date": "2025-01-11 07:47:31 UTC",
    "updated_date": "2025-01-11 07:47:31 UTC"
  },
  {
    "arxiv_id": "2501.06465v3",
    "title": "MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare",
    "authors": [
      "Ye Chen",
      "Dongdong Huang",
      "Haoyun Xu",
      "Cong Fu",
      "Lin Sheng",
      "Qingli Zhou",
      "Yuqiang Shen",
      "Kai Wang"
    ],
    "abstract": "We introduce the world's first clinical terminology for the Chinese\nhealthcare community, namely MedCT, accompanied by a clinical foundation model\nMedBERT and an entity linking model MedLink. The MedCT system enables\nstandardized and programmable representation of Chinese clinical data,\nsuccessively stimulating the development of new medicines, treatment pathways,\nand better patient outcomes for the populous Chinese community. Moreover, the\nMedCT knowledge graph provides a principled mechanism to minimize the\nhallucination problem of large language models (LLMs), therefore achieving\nsignificant levels of accuracy and safety in LLM-based clinical applications.\nBy leveraging the LLMs' emergent capabilities of generativeness and\nexpressiveness, we were able to rapidly built a production-quality terminology\nsystem and deployed to real-world clinical field within three months, while\nclassical terminologies like SNOMED CT have gone through more than twenty years\ndevelopment. Our experiments show that the MedCT system achieves\nstate-of-the-art (SOTA) performance in semantic matching and entity linking\ntasks, not only for Chinese but also for English. We also conducted a\nlongitudinal field experiment by applying MedCT and LLMs in a representative\nspectrum of clinical tasks, including electronic health record (EHR)\nauto-generation and medical document search for diagnostic decision making. Our\nstudy shows a multitude of values of MedCT for clinical workflows and patient\noutcomes, especially in the new genre of clinical LLM applications. We present\nour approach in sufficient engineering detail, such that implementing a\nclinical terminology for other non-English societies should be readily\nreproducible. We openly release our terminology, models and algorithms, along\nwith real-world clinical datasets for the development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted into ICCS 2025 and published in Springer's LNCS Series",
    "pdf_url": "http://arxiv.org/pdf/2501.06465v3",
    "published_date": "2025-01-11 07:35:51 UTC",
    "updated_date": "2025-04-10 07:29:10 UTC"
  },
  {
    "arxiv_id": "2501.06461v1",
    "title": "Assessing instructor-AI cooperation for grading essay-type questions in an introductory sociology course",
    "authors": [
      "Francisco Olivos",
      "Tobias Kamelski",
      "Sebasti√°n Ascui-Gac"
    ],
    "abstract": "This study explores the use of artificial intelligence (AI) as a\ncomplementary tool for grading essay-type questions in higher education,\nfocusing on its consistency with human grading and potential to reduce biases.\nUsing 70 handwritten exams from an introductory sociology course, we evaluated\ngenerative pre-trained transformers (GPT) models' performance in transcribing\nand scoring students' responses. GPT models were tested under various settings\nfor both transcription and grading tasks. Results show high similarity between\nhuman and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in\naccuracy. For grading, GPT demonstrated strong correlations with the human\ngrader scores, especially when template answers were provided. However,\ndiscrepancies remained, highlighting GPT's role as a \"second grader\" to flag\ninconsistencies for assessment reviewing rather than fully replace human\nevaluation. This study contributes to the growing literature on AI in\neducation, demonstrating its potential to enhance fairness and efficiency in\ngrading essay-type questions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.06461v1",
    "published_date": "2025-01-11 07:18:12 UTC",
    "updated_date": "2025-01-11 07:18:12 UTC"
  },
  {
    "arxiv_id": "2501.06444v1",
    "title": "On the Computational Capability of Graph Neural Networks: A Circuit Complexity Bound Perspective",
    "authors": [
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Wei Wang",
      "Jiahao Zhang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become the standard approach for learning\nand reasoning over relational data, leveraging the message-passing mechanism\nthat iteratively propagates node embeddings through graph structures. While\nGNNs have achieved significant empirical success, their theoretical limitations\nremain an active area of research. Existing studies primarily focus on\ncharacterizing GNN expressiveness through Weisfeiler-Lehman (WL) graph\nisomorphism tests. In this paper, we take a fundamentally different approach by\nexploring the computational limitations of GNNs through the lens of circuit\ncomplexity. Specifically, we analyze the circuit complexity of common GNN\narchitectures and prove that under constraints of constant-depth layers, linear\nor sublinear embedding sizes, and polynomial precision, GNNs cannot solve key\nproblems such as graph connectivity and graph isomorphism unless $\\mathsf{TC}^0\n= \\mathsf{NC}^1$. These results reveal the intrinsic expressivity limitations\nof GNNs behind their empirical success and introduce a novel framework for\nanalyzing GNN expressiveness that can be extended to a broader range of GNN\nmodels and graph decision problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06444v1",
    "published_date": "2025-01-11 05:54:10 UTC",
    "updated_date": "2025-01-11 05:54:10 UTC"
  },
  {
    "arxiv_id": "2501.06442v1",
    "title": "ARES: Auxiliary Range Expansion for Outlier Synthesis",
    "authors": [
      "Eui-Soo Jung",
      "Hae-Hun Seo",
      "Hyun-Woo Jung",
      "Je-Geon Oh",
      "Yoon-Yeong Kim"
    ],
    "abstract": "Recent successes of artificial intelligence and deep learning often depend on\nthe well-collected training dataset which is assumed to have an identical\ndistribution with the test dataset. However, this assumption, which is called\nclosed-set learning, is hard to meet in realistic scenarios for deploying deep\nlearning models. As one of the solutions to mitigate this assumption, research\non out-of-distribution (OOD) detection has been actively explored in various\ndomains. In OOD detection, we assume that we are given the data of a new class\nthat was not seen in the training phase, i.e., outlier, at the evaluation\nphase. The ultimate goal of OOD detection is to detect and classify such unseen\noutlier data as a novel \"unknown\" class. Among various research branches for\nOOD detection, generating a virtual outlier during the training phase has been\nproposed. However, conventional generation-based methodologies utilize\nin-distribution training dataset to imitate outlier instances, which limits the\nquality of the synthesized virtual outlier instance itself. In this paper, we\npropose a novel methodology for OOD detection named Auxiliary Range Expansion\nfor Outlier Synthesis, or ARES. ARES models the region for generating\nout-of-distribution instances by escaping from the given in-distribution\nregion; instead of remaining near the boundary of in-distribution region.\nVarious stages consists ARES to ultimately generate valuable OOD-like virtual\ninstances. The energy score-based discriminator is then trained to effectively\nseparate in-distribution data and outlier data. Quantitative experiments on\nbroad settings show the improvement of performance by our method, and\nqualitative results provide logical explanations of the mechanism behind it.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06442v1",
    "published_date": "2025-01-11 05:44:33 UTC",
    "updated_date": "2025-01-11 05:44:33 UTC"
  },
  {
    "arxiv_id": "2501.06434v1",
    "title": "Synthetic Feature Augmentation Improves Generalization Performance of Language Models",
    "authors": [
      "Ashok Choudhary",
      "Cornelius Thiels",
      "Hojjat Salehinejad"
    ],
    "abstract": "Training and fine-tuning deep learning models, especially large language\nmodels (LLMs), on limited and imbalanced datasets poses substantial challenges.\nThese issues often result in poor generalization, where models overfit to\ndominant classes and underperform on minority classes, leading to biased\npredictions and reduced robustness in real-world applications. To overcome\nthese challenges, we propose augmenting features in the embedding space by\ngenerating synthetic samples using a range of techniques. By upsampling\nunderrepresented classes, this method improves model performance and alleviates\ndata imbalance. We validate the effectiveness of this approach across multiple\nopen-source text classification benchmarks, demonstrating its potential to\nenhance model robustness and generalization in imbalanced data scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for presentation at IEEE SSCI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06434v1",
    "published_date": "2025-01-11 04:31:18 UTC",
    "updated_date": "2025-01-11 04:31:18 UTC"
  },
  {
    "arxiv_id": "2501.06432v1",
    "title": "Deep Learning on Hester Davis Scores for Inpatient Fall Prediction",
    "authors": [
      "Hojjat Salehinejad",
      "Ricky Rojas",
      "Kingsley Iheasirim",
      "Mohammed Yousufuddin",
      "Bijan Borah"
    ],
    "abstract": "Fall risk prediction among hospitalized patients is a critical aspect of\npatient safety in clinical settings, and accurate models can help prevent\nadverse events. The Hester Davis Score (HDS) is commonly used to assess fall\nrisk, with current clinical practice relying on a threshold-based approach. In\nthis method, a patient is classified as high-risk when their HDS exceeds a\npredefined threshold. However, this approach may fail to capture dynamic\npatterns in fall risk over time. In this study, we model the threshold-based\napproach and propose two machine learning approaches for enhanced fall\nprediction: One-step ahead fall prediction and sequence-to-point fall\nprediction. The one-step ahead model uses the HDS at the current timestamp to\npredict the risk at the next timestamp, while the sequence-to-point model\nleverages all preceding HDS values to predict fall risk using deep learning. We\ncompare these approaches to assess their accuracy in fall risk prediction,\ndemonstrating that deep learning can outperform the traditional threshold-based\nmethod by capturing temporal patterns and improving prediction reliability.\nThese findings highlight the potential for data-driven approaches to enhance\npatient safety through more reliable fall prevention strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for presentation at IEEE SSCI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06432v1",
    "published_date": "2025-01-11 04:20:13 UTC",
    "updated_date": "2025-01-11 04:20:13 UTC"
  },
  {
    "arxiv_id": "2501.06431v1",
    "title": "Aug3D: Augmenting large scale outdoor datasets for Generalizable Novel View Synthesis",
    "authors": [
      "Aditya Rauniyar",
      "Omar Alama",
      "Silong Yong",
      "Katia Sycara",
      "Sebastian Scherer"
    ],
    "abstract": "Recent photorealistic Novel View Synthesis (NVS) advances have increasingly\ngained attention. However, these approaches remain constrained to small indoor\nscenes. While optimization-based NVS models have attempted to address this,\ngeneralizable feed-forward methods, offering significant advantages, remain\nunderexplored. In this work, we train PixelNeRF, a feed-forward NVS model, on\nthe large-scale UrbanScene3D dataset. We propose four training strategies to\ncluster and train on this dataset, highlighting that performance is hindered by\nlimited view overlap. To address this, we introduce Aug3D, an augmentation\ntechnique that leverages reconstructed scenes using traditional\nStructure-from-Motion (SfM). Aug3D generates well-conditioned novel views\nthrough grid and semantic sampling to enhance feed-forward NVS model learning.\nOur experiments reveal that reducing the number of views per cluster from 20 to\n10 improves PSNR by 10%, but the performance remains suboptimal. Aug3D further\naddresses this by combining the newly generated novel views with the original\ndataset, demonstrating its effectiveness in improving the model's ability to\npredict novel views.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "IROS 2024 Workshop, 9 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06431v1",
    "published_date": "2025-01-11 04:13:26 UTC",
    "updated_date": "2025-01-11 04:13:26 UTC"
  },
  {
    "arxiv_id": "2501.06425v3",
    "title": "Tensor Product Attention Is All You Need",
    "authors": [
      "Yifan Zhang",
      "Yifeng Liu",
      "Huizhuo Yuan",
      "Zhen Qin",
      "Yang Yuan",
      "Quanquan Gu",
      "Andrew Chi-Chih Yao"
    ],
    "abstract": "Scaling language models to handle longer input sequences typically\nnecessitates large key-value (KV) caches, resulting in substantial memory\noverhead during inference. In this paper, we propose Tensor Product Attention\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\nqueries, keys, and values compactly, significantly shrinking KV cache size at\ninference time. By factorizing these representations into contextual low-rank\ncomponents (contextual factorization) and seamlessly integrating with RoPE, TPA\nachieves improved model quality alongside memory efficiency. Based on TPA, we\nintroduce the Tensor ProducT ATTenTion Transformer (T6), a new model\narchitecture for sequence modeling. Through extensive empirical evaluation of\nlanguage modeling tasks, we demonstrate that T6 exceeds the performance of\nstandard Transformer baselines including MHA, MQA, GQA, and MLA across various\nmetrics, including perplexity and a range of renowned evaluation benchmarks.\nNotably, TPA's memory efficiency enables the processing of significantly longer\nsequences under fixed resource constraints, addressing a critical scalability\nchallenge in modern language models. The code is available at\nhttps://github.com/tensorgi/T6.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06425v3",
    "published_date": "2025-01-11 03:37:10 UTC",
    "updated_date": "2025-04-09 20:51:08 UTC"
  },
  {
    "arxiv_id": "2501.06423v1",
    "title": "AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs",
    "authors": [
      "Xiaoxin Yin"
    ],
    "abstract": "Program synthesis has traditionally relied on human-provided specifications,\nexamples, or prior knowledge to generate functional algorithms. Existing\nmethods either emulate human-written algorithms or solve specific tasks without\ngenerating reusable programmatic logic, limiting their ability to create novel\nalgorithms. We introduce AlgoPilot, a groundbreaking approach for fully\nautomated program synthesis without human-written programs or trajectories.\nAlgoPilot leverages reinforcement learning (RL) guided by a Trajectory Language\nModel (TLM) to synthesize algorithms from scratch. The TLM, trained on\ntrajectories generated by random Python functions, serves as a soft constraint\nduring the RL process, aligning generated sequences with patterns likely to\nrepresent valid algorithms. Using sorting as a test case, AlgoPilot\ndemonstrates its ability to generate trajectories that are interpretable as\nclassical algorithms, such as Bubble Sort, while operating without prior\nalgorithmic knowledge. This work establishes a new paradigm for algorithm\ndiscovery and lays the groundwork for future advancements in autonomous program\nsynthesis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06423v1",
    "published_date": "2025-01-11 03:29:14 UTC",
    "updated_date": "2025-01-11 03:29:14 UTC"
  },
  {
    "arxiv_id": "2501.06417v1",
    "title": "DiscQuant: A Quantization Method for Neural Networks Inspired by Discrepancy Theory",
    "authors": [
      "Jerry Chee",
      "Arturs Backurs",
      "Rainie Heck",
      "Li Zhang",
      "Janardhan Kulkarni",
      "Thomas Rothvoss",
      "Sivakanth Gopi"
    ],
    "abstract": "Quantizing the weights of a neural network has two steps: (1) Finding a good\nlow bit-complexity representation for weights (which we call the quantization\ngrid) and (2) Rounding the original weights to values in the quantization grid.\nIn this paper, we study the problem of rounding optimally given any\nquantization grid. The simplest and most commonly used way to round is\nRound-to-Nearest (RTN). By rounding in a data-dependent way instead, one can\nimprove the quality of the quantized model significantly.\n  We study the rounding problem from the lens of \\emph{discrepancy theory},\nwhich studies how well we can round a continuous solution to a discrete\nsolution without affecting solution quality too much. We prove that given\n$m=\\mathrm{poly}(1/\\epsilon)$ samples from the data distribution, we can round\nall but $O(m)$ model weights such that the expected approximation error of the\nquantized model on the true data distribution is $\\le \\epsilon$ as long as the\nspace of gradients of the original model is approximately low rank (which we\nempirically validate).\n  Our proof, which is algorithmic, inspired a simple and practical rounding\nalgorithm called \\emph{DiscQuant}. In our experiments, we demonstrate that\nDiscQuant significantly improves over the prior state-of-the-art rounding\nmethod called GPTQ and the baseline RTN over a range of benchmarks on\nPhi3mini-3.8B and Llama3.1-8B. For example, rounding Phi3mini-3.8B to a fixed\nquantization grid with 3.25 bits per parameter using DiscQuant gets 64\\%\naccuracy on the GSM8k dataset, whereas GPTQ achieves 54\\% and RTN achieves 31\\%\n(the original model achieves 84\\%). We make our code available at\nhttps://github.com/jerry-chee/DiscQuant.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06417v1",
    "published_date": "2025-01-11 03:14:43 UTC",
    "updated_date": "2025-01-11 03:14:43 UTC"
  },
  {
    "arxiv_id": "2501.06416v2",
    "title": "Influencing Humans to Conform to Preference Models for RLHF",
    "authors": [
      "Stephane Hatgis-Kessell",
      "W. Bradley Knox",
      "Serena Booth",
      "Scott Niekum",
      "Peter Stone"
    ],
    "abstract": "Designing a reinforcement learning from human feedback (RLHF) algorithm to\napproximate a human's unobservable reward function requires assuming,\nimplicitly or explicitly, a model of human preferences. A preference model that\npoorly describes how humans generate preferences risks learning a poor\napproximation of the human's reward function. In this paper, we conduct three\nhuman studies to asses whether one can influence the expression of real human\npreferences to more closely conform to a desired preference model. Importantly,\nour approach does not seek to alter the human's unobserved reward function.\nRather, we change how humans use this reward function to generate preferences,\nsuch that they better match whatever preference model is assumed by a\nparticular RLHF algorithm. We introduce three interventions: showing humans the\nquantities that underlie a preference model, which is normally unobservable\ninformation derived from the reward function; training people to follow a\nspecific preference model; and modifying the preference elicitation question.\nAll intervention types show significant effects, providing practical tools to\nimprove preference data quality and the resultant alignment of the learned\nreward functions. Overall we establish a novel research direction in model\nalignment: designing interfaces and training interventions to increase human\nconformance with the modeling assumptions of the algorithm that will learn from\ntheir input.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06416v2",
    "published_date": "2025-01-11 03:12:53 UTC",
    "updated_date": "2025-02-08 05:44:45 UTC"
  },
  {
    "arxiv_id": "2501.14794v1",
    "title": "HeteroLLM: Accelerating Large Language Model Inference on Mobile SoCs platform with Heterogeneous AI Accelerators",
    "authors": [
      "Le Chen",
      "Dahu Feng",
      "Erhu Feng",
      "Rong Zhao",
      "Yingrui Wang",
      "Yubin Xia",
      "Haibo Chen",
      "Pinjie Xu"
    ],
    "abstract": "With the rapid advancement of artificial intelligence technologies such as\nChatGPT, AI agents and video generation,contemporary mobile systems have begun\nintegrating these AI capabilities on local devices to enhance privacy and\nreduce response latency. To meet the computational demands of AI tasks, current\nmobile SoCs are equipped with diverse AI accelerators, including GPUs and\nNeural Processing Units (NPUs). However, there has not been a comprehensive\ncharacterization of these heterogeneous processors, and existing designs\ntypically only leverage a single AI accelerator for LLM inference, leading to\nsuboptimal use of computational resources and memory bandwidth. In this paper,\nwe first summarize key performance characteristics of mobile SoC, including\nheterogeneous processors, unified memory, synchronization, etc. Drawing on\nthese observations, we propose different tensor partition strategies to fulfill\nthe distinct requirements of the prefill and decoding phases. We further design\na fast synchronization mechanism that leverages the unified memory address\nprovided by mobile SoCs. By employing these techniques, we present HeteroLLM,\nthe fastest LLM inference engine in mobile devices which supports both\nlayer-level and tensor-level heterogeneous execution. Evaluation results show\nthat HeteroLLM achieves 9.99 and 4.36 performance improvement over other\nmobile-side LLM inference engines: MLC and MNN.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14794v1",
    "published_date": "2025-01-11 02:42:02 UTC",
    "updated_date": "2025-01-11 02:42:02 UTC"
  },
  {
    "arxiv_id": "2501.06405v1",
    "title": "FocusDD: Real-World Scene Infusion for Robust Dataset Distillation",
    "authors": [
      "Youbing Hu",
      "Yun Cheng",
      "Olga Saukh",
      "Firat Ozdemir",
      "Anqi Lu",
      "Zhiqiang Cao",
      "Zhijun Li"
    ],
    "abstract": "Dataset distillation has emerged as a strategy to compress real-world\ndatasets for efficient training. However, it struggles with large-scale and\nhigh-resolution datasets, limiting its practicality. This paper introduces a\nnovel resolution-independent dataset distillation method Focus ed Dataset\nDistillation (FocusDD), which achieves diversity and realism in distilled data\nby identifying key information patches, thereby ensuring the generalization\ncapability of the distilled dataset across different network architectures.\nSpecifically, FocusDD leverages a pre-trained Vision Transformer (ViT) to\nextract key image patches, which are then synthesized into a single distilled\nimage. These distilled images, which capture multiple targets, are suitable not\nonly for classification tasks but also for dense tasks such as object\ndetection. To further improve the generalization of the distilled dataset, each\nsynthesized image is augmented with a downsampled view of the original image.\nExperimental results on the ImageNet-1K dataset demonstrate that, with 100\nimages per class (IPC), ResNet50 and MobileNet-v2 achieve validation accuracies\nof 71.0% and 62.6%, respectively, outperforming state-of-the-art methods by\n2.8% and 4.7%. Notably, FocusDD is the first method to use distilled datasets\nfor object detection tasks. On the COCO2017 dataset, with an IPC of 50,\nYOLOv11n and YOLOv11s achieve 24.4% and 32.1% mAP, respectively, further\nvalidating the effectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06405v1",
    "published_date": "2025-01-11 02:06:29 UTC",
    "updated_date": "2025-01-11 02:06:29 UTC"
  },
  {
    "arxiv_id": "2501.06404v1",
    "title": "A Hybrid Framework for Reinsurance Optimization: Integrating Generative Models and Reinforcement Learning",
    "authors": [
      "Stella C. Dong",
      "James R. Finlay"
    ],
    "abstract": "Reinsurance optimization is critical for insurers to manage risk exposure,\nensure financial stability, and maintain solvency. Traditional approaches often\nstruggle with dynamic claim distributions, high-dimensional constraints, and\nevolving market conditions. This paper introduces a novel hybrid framework that\nintegrates {Generative Models}, specifically Variational Autoencoders (VAEs),\nwith {Reinforcement Learning (RL)} using Proximal Policy Optimization (PPO).\nThe framework enables dynamic and scalable optimization of reinsurance\nstrategies by combining the generative modeling of complex claim distributions\nwith the adaptive decision-making capabilities of reinforcement learning.\n  The VAE component generates synthetic claims, including rare and catastrophic\nevents, addressing data scarcity and variability, while the PPO algorithm\ndynamically adjusts reinsurance parameters to maximize surplus and minimize\nruin probability. The framework's performance is validated through extensive\nexperiments, including out-of-sample testing, stress-testing scenarios (e.g.,\npandemic impacts, catastrophic events), and scalability analysis across\nportfolio sizes. Results demonstrate its superior adaptability, scalability,\nand robustness compared to traditional optimization techniques, achieving\nhigher final surpluses and computational efficiency.\n  Key contributions include the development of a hybrid approach for\nhigh-dimensional optimization, dynamic reinsurance parameterization, and\nvalidation against stochastic claim distributions. The proposed framework\noffers a transformative solution for modern reinsurance challenges, with\npotential applications in multi-line insurance operations, catastrophe\nmodeling, and risk-sharing strategy design.",
    "categories": [
      "econ.EM",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "econ.EM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06404v1",
    "published_date": "2025-01-11 02:02:32 UTC",
    "updated_date": "2025-01-11 02:02:32 UTC"
  },
  {
    "arxiv_id": "2501.06399v1",
    "title": "Has an AI model been trained on your images?",
    "authors": [
      "Matyas Bohacek",
      "Hany Farid"
    ],
    "abstract": "From a simple text prompt, generative-AI image models can create stunningly\nrealistic and creative images bounded, it seems, by only our imagination. These\nmodels have achieved this remarkable feat thanks, in part, to the ingestion of\nbillions of images collected from nearly every corner of the internet. Many\ncreators have understandably expressed concern over how their intellectual\nproperty has been ingested without their permission or a mechanism to opt out\nof training. As a result, questions of fair use and copyright infringement have\nquickly emerged. We describe a method that allows us to determine if a model\nwas trained on a specific image or set of images. This method is\ncomputationally efficient and assumes no explicit knowledge of the model\narchitecture or weights (so-called black-box membership inference). We\nanticipate that this method will be crucial for auditing existing models and,\nlooking ahead, ensuring the fairer development and deployment of generative AI\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06399v1",
    "published_date": "2025-01-11 01:12:23 UTC",
    "updated_date": "2025-01-11 01:12:23 UTC"
  },
  {
    "arxiv_id": "2501.06394v1",
    "title": "Unispeaker: A Unified Approach for Multimodality-driven Speaker Generation",
    "authors": [
      "Zhengyan Sheng",
      "Zhihao Du",
      "Heng Lu",
      "Shiliang Zhang",
      "Zhen-Hua Ling"
    ],
    "abstract": "Recent advancements in personalized speech generation have brought synthetic\nspeech increasingly close to the realism of target speakers' recordings, yet\nmultimodal speaker generation remains on the rise. This paper introduces\nUniSpeaker, a unified approach for multimodality-driven speaker generation.\nSpecifically, we propose a unified voice aggregator based on KV-Former,\napplying soft contrastive loss to map diverse voice description modalities into\na shared voice space, ensuring that the generated voice aligns more closely\nwith the input descriptions. To evaluate multimodality-driven voice control, we\nbuild the first multimodality-based voice control (MVC) benchmark, focusing on\nvoice suitability, voice diversity, and speech quality. UniSpeaker is evaluated\nacross five tasks using the MVC benchmark, and the experimental results\ndemonstrate that UniSpeaker outperforms previous modality-specific models.\nSpeech samples are available at \\url{https://UniSpeaker.github.io}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06394v1",
    "published_date": "2025-01-11 00:47:29 UTC",
    "updated_date": "2025-01-11 00:47:29 UTC"
  }
]