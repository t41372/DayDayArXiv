[
  {
    "arxiv_id": "2507.00322v1",
    "title": "Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones",
    "authors": [
      "Daking Rai",
      "Samuel Miller",
      "Kevin Moran",
      "Ziyu Yao"
    ],
    "abstract": "Despite remarkable advances in coding capabilities, language models (LMs) still struggle with simple syntactic tasks such as generating balanced parentheses. In this study, we investigate the underlying mechanisms behind the persistence of these errors across LMs of varying sizes (124M-7B) to both understand and mitigate the errors. Our study reveals that LMs rely on a number of components (attention heads and FF neurons) that independently make their own predictions. While some components reliably promote correct answers across a generalized range of inputs (i.e., implementing \"sound mechanisms''), others are less reliable and introduce noise by promoting incorrect tokens (i.e., implementing \"faulty mechanisms''). Errors occur when the faulty mechanisms overshadow the sound ones and dominantly affect the predictions. Motivated by this insight, we introduce RASteer, a steering method to systematically identify and increase the contribution of reliable components for improving model performance. RASteer substantially improves performance on balanced parentheses tasks, boosting accuracy of some models from $0$% to around $100$% without impairing the models' general coding ability. We further demonstrate its broader applicability in arithmetic reasoning tasks, achieving performance gains of up to around $20$%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 10 figures, Preprint",
    "pdf_url": "https://arxiv.org/pdf/2507.00322v1",
    "published_date": "2025-06-30 23:35:19 UTC",
    "updated_date": "2025-06-30 23:35:19 UTC"
  },
  {
    "arxiv_id": "2507.00310v2",
    "title": "AutoDiscovery: Open-ended Scientific Discovery via Bayesian Surprise",
    "authors": [
      "Dhruv Agarwal",
      "Bodhisattwa Prasad Majumder",
      "Reece Adamson",
      "Megha Chakravorty",
      "Satvika Reddy Gavireddy",
      "Aditya Parashar",
      "Harshit Surana",
      "Bhavana Dalvi Mishra",
      "Andrew McCallum",
      "Ashish Sabharwal",
      "Peter Clark"
    ],
    "abstract": "The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-driven settings, relying on human-specified research questions to guide hypothesis generation. However, scientific discovery may be accelerated further by allowing the AI system to drive exploration by its own criteria. The few existing approaches in open-ended ASD select hypotheses based on diversity heuristics or subjective proxies for human interestingness, but the former struggles to meaningfully navigate the typically vast hypothesis space, and the latter suffers from imprecise definitions. This paper presents AutoDiscovery -- a method for open-ended ASD that instead drives scientific exploration using Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior beliefs about a hypothesis to its posterior beliefs after gathering experimental results. To efficiently explore the space of nested hypotheses, our method employs a Monte Carlo tree search (MCTS) strategy with progressive widening using surprisal as the reward function. We evaluate AutoDiscovery in the setting of data-driven discovery across 21 real-world datasets spanning domains such as biology, economics, finance, and behavioral science. Our results demonstrate that under a fixed budget, AutoDiscovery substantially outperforms competitors by producing 5-29% more discoveries deemed surprising by the LLM. Our human evaluation further reveals that two-thirds of discoveries made by our system are surprising to domain experts as well, suggesting this is an important step towards building open-ended ASD systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2025; https://neurips.cc/virtual/2025/loc/san-diego/poster/116398",
    "pdf_url": "https://arxiv.org/pdf/2507.00310v2",
    "published_date": "2025-06-30 22:53:59 UTC",
    "updated_date": "2025-11-26 07:27:32 UTC"
  },
  {
    "arxiv_id": "2507.00297v1",
    "title": "Natural language processing for African languages",
    "authors": [
      "David Ifeoluwa Adelani"
    ],
    "abstract": "Recent advances in word embeddings and language models use large-scale, unlabelled data and self-supervised learning to boost NLP performance. Multilingual models, often trained on web-sourced data like Wikipedia, face challenges: few low-resource languages are included, their data is often noisy, and lack of labeled datasets makes it hard to evaluate performance outside high-resource languages like English. In this dissertation, we focus on languages spoken in Sub-Saharan Africa where all the indigenous languages in this region can be regarded as low-resourced in terms of the availability of labelled data for NLP tasks and unlabelled data found on the web. We analyse the noise in the publicly available corpora, and curate a high-quality corpus, demonstrating that the quality of semantic representations learned in word embeddings does not only depend on the amount of data but on the quality of pre-training data. We demonstrate empirically the limitations of word embeddings, and the opportunities the multilingual pre-trained language model (PLM) offers especially for languages unseen during pre-training and low-resource scenarios. We further study how to adapt and specialize multilingual PLMs to unseen African languages using a small amount of monolingual texts. To address the under-representation of the African languages in NLP research, we developed large scale human-annotated labelled datasets for 21 African languages in two impactful NLP tasks: named entity recognition and machine translation. We conduct an extensive empirical evaluation using state-of-the-art methods across supervised, weakly-supervised, and transfer learning settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD thesis",
    "pdf_url": "https://arxiv.org/pdf/2507.00297v1",
    "published_date": "2025-06-30 22:26:36 UTC",
    "updated_date": "2025-06-30 22:26:36 UTC"
  },
  {
    "arxiv_id": "2507.00292v2",
    "title": "Reducing Variability of Multiple Instance Learning Methods for Digital Pathology",
    "authors": [
      "Ali Mammadov",
      "Loïc Le Folgoc",
      "Guillaume Hocquet",
      "Pietro Gori"
    ],
    "abstract": "Digital pathology has revolutionized the field by enabling the digitization of tissue samples into whole slide images (WSIs). However, the high resolution and large size of WSIs present significant challenges when it comes to applying Deep Learning models. As a solution, WSIs are often divided into smaller patches with a global label (\\textit{i.e., diagnostic}) per slide, instead of a (too) costly pixel-wise annotation. By treating each slide as a bag of patches, Multiple Instance Learning (MIL) methods have emerged as a suitable solution for WSI classification. A major drawback of MIL methods is their high variability in performance across different runs, which can reach up to 10-15 AUC points on the test set, making it difficult to compare different MIL methods reliably. This variability mainly comes from three factors: i) weight initialization, ii) batch (shuffling) ordering, iii) and learning rate. To address that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL methods. We first train multiple models for a few epochs and average the most stable and promising ones based on validation scores. This approach can be applied to any existing MIL model to reduce performance variability. It also simplifies hyperparameter tuning and improves reproducibility while maintaining computational efficiency. We extensively validate our approach on WSI classification tasks using 2 different datasets, 3 initialization strategies and 5 MIL methods, for a total of more than 2000 experiments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MICCAI 2025 - This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in LNCS, Springer",
    "pdf_url": "https://arxiv.org/pdf/2507.00292v2",
    "published_date": "2025-06-30 22:10:24 UTC",
    "updated_date": "2025-07-02 12:37:04 UTC"
  },
  {
    "arxiv_id": "2507.00288v1",
    "title": "Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context",
    "authors": [
      "Claire Li",
      "David Freeborn"
    ],
    "abstract": "This study explores how AI-powered digital innovations are reshaping organisational accountability in a transnational governance context. As AI systems increasingly mediate decision-making in domains such as auditing and financial reporting, traditional mechanisms of accountability, based on control, transparency, and auditability, are being destabilised. We integrate the Technology Acceptance Model (TAM), Actor-Network Theory (ANT), and institutional theory to examine how organisations adopt AI technologies in response to regulatory, ethical, and cultural pressures that transcend national boundaries. We argue that accountability is co-constructed within global socio-technical networks, shaped not only by user perceptions but also by governance logics and normative expectations. Extending TAM, we incorporate compliance and legitimacy as key factors in perceived usefulness and usability. Drawing on ANT, we reconceptualise accountability as a relational and emergent property of networked assemblages. We propose two organisational strategies including internal governance reconfiguration and external actor-network engagement to foster responsible, legitimate, and globally accepted AI adoption in the accounting domain.",
    "categories": [
      "econ.TH",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "econ.TH",
    "comment": "22 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.00288v1",
    "published_date": "2025-06-30 21:56:37 UTC",
    "updated_date": "2025-06-30 21:56:37 UTC"
  },
  {
    "arxiv_id": "2507.00287v1",
    "title": "Self-Supervised Multiview Xray Matching",
    "authors": [
      "Mohamad Dabboussi",
      "Malo Huard",
      "Yann Gousseau",
      "Pietro Gori"
    ],
    "abstract": "Accurate interpretation of multi-view radiographs is crucial for diagnosing fractures, muscular injuries, and other anomalies. While significant advances have been made in AI-based analysis of single images, current methods often struggle to establish robust correspondences between different X-ray views, an essential capability for precise clinical evaluations. In this work, we present a novel self-supervised pipeline that eliminates the need for manual annotation by automatically generating a many-to-many correspondence matrix between synthetic X-ray views. This is achieved using digitally reconstructed radiographs (DRR), which are automatically derived from unannotated CT volumes. Our approach incorporates a transformer-based training phase to accurately predict correspondences across two or more X-ray views. Furthermore, we demonstrate that learning correspondences among synthetic X-ray views can be leveraged as a pretraining strategy to enhance automatic multi-view fracture detection on real data. Extensive evaluations on both synthetic and real X-ray datasets show that incorporating correspondences improves performance in multi-view fracture classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.00287v1",
    "published_date": "2025-06-30 21:56:14 UTC",
    "updated_date": "2025-06-30 21:56:14 UTC"
  },
  {
    "arxiv_id": "2507.00286v2",
    "title": "\"Before, I Asked My Mom, Now I Ask ChatGPT\": Visual Privacy Management with Generative AI for Blind and Low-Vision People",
    "authors": [
      "Tanusree Sharma",
      "Yu-Yun Tseng",
      "Lotus Zhang",
      "Ayae Ide",
      "Kelly Avery Mack",
      "Leah Findlater",
      "Danna Gurari",
      "Yang Wang"
    ],
    "abstract": "Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to interpret and manage visual content in their daily lives. While such tools can enhance the accessibility of visual content and so enable greater user independence, they also introduce complex challenges around visual privacy. In this paper, we investigate the current practices and future design preferences of blind and low vision individuals through an interview study with 21 participants. Our findings reveal a range of current practices with GenAI that balance privacy, efficiency, and emotional agency, with users accounting for privacy risks across six key scenarios, such as self-presentation, indoor/outdoor spatial privacy, social sharing, and handling professional content. Our findings reveal design preferences, including on-device processing, zero-retention guarantees, sensitive content redaction, privacy-aware appearance indicators, and multimodal tactile mirrored interaction methods. We conclude with actionable design recommendations to support user-centered visual privacy through GenAI, expanding the notion of privacy and responsible handling of others data.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00286v2",
    "published_date": "2025-06-30 21:55:21 UTC",
    "updated_date": "2025-07-19 04:31:05 UTC"
  },
  {
    "arxiv_id": "2507.02977v1",
    "title": "LLMs are Capable of Misaligned Behavior Under Explicit Prohibition and Surveillance",
    "authors": [
      "Igor Ivanov"
    ],
    "abstract": "In this paper, LLMs are tasked with completing an impossible quiz, while they are in a sandbox, monitored, told about these measures and instructed not to cheat. Some frontier LLMs cheat consistently and attempt to circumvent restrictions despite everything. The results reveal a fundamental tension between goal-directed behavior and alignment in current LLMs. The code and evaluation logs are available at github.com/baceolus/cheating_evals",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.02977v1",
    "published_date": "2025-06-30 21:37:00 UTC",
    "updated_date": "2025-06-30 21:37:00 UTC"
  },
  {
    "arxiv_id": "2507.00275v1",
    "title": "Double Q-learning for Value-based Deep Reinforcement Learning, Revisited",
    "authors": [
      "Prabhat Nagarajan",
      "Martha White",
      "Marlos C. Machado"
    ],
    "abstract": "Overestimation is pervasive in reinforcement learning (RL), including in Q-learning, which forms the algorithmic basis for many value-based deep RL algorithms. Double Q-learning is an algorithm introduced to address Q-learning's overestimation by training two Q-functions and using both to de-correlate action-selection and action-evaluation in bootstrap targets. Shortly after Q-learning was adapted to deep RL in the form of deep Q-networks (DQN), Double Q-learning was adapted to deep RL in the form of Double DQN. However, Double DQN only loosely adapts Double Q-learning, forgoing the training of two different Q-functions that bootstrap off one another. In this paper, we study algorithms that adapt this core idea of Double Q-learning for value-based deep RL. We term such algorithms Deep Double Q-learning (DDQL). Our aim is to understand whether DDQL exhibits less overestimation than Double DQN and whether performant instantiations of DDQL exist. We answer both questions affirmatively, demonstrating that DDQL reduces overestimation and outperforms Double DQN in aggregate across 57 Atari 2600 games, without requiring additional hyperparameters. We also study several aspects of DDQL, including its network architecture, replay ratio, and minibatch sampling strategy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.00275v1",
    "published_date": "2025-06-30 21:32:46 UTC",
    "updated_date": "2025-06-30 21:32:46 UTC"
  },
  {
    "arxiv_id": "2507.00269v2",
    "title": "Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations",
    "authors": [
      "Omar Claflin"
    ],
    "abstract": "Current sparse autoencoder (SAE) approaches to neural network interpretability assume that activations can be decomposed through linear superposition into sparse, interpretable features. Despite high reconstruction fidelity, SAEs consistently fail to eliminate polysemanticity and exhibit pathological behavioral errors. We propose that neural networks encode information in two complementary spaces compressed into the same substrate: feature identity and feature integration. To test this dual encoding hypothesis, we develop sequential and joint-training architectures to capture identity and integration patterns simultaneously. Joint training achieves 41.3% reconstruction improvement and 51.6% reduction in KL divergence errors. This architecture spontaneously develops bimodal feature organization: low squared norm features contributing to integration pathways and the rest contributing directly to the residual. Small nonlinear components (3% of parameters) achieve 16.5% standalone improvements, demonstrating parameter-efficient capture of computational relationships crucial for behavior. Additionally, intervention experiments using 2x2 factorial stimulus designs demonstrated that integration features exhibit selective sensitivity to experimental manipulations and produce systematic behavioral effects on model outputs, including significant statistical interaction effects across semantic dimensions. This work provides systematic evidence for (1) dual encoding in neural representations, (2) meaningful nonlinearly encoded feature interactions, and (3) introduces an architectural paradigm shift from post-hoc feature analysis to integrated computational design, establishing foundations for next-generation SAEs.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00269v2",
    "published_date": "2025-06-30 21:26:58 UTC",
    "updated_date": "2025-12-09 08:57:06 UTC"
  },
  {
    "arxiv_id": "2507.00268v1",
    "title": "Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems",
    "authors": [
      "Oren Fivel",
      "Matan Rudman",
      "Kobi Cohen"
    ],
    "abstract": "Deep reinforcement learning (DRL) has become a powerful tool for complex decision-making in machine learning and AI. However, traditional methods often assume perfect action execution, overlooking the uncertainties and deviations between an agent's selected actions and the actual system response. In real-world applications, such as robotics, mechatronics, and communication networks, execution mismatches arising from system dynamics, hardware constraints, and latency can significantly degrade performance. This work advances AI by developing a novel control-optimized DRL framework that explicitly models and compensates for action execution mismatches, a challenge largely overlooked in existing methods. Our approach establishes a structured two-stage process: determining the desired action and selecting the appropriate control signal to ensure proper execution. It trains the agent while accounting for action mismatches and controller corrections. By incorporating these factors into the training process, the AI agent optimizes the desired action with respect to both the actual control signal and the intended outcome, explicitly considering execution errors. This approach enhances robustness, ensuring that decision-making remains effective under real-world uncertainties. Our approach offers a substantial advancement for engineering practice by bridging the gap between idealized learning and real-world implementation. It equips intelligent agents operating in engineering environments with the ability to anticipate and adjust for actuation errors and system disturbances during training. We evaluate the framework in five widely used open-source mechanical simulation environments we restructured and developed to reflect real-world operating conditions, showcasing its robustness against uncertainties and offering a highly practical and efficient solution for control-oriented applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "27 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2507.00268v1",
    "published_date": "2025-06-30 21:25:52 UTC",
    "updated_date": "2025-06-30 21:25:52 UTC"
  },
  {
    "arxiv_id": "2507.00258v1",
    "title": "Impact of Fine-Tuning Methods on Memorization in Large Language Models",
    "authors": [
      "Jie Hou",
      "Chuxiong Wu",
      "Lannan Luo",
      "Qiang Zeng"
    ],
    "abstract": "As the capabilities of pre-trained large language models (LLMs) continue to advance, the \"pre-train and fine-tune\" paradigm has become increasingly mainstream, leading to the development of various fine-tuning methods. However, the privacy risks arising from memorization during fine-tuning have received relatively little attention. To address this gap, we categorize popular fine-tuning approaches and assess their impact on memorization through the lens of membership inference attacks (MIAs). Our results show that, compared to parameter-based fine-tuning, prompt-based fine-tuning achieves competitive performance while exhibiting lower vulnerability to MIAs. Furthermore, prompt-based methods maintain low memorization regardless of model scale. These findings suggest that parameter-based fine-tuning is more prone to leaking private information, whereas prompt-based fine-tuning serves as a more privacy-preserving option.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00258v1",
    "published_date": "2025-06-30 20:52:15 UTC",
    "updated_date": "2025-06-30 20:52:15 UTC"
  },
  {
    "arxiv_id": "2507.00257v1",
    "title": "Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning",
    "authors": [
      "Davide Salaorni",
      "Vincenzo De Paola",
      "Samuele Delpero",
      "Giovanni Dispoto",
      "Paolo Bonetti",
      "Alessio Russo",
      "Giuseppe Calcagno",
      "Francesco Trovò",
      "Matteo Papini",
      "Alberto Maria Metelli",
      "Marco Mussi",
      "Marcello Restelli"
    ],
    "abstract": "In recent years, \\emph{Reinforcement Learning} (RL) has made remarkable progress, achieving superhuman performance in a wide range of simulated environments. As research moves toward deploying RL in real-world applications, the field faces a new set of challenges inherent to real-world settings, such as large state-action spaces, non-stationarity, and partial observability. Despite their importance, these challenges are often underexplored in current benchmarks, which tend to focus on idealized, fully observable, and stationary environments, often neglecting to incorporate real-world complexities explicitly. In this paper, we introduce \\texttt{Gym4ReaL}, a comprehensive suite of realistic environments designed to support the development and evaluation of RL algorithms that can operate in real-world scenarios. The suite includes a diverse set of tasks that expose algorithms to a variety of practical challenges. Our experimental results show that, in these settings, standard RL algorithms confirm their competitiveness against rule-based benchmarks, motivating the development of new methods to fully exploit the potential of RL to tackle the complexities of real-world tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.00257v1",
    "published_date": "2025-06-30 20:47:50 UTC",
    "updated_date": "2025-06-30 20:47:50 UTC"
  },
  {
    "arxiv_id": "2507.00248v1",
    "title": "Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition",
    "authors": [
      "Nikita Nikitin",
      "Eugene Fomin"
    ],
    "abstract": "We present a novel framework for real-time sign language recognition using lightweight DNNs trained on limited data. Our system addresses key challenges in sign language recognition, including data scarcity, high computational costs, and discrepancies in frame rates between training and inference environments. By encoding sign language specific parameters, such as handshape, palm orientation, movement, and location into vectorized inputs, and leveraging MediaPipe for landmark extraction, we achieve highly separable input data representations. Our DNN architecture, optimized for sub 10MB deployment, enables accurate classification of 343 signs with less than 10ms latency on edge devices. The data annotation platform 'slait data' facilitates structured labeling and vector extraction. Our model achieved 92% accuracy in isolated sign recognition and has been integrated into the 'slait ai' web application, where it demonstrates stable inference.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 2 figures, 2 tables, for associated mpeg file, see https://slait.app/static/Screen_Recording.mp4",
    "pdf_url": "https://arxiv.org/pdf/2507.00248v1",
    "published_date": "2025-06-30 20:34:54 UTC",
    "updated_date": "2025-06-30 20:34:54 UTC"
  },
  {
    "arxiv_id": "2507.00239v1",
    "title": "Linearly Decoding Refused Knowledge in Aligned Language Models",
    "authors": [
      "Aryan Shrivastava",
      "Ari Holtzman"
    ],
    "abstract": "Most commonly used language models (LMs) are instruction-tuned and aligned using a combination of fine-tuning and reinforcement learning, causing them to refuse users requests deemed harmful by the model. However, jailbreak prompts can often bypass these refusal mechanisms and elicit harmful responses. In this work, we study the extent to which information accessed via jailbreak prompts is decodable using linear probes trained on LM hidden states. We show that a great deal of initially refused information is linearly decodable. For example, across models, the response of a jailbroken LM for the average IQ of a country can be predicted by a linear probe with Pearson correlations exceeding $0.8$. Surprisingly, we find that probes trained on base models (which do not refuse) sometimes transfer to their instruction-tuned versions and are capable of revealing information that jailbreaks decode generatively, suggesting that the internal representations of many refused properties persist from base LMs through instruction-tuning. Importantly, we show that this information is not merely \"leftover\" in instruction-tuned models, but is actively used by them: we find that probe-predicted values correlate with LM generated pairwise comparisons, indicating that the information decoded by our probes align with suppressed generative behavior that may be expressed more subtly in other downstream tasks. Overall, our results suggest that instruction-tuning does not wholly eliminate or even relocate harmful information in representation space-they merely suppress its direct expression, leaving it both linearly accessible and indirectly influential in downstream behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00239v1",
    "published_date": "2025-06-30 20:13:49 UTC",
    "updated_date": "2025-06-30 20:13:49 UTC"
  },
  {
    "arxiv_id": "2507.00234v1",
    "title": "Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations",
    "authors": [
      "Jiztom Kavalakkatt Francis",
      "Matthew J Darr"
    ],
    "abstract": "In this paper, we present a novel framework for enhancing model interpretability by integrating heatmaps produced separately by ResNet and a restructured 2D Transformer with globally weighted input saliency. We address the critical problem of spatial-temporal misalignment in existing interpretability methods, where convolutional networks fail to capture global context and Transformers lack localized precision - a limitation that impedes actionable insights in safety-critical domains like healthcare and industrial monitoring. Our method merges gradient-weighted activation maps (ResNet) and Transformer attention rollout into a unified visualization, achieving full spatial-temporal alignment while preserving real-time performance. Empirical evaluations on clinical (ECG arrhythmia detection) and industrial (energy consumption prediction) datasets demonstrate significant improvements: the hybrid framework achieves 94.1% accuracy (F1 0.93) on the PhysioNet dataset and reduces regression error to RMSE = 0.28 kWh (R2 = 0.95) on the UCI Energy Appliance dataset-outperforming standalone ResNet, Transformer, and InceptionTime baselines by 3.8-12.4%. An NLP module translates fused heatmaps into domain-specific narratives (e.g., \"Elevated ST-segment between 2-4 seconds suggests myocardial ischemia\"), validated via BLEU-4 (0.586) and ROUGE-L (0.650) scores. By formalizing interpretability as causal fidelity and spatial-temporal alignment, our approach bridges the gap between technical outputs and stakeholder understanding, offering a scalable solution for transparent, time-aware decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "https://arxiv.org/pdf/2507.00234v1",
    "published_date": "2025-06-30 20:04:35 UTC",
    "updated_date": "2025-06-30 20:04:35 UTC"
  },
  {
    "arxiv_id": "2507.00229v1",
    "title": "A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss",
    "authors": [
      "Tarikul Islam Tamiti",
      "Biraj Joshi",
      "Rida Hasan",
      "Rashedul Hasan",
      "Taieba Athay",
      "Nursad Mamun",
      "Anomadarshi Barua"
    ],
    "abstract": "Speech super-resolution (SSR) enhances low-resolution speech by increasing the sampling rate. While most SSR methods focus on magnitude reconstruction, recent research highlights the importance of phase reconstruction for improved perceptual quality. Therefore, we introduce CTFT-Net, a Complex Time-Frequency Transformation Network that reconstructs both magnitude and phase in complex domains for improved SSR tasks. It incorporates a complex global attention block to model inter-phoneme and inter-frequency dependencies and a complex conformer to capture long-range and local features, improving frequency reconstruction and noise robustness. CTFT-Net employs time-domain and multi-resolution frequency-domain loss functions for better generalization. Experiments show CTFT-Net outperforms state-of-the-art models (NU-Wave, WSRGlow, NVSR, AERO) on the VCTK dataset, particularly for extreme upsampling (2 kHz to 48 kHz), reconstructing high frequencies effectively without noisy artifacts.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00229v1",
    "published_date": "2025-06-30 19:53:15 UTC",
    "updated_date": "2025-06-30 19:53:15 UTC"
  },
  {
    "arxiv_id": "2507.00227v1",
    "title": "Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis",
    "authors": [
      "Paul Mayer",
      "Florian Lux",
      "Alejandro Pérez-González-de-Martos",
      "Angelina Elizarova",
      "Lindsey Vanderlyn",
      "Dirk Väth",
      "Ngoc Thang Vu"
    ],
    "abstract": "While generative methods have progressed rapidly in recent years, generating expressive prosody for an utterance remains a challenging task in text-to-speech synthesis. This is particularly true for systems that model prosody explicitly through parameters such as pitch, energy, and duration, which is commonly done for the sake of interpretability and controllability. In this work, we investigate the effectiveness of stochastic methods for this task, including Normalizing Flows, Conditional Flow Matching, and Rectified Flows. We compare these methods to a traditional deterministic baseline, as well as to real human realizations. Our extensive subjective and objective evaluations demonstrate that stochastic methods produce natural prosody on par with human speakers by capturing the variability inherent in human speech. Further, they open up additional controllability options by allowing the sampling temperature to be tuned.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at Interspeech 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.00227v1",
    "published_date": "2025-06-30 19:52:32 UTC",
    "updated_date": "2025-06-30 19:52:32 UTC"
  },
  {
    "arxiv_id": "2507.00225v3",
    "title": "Discovering the Underlying Analytic Structure Within Standard Model Constants Using Artificial Intelligence",
    "authors": [
      "S. V. Chekanov",
      "H. Kjellerstrand"
    ],
    "abstract": "This paper presents a method for uncovering hidden analytic relationships among the fundamental parameters of the Standard Model (SM), a foundational theory in physics that describes the fundamental particles and their interactions, using symbolic regression and genetic programming. Using this approach, we identify the simplest analytic relationships connecting pairs of these constants and report several notable expressions obtained with relative precision better than 1%. These results may serve as valuable inputs for model builders and artificial intelligence methods aimed at uncovering hidden patterns among the SM constants, or potentially used as building blocks for a deeper underlying law that connects all parameters of the SM through a small set of fundamental constants.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "hep-ph",
    "comment": "20 pages, 1 figure, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.00225v3",
    "published_date": "2025-06-30 19:51:50 UTC",
    "updated_date": "2025-12-01 15:53:39 UTC"
  },
  {
    "arxiv_id": "2507.00218v1",
    "title": "Learning for routing: A guided review of recent developments and future directions",
    "authors": [
      "Fangting Zhou",
      "Attila Lischka",
      "Balazs Kulcsar",
      "Jiaming Wu",
      "Morteza Haghir Chehreghani",
      "Gilbert Laporte"
    ],
    "abstract": "This paper reviews the current progress in applying machine learning (ML) tools to solve NP-hard combinatorial optimization problems, with a focus on routing problems such as the traveling salesman problem (TSP) and the vehicle routing problem (VRP). Due to the inherent complexity of these problems, exact algorithms often require excessive computational time to find optimal solutions, while heuristics can only provide approximate solutions without guaranteeing optimality. With the recent success of machine learning models, there is a growing trend in proposing and implementing diverse ML techniques to enhance the resolution of these challenging routing problems. We propose a taxonomy categorizing ML-based routing methods into construction-based and improvement-based approaches, highlighting their applicability to various problem characteristics. This review aims to integrate traditional OR methods with state-of-the-art ML techniques, providing a structured framework to guide future research and address emerging VRP variants.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in Transportation Research Part E: Logistics and Transportation Review",
    "pdf_url": "https://arxiv.org/pdf/2507.00218v1",
    "published_date": "2025-06-30 19:39:11 UTC",
    "updated_date": "2025-06-30 19:39:11 UTC"
  },
  {
    "arxiv_id": "2507.00214v1",
    "title": "Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning",
    "authors": [
      "Mads Henrichsen",
      "Rasmus Krebs"
    ],
    "abstract": "Standard classification models often map inputs directly to labels without explicit reasoning, potentially limiting their performance, robustness, and interpretability. This paper introduces a novel two-stage approach to enhance text classification by leveraging Large Language Model (LLM)-generated reasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model (henceforth Llama-R-Gen) on a general-purpose reasoning dataset (syvai/reasoning-gen) to generate textual reasoning (R) given a question and its answer. In the second stage, this generally trained Llama-R-Gen is used offline to create an augmented training dataset for a downstream generative model. This downstream model, based on Llama-3.2-1B-Instruct, takes only the input text (Q) and is trained to output the generated reasoning (R) immediately followed by the predicted emotion (A). We demonstrate this methodology on the dair-ai/emotion dataset for emotion classification. Our experiments show that the generative model trained to output reasoning and the emotion (Classifier Q->RA) achieves a significant improvement of 8.7 percentage points in accuracy (for emotion prediction) compared to a baseline generative model trained solely to output the emotion (Classifier Q->A), highlighting the strong generalization capabilities of the reasoning generation and the benefit of explicit reasoning training. This work underscores the potential of LLM-generated reasonings for creating richer training datasets, thereby improving the performance of diverse downstream NLP tasks and providing explicit explanations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00214v1",
    "published_date": "2025-06-30 19:34:57 UTC",
    "updated_date": "2025-06-30 19:34:57 UTC"
  },
  {
    "arxiv_id": "2507.00209v3",
    "title": "SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures",
    "authors": [
      "Fengyi Jiang",
      "Xiaorui Zhang",
      "Lingbo Jin",
      "Ruixing Liang",
      "Yuxin Chen",
      "Adi Chola Venkatesh",
      "Jason Culman",
      "Tiantian Wu",
      "Lirong Shao",
      "Wenqing Sun",
      "Cong Gao",
      "Hallie McNamara",
      "Jingpei Lu",
      "Omid Mohareri"
    ],
    "abstract": "High-resolution imaging is crucial for enhancing visual clarity and enabling precise computer-assisted guidance in minimally invasive surgery (MIS). Despite the increasing adoption of 4K endoscopic systems, there remains a significant gap in publicly available native 4K datasets tailored specifically for robotic-assisted MIS. We introduce SurgiSR4K, the first publicly accessible surgical imaging and video dataset captured at a native 4K resolution, representing realistic conditions of robotic-assisted procedures. SurgiSR4K comprises diverse visual scenarios including specular reflections, tool occlusions, bleeding, and soft tissue deformations, meticulously designed to reflect common challenges faced during laparoscopic and robotic surgeries. This dataset opens up possibilities for a broad range of computer vision tasks that might benefit from high resolution data, such as super resolution (SR), smoke removal, surgical instrument detection, 3D tissue reconstruction, monocular depth estimation, instance segmentation, novel view synthesis, and vision-language model (VLM) development. SurgiSR4K provides a robust foundation for advancing research in high-resolution surgical imaging and fosters the development of intelligent imaging technologies aimed at enhancing performance, safety, and usability in image-guided robotic surgeries.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00209v3",
    "published_date": "2025-06-30 19:23:57 UTC",
    "updated_date": "2025-07-29 02:56:23 UTC"
  },
  {
    "arxiv_id": "2507.00205v1",
    "title": "Holistic Artificial Intelligence in Medicine; improved performance and explainability",
    "authors": [
      "Periklis Petridis",
      "Georgios Margaritis",
      "Vasiliki Stoumpou",
      "Dimitris Bertsimas"
    ],
    "abstract": "With the increasing interest in deploying Artificial Intelligence in medicine, we previously introduced HAIM (Holistic AI in Medicine), a framework that fuses multimodal data to solve downstream clinical tasks. However, HAIM uses data in a task-agnostic manner and lacks explainability. To address these limitations, we introduce xHAIM (Explainable HAIM), a novel framework leveraging Generative AI to enhance both prediction and explainability through four structured steps: (1) automatically identifying task-relevant patient data across modalities, (2) generating comprehensive patient summaries, (3) using these summaries for improved predictive modeling, and (4) providing clinical explanations by linking predictions to patient-specific medical knowledge. Evaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9% to 90.3% across chest pathology and operative tasks. Importantly, xHAIM transforms AI from a black-box predictor into an explainable decision support system, enabling clinicians to interactively trace predictions back to relevant patient data, bridging AI advancements with clinical utility.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to npj Digital Medicine",
    "pdf_url": "https://arxiv.org/pdf/2507.00205v1",
    "published_date": "2025-06-30 19:15:06 UTC",
    "updated_date": "2025-06-30 19:15:06 UTC"
  },
  {
    "arxiv_id": "2507.00195v1",
    "title": "What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness",
    "authors": [
      "Kumar Kshitij Patel"
    ],
    "abstract": "This thesis contributes to the theoretical understanding of local update algorithms, especially Local SGD, in distributed and federated optimization under realistic models of data heterogeneity. A central focus is on the bounded second-order heterogeneity assumption, which is shown to be both necessary and sufficient for local updates to outperform centralized or mini-batch methods in convex and non-convex settings. The thesis establishes tight upper and lower bounds in several regimes for various local update algorithms and characterizes the min-max complexity of multiple problem classes. At its core is a fine-grained consensus-error-based analysis framework that yields sharper finite-time convergence bounds under third-order smoothness and relaxed heterogeneity assumptions. The thesis also extends to online federated learning, providing fundamental regret bounds under both first-order and bandit feedback. Together, these results clarify when and why local updates offer provable advantages, and the thesis serves as a self-contained guide for analyzing Local SGD in heterogeneous environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00195v1",
    "published_date": "2025-06-30 19:06:02 UTC",
    "updated_date": "2025-06-30 19:06:02 UTC"
  },
  {
    "arxiv_id": "2507.00191v1",
    "title": "Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions",
    "authors": [
      "Eray Erturk",
      "Fahad Kamran",
      "Salar Abbaspourazad",
      "Sean Jewell",
      "Harsh Sharma",
      "Yujie Li",
      "Sinead Williamson",
      "Nicholas J Foti",
      "Joseph Futoma"
    ],
    "abstract": "Wearable devices record physiological and behavioral signals that can improve health predictions. While foundation models are increasingly used for such predictions, they have been primarily applied to low-level sensor data, despite behavioral data often being more informative due to their alignment with physiologically relevant timescales and quantities. We develop foundation models of such behavioral signals using over 2.5B hours of wearable data from 162K individuals, systematically optimizing architectures and tokenization strategies for this unique dataset. Evaluated on 57 health-related tasks, our model shows strong performance across diverse real-world applications including individual-level classification and time-varying health state prediction. The model excels in behavior-driven tasks like sleep prediction, and improves further when combined with representations of raw sensor data. These results underscore the importance of tailoring foundation model design to wearables and demonstrate the potential to enable new health applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.00191v1",
    "published_date": "2025-06-30 19:01:00 UTC",
    "updated_date": "2025-06-30 19:01:00 UTC"
  },
  {
    "arxiv_id": "2507.00185v1",
    "title": "Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)",
    "authors": [
      "Yang Zhou",
      "Chrystie Wan Ning Quek",
      "Jun Zhou",
      "Yan Wang",
      "Yang Bai",
      "Yuhe Ke",
      "Jie Yao",
      "Laura Gutierrez",
      "Zhen Ling Teo",
      "Darren Shu Jeng Ting",
      "Brian T. Soetikno",
      "Christopher S. Nielsen",
      "Tobias Elze",
      "Zengxiang Li",
      "Linh Le Dinh",
      "Lionel Tim-Ee Cheng",
      "Tran Nguyen Tuan Anh",
      "Chee Leong Cheng",
      "Tien Yin Wong",
      "Nan Liu",
      "Iain Beehuat Tan",
      "Tony Kiat Hon Lim",
      "Rick Siow Mong Goh",
      "Yong Liu",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Current artificial intelligence models for medical imaging are predominantly single modality and single disease. Attempts to create multimodal and multi-disease models have resulted in inconsistent clinical accuracy. Furthermore, training these models typically requires large, labour-intensive, well-labelled datasets. We developed MerMED-FM, a state-of-the-art multimodal, multi-specialty foundation model trained using self-supervised learning and a memory module. MerMED-FM was trained on 3.3 million medical images from over ten specialties and seven modalities, including computed tomography (CT), chest X-rays (CXR), ultrasound (US), pathology patches, color fundus photography (CFP), optical coherence tomography (OCT) and dermatology images. MerMED-FM was evaluated across multiple diseases and compared against existing foundational models. Strong performance was achieved across all modalities, with AUROCs of 0.988 (OCT); 0.982 (pathology); 0.951 (US); 0.943 (CT); 0.931 (skin); 0.894 (CFP); 0.858 (CXR). MerMED-FM has the potential to be a highly adaptable, versatile, cross-specialty foundation model that enables robust medical imaging interpretation across diverse medical disciplines.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "42 pages, 3 composite figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.00185v1",
    "published_date": "2025-06-30 18:50:31 UTC",
    "updated_date": "2025-06-30 18:50:31 UTC"
  },
  {
    "arxiv_id": "2507.00184v2",
    "title": "Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros",
    "authors": [
      "Jacob Schrum",
      "Olivia Kilday",
      "Emilio Salas",
      "Bess Hagan",
      "Reid Williams"
    ],
    "abstract": "Recent research shows how diffusion models can unconditionally generate tile-based game levels, but use of diffusion models for text-to-level generation is underexplored. There are practical considerations for creating a usable model: caption/level pairs are needed, as is a text embedding model, and a way of generating entire playable levels, rather than individual scenes. We present strategies to automatically assign descriptive captions to an existing dataset, and train diffusion models using both pretrained text encoders and simple transformer models trained from scratch. Captions are automatically assigned to generated scenes so that the degree of overlap between input and output captions can be compared. We also assess the diversity and playability of the resulting level scenes. Results are compared with an unconditional diffusion model and a generative adversarial network, as well as the text-to-level approaches Five-Dollar Model and MarioGPT. Notably, the best diffusion model uses a simple transformer model for text embedding, and takes less time to train than diffusion models employing more complex text encoders, indicating that reliance on larger language models is not necessary. We also present a GUI allowing designers to construct long levels from model-generated scenes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to appear in The 21st AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (November 10-14, 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.00184v2",
    "published_date": "2025-06-30 18:50:26 UTC",
    "updated_date": "2025-08-15 00:45:45 UTC"
  },
  {
    "arxiv_id": "2507.00181v1",
    "title": "ChatGPT produces more \"lazy\" thinkers: Evidence of cognitive engagement decline",
    "authors": [
      "Georgios P. Georgiou"
    ],
    "abstract": "Despite the increasing use of large language models (LLMs) in education, concerns have emerged about their potential to reduce deep thinking and active learning. This study investigates the impact of generative artificial intelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of students during academic writing tasks. The study employed an experimental design with participants randomly assigned to either an AI-assisted (ChatGPT) or a non-assisted (control) condition. Participants completed a structured argumentative writing task followed by a cognitive engagement scale (CES), the CES-AI, developed to assess mental effort, attention, deep processing, and strategic thinking. The results revealed significantly lower cognitive engagement scores in the ChatGPT group compared to the control group. These findings suggest that AI assistance may lead to cognitive offloading. The study contributes to the growing body of literature on the psychological implications of AI in education and raises important questions about the integration of such tools into academic practice. It calls for pedagogical strategies that promote active, reflective engagement with AI-generated content to avoid compromising self-regulated learning and deep cognitive involvement of students.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00181v1",
    "published_date": "2025-06-30 18:41:50 UTC",
    "updated_date": "2025-06-30 18:41:50 UTC"
  },
  {
    "arxiv_id": "2507.00180v1",
    "title": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis",
    "authors": [
      "Vidhi Rathore"
    ],
    "abstract": "Modernizing legacy software systems is a critical but challenging task, often hampered by a lack of documentation and understanding of the original system's intricate decision logic. Traditional approaches like behavioral cloning merely replicate input-output behavior without capturing the underlying intent. This paper proposes a novel pipeline to automatically extract interpretable decision logic from legacy systems treated as black boxes. The approach uses a Reinforcement Learning (RL) agent to explore the input space and identify critical decision boundaries by rewarding actions that cause meaningful changes in the system's output. These counterfactual state transitions, where the output changes, are collected and clustered using K-Means. Decision trees are then trained on these clusters to extract human-readable rules that approximate the system's decision logic near the identified boundaries. I demonstrated the pipeline's effectiveness on three dummy legacy systems with varying complexity, including threshold-based, combined-conditional, and non-linear range logic. Results show that the RL agent successfully focuses exploration on relevant boundary regions, and the extracted rules accurately reflect the core logic of the underlying dummy systems, providing a promising foundation for generating specifications and test cases during legacy migration.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00180v1",
    "published_date": "2025-06-30 18:36:54 UTC",
    "updated_date": "2025-06-30 18:36:54 UTC"
  },
  {
    "arxiv_id": "2507.00161v1",
    "title": "Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments",
    "authors": [
      "Christopher M. Wegemer",
      "Edward Halim",
      "Jeff Burke"
    ],
    "abstract": "Political polarization undermines democratic civic education by exacerbating identity-based resistance to opposing viewpoints. Emerging AI technologies offer new opportunities to advance interventions that reduce polarization and promote political open-mindedness. We examined novel design strategies that leverage adaptive and emotionally-responsive civic narratives that may sustain students' emotional engagement in stories, and in turn, promote perspective-taking toward members of political out-groups. Drawing on theories from political psychology and narratology, we investigate how affective computing techniques can support three storytelling mechanisms: transportation into a story world, identification with characters, and interaction with the storyteller. Using a design-based research (DBR) approach, we iteratively developed and refined an AI-mediated Digital Civic Storytelling (AI-DCS) platform. Our prototype integrates facial emotion recognition and attention tracking to assess users' affective and attentional states in real time. Narrative content is organized around pre-structured story outlines, with beat-by-beat language adaptation implemented via GPT-4, personalizing linguistic tone to sustain students' emotional engagement in stories that center political perspectives different from their own. Our work offers a foundation for AI-supported, emotionally-sensitive strategies that address affective polarization while preserving learner autonomy. We conclude with implications for civic education interventions, algorithmic literacy, and HCI challenges associated with AI dialogue management and affect-adaptive learning environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00161v1",
    "published_date": "2025-06-30 18:11:12 UTC",
    "updated_date": "2025-06-30 18:11:12 UTC"
  },
  {
    "arxiv_id": "2507.00145v1",
    "title": "AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise",
    "authors": [
      "Hasan Yiğit"
    ],
    "abstract": "AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform entropy directly from physical noise, eliminating the need for bulky quantum devices or expensive laboratory-grade RF receivers. Instead, it relies on a low-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and then emits 32-bit high-entropy streams without any quantization step.\n  Unlike deterministic or trained artificial intelligence random number generators (RNGs), our dynamic inner-outer network couples adaptive natural sources and reseeding, yielding truly unpredictable and autonomous sequences. Generated numbers pass the NIST SP 800-22 battery better than a CPU-based method. It also passes nineteen bespoke statistical tests for both bit- and integer-level analysis. All results satisfy cryptographic standards, while forward and backward prediction experiments reveal no exploitable biases. The model's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft cores, as well as suitable for other resource-constrained platforms.\n  By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG broadens the reach of high-integrity random number generators across secure systems, cryptographic protocols, embedded and edge devices, stochastic simulations, and server applications that need randomness.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.IT",
      "eess.SP"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00145v1",
    "published_date": "2025-06-30 18:01:40 UTC",
    "updated_date": "2025-06-30 18:01:40 UTC"
  },
  {
    "arxiv_id": "2506.24125v1",
    "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation",
    "authors": [
      "Jiacheng Cui",
      "Xinyue Bi",
      "Yaxin Luo",
      "Xiaohan Zhao",
      "Jiacheng Liu",
      "Zhiqiang Shen"
    ],
    "abstract": "Residual connection has been extensively studied and widely applied at the model architecture level. However, its potential in the more challenging data-centric approaches remains unexplored. In this work, we introduce the concept of Data Residual Matching for the first time, leveraging data-level skip connections to facilitate data generation and mitigate data information vanishing. This approach maintains a balance between newly acquired knowledge through pixel space optimization and existing core local information identification within raw data modalities, specifically for the dataset distillation task. Furthermore, by incorporating optimization-level refinements, our method significantly improves computational efficiency, achieving superior performance while reducing training time and peak GPU memory usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art, demonstrating substantial improvements over existing methods across multiple dataset benchmarks in both efficiency and effectiveness. For instance, with ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the method achieves 47.7% test accuracy in single-model dataset distillation and 50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4% and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code at: https://github.com/Jiacheng8/FADRM",
    "pdf_url": "https://arxiv.org/pdf/2506.24125v1",
    "published_date": "2025-06-30 17:59:34 UTC",
    "updated_date": "2025-06-30 17:59:34 UTC"
  },
  {
    "arxiv_id": "2506.24120v2",
    "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime",
    "authors": [
      "Yuqing Wang",
      "Shangding Gu"
    ],
    "abstract": "Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complicated tasks. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{\\min}$, and prove that a smaller $h_{\\min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{\\min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connection and function composition in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.24120v2",
    "published_date": "2025-06-30 17:58:30 UTC",
    "updated_date": "2025-09-29 17:59:02 UTC"
  },
  {
    "arxiv_id": "2506.24119v2",
    "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning",
    "authors": [
      "Bo Liu",
      "Leon Guertler",
      "Simon Yu",
      "Zichen Liu",
      "Penghui Qi",
      "Daniel Balcells",
      "Mickel Liu",
      "Cheston Tan",
      "Weiyan Shi",
      "Min Lin",
      "Wee Sun Lee",
      "Natasha Jaques"
    ],
    "abstract": "Recent advances in reinforcement learning have shown that language models can develop sophisticated reasoning through training on tasks with verifiable rewards, but these approaches depend on human-curated problem-answer pairs and domain-specific reward engineering. We introduce SPIRAL, a self-play framework where models learn by playing multi-turn, zero-sum games against continuously improving versions of themselves, eliminating the need for human supervision. Through self-play, SPIRAL generates an infinite curriculum of progressively challenging problems as models must constantly adapt to stronger opponents. To enable this self-play training at scale, We implement a fully online, multi-turn, multi-agent reinforcement learning system for LLMs and propose role-conditioned advantage estimation (RAE) to stabilize multi-agent training. Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6% improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000 expert game trajectories. Analysis reveals that this transfer occurs through three cognitive patterns: systematic decomposition, expected value calculation, and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple Negotiation) further enhances performance as each game develops distinct reasoning strengths. Applying SPIRAL to a strong reasoning model (DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These results demonstrate that zero-sum games naturally develop transferable reasoning capabilities, highlighting a promising direction for autonomous reasoning development.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in Progress",
    "pdf_url": "https://arxiv.org/pdf/2506.24119v2",
    "published_date": "2025-06-30 17:58:13 UTC",
    "updated_date": "2025-07-01 02:29:52 UTC"
  },
  {
    "arxiv_id": "2506.24108v1",
    "title": "Navigating with Annealing Guidance Scale in Diffusion Space",
    "authors": [
      "Shai Yehezkel",
      "Omer Dahary",
      "Andrey Voynov",
      "Daniel Cohen-Or"
    ],
    "abstract": "Denoising diffusion models excel at generating high-quality images conditioned on text prompts, yet their effectiveness heavily relies on careful guidance during the sampling process. Classifier-Free Guidance (CFG) provides a widely used mechanism for steering generation by setting the guidance scale, which balances image quality and prompt alignment. However, the choice of the guidance scale has a critical impact on the convergence toward a visually appealing and prompt-adherent image. In this work, we propose an annealing guidance scheduler which dynamically adjusts the guidance scale over time based on the conditional noisy signal. By learning a scheduling policy, our method addresses the temperamental behavior of CFG. Empirical results demonstrate that our guidance scheduler significantly enhances image quality and alignment with the text prompt, advancing the performance of text-to-image generation. Notably, our novel scheduler requires no additional activations or memory consumption, and can seamlessly replace the common classifier-free guidance, offering an improved trade-off between prompt alignment and quality.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "Project page: https://annealing-guidance.github.io/annealing-guidance/",
    "pdf_url": "https://arxiv.org/pdf/2506.24108v1",
    "published_date": "2025-06-30 17:55:00 UTC",
    "updated_date": "2025-06-30 17:55:00 UTC"
  },
  {
    "arxiv_id": "2506.24106v1",
    "title": "On the Predictive Power of Representation Dispersion in Language Models",
    "authors": [
      "Yanhong Li",
      "Ming Li",
      "Karen Livescu",
      "Jiawei Zhou"
    ],
    "abstract": "We show that a language model's ability to predict text is tightly linked to the breadth of its embedding space: models that spread their contextual representations more widely tend to achieve lower perplexity. Concretely, we find that representation dispersion - the average pairwise cosine distance among hidden vectors - strongly and negatively correlates with perplexity across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia, news, scientific abstracts). Beyond illustrating this link, we show how dispersion can be leveraged for a range of practical tasks without requiring labeled data. First, measuring dispersion on unlabeled text allows us to predict downstream accuracy in new domains, offering a data-efficient tool for model selection. Next, we find that identifying layers with higher dispersion pinpoints the best representations for retrieval-based methods such as kNN-LM, bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple push-away objective into training, which increases dispersion in both single-domain and cross-domain scenarios and directly improves perplexity in each.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.24106v1",
    "published_date": "2025-06-30 17:53:50 UTC",
    "updated_date": "2025-06-30 17:53:50 UTC"
  },
  {
    "arxiv_id": "2506.24093v1",
    "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies",
    "authors": [
      "Paul Wachter",
      "Lukas Niehaus",
      "Julius Schöning"
    ],
    "abstract": "Synthetic data has emerged as a cost-effective alternative to real data for training artificial neural networks (ANN). However, the disparity between synthetic and real data results in a domain gap. That gap leads to poor performance and generalization of the trained ANN when applied to real-world scenarios. Several strategies have been developed to bridge this gap, which combine synthetic and real data, known as mixed training using hybrid datasets. While these strategies have been shown to mitigate the domain gap, a systematic evaluation of their generalizability and robustness across various tasks and architectures remains underexplored. To address this challenge, our study comprehensively analyzes two widely used mixing strategies on three prevalent architectures and three distinct hybrid datasets. From these datasets, we sample subsets with varying proportions of synthetic to real data to investigate the impact of synthetic and real components. The findings of this paper provide valuable insights into optimizing the use of synthetic data in the training process of any ANN, contributing to enhancing robustness and efficacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21pages, 14 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2506.24093v1",
    "published_date": "2025-06-30 17:48:14 UTC",
    "updated_date": "2025-06-30 17:48:14 UTC"
  },
  {
    "arxiv_id": "2506.24085v2",
    "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention",
    "authors": [
      "Wonwoong Cho",
      "Yanxia Zhang",
      "Yan-Ying Chen",
      "David I. Inouye"
    ],
    "abstract": "Blending visual and textual concepts into a new visual concept is a unique and powerful trait of human beings that can fuel creativity. However, in practice, cross-modal conceptual blending for humans is prone to cognitive biases, like design fixation, which leads to local minima in the design space. In this paper, we propose a T2I diffusion adapter \"IT-Blender\" that can automate the blending process to enhance human creativity. Prior works related to cross-modal conceptual blending are limited in encoding a real image without loss of details or in disentangling the image and text inputs. To address these gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend the latent representations of a clean reference image with those of the noisy generated image. Combined with our novel blended attention, IT-Blender encodes the real reference image without loss of details and blends the visual concept with the object specified by the text in a disentangled way. Our experiment results show that IT-Blender outperforms the baselines by a large margin in blending visual and textual concepts, shedding light on the new application of image generative models to augment human creativity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website is available at https://imagineforme.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2506.24085v2",
    "published_date": "2025-06-30 17:41:25 UTC",
    "updated_date": "2025-07-14 13:42:45 UTC"
  },
  {
    "arxiv_id": "2507.00108v1",
    "title": "Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives",
    "authors": [
      "Clemente Rubio-Manzano",
      "Jazna Meza",
      "Rodolfo Fernandez-Santibanez",
      "Christian Vidal-Castro"
    ],
    "abstract": "Computer programming is undergoing a true transformation driven by powerful new tools for automatic source code generation based on large language models. This transformation is also manifesting in introductory programming courses at universities around the world, generating an in-depth debate about how programming content should be taught, learned, and assessed in the context of generative artificial intelligence.\n  This article aims, on the one hand, to review the most relevant studies on this issue, highlighting the advantages and disadvantages identified in the specialized literature. On the other hand, it proposes enriching teaching and learning methodologies by focusing on code comprehension and execution rather than on mere coding or program functionality. In particular, it advocates for the use of visual representations of code and visual simulations of its execution as effective tools for teaching, learning, and assessing programming, thus fostering a deeper understanding among students.\n  Finally, the opinions of students who took the object-oriented programming course are presented to provide preliminary context supporting the incorporation of visual simulations in Java (or other languages) as part of the training process.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET",
      "cs.PL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00108v1",
    "published_date": "2025-06-30 17:38:27 UTC",
    "updated_date": "2025-06-30 17:38:27 UTC"
  },
  {
    "arxiv_id": "2506.24081v1",
    "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks",
    "authors": [
      "Rahul Kumar",
      "Wenqi Wei",
      "Ying Mao",
      "Junaid Farooq",
      "Ying Wang",
      "Juntao Chen"
    ],
    "abstract": "We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to sabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks. SQUASH is executed by inserting SWAP gate(s) into the variational quantum circuit of the victim HQNN. Unlike conventional noise-based or adversarial input attacks, SQUASH directly manipulates the circuit structure, leading to qubit misalignment and disrupting quantum state evolution. This attack is highly stealthy, as it does not require access to training data or introduce detectable perturbations in input states. Our results demonstrate that SQUASH significantly degrades classification performance, with untargeted SWAP attacks reducing accuracy by up to 74.08\\% and targeted SWAP attacks reducing target class accuracy by up to 79.78\\%. These findings reveal a critical vulnerability in HQNN implementations, underscoring the need for more resilient architectures against circuit-level adversarial interventions.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Keywords: Quantum Machine Learning, Hybrid Quantum Neural Networks, SWAP Test, Fidelity, Circuit-level Attack",
    "pdf_url": "https://arxiv.org/pdf/2506.24081v1",
    "published_date": "2025-06-30 17:36:31 UTC",
    "updated_date": "2025-06-30 17:36:31 UTC"
  },
  {
    "arxiv_id": "2506.24068v2",
    "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines",
    "authors": [
      "Ian R. McKenzie",
      "Oskar J. Hollinsworth",
      "Tom Tseng",
      "Xander Davies",
      "Stephen Casper",
      "Aaron D. Tucker",
      "Robert Kirk",
      "Adam Gleave"
    ],
    "abstract": "Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus model using one such defense pipeline, and other frontier developers including Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the security of such pipelines is unclear, with limited prior work evaluating or attacking these pipelines. We address this gap by developing and red-teaming an open-source defense pipeline. First, we find that a novel few-shot-prompted input and output classifier outperforms state-of-the-art open-weight safeguard model ShieldGemma across three attacks and two datasets, reducing the attack success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second, we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on ClearHarm in a black-box attack against the few-shot-prompted classifier pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33% ASR, providing initial evidence that it is feasible to design attacks with no access to the target pipeline. We conclude by suggesting specific mitigations that developers could use to thwart staged attacks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Fixed typos (including Figure 1), amended GPU-hours rather than days, clarified ReNeLLM prompt modifications",
    "pdf_url": "https://arxiv.org/pdf/2506.24068v2",
    "published_date": "2025-06-30 17:21:08 UTC",
    "updated_date": "2025-07-18 01:26:48 UTC"
  },
  {
    "arxiv_id": "2506.24044v1",
    "title": "A Survey on Vision-Language-Action Models for Autonomous Driving",
    "authors": [
      "Sicong Jiang",
      "Zilin Huang",
      "Kangan Qian",
      "Ziang Luo",
      "Tianze Zhu",
      "Yang Zhong",
      "Yihong Tang",
      "Menglin Kong",
      "Yunlong Wang",
      "Siwen Jiao",
      "Hao Ye",
      "Zihao Sheng",
      "Xin Zhao",
      "Tuopu Wen",
      "Zheng Fu",
      "Sikai Chen",
      "Kun Jiang",
      "Diange Yang",
      "Seongjin Choi",
      "Lijun Sun"
    ],
    "abstract": "The rapid progress of multimodal large language models (MLLM) has paved the way for Vision-Language-Action (VLA) paradigms, which integrate visual perception, natural language understanding, and control within a single policy. Researchers in autonomous driving are actively adapting these methods to the vehicle domain. Such models promise autonomous vehicles that can interpret high-level instructions, reason about complex traffic scenes, and make their own decisions. However, the literature remains fragmented and is rapidly expanding. This survey offers the first comprehensive overview of VLA for Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks shared across recent work, (ii) trace the evolution from early explainer to reasoning-centric VLA models, and (iii) compare over 20 representative models according to VLA's progress in the autonomous driving domain. We also consolidate existing datasets and benchmarks, highlighting protocols that jointly measure driving safety, accuracy, and explanation quality. Finally, we detail open challenges - robustness, real-time efficiency, and formal verification - and outline future directions of VLA4AD. This survey provides a concise yet complete reference for advancing interpretable socially aligned autonomous vehicles. Github repo is available at \\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.24044v1",
    "published_date": "2025-06-30 16:50:02 UTC",
    "updated_date": "2025-06-30 16:50:02 UTC"
  },
  {
    "arxiv_id": "2506.24026v1",
    "title": "Constructing Non-Markovian Decision Process via History Aggregator",
    "authors": [
      "Yongyi Wang",
      "Wenxin Li"
    ],
    "abstract": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest as a significant impediment, especially for paradigms such as Reinforcement Learning (RL), thereby exerting far-reaching consequences on the advancement and effectiveness of the associated systems. Nevertheless, the existing benchmarks are deficient in comprehensively assessing the capacity of decision algorithms to handle non-Markovian dynamics. To address this deficiency, we have devised a generalized methodology grounded in category theory. Notably, we established the category of Markov Decision Processes (MDP) and the category of non-Markovian Decision Processes (NMDP), and proved the equivalence relationship between them. This theoretical foundation provides a novel perspective for understanding and addressing non-Markovian dynamics. We further introduced non-Markovianity into decision-making problem settings via the History Aggregator for State (HAS). With HAS, we can precisely control the state dependency structure of decision-making problems in the time series. Our analysis demonstrates the effectiveness of our method in representing a broad range of non-Markovian dynamics. This approach facilitates a more rigorous and flexible evaluation of decision algorithms by testing them in problem settings where non-Markovian dynamics are explicitly constructed.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.24026v1",
    "published_date": "2025-06-30 16:32:31 UTC",
    "updated_date": "2025-06-30 16:32:31 UTC"
  },
  {
    "arxiv_id": "2506.24018v1",
    "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks",
    "authors": [
      "Veronica Lachi",
      "Francesco Ferrini",
      "Antonio Longa",
      "Bruno Lepri",
      "Andrea Passerini",
      "Manfred Jaeger"
    ],
    "abstract": "Graph Neural Networks (GNNs) are widely used to compute representations of node pairs for downstream tasks such as link prediction. Yet, theoretical understanding of their expressive power has focused almost entirely on graph-level representations. In this work, we shift the focus to links and provide the first comprehensive study of GNN expressiveness in link representation. We introduce a unifying framework, the $k_φ$-$k_ρ$-$m$ framework, that subsumes existing message-passing link models and enables formal expressiveness comparisons. Using this framework, we derive a hierarchy of state-of-the-art methods and offer theoretical tools to analyze future architectures. To complement our analysis, we propose a synthetic evaluation protocol comprising the first benchmark specifically designed to assess link-level expressiveness. Finally, we ask: does expressiveness matter in practice? We use a graph symmetry metric that quantifies the difficulty of distinguishing links and show that while expressive models may underperform on standard benchmarks, they significantly outperform simpler ones as symmetry increases, highlighting the need for dataset-aware model selection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.24018v1",
    "published_date": "2025-06-30 16:22:15 UTC",
    "updated_date": "2025-06-30 16:22:15 UTC"
  },
  {
    "arxiv_id": "2506.24016v1",
    "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations",
    "authors": [
      "Hyunjong Kim",
      "Sangyeop Kim",
      "Jongheon Jeong",
      "Yeongjae Cho",
      "Sungzoon Cho"
    ],
    "abstract": "Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains unverified. In this paper, we propose EXPERT, a reference-free evaluation metric that provides structured explanations based on three fundamental criteria: fluency, relevance, and descriptiveness. By constructing large-scale datasets of high-quality structured explanations, we develop a two-stage evaluation template to effectively supervise a vision-language model for both scoring and explanation generation. EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation. Our code and datasets are available at https://github.com/hjkim811/EXPERT.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2025 Findings",
    "pdf_url": "https://arxiv.org/pdf/2506.24016v1",
    "published_date": "2025-06-30 16:20:51 UTC",
    "updated_date": "2025-06-30 16:20:51 UTC"
  },
  {
    "arxiv_id": "2506.24009v1",
    "title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems",
    "authors": [
      "Xinquan Wang",
      "Fenghao Zhu",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Xiaoming Chen",
      "Zhaoyang Zhang",
      "Sami Muhaidat",
      "Mérouane Debbah"
    ],
    "abstract": "Large artificial intelligence (AI) models offer revolutionary potential for future wireless systems, promising unprecedented capabilities in network optimization and performance. However, current paradigms largely overlook crucial physical interactions. This oversight means they primarily rely on offline datasets, leading to difficulties in handling real-time wireless dynamics and non-stationary environments. Furthermore, these models often lack the capability for active environmental probing. This paper proposes a fundamental paradigm shift towards wireless embodied large AI (WELAI), moving from passive observation to active embodiment. We first identify key challenges faced by existing models, then we explore the design principles and system structure of WELAI. Besides, we outline prospective applications in next-generation wireless. Finally, through an illustrative case study, we demonstrate the effectiveness of WELAI and point out promising research directions for realizing adaptive, robust, and autonomous wireless systems.",
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "primary_category": "cs.IT",
    "comment": "7 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.24009v1",
    "published_date": "2025-06-30 16:13:55 UTC",
    "updated_date": "2025-06-30 16:13:55 UTC"
  },
  {
    "arxiv_id": "2506.23995v1",
    "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems",
    "authors": [
      "Mingfei Cheng",
      "Renzhi Wang",
      "Xiaofei Xie",
      "Yuan Zhou",
      "Lei Ma"
    ],
    "abstract": "Autonomous Driving System (ADS) testing is essential to ensure the safety and reliability of autonomous vehicles (AVs) before deployment. However, existing techniques primarily focus on evaluating ADS functionalities in single-AV settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes crucial to assess their cooperative performance, particularly regarding deadlocks, a fundamental coordination failure in which multiple AVs enter a circular waiting state indefinitely, resulting in motion planning failures. Despite its importance, the cooperative capability of ADSs to prevent deadlocks remains insufficiently underexplored. To address this gap, we propose the first dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique, STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs controlled by the ADS under test are in a circular wait state. STCLocker consists of three key components: Deadlock Oracle, Conflict Feedback, and Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable black-box mechanism for detecting deadlock cycles among multiple AVs within a given scenario. Conflict Feedback and Conflict-aware Scenario Generation collaborate to actively guide AVs into simultaneous competition over spatial conflict resources (i.e., shared passing regions) and temporal competitive behaviors (i.e., reaching the conflict region at the same time), thereby increasing the effectiveness of generating conflict-prone deadlocks. We evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA, a module-based ADS supporting cooperative communication. Experimental results show that, on average, STCLocker generates more DLS than the best-performing baseline.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23995v1",
    "published_date": "2025-06-30 15:58:10 UTC",
    "updated_date": "2025-06-30 15:58:10 UTC"
  },
  {
    "arxiv_id": "2506.23992v1",
    "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health",
    "authors": [
      "Aditya Shrivastava",
      "Komal Gupta",
      "Shraddha Arora"
    ],
    "abstract": "The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "14 page , 2 image , 2 tables , accepted under 5th International Conference on Innovations in Computational Intelligence and Computer Vision (ICICV-2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.23992v1",
    "published_date": "2025-06-30 15:55:41 UTC",
    "updated_date": "2025-06-30 15:55:41 UTC"
  },
  {
    "arxiv_id": "2506.23960v1",
    "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning",
    "authors": [
      "Mingfei Cheng",
      "Xiaofei Xie",
      "Renzhi Wang",
      "Yuan Zhou",
      "Ming Hu"
    ],
    "abstract": "Autonomous Driving Systems (ADSs) continue to face safety-critical risks due to the inherent limitations in their design and performance capabilities. Online repair plays a crucial role in mitigating such limitations, ensuring the runtime safety and reliability of ADSs. Existing online repair solutions enforce ADS compliance by transforming unacceptable trajectories into acceptable ones based on predefined specifications, such as rule-based constraints or training datasets. However, these approaches often lack generalizability, adaptability and tend to be overly conservative, resulting in ineffective repairs that not only fail to mitigate safety risks sufficiently but also degrade the overall driving experience. To address this issue, we propose Adaptive Decision Repair (ADReFT), a novel and effective repair method that identifies safety-critical states through offline learning from failed tests and generates appropriate mitigation actions to improve ADS safety. Specifically, ADReFT incorporates a transformer-based model with two joint heads, State Monitor and Decision Adapter, designed to capture complex driving environment interactions to evaluate state safety severity and generate adaptive repair actions. Given the absence of oracles for state safety identification, we first pretrain ADReFT using supervised learning with coarse annotations, i.e., labeling states preceding violations as positive samples and others as negative samples. It establishes ADReFT's foundational capability to mitigate safety-critical violations, though it may result in somewhat conservative mitigation strategies. Therefore, we subsequently finetune ADReFT using reinforcement learning to improve its initial capability and generate more precise and contextually appropriate repair decisions. Our evaluation results illustrate that ADReFT achieves better repair performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23960v1",
    "published_date": "2025-06-30 15:29:36 UTC",
    "updated_date": "2025-06-30 15:29:36 UTC"
  },
  {
    "arxiv_id": "2506.23952v3",
    "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support",
    "authors": [
      "Stefan Buijsman",
      "Sarah E. Carter",
      "Juan Pablo Bermúdez"
    ],
    "abstract": "AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "econ.GN"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23952v3",
    "published_date": "2025-06-30 15:20:10 UTC",
    "updated_date": "2025-07-09 09:55:27 UTC"
  },
  {
    "arxiv_id": "2506.23949v1",
    "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models",
    "authors": [
      "Anthony M. Barrett",
      "Jessica Newman",
      "Brandie Nonnecke",
      "Nada Madkour",
      "Dan Hendrycks",
      "Evan R. Murphy",
      "Krystal Jackson",
      "Deepika Raman"
    ],
    "abstract": "Increasingly multi-purpose AI models, such as cutting-edge large language models or other 'general-purpose AI' (GPAI) models, 'foundation models,' generative AI models, and 'frontier models' (typically all referred to hereafter with the umbrella term 'GPAI/foundation models' except where greater specificity is needed), can provide many beneficial capabilities but also risks of adverse events with profound consequences. This document provides risk-management practices or controls for identifying, analyzing, and mitigating risks of GPAI/foundation models. We intend this document primarily for developers of large-scale, state-of-the-art GPAI/foundation models; others that can benefit from this guidance include downstream developers of end-use applications that build on a GPAI/foundation model. This document facilitates conformity with or use of leading AI risk management-related standards, adapting and building on the generic voluntary guidance in the NIST AI Risk Management Framework and ISO/IEC 23894, with a focus on the unique issues faced by developers of GPAI/foundation models.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23949v1",
    "published_date": "2025-06-30 15:18:18 UTC",
    "updated_date": "2025-06-30 15:18:18 UTC"
  },
  {
    "arxiv_id": "2506.23944v2",
    "title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning",
    "authors": [
      "Fuhang Kuang",
      "Jiacheng You",
      "Yingdong Hu",
      "Tong Zhang",
      "Chuan Wen",
      "Yang Gao"
    ],
    "abstract": "Imitation learning models for robotic tasks typically rely on multi-modal inputs, such as RGB images, language, and proprioceptive states. While proprioception is intuitively important for decision-making and obstacle avoidance, simply incorporating all proprioceptive states leads to a surprising degradation in imitation learning performance. In this work, we identify the underlying issue as the proprioception shift problem, where the distributions of proprioceptive states diverge significantly between training and deployment. To address this challenge, we propose a domain adaptation framework that bridges the gap by utilizing rollout data collected during deployment. Using Wasserstein distance, we quantify the discrepancy between expert and rollout proprioceptive states and minimize this gap by adding noise to both sets of states, proportional to the Wasserstein distance. This strategy enhances robustness against proprioception shifts by aligning the training and deployment distributions. Experiments on robotic manipulation tasks demonstrate the efficacy of our method, enabling the imitation policy to leverage proprioception while mitigating its adverse effects. Our approach outperforms the naive solution which discards proprioception, and other baselines designed to address distributional shifts.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Need further modification",
    "pdf_url": "https://arxiv.org/pdf/2506.23944v2",
    "published_date": "2025-06-30 15:09:14 UTC",
    "updated_date": "2025-07-01 01:36:05 UTC"
  },
  {
    "arxiv_id": "2507.02969v1",
    "title": "Reinforcement Learning for Automated Cybersecurity Penetration Testing",
    "authors": [
      "Daniel López-Montero",
      "José L. Álvarez-Aldana",
      "Alicia Morales-Martínez",
      "Marta Gil-López",
      "Juan M. Auñón García"
    ],
    "abstract": "This paper aims to provide an innovative machine learning-based solution to automate security testing tasks for web applications, ensuring the correct functioning of all components while reducing project maintenance costs. Reinforcement Learning is proposed to select and prioritize tools and optimize the testing path. The presented approach utilizes a simulated webpage along with its network topology to train the agent. Additionally, the model leverages Geometric Deep Learning to create priors that reduce the search space and improve learning convergence. The validation and testing process was conducted on real-world vulnerable web pages commonly used by human hackers for learning. As a result of this study, a reinforcement learning algorithm was developed that maximizes the number of vulnerabilities found while minimizing the number of steps required",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02969v1",
    "published_date": "2025-06-30 15:06:17 UTC",
    "updated_date": "2025-06-30 15:06:17 UTC"
  },
  {
    "arxiv_id": "2506.23934v1",
    "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference",
    "authors": [
      "Xiangchen Li",
      "Saeid Ghafouri",
      "Bo Ji",
      "Hans Vandierendonck",
      "Deepu John",
      "Dimitrios S. Nikolopoulos"
    ],
    "abstract": "As machine learning inferences increasingly move to edge devices, adapting to diverse computational capabilities, hardware, and memory constraints becomes more critical. Instead of relying on a pre-trained model fixed for all future inference queries across diverse edge devices, we argue that planning an inference pattern with a request-specific model tailored to the device's computational capacity, accuracy requirements, and time constraints is more cost-efficient and robust to diverse scenarios. To this end, we propose an accuracy-aware and workload-balanced inference system that integrates joint model quantization and inference partitioning. In this approach, the server dynamically responds to inference queries by sending a quantized model and adaptively sharing the inference workload with the device. Meanwhile, the device's computational power, channel capacity, and accuracy requirements are considered when deciding.\n  Furthermore, we introduce a new optimization framework for the inference system, incorporating joint model quantization and partitioning. Our approach optimizes layer-wise quantization bit width and partition points to minimize time consumption and cost while accounting for varying accuracy requirements of tasks through an accuracy degradation metric in our optimization model. To our knowledge, this work represents the first exploration of optimizing quantization layer-wise bit-width in the inference serving system, by introducing theoretical measurement of accuracy degradation. Simulation results demonstrate a substantial reduction in overall time and power consumption, with computation payloads decreasing by over 80% and accuracy degradation kept below 1%.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23934v1",
    "published_date": "2025-06-30 15:03:35 UTC",
    "updated_date": "2025-06-30 15:03:35 UTC"
  },
  {
    "arxiv_id": "2506.23930v1",
    "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages",
    "authors": [
      "Ruhina Tabasshum Prome",
      "Tarikul Islam Tamiti",
      "Anomadarshi Barua"
    ],
    "abstract": "The rapid expansion of social media leads to a marked increase in hate speech, which threatens personal lives and results in numerous hate crimes. Detecting hate speech presents several challenges: diverse dialects, frequent code-mixing, and the prevalence of misspelled words in user-generated content on social media platforms. Recent progress in hate speech detection is typically concentrated on high-resource languages. However, low-resource languages still face significant challenges due to the lack of large-scale, high-quality datasets. This paper investigates how we can overcome this limitation via prompt engineering on large language models (LLMs) focusing on low-resource Bengali language. We investigate six prompting strategies - zero-shot prompting, refusal suppression, flattering the classifier, multi-shot prompting, role prompting, and finally our innovative metaphor prompting to detect hate speech effectively in low-resource languages. We pioneer the metaphor prompting to circumvent the built-in safety mechanisms of LLMs that marks a significant departure from existing jailbreaking methods. We investigate all six different prompting strategies on the Llama2-7B model and compare the results extensively with three pre-trained word embeddings - GloVe, Word2Vec, and FastText for three different deep learning models - multilayer perceptron (MLP), convolutional neural network (CNN), and bidirectional gated recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in the low-resource Bengali language, we also evaluate it in another low-resource language - Hindi, and two high-resource languages - English and German. The performance of all prompting techniques is evaluated using the F1 score, and environmental impact factor (IF), which measures CO$_2$ emissions, electricity usage, and computational time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23930v1",
    "published_date": "2025-06-30 14:59:25 UTC",
    "updated_date": "2025-06-30 14:59:25 UTC"
  },
  {
    "arxiv_id": "2507.02968v1",
    "title": "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing",
    "authors": [
      "Vijayalakshmi Ramasamy",
      "Seth Barrett",
      "Gokila Dorai",
      "Jessica Zumbach"
    ],
    "abstract": "Privacy policy documents are often lengthy, complex, and difficult for non-expert users to interpret, leading to a lack of transparency regarding the collection, processing, and sharing of personal data. As concerns over online privacy grow, it is essential to develop automated tools capable of analyzing privacy policies and identifying potential risks. In this study, we explore the potential of interactive graph visualizations to enhance user understanding of privacy policies by representing policy terms as structured graph models. This approach makes complex relationships more accessible and enables users to make informed decisions about their personal data (RQ1). We also employ graph mining algorithms to identify key themes, such as User Activity and Device Information, using dimensionality reduction techniques like t-SNE and PCA to assess clustering effectiveness. Our findings reveal that graph-based clustering improves policy content interpretability. It highlights patterns in user tracking and data sharing, which supports forensic investigations and identifies regulatory non-compliance. This research advances AI-driven tools for auditing privacy policies by integrating interactive visualizations with graph mining. Enhanced transparency fosters accountability and trust.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 Pages; 1 Algorithm; 1 Table; 2 Figures; Accepted by AIRC 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.02968v1",
    "published_date": "2025-06-30 14:55:57 UTC",
    "updated_date": "2025-06-30 14:55:57 UTC"
  },
  {
    "arxiv_id": "2506.23926v1",
    "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system",
    "authors": [
      "Junping Wang",
      "Bicheng Wang",
      "Yibo Xuea",
      "Yuan Xie"
    ],
    "abstract": "Resilience non-equilibrium measurement, the ability to maintain fundamental functionality amidst failures and errors, is crucial for scientific management and engineering applications of industrial chain. The problem is particularly challenging when the number or types of multiple co-evolution of resilience (for example, randomly placed) are extremely chaos. Existing end-to-end deep learning ordinarily do not generalize well to unseen full-feld reconstruction of spatiotemporal co-evolution structure, and predict resilience of network topology, especially in multiple chaos data regimes typically seen in real-world applications. To address this challenge, here we propose industrial brain, a human-like autonomous cognitive decision-making and planning framework integrating higher-order activity-driven neuro network and CT-OODA symbolic reasoning to autonomous plan resilience directly from observational data of global variable. The industrial brain not only understands and model structure of node activity dynamics and network co-evolution topology without simplifying assumptions, and reveal the underlying laws hidden behind complex networks, but also enabling accurate resilience prediction, inference, and planning. Experimental results show that industrial brain significantly outperforms resilience prediction and planning methods, with an accurate improvement of up to 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension reduction. It also generalizes to unseen topologies and dynamics and maintains robust performance despite observational disturbances. Our findings suggest that industrial brain addresses an important gap in resilience prediction and planning for industrial chain.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23926v1",
    "published_date": "2025-06-30 14:54:52 UTC",
    "updated_date": "2025-06-30 14:54:52 UTC"
  },
  {
    "arxiv_id": "2506.23924v1",
    "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice",
    "authors": [
      "Akshit Kumar",
      "Tianyi Peng",
      "Yuhang Wu",
      "Assaf Zeevi"
    ],
    "abstract": "Large language models (LLMs) have exhibited expert-level capabilities across various domains. However, their abilities to solve problems in Operations Research (OR) -- the analysis and optimization of mathematical models derived from real-world problems or their verbal descriptions -- remain underexplored. In this work, we take a first step toward evaluating LLMs' abilities to solve stochastic modeling problems, a core class of OR problems characterized by uncertainty and typically involving tools from probability, statistics, and stochastic processes. We manually procure a representative set of graduate-level homework and doctoral qualification-exam problems and test LLMs' abilities to solve them. We further leverage SimOpt, an open-source library of simulation-optimization problems and solvers, to investigate LLMs' abilities to make real-world decisions under uncertainty. Our results show that, though a nontrivial amount of work is still needed to reliably automate the stochastic modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom and practical settings. These findings highlight the potential of building AI agents that assist OR researchers and amplify the real-world impact of OR through automation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23924v1",
    "published_date": "2025-06-30 14:54:15 UTC",
    "updated_date": "2025-06-30 14:54:15 UTC"
  },
  {
    "arxiv_id": "2506.23923v1",
    "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System",
    "authors": [
      "Miguel Camacho-Sánchez",
      "Fernando García-Torres",
      "Jesper John Lisegaard",
      "Rocío del Amor",
      "Sankhya Mohanty",
      "Valery Naranjo"
    ],
    "abstract": "Resin infusion (RI) and resin transfer moulding (RTM) are critical processes for the manufacturing of high-performance fibre-reinforced polymer composites, particularly for large-scale applications such as wind turbine blades. Controlling the resin flow dynamics in these processes is critical to ensure the uniform impregnation of the fibre reinforcements, thereby preventing residual porosities and dry spots that impact the consequent structural integrity of the final component. This paper presents a reinforcement learning (RL) based strategy, established using process simulations, for synchronising the different resin flow fronts in an infusion scenario involving two resin inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our approach addresses the challenge of managing the fluid dynamics in a partially observable environment. The results demonstrate the effectiveness of the RL approach in achieving an accurate flow convergence, highlighting its potential towards improving process control and product quality in composites manufacturing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures, 45th Risø International Symposium on Materials Science",
    "pdf_url": "https://arxiv.org/pdf/2506.23923v1",
    "published_date": "2025-06-30 14:50:18 UTC",
    "updated_date": "2025-06-30 14:50:18 UTC"
  },
  {
    "arxiv_id": "2507.02967v1",
    "title": "YOLO-Based Pipeline Monitoring in Challenging Visual Environments",
    "authors": [
      "Pragya Dhungana",
      "Matteo Fresta",
      "Niraj Tamrakar",
      "Hariom Dhungana"
    ],
    "abstract": "Condition monitoring subsea pipelines in low-visibility underwater environments poses significant challenges due to turbidity, light distortion, and image degradation. Traditional visual-based inspection systems often fail to provide reliable data for mapping, object recognition, or defect detection in such conditions. This study explores the integration of advanced artificial intelligence (AI) techniques to enhance image quality, detect pipeline structures, and support autonomous fault diagnosis. This study conducts a comparative analysis of two most robust versions of YOLOv8 and Yolov11 and their three variants tailored for image segmentation tasks in complex and low-visibility subsea environments. Using pipeline inspection datasets captured beneath the seabed, it evaluates model performance in accurately delineating target structures under challenging visual conditions. The results indicated that YOLOv11 outperformed YOLOv8 in overall performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02967v1",
    "published_date": "2025-06-30 14:47:30 UTC",
    "updated_date": "2025-06-30 14:47:30 UTC"
  },
  {
    "arxiv_id": "2507.02966v2",
    "title": "PBa-LLM: Privacy- and Bias-aware NLP using Named-Entity Recognition (NER)",
    "authors": [
      "Gonzalo Mancera",
      "Aythami Morales",
      "Julian Fierrez",
      "Ruben Tolosana",
      "Alejandro Penna",
      "Miguel Lopez-Duran",
      "Francisco Jurado",
      "Alvaro Ortigosa"
    ],
    "abstract": "The use of Natural Language Processing (NLP) in highstakes AI-based applications has increased significantly in recent years, especially since the emergence of Large Language Models (LLMs). However, despite their strong performance, LLMs introduce important legal/ ethical concerns, particularly regarding privacy, data protection, and transparency. Due to these concerns, this work explores the use of Named- Entity Recognition (NER) to facilitate the privacy-preserving training (or adaptation) of LLMs. We propose a framework that uses NER technologies to anonymize sensitive information in text data, such as personal identities or geographic locations. An evaluation of the proposed privacy-preserving learning framework was conducted to measure its impact on user privacy and system performance in a particular high-stakes and sensitive setup: AI-based resume scoring for recruitment processes. The study involved two language models (BERT and RoBERTa) and six anonymization algorithms (based on Presidio, FLAIR, BERT, and different versions of GPT) applied to a database of 24,000 candidate profiles. The findings indicate that the proposed privacy preservation techniques effectively maintain system performance while playing a critical role in safeguarding candidate confidentiality, thus promoting trust in the experimented scenario. On top of the proposed privacy-preserving approach, we also experiment applying an existing approach that reduces the gender bias in LLMs, thus finally obtaining our proposed Privacyand Bias-aware LLMs (PBa-LLMs). Note that the proposed PBa-LLMs have been evaluated in a particular setup (resume scoring), but are generally applicable to any other LLM-based AI application.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI) 2025, Philadelphia, PA, USA, March 2025",
    "pdf_url": "https://arxiv.org/pdf/2507.02966v2",
    "published_date": "2025-06-30 14:42:49 UTC",
    "updated_date": "2025-07-09 08:02:08 UTC"
  },
  {
    "arxiv_id": "2506.23908v1",
    "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence",
    "authors": [
      "András György",
      "Tor Lattimore",
      "Nevena Lazić",
      "Csaba Szepesvári"
    ],
    "abstract": "Sound deductive reasoning -- the ability to derive new knowledge from existing facts and rules -- is an indisputably desirable aspect of general intelligence. Despite the major advances of AI systems in areas such as math and science, especially since the introduction of transformer architectures, it is well-documented that even the most advanced frontier systems regularly and consistently falter on easily-solvable deductive reasoning tasks. Hence, these systems are unfit to fulfill the dream of achieving artificial general intelligence capable of sound deductive reasoning. We argue that their unsound behavior is a consequence of the statistical learning approach powering their development. To overcome this, we contend that to achieve reliable deductive reasoning in learning-based AI systems, researchers must fundamentally shift from optimizing for statistical performance against distributions on reasoning problems and algorithmic tasks to embracing the more ambitious exact learning paradigm, which demands correctness on all inputs. We argue that exact learning is both essential and possible, and that this ambitious objective should guide algorithm design.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23908v1",
    "published_date": "2025-06-30 14:37:50 UTC",
    "updated_date": "2025-06-30 14:37:50 UTC"
  },
  {
    "arxiv_id": "2506.23903v3",
    "title": "Grounding DINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models",
    "authors": [
      "Hamza Rasaee",
      "Taha Koleilat",
      "Hassan Rivaz"
    ],
    "abstract": "Accurate and generalizable object segmentation in ultrasound imaging remains a significant challenge due to anatomical variability, diverse imaging protocols, and limited annotated data. In this study, we propose a prompt-driven vision-language model (VLM) that integrates Grounding DINO with SAM2 (Segment Anything Model2) to enable object segmentation across multiple ultrasound organs. A total of 18 public ultrasound datasets, encompassing the breast, thyroid, liver, prostate, kidney, and paraspinal muscle, were utilized. These datasets were divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for testing to evaluate performance in unseen distributions. Comprehensive experiments demonstrate that our approach outperforms state-of-the-art segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse, and SAMUS on most seen datasets while maintaining strong performance on unseen datasets without additional fine-tuning. These results underscore the promise of VLMs in scalable and robust ultrasound image analysis, reducing dependence on large, organ-specific annotated datasets. We will publish our code on code.sonography.ai after acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 3 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2506.23903v3",
    "published_date": "2025-06-30 14:33:44 UTC",
    "updated_date": "2025-09-08 19:18:30 UTC"
  },
  {
    "arxiv_id": "2507.00102v1",
    "title": "Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series",
    "authors": [
      "Bernd Hofmann",
      "Patrick Bruendl",
      "Huong Giang Nguyen",
      "Joerg Franke"
    ],
    "abstract": "Ensuring consistent product quality in modern manufacturing is crucial, particularly in safety-critical applications. Conventional quality control approaches, reliant on manually defined thresholds and features, lack adaptability to the complexity and variability inherent in production data and necessitate extensive domain expertise. Conversely, data-driven methods, such as machine learning, demonstrate high detection performance but typically function as black-box models, thereby limiting their acceptance in industrial environments where interpretability is paramount. This paper introduces a methodology for industrial fault detection, which is both data-driven and transparent. The approach integrates a supervised machine learning model for multi-class fault classification, Shapley Additive Explanations for post-hoc interpretability, and a do-main-specific visualisation technique that maps model explanations to operator-interpretable features. Furthermore, the study proposes an evaluation methodology that assesses model explanations through quantitative perturbation analysis and evaluates visualisations by qualitative expert assessment. The approach was applied to the crimping process, a safety-critical joining technique, using a dataset of univariate, discrete time series. The system achieves a fault detection accuracy of 95.9 %, and both quantitative selectivity analysis and qualitative expert evaluations confirmed the relevance and inter-pretability of the generated explanations. This human-centric approach is designed to enhance trust and interpretability in data-driven fault detection, thereby contributing to applied system design in industrial quality control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00102v1",
    "published_date": "2025-06-30 14:11:48 UTC",
    "updated_date": "2025-06-30 14:11:48 UTC"
  },
  {
    "arxiv_id": "2506.23875v1",
    "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic",
    "authors": [
      "Yuta Sato",
      "Kazuhiko Kawamoto",
      "Hiroshi Kera"
    ],
    "abstract": "The chain of thought is fundamental in Transformers, which is to perform step-by-step reasoning. Besides what intermediate steps work, the order of these steps critically affects the difficulty of the reasoning. This study addresses a novel task of unraveling chain of thought - reordering decoder input tokens to a learning-friendly sequence for Transformers to learn arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture of target sequences arranged in different orders and then identifies benign orders as those with fast loss drops in the early stage. As the search space grows factorially with sequence length, we propose a two-stage hierarchical approach for inter- and intra-block reordering. Experiments on four order-sensitive arithmetic tasks show that our method identifies a learning-friendly order out of a few billion candidates. Notably, on the multiplication task, it recovered the reverse-digit order reported in prior studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23875v1",
    "published_date": "2025-06-30 14:05:53 UTC",
    "updated_date": "2025-06-30 14:05:53 UTC"
  },
  {
    "arxiv_id": "2506.23869v1",
    "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance",
    "authors": [
      "Louis Bradshaw",
      "Honglu Fan",
      "Alexander Spangher",
      "Stella Biderman",
      "Simon Colton"
    ],
    "abstract": "We study the capabilities of generative autoregressive transformer models trained on large amounts of symbolic solo-piano transcriptions. After first pretraining on approximately 60,000 hours of music, we use a comparatively smaller, high-quality subset, to finetune models to produce musical continuations, perform symbolic classification tasks, and produce general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to symbolic music. When evaluating piano continuation coherence, our generative model outperforms leading symbolic generation techniques and remains competitive with proprietary audio generation models. On MIR classification benchmarks, frozen representations from our contrastive model achieve state-of-the-art results in linear probe experiments, while direct finetuning demonstrates the generalizability of pretrained representations, often requiring only a few hundred labeled examples to specialize to downstream tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "ISMIR (2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.23869v1",
    "published_date": "2025-06-30 14:00:14 UTC",
    "updated_date": "2025-06-30 14:00:14 UTC"
  },
  {
    "arxiv_id": "2506.23855v1",
    "title": "Differentially Private Synthetic Data Release for Topics API Outputs",
    "authors": [
      "Travis Dick",
      "Alessandro Epasto",
      "Adel Javanmard",
      "Josh Karlin",
      "Andres Munoz Medina",
      "Vahab Mirrokni",
      "Sergei Vassilvitskii",
      "Peilin Zhong"
    ],
    "abstract": "The analysis of the privacy properties of Privacy-Preserving Ads APIs is an area of research that has received strong interest from academics, industry, and regulators. Despite this interest, the empirical study of these methods is hindered by the lack of publicly available data. Reliable empirical analysis of the privacy properties of an API, in fact, requires access to a dataset consisting of realistic API outputs; however, privacy concerns prevent the general release of such data to the public.\n  In this work, we develop a novel methodology to construct synthetic API outputs that are simultaneously realistic enough to enable accurate study and provide strong privacy protections. We focus on one Privacy-Preserving Ads APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a methodology to generate a differentially-private dataset that closely matches the re-identification risk properties of the real Topics API data. The use of differential privacy provides strong theoretical bounds on the leakage of private user information from this release.\n  Our methodology is based on first computing a large number of differentially-private statistics describing how output API traces evolve over time. Then, we design a parameterized distribution over sequences of API traces and optimize its parameters so that they closely match the statistics obtained. Finally, we create the synthetic data by drawing from this distribution.\n  Our work is complemented by an open-source release of the anonymized dataset obtained by this methodology. We hope this will enable external researchers to analyze the API in-depth and replicate prior and future work on a realistic large-scale dataset. We believe that this work will contribute to fostering transparency regarding the privacy properties of Privacy-Preserving Ads APIs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23855v1",
    "published_date": "2025-06-30 13:46:57 UTC",
    "updated_date": "2025-06-30 13:46:57 UTC"
  },
  {
    "arxiv_id": "2506.23845v1",
    "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts",
    "authors": [
      "Kenny Peng",
      "Rajiv Movva",
      "Jon Kleinberg",
      "Emma Pierson",
      "Nikhil Garg"
    ],
    "abstract": "While sparse autoencoders (SAEs) have generated significant excitement, a series of negative results have added to skepticism about their usefulness. Here, we establish a conceptual distinction that reconciles competing narratives surrounding SAEs. We argue that while SAEs may be less effective for acting on known concepts, SAEs are powerful tools for discovering unknown concepts. This distinction cleanly separates existing negative and positive results, and suggests several classes of SAE applications. Specifically, we outline use cases for SAEs in (i) ML interpretability, explainability, fairness, auditing, and safety, and (ii) social and health sciences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23845v1",
    "published_date": "2025-06-30 13:35:56 UTC",
    "updated_date": "2025-06-30 13:35:56 UTC"
  },
  {
    "arxiv_id": "2506.23844v1",
    "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents",
    "authors": [
      "Hang Su",
      "Jun Luo",
      "Chang Liu",
      "Xiao Yang",
      "Yichi Zhang",
      "Yinpeng Dong",
      "Jun Zhu"
    ],
    "abstract": "Recent advances in large language models (LLMs) have catalyzed the rise of autonomous AI agents capable of perceiving, reasoning, and acting in dynamic, open-ended environments. These large-model agents mark a paradigm shift from static inference systems to interactive, memory-augmented entities. While these capabilities significantly expand the functional scope of AI, they also introduce qualitatively novel security risks - such as memory poisoning, tool misuse, reward hacking, and emergent misalignment - that extend beyond the threat models of conventional systems or standalone LLMs. In this survey, we first examine the structural foundations and key capabilities that underpin increasing levels of agent autonomy, including long-term memory retention, modular tool use, recursive planning, and reflective reasoning. We then analyze the corresponding security vulnerabilities across the agent stack, identifying failure modes such as deferred decision hazards, irreversible tool chains, and deceptive behaviors arising from internal state drift or value misalignment. These risks are traced to architectural fragilities that emerge across perception, cognition, memory, and action modules. To address these challenges, we systematically review recent defense strategies deployed at different autonomy layers, including input sanitization, memory lifecycle control, constrained decision-making, structured tool invocation, and introspective reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a unified cognitive framework grounded in Constrained Markov Decision Processes (CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation, and joint reward-risk optimization to enable principled, proactive safety across the agent's decision-making loop.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages",
    "pdf_url": "https://arxiv.org/pdf/2506.23844v1",
    "published_date": "2025-06-30 13:34:34 UTC",
    "updated_date": "2025-06-30 13:34:34 UTC"
  },
  {
    "arxiv_id": "2506.23840v1",
    "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model",
    "authors": [
      "Bowen Ding",
      "Yuhan Chen",
      "Futing Wang",
      "Lingfeng Ming",
      "Tao Lin"
    ],
    "abstract": "Large Reasoning Models (LRMs) excel at solving complex problems but face an overthinking dilemma. When handling simple tasks, they often produce verbose responses overloaded with thinking tokens (e.g., wait, however). These tokens trigger unnecessary high-level reasoning behaviors like reflection and backtracking, reducing efficiency. In this work, our pilot study reveals that these thinking-token-induced behaviors are not essential for effective problem-solving and may even hinder correct reasoning within constrained token budgets. We identify this phenomenon as the thinking trap. To mitigate this issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel algorithm featuring: (1) A rollout sampling strategy that guarantees balanced exposure to responses with and without thinking tokens; (2) A fine-grained advantage control technique to dynamically regulate the prediction of target tokens; (3) A policy shaping method ensuring stable gradient contributions from thinking tokens. Experimental results on five popular math reasoning benchmarks show that DuP-PO performs well on the popular LRM, which significantly improves their token efficiency during reasoning, while achieving superior performance of the base model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23840v1",
    "published_date": "2025-06-30 13:30:33 UTC",
    "updated_date": "2025-06-30 13:30:33 UTC"
  },
  {
    "arxiv_id": "2506.23826v1",
    "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins",
    "authors": [
      "Lluís C. Coll",
      "Martin W. Lauer-Schmaltz",
      "Philip Cash",
      "John P. Hansen",
      "Anja Maier"
    ],
    "abstract": "Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.ET",
    "comment": "24 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23826v1",
    "published_date": "2025-06-30 13:18:31 UTC",
    "updated_date": "2025-06-30 13:18:31 UTC"
  },
  {
    "arxiv_id": "2507.02965v1",
    "title": "Concept-based Adversarial Attack: a Probabilistic Perspective",
    "authors": [
      "Andi Zhang",
      "Xuan Ding",
      "Steven McDonagh",
      "Samuel Kaski"
    ],
    "abstract": "We propose a concept-based adversarial attack framework that extends beyond single-image perturbations by adopting a probabilistic perspective. Rather than modifying a single image, our method operates on an entire concept -- represented by a probabilistic generative model or a set of images -- to generate diverse adversarial examples. Preserving the concept is essential, as it ensures that the resulting adversarial images remain identifiable as instances of the original underlying category or identity. By sampling from this concept-based adversarial distribution, we generate images that maintain the original concept but vary in pose, viewpoint, or background, thereby misleading the classifier. Mathematically, this framework remains consistent with traditional adversarial attacks in a principled manner. Our theoretical and empirical results demonstrate that concept-based adversarial attacks yield more diverse adversarial examples and effectively preserve the underlying concept, while achieving higher attack efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02965v1",
    "published_date": "2025-06-30 13:18:15 UTC",
    "updated_date": "2025-06-30 13:18:15 UTC"
  },
  {
    "arxiv_id": "2506.23815v2",
    "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment",
    "authors": [
      "Patrick Stokkink"
    ],
    "abstract": "The influence of Artificial Intelligence (AI), and specifically Large Language Models (LLM), on education is continuously increasing. These models are frequently used by students, giving rise to the question whether current forms of assessment are still a valid way to evaluate student performance and comprehension. The theoretical framework developed in this paper is grounded in Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning objectives. We argue that AI influences learning objectives of different Bloom levels in a different way, and assessment has to be adopted accordingly. Furthermore, in line with Bloom's vision, formative and summative assessment should be aligned on whether the use of AI is permitted or not.\n  Although lecturers tend to agree that education and assessment need to be adapted to the presence of AI, a strong bias exists on the extent to which lecturers want to allow for AI in assessment. This bias is caused by a lecturer's familiarity with AI and specifically whether they use it themselves. To avoid this bias, we propose structured guidelines on a university or faculty level, to foster alignment among the staff. Besides that, we argue that teaching staff should be trained on the capabilities and limitations of AI tools. In this way, they are better able to adapt their assessment methods.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23815v2",
    "published_date": "2025-06-30 13:02:01 UTC",
    "updated_date": "2025-07-01 07:51:20 UTC"
  },
  {
    "arxiv_id": "2507.02964v1",
    "title": "Less Data, More Security: Advancing Cybersecurity LLMs Specialization via Resource-Efficient Domain-Adaptive Continuous Pre-training with Minimal Tokens",
    "authors": [
      "Salahuddin Salahuddin",
      "Ahmed Hussain",
      "Jussi Löppönen",
      "Toni Jutila",
      "Panos Papadimitratos"
    ],
    "abstract": "While Large Language Models (LLMs) demonstrate exceptional natural language capabilities, general-purpose models lack specialized domain knowledge for effective cybersecurity analysis. In this work, we investigate Domain-Adaptive Continuous Pretraining (DAP) as a methodology for enhancing cybersecurity understanding in pretrained LLMs while preserving general language capabilities. We systematically adapted three decoder-based architectures -- Llama-3.1-8B, DeepSeek-R1-Distill-Qwen-14B, and Llama-3.3-70B-Instruct -- using a curated 126-million-word cybersecurity corpus from standards, academic literature, and various other sources. Our approach employed constrained training parameters and distributed FSDP training to balance domain specialization with knowledge preservation. Evaluation across three cybersecurity benchmarks, namely, CTI-MCQ, CyberMetric, and SecEval, demonstrates consistent improvements post-adaptation. The Llama-3.3-70B-Ins-DAP model achieved state-of-the-art accuracies of 0.718, 0.933, and 0.864, respectively, outperforming specialized models, including Llama-Primus-Base. Notably, competitive performance was achieved using substantially smaller datasets (118.8 million versus 2.77 billion tokens), demonstrating efficient domain specialization viability. We establish that targeted continuous pretraining enables effective cybersecurity domain adaptation with computational feasibility, providing foundations for specialized AI assistants in threat analysis, vulnerability assessment, and security documentation while challenging prevailing assumptions about data requirements for LLM specialization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 Pages and 10 Figures",
    "pdf_url": "https://arxiv.org/pdf/2507.02964v1",
    "published_date": "2025-06-30 12:59:29 UTC",
    "updated_date": "2025-06-30 12:59:29 UTC"
  },
  {
    "arxiv_id": "2506.23793v1",
    "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning",
    "authors": [
      "Anton Andreychuk",
      "Konstantin Yakovlev",
      "Aleksandr Panov",
      "Alexey Skrynnik"
    ],
    "abstract": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23793v1",
    "published_date": "2025-06-30 12:34:31 UTC",
    "updated_date": "2025-06-30 12:34:31 UTC"
  },
  {
    "arxiv_id": "2506.23784v1",
    "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)",
    "authors": [
      "Parosh Aziz Abdulla",
      "Mohamed Faouzi Atig",
      "Julie Cailler",
      "Chencheng Liang",
      "Philipp Rümmer"
    ],
    "abstract": "Nielsen transformation is a standard approach for solving word equations: by repeatedly splitting equations and applying simplification steps, equations are rewritten until a solution is reached. When solving a conjunction of word equations in this way, the performance of the solver will depend considerably on the order in which equations are processed. In this work, the use of Graph Neural Networks (GNNs) for ranking word equations before and during the solving process is explored. For this, a novel graph-based representation for word equations is presented, preserving global information across conjuncts, enabling the GNN to have a holistic view during ranking. To handle the variable number of conjuncts, three approaches to adapt a multi-classification task to the problem of ranking equations are proposed. The training of the GNN is done with the help of minimum unsatisfiable subsets (MUSes) of word equations. The experimental results show that, compared to state-of-the-art string solvers, the new framework solves more problems in benchmarks where each variable appears at most once in each equation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23784v1",
    "published_date": "2025-06-30 12:24:24 UTC",
    "updated_date": "2025-06-30 12:24:24 UTC"
  },
  {
    "arxiv_id": "2506.23783v1",
    "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking",
    "authors": [
      "Shiao Wang",
      "Ju Huang",
      "Qingchuan Ma",
      "Jinfeng Gao",
      "Chunyi Xu",
      "Xiao Wang",
      "Lan Chen",
      "Bo Jiang"
    ],
    "abstract": "Combining traditional RGB cameras with bio-inspired event cameras for robust object tracking has garnered increasing attention in recent years. However, most existing multimodal tracking algorithms depend heavily on high-complexity Vision Transformer architectures for feature extraction and fusion across modalities. This not only leads to substantial computational overhead but also limits the effectiveness of cross-modal interactions. In this paper, we propose an efficient RGB-Event object tracking framework based on the linear-complexity Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a lightweight Prompt Generator that utilizes embedded features from each modality, together with a shared prompt pool, to dynamically generate modality-specific learnable prompt vectors. These prompts, along with the modality-specific embedded features, are then fed into a Vision Mamba-based FEMamba backbone, which facilitates prompt-guided feature extraction, cross-modal interaction, and fusion in a unified manner. Finally, the fused representations are passed to the tracking head for accurate target localization. Extensive experimental evaluations on multiple RGB-Event tracking benchmarks, including short-term COESOT dataset and long-term datasets, i.e., FE108 and FELT V2, demonstrate the superior performance and efficiency of the proposed tracking framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/Mamba_FETrack",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Journal extension of Mamba-FETrack which was published on Pattern Recognition and Computer Vision (PRCV) 2024",
    "pdf_url": "https://arxiv.org/pdf/2506.23783v1",
    "published_date": "2025-06-30 12:24:01 UTC",
    "updated_date": "2025-06-30 12:24:01 UTC"
  },
  {
    "arxiv_id": "2506.23782v2",
    "title": "WATS: Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling",
    "authors": [
      "Xiaoyang Li",
      "Linwei Tao",
      "Haohui Lu",
      "Minjing Dong",
      "Junbin Gao",
      "Chang Xu"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance on relational data; however, their confidence estimates often misalign with actual predictive correctness, posing significant limitations for deployment in safety-critical settings. While existing graph-aware calibration methods seek to mitigate this limitation, they primarily depend on coarse one-hop statistics, such as neighbor-predicted confidence, or latent node embeddings, thereby neglecting the fine-grained structural heterogeneity inherent in graph topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a post-hoc calibration framework that assigns node-specific temperatures based on tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the scalability and topology sensitivity of graph wavelets to refine confidence estimates, all without necessitating model retraining or access to neighboring logits or predictions. Extensive evaluations across seven benchmark datasets with varying graph structures and two GNN backbones demonstrate that WATS achieves the lowest Expected Calibration Error (ECE) among all compared methods, outperforming both classical and graph-specific baselines by up to 42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared with graph-specific methods. Moreover, WATS remains computationally efficient, scaling well across graphs of diverse sizes and densities. Code will be released based on publication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23782v2",
    "published_date": "2025-06-30 12:23:57 UTC",
    "updated_date": "2025-07-08 12:34:43 UTC"
  },
  {
    "arxiv_id": "2506.23773v1",
    "title": "BayesL: Towards a Logical Framework for Bayesian Networks",
    "authors": [
      "Stefano M. Nicoletti",
      "Mariëlle Stoelinga"
    ],
    "abstract": "We introduce BayesL, a novel logical framework for specifying, querying, and verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\") is a structured language that allows for the creation of queries over BNs. It facilitates versatile reasoning concerning causal and evidence-based relationships, and permits comprehensive what-if scenario evaluations without the need for manual modifications to the model.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23773v1",
    "published_date": "2025-06-30 12:18:00 UTC",
    "updated_date": "2025-06-30 12:18:00 UTC"
  },
  {
    "arxiv_id": "2506.23771v3",
    "title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving",
    "authors": [
      "Guizhe Jin",
      "Zhuoren Li",
      "Bo Leng",
      "Ran Yu",
      "Lu Xiong",
      "Chen Sun"
    ],
    "abstract": "Reinforcement Learning (RL) is increasingly used in autonomous driving (AD) and shows clear advantages. However, most RL-based AD methods overlook policy structure design. An RL policy that only outputs short-timescale vehicle control commands results in fluctuating driving behavior due to fluctuations in network outputs, while one that only outputs long-timescale driving goals cannot achieve unified optimality of driving behavior and control. Therefore, we propose a multi-timescale hierarchical reinforcement learning approach. Our approach adopts a hierarchical policy structure, where high- and low-level RL policies are unified-trained to produce long-timescale motion guidance and short-timescale control commands, respectively. Therein, motion guidance is explicitly represented by hybrid actions to capture multimodal driving behaviors on structured road and support incremental low-level extend-state updates. Additionally, a hierarchical safety mechanism is designed to ensure multi-timescale safety. Evaluation in simulator-based and HighD dataset-based highway multi-lane scenarios demonstrates that our approach significantly improves AD performance, effectively increasing driving efficiency, action consistency and safety.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, accepted for publication in IEEE Robotics and Automation Letters (RAL)",
    "pdf_url": "https://arxiv.org/pdf/2506.23771v3",
    "published_date": "2025-06-30 12:17:42 UTC",
    "updated_date": "2025-11-22 06:43:10 UTC"
  },
  {
    "arxiv_id": "2506.23762v1",
    "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead",
    "authors": [
      "Hongzhou Rao",
      "Yanjie Zhao",
      "Xinyi Hou",
      "Shenao Wang",
      "Haoyu Wang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has redefined artificial intelligence (AI), pushing the boundaries of AI research and enabling unbounded possibilities for both academia and the industry. However, LLM development faces increasingly complex challenges throughout its lifecycle, yet no existing research systematically explores these challenges and solutions from the perspective of software engineering (SE) approaches. To fill the gap, we systematically analyze research status throughout the LLM development lifecycle, divided into six phases: requirements engineering, dataset construction, model development and enhancement, testing and evaluation, deployment and operations, and maintenance and evolution. We then conclude by identifying the key challenges for each phase and presenting potential research directions to address these challenges. In general, we provide valuable insights from an SE perspective to facilitate future advances in LLM development.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23762v1",
    "published_date": "2025-06-30 12:09:29 UTC",
    "updated_date": "2025-06-30 12:09:29 UTC"
  },
  {
    "arxiv_id": "2507.00096v1",
    "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets",
    "authors": [
      "Ailiya Borjigin",
      "Wei Zhou",
      "Cong He"
    ],
    "abstract": "Alternative Assets tokenization is transforming non-traditional financial instruments are represented and traded on the web. However, ensuring trustworthiness in web-based tokenized ecosystems poses significant challenges, from verifying off-chain asset data to enforcing regulatory compliance. This paper proposes an AI-governed agent architecture that integrates intelligent agents with blockchain to achieve web-trustworthy tokenization of alternative assets. In the proposed architecture, autonomous agents orchestrate the tokenization process (asset verification, valuation, compliance checking, and lifecycle management), while an AI-driven governance layer monitors agent behavior and enforces trust through adaptive policies and cryptoeconomic incentives. We demonstrate that this approach enhances transparency, security, and compliance in asset tokenization, addressing key concerns around data authenticity and fraud. A case study on tokenizing real estate assets illustrates how the architecture mitigates risks (e.g., fraudulent listings and money laundering) through real-time AI anomaly detection and on-chain enforcement. Our evaluation and analysis suggest that combining AI governance with multi-agent systems and blockchain can significantly bolster trust in tokenized asset ecosystems. This work offers a novel framework for trustworthy asset tokenization on the web and provides insights for practitioners aiming to deploy secure, compliant tokenization platforms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 Pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2507.00096v1",
    "published_date": "2025-06-30 11:28:51 UTC",
    "updated_date": "2025-06-30 11:28:51 UTC"
  },
  {
    "arxiv_id": "2506.23735v1",
    "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data",
    "authors": [
      "JiaRu Wu",
      "Mingwei Liu"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance on various tasks, but existing evaluation benchmarks are often static and insufficient to fully assess their robustness and generalization in realistic scenarios. Prior work using evolutionary or adversarial data augmentation has improved evaluation diversity but lacks systematic control over perturbation types and multi-step complexity, limiting comprehensive robustness analysis. To address these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for close-ended tasks such as multi-choice question answering. AutoEvoEval introduces 22 interpretable atomic evolution operations and supports multi-round compositions, enabling controlled generation of diverse, challenging, and realistic test samples. We conduct extensive experiments addressing four research questions on a broad set of open- and closed-source LLMs. Our results show that atomic operations cause an average accuracy drop of 7.283\\%, with structure-disrupting or misleading semantic edits causing the largest declines. Model sensitivities vary significantly for the same perturbation, and combining multiple evolution steps amplifies adversarial effects by up to 52.932\\%. These findings suggest current benchmarks may overestimate true model generalization and emphasize the need for evolution-aware robustness evaluation. Code and resources are available at: https://github.com/SYSUSELab/AutoEvoEval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23735v1",
    "published_date": "2025-06-30 11:18:56 UTC",
    "updated_date": "2025-06-30 11:18:56 UTC"
  },
  {
    "arxiv_id": "2506.23734v1",
    "title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment",
    "authors": [
      "Hao Shi",
      "Xi Li",
      "Fangfang Xie"
    ],
    "abstract": "Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex dynamics like intransitivity and the Red Queen effect, leading to unstable convergence. To counter these challenges, this paper introduces the Marker Gene Method (MGM), a framework that establishes stability by using a 'marker gene' as a dynamic benchmark and an adaptive weighting mechanism to balance exploration and exploitation. We provide rigorous mathematical proofs demonstrating that MGM creates strong attractors near Nash Equilibria within the Strictly Competitive Game framework. Empirically, MGM demonstrates its efficacy across a spectrum of challenges: it stabilizes the canonical Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it successfully tames the notoriously pathological Shapley Biased Game. This work presents a theoretically sound and empirically validated framework that substantially enhances the stability and robustness of CCEAs in complex competitive environments.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.NE",
    "comment": "Submitted to IEEE Transactions on Evolutionary Computation. 13 pages, 10 figures. Supplementary material is included",
    "pdf_url": "https://arxiv.org/pdf/2506.23734v1",
    "published_date": "2025-06-30 11:13:36 UTC",
    "updated_date": "2025-06-30 11:13:36 UTC"
  },
  {
    "arxiv_id": "2506.23726v2",
    "title": "System-Embedded Diffusion Bridge Models",
    "authors": [
      "Bartlomiej Sobieski",
      "Matthew Tivnan",
      "Yuang Wang",
      "Siyeop Yoon",
      "Pengfei Jin",
      "Dufan Wu",
      "Quanzheng Li",
      "Przemyslaw Biecek"
    ],
    "abstract": "Solving inverse problems -- recovering signals from incomplete or noisy measurements -- is fundamental in science and engineering. Score-based generative models (SGMs) have recently emerged as a powerful framework for this task. Two main paradigms have formed: unsupervised approaches that adapt pretrained generative models to inverse problems, and supervised bridge methods that train stochastic processes conditioned on paired clean and corrupted data. While the former typically assume knowledge of the measurement model, the latter have largely overlooked this structural information. We introduce System embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge methods that explicitly embed the known linear measurement system into the coefficients of a matrix-valued SDE. This principled integration yields consistent improvements across diverse linear inverse problems and demonstrates robust generalization under system misspecification between training and deployment, offering a promising solution to real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23726v2",
    "published_date": "2025-06-30 10:58:49 UTC",
    "updated_date": "2025-10-24 17:47:21 UTC"
  },
  {
    "arxiv_id": "2506.23725v1",
    "title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?",
    "authors": [
      "Atharva Gundawar",
      "Som Sagar",
      "Ransalu Senanayake"
    ],
    "abstract": "Vision-Language Models (VLMs) are increasingly pivotal for generalist robot manipulation, enabling tasks such as physical reasoning, policy generation, and failure detection. However, their proficiency in these high-level applications often assumes a deep understanding of low-level physical prerequisites, a capability that remains largely unverified. For robots to perform actions reliably, they must comprehend intrinsic object properties (e.g., material, weight), action affordances (e.g., graspable, stackable), and physical constraints (e.g., stability, reachability, or an object's state, such as being closed). Despite the widespread use of VLMs in manipulation tasks, we argue that off-the-shelf models may lack this granular, physically grounded understanding, as such prerequisites are often overlooked during training.\n  To address this critical gap, we introduce PAC Bench, a comprehensive benchmark designed to systematically evaluate VLMs on their understanding of core Properties, Affordances, and Constraints (PAC) from a task executability perspective. PAC Bench features a diverse dataset with over 30,000 annotations, comprising 673 real-world images (115 object classes, 15 property types, and 1 to 3 affordances defined per class), 100 real-world humanoid-view scenarios, and 120 unique simulated constraint scenarios across four tasks.\n  Our evaluations reveal significant gaps in the ability of current VLMs to grasp fundamental physical concepts, highlighting limitations in their suitability for reliable robot manipulation and pointing to key areas for targeted research. PAC Bench also serves as a standardized benchmark for rigorously evaluating physical reasoning in VLMs and guiding the development of more robust, physically grounded models for robotic applications.\n  Project Page: https://pacbench.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23725v1",
    "published_date": "2025-06-30 10:58:36 UTC",
    "updated_date": "2025-06-30 10:58:36 UTC"
  },
  {
    "arxiv_id": "2506.23724v2",
    "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation",
    "authors": [
      "Chang'an Yi",
      "Xiaohui Deng",
      "Guohao Chen",
      "Yan Zhou",
      "Qinghua Lu",
      "Shuaicheng Niu"
    ],
    "abstract": "Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23724v2",
    "published_date": "2025-06-30 10:54:50 UTC",
    "updated_date": "2025-07-12 16:23:39 UTC"
  },
  {
    "arxiv_id": "2506.23721v1",
    "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound",
    "authors": [
      "Gijs Luijten",
      "Roberto Maria Scardigno",
      "Lisle Faray de Paiva",
      "Peter Hoyer",
      "Jens Kleesiek",
      "Domenico Buongiorno",
      "Vitoantonio Bevilacqua",
      "Jan Egger"
    ],
    "abstract": "Ultrasound (US) is widely accessible and radiation-free but has a steep learning curve due to its dynamic nature and non-standard imaging planes. Additionally, the constant need to shift focus between the US screen and the patient poses a challenge. To address these issues, we integrate deep learning (DL)-based semantic segmentation for real-time (RT) automated kidney volumetric measurements, which are essential for clinical assessment but are traditionally time-consuming and prone to fatigue. This automation allows clinicians to concentrate on image interpretation rather than manual measurements. Complementing DL, augmented reality (AR) enhances the usability of US by projecting the display directly into the clinician's field of view, improving ergonomics and reducing the cognitive load associated with screen-to-patient transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one streams directly via the application programming interface for a wireless setup, while the other supports any US device with video output for broader accessibility. We evaluate RT feasibility and accuracy using the Open Kidney Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model implementations, measurement algorithms, and a Wi-Fi-based streaming solution, enhancing US training and diagnostics, especially in point-of-care settings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23721v1",
    "published_date": "2025-06-30 10:49:54 UTC",
    "updated_date": "2025-06-30 10:49:54 UTC"
  },
  {
    "arxiv_id": "2506.23719v1",
    "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning",
    "authors": [
      "Alex Egg",
      "Martin Iglesias Goyanes",
      "Friso Kingma",
      "Andreu Mora",
      "Leandro von Werra",
      "Thomas Wolf"
    ],
    "abstract": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmark's design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23719v1",
    "published_date": "2025-06-30 10:49:21 UTC",
    "updated_date": "2025-06-30 10:49:21 UTC"
  },
  {
    "arxiv_id": "2506.23717v4",
    "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation",
    "authors": [
      "Xingting Yao",
      "Qinghao Hu",
      "Fei Zhou",
      "Tielong Liu",
      "Gang Li",
      "Peisong Wang",
      "Jian Cheng"
    ],
    "abstract": "Multi-bit spiking neural networks (SNNs) have recently become a heated research spot, pursuing energy-efficient and high-accurate AI. However, with more bits involved, the associated memory and computation demands escalate to the point where the performance improvements become disproportionate. Based on the insight that different layers demonstrate different importance and extra bits could be wasted and interfering, this paper presents an adaptive bit allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise allocation of memory and computation resources. Thus, SNN's efficiency and accuracy can be improved. Specifically, we parametrize the temporal lengths and the bit widths of weights and spikes, and make them learnable and controllable through gradients. To address the challenges caused by changeable bit widths and temporal lengths, we propose the refined spiking neuron, which can handle different temporal lengths, enable the derivation of gradients for temporal lengths, and suit spike quantization better. In addition, we theoretically formulate the step-size mismatch problem of learnable bit widths, which may incur severe quantization errors to SNN, and accordingly propose the step-size renewal mechanism to alleviate this issue. Experiments on various datasets, including the static CIFAR and ImageNet datasets and the dynamic CIFAR-DVS and DVS-GESTURE datasets, demonstrate that our methods can reduce the overall memory and computation cost while achieving higher accuracy. Particularly, our SEWResNet-34 can achieve a 2.69\\% accuracy gain and 4.16$\\times$ lower bit budgets over the advanced baseline work on ImageNet. This work is open-sourced at \\href{https://github.com/Ikarosy/Towards-Efficient-and-Accurate-Spiking-Neural-Networks-via-Adaptive-Bit-Allocation}{this link}.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Neural Networks, In press",
    "pdf_url": "https://arxiv.org/pdf/2506.23717v4",
    "published_date": "2025-06-30 10:45:16 UTC",
    "updated_date": "2025-11-30 10:08:45 UTC"
  },
  {
    "arxiv_id": "2507.01063v1",
    "title": "FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations",
    "authors": [
      "Madhav Kotecha"
    ],
    "abstract": "Online dating platforms have fundamentally transformed the formation of romantic relationships, with millions of users worldwide relying on algorithmic matching systems to find compatible partners. However, current recommendation systems in dating applications suffer from significant algorithmic deficiencies, including but not limited to popularity bias, filter bubble effects, and inadequate reciprocity modeling that limit effectiveness and introduce harmful biases. This research integrates foundational work with recent empirical findings to deliver a detailed analysis of dating app recommendation systems, highlighting key issues and suggesting research-backed solutions. Through analysis of reciprocal recommendation frameworks, fairness evaluation metrics, and industry implementations, we demonstrate that current systems achieve modest performance with collaborative filtering reaching 25.1\\% while reciprocal methods achieve 28.7\\%. Our proposed mathematical framework addresses these limitations through enhanced similarity measures, multi-objective optimization, and fairness-aware algorithms that maintain competitive accuracy while improving demographic representation to reduce algorithmic bias.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.01063v1",
    "published_date": "2025-06-30 10:36:57 UTC",
    "updated_date": "2025-06-30 10:36:57 UTC"
  },
  {
    "arxiv_id": "2506.23706v1",
    "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments",
    "authors": [
      "Christoph Schnabl",
      "Daniel Hugenroth",
      "Bill Marino",
      "Alastair R. Beresford"
    ],
    "abstract": "Benchmarks are important measures to evaluate safety and compliance of AI models at scale. However, they typically do not offer verifiable results and lack confidentiality for model IP and benchmark datasets. We propose Attestable Audits, which run inside Trusted Execution Environments and enable users to verify interaction with a compliant AI model. Our work protects sensitive data even when model provider and auditor do not trust each other. This addresses verification challenges raised in recent AI governance frameworks. We build a prototype demonstrating feasibility on typical audit benchmarks against Llama-3.1.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "ICML 2024 Workshop TAIG",
    "pdf_url": "https://arxiv.org/pdf/2506.23706v1",
    "published_date": "2025-06-30 10:29:42 UTC",
    "updated_date": "2025-06-30 10:29:42 UTC"
  },
  {
    "arxiv_id": "2506.23703v1",
    "title": "A New Perspective On AI Safety Through Control Theory Methodologies",
    "authors": [
      "Lars Ullrich",
      "Walter Zimmer",
      "Ross Greer",
      "Knut Graichen",
      "Alois C. Knoll",
      "Mohan Trivedi"
    ],
    "abstract": "While artificial intelligence (AI) is advancing rapidly and mastering increasingly complex problems with astonishing performance, the safety assurance of such systems is a major concern. Particularly in the context of safety-critical, real-world cyber-physical systems, AI promises to achieve a new level of autonomy but is hampered by a lack of safety assurance. While data-driven control takes up recent developments in AI to improve control systems, control theory in general could be leveraged to improve AI safety. Therefore, this article outlines a new perspective on AI safety based on an interdisciplinary interpretation of the underlying data-generation process and the respective abstraction by AI systems in a system theory-inspired and system analysis-driven manner. In this context, the new perspective, also referred to as data control, aims to stimulate AI engineering to take advantage of existing safety analysis and assurance in an interdisciplinary way to drive the paradigm of data control. Following a top-down approach, a generic foundation for safety analysis and assurance is outlined at an abstract level that can be refined for specific AI systems and applications and is prepared for future innovation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of Intelligent Transportation Systems (OJ-ITS)",
    "pdf_url": "https://arxiv.org/pdf/2506.23703v1",
    "published_date": "2025-06-30 10:26:59 UTC",
    "updated_date": "2025-06-30 10:26:59 UTC"
  },
  {
    "arxiv_id": "2507.00094v1",
    "title": "Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended)",
    "authors": [
      "Jacobo Casas-Ramos",
      "Sarah Winkler",
      "Alessandro Gianola",
      "Marco Montali",
      "Manuel Mucientes",
      "Manuel Lama"
    ],
    "abstract": "Despite growing interest in process analysis and mining for data-aware specifications, alignment-based conformance checking for declarative process models has focused on pure control-flow specifications, or mild data-aware extensions limited to numerical data and variable-to-constant comparisons. This is not surprising: finding alignments is computationally hard, even more so in the presence of data dependencies. In this paper, we challenge this problem in the case where the reference model is captured using data-aware Declare with general data types and data conditions. We show that, unexpectedly, it is possible to compute data-aware optimal alignments in this rich setting, enjoying at once efficiency and expressiveness. This is achieved by carefully combining the two best-known approaches to deal with control flow and data dependencies when computing alignments, namely A* search and SMT solving. Specifically, we introduce a novel algorithmic technique that efficiently explores the search space, generating descendant states through the application of repair actions aiming at incrementally resolving constraint violations. We prove the correctness of our algorithm and experimentally show its efficiency. The evaluation witnesses that our approach matches or surpasses the performance of the state of the art while also supporting significantly more expressive data dependencies, showcasing its potential to support real-world applications.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.DB",
    "comment": "Extended version of the paper of the same title accepted at the 23rd International Conference on Business Process Management (BPM 2025)",
    "pdf_url": "https://arxiv.org/pdf/2507.00094v1",
    "published_date": "2025-06-30 10:16:21 UTC",
    "updated_date": "2025-06-30 10:16:21 UTC"
  },
  {
    "arxiv_id": "2506.23692v1",
    "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models",
    "authors": [
      "Boyuan Zheng",
      "Zerui Fang",
      "Zhe Xu",
      "Rui Wang",
      "Yiwen Chen",
      "Cunshi Wang",
      "Mengwei Qu",
      "Lei Lei",
      "Zhen Feng",
      "Yan Liu",
      "Yuyang Li",
      "Mingzhou Tan",
      "Jiaji Wu",
      "Jianwei Shuai",
      "Jia Li",
      "Fangfu Ye"
    ],
    "abstract": "While AI for Science (AI4S) serves as an analytical tool in the current research paradigm, it doesn't solve its core inefficiency. We propose \"Agent for Science\" (Agent4S)-the use of LLM-driven agents to automate the entire research workflow-as the true Fifth Scientific Paradigm. This paper introduces a five-level classification for Agent4S, outlining a clear roadmap from simple task automation to fully autonomous, collaborative \"AI Scientists.\" This framework defines the next revolutionary step in scientific discovery.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23692v1",
    "published_date": "2025-06-30 10:11:39 UTC",
    "updated_date": "2025-06-30 10:11:39 UTC"
  },
  {
    "arxiv_id": "2506.23689v1",
    "title": "PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red",
    "authors": [
      "Zihao Liu",
      "Xinhang Sui",
      "Yueran Song",
      "Siwen Wang"
    ],
    "abstract": "We introduce PokéAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pokémon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution Agent. Our results show that the battle AI achieves an average win rate of 80.8% across 50 wild encounters, only 6% lower than the performance of an experienced human player. Furthermore, we find that a model's battle performance correlates strongly with its LLM Arena score on language-related tasks, indicating a meaningful link between linguistic ability and strategic reasoning. Finally, our analysis of gameplay logs reveals that each LLM exhibits a unique playstyle, suggesting that individual models develop distinct strategic behaviors.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23689v1",
    "published_date": "2025-06-30 10:09:13 UTC",
    "updated_date": "2025-06-30 10:09:13 UTC"
  },
  {
    "arxiv_id": "2507.00093v1",
    "title": "$σ$-Maximal Ancestral Graphs",
    "authors": [
      "Binghua Yao",
      "Joris M. Mooij"
    ],
    "abstract": "Maximal Ancestral Graphs (MAGs) provide an abstract representation of Directed Acyclic Graphs (DAGs) with latent (selection) variables. These graphical objects encode information about ancestral relations and d-separations of the DAGs they represent. This abstract representation has been used amongst others to prove the soundness and completeness of the FCI algorithm for causal discovery, and to derive a do-calculus for its output. One significant inherent limitation of MAGs is that they rule out the possibility of cyclic causal relationships. In this work, we address that limitation. We introduce and study a class of graphical objects that we coin ''$σ$-Maximal Ancestral Graphs'' (''$σ$-MAGs''). We show how these graphs provide an abstract representation of (possibly cyclic) Directed Graphs (DGs) with latent (selection) variables, analogously to how MAGs represent DAGs. We study the properties of these objects and provide a characterization of their Markov equivalence classes.",
    "categories": [
      "cs.DM",
      "cs.AI",
      "cs.DS",
      "math.ST"
    ],
    "primary_category": "cs.DM",
    "comment": "It has beee accepted by the 41st Conference on Uncertainty in Artificial Intelligence (UAI)",
    "pdf_url": "https://arxiv.org/pdf/2507.00093v1",
    "published_date": "2025-06-30 10:08:21 UTC",
    "updated_date": "2025-06-30 10:08:21 UTC"
  },
  {
    "arxiv_id": "2506.23679v2",
    "title": "Learning Modular Exponentiation with Transformers",
    "authors": [
      "David Demitri Africa",
      "Sara M. Kapoor",
      "Theo Simon Sorg",
      "Challenger Mishra"
    ],
    "abstract": "Modular exponentiation is crucial to number theory and cryptography, yet remains largely unexplored from a mechanistic interpretability standpoint. We train a 4-layer encoder-decoder Transformer model to perform this operation and investigate the emergence of numerical reasoning during training. Utilizing principled sampling strategies, PCA-based embedding analysis, and activation patching, we examine how number-theoretic properties are encoded within the model. We find that reciprocal operand training leads to strong performance gains, with sudden generalization across related moduli. These synchronized accuracy surges reflect grokking-like dynamics, suggesting the model internalizes shared arithmetic structure. We also find a subgraph consisting entirely of attention heads in the final layer sufficient to achieve full performance on the task of regular exponentiation. These results suggest that transformer models learn modular arithmetic through specialized computational circuits, paving the way for more interpretable and efficient neural approaches to modular exponentiation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 5th MATH-AI Workshop, NeurIPS'25",
    "pdf_url": "https://arxiv.org/pdf/2506.23679v2",
    "published_date": "2025-06-30 10:00:44 UTC",
    "updated_date": "2025-10-23 17:33:42 UTC"
  },
  {
    "arxiv_id": "2506.23678v1",
    "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models",
    "authors": [
      "Rock Yuren Pang",
      "K. J. Kevin Feng",
      "Shangbin Feng",
      "Chu Li",
      "Weijia Shi",
      "Yulia Tsvetkov",
      "Jeffrey Heer",
      "Katharina Reinecke"
    ],
    "abstract": "The output quality of large language models (LLMs) can be improved via \"reasoning\": generating segments of chain-of-thought (CoT) content to further condition the model prior to producing user-facing output. While these chains contain valuable information, they are verbose and lack explicit organization, making them tedious to review. Moreover, they lack opportunities for user feedback, such as to remove unwanted considerations, add desired ones, or clarify unclear assumptions. We introduce Interactive Reasoning, an interaction design that visualizes chain-of-thought outputs as a hierarchy of topics and enables user review and modification. We implement interactive reasoning in Hippo, a prototype for AI-assisted decision making in the face of uncertain trade-offs. In a user study with 16 participants, we find that interactive reasoning in Hippo allows users to quickly identify and interrupt erroneous generations, efficiently steer the model towards customized responses, and better understand both model reasoning and model outputs. Our work contributes to a new paradigm that incorporates user oversight into LLM reasoning processes.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23678v1",
    "published_date": "2025-06-30 10:00:43 UTC",
    "updated_date": "2025-06-30 10:00:43 UTC"
  },
  {
    "arxiv_id": "2507.00092v1",
    "title": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models",
    "authors": [
      "Basab Jha",
      "Firoj Paudel",
      "Ujjwal Puri",
      "Zhang Yuting",
      "Choi Donghyuk",
      "Wang Junhao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities at solving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but their decision-making processes remain somewhat blackbox. We introduce textbfinverse reasoning, a novel paradigm enabling LLMs to decompose and explain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a 4-billion-parameter reasoning model, employs a metacognitive structure that reflects back via attention processes to identify major decision points and generate explanations of reasoning choices. While typical CoT approaches are directed towards forward reasoning generation, inverse reasoning provides insight into why specific reasoning chains were selected over others. Through thorough testing of logical reasoning puzzles, math problems and ethical dilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we demonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy (74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for its task, and offers performance almost on par with models like Claude-3.5 Sonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for LLM self-reflection via inverse reasoning, (ii) a novel metalearning framework to reverse the attention flow, (iii) comprehensive evaluation frameworks for reasoning transparency, and (iv) evidence that increasing reasoning using inverse reasoning improves interpretability along with reasoning performance. Our work creates new avenues for transparent AI systems and closes significant gaps in AI safety, education, and scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 2 figures, 9 tables",
    "pdf_url": "https://arxiv.org/pdf/2507.00092v1",
    "published_date": "2025-06-30 09:53:41 UTC",
    "updated_date": "2025-06-30 09:53:41 UTC"
  },
  {
    "arxiv_id": "2506.23673v2",
    "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift",
    "authors": [
      "Jingsong Liu",
      "Han Li",
      "Chen Yang",
      "Michael Deutges",
      "Ario Sadafi",
      "Xin You",
      "Katharina Breininger",
      "Nassir Navab",
      "Peter J. Schüffler"
    ],
    "abstract": "Domain shift is a critical problem for pathology AI as pathology data is heavily influenced by center-specific conditions. Current pathology domain adaptation methods focus on image patches rather than WSI, thus failing to capture global WSI features required in typical clinical scenarios. In this work, we address the challenges of slide-level domain shift by proposing a Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD achieves multi-scale feature consistency and computationally efficient slide-level domain adaptation through two key components: (1) a hierarchical adaptation framework that integrates a Domain-level Alignment Solver for feature alignment, a Slide-level Geometric Invariance Regularization to preserve the morphological structure, and a Patch-level Attention Consistency Regularization to maintain local critical diagnostic cues; and (2) a prototype selection mechanism that reduces computational overhead. We validate our method on two slide-level tasks across five datasets, achieving a 4.1\\% AUROC improvement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in a UCEC survival prediction cohort. Our method provides a practical and reliable slide-level domain adaption solution for pathology institutions, minimizing both computational and annotation costs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23673v2",
    "published_date": "2025-06-30 09:52:01 UTC",
    "updated_date": "2025-08-08 14:04:58 UTC"
  },
  {
    "arxiv_id": "2507.01062v2",
    "title": "Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review",
    "authors": [
      "Seyma Yaman Kayadibi"
    ],
    "abstract": "The exponential development of generative artificial intelligence (GenAI) technologies like ChatGPT has raised increasing curiosity about their use in higher education, specifically with respect to how students view them, make use of them, and the implications for learning outcomes. This paper employs a hybrid methodological approach involving a systematic literature review and simulation-based modeling to explore student perceptions of GenAI use in the context of higher education. A total of nineteen empirical articles from 2023 through 2025 were selected from the PRISMA-based search targeting the Scopus database. Synthesis of emerging patterns from the literature was achieved by thematic categorization. Six of these had enough quantitative information, i.e., item-level means and standard deviations, to permit probabilistic modeling. One dataset, from the resulting subset, was itself selected as a representative case with which to illustrate inverse-variance weighting by Monte Carlo simulation, by virtue of its well-designed Likert scale format and thematic alignment with the use of computing systems by the researcher.\n  The simulation provided a composite \"Success Score\" forecasting the strength of the relationship between student perceptions and learning achievements. Findings reveal that attitude factors concerned with usability and real-world usefulness are significantly better predictors of positive learning achievement than affective or trust-based factors. Such an interdisciplinary perspective provides a unique means of linking thematic results with predictive modelling, resonating with longstanding controversies about the proper use of GenAI tools within the university.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "35 pages, 4 figures. All figures are image-based: one Python code screenshot, one regression model output, one success score distribution chart, and one PRISMA diagram. This article presents a standalone segment from the author's master's thesis at Victoria University",
    "pdf_url": "https://arxiv.org/pdf/2507.01062v2",
    "published_date": "2025-06-30 09:50:38 UTC",
    "updated_date": "2025-09-22 12:21:53 UTC"
  },
  {
    "arxiv_id": "2507.00090v3",
    "title": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study",
    "authors": [
      "Michael Corbeau",
      "Emmanuelle Claeys",
      "Mathieu Serrurier",
      "Pascale Zaraté"
    ],
    "abstract": "Allocation of personnel and material resources is highly sensible in the case of firefighter interventions. This allocation relies on simulations to experiment with various scenarios. The main objective of this allocation is the global optimization of the firefighters response. Data generation is then mandatory to study various scenarios In this study, we propose to compare different data generation methods. Methods such as Random Sampling, Tabular Variational Autoencoders, standard Generative Adversarial Networks, Conditional Tabular Generative Adversarial Networks and Diffusion Probabilistic Models are examined to ascertain their efficacy in capturing the intricacies of firefighter interventions. Traditional evaluation metrics often fall short in capturing the nuanced requirements of synthetic datasets for real-world scenarios. To address this gap, an evaluation of synthetic data quality is conducted using a combination of domain-specific metrics tailored to the firefighting domain and standard measures such as the Wasserstein distance. Domain-specific metrics include response time distribution, spatial-temporal distribution of interventions, and accidents representation. These metrics are designed to assess data variability, the preservation of fine and complex correlations and anomalies such as event with a very low occurrence, the conformity with the initial statistical distribution and the operational relevance of the synthetic data. The distribution has the particularity of being highly unbalanced, none of the variables following a Gaussian distribution, adding complexity to the data generation process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at IEEE SMC 2025 Vienna",
    "pdf_url": "https://arxiv.org/pdf/2507.00090v3",
    "published_date": "2025-06-30 09:43:23 UTC",
    "updated_date": "2025-07-29 07:56:27 UTC"
  },
  {
    "arxiv_id": "2506.23644v3",
    "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration",
    "authors": [
      "Junze Hu",
      "Xiangyu Jin",
      "Yizhe Zeng",
      "Yuling Liu",
      "Yunpeng Li",
      "Dan Du",
      "Kaiyu Xie",
      "Hongsong Zhu"
    ],
    "abstract": "We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "The experimental data in the experimental section needs to be improved, and there are some errors",
    "pdf_url": "https://arxiv.org/pdf/2506.23644v3",
    "published_date": "2025-06-30 09:14:49 UTC",
    "updated_date": "2025-07-19 04:22:39 UTC"
  },
  {
    "arxiv_id": "2507.00088v1",
    "title": "How large language models judge and influence human cooperation",
    "authors": [
      "Alexandre S. Pires",
      "Laurens Samson",
      "Sennay Ghebreab",
      "Fernando P. Santos"
    ],
    "abstract": "Humans increasingly rely on large language models (LLMs) to support decisions in social settings. Previous work suggests that such tools shape people's moral and political judgements. However, the long-term implications of LLM-based social decision-making remain unknown. How will human cooperation be affected when the assessment of social interactions relies on language models? This is a pressing question, as human cooperation is often driven by indirect reciprocity, reputations, and the capacity to judge interactions of others. Here, we assess how state-of-the-art LLMs judge cooperative actions. We provide 21 different LLMs with an extensive set of examples where individuals cooperate -- or refuse cooperating -- in a range of social contexts, and ask how these interactions should be judged. Furthermore, through an evolutionary game-theoretical model, we evaluate cooperation dynamics in populations where the extracted LLM-driven judgements prevail, assessing the long-term impact of LLMs on human prosociality. We observe a remarkable agreement in evaluating cooperation against good opponents. On the other hand, we notice within- and between-model variance when judging cooperation with ill-reputed individuals. We show that the differences revealed between models can significantly impact the prevalence of cooperation. Finally, we test prompts to steer LLM norms, showing that such interventions can shape LLM judgements, particularly through goal-oriented prompts. Our research connects LLM-based advices and long-term social dynamics, and highlights the need to carefully align LLM norms in order to preserve human cooperation.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00088v1",
    "published_date": "2025-06-30 09:14:42 UTC",
    "updated_date": "2025-06-30 09:14:42 UTC"
  },
  {
    "arxiv_id": "2506.23641v1",
    "title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation",
    "authors": [
      "Peng Huang",
      "Junhu Fu",
      "Bowen Guo",
      "Zeju Li",
      "Yuanyuan Wang",
      "Yi Guo"
    ],
    "abstract": "As the appearance of medical images is influenced by multiple underlying factors, generative models require rich attribute information beyond labels to produce realistic and diverse images. For instance, generating an image of skin lesion with specific patterns demands descriptions that go beyond diagnosis, such as shape, size, texture, and color. However, such detailed descriptions are not always accessible. To address this, we explore a framework, termed Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality and diversity of medical image generation. First, to derive descriptions from MLLMs without hallucination, we design a series of prompts following Chain-of-Thoughts for common medical imaging tasks, including dermatologic, colorectal, and chest X-ray images. Generated descriptions are utilized during training and stored across different categories. During testing, descriptions are randomly retrieved from the corresponding category for inference. Moreover, to make the generator robust to unseen combination of descriptions at the test time, we propose a Prototype Condition Mechanism that restricts test embeddings to be similar to those from training. Experiments on three common types of medical imaging across four datasets verify the effectiveness of VAP-Diffusion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23641v1",
    "published_date": "2025-06-30 09:11:19 UTC",
    "updated_date": "2025-06-30 09:11:19 UTC"
  },
  {
    "arxiv_id": "2506.23639v1",
    "title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding",
    "authors": [
      "Wanpeng Zhang",
      "Yicheng Feng",
      "Hao Luo",
      "Yijiang Li",
      "Zihao Yue",
      "Sipeng Zheng",
      "Zongqing Lu"
    ],
    "abstract": "Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23639v1",
    "published_date": "2025-06-30 09:08:08 UTC",
    "updated_date": "2025-06-30 09:08:08 UTC"
  },
  {
    "arxiv_id": "2507.01061v3",
    "title": "Epitome: Pioneering an Experimental Platform for AI-Social Science Integration",
    "authors": [
      "Jingjing Qu",
      "Kejia Hu",
      "Jun Zhu",
      "Yulei Ye",
      "Wenhao Li",
      "Teng Wang",
      "Zhiyun Chen",
      "Chaochao Lu",
      "Aimin Zhou",
      "Xiangfeng Wang",
      "Xia Hu",
      "James Evans"
    ],
    "abstract": "Large Language Models (LLMs) enable unprecedented social science experimentation by creating controlled hybrid human-AI environments. We introduce Epitome (www.epitome-ai.com), an open experimental platform that operationalizes this paradigm through Matrix-like social worlds where researchers can study isolated human subjects and groups interacting with LLM agents. This maintains ecological validity while enabling precise manipulation of social dynamics. Epitome approaches three frontiers: (1) methodological innovation using LLM confederates to reduce complexity while scaling interactions; (2) empirical investigation of human behavior in AI-saturated environments; and (3) exploration of emergent properties in hybrid collectives. Drawing on interdisciplinary foundations from management, communication, sociology, psychology, and ethics, the platform's modular architecture spans foundation model deployment through data collection. We validate Epitome through replication of three seminal experiments, demonstrating capacity to generate robust findings while reducing experimental complexity. This tool provides crucial insights for understanding how humans navigate AI-mediated social realities, knowledge essential for policy, education, and human-centered AI design.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "25 pages, 6figures",
    "pdf_url": "https://arxiv.org/pdf/2507.01061v3",
    "published_date": "2025-06-30 09:06:16 UTC",
    "updated_date": "2025-12-24 08:52:29 UTC"
  },
  {
    "arxiv_id": "2506.23635v1",
    "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model",
    "authors": [
      "Mu-Chi Chen",
      "Po-Hsuan Huang",
      "Xiangrui Ke",
      "Chia-Heng Tu",
      "Chun Jason Xue",
      "Shih-Hao Hung"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI) with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and Databricks' DBRX. This paper addresses the cost and scalability challenges encountered when constructing private LLM systems for personal or small group services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2 Ultra chips is established as a cost-efficient solution to host and accelerate the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our performance analysis reveal that parallel execution of the model's experts across two to four machine nodes significantly reduces inference time. We find that computation time for the experts is comparable to the communication time for exchanging their outputs, emphasizing the importance of network latency over bandwidth. We also observe significant management overhead due to Apple software stack's memory management logic. Based on these findings, we develop optimization schemes to eliminate the memory management overhead. As a result, the Mac Studio cluster is 1.15 times more cost-efficient than the state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we construct a performance model to estimate system performance under varying configurations, and the model provides valuable insights for designing private LLM systems.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "International Conference on Research in Adaptive and Convergent Systems (RACS '24), November 5--8, 2024, Pompei, Italy",
    "pdf_url": "https://arxiv.org/pdf/2506.23635v1",
    "published_date": "2025-06-30 09:04:25 UTC",
    "updated_date": "2025-06-30 09:04:25 UTC"
  },
  {
    "arxiv_id": "2506.23634v1",
    "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures",
    "authors": [
      "Youjeong Noh",
      "Joon-Young Paik",
      "Jingun Kwon",
      "Eun-Sun Cho"
    ],
    "abstract": "Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by converting programs into forms that are more complex to analyze. However, MBA has been increasingly exploited by malware developers to evade detection and cause significant real-world problems. Traditional MBA deobfuscation methods often consider these expressions as part of a black box and overlook their internal semantic information. To bridge this gap, we propose a truth table, which is an automatically constructed semantic representation of an expression's behavior that does not rely on external resources. The truth table is a mathematical form that represents the output of expression for all possible combinations of input. We also propose a general and extensible guided MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural encoder-decoder Seq2Seq architecture to incorporate this semantic guidance. Experimental results and in-depth analysis show that integrating expression semantics significantly improves performance and highlights the importance of internal semantic expressions in recovering obfuscated code to its original form.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23634v1",
    "published_date": "2025-06-30 09:03:13 UTC",
    "updated_date": "2025-06-30 09:03:13 UTC"
  },
  {
    "arxiv_id": "2507.02962v6",
    "title": "RAG-R1: Incentivizing the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism",
    "authors": [
      "Zhiwen Tan",
      "Jiaming Huang",
      "Qintong Wu",
      "Hongxuan Zhang",
      "Chenyi Zhuang",
      "Jinjie Gu"
    ],
    "abstract": "Large Language Models (LLMs), despite their remarkable capabilities, are prone to generating hallucinated or outdated content due to their static internal knowledge. While Retrieval-Augmented Generation (RAG) integrated with Reinforcement Learning (RL) offers a solution, these methods are fundamentally constrained by a single-query mode, leading to prohibitive latency and inherent brittleness. To overcome these limitations, we introduce RAG-R1, a novel two-stage training framework centered around multi-query parallelism. Our framework enables LLMs to adaptively leverage internal and external knowledge during the reasoning process while transitioning from the single-query mode to multi-query parallelism. This architectural shift bolsters reasoning robustness while significantly reducing inference latency. Extensive experiments on seven question-answering benchmarks confirm the superiority of our method, which outperforms the strongest baseline by up to 13.7% and decreases inference time by 11.1%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02962v6",
    "published_date": "2025-06-30 09:02:45 UTC",
    "updated_date": "2026-01-13 06:28:13 UTC"
  },
  {
    "arxiv_id": "2506.23629v2",
    "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data",
    "authors": [
      "Xin Liao",
      "Bing Yang",
      "Cai Yu"
    ],
    "abstract": "The integrity of Water Quality Data (WQD) is critical in environmental monitoring for scientific decision-making and ecological protection. However, water quality monitoring systems are often challenged by large amounts of missing data due to unavoidable problems such as sensor failures and communication delays, which further lead to water quality data becoming High-Dimensional and Sparse (HDS). Traditional data imputation methods are difficult to depict the potential dynamics and fail to capture the deep data features, resulting in unsatisfactory imputation performance. To effectively address the above issues, this paper proposes a Nonlinear Low-rank Representation model (NLR) with Convolutional Neural Networks (CNN) for imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing temporal features to model the temporal dependence of data between time slots, and b) Extracting nonlinear interactions and local patterns to mine higher-order relationships features and achieve deep fusion of multidimensional information. Experimental studies on three real water quality datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art data imputation models in terms of estimation accuracy. It provides an effective approach for handling water quality monitoring data in complex dynamic environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures, conference",
    "pdf_url": "https://arxiv.org/pdf/2506.23629v2",
    "published_date": "2025-06-30 08:48:19 UTC",
    "updated_date": "2025-09-10 12:50:14 UTC"
  },
  {
    "arxiv_id": "2506.23628v1",
    "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking",
    "authors": [
      "Antonio Ojea"
    ],
    "abstract": "Traditional Kubernetes networking struggles to meet the escalating demands of AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes Network Drivers (KNDs), a transformative, modular, and declarative architecture designed to overcome current imperative provisioning and API limitations. KNDs integrate network resource management into Kubernetes' core by utilizing Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements, and upcoming OCI Runtime Specification changes. Our DraNet implementation demonstrates declarative attachment of network interfaces, including Remote Direct Memory Access (RDMA) devices, significantly boosting high-performance AI/ML workloads. This capability enables sophisticated cloud-native applications and lays crucial groundwork for future Telco solutions, fostering a \"galaxy\" of specialized KNDs for enhanced application delivery and reduced operational complexity.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages, 9 figures, submitted to IEEE LCN Special Track on Cloud-AI-Native Mobile Networks Powered by eBPF (CAMe 2025)",
    "pdf_url": "https://arxiv.org/pdf/2506.23628v1",
    "published_date": "2025-06-30 08:45:54 UTC",
    "updated_date": "2025-06-30 08:45:54 UTC"
  },
  {
    "arxiv_id": "2506.23626v1",
    "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games",
    "authors": [
      "António Afonso",
      "Iolanda Leite",
      "Alessandro Sestini",
      "Florian Fuchs",
      "Konrad Tollmar",
      "Linus Gisslén"
    ],
    "abstract": "Reinforcement Learning (RL) in games has gained significant momentum in recent years, enabling the creation of different agent behaviors that can transform a player's gaming experience. However, deploying RL agents in production environments presents two key challenges: (1) designing an effective reward function typically requires an RL expert, and (2) when a game's content or mechanics are modified, previously tuned reward weights may no longer be optimal. Towards the latter challenge, we propose an automated approach for iteratively fine-tuning an RL agent's reward function weights, based on a user-defined language based behavioral goal. A Language Model (LM) proposes updated weights at each iteration based on this target behavior and a summary of performance statistics from prior training rounds. This closed-loop process allows the LM to self-correct and refine its output over time, producing increasingly aligned behavior without the need for manual reward engineering. We evaluate our approach in a racing task and show that it consistently improves agent performance across iterations. The LM-guided agents show a significant increase in performance from $9\\%$ to $74\\%$ success rate in just one iteration. We compare our LM-guided tuning against a human expert's manual weight design in the racing task: by the final iteration, the LM-tuned agent achieved an $80\\%$ success rate, and completed laps in an average of $855$ time steps, a competitive performance against the expert-tuned agent's peak $94\\%$ success, and $850$ time steps.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages in total, 10 pages of main paper, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23626v1",
    "published_date": "2025-06-30 08:45:04 UTC",
    "updated_date": "2025-06-30 08:45:04 UTC"
  },
  {
    "arxiv_id": "2507.00087v1",
    "title": "pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation",
    "authors": [
      "Jiale Zhao",
      "Pengzhi Mao",
      "Kaifei Wang",
      "Yiming Li",
      "Yaping Peng",
      "Ranfei Chen",
      "Shuqi Lu",
      "Xiaohong Ji",
      "Jiaxiang Ding",
      "Xin Zhang",
      "Yucheng Liao",
      "Weinan E",
      "Weijie Zhang",
      "Han Wen",
      "Hao Chi"
    ],
    "abstract": "Deep learning has advanced mass spectrometry data interpretation, yet most models remain feature extractors rather than unified scoring frameworks. We present pUniFind, the first large-scale multimodal pre-trained model in proteomics that integrates end-to-end peptide-spectrum scoring with open, zero-shot de novo sequencing. Trained on over 100 million open search-derived spectra, pUniFind aligns spectral and peptide modalities via cross modality prediction and outperforms traditional engines across diverse datasets, particularly achieving a 42.6 percent increase in the number of identified peptides in immunopeptidomics. Supporting over 1,300 modifications, pUniFind identifies 60 percent more PSMs than existing de novo methods despite a 300-fold larger search space. A deep learning based quality control module further recovers 38.5 percent additional peptides including 1,891 mapped to the genome but absent from reference proteomes while preserving full fragment ion coverage. These results establish a unified, scalable deep learning framework for proteomic analysis, offering improved sensitivity, modification coverage, and interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00087v1",
    "published_date": "2025-06-30 08:32:39 UTC",
    "updated_date": "2025-06-30 08:32:39 UTC"
  },
  {
    "arxiv_id": "2507.05317v2",
    "title": "PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT",
    "authors": [
      "Yi Liu",
      "Yiyang Wen",
      "Zekun Zhou",
      "Junqi Ma",
      "Linghang Wang",
      "Yucheng Yao",
      "Liu Shi",
      "Qiegen Liu"
    ],
    "abstract": "Generative diffusion models have received increasing attention in medical imaging, particularly in limited-angle computed tomography (LACT). Standard diffusion models achieve high-quality image reconstruction but require a large number of sampling steps during inference, resulting in substantial computational overhead. Although skip-sampling strategies have been proposed to improve efficiency, they often lead to loss of fine structural details. To address this issue, we propose a prior information embedding and wavelet feature fusion fast sampling diffusion model for LACT reconstruction. The PWD enables efficient sampling while preserving reconstruction fidelity in LACT, and effectively mitigates the degradation typically introduced by skip-sampling. Specifically, during the training phase, PWD maps the distribution of LACT images to that of fully sampled target images, enabling the model to learn structural correspondences between them. During inference, the LACT image serves as an explicit prior to guide the sampling trajectory, allowing for high-quality reconstruction with significantly fewer steps. In addition, PWD performs multi-scale feature fusion in the wavelet domain, effectively enhancing the reconstruction of fine details by leveraging both low-frequency and high-frequency information. Quantitative and qualitative evaluations on clinical dental arch CBCT and periapical datasets demonstrate that PWD outperforms existing methods under the same sampling condition. Using only 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and 10% gain in SSIM.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05317v2",
    "published_date": "2025-06-30 08:28:32 UTC",
    "updated_date": "2025-07-10 14:01:10 UTC"
  },
  {
    "arxiv_id": "2506.23605v1",
    "title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval",
    "authors": [
      "Suyash Maniyar",
      "Vishvesh Trivedi",
      "Ajoy Mondal",
      "Anand Mishra",
      "C. V. Jawahar"
    ],
    "abstract": "Lecture slide element detection and retrieval are key problems in slide understanding. Training effective models for these tasks often depends on extensive manual annotation. However, annotating large volumes of lecture slides for supervised training is labor intensive and requires domain expertise. To address this, we propose a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, which produces high-quality, coherent and realistic slides. We also create an evaluation benchmark, namely RealSlide by manually annotating 1,050 real lecture slides. To assess the utility of our synthetic slides, we perform few-shot transfer learning on real data using models pre-trained on them. Experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data. This demonstrates that synthetic data can effectively compensate for limited labeled lecture slides. The code and resources of our work are publicly available on our project website: https://synslidegen.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "40 pages including supplementary, accepted at ICDAR 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23605v1",
    "published_date": "2025-06-30 08:11:31 UTC",
    "updated_date": "2025-06-30 08:11:31 UTC"
  },
  {
    "arxiv_id": "2506.23603v2",
    "title": "SoK: Semantic Privacy in Large Language Models",
    "authors": [
      "Baihe Ma",
      "Yanna Jiang",
      "Xu Wang",
      "Guangsheng Yu",
      "Qin Wang",
      "Caijun Sun",
      "Chen Li",
      "Xuelei Qi",
      "Ying He",
      "Wei Ni",
      "Ren Ping Liu"
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly deployed in sensitive domains, traditional data privacy measures prove inadequate for protecting information that is implicit, contextual, or inferable - what we define as semantic privacy. This Systematization of Knowledge (SoK) introduces a lifecycle-centric framework to analyze how semantic privacy risks emerge across input processing, pretraining, fine-tuning, and alignment stages of LLMs. We categorize key attack vectors and assess how current defenses, such as differential privacy, embedding encryption, edge computing, and unlearning, address these threats. Our analysis reveals critical gaps in semantic-level protection, especially against contextual inference and latent representation leakage. We conclude by outlining open challenges, including quantifying semantic leakage, protecting multimodal inputs, balancing de-identification with generation quality, and ensuring transparency in privacy enforcement. This work aims to inform future research on designing robust, semantically aware privacy-preserving techniques for LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23603v2",
    "published_date": "2025-06-30 08:08:15 UTC",
    "updated_date": "2025-07-16 15:51:30 UTC"
  },
  {
    "arxiv_id": "2506.23601v2",
    "title": "Semantic-guided Diverse Decoding for Large Language Model",
    "authors": [
      "Weijie Shi",
      "Yue Cui",
      "Yaguang Wu",
      "Jingzhi Fang",
      "Shibo Zhang",
      "Mengze Li",
      "Sirui Han",
      "Jia Zhu",
      "Jiajie Xu",
      "Xiaofang Zhou"
    ],
    "abstract": "Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23601v2",
    "published_date": "2025-06-30 08:06:49 UTC",
    "updated_date": "2025-09-28 21:32:17 UTC"
  },
  {
    "arxiv_id": "2506.23596v1",
    "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series",
    "authors": [
      "Min-Yeong Park",
      "Won-Jeong Lee",
      "Seong Tae Kim",
      "Gyeong-Moon Park"
    ],
    "abstract": "Recently, forecasting future abnormal events has emerged as an important scenario to tackle real-world necessities. However, the solution of predicting specific future time points when anomalies will occur, known as Anomaly Prediction (AP), remains under-explored. Existing methods dealing with time series data fail in AP, focusing only on immediate anomalies or failing to provide precise predictions for future anomalies. To address the AP task, we propose a novel framework called Anomaly to Prompt (A2P), comprised of Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To enable the forecasting model to forecast abnormal time points, we adopt a strategy to learn the relationships of anomalies. For the robust detection of anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP) that simulates diverse anomaly patterns using signal adaptive prompt. Comprehensive experiments on multiple real-world datasets demonstrate the superiority of A2P over state-of-the-art methods, showcasing its ability to predict future anomalies. Our implementation code is available at https://github.com/KU-VGI/AP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 10 figures, 12 tables, ICML 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23596v1",
    "published_date": "2025-06-30 08:00:16 UTC",
    "updated_date": "2025-06-30 08:00:16 UTC"
  },
  {
    "arxiv_id": "2506.23589v1",
    "title": "Transition Matching: Scalable and Flexible Generative Modeling",
    "authors": [
      "Neta Shaul",
      "Uriel Singer",
      "Itai Gat",
      "Yaron Lipman"
    ],
    "abstract": "Diffusion and flow matching models have significantly advanced media generation, yet their design space is well-explored, somewhat limiting further improvements. Concurrently, autoregressive (AR) models, particularly those generating continuous tokens, have emerged as a promising direction for unifying text and media generation. This paper introduces Transition Matching (TM), a novel discrete-time, continuous-state generative paradigm that unifies and advances both diffusion/flow models and continuous AR generation. TM decomposes complex generation tasks into simpler Markov transitions, allowing for expressive non-deterministic probability transition kernels and arbitrary non-continuous supervision processes, thereby unlocking new flexible design avenues. We explore these choices through three TM variants: (i) Difference Transition Matching (DTM), which generalizes flow matching to discrete-time by directly learning transition probabilities, yielding state-of-the-art image quality and text adherence as well as improved sampling efficiency. (ii) Autoregressive Transition Matching (ARTM) and (iii) Full History Transition Matching (FHTM) are partially and fully causal models, respectively, that generalize continuous AR methods. They achieve continuous causal AR generation quality comparable to non-causal approaches and potentially enable seamless integration with existing AR text generation techniques. Notably, FHTM is the first fully causal model to match or surpass the performance of flow-based methods on text-to-image task in continuous domains. We demonstrate these contributions through a rigorous large-scale comparison of TM variants and relevant baselines, maintaining a fixed architecture, training data, and hyperparameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23589v1",
    "published_date": "2025-06-30 07:51:58 UTC",
    "updated_date": "2025-06-30 07:51:58 UTC"
  },
  {
    "arxiv_id": "2506.23584v2",
    "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation",
    "authors": [
      "Renjie Liang",
      "Zhengkang Fan",
      "Jinqian Pan",
      "Chenkun Sun",
      "Bruce Daniel Steinberg",
      "Russell Terry",
      "Jie Xu"
    ],
    "abstract": "Objective Renal cancer is a common malignancy and a major cause of cancer-related deaths. Computed tomography (CT) is central to early detection, staging, and treatment planning. However, the growing CT workload increases radiologists' burden and risks incomplete documentation. Automatically generating accurate reports remains challenging because it requires integrating visual interpretation with clinical reasoning. Advances in artificial intelligence (AI), especially large language and vision-language models, offer potential to reduce workload and enhance diagnostic quality.\n  Methods We propose a clinically informed, two-stage framework for automatic renal CT report generation. In Stage 1, a multi-task learning model detects structured clinical features from each 2D image. In Stage 2, a vision-language model generates free-text reports conditioned on the image and the detected features. To evaluate clinical fidelity, generated clinical features are extracted from the reports and compared with expert-annotated ground truth.\n  Results Experiments on an expert-labeled dataset show that incorporating detected features improves both report quality and clinical accuracy. The model achieved an average AUC of 0.75 for key imaging features and a METEOR score of 0.33, demonstrating higher clinical consistency and fewer template-driven errors.\n  Conclusion Linking structured feature detection with conditioned report generation provides a clinically grounded approach to integrate structured prediction and narrative drafting for renal CT reporting. This method enhances interpretability and clinical faithfulness, underscoring the value of domain-relevant evaluation metrics for medical AI development.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23584v2",
    "published_date": "2025-06-30 07:45:02 UTC",
    "updated_date": "2025-10-16 06:21:00 UTC"
  },
  {
    "arxiv_id": "2506.23581v2",
    "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection",
    "authors": [
      "Xiao Li",
      "Yiming Zhu",
      "Yifan Huang",
      "Wei Zhang",
      "Yingzhe He",
      "Jie Shi",
      "Xiaolin Hu"
    ],
    "abstract": "Object detection plays a crucial role in many security-sensitive applications. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, \\eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. While AT has been extensively studied in the $l_\\infty$ attack settings on classification models, AT against physically realizable attacks on object detectors has received limited exploration. Early attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored. In this work, we consider defending against various physically realizable attacks with a unified AT method. We propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures. Extensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7\\% over previous defense methods under one recent adversarial texture attack.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23581v2",
    "published_date": "2025-06-30 07:36:21 UTC",
    "updated_date": "2025-07-09 13:36:11 UTC"
  },
  {
    "arxiv_id": "2506.23576v1",
    "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models",
    "authors": [
      "Maria Carolina Cornelia Wit",
      "Jun Pang"
    ],
    "abstract": "Recent advances in large language models (LLMs) have raised concerns about jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper investigates the use of multi-agent LLM systems as a defence against such attacks. We evaluate three jailbreaking strategies, including the original AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the AutoDefense framework, we compare single-agent setups with two- and three-agent configurations. Our results show that multi-agent systems enhance resistance to jailbreaks, especially by reducing false negatives. However, its effectiveness varies by attack type, and it introduces trade-offs such as increased false positives and computational overhead. These findings point to the limitations of current automated defences and suggest directions for improving alignment robustness in future LLM systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2506.23576v1",
    "published_date": "2025-06-30 07:29:07 UTC",
    "updated_date": "2025-06-30 07:29:07 UTC"
  },
  {
    "arxiv_id": "2506.23573v1",
    "title": "Online Human Action Detection during Escorting",
    "authors": [
      "Siddhartha Mondal",
      "Avik Mitra",
      "Chayan Sarkar"
    ],
    "abstract": "The deployment of robot assistants in large indoor spaces has seen significant growth, with escorting tasks becoming a key application. However, most current escorting robots primarily rely on navigation-focused strategies, assuming that the person being escorted will follow without issue. In crowded environments, this assumption often falls short, as individuals may struggle to keep pace, become obstructed, get distracted, or need to stop unexpectedly. As a result, conventional robotic systems are often unable to provide effective escorting services due to their limited understanding of human movement dynamics. To address these challenges, an effective escorting robot must continuously detect and interpret human actions during the escorting process and adjust its movement accordingly. However, there is currently no existing dataset designed specifically for human action detection in the context of escorting. Given that escorting often occurs in crowded environments, where other individuals may enter the robot's camera view, the robot also needs to identify the specific human it is escorting (the subject) before predicting their actions. Since no existing model performs both person re-identification and action prediction in real-time, we propose a novel neural network architecture that can accomplish both tasks. This enables the robot to adjust its speed dynamically based on the escortee's movements and seamlessly resume escorting after any disruption. In comparative evaluations against strong baselines, our system demonstrates superior efficiency and effectiveness, showcasing its potential to significantly improve robotic escorting services in complex, real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in IEEE RO-MAN '25",
    "pdf_url": "https://arxiv.org/pdf/2506.23573v1",
    "published_date": "2025-06-30 07:25:31 UTC",
    "updated_date": "2025-06-30 07:25:31 UTC"
  },
  {
    "arxiv_id": "2506.23563v1",
    "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI",
    "authors": [
      "Huanjin Yao",
      "Jiaxing Huang",
      "Yawen Qiu",
      "Michael K. Chen",
      "Wenzheng Liu",
      "Wei Zhang",
      "Wenjie Zeng",
      "Xikun Zhang",
      "Jingyi Zhang",
      "Yuxin Song",
      "Wenhao Wu",
      "Dacheng Tao"
    ],
    "abstract": "Reasoning plays a crucial role in advancing Multimodal Large Language Models (MLLMs) toward Artificial General Intelligence. However, existing MLLM benchmarks often fall short in precisely and comprehensively evaluating long-chain reasoning abilities from three key aspects: (1) lack of difficulty and diversity, (2) susceptibility to guessability and memorization, (3) inadequate assessment of intermediate reasoning steps. To fill this gap, we introduce MMReason, a new benchmark designed to precisely and comprehensively evaluate MLLM long-chain reasoning capability with diverse, open-ended, challenging questions. First, we curate challenging questions requiring multi-step reasoning from various fields (i.e., 6 disciplines) and multiple difficulty levels (i.e., from pre-university to university, and from foundational to competition tiers). Second, these questions are reformulated into an open-ended format and filtered using a multi-model voting technique to eliminate shortcut cases related to guessing and memorization, ensuring robust reasoning evaluations. Third, we annotate the questions with detailed step-by-step solutions, and design a reference-based ternary scoring mechanism to reliably assess intermediate reasoning steps. With MMReason, we benchmark popular leading MLLMs and provide an in-depth analysis of their reasoning capabilities. We hope MMReason will serve as a valuable resource for advancing MLLM reasoning research. Code will be available at https://github.com/HJYao00/MMReason.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical report",
    "pdf_url": "https://arxiv.org/pdf/2506.23563v1",
    "published_date": "2025-06-30 07:14:38 UTC",
    "updated_date": "2025-06-30 07:14:38 UTC"
  },
  {
    "arxiv_id": "2506.23560v1",
    "title": "Tensor Train Quantum State Tomography using Compressed Sensing",
    "authors": [
      "Shakir Showkat Sofi",
      "Charlotte Vermeylen",
      "Lieven De Lathauwer"
    ],
    "abstract": "Quantum state tomography (QST) is a fundamental technique for estimating the state of a quantum system from measured data and plays a crucial role in evaluating the performance of quantum devices. However, standard estimation methods become impractical due to the exponential growth of parameters in the state representation. In this work, we address this challenge by parameterizing the state using a low-rank block tensor train decomposition and demonstrate that our approach is both memory- and computationally efficient. This framework applies to a broad class of quantum states that can be well approximated by low-rank decompositions, including pure states, nearly pure states, and ground states of Hamiltonians.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "eess.SP",
      "math.OC"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted for publication in EUSIPCO 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23560v1",
    "published_date": "2025-06-30 07:06:50 UTC",
    "updated_date": "2025-06-30 07:06:50 UTC"
  },
  {
    "arxiv_id": "2506.23549v2",
    "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers",
    "authors": [
      "Huai-Chih Wang",
      "Hsiang-Chun Chuang",
      "Hsi-Chun Cheng",
      "Dai-Jie Wu",
      "Shao-Hua Sun"
    ],
    "abstract": "Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require impractically extensive fine-tuning. To overcome these limitations, we propose Coordination Transformers (\\coot), a novel in-context coordination framework that uses recent interaction histories to rapidly adapt to unseen partners. Unlike prior approaches that primarily aim to diversify training partners, \\coot explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed interactions. Trained on trajectories collected from diverse pairs of agents with complementary preferences, \\coot quickly learns effective coordination strategies without explicit supervision or parameter updates. Across diverse coordination tasks in Overcooked, \\coot consistently outperforms baselines including population-based approaches, gradient-based fine-tuning, and a Meta-RL-inspired contextual adaptation method. Notably, fine-tuning proves unstable and ineffective, while Meta-RL struggles to achieve reliable coordination. By contrast, \\coot achieves stable, rapid in-context adaptation and is consistently ranked the most effective collaborator in human evaluations.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 12 tables, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23549v2",
    "published_date": "2025-06-30 06:45:39 UTC",
    "updated_date": "2025-10-18 07:51:43 UTC"
  },
  {
    "arxiv_id": "2507.02961v1",
    "title": "Flow-Through Tensors: A Unified Computational Graph Architecture for Multi-Layer Transportation Network Optimization",
    "authors": [
      "Xuesong",
      "Zhou",
      "Taehooie Kim",
      "Mostafa Ameli",
      "Henan",
      "Zhu",
      "Yu- dai Honma",
      "Ram M. Pendyala"
    ],
    "abstract": "Modern transportation network modeling increasingly involves the integration of diverse methodologies including sensor-based forecasting, reinforcement learning, classical flow optimization, and demand modeling that have traditionally been developed in isolation. This paper introduces Flow Through Tensors (FTT), a unified computational graph architecture that connects origin destination flows, path probabilities, and link travel times as interconnected tensors. Our framework makes three key contributions: first, it establishes a consistent mathematical structure that enables gradient-based optimization across previously separate modeling elements; second, it supports multidimensional analysis of traffic patterns over time, space, and user groups with precise quantification of system efficiency; third, it implements tensor decomposition techniques that maintain computational tractability for large scale applications. These innovations collectively enable real time control strategies, efficient coordination between multiple transportation modes and operators, and rigorous enforcement of physical network constraints. The FTT framework bridges the gap between theoretical transportation models and practical deployment needs, providing a foundation for next generation integrated mobility systems.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02961v1",
    "published_date": "2025-06-30 06:42:23 UTC",
    "updated_date": "2025-06-30 06:42:23 UTC"
  },
  {
    "arxiv_id": "2507.00085v1",
    "title": "A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism",
    "authors": [
      "Ruiyuan Jiang",
      "Dongyao Jia",
      "Eng Gee Lim",
      "Pengfei Fan",
      "Yuli Zhang",
      "Shangbo Wang"
    ],
    "abstract": "Accurate traffic prediction is essential for Intelligent Transportation Systems (ITS), yet current methods struggle with the inherent complexity and non-linearity of traffic dynamics, making it difficult to integrate spatial and temporal characteristics. Furthermore, existing approaches use static techniques to address non-stationary and anomalous historical data, which limits adaptability and undermines data smoothing. To overcome these challenges, we propose the Graph Fusion Enhanced Network (GFEN), an innovative framework for network-level traffic speed prediction. GFEN introduces a novel topological spatiotemporal graph fusion technique that meticulously extracts and merges spatial and temporal correlations from both data distribution and network topology using trainable methods, enabling the modeling of multi-scale spatiotemporal features. Additionally, GFEN employs a hybrid methodology combining a k-th order difference-based mathematical framework with an attention-based deep learning structure to adaptively smooth historical observations and dynamically mitigate data anomalies and non-stationarity. Extensive experiments demonstrate that GFEN surpasses state-of-the-art methods by approximately 6.3% in prediction accuracy and exhibits convergence rates nearly twice as fast as recent hybrid models, confirming its superior performance and potential to significantly enhance traffic prediction system efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.00085v1",
    "published_date": "2025-06-30 06:33:47 UTC",
    "updated_date": "2025-06-30 06:33:47 UTC"
  },
  {
    "arxiv_id": "2507.05266v1",
    "title": "User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs",
    "authors": [
      "Sougata Saha",
      "Monojit Choudhury"
    ],
    "abstract": "Measuring the generalization ability of Large Language Models (LLMs) is challenging due to data contamination. As models grow and computation becomes cheaper, ensuring tasks and test cases are unseen during training phases will become nearly impossible. We argue that knowledge-retrieval and reasoning tasks are not ideal for measuring generalization, as LLMs are not trained for specific tasks. Instead, we propose user behavior prediction, also a key aspect of personalization, as a theoretically sound, scalable, and robust alternative. We introduce a novel framework for this approach and test it on movie and music recommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct. Results align with our framework's predictions, showing GPT-4o outperforms GPT-4o-mini and Llama, though all models have much room for improvement, especially Llama.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.05266v1",
    "published_date": "2025-06-30 06:14:32 UTC",
    "updated_date": "2025-06-30 06:14:32 UTC"
  },
  {
    "arxiv_id": "2506.23538v2",
    "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound",
    "authors": [
      "Yuhao Huang",
      "Yueyue Xu",
      "Haoran Dou",
      "Jiaxiao Deng",
      "Xin Yang",
      "Hongyu Zheng",
      "Dong Ni"
    ],
    "abstract": "Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage, preterm birth, and an increased risk of pregnancy complications. Compared to traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane, providing a clear visualization of the uterine morphology for assessing CUAs accurately. In this paper, we propose an intelligent system for simultaneous automated plane localization and CUA diagnosis. Our highlights are: 1) we develop a denoising diffusion model with local (plane) and global (volume/text) guidance, using an adaptive weighting strategy to optimize attention allocation to different conditions; 2) we introduce a reinforcement learning-based framework with unsupervised rewards to extract the key slice summary from redundant sequences, fully integrating information across multiple planes to reduce learning difficulty; 3) we provide text-driven uncertainty modeling for coarse prediction, and leverage it to adjust the classification probability for overall performance improvement. Extensive experiments on a large 3D uterine US dataset show the efficacy of our method, in terms of plane localization and CUA diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI 2025;10 pages, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23538v2",
    "published_date": "2025-06-30 06:07:41 UTC",
    "updated_date": "2025-09-11 06:34:11 UTC"
  },
  {
    "arxiv_id": "2506.23524v1",
    "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning",
    "authors": [
      "Phan Quoc Hung Mai",
      "Quang Hung Nguyen",
      "Phuong Giang Duong",
      "Hong Hanh Nguyen",
      "Nguyen Tuan Long"
    ],
    "abstract": "In the field of education, understanding students' opinions through their comments is crucial, especially in the Vietnamese language, where resources remain limited. Existing educational datasets often lack domain relevance and student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese dataset for Educational Sentiment Classification and Topic Classification, curated from university forums, which offers more samples, richer class diversity, longer texts, and broader vocabulary. In addition, we explore multitask learning using encoder-only language models (BERT), in which we showed that it achieves performance up to 83.7% and 79.8% accuracy for sentiment and topic classification tasks. We also benchmark our dataset and model with other datasets and models, including Large Language Models, and discuss these benchmarks. The dataset is publicly available at: https://huggingface.co/datasets/hung20gg/NEU-ESC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23524v1",
    "published_date": "2025-06-30 05:19:04 UTC",
    "updated_date": "2025-06-30 05:19:04 UTC"
  },
  {
    "arxiv_id": "2506.23520v2",
    "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data",
    "authors": [
      "Yu Zhang",
      "Ruijie Yu",
      "Jidong Tian",
      "Feng Zhu",
      "Jiapeng Liu",
      "Xiaokang Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "abstract": "With the increasing interest in robotic synthesis in the context of organic chemistry, the automated extraction of chemical procedures from literature is critical. However, this task remains challenging due to the inherent ambiguity of chemical language and the high cost of human annotation required for developing reliable computer-aided extraction protocols. Here, we present ChemActor, a fully fine-tuned large language model (LLM), as a chemical executor to convert between unstructured experimental procedures and structured action sequences. We propose a sequential LLM-generated data framework to address the challenges of insufficient and low-quality annotated data. This framework integrates a data selection module that selects data based on distribution divergence, with a general-purpose LLM, to generate machine-executable actions from a single molecule input. Additionally, we introduce a novel multi-round LLMs circle review metric, which reflects the model's advanced understanding of chemical experimental procedures. Extensive experiments on reaction-to-description (R2D) and description-to-action (D2A) tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves state-of-the-art performance, outperforming the baseline model by 10%. The code is available at: https://github.com/Zhanghahah/ChemActor.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23520v2",
    "published_date": "2025-06-30 05:11:19 UTC",
    "updated_date": "2025-07-01 08:11:18 UTC"
  },
  {
    "arxiv_id": "2506.23517v1",
    "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays",
    "authors": [
      "Selin Dik",
      "Osman Erdem",
      "Mehmet Dik"
    ],
    "abstract": "As the use of AI tools by students has become more prevalent, instructors have started using AI detection tools like GPTZero and QuillBot to detect AI written text. However, the reliability of these detectors remains uncertain. In our study, we focused mostly on the success rate of GPTZero, the most-used AI detector, in identifying AI-generated texts based on different lengths of randomly submitted essays: short (40-100 word count), medium (100-350 word count), and long (350-800 word count). We gathered a data set consisting of twenty-eight AI-generated papers and fifty human-written papers. With this randomized essay data, papers were individually plugged into GPTZero and measured for percentage of AI generation and confidence. A vast majority of the AI-generated papers were detected accurately (ranging from 91-100% AI believed generation), while the human generated essays fluctuated; there were a handful of false positives. These findings suggest that although GPTZero is effective at detecting purely AI-generated content, its reliability in distinguishing human-authored texts is limited. Educators should therefore exercise caution when relying solely on AI detection tools.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23517v1",
    "published_date": "2025-06-30 04:53:27 UTC",
    "updated_date": "2025-06-30 04:53:27 UTC"
  },
  {
    "arxiv_id": "2506.23516v3",
    "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
    "authors": [
      "Seung-Wook Kim",
      "Seongyeol Kim",
      "Jiah Kim",
      "Seowon Ji",
      "Se-Ho Lee"
    ],
    "abstract": "Federated learning (FL) often suffers from performance degradation due to key challenges such as data heterogeneity and communication constraints. To address these limitations, we present a novel FL framework called FedWSQ, which integrates weight standardization (WS) and the proposed distribution-aware non-uniform quantization (DANUQ). WS enhances FL performance by filtering out biased components in local updates during training, thereby improving the robustness of the model against data heterogeneity and unstable client participation. In addition, DANUQ minimizes quantization errors by leveraging the statistical properties of local model updates. As a result, FedWSQ significantly reduces communication overhead while maintaining superior model accuracy. Extensive experiments on FL benchmark datasets demonstrate that FedWSQ consistently outperforms existing FL methods across various challenging FL settings, including extreme data heterogeneity and ultra-low-bit communication scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23516v3",
    "published_date": "2025-06-30 04:46:25 UTC",
    "updated_date": "2025-07-22 03:52:09 UTC"
  },
  {
    "arxiv_id": "2507.02960v1",
    "title": "Optimization of Low-Latency Spiking Neural Networks Utilizing Historical Dynamics of Refractory Periods",
    "authors": [
      "Liying Tao",
      "Zonglin Yang",
      "Delong Shang"
    ],
    "abstract": "The refractory period controls neuron spike firing rate, crucial for network stability and noise resistance. With advancements in spiking neural network (SNN) training methods, low-latency SNN applications have expanded. In low-latency SNNs, shorter simulation steps render traditional refractory mechanisms, which rely on empirical distributions or spike firing rates, less effective. However, omitting the refractory period amplifies the risk of neuron over-activation and reduces the system's robustness to noise. To address this challenge, we propose a historical dynamic refractory period (HDRP) model that leverages membrane potential derivative with historical refractory periods to estimate an initial refractory period and dynamically adjust its duration. Additionally, we propose a threshold-dependent refractory kernel to mitigate excessive neuron state accumulation. Our approach retains the binary characteristics of SNNs while enhancing both noise resistance and overall performance. Experimental results show that HDRP-SNN significantly reduces redundant spikes compared to traditional SNNs, and achieves state-of-the-art (SOTA) accuracy both on static datasets and neuromorphic datasets. Moreover, HDRP-SNN outperforms artificial neural networks (ANNs) and traditional SNNs in noise resistance, highlighting the crucial role of the HDRP mechanism in enhancing the performance of low-latency SNNs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02960v1",
    "published_date": "2025-06-30 04:42:19 UTC",
    "updated_date": "2025-06-30 04:42:19 UTC"
  },
  {
    "arxiv_id": "2506.23514v1",
    "title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments",
    "authors": [
      "Sai Krishna Ghanta",
      "Ramviyas Parasuraman"
    ],
    "abstract": "Relative localization is a crucial capability for multi-robot systems operating in GPS-denied environments. Existing approaches for multi-robot relative localization often depend on costly or short-range sensors like cameras and LiDARs. Consequently, these approaches face challenges such as high computational overhead (e.g., map merging) and difficulties in disjoint environments. To address this limitation, this paper introduces MGPRL, a novel distributed framework for multi-robot relative localization using convex-hull of multiple Wi-Fi access points (AP). To accomplish this, we employ co-regionalized multi-output Gaussian Processes for efficient Radio Signal Strength Indicator (RSSI) field prediction and perform uncertainty-aware multi-AP localization, which is further coupled with weighted convex hull-based alignment for robust relative pose estimation. Each robot predicts the RSSI field of the environment by an online scan of APs in its environment, which are utilized for position estimation of multiple APs. To perform relative localization, each robot aligns the convex hull of its predicted AP locations with that of the neighbor robots. This approach is well-suited for devices with limited computational resources and operates solely on widely available Wi-Fi RSSI measurements without necessitating any dedicated pre-calibration or offline fingerprinting. We rigorously evaluate the performance of the proposed MGPRL in ROS simulations and demonstrate it with real-world experiments, comparing it against multiple state-of-the-art approaches. The results showcase that MGPRL outperforms existing methods in terms of localization accuracy and computational efficiency. Finally, we open source MGPRL as a ROS package https://github.com/herolab-uga/MGPRL.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IROS 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23514v1",
    "published_date": "2025-06-30 04:35:00 UTC",
    "updated_date": "2025-06-30 04:35:00 UTC"
  },
  {
    "arxiv_id": "2507.22065v1",
    "title": "Fuzzing: Randomness? Reasoning! Efficient Directed Fuzzing via Large Language Models",
    "authors": [
      "Xiaotao Feng",
      "Xiaogang Zhu",
      "Kun Hu",
      "Jincheng Wang",
      "Yingjie Cao",
      "Guang Gong",
      "Jianfeng Pan"
    ],
    "abstract": "Fuzzing is highly effective in detecting bugs due to the key contribution of randomness. However, randomness significantly reduces the efficiency of fuzzing, causing it to cost days or weeks to expose bugs. Even though directed fuzzing reduces randomness by guiding fuzzing towards target buggy locations, the dilemma of randomness still challenges directed fuzzers. Two critical components, which are seeds and mutators, contain randomness and are closely tied to the conditions required for triggering bugs. Therefore, to address the challenge of randomness, we propose to use large language models (LLMs) to remove the randomness in seeds and reduce the randomness in mutators. With their strong reasoning and code generation capabilities, LLMs can be used to generate reachable seeds that target pre-determined locations and to construct bug-specific mutators tailored for specific bugs. We propose RandLuzz, which integrates LLMs and directed fuzzing, to improve the quality of seeds and mutators, resulting in efficient bug exposure. RandLuzz analyzes function call chain or functionality to guide LLMs in generating reachable seeds. To construct bug-specific mutators, RandLuzz uses LLMs to perform bug analysis, obtaining information such as bug causes and mutation suggestions, which further help generate code that performs bug-specific mutations. We evaluate RandLuzz by comparing it with four state-of-the-art directed fuzzers, AFLGo, Beacon, WindRanger, and SelectFuzz. With RandLuzz-generated seeds, the fuzzers achieve an average speedup ranging from 2.1$\\times$ to 4.8$\\times$ compared to using widely-used initial seeds. Additionally, when evaluated on individual bugs, RandLuzz achieves up to a 2.7$\\times$ speedup compared to the second-fastest exposure. On 8 bugs, RandLuzz can even expose them within 60 seconds.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22065v1",
    "published_date": "2025-06-30 04:33:52 UTC",
    "updated_date": "2025-06-30 04:33:52 UTC"
  },
  {
    "arxiv_id": "2507.00083v1",
    "title": "Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks",
    "authors": [
      "Wei Meng"
    ],
    "abstract": "This study addresses the lack of structured causal modeling between tactical strike behavior and strategic delay in current strategic-level simulations, particularly the structural bottlenecks in capturing intermediate variables within the \"resilience - nodal suppression - negotiation window\" chain. We propose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN), a novel framework that closes the causal loop from tactical input to strategic delay output. The model integrates graph attention mechanisms, counterfactual simulation units, and spatial intervention node reconstruction to enable dynamic simulations of strike configurations and synchronization strategies. Training data are generated from a multi-physics simulation platform (GEANT4 + COMSOL) under NIST SP 800-160 standards, ensuring structural traceability and policy-level validation. Experimental results demonstrate that IA-STGNN significantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost), achieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5 percent accuracy, while improving causal path consistency and intervention stability. IA-STGNN enables interpretable prediction of strategic delay and supports applications such as nuclear deterrence simulation, diplomatic window assessment, and multi-strategy optimization, providing a structured and transparent AI decision-support mechanism for high-level policy modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper proposes the first closed-loop causal modeling framework (IA-STGNN) that links tactical strike variables to strategic delay outcomes via graph neural networks with counterfactual reasoning",
    "pdf_url": "https://arxiv.org/pdf/2507.00083v1",
    "published_date": "2025-06-30 04:26:10 UTC",
    "updated_date": "2025-06-30 04:26:10 UTC"
  },
  {
    "arxiv_id": "2507.02959v1",
    "title": "A Novel Active Learning Approach to Label One Million Unknown Malware Variants",
    "authors": [
      "Ahmed Bensaoud",
      "Jugal Kalita"
    ],
    "abstract": "Active learning for classification seeks to reduce the cost of labeling samples by finding unlabeled examples about which the current model is least certain and sending them to an annotator/expert to label. Bayesian theory can provide a probabilistic view of deep neural network models by asserting a prior distribution over model parameters and estimating the uncertainties by posterior distribution over these parameters. This paper proposes two novel active learning approaches to label one million malware examples belonging to different unknown modern malware families. The first model is Inception-V4+PCA combined with several support vector machine (SVM) algorithms (UTSVM, PSVM, SVM-GSU, TBSVM). The second model is Vision Transformer based Bayesian Neural Networks ViT-BNN. Our proposed ViT-BNN is a state-of-the-art active learning approach that differs from current methods and can apply to any particular task. The experiments demonstrate that the ViT-BNN is more stable and robust in handling uncertainty.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2507.02959v1",
    "published_date": "2025-06-30 04:18:31 UTC",
    "updated_date": "2025-06-30 04:18:31 UTC"
  },
  {
    "arxiv_id": "2506.23508v3",
    "title": "Why Reinforcement Fine-Tuning Enables MLLMs Preserve Prior Knowledge Better: A Data Perspective",
    "authors": [
      "Zhihao Zhang",
      "Qiaole Dong",
      "Qi Zhang",
      "Jun Zhao",
      "Enyu Zhou",
      "Zhiheng Xi",
      "Senjie Jin",
      "Xiaoran Fan",
      "Yuhao Zhou",
      "Mingqi Wu",
      "Yanwei Fu",
      "Tao Ji",
      "Tao Gui",
      "Xuanjing Huang",
      "Kai Chen"
    ],
    "abstract": "Post-training algorithms such as Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large language models to downstream tasks. While effective at task adaptation, their impact on prior knowledge remains unclear. In this paper, we introduce jigsaw puzzles as a novel task absent from existing pretraining corpora and systematically study the behavior of SFT and RFT on open-source multimodal model, Qwen2.5-VL series. Our experiments reveal a sharp trade-off: SFT enables rapid task acquisition but leads to catastrophic forgetting, whereas RFT learns more slowly but maintains prior knowledge. We study this phenomenon through learning dynamics by examining both the magnitude and direction of how training data influence prior knowledge. Our analysis shows that RFT mainly reinforces correct samples naturally aligned with the base model's probability landscape, leading to weaker interference with prior knowledge. Moreover, training on RFT-simulated rollouts, which exert a small magnitude of influence and are well aligned in direction to prior knowledge, allows SFT to preserve prior knowledge better while rapidly learning new tasks. These findings suggest that distribution of training data, rather than algorithmic differences, plays a central role in forgetting, and highlight RFT's potential for stable continual learning in multimodal large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages (Preprint.)",
    "pdf_url": "https://arxiv.org/pdf/2506.23508v3",
    "published_date": "2025-06-30 04:15:01 UTC",
    "updated_date": "2025-12-16 08:41:22 UTC"
  },
  {
    "arxiv_id": "2506.23506v1",
    "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI",
    "authors": [
      "Bowen Xin",
      "Rohan Hickey",
      "Tamara Blake",
      "Jin Jin",
      "Claire E Wainwright",
      "Thomas Benkert",
      "Alto Stemmer",
      "Peter Sly",
      "David Coman",
      "Jason Dowling"
    ],
    "abstract": "Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE) represents a recent breakthrough in lung structure imaging, providing image resolution and quality comparable to computed tomography (CT). Due to the absence of ionising radiation, MRI is often preferred over CT in paediatric diseases such as cystic fibrosis (CF), one of the most common genetic disorders in Caucasians. To assess structural lung damage in CF imaging, CT scoring systems provide valuable quantitative insights for disease diagnosis and progression. However, few quantitative scoring systems are available in structural lung MRI (e.g., UTE-MRI). To provide fast and accurate quantification in lung MRI, we investigated the feasibility of novel Artificial intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3) lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification and reporting. The results shows that our APL scoring took 8.2 minutes per subject, which was more than twice as fast as the previous grid-level scoring. Additionally, our pixel-level scoring was statistically more accurate (p=0.021), while strongly correlating with grid-level scoring (R=0.973, p=5.85e-9). This tool has great potential to streamline the workflow of UTE lung MRI in clinical settings, and be extended to other structural lung MRI sequences (e.g., BLADE MRI), and for other lung diseases (e.g., bronchopulmonary dysplasia).",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "Oral presentation in ISMRM2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23506v1",
    "published_date": "2025-06-30 04:08:42 UTC",
    "updated_date": "2025-06-30 04:08:42 UTC"
  },
  {
    "arxiv_id": "2506.23504v1",
    "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM",
    "authors": [
      "Bosubabu Sambana",
      "Kotamsetty Geethika Devi",
      "Bandi Rajeswara Reddy",
      "Galeti Mohammad Hussain",
      "Gownivalla Siddartha"
    ],
    "abstract": "The recent development of advanced machine learning methods for hybrid models has greatly addressed the need for the correct prediction of electrical prices. This method combines AlexNet and LSTM algorithms, which are used to introduce a new model with higher accuracy in price forecasting. Despite RNN and ANN being effective, they often fail to deal with forex time sequence data. The traditional methods do not accurately forecast the prices. These traditional methods only focus on demand and price which leads to insufficient analysis of data. To address this issue, using the hybrid approach, which focuses on external variables that also effect the predicted prices. Nevertheless, due to AlexNet's excellent feature extraction and LSTM's learning sequential patterns, the prediction accuracy is vastly increased. The model is built on the past data, which has been supplied with the most significant elements like demand, temperature, sunlight, and rain. For example, the model applies methods, such as minimum-maximum scaling and a time window, to predict the electricity prices of the future. The results show that this hybrid model is good than the standalone ones in terms of accuracy. Although we got our accuracy rating of 97.08, it shows higher accompaniments than remaining models RNN and ANN with accuracies of 96.64 and 96.63 respectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 Pages, 7 Figures",
    "pdf_url": "https://arxiv.org/pdf/2506.23504v1",
    "published_date": "2025-06-30 04:06:24 UTC",
    "updated_date": "2025-06-30 04:06:24 UTC"
  },
  {
    "arxiv_id": "2506.23503v1",
    "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence",
    "authors": [
      "Bosubabu Sambana",
      "Kondreddygari Archana",
      "Suram Indhra Sena Reddy",
      "Shaik Meethaigar Jameer Basha",
      "Shaik Karishma"
    ],
    "abstract": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the irrational thought patterns associated with mental health disorders, but its effectiveness relies on accurately identifying cognitive pathways to provide targeted treatment. In today's digital age, individuals often express negative emotions on social media, where they may reveal cognitive distortions, and in severe cases, exhibit suicidal tendencies. However, there is a significant gap in methodologies designed to analyze these cognitive pathways, which could be critical for psychotherapists aiming to deliver timely and effective interventions in online environments. Cognitive Behavioral Therapy (CBT) framework leveraging acceptance, commitment and data augmentation to categorize and address both textual and visual content as positive or negative. Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5, PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages focusing on detecting negative emotions and cognitive distortions within social media data. While existing models are primarily designed to identify negative thoughts, the proposed system goes beyond this by predicting additional negative side effects and other potential mental health disorders likes Phobias, Eating Disorders. This enhancement allows for a more comprehensive understanding and intervention strategy, offering psychotherapists a powerful tool for early detection and treatment of various psychological issues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23503v1",
    "published_date": "2025-06-30 03:59:00 UTC",
    "updated_date": "2025-06-30 03:59:00 UTC"
  },
  {
    "arxiv_id": "2506.23492v1",
    "title": "Sample Margin-Aware Recalibration of Temperature Scaling",
    "authors": [
      "Haolan Guo",
      "Linwei Tao",
      "Haoyang Luo",
      "Minjing Dong",
      "Chang Xu"
    ],
    "abstract": "Recent advances in deep learning have significantly improved predictive accuracy. However, modern neural networks remain systematically overconfident, posing risks for deployment in safety-critical scenarios. Current post-hoc calibration methods face a fundamental dilemma: global approaches like Temperature Scaling apply uniform adjustments across all samples, introducing high bias despite computational efficiency, while more expressive methods that operate on full logit distributions suffer from high variance due to noisy high-dimensional inputs and insufficient validation data. To address these challenges, we propose Sample Margin-Aware Recalibration of Temperature (SMART), a lightweight, data-efficient recalibration method that precisely scales logits based on the margin between the top two logits -- termed the logit gap. Specifically, the logit gap serves as a denoised, scalar signal directly tied to decision boundary uncertainty, providing a robust indicator that avoids the noise inherent in high-dimensional logit spaces while preserving model prediction invariance. Meanwhile, SMART employs a novel soft-binned Expected Calibration Error (SoftECE) objective that balances model bias and variance through adaptive binning, enabling stable parameter updates even with extremely limited calibration data. Extensive evaluations across diverse datasets and architectures demonstrate that SMART achieves state-of-the-art calibration performance even with substantially fewer parameters compared to existing parametric methods, offering a principled, robust, and highly efficient solution for practical uncertainty quantification in neural network predictions. The source code is available at: https://anonymous.4open.science/r/SMART-8B11.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23492v1",
    "published_date": "2025-06-30 03:35:05 UTC",
    "updated_date": "2025-06-30 03:35:05 UTC"
  },
  {
    "arxiv_id": "2506.23491v3",
    "title": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding",
    "authors": [
      "ZongHan Hsieh",
      "Tzer-Jen Wei",
      "ShengJing Yang"
    ],
    "abstract": "In this paper, we present ZonUI-3B, a lightweight Vision-Language Model (VLM) that can be fully trained on a single consumer-grade GPU (RTX 4090) while delivering performance comparable to significantly larger models on GUI grounding tasks. The model incorporates several key innovations: (i) combine cross-platform, multi-resolution dataset of 24K examples from diverse sources including mobile, desktop, and web GUI screenshots to effectively address data scarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning strategy, where initial cross-platform training establishes robust GUI understanding, followed by specialized fine-tuning on high-resolution data to significantly enhance model adaptability; and (iii) data curation and redundancy reduction strategies, demonstrating that randomly sampling a smaller subset with reduced redundancy achieves performance comparable to larger datasets, emphasizing data diversity over sheer volume. Empirical evaluation on standard GUI grounding benchmarks, including ScreenSpot, ScreenSpot-v2, and the challenging ScreenSpot-Pro, highlights ZonUI-3B's exceptional accuracy, achieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters. Ablation studies validate the critical role of balanced sampling and two-stage fine-tuning in enhancing robustness, particularly in high-resolution desktop scenarios. The ZonUI-3B is available at: https://github.com/Han1018/ZonUI-3B",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23491v3",
    "published_date": "2025-06-30 03:33:02 UTC",
    "updated_date": "2025-07-18 06:03:26 UTC"
  },
  {
    "arxiv_id": "2506.23490v1",
    "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound",
    "authors": [
      "Junxuan Yu",
      "Yaofei Duan",
      "Yuhao Huang",
      "Yu Wang",
      "Rongbo Ling",
      "Weihao Luo",
      "Ang Zhang",
      "Jingxian Xu",
      "Qiongying Ni",
      "Yongsong Zhou",
      "Binghan Li",
      "Haoran Dou",
      "Liping Liu",
      "Yanfen Chu",
      "Feng Geng",
      "Zhe Sheng",
      "Zhifeng Ding",
      "Dingxin Zhang",
      "Rui Huang",
      "Yuhang Zhang",
      "Xiaowei Xu",
      "Tao Tan",
      "Dong Ni",
      "Zhongshan Gou",
      "Xin Yang"
    ],
    "abstract": "Echocardiography is routine for cardiac examination. However, 2D ultrasound (US) struggles with accurate metric calculation and direct observation of 3D cardiac structures. Moreover, 3D US is limited by low resolution, small field of view and scarce availability in practice. Constructing the cardiac anatomical twin from 2D images is promising to provide precise treatment planning and clinical quantification. However, it remains challenging due to the rare paired data, complex structures, and US noises. In this study, we introduce a novel generative framework UltraTwin, to obtain cardiac anatomical twin from sparse multi-view 2D US. Our contribution is three-fold. First, pioneered the construction of a real-world and high-quality dataset containing strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we propose a coarse-to-fine scheme to achieve hierarchical reconstruction optimization. Last, we introduce an implicit autoencoder for topology-aware constraints. Extensive experiments show that UltraTwin reconstructs high-quality anatomical twins versus strong competitors. We believe it advances anatomical twin modeling for potential applications in personalized cardiac care.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "accepted by miccai 2025",
    "pdf_url": "https://arxiv.org/pdf/2506.23490v1",
    "published_date": "2025-06-30 03:27:42 UTC",
    "updated_date": "2025-06-30 03:27:42 UTC"
  },
  {
    "arxiv_id": "2506.23485v1",
    "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent",
    "authors": [
      "Haocheng Yu",
      "Yaxiong Wu",
      "Hao Wang",
      "Wei Guo",
      "Yong Liu",
      "Yawen Li",
      "Yuyang Ye",
      "Junping Du",
      "Enhong Chen"
    ],
    "abstract": "Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing users' real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agent's and human experts' experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:https://github.com/Alcein/TAIRA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23485v1",
    "published_date": "2025-06-30 03:15:50 UTC",
    "updated_date": "2025-06-30 03:15:50 UTC"
  },
  {
    "arxiv_id": "2507.00082v1",
    "title": "Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission",
    "authors": [
      "Faranaksadat Solat",
      "Joohyung Lee",
      "Mohamed Seif",
      "Dusit Niyato",
      "H. Vincent Poor"
    ],
    "abstract": "Hybrid Language Models (HLMs) combine the low-latency efficiency of Small Language Models (SLMs) on edge devices with the high accuracy of Large Language Models (LLMs) on centralized servers. Unlike traditional end-to-end LLM inference, HLMs reduce latency and communication by invoking LLMs only when local SLM predictions are uncertain, i.e., when token-level confidence is low or entropy is high. However, ambiguous or low-confidence predictions still require frequent offloading to the LLM, leading to significant communication overhead in bandwidth-constrained settings. To address this, we propose FedHLM, a communication-efficient HLM framework that integrates uncertainty-aware inference with Federated Learning (FL). FedHLM's key innovation lies in collaboratively learning token-level uncertainty thresholds that govern when LLM assistance is needed. Rather than using static or manually tuned thresholds, FedHLM employs FL to optimize these thresholds in a privacy-preserving, distributed manner. Additionally, it leverages embedding-based token representations for Peer-to-Peer (P2P) resolution, enabling clients to reuse tokens inferred by semantically similar peers without engaging the LLM. We further introduce hierarchical model aggregation: edge servers refine local routing policies through client updates, while cross-cluster coordination aligns global decision boundaries. This layered design captures recurring uncertainty patterns, reducing redundant LLM queries. Experiments on large-scale news classification tasks show that FedHLM reduces LLM transmissions by over 95 percent with negligible accuracy loss, making it well-suited for scalable and efficient edge-AI applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 16 figures, IEEE Internet of Things",
    "pdf_url": "https://arxiv.org/pdf/2507.00082v1",
    "published_date": "2025-06-30 02:56:11 UTC",
    "updated_date": "2025-06-30 02:56:11 UTC"
  },
  {
    "arxiv_id": "2506.23465v1",
    "title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models",
    "authors": [
      "Nazanin Mahjourian",
      "Vinh Nguyen"
    ],
    "abstract": "The success of machine learning models in industrial applications is heavily dependent on the quality of the datasets used to train the models. However, large-scale datasets, specially those constructed from crowd-sourcing and web-scraping, often suffer from label noise, inconsistencies, and errors. This problem is particularly pronounced in manufacturing domains, where obtaining high-quality labels is costly and time-consuming. This paper introduces Vision-Language Sanitization and Refinement (VLSR), which is a vision-language-based framework for label sanitization and refinement in multi-label manufacturing image datasets. This method embeds both images and their associated textual labels into a shared semantic space leveraging the CLIP vision-language model. Then two key tasks are addressed in this process by computing the cosine similarity between embeddings. First, label sanitization is performed to identify irrelevant, misspelled, or semantically weak labels, and surface the most semantically aligned label for each image by comparing image-label pairs using cosine similarity between image and label embeddings. Second, the method applies density-based clustering on text embeddings, followed by iterative cluster merging, to group semantically similar labels into unified label groups. The Factorynet dataset, which includes noisy labels from both human annotations and web-scraped sources, is employed to evaluate the effectiveness of the proposed framework. Experimental results demonstrate that the VLSR framework successfully identifies problematic labels and improves label consistency. This method enables a significant reduction in label vocabulary through clustering, which ultimately enhances the dataset's quality for training robust machine learning models in industrial applications with minimal human intervention.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23465v1",
    "published_date": "2025-06-30 02:13:09 UTC",
    "updated_date": "2025-06-30 02:13:09 UTC"
  },
  {
    "arxiv_id": "2506.23464v2",
    "title": "The Confidence Paradox: Can LLM Know When It's Wrong",
    "authors": [
      "Sahil Tripathi",
      "Md Tabrez Nafis",
      "Imran Hussain",
      "Jiechao Gao"
    ],
    "abstract": "Document Visual Question Answering (DocVQA) models often produce overconfident or ethically misaligned responses, especially under uncertainty. Existing models like LayoutLMv3, UDOP, and DONUT focus on accuracy but lack ethical calibration. We propose HonestVQA, a model-agnostic, self-supervised framework that aligns model confidence with correctness using weighted loss and contrastive learning. We introduce two new metrics Honesty Score (H-Score) and Ethical Confidence Index (ECI)-to evaluate ethical alignment. HonestVQA improves accuracy and F1 by up to 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets, while reducing overconfidence. It also generalizes well across domains, achieving 78.9% accuracy and 76.1% F1-score.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 14th IJCNLP & 4th AACL 2025 (Main)",
    "pdf_url": "https://arxiv.org/pdf/2506.23464v2",
    "published_date": "2025-06-30 02:06:54 UTC",
    "updated_date": "2025-10-28 10:19:32 UTC"
  },
  {
    "arxiv_id": "2507.00081v1",
    "title": "State and Memory is All You Need for Robust and Reliable AI Agents",
    "authors": [
      "Matthew Muhoberac",
      "Atharva Parikh",
      "Nirvi Vakharia",
      "Saniya Virani",
      "Aco Radujevic",
      "Savannah Wood",
      "Meghav Verma",
      "Dimitri Metaxotos",
      "Jeyaraman Soundararajan",
      "Thierry Masquelin",
      "Alexander G. Godfrey",
      "Sean Gardner",
      "Dobrila Rudnicki",
      "Sam Michael",
      "Gaurav Chopra"
    ],
    "abstract": "Large language models (LLMs) have enabled powerful advances in natural language understanding and generation. Yet their application to complex, real-world scientific workflows remain limited by challenges in memory, planning, and tool integration. Here, we introduce SciBORG (Scientific Bespoke Artificial Intelligence Agents Optimized for Research Goals), a modular agentic framework that allows LLM-based agents to autonomously plan, reason, and achieve robust and reliable domain-specific task execution. Agents are constructed dynamically from source code documentation and augmented with finite-state automata (FSA) memory, enabling persistent state tracking and context-aware decision-making. This approach eliminates the need for manual prompt engineering and allows for robust, scalable deployment across diverse applications via maintaining context across extended workflows and to recover from tool or execution failures. We validate SciBORG through integration with both physical and virtual hardware, such as microwave synthesizers for executing user-specified reactions, with context-aware decision making and demonstrate its use in autonomous multi-step bioassay retrieval from the PubChem database utilizing multi-step planning, reasoning, agent-to-agent communication and coordination for execution of exploratory tasks. Systematic benchmarking shows that SciBORG agents achieve reliable execution, adaptive planning, and interpretable state transitions. Our results show that memory and state awareness are critical enablers of agentic planning and reliability, offering a generalizable foundation for deploying AI agents in complex environments.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.ET",
      "physics.chem-ph"
    ],
    "primary_category": "cs.MA",
    "comment": "5 Main Figures, 10 Extended Data Figures (37 Pages) for Manuscript ; 9 Supplementary Tables, 40 Supplementary Figures (180 Pages) for Supporting Information",
    "pdf_url": "https://arxiv.org/pdf/2507.00081v1",
    "published_date": "2025-06-30 02:02:35 UTC",
    "updated_date": "2025-06-30 02:02:35 UTC"
  },
  {
    "arxiv_id": "2506.23462v1",
    "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification",
    "authors": [
      "Manaswi Kulahara",
      "Gautam Siddharth Kashyap",
      "Nipun Joshi",
      "Arpita Soni"
    ],
    "abstract": "Effective disaster management requires timely and accurate insights, yet traditional methods struggle to integrate multimodal data such as images, weather records, and textual reports. To address this, we propose DisasterNet-LLM, a specialized Large Language Model (LLM) designed for comprehensive disaster analysis. By leveraging advanced pretraining, cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM excels in disaster classification. Experimental results demonstrate its superiority over state-of-the-art models, achieving higher accuracy of 89.5%, an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal disaster classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in the 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane, Australia",
    "pdf_url": "https://arxiv.org/pdf/2506.23462v1",
    "published_date": "2025-06-30 01:56:05 UTC",
    "updated_date": "2025-06-30 01:56:05 UTC"
  },
  {
    "arxiv_id": "2506.23461v1",
    "title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation",
    "authors": [
      "Yun Xing",
      "Qing Guo",
      "Xiaoguang Li",
      "Yihao Huang",
      "Xiaofeng Cao",
      "Di Lin",
      "Ivor Tsang",
      "Lei Ma"
    ],
    "abstract": "In this work, we focus on a novel and practical task, i.e., Time-vAriant iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image by leveraging the complementary information from a reference image, where both images captured the same scene but with a significant time gap in between, i.e., time-variant images. Different from conventional reference-guided image inpainting, the reference image under TAMP setup presents significant content distinction to the target image and potentially also suffers from damages. Such an application frequently happens in our daily lives to restore a damaged image by referring to another reference image, where there is no guarantee of the reference image's source and quality. In particular, our study finds that even state-of-the-art (SOTA) reference-guided image inpainting methods fail to achieve plausible results due to the chaotic image complementation. To address such an ill-posed problem, we propose a novel Interactive Distribution Transition Estimation (InDiTE) module which interactively complements the time-variant images with adaptive semantics thus facilitate the restoration of damaged regions. To further boost the performance, we propose our TAMP solution, namely Interactive Distribution Transition Estimation-driven Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and conducts latent cross-reference during sampling. Moreover, considering the lack of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street, based on existing image and mask datasets. We conduct experiments on the TAMP-Street datasets under two different time-variant image inpainting settings, which show our method consistently outperform SOTA reference-guided image inpainting methods for solving TAMP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2506.23461v1",
    "published_date": "2025-06-30 01:45:33 UTC",
    "updated_date": "2025-06-30 01:45:33 UTC"
  },
  {
    "arxiv_id": "2506.23437v1",
    "title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection",
    "authors": [
      "Stefano Giacomelli",
      "Marco Giordano",
      "Claudia Rinaldi",
      "Fabio Graziosi"
    ],
    "abstract": "Accurate recognition of Emergency Vehicle (EV) sirens is critical for the integration of intelligent transportation systems, smart city monitoring systems, and autonomous driving technologies. Modern automatic solutions are limited by the lack of large scale, curated datasets and by the computational demands of state of the art sound event detection models. This work introduces E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight Convolutional Neural Network architecture derived from the PANNs framework, specifically optimized for binary EV siren detection. Leveraging our dedicated subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across multiple reference datasets and test its viability on embedded hardware. The experimental campaign includes ablation studies, cross-domain benchmarking, and real-time inference deployment on edge device. Interpretability analyses exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into the model internal representations and validate its ability to capture distinct spectrotemporal patterns associated with different types of EV sirens. Real time performance is assessed through frame wise and event based detection metrics, as well as a detailed analysis of false positive activations. Results demonstrate that E2PANNs establish a new state of the art in this research domain, with high computational efficiency, and suitability for edge-based audio monitoring and safety-critical applications.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "pre-print (submitted to the IEEE/ACM Transactions on Audio, Speech, and Language Processing)",
    "pdf_url": "https://arxiv.org/pdf/2506.23437v1",
    "published_date": "2025-06-30 00:21:07 UTC",
    "updated_date": "2025-06-30 00:21:07 UTC"
  }
]