{
  "date": "2025-03-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-03 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的论文亮点纷呈，涵盖了从改进 Transformer 架构、深入理解神经网络泛化理论，到评估和应用大型语言模型（LLMs）的广泛议题。值得关注的包括引入遗忘门机制的 Forgetting Transformer、针对多层神经网络的近乎完整的非渐近泛化理论、以及对 LLMs 在特定领域（如测试测量、教育、环境影响、政治倾向）能力和偏见的深入探讨。此外，扩散模型、图神经网络、多智能体强化学习和可解释 AI 也是今日的热点。\n\n**重点论文 & 热点话题:**\n\n*   **Transformer 架构创新:**\n    *   **遗忘 Transformer：带遗忘门的 Softmax 注意力 (Forgetting Transformer: Softmax Attention with a Forget Gate):** 由 Aaron Courville 团队提出，将遗忘门机制引入 Transformer 的注意力，命名为 FoX。实验表明 FoX 在长上下文语言建模、长度外推等方面优于标准 Transformer，且兼容 FlashAttention，无需位置编码。同时引入的 \"Pro\" 块设计也显著提升了 FoX 和 Transformer 的性能。(ICLR 2025)\n    *   **Liger：将大型语言模型线性化为门控循环结构 (Liger: Linearizing Large Language Models to Gated Recurrent Structures):** 提出 Liger 方法，将预训练 LLM 转换为门控线性循环模型，无需添加额外参数，通过重用预训练权重构建门控机制，并结合 LoRA 轻量微调恢复性能。引入 Liger Attention 混合注意力机制进一步提升效果。\n\n*   **LLM 评估与应用:**\n    *   **TMIQ：量化大型语言模型中的测试与测量领域智能 (TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models):** 提出 TMIQ 基准，用于定量评估 LLMs 在电子工程测试测量任务中的能力，包括 SCPI 命令匹配、思维链推理等，并发布了命令行工具。(IEEE I2MTC 2025)\n    *   **LLMs 作为教育分析师：将多模态数据轨迹转化为可操作的阅读评估报告 (LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports):** 探索使用 LLMs 结合眼动追踪等多模态数据，生成面向教育者的阅读行为分析报告，并通过专家和教师评估其有效性。\n    *   **全面评估创建语言模型的环境影响 (Holistically Evaluating the Environmental Impact of Creating Language Models):** 首次详细估算了 LLM 开发全周期的环境影响（硬件制造、模型开发、最终训练），发现模型开发阶段的碳排放和水消耗占相当大比例（约 50%），且训练过程中的功耗波动较大。(ICLR 2025 Spotlight)\n    *   **大型语言模型中涌现政治观点的线性表示 (Linear Representations of Political Perspective Emerge in Large Language Models):** 发现 LLMs (Llama-2, Mistral, Vicuna) 内部激活空间中存在政治观点的线性表示，可通过探针预测议员和新闻媒体的政治倾向，并能通过线性干预引导模型立场。(ICLR 2025)\n    *   **MultiAgentBench：评估 LLM 智能体的协作与竞争 (MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents):** 提出 MultiAgentBench，一个评估 LLM 多智能体系统在协作和竞争场景下表现的综合基准，包含新的 KPI 指标，并评估了不同协调协议和策略。\n    *   **ToolRet：大型语言模型工具检索基准测试 (Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models):** 提出 ToolRet 基准，包含 7.6k 检索任务和 43k 工具，发现现有 IR 模型在工具检索上表现不佳，影响 LLM 工具使用效果，并提供了一个大型训练数据集以优化 IR 模型。\n    *   **AutoAdvExBench：对对抗样本防御进行自主利用的基准测试 (AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses):** 引入 AutoAdvExBench，评估 LLMs 是否能自主利用对抗样本防御措施。发现现有 LLM 代理在真实防御上的成功率远低于 CTF 式防御。\n    *   **Persuade Me if You Can：评估大型语言模型说服有效性和易感性的框架 (Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models):** 提出 PMIYC 框架，通过多智能体交互自动评估 LLMs 的说服能力和被说服的易感性。发现 Llama-3.3-70B 和 GPT-4o 说服力相当，但 GPT-4o 对错误信息抵抗力更强。\n    *   **自适应评估模型与任务启发 (Adaptively evaluating models with task elicitation):** 提出自适应评估框架，使用评估器代理在领域数据集中搜索目标模型的行为，生成困难任务以发现和探测模型的失败模式。\n    *   **HoH：评估过时信息对 RAG 影响的动态基准 (HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation):** 提出首个评估 RAG 中过时信息影响的基准 HoH，发现过时信息会显著降低 RAG 准确性并可能误导模型。\n    *   **LLM-Advisor：跨多地形的成本效益路径规划 LLM 基准 (LLM-Advisor: An LLM Benchmark for Cost-efficient Path Planning across Multiple Terrains):** 提出 LLM-Advisor，利用 LLM 作为路径规划顾问，选择性提供建议以优化多地形路径成本，并提出幻觉缓解策略。\n    *   **科学推理：多模态生成式 LLM 评估 (Scientific Reasoning: Assessment of Multimodal Generative LLMs):** 在 ScienceQA 上评估 MLLMs 的科学推理能力，发现 Gemini 模型在少上下文时准确率高，多上下文时解释与人类相似度高。\n\n*   **理论与基础:**\n    *   **近乎完整的多层神经网络非渐近泛化理论：超越偏差-方差权衡 (A Near Complete Nonasymptotic Generalization Theory For Multilayer Neural Networks: Beyond the Bias-Variance Tradeoff):** 提出针对具有任意 Lipschitz 激活和 Lipschitz 损失函数的多层神经网络的近乎完整的非渐近泛化理论，不要求损失函数有界，考虑了近似误差，并展示了其在 ReLU 网络上的近乎最优性及双下降现象。\n    *   **抛物线持续学习 (Parabolic Continual Learning):** 提出一种新的持续学习方法，通过施加抛物线偏微分方程 (PDE) 的属性来正则化损失随时间的预期行为，利用记忆缓冲区作为边界条件来分析遗忘和泛化误差。\n    *   **图任务中 Transformer 的深度-宽度权衡的算法推理 (Depth-Width tradeoffs in Algorithmic Reasoning of Graph Tasks with Transformers):** 分析了 Transformer 解决图任务时深度和宽度的权衡，发现在线性宽度下，常数深度足以解决许多图问题，而某些问题需要二次宽度。\n    *   **将分段线性 Kolmogorov Arnold 网络与 ReLU 网络联系起来 (Relating Piecewise Linear Kolmogorov Arnold Networks to ReLU Networks):** 提供了将分段线性 KAN 转换为 ReLU 网络以及反向转换的显式构造。(AISTATS 2025)\n\n*   **模型压缩与效率:**\n    *   **RSQ：从重要 Token 学习带来更好的量化 LLM (RSQ: Learning from Important Tokens Leads to Better Quantized LLMs):** 提出 RSQ 方法，通过旋转减轻异常值、根据重要性缩放 Token 特征、并使用缩放后 Token 的二阶统计量进行 GPTQ 量化，优先从重要 Token（如注意力分数高的）学习，提升量化效果。\n    *   **EliteKV：通过 RoPE 频率选择和联合低秩投影实现可扩展的 KV 缓存压缩 (EliteKV: Scalable KV Cache Compression via RoPE Frequency Selection and Joint Low-Rank Projection):** 提出 EliteKV 框架，通过识别头的频率偏好并选择性恢复线性，结合键和值的联合低秩压缩，实现 RoPE 模型 KV 缓存的高效压缩（75%）同时保持性能。\n    *   **CacheQuant：全面加速的扩散模型 (CacheQuant: Comprehensively Accelerated Diffusion Models):** 提出 CacheQuant，一个联合优化模型缓存和量化技术的训练无关范式，通过动态规划确定最优缓存调度并解耦误差校正，显著加速扩散模型推理。(CVPR 2025)\n    *   **PipeOffload：通过内存优化提高流水线并行性的可扩展性 (PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization):** 研究流水线并行中的内存卸载策略，发现大部分激活可以无显著开销地卸载，并提出选择性卸载策略，有效降低峰值内存，使 PP 成为比 TP 更强的选择。\n\n*   **多模态与视觉:**\n    *   **Phi-4-Mini 技术报告：通过 LoRA 混合实现紧凑而强大的多模态语言模型 (Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs):** 微软发布 Phi-4-Mini (3.8B 语言模型) 和 Phi-4-Multimodal（集成文本、视觉、语音/音频）。Phi-4-Mini 在数学和编码上表现优异。Phi-4-Multimodal 使用 LoRA 适配器和模态特定路由器，支持多种模态组合输入，在 OpenASR 等基准上取得 SOTA。\n    *   **Abn-BLIP：用于 CTPA 肺栓塞诊断和报告生成的异常对齐自举语言-图像预训练 (Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA):** 提出 Abn-BLIP 模型，用于 CTPA 图像的肺栓塞诊断和报告生成，通过可学习查询和跨模态注意力机制对齐异常发现，提升报告准确性和全面性。\n    *   **MINT：统一生成模型中用于增强图像生成的多模态思维链 (MINT: Multi-modal Chain of Thought in Unified Generative Models for Enhanced Image Generation):** 提出 MINT，一个具有原生多模态思维链（MCoT）能力的统一生成模型，通过专家混合 Transformer 结构（MTXpert）和 MCoT 训练范式，增强复杂条件下的图像生成能力。\n    *   **KeyFace：通过关键帧插值实现长序列的富有表现力的音频驱动面部动画 (KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation):** 提出 KeyFace，一个两阶段扩散框架，先生成低帧率关键帧，再插值生成平滑长序列面部动画，并融入情感和非语音发声。(CVPR 2025)\n    *   **通过以服装为中心的修复生成细粒度可控的服装展示图像 (Fine-Grained Controllable Apparel Showcase Image Generation via Garment-Centric Outpainting):** 提出 GCO 框架，基于 LDM，输入分割后的服装图像，通过文本提示和面部图像生成模特穿着效果，能精确保留服装细节并进行细粒度控制。\n\n*   **强化学习与机器人:**\n    *   **M3HF：来自混合质量多阶段人类反馈的多智能体强化学习 (M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality):** 提出 M3HF 框架，将不同专业水平人类的多阶段反馈整合到 MARL 训练中，通过 LLM 解析反馈并自适应更新奖励函数，提升多智能体协作。\n    *   **FRMD：具有一致性蒸馏运动基元的快速机器人运动扩散，用于平滑动作生成 (FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation):** 提出 FRMD，将运动基元 (MPs) 与一致性模型结合，实现单步、平滑且时序一致的机器人轨迹生成。\n    *   **对抗性智能体：使用强化学习进行黑盒规避攻击 (Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning):** 展示如何使用 RL 开发新的对抗性攻击，通过学习生成对抗样本，利用过去的攻击经验改进未来攻击，并在 CIFAR-10 上验证了其有效性和效率。\n    *   **SrSv：将序贯部署与序贯价值估计相结合用于多智能体强化学习 (SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning):** 提出 SrSv 框架，利用 Transformer 的自回归特性处理变化的智能体数量，并引入序贯价值估计方法捕捉智能体间的相互依赖，提升 MARL 的训练效率和可扩展性。\n    *   **面向鲁棒横向控制的主动推理框架下的感知运动学习 (Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control):** 提出结合主动推理 (AIF) 的感知运动学习 (PML) 框架，用于增强高度自动化车辆 (HAV) 的横向控制能力，通过生成模型统一深度学习和主动推理，提高适应性。(IROS 2025 提交)\n\n*   **其他亮点:**\n    *   **生物医学基础模型：综述 (Biomedical Foundation Model: A Survey):** 全面综述了基础模型（如 LLMs, VLMs）在计算生物学、药物发现、临床信息学、医学影像和公共卫生等生物医学领域的应用潜力。\n    *   **任务特定提示在上下文学习中的可证明优势 (Provable Benefits of Task-Specific Prompts for In-context Learning):** 理论分析表明，在任务分布可分解的情况下，使用任务特定的提示和预测头可以帮助单层注意力模型学习先验信息，促进协方差-均值解耦。(AISTATS 2025)\n    *   **超越 Matryoshka：重新审视用于自适应表示的稀疏编码 (Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation):** 提出对比稀疏表示 (CSR)，一种基于稀疏编码的自适应嵌入长度方法，通过轻量级自编码和对比目标，在保持语义质量的同时实现灵活的推理，性能优于 MRL。\n    *   **SAGE：RAG 精确检索框架 (SAGE: A Framework of Precise Retrieval for RAG):** 提出 SAGE 框架，通过训练语义分割模型改进分块，设计动态块选择算法，并让 LLM 评估和调整检索量，提升 RAG 的问答质量和成本效率。\n    *   **Spark-TTS：具有单流解耦语音 Token 的高效基于 LLM 的文本到语音模型 (Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens):** 提出 Spark-TTS 系统，使用 BiCodec（单流语音编解码器）将语音分解为语义和说话人属性 Token，结合 Qwen2.5 LLM 和 CoT 实现零样本语音克隆和高度可控的语音合成。(ACL 2025 提交)\n    *   **学习猜想从零开始 (Learning Conjecturing from Scratch):** 开发了一种自学习方法，用于在 OEIS 派生的数据集上进行归纳谓词的猜想。通过神经网络翻译器学习问题与谓词的对应关系，并利用 z3 证明器进行验证和迭代优化，最终解决了大量问题。\n\n**快速浏览:**\n\n*   **泛化理论:** (#2) 提出了新的多层神经网络泛化理论。\n*   **持续学习:** (#4) 提出抛物线持续学习方法；(#70) 提出 STAR 损失函数用于缓解遗忘；(#74) 提出 LTF 框架用于时序图持续学习。\n*   **可解释性/探测:** (#10) 发现 LLM 中的政治倾向线性表示；(#11) 提出 Superscopes 放大内部特征表示；(#33) 探讨稀疏自编码器与概念几何的对偶性；(#65) 提出可解释等变代理模型的数学基础；(#79) 提出神经元语义归因方法评估 LLM 剪枝。\n*   **多智能体/博弈:** (#12) M3HF 利用人类反馈进行 MARL；(#13) AGDebugger 用于多智能体 AI 系统调试；(#23) 研究 LLM 中的群体认同和信念一致性；(#28) 探讨点赞/点踩投票中的比例性；(#93) SrSv 框架用于 MARL；(#160) 提出用于服务人力优化的 MARL 框架。\n*   **扩散模型应用:** (#8) 用于北极海冰预测；(#18) FRMD 用于机器人运动生成；(#19) DSearch 用于扩散模型推理时对齐；(#106) 异构噪声积分用于对抗净化；(#110) 结合 Transformer 用于贝叶斯逆问题；(#117) CacheQuant 加速扩散模型；(#122) GCO 用于服装图像生成；(#134) Tera-MIND 用于模拟鼠脑；(#159) DynamicDPS 减少医学图像重建幻觉。\n*   **图神经网络:** (#49) EgoNetGNN 学习异构同伴效应的暴露映射；(#58) EM-ReSeleCT 用于多变量时间序列预测；(#62) OpenGS-SLAM 用于开放集语义 SLAM；(#63) KG-RAR 图增强 LLM 推理；(#74) LTF 用于时序图持续学习；(#77) HOGRL 用于信用卡欺诈检测；(#107) 结合 GNN 进行谣言检测；(#142) STGAN 用于路面病害预测；(#158) 深度自适应 GNN。\n*   **医学 AI:** (#5) 生物医学基础模型综述；(#17) EPEE 提高生物医学基础模型效率；(#21) Abn-BLIP 用于肺栓塞诊断；(#60) 深度学习去噪增强声纳图像目标检测；(#61) DisPro 用于不完整多模态生存预测；(#69) 三流深度特征选择用于高血压视网膜病变诊断；(#71) Swin Transformer 用于肺结节检测；(#85) DRS+ML 在光学诊断中的应用综述；(#100) ML 在临床语音障碍分类中的应用综述；(#120) nnUZoo 框架比较 CNN/Transformer/Mamba 在医学图像分割性能；(#129) 语音克隆用于构音障碍语音合成；(#132) 协方差多尺度表示用于阿尔茨海默症分类；(#140) Autoencoder 用于 CMP 系统健康管理；(#159) DynamicDPS 减少医学图像重建幻觉。\n*   **AI 伦理与安全:** (#14) AI 说服 AI vs AI 说服人类；(#15) XAI 在威胁情报中的作用调查；(#30) 通过 LLM 越狱 T2I 模型安全防护；(#37) AutoAdvExBench 评估 LLM 自主利用对抗防御；(#44) 零信任 AI 模型安全架构；(#45) SAKE 通过引导激活进行知识编辑；(#66) LLM 作为个人数据的法律影响；(#80) PIC Prompting 改善 LLM 对隐式有毒语言的推理；(#90) 确保相互隐私对评估专有 AI 很重要；(#114) 评估 LLM 风险感知决策；(#126) 检测合成表格数据；(#133) HoH 评估过时信息对 RAG 的影响；(#156) SolBench 评估 Solidity 代码生成的函数正确性；(#157) FAIR 框架研究制造业 AI 弹性。\n*   **人机交互/工具:** (#7) LLM 生成阅读报告；(#13) 多智能体调试工具；(#24) 用预训练嵌入作为行为规范机制；(#25) TactStyle 生成触觉纹理；(#43) ToolRet 工具检索基准；(#87) AskToAct 通过自校正澄清增强 LLM 工具使用；(#139) 众包研究工作匹配系统中的指标偏好。\n*   **特定领域应用:** (#3) 测试测量 (TMIQ)；(#8) 北极海冰预测；(#9) AI 环境影响；(#26) 光照方向估计；(#55) 机器人规划 (Code-as-Symbolic-Planner)；(#64) 交通异常解决 (CoT-VLM4Tar)；(#89) 业务场景根因分析 (ProRCA)；(#91) 领域特定小模型；(#96) 卫星调度 DRL；(#105) 工业过程控制世界模型；(#107) 社交媒体谣言检测；(#109) 地理语义解析 (GSP)；(#111) 瑞士法律翻译基准 (SwiLTra-Bench)；(#112) HAR TinyML；(#125) CFD+LLM (OptMetaOpenFOAM)；(#131) 机器人路径规划 (LLM-Advisor)；(#135) MAPF 测试平台 (SMART)；(#137) 电网故障定位；(#142) 路面病害预测；(#144) AI ETF/Token 与绿色市场联动；(#152) 安保调度车辆路径问题；(#157) 制造业 AI 弹性；(#161) 农业环境物体搜索。\n\n希望这份 TLDR 能帮助你快速了解 arXiv 的最新动态！",
  "papers": [
    {
      "arxiv_id": "2503.02130v1",
      "title": "Forgetting Transformer: Softmax Attention with a Forget Gate",
      "title_zh": "遗忘Transformer：带遗忘门的Softmax注意力机制",
      "authors": [
        "Zhixuan Lin",
        "Evgenii Nikishin",
        "Xu Owen He",
        "Aaron Courville"
      ],
      "abstract": "An essential component of modern recurrent sequence models is the forget\ngate. While Transformers do not have an explicit recurrent form, we show that a\nforget gate can be naturally incorporated into Transformers by down-weighting\nthe unnormalized attention scores in a data-dependent way. We name this\nattention mechanism the Forgetting Attention and the resulting model the\nForgetting Transformer (FoX). We show that FoX outperforms the Transformer on\nlong-context language modeling, length extrapolation, and short-context\ndownstream tasks, while performing on par with the Transformer on long-context\ndownstream tasks. Moreover, it is compatible with the FlashAttention algorithm\nand does not require any positional embeddings. Several analyses, including the\nneedle-in-the-haystack test, show that FoX also retains the Transformer's\nsuperior long-context capabilities over recurrent sequence models such as\nMamba-2, HGRN2, and DeltaNet. We also introduce a \"Pro\" block design that\nincorporates some common architectural components in recurrent sequence models\nand find it significantly improves the performance of both FoX and the\nTransformer. Our code is available at\nhttps://github.com/zhixuan-lin/forgetting-transformer.",
      "tldr_zh": "该研究提出了Forgetting Transformer（FoX）模型，通过在Transformer的Softmax注意力机制中引入类似循环神经网络的遗忘门（forget gate），以数据依赖方式动态调节未归一化的注意力分数。实验表明，该模型在长文本语言建模、长度外推和短文本下游任务中优于标准Transformer，同时保持与FlashAttention算法的兼容性且无需位置编码。特别设计的\"Pro\"模块进一步提升了模型性能，分析证实FoX在长文本处理能力上依然优于Mamba-2等循环序列模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02130v1",
      "published_date": "2025-03-03 23:35:23 UTC",
      "updated_date": "2025-03-03 23:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:54:41.898077"
    },
    {
      "arxiv_id": "2503.02129v1",
      "title": "A Near Complete Nonasymptotic Generalization Theory For Multilayer Neural Networks: Beyond the Bias-Variance Tradeoff",
      "title_zh": "多层神经网络近乎完备的非渐近泛化理论：突破偏差-方差权衡",
      "authors": [
        "Hao Yu",
        "Xiangyang Ji"
      ],
      "abstract": "We propose a first near complete (that will make explicit sense in the main\ntext) nonasymptotic generalization theory for multilayer neural networks with\narbitrary Lipschitz activations and general Lipschitz loss functions (with some\nvery mild conditions). In particular, it doens't require the boundness of loss\nfunction, as commonly assumed in the literature. Our theory goes beyond the\nbias-variance tradeoff, aligned with phenomenon typically encountered in deep\nlearning. It is therefore sharp different with other existing nonasymptotic\ngeneralization error bounds for neural networks. More explicitly, we propose an\nexplicit generalization error upper bound for multilayer neural networks with\narbitrary Lipschitz activations $\\sigma$ with $\\sigma(0)=0$ and broad enough\nLipschitz loss functions, without requiring either the width, depth or other\nhyperparameters of the neural network approaching infinity, a specific neural\nnetwork architect (e.g. sparsity, boundness of some norms), a particular\nactivation function, a particular optimization algorithm or boundness of the\nloss function, and with taking the approximation error into consideration.\nGeneral Lipschitz activation can also be accommodated into our framework. A\nfeature of our theory is that it also considers approximation errors.\nFurthermore, we show the near minimax optimality of our theory for multilayer\nReLU networks for regression problems. Notably, our upper bound exhibits the\nfamous double descent phenomenon for such networks, which is the most\ndistinguished characteristic compared with other existing results. This work\nemphasizes a view that many classical results should be improved to embrace the\nunintuitive characteristics of deep learning to get a better understanding of\nit.",
      "tldr_zh": "该研究提出了首个近乎完整的多层神经网络非渐近泛化理论，突破了传统偏差-方差权衡框架。该理论适用于任意Lipschitz激活函数和广义Lipschitz损失函数（仅需极温和条件），不要求损失函数有界、网络宽度/深度趋于无穷或特定网络结构等常见假设。关键创新在于：1）推导出显式泛化误差上界并考虑近似误差；2）证明其在ReLU网络回归问题中的近极小极大最优性；3）首次通过理论框架重现了深度学习中著名的双下降现象。这项工作为理解深度学习的反直觉特性提供了新视角，表明需要改进经典理论以适应深度学习的新范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02129v1",
      "published_date": "2025-03-03 23:34:12 UTC",
      "updated_date": "2025-03-03 23:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:54:30.060313"
    },
    {
      "arxiv_id": "2503.02123v1",
      "title": "TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models",
      "title_zh": "TMIQ：量化大型语言模型在测试与测量领域的智能水平",
      "authors": [
        "Emmanuel A. Olowe",
        "Danial Chitnis"
      ],
      "abstract": "The Test and Measurement domain, known for its strict requirements for\naccuracy and efficiency, is increasingly adopting Generative AI technologies to\nenhance the performance of data analysis, automation, and decision-making\nprocesses. Among these, Large Language Models (LLMs) show significant promise\nfor advancing automation and precision in testing. However, the evaluation of\nLLMs in this specialized area remains insufficiently explored. To address this\ngap, we introduce the Test and Measurement Intelligence Quotient (TMIQ), a\nbenchmark designed to quantitatively assess LLMs across a wide range of\nelectronic engineering tasks. TMIQ offers a comprehensive set of scenarios and\nmetrics for detailed evaluation, including SCPI command matching accuracy,\nranked response evaluation, Chain-of-Thought Reasoning (CoT), and the impact of\noutput formatting variations required by LLMs on performance. In testing\nvarious LLMs, our findings indicate varying levels of proficiency, with exact\nSCPI command match accuracy ranging from around 56% to 73%, and ranked matching\nfirst-position scores achieving around 33% for the best-performing model. We\nalso assess token usage, cost-efficiency, and response times, identifying\ntrade-offs between accuracy and operational efficiency. Additionally, we\npresent a command-line interface (CLI) tool that enables users to generate\ndatasets using the same methodology, allowing for tailored assessments of LLMs.\nTMIQ and the CLI tool provide a rigorous, reproducible means of evaluating LLMs\nfor production environments, facilitating continuous monitoring and identifying\nstrengths and areas for improvement, and driving innovation in their selections\nfor applications within the Test and Measurement industry.",
      "tldr_zh": "该研究提出了测试与测量领域智能指数(TMIQ)，用于量化评估大语言模型(LLMs)在电子工程任务中的表现。TMIQ通过SCPI命令匹配准确率、排名响应评估、链式思维推理(CoT)等指标，全面测试LLMs的性能。实验结果显示，不同LLMs的SCPI命令匹配准确率在56%到73%之间，排名匹配最佳模型的首位得分约为33%。研究还开发了命令行工具，支持生成定制数据集，为测试与测量领域的LLMs应用提供了可重复的评估方法，推动其在生产环境中的创新应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted in IEEE I2MTC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02123v1",
      "published_date": "2025-03-03 23:12:49 UTC",
      "updated_date": "2025-03-03 23:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:54:26.415565"
    },
    {
      "arxiv_id": "2503.02117v1",
      "title": "Parabolic Continual Learning",
      "title_zh": "抛物线持续学习",
      "authors": [
        "Haoming Yang",
        "Ali Hasan",
        "Vahid Tarokh"
      ],
      "abstract": "Regularizing continual learning techniques is important for anticipating\nalgorithmic behavior under new realizations of data. We introduce a new\napproach to continual learning by imposing the properties of a parabolic\npartial differential equation (PDE) to regularize the expected behavior of the\nloss over time. This class of parabolic PDEs has a number of favorable\nproperties that allow us to analyze the error incurred through forgetting and\nthe error induced through generalization. Specifically, we do this through\nimposing boundary conditions where the boundary is given by a memory buffer. By\nusing the memory buffer as a boundary, we can enforce long term dependencies by\nbounding the expected error by the boundary loss. Finally, we illustrate the\nempirical performance of the method on a series of continual learning tasks.",
      "tldr_zh": "该研究提出了一种基于抛物线偏微分方程（Parabolic PDE）的持续学习（Continual Learning）新方法，通过将PDE的特性应用于损失函数的时间演化来正则化学习过程。该方法利用记忆缓冲区作为边界条件，能够分析遗忘误差和泛化误差，并通过边界损失约束长期依赖关系。实验结果表明，该方法在多个持续学习任务中表现出色，为理解算法在数据动态变化下的行为提供了理论支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02117v1",
      "published_date": "2025-03-03 22:59:13 UTC",
      "updated_date": "2025-03-03 22:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:54:34.336396"
    },
    {
      "arxiv_id": "2503.02104v1",
      "title": "Biomedical Foundation Model: A Survey",
      "title_zh": "生物医学基础模型：综述",
      "authors": [
        "Xiangrui Liu",
        "Yuanyuan Zhang",
        "Yingzhou Lu",
        "Changchang Yin",
        "Xiaoling Hu",
        "Xiaoou Liu",
        "Lulu Chen",
        "Sheng Wang",
        "Alexander Rodriguez",
        "Huaxiu Yao",
        "Yezhou Yang",
        "Ping Zhang",
        "Jintai Chen",
        "Tianfan Fu",
        "Xiao Wang"
      ],
      "abstract": "Foundation models, first introduced in 2021, are large-scale pre-trained\nmodels (e.g., large language models (LLMs) and vision-language models (VLMs))\nthat learn from extensive unlabeled datasets through unsupervised methods,\nenabling them to excel in diverse downstream tasks. These models, like GPT, can\nbe adapted to various applications such as question answering and visual\nunderstanding, outperforming task-specific AI models and earning their name due\nto broad applicability across fields. The development of biomedical foundation\nmodels marks a significant milestone in leveraging artificial intelligence (AI)\nto understand complex biological phenomena and advance medical research and\npractice. This survey explores the potential of foundation models across\ndiverse domains within biomedical fields, including computational biology, drug\ndiscovery and development, clinical informatics, medical imaging, and public\nhealth. The purpose of this survey is to inspire ongoing research in the\napplication of foundation models to health science.",
      "tldr_zh": "本文综述了生物医学领域中的基础模型(Foundation Models)研究进展。这些大规模预训练模型（如GPT等LLMs和VLMs）通过无监督方法从海量无标签数据中学习，在计算生物学、药物研发、临床信息学、医学影像和公共卫生等多个生物医学领域展现出广泛适用性和强大性能。该研究旨在激发基础模型在健康科学领域的持续探索与应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02104v1",
      "published_date": "2025-03-03 22:42:00 UTC",
      "updated_date": "2025-03-03 22:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:54:41.624647"
    },
    {
      "arxiv_id": "2503.02102v2",
      "title": "Provable Benefits of Task-Specific Prompts for In-context Learning",
      "title_zh": "可证明的任务特定提示对上下文学习的优势",
      "authors": [
        "Xiangyu Chang",
        "Yingcong Li",
        "Muti Kara",
        "Samet Oymak",
        "Amit K. Roy-Chowdhury"
      ],
      "abstract": "The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.",
      "tldr_zh": "本研究探讨了任务特定提示(prompt)对上下文学习(In-context Learning)的可证明优势。通过分析全局任务分布可划分为条件任务分布的联合这一新设定，研究发现任务特定提示和预测头能够有效学习条件任务分布的先验信息。结果表明，任务特定提示实现了协方差-均值解耦，其中提示调优解释分布的均值，而方差则通过上下文学习获得。引入任务特定头进一步促进这一过程，使均值和方差估计完全解耦。这一协方差-均值视角同样解释了联合训练提示和注意力权重为何优于预训练后的微调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02102v2",
      "published_date": "2025-03-03 22:37:03 UTC",
      "updated_date": "2025-03-05 16:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:16.357664"
    },
    {
      "arxiv_id": "2503.02099v1",
      "title": "LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports",
      "title_zh": "LLMs 作为教育分析师：将多模态数据痕迹转化为可操作的阅读评估报告",
      "authors": [
        "Eduardo Davalos",
        "Yike Zhang",
        "Namrata Srivastava",
        "Jorge Alberto Salas",
        "Sara McFadden",
        "Sun-Joo Cho",
        "Gautam Biswas",
        "Amanda Goodwin"
      ],
      "abstract": "Reading assessments are essential for enhancing students' comprehension, yet\nmany EdTech applications focus mainly on outcome-based metrics, providing\nlimited insights into student behavior and cognition. This study investigates\nthe use of multimodal data sources -- including eye-tracking data, learning\noutcomes, assessment content, and teaching standards -- to derive meaningful\nreading insights. We employ unsupervised learning techniques to identify\ndistinct reading behavior patterns, and then a large language model (LLM)\nsynthesizes the derived information into actionable reports for educators,\nstreamlining the interpretation process. LLM experts and human educators\nevaluate these reports for clarity, accuracy, relevance, and pedagogical\nusefulness. Our findings indicate that LLMs can effectively function as\neducational analysts, turning diverse data into teacher-friendly insights that\nare well-received by educators. While promising for automating insight\ngeneration, human oversight remains crucial to ensure reliability and fairness.\nThis research advances human-centered AI in education, connecting data-driven\nanalytics with practical classroom applications.",
      "tldr_zh": "该研究探索了将大语言模型(LLMs)作为教育分析师的潜力，通过整合眼动追踪数据、学习成果、评估内容和教学标准等多模态数据，生成可操作的阅读评估报告。研究采用无监督学习技术识别不同的阅读行为模式，并利用LLMs将这些数据合成为教师易于理解的报告。评估显示，LLMs生成的报告在清晰度、准确性、相关性和教学实用性方面表现良好，为教育领域的数据驱动分析提供了新思路，同时强调了人工监督对确保可靠性和公平性的重要性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "I.2.1; I.2.7; K.3.1"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.02099v1",
      "published_date": "2025-03-03 22:34:08 UTC",
      "updated_date": "2025-03-03 22:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:11.998430"
    },
    {
      "arxiv_id": "2503.02093v1",
      "title": "Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction",
      "title_zh": "从相关性到因果性：一种用于北极海冰预测的因果深度学习框架",
      "authors": [
        "Emam Hossain",
        "Muhammad Hasan Ferdous",
        "Jianwu Wang",
        "Aneesh Subramanian",
        "Md Osman Gani"
      ],
      "abstract": "Traditional machine learning and deep learning techniques rely on\ncorrelation-based learning, often failing to distinguish spurious associations\nfrom true causal relationships, which limits robustness, interpretability, and\ngeneralizability. To address these challenges, we propose a causality-driven\ndeep learning framework that integrates Multivariate Granger Causality (MVGC)\nand PCMCI+ causal discovery algorithms with a hybrid deep learning\narchitecture. Using 43 years (1979-2021) of daily and monthly Arctic Sea Ice\nExtent (SIE) and ocean-atmospheric datasets, our approach identifies causally\nsignificant factors, prioritizes features with direct influence, reduces\nfeature overhead, and improves computational efficiency. Experiments\ndemonstrate that integrating causal features enhances the deep learning model's\npredictive accuracy and interpretability across multiple lead times. Beyond SIE\nprediction, the proposed framework offers a scalable solution for dynamic,\nhigh-dimensional systems, advancing both theoretical understanding and\npractical applications in predictive modeling.",
      "tldr_zh": "该研究提出了一种因果驱动的深度学习框架，结合了多变量格兰杰因果(MVGC)和PCMCI+因果发现算法，用于北极海冰范围(SIE)预测。通过分析43年的海冰和海洋-大气数据，该框架识别出具有因果显著性的特征，减少了冗余特征并提高了计算效率。实验表明，引入因果特征显著提升了模型在不同时间跨度下的预测精度和可解释性。该框架为高维动态系统的预测建模提供了可扩展的理论和实践解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Publication in Causal AI for Robust Decision Making\n  (CARD) Workshop in the International Conference on Pervasive Computing and\n  Communications (PerCom 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.02093v1",
      "published_date": "2025-03-03 22:24:14 UTC",
      "updated_date": "2025-03-03 22:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:09.923088"
    },
    {
      "arxiv_id": "2503.05804v1",
      "title": "Holistically Evaluating the Environmental Impact of Creating Language Models",
      "title_zh": "全面评估语言模型创建的环境影响",
      "authors": [
        "Jacob Morrison",
        "Clara Na",
        "Jared Fernandez",
        "Tim Dettmers",
        "Emma Strubell",
        "Jesse Dodge"
      ],
      "abstract": "As the performance of artificial intelligence systems has dramatically\nincreased, so too has the environmental impact of creating these systems. While\nmany model developers release estimates of the power consumption and carbon\nemissions from the final training runs for their latest models, there is\ncomparatively little transparency into the impact of model development,\nhardware manufacturing, and total water usage throughout. In this work, we\nestimate the real-world environmental impact of developing a series of language\nmodels, ranging from 20 million to 13 billion active parameters, trained on up\nto 5.6 trillion tokens each. When accounting for hardware manufacturing, model\ndevelopment, and our final training runs, we find that our series of models\nreleased 493 metric tons of carbon emissions, equivalent to powering about 98\nhomes in the United States for one year, and consumed 2.769 million liters of\nwater, equivalent to about 24.5 years of water usage by a person in the United\nStates, even though our data center is extremely water-efficient. We measure\nand report the environmental impact of our model development; to the best of\nour knowledge we are the first to do so for LLMs, and we find that model\ndevelopment, the impact of which is generally not disclosed by most model\ndevelopers, amounted to ~50% of that of training. By looking at detailed time\nseries data for power consumption, we also find that power usage throughout\ntraining is not consistent, fluctuating between ~15% and ~85% of our hardware's\nmaximum power draw, with negative implications for grid-scale planning as\ndemand continues to grow. We close with a discussion on the continued\ndifficulty of estimating the environmental impact of AI systems, and key\ntakeaways for model developers and the public at large.",
      "tldr_zh": "该研究全面评估了开发语言模型（LLMs）的环境影响，包括硬件制造、模型开发和最终训练阶段。研究发现，开发一系列参数规模从2000万到130亿的模型共排放了493吨二氧化碳，相当于美国98户家庭一年的用电量，并消耗了276.9万升水，相当于美国个人24.5年的用水量。值得注意的是，模型开发的环境影响占总影响的约50%，而这一部分通常未被大多数开发者披露。研究还指出，训练期间的电力使用并不稳定，波动在硬件最大功率的15%到85%之间，这对电网规划提出了挑战。研究呼吁提高AI系统环境影响的透明度，并为开发者和公众提供了关键启示。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "ICLR 2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2503.05804v1",
      "published_date": "2025-03-03 22:16:15 UTC",
      "updated_date": "2025-03-03 22:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:20.188119"
    },
    {
      "arxiv_id": "2503.02080v1",
      "title": "Linear Representations of Political Perspective Emerge in Large Language Models",
      "title_zh": "大语言模型中的政治视角线性表征",
      "authors": [
        "Junsol Kim",
        "James Evans",
        "Aaron Schein"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the ability to generate text\nthat realistically reflects a range of different subjective human perspectives.\nThis paper studies how LLMs are seemingly able to reflect more liberal versus\nmore conservative viewpoints among other political perspectives in American\npolitics. We show that LLMs possess linear representations of political\nperspectives within activation space, wherein more similar perspectives are\nrepresented closer together. To do so, we probe the attention heads across the\nlayers of three open transformer-based LLMs (\\texttt{Llama-2-7b-chat},\n\\texttt{Mistral-7b-instruct}, \\texttt{Vicuna-7b}). We first prompt models to\ngenerate text from the perspectives of different U.S.~lawmakers. We then\nidentify sets of attention heads whose activations linearly predict those\nlawmakers' DW-NOMINATE scores, a widely-used and validated measure of political\nideology. We find that highly predictive heads are primarily located in the\nmiddle layers, often speculated to encode high-level concepts and tasks. Using\nprobes only trained to predict lawmakers' ideology, we then show that the same\nprobes can predict measures of news outlets' slant from the activations of\nmodels prompted to simulate text from those news outlets. These linear probes\nallow us to visualize, interpret, and monitor ideological stances implicitly\nadopted by an LLM as it generates open-ended responses. Finally, we demonstrate\nthat by applying linear interventions to these attention heads, we can steer\nthe model outputs toward a more liberal or conservative stance. Overall, our\nresearch suggests that LLMs possess a high-level linear representation of\nAmerican political ideology and that by leveraging recent advances in\nmechanistic interpretability, we can identify, monitor, and steer the\nsubjective perspective underlying generated text.",
      "tldr_zh": "该研究发现大语言模型(LLMs)在激活空间中存在美国政治意识形态的线性表征，相似的政治观点在表征空间中更接近。研究者通过分析三个开源Transformer模型(\\texttt{Llama-2-7b-chat}, \\texttt{Mistral-7b-instruct}, \\texttt{Vicuna-7b})的注意力头激活，成功预测了美国立法者的DW-NOMINATE得分（衡量政治意识形态的指标），并发现最具预测性的注意力头主要位于模型中间层。此外，研究还表明，通过线性干预这些注意力头，可以引导模型生成更自由或更保守的文本。这些发现为理解、监控和引导LLMs生成文本的主观视角提供了新的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02080v1",
      "published_date": "2025-03-03 21:59:01 UTC",
      "updated_date": "2025-03-03 21:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:25.867547"
    },
    {
      "arxiv_id": "2503.02078v2",
      "title": "Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation",
      "title_zh": "Superscopes：通过放大内部特征表征增强语言模型可解释性",
      "authors": [
        "Jonathan Jacobi",
        "Gal Niv"
      ],
      "abstract": "Understanding and interpreting the internal representations of large language\nmodels (LLMs) remains an open challenge. Patchscopes introduced a method for\nprobing internal activations by patching them into new prompts, prompting\nmodels to self-explain their hidden representations. We introduce Superscopes,\na technique that systematically amplifies superposed features in MLP outputs\n(multilayer perceptron) and hidden states before patching them into new\ncontexts. Inspired by the \"features as directions\" perspective and the\nClassifier-Free Guidance (CFG) approach from diffusion models, Superscopes\namplifies weak but meaningful features, enabling the interpretation of internal\nrepresentations that previous methods failed to explain-all without requiring\nadditional training. This approach provides new insights into how LLMs build\ncontext and represent complex concepts, further advancing mechanistic\ninterpretability.",
      "tldr_zh": "该研究提出了Superscopes技术，用于放大语言模型（LLMs）内部多层感知机（MLP）输出和隐藏状态中的叠加特征，从而更清晰地解释其内部表征。受“特征即方向”观点和扩散模型中Classifier-Free Guidance（CFG）方法的启发，Superscopes无需额外训练即可增强弱但有意义的特征，揭示了以往方法未能解释的内部表征机制。这一技术为理解LLMs如何构建上下文和表示复杂概念提供了新的视角，推动了模型可解释性的研究进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02078v2",
      "published_date": "2025-03-03 21:58:12 UTC",
      "updated_date": "2025-03-09 10:27:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:40.746963"
    },
    {
      "arxiv_id": "2503.02077v2",
      "title": "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality",
      "title_zh": "M3HF：基于多阶段混合质量人类反馈的多智能体强化学习",
      "authors": [
        "Ziyan Wang",
        "Zhicheng Zhang",
        "Fei Fang",
        "Yali Du"
      ],
      "abstract": "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality (M3HF),\na novel framework that integrates multi-phase human feedback of mixed quality\ninto the MARL training process. By involving humans with diverse expertise\nlevels to provide iterative guidance, M3HF leverages both expert and non-expert\nfeedback to continuously refine agents' policies. During training, we\nstrategically pause agent learning for human evaluation, parse feedback using\nlarge language models to assign it appropriately and update reward functions\nthrough predefined templates and adaptive weight by using weight decay and\nperformance-based adjustments. Our approach enables the integration of nuanced\nhuman insights across various levels of quality, enhancing the interpretability\nand robustness of multi-agent cooperation. Empirical results in challenging\nenvironments demonstrate that M3HF significantly outperforms state-of-the-art\nmethods, effectively addressing the complexities of reward design in MARL and\nenabling broader human participation in the training process.",
      "tldr_zh": "该研究提出M3HF框架，通过整合多阶段混合质量的人类反馈来解决多智能体强化学习(MARL)中的奖励函数设计难题。该方法创新性地利用大语言模型解析不同专业水平的人类反馈，通过预设模板和自适应权重机制(结合权重衰减与性能调整)动态更新奖励函数。实验证明，M3HF在复杂协作环境中显著优于现有方法，不仅提高了多智能体合作的鲁棒性，还实现了更广泛的人类参与训练过程。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Seventeen pages, four figures",
      "pdf_url": "http://arxiv.org/pdf/2503.02077v2",
      "published_date": "2025-03-03 21:58:10 UTC",
      "updated_date": "2025-03-06 20:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:55:56.778253"
    },
    {
      "arxiv_id": "2503.02068v1",
      "title": "Interactive Debugging and Steering of Multi-Agent AI Systems",
      "title_zh": "交互式调试与多智能体AI系统的动态引导",
      "authors": [
        "Will Epperson",
        "Gagan Bansal",
        "Victor Dibia",
        "Adam Fourney",
        "Jack Gerrits",
        "Erkang Zhu",
        "Saleema Amershi"
      ],
      "abstract": "Fully autonomous teams of LLM-powered AI agents are emerging that collaborate\nto perform complex tasks for users. What challenges do developers face when\ntrying to build and debug these AI agent teams? In formative interviews with\nfive AI agent developers, we identify core challenges: difficulty reviewing\nlong agent conversations to localize errors, lack of support in current tools\nfor interactive debugging, and the need for tool support to iterate on agent\nconfiguration. Based on these needs, we developed an interactive multi-agent\ndebugging tool, AGDebugger, with a UI for browsing and sending messages, the\nability to edit and reset prior agent messages, and an overview visualization\nfor navigating complex message histories. In a two-part user study with 14\nparticipants, we identify common user strategies for steering agents and\nhighlight the importance of interactive message resets for debugging. Our\nstudies deepen understanding of interfaces for debugging increasingly important\nagentic workflows.",
      "tldr_zh": "本研究关注开发者在构建和调试由LLM驱动的多智能体AI系统时面临的挑战，包括难以审查长对话以定位错误、缺乏交互式调试工具支持等。基于这些需求，研究者开发了AGDebugger工具，提供浏览和发送消息的界面、编辑和重置历史消息的功能，以及复杂消息历史概览的可视化。通过14名参与者的用户研究，揭示了常见的智能体引导策略，并强调了交互式消息重置在调试中的重要性，为日益重要的智能体工作流调试提供了界面设计洞见。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "Published at CHI 25",
      "pdf_url": "http://arxiv.org/pdf/2503.02068v1",
      "published_date": "2025-03-03 21:42:54 UTC",
      "updated_date": "2025-03-03 21:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:04.538034"
    },
    {
      "arxiv_id": "2503.02067v1",
      "title": "AI persuading AI vs AI persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior",
      "title_zh": "AI说服AI与AI说服人类：大语言模型在促进环保行为中的差异有效性",
      "authors": [
        "Alexander Doudkin",
        "Pat Pataranutaporn",
        "Pattie Maes"
      ],
      "abstract": "Pro-environmental behavior (PEB) is vital to combat climate change, yet\nturning awareness into intention and action remains elusive. We explore large\nlanguage models (LLMs) as tools to promote PEB, comparing their impact across\n3,200 participants: real humans (n=1,200), simulated humans based on actual\nparticipant data (n=1,200), and fully synthetic personas (n=1,200). All three\nparticipant groups faced personalized or standard chatbots, or static\nstatements, employing four persuasion strategies (moral foundations, future\nself-continuity, action orientation, or \"freestyle\" chosen by the LLM). Results\nreveal a \"synthetic persuasion paradox\": synthetic and simulated agents\nsignificantly affect their post-intervention PEB stance, while human responses\nbarely shift. Simulated participants better approximate human trends but still\noverestimate effects. This disconnect underscores LLM's potential for\npre-evaluating PEB interventions but warns of its limits in predicting\nreal-world behavior. We call for refined synthetic modeling and sustained and\nextended human trials to align conversational AI's promise with tangible\nsustainability outcomes.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在促进环保行为(PEB)中的有效性，比较了其对真实人类、基于真实数据的模拟人类和完全合成的虚拟人的影响。研究发现，合成和模拟代理对干预后的PEB立场有显著影响，而真实人类的反应几乎没有变化。模拟参与者能更好地近似人类趋势，但仍高估了效果。这一“合成说服悖论”表明，LLMs在预先评估PEB干预措施方面具有潜力，但在预测现实行为方面存在局限。研究呼吁改进合成建模并进行长期的人类试验，以将对话式AI的潜力转化为实际的可持续发展成果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 13 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.02067v1",
      "published_date": "2025-03-03 21:40:55 UTC",
      "updated_date": "2025-03-03 21:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:08.621077"
    },
    {
      "arxiv_id": "2503.02065v1",
      "title": "Survey Perspective: The Role of Explainable AI in Threat Intelligence",
      "title_zh": "调研视角：可解释AI在威胁情报中的作用",
      "authors": [
        "Nidhi Rastogi",
        "Devang Dhanuka",
        "Amulya Saxena",
        "Pranjal Mairal",
        "Le Nguyen"
      ],
      "abstract": "The increasing reliance on AI-based security tools in Security Operations\nCenters (SOCs) has transformed threat detection and response, yet analysts\nfrequently struggle with alert overload, false positives, and lack of\ncontextual relevance. The inability to effectively analyze AI-generated\nsecurity alerts lead to inefficiencies in incident response and reduces trust\nin automated decision-making. In this paper, we show results and analysis of\nour investigation of how SOC analysts navigate AI-based alerts, their\nchallenges with current security tools, and how explainability (XAI) integrated\ninto their security workflows has the potential to become an effective decision\nsupport. In this vein, we conducted an industry survey. Using the survey\nresponses, we analyze how security analysts' process, retrieve, and prioritize\nalerts. Our findings indicate that most analysts have not yet adopted\nXAI-integrated tools, but they express high interest in attack attribution,\nconfidence scores, and feature contribution explanations to improve\ninterpretability, and triage efficiency. Based on our findings, we also propose\npractical design recommendations for XAI-enhanced security alert systems,\nenabling AI-based cybersecurity solutions to be more transparent,\ninterpretable, and actionable.",
      "tldr_zh": "本研究探讨了可解释人工智能(XAI)在威胁情报中的角色，重点分析了安全运营中心(SOC)分析师在处理AI生成的安全警报时面临的挑战，如警报过载、误报和缺乏上下文关联性。通过行业调查发现，尽管大多数分析师尚未采用XAI集成工具，但他们对其在攻击归因、置信度评分和特征贡献解释方面的潜力表现出高度兴趣。基于调查结果，研究提出了XAI增强型安全警报系统的设计建议，旨在提高AI网络安全解决方案的透明度、可解释性和可操作性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02065v1",
      "published_date": "2025-03-03 21:39:15 UTC",
      "updated_date": "2025-03-03 21:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:11.327907"
    },
    {
      "arxiv_id": "2503.02057v1",
      "title": "Hebbian learning the local structure of language",
      "title_zh": "赫布学习：语言的局部结构",
      "authors": [
        "P. Myles Eugenio"
      ],
      "abstract": "Learning in the brain is local and unsupervised (Hebbian). We derive the\nfoundations of an effective human language model inspired by these microscopic\nconstraints. It has two parts: (1) a hierarchy of neurons which learns to\ntokenize words from text (whichiswhatyoudowhenyoureadthis); and (2) additional\nneurons which bind the learned symanticless patterns of the tokenizer into a\nsymanticful token (an embedding). The model permits continuous parallel\nlearning without forgetting; and is a powerful tokenizer which performs\nrenormalization group. This allows it to exploit redundancy, such that it\ngenerates tokens which are always decomposable into a basis set (e.g an\nalphabet), and can mix features learned from multiple languages. We find that\nthe structure of this model allows it to learn a natural language morphology\nWITHOUT data. The language data generated by this model predicts the correct\ndistribution of word-forming patterns observed in real languages, and further\ndemonstrates why microscopically human speech is broken up into words. This\nmodel provides the basis for understanding the microscopic origins of language\nand human creativity.",
      "tldr_zh": "该研究提出了一种受大脑Hebbian学习启发的语言模型，通过局部和无监督的方式模拟人类语言学习过程。模型包含两部分：一是用于从文本中学习分词（tokenize）的神经元层次结构，二是将分词的语义模式绑定为有意义嵌入的附加神经元。该模型支持连续并行学习且不会遗忘，能够进行重整化群操作，利用冗余生成可分解为基集（如字母表）的分词，并可混合多语言特征。研究结果表明，该模型无需数据即可学习自然语言的形态结构，生成的语言数据能够预测真实语言中的词汇形成模式分布，并解释了人类语言为何以词汇为单位进行分割，为理解语言的微观起源和人类创造力提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "10 figures, 14 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.02057v1",
      "published_date": "2025-03-03 21:15:57 UTC",
      "updated_date": "2025-03-03 21:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:27.181786"
    },
    {
      "arxiv_id": "2503.02053v1",
      "title": "EPEE: Towards Efficient and Effective Foundation Models in Biomedicine",
      "title_zh": "EPEE：迈向生物医学中高效且有效的基础模型",
      "authors": [
        "Zaifu Zhan",
        "Shuang Zhou",
        "Huixue Zhou",
        "Zirui Liu",
        "Rui Zhang"
      ],
      "abstract": "Foundation models, including language models, e.g., GPT, and vision models,\ne.g., CLIP, have significantly advanced numerous biomedical tasks. Despite\nthese advancements, the high inference latency and the \"overthinking\" issues in\nmodel inference impair the efficiency and effectiveness of foundation models,\nthus limiting their application in real-time clinical settings. To address\nthese challenges, we proposed EPEE (Entropy- and Patience-based Early Exiting),\na novel hybrid strategy designed to improve the inference efficiency of\nfoundation models. The core idea was to leverage the strengths of entropy-based\nand patience-based early exiting methods to overcome their respective\nweaknesses. To evaluate EPEE, we conducted experiments on three core biomedical\ntasks-classification, relation extraction, and event extraction-using four\nfoundation models (BERT, ALBERT, GPT-2, and ViT) across twelve datasets,\nincluding clinical notes and medical images. The results showed that EPEE\nsignificantly reduced inference time while maintaining or improving accuracy,\ndemonstrating its adaptability to diverse datasets and tasks. EPEE addressed\ncritical barriers to deploying foundation models in healthcare by balancing\nefficiency and effectiveness. It potentially provided a practical solution for\nreal-time clinical decision-making with foundation models, supporting reliable\nand efficient workflows.",
      "tldr_zh": "该研究提出了一种名为EPEE（基于熵和耐心的早期退出）的混合策略，旨在提高生物医学领域基础模型（如BERT、GPT-2等）的推理效率。EPEE结合了基于熵和耐心的早期退出方法，克服了单一方法的局限性，显著减少了推理时间，同时保持或提高了模型在分类、关系抽取和事件抽取等任务中的准确性。实验在12个数据集上进行，涵盖临床笔记和医学图像，结果表明EPEE能够适应多样化的数据和任务，为实时临床决策提供了可靠且高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to npj Digital Medicine",
      "pdf_url": "http://arxiv.org/pdf/2503.02053v1",
      "published_date": "2025-03-03 21:11:13 UTC",
      "updated_date": "2025-03-03 21:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:48.783183"
    },
    {
      "arxiv_id": "2503.02048v1",
      "title": "FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation",
      "title_zh": "FRMD：基于一致性蒸馏运动基元的快速机器人动作扩散模型——实现流畅动作生成",
      "authors": [
        "Xirui Shi",
        "Jun Jin"
      ],
      "abstract": "We consider the problem of using diffusion models to generate fast, smooth,\nand temporally consistent robot motions. Although diffusion models have\ndemonstrated superior performance in robot learning due to their task\nscalability and multi-modal flexibility, they suffer from two fundamental\nlimitations: (1) they often produce non-smooth, jerky motions due to their\ninability to capture temporally consistent movement dynamics, and (2) their\niterative sampling process incurs prohibitive latency for many robotic tasks.\nInspired by classic robot motion generation methods such as DMPs and ProMPs,\nwhich capture temporally and spatially consistent dynamic of trajectories using\nlow-dimensional vectors -- and by recent advances in diffusion-based image\ngeneration that use consistency models with probability flow ODEs to accelerate\nthe denoising process, we propose Fast Robot Motion Diffusion (FRMD). FRMD\nuniquely integrates Movement Primitives (MPs) with Consistency Models to enable\nefficient, single-step trajectory generation. By leveraging probabilistic flow\nODEs and consistency distillation, our method models trajectory distributions\nwhile learning a compact, time-continuous motion representation within an\nencoder-decoder architecture. This unified approach eliminates the slow,\nmulti-step denoising process of conventional diffusion models, enabling\nefficient one-step inference and smooth robot motion generation. We extensively\nevaluated our FRMD on the well-recognized Meta-World and ManiSkills Benchmarks,\nranging from simple to more complex manipulation tasks, comparing its\nperformance against state-of-the-art baselines. Our results show that FRMD\ngenerates significantly faster, smoother trajectories while achieving higher\nsuccess rates.",
      "tldr_zh": "本研究提出了FRMD（Fast Robot Motion Diffusion）方法，通过将运动基元(Movement Primitives)与一致性模型(Consistency Models)相结合，解决了传统扩散模型在机器人运动生成中存在的两个主要问题：运动不连贯和迭代采样延迟。FRMD利用概率流ODE和一致性蒸馏技术，在编码器-解码器架构中学习紧凑的连续时间运动表示，实现了高效的单步轨迹生成。实验表明，FRMD在Meta-World和ManiSkills基准测试中，相比现有方法能生成更快、更平滑的轨迹，同时提高了任务成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: text overlap with arXiv:2406.01586 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2503.02048v1",
      "published_date": "2025-03-03 20:56:39 UTC",
      "updated_date": "2025-03-03 20:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:35.496831"
    },
    {
      "arxiv_id": "2503.02039v1",
      "title": "Dynamic Search for Inference-Time Alignment in Diffusion Models",
      "title_zh": "扩散模型中基于动态搜索的推理时对齐方法",
      "authors": [
        "Xiner Li",
        "Masatoshi Uehara",
        "Xingyu Su",
        "Gabriele Scalia",
        "Tommaso Biancalani",
        "Aviv Regev",
        "Sergey Levine",
        "Shuiwang Ji"
      ],
      "abstract": "Diffusion models have shown promising generative capabilities across diverse\ndomains, yet aligning their outputs with desired reward functions remains a\nchallenge, particularly in cases where reward functions are non-differentiable.\nSome gradient-free guidance methods have been developed, but they often\nstruggle to achieve optimal inference-time alignment. In this work, we newly\nframe inference-time alignment in diffusion as a search problem and propose\nDynamic Search for Diffusion (DSearch), which subsamples from denoising\nprocesses and approximates intermediate node rewards. It also dynamically\nadjusts beam width and tree expansion to efficiently explore high-reward\ngenerations. To refine intermediate decisions, DSearch incorporates adaptive\nscheduling based on noise levels and a lookahead heuristic function. We\nvalidate DSearch across multiple domains, including biological sequence design,\nmolecular optimization, and image generation, demonstrating superior reward\noptimization compared to existing approaches.",
      "tldr_zh": "本研究提出了一种名为动态搜索（DSearch）的新方法，用于在扩散模型（Diffusion Models）的推理阶段实现输出与目标奖励函数的对齐。DSearch将推理对齐问题转化为搜索问题，通过子采样去噪过程并近似中间节点奖励，动态调整搜索宽度和树扩展，以高效探索高奖励生成结果。该方法还结合了基于噪声水平的自适应调度和前瞻启发函数，优化中间决策。实验表明，DSearch在生物序列设计、分子优化和图像生成等多个领域均优于现有方法，显著提升了奖励优化效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02039v1",
      "published_date": "2025-03-03 20:32:05 UTC",
      "updated_date": "2025-03-03 20:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:56:42.336382"
    },
    {
      "arxiv_id": "2503.05803v1",
      "title": "Federated Learning Framework via Distributed Mutual Learning",
      "title_zh": "基于分布式互学习的联邦学习框架",
      "authors": [
        "Yash Gupta"
      ],
      "abstract": "Federated Learning often relies on sharing full or partial model weights,\nwhich can burden network bandwidth and raise privacy risks. We present a\nloss-based alternative using distributed mutual learning. Instead of\ntransmitting weights, clients periodically share their loss predictions on a\npublic test set. Each client then refines its model by combining its local loss\nwith the average Kullback-Leibler divergence over losses from other clients.\nThis collaborative approach both reduces transmission overhead and preserves\ndata privacy. Experiments on a face mask detection task demonstrate that our\nmethod outperforms weight-sharing baselines, achieving higher accuracy on\nunseen data while providing stronger generalization and privacy benefits.",
      "tldr_zh": "该研究提出了一种基于分布式互学习（distributed mutual learning）的联邦学习新框架。该方法创新性地采用损失预测共享机制替代传统的模型权重传输，客户端通过交换在公共测试集上的损失预测并结合Kullback-Leibler散度进行模型优化，既降低了网络传输开销又增强了数据隐私保护。在口罩检测任务上的实验表明，该方法不仅优于权重共享基线模型，在未见数据上实现了更高准确率，同时具备更好的泛化能力和隐私保护优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05803v1",
      "published_date": "2025-03-03 20:15:32 UTC",
      "updated_date": "2025-03-03 20:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:57:16.426908"
    },
    {
      "arxiv_id": "2503.02034v1",
      "title": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA",
      "title_zh": "Abn-BLIP：基于异常对齐的引导式语言-图像预训练用于CTPA肺栓塞诊断与报告生成",
      "authors": [
        "Zhusi Zhong",
        "Yuli Wang",
        "Lulu Bi",
        "Zhuoqi Ma",
        "Sun Ho Ahn",
        "Christopher J. Mullin",
        "Colin F. Greineder",
        "Michael K. Atalay",
        "Scott Collins",
        "Grayson L. Baird",
        "Cheng Ting Lin",
        "Webster Stayman",
        "Todd M. Kolb",
        "Ihab Kamel",
        "Harrison X. Bai",
        "Zhicheng Jiao"
      ],
      "abstract": "Medical imaging plays a pivotal role in modern healthcare, with computed\ntomography pulmonary angiography (CTPA) being a critical tool for diagnosing\npulmonary embolism and other thoracic conditions. However, the complexity of\ninterpreting CTPA scans and generating accurate radiology reports remains a\nsignificant challenge. This paper introduces Abn-BLIP (Abnormality-aligned\nBootstrapping Language-Image Pretraining), an advanced diagnosis model designed\nto align abnormal findings to generate the accuracy and comprehensiveness of\nradiology reports. By leveraging learnable queries and cross-modal attention\nmechanisms, our model demonstrates superior performance in detecting\nabnormalities, reducing missed findings, and generating structured reports\ncompared to existing methods. Our experiments show that Abn-BLIP outperforms\nstate-of-the-art medical vision-language models and 3D report generation\nmethods in both accuracy and clinical relevance. These results highlight the\npotential of integrating multimodal learning strategies for improving radiology\nreporting. The source code is available at https://github.com/zzs95/abn-blip.",
      "tldr_zh": "本研究提出Abn-BLIP（异常对齐的自举语言-图像预训练）模型，用于从CT肺动脉造影(CTPA)中诊断肺栓塞并生成放射学报告。该模型通过可学习查询(learnable queries)和跨模态注意力机制，将异常发现与报告生成对齐，显著提高了异常检测准确率并减少漏诊。实验表明，Abn-BLIP在诊断精度和报告临床相关性上均优于当前最先进的医学视觉-语言模型和3D报告生成方法，为改进放射学报告提供了有效的多模态学习策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02034v1",
      "published_date": "2025-03-03 20:13:39 UTC",
      "updated_date": "2025-03-03 20:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:57:40.510804"
    },
    {
      "arxiv_id": "2503.02032v1",
      "title": "Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering",
      "title_zh": "OpenAI GPT-4o 与 DeepSeek R1 在科学文本分类中的提示工程比较分析",
      "authors": [
        "Aniruddha Maiti",
        "Samuel Adewumi",
        "Temesgen Alemayehu Tikure",
        "Zichun Wang",
        "Niladri Sengupta",
        "Anastasiia Sukhanova",
        "Ananya Jana"
      ],
      "abstract": "This study examines how large language models categorize sentences from\nscientific papers using prompt engineering. We use two advanced web-based\nmodels, GPT-4o (by OpenAI) and DeepSeek R1, to classify sentences into\npredefined relationship categories. DeepSeek R1 has been tested on benchmark\ndatasets in its technical report. However, its performance in scientific text\ncategorization remains unexplored. To address this gap, we introduce a new\nevaluation method designed specifically for this task. We also compile a\ndataset of cleaned scientific papers from diverse domains. This dataset\nprovides a platform for comparing the two models. Using this dataset, we\nanalyze their effectiveness and consistency in categorization.",
      "tldr_zh": "本研究通过提示工程（Prompt Engineering）比较了OpenAI的GPT-4o和DeepSeek R1在科学文本分类任务中的表现。研究提出了一种新的评估方法，并构建了一个涵盖多领域的科学论文数据集，用于测试这两种大型语言模型在句子关系分类中的效果和一致性。实验填补了DeepSeek R1在科学文本分类领域性能评估的空白，并为其与GPT-4o的对比提供了实证依据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ASEE North Central Section 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02032v1",
      "published_date": "2025-03-03 20:09:35 UTC",
      "updated_date": "2025-03-03 20:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:14.627908"
    },
    {
      "arxiv_id": "2503.02016v1",
      "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs",
      "title_zh": "关注（信念）鸿沟：大语言模型世界中的群体认同",
      "authors": [
        "Angana Borah",
        "Marwa Houalla",
        "Rada Mihalcea"
      ],
      "abstract": "Social biases and belief-driven behaviors can significantly impact Large\nLanguage Models (LLMs) decisions on several tasks. As LLMs are increasingly\nused in multi-agent systems for societal simulations, their ability to model\nfundamental group psychological characteristics remains critical yet\nunder-explored. In this study, we present a multi-agent framework that\nsimulates belief congruence, a classical group psychology theory that plays a\ncrucial role in shaping societal interactions and preferences. Our findings\nreveal that LLMs exhibit amplified belief congruence compared to humans, across\ndiverse contexts. We further investigate the implications of this behavior on\ntwo downstream tasks: (1) misinformation dissemination and (2) LLM learning,\nfinding that belief congruence in LLMs increases misinformation dissemination\nand impedes learning. To mitigate these negative impacts, we propose strategies\ninspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global\ncitizenship framework. Our results show that the best strategies reduce\nmisinformation dissemination by up to 37% and enhance learning by 11%. Bridging\nsocial psychology and AI, our work provides insights to navigate real-world\ninteractions using LLMs while addressing belief-driven biases.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在群体心理学中的表现，特别是其信念一致性（belief congruence）行为。研究发现，LLMs在模拟群体互动时表现出比人类更强的信念一致性，导致其在虚假信息传播任务中加剧了错误信息的扩散，并在学习任务中阻碍了进步。为了减轻这些负面影响，研究提出了基于接触假设、准确性提示和全球公民框架的缓解策略，成功将虚假信息传播减少37%，并将学习效果提升11%。这项研究为在现实世界应用中减少LLMs的信念驱动偏见提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02016v1",
      "published_date": "2025-03-03 19:50:52 UTC",
      "updated_date": "2025-03-03 19:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:57:55.133327"
    },
    {
      "arxiv_id": "2503.02012v2",
      "title": "Pretrained Embeddings as a Behavior Specification Mechanism",
      "title_zh": "预训练嵌入作为行为规范机制",
      "authors": [
        "Parv Kapoor",
        "Abigail Hammer",
        "Ashish Kapoor",
        "Karen Leung",
        "Eunsuk Kang"
      ],
      "abstract": "We propose an approach to formally specifying the behavioral properties of\nsystems that rely on a perception model for interactions with the physical\nworld. The key idea is to introduce embeddings -- mathematical representations\nof a real-world concept -- as a first-class construct in a specification\nlanguage, where properties are expressed in terms of distances between a pair\nof ideal and observed embeddings. To realize this approach, we propose a new\ntype of temporal logic called Embedding Temporal Logic (ETL), and describe how\nit can be used to express a wider range of properties about AI-enabled systems\nthan previously possible. We demonstrate the applicability of ETL through a\npreliminary evaluation involving planning tasks in robots that are driven by\nfoundation models; the results are promising, showing that embedding-based\nspecifications can be used to steer a system towards desirable behaviors.",
      "tldr_zh": "本文提出了一种基于预训练嵌入(embeddings)的行为规范机制，用于形式化描述依赖感知模型与物理世界交互的系统的行为属性。核心思想是将嵌入——即真实世界概念的数学表示——作为规范语言中的一等公民，通过理想嵌入与观测嵌入之间的距离来表达系统属性。为此，作者提出了一种新型时序逻辑——嵌入时序逻辑(Embedding Temporal Logic, ETL)，能够比现有方法表达更广泛的AI系统属性。初步实验表明，ETL在基于基础模型的机器人规划任务中表现良好，证明了嵌入规范可用于引导系统实现期望行为。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.02012v2",
      "published_date": "2025-03-03 19:41:22 UTC",
      "updated_date": "2025-03-06 14:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:28.375370"
    },
    {
      "arxiv_id": "2503.02007v1",
      "title": "TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication",
      "title_zh": "TactStyle：利用生成式AI为数字制造生成触觉纹理",
      "authors": [
        "Faraz Faruqi",
        "Maxine Perroni-Scharf",
        "Jaskaran Singh Walia",
        "Yunyi Zhu",
        "Shuyue Feng",
        "Donald Degraen",
        "Stefanie Mueller"
      ],
      "abstract": "Recent work in Generative AI enables the stylization of 3D models based on\nimage prompts. However, these methods do not incorporate tactile information,\nleading to designs that lack the expected tactile properties. We present\nTactStyle, a system that allows creators to stylize 3D models with images while\nincorporating the expected tactile properties. TactStyle accomplishes this\nusing a modified image-generation model fine-tuned to generate heightfields for\ngiven surface textures. By optimizing 3D model surfaces to embody a generated\ntexture, TactStyle creates models that match the desired style and replicate\nthe tactile experience. We utilize a large-scale dataset of textures to train\nour texture generation model. In a psychophysical experiment, we evaluate the\ntactile qualities of a set of 3D-printed original textures and TactStyle's\ngenerated textures. Our results show that TactStyle successfully generates a\nwide range of tactile features from a single image input, enabling a novel\napproach to haptic design.",
      "tldr_zh": "本文提出了TactStyle系统，利用生成式AI为3D模型生成具有触觉特性的纹理。该系统通过微调图像生成模型，生成给定表面纹理的高度场，并优化3D模型表面以体现生成的纹理，从而确保模型不仅符合视觉风格，还能复制预期的触觉体验。基于大规模纹理数据集训练的模型，在心理物理实验中验证了其生成的纹理与原始纹理在触觉特性上的高度一致性，为触觉设计提供了一种创新方法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02007v1",
      "published_date": "2025-03-03 19:29:27 UTC",
      "updated_date": "2025-03-03 19:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:03.725774"
    },
    {
      "arxiv_id": "2503.05802v1",
      "title": "Illuminant and light direction estimation using Wasserstein distance method",
      "title_zh": "基于Wasserstein距离方法的照明和光源方向估计",
      "authors": [
        "Selcuk Yazar"
      ],
      "abstract": "Illumination estimation remains a pivotal challenge in image processing,\nparticularly for robotics, where robust environmental perception is essential\nunder varying lighting conditions. Traditional approaches, such as RGB\nhistograms and GIST descriptors, often fail in complex scenarios due to their\nsensitivity to illumination changes. This study introduces a novel method\nutilizing the Wasserstein distance, rooted in optimal transport theory, to\nestimate illuminant and light direction in images. Experiments on diverse\nimages indoor scenes, black-and-white photographs, and night images demonstrate\nthe method's efficacy in detecting dominant light sources and estimating their\ndirections, outperforming traditional statistical methods in complex lighting\nenvironments. The approach shows promise for applications in light source\nlocalization, image quality assessment, and object detection enhancement.\nFuture research may explore adaptive thresholding and integrate gradient\nanalysis to enhance accuracy, offering a scalable solution for real-world\nillumination challenges in robotics and beyond.",
      "tldr_zh": "本研究提出了一种基于Wasserstein距离的新方法，用于估计图像中的光源和光照方向，解决了传统RGB直方图和GIST描述符在复杂光照条件下表现不佳的问题。该方法利用最优传输理论，在室内场景、黑白照片和夜间图像等多种环境下表现出色，能够有效检测主光源并估计其方向，优于传统统计方法。这一方法在光源定位、图像质量评估和物体检测增强等领域具有应用潜力，为机器人和图像处理中的实际光照挑战提供了可扩展的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05802v1",
      "published_date": "2025-03-03 19:20:09 UTC",
      "updated_date": "2025-03-03 19:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:30.387242"
    },
    {
      "arxiv_id": "2503.01986v1",
      "title": "Adaptively evaluating models with task elicitation",
      "title_zh": "通过任务启发自适应评估模型",
      "authors": [
        "Davis Brown",
        "Prithvi Balehannina",
        "Helen Jin",
        "Shreya Havaldar",
        "Hamed Hassani",
        "Eric Wong"
      ],
      "abstract": "Manual curation of evaluation datasets is struggling to keep up with the\nrapidly expanding capabilities and deployment scenarios of language models.\nTowards scalable model profiling, we introduce and validate a framework for\nevaluating LLMs, called Adaptive Evaluations. Adaptive evaluations use\nscaffolded language models (evaluator agents) to search through a target\nmodel's behavior on a domain dataset and create difficult questions (tasks)\nthat can discover and probe the model's failure modes. We find that frontier\nmodels lack consistency when adaptively probed with our framework on a diverse\nsuite of datasets and tasks, including but not limited to legal reasoning,\nforecasting, and online harassment. Generated questions pass human validity\nchecks and often transfer to other models with different capability profiles,\ndemonstrating that adaptive evaluations can also be used to create difficult\ndomain-specific datasets.",
      "tldr_zh": "本研究提出了一种名为“自适应评估”(Adaptive Evaluations)的框架，用于扩展语言模型(LLMs)的评估能力。该框架利用脚手架语言模型（评估代理）在目标模型的行为中搜索，并生成能够探测模型失败模式的困难问题（任务）。实验表明，前沿模型在面对多样化的数据集和任务（如法律推理、预测和在线骚扰）时缺乏一致性。生成的问题通过了人类有效性检查，并且通常能迁移到其他不同能力配置的模型上，表明该框架还可用于创建困难的领域特定数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01986v1",
      "published_date": "2025-03-03 19:04:10 UTC",
      "updated_date": "2025-03-03 19:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:29.161782"
    },
    {
      "arxiv_id": "2503.01985v1",
      "title": "Proportionality in Thumbs Up and Down Voting",
      "title_zh": "点赞与点踩投票中的比例性",
      "authors": [
        "Sonja Kraiczy",
        "Georgios Papasotiropoulos",
        "Grzegorz Pierczyński",
        "Piotr Skowron"
      ],
      "abstract": "Consider the decision-making setting where agents elect a panel by expressing\nboth positive and negative preferences. Prominently, in constitutional AI,\ncitizens democratically select a slate of ethical preferences on which a\nfoundation model is to be trained. There, in practice, agents may both approve\nand disapprove of different ethical principles. Proportionality has been\nwell-studied in computational social choice for approval ballots, but its\nmeaning remains unclear when negative sentiments are also considered. In this\nwork, we propose two conceptually distinct approaches to interpret\nproportionality in the presence of up and down votes. The first approach treats\nthe satisfaction from electing candidates and the impact of vetoing them as\ncomparable, leading to combined proportionality guarantees. The second approach\nconsiders veto power separately, introducing guarantees distinct from\ntraditional proportionality. We formalize axioms for each perspective and\nexamine their satisfiability by suitable adaptations of Phragm\\'en's rule,\nProportional Approval Voting rule and the Method of Equal Shares.",
      "tldr_zh": "本研究探讨了在正反投票（thumbs up and down voting）情境下的比例性问题，特别是在宪法AI中公民选择伦理偏好面板的背景下。研究提出了两种截然不同的方法来解释正反投票下的比例性：第一种方法将选举候选人的满足感与否决他们的影响视为可比较的，从而得出综合的比例性保证；第二种方法则单独考虑否决权，引入与传统比例性不同的保证。研究通过调整Phragmén规则、比例批准投票规则和均等份额方法，形式化并检验了这些视角下的公理可满足性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01985v1",
      "published_date": "2025-03-03 19:02:37 UTC",
      "updated_date": "2025-03-03 19:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:47.345148"
    },
    {
      "arxiv_id": "2503.01980v1",
      "title": "Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval",
      "title_zh": "基于循环增强的视觉与语言Transformer实现鲁棒多模态文档检索",
      "authors": [
        "Davide Caffagni",
        "Sara Sarto",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "Cross-modal retrieval is gaining increasing efficacy and interest from the\nresearch community, thanks to large-scale training, novel architectural and\nlearning designs, and its application in LLMs and multimodal LLMs. In this\npaper, we move a step forward and design an approach that allows for multimodal\nqueries, composed of both an image and a text, and can search within\ncollections of multimodal documents, where images and text are interleaved. Our\nmodel, ReT, employs multi-level representations extracted from different layers\nof both visual and textual backbones, both at the query and document side. To\nallow for multi-level and cross-modal understanding and feature extraction, ReT\nemploys a novel Transformer-based recurrent cell that integrates both textual\nand visual features at different layers, and leverages sigmoidal gates inspired\nby the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR\nbenchmarks show that ReT achieves state-of-the-art performance across diverse\nsettings. Our source code and trained models are publicly available at\nhttps://github.com/aimagelab/ReT.",
      "tldr_zh": "本研究提出了Recurrence-Enhanced Vision-and-Language Transformers (ReT)，一种用于多模态文档检索的增强型Transformer模型。ReT通过引入基于LSTM启发的sigmoidal门控机制，实现了视觉和文本特征在不同层级的深度融合，支持由图像和文本组成的多模态查询，并能在图像和文本交织的多模态文档集合中进行检索。实验表明，ReT在M2KR和M-BEIR基准测试中取得了最先进的性能，为多模态检索任务提供了更强大的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01980v1",
      "published_date": "2025-03-03 19:01:17 UTC",
      "updated_date": "2025-03-03 19:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:35.662197"
    },
    {
      "arxiv_id": "2503.01839v1",
      "title": "Jailbreaking Safeguarded Text-to-Image Models via Large Language Models",
      "title_zh": "通过大型语言模型突破受保护文本到图像模型的安全防护",
      "authors": [
        "Zhengyuan Jiang",
        "Yuepeng Hu",
        "Yuchen Yang",
        "Yinzhi Cao",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Text-to-Image models may generate harmful content, such as pornographic\nimages, particularly when unsafe prompts are submitted. To address this issue,\nsafety filters are often added on top of text-to-image models, or the models\nthemselves are aligned to reduce harmful outputs. However, these defenses\nremain vulnerable when an attacker strategically designs adversarial prompts to\nbypass these safety guardrails. In this work, we propose PromptTune, a method\nto jailbreak text-to-image models with safety guardrails using a fine-tuned\nlarge language model. Unlike other query-based jailbreak attacks that require\nrepeated queries to the target model, our attack generates adversarial prompts\nefficiently after fine-tuning our AttackLLM. We evaluate our method on three\ndatasets of unsafe prompts and against five safety guardrails. Our results\ndemonstrate that our approach effectively bypasses safety guardrails,\noutperforms existing no-box attacks, and also facilitates other query-based\nattacks.",
      "tldr_zh": "该研究提出了PromptTune方法，利用微调的大型语言模型（AttackLLM）绕过文本到图像模型的安全防护机制，生成对抗性提示（adversarial prompts）。与需要多次查询目标模型的传统攻击不同，该方法在微调后能高效生成对抗性提示。实验表明，该方法在三个不安全提示数据集和五种安全防护机制上均能有效绕过防护，优于现有的无盒攻击（no-box attacks），并支持其他基于查询的攻击。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01839v1",
      "published_date": "2025-03-03 18:58:46 UTC",
      "updated_date": "2025-03-03 18:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:58:43.978748"
    },
    {
      "arxiv_id": "2503.01836v1",
      "title": "CrowdSelect: Synthetic Instruction Data Selection with Multi-LLM Wisdom",
      "title_zh": "CrowdSelect：基于多LLM智慧的合成指令数据选择",
      "authors": [
        "Yisen Li",
        "Lingfeng Yang",
        "Wenxuan Shen",
        "Pan Zhou",
        "Yao Wan",
        "Weiwei Lin",
        "Dongping Chen"
      ],
      "abstract": "Distilling advanced Large Language Models' instruction-following capabilities\ninto smaller models using a selected subset has become a mainstream approach in\nmodel training. While existing synthetic instruction data selection strategies\nrely mainly on single-dimensional signals (i.e., reward scores, model\nperplexity), they fail to capture the complexity of instruction-following\nacross diverse fields. Therefore, we investigate more diverse signals to\ncapture comprehensive instruction-response pair characteristics and propose\nthree foundational metrics that leverage Multi-LLM wisdom, informed by (1)\ndiverse LLM responses and (2) reward model assessment. Building upon base\nmetrics, we propose CrowdSelect, an integrated metric incorporating a\nclustering-based approach to maintain response diversity. Our comprehensive\nexperiments demonstrate that our foundation metrics consistently improve\nperformance across 4 base models on MT-bench and Arena-Hard. CrowdSelect,\nefficiently incorporating all metrics, achieves state-of-the-art performance in\nboth Full and LoRA fine-tuning, showing improvements of 4.81% on Arena-Hard and\n11.1% on MT-bench with Llama-3.2-3b-instruct. We hope our findings will bring\nvaluable insights for future research in this direction. Code are available at\nhttps://github.com/listentm/crowdselect.",
      "tldr_zh": "该研究提出了CrowdSelect，一种基于多LLM智慧的合成指令数据选择方法，旨在提升小模型在指令跟随任务中的表现。通过结合多样化的LLM响应和奖励模型评估，提出了三个基础指标，并进一步开发了集成这些指标的CrowdSelect方法，采用聚类策略保持响应多样性。实验表明，CrowdSelect在MT-bench和Arena-Hard基准测试中显著提升了模型性能，特别是在Llama-3.2-3b-instruct模型上，分别实现了11.1%和4.81%的改进。该方法为指令数据选择提供了新的研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01836v1",
      "published_date": "2025-03-03 18:56:44 UTC",
      "updated_date": "2025-03-03 18:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:59:27.888046"
    },
    {
      "arxiv_id": "2503.01829v2",
      "title": "Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models",
      "title_zh": "说服我试试看：评估大型语言模型说服效果与易感性的框架",
      "authors": [
        "Nimet Beyza Bozdag",
        "Shuhaib Mehri",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate persuasive capabilities that rival\nhuman-level persuasion. While these capabilities can be used for social good,\nthey also present risks of potential misuse. Moreover, LLMs' susceptibility to\npersuasion raises concerns about alignment with ethical principles. To study\nthese dynamics, we introduce Persuade Me If You Can (PMIYC), an automated\nframework for evaluating persuasion through multi-agent interactions. Here,\nPersuader agents engage in multi-turn conversations with the Persuadee agents,\nallowing us to measure LLMs' persuasive effectiveness and their susceptibility\nto persuasion. We conduct comprehensive evaluations across diverse LLMs,\nensuring each model is assessed against others in both subjective and\nmisinformation contexts. We validate the efficacy of our framework through\nhuman evaluations and show alignment with prior work. PMIYC offers a scalable\nalternative to human annotation for studying persuasion in LLMs. Through PMIYC,\nwe find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness,\noutperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50%\ngreater resistance to persuasion for misinformation compared to Llama-3.3-70B.\nThese findings provide empirical insights into the persuasive dynamics of LLMs\nand contribute to the development of safer AI systems.",
      "tldr_zh": "该研究提出了“Persuade Me If You Can (PMIYC)”框架，用于评估大语言模型(LLMs)的说服力及其对说服的易感性。通过多智能体交互，PMIYC在主观信息和错误信息情境下对多种LLMs进行了全面评估。研究发现，Llama-3.3-70B和GPT-4o的说服力相当，均优于Claude 3 Haiku 30%；然而，GPT-4o在抵抗错误信息说服方面表现更佳，比Llama-3.3-70B高出50%以上。该框架为研究LLMs的说服动态提供了可扩展的自动化工具，并有助于开发更安全的AI系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01829v2",
      "published_date": "2025-03-03 18:53:21 UTC",
      "updated_date": "2025-03-06 22:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:59:22.310038"
    },
    {
      "arxiv_id": "2503.01822v1",
      "title": "Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry",
      "title_zh": "投影假设：稀疏自编码器与概念几何的对偶性",
      "authors": [
        "Sai Sumedh R. Hindupur",
        "Ekdeep Singh Lubana",
        "Thomas Fel",
        "Demba Ba"
      ],
      "abstract": "Sparse Autoencoders (SAEs) are widely used to interpret neural networks by\nidentifying meaningful concepts from their representations. However, do SAEs\ntruly uncover all concepts a model relies on, or are they inherently biased\ntoward certain kinds of concepts? We introduce a unified framework that recasts\nSAEs as solutions to a bilevel optimization problem, revealing a fundamental\nchallenge: each SAE imposes structural assumptions about how concepts are\nencoded in model representations, which in turn shapes what it can and cannot\ndetect. This means different SAEs are not interchangeable -- switching\narchitectures can expose entirely new concepts or obscure existing ones. To\nsystematically probe this effect, we evaluate SAEs across a spectrum of\nsettings: from controlled toy models that isolate key variables, to\nsemi-synthetic experiments on real model activations and finally to\nlarge-scale, naturalistic datasets. Across this progression, we examine two\nfundamental properties that real-world concepts often exhibit: heterogeneity in\nintrinsic dimensionality (some concepts are inherently low-dimensional, others\nare not) and nonlinear separability. We show that SAEs fail to recover concepts\nwhen these properties are ignored, and we design a new SAE that explicitly\nincorporates both, enabling the discovery of previously hidden concepts and\nreinforcing our theoretical insights. Our findings challenge the idea of a\nuniversal SAE and underscores the need for architecture-specific choices in\nmodel interpretability. Overall, we argue an SAE does not just reveal concepts\n-- it determines what can be seen at all.",
      "tldr_zh": "该研究探讨了稀疏自编码器(SAEs)在解释神经网络时的局限性，揭示了SAEs本质上会对概念检测产生结构性偏差。通过将SAEs重新定义为双层优化问题，研究发现不同的SAE架构会暴露或隐藏不同的概念，这取决于它们对概念编码方式的假设。为了系统地分析这一效应，研究从玩具模型到大规模自然数据集进行了一系列实验，重点关注概念的两个关键属性：内在维度的异质性和非线性可分性。结果表明，忽略这些属性会导致SAEs无法恢复概念，而新设计的SAE通过显式结合这些属性，能够发现之前隐藏的概念。研究挑战了通用SAE的观念，强调了模型可解释性中架构选择的重要性，并指出SAE不仅揭示概念，还决定了哪些概念可以被发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.01822v1",
      "published_date": "2025-03-03 18:47:40 UTC",
      "updated_date": "2025-03-03 18:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:59:51.645060"
    },
    {
      "arxiv_id": "2503.01820v1",
      "title": "RSQ: Learning from Important Tokens Leads to Better Quantized LLMs",
      "title_zh": "RSQ：从重要词元学习提升量化大型语言模型性能",
      "authors": [
        "Yi-Lin Sung",
        "Prateek Yadav",
        "Jialu Li",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Layer-wise quantization is a key technique for efficiently compressing large\nmodels without expensive retraining. Previous methods typically quantize the\nweights of each layer by \"uniformly\" optimizing the layer reconstruction loss\nacross all output tokens. However, in this paper, we demonstrate that\nbetter-quantized models can be obtained by prioritizing learning from important\ntokens (e.g. which have large attention scores). Building on this finding, we\npropose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations\n(orthogonal transformation) to the model to mitigate outliers (those with\nexceptionally large magnitude), (2) scales the token feature based on its\nimportance, and (3) quantizes the model using the GPTQ framework with the\nsecond-order statistics computed by scaled tokens. To compute token importance,\nwe explore both heuristic and dynamic strategies. Based on a thorough analysis\nof all approaches, we adopt attention concentration, which uses attention\nscores of each token as its importance, as the best approach. We demonstrate\nthat RSQ consistently outperforms baseline methods across multiple downstream\ntasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally,\nmodels quantized with RSQ achieve superior performance on long-context tasks,\nfurther highlighting its effectiveness. Lastly, RSQ demonstrates\ngeneralizability across various setups, including different model sizes,\ncalibration datasets, bit precisions, and quantization methods.",
      "tldr_zh": "本文提出了RSQ（Rotate, Scale, then Quantize）方法，通过优先学习重要token（如具有较大attention score的token）来提升量化大型语言模型（LLMs）的效果。RSQ首先通过正交变换缓解异常值影响，然后根据token重要性进行特征缩放，最后在GPTQ框架下利用缩放后的token进行量化。实验表明，RSQ在LLaMA3、Mistral和Qwen2.5等多个模型家族上均优于基线方法，尤其在长上下文任务中表现突出，并展示了在不同模型规模、校准数据集、比特精度和量化方法下的广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Our code is available at https://github.com/ylsung/rsq",
      "pdf_url": "http://arxiv.org/pdf/2503.01820v1",
      "published_date": "2025-03-03 18:46:33 UTC",
      "updated_date": "2025-03-03 18:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:00:05.739219"
    },
    {
      "arxiv_id": "2503.01819v1",
      "title": "Do GFlowNets Transfer? Case Study on the Game of 24/42",
      "title_zh": "GFlowNets是否具备迁移能力？基于24/42游戏的案例研究",
      "authors": [
        "Adesh Gupta",
        "Abhinav Kumar",
        "Mansi Gupta",
        "Paras Chopra"
      ],
      "abstract": "Generating diverse solutions is key to human-like reasoning, yet\nautoregressive language models focus on single accurate responses, limiting\ncreativity. GFlowNets optimize solution generation as a flow network, promising\ngreater diversity. Our case study shows their limited zero-shot transferability\nby fine-tuning small and medium-sized large language models on the Game of 24\nand testing them on the Game of 42 datasets. Results revealed that GFlowNets\nstruggle to maintain solution diversity and accuracy, highlighting key\nlimitations in their cross-task generalization and the need for future research\nin improved transfer learning capabilities.",
      "tldr_zh": "这篇论文研究了GFlowNets在跨任务迁移中的表现。通过在\"24点游戏\"数据集上微调中小型语言模型，并在\"42点游戏\"上进行测试，发现GFlowNets难以保持解法的多样性和准确性。该研究揭示了GFlowNets在跨任务泛化方面的关键局限，指出需要改进其迁移学习能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01819v1",
      "published_date": "2025-03-03 18:43:25 UTC",
      "updated_date": "2025-03-03 18:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:59:55.808905"
    },
    {
      "arxiv_id": "2503.01814v1",
      "title": "LLMInit: A Free Lunch from Large Language Models for Selective Initialization of Recommendation",
      "title_zh": "LLMInit：利用大型语言模型进行选择性初始化的推荐系统免费午餐",
      "authors": [
        "Weizhi Zhang",
        "Liangwei Yang",
        "Wooseong Yang",
        "Henry Peng Zou",
        "Yuqing Liu",
        "Ke Xu",
        "Sourav Medya",
        "Philip S. Yu"
      ],
      "abstract": "Collaborative filtering models, particularly graph-based approaches, have\ndemonstrated strong performance in capturing user-item interactions for\nrecommendation systems. However, they continue to struggle in cold-start and\ndata-sparse scenarios. The emergence of large language models (LLMs) like GPT\nand LLaMA presents new possibilities for enhancing recommendation performance,\nespecially in cold-start settings. Despite their promise, LLMs pose challenges\nrelated to scalability and efficiency due to their high computational demands\nand limited ability to model complex user-item relationships effectively. In\nthis work, we introduce a novel perspective on leveraging LLMs for CF model\ninitialization. Through experiments, we uncover an embedding collapse issue\nwhen scaling CF models to larger embedding dimensions. To effectively harness\nlarge-scale LLM embeddings, we propose innovative selective initialization\nstrategies utilizing random, uniform, and variance-based index sampling. Our\ncomprehensive evaluation on multiple real-world datasets demonstrates\nsignificant performance gains across various CF models while maintaining a\nlower computational cost compared to existing LLM-based recommendation\napproaches.",
      "tldr_zh": "该研究提出LLMInit框架，利用大语言模型(LLMs)为推荐系统的协同过滤(CF)模型提供选择性初始化，以解决冷启动和数据稀疏问题。研究发现，CF模型在扩展嵌入维度时会出现嵌入崩溃现象，为此提出了基于随机、均匀和方差采样的初始化策略。实验表明，该方法在多个真实数据集上显著提升了CF模型的性能，同时相比现有LLM推荐方法降低了计算成本。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01814v1",
      "published_date": "2025-03-03 18:41:59 UTC",
      "updated_date": "2025-03-03 18:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T01:59:53.917649"
    },
    {
      "arxiv_id": "2503.01811v1",
      "title": "AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses",
      "title_zh": "AutoAdvExBench：对抗样本防御自主利用的基准测试",
      "authors": [
        "Nicholas Carlini",
        "Javier Rando",
        "Edoardo Debenedetti",
        "Milad Nasr",
        "Florian Tramèr"
      ],
      "abstract": "We introduce AutoAdvExBench, a benchmark to evaluate if large language models\n(LLMs) can autonomously exploit defenses to adversarial examples. Unlike\nexisting security benchmarks that often serve as proxies for real-world tasks,\nbench directly measures LLMs' success on tasks regularly performed by machine\nlearning security experts. This approach offers a significant advantage: if a\nLLM could solve the challenges presented in bench, it would immediately present\npractical utility for adversarial machine learning researchers. We then design\na strong agent that is capable of breaking 75% of CTF-like (\"homework\nexercise\") adversarial example defenses. However, we show that this agent is\nonly able to succeed on 13% of the real-world defenses in our benchmark,\nindicating the large gap between difficulty in attacking \"real\" code, and\nCTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses\nonly succeeds on 54% of CTF-like defenses. We make this benchmark available at\nhttps://github.com/ethz-spylab/AutoAdvExBench.",
      "tldr_zh": "该研究提出了AutoAdvExBench，一个用于评估大语言模型(LLMs)能否自主利用对抗样本防御的基准测试。与现有安全基准不同，该测试直接衡量LLMs在机器学习安全专家日常任务中的表现，具有实际应用价值。研究设计了一个强大的智能体，能够破解75%的CTF式对抗样本防御，但在真实防御中仅成功13%，揭示了攻击“真实”代码与CTF式代码之间的巨大难度差距。相比之下，一个更强的LLM在真实防御中成功率为21%，而在CTF式防御中为54%。该基准已开源。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01811v1",
      "published_date": "2025-03-03 18:39:48 UTC",
      "updated_date": "2025-03-03 18:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:00:32.236020"
    },
    {
      "arxiv_id": "2503.01805v1",
      "title": "Depth-Width tradeoffs in Algorithmic Reasoning of Graph Tasks with Transformers",
      "title_zh": "图任务算法推理中Transformer的深度-宽度权衡关系",
      "authors": [
        "Gilad Yehudai",
        "Clayton Sanford",
        "Maya Bechler-Speicher",
        "Orr Fischer",
        "Ran Gilad-Bachrach",
        "Amir Globerson"
      ],
      "abstract": "Transformers have revolutionized the field of machine learning. In\nparticular, they can be used to solve complex algorithmic problems, including\ngraph-based tasks. In such algorithmic tasks a key question is what is the\nminimal size of a transformer that can implement a task. Recent work has begun\nto explore this problem for graph-based tasks, showing that for sub-linear\nembedding dimension (i.e., model width) logarithmic depth suffices. However, an\nopen question, which we address here, is what happens if width is allowed to\ngrow linearly. Here we analyze this setting, and provide the surprising result\nthat with linear width, constant depth suffices for solving a host of\ngraph-based problems. This suggests that a moderate increase in width can allow\nmuch shallower models, which are advantageous in terms of inference time. For\nother problems, we show that quadratic width is required. Our results\ndemonstrate the complex and intriguing landscape of transformer implementations\nof graph-based algorithms. We support our theoretical results with empirical\nevaluations.",
      "tldr_zh": "该研究探讨了Transformer模型在解决图任务时的深度-宽度权衡问题。研究发现，当模型宽度（embedding dimension）线性增长时，仅需常数深度即可解决多种图任务，这表明适度增加宽度可以显著降低模型深度，从而提升推理效率。然而，对于某些问题，二次方宽度是必要的。研究通过理论分析和实验验证，揭示了Transformer在图算法实现中的复杂性，为模型设计提供了新的见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01805v1",
      "published_date": "2025-03-03 18:33:58 UTC",
      "updated_date": "2025-03-03 18:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:00:25.617893"
    },
    {
      "arxiv_id": "2503.01804v2",
      "title": "$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding",
      "title_zh": "$\\texttt{SEM-CTRL}$：语义控制解码",
      "authors": [
        "Mohammad Albinhassan",
        "Pranava Madhyastha",
        "Alessandra Russo"
      ],
      "abstract": "Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.",
      "tldr_zh": "该研究提出了$\\texttt{SEM-CTRL}$，一种通过语义控制解码来确保大语言模型(LLM)输出语法和语义正确性的统一方法。该方法结合了基于蒙特卡洛树搜索(MCTS)的令牌级解码和基于逻辑的Answer Set Grammars约束，无需微调即可直接应用于现成的LLM。实验表明，$\\texttt{SEM-CTRL}$使小型预训练LLM在语法合成、组合推理和规划等任务中，不仅优于更大的模型和当前最先进的推理模型，还能保证解的正确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01804v2",
      "published_date": "2025-03-03 18:33:46 UTC",
      "updated_date": "2025-03-06 16:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:00:42.194026"
    },
    {
      "arxiv_id": "2503.01792v1",
      "title": "Generating Counterfactual Explanations Under Temporal Constraints",
      "title_zh": "时间约束下的反事实解释生成",
      "authors": [
        "Andrei Buliga",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Marco Montali",
        "Massimiliano Ronzani"
      ],
      "abstract": "Counterfactual explanations are one of the prominent eXplainable Artificial\nIntelligence (XAI) techniques, and suggest changes to input data that could\nalter predictions, leading to more favourable outcomes. Existing counterfactual\nmethods do not readily apply to temporal domains, such as that of process\nmining, where data take the form of traces of activities that must obey to\ntemporal background knowledge expressing which dynamics are possible and which\nnot. Specifically, counterfactuals generated off-the-shelf may violate the\nbackground knowledge, leading to inconsistent explanations. This work tackles\nthis challenge by introducing a novel approach for generating temporally\nconstrained counterfactuals, guaranteed to comply by design with background\nknowledge expressed in Linear Temporal Logic on process traces (LTLp). We do so\nby infusing automata-theoretic techniques for LTLp inside a genetic algorithm\nfor counterfactual generation. The empirical evaluation shows that the\ngenerated counterfactuals are temporally meaningful and more interpretable for\napplications involving temporal dependencies.",
      "tldr_zh": "该研究提出了一种生成符合时间约束的反事实解释(Counterfactual Explanations)的新方法，解决了现有方法在时序领域(如流程挖掘)中可能违反时间背景知识的问题。通过将线性时序逻辑(LTLp)与自动机理论技术融入遗传算法，该方法能够确保生成的反事实解释始终符合预设的时间约束条件。实验表明，该方法生成的解释在涉及时间依赖的应用中更具时序意义和可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01792v1",
      "published_date": "2025-03-03 18:22:48 UTC",
      "updated_date": "2025-03-03 18:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:01:02.197577"
    },
    {
      "arxiv_id": "2503.09613v1",
      "title": "Empowering the Future Workforce: Prioritizing Education for the AI-Accelerated Job Market",
      "title_zh": "赋能未来劳动力：在AI加速的就业市场中优先发展教育",
      "authors": [
        "Lisa Amini",
        "Henry F. Korth",
        "Nita Patel",
        "Evan Peck",
        "Ben Zorn"
      ],
      "abstract": "AI's rapid integration into the workplace demands new approaches to workforce\neducation and training and broader AI literacy across disciplines. Coordinated\naction from government, industry, and educational institutions is necessary to\nensure workers can adapt to accelerating technological change.",
      "tldr_zh": "该论文探讨了人工智能（AI）快速融入职场对劳动力教育和培训提出的新需求，强调了跨学科AI素养的重要性。研究指出，政府、行业和教育机构需要协同行动，以确保劳动者能够适应加速的技术变革。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09613v1",
      "published_date": "2025-03-03 18:15:45 UTC",
      "updated_date": "2025-03-03 18:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:01:17.597273"
    },
    {
      "arxiv_id": "2503.01776v2",
      "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation",
      "title_zh": "超越嵌套：重新审视稀疏编码以实现自适应表示",
      "authors": [
        "Tiansheng Wen",
        "Yifei Wang",
        "Zequn Zeng",
        "Zhong Peng",
        "Yudi Su",
        "Xinyang Liu",
        "Bo Chen",
        "Hongwei Liu",
        "Stefanie Jegelka",
        "Chenyu You"
      ],
      "abstract": "Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep",
      "tldr_zh": "该论文提出了一种基于稀疏编码的新型自适应表征学习方法Contrastive Sparse Representation (CSR)，用于替代现有的Matryoshka Representation Learning (MRL)方法。CSR通过轻量级自动编码和任务感知的对比目标，将预训练嵌入转换为高维稀疏特征空间，实现了更高效的自适应表征。实验表明，CSR在图像、文本和多模态基准测试中不仅显著优于MRL的准确率和检索速度，还将训练时间缩短至MRL所需时间的一小部分，为实际应用中效率与保真度并重的场景提供了更优解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "A novel sparse coding framework designed for learning adaptive\n  representation",
      "pdf_url": "http://arxiv.org/pdf/2503.01776v2",
      "published_date": "2025-03-03 17:59:48 UTC",
      "updated_date": "2025-03-05 17:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:01:53.614535"
    },
    {
      "arxiv_id": "2503.01763v1",
      "title": "Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models",
      "title_zh": "检索模型不擅长工具选择：大型语言模型工具检索的基准测试",
      "authors": [
        "Zhengliang Shi",
        "Yuhan Wang",
        "Lingyong Yan",
        "Pengjie Ren",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Zhaochun Ren"
      ],
      "abstract": "Tool learning aims to augment large language models (LLMs) with diverse\ntools, enabling them to act as agents for solving practical tasks. Due to the\nlimited context length of tool-using LLMs, adopting information retrieval (IR)\nmodels to select useful tools from large toolsets is a critical initial step.\nHowever, the performance of IR models in tool retrieval tasks remains\nunderexplored and unclear. Most tool-use benchmarks simplify this step by\nmanually pre-annotating a small set of relevant tools for each task, which is\nfar from the real-world scenarios. In this paper, we propose ToolRet, a\nheterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,\nand a corpus of 43k tools, collected from existing datasets. We benchmark six\ntypes of models on ToolRet. Surprisingly, even the models with strong\nperformance in conventional IR benchmarks, exhibit poor performance on ToolRet.\nThis low retrieval quality degrades the task pass rate of tool-use LLMs. As a\nfurther step, we contribute a large-scale training dataset with over 200k\ninstances, which substantially optimizes the tool retrieval ability of IR\nmodels.",
      "tldr_zh": "该研究提出了ToolRet，一个包含7.6k多样化检索任务和43k工具语料库的异构工具检索基准，用于评估信息检索(IR)模型在为大语言模型(LLMs)选择工具时的表现。研究发现，即使在传统IR基准上表现优异的模型，在ToolRet上的表现也较差，这显著降低了工具使用LLMs的任务通过率。此外，研究贡献了一个包含200k实例的大规模训练数据集，显著优化了IR模型的工具检索能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01763v1",
      "published_date": "2025-03-03 17:37:16 UTC",
      "updated_date": "2025-03-03 17:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:01:45.650275"
    },
    {
      "arxiv_id": "2503.01758v1",
      "title": "Zero-Trust Artificial Intelligence Model Security Based on Moving Target Defense and Content Disarm and Reconstruction",
      "title_zh": "基于移动目标防御与内容拆解重建的零信任人工智能模型安全",
      "authors": [
        "Daniel Gilkarov",
        "Ran Dubin"
      ],
      "abstract": "This paper examines the challenges in distributing AI models through model\nzoos and file transfer mechanisms. Despite advancements in security measures,\nvulnerabilities persist, necessitating a multi-layered approach to mitigate\nrisks effectively. The physical security of model files is critical, requiring\nstringent access controls and attack prevention solutions. This paper proposes\na novel solution architecture composed of two prevention approaches. The first\nis Content Disarm and Reconstruction (CDR), which focuses on disarming\nserialization attacks that enable attackers to run malicious code as soon as\nthe model is loaded. The second is protecting the model architecture and\nweights from attacks by using Moving Target Defense (MTD), alerting the model\nstructure, and providing verification steps to detect such attacks. The paper\nfocuses on the highly exploitable Pickle and PyTorch file formats. It\ndemonstrates a 100% disarm rate while validated against known AI model\nrepositories and actual malware attacks from the HuggingFace model zoo.",
      "tldr_zh": "本文提出了一种基于零信任原则的AI模型安全架构，结合移动目标防御（MTD）和内容拆解与重建（CDR）技术，有效应对模型分发中的安全风险。CDR技术专注于拆解序列化攻击，防止恶意代码在模型加载时执行；MTD技术则通过动态改变模型结构和验证步骤，保护模型架构和权重免受攻击。实验表明，该方案在针对Pickle和PyTorch文件格式的测试中实现了100%的拆解率，并通过HuggingFace模型库的实际恶意攻击验证了其有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01758v1",
      "published_date": "2025-03-03 17:32:19 UTC",
      "updated_date": "2025-03-03 17:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:01:48.319922"
    },
    {
      "arxiv_id": "2503.01751v1",
      "title": "SAKE: Steering Activations for Knowledge Editing",
      "title_zh": "SAKE：知识编辑的激活导向方法",
      "authors": [
        "Marco Scialanga",
        "Thibault Laugel",
        "Vincent Grari",
        "Marcin Detyniecki"
      ],
      "abstract": "As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.",
      "tldr_zh": "该研究提出了SAKE方法，通过将待编辑的事实建模为分布而非单一提示，利用最优传输(Optimal Transport)技术，在大型语言模型(LLMs)中实现对知识编辑的全局控制。相比现有方法，SAKE能够更好地处理事实的上下文变体和逻辑推理，提高了知识编辑的鲁棒性和泛化能力。实验结果表明，SAKE在知识编辑任务中表现优于现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01751v1",
      "published_date": "2025-03-03 17:20:29 UTC",
      "updated_date": "2025-03-03 17:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:02:00.689530"
    },
    {
      "arxiv_id": "2503.01747v2",
      "title": "Position: Don't use the CLT in LLM evals with fewer than a few hundred datapoints",
      "title_zh": "立场：在少于数百个数据点的大语言模型评估中，不要使用中心极限定理",
      "authors": [
        "Sam Bowyer",
        "Laurence Aitchison",
        "Desi R. Ivanova"
      ],
      "abstract": "Rigorous statistical evaluations of large language models (LLMs), including\nvalid error bars and significance testing, are essential for meaningful and\nreliable performance assessment. Currently, when such statistical measures are\nreported, they typically rely on the Central Limit Theorem (CLT). In this\nposition paper, we argue that while CLT-based methods for uncertainty\nquantification are appropriate when benchmarks consist of thousands of\nexamples, they fail to provide adequate uncertainty estimates for LLM\nevaluations that rely on smaller, highly specialized benchmarks. In these\nsmall-data settings, we demonstrate that CLT-based methods perform very poorly,\nusually dramatically underestimating uncertainty (i.e. producing error bars\nthat are too small). We give recommendations for alternative frequentist and\nBayesian methods that are both easy to implement and more appropriate in these\nincreasingly common scenarios. We provide a simple Python library for these\nBayesian methods at https://github.com/sambowyer/bayes_evals .",
      "tldr_zh": "本论文指出，在大语言模型（LLMs）评估中，当数据点少于数百个时，不应使用中心极限定理（CLT）进行统计分析。作者通过实证分析表明，在数据量较小的场景下，基于CLT的方法会严重低估不确定性，导致误差范围过小。为此，论文推荐使用更合适的频率学派和贝叶斯方法，并提供了一个易于实现的Python库（bayes_evals）来支持这些方法，以提高LLM评估的可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 37 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01747v2",
      "published_date": "2025-03-03 17:15:17 UTC",
      "updated_date": "2025-03-04 11:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:02:03.422119"
    },
    {
      "arxiv_id": "2503.01743v2",
      "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs",
      "title_zh": "Phi-4-Mini 技术报告：通过混合 LoRAs 实现紧凑而强大的多模态语言模型",
      "authors": [
        "Microsoft",
        ":",
        "Abdelrahman Abouelenin",
        "Atabak Ashfaq",
        "Adam Atkinson",
        "Hany Awadalla",
        "Nguyen Bach",
        "Jianmin Bao",
        "Alon Benhaim",
        "Martin Cai",
        "Vishrav Chaudhary",
        "Congcong Chen",
        "Dong Chen",
        "Dongdong Chen",
        "Junkun Chen",
        "Weizhu Chen",
        "Yen-Chun Chen",
        "Yi-ling Chen",
        "Qi Dai",
        "Xiyang Dai",
        "Ruchao Fan",
        "Mei Gao",
        "Min Gao",
        "Amit Garg",
        "Abhishek Goswami",
        "Junheng Hao",
        "Amr Hendy",
        "Yuxuan Hu",
        "Xin Jin",
        "Mahmoud Khademi",
        "Dongwoo Kim",
        "Young Jin Kim",
        "Gina Lee",
        "Jinyu Li",
        "Yunsheng Li",
        "Chen Liang",
        "Xihui Lin",
        "Zeqi Lin",
        "Mengchen Liu",
        "Yang Liu",
        "Gilsinia Lopez",
        "Chong Luo",
        "Piyush Madan",
        "Vadim Mazalov",
        "Arindam Mitra",
        "Ali Mousavi",
        "Anh Nguyen",
        "Jing Pan",
        "Daniel Perez-Becker",
        "Jacob Platin",
        "Thomas Portet",
        "Kai Qiu",
        "Bo Ren",
        "Liliang Ren",
        "Sambuddha Roy",
        "Ning Shang",
        "Yelong Shen",
        "Saksham Singhal",
        "Subhojit Som",
        "Xia Song",
        "Tetyana Sych",
        "Praneetha Vaddamanu",
        "Shuohang Wang",
        "Yiming Wang",
        "Zhenghao Wang",
        "Haibin Wu",
        "Haoran Xu",
        "Weijian Xu",
        "Yifan Yang",
        "Ziyi Yang",
        "Donghan Yu",
        "Ishmam Zabir",
        "Jianwen Zhang",
        "Li Lyna Zhang",
        "Yunan Zhang",
        "Xiren Zhou"
      ],
      "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.",
      "tldr_zh": "该研究提出了Phi-4-Mini和Phi-4-Multimodal，分别是紧凑但高性能的语言模型和多模态模型。Phi-4-Mini是一个38亿参数的语言模型，通过高质量的网络和合成数据训练，在数学和编程任务上显著优于同类开源模型，甚至匹敌两倍规模的模型。其成功得益于精心设计的合成数据配方，并扩展了词汇量至20万token以支持多语言应用。Phi-4-Multimodal则整合了文本、视觉和语音/音频输入，采用LoRA适配器和模态特定路由器的创新方法，支持多种模态组合，并在OpenASR榜单中排名第一。此外，通过进一步训练，Phi-4-Mini在推理能力上达到了与更大模型相当甚至超越的水平。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01743v2",
      "published_date": "2025-03-03 17:05:52 UTC",
      "updated_date": "2025-03-07 09:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:02:16.335195"
    },
    {
      "arxiv_id": "2503.01734v1",
      "title": "Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning",
      "title_zh": "对抗性智能体：基于强化学习的黑盒规避攻击",
      "authors": [
        "Kyle Domico",
        "Jean-Charles Noirot Ferrand",
        "Ryan Sheatsley",
        "Eric Pauley",
        "Josiah Hanna",
        "Patrick McDaniel"
      ],
      "abstract": "Reinforcement learning (RL) offers powerful techniques for solving complex\nsequential decision-making tasks from experience. In this paper, we demonstrate\nhow RL can be applied to adversarial machine learning (AML) to develop a new\nclass of attacks that learn to generate adversarial examples: inputs designed\nto fool machine learning models. Unlike traditional AML methods that craft\nadversarial examples independently, our RL-based approach retains and exploits\npast attack experience to improve future attacks. We formulate adversarial\nexample generation as a Markov Decision Process and evaluate RL's ability to\n(a) learn effective and efficient attack strategies and (b) compete with\nstate-of-the-art AML. On CIFAR-10, our agent increases the success rate of\nadversarial examples by 19.4% and decreases the median number of victim model\nqueries per adversarial example by 53.2% from the start to the end of training.\nIn a head-to-head comparison with a state-of-the-art image attack,\nSquareAttack, our approach enables an adversary to generate adversarial\nexamples with 13.1% more success after 5000 episodes of training. From a\nsecurity perspective, this work demonstrates a powerful new attack vector that\nuses RL to attack ML models efficiently and at scale.",
      "tldr_zh": "本文提出了一种基于强化学习（RL）的新型黑盒对抗攻击方法，通过将对抗样本生成建模为马尔可夫决策过程（MDP），利用RL学习高效的攻击策略。与传统独立生成对抗样本的方法不同，该方法利用过去的攻击经验不断优化攻击效果。实验表明，在CIFAR-10数据集上，该方法的攻击成功率提升了19.4%，同时将每次攻击所需的模型查询次数减少了53.2%。与当前最先进的图像攻击方法SquareAttack相比，经过5000轮训练后，其攻击成功率提高了13.1%。该研究展示了RL在高效、大规模攻击机器学习模型方面的强大潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01734v1",
      "published_date": "2025-03-03 16:54:03 UTC",
      "updated_date": "2025-03-03 16:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:03:14.257245"
    },
    {
      "arxiv_id": "2503.01722v1",
      "title": "Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects",
      "title_zh": "学习用于推断异质同伴效应的暴露映射函数",
      "authors": [
        "Shishir Adhikari",
        "Sourav Medya",
        "Elena Zheleva"
      ],
      "abstract": "In causal inference, interference refers to the phenomenon in which the\nactions of peers in a network can influence an individual's outcome. Peer\neffect refers to the difference in counterfactual outcomes of an individual for\ndifferent levels of peer exposure, the extent to which an individual is exposed\nto the treatments, actions, or behaviors of peers. Estimating peer effects\nrequires deciding how to represent peer exposure. Typically, researchers define\nan exposure mapping function that aggregates peer treatments and outputs peer\nexposure. Most existing approaches for defining exposure mapping functions\nassume peer exposure based on the number or fraction of treated peers. Recent\nstudies have investigated more complex functions of peer exposure which capture\nthat different peers can exert different degrees of influence. However, none of\nthese works have explicitly considered the problem of automatically learning\nthe exposure mapping function. In this work, we focus on learning this function\nfor the purpose of estimating heterogeneous peer effects, where heterogeneity\nrefers to the variation in counterfactual outcomes for the same peer exposure\nbut different individual's contexts. We develop EgoNetGNN, a graph neural\nnetwork (GNN)-based method, to automatically learn the appropriate exposure\nmapping function allowing for complex peer influence mechanisms that, in\naddition to peer treatments, can involve the local neighborhood structure and\nedge attributes. We show that GNN models that use peer exposure based on the\nnumber or fraction of treated peers or learn peer exposure naively face\ndifficulty accounting for such influence mechanisms. Our comprehensive\nevaluation on synthetic and semi-synthetic network data shows that our method\nis more robust to different unknown underlying influence mechanisms when\nestimating heterogeneous peer effects when compared to state-of-the-art\nbaselines.",
      "tldr_zh": "本研究提出了一种基于图神经网络(GNN)的方法EgoNetGNN，用于自动学习网络中个体暴露于同伴影响的映射函数，以估计异质同伴效应。与现有方法不同，EgoNetGNN不仅考虑同伴处理的数量或比例，还结合局部网络结构和边属性，捕捉复杂的同伴影响机制。实验表明，该方法在估计异质同伴效应时，对不同未知影响机制具有更强的鲁棒性，优于现有基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01722v1",
      "published_date": "2025-03-03 16:37:05 UTC",
      "updated_date": "2025-03-03 16:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:02:22.263198"
    },
    {
      "arxiv_id": "2503.01715v2",
      "title": "KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation",
      "title_zh": "KeyFace：基于关键帧插值的长序列表情音频驱动面部动画",
      "authors": [
        "Antoni Bigata",
        "Michał Stypułkowski",
        "Rodrigo Mira",
        "Stella Bounareli",
        "Konstantinos Vougioukas",
        "Zoe Landgraf",
        "Nikita Drobyshev",
        "Maciej Zieba",
        "Stavros Petridis",
        "Maja Pantic"
      ],
      "abstract": "Current audio-driven facial animation methods achieve impressive results for\nshort videos but suffer from error accumulation and identity drift when\nextended to longer durations. Existing methods attempt to mitigate this through\nexternal spatial control, increasing long-term consistency but compromising the\nnaturalness of motion. We propose KeyFace, a novel two-stage diffusion-based\nframework, to address these issues. In the first stage, keyframes are generated\nat a low frame rate, conditioned on audio input and an identity frame, to\ncapture essential facial expressions and movements over extended periods of\ntime. In the second stage, an interpolation model fills in the gaps between\nkeyframes, ensuring smooth transitions and temporal coherence. To further\nenhance realism, we incorporate continuous emotion representations and handle a\nwide range of non-speech vocalizations (NSVs), such as laughter and sighs. We\nalso introduce two new evaluation metrics for assessing lip synchronization and\nNSV generation. Experimental results show that KeyFace outperforms\nstate-of-the-art methods in generating natural, coherent facial animations over\nextended durations, successfully encompassing NSVs and continuous emotions.",
      "tldr_zh": "本文提出KeyFace，一种基于扩散模型的两阶段框架，用于生成长时间序列的音频驱动面部动画。第一阶段以音频输入和身份帧为条件生成低帧率关键帧，捕捉长时间内的面部表情和动作；第二阶段通过插值模型填补关键帧之间的过渡，确保动画的平滑性和时间一致性。该框架还引入连续情感表达，并处理非语音发声（如笑声和叹息），显著提升了动画的自然度和一致性。实验结果表明，KeyFace在长时间动画生成上优于现有方法，尤其是在非语音发声和连续情感表现方面。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01715v2",
      "published_date": "2025-03-03 16:31:55 UTC",
      "updated_date": "2025-03-19 12:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:02:35.430335"
    },
    {
      "arxiv_id": "2503.01714v1",
      "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
      "title_zh": "词形至关重要：LLM 在 Typoglycemia 下的语义重构",
      "authors": [
        "Chenxi Wang",
        "Tianle Gu",
        "Zhongyu Wei",
        "Lang Gao",
        "Zirui Song",
        "Xiuying Chen"
      ],
      "abstract": "Human readers can efficiently comprehend scrambled words, a phenomenon known\nas Typoglycemia, primarily by relying on word form; if word form alone is\ninsufficient, they further utilize contextual cues for interpretation. While\nadvanced large language models (LLMs) exhibit similar abilities, the underlying\nmechanisms remain unclear. To investigate this, we conduct controlled\nexperiments to analyze the roles of word form and contextual information in\nsemantic reconstruction and examine LLM attention patterns. Specifically, we\nfirst propose SemRecScore, a reliable metric to quantify the degree of semantic\nreconstruction, and validate its effectiveness. Using this metric, we study how\nword form and contextual information influence LLMs' semantic reconstruction\nability, identifying word form as the core factor in this process. Furthermore,\nwe analyze how LLMs utilize word form and find that they rely on specialized\nattention heads to extract and process word form information, with this\nmechanism remaining stable across varying levels of word scrambling. This\ndistinction between LLMs' fixed attention patterns primarily focused on word\nform and human readers' adaptive strategy in balancing word form and contextual\ninformation provides insights into enhancing LLM performance by incorporating\nhuman-like, context-aware mechanisms.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在Typoglycemia（乱序单词识别）现象下的语义重建机制。研究提出了SemRecScore指标来量化语义重建程度，发现LLMs主要依赖单词形式进行语义重建，并通过特定的注意力头提取和处理单词形式信息，这一机制在不同程度的单词乱序下保持稳定。与人类读者灵活平衡单词形式和上下文信息的策略不同，LLMs的固定注意力模式主要集中于单词形式，研究结果为通过融入类人、上下文感知机制来提升LLM性能提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 10 figures, submitted to ACL Rolling Review, February 2025\n  cycle, see https://github.com/Aurora-cx/TypoLLM",
      "pdf_url": "http://arxiv.org/pdf/2503.01714v1",
      "published_date": "2025-03-03 16:31:45 UTC",
      "updated_date": "2025-03-03 16:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:03:29.453103"
    },
    {
      "arxiv_id": "2503.01713v1",
      "title": "SAGE: A Framework of Precise Retrieval for RAG",
      "title_zh": "SAGE：面向RAG的精准检索框架",
      "authors": [
        "Jintao Zhang",
        "Guoliang Li",
        "Jinyang Su"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.",
      "tldr_zh": "该研究提出了SAGE框架，旨在解决检索增强生成（RAG）在问答任务中的两个主要问题：语义无关的文本分割和检索上下文的相关性不足。SAGE通过训练语义分割模型将语料库划分为语义完整的片段，并设计动态片段选择算法，基于相关性得分的变化速度筛选最相关的片段。此外，SAGE还引入大语言模型（LLMs）评估检索片段的适量性并调整上下文数量。实验表明，SAGE在问答质量上比基线模型平均提高61.25%，并通过减少噪声上下文，将LLM推理的token成本效率提升49.41%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01713v1",
      "published_date": "2025-03-03 16:25:58 UTC",
      "updated_date": "2025-03-03 16:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:03:48.678049"
    },
    {
      "arxiv_id": "2503.01710v1",
      "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
      "title_zh": "Spark-TTS：一种基于单流解耦语音标记的高效大型语言模型文本转语音模型",
      "authors": [
        "Xinsheng Wang",
        "Mingqi Jiang",
        "Ziyang Ma",
        "Ziyu Zhang",
        "Songxiang Liu",
        "Linqin Li",
        "Zheng Liang",
        "Qixi Zheng",
        "Rui Wang",
        "Xiaoqin Feng",
        "Weizhen Bian",
        "Zhen Ye",
        "Sitong Cheng",
        "Ruibin Yuan",
        "Zhixian Zhao",
        "Xinfa Zhu",
        "Jiahao Pan",
        "Liumeng Xue",
        "Pengcheng Zhu",
        "Yunlin Chen",
        "Zhifei Li",
        "Xie Chen",
        "Lei Xie",
        "Yike Guo",
        "Wei Xue"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have driven significant\nprogress in zero-shot text-to-speech (TTS) synthesis. However, existing\nfoundation models rely on multi-stage processing or complex architectures for\npredicting multiple codebooks, limiting efficiency and integration flexibility.\nTo overcome these challenges, we introduce Spark-TTS, a novel system powered by\nBiCodec, a single-stream speech codec that decomposes speech into two\ncomplementary token types: low-bitrate semantic tokens for linguistic content\nand fixed-length global tokens for speaker attributes. This disentangled\nrepresentation, combined with the Qwen2.5 LLM and a chain-of-thought (CoT)\ngeneration approach, enables both coarse-grained control (e.g., gender,\nspeaking style) and fine-grained adjustments (e.g., precise pitch values,\nspeaking rate). To facilitate research in controllable TTS, we introduce\nVoxBox, a meticulously curated 100,000-hour dataset with comprehensive\nattribute annotations. Extensive experiments demonstrate that Spark-TTS not\nonly achieves state-of-the-art zero-shot voice cloning but also generates\nhighly customizable voices that surpass the limitations of reference-based\nsynthesis. Source code, pre-trained models, and audio samples are available at\nhttps://github.com/SparkAudio/Spark-TTS.",
      "tldr_zh": "该研究提出了Spark-TTS，一种基于大语言模型(LLM)的高效文本转语音(TTS)系统。其创新点在于采用BiCodec语音编解码器，将语音分解为语义token（表征语言内容）和全局token（表征说话人特征）两种解耦表示，结合Qwen2.5 LLM和链式思维(CoT)生成方法，实现了从粗粒度（如性别、说话风格）到细粒度（如精确音高、语速）的语音控制。研究团队还开源了包含10万小时标注数据的VoxBox数据集，实验表明Spark-TTS在零样本语音克隆和可控语音合成方面达到最先进水平。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01710v1",
      "published_date": "2025-03-03 16:23:10 UTC",
      "updated_date": "2025-03-03 16:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:12.827560"
    },
    {
      "arxiv_id": "2503.01702v1",
      "title": "Relating Piecewise Linear Kolmogorov Arnold Networks to ReLU Networks",
      "title_zh": "分段线性Kolmogorov-Arnold网络与ReLU网络的关联研究",
      "authors": [
        "Nandi Schoots",
        "Mattia Jacopo Villani",
        "Niels uit de Bos"
      ],
      "abstract": "Kolmogorov-Arnold Networks are a new family of neural network architectures\nwhich holds promise for overcoming the curse of dimensionality and has\ninterpretability benefits (arXiv:2404.19756). In this paper, we explore the\nconnection between Kolmogorov Arnold Networks (KANs) with piecewise linear\n(univariate real) functions and ReLU networks. We provide completely explicit\nconstructions to convert a piecewise linear KAN into a ReLU network and vice\nversa.",
      "tldr_zh": "本文探讨了分段线性Kolmogorov-Arnold网络（KANs）与ReLU网络之间的关系。研究提供了明确的构造方法，可以将分段线性KAN转换为ReLU网络，反之亦然。这一发现为理解KANs在克服维度诅咒和提升模型可解释性方面的潜力提供了新的视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to AISTATS 2025; 12 pages including bibliography and\n  appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.01702v1",
      "published_date": "2025-03-03 16:15:56 UTC",
      "updated_date": "2025-03-03 16:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:12.331921"
    },
    {
      "arxiv_id": "2503.01700v1",
      "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation",
      "title_zh": "代码即符号规划器：基于基础模型通过符号代码生成的机器人规划",
      "authors": [
        "Yongchao Chen",
        "Yilun Hao",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "abstract": "Recent works have shown great potentials of Large Language Models (LLMs) in\nrobot task and motion planning (TAMP). Current LLM approaches generate text- or\ncode-based reasoning chains with sub-goals and action plans. However, they do\nnot fully leverage LLMs' symbolic computing and code generation capabilities.\nMany robot TAMP tasks involve complex optimization under multiple constraints,\nwhere pure textual reasoning is insufficient. While augmenting LLMs with\npredefined solvers and planners improves performance, it lacks generalization\nacross tasks. Given LLMs' growing coding proficiency, we enhance their TAMP\ncapabilities by steering them to generate code as symbolic planners for\noptimization and constraint verification. Unlike prior work that uses code to\ninterface with robot action modules, we steer LLMs to generate code as solvers,\nplanners, and checkers for TAMP tasks requiring symbolic computing, while still\nleveraging textual reasoning to incorporate common sense. With a multi-round\nguidance and answer evolution framework, the proposed Code-as-Symbolic-Planner\nimproves success rates by average 24.1\\% over best baseline methods across\nseven typical TAMP tasks and three popular LLMs. Code-as-Symbolic-Planner shows\nstrong effectiveness and generalizability across discrete and continuous\nenvironments, 2D/3D simulations and real-world settings, as well as single- and\nmulti-robot tasks with diverse requirements. See our project website\nhttps://yongchao98.github.io/Code-Symbol-Planner/ for prompts, videos, and\ncode.",
      "tldr_zh": "该研究提出Code-as-Symbolic-Planner框架，通过引导大语言模型(LLMs)生成符号化代码来增强机器人任务与运动规划(TAMP)能力。不同于传统仅用代码连接执行模块的方法，该框架让LLMs直接生成用于符号计算、优化和约束验证的求解器代码，同时保留文本推理处理常识的优势。实验表明，该方法在七类TAMP任务中平均成功率比基线提升24.1%，在离散/连续环境、2D/3D仿真及真实场景中均展现强大泛化能力，支持单/多机器人复杂需求。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01700v1",
      "published_date": "2025-03-03 16:13:41 UTC",
      "updated_date": "2025-03-03 16:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:11.193166"
    },
    {
      "arxiv_id": "2503.01676v2",
      "title": "Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control",
      "title_zh": "基于主动推理框架的感知运动学习实现鲁棒横向控制",
      "authors": [
        "Elahe Delavari",
        "John Moore",
        "Junho Hong",
        "Jaerock Kwon"
      ],
      "abstract": "This paper presents a novel Perceptual Motor Learning (PML) framework\nintegrated with Active Inference (AIF) to enhance lateral control in Highly\nAutomated Vehicles (HAVs). PML, inspired by human motor learning, emphasizes\nthe seamless integration of perception and action, enabling efficient\ndecision-making in dynamic environments. Traditional autonomous driving\napproaches--including modular pipelines, imitation learning, and reinforcement\nlearning--struggle with adaptability, generalization, and computational\nefficiency. In contrast, PML with AIF leverages a generative model to minimize\nprediction error (\"surprise\") and actively shape vehicle control based on\nlearned perceptual-motor representations. Our approach unifies deep learning\nwith active inference principles, allowing HAVs to perform lane-keeping\nmaneuvers with minimal data and without extensive retraining across different\nenvironments. Extensive experiments in the CARLA simulator demonstrate that PML\nwith AIF enhances adaptability without increasing computational overhead while\nachieving performance comparable to conventional methods. These findings\nhighlight the potential of PML-driven active inference as a robust alternative\nfor real-world autonomous driving applications.",
      "tldr_zh": "本研究提出了一种结合感知运动学习（PML）和主动推理（AIF）的新框架，用于提升高自动化车辆（HAVs）的横向控制能力。该框架通过生成模型最小化预测误差（“surprise”），并基于学习的感知-运动表示主动调整车辆控制，从而实现高效决策。与传统方法相比，PML与AIF的结合在CARLA模拟器中表现出更强的适应性和计算效率，且无需大量数据或跨环境重新训练。实验结果表明，该框架在保持性能的同时，为现实世界的自动驾驶应用提供了一种鲁棒的替代方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to IROS 2025 and is currently under\n  review. Supersedes arXiv:2407.07684",
      "pdf_url": "http://arxiv.org/pdf/2503.01676v2",
      "published_date": "2025-03-03 15:49:18 UTC",
      "updated_date": "2025-03-05 01:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:12.854788"
    },
    {
      "arxiv_id": "2503.01670v1",
      "title": "Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization",
      "title_zh": "评估大语言模型对混合语境幻觉的评判能力：以摘要任务为视角",
      "authors": [
        "Siya Qi",
        "Rui Cao",
        "Yulan He",
        "Zheng Yuan"
      ],
      "abstract": "With the rapid development of large language models (LLMs), LLM-as-a-judge\nhas emerged as a widely adopted approach for text quality evaluation, including\nhallucination evaluation. While previous studies have focused exclusively on\nsingle-context evaluation (e.g., discourse faithfulness or world factuality),\nreal-world hallucinations typically involve mixed contexts, which remains\ninadequately evaluated. In this study, we use summarization as a representative\ntask to comprehensively evaluate LLMs' capability in detecting mixed-context\nhallucinations, specifically distinguishing between factual and non-factual\nhallucinations. Through extensive experiments across direct generation and\nretrieval-based models of varying scales, our main observations are: (1) LLMs'\nintrinsic knowledge introduces inherent biases in hallucination evaluation; (2)\nThese biases particularly impact the detection of factual hallucinations,\nyielding a significant performance bottleneck; (3) The fundamental challenge\nlies in effective knowledge utilization, balancing between LLMs' intrinsic\nknowledge and external context for accurate mixed-context hallucination\nevaluation.",
      "tldr_zh": "本研究通过摘要任务评估了大语言模型（LLMs）在检测混合上下文幻觉（mixed-context hallucination）中的能力，特别是区分事实与非事实幻觉的表现。实验发现，LLMs 的内在知识会引入评估偏差，尤其在检测事实幻觉时表现显著受限。核心挑战在于如何有效利用知识，平衡 LLMs 的内在知识与外部上下文，以实现准确的混合上下文幻觉评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures for main body",
      "pdf_url": "http://arxiv.org/pdf/2503.01670v1",
      "published_date": "2025-03-03 15:42:57 UTC",
      "updated_date": "2025-03-03 15:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:34.636532"
    },
    {
      "arxiv_id": "2503.01669v1",
      "title": "An Efficient Continual Learning Framework for Multivariate Time Series Prediction Tasks with Application to Vehicle State Estimation",
      "title_zh": "一种高效的多变量时间序列预测任务持续学习框架及其在车辆状态估计中的应用",
      "authors": [
        "Arvin Hosseinzadeh",
        "Ladan Khoshnevisan",
        "Mohammad Pirani",
        "Shojaeddin Chenouri",
        "Amir Khajepour"
      ],
      "abstract": "In continual time series analysis using neural networks, catastrophic\nforgetting (CF) of previously learned models when training on new data domains\nhas always been a significant challenge. This problem is especially challenging\nin vehicle estimation and control, where new information is sequentially\nintroduced to the model. Unfortunately, existing work on continual learning has\nnot sufficiently addressed the adverse effects of catastrophic forgetting in\ntime series analysis, particularly in multivariate output environments. In this\npaper, we present EM-ReSeleCT (Efficient Multivariate Representative Selection\nfor Continual Learning in Time Series Tasks), an enhanced approach designed to\nhandle continual learning in multivariate environments. Our approach\nstrategically selects representative subsets from old and historical data and\nincorporates memory-based continual learning techniques with an improved\noptimization algorithm to adapt the pre-trained model on new information while\npreserving previously acquired information. Additionally, we develop a\nsequence-to-sequence transformer model (autoregressive model) specifically\ndesigned for vehicle state estimation. Moreover, we propose an uncertainty\nquantification framework using conformal prediction to assess the sensitivity\nof the memory size and to showcase the robustness of the proposed method.\nExperimental results from tests on an electric Equinox vehicle highlight the\nsuperiority of our method in continually learning new information while\nretaining prior knowledge, outperforming state-of-the-art continual learning\nmethods. Furthermore, EM-ReSeleCT significantly reduces training time, a\ncritical advantage in continual learning applications.",
      "tldr_zh": "本文提出了一种名为EM-ReSeleCT的高效持续学习框架，专门用于多变量时间序列预测任务，并以车辆状态估计为应用场景。该框架通过策略性地选择历史数据的代表性子集，结合基于记忆的持续学习技术和改进的优化算法，有效缓解了神经网络在持续学习中的灾难性遗忘问题。同时，研究开发了一种序列到序列的Transformer模型，并引入基于保形预测的不确定性量化框架，以评估方法的鲁棒性。实验结果表明，该方法在电动汽车状态估计任务中显著优于现有持续学习方法，同时大幅减少了训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01669v1",
      "published_date": "2025-03-03 15:42:06 UTC",
      "updated_date": "2025-03-03 15:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:35.239197"
    },
    {
      "arxiv_id": "2503.01658v1",
      "title": "CoPL: Collaborative Preference Learning for Personalizing LLMs",
      "title_zh": "CoPL：面向大语言模型个性化的协作偏好学习",
      "authors": [
        "Youngbin Choi",
        "Seunghyuk Cho",
        "Minjong Lee",
        "MoonJeong Park",
        "Yesong Ko",
        "Jungseul Ok",
        "Dongwoo Kim"
      ],
      "abstract": "Personalizing large language models (LLMs) is important for aligning outputs\nwith diverse user preferences, yet existing methods struggle with flexibility\nand generalization. We propose CoPL (Collaborative Preference Learning), a\ngraph-based collaborative filtering framework that models user-response\nrelationships to enhance preference estimation, particularly in sparse\nannotation settings. By integrating a mixture of LoRA experts, CoPL efficiently\nfine-tunes LLMs while dynamically balancing shared and user-specific\npreferences. Additionally, an optimization-free adaptation strategy enables\ngeneralization to unseen users without fine-tuning. Experiments on\nUltraFeedback-P demonstrate that CoPL outperforms existing personalized reward\nmodels, effectively capturing both common and controversial preferences, making\nit a scalable solution for personalized LLM alignment.",
      "tldr_zh": "本研究提出了CoPL（协作偏好学习），一种基于图结构的协同过滤框架，用于个性化大语言模型（LLMs）。CoPL通过建模用户-响应关系，在稀疏标注场景下增强偏好估计，并结合LoRA专家混合机制，动态平衡共享和用户特定偏好。该框架无需优化即可泛化到未见用户，实验表明其在UltraFeedback-P数据集上优于现有方法，能够有效捕捉共同和争议性偏好，为个性化LLM对齐提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "13pages, 4 figures, 6tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01658v1",
      "published_date": "2025-03-03 15:32:02 UTC",
      "updated_date": "2025-03-03 15:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:38.489941"
    },
    {
      "arxiv_id": "2503.01655v1",
      "title": "Enhancing Object Detection Accuracy in Underwater Sonar Images through Deep Learning-based Denoising",
      "title_zh": "通过基于深度学习的去噪技术提升水下声呐图像中的目标检测精度",
      "authors": [
        "Ziyu Wang",
        "Tao Xue",
        "Yanbin Wang",
        "Jingyuan Li",
        "Haibin Zhang",
        "Zhiqiang Xu",
        "Gaofei Xu"
      ],
      "abstract": "Sonar image object detection is crucial for underwater robotics and other\napplications. However, various types of noise in sonar images can affect the\naccuracy of object detection. Denoising, as a critical preprocessing step, aims\nto remove noise while retaining useful information to improve detection\naccuracy. Although deep learning-based denoising algorithms perform well on\noptical images, their application to underwater sonar images remains\nunderexplored. This paper systematically evaluates the effectiveness of several\ndeep learning-based denoising algorithms, originally designed for optical\nimages, in the context of underwater sonar image object detection. We apply\nnine trained denoising models to images from five open-source sonar datasets,\neach processing different types of noise. We then test the denoised images\nusing four object detection algorithms. The results show that different\ndenoising models have varying effects on detection performance. By combining\nthe strengths of multiple denoising models, the detection results can be\noptimized, thus more effectively suppressing noise. Additionally, we adopt a\nmulti-frame denoising technique, using different outputs generated by multiple\ndenoising models as multiple frames of the same scene for further processing to\nenhance detection accuracy. This method, originally designed for optical\nimages, leverages complementary noise-reduction effects. Experimental results\nshow that denoised sonar images improve the performance of object detection\nalgorithms compared to the original sonar images.",
      "tldr_zh": "本研究系统评估了多种基于深度学习的去噪算法在水下声纳图像目标检测中的应用效果。通过将九种去噪模型应用于五个开源声纳数据集，并结合四种目标检测算法进行测试，发现不同去噪模型对检测性能有显著影响。研究提出了一种多帧去噪技术，利用多个去噪模型的输出作为同一场景的多帧图像进行进一步处理，从而优化检测结果。实验表明，去噪后的声纳图像显著提升了目标检测算法的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01655v1",
      "published_date": "2025-03-03 15:30:39 UTC",
      "updated_date": "2025-03-03 15:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:04:44.990712"
    },
    {
      "arxiv_id": "2503.01653v2",
      "title": "Distilled Prompt Learning for Incomplete Multimodal Survival Prediction",
      "title_zh": "蒸馏式提示学习用于不完整多模态生存预测",
      "authors": [
        "Yingxue Xu",
        "Fengtao Zhou",
        "Chenyu Zhao",
        "Yihui Wang",
        "Can Yang",
        "Hao Chen"
      ],
      "abstract": "The integration of multimodal data including pathology images and gene\nprofiles is widely applied in precise survival prediction. Despite recent\nadvances in multimodal survival models, collecting complete modalities for\nmultimodal fusion still poses a significant challenge, hindering their\napplication in clinical settings. Current approaches tackling incomplete\nmodalities often fall short, as they typically compensate for only a limited\npart of the knowledge of missing modalities. To address this issue, we propose\na Distilled Prompt Learning framework (DisPro) to utilize the strong robustness\nof Large Language Models (LLMs) to missing modalities, which employs two-stage\nprompting for compensation of comprehensive information for missing modalities.\nIn the first stage, Unimodal Prompting (UniPro) distills the knowledge\ndistribution of each modality, preparing for supplementing modality-specific\nknowledge of the missing modality in the subsequent stage. In the second stage,\nMultimodal Prompting (MultiPro) leverages available modalities as prompts for\nLLMs to infer the missing modality, which provides modality-common information.\nSimultaneously, the unimodal knowledge acquired in the first stage is injected\ninto multimodal inference to compensate for the modality-specific knowledge of\nthe missing modality. Extensive experiments covering various missing scenarios\ndemonstrated the superiority of the proposed method. The code is available at\nhttps://github.com/Innse/DisPro.",
      "tldr_zh": "该研究提出了一种蒸馏提示学习框架(DisPro)，用于解决多模态生存预测中数据缺失的难题。该方法通过两阶段提示机制：第一阶段(UniPro)提取各模态的知识分布，第二阶段(MultiPro)利用可用模态作为大型语言模型(LLMs)的提示来推断缺失模态，并注入第一阶段获取的特定模态知识。实验表明，该框架在各种数据缺失场景下均优于现有方法，为病理图像和基因图谱等多模态数据的不完整整合提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01653v2",
      "published_date": "2025-03-03 15:28:26 UTC",
      "updated_date": "2025-03-24 09:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:15:13.188214"
    },
    {
      "arxiv_id": "2503.01646v1",
      "title": "OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding",
      "title_zh": "OpenGS-SLAM：基于3D高斯泼溅的开放集稠密语义SLAM，实现对象级场景理解",
      "authors": [
        "Dianyi Yang",
        "Yu Gao",
        "Xihan Wang",
        "Yufeng Yue",
        "Yi Yang",
        "Mengyin Fu"
      ],
      "abstract": "Recent advancements in 3D Gaussian Splatting have significantly improved the\nefficiency and quality of dense semantic SLAM. However, previous methods are\ngenerally constrained by limited-category pre-trained classifiers and implicit\nsemantic representation, which hinder their performance in open-set scenarios\nand restrict 3D object-level scene understanding. To address these issues, we\npropose OpenGS-SLAM, an innovative framework that utilizes 3D Gaussian\nrepresentation to perform dense semantic SLAM in open-set environments. Our\nsystem integrates explicit semantic labels derived from 2D foundational models\ninto the 3D Gaussian framework, facilitating robust 3D object-level scene\nunderstanding. We introduce Gaussian Voting Splatting to enable fast 2D label\nmap rendering and scene updating. Additionally, we propose a Confidence-based\n2D Label Consensus method to ensure consistent labeling across multiple views.\nFurthermore, we employ a Segmentation Counter Pruning strategy to improve the\naccuracy of semantic scene representation. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the effectiveness of our method\nin scene understanding, tracking, and mapping, achieving 10 times faster\nsemantic rendering and 2 times lower storage costs compared to existing\nmethods. Project page: https://young-bit.github.io/opengs-github.github.io/.",
      "tldr_zh": "该研究提出了OpenGS-SLAM，一种基于3D Gaussian Splatting的开集密集语义SLAM框架，旨在提升开放环境下的3D物体级场景理解能力。该框架通过将2D基础模型生成的显式语义标签融入3D Gaussian表示，实现了高效的语义渲染和场景更新。研究引入了Gaussian Voting Splatting加速2D标签图渲染，并提出基于置信度的2D标签一致性方法和分割计数剪枝策略，以提升语义表示的准确性。实验表明，该方法在场景理解、跟踪和建图方面表现出色，语义渲染速度提升10倍，存储成本降低50%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01646v1",
      "published_date": "2025-03-03 15:23:21 UTC",
      "updated_date": "2025-03-03 15:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:05:41.118703"
    },
    {
      "arxiv_id": "2503.01642v1",
      "title": "Graph-Augmented Reasoning: Evolving Step-by-Step Knowledge Graph Retrieval for LLM Reasoning",
      "title_zh": "图增强推理：面向大语言模型推理的渐进式知识图谱检索演化",
      "authors": [
        "Wenjie Wu",
        "Yongcheng Jing",
        "Yingjie Wang",
        "Wenbin Hu",
        "Dacheng Tao"
      ],
      "abstract": "Recent large language model (LLM) reasoning, despite its success, suffers\nfrom limited domain knowledge, susceptibility to hallucinations, and\nconstrained reasoning depth, particularly in small-scale models deployed in\nresource-constrained environments. This paper presents the first investigation\ninto integrating step-wise knowledge graph retrieval with step-wise reasoning\nto address these challenges, introducing a novel paradigm termed as\ngraph-augmented reasoning. Our goal is to enable frozen, small-scale LLMs to\nretrieve and process relevant mathematical knowledge in a step-wise manner,\nenhancing their problem-solving abilities without additional training. To this\nend, we propose KG-RAR, a framework centered on process-oriented knowledge\ngraph construction, a hierarchical retrieval strategy, and a universal\npost-retrieval processing and reward model (PRP-RM) that refines retrieved\ninformation and evaluates each reasoning step. Experiments on the Math500 and\nGSM8K benchmarks across six models demonstrate that KG-RAR yields encouraging\nresults, achieving a 20.73\\% relative improvement with Llama-3B on Math500.",
      "tldr_zh": "该论文提出**Graph-Augmented Reasoning**（图增强推理）这一新范式，通过**分步知识图谱检索**与分步推理相结合来增强LLM的数学问题解决能力。核心贡献是KG-RAR框架，包含面向过程的知识图谱构建、分层检索策略以及统一的后检索处理与奖励模型（PRP-RM），可在不微调模型的情况下显著提升小规模LLM（如Llama-3B）的推理性能。在Math500和GSM8K基准测试中，该方法使3B参数模型的准确率相对提升20.73%，有效缓解了领域知识不足和推理深度受限问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01642v1",
      "published_date": "2025-03-03 15:20:41 UTC",
      "updated_date": "2025-03-03 15:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:05:48.747879"
    },
    {
      "arxiv_id": "2503.01632v1",
      "title": "CoT-VLM4Tar: Chain-of-Thought Guided Vision-Language Models for Traffic Anomaly Resolution",
      "title_zh": "CoT-VLM4Tar：基于链式思维引导的视觉-语言模型用于交通异常处理",
      "authors": [
        "Tianchi Ren",
        "Haibo Hu",
        "Jiacheng Zuo",
        "Xinhong Chen",
        "Jianping Wang",
        "Chun Jason Xue",
        "Jen-Ming Wu",
        "Nan Guan"
      ],
      "abstract": "With the acceleration of urbanization, modern urban traffic systems are\nbecoming increasingly complex, leading to frequent traffic anomalies. These\nanomalies encompass not only common traffic jams but also more challenging\nissues such as phantom traffic jams, intersection deadlocks, and accident\nliability analysis, which severely impact traffic flow, vehicular safety, and\noverall transportation efficiency. Currently, existing solutions primarily rely\non manual intervention by traffic police or artificial intelligence-based\ndetection systems. However, these methods often suffer from response delays and\ninconsistent management due to inadequate resources, while AI detection\nsystems, despite enhancing efficiency to some extent, still struggle to handle\ncomplex traffic anomalies in a real-time and precise manner. To address these\nissues, we propose CoT-VLM4Tar: (Chain of Thought Visual-Language Model for\nTraffic Anomaly Resolution), this innovative approach introduces a new\nchain-of-thought to guide the VLM in analyzing, reasoning, and generating\nsolutions for traffic anomalies with greater reasonable and effective solution,\nand to evaluate the performance and effectiveness of our method, we developed a\nclosed-loop testing framework based on the CARLA simulator. Furthermore, to\nensure seamless integration of the solutions generated by the VLM with the\nCARLA simulator, we implement an itegration module that converts these\nsolutions into executable commands. Our results demonstrate the effectiveness\nof VLM in the resolution of real-time traffic anomalies, providing a\nproof-of-concept for its integration into autonomous traffic management\nsystems.",
      "tldr_zh": "本研究提出了CoT-VLM4Tar，一种基于链式思维推理(Chain-of-Thought)的视觉语言模型(VLM)，用于解决复杂的交通异常问题。该模型通过引入新的链式思维机制，能够实时分析、推理并生成针对交通异常的合理解决方案。研究基于CARLA模拟器构建了闭环测试框架，并通过集成模块将VLM生成的解决方案转化为可执行命令。实验结果表明，该方法在实时交通异常处理中表现出色，为自动驾驶交通管理系统的集成提供了概念验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01632v1",
      "published_date": "2025-03-03 15:07:25 UTC",
      "updated_date": "2025-03-03 15:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:05:30.227606"
    },
    {
      "arxiv_id": "2503.01942v1",
      "title": "Mathematical Foundation of Interpretable Equivariant Surrogate Models",
      "title_zh": "可解释等变替代模型的数学基础",
      "authors": [
        "Jacopo Joy Colombini",
        "Filippo Bonchi",
        "Francesco Giannini",
        "Fosca Giannotti",
        "Roberto Pellungrini",
        "Patrizio Frosini"
      ],
      "abstract": "This paper introduces a rigorous mathematical framework for neural network\nexplainability, and more broadly for the explainability of equivariant\noperators called Group Equivariant Operators (GEOs) based on Group Equivariant\nNon-Expansive Operators (GENEOs) transformations. The central concept involves\nquantifying the distance between GEOs by measuring the non-commutativity of\nspecific diagrams. Additionally, the paper proposes a definition of\ninterpretability of GEOs according to a complexity measure that can be defined\naccording to each user preferences. Moreover, we explore the formal properties\nof this framework and show how it can be applied in classical machine learning\nscenarios, like image classification with convolutional neural networks.",
      "tldr_zh": "本文提出了一个严格的数学框架，用于神经网络的可解释性，特别是针对等变算子（GEOs）的可解释性，基于群等变非扩张算子（GENEOs）的变换。核心思想是通过测量特定图的非交换性来量化GEOs之间的距离，并根据用户偏好的复杂度度量定义GEOs的可解释性。该框架探索了其形式化特性，并展示了如何将其应用于经典机器学习场景，如卷积神经网络的图像分类。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01942v1",
      "published_date": "2025-03-03 15:06:43 UTC",
      "updated_date": "2025-03-03 15:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:06:09.985283"
    },
    {
      "arxiv_id": "2503.01630v1",
      "title": "Machine Learners Should Acknowledge the Legal Implications of Large Language Models as Personal Data",
      "title_zh": "机器学习研究者应承认大语言模型作为个人数据的法律影响",
      "authors": [
        "Henrik Nolte",
        "Michèle Finck",
        "Kristof Meding"
      ],
      "abstract": "Does GPT know you? The answer depends on your level of public recognition;\nhowever, if your information was available on a website, the answer is probably\nyes. All Large Language Models (LLMs) memorize training data to some extent. If\nan LLM training corpus includes personal data, it also memorizes personal data.\nDeveloping an LLM typically involves processing personal data, which falls\ndirectly within the scope of data protection laws. If a person is identified or\nidentifiable, the implications are far-reaching: the AI system is subject to EU\nGeneral Data Protection Regulation requirements even after the training phase\nis concluded. To back our arguments: (1.) We reiterate that LLMs output\ntraining data at inference time, be it verbatim or in generalized form. (2.) We\nshow that some LLMs can thus be considered personal data on their own. This\ntriggers a cascade of data protection implications such as data subject rights,\nincluding rights to access, rectification, or erasure. These rights extend to\nthe information embedded with-in the AI model. (3.) This paper argues that\nmachine learning researchers must acknowledge the legal implications of LLMs as\npersonal data throughout the full ML development lifecycle, from data\ncollection and curation to model provision on, e.g., GitHub or Hugging Face.\n(4.) We propose different ways for the ML research community to deal with these\nlegal implications. Our paper serves as a starting point for improving the\nalignment between data protection law and the technical capabilities of LLMs.\nOur findings underscore the need for more interaction between the legal domain\nand the ML community.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在数据保护法下的法律影响。研究表明，LLMs会在训练过程中记忆个人信息，从而可能被视为个人数据，需遵守欧盟《通用数据保护条例》（GDPR），包括数据主体的访问、更正和删除权利。作者提出，机器学习研究者应在整个开发周期中考虑这些法律影响，并呼吁加强法律与机器学习领域的互动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01630v1",
      "published_date": "2025-03-03 15:05:48 UTC",
      "updated_date": "2025-03-03 15:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:05:59.116030"
    },
    {
      "arxiv_id": "2503.01619v1",
      "title": "Advancing vision-language models in front-end development via data synthesis",
      "title_zh": "通过数据合成提升前端开发中的视觉语言模型",
      "authors": [
        "Tong Ge",
        "Yashu Liu",
        "Jieping Ye",
        "Tianyi Li",
        "Chao Wang"
      ],
      "abstract": "Modern front-end (FE) development, especially when leveraging the unique\nfeatures of frameworks like React and Vue, presents distinctive challenges.\nThese include managing modular architectures, ensuring synchronization between\ndata and visual outputs for declarative rendering, and adapting reusable\ncomponents to various scenarios. Such complexities make it particularly\ndifficult for state-of-the-art large vision-language models (VLMs) to generate\naccurate and functional code directly from design images. To address these\nchallenges, we propose a reflective agentic workflow that synthesizes\nhigh-quality image-text data to capture the diverse characteristics of FE\ndevelopment. This workflow automates the extraction of\nself-contained\\footnote{A \\textbf{self-contained} code snippet is one that\nencapsulates all necessary logic, styling, and dependencies, ensuring it\nfunctions independently without requiring external imports or context.} code\nsnippets from real-world projects, renders the corresponding visual outputs,\nand generates detailed descriptions that link design elements to functional\ncode. To further expand the scope and utility of the synthesis, we introduce\nthree data synthesis strategies: Evolution-based synthesis, which enables\nscalable and diverse dataset expansion; Waterfall-Model-based synthesis, which\ngenerates logically coherent code derived from system requirements; and\nAdditive Development synthesis, which iteratively increases the complexity of\nhuman-authored components. We build a large vision-language model, Flame,\ntrained on the synthesized datasets and demonstrate its effectiveness in\ngenerating React code via the $\\text{pass}@k$ metric. Our results suggest that\na code VLM trained to interpret images before code generation may achieve\nbetter performance.",
      "tldr_zh": "该研究提出了一种通过数据合成提升视觉语言模型(VLMs)在前端开发中应用能力的方法。研究设计了一种反射式代理工作流，自动从真实项目中提取自包含代码片段并生成对应的视觉输出和详细描述，从而合成高质量图像-文本数据。此外，提出了三种数据合成策略：基于进化的合成、基于瀑布模型的合成和增量开发合成，以扩展数据集的范围和实用性。基于这些合成数据训练的视觉语言模型Flame在生成React代码的任务中表现出色，验证了该方法在提升前端开发代码生成性能方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01619v1",
      "published_date": "2025-03-03 14:54:01 UTC",
      "updated_date": "2025-03-03 14:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:06:07.200666"
    },
    {
      "arxiv_id": "2503.01606v1",
      "title": "Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering",
      "title_zh": "超越提示：面向开放域问答的高效嵌入框架",
      "authors": [
        "Zhanghao Hu",
        "Hanqi Yan",
        "Qingling Zhu",
        "Zhenyi Shen",
        "Yulan He",
        "Lin Gui"
      ],
      "abstract": "Large language models have recently pushed open domain question answering\n(ODQA) to new frontiers. However, prevailing retriever-reader pipelines often\ndepend on multiple rounds of prompt level instructions, leading to high\ncomputational overhead, instability, and suboptimal retrieval coverage. In this\npaper, we propose EmbQA, an embedding-level framework that alleviates these\nshortcomings by enhancing both the retriever and the reader. Specifically, we\nrefine query representations via lightweight linear layers under an\nunsupervised contrastive learning objective, thereby reordering retrieved\npassages to highlight those most likely to contain correct answers.\nAdditionally, we introduce an exploratory embedding that broadens the model's\nlatent semantic space to diversify candidate generation and employs an\nentropy-based selection mechanism to choose the most confident answer\nautomatically. Extensive experiments across three open-source LLMs, three\nretrieval methods, and four ODQA benchmarks demonstrate that EmbQA\nsubstantially outperforms recent baselines in both accuracy and efficiency.",
      "tldr_zh": "该研究提出了EmbQA，一种用于开放域问答(ODQA)的高效嵌入框架，旨在解决现有检索-阅读管道中存在的计算开销大、不稳定和检索覆盖率低等问题。EmbQA通过无监督对比学习目标优化查询表示，重新排序检索到的段落以突出最可能包含正确答案的部分，并引入探索性嵌入扩展模型的潜在语义空间，结合基于熵的选择机制自动选择最可信的答案。实验表明，EmbQA在多个开放域问答基准测试中显著提升了准确性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01606v1",
      "published_date": "2025-03-03 14:41:35 UTC",
      "updated_date": "2025-03-03 14:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:06:23.742978"
    },
    {
      "arxiv_id": "2503.01603v1",
      "title": "Triple-Stream Deep Feature Selection with Metaheuristic Optimization and Machine Learning for Multi-Stage Hypertensive Retinopathy Diagnosis",
      "title_zh": "基于元启发式优化与机器学习的三重流深度特征选择用于多阶段高血压性视网膜病变诊断",
      "authors": [
        "Suleyman Burcin Suyun",
        "Mustafa Yurdakul",
        "Sakir Tasdemir",
        "Serkan Bilic"
      ],
      "abstract": "Hypertensive retinopathy (HR) is a severe eye disease that may cause\npermanent vision loss if not diagnosed early. Traditional diagnostic methods\nare time-consuming and subjective, highlighting the need for an automated,\nreliable system. Existing studies often use a single Deep Learning (DL) model,\nstruggling to distinguish HR stages. This study introduces a three-stage\napproach to enhance HR diagnosis accuracy. Initially, 14 CNN models were\ntested, identifying DenseNet169, MobileNet, and ResNet152 as the most\neffective. DenseNet169 achieved 87.73% accuracy, 87.75% precision, 87.73%\nrecall, 87.67% F1-score, and 0.8359 Cohen's Kappa. MobileNet followed with\n86.40% accuracy, 86.60% precision, 86.40% recall, 86.31% F1-score, and 0.8180\nCohen's Kappa. ResNet152 ranked third with 85.87% accuracy, 86.01% precision,\n85.87% recall, 85.83% F1-score, and 0.8188 Cohen's Kappa. In the second stage,\ndeep features from these models were fused and classified using Machine\nLearning (ML) algorithms (SVM, RF, XGBoost). SVM (sigmoid kernel) performed\nbest with 92.00% accuracy, 91.93% precision, 92.00% recall, 91.91% F1-score,\nand 0.8930 Cohen's Kappa. The third stage applied meta-heuristic optimization\n(GA, ABC, PSO, HHO) for feature selection. HHO yielded 94.66% accuracy,\nprecision, and recall, 94.64% F1-score, and 0.9286 Cohen's Kappa. The proposed\napproach surpassed single CNN models and previous studies in HR diagnosis\naccuracy and generalization.",
      "tldr_zh": "该研究提出了一种基于三重流深度特征选择与元启发式优化的多阶段高血压性视网膜病变(HR)诊断方法。首先，通过测试14种CNN模型，筛选出DenseNet169、MobileNet和ResNet152作为最优模型；其次，融合这些模型的深度特征，并利用机器学习算法（如SVM）进行分类，SVM（sigmoid核）表现最佳；最后，采用元启发式优化（如HHO）进行特征选择，显著提升了诊断性能。实验结果表明，该方法在HR诊断准确率（94.66%）和泛化能力上均优于单一CNN模型和现有研究，为自动化HR诊断提供了可靠解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01603v1",
      "published_date": "2025-03-03 14:39:46 UTC",
      "updated_date": "2025-03-03 14:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:06:45.374351"
    },
    {
      "arxiv_id": "2503.01595v1",
      "title": "STAR: Stability-Inducing Weight Perturbation for Continual Learning",
      "title_zh": "STAR：持续学习中的稳定性诱导权重扰动方法",
      "authors": [
        "Masih Eskandar",
        "Tooba Imtiaz",
        "Davin Hill",
        "Zifeng Wang",
        "Jennifer Dy"
      ],
      "abstract": "Humans can naturally learn new and varying tasks in a sequential manner.\nContinual learning is a class of learning algorithms that updates its learned\nmodel as it sees new data (on potentially new tasks) in a sequence. A key\nchallenge in continual learning is that as the model is updated to learn new\ntasks, it becomes susceptible to catastrophic forgetting, where knowledge of\npreviously learned tasks is lost. A popular approach to mitigate forgetting\nduring continual learning is to maintain a small buffer of previously-seen\nsamples and to replay them during training. However, this approach is limited\nby the small buffer size, and while forgetting is reduced, it is still present.\nIn this paper, we propose a novel loss function, STAR, that exploits the\nworst-case parameter perturbation that reduces the KL-divergence of model\npredictions with that of its local parameter neighborhood to promote stability\nand alleviate forgetting. STAR can be combined with almost any existing\nrehearsal-based method as a plug-and-play component. We empirically show that\nSTAR consistently improves the performance of existing methods by up to 15%\nacross varying baselines and achieves superior or competitive accuracy to that\nof state-of-the-art methods aimed at improving rehearsal-based continual\nlearning.",
      "tldr_zh": "本文提出了一种名为STAR的新型损失函数，用于解决持续学习中的灾难性遗忘问题。STAR通过利用最坏情况下的参数扰动，减少模型预测与其局部参数邻域之间的KL散度，从而提升模型稳定性并减轻遗忘。该方法可与现有的基于回放的方法无缝结合，实验表明，STAR在不同基线方法上性能提升高达15%，并达到了与最先进方法相当或更优的精度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01595v1",
      "published_date": "2025-03-03 14:32:03 UTC",
      "updated_date": "2025-03-03 14:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:06:23.048606"
    },
    {
      "arxiv_id": "2503.01592v1",
      "title": "An Efficient Approach to Detecting Lung Nodules Using Swin Transformer",
      "title_zh": "基于Swin Transformer的肺结节高效检测方法",
      "authors": [
        "Saeed Shakuri",
        "Alireza Rezvanian"
      ],
      "abstract": "Lung cancer has the highest rate of cancer-caused deaths, and early-stage\ndiagnosis could increase the survival rate. Lung nodules are common indicators\nof lung cancer, making their detection crucial. Various lung nodule detection\nmodels exist, but many lack efficiency. Hence, we propose a more efficient\napproach by leveraging 2D CT slices, reducing computational load and complexity\nin training and inference. We employ the tiny version of Swin Transformer to\nbenefit from Vision Transformers (ViT) while maintaining low computational\ncost. A Feature Pyramid Network is added to enhance detection, particularly for\nsmall nodules. Additionally, Transfer Learning is used to accelerate training.\nOur experimental results show that the proposed model outperforms\nstate-of-the-art methods, achieving higher mAP and mAR for small nodules by\n1.3% and 1.6%, respectively. Overall, our model achieves the highest mAP of\n94.7% and mAR of 94.9%.",
      "tldr_zh": "本研究提出了一种基于Swin Transformer的高效肺结节检测方法，旨在提高肺癌早期诊断的准确性。通过使用2D CT切片降低计算复杂度，并采用Swin Transformer的轻量版本结合特征金字塔网络(FPN)，显著提升了小结节的检测性能。实验结果表明，该模型在mAP和mAR指标上均优于现有方法，特别是在小结节的检测上分别提高了1.3%和1.6%，整体mAP和mAR分别达到了94.7%和94.9%。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "19th Iranian Conference on Intelligent Systems (ICIS), IEEE, 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01592v1",
      "published_date": "2025-03-03 14:30:14 UTC",
      "updated_date": "2025-03-03 14:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:15:45.504961"
    },
    {
      "arxiv_id": "2503.01586v1",
      "title": "EliteKV: Scalable KV Cache Compression via RoPE Frequency Selection and Joint Low-Rank Projection",
      "title_zh": "EliteKV：通过RoPE频率选择与联合低秩投影实现可扩展的键值缓存压缩",
      "authors": [
        "Yuhao Zhou",
        "Sirui Song",
        "Boyang Liu",
        "Zhiheng Xi",
        "Senjie Jin",
        "Xiaoran Fan",
        "Zhihao Zhang",
        "Wei Li",
        "Xuanjing Huang"
      ],
      "abstract": "Rotary Position Embedding (RoPE) enables each attention head to capture\nmulti-frequency information along the sequence dimension and is widely applied\nin foundation models. However, the nonlinearity introduced by RoPE complicates\noptimization of the key state in the Key-Value (KV) cache for RoPE-based\nattention. Existing KV cache compression methods typically store key state\nbefore rotation and apply the transformation during decoding, introducing\nadditional computational overhead. This paper introduces EliteKV, a flexible\nmodification framework for RoPE-based models supporting variable KV cache\ncompression ratios. EliteKV first identifies the intrinsic frequency preference\nof each head using RoPElite, selectively restoring linearity to certain\ndimensions of key within attention computation. Building on this, joint\nlow-rank compression of key and value enables partial cache sharing.\nExperimental results show that with minimal uptraining on only $0.6\\%$ of the\noriginal training data, RoPE-based models achieve a $75\\%$ reduction in KV\ncache size while preserving performance within a negligible margin.\nFurthermore, EliteKV consistently performs well across models of different\nscales within the same family.",
      "tldr_zh": "该研究提出了EliteKV，一种基于旋转位置嵌入(RoPE)的可扩展键值(KV)缓存压缩框架。该方法通过RoPElite识别每个注意力头的固有频率偏好，在注意力计算中部分恢复键的线性特性，并结合键和值的联合低秩压缩实现缓存共享。实验表明，仅使用原始训练数据的0.6%进行微调，EliteKV就能在保持性能几乎不变的前提下，将KV缓存大小减少75%，且在不同规模模型上表现一致。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01586v1",
      "published_date": "2025-03-03 14:26:51 UTC",
      "updated_date": "2025-03-03 14:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:15:37.658847"
    },
    {
      "arxiv_id": "2503.01584v1",
      "title": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models",
      "title_zh": "SENSEI：基于基础模型引导的语义探索学习通用世界模型",
      "authors": [
        "Cansu Sancaktar",
        "Christian Gumbsch",
        "Andrii Zadaianchuk",
        "Pavel Kolev",
        "Georg Martius"
      ],
      "abstract": "Exploration is a cornerstone of reinforcement learning (RL). Intrinsic\nmotivation attempts to decouple exploration from external, task-based rewards.\nHowever, established approaches to intrinsic motivation that follow general\nprinciples such as information gain, often only uncover low-level interactions.\nIn contrast, children's play suggests that they engage in meaningful high-level\nbehavior by imitating or interacting with their caregivers. Recent work has\nfocused on using foundation models to inject these semantic biases into\nexploration. However, these methods often rely on unrealistic assumptions, such\nas language-embedded environments or access to high-level actions. We propose\nSEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL\nagents with an intrinsic motivation for semantically meaningful behavior.\nSENSEI distills a reward signal of interestingness from Vision Language Model\n(VLM) annotations, enabling an agent to predict these rewards through a world\nmodel. Using model-based RL, SENSEI trains an exploration policy that jointly\nmaximizes semantic rewards and uncertainty. We show that in both robotic and\nvideo game-like simulations SENSEI discovers a variety of meaningful behaviors\nfrom image observations and low-level actions. SENSEI provides a general tool\nfor learning from foundation model feedback, a crucial research direction, as\nVLMs become more powerful.",
      "tldr_zh": "该研究提出了SENSEI框架，通过结合视觉语言模型（VLM）和基于模型的强化学习（RL），为智能体赋予语义驱动的探索能力。SENSEI从VLM的注释中提取“兴趣度”奖励信号，并通过世界模型预测这些奖励，使智能体能够在图像观测和低层动作中发现多样化的有意义行为。实验表明，SENSEI在机器人和视频游戏模拟中均能有效实现语义探索，为利用基础模型反馈进行学习提供了通用工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, under review. Project webpage at\n  https://sites.google.com/view/sensei-paper",
      "pdf_url": "http://arxiv.org/pdf/2503.01584v1",
      "published_date": "2025-03-03 14:26:15 UTC",
      "updated_date": "2025-03-03 14:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:15:49.229361"
    },
    {
      "arxiv_id": "2503.01580v1",
      "title": "A Selective Learning Method for Temporal Graph Continual Learning",
      "title_zh": "时序图持续学习中的选择性学习方法",
      "authors": [
        "Hanmo Liu",
        "Shimin Di",
        "Haoyang Li",
        "Xun Jian",
        "Yue Wang",
        "Lei Chen"
      ],
      "abstract": "Node classification is a key task in temporal graph learning (TGL). Real-life\ntemporal graphs often introduce new node classes over time, but existing TGL\nmethods assume a fixed set of classes. This assumption brings limitations, as\nupdating models with full data is costly, while focusing only on new classes\nresults in forgetting old ones. Graph continual learning (GCL) methods mitigate\nforgetting using old-class subsets but fail to account for their evolution. We\ndefine this novel problem as temporal graph continual learning (TGCL), which\nfocuses on efficiently maintaining up-to-date knowledge of old classes. To\ntackle TGCL, we propose a selective learning framework that substitutes the\nold-class data with its subsets, Learning Towards the Future (LTF). We derive\nan upper bound on the error caused by such replacement and transform it into\nobjectives for selecting and learning subsets that minimize classification\nerror while preserving the distribution of the full old-class data. Experiments\non three real-world datasets validate the effectiveness of LTF on TGCL.",
      "tldr_zh": "该研究提出了一种面向时序图持续学习(TGCL)的选择性学习框架LTF，旨在解决时序图中节点分类任务中新类别不断引入而旧类别知识遗忘的问题。LTF通过用旧类别的子集替代完整数据，并推导出替换误差的上界，将其转化为优化目标，以最小化分类误差并保持旧类别数据的分布。实验表明，LTF在三个真实世界数据集上有效提升了TGCL的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01580v1",
      "published_date": "2025-03-03 14:22:20 UTC",
      "updated_date": "2025-03-03 14:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:15:49.476685"
    },
    {
      "arxiv_id": "2503.01941v1",
      "title": "Task Scheduling & Forgetting in Multi-Task Reinforcement Learning",
      "title_zh": "多任务强化学习中的任务调度与遗忘",
      "authors": [
        "Marc Speckmann",
        "Theresa Eimer"
      ],
      "abstract": "Reinforcement learning (RL) agents can forget tasks they have previously been\ntrained on. There is a rich body of work on such forgetting effects in humans.\nTherefore we look for commonalities in the forgetting behavior of humans and RL\nagents across tasks and test the viability of forgetting prevention measures\nfrom learning theory in RL. We find that in many cases, RL agents exhibit\nforgetting curves similar to those of humans. Methods like Leitner or SuperMemo\nhave been shown to be effective at counteracting human forgetting, but we\ndemonstrate they do not transfer as well to RL. We identify a likely cause:\nasymmetrical learning and retention patterns between tasks that cannot be\ncaptured by retention-based or performance-based curriculum strategies.",
      "tldr_zh": "该研究探讨了多任务强化学习(RL)中的任务调度与遗忘现象，发现RL智能体会像人类一样表现出类似的遗忘曲线。研究测试了Leitner和SuperMemo等人类遗忘预防方法在RL中的适用性，发现这些方法效果不佳。研究指出关键原因在于任务间存在不对称的学习和保持模式，这无法被基于记忆保持或性能的课程策略所捕捉。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at RLDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01941v1",
      "published_date": "2025-03-03 14:12:52 UTC",
      "updated_date": "2025-03-03 14:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:05.805033"
    },
    {
      "arxiv_id": "2503.01557v1",
      "title": "MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic Network",
      "title_zh": "MoCFL：面向高度动态网络的移动集群联邦学习框架",
      "authors": [
        "Kai Fang",
        "Jiangtao Deng",
        "Chengzu Dong",
        "Usman Naseem",
        "Tongcun Liu",
        "Hailin Feng",
        "Wei Wang"
      ],
      "abstract": "Frequent fluctuations of client nodes in highly dynamic mobile clusters can\nlead to significant changes in feature space distribution and data drift,\nposing substantial challenges to the robustness of existing federated learning\n(FL) strategies. To address these issues, we proposed a mobile cluster\nfederated learning framework (MoCFL). MoCFL enhances feature aggregation by\nintroducing an affinity matrix that quantifies the similarity between local\nfeature extractors from different clients, addressing dynamic data distribution\nchanges caused by frequent client churn and topology changes. Additionally,\nMoCFL integrates historical and current feature information when training the\nglobal classifier, effectively mitigating the catastrophic forgetting problem\nfrequently encountered in mobile scenarios. This synergistic combination\nensures that MoCFL maintains high performance and stability in dynamically\nchanging mobile environments. Experimental results on the UNSW-NB15 dataset\nshow that MoCFL excels in dynamic environments, demonstrating superior\nrobustness and accuracy while maintaining reasonable training costs.",
      "tldr_zh": "本研究提出移动集群联邦学习框架MoCFL，针对高度动态网络中客户端节点频繁波动导致的特征空间分布变化和数据漂移问题。该框架通过引入量化客户端间本地特征提取器相似性的亲和矩阵(affinity matrix)，有效处理因客户端频繁变动引发的动态数据分布变化，并整合历史与当前特征信息来缓解移动场景中的灾难性遗忘问题。实验表明，MoCFL在UNSW-NB15数据集上展现出优异的鲁棒性和准确性，同时保持合理的训练成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2503.01557v1",
      "published_date": "2025-03-03 13:59:47 UTC",
      "updated_date": "2025-03-03 13:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:14.612640"
    },
    {
      "arxiv_id": "2503.01556v1",
      "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection",
      "title_zh": "面向信用卡欺诈检测的高效高阶图表示学习",
      "authors": [
        "Yao Zou",
        "Dawei Cheng"
      ],
      "abstract": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals.",
      "tldr_zh": "本研究提出了一种新型高阶图表示学习模型（HOGRL），用于解决信用卡欺诈检测中欺诈者通过多层间接交易伪装行为的难题。HOGRL通过构建高阶交易图并学习每一阶的纯表示，避免了多层聚合过程中引入过多噪声，从而识别欺诈者的多跳间接交易。此外，模型引入专家混合注意力机制，自动确定不同阶表示的重要性，优化欺诈检测性能。实验结果表明，HOGRL在开源和真实数据集上均显著优于现有欺诈检测基线模型，有效应对高阶欺诈伪装问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 91B06",
        "I.2.6; H.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures, accepted at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01556v1",
      "published_date": "2025-03-03 13:59:46 UTC",
      "updated_date": "2025-03-03 13:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:41.386128"
    },
    {
      "arxiv_id": "2503.01544v1",
      "title": "Compositional Reasoning with Transformers, RNNs, and Chain of Thought",
      "title_zh": "基于Transformer、RNN与链式思维的组合推理",
      "authors": [
        "Gilad Yehudai",
        "Noah Amsel",
        "Joan Bruna"
      ],
      "abstract": "We study and compare the expressive power of transformers, RNNs, and\ntransformers with chain of thought tokens on a simple and natural class of\nproblems we term Compositional Reasoning Questions (CRQ). This family captures\nproblems like evaluating Boolean formulas and multi-step word problems.\nAssuming standard hardness assumptions from circuit complexity and\ncommunication complexity, we prove that none of these three architectures is\ncapable of solving CRQs unless some hyperparameter (depth, embedding dimension,\nand number of chain of thought tokens, respectively) grows with the size of the\ninput. We also provide a construction for each architecture that solves CRQs.\nFor transformers, our construction uses depth that is logarithmic in the\nproblem size. For RNNs, logarithmic embedding dimension is necessary and\nsufficient, so long as the inputs are provided in a certain order. (Otherwise,\na linear dimension is necessary). For transformers with chain of thought, our\nconstruction uses $n$ CoT tokens. These results show that, while CRQs are\ninherently hard, there are several different ways for language models to\novercome this hardness. Even for a single class of problems, each architecture\nhas strengths and weaknesses, and none is strictly better than the others.",
      "tldr_zh": "本研究探讨了Transformer、RNN以及结合链式思维（Chain of Thought, CoT）的Transformer在解决组合推理问题（Compositional Reasoning Questions, CRQ）上的表达能力。基于电路复杂性和通信复杂性的假设，研究证明这些模型在特定超参数（如深度、嵌入维度或CoT token数量）随输入规模增长时才能解决CRQ问题。研究还提出了每种模型的构造方案：Transformer需要深度与问题规模成对数关系，RNN在特定输入顺序下需要对数嵌入维度（否则需线性维度），而结合CoT的Transformer需要与输入规模线性相关的CoT token。结果表明，尽管CRQ问题具有固有难度，但不同模型各有优劣，没有一种模型在所有情况下表现最优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01544v1",
      "published_date": "2025-03-03 13:52:45 UTC",
      "updated_date": "2025-03-03 13:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:35.308576"
    },
    {
      "arxiv_id": "2503.01542v1",
      "title": "Revisiting Large Language Model Pruning using Neuron Semantic Attribution",
      "title_zh": "重审基于神经元语义归因的大语言模型剪枝方法",
      "authors": [
        "Yizhuo Ding",
        "Xinwei Sun",
        "Yanwei Fu",
        "Guosheng Hu"
      ],
      "abstract": "Model pruning technique is vital for accelerating large language models by\nreducing their size and computational requirements. However, the\ngeneralizability of existing pruning methods across diverse datasets and tasks\nremains unclear. Thus, we conduct extensive evaluations on 24 datasets and 4\ntasks using popular pruning methods. Based on these evaluations, we find and\nthen investigate that calibration set greatly affect the performance of pruning\nmethods. In addition, we surprisingly find a significant performance drop of\nexisting pruning methods in sentiment classification tasks. To understand the\nlink between performance drop and pruned neurons, we propose Neuron Semantic\nAttribution, which learns to associate each neuron with specific semantics.\nThis method first makes the unpruned neurons of LLMs explainable.",
      "tldr_zh": "本研究重新审视了基于神经元语义归因(Neuron Semantic Attribution)的大语言模型剪枝技术，发现现有剪枝方法在跨数据集和任务上的泛化性存在局限。通过24个数据集和4项任务的广泛评估，研究发现校准集对剪枝性能影响显著，并揭示了现有方法在情感分类任务中的性能显著下降。为此，作者提出神经元语义归因方法，将每个神经元与特定语义关联，首次实现了大语言模型中未剪枝神经元的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01542v1",
      "published_date": "2025-03-03 13:52:17 UTC",
      "updated_date": "2025-03-03 13:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:51.904005"
    },
    {
      "arxiv_id": "2503.01539v1",
      "title": "Pragmatic Inference Chain (PIC) Improving LLMs' Reasoning of Authentic Implicit Toxic Language",
      "title_zh": "实用推理链（PIC）：提升大语言模型对真实隐含毒性语言的推理能力",
      "authors": [
        "Xi Chen",
        "Shuo Wang"
      ],
      "abstract": "The rapid development of large language models (LLMs) gives rise to ethical\nconcerns about their performance, while opening new avenues for developing\ntoxic language detection techniques. However, LLMs' unethical output and their\ncapability of detecting toxicity have primarily been tested on language data\nthat do not demand complex meaning inference, such as the biased associations\nof 'he' with programmer and 'she' with household. Nowadays toxic language\nadopts a much more creative range of implicit forms, thanks to advanced\ncensorship. In this study, we collect authentic toxic interactions that evade\nonline censorship and that are verified by human annotators as inference\nintensive. To evaluate and improve LLMs' reasoning of the authentic implicit\ntoxic language, we propose a new prompting method, Pragmatic Inference Chain\n(PIC), drawn on interdisciplinary findings from cognitive science and\nlinguistics. The PIC prompting significantly improves the success rate of\nGPT-4o, Llama-3.1-70B-Instruct, and DeepSeek-v2.5 in identifying implicit toxic\nlanguage, compared to both direct prompting and Chain-of-Thought. In addition,\nit also facilitates the models to produce more explicit and coherent reasoning\nprocesses, hence can potentially be generalized to other inference-intensive\ntasks, e.g., understanding humour and metaphors.",
      "tldr_zh": "该研究提出了一种新的提示方法——实用推理链(Pragmatic Inference Chain, PIC)，旨在提升大语言模型(LLMs)对真实隐含毒性语言的推理能力。基于认知科学和语言学的跨学科发现，PIC显著提高了GPT-4o、Llama-3.1-70B-Instruct和DeepSeek-v2.5在识别隐含毒性语言上的成功率，优于直接提示和链式思维(Chain-of-Thought)方法。此外，PIC还能帮助模型生成更明确和连贯的推理过程，可推广至其他推理密集型任务，如理解幽默和隐喻。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01539v1",
      "published_date": "2025-03-03 13:51:05 UTC",
      "updated_date": "2025-03-03 13:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:16:44.120313"
    },
    {
      "arxiv_id": "2503.01536v1",
      "title": "Entailment vs. Verification for Partial-assignment Satisfiability and Enumeration",
      "title_zh": "部分赋值可满足性与枚举中的蕴涵与验证对比",
      "authors": [
        "Roberto Sebastiani"
      ],
      "abstract": "Many procedures for SAT-related problems, in particular for those requiring\nthe complete enumeration of satisfying truth assignments, rely their efficiency\nand effectiveness on the detection of (possibly small) partial assignments\nsatisfying an input formula. Surprisingly, there seems to be no unique\nuniversally-agreed definition of formula satisfaction by a partial assignment\nin the literature. In this paper we analyze in deep the issue of satisfaction\nby partial assignments, raising a flag about some ambiguities and subtleties of\nthis concept, and investigating their practical consequences. We identify two\nalternative notions that are implicitly used in the literature, namely\nverification and entailment, which coincide if applied to CNF formulas but\ndiffer and present complementary properties if applied to non-CNF or to\nexistentially-quantified formulas. We show that, although the former is easier\nto check and as such is implicitly used by most current search procedures, the\nlatter has better theoretical properties, and can improve the efficiency and\neffectiveness of enumeration procedures.",
      "tldr_zh": "该论文深入分析了部分赋值(partial assignment)在满足布尔公式(SAT)问题中的定义模糊性及其实际影响，并提出了两种替代概念：验证(verification)和蕴涵(entailment)。研究发现，这两种概念在应用于CNF公式时一致，但在非CNF或存在量词公式中表现出不同的互补特性。尽管验证更容易检查并被大多数搜索算法隐式使用，但蕴涵具有更好的理论性质，能够提高枚举算法的效率和有效性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01536v1",
      "published_date": "2025-03-03 13:49:11 UTC",
      "updated_date": "2025-03-03 13:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:09.387507"
    },
    {
      "arxiv_id": "2503.01508v2",
      "title": "Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty",
      "title_zh": "赋能AI科学家识别创新：一种评估新颖性的领域无关算法",
      "authors": [
        "Yao Wang",
        "Mingxuan Cui",
        "Arthur Jiang"
      ],
      "abstract": "In the pursuit of Artificial General Intelligence (AGI), automating the\ngeneration and evaluation of novel research ideas is a key challenge in\nAI-driven scientific discovery. This paper presents Relative Neighbor Density\n(RND), a domain-agnostic algorithm for novelty assessment in research ideas\nthat overcomes the limitations of existing approaches by comparing an idea's\nlocal density with its adjacent neighbors' densities. We first developed a\nscalable methodology to create test set without expert labeling, addressing a\nfundamental challenge in novelty assessment. Using these test sets, we\ndemonstrate that our RND algorithm achieves state-of-the-art (SOTA) performance\nin computer science (AUROC=0.820) and biomedical research (AUROC=0.765)\ndomains. Most significantly, while SOTA models like Sonnet-3.7 and existing\nmetrics show domain-specific performance degradation, RND maintains consistent\naccuracies across domains by its domain-invariant property, outperforming all\nbenchmarks by a substantial margin (0.795 v.s. 0.597) on cross-domain\nevaluation. These results validate RND as a generalizable solution for\nautomated novelty assessment in scientific research.",
      "tldr_zh": "本文提出了一种领域无关的算法——相对邻居密度（RND），用于评估研究想法的创新性。该算法通过比较想法与其相邻邻居的局部密度来克服现有方法的局限性，无需专家标注即可创建测试集。实验表明，RND在计算机科学（AUROC=0.820）和生物医学研究（AUROC=0.765）领域达到了最先进的性能，并在跨领域评估中显著优于其他基准模型（0.795 vs. 0.597），展示了其在科学研究中自动化创新性评估的通用性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01508v2",
      "published_date": "2025-03-03 13:22:39 UTC",
      "updated_date": "2025-03-10 06:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:23.556806"
    },
    {
      "arxiv_id": "2503.01507v2",
      "title": "Compare different SG-Schemes based on large least square problems",
      "title_zh": "基于大规模最小二乘问题比较不同随机梯度方案",
      "authors": [
        "Ramkrishna Acharya"
      ],
      "abstract": "This study reviews popular stochastic gradient-based schemes based on large\nleast-square problems. These schemes, often called optimizers in machine\nlearning, play a crucial role in finding better model parameters. Hence, this\nstudy focuses on viewing such optimizers with different hyper-parameters and\nanalyzing them based on least square problems. Codes that produced results in\nthis work are available on\nhttps://github.com/q-viper/gradients-based-methods-on-large-least-square.",
      "tldr_zh": "本研究回顾了基于大规模最小二乘问题的几种流行随机梯度优化方案（SG-Schemes），这些优化器在机器学习中用于寻找更好的模型参数。研究通过不同超参数配置，分析了这些优化器在最小二乘问题上的表现，并提供了相关代码实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01507v2",
      "published_date": "2025-03-03 13:22:37 UTC",
      "updated_date": "2025-03-04 08:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:23.284320"
    },
    {
      "arxiv_id": "2503.01505v1",
      "title": "Lossy Neural Compression for Geospatial Analytics: A Review",
      "title_zh": "面向地理空间分析的有损神经压缩技术综述",
      "authors": [
        "Carlos Gomes",
        "Isabelle Wittmann",
        "Damien Robert",
        "Johannes Jakubik",
        "Tim Reichelt",
        "Michele Martone",
        "Stefano Maurogiovanni",
        "Rikard Vinge",
        "Jonas Hurst",
        "Erik Scheurer",
        "Rocco Sedona",
        "Thomas Brunschwiler",
        "Stefan Kesselheim",
        "Matej Batic",
        "Philip Stier",
        "Jan Dirk Wegner",
        "Gabriele Cavallaro",
        "Edzer Pebesma",
        "Michael Marszalek",
        "Miguel A Belenguer-Plomer",
        "Kennedy Adriko",
        "Paolo Fraccaro",
        "Romeo Kienzler",
        "Rania Briq",
        "Sabrina Benassou",
        "Michele Lazzarini",
        "Conrad M Albrecht"
      ],
      "abstract": "Over the past decades, there has been an explosion in the amount of available\nEarth Observation (EO) data. The unprecedented coverage of the Earth's surface\nand atmosphere by satellite imagery has resulted in large volumes of data that\nmust be transmitted to ground stations, stored in data centers, and distributed\nto end users. Modern Earth System Models (ESMs) face similar challenges,\noperating at high spatial and temporal resolutions, producing petabytes of data\nper simulated day. Data compression has gained relevance over the past decade,\nwith neural compression (NC) emerging from deep learning and information\ntheory, making EO data and ESM outputs ideal candidates due to their abundance\nof unlabeled data. In this review, we outline recent developments in NC applied\nto geospatial data. We introduce the fundamental concepts of NC including\nseminal works in its traditional applications to image and video compression\ndomains with focus on lossy compression. We discuss the unique characteristics\nof EO and ESM data, contrasting them with \"natural images\", and explain the\nadditional challenges and opportunities they present. Moreover, we review\ncurrent applications of NC across various EO modalities and explore the limited\nefforts in ESM compression to date. The advent of self-supervised learning\n(SSL) and foundation models (FM) has advanced methods to efficiently distill\nrepresentations from vast unlabeled data. We connect these developments to NC\nfor EO, highlighting the similarities between the two fields and elaborate on\nthe potential of transferring compressed feature representations for\nmachine--to--machine communication. Based on insights drawn from this review,\nwe devise future directions relevant to applications in EO and ESM.",
      "tldr_zh": "本文综述了神经压缩（Neural Compression, NC）技术在地球观测（EO）和地球系统模型（ESM）数据中的应用。文章介绍了NC的基本概念及其在图像和视频压缩中的传统应用，重点探讨了有损压缩技术。针对EO和ESM数据的独特特征，文章分析了其与“自然图像”的区别，并指出了相关挑战与机遇。此外，文章还回顾了NC在不同EO模态中的当前应用，并探讨了其在ESM压缩中的有限尝试。结合自监督学习（SSL）和基础模型（FM）的发展，文章展望了NC在EO领域的潜力，特别是压缩特征表示在机器间通信中的应用前景，并为未来研究方向提供了建议。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "physics.geo-ph"
      ],
      "primary_category": "eess.SP",
      "comment": "self-consistent review paper",
      "pdf_url": "http://arxiv.org/pdf/2503.01505v1",
      "published_date": "2025-03-03 13:19:43 UTC",
      "updated_date": "2025-03-03 13:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:57.904018"
    },
    {
      "arxiv_id": "2503.02905v1",
      "title": "Machine Learning Applications to Diffuse Reflectance Spectroscopy in Optical Diagnosis; A Systematic Review",
      "title_zh": "机器学习在光学诊断中漫反射光谱应用的系统综述",
      "authors": [
        "Nicola Rossberg",
        "Celina L. Li",
        "Simone Innocente",
        "Stefan Andersson-Engels",
        "Katarzyna Komolibus",
        "Barry O'Sullivan",
        "Andrea Visentin"
      ],
      "abstract": "Diffuse Reflectance Spectroscopy has demonstrated a strong aptitude for\nidentifying and differentiating biological tissues. However, the broadband and\nsmooth nature of these signals require algorithmic processing, as they are\noften difficult for the human eye to distinguish. The implementation of machine\nlearning models for this task has demonstrated high levels of diagnostic\naccuracies and led to a wide range of proposed methodologies for applications\nin various illnesses and conditions. In this systematic review, we summarise\nthe state of the art of these applications, highlight current gaps in research\nand identify future directions. This review was conducted in accordance with\nthe PRISMA guidelines. 77 studies were retrieved and in-depth analysis was\nconducted. It is concluded that diffuse reflectance spectroscopy and machine\nlearning have strong potential for tissue differentiation in clinical\napplications, but more rigorous sample stratification in tandem with in-vivo\nvalidation and explainable algorithm development is required going forward.",
      "tldr_zh": "本文系统综述了机器学习在漫反射光谱（Diffuse Reflectance Spectroscopy）光学诊断中的应用。研究发现，机器学习模型在处理生物组织识别和区分任务中表现出高诊断准确性，并提出了多种方法应用于不同疾病和病症。通过对77项研究的深入分析，作者指出漫反射光谱与机器学习在临床组织区分中具有巨大潜力，但未来需要更严格的样本分层、体内验证以及可解释算法的开发。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68Txx",
        "J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "52 pages, Preprint, Systematic Review",
      "pdf_url": "http://arxiv.org/pdf/2503.02905v1",
      "published_date": "2025-03-03 13:10:16 UTC",
      "updated_date": "2025-03-03 13:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:35.118447"
    },
    {
      "arxiv_id": "2503.01496v1",
      "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures",
      "title_zh": "Liger：将大语言模型线性化为门控循环结构",
      "authors": [
        "Disen Lan",
        "Weigao Sun",
        "Jiaxi Hu",
        "Jusen Du",
        "Yu Cheng"
      ],
      "abstract": "Transformers with linear recurrent modeling offer linear-time training and\nconstant-memory inference. Despite their demonstrated efficiency and\nperformance, pretraining such non-standard architectures from scratch remains\ncostly and risky. The linearization of large language models (LLMs) transforms\npretrained standard models into linear recurrent structures, enabling more\nefficient deployment. However, current linearization methods typically\nintroduce additional feature map modules that require extensive fine-tuning and\noverlook the gating mechanisms used in state-of-the-art linear recurrent\nmodels. To address these issues, this paper presents Liger, short for\nLinearizing LLMs to gated recurrent structures. Liger is a novel approach for\nconverting pretrained LLMs into gated linear recurrent models without adding\nextra parameters. It repurposes the pretrained key matrix weights to construct\ndiverse gating mechanisms, facilitating the formation of various gated\nrecurrent structures while avoiding the need to train additional components\nfrom scratch. Using lightweight fine-tuning with Low-Rank Adaptation (LoRA),\nLiger restores the performance of the linearized gated recurrent models to\nmatch that of the original LLMs. Additionally, we introduce Liger Attention, an\nintra-layer hybrid attention mechanism, which significantly recovers 93\\% of\nthe Transformer-based LLM at 0.02\\% pre-training tokens during the\nlinearization process, achieving competitive results across multiple\nbenchmarks, as validated on models ranging from 1B to 8B parameters. Code is\navailable at https://github.com/OpenSparseLLMs/Linearization.",
      "tldr_zh": "本文提出Liger，一种将预训练大语言模型(LLMs)线性化为门控循环结构的新方法。Liger通过重用预训练的key矩阵权重构建多样化的门控机制，无需额外参数即可实现线性化，并利用低秩适应(LoRA)进行轻量微调，使线性化模型的性能恢复至原始LLM水平。此外，Liger引入层内混合注意力机制(Liger Attention)，显著提升了线性化过程中的模型性能，在多个基准测试中表现出竞争力。该方法为高效部署LLMs提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical report, 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01496v1",
      "published_date": "2025-03-03 13:08:00 UTC",
      "updated_date": "2025-03-03 13:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:17:50.477299"
    },
    {
      "arxiv_id": "2503.01940v1",
      "title": "AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification",
      "title_zh": "AskToAct：通过自我纠正澄清增强大语言模型的工具使用能力",
      "authors": [
        "Xuan Zhang",
        "Yongliang Shen",
        "Zhe Zheng",
        "Linjuan Wu",
        "Wenqi Zhang",
        "Yuchen Yan",
        "Qiuying Peng",
        "Jun Wang",
        "Weiming Lu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ntool learning. In real-world scenarios, user queries are often ambiguous and\nincomplete, requiring effective clarification. However, existing interactive\nclarification approaches face two critical limitations: reliance on manually\nconstructed datasets and lack of error correction mechanisms during multi-turn\nclarification. We present AskToAct, which addresses these challenges by\nexploiting the structural mapping between queries and their tool invocation\nsolutions. Our key insight is that tool parameters naturally represent explicit\nuser intents. By systematically removing key parameters from queries while\nretaining them as ground truth, we enable automated construction of\nhigh-quality training data. We further enhance model robustness by fine-tuning\non error-correction augmented data using selective masking mechanism, enabling\ndynamic error detection during clarification interactions. Comprehensive\nexperiments demonstrate that AskToAct significantly outperforms existing\napproaches, achieving above 79% accuracy in recovering critical unspecified\nintents and enhancing clarification efficiency by an average of 48.34% while\nmaintaining high accuracy in tool invocation. Our framework exhibits robust\nperformance across varying complexity levels and successfully generalizes to\nentirely unseen APIs without additional training, achieving performance\ncomparable to GPT-4 with substantially fewer computational resources.",
      "tldr_zh": "该研究提出了AskToAct框架，旨在提升大语言模型(LLMs)在工具使用中的表现，通过自我修正的澄清机制解决用户查询模糊和不完整的问题。其核心创新在于利用查询与工具调用解决方案之间的结构化映射，通过系统性地移除关键参数并保留其作为真实值，自动构建高质量训练数据。此外，通过选择性掩码机制增强模型对错误的动态检测能力。实验表明，AskToAct在恢复未明确意图的准确率超过79%，澄清效率提升48.34%，并在无需额外训练的情况下成功泛化到全新API，性能接近GPT-4但计算资源需求显著降低。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01940v1",
      "published_date": "2025-03-03 12:55:49 UTC",
      "updated_date": "2025-03-03 12:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:18:02.855723"
    },
    {
      "arxiv_id": "2503.01478v5",
      "title": "SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity Reduction",
      "title_zh": "SePer：通过语义困惑度降低衡量检索效用",
      "authors": [
        "Lu Dai",
        "Yijie Xu",
        "Jinhui Ye",
        "Hao Liu",
        "Hui Xiong"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.",
      "tldr_zh": "本研究提出了语义困惑度(Semantic Perplexity, SePer)这一自动评估方法，用于衡量检索增强生成(RAG)框架中检索的质量。SePer通过量化检索后语言模型内部对信息正确性的置信度，即语义困惑度的减少程度，来评估检索的效用。实验表明，SePer不仅与人类偏好高度一致，还能在各种RAG场景中提供更精确和高效的检索效用评估，弥补了传统指标如NDCG在理解检索对生成过程真实贡献方面的不足。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2503.01478v5",
      "published_date": "2025-03-03 12:37:34 UTC",
      "updated_date": "2025-03-20 11:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:18:12.389266"
    },
    {
      "arxiv_id": "2503.01475v1",
      "title": "ProRCA: A Causal Python Package for Actionable Root Cause Analysis in Real-world Business Scenarios",
      "title_zh": "ProRCA：面向实际业务场景的可操作根因分析因果推理Python包",
      "authors": [
        "Ahmed Dawoud",
        "Shravan Talupula"
      ],
      "abstract": "Root Cause Analysis (RCA) is becoming ever more critical as modern systems\ngrow in complexity, volume of data, and interdependencies. While traditional\nRCA methods frequently rely on correlation-based or rule-based techniques,\nthese approaches can prove inadequate in highly dynamic, multi-layered\nenvironments. In this paper, we present a pathway-tracing package built on the\nDoWhy causal inference library. Our method integrates conditional anomaly\nscoring, noise-based attribution, and depth-first path exploration to reveal\nmulti-hop causal chains. By systematically tracing entire causal pathways from\nan observed anomaly back to the initial triggers, our approach provides a\ncomprehensive, end-to-end RCA solution. Experimental evaluations with synthetic\nanomaly injections demonstrate the package's ability to accurately isolate\ntriggers and rank root causes by their overall significance.",
      "tldr_zh": "该研究提出了ProRCA因果分析Python工具包，基于DoWhy因果推断库构建，用于解决复杂商业环境中的根因分析问题。该方法整合了条件异常评分、基于噪声的归因和深度优先路径探索技术，能够追踪多跳因果链，从观测异常回溯至初始触发因素。实验通过注入合成异常数据验证了该工具包能准确隔离触发因素并按重要性排序根因，为动态多层系统提供了端到端的可操作根因分析方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01475v1",
      "published_date": "2025-03-03 12:33:17 UTC",
      "updated_date": "2025-03-03 12:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:18:34.266093"
    },
    {
      "arxiv_id": "2503.01470v1",
      "title": "Position: Ensuring mutual privacy is necessary for effective external evaluation of proprietary AI systems",
      "title_zh": "立场声明：确保互惠隐私是实现专有AI系统有效外部评估的必要条件",
      "authors": [
        "Ben Bucknall",
        "Robert F. Trager",
        "Michael A. Osborne"
      ],
      "abstract": "The external evaluation of AI systems is increasingly recognised as a crucial\napproach for understanding their potential risks. However, facilitating\nexternal evaluation in practice faces significant challenges in balancing\nevaluators' need for system access with AI developers' privacy and security\nconcerns. Additionally, evaluators have reason to protect their own privacy -\nfor example, in order to maintain the integrity of held-out test sets. We refer\nto the challenge of ensuring both developers' and evaluators' privacy as one of\nproviding mutual privacy. In this position paper, we argue that (i) addressing\nthis mutual privacy challenge is essential for effective external evaluation of\nAI systems, and (ii) current methods for facilitating external evaluation\ninadequately address this challenge, particularly when it comes to preserving\nevaluators' privacy. In making these arguments, we formalise the mutual privacy\nproblem; examine the privacy and access requirements of both model owners and\nevaluators; and explore potential solutions to this challenge, including\nthrough the application of cryptographic and hardware-based approaches.",
      "tldr_zh": "本文提出，确保“互惠隐私”（mutual privacy）是有效外部评估专有AI系统的关键。作者认为，当前的外部评估方法在平衡开发者隐私和评估者访问需求方面存在不足，尤其是未能充分保护评估者的隐私（如测试集的完整性）。论文形式化了互惠隐私问题，分析了模型所有者和评估者的隐私与访问需求，并探讨了通过密码学和硬件技术等潜在解决方案来应对这一挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01470v1",
      "published_date": "2025-03-03 12:24:59 UTC",
      "updated_date": "2025-03-03 12:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:18:15.416780"
    },
    {
      "arxiv_id": "2503.01464v1",
      "title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models",
      "title_zh": "重新思考数据：提升特定领域小型语言模型性能的新思路",
      "authors": [
        "Boris Nazarov",
        "Darya Frolova",
        "Yackov Lubarsky",
        "Alexei Gaissinski",
        "Pavel Kisilev"
      ],
      "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed\non domain-specific data has shown significant promise. However, commercial use\nof such LLMs is limited by the high computational cost required for their\ndeployment at scale. On the other hand, small Language Models (LMs) are much\nmore cost effective but have subpar performance in a similar setup. This paper\npresents our approach to finetuning a small LM, that reaches high accuracy in\nmultiple choice question answering task. We achieve this by improving data\nquality at each stage of the LM training pipeline. In particular, we start with\ndata structuring resulting in extraction of compact, semantically meaningful\ntext chunks used by a retriever. This allows more efficient knowledge digestion\nby the LM. Further, we improve the retrieved context by training a lightweight\nChunk Re-Ranker (CRR) that generates more accurate relative relevance chunk\nscores. Finally, we improve the model generalization ability by merging the\nmodels fine-tuned with different parameters on different data subsets. We\npresent detailed procedure descriptions, and corresponding experimental\nfindings that show the improvements of each one of the proposed techniques.",
      "tldr_zh": "该研究提出了一种优化小语言模型(LMs)在特定领域任务中表现的方法，通过提升数据质量显著提高了模型性能。研究采用数据结构化方法提取语义紧凑的文本块，训练轻量级的Chunk Re-Ranker(CRR)提升检索上下文的相关性，并通过合并在不同参数和数据子集上微调的模型来增强泛化能力。实验表明，这些改进使得小语言模型在多项选择题回答任务中达到了高准确率，为降低商业部署成本提供了可行方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01464v1",
      "published_date": "2025-03-03 12:19:12 UTC",
      "updated_date": "2025-03-03 12:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:18:47.609382"
    },
    {
      "arxiv_id": "2503.01461v1",
      "title": "Towards Widening The Distillation Bottleneck for Reasoning Models",
      "title_zh": "拓宽推理模型蒸馏瓶颈的探索",
      "authors": [
        "Huifeng Yin",
        "Yu Zhao",
        "Minghao Wu",
        "Xuanfan Ni",
        "Bo Zeng",
        "Hao Wang",
        "Tianqi Shi",
        "Liangying Shao",
        "Chenyang Lyu",
        "Longyue Wang",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "abstract": "Large Reasoning Models(LRMs) such as OpenAI o1 and DeepSeek-R1 have shown\nremarkable reasoning capabilities by scaling test-time compute and generating\nlong Chain-of-Thought(CoT). Distillation--post-training on LRMs-generated\ndata--is a straightforward yet effective method to enhance the reasoning\nabilities of smaller models, but faces a critical bottleneck: we found that\ndistilled long CoT data poses learning difficulty for small models and leads to\nthe inheritance of biases (i.e. over-thinking) when using Supervised\nFine-tuning(SFT) and Reinforcement Learning(RL) methods. To alleviate this\nbottleneck, we propose constructing tree-based CoT data from scratch via Monte\nCarlo Tree Search(MCTS). We then exploit a set of CoT-aware approaches,\nincluding Thoughts Length Balance, Fine-grained DPO, and Joint Post-training\nObjective, to enhance SFT and RL on the construted data.",
      "tldr_zh": "该研究针对大型推理模型(LRMs)到小型模型的知识蒸馏瓶颈问题提出了创新解决方案。研究发现，直接蒸馏长链式思维(CoT)数据会导致小型模型学习困难并继承偏差（如过度思考）。为此，作者提出通过蒙特卡洛树搜索(MCTS)从头构建树状CoT数据，并结合思维长度平衡、细粒度DPO和联合后训练目标等CoT感知方法，优化监督微调(SFT)和强化学习(RL)过程，从而有效提升小型模型的推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01461v1",
      "published_date": "2025-03-03 12:17:36 UTC",
      "updated_date": "2025-03-03 12:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:05.528112"
    },
    {
      "arxiv_id": "2503.01458v1",
      "title": "SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning",
      "title_zh": "SrSv：将序列化行动部署与序列化价值估计整合的多智能体强化学习方法",
      "authors": [
        "Xu Wan",
        "Chao Yang",
        "Cheng Yang",
        "Jie Song",
        "Mingyang Sun"
      ],
      "abstract": "Although multi-agent reinforcement learning (MARL) has shown its success\nacross diverse domains, extending its application to large-scale real-world\nsystems still faces significant challenges. Primarily, the high complexity of\nreal-world environments exacerbates the credit assignment problem,\nsubstantially reducing training efficiency. Moreover, the variability of agent\npopulations in large-scale scenarios necessitates scalable decision-making\nmechanisms. To address these challenges, we propose a novel framework:\nSequential rollout with Sequential value estimation (SrSv). This framework aims\nto capture agent interdependence and provide a scalable solution for\ncooperative MARL. Specifically, SrSv leverages the autoregressive property of\nthe Transformer model to handle varying populations through sequential action\nrollout. Furthermore, to capture the interdependence of policy distributions\nand value functions among multiple agents, we introduce an innovative\nsequential value estimation methodology and integrates the value approximation\ninto an attention-based sequential model. We evaluate SrSv on three benchmarks:\nMulti-Agent MuJoCo, StarCraft Multi-Agent Challenge, and DubinsCars.\nExperimental results demonstrate that SrSv significantly outperforms baseline\nmethods in terms of training efficiency without compromising convergence\nperformance. Moreover, when implemented in a large-scale DubinsCar system with\n1,024 agents, our framework surpasses existing benchmarks, highlighting the\nexcellent scalability of SrSv.",
      "tldr_zh": "该研究提出了一种新型多智能体强化学习(MARL)框架SrSv，通过将顺序动作生成(Sequential Rollout)与顺序价值估计(Sequential Value Estimation)相结合，解决了大规模现实系统中信用分配和可扩展性难题。SrSv利用Transformer的自回归特性处理智能体数量变化，并通过基于注意力机制的顺序模型捕捉策略分布与价值函数间的相互依赖关系。实验表明，SrSv在Multi-Agent MuJoCo、StarCraft Multi-Agent Challenge和DubinsCars三个基准测试中显著提升了训练效率，并在包含1024个智能体的大规模DubinsCar系统中展现了优异的可扩展性，超越了现有基准方法。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01458v1",
      "published_date": "2025-03-03 12:17:18 UTC",
      "updated_date": "2025-03-03 12:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:04.508309"
    },
    {
      "arxiv_id": "2503.01457v1",
      "title": "Structural Deep Encoding for Table Question Answering",
      "title_zh": "表结构深度编码在表格问答中的应用",
      "authors": [
        "Raphaël Mouravieff",
        "Benjamin Piwowarski",
        "Sylvain Lamprier"
      ],
      "abstract": "Although Transformers-based architectures excel at processing textual\ninformation, their naive adaptation for tabular data often involves flattening\nthe table structure. This simplification can lead to the loss of essential\ninter-dependencies between rows, columns, and cells, while also posing\nscalability challenges for large tables. To address these issues, prior works\nhave explored special tokens, structured embeddings, and sparse attention\npatterns. In this paper, we conduct a comprehensive analysis of tabular\nencoding techniques, which highlights the crucial role of attention sparsity in\npreserving structural information of tables. We also introduce a set of novel\nsparse attention mask designs for tabular data, that not only enhance\ncomputational efficiency but also preserve structural integrity, leading to\nbetter overall performance.",
      "tldr_zh": "本文研究了基于Transformer架构的表格问答任务，指出直接将表格数据扁平化处理会丢失行列和单元格之间的关键依赖关系，并面临大规模表格的可扩展性问题。通过全面分析表格编码技术，研究发现注意力稀疏性在保留表格结构信息中起关键作用。为此，作者提出了一系列新颖的稀疏注意力掩码设计，不仅提高了计算效率，还保持了表格的结构完整性，从而提升了整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01457v1",
      "published_date": "2025-03-03 12:16:43 UTC",
      "updated_date": "2025-03-03 12:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:45.055979"
    },
    {
      "arxiv_id": "2503.01453v1",
      "title": "AC-Lite : A Lightweight Image Captioning Model for Low-Resource Assamese Language",
      "title_zh": "AC-Lite：面向低资源阿萨姆语的轻量级图像描述模型",
      "authors": [
        "Pankaj Choudhury",
        "Yogesh Aggarwal",
        "Prithwijit Guha",
        "Sukumar Nandi"
      ],
      "abstract": "Neural networks have significantly advanced AI applications, yet their\nreal-world adoption remains constrained by high computational demands, hardware\nlimitations, and accessibility challenges. In image captioning, many\nstate-of-the-art models have achieved impressive performances while relying on\nresource-intensive architectures. This made them impractical for deployment on\nresource-constrained devices. This limitation is particularly noticeable for\napplications involving low-resource languages. We demonstrate the case of image\ncaptioning in Assamese language, where lack of effective, scalable systems can\nrestrict the accessibility of AI-based solutions for native Assamese speakers.\nThis work presents AC-Lite, a computationally efficient model for image\ncaptioning in low-resource Assamese language. AC-Lite reduces computational\nrequirements by replacing computation-heavy visual feature extractors like\nFasterRCNN with lightweight ShuffleNetv2x1.5. Additionally, Gated Recurrent\nUnits (GRUs) are used as the caption decoder to further reduce computational\ndemands and model parameters. Furthermore, the integration of bilinear\nattention enhances the model's overall performance. AC-Lite can operate on edge\ndevices, thereby eliminating the need for computation on remote servers. The\nproposed AC-Lite model achieves 82.3 CIDEr score on the COCO-AC dataset with\n1.098 GFLOPs and 25.65M parameters.",
      "tldr_zh": "本文提出AC-Lite，一种面向低资源阿萨姆语的轻量级图像描述生成模型。该模型采用ShuffleNetv2x1.5替代计算密集型的FasterRCNN视觉特征提取器，并选用GRU作为解码器，显著降低了计算开销和参数量。通过引入双线性注意力机制，模型在COCO-AC数据集上取得82.3的CIDEr分数，仅需1.098 GFLOPs计算量和25.65M参数，可直接部署于边缘设备运行。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01453v1",
      "published_date": "2025-03-03 12:07:52 UTC",
      "updated_date": "2025-03-03 12:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:18.245465"
    },
    {
      "arxiv_id": "2503.04803v1",
      "title": "An energy-efficient learning solution for the Agile Earth Observation Satellite Scheduling Problem",
      "title_zh": "一种针对敏捷地球观测卫星调度问题的节能学习解决方案",
      "authors": [
        "Antonio M. Mercado-Martínez",
        "Beatriz Soret",
        "Antonio Jurado-Navas"
      ],
      "abstract": "The Agile Earth Observation Satellite Scheduling Problem (AEOSSP) entails\nfinding the subset of observation targets to be scheduled along the satellite's\norbit while meeting operational constraints of time, energy and memory. The\nproblem of deciding what and when to observe is inherently complex, and becomes\neven more challenging when considering several issues that compromise the\nquality of the captured images, such as cloud occlusion, atmospheric\nturbulence, and image resolution. This paper presents a Deep Reinforcement\nLearning (DRL) approach for addressing the AEOSSP with time-dependent profits,\nintegrating these three factors to optimize the use of energy and memory\nresources. The proposed method involves a dual decision-making process:\nselecting the sequence of targets and determining the optimal observation time\nfor each. Our results demonstrate that the proposed algorithm reduces the\ncapture of images that fail to meet quality requirements by > 60% and\nconsequently decreases energy waste from attitude maneuvers by up to 78%, all\nwhile maintaining strong observation performance.",
      "tldr_zh": "本文提出了一种基于深度强化学习(Deep Reinforcement Learning, DRL)的解决方案，用于优化敏捷地球观测卫星调度问题(Agile Earth Observation Satellite Scheduling Problem, AEOSSP)。该方法通过双重决策过程选择观测目标序列并确定最佳观测时间，综合考虑云层遮挡、大气湍流和图像分辨率等因素，优化能源和内存资源的使用。实验结果表明，该算法将不符合质量要求的图像捕获量减少超过60%，并减少姿态调整导致的能源浪费高达78%，同时保持了良好的观测性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the IEEE\n  International Conference on Machine Learning for Communication and Networking\n  (ICMLCN) Special Sessions 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04803v1",
      "published_date": "2025-03-03 12:01:27 UTC",
      "updated_date": "2025-03-03 12:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:45.682232"
    },
    {
      "arxiv_id": "2503.01450v2",
      "title": "POPGym Arcade: Parallel Pixelated POMDPs",
      "title_zh": "POPGym Arcade：并行像素化部分可观测马尔可夫决策过程",
      "authors": [
        "Zekang Wang",
        "Zhe He",
        "Edan Toledo",
        "Steven Morad"
      ],
      "abstract": "We introduce POPGym Arcade, a benchmark consisting of 7 pixel-based\nenvironments each with three difficulties, utilizing a single observation and\naction space. Each environment offers both fully observable and partially\nobservable variants, enabling counterfactual studies on partial observability.\nPOPGym Arcade utilizes JIT compilation on hardware accelerators to achieve\nsubstantial speedups over CPU-bound environments. Moreover, this enables\nPodracer-style architectures to further increase hardware utilization and\ntraining speed. We evaluate memory models on our environments using a Podracer\nvariant of Q learning, and examine the results. Finally, we generate memory\nsaliency maps, uncovering how memories propagate through policies. Our library\nis available at https://github.com/bolt-research/popgym_arcade.",
      "tldr_zh": "该研究提出了POPGym Arcade，一个包含7个像素化环境的基准测试集，每个环境提供三种难度和统一的观测与动作空间。该平台支持完全可观测和部分可观测的变体，便于进行部分可观测性的对比研究。通过利用硬件加速器的即时编译技术，POPGym Arcade显著提升了训练速度，并支持Podracer架构以进一步提高硬件利用率和训练效率。研究还使用Podracer变体的Q学习评估了记忆模型，并生成了记忆显著性图，揭示了记忆在策略中的传播机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01450v2",
      "published_date": "2025-03-03 11:59:03 UTC",
      "updated_date": "2025-03-04 05:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:19:34.984472"
    },
    {
      "arxiv_id": "2503.01442v1",
      "title": "Leveraging LLMs for Mental Health: Detection and Recommendations from Social Discussions",
      "title_zh": "利用大型语言模型助力心理健康：从社交讨论中实现检测与建议",
      "authors": [
        "Vaishali Aggarwal",
        "Sachin Thukral",
        "Krushil Patel",
        "Arnab Chatterjee"
      ],
      "abstract": "Textual data from social platforms captures various aspects of mental health\nthrough discussions around and across issues, while users reach out for help\nand others sympathize and offer support. We propose a comprehensive framework\nthat leverages Natural Language Processing (NLP) and Generative AI techniques\nto identify and assess mental health disorders, detect their severity, and\ncreate recommendations for behavior change and therapeutic interventions based\non users' posts on Reddit.\n  To classify the disorders, we use rule-based labeling methods as well as\nadvanced pre-trained NLP models to extract nuanced semantic features from the\ndata. We fine-tune domain-adapted and generic pre-trained NLP models based on\npredictions from specialized Large Language Models (LLMs) to improve\nclassification accuracy. Our hybrid approach combines the generalization\ncapabilities of pre-trained models with the domain-specific insights captured\nby LLMs, providing an improved understanding of mental health discourse. Our\nfindings highlight the strengths and limitations of each model, offering\nvaluable insights into their practical applicability.\n  This research potentially facilitates early detection and personalized care\nto aid practitioners and aims to facilitate timely interventions and improve\noverall well-being, thereby contributing to the broader field of mental health\nsurveillance and digital health analytics.",
      "tldr_zh": "该研究提出了一种综合框架，利用自然语言处理（NLP）和生成式AI技术，通过分析Reddit用户帖子来识别和评估心理健康问题，检测其严重程度，并生成行为改变和治疗干预的建议。研究结合了基于规则的标注方法和预训练NLP模型，并利用大型语言模型（LLMs）的预测结果对模型进行微调，以提高分类准确性。这种混合方法结合了预训练模型的泛化能力和LLMs的领域特定洞察，为心理健康话语的理解提供了改进。研究结果展示了各模型的优势和局限性，为心理健康监测和数字健康分析领域提供了有价值的实践见解。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01442v1",
      "published_date": "2025-03-03 11:48:01 UTC",
      "updated_date": "2025-03-03 11:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:04.018968"
    },
    {
      "arxiv_id": "2503.01437v1",
      "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning",
      "title_zh": "Eau De Q-网络：深度强化学习中神经网络的适应性蒸馏",
      "authors": [
        "Théo Vincent",
        "Tim Faust",
        "Yogesh Tripathi",
        "Jan Peters",
        "Carlo D'Eramo"
      ],
      "abstract": "Recent works have successfully demonstrated that sparse deep reinforcement\nlearning agents can be competitive against their dense counterparts. This opens\nup opportunities for reinforcement learning applications in fields where\ninference time and memory requirements are cost-sensitive or limited by\nhardware. Until now, dense-to-sparse methods have relied on hand-designed\nsparsity schedules that are not synchronized with the agent's learning pace.\nCrucially, the final sparsity level is chosen as a hyperparameter, which\nrequires careful tuning as setting it too high might lead to poor performances.\nIn this work, we address these shortcomings by crafting a dense-to-sparse\nalgorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at\nthe agent's learning pace, we consider multiple online networks with different\nsparsity levels, where each online network is trained from a shared target\nnetwork. At each target update, the online network with the smallest loss is\nchosen as the next target network, while the other networks are replaced by a\npruned version of the chosen network. We evaluate the proposed approach on the\nAtari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN\nreaches high sparsity levels while keeping performances high.",
      "tldr_zh": "该研究提出名为EauDeQN（Eau De $Q$-Network）的新型自适应蒸馏算法，用于深度强化学习中的神经网络稀疏化。该方法通过维护多个不同稀疏度的在线网络，动态选择损失最小的网络作为目标网络，其余网络则替换为选定网络的剪枝版本，实现与智能体学习进度同步的稀疏化。实验在Atari 2600基准和MuJoCo物理模拟器上验证了该算法，结果显示EauDeQN能在保持高性能的同时达到较高的稀疏度，解决了传统方法需要手动调参稀疏度的问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at RLDM",
      "pdf_url": "http://arxiv.org/pdf/2503.01437v1",
      "published_date": "2025-03-03 11:39:03 UTC",
      "updated_date": "2025-03-03 11:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:09.467446"
    },
    {
      "arxiv_id": "2503.04802v1",
      "title": "The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification",
      "title_zh": "语音障碍中的秩序：临床语音分类的机器学习方法现状综述",
      "authors": [
        "Birger Moell",
        "Fredrik Sand Aronsson",
        "Per Östberg",
        "Jonas Beskow"
      ],
      "abstract": "Background:Speech patterns have emerged as potential diagnostic markers for\nconditions with varying etiologies. Machine learning (ML) presents an\nopportunity to harness these patterns for accurate disease diagnosis.\n  Objective: This review synthesized findings from studies exploring ML's\ncapability in leveraging speech for the diagnosis of neurological, laryngeal\nand mental disorders.\n  Methods: A systematic examination of 564 articles was conducted with 91\narticles included in the study, which encompassed a wide spectrum of\nconditions, ranging from voice pathologies to mental and neurological\ndisorders. Methods for speech classifications were assessed based on the\nrelevant studies and scored between 0-10 based on the reported diagnostic\naccuracy of their ML models.\n  Results: High diagnostic accuracies were consistently observed for laryngeal\ndisorders, dysarthria, and changes related to speech in Parkinsons disease.\nThese findings indicate the robust potential of speech as a diagnostic tool.\nDisorders like depression, schizophrenia, mild cognitive impairment and\nAlzheimers dementia also demonstrated high accuracies, albeit with some\nvariability across studies. Meanwhile, disorders like OCD and autism\nhighlighted the need for more extensive research to ascertain the relationship\nbetween speech patterns and the respective conditions.\n  Conclusion: ML models utilizing speech patterns demonstrate promising\npotential in diagnosing a range of mental, laryngeal, and neurological\ndisorders. However, the efficacy varies across conditions, and further research\nis needed. The integration of these models into clinical practice could\npotentially revolutionize the evaluation and diagnosis of a number of different\nmedical conditions.",
      "tldr_zh": "这篇综述研究评估了机器学习(ML)在利用语音模式诊断神经、喉部和精神障碍方面的最新进展。通过对564篇文献的系统分析，研究发现ML模型在喉部疾病、构音障碍和帕金森病相关语音变化诊断中表现出较高的准确性，同时在抑郁症、精神分裂症、轻度认知障碍和阿尔茨海默病诊断中也显示出潜力。然而，对于强迫症和自闭症等疾病，仍需进一步研究以明确语音模式与疾病的关系。研究结果表明，基于语音的ML模型在多种疾病诊断中具有广阔前景，但其有效性因疾病类型而异，未来研究需进一步完善模型并将其整合到临床实践中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04802v1",
      "published_date": "2025-03-03 11:33:02 UTC",
      "updated_date": "2025-03-03 11:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:07.490676"
    },
    {
      "arxiv_id": "2503.01424v1",
      "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems",
      "title_zh": "从假设到发表：AI驱动研究支持系统全面综述",
      "authors": [
        "Zekun Zhou",
        "Xiaocheng Feng",
        "Lei Huang",
        "Xiachong Feng",
        "Ziyun Song",
        "Ruihan Chen",
        "Liang Zhao",
        "Weitao Ma",
        "Yuxuan Gu",
        "Baoxin Wang",
        "Dayong Wu",
        "Guoping Hu",
        "Ting Liu",
        "Bing Qin"
      ],
      "abstract": "Research is a fundamental process driving the advancement of human\ncivilization, yet it demands substantial time and effort from researchers. In\nrecent years, the rapid development of artificial intelligence (AI)\ntechnologies has inspired researchers to explore how AI can accelerate and\nenhance research. To monitor relevant advancements, this paper presents a\nsystematic review of the progress in this domain. Specifically, we organize the\nrelevant studies into three main categories: hypothesis formulation, hypothesis\nvalidation, and manuscript publication. Hypothesis formulation involves\nknowledge synthesis and hypothesis generation. Hypothesis validation includes\nthe verification of scientific claims, theorem proving, and experiment\nvalidation. Manuscript publication encompasses manuscript writing and the peer\nreview process. Furthermore, we identify and discuss the current challenges\nfaced in these areas, as well as potential future directions for research.\nFinally, we also offer a comprehensive overview of existing benchmarks and\ntools across various domains that support the integration of AI into the\nresearch process. We hope this paper serves as an introduction for beginners\nand fosters future research. Resources have been made publicly available at\nhttps://github.com/zkzhou126/AI-for-Research.",
      "tldr_zh": "本文系统综述了人工智能（AI）在研究支持系统中的应用，将相关研究分为三大类：假设提出、假设验证和论文发表。假设提出涉及知识综合与假设生成，假设验证包括科学主张验证、定理证明和实验验证，论文发表涵盖文稿撰写与同行评审过程。文章还探讨了当前面临的挑战及未来研究方向，并提供了跨领域支持AI集成研究的基准和工具概述。该综述旨在为初学者提供入门指南，并推动未来研究发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01424v1",
      "published_date": "2025-03-03 11:27:13 UTC",
      "updated_date": "2025-03-03 11:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:23.749096"
    },
    {
      "arxiv_id": "2503.01422v1",
      "title": "Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding",
      "title_zh": "采样高效的测试时扩展：在早期解码中自估计最佳N采样",
      "authors": [
        "Yiming Wang",
        "Pei Zhang",
        "Siyuan Huang",
        "Baosong Yang",
        "Zhuosheng Zhang",
        "Fei Huang",
        "Rui Wang"
      ],
      "abstract": "Test-time scaling improves large language model performance by adding extra\ncompute during decoding. Best-of-N (BoN) sampling serves as a common scaling\ntechnique, broadening the search space for finding better solutions from the\nmodel distribution. However, traditional BoN requires N full generations,\nleading to high GPU memory overhead and time latency. Moreover, some methods\ndepend on reward models, adding computational cost and limiting domain\ngeneralization.\n  In this paper, we propose Self-Truncation Best-of-N (ST-BoN), a novel\ndecoding method that avoids fully generating all samplings and eliminates the\nneed for reward models. ST-BoN introduces early sampling consistency to\nestimate the most promising sample, truncating suboptimal ones to free memory\nand accelerate inference. This pushes the sampling-efficient test-time scaling.\nCompared to traditional BoN, ST-BoN can reduce dynamic GPU memory overhead by\nover 90% and time latency by 50%, while achieving comparable or even better\nperformance across reasoning and open-ended domains.",
      "tldr_zh": "该研究提出了一种采样高效的测试时扩展方法——自截断最佳N采样（ST-BoN），用于优化大语言模型的解码过程。传统的最佳N采样（BoN）需要完整生成N个样本，导致高GPU内存开销和时间延迟；而ST-BoN通过早期采样一致性估计最有潜力的样本，截断次优样本，从而显著减少动态GPU内存开销（超过90%）和时间延迟（50%）。实验表明，ST-BoN在推理和开放式任务中表现优于或与传统BoN相当，且无需依赖奖励模型，提升了领域泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 14 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01422v1",
      "published_date": "2025-03-03 11:21:01 UTC",
      "updated_date": "2025-03-03 11:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:42.406738"
    },
    {
      "arxiv_id": "2503.01419v1",
      "title": "Parameter-Efficient Fine-Tuning of Large Language Models via Deconvolution in Subspace",
      "title_zh": "基于子空间反卷积的大语言模型参数高效微调方法",
      "authors": [
        "Jia-Chen Zhang",
        "Yu-Jie Xiong",
        "Chun-Ming Xia",
        "Dong-Hai Zhu",
        "Xi-He Qiu"
      ],
      "abstract": "Large language model (LLM) is considered a milestone towards achieving\nArtificial General Intelligence (AGI). With its advanced emergent capabilities,\nit adapt to a wide range of specific applications. Fine-tuning LLMs for various\ndownstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA) is\nwell-known for its parameter efficiency. It can reduce the number of parameters\nneeded to fine-tune LLMs by several orders of magnitude. However, LoRA-based\napproaches encounter a significant limitation due to the bottleneck imposed by\nrank one decomposition. As the parameters count in LLMs increase, even rank one\ndecomposition might surpass the number of parameters truly necessary for\nhandling more downstream tasks. In this paper, we propose a new method for\nParameter-Efficient Fine-Tuning (PEFT) via deconvolution in subspace, dubbed as\nDCFT. We innovatively use deconvolution to complete details and enhance\nknowledge in subspace incremental matrices, and dynamically control parameters\nby adjusting the kernel size, unconstrained by rank-one decomposition.\nExtensive experiments are conducted to validate the effectiveness of DCFT.\nResults show that compared to LoRA, DCFT achieve an 8$\\times$ reduction in\nparameters, and still achieves highly impressive performance. Our code is\navailable here: https://github.com/Godz-z/DCFT.",
      "tldr_zh": "本文提出了一种基于子空间反卷积的参数高效微调方法DCFT，用于优化大语言模型(LLMs)的微调过程。与传统的低秩适应(LoRA)方法相比，DCFT通过反卷积在子空间增量矩阵中补充细节和增强知识，并动态调整核大小以控制参数，突破了一阶分解的限制。实验表明，DCFT在减少8倍参数的同时，仍能保持卓越的性能，为LLMs的高效微调提供了新的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2503.01419v1",
      "published_date": "2025-03-03 11:15:50 UTC",
      "updated_date": "2025-03-03 11:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:20:46.356948"
    },
    {
      "arxiv_id": "2503.01413v2",
      "title": "Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards based Co-constructive Approach",
      "title_zh": "构建区间二型模糊隶属函数：基于卡牌的共同构建方法",
      "authors": [
        "Bapi Dutta",
        "Diego García-Zamora",
        "José Rui Figueira",
        "Luis Martínez"
      ],
      "abstract": "Since its inception, Fuzzy Set has been widely used to handle uncertainty and\nimprecision in decision-making. However, conventional fuzzy sets, often\nreferred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher\nlevels of uncertainty, particularly when decision-makers (DMs) express\nhesitation or ambiguity in membership degree. To address this, Interval Type-2\nFuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in\nmembership degree allocation, which enhanced flexibility in modelling\nsubjective judgments. Despite their advantages, existing IT2FS construction\nmethods often lack active involvement from DMs and that limits the\ninterpretability and effectiveness of decision models. This study proposes a\nsocio-technical co-constructive approach for developing IT2FS models of\nlinguistic terms by facilitating the active involvement of DMs in preference\nelicitation and its application in multicriteria decision-making (MCDM)\nproblems. Our methodology is structured in two phases. The first phase involves\nan interactive process between the DM and the decision analyst, in which a\nmodified version of Deck-of-Cards (DoC) method is proposed to construct T1FS\nmembership functions on a ratio scale. We then extend this method to\nincorporate ambiguity in subjective judgment and that resulted in an IT2FS\nmodel that better captures uncertainty in DM's linguistic assessments. The\nsecond phase formalizes the constructed IT2FS model for application in MCDM by\ndefining an appropriate mathematical representation of such information,\naggregation rules, and an admissible ordering principle. The proposed framework\nenhances the reliability and effectiveness of fuzzy decision-making not only by\naccurately representing DM's personalized semantics of linguistic information.",
      "tldr_zh": "本研究提出了一种基于“纸牌法”(Deck-of-Cards)的社会技术协同构建方法，用于构建区间二型模糊集(Interval Type-2 Fuzzy Sets, IT2FS)的隶属函数，以解决传统模糊集在捕捉决策者(DMs)犹豫和模糊性方面的不足。该方法分为两个阶段：第一阶段通过改进的纸牌法，在比例尺度上构建一型模糊集(T1FS)的隶属函数，并扩展至二型模糊集以更好地捕捉决策者的主观判断；第二阶段将构建的IT2FS模型形式化，应用于多准则决策(MCDM)问题，定义了相应的数学表示、聚合规则和可接受排序原则。该框架通过增强决策者参与，提高了模糊决策的可靠性和有效性，更准确地反映了决策者对语言信息的个性化语义理解。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01413v2",
      "published_date": "2025-03-03 11:08:18 UTC",
      "updated_date": "2025-03-11 15:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:10.464143"
    },
    {
      "arxiv_id": "2503.01411v1",
      "title": "Learning Actionable World Models for Industrial Process Control",
      "title_zh": "学习工业过程控制的可操作世界模型",
      "authors": [
        "Peng Yan",
        "Ahmed Abdulkadir",
        "Gerrit A. Schatte",
        "Giulia Aguzzi",
        "Joonsu Gha",
        "Nikola Pascher",
        "Matthias Rosenthal",
        "Yunlong Gao",
        "Benjamin F. Grewe",
        "Thilo Stadelmann"
      ],
      "abstract": "To go from (passive) process monitoring to active process control, an\neffective AI system must learn about the behavior of the complex system from\nvery limited training data, forming an ad-hoc digital twin with respect to\nprocess in- and outputs that captures the consequences of actions on the\nprocess's world. We propose a novel methodology based on learning world models\nthat disentangles process parameters in the learned latent representation,\nallowing for fine-grained control. Representation learning is driven by the\nlatent factors that influence the processes through contrastive learning within\na joint embedding predictive architecture. This makes changes in\nrepresentations predictable from changes in inputs and vice versa, facilitating\ninterpretability of key factors responsible for process variations, paving the\nway for effective control actions to keep the process within operational\nbounds. The effectiveness of our method is validated on the example of plastic\ninjection molding, demonstrating practical relevance in proposing specific\ncontrol actions for a notoriously unstable process.",
      "tldr_zh": "该研究提出了一种基于世界模型学习的新方法，用于工业过程控制，旨在从有限的训练数据中构建一个能够捕捉过程输入输出行为及其动作后果的数字孪生体。通过对比学习在联合嵌入预测架构中驱动表示学习，该方法解耦了学习潜在表示中的过程参数，使得输入变化与表示变化可相互预测，从而增强了对过程变化关键因素的可解释性。研究以塑料注塑成型为例验证了方法的有效性，展示了其在提出针对不稳定过程的具体控制措施方面的实际应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2.0; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01411v1",
      "published_date": "2025-03-03 11:05:44 UTC",
      "updated_date": "2025-03-03 11:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:31.136425"
    },
    {
      "arxiv_id": "2503.01407v2",
      "title": "Divide and Conquer: Heterogeneous Noise Integration for Diffusion-based Adversarial Purification",
      "title_zh": "分而治之：基于扩散模型对抗净化的异构噪声集成",
      "authors": [
        "Gaozheng Pei",
        "Shaojie Lyu",
        "Gong Chen",
        "Ke Ma",
        "Qianqian Xu",
        "Yingfei Sun",
        "Qingming Huang"
      ],
      "abstract": "Existing diffusion-based purification methods aim to disrupt adversarial\nperturbations by introducing a certain amount of noise through a forward\ndiffusion process, followed by a reverse process to recover clean examples.\nHowever, this approach is fundamentally flawed: the uniform operation of the\nforward process across all pixels compromises normal pixels while attempting to\ncombat adversarial perturbations, resulting in the target model producing\nincorrect predictions. Simply relying on low-intensity noise is insufficient\nfor effective defense. To address this critical issue, we implement a\nheterogeneous purification strategy grounded in the interpretability of neural\nnetworks. Our method decisively applies higher-intensity noise to specific\npixels that the target model focuses on while the remaining pixels are\nsubjected to only low-intensity noise. This requirement motivates us to\nredesign the sampling process of the diffusion model, allowing for the\neffective removal of varying noise levels. Furthermore, to evaluate our method\nagainst strong adaptative attack, our proposed method sharply reduces time cost\nand memory usage through a single-step resampling. The empirical evidence from\nextensive experiments across three datasets demonstrates that our method\noutperforms most current adversarial training and purification techniques by a\nsubstantial margin.",
      "tldr_zh": "本文提出了一种基于扩散模型的异构噪声对抗净化方法，通过神经网络可解释性技术，在目标模型关注的像素上施加高强度噪声，而对其他像素仅施加低强度噪声，从而有效去除对抗扰动。该方法重新设计了扩散模型的采样过程，并通过单步重采样显著降低了时间成本和内存消耗。实验结果表明，该方法在三个数据集上的表现大幅优于现有的对抗训练和净化技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01407v2",
      "published_date": "2025-03-03 11:00:25 UTC",
      "updated_date": "2025-03-24 07:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:03.625761"
    },
    {
      "arxiv_id": "2503.01394v1",
      "title": "Enhancing Social Media Rumor Detection: A Semantic and Graph Neural Network Approach for the 2024 Global Election",
      "title_zh": "增强社交媒体谣言检测：面向2024年全球选举的语义与图神经网络方法",
      "authors": [
        "Liu Yan",
        "Liu Yunpeng",
        "Zhao Liang"
      ],
      "abstract": "The development of social media platforms has revolutionized the speed and\nmanner in which information is disseminated, leading to both beneficial and\ndetrimental effects on society. While these platforms facilitate rapid\ncommunication, they also accelerate the spread of rumors and extremist speech,\nimpacting public perception and behavior significantly. This issue is\nparticularly pronounced during election periods, where the influence of social\nmedia on election outcomes has become a matter of global concern. With the\nunprecedented number of elections in 2024, against this backdrop, the election\necosystem has encountered unprecedented challenges. This study addresses the\nurgent need for effective rumor detection on social media by proposing a novel\nmethod that combines semantic analysis with graph neural networks. We have\nmeticulously collected a dataset from PolitiFact and Twitter, focusing on\npolitically relevant rumors. Our approach involves semantic analysis using a\nfine-tuned BERT model to vectorize text content and construct a directed graph\nwhere tweets and comments are nodes, and interactions are edges. The core of\nour method is a graph neural network, SAGEWithEdgeAttention, which extends the\nGraphSAGE model by incorporating first-order differences as edge attributes and\napplying an attention mechanism to enhance feature aggregation. This innovative\napproach allows for the fine-grained analysis of the complex social network\nstructure, improving rumor detection accuracy. The study concludes that our\nmethod significantly outperforms traditional content analysis and time-based\nmodels, offering a theoretically sound and practically efficient solution.",
      "tldr_zh": "本研究提出了一种结合语义分析和图神经网络(GNN)的新方法，用于增强社交媒体谣言检测，特别是在2024年全球选举背景下。该方法利用微调的BERT模型对文本内容进行向量化，并构建以推文和评论为节点、互动为边的有向图，同时提出了一种改进的图神经网络SAGEWithEdgeAttention，通过引入一阶差分作为边属性并应用注意力机制来增强特征聚合。实验结果表明，该方法在检测政治相关谣言方面显著优于传统的内容分析和时间模型，为应对选举期间的社交媒体谣言提供了有效的解决方案。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01394v1",
      "published_date": "2025-03-03 10:49:33 UTC",
      "updated_date": "2025-03-03 10:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:13.289813"
    },
    {
      "arxiv_id": "2503.01389v1",
      "title": "Learning Conjecturing from Scratch",
      "title_zh": "从零开始学习猜想",
      "authors": [
        "Thibault Gauthier",
        "Josef Urban"
      ],
      "abstract": "We develop a self-learning approach for conjecturing of induction predicates\non a dataset of 16197 problems derived from the OEIS. These problems are hard\nfor today's SMT and ATP systems because they require a combination of inductive\nand arithmetical reasoning.\n  Starting from scratch, our approach consists of a feedback loop that iterates\nbetween (i) training a neural translator to learn the correspondence between\nthe problems solved so far and the induction predicates useful for them, (ii)\nusing the trained neural system to generate many new induction predicates for\nthe problems, (iii) fast runs of the z3 prover attempting to prove the problems\nusing the generated predicates, (iv) using heuristics such as predicate size\nand solution speed on the proved problems to choose the best predicates for the\nnext iteration of training.\n  The algorithm discovers on its own many interesting induction predicates,\nultimately solving 5565 problems, compared to 2265 problems solved by CVC5,\nVampire or Z3 in 60 seconds.",
      "tldr_zh": "本文提出了一种自学习的归纳谓词猜想方法，用于解决从OEIS数据库提取的16,197个需要归纳和算术推理组合的难题。该方法通过神经翻译器训练、谓词生成、z3求解器验证和启发式筛选的反馈循环，自主发现有效的归纳谓词。实验表明，该算法自主发现了多种有趣的归纳谓词，最终解决了5,565个问题，远超CVC5、Vampire和Z3在60秒内解决的2,265个问题。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.NE",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01389v1",
      "published_date": "2025-03-03 10:39:38 UTC",
      "updated_date": "2025-03-03 10:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:21.234533"
    },
    {
      "arxiv_id": "2503.01386v1",
      "title": "Geo-Semantic-Parsing: AI-powered geoparsing by traversing semantic knowledge graphs",
      "title_zh": "地理语义解析：通过遍历语义知识图谱实现AI驱动的地理解析",
      "authors": [
        "Leonardo Nizzoli",
        "Marco Avvenuti",
        "Maurizio Tesconi",
        "Stefano Cresci"
      ],
      "abstract": "Online social networks convey rich information about geospatial facets of\nreality. However in most cases, geographic information is not explicit and\nstructured, thus preventing its exploitation in real-time applications. We\naddress this limitation by introducing a novel geoparsing and geotagging\ntechnique called Geo-Semantic-Parsing (GSP). GSP identifies location references\nin free text and extracts the corresponding geographic coordinates. To reach\nthis goal, we employ a semantic annotator to identify relevant portions of the\ninput text and to link them to the corresponding entity in a knowledge graph.\nThen, we devise and experiment with several efficient strategies for traversing\nthe knowledge graph, thus expanding the available set of information for the\ngeoparsing task. Finally, we exploit all available information for learning a\nregression model that selects the best entity with which to geotag the input\ntext. We evaluate GSP on a well-known reference dataset including almost 10k\nevent-related tweets, achieving $F1=0.66$. We extensively compare our results\nwith those of 2 baselines and 3 state-of-the-art geoparsing techniques,\nachieving the best performance. On the same dataset, competitors obtain $F1\n\\leq 0.55$. We conclude by providing in-depth analyses of our results, showing\nthat the overall superior performance of GSP is mainly due to a large\nimprovement in recall, with respect to existing techniques.",
      "tldr_zh": "该研究提出了一种名为Geo-Semantic-Parsing (GSP)的新型地理解析和地理标记技术，通过语义知识图谱的遍历实现AI驱动的地理信息提取。GSP首先使用语义标注器识别文本中的位置引用并将其链接到知识图谱中的实体，然后设计多种策略遍历知识图谱以扩展可用信息，最后利用回归模型选择最佳实体进行地理标记。在包含近1万条事件相关推文的数据集上，GSP取得了F1=0.66的最佳性能，显著优于现有技术，尤其是召回率的大幅提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Postprint of the article published in the Decision Support Systems\n  journal. Please, cite accordingly",
      "pdf_url": "http://arxiv.org/pdf/2503.01386v1",
      "published_date": "2025-03-03 10:30:23 UTC",
      "updated_date": "2025-03-03 10:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:27.063308"
    },
    {
      "arxiv_id": "2503.01375v1",
      "title": "Combining Flow Matching and Transformers for Efficient Solution of Bayesian Inverse Problems",
      "title_zh": "结合流匹配与Transformer高效求解贝叶斯逆问题",
      "authors": [
        "Daniil Sherki",
        "Ivan Oseledets",
        "Ekaterina Muravleva"
      ],
      "abstract": "Solving Bayesian inverse problems efficiently remains a significant challenge\ndue to the complexity of posterior distributions and the computational cost of\ntraditional sampling methods. Given a series of observations and the forward\nmodel, we want to recover the distribution of the parameters, conditioned on\nobserved experimental data. We show, that combining Conditional Flow Mathching\n(CFM) with transformer-based architecture, we can efficiently sample from such\nkind of distribution, conditioned on variable number of observations.",
      "tldr_zh": "本研究提出了一种结合条件流匹配(Conditional Flow Matching, CFM)和Transformer架构的高效方法，用于解决贝叶斯反问题。该方法能够在给定一系列观测数据和前向模型的情况下，有效地从条件于观测数据的参数分布中进行采样。与传统采样方法相比，该技术显著降低了计算成本，并能够处理可变数量的观测数据，为复杂后验分布的求解提供了一种高效的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01375v1",
      "published_date": "2025-03-03 10:17:56 UTC",
      "updated_date": "2025-03-03 10:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:21:35.548939"
    },
    {
      "arxiv_id": "2503.01372v1",
      "title": "SwiLTra-Bench: The Swiss Legal Translation Benchmark",
      "title_zh": "SwiLTra-Bench：瑞士法律翻译基准测试集",
      "authors": [
        "Joel Niklaus",
        "Jakob Merane",
        "Luka Nenadic",
        "Sina Ahmadi",
        "Yingqiang Gao",
        "Cyrill A. H. Chevalley",
        "Claude Humbel",
        "Christophe Gösken",
        "Lorenzo Tanzi",
        "Thomas Lüthi",
        "Stefan Palombo",
        "Spencer Poff",
        "Boling Yang",
        "Nan Wu",
        "Matthew Guillod",
        "Robin Mamié",
        "Daniel Brunner",
        "Julio Pereyra",
        "Niko Grupen"
      ],
      "abstract": "In Switzerland legal translation is uniquely important due to the country's\nfour official languages and requirements for multilingual legal documentation.\nHowever, this process traditionally relies on professionals who must be both\nlegal experts and skilled translators -- creating bottlenecks and impacting\neffective access to justice. To address this challenge, we introduce\nSwiLTra-Bench, a comprehensive multilingual benchmark of over 180K aligned\nSwiss legal translation pairs comprising laws, headnotes, and press releases\nacross all Swiss languages along with English, designed to evaluate LLM-based\ntranslation systems. Our systematic evaluation reveals that frontier models\nachieve superior translation performance across all document types, while\nspecialized translation systems excel specifically in laws but under-perform in\nheadnotes. Through rigorous testing and human expert validation, we demonstrate\nthat while fine-tuning open SLMs significantly improves their translation\nquality, they still lag behind the best zero-shot prompted frontier models such\nas Claude-3.5-Sonnet. Additionally, we present SwiLTra-Judge, a specialized LLM\nevaluation system that aligns best with human expert assessments.",
      "tldr_zh": "该研究提出了SwiLTra-Bench，一个包含18万条对齐法律翻译对的多语言基准，涵盖瑞士所有官方语言和英语的法律、判例摘要和新闻稿，用于评估基于大语言模型(LLM)的翻译系统。研究发现，前沿模型在所有文档类型上表现优异，而专业翻译系统在法律文本上表现突出，但在判例摘要上欠佳。实验表明，尽管对开源模型进行微调可以显著提升翻译质量，但其表现仍不及零样本提示的前沿模型（如Claude-3.5-Sonnet）。此外，研究还开发了SwiLTra-Judge，一个与人类专家评估高度一致的LLM评估系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01372v1",
      "published_date": "2025-03-03 10:10:30 UTC",
      "updated_date": "2025-03-03 10:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:15.083361"
    },
    {
      "arxiv_id": "2503.01353v1",
      "title": "Dendron: Enhancing Human Activity Recognition with On-Device TinyML Learning",
      "title_zh": "Dendron：通过设备端 TinyML 学习增强人类活动识别",
      "authors": [
        "Hazem Hesham Yousef Shalby",
        "Manuel Roveri"
      ],
      "abstract": "Human activity recognition (HAR) is a research field that employs Machine\nLearning (ML) techniques to identify user activities. Recent studies have\nprioritized the development of HAR solutions directly executed on wearable\ndevices, enabling the on-device activity recognition. This approach is\nsupported by the Tiny Machine Learning (TinyML) paradigm, which integrates ML\nwithin embedded devices with limited resources. However, existing approaches in\nthe field lack in the capability for on-device learning of new HAR tasks,\nparticularly when supervised data are scarce. To address this limitation, our\npaper introduces Dendron, a novel TinyML methodology designed to facilitate the\non-device learning of new tasks for HAR, even in conditions of limited\nsupervised data. Experimental results on two public-available datasets and an\noff-the-shelf device (STM32-NUCLEO-F401RE) show the effectiveness and\nefficiency of the proposed solution.",
      "tldr_zh": "该研究提出了Dendron，一种创新的TinyML方法，旨在解决现有可穿戴设备上人类活动识别(HAR)系统在监督数据稀缺时难以进行设备端学习的问题。该方法通过在资源受限的嵌入式设备上实现新任务的设备端学习，显著提升了HAR的灵活性和适应性。实验结果表明，Dendron在两个公开数据集和商用设备(STM32-NUCLEO-F401RE)上均展现出高效且有效的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE SSCI",
      "pdf_url": "http://arxiv.org/pdf/2503.01353v1",
      "published_date": "2025-03-03 09:45:52 UTC",
      "updated_date": "2025-03-03 09:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:02.892117"
    },
    {
      "arxiv_id": "2503.01345v1",
      "title": "Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness",
      "title_zh": "相同问题，不同表述：基于潜在对抗框架的提示鲁棒性研究",
      "authors": [
        "Tingchen Fu",
        "Fazl Barez"
      ],
      "abstract": "Insensitivity to semantically-preserving variations of prompts (paraphrases)\nis crucial for reliable behavior and real-world deployment of large language\nmodels. However, language models exhibit significant performance degradation\nwhen faced with semantically equivalent but differently phrased prompts, and\nexisting solutions either depend on trial-and-error prompt engineering or\nrequire computationally expensive inference-time algorithms. In this study,\nbuilt on the key insight that worst-case prompts exhibit a drift in embedding\nspace, we present Latent Adversarial Paraphrasing (LAP), a dual-loop\nadversarial framework: the inner loop trains a learnable perturbation to serve\nas a \"latent continuous paraphrase\" while preserving semantics through\nLagrangian regulation, and the outer loop optimizes the language model\nparameters on these perturbations. We conduct extensive experiments to\ndemonstrate the effectiveness of LAP across multiple LLM architectures on the\nRobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case\nwin-rate compared with vanilla supervised fine-tuning.",
      "tldr_zh": "该研究提出了一种潜在对抗框架Latent Adversarial Paraphrasing (LAP)，旨在提升大语言模型(LLM)对语义相同但表述不同的提示(prompt)的鲁棒性。LAP采用双循环对抗机制：内循环通过拉格朗日调节训练可学习的扰动，生成语义保持的“潜在连续改写”；外循环则基于这些扰动优化语言模型参数。实验表明，LAP在RobustAlpaca基准测试中显著提升了多种LLM架构的最坏情况胜率，相较于传统监督微调方法提高了0.5%-4%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01345v1",
      "published_date": "2025-03-03 09:36:50 UTC",
      "updated_date": "2025-03-03 09:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:14.563962"
    },
    {
      "arxiv_id": "2503.01332v1",
      "title": "Answer, Refuse, or Guess? Investigating Risk-Aware Decision Making in Language Models",
      "title_zh": "回答、拒绝还是猜测？探究语言模型中的风险感知决策",
      "authors": [
        "Cheng-Kuang Wu",
        "Zhi Rui Tam",
        "Chieh-Yen Lin",
        "Yun-Nung Chen",
        "Hung-yi Lee"
      ],
      "abstract": "Knowing when to answer or refuse is crucial for safe and reliable\ndecision-making language agents. Although prior work has introduced refusal\nstrategies to boost LMs' reliability, how these models adapt their decisions to\ndifferent risk levels remains underexplored. We formalize the task of\nrisk-aware decision-making, expose critical weaknesses in existing LMs, and\npropose skill-decomposition solutions to mitigate them. Our findings show that\neven cutting-edge LMs--both regular and reasoning models--still require\nexplicit prompt chaining to handle the task effectively, revealing the\nchallenges that must be overcome to achieve truly autonomous decision-making\nagents.",
      "tldr_zh": "该研究探讨了语言模型(LMs)在风险感知决策中的表现，重点关注模型何时应回答、拒绝或猜测。研究发现即使是当前最先进的常规和推理模型，在处理不同风险等级时仍需明确的提示链(prompt chaining)才能有效完成决策任务。作者提出了技能分解(skill-decomposition)解决方案以改善现有模型的缺陷，揭示了实现真正自主决策代理所面临的挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.01332v1",
      "published_date": "2025-03-03 09:16:26 UTC",
      "updated_date": "2025-03-03 09:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:16.962243"
    },
    {
      "arxiv_id": "2503.01329v1",
      "title": "Neural ODE Transformers: Analyzing Internal Dynamics and Adaptive Fine-tuning",
      "title_zh": "Neural ODE Transformers：内部动态分析与自适应微调",
      "authors": [
        "Anh Tong",
        "Thanh Nguyen-Tang",
        "Dongeun Lee",
        "Duc Nguyen",
        "Toan Tran",
        "David Hall",
        "Cheongwoong Kang",
        "Jaesik Choi"
      ],
      "abstract": "Recent advancements in large language models (LLMs) based on transformer\narchitectures have sparked significant interest in understanding their inner\nworkings. In this paper, we introduce a novel approach to modeling transformer\narchitectures using highly flexible non-autonomous neural ordinary differential\nequations (ODEs). Our proposed model parameterizes all weights of attention and\nfeed-forward blocks through neural networks, expressing these weights as\nfunctions of a continuous layer index. Through spectral analysis of the model's\ndynamics, we uncover an increase in eigenvalue magnitude that challenges the\nweight-sharing assumption prevalent in existing theoretical studies. We also\nleverage the Lyapunov exponent to examine token-level sensitivity, enhancing\nmodel interpretability. Our neural ODE transformer demonstrates performance\ncomparable to or better than vanilla transformers across various configurations\nand datasets, while offering flexible fine-tuning capabilities that can adapt\nto different architectural constraints.",
      "tldr_zh": "本文提出了一种基于神经常微分方程(Neural ODE)的新型Transformer架构，将注意力机制和前馈网络的权重参数化为连续层索引的函数。通过谱分析发现该模型的动态特性挑战了现有理论研究中权重共享的假设，并利用Lyapunov指数增强了模型可解释性。实验表明，这种神经ODE Transformer在保持与标准Transformer相当性能的同时，提供了更灵活的架构适应性和微调能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01329v1",
      "published_date": "2025-03-03 09:12:14 UTC",
      "updated_date": "2025-03-03 09:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:25.444207"
    },
    {
      "arxiv_id": "2503.01328v1",
      "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
      "title_zh": "PipeOffload：通过内存优化提升管道并行的可扩展性",
      "authors": [
        "Xinyi Wan",
        "Penghui Qi",
        "Guangxing Huang",
        "Jialin Li",
        "Min Lin"
      ],
      "abstract": "Pipeline parallelism (PP) is widely used for training large language models\n(LLMs), yet its scalability is often constrained by high activation memory\nconsumption as the number of in-flight microbatches grows with the degree of\nPP. In this paper, we focus on addressing this challenge by leveraging the\nunder-explored memory offload strategy in PP. With empirical study, we discover\nthat in the majority of standard configurations, at least half, and potentially\nall, of the activations can be offloaded with negligible overhead. In the cases\nwhere full overload is not possible, we introduce a novel selective offload\nstrategy that decreases peak activation memory in a better-than-linear manner.\nFurthermore, we integrate memory offload with other techniques to jointly\nconsider overall throughput and memory limitation. Our experiments proves that\nthe per-device activation memory effectively reduces with the total number of\nstages, making PP a stronger alternative than TP, offering up to a 19\\%\nacceleration with even lower memory consumption. The implementation is\nopen-sourced at\n\\href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
      "tldr_zh": "该研究提出PipeOffload，一种通过内存优化提升流水线并行(PP)可扩展性的方法，针对大语言模型(LLM)训练中因微批次增加导致的高激活内存消耗问题。研究发现标准配置下至少半数激活可被卸载且开销可忽略，并提出新型选择性卸载策略使峰值内存以超线性方式降低。实验证明该方法使每设备激活内存随流水线阶段数有效减少，相比张量并行(TP)提速达19%且内存消耗更低，相关代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01328v1",
      "published_date": "2025-03-03 09:11:06 UTC",
      "updated_date": "2025-03-03 09:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:44.115379"
    },
    {
      "arxiv_id": "2503.01323v1",
      "title": "CacheQuant: Comprehensively Accelerated Diffusion Models",
      "title_zh": "CacheQuant：全面加速扩散模型",
      "authors": [
        "Xuewen Liu",
        "Zhikai Li",
        "Qingyi Gu"
      ],
      "abstract": "Diffusion models have gradually gained prominence in the field of image\nsynthesis, showcasing remarkable generative capabilities. Nevertheless, the\nslow inference and complex networks, resulting from redundancy at both temporal\nand structural levels, hinder their low-latency applications in real-world\nscenarios. Current acceleration methods for diffusion models focus separately\non temporal and structural levels. However, independent optimization at each\nlevel to further push the acceleration limits results in significant\nperformance degradation. On the other hand, integrating optimizations at both\nlevels can compound the acceleration effects. Unfortunately, we find that the\noptimizations at these two levels are not entirely orthogonal. Performing\nseparate optimizations and then simply integrating them results in\nunsatisfactory performance. To tackle this issue, we propose CacheQuant, a\nnovel training-free paradigm that comprehensively accelerates diffusion models\nby jointly optimizing model caching and quantization techniques. Specifically,\nwe employ a dynamic programming approach to determine the optimal cache\nschedule, in which the properties of caching and quantization are carefully\nconsidered to minimize errors. Additionally, we propose decoupled error\ncorrection to further mitigate the coupled and accumulated errors step by step.\nExperimental results show that CacheQuant achieves a 5.18 speedup and 4\ncompression for Stable Diffusion on MS-COCO, with only a 0.02 loss in CLIP\nscore. Our code are open-sourced: https://github.com/BienLuky/CacheQuant .",
      "tldr_zh": "本研究提出了CacheQuant，一种无需训练的综合加速框架，通过联合优化模型缓存和量化技术来加速扩散模型。该方法采用动态规划方法确定最优缓存策略，并结合解耦误差校正技术，逐步减少误差累积。实验结果表明，CacheQuant在MS-COCO数据集上实现了5.18倍的加速和4倍的压缩，同时仅导致CLIP分数损失0.02，显著提升了扩散模型的推理效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01323v1",
      "published_date": "2025-03-03 09:04:51 UTC",
      "updated_date": "2025-03-03 09:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:59.139479"
    },
    {
      "arxiv_id": "2503.04801v1",
      "title": "Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models",
      "title_zh": "探索与评估多模态大语言模型的多模态知识推理一致性",
      "authors": [
        "Boyu Jia",
        "Junzhe Zhang",
        "Huixuan Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "In recent years, multimodal large language models (MLLMs) have achieved\nsignificant breakthroughs, enhancing understanding across text and vision.\nHowever, current MLLMs still face challenges in effectively integrating\nknowledge across these modalities during multimodal knowledge reasoning,\nleading to inconsistencies in reasoning outcomes. To systematically explore\nthis issue, we propose four evaluation tasks and construct a new dataset. We\nconduct a series of experiments on this dataset to analyze and compare the\nextent of consistency degradation in multimodal knowledge reasoning within\nMLLMs. Based on the experimental results, we identify factors contributing to\nthe observed degradation in consistency. Our research provides new insights\ninto the challenges of multimodal knowledge reasoning and offers valuable\nguidance for future efforts aimed at improving MLLMs.",
      "tldr_zh": "本研究系统探索了多模态大语言模型(MLLMs)在多模态知识推理中的一致性退化问题。研究者提出了四项评估任务并构建了新数据集，通过实验分析比较了MLLMs在多模态知识推理中的一致性退化程度，并识别了导致退化的重要因素。该研究为改进MLLMs的多模态知识推理能力提供了新的见解和指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04801v1",
      "published_date": "2025-03-03 09:01:51 UTC",
      "updated_date": "2025-03-03 09:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:51.361319"
    },
    {
      "arxiv_id": "2503.01314v1",
      "title": "Scaling Law Phenomena Across Regression Paradigms: Multiple and Kernel Approaches",
      "title_zh": "跨回归范式的缩放律现象：多元与核方法研究",
      "authors": [
        "Yifang Chen",
        "Xuyang Guo",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have achieved remarkable success. A\nkey factor behind this success is the scaling law observed by OpenAI.\nSpecifically, for models with Transformer architecture, the test loss exhibits\na power-law relationship with model size, dataset size, and the amount of\ncomputation used in training, demonstrating trends that span more than seven\norders of magnitude. This scaling law challenges traditional machine learning\nwisdom, notably the Oscar Scissors principle, which suggests that an\noverparametrized algorithm will overfit the training datasets, resulting in\npoor test performance. Recent research has also identified the scaling law in\nsimpler machine learning contexts, such as linear regression. However, fully\nexplaining the scaling law in large practical models remains an elusive goal.\nIn this work, we advance our understanding by demonstrating that the scaling\nlaw phenomenon extends to multiple regression and kernel regression settings,\nwhich are significantly more expressive and powerful than linear methods. Our\nanalysis provides deeper insights into the scaling law, potentially enhancing\nour understanding of LLMs.",
      "tldr_zh": "该研究探讨了扩展定律（scaling law）在多元回归和核回归中的表现，发现这些更强大的回归方法同样遵循与模型规模、数据集大小和计算量之间的幂律关系。这一发现挑战了传统机器学习中的过拟合理论（如Oscar Scissors原则），并为进一步理解大规模语言模型（LLMs）的性能提供了新的视角。研究结果表明，扩展定律不仅适用于线性回归，还适用于更复杂的回归范式，为机器学习模型的设计和优化提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01314v1",
      "published_date": "2025-03-03 08:57:49 UTC",
      "updated_date": "2025-03-03 08:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:22:59.477868"
    },
    {
      "arxiv_id": "2503.01306v1",
      "title": "From Claims to Evidence: A Unified Framework and Critical Analysis of CNN vs. Transformer vs. Mamba in Medical Image Segmentation",
      "title_zh": "从主张到证据：医学图像分割中CNN、Transformer与Mamba的统一框架与批判性分析",
      "authors": [
        "Pooya Mohammadi Kazaj",
        "Giovanni Baj",
        "Yazdan Salimi",
        "Anselm W. Stark",
        "Waldo Valenzuela",
        "George CM. Siontis",
        "Habib Zaidi",
        "Mauricio Reyes",
        "Christoph Graeni",
        "Isaac Shiri"
      ],
      "abstract": "While numerous architectures for medical image segmentation have been\nproposed, achieving competitive performance with state-of-the-art models\nnetworks such as nnUNet, still leave room for further innovation. In this work,\nwe introduce nnUZoo, an open source benchmarking framework built upon nnUNet,\nwhich incorporates various deep learning architectures, including CNNs,\nTransformers, and Mamba-based models. Using this framework, we provide a fair\ncomparison to demystify performance claims across different medical image\nsegmentation tasks. Additionally, in an effort to enrich the benchmarking, we\nexplored five new architectures based on Mamba and Transformers, collectively\nnamed X2Net, and integrated them into nnUZoo for further evaluation. The\nproposed models combine the features of conventional U2Net, nnUNet, CNN,\nTransformer, and Mamba layers and architectures, called X2Net (UNETR2Net\n(UNETR), SwT2Net (SwinTransformer), SS2D2Net (SwinUMamba), Alt1DM2Net\n(LightUMamba), and MambaND2Net (MambaND)). We extensively evaluate the\nperformance of different models on six diverse medical image segmentation\ndatasets, including microscopy, ultrasound, CT, MRI, and PET, covering various\nbody parts, organs, and labels. We compare their performance, in terms of dice\nscore and computational efficiency, against their baseline models, U2Net, and\nnnUNet. CNN models like nnUNet and U2Net demonstrated both speed and accuracy,\nmaking them effective choices for medical image segmentation tasks.\nTransformer-based models, while promising for certain imaging modalities,\nexhibited high computational costs. Proposed Mamba-based X2Net architecture\n(SS2D2Net) achieved competitive accuracy with no significantly difference from\nnnUNet and U2Net, while using fewer parameters. However, they required\nsignificantly longer training time, highlighting a trade-off between model\nefficiency and computational cost.",
      "tldr_zh": "本研究提出了nnUZoo，一个基于nnUNet的开源基准测试框架，用于公平比较CNN、Transformer和Mamba架构在医学图像分割任务中的性能。通过整合五种新设计的X2Net架构（结合U2Net、nnUNet、CNN、Transformer和Mamba），研究在六种多样化的医学图像数据集上进行了广泛评估。结果表明，CNN模型（如nnUNet和U2Net）在速度和准确性上表现优异，Transformer模型在某些成像模态中表现良好但计算成本高，而Mamba架构的X2Net（如SS2D2Net）在精度上与nnUNet和U2Net相当，但训练时间显著更长，揭示了模型效率与计算成本之间的权衡。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01306v1",
      "published_date": "2025-03-03 08:44:51 UTC",
      "updated_date": "2025-03-03 08:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:23:18.396082"
    },
    {
      "arxiv_id": "2503.01298v1",
      "title": "MINT: Multi-modal Chain of Thought in Unified Generative Models for Enhanced Image Generation",
      "title_zh": "MINT：统一生成模型中的多模态链式思维推理增强图像生成",
      "authors": [
        "Yi Wang",
        "Mushui Liu",
        "Wanggui He",
        "Longxiang Zhang",
        "Ziwei Huang",
        "Guanghao Zhang",
        "Fangxun Shu",
        "Zhong Tao",
        "Dong She",
        "Zhelun Yu",
        "Haoyuan Li",
        "Weilong Dai",
        "Mingli Song",
        "Jie Song",
        "Hao Jiang"
      ],
      "abstract": "Unified generative models have demonstrated extraordinary performance in both\ntext and image generation. However, they tend to underperform when generating\nintricate images with various interwoven conditions, which is hard to solely\nrely on straightforward text-to-image generation. In response to this\nchallenge, we introduce MINT, an innovative unified generative model, empowered\nwith native multimodal chain of thought (MCoT) for enhanced image generation\nfor the first time. Firstly, we design Mixture of Transformer Experts\n(MTXpert), an expert-parallel structure that effectively supports both natural\nlanguage generation (NLG) and visual capabilities, while avoiding potential\nmodality conflicts that could hinder the full potential of each modality.\nBuilding on this, we propose an innovative MCoT training paradigm, a\nstep-by-step approach to multimodal thinking, reasoning, and reflection\nspecifically designed to enhance image generation. This paradigm equips MINT\nwith nuanced, element-wise decoupled alignment and a comprehensive\nunderstanding of textual and visual components. Furthermore, it fosters\nadvanced multimodal reasoning and self-reflection, enabling the construction of\nimages that are firmly grounded in the logical relationships between these\nelements. Notably, MINT has been validated to exhibit superior performance\nacross multiple benchmarks for text-to-image (T2I) and image-to-text (I2T)\ntasks.",
      "tldr_zh": "该研究提出MINT模型，首次将多模态思维链(MCoT)技术整合到统一生成模型中，显著提升复杂条件图像生成能力。通过创新的专家并行架构MTXpert，该模型有效协调文本与视觉模态处理，避免模态冲突；并采用分步式MCoT训练范式，实现对图像元素的细粒度解耦对齐和逻辑关系理解。实验表明，MINT在文本到图像(T2I)和图像到文本(I2T)任务的多项基准测试中均表现优异。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01298v1",
      "published_date": "2025-03-03 08:36:16 UTC",
      "updated_date": "2025-03-03 08:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:23:43.758372"
    },
    {
      "arxiv_id": "2503.01294v1",
      "title": "Fine-Grained Controllable Apparel Showcase Image Generation via Garment-Centric Outpainting",
      "title_zh": "基于服装中心外绘的细粒度可控服装展示图像生成",
      "authors": [
        "Rong Zhang",
        "Jingnan Wang",
        "Zhiwen Zuo",
        "Jianfeng Dong",
        "Wei Li",
        "Chi Wang",
        "Weiwei Xu",
        "Xun Wang"
      ],
      "abstract": "In this paper, we propose a novel garment-centric outpainting (GCO) framework\nbased on the latent diffusion model (LDM) for fine-grained controllable apparel\nshowcase image generation. The proposed framework aims at customizing a fashion\nmodel wearing a given garment via text prompts and facial images. Different\nfrom existing methods, our framework takes a garment image segmented from a\ndressed mannequin or a person as the input, eliminating the need for learning\ncloth deformation and ensuring faithful preservation of garment details. The\nproposed framework consists of two stages. In the first stage, we introduce a\ngarment-adaptive pose prediction model that generates diverse poses given the\ngarment. Then, in the next stage, we generate apparel showcase images,\nconditioned on the garment and the predicted poses, along with specified text\nprompts and facial images. Notably, a multi-scale appearance customization\nmodule (MS-ACM) is designed to allow both overall and fine-grained text-based\ncontrol over the generated model's appearance. Moreover, we leverage a\nlightweight feature fusion operation without introducing any extra encoders or\nmodules to integrate multiple conditions, which is more efficient. Extensive\nexperiments validate the superior performance of our framework compared to\nstate-of-the-art methods.",
      "tldr_zh": "本研究提出了一种基于潜在扩散模型(LDM)的服装中心外绘(GCO)框架，用于细粒度可控的服装展示图像生成。该框架通过文本提示和面部图像定制穿着特定服装的时尚模特，直接从服装图像生成多样化的姿态，并设计了多尺度外观定制模块(MS-ACM)，实现对生成模特外观的整体和细节控制。与现有方法相比，该框架无需学习服装变形，能更高效地整合多种条件，实验证明其在生成质量和控制灵活性上优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01294v1",
      "published_date": "2025-03-03 08:30:37 UTC",
      "updated_date": "2025-03-03 08:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:23:47.136340"
    },
    {
      "arxiv_id": "2503.01290v1",
      "title": "ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder",
      "title_zh": "ACTIVA：基于Transformer变分自编码器的无图因果效应摊销估计方法",
      "authors": [
        "Andreas Sauter",
        "Saber Salehkaleybar",
        "Aske Plaat",
        "Erman Acar"
      ],
      "abstract": "Predicting the distribution of outcomes under hypothetical interventions is\ncrucial in domains like healthcare, economics, and policy-making. Current\nmethods often rely on strong assumptions, such as known causal graphs or\nparametric models, and lack amortization across problem instances, limiting\ntheir practicality. We propose a novel transformer-based conditional\nvariational autoencoder architecture, named ACTIVA, that extends causal\ntransformer encoders to predict causal effects as mixtures of Gaussians. Our\nmethod requires no causal graph and predicts interventional distributions given\nonly observational data and a queried intervention. By amortizing over many\nsimulated instances, it enables zero-shot generalization to novel datasets\nwithout retraining. Experiments demonstrate accurate predictions for synthetic\nand semi-synthetic data, showcasing the effectiveness of our graph-free,\namortized causal inference approach.",
      "tldr_zh": "该研究提出了ACTIVA，一种基于Transformer的条件变分自编码器架构，用于无需因果图的因果效应估计。该方法通过将因果效应预测为高斯混合模型，仅需观测数据和干预查询即可预测干预分布，无需重新训练即可实现对新数据集的零样本泛化。实验表明，ACTIVA在合成和半合成数据上表现优异，展示了一种无需因果图、可摊销的因果推理方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01290v1",
      "published_date": "2025-03-03 08:28:25 UTC",
      "updated_date": "2025-03-03 08:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:23:46.794907"
    },
    {
      "arxiv_id": "2503.01287v1",
      "title": "Robust Simulation-Based Inference under Missing Data via Neural Processes",
      "title_zh": "基于神经过程的缺失数据下鲁棒模拟推理",
      "authors": [
        "Yogesh Verma",
        "Ayush Bharti",
        "Vikas Garg"
      ],
      "abstract": "Simulation-based inference (SBI) methods typically require fully observed\ndata to infer parameters of models with intractable likelihood functions.\nHowever, datasets often contain missing values due to incomplete observations,\ndata corruptions (common in astrophysics), or instrument limitations (e.g., in\nhigh-energy physics applications). In such scenarios, missing data must be\nimputed before applying any SBI method. We formalize the problem of missing\ndata in SBI and demonstrate that naive imputation methods can introduce bias in\nthe estimation of SBI posterior. We also introduce a novel amortized method\nthat addresses this issue by jointly learning the imputation model and the\ninference network within a neural posterior estimation (NPE) framework.\nExtensive empirical results on SBI benchmarks show that our approach provides\nrobust inference outcomes compared to standard baselines for varying levels of\nmissing data. Moreover, we demonstrate the merits of our imputation model on\ntwo real-world bioactivity datasets (Adrenergic and Kinase assays). Code is\navailable at https://github.com/Aalto-QuML/RISE.",
      "tldr_zh": "该论文提出了一种基于神经过程(Neural Processes)的鲁棒模拟推理方法，用于解决缺失数据下的参数推断问题。针对传统模拟推理(SBI)方法在数据缺失时直接插补会导致后验估计偏差的问题，作者开发了一种新型端到端框架，将数据插补模型与神经后验估计(NPE)网络联合训练。实验表明，该方法在标准SBI基准测试和两个真实生物活性数据集(肾上腺素能和激酶实验)上均优于传统基线，能够有效处理不同程度的缺失数据情况。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01287v1",
      "published_date": "2025-03-03 08:22:01 UTC",
      "updated_date": "2025-03-03 08:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:12.558290"
    },
    {
      "arxiv_id": "2503.01273v1",
      "title": "OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD",
      "title_zh": "OptMetaOpenFOAM：基于CFD的敏感性分析与参数优化——大语言模型驱动的链式思维框架",
      "authors": [
        "Yuxuan Chen",
        "Long Zhang",
        "Xu Zhu",
        "Hua Zhou",
        "Zhuyin Ren"
      ],
      "abstract": "Merging natural language interfaces with computational fluid dynamics (CFD)\nworkflows presents transformative opportunities for both industry and research.\nIn this study, we introduce OptMetaOpenFOAM - a novel framework that bridges\nMetaOpenFOAM with external analysis and optimization tool libraries through a\nlarge language model (LLM)-driven chain-of-thought (COT) methodology. By\nautomating complex CFD tasks via natural language inputs, the framework\nempowers non-expert users to perform sensitivity analyses and parameter\noptimizations with markedly improved efficiency. The test dataset comprises 11\ndistinct CFD analysis or optimization tasks, including a baseline simulation\ntask derived from an OpenFOAM tutorial covering fluid dynamics, combustion, and\nheat transfer. Results confirm that OptMetaOpenFOAM can accurately interpret\nuser requirements expressed in natural language and effectively invoke external\ntool libraries alongside MetaOpenFOAM to complete the tasks. Furthermore,\nvalidation on a non-OpenFOAM tutorial case - namely, a hydrogen combustion\nchamber - demonstrates that a mere 200-character natural language input can\ntrigger a sequence of simulation, postprocessing, analysis, and optimization\ntasks spanning over 2,000 lines of code. These findings underscore the\ntransformative potential of LLM-driven COT methodologies in linking external\ntool for advanced analysis and optimization, positioning OptMetaOpenFOAM as an\neffective tool that streamlines CFD simulations and enhances their convenience\nand efficiency for both industrial and research applications. Code is available\nat https://github.com/Terry-cyx/MetaOpenFOAM.",
      "tldr_zh": "该研究提出了OptMetaOpenFOAM，一种基于大语言模型(LLM)驱动的链式思维推理(Chain-of-Thought)框架，用于自动化计算流体力学(CFD)的敏感性分析和参数优化。该框架通过自然语言输入，将MetaOpenFOAM与外部分析优化工具库连接，使非专家用户能够高效完成复杂CFD任务。实验表明，仅需200字符的自然语言输入即可触发包含2000多行代码的仿真、后处理、分析和优化任务，显著提升了CFD仿真的便利性和效率。",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01273v1",
      "published_date": "2025-03-03 07:55:43 UTC",
      "updated_date": "2025-03-03 07:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:14.414107"
    },
    {
      "arxiv_id": "2503.01937v1",
      "title": "Synthetic Tabular Data Detection In the Wild",
      "title_zh": "真实场景中的合成表格数据检测",
      "authors": [
        "G. Charbel N. Kindji",
        "Elisa Fromont",
        "Lina Maria Rojas-Barahona",
        "Tanguy Urvoy"
      ],
      "abstract": "Detecting synthetic tabular data is essential to prevent the distribution of\nfalse or manipulated datasets that could compromise data-driven\ndecision-making. This study explores whether synthetic tabular data can be\nreliably identified across different tables. This challenge is unique to\ntabular data, where structures (such as number of columns, data types, and\nformats) can vary widely from one table to another. We propose four\ntable-agnostic detectors combined with simple preprocessing schemes that we\nevaluate on six evaluation protocols, with different levels of ''wildness''.\nOur results show that cross-table learning on a restricted set of tables is\npossible even with naive preprocessing schemes. They confirm however that\ncross-table transfer (i.e. deployment on a table that has not been seen before)\nis challenging. This suggests that sophisticated encoding schemes are required\nto handle this problem.",
      "tldr_zh": "本研究探讨了如何在多样化的表格数据中可靠检测合成数据。针对表格数据结构（如列数、数据类型和格式）差异大的特点，提出了四种与表格无关的检测器，并结合简单预处理方案，在六种不同“野性”程度的评估协议中进行了测试。结果表明，尽管在受限表格集上进行跨表格学习是可行的，但在未见过的表格上进行跨表格迁移仍具有挑战性，说明需要更复杂的编码方案来解决这一问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "International Symposium on Intelligent Data Analysis, May 2025,\n  Konstanz, Germany",
      "pdf_url": "http://arxiv.org/pdf/2503.01937v1",
      "published_date": "2025-03-03 07:53:16 UTC",
      "updated_date": "2025-03-03 07:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:14.173964"
    },
    {
      "arxiv_id": "2503.01936v1",
      "title": "Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization",
      "title_zh": "面向决策的时间序列基础模型微调以实现可调度馈线优化",
      "authors": [
        "Maximilian Beichter",
        "Nils Friederich",
        "Janik Pinter",
        "Dorina Werling",
        "Kaleb Phipps",
        "Sebastian Beichter",
        "Oliver Neumann",
        "Ralf Mikut",
        "Veit Hagenmeyer",
        "Benedikt Heidrich"
      ],
      "abstract": "Time series foundation models provide a universal solution for generating\nforecasts to support optimization problems in energy systems. Those foundation\nmodels are typically trained in a prediction-focused manner to maximize\nforecast quality. In contrast, decision-focused learning directly improves the\nresulting value of the forecast in downstream optimization rather than merely\nmaximizing forecasting quality. The practical integration of forecast values\ninto forecasting models is challenging, particularly when addressing complex\napplications with diverse instances, such as buildings. This becomes even more\ncomplicated when instances possess specific characteristics that require\ninstance-specific, tailored predictions to increase the forecast value. To\ntackle this challenge, we use decision-focused fine-tuning within time series\nfoundation models to offer a scalable and efficient solution for\ndecision-focused learning applied to the dispatchable feeder optimization\nproblem. To obtain more robust predictions for scarce building data, we use\nMoirai as a state-of-the-art foundation model, which offers robust and\ngeneralized results with few-shot parameter-efficient fine-tuning. Comparing\nthe decision-focused fine-tuned Moirai with a state-of-the-art classical\nprediction-focused fine-tuning Morai, we observe an improvement of 9.45% in\naverage total daily costs.",
      "tldr_zh": "该研究提出了一种基于决策导向微调(Decision-Focused Fine-Tuning)的时间序列基础模型方法，用于优化可调度馈线问题。与传统预测导向方法不同，该方法直接优化下游决策价值，而非单纯提高预测精度。研究采用Moirai作为基础模型，通过少量样本进行参数高效微调，显著提升了模型在稀缺建筑数据上的鲁棒性。实验表明，与经典预测导向微调相比，该方法将平均每日总成本降低了9.45%，为复杂能源系统优化提供了高效且可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01936v1",
      "published_date": "2025-03-03 07:47:20 UTC",
      "updated_date": "2025-03-03 07:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:27.226217"
    },
    {
      "arxiv_id": "2503.01268v1",
      "title": "Multi-Level Collaboration in Model Merging",
      "title_zh": "模型合并中的多层次协作",
      "authors": [
        "Qi Li",
        "Runpeng Yu",
        "Xinchao Wang"
      ],
      "abstract": "Parameter-level model merging is an emerging paradigm in multi-task learning\nwith significant promise. Previous research has explored its connections with\nprediction-level model ensembling-commonly viewed as the upper bound for\nmerging-to reveal the potential of achieving performance consistency between\nthe two. However, this observation relies on certain preconditions, such as\nbeing limited to two models, using ViT-based models, and all models are\nfine-tuned from the same pre-trained checkpoint. To further understand the\nintrinsic connections between model merging and model ensembling, this paper\nexplores an interesting possibility: If these restrictions are removed, can\nperformance consistency still be achieved between merging and ensembling? To\nanswer this question, we first theoretically establish a performance\ncorrelation between merging and ensembling. We find that even when previous\nrestrictions are not met, there is still a way for model merging to attain a\nnear-identical and superior performance similar to that of ensembling. To\nverify whether our findings are practical, we introduce a validation framework\ntermed Neural Ligand (NeuLig). The learning process of NeuLig is meticulously\ndesigned with a specialized loss function supported by theoretical foundations.\nExperimental results demonstrate the robust resilience of NeuLig in terms of\nboth model scale and the number of collaborating models. For instance, for the\ncase involving 5 CLIP-ViT-B/32 models, parameter-level merging achieves the\nsame performance as prediction-level ensembling (merging: 95.44% vs.\nensembling: 95.46%).",
      "tldr_zh": "本文探讨了模型合并（model merging）与模型集成（model ensembling）之间的内在联系，提出了即使在放宽模型数量、架构和预训练条件等限制的情况下，模型合并仍能达到与模型集成相近甚至更优的性能。通过理论分析，研究揭示了二者之间的性能相关性，并提出了名为Neural Ligand（NeuLig）的验证框架，其学习过程通过专门设计的损失函数实现理论支持。实验结果表明，NeuLig在模型规模和协作模型数量方面表现出强大的鲁棒性，例如在5个CLIP-ViT-B/32模型的情况下，参数级合并达到了与预测级集成相同的性能（合并：95.44% vs. 集成：95.46%）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01268v1",
      "published_date": "2025-03-03 07:45:04 UTC",
      "updated_date": "2025-03-03 07:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:30.050188"
    },
    {
      "arxiv_id": "2503.01266v1",
      "title": "Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology",
      "title_zh": "构音障碍语音合成的声纹克隆：解决言语病理学中的数据稀缺问题",
      "authors": [
        "Birger Moell",
        "Fredrik Sand Aronsson"
      ],
      "abstract": "This study explores voice cloning to generate synthetic speech replicating\nthe unique patterns of individuals with dysarthria. Using the TORGO dataset, we\naddress data scarcity and privacy challenges in speech-language pathology. Our\ncontributions include demonstrating that voice cloning preserves dysarthric\nspeech characteristics, analyzing differences between real and synthetic data,\nand discussing implications for diagnostics, rehabilitation, and communication.\nWe cloned voices from dysarthric and control speakers using a commercial\nplatform, ensuring gender-matched synthetic voices. A licensed speech-language\npathologist (SLP) evaluated a subset for dysarthria, speaker gender, and\nsynthetic indicators. The SLP correctly identified dysarthria in all cases and\nspeaker gender in 95% but misclassified 30% of synthetic samples as real,\nindicating high realism. Our results suggest synthetic speech effectively\ncaptures disordered characteristics and that voice cloning has advanced to\nproduce high-quality data resembling real speech, even to trained\nprofessionals. This has critical implications for healthcare, where synthetic\ndata can mitigate data scarcity, protect privacy, and enhance AI-driven\ndiagnostics. By enabling the creation of diverse, high-quality speech datasets,\nvoice cloning can improve generalizable models, personalize therapy, and\nadvance assistive technologies for dysarthria.\n  We publicly release our synthetic dataset to foster further research and\ncollaboration, aiming to develop robust models that improve patient outcomes in\nspeech-language pathology.",
      "tldr_zh": "本研究利用语音克隆技术生成模拟构音障碍患者独特语音模式的合成语音，以解决言语病理学领域的数据稀缺和隐私问题。通过使用TORGO数据集，研究验证了语音克隆能够保留构音障碍的语音特征，并分析了真实与合成数据之间的差异。实验显示，合成语音具有高度真实性，甚至被专业言语病理学家误认为真实语音的比例达30%。研究结果表明，语音克隆技术能够有效捕捉语音障碍特征，生成的合成数据可用于缓解数据稀缺、保护隐私并提升AI驱动的诊断能力。此外，研究团队公开了合成数据集，以促进进一步研究和合作，旨在开发更强大的模型，改善言语病理学患者的治疗效果。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01266v1",
      "published_date": "2025-03-03 07:44:49 UTC",
      "updated_date": "2025-03-03 07:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:24:36.458425"
    },
    {
      "arxiv_id": "2503.01238v1",
      "title": "A Taxonomy for Evaluating Generalist Robot Policies",
      "title_zh": "评估通用机器人策略的分类体系",
      "authors": [
        "Jensen Gao",
        "Suneel Belkhale",
        "Sudeep Dasari",
        "Ashwin Balakrishna",
        "Dhruv Shah",
        "Dorsa Sadigh"
      ],
      "abstract": "Machine learning for robotics promises to unlock generalization to novel\ntasks and environments. Guided by this promise, many recent works have focused\non scaling up robot data collection and developing larger, more expressive\npolicies to achieve this. But how do we measure progress towards this goal of\npolicy generalization in practice? Evaluating and quantifying generalization is\nthe Wild West of modern robotics, with each work proposing and measuring\ndifferent types of generalization in their own, often difficult to reproduce,\nsettings. In this work, our goal is (1) to outline the forms of generalization\nwe believe are important in robot manipulation in a comprehensive and\nfine-grained manner, and (2) to provide reproducible guidelines for measuring\nthese notions of generalization. We first propose STAR-Gen, a taxonomy of\ngeneralization for robot manipulation structured around visual, semantic, and\nbehavioral generalization. We discuss how our taxonomy encompasses most prior\nnotions of generalization in robotics. Next, we instantiate STAR-Gen with a\nconcrete real-world benchmark based on the widely-used Bridge V2 dataset. We\nevaluate a variety of state-of-the-art models on this benchmark to demonstrate\nthe utility of our taxonomy in practice. Our taxonomy of generalization can\nyield many interesting insights into existing models: for example, we observe\nthat current vision-language-action models struggle with various types of\nsemantic generalization, despite the promise of pre-training on internet-scale\nlanguage datasets. We believe STAR-Gen and our guidelines can improve the\ndissemination and evaluation of progress towards generalization in robotics,\nwhich we hope will guide model design and future data collection efforts. We\nprovide videos and demos at our website stargen-taxonomy.github.io.",
      "tldr_zh": "该研究提出了STAR-Gen，一种针对机器人操作任务中泛化能力的分类体系，涵盖视觉、语义和行为三个维度的泛化。研究旨在为机器人策略的泛化评估提供系统化、可复现的指南，并通过基于Bridge V2数据集的具体基准测试，验证了该分类体系的实用性。研究发现，现有的视觉-语言-动作模型在语义泛化方面表现不佳，尽管它们已在大规模语言数据集上进行了预训练。该分类体系有望为机器人泛化能力的评估和模型设计提供指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01238v1",
      "published_date": "2025-03-03 07:03:00 UTC",
      "updated_date": "2025-03-03 07:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:04.152122"
    },
    {
      "arxiv_id": "2503.01236v1",
      "title": "LLM-Advisor: An LLM Benchmark for Cost-efficient Path Planning across Multiple Terrains",
      "title_zh": "LLM-Advisor：面向多地形成本高效路径规划的LLM基准",
      "authors": [
        "Ling Xiao",
        "Toshihiko Yamasaki"
      ],
      "abstract": "Multi-terrain cost-efficient path planning is a crucial task in robot\nnavigation, requiring the identification of a path from the start to the goal\nthat not only avoids obstacles but also minimizes travel costs. This is\nespecially crucial for real-world applications where robots need to navigate\ndiverse terrains in outdoor environments, where recharging or refueling is\ndifficult. However, there is very limited research on this topic. In this\npaper, we develop a prompt-based approach, LLM-Advisor, which leverages large\nlanguage models (LLMs) as effective advisors for path planning. The LLM-Advisor\nselectively provides suggestions, demonstrating its ability to recognize when\nno modifications are necessary. When suggestions are made, 70.59% of the paths\nsuggested for the A* algorithm, 69.47% for the RRT* algorithm, and 78.70% for\nthe LLM-A* algorithm achieve greater cost efficiency. Since LLM-Advisor may\noccasionally lack common sense in their suggestions, we propose two\nhallucination-mitigation strategies. Furthermore, we experimentally verified\nthat GPT-4o performs poorly in zero-shot path planning, even when terrain\ndescriptions are clearly provided, demonstrating its low spatial awareness. We\nalso experimentally demonstrate that using an LLM as an advisor is more\neffective than directly integrating it into the path-planning loop. Since LLMs\nmay generate hallucinations, using LLMs in the loop of a search-based method\n(such as A*) may lead to a higher number of failed paths, demonstrating that\nour proposed LLM-Advisor is a better choice.",
      "tldr_zh": "该研究提出了LLM-Advisor，一个基于大语言模型（LLMs）的路径规划顾问系统，用于解决多地形成本最优路径规划问题。该系统通过选择性建议机制，显著提升了A*、RRT*和LLM-A*等算法的路径规划效率（提升幅度达69.47%-78.70%），并提出了两种幻觉缓解策略。实验表明，直接集成LLM到规划环路会导致更高失败率，而作为顾问使用时效果更优，同时揭示了GPT-4o在零样本路径规划中的空间认知缺陷。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01236v1",
      "published_date": "2025-03-03 07:02:10 UTC",
      "updated_date": "2025-03-03 07:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:54.438085"
    },
    {
      "arxiv_id": "2503.01232v1",
      "title": "Learning Covariance-Based Multi-Scale Representation of Neuroimaging Measures for Alzheimer Classification",
      "title_zh": "基于协方差的多尺度神经影像表征学习用于阿尔茨海默症分类",
      "authors": [
        "Seunghun Baek",
        "Injun Choi",
        "Mustafa Dere",
        "Minjeong Kim",
        "Guorong Wu",
        "Won Hwa Kim"
      ],
      "abstract": "Stacking excessive layers in DNN results in highly underdetermined system\nwhen training samples are limited, which is very common in medical\napplications. In this regard, we present a framework capable of deriving an\nefficient high-dimensional space with reasonable increase in model size. This\nis done by utilizing a transform (i.e., convolution) that leverages scale-space\ntheory with covariance structure. The overall model trains on this transform\ntogether with a downstream classifier (i.e., Fully Connected layer) to capture\nthe optimal multi-scale representation of the original data which corresponds\nto task-specific components in a dual space. Experiments on neuroimaging\nmeasures from Alzheimer's Disease Neuroimaging Initiative (ADNI) study show\nthat our model performs better and converges faster than conventional models\neven when the model size is significantly reduced. The trained model is made\ninterpretable using gradient information over the multi-scale transform to\ndelineate personalized AD-specific regions in the brain.",
      "tldr_zh": "本文提出了一种基于协方差的多尺度表征学习方法，用于解决医学影像数据有限时深度神经网络（DNN）训练不足的问题。该方法通过结合尺度空间理论和协方差结构的卷积变换，构建高效的高维表征空间，并配合全连接层分类器捕捉任务相关的多尺度特征。在阿尔茨海默病神经影像学（ADNI）数据集上的实验表明，该模型在显著减小规模的同时，仍能取得更好的分类性能并更快收敛。此外，模型利用多尺度变换的梯度信息实现了可解释性，可定位患者个体化的大脑异常区域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ISBI 2023",
      "pdf_url": "http://arxiv.org/pdf/2503.01232v1",
      "published_date": "2025-03-03 06:55:35 UTC",
      "updated_date": "2025-03-03 06:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:34.847542"
    },
    {
      "arxiv_id": "2503.04800v1",
      "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
      "title_zh": "HoH：评估过时信息对检索增强生成影响的动态基准",
      "authors": [
        "Jie Ouyang",
        "Tingyue Pan",
        "Mingyue Cheng",
        "Ruiran Yan",
        "Yucong Luo",
        "Jiaying Lin",
        "Qi Liu"
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) has emerged as an effective\napproach for addressing the knowledge outdating problem in Large Language\nModels (LLMs), it faces a critical challenge: the prevalence of outdated\ninformation in knowledge bases. Current research primarily focuses on\nincorporating up-to-date information, yet the impact of outdated information\ncoexisting in retrieval sources remains inadequately addressed. To bridge this\ngap, we introduce HoH, the first benchmark specifically designed to evaluate\nthe impact of outdated information on RAG. Our benchmark leverages token-level\ndiff algorithms combined with LLM pipelines to efficiently create a large-scale\nQA dataset that accurately captures temporal knowledge evolution in real-world\nfacts. Through comprehensive experiments, we reveal that outdated information\nsignificantly degrades RAG performance in two critical ways: (1) it\nsubstantially reduces response accuracy by distracting models from correct\ninformation, and (2) it can mislead models into generating potentially harmful\noutputs, even when current information is available. Current RAG approaches\nstruggle with both retrieval and generation aspects when handling outdated\ninformation. These findings highlight the urgent need for innovative solutions\nto address the temporal challenges in RAG.",
      "tldr_zh": "该研究提出了首个专门评估过时信息对检索增强生成(RAG)影响的基准测试HoH。通过结合token差异算法和LLM流程，该团队构建了能准确反映现实世界知识演变的QA数据集。实验发现过时信息会以两种方式显著降低RAG性能：既会分散模型注意力降低准确率，又可能诱导生成有害内容。研究揭示了当前RAG方法在处理时序信息时的重大缺陷，为改进方向提供了重要依据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04800v1",
      "published_date": "2025-03-03 06:54:05 UTC",
      "updated_date": "2025-03-03 06:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:37.524807"
    },
    {
      "arxiv_id": "2503.01220v2",
      "title": "Tera-MIND: Tera-scale mouse brain simulation via spatial mRNA-guided diffusion",
      "title_zh": "Tera-MIND：通过空间mRNA引导扩散实现太尺度小鼠大脑模拟",
      "authors": [
        "Jiqing Wu",
        "Ingrid Berg",
        "Yawei Li",
        "Ender Konukoglu",
        "Viktor H. Koelzer"
      ],
      "abstract": "Holistic 3D modeling of molecularly defined brain structures is crucial for\nunderstanding complex brain functions. Emerging tissue profiling technologies\nenable the construction of a comprehensive atlas of the mammalian brain with\nsub-cellular resolution and spatially resolved gene expression data. However,\nsuch tera-scale volumetric datasets present significant computational\nchallenges in understanding complex brain functions within their native 3D\nspatial context. Here, we propose the novel generative approach\n$\\textbf{Tera-MIND}$, which can simulate $\\textbf{Tera}$-scale $\\textbf{M}$ouse\nbra$\\textbf{IN}$s in 3D using a patch-based and boundary-aware\n$\\textbf{D}$iffusion model. Taking spatial transcriptomic data as the\nconditional input, we generate virtual mouse brains with comprehensive cellular\nmorphological detail at teravoxel scale. Through the lens of 3D $gene$-$gene$\nself-attention, we identify spatial molecular interactions for key\ntranscriptomic pathways in the murine brain, exemplified by glutamatergic and\ndopaminergic neuronal systems. Importantly, these $in$-$silico$ biological\nfindings are consistent and reproducible across three tera-scale virtual mouse\nbrains. Therefore, Tera-MIND showcases a promising path toward efficient and\ngenerative simulations of whole organ systems for biomedical research. Project\nwebsite: https://musikisomorphie.github.io/Tera-MIND.html",
      "tldr_zh": "该研究提出了Tera-MIND方法，一种基于空间mRNA引导扩散的万亿级小鼠大脑模拟技术。该方法采用分块边界感知扩散模型，以空间转录组数据为条件输入，生成具有完整细胞形态细节的万亿体素级虚拟小鼠大脑。通过3D基因-基因自注意力机制，研究揭示了小鼠大脑中关键转录通路的空间分子相互作用，特别是在谷氨酸能和多巴胺能神经元系统中的发现。这些计算机模拟结果在三个万亿级虚拟大脑中均表现出高度一致性和可重复性，为生物医学研究的全器官系统高效生成式模拟开辟了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01220v2",
      "published_date": "2025-03-03 06:37:30 UTC",
      "updated_date": "2025-03-04 06:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:58.922058"
    },
    {
      "arxiv_id": "2503.04798v1",
      "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)",
      "title_zh": "推动MAPF迈向现实世界：可扩展的多智能体真实测试平台（SMART）",
      "authors": [
        "Jingtian Yan",
        "Zhifei Li",
        "William Kang",
        "Yulun Zhang",
        "Stephen Smith",
        "Jiaoyang Li"
      ],
      "abstract": "We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and\nefficient software tool for evaluating Multi-Agent Path Finding (MAPF)\nalgorithms. MAPF focuses on planning collision-free paths for a group of\nagents. While state-of-the-art MAPF algorithms can plan paths for hundreds of\nrobots in seconds, they often rely on simplified robot models, making their\nreal-world performance unclear. Researchers typically lack access to hundreds\nof physical robots in laboratory settings to evaluate the algorithms.\nMeanwhile, industrial professionals who lack expertise in MAPF require an\neasy-to-use simulator to efficiently test and understand the performance of\nMAPF algorithms in their specific settings. SMART fills this gap with several\nadvantages: (1) SMART uses a physics-engine-based simulator to create realistic\nsimulation environments, accounting for complex real-world factors such as\nrobot kinodynamics and execution uncertainties, (2) SMART uses an execution\nmonitor framework based on the Action Dependency Graph, facilitating seamless\nintegration with various MAPF algorithms and robot models, and (3) SMART scales\nto thousands of robots. In addition, we use SMART to explore and demonstrate\nresearch questions about the execution of MAPF algorithms in real-world\nscenarios. The code is publicly available at\nhttps://jingtianyan.github.io/publication/2025-smart.",
      "tldr_zh": "该研究提出了SMART（Scalable Multi-Agent Realistic Testbed），一个面向真实世界的多智能体路径规划（MAPF）算法评估平台。SMART通过基于物理引擎的模拟器，考虑机器人动力学和执行不确定性等复杂因素，创建了高度真实的仿真环境。其执行监控框架基于动作依赖图（Action Dependency Graph），支持多种MAPF算法和机器人模型的集成，并可扩展至数千个机器人。SMART为研究人员和工业从业者提供了一个易于使用的工具，用于测试和理解MAPF算法在真实场景中的性能。代码已开源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04798v1",
      "published_date": "2025-03-03 05:26:59 UTC",
      "updated_date": "2025-03-03 05:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:58.581213"
    },
    {
      "arxiv_id": "2503.01935v1",
      "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
      "title_zh": "MultiAgentBench：评估LLM智能体协作与竞争的基准",
      "authors": [
        "Kunlun Zhu",
        "Hongyi Du",
        "Zhaochen Hong",
        "Xiaocheng Yang",
        "Shuyi Guo",
        "Zhe Wang",
        "Zhenhailong Wang",
        "Cheng Qian",
        "Xiangru Tang",
        "Heng Ji",
        "Jiaxuan You"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous\nagents, yet existing benchmarks either focus on single-agent tasks or are\nconfined to narrow domains, failing to capture the dynamics of multi-agent\ncoordination and competition. In this paper, we introduce MultiAgentBench, a\ncomprehensive benchmark designed to evaluate LLM-based multi-agent systems\nacross diverse, interactive scenarios. Our framework measures not only task\ncompletion but also the quality of collaboration and competition using novel,\nmilestone-based key performance indicators. Moreover, we evaluate various\ncoordination protocols (including star, chain, tree, and graph topologies) and\ninnovative strategies such as group discussion and cognitive planning. Notably,\ngpt-4o-mini reaches the average highest task score, graph structure performs\nthe best among coordination protocols in the research scenario, and cognitive\nplanning improves milestone achievement rates by 3%. Code and datasets are\npublic available at https://github.com/MultiagentBench/MARBLE.",
      "tldr_zh": "该研究提出了MultiAgentBench，一个专门用于评估大语言模型(LLMs)在多智能体系统中协作与竞争能力的综合性基准测试。该框架通过多样化的交互场景，不仅衡量任务完成度，还使用基于里程碑的关键绩效指标来评估协作与竞争的质量。研究测试了多种协调协议（如星型、链式、树状和图状拓扑）和创新策略（如小组讨论和认知规划），发现图结构在研究场景中表现最佳，而认知规划将里程碑达成率提高了3%。相关代码和数据集已开源。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "https://github.com/MultiagentBench/MARBLE",
      "pdf_url": "http://arxiv.org/pdf/2503.01935v1",
      "published_date": "2025-03-03 05:18:50 UTC",
      "updated_date": "2025-03-03 05:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:25:56.946706"
    },
    {
      "arxiv_id": "2503.05797v1",
      "title": "Fault Localization and State Estimation of Power Grid under Parallel Cyber-Physical Attacks",
      "title_zh": "并行网络物理攻击下电网的故障定位与状态估计",
      "authors": [
        "Junhao Ren",
        "Kai Zhao",
        "Guangxiao Zhang",
        "Xinghua Liu",
        "Chao Zhai",
        "Gaoxi Xiao"
      ],
      "abstract": "Parallel cyber-physical attacks (PCPA) refer to those attacks on power grids\nby disturbing/cutting off physical transmission lines and meanwhile blocking\ntransmission of measurement data to dwarf or delay the system protection and\nrecovery actions. Such fierce hostile attacks impose critical threats to the\nmodern power grids when there is a fusion of power grids and telecommunication\ntechnologies. In this paper, we investigate the fault diagnosis problem of\nfaulty transmission lines under a broader spectrum of PCPA for a linearized (or\nDC) power flow model. The physical attack mechanism of PCPA includes not only\ndisconnection but also admittance value modification on transmission lines, for\nexample, by invading distributed flexible AC transmission system (D-FACTS). To\ntackle the problem, we first recover the information of voltage phase angles\nwithin the attacked area. Using the information of voltage phase angle and\npower injection of buses, a graph attention network-based fault localization\n(GAT-FL) algorithm is proposed to find the locations of the physical attacks.\nBy capitalizing on the feature extraction capability of the GAT on graph data,\nthe fault localization algorithm outperforms the existing results when under\ncyber attacks, e.g., denial of service (DoS) attacks. A line state\nidentification algorithm is then developed to identify the states of the\ntransmission lines within the attacked area. Specifically, the algorithm\nrestores the power injection of buses within the attacked area and then\nidentities the state of all the transmission lines within the attacked area by\nsolving a linear programming (LP) problem. Experimental simulations are\neffectiveness of the proposed fault diagnosis algorithms.",
      "tldr_zh": "该论文研究了电力系统在并行网络物理攻击（PCPA）下的故障定位与状态估计问题。针对攻击同时破坏物理输电线路和阻断测量数据传输的特点，提出了一种基于图注意力网络（GAT）的故障定位算法（GAT-FL），利用电压相位角和节点功率注入信息，有效定位物理攻击位置。此外，开发了一种输电线路状态识别算法，通过线性规划（LP）问题恢复攻击区域内节点的功率注入并识别线路状态。实验表明，所提算法在应对拒绝服务（DoS）等网络攻击时优于现有方法。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "10 pages, 3 figures, 5 tables, journal",
      "pdf_url": "http://arxiv.org/pdf/2503.05797v1",
      "published_date": "2025-03-03 05:10:41 UTC",
      "updated_date": "2025-03-03 05:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:26:45.677612"
    },
    {
      "arxiv_id": "2503.02897v1",
      "title": "ClipGrader: Leveraging Vision-Language Models for Robust Label Quality Assessment in Object Detection",
      "title_zh": "ClipGrader：利用视觉-语言模型实现目标检测中标签质量的稳健评估",
      "authors": [
        "Hong Lu",
        "Yali Bian",
        "Rahul C. Shah"
      ],
      "abstract": "High-quality annotations are essential for object detection models, but\nensuring label accuracy - especially for bounding boxes - remains both\nchallenging and costly. This paper introduces ClipGrader, a novel approach that\nleverages vision-language models to automatically assess the accuracy of\nbounding box annotations. By adapting CLIP (Contrastive Language-Image\nPre-training) to evaluate both class label correctness and spatial precision of\nbounding box, ClipGrader offers an effective solution for grading object\ndetection labels. Tested on modified object detection datasets with\nartificially disturbed bounding boxes, ClipGrader achieves 91% accuracy on COCO\nwith a 1.8% false positive rate. Moreover, it maintains 87% accuracy with a\n2.1% false positive rate when trained on just 10% of the COCO data. ClipGrader\nalso scales effectively to larger datasets such as LVIS, achieving 79% accuracy\nacross 1,203 classes. Our experiments demonstrate ClipGrader's ability to\nidentify errors in existing COCO annotations, highlighting its potential for\ndataset refinement. When integrated into a semi-supervised object detection\n(SSOD) model, ClipGrader readily improves the pseudo label quality, helping\nachieve higher mAP (mean Average Precision) throughout the training process.\nClipGrader thus provides a scalable AI-assisted tool for enhancing annotation\nquality control and verifying annotations in large-scale object detection\ndatasets.",
      "tldr_zh": "本文提出了ClipGrader，一种基于视觉语言模型(Vision-Language Models)的自动标注质量评估方法，用于评估目标检测中边界框标注的准确性和空间精度。通过改进CLIP模型，ClipGrader在COCO数据集上实现了91%的准确率和1.8%的误报率，并在仅使用10%数据训练时仍保持87%的准确率。实验表明，ClipGrader不仅能有效识别现有COCO标注中的错误，还能提升半监督目标检测(SSOD)模型的伪标签质量，从而提高训练过程中的平均精度(mAP)。该工具为大尺度目标检测数据集的标注质量控制提供了可扩展的AI辅助解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02897v1",
      "published_date": "2025-03-03 05:02:31 UTC",
      "updated_date": "2025-03-03 05:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:26:15.531529"
    },
    {
      "arxiv_id": "2503.05796v1",
      "title": "Towards Multi-Stakeholder Evaluation of ML Models: A Crowdsourcing Study on Metric Preferences in Job-matching System",
      "title_zh": "迈向多利益相关者的机器学习模型评估：基于众包研究的职位匹配系统指标偏好分析",
      "authors": [
        "Takuya Yokota",
        "Yuri Nakao"
      ],
      "abstract": "While machine learning (ML) technology affects diverse stakeholders, there is\nno one-size-fits-all metric to evaluate the quality of outputs, including\nperformance and fairness. Using predetermined metrics without soliciting\nstakeholder opinions is problematic because it leads to an unfair disregard for\nstakeholders in the ML pipeline. In this study, to establish practical ways to\nincorporate diverse stakeholder opinions into the selection of metrics for ML,\nwe investigate participants' preferences for different metrics by using\ncrowdsourcing. We ask 837 participants to choose a better model from two\nhypothetical ML models in a hypothetical job-matching system twenty times and\ncalculate their utility values for seven metrics. To examine the participants'\nfeedback in detail, we divide them into five clusters based on their utility\nvalues and analyze the tendencies of each cluster, including their preferences\nfor metrics and common attributes. Based on the results, we discuss the points\nthat should be considered when selecting appropriate metrics and evaluating ML\nmodels with multiple stakeholders.",
      "tldr_zh": "本研究通过众包实验探索了在求职匹配系统中多利益相关者对机器学习（ML）模型评估指标的选择偏好。研究邀请了837名参与者从两个假设的ML模型中选择更优模型，并计算他们对七种指标的效用值。通过将参与者分为五个聚类，分析了不同群体的指标偏好和共同属性。研究结果为在多利益相关者场景下选择合适的评估指标和评估ML模型提供了实践指导，强调了在ML管道中纳入利益相关者意见的重要性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This version of the contribution has been accepted for publication,\n  after peer review (when applicable) but is not the Version of Record and does\n  not reflect post-acceptance improvements, or any corrections. Use of this\n  Accepted Version is subject to the publisher's Accepted Manuscript terms of\n  use\n  https://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms",
      "pdf_url": "http://arxiv.org/pdf/2503.05796v1",
      "published_date": "2025-03-03 04:51:33 UTC",
      "updated_date": "2025-03-03 04:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:26:24.562413"
    },
    {
      "arxiv_id": "2503.01176v1",
      "title": "Prognostics and Health Management of Wafer Chemical-Mechanical Polishing System using Autoencoder",
      "title_zh": "基于自动编码器的晶圆化学机械抛光系统预测与健康管理",
      "authors": [
        "Kart-Leong Lim",
        "Rahul Dutta"
      ],
      "abstract": "The Prognostics and Health Management Data Challenge (PHM) 2016 tracks the\nhealth state of components of a semiconductor wafer polishing process. The\nultimate goal is to develop an ability to predict the measurement on the wafer\nsurface wear through monitoring the components health state. This translates to\ncost saving in large scale production. The PHM dataset contains many time\nseries measurements not utilized by traditional physics based approach. On the\nother hand task, applying a data driven approach such as deep learning to the\nPHM dataset is non-trivial. The main issue with supervised deep learning is\nthat class label is not available to the PHM dataset. Second, the feature space\ntrained by an unsupervised deep learner is not specifically targeted at the\npredictive ability or regression. In this work, we propose using the\nautoencoder based clustering whereby the feature space trained is found to be\nmore suitable for performing regression. This is due to having a more compact\ndistribution of samples respective to their nearest cluster means. We justify\nour claims by comparing the performance of our proposed method on the PHM\ndataset with several baselines such as the autoencoder as well as\nstate-of-the-art approaches.",
      "tldr_zh": "该研究提出了一种基于自动编码器(autoencoder)的聚类方法，用于半导体晶圆化学机械抛光(CMP)系统的故障预测与健康管理(PHM)。针对PHM 2016数据集中缺乏类别标签的问题，该方法通过无监督学习构建更紧凑的特征空间分布，相比传统物理方法和现有深度学习方案更适合回归预测任务。实验表明，该方法在晶圆表面磨损预测任务上优于自动编码器和现有最优方法，为大规模半导体生产提供了有效的成本节约方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01176v1",
      "published_date": "2025-03-03 04:48:34 UTC",
      "updated_date": "2025-03-03 04:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:27:16.016425"
    },
    {
      "arxiv_id": "2503.01163v1",
      "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers",
      "title_zh": "基于多臂赌博机的提示设计策略选择优化提升提示优化器性能",
      "authors": [
        "Rin Ashizawa",
        "Yoichi Hirose",
        "Nozomu Yoshinari",
        "Kento Uchida",
        "Shinichi Shirakawa"
      ],
      "abstract": "Prompt optimization aims to search for effective prompts that enhance the\nperformance of large language models (LLMs). Although existing prompt\noptimization methods have discovered effective prompts, they often differ from\nsophisticated prompts carefully designed by human experts. Prompt design\nstrategies, representing best practices for improving prompt performance, can\nbe key to improving prompt optimization. Recently, a method termed the\nAutonomous Prompt Engineering Toolbox (APET) has incorporated various prompt\ndesign strategies into the prompt optimization process. In APET, the LLM is\nneeded to implicitly select and apply the appropriate strategies because prompt\ndesign strategies can have negative effects. This implicit selection may be\nsuboptimal due to the limited optimization capabilities of LLMs. This paper\nintroduces Optimizing Prompts with sTrategy Selection (OPTS), which implements\nexplicit selection mechanisms for prompt design. We propose three mechanisms,\nincluding a Thompson sampling-based approach, and integrate them into\nEvoPrompt, a well-known prompt optimizer. Experiments optimizing prompts for\ntwo LLMs, Llama-3-8B-Instruct and GPT-4o mini, were conducted using BIG-Bench\nHard. Our results show that the selection of prompt design strategies improves\nthe performance of EvoPrompt, and the Thompson sampling-based mechanism\nachieves the best overall results. Our experimental code is provided at\nhttps://github.com/shiralab/OPTS .",
      "tldr_zh": "本研究提出了OPTS（Optimizing Prompts with sTrategy Selection），通过显式选择机制改进提示词优化。该方法整合了三种策略选择机制，包括基于Thompson采样的方法，并将其应用于知名提示词优化器EvoPrompt中。实验在Llama-3-8B-Instruct和GPT-4o mini两个大语言模型上使用BIG-Bench Hard数据集进行，结果表明，显式策略选择显著提升了EvoPrompt的性能，其中Thompson采样机制表现最佳。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01163v1",
      "published_date": "2025-03-03 04:24:04 UTC",
      "updated_date": "2025-03-03 04:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:27:33.247783"
    },
    {
      "arxiv_id": "2503.01152v1",
      "title": "STGAN: Spatial-temporal Graph Autoregression Network for Pavement Distress Deterioration Prediction",
      "title_zh": "STGAN：基于时空图自回归网络的路面病害恶化预测",
      "authors": [
        "Shilin Tong",
        "Difei Wu",
        "Xiaona Liu",
        "Le Zheng",
        "Yuchuan Du",
        "Difan Zou"
      ],
      "abstract": "Pavement distress significantly compromises road integrity and poses risks to\ndrivers. Accurate prediction of pavement distress deterioration is essential\nfor effective road management, cost reduction in maintenance, and improvement\nof traffic safety. However, real-world data on pavement distress is usually\ncollected irregularly, resulting in uneven, asynchronous, and sparse\nspatial-temporal datasets. This hinders the application of existing\nspatial-temporal models, such as DCRNN, since they are only applicable to\nregularly and synchronously collected data. To overcome these challenges, we\npropose the Spatial-Temporal Graph Autoregression Network (STGAN), a novel\ngraph neural network model designed for accurately predicting irregular\npavement distress deterioration using complex spatial-temporal data.\nSpecifically, STGAN integrates the temporal domain into the spatial domain,\ncreating a larger graph where nodes are represented by spatial-temporal tuples\nand edges are formed based on a similarity-based connection mechanism.\nFurthermore, based on the constructed spatiotemporal graph, we formulate\npavement distress deterioration prediction as a graph autoregression task,\ni.e., the graph size increases incrementally and the prediction is performed\nsequentially. This is accomplished by a novel spatial-temporal attention\nmechanism deployed by STGAN. Utilizing the ConTrack dataset, which contains\npavement distress records collected from different locations in Shanghai, we\ndemonstrate the superior performance of STGAN in capturing spatial-temporal\ncorrelations and addressing the aforementioned challenges. Experimental results\nfurther show that STGAN outperforms baseline models, and ablation studies\nconfirm the effectiveness of its novel modules. Our findings contribute to\npromoting proactive road maintenance decision-making and ultimately enhancing\nroad safety and resilience.",
      "tldr_zh": "该研究提出了STGAN（时空图自回归网络），一种用于预测路面病害恶化的新型图神经网络模型。STGAN通过将时间域整合到空间域中，构建了一个更大的图，其中节点由时空元组表示，边基于相似性连接机制形成，并采用时空注意力机制进行自回归预测。实验表明，STGAN在捕捉时空相关性方面表现出色，优于现有基线模型，为主动式道路维护决策提供了有力支持，从而提升道路安全性和耐久性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 16 figures, 4 tables, accepted by IEEE Transactions on\n  Intelligent Transportation Systems (TITS)",
      "pdf_url": "http://arxiv.org/pdf/2503.01152v1",
      "published_date": "2025-03-03 03:59:34 UTC",
      "updated_date": "2025-03-03 03:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:27:46.040356"
    },
    {
      "arxiv_id": "2503.01151v1",
      "title": "ReaderLM-v2: Small Language Model for HTML to Markdown and JSON",
      "title_zh": "ReaderLM-v2：面向HTML转Markdown与JSON的小型语言模型",
      "authors": [
        "Feng Wang",
        "Zesheng Shi",
        "Bo Wang",
        "Nan Wang",
        "Han Xiao"
      ],
      "abstract": "We present ReaderLM-v2, a compact 1.5 billion parameter language model\ndesigned for efficient web content extraction. Our model processes documents up\nto 512K tokens, transforming messy HTML into clean Markdown or JSON formats\nwith high accuracy -- making it an ideal tool for grounding large language\nmodels. The model's effectiveness results from two key innovations: (1) a\nthree-stage data synthesis pipeline that generates high quality, diverse\ntraining data by iteratively drafting, refining, and critiquing web content\nextraction; and (2) a unified training framework combining continuous\npre-training with multi-objective optimization. Intensive evaluation\ndemonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger\nmodels by 15-20\\% on carefully curated benchmarks, particularly excelling at\ndocuments exceeding 100K tokens, while maintaining significantly lower\ncomputational requirements.",
      "tldr_zh": "该研究提出了ReaderLM-v2，一个仅有15亿参数的小型语言模型，专注于高效提取网页内容，将复杂的HTML转换为简洁的Markdown或JSON格式。其核心创新包括：三阶段数据合成管道，通过迭代生成高质量、多样化的训练数据；以及结合持续预训练和多目标优化的统一训练框架。实验表明，ReaderLM-v2在处理超过10万token的文档时，性能优于GPT-4等更大模型15-20%，同时计算资源需求显著降低。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68T50",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 10-12 refs",
      "pdf_url": "http://arxiv.org/pdf/2503.01151v1",
      "published_date": "2025-03-03 03:57:04 UTC",
      "updated_date": "2025-03-03 03:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:12.057787"
    },
    {
      "arxiv_id": "2503.01148v1",
      "title": "Dynamic spillovers and investment strategies across artificial intelligence ETFs, artificial intelligence tokens, and green markets",
      "title_zh": "人工智能ETF、人工智能代币与绿色市场间的动态溢出效应及投资策略",
      "authors": [
        "Ying-Hui Shao",
        "Yan-Hong Yang",
        "Wei-Xing Zhou"
      ],
      "abstract": "This paper investigates the risk spillovers among AI ETFs, AI tokens, and\ngreen markets using the R2 decomposition method. We reveal several key\ninsights. First, the overall transmission connectedness index (TCI) closely\naligns with the contemporaneous TCI, while the lagged TCI is significantly\nlower. Second, AI ETFs and clean energy act as risk transmitters, whereas AI\ntokens and green bond function as risk receivers. Third, AI tokens are\ndifficult to hedge and provide limited hedging ability compared to AI ETFs and\ngreen assets. However, multivariate portfolios effectively reduce AI tokens\ninvestment risk. Among them, the minimum correlation portfolio outperforms the\nminimum variance and minimum connectedness portfolios.",
      "tldr_zh": "本研究采用R2分解方法分析人工智能ETF、AI代币与绿色市场间的风险溢出效应，揭示三个关键发现：(1)总体传染关联指数(TCI)主要由同期效应主导，滞后效应显著较弱；(2)AI ETF和清洁能源市场是主要风险输出源，而AI代币与绿色债券则充当风险接收方；(3)相比AI ETF和绿色资产，AI代币对冲难度大且效果有限，但多元投资组合能有效降低其风险，其中最小相关性组合表现优于最小方差和最小关联度组合。",
      "categories": [
        "q-fin.RM",
        "cs.AI"
      ],
      "primary_category": "q-fin.RM",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01148v1",
      "published_date": "2025-03-03 03:53:33 UTC",
      "updated_date": "2025-03-03 03:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:04.336094"
    },
    {
      "arxiv_id": "2503.01144v1",
      "title": "One-shot In-context Part Segmentation",
      "title_zh": "单样本上下文部件分割",
      "authors": [
        "Zhenqi Dai",
        "Ting Liu",
        "Xingxing Zhang",
        "Yunchao Wei",
        "Yanning Zhang"
      ],
      "abstract": "In this paper, we present the One-shot In-context Part Segmentation (OIParts)\nframework, designed to tackle the challenges of part segmentation by leveraging\nvisual foundation models (VFMs). Existing training-based one-shot part\nsegmentation methods that utilize VFMs encounter difficulties when faced with\nscenarios where the one-shot image and test image exhibit significant variance\nin appearance and perspective, or when the object in the test image is\npartially visible. We argue that training on the one-shot example often leads\nto overfitting, thereby compromising the model's generalization capability. Our\nframework offers a novel approach to part segmentation that is training-free,\nflexible, and data-efficient, requiring only a single in-context example for\nprecise segmentation with superior generalization ability. By thoroughly\nexploring the complementary strengths of VFMs, specifically DINOv2 and Stable\nDiffusion, we introduce an adaptive channel selection approach by minimizing\nthe intra-class distance for better exploiting these two features, thereby\nenhancing the discriminatory power of the extracted features for the\nfine-grained parts. We have achieved remarkable segmentation performance across\ndiverse object categories. The OIParts framework not only eliminates the need\nfor extensive labeled data but also demonstrates superior generalization\nability. Through comprehensive experimentation on three benchmark datasets, we\nhave demonstrated the superiority of our proposed method over existing part\nsegmentation approaches in one-shot settings.",
      "tldr_zh": "本文提出One-shot In-context Part Segmentation (OIParts)框架，利用视觉基础模型(VFMs)实现无需训练的one-shot部件分割。该方法通过整合DINOv2和Stable Diffusion特征，采用自适应通道选择策略最小化类内距离，有效解决了现有方法在面对视角差异或部分遮挡时的泛化问题。在三个基准数据集上的实验表明，该框架仅需单张示例图像即可实现精确分割，性能优于现有one-shot部件分割方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01144v1",
      "published_date": "2025-03-03 03:50:54 UTC",
      "updated_date": "2025-03-03 03:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:13.662360"
    },
    {
      "arxiv_id": "2503.01141v1",
      "title": "How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach",
      "title_zh": "大语言模型如何压缩其自身的链式思维？基于标记复杂度的研究",
      "authors": [
        "Ayeong Lee",
        "Ethan Che",
        "Tianyi Peng"
      ],
      "abstract": "Chain-of-thought prompting has emerged as a powerful technique for enabling\nlarge language models (LLMs) to solve complex reasoning tasks. However, these\nreasoning chains can be verbose, raising concerns about efficiency. In\nresponse, recent works have sought to decrease response lengths through simple\nprompting strategies (e.g. 'be concise'). In this work, we conduct the first\nsystematic study of the relationship between reasoning length and model\nperformance across a diverse range of compression instructions (e.g. 'use 10\nwords or less' or 'remove all punctuation'). In doing so, we discover a\nuniversal tradeoff between reasoning length and accuracy that persists across\neven very distinct reasoning chains. We demonstrate that this tradeoff emerges\nfrom a sharp threshold behavior at the question level: each task has an\nintrinsic 'token complexity' - a minimal number of tokens required for\nsuccessful problem-solving. We show how token complexity enables us to compute\ninformation-theoretic limits on the accuracy-compression tradeoff, and find\nthat prompt-based compression strategies operate far from these theoretical\nlimits. This suggests there may be significant room for improvement and our\nframework provides a benchmark to help researchers evaluate progress in\nreasoning efficiency. Our work also highlights the importance of adaptive\ncompression -- giving shorter responses for easier questions -- and we show\nthat token complexity is a useful tool for measuring this capability.",
      "tldr_zh": "本研究首次系统性地探讨了大语言模型(LLMs)在链式思维推理(Chain-of-Thought)中的压缩效率与性能之间的关系。研究发现，推理长度与准确性之间存在普遍权衡，且每个任务具有内在的\"token complexity\"——成功解决问题所需的最小token数量。研究提出了基于token complexity的信息论极限框架，揭示了当前基于提示的压缩策略与理论极限存在显著差距，表明推理效率仍有较大提升空间。此外，研究强调了自适应压缩的重要性，并证明token complexity是衡量这一能力的有效工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01141v1",
      "published_date": "2025-03-03 03:48:20 UTC",
      "updated_date": "2025-03-03 03:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:14.624541"
    },
    {
      "arxiv_id": "2503.01139v2",
      "title": "Can Large Language Models Help Experimental Design for Causal Discovery?",
      "title_zh": "大型语言模型能否助力因果发现的实验设计？",
      "authors": [
        "Junyi Li",
        "Yongqiang Chen",
        "Chenxi Liu",
        "Qianyi Cai",
        "Tongliang Liu",
        "Bo Han",
        "Kun Zhang",
        "Hui Xiong"
      ],
      "abstract": "Designing proper experiments and selecting optimal intervention targets is a\nlongstanding problem in scientific or causal discovery. Identifying the\nunderlying causal structure from observational data alone is inherently\ndifficult. Obtaining interventional data, on the other hand, is crucial to\ncausal discovery, yet it is usually expensive and time-consuming to gather\nsufficient interventional data to facilitate causal discovery. Previous\napproaches commonly utilize uncertainty or gradient signals to determine the\nintervention targets. However, numerical-based approaches may yield suboptimal\nresults due to the inaccurate estimation of the guiding signals at the\nbeginning when with limited interventional data. In this work, we investigate a\ndifferent approach, whether we can leverage Large Language Models (LLMs) to\nassist with the intervention targeting in causal discovery by making use of the\nrich world knowledge about the experimental design in LLMs. Specifically, we\npresent Large Language Model Guided Intervention Targeting (LeGIT) -- a robust\nframework that effectively incorporates LLMs to augment existing numerical\napproaches for the intervention targeting in causal discovery. Across 4\nrealistic benchmark scales, LeGIT demonstrates significant improvements and\nrobustness over existing methods and even surpasses humans, which demonstrates\nthe usefulness of LLMs in assisting with experimental design for scientific\ndiscovery.",
      "tldr_zh": "该研究探讨了利用大型语言模型(LLMs)辅助因果发现中的实验设计问题，提出了LeGIT框架。通过结合LLMs的世界知识和传统数值方法，LeGIT优化了干预目标的选择，显著提升了因果发现的效果。在四个实际基准测试中，LeGIT不仅优于现有方法，甚至超越了人类表现，证明了LLMs在科学实验设计中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01139v2",
      "published_date": "2025-03-03 03:43:05 UTC",
      "updated_date": "2025-03-04 04:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:14.369326"
    },
    {
      "arxiv_id": "2503.01134v1",
      "title": "Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs",
      "title_zh": "部分可观测马尔可夫决策过程中历史依赖策略的离策略评估统计可处理性",
      "authors": [
        "Yuheng Zhang",
        "Nan Jiang"
      ],
      "abstract": "We investigate off-policy evaluation (OPE), a central and fundamental problem\nin reinforcement learning (RL), in the challenging setting of Partially\nObservable Markov Decision Processes (POMDPs) with large observation spaces.\nRecent works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a\nmodel-free framework and identified important coverage assumptions (called\nbelief and outcome coverage) that enable accurate OPE of memoryless policies\nwith polynomial sample complexities, but handling more general target policies\nthat depend on the entire observable history remained an open problem. In this\nwork, we prove information-theoretic hardness for model-free OPE of\nhistory-dependent policies in several settings, characterized by additional\nassumptions imposed on the behavior policy (memoryless vs. history-dependent)\nand/or the state-revealing property of the POMDP (single-step vs. multi-step\nrevealing). We further show that some hardness can be circumvented by a natural\nmodel-based algorithm -- whose analysis has surprisingly eluded the literature\ndespite the algorithm's simplicity -- demonstrating provable separation between\nmodel-free and model-based OPE in POMDPs.",
      "tldr_zh": "本研究探讨了在部分可观测马尔可夫决策过程（POMDPs）中，对依赖历史的目标策略进行离策略评估（OPE）的统计可处理性问题。研究发现，在多种设置下，模型无关的OPE对历史依赖策略存在信息理论上的困难，但通过一种简单的基于模型的算法可以部分规避这些困难。这揭示了POMDPs中模型无关与基于模型的OPE之间的可证明分离，为复杂RL问题的解决提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01134v1",
      "published_date": "2025-03-03 03:29:05 UTC",
      "updated_date": "2025-03-03 03:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:26.186706"
    },
    {
      "arxiv_id": "2503.01131v1",
      "title": "Beyond QA Pairs: Assessing Parameter-Efficient Fine-Tuning for Fact Embedding in LLMs",
      "title_zh": "超越问答对：评估参数高效微调在大型语言模型中的事实嵌入效果",
      "authors": [
        "Shivam Ratnakar",
        "Abhiroop Talasila",
        "Raghav Chamadiya",
        "Nikhil Agarwal",
        "Vinayak K Doifode"
      ],
      "abstract": "This paper presents an extensive examination of Parameter-Efficient\nFine-Tuning (PEFT) for embedding domain specific facts into Large Language\nModels (LLMs), focusing on improving the fine-tuning process by categorizing\nquestion-answer (QA) pairs into Factual and Conceptual classes using a\nBERT-based classifier. Two distinct Llama-2 models are fine-tuned based on\nthese classifications and evaluated using larger models like GPT-3.5 Turbo and\nGemini. Our results indicate that models trained on conceptual datasets\noutperform those trained on factual datasets. Additionally, we compare the\nefficiency of two synthetic fine-tuning dataset generation techniques, D-RAG\nand D-Naive, with D-Naive demonstrating superior performance. Although PEFT has\nshown effectiveness, our research indicates that it may not be the most optimal\nmethod for embedding facts into LLMs. However, it has demonstrated exceptional\nperformance in instruction-based tasks. Our findings are reinforced by a\n1000-sample dataset in the data center domain, where the fine-tuned Llama-2 7B\nmodel significantly outperforms the baseline model in generating product\nrecommendations. Our study highlights the importance of QA pair categorization\nand synthetic dataset generation techniques in enhancing the performance of\nLLMs in specific domains.",
      "tldr_zh": "本研究深入探讨了参数高效微调(PEFT)在将领域特定事实嵌入大型语言模型(LLMs)中的应用。通过使用BERT分类器将问答对分为事实类和概念类，并对Llama-2模型进行微调，研究发现基于概念类数据集训练的模型表现优于事实类数据集。此外，比较了两种合成微调数据集生成技术(D-RAG和D-Naive)，发现D-Naive效果更佳。结果表明，PEFT在指令型任务中表现出色，但在嵌入事实方面可能并非最优方法。研究还通过数据中心领域的1000样本数据集验证了微调后的Llama-2 7B模型在产品推荐任务中显著优于基线模型，强调了问答对分类和合成数据集生成技术在提升LLMs领域性能中的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at the Workshop on Preparing Good Data for Generative AI:\n  Challenges and Approaches (Good-Data) in conjunction with AAAI 2025. The\n  authors retain the copyright",
      "pdf_url": "http://arxiv.org/pdf/2503.01131v1",
      "published_date": "2025-03-03 03:26:30 UTC",
      "updated_date": "2025-03-03 03:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:34.238889"
    },
    {
      "arxiv_id": "2503.01126v2",
      "title": "Constrained multi-fidelity Bayesian optimization with automatic stop condition",
      "title_zh": "带自动停止条件的约束多保真贝叶斯优化",
      "authors": [
        "Zahra Zanjani Foumani",
        "Ramin Bostanabad"
      ],
      "abstract": "Bayesian optimization (BO) is increasingly employed in critical applications\nto find the optimal design with minimal cost. While BO is known for its sample\nefficiency, relying solely on costly high-fidelity data can still result in\nhigh costs. This is especially the case in constrained search spaces where BO\nmust not only optimize but also ensure feasibility. A related issue in the BO\nliterature is the lack of a systematic stopping criterion. To solve these\nchallenges, we develop a constrained cost-aware multi-fidelity BO (CMFBO)\nframework whose goal is to minimize overall sampling costs by utilizing\ninexpensive low-fidelity sources while ensuring feasibility. In our case, the\nconstraints can change across the data sources and may be even black-box\nfunctions. We also introduce a systematic stopping criterion that addresses the\nlong-lasting issue associated with BO's convergence assessment. Our framework\nis publicly available on GitHub through the GP+ Python package and herein we\nvalidate it's efficacy on multiple benchmark problems.",
      "tldr_zh": "该研究提出了一种带自动停止条件的约束多保真度贝叶斯优化(CMFBO)框架。该方法通过利用低成本低保真度数据源来最小化采样成本，同时处理跨数据源变化的黑盒约束条件。研究者还开发了系统性停止准则，解决了贝叶斯优化中长期存在的收敛评估问题。该框架已在GP+ Python包中开源，并在多个基准问题上验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01126v2",
      "published_date": "2025-03-03 03:13:35 UTC",
      "updated_date": "2025-03-21 22:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:45.978093"
    },
    {
      "arxiv_id": "2503.01931v1",
      "title": "Adversarial Generative Flow Network for Solving Vehicle Routing Problems",
      "title_zh": "对抗性生成流网络在车辆路径规划问题中的应用",
      "authors": [
        "Ni Zhang",
        "Jingfeng Yang",
        "Zhiguang Cao",
        "Xu Chi"
      ],
      "abstract": "Recent research into solving vehicle routing problems (VRPs) has gained\nsignificant traction, particularly through the application of deep\n(reinforcement) learning for end-to-end solution construction. However, many\ncurrent construction-based neural solvers predominantly utilize Transformer\narchitectures, which can face scalability challenges and struggle to produce\ndiverse solutions. To address these limitations, we introduce a novel framework\nbeyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks\n(AGFN). This framework integrates the generative flow network (GFlowNet)-a\nprobabilistic model inherently adept at generating diverse solutions\n(routes)-with a complementary model for discriminating (or evaluating) the\nsolutions. These models are trained alternately in an adversarial manner to\nimprove the overall solution quality, followed by a proposed hybrid decoding\nmethod to construct the solution. We apply the AGFN framework to solve the\ncapacitated vehicle routing problem (CVRP) and travelling salesman problem\n(TSP), and our experimental results demonstrate that AGFN surpasses the popular\nconstruction-based neural solvers, showcasing strong generalization\ncapabilities on synthetic and real-world benchmark instances.",
      "tldr_zh": "本文提出对抗生成流网络（AGFN），用于解决车辆路径规划问题（VRP）。该框架结合生成流网络（GFlowNet）和判别模型，通过对抗训练提升解的质量，并采用混合解码方法构建路径方案。实验表明，AGFN在容量约束车辆路径问题（CVRP）和旅行商问题（TSP）上超越现有基于Transformer的神经求解器，展现出优异的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01931v1",
      "published_date": "2025-03-03 03:06:56 UTC",
      "updated_date": "2025-03-03 03:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:28:59.304139"
    },
    {
      "arxiv_id": "2503.01121v1",
      "title": "Hybrid Metaheuristic Vehicle Routing Problem for Security Dispatch Operations",
      "title_zh": "混合元启发式车辆路径规划在安防调度作业中的应用",
      "authors": [
        "Nguyen Gia Hien Vu",
        "Yifan Tang",
        "Rey Lim",
        "G. Gary Wang"
      ],
      "abstract": "This paper investigates the optimization of the Vehicle Routing Problem for\nSecurity Dispatch (VRPSD). VRPSD focuses on security and patrolling\napplications which involve challenging constraints including precise timing and\nstrict time windows. We propose three algorithms based on different\nmetaheuristics, which are Adaptive Large Neighborhood Search (ALNS), Tabu\nSearch (TS), and Threshold Accepting (TA). The first algorithm combines\nsingle-phase ALNS with TA, the second employs a multiphase ALNS with TA, and\nthe third integrates multiphase ALNS, TS, and TA. Experiments are conducted on\nan instance comprising 251 customer requests. The results demonstrate that the\nthird algorithm, the hybrid multiphase ALNS-TS-TA algorithm, delivers the best\nperformance. This approach simultaneously leverages the large-area search\ncapabilities of ALNS for exploration and effectively escapes local optima when\nthe multiphase ALNS is coupled with TS and TA. Furthermore, in our experiments,\nthe hybrid multiphase ALNS-TS-TA algorithm is the only one that shows potential\nfor improving results with increased computation time across all attempts.",
      "tldr_zh": "本文研究了安全调度车辆路径问题(VRPSD)的优化，针对涉及精确时间和严格时间窗口的巡逻与安全应用提出了三种基于元启发式算法的解决方案。这些算法结合了自适应大邻域搜索(ALNS)、禁忌搜索(TS)和阈值接受(TA)技术，其中第三种算法——多阶段ALNS-TS-TA混合算法表现最佳。实验表明，该算法能够有效利用ALNS的大范围搜索能力进行探索，并通过结合TS和TA避免局部最优解，同时随着计算时间的增加，其性能进一步提升。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01121v1",
      "published_date": "2025-03-03 02:58:49 UTC",
      "updated_date": "2025-03-03 02:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:12.036341"
    },
    {
      "arxiv_id": "2503.01109v1",
      "title": "FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion",
      "title_zh": "FGS-SLAM：基于傅里叶变换的高斯泼溅实时SLAM系统及稀疏-稠密地图融合",
      "authors": [
        "Yansong Xu",
        "Junlin Li",
        "Wei Zhang",
        "Siyu Chen",
        "Shengyong Zhang",
        "Yuquan Leng",
        "Weijia Zhou"
      ],
      "abstract": "3D gaussian splatting has advanced simultaneous localization and mapping\n(SLAM) technology by enabling real-time positioning and the construction of\nhigh-fidelity maps. However, the uncertainty in gaussian position and\ninitialization parameters introduces challenges, often requiring extensive\niterative convergence and resulting in redundant or insufficient gaussian\nrepresentations. To address this, we introduce a novel adaptive densification\nmethod based on Fourier frequency domain analysis to establish gaussian priors\nfor rapid convergence. Additionally, we propose constructing independent and\nunified sparse and dense maps, where a sparse map supports efficient tracking\nvia Generalized Iterative Closest Point (GICP) and a dense map creates\nhigh-fidelity visual representations. This is the first SLAM system leveraging\nfrequency domain analysis to achieve high-quality gaussian mapping in\nreal-time. Experimental results demonstrate an average frame rate of 36 FPS on\nReplica and TUM RGB-D datasets, achieving competitive accuracy in both\nlocalization and mapping.",
      "tldr_zh": "该论文提出了FGS-SLAM，一种基于傅里叶分析的实时SLAM系统，通过高斯泼溅(Gaussian Splatting)技术实现定位与建图。创新点包括：1）采用傅里叶频域分析的自适应致密化方法，建立高斯先验以加速收敛；2）构建独立的稀疏地图（基于GICP算法）与稠密地图（用于高保真视觉表示）融合框架。实验显示系统在Replica和TUM RGB-D数据集上达到36FPS的实时性能，同时保持定位和建图的精度优势，成为首个利用频域分析实现高质量高斯建图的实时SLAM系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01109v1",
      "published_date": "2025-03-03 02:33:39 UTC",
      "updated_date": "2025-03-03 02:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:32.328836"
    },
    {
      "arxiv_id": "2503.01102v1",
      "title": "Ground contact and reaction force sensing for linear policy control of quadruped robot",
      "title_zh": "四足机器人线性策略控制中的地面接触与反作用力感知",
      "authors": [
        "Harshita Mhaske",
        "Aniket Mandhare",
        "Jidong Huang",
        "Yu Bai"
      ],
      "abstract": "Designing robots capable of traversing uneven terrain and overcoming physical\nobstacles has been a longstanding challenge in the field of robotics. Walking\nrobots show promise in this regard due to their agility, redundant DOFs and\nintermittent ground contact of locomoting appendages. However, the complexity\nof walking robots and their numerous DOFs make controlling them extremely\ndifficult and computation heavy. Linear policies trained with reinforcement\nlearning have been shown to perform adequately to enable quadrupedal walking,\nwhile being computationally light weight. The goal of this research is to study\nthe effect of augmentation of observation space of a linear policy with newer\nstate variables on performance of the policy. Since ground contact and reaction\nforces are the primary means of robot-environment interaction, they are\nessential state variables on which the linear policy must be informed.\nExperimental results show that augmenting the observation space with ground\ncontact and reaction force data trains policies with better survivability,\nbetter stability against external disturbances and higher adaptability to\nuntrained conditions.",
      "tldr_zh": "该研究探讨了通过增强线性策略的观测空间来改善四足机器人控制性能的方法。研究表明，将地面接触力和反作用力作为新的状态变量加入观测空间，可以训练出更具生存能力、抗干扰性和适应性的控制策略。实验证明，这种增强的线性策略在未训练条件下表现出更高的稳定性和适应性，为四足机器人在不平坦地形上的行走提供了更有效的控制方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "5 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01102v1",
      "published_date": "2025-03-03 02:04:55 UTC",
      "updated_date": "2025-03-03 02:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:28.757899"
    },
    {
      "arxiv_id": "2503.01100v2",
      "title": "Fence Theorem: Towards Dual-Objective Semantic-Structure Isolation in Preprocessing Phase for 3D Anomaly Detection",
      "title_zh": "栅栏定理：面向3D异常检测预处理阶段的双重目标语义结构隔离",
      "authors": [
        "Hanzhe Liang",
        "Jie Zhou",
        "Xuanxin Chen",
        "Tao Dai",
        "Jinbao Wang",
        "Can Gao"
      ],
      "abstract": "3D anomaly detection (AD) is prominent but difficult due to lacking a unified\ntheoretical foundation for preprocessing design. We establish the Fence\nTheorem, formalizing preprocessing as a dual-objective semantic isolator: (1)\nmitigating cross-semantic interference to the greatest extent feasible and (2)\nconfining anomaly judgments to aligned semantic spaces wherever viable, thereby\nestablishing intra-semantic comparability. Any preprocessing approach achieves\nthis goal through a two-stage process of Emantic-Division and\nSpatial-Constraints stage. Through systematic deconstruction, we theoretically\nand experimentally subsume existing preprocessing methods under this theorem\nvia tripartite evidence: qualitative analyses, quantitative studies, and\nmathematical proofs. Guided by the Fence Theorem, we implement Patch3D,\nconsisting of Patch-Cutting and Patch-Matching modules, to segment semantic\nspaces and consolidate similar ones while independently modeling normal\nfeatures within each space. Experiments on Anomaly-ShapeNet and Real3D-AD with\ndifferent settings demonstrate that progressively finer-grained semantic\nalignment in preprocessing directly enhances point-level AD accuracy, providing\ninverse validation of the theorem's causal logic.",
      "tldr_zh": "该研究提出了\"Fence Theorem\"，为3D异常检测（AD）的预处理阶段建立了首个理论框架，将预处理形式化为具有双重目标的语义隔离器：最大程度减少跨语义干扰，并将异常判断限制在语义对齐的空间内。基于该定理，作者开发了Patch3D方法，通过Patch-Cutting和Patch-Matching模块分割语义空间并独立建模每个空间的正常特征。在Anomaly-ShapeNet和Real3D-AD数据集上的实验表明，预处理中逐步精细的语义对齐能直接提升点级AD准确率，逆向验证了该定理的因果逻辑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01100v2",
      "published_date": "2025-03-03 01:58:11 UTC",
      "updated_date": "2025-03-04 04:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:32.308439"
    },
    {
      "arxiv_id": "2503.01098v1",
      "title": "SolBench: A Dataset and Benchmark for Evaluating Functional Correctness in Solidity Code Completion and Repair",
      "title_zh": "SolBench：用于评估 Solidity 代码补全与修复功能正确性的数据集与基准",
      "authors": [
        "Zaoyu Chen",
        "Haoran Qin",
        "Nuo Chen",
        "Xiangyu Zhao",
        "Lei Xue",
        "Xiapu Luo",
        "Xiao-Ming Wu"
      ],
      "abstract": "Smart contracts are crucial programs on blockchains, and their immutability\npost-deployment makes functional correctness vital. Despite progress in code\ncompletion models, benchmarks for Solidity, the primary smart contract\nlanguage, are lacking. Existing metrics like BLEU do not adequately assess the\nfunctional correctness of generated smart contracts. To fill this gap, we\nintroduce SolBench, a benchmark for evaluating the functional correctness of\nSolidity smart contracts generated by code completion models. SolBench includes\n4,178 functions from 1,155 Ethereum-deployed contracts. Testing advanced models\nrevealed challenges in generating correct code without context, as Solidity\nfunctions rely on context-defined variables and interfaces. To address this, we\npropose a Retrieval-Augmented Code Repair framework. In this framework, an\nexecutor verifies functional correctness, and if necessary, an LLM repairs the\ncode using retrieved snippets informed by executor traces. We conduct a\ncomprehensive evaluation of both closed-source and open-source LLMs across\nvarious model sizes and series to assess their performance in smart contract\ncompletion. The results show that code repair and retrieval techniques\neffectively enhance the correctness of smart contract completion while reducing\ncomputational costs.",
      "tldr_zh": "该研究提出了SolBench——首个专注于评估Solidity智能合约功能正确性的代码补全与修复基准数据集。基于4,178个实际部署的以太坊合约函数，研究发现现有代码补全模型难以生成依赖上下文变量的正确Solidity代码。为此，作者提出检索增强的代码修复框架，通过执行器验证功能正确性，并利用LLM结合检索片段进行修复。实验表明，该框架能有效提升各类LLM模型生成智能合约的正确性，同时降低计算成本。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01098v1",
      "published_date": "2025-03-03 01:55:20 UTC",
      "updated_date": "2025-03-03 01:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:42.945739"
    },
    {
      "arxiv_id": "2503.01086v1",
      "title": "FAIR: Facilitating Artificial Intelligence Resilience in Manufacturing Industrial Internet",
      "title_zh": "FAIR：促进制造工业互联网中的人工智能韧性",
      "authors": [
        "Yingyan Zeng",
        "Ismini Lourentzou",
        "Xinwei Deng",
        "Ran Jin"
      ],
      "abstract": "Artificial intelligence (AI) systems have been increasingly adopted in the\nManufacturing Industrial Internet (MII). Investigating and enabling the AI\nresilience is very important to alleviate profound impact of AI system failures\nin manufacturing and Industrial Internet of Things (IIoT) operations, leading\nto critical decision making. However, there is a wide knowledge gap in defining\nthe resilience of AI systems and analyzing potential root causes and\ncorresponding mitigation strategies. In this work, we propose a novel framework\nfor investigating the resilience of AI performance over time under hazard\nfactors in data quality, AI pipelines, and the cyber-physical layer. The\nproposed method can facilitate effective diagnosis and mitigation strategies to\nrecover AI performance based on a multimodal multi-head self latent attention\nmodel. The merits of the proposed method are elaborated using an MII testbed of\nconnected Aerosol Jet Printing (AJP) machines, fog nodes, and Cloud with\ninference tasks via AI pipelines.",
      "tldr_zh": "该研究提出FAIR框架，旨在提升制造业工业互联网(MII)中人工智能系统的韧性。通过分析数据质量、AI流程和网络物理层中的风险因素，该框架采用多模态多头自潜在注意力模型，为AI性能下降提供诊断和恢复策略。实验基于气溶胶喷射打印(AJP)设备的工业物联网测试平台，验证了该方案在保障关键决策可靠性方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01086v1",
      "published_date": "2025-03-03 01:17:22 UTC",
      "updated_date": "2025-03-03 01:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:51.756552"
    },
    {
      "arxiv_id": "2503.01079v1",
      "title": "Depth-Adaptive Graph Neural Networks via Learnable Bakry-'Emery Curvature",
      "title_zh": "深度自适应图神经网络：基于可学习巴克里-埃默里曲率的方法",
      "authors": [
        "Asela Hevapathige",
        "Ahad N. Zehmakan",
        "Qing Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated strong representation learning\ncapabilities for graph-based tasks. Recent advances on GNNs leverage geometric\nproperties, such as curvature, to enhance its representation capabilities by\nmodeling complex connectivity patterns and information flow within graphs.\nHowever, most existing approaches focus solely on discrete graph topology,\noverlooking diffusion dynamics and task-specific dependencies essential for\neffective learning. To address this, we propose integrating Bakry-\\'Emery\ncurvature, which captures both structural and task-driven aspects of\ninformation propagation. We develop an efficient, learnable approximation\nstrategy, making curvature computation scalable for large graphs. Furthermore,\nwe introduce an adaptive depth mechanism that dynamically adjusts\nmessage-passing layers per vertex based on its curvature, ensuring efficient\npropagation. Our theoretical analysis establishes a link between curvature and\nfeature distinctiveness, showing that high-curvature vertices require fewer\nlayers, while low-curvature ones benefit from deeper propagation. Extensive\nexperiments on benchmark datasets validate the effectiveness of our approach,\nshowing consistent performance improvements across diverse graph learning\ntasks.",
      "tldr_zh": "本研究提出了一种基于可学习Bakry-'Emery曲率的深度自适应图神经网络（GNNs），通过结合图的结构特性和任务驱动的信息传播特性，增强了图表示学习能力。该方法开发了一种高效的曲率近似计算策略，使其适用于大规模图，并引入了一种自适应深度机制，根据节点的曲率动态调整消息传递层数。理论分析表明，高曲率节点需要较少的层数，而低曲率节点则受益于更深层次的传播。实验结果表明，该方法在多种图学习任务中均表现出显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01079v1",
      "published_date": "2025-03-03 00:48:41 UTC",
      "updated_date": "2025-03-03 00:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:29:55.487867"
    },
    {
      "arxiv_id": "2503.01075v1",
      "title": "Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS",
      "title_zh": "应对医学图像重建中条件模型的幻觉问题：DynamicDPS动态去噪后采样方法",
      "authors": [
        "Seunghoi Kim",
        "Henry F. J. Tregidgo",
        "Matteo Figini",
        "Chen Jin",
        "Sarang Joshi",
        "Daniel C. Alexander"
      ],
      "abstract": "Hallucinations are spurious structures not present in the ground truth,\nposing a critical challenge in medical image reconstruction, especially for\ndata-driven conditional models. We hypothesize that combining an unconditional\ndiffusion model with data consistency, trained on a diverse dataset, can reduce\nthese hallucinations. Based on this, we propose DynamicDPS, a diffusion-based\nframework that integrates conditional and unconditional diffusion models to\nenhance low-quality medical images while systematically reducing\nhallucinations. Our approach first generates an initial reconstruction using a\nconditional model, then refines it with an adaptive diffusion-based inverse\nproblem solver. DynamicDPS skips early stage in the reverse process by\nselecting an optimal starting time point per sample and applies Wolfe's line\nsearch for adaptive step sizes, improving both efficiency and image fidelity.\nUsing diffusion priors and data consistency, our method effectively reduces\nhallucinations from any conditional model output. We validate its effectiveness\nin Image Quality Transfer for low-field MRI enhancement. Extensive evaluations\non synthetic and real MR scans, including a downstream task for tissue volume\nestimation, show that DynamicDPS reduces hallucinations, improving relative\nvolume estimation by over 15% for critical tissues while using only 5% of the\nsampling steps required by baseline diffusion models. As a model-agnostic and\nfine-tuning-free approach, DynamicDPS offers a robust solution for\nhallucination reduction in medical imaging. The code will be made publicly\navailable upon publication.",
      "tldr_zh": "该研究提出DynamicDPS框架，通过结合条件扩散模型和无条件扩散模型来解决医学图像重建中的幻觉问题。该方法采用动态反向过程，通过自适应选择起始时间点和步长优化，在仅需5%采样步骤的情况下，将关键组织的体积估计精度提升15%以上。实验证明该模型无关的方法能有效减少低场MRI增强中的虚假结构，为医学成像提供了无需微调的鲁棒解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01075v1",
      "published_date": "2025-03-03 00:33:04 UTC",
      "updated_date": "2025-03-03 00:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:30:13.756684"
    },
    {
      "arxiv_id": "2503.01069v1",
      "title": "Multi-Agent Reinforcement Learning with Long-Term Performance Objectives for Service Workforce Optimization",
      "title_zh": "面向长期绩效目标的多智能体强化学习在服务型劳动力优化中的应用",
      "authors": [
        "Kareem Eissa",
        "Rayal Prasad",
        "Sarith Mohan",
        "Ankur Kapoor",
        "Dorin Comaniciu",
        "Vivek Singh"
      ],
      "abstract": "Workforce optimization plays a crucial role in efficient organizational\noperations where decision-making may span several different administrative and\ntime scales. For instance, dispatching personnel to immediate service requests\nwhile managing talent acquisition with various expertise sets up a highly\ndynamic optimization problem. Existing work focuses on specific sub-problems\nsuch as resource allocation and facility location, which are solved with\nheuristics like local-search and, more recently, deep reinforcement learning.\nHowever, these may not accurately represent real-world scenarios where such\nsub-problems are not fully independent. Our aim is to fill this gap by creating\na simulator that models a unified workforce optimization problem. Specifically,\nwe designed a modular simulator to support the development of reinforcement\nlearning methods for integrated workforce optimization problems. We focus on\nthree interdependent aspects: personnel dispatch, workforce management, and\npersonnel positioning. The simulator provides configurable parameterizations to\nhelp explore dynamic scenarios with varying levels of stochasticity and\nnon-stationarity. To facilitate benchmarking and ablation studies, we also\ninclude heuristic and RL baselines for the above mentioned aspects.",
      "tldr_zh": "该研究提出了一种基于多智能体强化学习(MARL)的服务型劳动力优化框架，针对传统方法在分治优化中的局限性。研究者开发了模块化仿真器，统一建模人员调度、劳动力管理和岗位配置三个相互依存的优化维度，支持可配置参数以模拟不同随机性和非平稳性场景。该框架包含启发式和强化学习基线方法，为动态劳动力优化问题提供了首个集成解决方案测试平台。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01069v1",
      "published_date": "2025-03-03 00:16:47 UTC",
      "updated_date": "2025-03-03 00:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:30:55.242331"
    },
    {
      "arxiv_id": "2503.01068v1",
      "title": "Language-Guided Object Search in Agricultural Environments",
      "title_zh": "农业环境中的语言引导物体搜索",
      "authors": [
        "Advaith Balaji",
        "Saket Pradhan",
        "Dmitry Berenson"
      ],
      "abstract": "Creating robots that can assist in farms and gardens can help reduce the\nmental and physical workload experienced by farm workers. We tackle the problem\nof object search in a farm environment, providing a method that allows a robot\nto semantically reason about the location of an unseen target object among a\nset of previously seen objects in the environment using a Large Language Model\n(LLM). We leverage object-to-object semantic relationships to plan a path\nthrough the environment that will allow us to accurately and efficiently locate\nour target object while also reducing the overall distance traveled, without\nneeding high-level room or area-level semantic relationships. During our\nevaluations, we found that our method outperformed a current state-of-the-art\nbaseline and our ablations. Our offline testing yielded an average path\nefficiency of 84%, reflecting how closely the predicted path aligns with the\nideal path. Upon deploying our system on the Boston Dynamics Spot robot in a\nreal-world farm environment, we found that our system had a success rate of\n80%, with a success weighted by path length of 0.67, which demonstrates a\nreasonable trade-off between task success and path efficiency under real-world\nconditions. The project website can be viewed at\nhttps://adi-balaji.github.io/losae/",
      "tldr_zh": "本研究提出了一种基于大语言模型(LLM)的农业环境物体搜索方法，通过语义推理预测目标物体位置并规划高效搜索路径。该方法利用物体间的语义关联性（而非高级区域语义）进行路径规划，在离线测试中达到84%的平均路径效率。在波士顿动力Spot机器人上的实地测试显示，系统成功率达80%，成功路径长度加权值为0.67，在真实农场环境中实现了任务成功率与路径效率的良好平衡。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, 2 tables, accepted to the 2025 International\n  Conference on Robotics and Automation (ICRA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.01068v1",
      "published_date": "2025-03-03 00:15:45 UTC",
      "updated_date": "2025-03-03 00:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:31:22.535695"
    },
    {
      "arxiv_id": "2503.01064v1",
      "title": "Scientific Reasoning: Assessment of Multimodal Generative LLMs",
      "title_zh": "科学推理：多模态生成式大语言模型的评估",
      "authors": [
        "Florian Dreyer",
        "Ekaterina Kolos",
        "Daria Matiash"
      ],
      "abstract": "Large language models (LLMs) can answer questions and reason about complex\ntasks, also from the scientific domain. We assess several multimodal LLMs\n(MLLMs) on ScienceQA and find that Gemini models show the highest accuracy with\nlittle context, and the highest textual similarity to human explanations with\nricher context. Adapter-tuning of smaller MLLMs did not lead to any reliable\nperformance. Training from Gemini outputs consistently underperformed training\nfrom the original data.",
      "tldr_zh": "该研究评估了多模态大语言模型(MLLMs)在科学推理任务(ScienceQA)中的表现。研究发现，Gemini系列模型在少量上下文条件下准确率最高，在丰富上下文条件下其解释文本与人类答案的相似度最高。实验表明，对小规模MLLMs进行适配器调优(Adapter-tuning)未能带来可靠性能提升，而基于Gemini输出进行训练的效果始终不如原始数据训练。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01064v1",
      "published_date": "2025-03-03 00:07:22 UTC",
      "updated_date": "2025-03-03 00:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-03-26T02:31:16.405112"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 162,
  "processed_papers_count": 162,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-03-26T02:32:27.766833"
}