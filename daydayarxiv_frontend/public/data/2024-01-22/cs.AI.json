{
  "date": "2024-01-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-22 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 105 篇论文，主要聚焦于 AI 模型优化（如 LLM 的鲁棒性和泛化）、联邦学习、图神经网络应用，以及医疗和量子计算领域，其中令人印象深刻的包括 LLM 的 hallucination 检测和量子灵感算法，知名学者如 Dawn Song 和 Bo Li 的作品脱颖而出。\n\n今天的核心论文多围绕机器学习和 AI 应用，强调模型的泛化、安全性和效率。下面，我将挑选最具影响力和话题度的论文优先讨论（如 LLM 相关、联邦学习和医疗 AI），并将相关主题归类快速概述。其他较常规的论文（如某些优化算法或小规模实验）将简要掠过，以控制篇幅。\n\n### LLM 和 AI 安全\n- **Hallucination is Inevitable: An Innate Limitation of Large Language Models (幻觉是不可避免的：Large Language Models 的固有限制)**  \n  这篇论文由 Ziwei Xu、Sanjay Jain 和 Mohan Kankanhalli 撰写，证明了 LLM 在学习理论下不可避免地产生幻觉（hallucination），并分析了其在真实世界的影响。主要贡献：形式化证明 LLM 无法学习所有可计算函数，并讨论了缓解策略。该工作有深度理论基础，值得关注 AI 模型的可靠性。\n\n- **Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts? (被生成上下文蒙蔽：当知识冲突时，语言模型如何合并生成和检索上下文？)**  \n  作者包括 Hexiang Tan 和 Feng Sun。论文揭示了 LLM 在处理冲突上下文时偏好生成上下文，导致错误。主要发现：提出多模态分析框架，展示 LLM 的偏差，并通过实验验证改进方法。该论文与前文相关，强调 LLM 的知识整合问题。\n\n- **WARM: On the Benefits of Weight Averaged Reward Models (WARM：权重平均奖励模型的优势)**  \n  由 Alexandre Ramé 等作者完成，聚焦强化学习中的 LLM 校准。贡献：引入权重平均技术提升奖励模型的鲁棒性，实验显示在摘要任务中提升 79.4% 的性能。该工作实用性强，适合 AI 应用场景。\n\n其他 LLM 相关论文如 **GRATH: Gradual Self-Truthifying for Large Language Models** 和 **Spotting LLMs With Binoculars** 等，均探讨了 LLM 的真诚性和检测，但这些更侧重技术细节，我快速掠过：它们通过自监督优化和对比学习改善 LLM 性能，平均提升 20-50%，但未有突破性创新。\n\n### 联邦学习和图神经网络\n- **FedGTA: Topology-aware Averaging for Federated Graph Learning (FedGTA：拓扑感知的联邦图学习平均)**  \n  作者 Xunkai Li 等。论文解决联邦学习中图拓扑异质性问题。贡献：提出自适应聚合算法，提升图神经网络在异构数据下的准确性，实验在 12 个数据集上优于基准 3-5%。这篇有实际部署潜力，相关作者来自知名机构。\n\n- **AdaFGL: A New Paradigm for Federated Node Classification with Topology Heterogeneity (AdaFGL：处理拓扑异质性的联邦节点分类新范式)**  \n  同上作者团队。重点在联邦图学习中处理拓扑差异。发现：解耦训练策略显著提高分类准确性，实验显示在结构非独立同分布场景下提升 5.57%。与 FedGTA 相关，强化了联邦学习的实用性。\n\n其他图学习论文如 **Tensor-view Topological Graph Neural Network** 和 **Graph Condensation: A Survey** 等，快速总结：前者通过拓扑图神经网络提升图分类性能，后者综述了图压缩技术，但这些较学术化，我仅提及其在高维数据上的 10-20% 效率提升。\n\n### 医疗和生物应用\n- **OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection (OCT-SelfNet：多模态自监督框架用于视网膜疾病检测)**  \n  作者 Fatema-E Jannat 等。论文提出自监督框架检测眼部疾病。贡献：结合多模态数据和 SwinV2 骨干网络，提升 AUC-ROC 到 77%，显著优于基准模型。该工作在医疗 AI 中有实际价值。\n\n- **Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council (通过偏置委员会学习自适应一致性进行医疗图像去偏置)**  \n  作者 Luyang Luo 等。解决医疗图像数据集偏置问题。发现：提出 Ada-ABC 框架，提升模型鲁棒性，实验在多个数据集上提高 5-10% 准确率。该论文实用，解决真实医疗场景的公平性。\n\n其他医疗论文如 **PsySafe** 和 **Zoom-shot** 等，快速掠过：前者探讨多代理系统心理安全，后者用于图像生成，但影响力较小，仅在特定任务中提升 10-20%。\n\n### 其他亮点\n- **Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization (检索引导的强化学习用于布尔电路最小化)**  \n  作者 Animesh Basak Chowdhury 等。贡献：结合强化学习和检索技术，优化硬件设计，实验显示减少 24.8% 电路规模。该工作有工业应用潜力。\n\n- **Quantum-Inspired Machine Learning for Molecular Docking (量子灵感机器学习用于分子对接)**  \n  论文提出量子算法优化分子对接。发现：在药物设计中提升 10% 精度，超越传统方法。该主题前沿，适合量子计算爱好者。\n\n剩余论文如某些强化学习或图像处理工作（如 **Broiler-Net**），我直接掠过：它们在特定领域（如家禽行为分析）有小幅改进，但整体话题度不高。\n\n总之，今天的 arXiv 更新突显 AI 领域的创新，尤其在 LLM 安全和联邦学习上，有望推动实际应用。更多细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2401.12406v1",
      "title": "Enhancing In-context Learning via Linear Probe Calibration",
      "title_zh": "通过线性探针校准增强上下文学习",
      "authors": [
        "Momin Abbas",
        "Yi Zhou",
        "Parikshit Ram",
        "Nathalie Baracaldo",
        "Horst Samulowitz",
        "Theodoros Salonidis",
        "Tianyi Chen"
      ],
      "abstract": "In-context learning (ICL) is a new paradigm for natural language processing\nthat utilizes Generative Pre-trained Transformer (GPT)-like models. This\napproach uses prompts that include in-context demonstrations to generate the\ncorresponding output for a new query input. However, applying ICL in real cases\ndoes not scale with the number of samples, and lacks robustness to different\nprompt templates and demonstration permutations. In this paper, we first show\nthat GPT-like models using ICL result in unreliable predictions based on a new\nmetric based on Shannon entropy. Then, to solve this problem, we propose a new\ntechnique called the Linear Probe Calibration (LinC), a method that calibrates\nthe model's output probabilities, resulting in reliable predictions and\nimproved performance, while requiring only minimal additional samples (as few\nas five labeled data samples). LinC significantly enhances the ICL test\nperformance of GPT models on various benchmark datasets, with an average\nimprovement of up to 21%, and up to a 50% improvement in some cases, and\nsignificantly boosts the performance of PEFT methods, especially in the low\nresource regime. Moreover, LinC achieves lower expected calibration error, and\nis highly robust to varying label proportions, prompt templates, and\ndemonstration permutations. Our code is available at\n\\url{https://github.com/mominabbass/LinC}.",
      "tldr_zh": "这篇论文探讨了In-context Learning (ICL) 在自然语言处理中的问题，如随样本数扩展困难和对提示模板及演示排列的鲁棒性不足，并使用基于Shannon entropy的新指标证明了ICL预测的不可靠性。作者提出Linear Probe Calibration (LinC)方法，通过校准模型输出概率，仅需少量额外标记样本（如5个），显著提升GPT-like模型的性能，在各种基准数据集上平均改善高达21%，某些情况下达50%。此外，LinC还降低了预期校准错误，并增强了PEFT方法在低资源场景下的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at AISTATS2024",
      "pdf_url": "http://arxiv.org/pdf/2401.12406v1",
      "published_date": "2024-01-22 23:35:09 UTC",
      "updated_date": "2024-01-22 23:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:16:52.839252"
    },
    {
      "arxiv_id": "2401.12393v3",
      "title": "Declarative Privacy-Preserving Inference Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Guan",
        "Ansh Tiwari",
        "Summer Gautier",
        "Rajan Hari Ambrish",
        "Lixi Zhou",
        "Yancheng Wang",
        "Deepti Gupta",
        "Yingzhen Yang",
        "Chaowei Xiao",
        "Kanchan Chowdhury",
        "Jia Zou"
      ],
      "abstract": "Detecting inference queries running over personal attributes and protecting\nsuch queries from leaking individual information requires tremendous effort\nfrom practitioners. To tackle this problem, we propose an end-to-end workflow\nfor automating privacy-preserving inference queries including the detection of\nsubqueries that involve AI/ML model inferences on sensitive attributes. Our\nproposed novel declarative privacy-preserving workflow allows users to specify\n\"what private information to protect\" rather than \"how to protect\". Under the\nhood, the system automatically chooses privacy-preserving plans and\nhyper-parameters.",
      "tldr_zh": "该研究针对检测和保护涉及个人属性的推理查询问题，提出了一种端到端的声明式隐私保护工作流，以减少实践者的手动努力。\n用户只需指定“要保护什么私人信息”，而非“如何保护”，系统会自动检测子查询（如AI/ML模型推理）并选择合适的隐私保护计划和超参数。\n这种方法简化了隐私保护过程，提高了效率和易用性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12393v3",
      "published_date": "2024-01-22 22:50:59 UTC",
      "updated_date": "2025-02-18 00:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:17:04.236971"
    },
    {
      "arxiv_id": "2401.12392v1",
      "title": "Evaluating Roadside Perception for Autonomous Vehicles: Insights from Field Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Rusheng Zhang",
        "Depu Meng",
        "Shengyin Shen",
        "Tinghan Wang",
        "Tai Karir",
        "Michael Maile",
        "Henry X. Liu"
      ],
      "abstract": "Roadside perception systems are increasingly crucial in enhancing traffic\nsafety and facilitating cooperative driving for autonomous vehicles. Despite\nrapid technological advancements, a major challenge persists for this newly\narising field: the absence of standardized evaluation methods and benchmarks\nfor these systems. This limitation hampers the ability to effectively assess\nand compare the performance of different systems, thus constraining progress in\nthis vital field. This paper introduces a comprehensive evaluation methodology\nspecifically designed to assess the performance of roadside perception systems.\nOur methodology encompasses measurement techniques, metric selection, and\nexperimental trial design, all grounded in real-world field testing to ensure\nthe practical applicability of our approach.\n  We applied our methodology in Mcity\\footnote{\\url{https://mcity.umich.edu/}},\na controlled testing environment, to evaluate various off-the-shelf perception\nsystems. This approach allowed for an in-depth comparative analysis of their\nperformance in realistic scenarios, offering key insights into their respective\nstrengths and limitations. The findings of this study are poised to inform the\ndevelopment of industry-standard benchmarks and evaluation methods, thereby\nenhancing the effectiveness of roadside perception system development and\ndeployment for autonomous vehicles. We anticipate that this paper will\nstimulate essential discourse on standardizing evaluation methods for roadside\nperception systems, thus pushing the frontiers of this technology. Furthermore,\nour results offer both academia and industry a comprehensive understanding of\nthe capabilities of contemporary infrastructure-based perception systems.",
      "tldr_zh": "这篇论文评估了自动驾驶车辆的路边感知系统（roadside perception systems），强调了该领域缺乏标准化评估方法和基准的挑战，并提出了一种全面的评估方法，包括测量技术、指标选择和实验设计，这些基于真实现场测试（field testing）。研究团队在 Mcity 测试环境中应用该方法，对各种现成感知系统进行了深入比较分析，揭示了它们的优势和局限性。结果表明，此方法能提升系统性能评估的准确性，并为制定行业标准提供关键见解，推动路边感知系统的开发和部署。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 figures, 8 tables, 14 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.12392v1",
      "published_date": "2024-01-22 22:47:02 UTC",
      "updated_date": "2024-01-22 22:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:17:17.409277"
    },
    {
      "arxiv_id": "2401.12379v1",
      "title": "Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Roberson",
        "Gowtham Kaki",
        "Ashutosh Trivedi"
      ],
      "abstract": "This study investigates various approaches to using Large Language Models\n(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights\nderived. Employing the popular Text-to-SQL dataset, spider, the goal was to\ninput a natural language question along with the database schema and output the\ncorrect SQL SELECT query. The initial approach was to fine-tune a local and\nopen-source model to generate the SELECT query. After QLoRa fine-tuning\nWizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy\nfor generated queries rose to a high of 61%. With the second approach, using\nthe fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error\ncorrection), the execution accuracy reached a high of 82.1%. Of all the\nincorrect queries, most can be categorized into a seven different categories of\nwhat went wrong: selecting the wrong columns or wrong order of columns,\ngrouping by the wrong column, predicting the wrong values in conditionals,\nusing different aggregates than the ground truth, extra or too few JOIN\nclauses, inconsistencies in the Spider dataset, and lastly completely incorrect\nquery structure. Most if not all of the queries fall into these categories and\nit is insightful to understanding where the faults still lie with LLM program\nsynthesis and where they can be improved.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在 Text-to-SQL 合成中的有效性，使用 Spider 数据集将自然语言查询和数据库模式转换为 SQL SELECT 查询。研究采用两种方法：首先，通过 QLoRa 微调 WizardCoder-15B 模型，实现了 61% 的执行准确率；其次，结合微调的 gpt-3.5-turbo-16k (Few-shot) 和 gpt-4-turbo (Zero-shot 错误修正)，将准确率提升至 82.1%。论文分析了错误查询的七大常见类别，包括选择错误列、聚合函数不匹配或额外 JOIN 子句等。这些发现揭示了 LLMs 程序合成的潜在缺陷，并为未来改进提供了宝贵洞见。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12379v1",
      "published_date": "2024-01-22 22:05:42 UTC",
      "updated_date": "2024-01-22 22:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:17:32.111934"
    },
    {
      "arxiv_id": "2401.12375v1",
      "title": "Development of an NLP-driven computer-based test guide for visually impaired students",
      "title_zh": "NLP 驱动的计算机化测试指南的开发，用于视力受损学生",
      "authors": [
        "Tubo Faustinah Nemieboka",
        "Ikechukwu E. Onyenwe",
        "Doris C. Asogwa"
      ],
      "abstract": "In recent years, advancements in Natural Language Processing (NLP) techniques\nhave revolutionized the field of accessibility and exclusivity of testing,\nparticularly for visually impaired students (VIS). CBT has shown in years back\nits relevance in terms of administering exams electronically, making the test\nprocess easier, providing quicker and more accurate results, and offering\ngreater flexibility and accessibility for candidates. Yet, its relevance was\nnot felt by the visually impaired students as they cannot access printed\ndocuments. Hence, in this paper, we present an NLP-driven Computer-Based Test\nguide for visually impaired students. It employs a speech technology\npre-trained methods to provide real-time assistance and support to visually\nimpaired students. The system utilizes NLP technologies to convert the\ntext-based questions and the associated options in a machine-readable format.\nSubsequently, the speech technology pre-trained model processes the converted\ntext enabling the VIS to comprehend and analyze the content. Furthermore, we\nvalidated that this pre-trained model is not perverse by testing for accuracy\nusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with the\nvoice recordings obtained from 20 VIS which is been predicted by the system to\nattain values for precision, recall, and F1-scores. These metrics are used to\nassess the performance of the pre-trained model and have indicated that it is\nproficient enough to give its better performance to the evaluated system. The\nmethodology adopted for this system is Object Oriented Analysis and Design\nMethodology (OOADM) where Objects are discussed and built by modeling\nreal-world instances.",
      "tldr_zh": "本文开发了一个基于 Natural Language Processing (NLP) 驱动的计算机化测试指导系统，旨在为视力受损学生 (VIS) 提供可访问的考试环境。该系统利用语音技术预训练模型，将文本问题和选项转换为机器可读格式，并通过实时语音处理帮助 VIS 理解和分析内容。研究采用 Object Oriented Analysis and Design Methodology (OOADM) 作为开发框架，并通过测试样本音频数据集评估模型性能，取得了较高的精确度、召回率和 F1 分数，证明了系统的可靠性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12375v1",
      "published_date": "2024-01-22 21:59:00 UTC",
      "updated_date": "2024-01-22 21:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:17:41.781764"
    },
    {
      "arxiv_id": "2401.12344v1",
      "title": "OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for Generalized and Robust Retinal Disease Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Fatema-E Jannat",
        "Sina Gholami",
        "Minhaj Nur Alam",
        "Hamed Tabkhi"
      ],
      "abstract": "Despite the revolutionary impact of AI and the development of locally trained\nalgorithms, achieving widespread generalized learning from multi-modal data in\nmedical AI remains a significant challenge. This gap hinders the practical\ndeployment of scalable medical AI solutions. Addressing this challenge, our\nresearch contributes a self-supervised robust machine learning framework,\nOCT-SelfNet, for detecting eye diseases using optical coherence tomography\n(OCT) images. In this work, various data sets from various institutions are\ncombined enabling a more comprehensive range of representation. Our method\naddresses the issue using a two-phase training approach that combines\nself-supervised pretraining and supervised fine-tuning with a mask autoencoder\nbased on the SwinV2 backbone by providing a solution for real-world clinical\ndeployment. Extensive experiments on three datasets with different encoder\nbackbones, low data settings, unseen data settings, and the effect of\naugmentation show that our method outperforms the baseline model, Resnet-50 by\nconsistently attaining AUC-ROC performance surpassing 77% across all tests,\nwhereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PR\nmetric, our proposed method exceeded 42%, showcasing a substantial increase of\nat least 10% in performance compared to the baseline, which exceeded only 33%.\nThis contributes to our understanding of our approach's potential and\nemphasizes its usefulness in clinical settings.",
      "tldr_zh": "该论文提出了 OCT-SelfNet，一个自监督框架，用于从多模态数据集检测视网膜疾病，旨在解决医疗 AI 在泛化学习方面的挑战。方法采用两阶段训练策略，包括基于 SwinV2 骨干的 Mask Autoencoder 自监督预训练和后续监督细调，以处理来自不同机构的 OCT 图像数据。实验结果显示，OCT-SelfNet 在三个数据集上的 AUC-ROC 性能超过 77%，AUC-PR 超过 42%，比基线模型 Resnet-50 提升至少 10%，证明了其在低数据和未见数据场景中的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.12344v1",
      "published_date": "2024-01-22 20:17:14 UTC",
      "updated_date": "2024-01-22 20:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:17:53.331583"
    },
    {
      "arxiv_id": "2401.12340v1",
      "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer Learning for Target Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Shoaib Meraj Sami",
        "Md Mahedi Hasan",
        "Nasser M. Nasrabadi",
        "Raghuveer Rao"
      ],
      "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task,\nprimarily due to the unavailability of labeled data in the target domain.\nHence, it is essential to construct an optimal target domain classifier by\nutilizing the labeled information of the source domain images. The transductive\ntransfer learning (TTL) method that incorporates a CycleGAN-based unpaired\ndomain translation network has been previously proposed in the literature for\neffective ATR annotation. Although this method demonstrates great potential for\nATR, it severely suffers from lower annotation performance, higher Fr\\'echet\nInception Distance (FID) score, and the presence of visual artifacts in the\nsynthetic images. To address these issues, we propose a hybrid contrastive\nlearning base unpaired domain translation (H-CUT) network that achieves a\nsignificantly lower FID score. It incorporates both attention and entropy to\nemphasize the domain-specific region, a noisy feature mixup module to generate\nhigh variational synthetic negative patches, and a modulated noise contrastive\nestimation (MoNCE) loss to reweight all negative patches using optimal\ntransport for better performance. Our proposed contrastive learning and\ncycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks\nand two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and\nidentity losses. In C3TTL, two H-CUT networks have been employed through a\nbijection mapping to feed the reconstructed source domain images into a\npretrained classifier to guide the optimal target domain classifier. Extensive\nexperimental analysis conducted on three ATR datasets demonstrates that the\nproposed C3TTL method is effective in annotating civilian and military\nvehicles, as well as ship targets.",
      "tldr_zh": "该论文针对自动目标识别 (ATR) 中的目标标注问题，提出了一种基于对比学习和循环一致性的跨域转移学习 (Transductive Transfer Learning) 框架 C3TTL，以解决源域数据利用不足和合成图像质量低的问题。C3TTL 框架包括两个 H-CUT 网络，该网络结合 attention、entropy、noisy feature mixup 模块以及 MoNCE loss，通过最优传输重新加权负样本，并同时优化 cycle-consistency 和身份损失，以生成高质量的合成图像。实验结果显示，在三个 ATR 数据集上，C3TTL 显著提高了标注性能，降低了 Fréchet Inception Distance (FID) 分数，并在标注民用和军用车辆以及船只目标方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "This Paper is Accepted in IEEE TRANSACTIONS ON AEROSPACE AND\n  ELECTRONIC SYSTEMS. This Arxiv version is an older version than the reviewed\n  version",
      "pdf_url": "http://arxiv.org/pdf/2401.12340v1",
      "published_date": "2024-01-22 20:08:57 UTC",
      "updated_date": "2024-01-22 20:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:18:07.932009"
    },
    {
      "arxiv_id": "2401.12329v1",
      "title": "Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres",
      "title_zh": "迈向交通基础设施的优先使用：车辆特定动态访问限制到市中心的案例",
      "authors": [
        "Holger Billhardt",
        "Alberto Fernández",
        "Pasqual Martí",
        "Javier Prieto Tejedor",
        "Sascha Ossowski"
      ],
      "abstract": "One of the main problems that local authorities of large cities have to face\nis the regulation of urban mobility. They need to provide the means to allow\nfor the efficient movement of people and distribution of goods. However, the\nprovisioning of transportation services needs to take into account general\nglobal objectives, like reducing emissions and having more healthy living\nenvironments, which may not always be aligned with individual interests. Urban\nmobility is usually provided through a transport infrastructure that includes\nall the elements that support mobility. On many occasions, the capacity of the\nelements of this infrastructure is lower than the actual demand and thus\ndifferent transportation activities compete for their use. In this paper, we\nargue that scarce transport infrastructure elements should be assigned\ndynamically and in a prioritised manner to transport activities that have a\nhigher utility from the point of view of society; for example, activities that\nproduce less pollution and provide more value to society. In this paper, we\ndefine a general model for prioritizing the use of a particular type of\ntransportation infrastructure element called time-unlimited elements, whose\nusage time is unknown a priori, and illustrate its dynamics through two use\ncases: vehicle-specific dynamic access restriction in city centres (i) based on\nthe usage levels of available parking spaces and (ii) to assure sustained\nadmissible air quality levels in the city centre. We carry out several\nexperiments using the SUMO traffic simulation tool to evaluate our proposal.",
      "tldr_zh": "这座论文探讨了城市交通基础设施的优先使用问题，特别是通过车辆特定动态访问限制（vehicle-specific dynamic access restrictions）来平衡交通效率、社会价值（如减少排放和改善空气质量）。论文提出一个通用模型，用于动态分配稀缺的“time-unlimited elements”（时间不确定元素），并通过两个用例进行说明：基于可用停车位使用水平的访问控制，以及确保城市中心空气质量的持续合规。实验结果显示，使用 SUMO 交通模拟工具后，该方法在实际场景中表现出显著的优化潜力。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12329v1",
      "published_date": "2024-01-22 19:43:54 UTC",
      "updated_date": "2024-01-22 19:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:18:16.370213"
    },
    {
      "arxiv_id": "2401.12326v1",
      "title": "Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Xiong",
        "Thanet Markchom",
        "Ziwei Zheng",
        "Subin Jung",
        "Varun Ojha",
        "Huizhi Liang"
      ],
      "abstract": "SemEval-2024 Task 8 introduces the challenge of identifying machine-generated\ntexts from diverse Large Language Models (LLMs) in various languages and\ndomains. The task comprises three subtasks: binary classification in\nmonolingual and multilingual (Subtask A), multi-class classification (Subtask\nB), and mixed text detection (Subtask C). This paper focuses on Subtask A & B.\nEach subtask is supported by three datasets for training, development, and\ntesting. To tackle this task, two methods: 1) using traditional machine\nlearning (ML) with natural language preprocessing (NLP) for feature extraction,\nand 2) fine-tuning LLMs for text classification. The results show that\ntransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in\neffectiveness, with majority voting being particularly effective in\nmultilingual contexts for identifying machine-generated texts.",
      "tldr_zh": "这篇论文针对SemEval-2024 Task 8的Subtask A和B，探讨了检测多生成器、多领域和多语言机器生成文本的方法，包括单语和多语二元分类以及多类分类。研究采用了两种方法：一是使用传统机器学习(ML)结合自然语言预处理(NLP)进行特征提取，二是微调Large Language Models (LLMs)如LoRA-RoBERTa进行文本分类。结果表明，transformer模型在有效性上超过了传统ML方法，尤其在多语言场景中，多数投票机制显著提高了机器生成文本的识别准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12326v1",
      "published_date": "2024-01-22 19:39:05 UTC",
      "updated_date": "2024-01-22 19:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:18:29.140566"
    },
    {
      "arxiv_id": "2401.12324v1",
      "title": "Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Holger Billhardt",
        "José-Antonio Santos",
        "Alberto Fernández",
        "Mar Moreno",
        "Sascha Ossowski",
        "José A. Rodríguez"
      ],
      "abstract": "In recent years many novel applications have appeared that promote the\nprovision of services and activities in a collaborative manner. The key idea\nbehind such systems is to take advantage of idle or underused capacities of\nexisting resources, in order to provide improved services that assist people in\ntheir daily tasks, with additional functionality, enhanced efficiency, and/or\nreduced cost. Particularly in the domain of urban transportation, many\nresearchers have put forward novel ideas, which are then implemented and\nevaluated through prototypes that usually draw upon AI methods and tools.\nHowever, such proposals also bring up multiple non-technical issues that need\nto be identified and addressed adequately if such systems are ever meant to be\napplied to the real world. While, in practice, legal and ethical aspects\nrelated to such AI-based systems are seldomly considered in the beginning of\nthe research and development process, we argue that they not only restrict\ndesign decisions, but can also help guiding them. In this manuscript, we set\nout from a prototype of a taxi coordination service that mediates between\nindividual (and autonomous) taxis and potential customers. After representing\nkey aspects of its operation in a semi-structured manner, we analyse its\nviability from the viewpoint of current legal restrictions and constraints, so\nas to identify additional non-functional requirements as well as options to\naddress them. Then, we go one step ahead, and actually modify the existing\nprototype to incorporate the previously identified recommendations. Performing\nexperiments with this improved system helps us identify the most adequate\noption among several legally admissible alternatives.",
      "tldr_zh": "该论文探讨了在城市交通领域中，如何通过法律分析来简化先进的出租车分配策略，以应对AI系统可能引发的法律和伦理问题。研究者从一个出租车协调服务的原型出发，通过半结构化方式分析其关键操作，并评估当前法律限制以识别非功能性要求。最终，他们修改了原型以整合这些推荐，并通过实验比较了几种合法可行的选项，确定了最合适的方案，从而为AI-based交通系统的实际应用提供了指导。",
      "categories": [
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12324v1",
      "published_date": "2024-01-22 19:35:28 UTC",
      "updated_date": "2024-01-22 19:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:18:39.304815"
    },
    {
      "arxiv_id": "2401.12322v1",
      "title": "Smart Recommendations for Renting Bikes in Bike Sharing Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Holger Billhardt",
        "Alberto Fernández",
        "Sascha Ossowski"
      ],
      "abstract": "Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems\n-- have become increasingly popular in big cities in recent years. On the one\nhand, they provide a cheaper and environmentally friendlier means of\ntransportation than private cars, and on the other hand, they satisfy the\nindividual mobility demands of citizens better than traditional public\ntransport systems. One of their advantages in this regard is their\navailability, e.g., the possibility of taking (or leaving) a vehicle almost\nanywhere in a city. This availability obviously depends on different strategic\nand operational management decisions and policies, such as the dimension of the\nfleet or the (re)distribution of vehicles. Agglutination problems -- where, due\nto usage patterns, available vehicles are concentrated in certain areas,\nwhereas no vehicles are available in others -- are quite common in such\nsystems, and need to be dealt with. Research has been dedicated to this\nproblem, specifying different techniques to reduce imbalanced situations. In\nthis paper, we present and compare strategies for recommending stations to\nusers who wish to rent or return bikes in station-based bike-sharing systems.\nOur first contribution is a novel recommendation strategy based on queuing\ntheory that recommends stations based on their utility to the user in terms of\nlower distance and higher probability of finding a bike or slot. Then, we go\none step further, defining a strategy that recommends stations by combining the\nutility of a particular user with the utility of the global system, measured in\nterms of the improvement in the distribution of bikes and slots with respect to\nthe expected future demand, with the aim of implicitly avoiding or alleviating\nbalancing problems. We present several experiments to evaluate our proposal\nwith real data from the bike sharing system BiciMAD in Madrid.",
      "tldr_zh": "本研究针对自行车共享系统中的车辆聚集问题（agglutination problems），提出智能推荐策略，以优化用户租还车的体验和系统整体平衡。论文首先引入一种基于排队理论（queuing theory）的推荐方法，评估站点的用户效用，包括距离和找到自行车或空位的概率。其次，开发了一种结合用户效用与系统全局效用的策略，考虑未来需求分布以缓解平衡问题。实验使用马德里 BiciMAD 系统的真实数据进行评估，证明了这些策略的有效性。",
      "categories": [
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12322v1",
      "published_date": "2024-01-22 19:29:33 UTC",
      "updated_date": "2024-01-22 19:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:18:52.155967"
    },
    {
      "arxiv_id": "2401.12292v2",
      "title": "GRATH: Gradual Self-Truthifying for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weixin Chen",
        "Dawn Song",
        "Bo Li"
      ],
      "abstract": "Truthfulness is paramount for large language models (LLMs) as they are\nincreasingly deployed in real-world applications. However, existing LLMs still\nstruggle with generating truthful content, as evidenced by their modest\nperformance on benchmarks like TruthfulQA. To address this issue, we propose\nGRAdual self-truTHifying (GRATH), a novel post-processing method to enhance\ntruthfulness of LLMs. GRATH utilizes out-of-domain question prompts to generate\npairwise truthfulness training data with each pair containing a question and\nits correct and incorrect answers, and then optimizes the model via direct\npreference optimization (DPO) to learn from the truthfulness difference between\nanswer pairs. GRATH iteratively refines truthfulness data and updates the\nmodel, leading to a gradual improvement in model truthfulness in a\nself-supervised manner. Empirically, we evaluate GRATH using different 7B-LLMs\nand compare with LLMs with similar or even larger sizes on benchmark datasets.\nOur results show that GRATH effectively improves LLMs' truthfulness without\ncompromising other core capabilities. Notably, GRATH achieves state-of-the-art\nperformance on TruthfulQA, with MC1 accuracy of 54.71% and MC2 accuracy of\n69.10%, which even surpass those on 70B-LLMs.",
      "tldr_zh": "该论文提出 GRATH，一种渐进式自监督方法，用于提升大型语言模型 (LLMs) 的真实性，以解决模型在 TruthfulQA 等基准上的表现不足问题。GRATH 通过使用域外问题提示生成配对训练数据（包括问题、正确答案和错误答案），并应用直接偏好优化 (DPO) 进行迭代优化，实现模型真实性的逐步改进。实验结果表明，GRATH 在 7B-LLMs 上显著提升了真实性表现，在 TruthfulQA 上达到 MC1 准确率 54.71% 和 MC2 准确率 69.10%，甚至超过了 70B-LLMs，同时不影响其他核心能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12292v2",
      "published_date": "2024-01-22 19:00:08 UTC",
      "updated_date": "2024-01-31 06:44:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:19:05.633950"
    },
    {
      "arxiv_id": "2401.12275v2",
      "title": "Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation",
      "title_zh": "多智能体动态关系推理用于社交机器人导航",
      "authors": [
        "Jiachen Li",
        "Chuanbo Hua",
        "Jianpeng Yao",
        "Hengbo Ma",
        "Jinkyoo Park",
        "Victoria Dax",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Social robot navigation can be helpful in various contexts of daily life but\nrequires safe human-robot interactions and efficient trajectory planning. While\nmodeling pairwise relations has been widely studied in multi-agent interacting\nsystems, the ability to capture larger-scale group-wise activities is limited.\nIn this paper, we propose a systematic relational reasoning approach with\nexplicit inference of the underlying dynamically evolving relational\nstructures, and we demonstrate its effectiveness for multi-agent trajectory\nprediction and social robot navigation. In addition to the edges between pairs\nof nodes (i.e., agents), we propose to infer hyperedges that adaptively connect\nmultiple nodes to enable group-wise reasoning in an unsupervised manner. Our\napproach infers dynamically evolving relation graphs and hypergraphs to capture\nthe evolution of relations, which the trajectory predictor employs to generate\nfuture states. Meanwhile, we propose to regularize the sharpness and sparsity\nof the learned relations and the smoothness of the relation evolution, which\nproves to enhance training stability and model performance. The proposed\napproach is validated on synthetic crowd simulations and real-world benchmark\ndatasets. Experiments demonstrate that the approach infers reasonable relations\nand achieves state-of-the-art prediction performance. In addition, we present a\ndeep reinforcement learning (DRL) framework for social robot navigation, which\nincorporates relational reasoning and trajectory prediction systematically. In\na group-based crowd simulation, our method outperforms the strongest baseline\nby a significant margin in terms of safety, efficiency, and social compliance\nin dense, interactive scenarios. We also demonstrate the practical\napplicability of our method with real-world robot experiments. The code and\nvideos can be found at https://relational-reasoning-nav.github.io/.",
      "tldr_zh": "这篇论文提出了一种多智能体动态关系推理方法，用于社会机器人导航，以解决传统方法在捕捉大规模群体活动方面的局限性。该方法通过显式推断动态演变的图和超边（hyperedges），实现无监督的群体推理，并结合轨迹预测来生成未来状态，同时引入正则化机制提升训练稳定性和性能。在实验验证中，该方法在合成人群模拟和真实数据集上取得了state-of-the-art的预测性能，并在深度强化学习（DRL）框架下显著提高了机器人在密集场景中的安全、效率和社会合规性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://relational-reasoning-nav.github.io/; 20\n  pages, 9 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.12275v2",
      "published_date": "2024-01-22 18:58:22 UTC",
      "updated_date": "2024-11-11 18:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:19:17.590552"
    },
    {
      "arxiv_id": "2401.12205v1",
      "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
      "title_zh": "翻译失败",
      "authors": [
        "Animesh Basak Chowdhury",
        "Marco Romanelli",
        "Benjamin Tan",
        "Ramesh Karri",
        "Siddharth Garg"
      ],
      "abstract": "Logic synthesis, a pivotal stage in chip design, entails optimizing chip\nspecifications encoded in hardware description languages like Verilog into\nhighly efficient implementations using Boolean logic gates. The process\ninvolves a sequential application of logic minimization heuristics (``synthesis\nrecipe\"), with their arrangement significantly impacting crucial metrics such\nas area and delay. Addressing the challenge posed by the broad spectrum of\ndesign complexities - from variations of past designs (e.g., adders and\nmultipliers) to entirely novel configurations (e.g., innovative processor\ninstructions) - requires a nuanced `synthesis recipe` guided by human expertise\nand intuition. This study conducts a thorough examination of learning and\nsearch techniques for logic synthesis, unearthing a surprising revelation:\npre-trained agents, when confronted with entirely novel designs, may veer off\ncourse, detrimentally affecting the search trajectory. We present ABC-RL, a\nmeticulously tuned $\\alpha$ parameter that adeptly adjusts recommendations from\npre-trained agents during the search process. Computed based on similarity\nscores through nearest neighbor retrieval from the training dataset, ABC-RL\nyields superior synthesis recipes tailored for a wide array of hardware\ndesigns. Our findings showcase substantial enhancements in the\nQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to\n24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an\nimpressive up to 9x reduction in runtime (iso-QoR) when compared to current\nstate-of-the-art methodologies.",
      "tldr_zh": "这篇论文针对布尔电路最小化问题，提出了一种检索引导的Reinforcement Learning方法，用于优化逻辑综合中的synthesis recipe，以应对从经典设计（如加法器和乘法器）到新颖配置（如创新处理器指令）的广泛复杂性。方法通过ABC-RL参数调整，根据训练数据集的最近邻检索相似性分数，动态修正预训练代理的推荐，从而生成更有效的硬件设计方案。实验结果显示，ABC-RL显著提升了Quality-of-result (QoR)高达24.8%，并在等QoR条件下将运行时间减少高达9倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.12205v1",
      "published_date": "2024-01-22 18:46:30 UTC",
      "updated_date": "2024-01-22 18:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:19:29.215650"
    },
    {
      "arxiv_id": "2401.12203v1",
      "title": "Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources",
      "title_zh": "无监督机器学习用于天体物理 X 射线源的分类",
      "authors": [
        "Víctor Samuel Pérez-Díaz",
        "Juan Rafael Martínez-Galarza",
        "Alexander Caicedo",
        "Raffaele D'Abrusco"
      ],
      "abstract": "The automatic classification of X-ray detections is a necessary step in\nextracting astrophysical information from compiled catalogs of astrophysical\nsources. Classification is useful for the study of individual objects,\nstatistics for population studies, as well as for anomaly detection, i.e., the\nidentification of new unexplored phenomena, including transients and spectrally\nextreme sources. Despite the importance of this task, classification remains\nchallenging in X-ray astronomy due to the lack of optical counterparts and\nrepresentative training sets. We develop an alternative methodology that\nemploys an unsupervised machine learning approach to provide probabilistic\nclasses to Chandra Source Catalog sources with a limited number of labeled\nsources, and without ancillary information from optical and infrared catalogs.\nWe provide a catalog of probabilistic classes for 8,756 sources, comprising a\ntotal of 14,507 detections, and demonstrate the success of the method at\nidentifying emission from young stellar objects, as well as distinguishing\nbetween small-scale and large-scale compact accretors with a significant level\nof confidence. We investigate the consistency between the distribution of\nfeatures among classified objects and well-established astrophysical hypotheses\nsuch as the unified AGN model. This provides interpretability to the\nprobabilistic classifier. Code and tables are available publicly through\nGitHub. We provide a web playground for readers to explore our final\nclassification at https://umlcaxs-playground.streamlit.app.",
      "tldr_zh": "本研究提出了一种无监督机器学习方法，用于对天体物理X-ray源进行分类，旨在解决缺乏光学对应物和代表性训练集的挑战。该方法利用有限的标记源为Chandra Source Catalog中的源提供概率类标签，而不依赖光学或红外目录，成功为8,756个源（14,507个检测）生成分类目录，并准确识别年轻恒星物体（young stellar objects）以及区分小规模和大规模致密吸积体。通过验证分类结果与统一AGN模型等天体物理假设的一致性，该方法增强了解释性。代码和表格已公开可用，并提供网页工具（https://umlcaxs-playground.streamlit.app）供进一步探索。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "21 pages, 11 figures. Accepted in MNRAS",
      "pdf_url": "http://arxiv.org/pdf/2401.12203v1",
      "published_date": "2024-01-22 18:42:31 UTC",
      "updated_date": "2024-01-22 18:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:19:40.849757"
    },
    {
      "arxiv_id": "2401.12202v2",
      "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics",
      "title_zh": "OK-Robot: 机器人学中整合开放知识模型的真正关键",
      "authors": [
        "Peiqi Liu",
        "Yaswanth Orru",
        "Jay Vakil",
        "Chris Paxton",
        "Nur Muhammad Mahi Shafiullah",
        "Lerrel Pinto"
      ],
      "abstract": "Remarkable progress has been made in recent years in the fields of vision,\nlanguage, and robotics. We now have vision models capable of recognizing\nobjects based on language queries, navigation systems that can effectively\ncontrol mobile systems, and grasping models that can handle a wide range of\nobjects. Despite these advancements, general-purpose applications of robotics\nstill lag behind, even though they rely on these fundamental capabilities of\nrecognition, navigation, and grasping. In this paper, we adopt a systems-first\napproach to develop a new Open Knowledge-based robotics framework called\nOK-Robot. By combining Vision-Language Models (VLMs) for object detection,\nnavigation primitives for movement, and grasping primitives for object\nmanipulation, OK-Robot offers a integrated solution for pick-and-drop\noperations without requiring any training. To evaluate its performance, we run\nOK-Robot in 10 real-world home environments. The results demonstrate that\nOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,\nrepresenting a new state-of-the-art in Open Vocabulary Mobile Manipulation\n(OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered\nenvironments, OK-Robot's performance increases to 82%. However, the most\nimportant insight gained from OK-Robot is the critical role of nuanced details\nwhen combining Open Knowledge systems like VLMs with robotic modules. Videos of\nour experiments and code are available on our website:\nhttps://ok-robot.github.io",
      "tldr_zh": "本研究提出OK-Robot框架，通过整合Vision-Language Models (VLMs)用于物体检测、导航原语用于移动以及抓取原语用于操作，实现无需训练的开放词汇移动操作。OK-Robot在10个真实家庭环境中测试，取得了58.5%的成功率，并在整洁环境中提升至82%，比先前工作提高了近1.8倍，成为Open Vocabulary Mobile Manipulation (OVMM)的新基准。论文强调，结合VLMs与机器人模块时，细微细节的处理至关重要，这为通用机器人应用提供了关键见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Github repo: https://github.com/ok-robot/ok-robot",
      "pdf_url": "http://arxiv.org/pdf/2401.12202v2",
      "published_date": "2024-01-22 18:42:20 UTC",
      "updated_date": "2024-02-29 17:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:19:52.039209"
    },
    {
      "arxiv_id": "2401.12192v4",
      "title": "Text Embedding Inversion Security for Multilingual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyi Chen",
        "Heather Lent",
        "Johannes Bjerva"
      ],
      "abstract": "Textual data is often represented as real-numbered embeddings in NLP,\nparticularly with the popularity of large language models (LLMs) and Embeddings\nas a Service (EaaS). However, storing sensitive information as embeddings can\nbe susceptible to security breaches, as research shows that text can be\nreconstructed from embeddings, even without knowledge of the underlying model.\nWhile defence mechanisms have been explored, these are exclusively focused on\nEnglish, leaving other languages potentially exposed to attacks. This work\nexplores LLM security through multilingual embedding inversion. We define the\nproblem of black-box multilingual and cross-lingual inversion attacks, and\nexplore their potential implications. Our findings suggest that multilingual\nLLMs may be more vulnerable to inversion attacks, in part because English-based\ndefences may be ineffective. To alleviate this, we propose a simple masking\ndefense effective for both monolingual and multilingual models. This study is\nthe first to investigate multilingual inversion attacks, shedding light on the\ndifferences in attacks and defenses across monolingual and multilingual\nsettings.",
      "tldr_zh": "这篇论文探讨了多语言语言模型（multilingual LLMs）中文本嵌入（text embeddings）的安全问题，特别是黑盒多语言和跨语言反转攻击（inversion attacks），这些攻击可能导致敏感信息从嵌入中重建。研究发现，多语言LLMs 比单语言模型更容易受到攻击，因为基于英语的防御机制（如 Embeddings as a Service, EaaS）无效。作者提出了一种简单的掩码防御（masking defense），适用于单语言和多语言设置，这是首次系统调查多语言反转攻击，并揭示了不同语言环境下的攻击和防御差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 17 Tables, 6 Figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12192v4",
      "published_date": "2024-01-22 18:34:42 UTC",
      "updated_date": "2024-06-05 10:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:20:05.277967"
    },
    {
      "arxiv_id": "2401.12187v1",
      "title": "WARM: On the Benefits of Weight Averaged Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Ramé",
        "Nino Vieillard",
        "Léonard Hussenot",
        "Robert Dadashi",
        "Geoffrey Cideron",
        "Olivier Bachem",
        "Johan Ferret"
      ],
      "abstract": "Aligning large language models (LLMs) with human preferences through\nreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit\nfailures in the reward model (RM) to achieve seemingly high rewards without\nmeeting the underlying objectives. We identify two primary challenges when\ndesigning RMs to mitigate reward hacking: distribution shifts during the RL\nprocess and inconsistencies in human preferences. As a solution, we propose\nWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then\naveraging them in the weight space. This strategy follows the observation that\nfine-tuned weights remain linearly mode connected when sharing the same\npre-training. By averaging weights, WARM improves efficiency compared to the\ntraditional ensembling of predictions, while improving reliability under\ndistribution shifts and robustness to preference inconsistencies. Our\nexperiments on summarization tasks, using best-of-N and RL methods, shows that\nWARM improves the overall quality and alignment of LLM predictions; for\nexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy\nRL fine-tuned with a single RM.",
      "tldr_zh": "这项研究探讨了在使用强化学习从人类反馈（RLHF）对大型语言模型（LLMs）进行对齐时，奖励模型（RM）可能导致的奖励黑客问题，特别是在分布偏移和人类偏好不一致的挑战下。作者提出Weight Averaged Reward Models (WARM) 方法，通过微调多个RM并在权重空间上平均它们，提高了模型的效率和鲁棒性。实验在摘要任务上显示，使用WARM微调的策略RL比单一RM微调的策略RL有79.4%的胜率，从而提升了LLM预测的质量和对齐性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12187v1",
      "published_date": "2024-01-22 18:27:08 UTC",
      "updated_date": "2024-01-22 18:27:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:20:16.482240"
    },
    {
      "arxiv_id": "2401.12181v1",
      "title": "Universal Neurons in GPT2 Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wes Gurnee",
        "Theo Horsley",
        "Zifan Carl Guo",
        "Tara Rezaei Kheirkhah",
        "Qinyi Sun",
        "Will Hathaway",
        "Neel Nanda",
        "Dimitris Bertsimas"
      ],
      "abstract": "A basic question within the emerging field of mechanistic interpretability is\nthe degree to which neural networks learn the same underlying mechanisms. In\nother words, are neural mechanisms universal across different models? In this\nwork, we study the universality of individual neurons across GPT2 models\ntrained from different initial random seeds, motivated by the hypothesis that\nuniversal neurons are likely to be interpretable. In particular, we compute\npairwise correlations of neuron activations over 100 million tokens for every\nneuron pair across five different seeds and find that 1-5\\% of neurons are\nuniversal, that is, pairs of neurons which consistently activate on the same\ninputs. We then study these universal neurons in detail, finding that they\nusually have clear interpretations and taxonomize them into a small number of\nneuron families. We conclude by studying patterns in neuron weights to\nestablish several universal functional roles of neurons in simple circuits:\ndeactivating attention heads, changing the entropy of the next token\ndistribution, and predicting the next token to (not) be within a particular\nset.",
      "tldr_zh": "本研究探讨了在不同初始随机种子训练的 GPT2 模型中，神经元的通用性，以揭示神经网络的机械解释性（mechanistic interpretability）。研究者通过计算五个模型中每对神经元的激活相关性，基于 1 亿 tokens 的数据，发现 1-5% 的神经元是通用的，即在不同模型中对相同输入一致激活。这些通用神经元通常具有清晰的解释，并被分类成几个神经元家族。最后，通过分析神经元权重，论文确立了几个通用功能角色，如关闭注意力头、改变下一个 token 分布的熵，以及预测下一个 token 是否在特定集合中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12181v1",
      "published_date": "2024-01-22 18:11:01 UTC",
      "updated_date": "2024-01-22 18:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:20:29.530645"
    },
    {
      "arxiv_id": "2401.12179v2",
      "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Novack",
        "Julian McAuley",
        "Taylor Berg-Kirkpatrick",
        "Nicholas J. Bryan"
      ],
      "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose\nframe-work for controlling pre-trained text-to-music diffusion models at\ninference-time via optimizing initial noise latents. Our method can be used to\noptimize through any differentiable feature matching loss to achieve a target\n(stylized) output and leverages gradient checkpointing for memory efficiency.\nWe demonstrate a surprisingly wide-range of applications for music generation\nincluding inpainting, outpainting, and looping as well as intensity, melody,\nand musical structure control - all without ever fine-tuning the underlying\nmodel. When we compare our approach against related training, guidance, and\noptimization-based methods, we find DITTO achieves state-of-the-art performance\non nearly all tasks, including outperforming comparable approaches on\ncontrollability, audio quality, and computational efficiency, thus opening the\ndoor for high-quality, flexible, training-free control of diffusion models.\nSound examples can be found at https://DITTO-Music.github.io/web/.",
      "tldr_zh": "我们提出 DITTO，一种 Diffusion Inference-Time T-Optimization 框架，用于在推理时控制预训练的 text-to-music diffusion models，通过优化初始噪声潜在变量和可微分特征匹配损失来实现目标输出，同时利用梯度检查点提升内存效率。DITTO 支持多种音乐生成应用，包括 inpainting, outpainting, looping，以及强度、旋律和音乐结构控制，而无需对底层模型进行微调。实验表明，该方法在可控性、音频质量和计算效率上优于相关训练、引导和优化方法，实现了 state-of-the-art 性能，为灵活的训练-free 音乐生成开辟了新路径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Oral at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.12179v2",
      "published_date": "2024-01-22 18:10:10 UTC",
      "updated_date": "2024-06-03 17:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:20:41.264825"
    },
    {
      "arxiv_id": "2401.12178v1",
      "title": "In-Context Learning for Extreme Multi-Label Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Karel D'Oosterlinck",
        "Omar Khattab",
        "François Remy",
        "Thomas Demeester",
        "Chris Develder",
        "Christopher Potts"
      ],
      "abstract": "Multi-label classification problems with thousands of classes are hard to\nsolve with in-context learning alone, as language models (LMs) might lack prior\nknowledge about the precise classes or how to assign them, and it is generally\ninfeasible to demonstrate every class in a prompt. We propose a general\nprogram, $\\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactions\nbetween LMs and retrievers to efficiently tackle such problems. We implement\nthis program using the $\\texttt{DSPy}$ programming model, which specifies\nin-context systems in a declarative manner, and use $\\texttt{DSPy}$ optimizers\nto tune it towards specific datasets by bootstrapping only tens of few-shot\nexamples. Our primary extreme classification program, optimized separately for\neach task, attains state-of-the-art results across three benchmarks (HOUSE,\nTECH, TECHWOLF). We apply the same program to a benchmark with vastly different\ncharacteristics and attain competitive performance as well (BioDEX). Unlike\nprior work, our proposed solution requires no finetuning, is easily applicable\nto new tasks, alleviates prompt engineering, and requires only tens of labeled\nexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.",
      "tldr_zh": "本文提出了一种针对极端多标签分类（Extreme Multi-Label Classification）的 In-Context Learning 方法，解决语言模型在处理数千类标签时面临的知识缺口和提示限制问题，通过通用程序 Infer--Retrieve--Rank 定义语言模型与检索器之间的多步交互。利用 DSPy 编程模型实现该程序，并通过 DSPy 优化器仅基于数十个 few-shot 示例进行针对性调整，无需微调即可适应新任务。实验结果显示，该方法在 HOUSE、TECH 和 TECHWOLF 基准上达到了最先进性能，在 BioDEX 上也表现出竞争性优势，显著减少了提示工程需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12178v1",
      "published_date": "2024-01-22 18:09:52 UTC",
      "updated_date": "2024-01-22 18:09:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:20:54.815891"
    },
    {
      "arxiv_id": "2401.12176v1",
      "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses",
      "title_zh": "Broiler-Net：一个深度卷积框架用于禽舍中",
      "authors": [
        "Tahereh Zarrat Ehsan",
        "Seyed Mehdi Mohtavipour"
      ],
      "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal\nchicken health conditions, minimizing economic losses and bolstering\nprofitability. This paper presents a novel real-time framework for analyzing\nchicken behavior in cage-free poultry houses to detect abnormal behaviors.\nSpecifically, two significant abnormalities, namely inactive broiler and\nhuddling behavior, are investigated in this study. The proposed framework\ncomprises three key steps: (1) chicken detection utilizing a state-of-the-art\ndeep learning model, (2) tracking individual chickens across consecutive frames\nwith a fast tracker module, and (3) detecting abnormal behaviors within the\nvideo stream. Experimental studies are conducted to evaluate the efficacy of\nthe proposed algorithm in accurately assessing chicken behavior. The results\nillustrate that our framework provides a precise and efficient solution for\nreal-time anomaly detection, facilitating timely interventions to maintain\nchicken health and enhance overall productivity on poultry farms. Github:\nhttps://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis",
      "tldr_zh": "本研究提出Broiler-Net，一种基于深度卷积框架的实时系统，用于分析笼自由家禽房中鸡的行为异常，特别是inactive broiler（非活跃鸡）和huddling behavior（挤成一团行为）。框架包括三个关键步骤：利用先进的深度学习模型进行鸡检测、使用快速跟踪器模块在连续帧中跟踪个体鸡，以及在视频流中检测异常行为。实验结果显示，该系统提供精确且高效的实时异常检测，帮助及时干预以维护鸡健康并提升家禽养殖的生产力。GitHub链接：https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12176v1",
      "published_date": "2024-01-22 18:09:15 UTC",
      "updated_date": "2024-01-22 18:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:21:06.477180"
    },
    {
      "arxiv_id": "2401.12170v1",
      "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems",
      "title_zh": "随机多智能体系统中的自然策略能力",
      "authors": [
        "Raphaël Berthon",
        "Joost-Pieter Katoen",
        "Munyque Mittelmann",
        "Aniello Murano"
      ],
      "abstract": "Strategies synthesized using formal methods can be complex and often require\ninfinite memory, which does not correspond to the expected behavior when trying\nto model Multi-Agent Systems (MAS). To capture such behaviors, natural\nstrategies are a recently proposed framework striking a balance between the\nability of agents to strategize with memory and the model-checking complexity,\nbut until now has been restricted to fully deterministic settings. For the\nfirst time, we consider the probabilistic temporal logics PATL and PATL* under\nnatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,\nin stochastic MAS, NatPATL model-checking is NP-complete when the active\ncoalition is restricted to deterministic strategies. We also give a 2NEXPTIME\ncomplexity result for NatPATL* with the same restriction. In the unrestricted\ncase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for\nNatPATL*.",
      "tldr_zh": "该论文探讨了在随机多智能体系统 (MAS) 中，自然策略 (natural strategies) 的应用，以解决形式方法合成的复杂策略问题，这些策略往往需要无限记忆且不切实际。作者首次扩展自然策略到概率时序逻辑 PATL 和 PATL*（分别称为 NatPATL 和 NatPATL*），并分析了其模型检查复杂性：在活跃联盟限制为确定性策略时，NatPATL 为 NP-complete，NatPATL* 为 2NEXPTIME；无限制情况下，NatPATL 为 EXPSPACE，NatPATL* 为 3EXPSPACE。主要贡献在于提供了这些复杂性结果，提升了 MAS 中策略建模的可行性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Extended version of the paper accepted at AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.12170v1",
      "published_date": "2024-01-22 18:04:26 UTC",
      "updated_date": "2024-01-22 18:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:21:19.553822"
    },
    {
      "arxiv_id": "2401.12164v1",
      "title": "Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE",
      "title_zh": "利用多特征和 t-SNE 的非线性规范相关分析对土地覆盖图像进行半监督分割",
      "authors": [
        "Hong Wei",
        "James Xiao",
        "Yichao Zhang",
        "Xia Hong"
      ],
      "abstract": "Image segmentation is a clustering task whereby each pixel is assigned a\ncluster label. Remote sensing data usually consists of multiple bands of\nspectral images in which there exist semantically meaningful land cover\nsubregions, co-registered with other source data such as LIDAR (LIght Detection\nAnd Ranging) data, where available. This suggests that, in order to account for\nspatial correlation between pixels, a feature vector associated with each pixel\nmay be a vectorized tensor representing the multiple bands and a local patch as\nappropriate. Similarly, multiple types of texture features based on a pixel's\nlocal patch would also be beneficial for encoding locally statistical\ninformation and spatial variations, without necessarily labelling pixel-wise a\nlarge amount of ground truth, then training a supervised model, which is\nsometimes impractical. In this work, by resorting to label only a small\nquantity of pixels, a new semi-supervised segmentation approach is proposed.\nInitially, over all pixels, an image data matrix is created in high dimensional\nfeature space. Then, t-SNE projects the high dimensional data onto 3D\nembedding. By using radial basis functions as input features, which use the\nlabelled data samples as centres, to pair with the output class labels, a\nmodified canonical correlation analysis algorithm, referred to as RBF-CCA, is\nintroduced which learns the associated projection matrix via the small labelled\ndata set. The associated canonical variables, obtained for the full image, are\napplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA\nalgorithm has been implemented on several remotely sensed multispectral images,\ndemonstrating excellent segmentation results.",
      "tldr_zh": "该论文提出了一种半监督图像分割方法，用于遥感土地覆盖图像的聚类任务，通过整合多种特征和 t-SNE 进行处理。方法首先构建高维特征空间的数据矩阵，包括光谱带、局部 patch 和纹理特征，然后使用 t-SNE 将数据投影到 3D 嵌入空间。接着，引入 RBF-CCA（基于径向基函数的规范相关分析）算法，利用少量标记像素学习投影矩阵，并结合 k-means clustering 对全图像进行聚类。实验结果显示，该方法在多个遥感多光谱图像上实现了优秀的分割性能，证明了其在减少标注需求方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12164v1",
      "published_date": "2024-01-22 17:56:07 UTC",
      "updated_date": "2024-01-22 17:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:21:30.303213"
    },
    {
      "arxiv_id": "2401.12132v1",
      "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI",
      "title_zh": "翻译失败",
      "authors": [
        "John D. Mayfield",
        "Issam El Naqa"
      ],
      "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term\nMemory (LSTM) models were studied to provide sequential relationships for each\ntimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot\nstudy, we compared three QCNN-LSTM models for binary classification of MS\ndisability benchmarked against classical neural network architectures. Our\nhypothesis is that quantum models will provide competitive performance. Methods\nMatrix Product State (MPS), reverse Multistate Entanglement Renormalization\nAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM\nlayer to process near-annual MRI data of patients diagnosed with MS. These were\nbenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision\nTransformer (ViViT). Predicted logits were measured against ground truth labels\nof each patient's Extended Disability Severity Score (EDSS) using binary\ncross-entropy loss. Training/validation/holdout testing was partitioned using\n5-fold cross validation with a total split of 60:20:20. Levene's test of\nvariance was used to measure statistical difference and Student's t-test for\npaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and\nTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively\n(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73\nand 0.77, respectively (p-value 0.631). Overall variance and mean were not\nstatistically significant (p-value 0.713), however, time to train was\nsignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,\nrespectively, p-value <0.001). Conclusion QCNN-LSTM models perform\ncompetitively to their classical counterparts with greater efficiency in train\ntime. Clinically, these can add value in terms of efficiency to time-dependent\ndeep learning prediction of disease progression based upon medical imaging.",
      "tldr_zh": "本研究评估了 QCNN-LSTM 模型在多发性硬化（Multiple Sclerosis, MS）患者残疾预测中的性能，使用序列多序列 MRI 数据进行分析。研究比较了三种量子模型（MPS-LSTM、reverse MERA-LSTM 和 TTN-LSTM）与经典模型（VGG-LSTM 和 ViViT）在二元分类任务上的表现，基于 Extended Disability Severity Score (EDSS) 标签进行评估。结果显示，量子模型的 ROC-AUC 分别为 0.70、0.77 和 0.81，与经典模型（0.73 和 0.77）的性能相当，但训练时间显著更快（39.4 秒 vs. 224 和 218 秒）。总之，QCNN-LSTM 模型展示了与传统方法竞争力的效率优势，有望提升基于医疗影像的疾病进展预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "eess.IV",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12132v1",
      "published_date": "2024-01-22 17:14:47 UTC",
      "updated_date": "2024-01-22 17:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:21:42.561135"
    },
    {
      "arxiv_id": "2401.12273v2",
      "title": "The Ethics of Interaction: Mitigating Security Threats in LLMs",
      "title_zh": "互动的伦理：缓解大型语言模型中的安全威胁",
      "authors": [
        "Ashutosh Kumar",
        "Shiv Vignesh Murthy",
        "Sagarika Singh",
        "Swathy Ragupathy"
      ],
      "abstract": "This paper comprehensively explores the ethical challenges arising from\nsecurity threats to Large Language Models (LLMs). These intricate digital\nrepositories are increasingly integrated into our daily lives, making them\nprime targets for attacks that can compromise their training data and the\nconfidentiality of their data sources. The paper delves into the nuanced\nethical repercussions of such security threats on society and individual\nprivacy. We scrutinize five major threats--prompt injection, jailbreaking,\nPersonal Identifiable Information (PII) exposure, sexually explicit content,\nand hate-based content--going beyond mere identification to assess their\ncritical ethical consequences and the urgency they create for robust defensive\nstrategies. The escalating reliance on LLMs underscores the crucial need for\nensuring these systems operate within the bounds of ethical norms, particularly\nas their misuse can lead to significant societal and individual harm. We\npropose conceptualizing and developing an evaluative tool tailored for LLMs,\nwhich would serve a dual purpose: guiding developers and designers in\npreemptive fortification of backend systems and scrutinizing the ethical\ndimensions of LLM chatbot responses during the testing phase. By comparing LLM\nresponses with those expected from humans in a moral context, we aim to discern\nthe degree to which AI behaviors align with the ethical values held by a\nbroader society. Ultimately, this paper not only underscores the ethical\ntroubles presented by LLMs; it also highlights a path toward cultivating trust\nin these systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的安全威胁及其伦理挑战，包括 prompt injection、jailbreaking、Personal Identifiable Information (PII) exposure、sexually explicit content 和 hate-based content 等五大威胁，并评估了这些问题对社会和个人隐私的潜在危害。作者强调了强化防御策略的紧迫性，以防止 LLMs 被滥用导致严重后果。论文提出开发一个专属评估工具，用于指导开发者在后端系统加固和测试阶段审查 LLM 响应的伦理维度，通过与人类道德行为的比较，确保 AI 行为符合社会价值观。最终，该研究为提升对 LLMs 的信任提供了关键路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12273v2",
      "published_date": "2024-01-22 17:11:37 UTC",
      "updated_date": "2024-07-10 09:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:21:55.056511"
    },
    {
      "arxiv_id": "2401.12113v2",
      "title": "Extracting Formulae in Many-Valued Logic from Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yani Zhang",
        "Helmut Bölcskei"
      ],
      "abstract": "We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.",
      "tldr_zh": "该论文提出了一种新视角，将深度 ReLU networks 视为 Lukasiewicz infinite-valued logic 的电路对应物，这是一种多值（Many-Valued）逻辑的推广。研究团队呈现了一个算法，用于从深度 ReLU networks 中提取 Many-Valued Logic 公式，该算法适用于具有一般权重（如实值权重）的网络。最终，这使得可以从基于数据的训练网络中提取逻辑公式，从而为解释神经网络决策提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "Signicant extension of the previous version",
      "pdf_url": "http://arxiv.org/pdf/2401.12113v2",
      "published_date": "2024-01-22 16:51:01 UTC",
      "updated_date": "2025-03-06 11:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:22:04.992912"
    },
    {
      "arxiv_id": "2401.12108v1",
      "title": "On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using Streaming Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremias Dötterl",
        "Ralf Bruns",
        "Jürgen Dunkel",
        "Sascha Ossowski"
      ],
      "abstract": "In parcel delivery, the \"last mile\" from the parcel hub to the customer is\ncostly, especially for time-sensitive delivery tasks that have to be completed\nwithin hours after arrival. Recently, crowdshipping has attracted increased\nattention as a new alternative to traditional delivery modes. In crowdshipping,\nprivate citizens (\"the crowd\") perform short detours in their daily lives to\ncontribute to parcel delivery in exchange for small incentives. However,\nachieving desirable crowd behavior is challenging as the crowd is highly\ndynamic and consists of autonomous, self-interested individuals. Leveraging\ncrowdshipping for time-sensitive deliveries remains an open challenge. In this\npaper, we present an agent-based approach to on-time parcel delivery with\ncrowds. Our system performs data stream processing on the couriers' smartphone\nsensor data to predict delivery delays. Whenever a delay is predicted, the\nsystem attempts to forge an agreement for transferring the parcel from the\ncurrent deliverer to a more promising courier nearby. Our experiments show that\nthrough accurate delay predictions and purposeful task transfers many delays\ncan be prevented that would occur without our approach.",
      "tldr_zh": "该论文探讨了 crowdshipping 系统中的及时递送问题，针对最后一英里时间敏感任务的挑战，提出了一种 agent-based approach，利用 streaming data 处理 courier 的智能手机传感器数据来预测递送延误。系统在检测到延误风险时，通过协商将包裹转移给附近更可靠的 courier，从而主动防止延误发生。实验结果显示，该方法显著减少了潜在延误，比传统方式更有效。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12108v1",
      "published_date": "2024-01-22 16:45:15 UTC",
      "updated_date": "2024-01-22 16:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:22:17.957779"
    },
    {
      "arxiv_id": "2401.12086v2",
      "title": "West-of-N: Synthetic Preferences for Self-Improving Reward Models",
      "title_zh": "West-of-N：",
      "authors": [
        "Alizée Pace",
        "Jonathan Mallinson",
        "Eric Malmi",
        "Sebastian Krause",
        "Aliaksei Severyn"
      ],
      "abstract": "The success of reinforcement learning from human feedback (RLHF) in language\nmodel alignment is strongly dependent on the quality of the underlying reward\nmodel. In this paper, we present a novel approach to improve reward model\nquality by generating synthetic preference data, thereby augmenting the\ntraining dataset with on-policy, high-quality preference pairs. Motivated by\nthe promising results of Best-of-N sampling strategies in language model\ntraining, we extend their application to reward model training. This results in\na self-training strategy to generate preference pairs by selecting the best and\nworst candidates in a pool of responses to a given query. Empirically, we find\nthat this approach improves the performance of any reward model, with an effect\ncomparable to the addition of a similar quantity of human preference data. This\nwork opens up new avenues of research for improving RLHF for language model\nalignment, by offering synthetic preference generation as a solution to reward\nmodeling challenges.",
      "tldr_zh": "该论文提出West-of-N方法，通过生成合成偏好数据来提升奖励模型（reward model）的质量，从而改善强化学习从人类反馈（RLHF）在语言模型对齐中的性能。具体而言，该方法扩展了Best-of-N采样策略，采用自训练机制从查询响应池中选择最佳和最差候选生成偏好对。实验结果显示，这种合成数据生成方式能显著提高奖励模型的表现，其效果相当于添加等量的人类偏好数据，为RLHF的优化提供新的研究路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12086v2",
      "published_date": "2024-01-22 16:24:43 UTC",
      "updated_date": "2024-10-25 12:04:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:22:29.726522"
    },
    {
      "arxiv_id": "2401.12070v3",
      "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text",
      "title_zh": "翻译失败",
      "authors": [
        "Abhimanyu Hans",
        "Avi Schwarzschild",
        "Valeriia Cherepanova",
        "Hamid Kazemi",
        "Aniruddha Saha",
        "Micah Goldblum",
        "Jonas Geiping",
        "Tom Goldstein"
      ],
      "abstract": "Detecting text generated by modern large language models is thought to be\nhard, as both LLMs and humans can exhibit a wide range of complex behaviors.\nHowever, we find that a score based on contrasting two closely related language\nmodels is highly accurate at separating human-generated and machine-generated\ntext. Based on this mechanism, we propose a novel LLM detector that only\nrequires simple calculations using a pair of pre-trained LLMs. The method,\ncalled Binoculars, achieves state-of-the-art accuracy without any training\ndata. It is capable of spotting machine text from a range of modern LLMs\nwithout any model-specific modifications. We comprehensively evaluate\nBinoculars on a number of text sources and in varied situations. Over a wide\nrange of document types, Binoculars detects over 90% of generated samples from\nChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being\ntrained on any ChatGPT data.",
      "tldr_zh": "这篇论文提出了一种名为 Binoculars 的零样本方法，用于检测大型语言模型（LLMs）生成文本，通过对比两个预训练 LLMs 的分数来区分人类和机器生成内容，从而避免了训练数据的依赖。Binoculars 能够在不进行模型特定修改的情况下，准确识别各种现代 LLMs（如 ChatGPT）生成的文本。实验结果显示，在假正率仅 0.01% 的情况下，该方法对多种文档类型检测超过 90% 的机器生成样本，实现了 state-of-the-art 准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, code available at https://github.com/ahans30/Binoculars",
      "pdf_url": "http://arxiv.org/pdf/2401.12070v3",
      "published_date": "2024-01-22 16:09:47 UTC",
      "updated_date": "2024-10-13 19:12:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:22:41.816953"
    },
    {
      "arxiv_id": "2401.12051v1",
      "title": "CloSe: A 3D Clothing Segmentation Dataset and Model",
      "title_zh": "CloSe：3D 服装分割数据集和模型",
      "authors": [
        "Dimitrije Antić",
        "Garvita Tiwari",
        "Batuhan Ozcomlekci",
        "Riccardo Marin",
        "Gerard Pons-Moll"
      ],
      "abstract": "3D Clothing modeling and datasets play crucial role in the entertainment,\nanimation, and digital fashion industries. Existing work often lacks detailed\nsemantic understanding or uses synthetic datasets, lacking realism and\npersonalization. To address this, we first introduce CloSe-D: a novel\nlarge-scale dataset containing 3D clothing segmentation of 3167 scans, covering\na range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,\nthe first learning-based 3D clothing segmentation model for fine-grained\nsegmentation from colored point clouds. CloSe-Net uses local point features,\nbody-clothing correlation, and a garment-class and point features-based\nattention module, improving performance over baselines and prior work. The\nproposed attention module enables our model to learn appearance and\ngeometry-dependent clothing prior from data. We further validate the efficacy\nof our approach by successfully segmenting publicly available datasets of\npeople in clothing. We also introduce CloSe-T, a 3D interactive tool for\nrefining segmentation labels. Combining the tool with CloSe-T in a continual\nlearning setup demonstrates improved generalization on real-world data.\nDataset, model, and tool can be found at\nhttps://virtualhumans.mpi-inf.mpg.de/close3dv24/.",
      "tldr_zh": "本研究引入了CloSe-D，一种大规模3D服装分割数据集，包含3167个扫描和18个服装类别，以解决现有数据集缺乏真实性和语义细节的问题。论文提出CloSe-Net，一种基于学习的3D服装分割模型，利用局部点特征、身体-服装相关性以及基于服装类别和点特征的注意力模块，从彩色点云中实现细粒度分割，并从数据中学习外观和几何相关的服装先验。实验结果显示，CloSe-Net在基准上性能优于现有方法，并在公开数据集上验证了其有效性；此外，作者还开发了CloSe-T交互工具，通过持续学习提升模型在真实世界数据的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12051v1",
      "published_date": "2024-01-22 15:42:21 UTC",
      "updated_date": "2024-01-22 15:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:22:54.876566"
    },
    {
      "arxiv_id": "2402.10067v1",
      "title": "LLM-based policy generation for intent-based management of applications",
      "title_zh": "翻译失败",
      "authors": [
        "Kristina Dzeparoska",
        "Jieyu Lin",
        "Ali Tizghadam",
        "Alberto Leon-Garcia"
      ],
      "abstract": "Automated management requires decomposing high-level user requests, such as\nintents, to an abstraction that the system can understand and execute. This is\nchallenging because even a simple intent requires performing a number of\nordered steps. And the task of identifying and adapting these steps (as\nconditions change) requires a decomposition approach that cannot be exactly\npre-defined beforehand. To tackle these challenges and support automated intent\ndecomposition and execution, we explore the few-shot capability of Large\nLanguage Models (LLMs). We propose a pipeline that progressively decomposes\nintents by generating the required actions using a policy-based abstraction.\nThis allows us to automate the policy execution by creating a closed control\nloop for the intent deployment. To do so, we generate and map the policies to\nAPIs and form application management loops that perform the necessary\nmonitoring, analysis, planning and execution. We evaluate our proposal with a\nuse-case to fulfill and assure an application service chain of virtual network\nfunctions. Using our approach, we can generalize and generate the necessary\nsteps to realize intents, thereby enabling intent automation for application\nmanagement.",
      "tldr_zh": "这篇论文提出了一种基于Large Language Models (LLMs)的政策生成方法，用于应用的意图-based管理，旨在解决高层用户意图分解和执行的挑战。方法采用few-shot学习构建一个管道，通过逐步生成基于政策的抽象，将意图分解为有序动作，并映射到APIs以形成封闭的控制循环，包括监控、分析、规划和执行。实验通过一个应用服务链的虚拟网络函数用例验证了该方法，能够泛化生成必要步骤，从而实现应用的意图自动化管理。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.FL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "This article has been accepted for publication in 2023 19th\n  International Conference on Network and Service Management (CNSM), 3rd\n  International Workshop on Analytics for Service and Application Management\n  (AnServApp 2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.10067v1",
      "published_date": "2024-01-22 15:37:04 UTC",
      "updated_date": "2024-01-22 15:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:23:06.626813"
    },
    {
      "arxiv_id": "2402.01688v1",
      "title": "An Online Hierarchical Energy Management System for Energy Communities, Complying with the Current Technical Legislation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Antonino Capillo",
        "Enrico De Santis",
        "Fabio Massimo Frattale Mascioli",
        "Antonello Rizzi"
      ],
      "abstract": "Efforts in the fight against Climate Change are increasingly oriented towards\nnew energy efficiency strategies in Smart Grids (SGs). In 2018, with proper\nlegislation, the European Union (EU) defined the Renewable Energy Community\n(REC) as a local electrical grid whose participants share their self-produced\nrenewable energy, aiming at reducing bill costs by taking advantage of proper\nincentives. That action aspires to accelerate the spread of local renewable\nenergy exploitation, whose costs could not be within everyone's reach. Since a\nREC is technically an SG, the strategies above can be applied, and\nspecifically, practical Energy Management Systems (EMSs) are required.\nTherefore, in this work, an online Hierarchical EMS (HEMS) is synthesized for\nREC cost minimization to evaluate its superiority over a local self-consumption\napproach. EU technical indications (as inherited from Italy) are diligently\nfollowed, aiming for results that are as realistic as possible. Power flows\nbetween REC nodes, or Microgrids (MGs) are optimized by taking Energy Storage\nSystems (ESSs) and PV plant costs, energy purchase costs, and REC incentives. A\nhybrid Fuzzy Inference System - Genetic Algorithm (FIS-GA) model is implemented\nwith the GA encoding the FIS parameters. Power generation and consumption,\nwhich are the overall system input, are predicted by a LSTM trained on\nhistorical data. The proposed hierarchical model achieves good precision in\nshort computation times and outperforms the self-consumption approach, leading\nto about 20% savings compared to the latter. In addition, the Explainable AI\n(XAI), which characterizes the model through the FIS, makes results more\nreliable thanks to an excellent human interpretation level. To finish, the HEMS\nis parametrized so that it is straightforward to switch to another Country's\ntechnical legislation framework.",
      "tldr_zh": "该研究提出了一种在线 Hierarchical Energy Management System (HEMS) 用于 Renewable Energy Community (REC)，旨在通过优化电力流动来最小化社区能源成本，同时严格遵守欧盟（如意大利）的技术法规框架。HEMS 整合了 Energy Storage Systems (ESSs)、光伏 (PV) 设施成本、能源采购成本以及 REC 激励机制，并采用混合 Fuzzy Inference System - Genetic Algorithm (FIS-GA) 模型结合 LSTM 预测来处理电力生成和消费数据。实验结果显示，该系统相较于本地自消费方法可节省约 20% 的成本，并通过 Explainable AI (XAI) 提升了结果的可解释性和可靠性；此外，系统设计灵活，便于适应其他国家的法规框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01688v1",
      "published_date": "2024-01-22 15:29:54 UTC",
      "updated_date": "2024-01-22 15:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:23:19.032714"
    },
    {
      "arxiv_id": "2401.12032v1",
      "title": "MINT: A wrapper to make multi-modal and multi-image AI models interactive",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Freyberg",
        "Abhijit Guha Roy",
        "Terry Spitz",
        "Beverly Freeman",
        "Mike Schaekermann",
        "Patricia Strachan",
        "Eva Schnider",
        "Renee Wong",
        "Dale R Webster",
        "Alan Karthikesalingam",
        "Yun Liu",
        "Krishnamurthy Dvijotham",
        "Umesh Telang"
      ],
      "abstract": "During the diagnostic process, doctors incorporate multimodal information\nincluding imaging and the medical history - and similarly medical AI\ndevelopment has increasingly become multimodal. In this paper we tackle a more\nsubtle challenge: doctors take a targeted medical history to obtain only the\nmost pertinent pieces of information; how do we enable AI to do the same? We\ndevelop a wrapper method named MINT (Make your model INTeractive) that\nautomatically determines what pieces of information are most valuable at each\nstep, and ask for only the most useful information. We demonstrate the efficacy\nof MINT wrapping a skin disease prediction model, where multiple images and a\nset of optional answers to $25$ standard metadata questions (i.e., structured\nmedical history) are used by a multi-modal deep network to provide a\ndifferential diagnosis. We show that MINT can identify whether metadata inputs\nare needed and if so, which question to ask next. We also demonstrate that when\ncollecting multiple images, MINT can identify if an additional image would be\nbeneficial, and if so, which type of image to capture. We showed that MINT\nreduces the number of metadata and image inputs needed by 82% and 36.2%\nrespectively, while maintaining predictive performance. Using real-world AI\ndermatology system data, we show that needing fewer inputs can retain users\nthat may otherwise fail to complete the system submission and drop off without\na diagnosis. Qualitative examples show MINT can closely mimic the step-by-step\ndecision making process of a clinical workflow and how this is different for\nstraight forward cases versus more difficult, ambiguous cases. Finally we\ndemonstrate how MINT is robust to different underlying multi-model classifiers\nand can be easily adapted to user requirements without significant model\nre-training.",
      "tldr_zh": "本研究提出了一种名为 MINT 的包装器方法，用于使多模态和多图像 AI 模型变得交互式，模仿医生有针对性地获取信息。MINT 通过自动评估每个步骤中最有价值的输入，仅请求必要的元数据或图像，从而应用于皮肤病预测模型中。实验结果显示，MINT 减少了 82% 的元数据输入和 36.2% 的图像输入，同时保持预测性能，并能提高用户保留率，避免用户中途放弃。总之，MINT 能模拟临床决策流程，对不同多模态分类器具有鲁棒性，且易于适应用户需求而不需大量重新训练。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.12032v1",
      "published_date": "2024-01-22 15:17:54 UTC",
      "updated_date": "2024-01-22 15:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:23:29.889736"
    },
    {
      "arxiv_id": "2401.12024v1",
      "title": "Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Dave",
        "Fotios Lygerakis",
        "Elmar Rueckert"
      ],
      "abstract": "The rapidly evolving field of robotics necessitates methods that can\nfacilitate the fusion of multiple modalities. Specifically, when it comes to\ninteracting with tangible objects, effectively combining visual and tactile\nsensory data is key to understanding and navigating the complex dynamics of the\nphysical world, enabling a more nuanced and adaptable response to changing\nenvironments. Nevertheless, much of the earlier work in merging these two\nsensory modalities has relied on supervised methods utilizing datasets labeled\nby humans.This paper introduces MViTac, a novel methodology that leverages\ncontrastive learning to integrate vision and touch sensations in a\nself-supervised fashion. By availing both sensory inputs, MViTac leverages\nintra and inter-modality losses for learning representations, resulting in\nenhanced material property classification and more adept grasping prediction.\nThrough a series of experiments, we showcase the effectiveness of our method\nand its superiority over existing state-of-the-art self-supervised and\nsupervised techniques. In evaluating our methodology, we focus on two distinct\ntasks: material classification and grasping success prediction. Our results\nindicate that MViTac facilitates the development of improved modality encoders,\nyielding more robust representations as evidenced by linear probing\nassessments.",
      "tldr_zh": "这篇论文提出了一种名为 MViTac 的新方法，通过自监督对比学习(Self-Supervised Contrastive Pre-Training)来整合视觉和触觉模态，实现多模态表示学习，以提升机器人对物理世界的理解。MViTac 利用 intra 和 inter-modality losses 来学习鲁棒的表示，应用于材料属性分类和抓取成功预测任务。实验结果表明，该方法优于现有自监督和监督技术，在线性探测评估中显示出更高的准确性和鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12024v1",
      "published_date": "2024-01-22 15:11:57 UTC",
      "updated_date": "2024-01-22 15:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:23:42.764729"
    },
    {
      "arxiv_id": "2402.00045v5",
      "title": "Detecting Multimedia Generated by Large AI Models: A Survey",
      "title_zh": "检测大型AI模型生成的多媒体：综述",
      "authors": [
        "Li Lin",
        "Neeraj Gupta",
        "Yue Zhang",
        "Hainan Ren",
        "Chun-Hao Liu",
        "Feng Ding",
        "Xin Wang",
        "Xin Li",
        "Luisa Verdoliva",
        "Shu Hu"
      ],
      "abstract": "The rapid advancement of Large AI Models (LAIMs), particularly diffusion\nmodels and large language models, has marked a new era where AI-generated\nmultimedia is increasingly integrated into various aspects of daily life.\nAlthough beneficial in numerous fields, this content presents significant\nrisks, including potential misuse, societal disruptions, and ethical concerns.\nConsequently, detecting multimedia generated by LAIMs has become crucial, with\na marked rise in related research. Despite this, there remains a notable gap in\nsystematic surveys that focus specifically on detecting LAIM-generated\nmultimedia. Addressing this, we provide the first survey to comprehensively\ncover existing research on detecting multimedia (such as text, images, videos,\naudio, and multimodal content) created by LAIMs. Specifically, we introduce a\nnovel taxonomy for detection methods, categorized by media modality, and\naligned with two perspectives: pure detection (aiming to enhance detection\nperformance) and beyond detection (adding attributes like generalizability,\nrobustness, and interpretability to detectors). Additionally, we have presented\na brief overview of generation mechanisms, public datasets, online detection\ntools, and evaluation metrics to provide a valuable resource for researchers\nand practitioners in this field. Most importantly, we offer a focused analysis\nfrom a social media perspective to highlight their broader societal impact.\nFurthermore, we identify current challenges in detection and propose directions\nfor future research that address unexplored, ongoing, and emerging issues in\ndetecting multimedia generated by LAIMs. Our aim for this survey is to fill an\nacademic gap and contribute to global AI security efforts, helping to ensure\nthe integrity of information in the digital realm. The project link is\nhttps://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.",
      "tldr_zh": "这篇调查论文探讨了检测由 Large AI Models (LAIMs) 生成的多媒体内容的重要性，包括文本、图像、视频、音频和多模态内容，以应对潜在的滥用和社会风险。论文首次提出了一种新颖的分类法，按媒体模态划分，并从纯检测（提升性能）和超越检测（增强泛化性、鲁棒性和可解释性）两个视角系统总结现有研究。作者还概述了生成机制、公共数据集、在线工具、评估指标，并从社交媒体角度分析其社会影响，同时指出了当前挑战并提出未来研究方向，以支持全球 AI 安全和信息完整性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00045v5",
      "published_date": "2024-01-22 15:08:19 UTC",
      "updated_date": "2025-05-14 16:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:23:54.339363"
    },
    {
      "arxiv_id": "2402.01686v1",
      "title": "A Systematic Mapping Study of Digital Twins for Diagnosis in Transportation",
      "title_zh": "翻译失败",
      "authors": [
        "Liliana Marie Prikler",
        "Franz Wotawa"
      ],
      "abstract": "In recent years, digital twins have been proposed and implemented in various\nfields with potential applications ranging from prototyping to maintenance.\nGoing forward, they are to enable numerous efficient and sustainable\ntechnologies, among them autonomous cars. However, despite a large body of\nresearch in many fields, academics have yet to agree on what exactly a digital\ntwin is -- and as a result, what its capabilities and limitations might be. To\nfurther our understanding, we explore the capabilities of digital twins\nconcerning diagnosis in the field of transportation. We conduct a systematic\nmapping study including digital twins of vehicles and their components, as well\nas transportation infrastructure. We discovered that few papers on digital\ntwins describe any diagnostic process. Furthermore, most existing approaches\nappear limited to system monitoring or fault detection. These findings suggest\nthat we need more research for diagnostic reasoning utilizing digital twins.",
      "tldr_zh": "本研究通过系统映射研究（systematic mapping study）探讨了数字孪生（digital twins）在交通领域诊断的应用，涵盖车辆及其组件以及交通基础设施。结果显示，尽管数字孪生在原型设计和维护等方面有潜力，但现有文献中鲜有描述完整的诊断过程，大多数方法仅限于系统监控或故障检测。研究发现，这一局限性凸显了需要进一步开展诊断推理方面的研究，以充分发挥数字孪生在可持续技术和自主车辆（如autonomous cars）中的作用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01686v1",
      "published_date": "2024-01-22 15:01:37 UTC",
      "updated_date": "2024-01-22 15:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:24:05.177783"
    },
    {
      "arxiv_id": "2401.12014v1",
      "title": "Robustness to distribution shifts of compressed networks for edge devices",
      "title_zh": "边缘设备压缩网络对分布偏移的鲁棒性",
      "authors": [
        "Lulan Shen",
        "Ali Edalati",
        "Brett Meyer",
        "Warren Gross",
        "James J. Clark"
      ],
      "abstract": "It is necessary to develop efficient DNNs deployed on edge devices with\nlimited computation resources. However, the compressed networks often execute\nnew tasks in the target domain, which is different from the source domain where\nthe original network is trained. It is important to investigate the robustness\nof compressed networks in two types of data distribution shifts: domain shifts\nand adversarial perturbations. In this study, we discover that compressed\nmodels are less robust to distribution shifts than their original networks.\nInterestingly, larger networks are more vulnerable to losing robustness than\nsmaller ones, even when they are compressed to a similar size as the smaller\nnetworks. Furthermore, compact networks obtained by knowledge distillation are\nmuch more robust to distribution shifts than pruned networks. Finally,\npost-training quantization is a reliable method for achieving significant\nrobustness to distribution shifts, and it outperforms both pruned and distilled\nmodels in terms of robustness.",
      "tldr_zh": "本研究探讨了部署在边缘设备的压缩神经网络(DNNs)对数据分布偏移的鲁棒性，包括领域偏移(domain shifts)和对抗性扰动(adversarial perturbations)。研究发现，压缩模型比原始网络更易受分布偏移影响，且较大网络在压缩后更容易丧失鲁棒性，即使压缩到与小型网络类似的大小。相比之下，通过知识蒸馏(knowledge distillation)获得的紧凑网络在鲁棒性上优于剪枝(pruned)网络，而训练后量化(post-training quantization)是提升鲁棒性的可靠方法，且在整体表现上超越了剪枝和蒸馏模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12014v1",
      "published_date": "2024-01-22 15:00:32 UTC",
      "updated_date": "2024-01-22 15:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:24:19.184941"
    },
    {
      "arxiv_id": "2401.12007v3",
      "title": "Tensor-view Topological Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Wen",
        "Elynn Chen",
        "Yuzhou Chen"
      ],
      "abstract": "Graph classification is an important learning task for graph-structured data.\nGraph neural networks (GNNs) have recently gained growing attention in graph\nlearning and have shown significant improvements in many important graph\nproblems. Despite their state-of-the-art performances, existing GNNs only use\nlocal information from a very limited neighborhood around each node, suffering\nfrom loss of multi-modal information and overheads of excessive computation. To\naddress these issues, we propose a novel Tensor-view Topological Graph Neural\nNetwork (TTG-NN), a class of simple yet effective topological deep learning\nbuilt upon persistent homology, graph convolution, and tensor operations. This\nnew method incorporates tensor learning to simultaneously capture Tensor-view\nTopological (TT), as well as Tensor-view Graph (TG) structural information on\nboth local and global levels. Computationally, to fully exploit graph topology\nand structure, we propose two flexible TT and TG representation learning\nmodules that disentangle feature tensor aggregation and transformation and\nlearn to preserve multi-modal structure with less computation. Theoretically,\nwe derive high probability bounds on both the out-of-sample and in-sample mean\nsquared approximation errors for our proposed Tensor Transformation Layer\n(TTL). Real data experiments show that the proposed TTG-NN outperforms 20\nstate-of-the-art methods on various graph benchmarks.",
      "tldr_zh": "该研究针对图神经网络(GNNs)在图分类任务中的局限性（如仅依赖局部信息导致多模态信息丢失和计算开销增加）提出了一种新型Tensor-view Topological Graph Neural Network (TTG-NN)。该框架结合persistent homology、图卷积和张量操作，通过Tensor-view Topological (TT) 和Tensor-view Graph (TG)表示学习模块，同时捕获局部和全局结构信息，并解耦特征张量聚合与变换，以减少计算量。理论上，该方法为Tensor Transformation Layer (TTL)提供了高概率均方逼近误差边界；实验结果显示，TTG-NN在各种图基准上优于20种最先进方法，显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.12007v3",
      "published_date": "2024-01-22 14:55:01 UTC",
      "updated_date": "2024-01-30 03:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:24:30.099160"
    },
    {
      "arxiv_id": "2401.11963v4",
      "title": "Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey on Hybrid Algorithms",
      "title_zh": "桥接进化算法与强化学习：混合算法的全面综述",
      "authors": [
        "Pengyi Li",
        "Jianye Hao",
        "Hongyao Tang",
        "Xian Fu",
        "Yan Zheng",
        "Ke Tang"
      ],
      "abstract": "Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary\nAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, has\ndemonstrated remarkable performance advancements. By fusing both approaches,\nERL has emerged as a promising research direction. This survey offers a\ncomprehensive overview of the diverse research branches in ERL. Specifically,\nwe systematically summarize recent advancements in related algorithms and\nidentify three primary research directions: EA-assisted Optimization of RL,\nRL-assisted Optimization of EA, and synergistic optimization of EA and RL.\nFollowing that, we conduct an in-depth analysis of each research direction,\norganizing multiple research branches. We elucidate the problems that each\nbranch aims to tackle and how the integration of EAs and RL addresses these\nchallenges. In conclusion, we discuss potential challenges and prospective\nfuture research directions across various research directions. To facilitate\nresearchers in delving into ERL, we organize the algorithms and codes involved\non https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning.",
      "tldr_zh": "这篇论文对 Evolutionary Reinforcement Learning (ERL) 进行了全面调查，探讨了将 Evolutionary Algorithms (EAs) 与 Reinforcement Learning (RL) 相结合的混合算法及其性能提升。论文系统总结了最近的算法进展，并将研究分为三个主要方向：EA-assisted Optimization of RL、RL-assisted Optimization of EA，以及 EA 和 RL 的协同优化。作者通过深入分析每个方向，阐述了这些方法如何解决特定优化挑战，并讨论了潜在问题和未来研究方向。最后，论文提供了算法和代码的 GitHub 资源（https://github.com/yeshenpy/Awesome-Evolutionary-Reinforcement-Learning），以便研究者进一步探索。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11963v4",
      "published_date": "2024-01-22 14:06:37 UTC",
      "updated_date": "2024-06-22 03:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:24:43.207889"
    },
    {
      "arxiv_id": "2401.14417v1",
      "title": "Fuzzy Logic Function as a Post-hoc Explanator of the Nonlinear Classifier",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Klimo",
        "Lubomir Kralik"
      ],
      "abstract": "Pattern recognition systems implemented using deep neural networks achieve\nbetter results than linear models. However, their drawback is the black box\nproperty. This property means that one with no experience utilising nonlinear\nsystems may need help understanding the outcome of the decision. Such a\nsolution is unacceptable to the user responsible for the final decision. He\nmust not only believe in the decision but also understand it. Therefore,\nrecognisers must have an architecture that allows interpreters to interpret the\nfindings. The idea of post-hoc explainable classifiers is to design an\ninterpretable classifier parallel to the black box classifier, giving the same\ndecisions as the black box classifier. This paper shows that the explainable\nclassifier completes matching classification decisions with the black box\nclassifier on the MNIST and FashionMNIST databases if Zadeh`s fuzzy logic\nfunction forms the classifier and DeconvNet importance gives the truth values.\nSince the other tested significance measures achieved lower performance than\nDeconvNet, it is the optimal transformation of the feature values to their\ntruth values as inputs to the fuzzy logic function for the databases and\nrecogniser architecture used.",
      "tldr_zh": "本研究针对深度神经网络（Deep Neural Networks）作为非线性分类器（Nonlinear Classifier）的黑箱特性问题，提出了一种后验可解释分类器（Post-hoc Explainable Classifiers），使用 Zadeh's fuzzy logic function 作为解释器，以提供与黑箱分类器相同的决策结果。方法涉及将 DeconvNet 重要性作为特征值到真值的转换输入，构建一个可解释的并行分类器。实验在 MNIST 和 FashionMNIST 数据集上显示，该解释器实现了与黑箱分类器完全匹配的分类决策，而其他重要性措施表现较差，因此 DeconvNet 被证明是最优选择，为提升分类器可解释性提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.14417v1",
      "published_date": "2024-01-22 13:58:03 UTC",
      "updated_date": "2024-01-22 13:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:24:56.253404"
    },
    {
      "arxiv_id": "2403.08776v1",
      "title": "Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Fatma Shalabi",
        "Hichem Felouat",
        "Huy H. Nguyen",
        "Isao Echizen"
      ],
      "abstract": "Out-of-context (OOC) detection is a challenging task involving identifying\nimages and texts that are irrelevant to the context in which they are\npresented. Large vision-language models (LVLMs) are effective at various tasks,\nincluding image classification and text generation. However, the extent of\ntheir proficiency in multimodal OOC detection tasks is unclear. In this paper,\nwe investigate the ability of LVLMs to detect multimodal OOC and show that\nthese models cannot achieve high accuracy on OOC detection tasks without\nfine-tuning. However, we demonstrate that fine-tuning LVLMs on multimodal OOC\ndatasets can further improve their OOC detection accuracy. To evaluate the\nperformance of LVLMs on OOC detection tasks, we fine-tune MiniGPT-4 on the\nNewsCLIPpings dataset, a large dataset of multimodal OOC. Our results show that\nfine-tuning MiniGPT-4 on the NewsCLIPpings dataset significantly improves the\nOOC detection accuracy in this dataset. This suggests that fine-tuning can\nsignificantly improve the performance of LVLMs on OOC detection tasks.",
      "tldr_zh": "这篇论文探讨了利用基于聊天的 Large Vision-Language Models (LVLMs) 来检测多模态 Out-of-Context (OOC) 问题，即识别图像和文本与上下文无关的情况。研究发现，LVLMs 在未经微调时无法在 OOC 检测任务中达到高准确率，但通过微调这些模型，可以显著提升其性能。在 NewsCLIPpings 数据集上微调 MiniGPT-4 后，OOC 检测准确率得到明显改善，证明了微调策略的有效性。总的来说，该工作为提升 LVLMs 在多模态 OOC 检测中的应用提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 6 figures , conference",
      "pdf_url": "http://arxiv.org/pdf/2403.08776v1",
      "published_date": "2024-01-22 13:54:40 UTC",
      "updated_date": "2024-01-22 13:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:25:08.236964"
    },
    {
      "arxiv_id": "2401.11944v4",
      "title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Zhang",
        "Xinrun Du",
        "Bei Chen",
        "Yiming Liang",
        "Tongxu Luo",
        "Tianyu Zheng",
        "Kang Zhu",
        "Yuyang Cheng",
        "Chunpu Xu",
        "Shuyue Guo",
        "Haoran Zhang",
        "Xingwei Qu",
        "Junjie Wang",
        "Ruibin Yuan",
        "Yizhi Li",
        "Zekun Wang",
        "Yudong Liu",
        "Yu-Hsuan Tsai",
        "Fengji Zhang",
        "Chenghua Lin",
        "Wenhao Huang",
        "Jie Fu"
      ],
      "abstract": "As the capabilities of large multimodal models (LMMs) continue to advance,\nevaluating the performance of LMMs emerges as an increasing need. Additionally,\nthere is an even larger gap in evaluating the advanced knowledge and reasoning\nabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,\na new Chinese Massive Multi-discipline Multimodal Understanding benchmark\ndesigned to evaluate LMMs on tasks demanding college-level subject knowledge\nand deliberate reasoning in a Chinese context. CMMMU is inspired by and\nstrictly follows the annotation and analysis pattern of MMMU. CMMMU includes\n12k manually collected multimodal questions from college exams, quizzes, and\ntextbooks, covering six core disciplines: Art & Design, Business, Science,\nHealth & Medicine, Humanities & Social Science, and Tech & Engineering, like\nits companion, MMMU. These questions span 30 subjects and comprise 39 highly\nheterogeneous image types, such as charts, diagrams, maps, tables, music\nsheets, and chemical structures. CMMMU focuses on complex perception and\nreasoning with domain-specific knowledge in the Chinese context. We evaluate 11\nopen-source LLMs and one proprietary GPT-4V(ision). Even GPT-4V only achieves\naccuracies of 42%, indicating a large space for improvement. CMMMU will boost\nthe community to build the next-generation LMMs towards expert artificial\nintelligence and promote the democratization of LMMs by providing diverse\nlanguage contexts.",
      "tldr_zh": "该论文引入 CMMMU，这是一个针对中文语境的大型多学科多模态理解基准，用于评估大型多模态模型 (LMMs) 在需要大学级知识和推理的任务中的表现。CMMMU 包含 12k 个手动收集的多模态问题，覆盖艺术与设计、商业、科学、健康与医学、人文与社会科学以及技术与工程等六大领域，并涉及 30 个科目和 39 种异质图像类型，如图表、地图和化学结构。实验结果显示，即使是 GPT-4V 的准确率仅为 42%，突显了 LMMs 在中文语境下改进的空间，并旨在推动社区构建下一代专家级 AI，促进 LMMs 的多样化应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11944v4",
      "published_date": "2024-01-22 13:34:34 UTC",
      "updated_date": "2024-11-04 13:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:25:21.071733"
    },
    {
      "arxiv_id": "2401.11913v2",
      "title": "Large receptive field strategy and important feature extraction strategy in 3D object detection",
      "title_zh": "翻译失败",
      "authors": [
        "Leichao Cui",
        "Xiuxian Li",
        "Min Meng",
        "Guangyu Jia"
      ],
      "abstract": "The enhancement of 3D object detection is pivotal for precise environmental\nperception and improved task execution capabilities in autonomous driving.\nLiDAR point clouds, offering accurate depth information, serve as a crucial\ninformation for this purpose. Our study focuses on key challenges in 3D target\ndetection. To tackle the challenge of expanding the receptive field of a 3D\nconvolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).\nThis module achieves adaptive expansion of the 3D convolutional kernel's\nreceptive field, balancing the expansion with acceptable computational loads.\nThis innovation reduces operations, expands the receptive field, and allows the\nmodel to dynamically adjust to different object requirements. Simultaneously,\nwe identify redundant information in 3D features. Employing the Feature\nSelection Module (FSM) quantitatively evaluates and eliminates non-important\nfeatures, achieving the separation of output box fitting and feature\nextraction. This innovation enables the detector to focus on critical features,\nresulting in model compression, reduced computational burden, and minimized\ncandidate frame interference. Extensive experiments confirm that both DFFM and\nFSM not only enhance current benchmarks, particularly in small target\ndetection, but also accelerate network performance. Importantly, these modules\nexhibit effective complementarity.",
      "tldr_zh": "本研究针对 3D object detection 中的关键挑战，提出两种策略：Dynamic Feature Fusion Module (DFFM) 用于扩展 3D 卷积核的 receptive field，通过动态调整实现计算负载平衡和模型适应性；以及 Feature Selection Module (FSM) 用于量化评估并去除冗余特征，从而专注于重要信息并实现模型压缩。DFFM 和 FSM 相结合，不仅减少了计算负担和候选框干扰，还提升了小目标检测的准确性。实验验证显示，这两种模块在 LiDAR 点云数据上显著提高了基准性能，并展示了有效的互补性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11913v2",
      "published_date": "2024-01-22 13:01:28 UTC",
      "updated_date": "2024-03-10 10:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:25:32.709011"
    },
    {
      "arxiv_id": "2401.11911v6",
      "title": "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts When Knowledge Conflicts?",
      "title_zh": "翻译失败",
      "authors": [
        "Hexiang Tan",
        "Fei Sun",
        "Wanli Yang",
        "Yuanzhuo Wang",
        "Qi Cao",
        "Xueqi Cheng"
      ],
      "abstract": "While auxiliary information has become a key to enhancing Large Language\nModels (LLMs), relatively little is known about how LLMs merge these contexts,\nspecifically contexts generated by LLMs and those retrieved from external\nsources. To investigate this, we formulate a systematic framework to identify\nwhether LLMs' responses are attributed to either generated or retrieved\ncontexts. To easily trace the origin of the response, we construct datasets\nwith conflicting contexts, i.e., each question is paired with both generated\nand retrieved contexts, yet only one of them contains the correct answer. Our\nexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) to\nfavor generated contexts, even when they provide incorrect information. We\nfurther identify two key factors contributing to this bias: i) contexts\ngenerated by LLMs typically show greater similarity to the questions,\nincreasing their likelihood of being selected; ii) the segmentation process\nused in retrieved contexts disrupts their completeness, thereby hindering their\nfull utilization in LLMs. Our analysis enhances the understanding of how LLMs\nmerge diverse contexts, offers valuable insights for advancing current LLM\naugmentation methods, and highlights the risk of generated misinformation for\nretrieval-augmented LLMs.",
      "tldr_zh": "这篇论文研究大型语言模型(LLMs)如何合并生成上下文和检索上下文，特别是当两者知识冲突时。作者构建了一个系统框架和冲突上下文数据集，通过实验发现LLMs（如GPT-4/3.5和Llama2）显著偏好生成上下文，即使其信息不正确。关键因素包括生成上下文与问题的相似性，以及检索上下文的分割导致其不完整。该研究深化了对LLMs上下文合并机制的理解，提供改进LLM增强方法的洞见，并警示生成错误信息对retrieval-augmented LLMs的风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main, Homepage\n  (https://tan-hexiang.github.io/Blinded_by_Generated_Contexts/)",
      "pdf_url": "http://arxiv.org/pdf/2401.11911v6",
      "published_date": "2024-01-22 12:54:04 UTC",
      "updated_date": "2024-06-11 02:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:25:44.352852"
    },
    {
      "arxiv_id": "2401.13002v1",
      "title": "Theorem Discovery Amongst Cyclic Polygons",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Todd"
      ],
      "abstract": "We examine a class of geometric theorems on cyclic 2n-gons. We prove that if\nwe take n disjoint pairs of sides, each pair separated by an even number of\npolygon sides, then there is a linear combination of the angles between those\nsides which is constant. We present a formula for the linear combination, which\nprovides a theorem statement in terms of those angles. We describe a program\nwhich uses this result to generate new geometry proof problems and their\nsolutions.",
      "tldr_zh": "本研究探讨了循环 2n 边形（cyclic 2n-gons）中的几何定理，证明了如果取 n 个不相交的边对，每对边之间由偶数个边隔开，那么这些边之间角度的线性组合（linear combination）是常数。论文提供了该线性组合的公式，作为一个基于角度的定理表述。最终，该结果被用于开发一个程序，自动生成新的几何证明问题（geometry proof problems）及其解决方案，从而促进定理发现的应用。",
      "categories": [
        "cs.CG",
        "cs.AI"
      ],
      "primary_category": "cs.CG",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.13002v1",
      "published_date": "2024-01-22 12:52:55 UTC",
      "updated_date": "2024-01-22 12:52:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:25:56.399794"
    },
    {
      "arxiv_id": "2401.13704v1",
      "title": "Using Java Geometry Expert as Guide in the Preparations for Math Contests",
      "title_zh": "翻译失败",
      "authors": [
        "Ines Ganglmayr",
        "Zoltán Kovács"
      ],
      "abstract": "We give an insight into Java Geometry Expert (JGEX) in use in a school\ncontext, focusing on the Austrian school system. JGEX can offer great support\nin some classroom situations, especially for solving mathematical competition\ntasks. Also, we discuss some limitations of the program.",
      "tldr_zh": "本文探讨了 Java Geometry Expert (JGEX) 在学校环境中的应用，特别针对奥地利学校系统，展示了其在课堂教学中的潜力。JGEX 能为解决数学竞赛任务提供有力支持，帮助学生在相关情境中提升问题解决能力。同时，论文指出了该程序的一些局限性，如适用范围和功能限制，以供实际使用参考。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CG",
        "cs.SC"
      ],
      "primary_category": "cs.CY",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.13704v1",
      "published_date": "2024-01-22 12:52:07 UTC",
      "updated_date": "2024-01-22 12:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:26:07.229650"
    },
    {
      "arxiv_id": "2401.13703v1",
      "title": "Solving Some Geometry Problems of the Náboj 2023 Contest with Automated Deduction in GeoGebra Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Amela Hota",
        "Zoltán Kovács",
        "Alexander Vujic"
      ],
      "abstract": "In this article, we solve some of the geometry problems of the N\\'aboj 2023\ncompetition with the help of a computer, using examples that the software tool\nGeoGebra Discovery can calculate. In each case, the calculation requires\nsymbolic computations. We analyze the difficulty of feeding the problem into\nthe machine and set further goals to make the problems of this type of contests\neven more tractable in the future.",
      "tldr_zh": "这篇论文利用 GeoGebra Discovery 的自动演绎（Automated Deduction）功能，通过符号计算（symbolic computations）解决了 Náboj 2023 比赛中的部分几何问题。作者详细分析了将这些问题输入计算机的难度，包括数据准备和计算过程。最终，论文设定了进一步目标，以提升此类竞赛几何问题的可处理性，为未来自动化工具的应用提供参考。",
      "categories": [
        "math.HO",
        "cs.AI",
        "cs.CG",
        "cs.SC"
      ],
      "primary_category": "math.HO",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.13703v1",
      "published_date": "2024-01-22 12:51:51 UTC",
      "updated_date": "2024-01-22 12:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:26:18.725080"
    },
    {
      "arxiv_id": "2401.11906v1",
      "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad problem: Lessons Learned",
      "title_zh": "翻译失败",
      "authors": [
        "Belén Ariño-Morera",
        "Zoltán Kovács",
        "Tomás Recio",
        "Piedad Tolmos"
      ],
      "abstract": "We address, through the automated reasoning tools in GeoGebra Discovery, a\nproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying\nto solve this problem gives rise to four different kind of feedback: the almost\ninstantaneous, automated solution of the proposed problem; the measure of its\ncomplexity, according to some recent proposals; the automated discovery of a\ngeneralization of the given assertion, showing that the same statement is true\nover more general polygons than those mentioned in the problem; and the\ndifficulties associated to the analysis of the surprising and involved high\nnumber of degenerate cases that appear when using the LocusEquation command in\nthis problem. In our communication we will describe and reflect on these\ndiverse issues, enhancing its exemplar role for showing some of the advantages,\nproblems, and current fields of development of GeoGebra Discovery.",
      "tldr_zh": "本文使用 GeoGebra Discovery 的自动推理工具解决了 2023 年奥地利数学奥林匹克区域阶段的一个问题，并从中总结了四种关键反馈：即时自动解决方案、问题复杂度的测量、断言的自动泛化（适用于更一般的多边形），以及分析 LocusEquation 命令中大量退化情况的困难。研究展示了 GeoGebra Discovery 在数学问题求解中的优势，如快速发现和泛化能力，同时指出了其潜在挑战，例如处理退化案例的复杂性。这些经验教训为 GeoGebra Discovery 的未来发展和改进提供了宝贵见解。",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.SC",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.11906v1",
      "published_date": "2024-01-22 12:51:35 UTC",
      "updated_date": "2024-01-22 12:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:26:33.440505"
    },
    {
      "arxiv_id": "2401.11905v1",
      "title": "Considerations on Approaches and Metrics in Automated Theorem Generation/Finding in Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Quaresma",
        "Pierluigi Graziani",
        "Stefano M. Nicoletti"
      ],
      "abstract": "The pursue of what are properties that can be identified to permit an\nautomated reasoning program to generate and find new and interesting theorems\nis an interesting research goal (pun intended). The automatic discovery of new\ntheorems is a goal in itself, and it has been addressed in specific areas, with\ndifferent methods. The separation of the \"weeds\", uninteresting, trivial facts,\nfrom the \"wheat\", new and interesting facts, is much harder, but is also being\naddressed by different authors using different approaches. In this paper we\nwill focus on geometry. We present and discuss different approaches for the\nautomatic discovery of geometric theorems (and properties), and different\nmetrics to find the interesting theorems among all those that were generated.\nAfter this description we will introduce the first result of this article: an\nundecidability result proving that having an algorithmic procedure that decides\nfor every possible Turing Machine that produces theorems, whether it is able to\nproduce also interesting theorems, is an undecidable problem. Consequently, we\nwill argue that judging whether a theorem prover is able to produce interesting\ntheorems remains a non deterministic task, at best a task to be addressed by\nprogram based in an algorithm guided by heuristics criteria. Therefore, as a\nhuman, to satisfy this task two things are necessary: an expert survey that\nsheds light on what a theorem prover/finder of interesting geometric theorems\nis, and - to enable this analysis - other surveys that clarify metrics and\napproaches related to the interestingness of geometric theorems. In the\nconclusion of this article we will introduce the structure of two of these\nsurveys - the second result of this article - and we will discuss some future\nwork.",
      "tldr_zh": "该论文探讨了几何领域自动定理生成/发现（Automated Theorem Generation/Finding）的各种方法和指标，旨在区分有趣的定理（wheat）和琐碎事实（weeds）。作者分析了不同方法用于自动发现几何定理，以及评估定理“有趣性”的指标，并证明了一个关键问题：判断一个产生定理的Turing Machine是否能产生有趣定理是不可判定的（undecidability result）。因此，该任务被视为非确定性的，需要依赖启发式算法和专家调查来指导未来研究。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "I.2.3; F4"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.11905v1",
      "published_date": "2024-01-22 12:51:19 UTC",
      "updated_date": "2024-01-22 12:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:26:44.842576"
    },
    {
      "arxiv_id": "2401.11903v1",
      "title": "Automation of Triangle Ruler-and-Compass Constructions Using Constraint Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Milan Banković"
      ],
      "abstract": "In this paper, we present an approach to automated solving of triangle\nruler-and-compass construction problems using finite-domain constraint solvers.\nThe constraint model is described in the MiniZinc modeling language, and is\nbased on the automated planning. The main benefit of using general constraint\nsolvers for such purpose, instead of developing dedicated tools, is that we can\nrely on the efficient search that is already implemented within the solver,\nenabling us to focus on geometric aspects of the problem. We may also use the\nsolver's built-in optimization capabilities to search for the shortest possible\nconstructions. We evaluate our approach on 74 solvable problems from the\nWernick's list, and compare it to the dedicated triangle construction solver\nArgoTriCS. The results show that our approach is comparable to dedicated tools,\nwhile it requires much less effort to implement. Also, our model often finds\nshorter constructions, thanks to the optimization capabilities offered by the\nconstraint solvers.",
      "tldr_zh": "本文提出了一种使用 finite-domain constraint solvers 自动解决三角形直尺和圆规构造问题的方法，该方法基于 automated planning 并采用 MiniZinc 建模语言，允许利用求解器的现有搜索和优化功能来专注于几何方面并寻找最短构造。相比开发专用工具，这种方法实现起来更简单高效。实验在 Wernick's list 的74个可解问题上进行，结果显示其性能与专用工具 ArgoTriCS 相当，且经常发现更短的构造方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.11903v1",
      "published_date": "2024-01-22 12:50:46 UTC",
      "updated_date": "2024-01-22 12:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:26:57.219615"
    },
    {
      "arxiv_id": "2401.11900v1",
      "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Zoltán Kovács",
        "Tomás Recio",
        "M. Pilar Vélez"
      ],
      "abstract": "In our contribution we describe some on-going improvements concerning the\nAutomated Reasoning Tools developed in GeoGebra Discovery, providing different\nexamples of the performance of these new features. We describe the new\nShowProof command, that outputs both the sequence of the different steps\nperformed by GeoGebra Discovery to confirm a certain statement, as well as a\nnumber intending to grade the difficulty or interest of the assertion. The\nproposal of this assessment measure, involving the comparison of the expression\nof the thesis (or conclusion) as a combination of the hypotheses, will be\ndeveloped.",
      "tldr_zh": "这篇论文介绍了GeoGebra Discovery中Automated Reasoning Tools的改进，重点展示新的ShowProof命令。该命令不仅输出GeoGebra Discovery用于验证声明的步骤序列，还提供一个数字指标来评估声明的难度或兴趣。评估方法涉及将结论表达为假设的组合，并通过多种示例验证了这些新功能的性能，为几何证明和教育工具的优化提供了潜在价值。",
      "categories": [
        "cs.SC",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.SC",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.11900v1",
      "published_date": "2024-01-22 12:50:12 UTC",
      "updated_date": "2024-01-22 12:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:27:08.501465"
    },
    {
      "arxiv_id": "2401.11898v1",
      "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an Approach based on Constraint Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Salwa Tabet Gonzalez",
        "Predrag Janičić",
        "Julien Narboux"
      ],
      "abstract": "Conjecturing and theorem proving are activities at the center of mathematical\npractice and are difficult to separate. In this paper, we propose a framework\nfor completing incomplete conjectures and incomplete proofs. The framework can\nturn a conjecture with missing assumptions and with an under-specified goal\ninto a proper theorem. Also, the proposed framework can help in completing a\nproof sketch into a human-readable and machine-checkable proof. Our approach is\nfocused on synthetic geometry, and uses coherent logic and constraint solving.\nThe proposed approach is uniform for all three kinds of tasks, flexible and, to\nour knowledge, unique such approach.",
      "tldr_zh": "该论文提出一个基于约束求解（constraint solving）的框架，用于自动完成合成几何（synthetic geometry）中的不完整猜想和证明，从而将缺少假设或目标不明确的猜想转化为正确的定理。框架还可将证明草图转化为人类可读且机器可检查的完整证明，方法结合了coherent logic和约束求解技术。整体方法适用于多种任务、具有统一性和灵活性，据称是此类研究的独特尝试。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.11898v1",
      "published_date": "2024-01-22 12:49:08 UTC",
      "updated_date": "2024-01-22 12:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:27:20.918580"
    },
    {
      "arxiv_id": "2401.13700v1",
      "title": "Towards Automated Readable Proofs of Ruler and Compass Constructions",
      "title_zh": "翻译失败",
      "authors": [
        "Vesna Marinković",
        "Tijana Šukilović",
        "Filip Marić"
      ],
      "abstract": "Although there are several systems that successfully generate construction\nsteps for ruler and compass construction problems, none of them provides\nreadable synthetic correctness proofs for generated constructions. In the\npresent work, we demonstrate how our triangle construction solver ArgoTriCS can\ncooperate with automated theorem provers for first order logic and coherent\nlogic so that it generates construction correctness proofs, that are both\nhuman-readable and formal (can be checked by interactive theorem provers such\nas Coq or Isabelle/HOL). These proofs currently rely on many high-level lemmas\nand our goal is to have them all formally shown from the basic axioms of\ngeometry.",
      "tldr_zh": "本研究针对尺规作图（ruler and compass constructions）的自动生成问题，指出现有系统虽能产生构造步骤，但缺乏可读的合成正确性证明。作者展示了三角形构造求解器 ArgoTriCS 与第一阶逻辑和相干逻辑的自动定理证明器（automated theorem provers）合作的方法，从而生成既人类可读又正式的构造正确性证明，这些证明可由交互式定理证明器如 Coq 或 Isabelle/HOL 验证。目前，这些证明依赖于高层引理，未来目标是将它们全部从几何的基本公理中正式推导。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1"
      ],
      "primary_category": "cs.LO",
      "comment": "In Proceedings ADG 2023, arXiv:2401.10725",
      "pdf_url": "http://arxiv.org/pdf/2401.13700v1",
      "published_date": "2024-01-22 12:48:51 UTC",
      "updated_date": "2024-01-22 12:48:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:27:33.521041"
    },
    {
      "arxiv_id": "2401.13001v1",
      "title": "PatternPortrait: Draw Me Like One of Your Scribbles",
      "title_zh": "翻译失败",
      "authors": [
        "Sabine Wieluch",
        "Friedhelm Schwenker"
      ],
      "abstract": "This paper introduces a process for generating abstract portrait drawings\nfrom pictures. Their unique style is created by utilizing single freehand\npattern sketches as references to generate unique patterns for shading. The\nmethod involves extracting facial and body features from images and\ntransforming them into vector lines. A key aspect of the research is the\ndevelopment of a graph neural network architecture designed to learn sketch\nstroke representations in vector form, enabling the generation of diverse\nstroke variations. The combination of these two approaches creates joyful\nabstract drawings that are realized via a pen plotter. The presented process\ngarnered positive feedback from an audience of approximately 280 participants.",
      "tldr_zh": "该论文提出PatternPortrait方法，用于从图片生成抽象肖像画，通过单笔自由手绘图案作为参考来创建独特的阴影效果。方法包括提取面部和身体特征转化为向量线条，并开发Graph Neural Network架构来学习草图笔触表示，从而生成多样的笔触变化。最终，将这些元素结合使用笔绘机实现欢乐的抽象绘图，该过程从约280名参与者那里获得了积极反馈。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13001v1",
      "published_date": "2024-01-22 12:33:11 UTC",
      "updated_date": "2024-01-22 12:33:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:27:45.484957"
    },
    {
      "arxiv_id": "2402.16868v2",
      "title": "Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer",
      "title_zh": "基于码",
      "authors": [
        "Peigen Ye",
        "Yaping Sun",
        "Shumin Yao",
        "Hao Chen",
        "Xiaodong Xu",
        "Shuguang Cui"
      ],
      "abstract": "Codebook-based generative semantic communication attracts increasing\nattention, since only indices are required to be transmitted when the codebook\nis shared between transmitter and receiver. However, due to the fact that the\nsemantic relations among code vectors are not necessarily related to the\ndistance of the corresponding code indices, the performance of the\ncodebook-enabled semantic communication system is susceptible to the channel\nnoise. Thus, how to improve the system robustness against the noise requires\ncareful design. This paper proposes a robust codebook-assisted image semantic\ncommunication system, where semantic codec and codebook are first jointly\nconstructed, and then vector-to-index transformer is designed guided by the\ncodebook to eliminate the effects of channel noise, and achieve image\ngeneration. Thanks to the assistance of the high-quality codebook to the\nTransformer, the generated images at the receiver outperform those of the\ncompared methods in terms of visual perception. In the end, numerical results\nand generated images demonstrate the advantages of the generative semantic\ncommunication method over JPEG+LDPC and traditional joint source channel coding\n(JSCC) methods.",
      "tldr_zh": "该论文提出了一种基于codebook的生成式端到端语义通信系统，利用Transformer提升系统鲁棒性，以应对channel noise对通信性能的影响。系统通过联合构建semantic codec和codebook，并设计vector-to-index transformer来消除噪声干扰，实现高效的image generation。在数值实验和图像生成结果中，该方法在视觉感知上优于JPEG+LDPC和传统JSCC方法，展示了显著的优势。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "IEEE INFOCOM PerAI6G 2024(accepted)",
      "pdf_url": "http://arxiv.org/pdf/2402.16868v2",
      "published_date": "2024-01-22 12:19:21 UTC",
      "updated_date": "2024-03-05 18:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:27:56.975062"
    },
    {
      "arxiv_id": "2401.11880v3",
      "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Zaibin Zhang",
        "Yongting Zhang",
        "Lijun Li",
        "Hongzhi Gao",
        "Lijun Wang",
        "Huchuan Lu",
        "Feng Zhao",
        "Yu Qiao",
        "Jing Shao"
      ],
      "abstract": "Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit\nprofound capabilities in collective intelligence. However, the potential misuse\nof this intelligence for malicious purposes presents significant risks. To\ndate, comprehensive research on the safety issues associated with multi-agent\nsystems remains limited. In this paper, we explore these concerns through the\ninnovative lens of agent psychology, revealing that the dark psychological\nstates of agents constitute a significant threat to safety. To tackle these\nconcerns, we propose a comprehensive framework (PsySafe) grounded in agent\npsychology, focusing on three key areas: firstly, identifying how dark\npersonality traits in agents can lead to risky behaviors; secondly, evaluating\nthe safety of multi-agent systems from the psychological and behavioral\nperspectives, and thirdly, devising effective strategies to mitigate these\nrisks. Our experiments reveal several intriguing phenomena, such as the\ncollective dangerous behaviors among agents, agents' self-reflection when\nengaging in dangerous behavior, and the correlation between agents'\npsychological assessments and dangerous behaviors. We anticipate that our\nframework and observations will provide valuable insights for further research\ninto the safety of multi-agent systems. We will make our data and code publicly\naccessible at https://github.com/AI4Good24/PsySafe.",
      "tldr_zh": "这篇论文探讨了基于 Large Language Models (LLMs) 的多智能体系统在集体智能方面的潜力，同时强调了其被滥用于恶意目的的安全风险。作者提出一个全面框架 PsySafe，基于智能体心理学，涵盖识别黑暗个性特征导致的风险行为、从心理和行为角度评估系统安全，以及制定有效的缓解策略。实验观察到诸如智能体间的集体危险行为、智能体的自我反思现象，以及心理评估与危险行为的关联等 intriguing 现象。该框架为多智能体系统安全研究提供了宝贵洞见，并公开了数据和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11880v3",
      "published_date": "2024-01-22 12:11:55 UTC",
      "updated_date": "2024-08-20 06:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:28:10.503338"
    },
    {
      "arxiv_id": "2401.11865v1",
      "title": "Toward Semantic Interoperability of Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Idoia Berges",
        "Jesús Bermúdez",
        "Arantza Illarramendi"
      ],
      "abstract": "Although the goal of achieving semantic interoperability of electronic health\nrecords (EHRs) is pursued by many researchers, it has not been accomplished\nyet. In this paper, we present a proposal that smoothes out the way toward the\nachievement of that goal. In particular, our study focuses on medical diagnoses\nstatements. In summary, the main contributions of our ontology-based proposal\nare the following: first, it includes a canonical ontology whose EHR-related\nterms focus on semantic aspects. As a result, their descriptions are\nindependent of languages and technology aspects used in different organizations\nto represent EHRs. Moreover, those terms are related to their corresponding\ncodes in well-known medical terminologies. Second, it deals with modules that\nallow obtaining rich ontological representations of EHR information managed by\nproprietary models of health information systems. The features of one specific\nmodule are shown as reference. Third, it considers the necessary mapping axioms\nbetween ontological terms enhanced with so-called path mappings. This feature\nsmoothes out structural differences between heterogeneous EHR representations,\nallowing proper alignment of information.",
      "tldr_zh": "该论文探讨了实现电子健康记录 (EHRs) 语义互操作性的挑战，并提出了一种基于本体论的解决方案，专注于医疗诊断语句。它的主要贡献包括一个规范的本体论 (canonical ontology)，其术语独立于语言和技术细节，并与知名医疗术语代码相关联，以确保语义一致性。该提案还引入了模块化系统，用于从专有健康信息系统的EHR信息中获取丰富的本体论表示，以及映射公理 (mapping axioms) 和路径映射 (path mappings) 来处理异构结构差异，从而促进信息对齐。该方法为实现EHRs的语义互操作性铺平了道路，提升了医疗数据共享的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the Accepted Manuscript. The definitive, peer reviewed and\n  edited version of this article is: Idoia Berges, Jes\\'us Berm\\'udez, Arantza\n  Illarramendi: Toward Semantic Interoperability of Electronic Health Records.\n  IEEE Trans. Inf. Technol. Biomed. 16(3): 424-431 (2012).\n  DOI:10.1109/TITB.2011.2180917. Copyright 2011 IEEE",
      "pdf_url": "http://arxiv.org/pdf/2401.11865v1",
      "published_date": "2024-01-22 11:39:55 UTC",
      "updated_date": "2024-01-22 11:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:28:24.198944"
    },
    {
      "arxiv_id": "2401.11864v5",
      "title": "Distilling Mathematical Reasoning Capabilities into Small Language Models",
      "title_zh": "将数学",
      "authors": [
        "Xunyu Zhu",
        "Jian Li",
        "Yong Liu",
        "Can Ma",
        "Weiping Wang"
      ],
      "abstract": "This work addresses the challenge of democratizing advanced Large Language\nModels (LLMs) by compressing their mathematical reasoning capabilities into\nsub-billion parameter Small Language Models (SLMs) without compromising\nperformance. We introduce Equation-of-Thought Distillation (EoTD), a novel\ntechnique that encapsulates the reasoning process into equation-based\nrepresentations to construct an EoTD dataset for fine-tuning SLMs.\nAdditionally, we propose the Ensemble Thoughts Distillation (ETD) framework to\nenhance the reasoning performance of SLMs. This involves creating a reasoning\ndataset with multiple thought processes, including Chain-of-Thought (CoT),\nProgram-of-Thought (PoT), and Equation-of-Thought (EoT), and using it for\nfine-tuning. Our experimental performance demonstrates that EoTD significantly\nboosts the reasoning abilities of SLMs, while ETD enables these models to\nachieve state-of-the-art reasoning performance.",
      "tldr_zh": "本研究旨在将大型语言模型（LLMs）的数学推理能力压缩到小型语言模型（SLMs）中，同时保持性能不减。研究者引入了 Equation-of-Thought Distillation (EoTD)，一种将推理过程转化为基于方程的表示技术，用于构建数据集并微调 SLMs。此外，他们提出了 Ensemble Thoughts Distillation (ETD) 框架，该框架整合 Chain-of-Thought (CoT)、Program-of-Thought (PoT) 和 Equation-of-Thought (EoT) 等多种思考过程来增强 SLMs 的推理性能。实验结果表明，EoTD 显著提升了 SLMs 的推理能力，而 ETD 使这些模型达到了最先进的性能水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2401.11864v5",
      "published_date": "2024-01-22 11:37:18 UTC",
      "updated_date": "2024-08-01 04:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:28:36.456790"
    },
    {
      "arxiv_id": "2401.11860v1",
      "title": "A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuandi Wu",
        "Brett Sicard",
        "Stephen Andrew Gadsden"
      ],
      "abstract": "This study presents a comprehensive overview of PIML techniques in the\ncontext of condition monitoring. The central concept driving PIML is the\nincorporation of known physical laws and constraints into machine learning\nalgorithms, enabling them to learn from available data while remaining\nconsistent with physical principles. Through fusing domain knowledge with\ndata-driven learning, PIML methods offer enhanced accuracy and interpretability\nin comparison to purely data-driven approaches. In this comprehensive survey,\ndetailed examinations are performed with regard to the methodology by which\nknown physical principles are integrated within machine learning frameworks, as\nwell as their suitability for specific tasks within condition monitoring.\nIncorporation of physical knowledge into the ML model may be realized in a\nvariety of methods, with each having its unique advantages and drawbacks. The\ndistinct advantages and limitations of each methodology for the integration of\nphysics within data-driven models are detailed, considering factors such as\ncomputational efficiency, model interpretability, and generalizability to\ndifferent systems in condition monitoring and fault detection. Several case\nstudies and works of literature utilizing this emerging concept are presented\nto demonstrate the efficacy of PIML in condition monitoring applications. From\nthe literature reviewed, the versatility and potential of PIML in condition\nmonitoring may be demonstrated. Novel PIML methods offer an innovative solution\nfor addressing the complexities of condition monitoring and associated\nchallenges. This comprehensive survey helps form the foundation for future work\nin the field. As the technology continues to advance, PIML is expected to play\na crucial role in enhancing maintenance strategies, system reliability, and\noverall operational efficiency in engineering systems.",
      "tldr_zh": "本综述论文探讨了 Physics-Informed Machine Learning (PIML) 方法在条件监测和异常检测中的应用，核心在于将已知的物理定律和约束融入机器学习算法中，以提升模型的准确性和可解释性。论文详细分析了多种整合物理知识的策略，包括直接嵌入物理原则或使用混合框架，并评估了这些方法的优缺点，如计算效率、模型可解释性以及对不同系统的泛化能力。通过呈现多个案例研究，论文证明了 PIML 在条件监测领域的有效性，并为未来研究奠定基础，有望改善工程系统的维护策略和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper has been submitted for review to the journal Expert Systems\n  with Applications (December 31, 2023). 90 pages, 22 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.11860v1",
      "published_date": "2024-01-22 11:29:44 UTC",
      "updated_date": "2024-01-22 11:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:28:45.385723"
    },
    {
      "arxiv_id": "2401.11852v1",
      "title": "The Right Model for the Job: An Evaluation of Legal Multi-Label Classification Baselines",
      "title_zh": "合适的",
      "authors": [
        "Martina Forster",
        "Claudia Schulz",
        "Prudhvi Nokku",
        "Melicaalsadat Mirsafian",
        "Jaykumar Kasundra",
        "Stavroula Skylaki"
      ],
      "abstract": "Multi-Label Classification (MLC) is a common task in the legal domain, where\nmore than one label may be assigned to a legal document. A wide range of\nmethods can be applied, ranging from traditional ML approaches to the latest\nTransformer-based architectures. In this work, we perform an evaluation of\ndifferent MLC methods using two public legal datasets, POSTURE50K and\nEURLEX57K. By varying the amount of training data and the number of labels, we\nexplore the comparative advantage offered by different approaches in relation\nto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT\nas performing consistently well in legal MLC with reasonable computational\ndemands. T5 also demonstrates comparable performance while offering advantages\nas a generative model in the presence of changing label sets. Finally, we show\nthat the CrossEncoder exhibits potential for notable macro-F1 score\nimprovements, albeit with increased computational costs.",
      "tldr_zh": "这篇论文评估了多种多标签分类 (Multi-Label Classification, MLC) 方法在法律领域的表现，使用了两个公共数据集 POSTURE50K 和 EURLEX57K，通过改变训练数据量和标签数量来比较传统机器学习方法与 Transformer-based 架构的优劣。研究发现，DistilRoBERTa 和 LegalBERT 在法律 MLC 任务中表现出色，同时保持合理的计算需求；T5 模型也展现了可比性能，并作为生成模型在标签集变化时具有优势。最终，CrossEncoder 虽然能显著提升 macro-F1 分数，但伴随较高的计算成本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11852v1",
      "published_date": "2024-01-22 11:15:07 UTC",
      "updated_date": "2024-01-22 11:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:28:58.128228"
    },
    {
      "arxiv_id": "2401.11851v2",
      "title": "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Ji",
        "Chao Fang",
        "Zhongfeng Wang"
      ],
      "abstract": "Existing binary Transformers are promising in edge deployment due to their\ncompact model size, low computational complexity, and considerable inference\naccuracy. However, deploying binary Transformers faces challenges on prior\nprocessors due to inefficient execution of quantized matrix multiplication\n(QMM) and the energy consumption overhead caused by multi-precision\nactivations. To tackle the challenges above, we first develop a computation\nflow abstraction method for binary Transformers to improve QMM execution\nefficiency by optimizing the computation order. Furthermore, a binarized\nenergy-efficient Transformer accelerator, namely BETA, is proposed to boost the\nefficient deployment at the edge. Notably, BETA features a configurable QMM\nengine, accommodating diverse activation precisions of binary Transformers and\noffering high-parallelism and high-speed for QMMs with impressive energy\nefficiency. Experimental results evaluated on ZCU102 FPGA show BETA achieves an\naverage energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior\nFPGA-based accelerators, showing BETA's good potential for edge Transformer\nacceleration.",
      "tldr_zh": "本论文提出BETA，一种二进制能量高效Transformer加速器，旨在解决现有Binary Transformers在边缘部署中面临的量化矩阵乘法(QMM)执行低效和多精度激活能量消耗开销等问题。研究团队开发了计算流抽象方法，通过优化计算顺序提升QMM效率，并设计了可配置的QMM引擎，支持多样激活精度并实现高并行性。实验结果显示，在ZCU102 FPGA上，BETA的平均能量效率达174 GOPS/W，比现有FPGA加速器高1.76~21.92倍，展示了其在边缘Transformer加速方面的显著潜力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "This paper is accepted by 2024 IEEE International Symposium on\n  Circuits and Systems (ISCAS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11851v2",
      "published_date": "2024-01-22 11:14:08 UTC",
      "updated_date": "2024-01-23 04:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:29:10.225067"
    },
    {
      "arxiv_id": "2401.11849v3",
      "title": "Self-Labeling the Job Shop Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Corsini",
        "Angelo Porrello",
        "Simone Calderara",
        "Mauro Dell'Amico"
      ],
      "abstract": "This work proposes a self-supervised training strategy designed for\ncombinatorial problems. An obstacle in applying supervised paradigms to such\nproblems is the need for costly target solutions often produced with exact\nsolvers. Inspired by semi- and self-supervised learning, we show that\ngenerative models can be trained by sampling multiple solutions and using the\nbest one according to the problem objective as a pseudo-label. In this way, we\niteratively improve the model generation capability by relying only on its\nself-supervision, eliminating the need for optimality information. We validate\nthis Self-Labeling Improvement Method (SLIM) on the Job Shop Scheduling (JSP),\na complex combinatorial problem that is receiving much attention from the\nneural combinatorial community. We propose a generative model based on the\nwell-known Pointer Network and train it with SLIM. Experiments on popular\nbenchmarks demonstrate the potential of this approach as the resulting models\noutperform constructive heuristics and state-of-the-art learning proposals for\nthe JSP. Lastly, we prove the robustness of SLIM to various parameters and its\ngenerality by applying it to the Traveling Salesman Problem.",
      "tldr_zh": "这篇论文提出了一种自监督训练策略，名为 Self-Labeling Improvement Method (SLIM)，用于组合优化问题，以避免传统监督学习中依赖昂贵精确解的缺点。SLIM 通过生成模型采样多个解决方案，并使用问题目标下最佳解决方案作为伪标签，进行迭代自监督改进，从而提升模型性能。实验结果显示，在 Job Shop Scheduling (JSP) 基准上，该方法基于 Pointer Network 的模型优于构造性启发式算法和现有学习方法；此外，SLIM 证明了其鲁棒性和通用性，通过应用于 Traveling Salesman Problem (TSP) 进一步验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO",
        "I.2; G.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 38th Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11849v3",
      "published_date": "2024-01-22 11:08:36 UTC",
      "updated_date": "2024-10-31 11:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:29:22.852681"
    },
    {
      "arxiv_id": "2401.11848v1",
      "title": "ExtruOnt: An ontology for describing a type of manufacturing machine for Industry 4.0 systems",
      "title_zh": "翻译失败",
      "authors": [
        "Víctor Julio Ramírez-Durán",
        "Idoia Berges",
        "Arantza Illarramendi"
      ],
      "abstract": "Semantically rich descriptions of manufacturing machines, offered in a\nmachine-interpretable code, can provide interesting benefits in Industry 4.0\nscenarios. However, the lack of that type of descriptions is evident. In this\npaper we present the development effort made to build an ontology, called\nExtruOnt, for describing a type of manufacturing machine, more precisely, a\ntype that performs an extrusion process (extruder). Although the scope of the\nontology is restricted to a concrete domain, it could be used as a model for\nthe development of other ontologies for describing manufacturing machines in\nIndustry 4.0 scenarios. The terms of the ExtruOnt ontology provide different\ntypes of information related with an extruder, which are reflected in distinct\nmodules that constitute the ontology. Thus, it contains classes and properties\nfor expressing descriptions about components of an extruder, spatial\nconnections, features, and 3D representations of those components, and finally\nthe sensors used to capture indicators about the performance of this type of\nmachine. The ontology development process has been carried out in close\ncollaboration with domain experts.",
      "tldr_zh": "本论文提出了 ExtruOnt，这是一个 ontology，用于描述 Industry 4.0 系统中的一种制造机器，特别是进行挤出过程的 extruder，以提供语义丰富的机器可解释描述。该 ontology 包括模块化的类和属性，涵盖挤出机的组件、空间连接、特征、3D 表示以及性能传感器，从而填补了当前描述缺失的空白。尽管范围局限于挤出机领域，ExtruOnt 可作为开发其他制造机器 ontology 的参考模型，并通过与领域专家密切合作确保其准确性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is the accepted manuscript. The definitive, peer reviewed and\n  edited version of this article is published in Semantic Web 11(6): 887-909\n  (2020) https://doi.org/10.3233/sw-200376",
      "pdf_url": "http://arxiv.org/pdf/2401.11848v1",
      "published_date": "2024-01-22 11:05:54 UTC",
      "updated_date": "2024-01-22 11:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:29:34.373397"
    },
    {
      "arxiv_id": "2401.11844v1",
      "title": "Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field Crop Yield Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Mena",
        "Deepak Pathak",
        "Hiba Najjar",
        "Cristhian Sanchez",
        "Patrick Helber",
        "Benjamin Bischke",
        "Peter Habelitz",
        "Miro Miranda",
        "Jayanth Siddamsetty",
        "Marlon Nuske",
        "Marcela Charfuelan",
        "Diego Arenas",
        "Michaela Vollmer",
        "Andreas Dengel"
      ],
      "abstract": "Accurate crop yield prediction is of utmost importance for informed\ndecision-making in agriculture, aiding farmers, and industry stakeholders.\nHowever, this task is complex and depends on multiple factors, such as\nenvironmental conditions, soil properties, and management practices. Combining\nheterogeneous data views poses a fusion challenge, like identifying the\nview-specific contribution to the predictive task. We present a novel\nmulti-view learning approach to predict crop yield for different crops\n(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our\nmulti-view input data includes multi-spectral optical images from Sentinel-2\nsatellites and weather data as dynamic features during the crop growing season,\ncomplemented by static features like soil properties and topographic\ninformation. To effectively fuse the data, we introduce a Multi-view Gated\nFusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)\nmodule. The view-encoders handle the heterogeneity of data sources with varying\ntemporal resolutions by learning a view-specific representation. These\nrepresentations are adaptively fused via a weighted sum. The fusion weights are\ncomputed for each sample by the GU using a concatenation of the\nview-representations. The MVGF model is trained at sub-field level with 10 m\nresolution pixels. Our evaluations show that the MVGF outperforms conventional\nmodels on the same task, achieving the best results by incorporating all the\ndata sources, unlike the usual fusion results in the literature. For Argentina,\nthe MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,\nwhile at field level evaluation (comparing field averages), it reaches around\n0.80 across different countries. The GU module learned different weights based\non the country and crop-type, aligning with the variable significance of each\ndata source to the prediction task.",
      "tldr_zh": "该论文提出了一种新的多视图学习方法，用于精确预测子田作物产量（如大豆、小麦和油菜籽），针对阿根廷、乌拉圭和德国等地区的数据融合挑战。核心方法是 Multi-view Gated Fusion (MVGF) 模型，该模型通过专用的视图编码器处理异构数据（如 Sentinel-2 卫星的多光谱图像、天气数据、土壤属性和地形信息），并利用 Gated Unit (GU) 模块进行适应性加权融合。实验结果显示，MVGF 优于传统模型，在子田级别（10 m 分辨率）达到 R2 值 0.68，在田级别跨国家平均达 0.80，且 GU 模块根据国家和作物类型动态调整数据权重，突显了多源数据整合的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11844v1",
      "published_date": "2024-01-22 11:01:52 UTC",
      "updated_date": "2024-01-22 11:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:29:50.244855"
    },
    {
      "arxiv_id": "2401.11840v1",
      "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyoon Sim",
        "Sooyeon Jeon",
        "InJun Choi",
        "Guorong Wu",
        "Won Hwa Kim"
      ],
      "abstract": "Various Graph Neural Networks (GNNs) have been successful in analyzing data\nin non-Euclidean spaces, however, they have limitations such as oversmoothing,\ni.e., information becomes excessively averaged as the number of hidden layers\nincreases. The issue stems from the intrinsic formulation of conventional graph\nconvolution where the nodal features are aggregated from a direct neighborhood\nper layer across the entire nodes in the graph. As setting different number of\nhidden layers per node is infeasible, recent works leverage a diffusion kernel\nto redefine the graph structure and incorporate information from farther nodes.\nUnfortunately, such approaches suffer from heavy diagonalization of a graph\nLaplacian or learning a large transform matrix. In this regards, we propose a\ndiffusion learning framework, where the range of feature aggregation is\ncontrolled by the scale of a diffusion kernel. For efficient computation, we\nderive closed-form derivatives of approximations of the graph convolution with\nrespect to the scale, so that node-wise range can be adaptively learned. With a\ndownstream classifier, the entire framework is made trainable in an end-to-end\nmanner. Our model is tested on various standard datasets for node-wise\nclassification for the state-of-the-art performance, and it is also validated\non a real-world brain network data for graph classifications to demonstrate its\npracticality for Alzheimer classification.",
      "tldr_zh": "本论文针对图神经网络(GNNs)中的过度平滑(oversmoothing)问题，提出了一种自适应扩散核学习框架，以优化图卷积(graph convolution)过程。该框架通过控制扩散核的规模来动态调整特征聚合范围，并利用闭式导数(closed-form derivatives)实现高效计算，使节点-wise 范围可适应性学习。整个系统以端到端(end-to-end)方式训练，并在标准数据集上实现节点分类的state-of-the-art性能，同时在真实脑网络数据中验证其实际应用，如阿尔茨海默病分类。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, Accepted to AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11840v1",
      "published_date": "2024-01-22 10:57:11 UTC",
      "updated_date": "2024-01-22 10:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:29:59.969565"
    },
    {
      "arxiv_id": "2401.11819v2",
      "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Xu",
        "Hang Xue",
        "Lei Zhu",
        "Kangkang Zhao"
      ],
      "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate\nthe mathematical reasoning abilities of Chinese language models. SC-Math6 is\ndesigned as an upgraded Chinese version of the GSM8K dataset with enhanced\ndifficulty, diversity, and application scope. It consists of over 2000\nmathematical word problems requiring multi-step reasoning and providing natural\nlanguage solutions. We propose an innovative scheme to quantify the reasoning\ncapability of large models based on performance over problems with different\nreasoning steps. Experiments on 13 representative Chinese models demonstrate a\nclear stratification of reasoning levels, with top models like GPT-4 showing\nsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoning\nbenchmarks and provides a comprehensive testbed to advance the intelligence of\nChinese language models.",
      "tldr_zh": "我们引入了 SuperCLUE-Math6（SC-Math6），一个针对中文语言模型（LLMs）的多步数学推理基准数据集，作为 GSM8K 的升级版本，具有更高的难度、多样性和应用范围，包含超过 2000 个需要多步推理的数学文字问题，并提供自然语言解决方案。该数据集提出了一种创新方案，通过评估模型在不同推理步骤问题上的表现来量化其推理能力。在对 13 个代表性中文模型的实验中，结果显示出明显的推理水平分层，其中顶级模型如 GPT-4 表现出色。SC-Math6 填补了中文数学推理基准的空白，为提升中文语言模型的智能提供了一个全面的测试平台。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Dataset revised and finalized, results updated with new model; 8\n  pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.11819v2",
      "published_date": "2024-01-22 10:30:11 UTC",
      "updated_date": "2024-02-02 02:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:30:10.529825"
    },
    {
      "arxiv_id": "2401.11817v2",
      "title": "Hallucination is Inevitable: An Innate Limitation of Large Language Models",
      "title_zh": "幻觉是不可避免的：大型语言模型的一个固有限制",
      "authors": [
        "Ziwei Xu",
        "Sanjay Jain",
        "Mohan Kankanhalli"
      ],
      "abstract": "Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all the computable functions and will\ntherefore inevitably hallucinate if used as general problem solvers. Since the\nformal world is a part of the real world which is much more complicated,\nhallucinations are also inevitable for real world LLMs. Furthermore, for real\nworld LLMs constrained by provable time complexity, we describe the\nhallucination-prone tasks and empirically validate our claims. Finally, using\nthe formal world framework, we discuss the possible mechanisms and efficacies\nof existing hallucination mitigators as well as the practical implications on\nthe safe deployment of LLMs.",
      "tldr_zh": "该论文证明，大型语言模型（LLMs）的幻觉（hallucination）是其固有限制，无法完全消除。作者通过形式化定义一个形式世界，将幻觉定义为LLMs与真实函数的不一致，并运用学习理论证明LLMs无法学习所有可计算函数，因此在作为通用问题求解器时不可避免地会产生幻觉。在真实世界中，这种问题同样存在，尤其对受时间复杂度约束的LLMs，论文识别了易产生幻觉的任务并通过实验验证了这一声明。最后，论文讨论了现有幻觉缓解机制的效能及其对LLMs安全部署的实际影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11817v2",
      "published_date": "2024-01-22 10:26:14 UTC",
      "updated_date": "2025-02-13 08:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:30:23.307516"
    },
    {
      "arxiv_id": "2401.11814v1",
      "title": "Symbrain: A large-scale dataset of MRI images for neonatal brain symmetry analysis",
      "title_zh": "Symbrain: 用于新生儿大脑对称性分析的大规模 MRI 图像数据集",
      "authors": [
        "Arnaud Gucciardi",
        "Safouane El Ghazouali",
        "Francesca Venturini",
        "Vida Groznik",
        "Umberto Michelucci"
      ],
      "abstract": "This paper presents an annotated dataset of brain MRI images designed to\nadvance the field of brain symmetry study. Magnetic resonance imaging (MRI) has\ngained interest in analyzing brain symmetry in neonatal infants, and challenges\nremain due to the vast size differences between fetal and adult brains.\nClassification methods for brain structural MRI use scales and visual cues to\nassess hemisphere symmetry, which can help diagnose neonatal patients by\ncomparing hemispheres and anatomical regions of interest in the brain. Using\nthe Developing Human Connectome Project dataset, this work presents a dataset\ncomprising cerebral images extracted as slices across selected portions of\ninterest for clinical evaluation . All the extracted images are annotated with\nthe brain's midline. All the extracted images are annotated with the brain's\nmidline. From the assumption that a decrease in symmetry is directly related to\npossible clinical pathologies, the dataset can contribute to a more precise\ndiagnosis because it can be used to train deep learning model application in\nneonatal cerebral MRI anomaly detection from postnatal infant scans thanks to\ncomputer vision. Such models learn to identify and classify anomalies by\nidentifying potential asymmetrical patterns in medical MRI images. Furthermore,\nthis dataset can contribute to the research and development of methods using\nthe relative symmetry of the two brain hemispheres for crucial diagnosis and\ntreatment planning.",
      "tldr_zh": "这篇论文介绍了Symbrain数据集，这是一个大规模的注释脑MRI图像数据集，旨在推进新生儿脑对称性分析，以应对胎儿和成人脑部大小差异带来的挑战。数据集基于Developing Human Connectome Project提取的脑部切片，并标注了脑中线，假设脑对称性减少与临床病理相关。Symbrain可用于训练深度学习模型和computer vision技术，识别脑部不对称模式，从而提升新生儿MRI异常检测的诊断精度和治疗规划。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 2 figures, Dataset Paper, Medical AI",
      "pdf_url": "http://arxiv.org/pdf/2401.11814v1",
      "published_date": "2024-01-22 10:22:14 UTC",
      "updated_date": "2024-01-22 10:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:30:33.688594"
    },
    {
      "arxiv_id": "2401.11810v1",
      "title": "Generalization and Informativeness of Conformal Prediction",
      "title_zh": "保形预测的泛化与信息性",
      "authors": [
        "Matteo Zecchin",
        "Sangwoo Park",
        "Osvaldo Simeone",
        "Fredrik Hellström"
      ],
      "abstract": "The safe integration of machine learning modules in decision-making processes\nhinges on their ability to quantify uncertainty. A popular technique to achieve\nthis goal is conformal prediction (CP), which transforms an arbitrary base\npredictor into a set predictor with coverage guarantees. While CP certifies the\npredicted set to contain the target quantity with a user-defined tolerance, it\ndoes not provide control over the average size of the predicted sets, i.e.,\nover the informativeness of the prediction. In this work, a theoretical\nconnection is established between the generalization properties of the base\npredictor and the informativeness of the resulting CP prediction sets. To this\nend, an upper bound is derived on the expected size of the CP set predictor\nthat builds on generalization error bounds for the base predictor. The derived\nupper bound provides insights into the dependence of the average size of the CP\nset predictor on the amount of calibration data, the target reliability, and\nthe generalization performance of the base predictor. The theoretical insights\nare validated using simple numerical regression and classification tasks.",
      "tldr_zh": "本研究探讨了 Conformal Prediction (CP) 在机器学习中的不确定性量化问题，CP 将基础预测器转换为具有覆盖保证的集合预测器，但无法控制预测集合的平均大小（即 informativeness）。研究者建立了基础预测器的 generalization 性能与 CP 预测集合信息性之间的理论联系，通过推导 CP 集合预测器预期大小的上界，该上界基于基础预测器的泛化误差，并揭示了其对校准数据量、目标可靠性和预测器性能的依赖性。最终，通过简单数值回归和分类任务的实验验证了这些理论洞见，为提升 CP 的实用性提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11810v1",
      "published_date": "2024-01-22 10:14:45 UTC",
      "updated_date": "2024-01-22 10:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:30:45.720919"
    },
    {
      "arxiv_id": "2401.11798v4",
      "title": "Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Izadi",
        "Mehran Safayani",
        "Abdolreza Mirzaei"
      ],
      "abstract": "Efficient real-time traffic prediction is crucial for reducing transportation\ntime. To predict traffic conditions, we employ a spatio-temporal graph neural\nnetwork (ST-GNN) to model our real-time traffic data as temporal graphs.\nDespite its capabilities, it often encounters challenges in delivering\nefficient real-time predictions for real-world traffic data. Recognizing the\nsignificance of timely prediction due to the dynamic nature of real-time data,\nwe employ knowledge distillation (KD) as a solution to enhance the execution\ntime of ST-GNNs for traffic prediction. In this paper, We introduce a cost\nfunction designed to train a network with fewer parameters (the student) using\ndistilled data from a complex network (the teacher) while maintaining its\naccuracy close to that of the teacher. We use knowledge distillation,\nincorporating spatial-temporal correlations from the teacher network to enable\nthe student to learn the complex patterns perceived by the teacher. However, a\nchallenge arises in determining the student network architecture rather than\nconsidering it inadvertently. To address this challenge, we propose an\nalgorithm that utilizes the cost function to calculate pruning scores,\naddressing small network architecture search issues, and jointly fine-tunes the\nnetwork resulting from each pruning stage using KD. Ultimately, we evaluate our\nproposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results\nindicate that our method can maintain the student's accuracy close to that of\nthe teacher, even with the retention of only 3% of network parameters.",
      "tldr_zh": "该研究针对实时交通预测的效率问题，提出了一种基于知识蒸馏（KD）的时空图卷积神经网络（ST-GNN）优化方法，通过将复杂教师网络的知识转移到参数更少的学生网络，从而维持高准确性并加速预测过程。具体而言，该方法设计了一个成本函数来捕捉空间-时间相关性，并引入一个算法计算修剪分数，以自动搜索和微调学生网络架构。实验在 PeMSD7 和 PeMSD8 数据集上验证，结果显示学生网络仅保留 3% 参数时，其准确性仍接近教师网络，为高效的交通预测提供了可行方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11798v4",
      "published_date": "2024-01-22 09:54:49 UTC",
      "updated_date": "2024-09-24 08:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:30:57.823711"
    },
    {
      "arxiv_id": "2401.11792v6",
      "title": "Efficient and Generalized end-to-end Autonomous Driving System with Latent Deep Reinforcement Learning and Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Zuojin Tang",
        "Xiaoyu Chen",
        "YongQiang Li",
        "Jianyu Chen"
      ],
      "abstract": "An intelligent driving system should dynamically formulate appropriate\ndriving strategies based on the current environment and vehicle status while\nensuring system security and reliability. However, methods based on\nreinforcement learning and imitation learning often suffer from high sample\ncomplexity, poor generalization, and low safety. To address these challenges,\nthis paper introduces an Efficient and Generalized end-to-end Autonomous\nDriving System (EGADS) for complex and varied scenarios. The RL agent in our\nEGADS combines variational inference with normalizing flows, which are\nindependent of distribution assumptions. This combination allows the agent to\ncapture historical information relevant to driving in latent space effectively,\nthereby significantly reducing sample complexity. Additionally, we enhance\nsafety by formulating robust safety constraints and improve generalization and\nperformance by integrating RL with expert demonstrations. Experimental results\ndemonstrate that, compared to existing methods, EGADS significantly reduces\nsample complexity, greatly improves safety performance, and exhibits strong\ngeneralization capabilities in complex urban scenarios. Particularly, we\ncontributed an expert dataset collected through human expert steering wheel\ncontrol, specifically using the G29 steering wheel.",
      "tldr_zh": "该论文针对强化学习（Reinforcement Learning）和模仿学习（Imitation Learning）在自动驾驶中存在的样本复杂度高、泛化性差和安全性低的问题，提出了一种高效且泛化的端到端系统 EGADS。EGADS 通过结合变分推理（Variational Inference）和归一化流（Normalizing Flows），在潜在空间（Latent Space）有效捕获驾驶相关历史信息，并融入稳健安全约束和专家演示，以显著降低样本复杂度并提升性能。实验结果显示，EGADS 在复杂城市场景中比现有方法减少样本复杂度、提高安全性，并展示了强大的泛化能力；此外，论文贡献了一个由人类专家使用 G29 方向盘收集的专家数据集。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11792v6",
      "published_date": "2024-01-22 09:44:16 UTC",
      "updated_date": "2024-06-16 12:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:31:11.846139"
    },
    {
      "arxiv_id": "2401.12999v2",
      "title": "Quantum-Inspired Machine Learning for Molecular Docking",
      "title_zh": "翻译失败",
      "authors": [
        "Runqiu Shu",
        "Bowen Liu",
        "Zhaoping Xiong",
        "Xiaopeng Cui",
        "Yunting Li",
        "Wei Cui",
        "Man-Hong Yung",
        "Nan Qiao"
      ],
      "abstract": "Molecular docking is an important tool for structure-based drug design,\naccelerating the efficiency of drug development. Complex and dynamic binding\nprocesses between proteins and small molecules require searching and sampling\nover a wide spatial range. Traditional docking by searching for possible\nbinding sites and conformations is computationally complex and results poorly\nunder blind docking. Quantum-inspired algorithms combining quantum properties\nand annealing show great advantages in solving combinatorial optimization\nproblems. Inspired by this, we achieve an improved in blind docking by using\nquantum-inspired combined with gradients learned by deep learning in the\nencoded molecular space. Numerical simulation shows that our method outperforms\ntraditional docking algorithms and deep learning-based algorithms over 10\\%.\nCompared to the current state-of-the-art deep learning-based docking algorithm\nDiffDock, the success rate of Top-1 (RMSD<2) achieves an improvement from 33\\%\nto 35\\% in our same setup. In particular, a 6\\% improvement is realized in the\nhigh-precision region(RMSD<1) on molecules data unseen in DiffDock, which\ndemonstrates the well-generalized of our method.",
      "tldr_zh": "本研究提出了一种Quantum-Inspired Machine Learning方法，用于Molecular Docking，以解决传统算法在盲对接中的计算复杂性和低效问题。该方法结合量子属性和退火算法，与深度学习梯度在编码的分子空间中进行优化，提升了搜索和采样过程。实验结果显示，该方法比传统算法和基于深度学习的算法提高了超过10%的性能，与最先进算法DiffDock相比，Top-1成功率（RMSD<2）从33%提升到35%，并在高精度区域（RMSD<1）上对未见分子数据实现了6%的改善，展示了优秀的泛化能力。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.12999v2",
      "published_date": "2024-01-22 09:16:41 UTC",
      "updated_date": "2024-02-22 02:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:31:23.896838"
    },
    {
      "arxiv_id": "2401.11772v2",
      "title": "LightDiC: A Simple yet Effective Approach for Large-scale Digraph Representation Learning",
      "title_zh": "LightDiC：大规模有向图表示学习的简单而有效方法",
      "authors": [
        "Xunkai Li",
        "Meihao Liao",
        "Zhengyu Wu",
        "Daohan Su",
        "Wentao Zhang",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Most existing graph neural networks (GNNs) are limited to undirected graphs,\nwhose restricted scope of the captured relational information hinders their\nexpressive capabilities and deployments in real-world scenarios. Compared with\nundirected graphs, directed graphs (digraphs) fit the demand for modeling more\ncomplex topological systems by capturing more intricate relationships between\nnodes, such as formulating transportation and financial networks. While some\ndirected GNNs have been introduced, their inspiration mainly comes from deep\nlearning architectures, which lead to redundant complexity and computation,\nmaking them inapplicable to large-scale databases. To address these issues, we\npropose LightDiC, a scalable variant of the digraph convolution based on the\nmagnetic Laplacian. Since topology-related computations are conducted solely\nduring offline pre-processing, LightDiC achieves exceptional scalability,\nenabling downstream predictions to be trained separately without incurring\nrecursive computational costs. Theoretical analysis shows that LightDiC\nutilizes directed information to achieve message passing based on the complex\nfield, which corresponds to the proximal gradient descent process of the\nDirichlet energy optimization function from the perspective of digraph signal\ndenoising, ensuring its expressiveness. Experimental results demonstrate that\nLightDiC performs comparably well or even outperforms other SOTA methods in\nvarious downstream tasks, with fewer learnable parameters and higher training\nefficiency. Notably, LightDiC is the first DiGNN to provide satisfactory\nresults in the most representative large-scale database (ogbn-papers100M).",
      "tldr_zh": "该研究指出，现有的图神经网络(GNNs)主要针对无向图，限制了捕捉复杂关系的表达能力，而有向图(digraphs)更适合建模如交通和金融网络等系统。为解决现有有向GNNs的计算冗余问题，提出LightDiC，一种基于magnetic Laplacian的简单可扩展有向图卷积方法，通过离线预处理拓扑计算，实现高效的消息传递，并对应于有向图信号去噪的Dirichlet能量优化函数的近端梯度下降过程。实验结果显示，LightDiC在各种下游任务中性能与SOTA方法相当或更优，具有更少的参数和更高的训练效率，并在大型数据库ogbn-papers100M上首次取得满意结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by VLDB 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11772v2",
      "published_date": "2024-01-22 09:09:10 UTC",
      "updated_date": "2024-02-18 01:40:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:31:35.672836"
    },
    {
      "arxiv_id": "2402.01685v3",
      "title": "SMUTF: Schema Matching Using Generative Tags and Hybrid Features",
      "title_zh": "SMUTF：使用生成标签和混合特征的模式匹配",
      "authors": [
        "Yu Zhang",
        "Mei Di",
        "Haozheng Luo",
        "Chenwei Xu",
        "Richard Tzong-Han Tsai"
      ],
      "abstract": "We introduce SMUTF (Schema Matching Using Generative Tags and Hybrid\nFeatures), a unique approach for large-scale tabular data schema matching (SM),\nwhich assumes that supervised learning does not affect performance in\nopen-domain tasks, thereby enabling effective cross-domain matching. This\nsystem uniquely combines rule-based feature engineering, pre-trained language\nmodels, and generative large language models. In an innovative adaptation\ninspired by the Humanitarian Exchange Language, we deploy \"generative tags\" for\neach data column, enhancing the effectiveness of SM. SMUTF exhibits extensive\nversatility, working seamlessly with any pre-existing pre-trained embeddings,\nclassification methods, and generative models.\n  Recognizing the lack of extensive, publicly available datasets for SM, we\nhave created and open-sourced the HDXSM dataset from the public humanitarian\ndata. We believe this to be the most exhaustive SM dataset currently available.\nIn evaluations across various public datasets and the novel HDXSM dataset,\nSMUTF demonstrated exceptional performance, surpassing existing\nstate-of-the-art models in terms of accuracy and efficiency, and improving the\nF1 score by 11.84% and the AUC of ROC by 5.08%. Code is available at\nhttps://github.com/fireindark707/Python-Schema-Matching.",
      "tldr_zh": "本文提出 SMUTF，一种用于大规模表格数据 Schema Matching (SM) 的创新方法，通过结合 rule-based feature engineering、pre-trained language models 和 generative large language models，实现有效的跨域匹配，并利用 generative tags 增强匹配效果。SMUTF 具有高度灵活性，可与任何现有的预训练嵌入、分类方法和生成模型无缝整合。为解决 SM 数据集缺乏的问题，研究者创建并开源了 HDXSM 数据集，这是目前最全面的公开 SM 数据集。在多种公共数据集和 HDXSM 的评估中，SMUTF 超过了现有最先进模型，提高了 F1 score 11.84% 和 AUC of ROC 5.08%，展示了其在准确性和效率方面的优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Information Systems",
      "pdf_url": "http://arxiv.org/pdf/2402.01685v3",
      "published_date": "2024-01-22 08:47:50 UTC",
      "updated_date": "2025-05-03 07:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:31:48.350212"
    },
    {
      "arxiv_id": "2401.11755v1",
      "title": "FedGTA: Topology-aware Averaging for Federated Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xunkai Li",
        "Zhengyu Wu",
        "Wentao Zhang",
        "Yinlin Zhu",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Federated Graph Learning (FGL) is a distributed machine learning paradigm\nthat enables collaborative training on large-scale subgraphs across multiple\nlocal systems. Existing FGL studies fall into two categories: (i) FGL\nOptimization, which improves multi-client training in existing machine learning\nmodels; (ii) FGL Model, which enhances performance with complex local models\nand multi-client interactions. However, most FGL optimization strategies are\ndesigned specifically for the computer vision domain and ignore graph\nstructure, presenting dissatisfied performance and slow convergence. Meanwhile,\ncomplex local model architectures in FGL Models studies lack scalability for\nhandling large-scale subgraphs and have deployment limitations. To address\nthese issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a\npersonalized optimization strategy that optimizes through topology-aware local\nsmoothing confidence and mixed neighbor features. During experiments, we deploy\nFedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.\nThis allows us to evaluate the performance and robustness of FedGTA across a\nrange of scenarios. Extensive experiments demonstrate that FedGTA achieves\nstate-of-the-art performance while exhibiting high scalability and efficiency.\nThe experiment includes ogbn-papers100M, the most representative large-scale\ngraph database so that we can verify the applicability of our method to\nlarge-scale graph learning. To the best of our knowledge, our study is the\nfirst to bridge large-scale graph learning with FGL using this optimization\nstrategy, contributing to the development of efficient and scalable FGL\nmethods.",
      "tldr_zh": "该论文提出FedGTA，一种针对Federated Graph Learning (FGL)的个性化优化策略，通过topology-aware local smoothing confidence和mixed neighbor features来处理图结构问题，提升训练性能和收敛速度。FedGTA解决了现有FGL方法在忽略图结构和可扩展性方面的不足，并在12个多规模真实数据集（如ogbn-papers100M）上进行实验，使用Louvain和Metis分割。实验结果显示，FedGTA实现了最先进性能，具有高可扩展性和效率，并首次将大型图学习与FGL优化策略相结合，促进了高效可扩展FGL方法的开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by VLDB 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11755v1",
      "published_date": "2024-01-22 08:31:53 UTC",
      "updated_date": "2024-01-22 08:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:31:57.702109"
    },
    {
      "arxiv_id": "2401.11753v1",
      "title": "From Knowledge Organization to Knowledge Representation and Back",
      "title_zh": "从知识组织到知识表示并返回",
      "authors": [
        "Fausto Giunchiglia",
        "Mayukh Bagchi",
        "Subhashis Das"
      ],
      "abstract": "Knowledge Organization (KO) and Knowledge Representation (KR) have been the\ntwo mainstream methodologies of knowledge modelling in the Information Science\ncommunity and the Artificial Intelligence community, respectively. The\nfacet-analytical tradition of KO has developed an exhaustive set of guiding\ncanons for ensuring quality in organising and managing knowledge but has\nremained limited in terms of technology-driven activities to expand its scope\nand services beyond the bibliographic universe of knowledge. KR, on the other\nhand, boasts of a robust ecosystem of technologies and technology-driven\nservice design which can be tailored to model any entity or scale to any\nservice in the entire universe of knowledge. This paper elucidates both the\nfacet-analytical KO and KR methodologies in detail and provides a functional\nmapping between them. Out of the mapping, the paper proposes an integrated\nKR-enriched KO methodology with all the standard components of a KO methodology\nplus the advanced technologies provided by the KR approach. The practical\nbenefits of the methodological integration has been exemplified through the\nflagship application of the Digital University at the University of Trento,\nItaly.",
      "tldr_zh": "这篇论文探讨了Knowledge Organization (KO) 和 Knowledge Representation (KR) 作为知识建模的两大主流方法，其中KO的facet-analytical传统提供了全面的指导准则，但受限于技术应用，而KR则拥有强大的技术生态，能扩展到更广泛的知识领域。论文详细阐述了两种方法的特性，并通过功能映射提出了一种整合的KR-enriched KO方法论，该方法结合了KO的标准组件和KR的先进技术。最终，通过意大利Trento大学Digital University的应用，展示了这一整合方法论的实际益处，如提升知识管理和服务的效率和规模。",
      "categories": [
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted @ Annals of Library and Information Studies (ALIS) Journal -\n  Ranganathan Commemorative Issue (2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11753v1",
      "published_date": "2024-01-22 08:28:28 UTC",
      "updated_date": "2024-01-22 08:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:32:09.987239"
    },
    {
      "arxiv_id": "2401.11750v1",
      "title": "AdaFGL: A New Paradigm for Federated Node Classification with Topology Heterogeneity",
      "title_zh": "AdaFGL：一种用于拓扑异质性的联邦节点分类新范式",
      "authors": [
        "Xunkai Li",
        "Zhengyu Wu",
        "Wentao Zhang",
        "Henan Sun",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Recently, Federated Graph Learning (FGL) has attracted significant attention\nas a distributed framework based on graph neural networks, primarily due to its\ncapability to break data silos. Existing FGL studies employ community split on\nthe homophilous global graph by default to simulate federated semi-supervised\nnode classification settings. Such a strategy assumes the consistency of\ntopology between the multi-client subgraphs and the global graph, where\nconnected nodes are highly likely to possess similar feature distributions and\nthe same label. However, in real-world implementations, the varying\nperspectives of local data engineering result in various subgraph topologies,\nposing unique heterogeneity challenges in FGL. Unlike the well-known label\nNon-independent identical distribution (Non-iid) problems in federated\nlearning, FGL heterogeneity essentially reveals the topological divergence\namong multiple clients, namely homophily or heterophily. To simulate and handle\nthis unique challenge, we introduce the concept of structure Non-iid split and\nthen present a new paradigm called \\underline{Ada}ptive \\underline{F}ederated\n\\underline{G}raph \\underline{L}earning (AdaFGL), a decoupled two-step\npersonalized approach. To begin with, AdaFGL employs standard multi-client\nfederated collaborative training to acquire the federated knowledge extractor\nby aggregating uploaded models in the final round at the server. Then, each\nclient conducts personalized training based on the local subgraph and the\nfederated knowledge extractor. Extensive experiments on the 12 graph benchmark\ndatasets validate the superior performance of AdaFGL over state-of-the-art\nbaselines. Specifically, in terms of test accuracy, our proposed AdaFGL\noutperforms baselines by significant margins of 3.24\\% and 5.57\\% on community\nsplit and structure Non-iid split, respectively.",
      "tldr_zh": "该论文针对 Federated Graph Learning (FGL) 中的拓扑异质性问题，提出了一种新范式 AdaFGL，以解决现实场景中子图拓扑差异（如 homophily 或 heterophily）导致的结构 Non-iid 挑战。AdaFGL 采用解耦的两步方法：首先，通过多客户端联邦协作训练获取联邦知识提取器；然后，每个客户端基于本地子图和该提取器进行个性化训练。实验在 12 个图基准数据集上验证了其优越性，测试准确率分别在社区分割和结构 Non-iid 分割上比基线提升了 3.24% 和 5.57%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11750v1",
      "published_date": "2024-01-22 08:23:31 UTC",
      "updated_date": "2024-01-22 08:23:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:32:23.702948"
    },
    {
      "arxiv_id": "2401.11748v3",
      "title": "GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient Inversion Attacks?",
      "title_zh": "GI-PIP：我们是否需要不切实际的辅助数据集用于梯度反演攻击？",
      "authors": [
        "Yu Sun",
        "Gaojian Xiong",
        "Xianxun Yao",
        "Kailang Ma",
        "Jian Cui"
      ],
      "abstract": "Deep gradient inversion attacks expose a serious threat to Federated Learning\n(FL) by accurately recovering private data from shared gradients. However, the\nstate-of-the-art heavily relies on impractical assumptions to access excessive\nauxiliary data, which violates the basic data partitioning principle of FL. In\nthis paper, a novel method, Gradient Inversion Attack using Practical Image\nPrior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits\nanomaly detection models to capture the underlying distribution from fewer\ndata, while GAN-based methods consume significant more data to synthesize\nimages. The extracted distribution is then leveraged to regulate the attack\nprocess as Anomaly Score loss. Experimental results show that GI-PIP achieves a\n16.12 dB PSNR recovery using only 3.8% data of ImageNet, while GAN-based\nmethods necessitate over 70%. Moreover, GI-PIP exhibits superior capability on\ndistribution generalization compared to GAN-based methods. Our approach\nsignificantly alleviates the auxiliary data requirement on both amount and\ndistribution in gradient inversion attacks, hence posing more substantial\nthreat to real-world FL.",
      "tldr_zh": "该研究质疑了梯度反演攻击（Gradient Inversion Attacks）是否需要不切实际的辅助数据集，并提出了一种新方法 GI-PIP，用于 Federated Learning (FL) 中的隐私数据恢复。GI-PIP 利用异常检测模型从更少的数据（如 ImageNet 的 3.8%）中捕获底层分布，并通过 Anomaly Score loss 调节攻击过程，从而避免了 GAN-based methods 的高数据需求。实验结果显示，GI-PIP 实现了 16.12 dB 的 PSNR 恢复率，并展示了优越的分布泛化能力，最终显著降低了辅助数据的数量和分布要求，对真实世界的 FL 安全构成更大威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11748v3",
      "published_date": "2024-01-22 08:20:47 UTC",
      "updated_date": "2024-04-01 12:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:32:36.439876"
    },
    {
      "arxiv_id": "2402.01684v1",
      "title": "A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs Using the CGC-LORA Algorithm",
      "title_zh": "一种在 LLMs 中",
      "authors": [
        "Chao Song",
        "Zhihao Ye",
        "Qiqiang Lin",
        "Qiuying Peng",
        "Jun Wang"
      ],
      "abstract": "With the productive evolution of large language models (LLMs) in the field of\nnatural language processing (NLP), tons of effort has been made to effectively\nfine-tune common pre-trained LLMs to fulfill a variety of tasks in one or\nmultiple specific domain. In practice, there are two prevailing ways, in which\nthe adaptation can be achieved: (i) Multiple Independent Models: Pre-trained\nLLMs are fine-tuned a few times independently using the corresponding training\nsamples from each task. (ii) An Integrated Model: Samples from all tasks are\nemployed to fine-tune a pre-trianed LLM unitedly. To address the high computing\ncost and seesawing issue simultaneously, we propose a unified framework that\nimplements a 1 + N mutli-task fine-tuning pattern in LLMs using a novel\nCustomized Gate Control (CGC) Low-rank Adaptation (LoRA) algorithm. Our work\naims to take an advantage of both MTL (i.e., CGC) and PEFT (i.e., LoRA) scheme.\nFor a given cluster of tasks, we design an innovative layer that contains two\ntypes of experts as additional trainable parameters to make LoRA be compatible\nwith MTL. To comprehensively evaluate the proposed framework, we conduct\nwell-designed experiments on two public datasets. The experimental results\ndemonstrate that the unified framework with CGC-LoRA modules achieves higher\nevaluation scores than all benchmarks on both two datasets.",
      "tldr_zh": "这篇论文提出一个统一框架，使用 Customized Gate Control (CGC) Low-rank Adaptation (LoRA) 算法，在大型语言模型 (LLMs) 中实现 1+N 多任务微调模式，以解决传统方法的高计算成本和性能波动问题。该框架结合了多任务学习 (MTL) 和参数高效微调 (PEFT) 的优势，通过设计一个创新层包含两种专家作为额外可训练参数，使 LoRA 与 MTL 兼容。在两个公共数据集上的实验结果显示，该框架的评估分数高于所有基准模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01684v1",
      "published_date": "2024-01-22 07:58:31 UTC",
      "updated_date": "2024-01-22 07:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:32:49.472256"
    },
    {
      "arxiv_id": "2402.06638v1",
      "title": "Transformers with Attentive Federated Aggregation for Time Series Stock Forecasting",
      "title_zh": "基于注意力联邦聚合的 Transformers 用于时间序列股票预测",
      "authors": [
        "Chu Myaet Thwal",
        "Ye Lin Tun",
        "Kitae Kim",
        "Seong-Bae Park",
        "Choong Seon Hong"
      ],
      "abstract": "Recent innovations in transformers have shown their superior performance in\nnatural language processing (NLP) and computer vision (CV). The ability to\ncapture long-range dependencies and interactions in sequential data has also\ntriggered a great interest in time series modeling, leading to the widespread\nuse of transformers in many time series applications. However, being the most\ncommon and crucial application, the adaptation of transformers to time series\nforecasting has remained limited, with both promising and inconsistent results.\nIn contrast to the challenges in NLP and CV, time series problems not only add\nthe complexity of order or temporal dependence among input sequences but also\nconsider trend, level, and seasonality information that much of this data is\nvaluable for decision making. The conventional training scheme has shown\ndeficiencies regarding model overfitting, data scarcity, and privacy issues\nwhen working with transformers for a forecasting task. In this work, we propose\nattentive federated transformers for time series stock forecasting with better\nperformance while preserving the privacy of participating enterprises.\nEmpirical results on various stock data from the Yahoo! Finance website\nindicate the superiority of our proposed scheme in dealing with the above\nchallenges and data heterogeneity in federated learning.",
      "tldr_zh": "该研究针对时间序列股票预测的挑战，提出了一种结合 Transformers 和 Attentive Federated Aggregation 的联邦学习框架，以解决模型过拟合、数据稀缺以及隐私保护问题。相比传统方法，该框架利用注意力机制在联邦环境中聚合数据，捕捉序列中的长期依赖性和趋势、季节性信息，同时确保参与企业的隐私。该方法在 Yahoo! Finance 的各种股票数据上实验中表现出优越性，显著提高了预测准确性，并有效处理了联邦学习中的数据异质性。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CE",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "Published in IEEE ICOIN 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.06638v1",
      "published_date": "2024-01-22 07:33:28 UTC",
      "updated_date": "2024-01-22 07:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:33:01.798112"
    },
    {
      "arxiv_id": "2401.11736v1",
      "title": "Attention on Personalized Clinical Decision Support System: Federated Learning Approach",
      "title_zh": "针对个性化临床",
      "authors": [
        "Chu Myaet Thwal",
        "Kyi Thar",
        "Ye Lin Tun",
        "Choong Seon Hong"
      ],
      "abstract": "Health management has become a primary problem as new kinds of diseases and\ncomplex symptoms are introduced to a rapidly growing modern society. Building a\nbetter and smarter healthcare infrastructure is one of the ultimate goals of a\nsmart city. To the best of our knowledge, neural network models are already\nemployed to assist healthcare professionals in achieving this goal. Typically,\ntraining a neural network requires a rich amount of data but heterogeneous and\nvulnerable properties of clinical data introduce a challenge for the\ntraditional centralized network. Moreover, adding new inputs to a medical\ndatabase requires re-training an existing model from scratch. To tackle these\nchallenges, we proposed a deep learning-based clinical decision support system\ntrained and managed under a federated learning paradigm. We focused on a novel\nstrategy to guarantee the safety of patient privacy and overcome the risk of\ncyberattacks while enabling large-scale clinical data mining. As a result, we\ncan leverage rich clinical data for training each local neural network without\nthe need for exchanging the confidential data of patients. Moreover, we\nimplemented the proposed scheme as a sequence-to-sequence model architecture\nintegrating the attention mechanism. Thus, our objective is to provide a\npersonalized clinical decision support system with evolvable characteristics\nthat can deliver accurate solutions and assist healthcare professionals in\nmedical diagnosing.",
      "tldr_zh": "该研究针对健康管理中的数据隐私和重新训练挑战，提出了一种基于Federated Learning的深度学习Clinical Decision Support System，以协助医疗专业人士。系统通过本地训练神经网络，避免交换患者机密数据，从而实现大规模临床数据挖掘并保障隐私安全。该方案采用Sequence-to-Sequence Model整合Attention Mechanism，提供个性化的、可演化的诊断支持，帮助实现准确的医疗决策。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in IEEE BigComp 2021",
      "pdf_url": "http://arxiv.org/pdf/2401.11736v1",
      "published_date": "2024-01-22 07:24:15 UTC",
      "updated_date": "2024-01-22 07:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:33:13.895638"
    },
    {
      "arxiv_id": "2401.11731v1",
      "title": "Fast and Scalable Network Slicing by Integrating Deep Learning with Lagrangian Methods",
      "title_zh": "快速且可扩展的网络切片，通过整合深度学习与拉格朗日方法",
      "authors": [
        "Tianlun Hu",
        "Qi Liao",
        "Qiang Liu",
        "Antonio Massaro",
        "Georg Carle"
      ],
      "abstract": "Network slicing is a key technique in 5G and beyond for efficiently\nsupporting diverse services. Many network slicing solutions rely on deep\nlearning to manage complex and high-dimensional resource allocation problems.\nHowever, deep learning models suffer limited generalization and adaptability to\ndynamic slicing configurations. In this paper, we propose a novel framework\nthat integrates constrained optimization methods and deep learning models,\nresulting in strong generalization and superior approximation capability. Based\non the proposed framework, we design a new neural-assisted algorithm to\nallocate radio resources to slices to maximize the network utility under\ninter-slice resource constraints. The algorithm exhibits high scalability,\naccommodating varying numbers of slices and slice configurations with ease. We\nimplement the proposed solution in a system-level network simulator and\nevaluate its performance extensively by comparing it to state-of-the-art\nsolutions including deep reinforcement learning approaches. The numerical\nresults show that our solution obtains near-optimal quality-of-service\nsatisfaction and promising generalization performance under different network\nslicing scenarios.",
      "tldr_zh": "这篇论文提出了一种快速且可伸缩的网络切片框架，通过整合深度学习和Lagrangian methods来解决5G及以上网络中复杂资源分配问题的泛化性和适应性挑战。框架设计了一个新的神经辅助算法，用于在资源约束下分配无线资源以最大化网络效用，并轻松适应不同数量的切片和配置。实验结果显示，该算法在系统级模拟器中比现有解决方案（如深度强化学习方法）表现出近优的服务质量满足和优秀的泛化性能。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 5 figures, IEEE Global Communications Conference 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.11731v1",
      "published_date": "2024-01-22 07:19:16 UTC",
      "updated_date": "2024-01-22 07:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:33:27.568797"
    },
    {
      "arxiv_id": "2401.11724v1",
      "title": "Augmenting Prototype Network with TransMix for Few-shot Hyperspectral Image Classification",
      "title_zh": "使用 TransMix 增强原型网络进行少样本高光谱图像分类",
      "authors": [
        "Chun Liu",
        "Longwei Yang",
        "Dongmei Dong",
        "Zheng Li",
        "Wei Yang",
        "Zhigang Han",
        "Jiayao Wang"
      ],
      "abstract": "Few-shot hyperspectral image classification aims to identify the classes of\neach pixel in the images by only marking few of these pixels. And in order to\nobtain the spatial-spectral joint features of each pixel, the fixed-size\npatches centering around each pixel are often used for classification. However,\nobserving the classification results of existing methods, we found that\nboundary patches corresponding to the pixels which are located at the boundary\nof the objects in the hyperspectral images, are hard to classify. These\nboundary patchs are mixed with multi-class spectral information. Inspired by\nthis, we propose to augment the prototype network with TransMix for few-shot\nhyperspectrial image classification(APNT). While taking the prototype network\nas the backbone, it adopts the transformer as feature extractor to learn the\npixel-to-pixel relation and pay different attentions to different pixels. At\nthe same time, instead of directly using the patches which are cut from the\nhyperspectral images for training, it randomly mixs up two patches to imitate\nthe boundary patches and uses the synthetic patches to train the model, with\nthe aim to enlarge the number of hard training samples and enhance their\ndiversity. And by following the data agumentation technique TransMix, the\nattention returned by the transformer is also used to mix up the labels of two\npatches to generate better labels for synthetic patches. Compared with existing\nmethods, the proposed method has demonstrated sate of the art performance and\nbetter robustness for few-shot hyperspectral image classification in our\nexperiments.",
      "tldr_zh": "本研究针对少样本（Few-shot）超光谱图像分类问题，提出了一种增强原型网络的方法（APNT），旨在解决边界像素补丁的分类困难，这些补丁往往包含多类光谱信息。APNT 以原型网络（Prototype Network）作为主干，使用 Transformer 作为特征提取器，学习像素间关系并分配不同注意力，同时通过随机混合两个补丁来模拟边界补丁，增加训练样本的多样性和数量。借鉴 TransMix 数据增强技术，该方法还利用 Transformer 的注意力机制混合标签，以生成更精确的合成补丁标签。实验结果表明，APNT 在少样本超光谱图像分类任务中实现了最先进性能和更好的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11724v1",
      "published_date": "2024-01-22 06:56:52 UTC",
      "updated_date": "2024-01-22 06:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:33:37.674300"
    },
    {
      "arxiv_id": "2401.11723v2",
      "title": "Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey and the Open Libraries Behind Them",
      "title_zh": "剖析基于机器学习的",
      "authors": [
        "Chao Liu",
        "Boxi Chen",
        "Wei Shao",
        "Chris Zhang",
        "Kelvin Wong",
        "Yi Zhang"
      ],
      "abstract": "The advent of the Internet of Things (IoT) has brought forth an era of\nunprecedented connectivity, with an estimated 80 billion smart devices expected\nto be in operation by the end of 2025. These devices facilitate a multitude of\nsmart applications, enhancing the quality of life and efficiency across various\ndomains. Machine Learning (ML) serves as a crucial technology, not only for\nanalyzing IoT-generated data but also for diverse applications within the IoT\necosystem. For instance, ML finds utility in IoT device recognition, anomaly\ndetection, and even in uncovering malicious activities. This paper embarks on a\ncomprehensive exploration of the security threats arising from ML's integration\ninto various facets of IoT, spanning various attack types including membership\ninference, adversarial evasion, reconstruction, property inference, model\nextraction, and poisoning attacks. Unlike previous studies, our work offers a\nholistic perspective, categorizing threats based on criteria such as adversary\nmodels, attack targets, and key security attributes (confidentiality,\navailability, and integrity). We delve into the underlying techniques of ML\nattacks in IoT environment, providing a critical evaluation of their mechanisms\nand impacts. Furthermore, our research thoroughly assesses 65 libraries, both\nauthor-contributed and third-party, evaluating their role in safeguarding model\nand data privacy. We emphasize the availability and usability of these\nlibraries, aiming to arm the community with the necessary tools to bolster\ntheir defenses against the evolving threat landscape. Through our comprehensive\nreview and analysis, this paper seeks to contribute to the ongoing discourse on\nML-based IoT security, offering valuable insights and practical solutions to\nsecure ML models and data in the rapidly expanding field of artificial\nintelligence in IoT.",
      "tldr_zh": "这篇论文对 Machine Learning (ML) 在 IoT 生态系统中的安全威胁进行了全面调查，涵盖了 membership inference, adversarial evasion, reconstruction, property inference, model extraction 和 poisoning attacks 等攻击类型。论文基于 adversary models、attack targets 和关键安全属性（confidentiality, availability, integrity）对这些威胁进行分类，并分析了其底层机制和对 IoT 的潜在影响。研究评估了65个开源库（包括作者贡献和第三方库），评估它们在保护模型和数据隐私方面的可用性和有效性。最终，该工作为 ML-based IoT 安全提供了宝贵见解和实用防御工具，推动了该领域的风险管理。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11723v2",
      "published_date": "2024-01-22 06:52:35 UTC",
      "updated_date": "2024-01-27 01:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:33:51.782907"
    },
    {
      "arxiv_id": "2401.11720v3",
      "title": "Graph Condensation: A Survey",
      "title_zh": "图凝聚：综述",
      "authors": [
        "Xinyi Gao",
        "Junliang Yu",
        "Tong Chen",
        "Guanhua Ye",
        "Wentao Zhang",
        "Hongzhi Yin"
      ],
      "abstract": "The rapid growth of graph data poses significant challenges in storage,\ntransmission, and particularly the training of graph neural networks (GNNs). To\naddress these challenges, graph condensation (GC) has emerged as an innovative\nsolution. GC focuses on synthesizing a compact yet highly representative graph,\nenabling GNNs trained on it to achieve performance comparable to those trained\non the original large graph. The notable efficacy of GC and its broad prospects\nhave garnered significant attention and spurred extensive research. This survey\npaper provides an up-to-date and systematic overview of GC, organizing existing\nresearch into five categories aligned with critical GC evaluation criteria:\neffectiveness, generalization, efficiency, fairness, and robustness. To\nfacilitate an in-depth and comprehensive understanding of GC, this paper\nexamines various methods under each category and thoroughly discusses two\nessential components within GC: optimization strategies and condensed graph\ngeneration. We also empirically compare and analyze representative GC methods\nwith diverse optimization strategies based on the five proposed GC evaluation\ncriteria. Finally, we explore the applications of GC in various fields, outline\nthe related open-source libraries, and highlight the present challenges and\nnovel insights, with the aim of promoting advancements in future research. The\nrelated resources can be found at\nhttps://github.com/XYGaoG/Graph-Condensation-Papers.",
      "tldr_zh": "这篇调查论文综述了Graph Condensation (GC)，一种通过合成紧凑且代表性的图来解决图数据增长在存储、传输和Graph Neural Networks (GNNs)训练方面挑战的创新方法。论文将现有研究组织成五个关键评价标准：有效性、泛化性、效率、公平性和鲁棒性，并详细探讨了优化策略和压缩图生成技术。同时，通过实验比较代表性方法，论文分析了GC在各领域的应用、开源资源，并指出了未来研究挑战和潜在进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Transactions on Knowledge and Data Engineering (TKDE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2401.11720v3",
      "published_date": "2024-01-22 06:47:00 UTC",
      "updated_date": "2025-01-27 09:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:34:02.419970"
    },
    {
      "arxiv_id": "2401.11719v1",
      "title": "SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation",
      "title_zh": "SFC：弱",
      "authors": [
        "Xinqiao Zhao",
        "Feilong Tang",
        "Xiaoyang Wang",
        "Jimin Xiao"
      ],
      "abstract": "Image-level weakly supervised semantic segmentation has received increasing\nattention due to its low annotation cost. Existing methods mainly rely on Class\nActivation Mapping (CAM) to obtain pseudo-labels for training semantic\nsegmentation models. In this work, we are the first to demonstrate that\nlong-tailed distribution in training data can cause the CAM calculated through\nclassifier weights over-activated for head classes and under-activated for tail\nclasses due to the shared features among head- and tail- classes. This degrades\npseudo-label quality and further influences final semantic segmentation\nperformance. To address this issue, we propose a Shared Feature Calibration\n(SFC) method for CAM generation. Specifically, we leverage the class prototypes\nthat carry positive shared features and propose a Multi-Scaled\nDistribution-Weighted (MSDW) consistency loss for narrowing the gap between the\nCAMs generated through classifier weights and class prototypes during training.\nThe MSDW loss counterbalances over-activation and under-activation by\ncalibrating the shared features in head-/tail-class classifier weights.\nExperimental results show that our SFC significantly improves CAM boundaries\nand achieves new state-of-the-art performances. The project is available at\nhttps://github.com/Barrett-python/SFC.",
      "tldr_zh": "本论文探讨了图像级弱监督语义分割中的问题，即训练数据长尾分布导致Class Activation Mapping (CAM)对头类过度激活、对尾类激活不足，从而影响伪标签质量和最终性能。为解决这一问题，作者提出Shared Feature Calibration (SFC)方法，该方法利用类原型提取正共享特征，并引入Multi-Scaled Distribution-Weighted (MSDW)一致性损失来校准头尾类分类器权重间的差距，实现激活平衡。实验结果表明，SFC显著改善了CAM边界，并在弱监督语义分割任务上达到了新的state-of-the-art性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11719v1",
      "published_date": "2024-01-22 06:43:13 UTC",
      "updated_date": "2024-01-22 06:43:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:34:14.516768"
    },
    {
      "arxiv_id": "2401.11713v1",
      "title": "Medical Image Debiasing by Learning Adaptive Agreement from a Biased Council",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Luo",
        "Xin Huang",
        "Minghao Wang",
        "Zhuoyue Wan",
        "Hao Chen"
      ],
      "abstract": "Deep learning could be prone to learning shortcuts raised by dataset bias and\nresult in inaccurate, unreliable, and unfair models, which impedes its adoption\nin real-world clinical applications. Despite its significance, there is a\ndearth of research in the medical image classification domain to address\ndataset bias. Furthermore, the bias labels are often agnostic, as identifying\nbiases can be laborious and depend on post-hoc interpretation. This paper\nproposes learning Adaptive Agreement from a Biased Council (Ada-ABC), a\ndebiasing framework that does not rely on explicit bias labels to tackle\ndataset bias in medical images. Ada-ABC develops a biased council consisting of\nmultiple classifiers optimized with generalized cross entropy loss to learn the\ndataset bias. A debiasing model is then simultaneously trained under the\nguidance of the biased council. Specifically, the debiasing model is required\nto learn adaptive agreement with the biased council by agreeing on the\ncorrectly predicted samples and disagreeing on the wrongly predicted samples by\nthe biased council. In this way, the debiasing model could learn the target\nattribute on the samples without spurious correlations while also avoiding\nignoring the rich information in samples with spurious correlations. We\ntheoretically demonstrated that the debiasing model could learn the target\nfeatures when the biased model successfully captures dataset bias. Moreover, to\nour best knowledge, we constructed the first medical debiasing benchmark from\nfour datasets containing seven different bias scenarios. Our extensive\nexperiments practically showed that our proposed Ada-ABC outperformed\ncompetitive approaches, verifying its effectiveness in mitigating dataset bias\nfor medical image classification. The codes and organized benchmark datasets\nwill be made publicly available.",
      "tldr_zh": "该研究针对深度学习在医疗图像分类中因数据集偏差而导致的模型不准确和不公平问题，提出了一种名为 Ada-ABC 的去偏置框架，该框架无需显式偏差标签。Ada-ABC 通过构建一个由多个分类器组成的偏置委员会，使用广义交叉熵损失来学习数据集偏差，然后训练去偏置模型，使其在偏置委员会的指导下学习自适应协议，即同意正确预测样本并反对错误预测样本，从而避免虚假相关影响。研究理论证明了该框架能有效学习目标特征，并构建了首个医疗去偏置基准，包括四个数据集和七种偏差场景；实验结果显示，Ada-ABC 优于现有方法，验证了其在缓解数据集偏差方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures, 3 tables. Code and benchmark will be released\n  via https://github.com/LLYXC/Ada-ABC/tree/main",
      "pdf_url": "http://arxiv.org/pdf/2401.11713v1",
      "published_date": "2024-01-22 06:29:52 UTC",
      "updated_date": "2024-01-22 06:29:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:34:27.862447"
    },
    {
      "arxiv_id": "2401.11708v3",
      "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Yang",
        "Zhaochen Yu",
        "Chenlin Meng",
        "Minkai Xu",
        "Stefano Ermon",
        "Bin Cui"
      ],
      "abstract": "Diffusion models have exhibit exceptional performance in text-to-image\ngeneration and editing. However, existing methods often face challenges when\nhandling complex text prompts that involve multiple objects with multiple\nattributes and relationships. In this paper, we propose a brand new\ntraining-free text-to-image generation/editing framework, namely Recaption,\nPlan and Generate (RPG), harnessing the powerful chain-of-thought reasoning\nability of multimodal LLMs to enhance the compositionality of text-to-image\ndiffusion models. Our approach employs the MLLM as a global planner to\ndecompose the process of generating complex images into multiple simpler\ngeneration tasks within subregions. We propose complementary regional diffusion\nto enable region-wise compositional generation. Furthermore, we integrate\ntext-guided image generation and editing within the proposed RPG in a\nclosed-loop fashion, thereby enhancing generalization ability. Extensive\nexperiments demonstrate our RPG outperforms state-of-the-art text-to-image\ndiffusion models, including DALL-E 3 and SDXL, particularly in multi-category\nobject composition and text-image semantic alignment. Notably, our RPG\nframework exhibits wide compatibility with various MLLM architectures (e.g.,\nMiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available\nat: https://github.com/YangLing0818/RPG-DiffusionMaster",
      "tldr_zh": "本文提出 RPG（Recaption, Plan and Generate）框架，利用 Multimodal LLMs 的链式思维能力，解决文本到图像扩散模型在处理复杂提示（如多对象、多属性关系）时的挑战。RPG 以 MLLM 作为全局规划器，将复杂图像生成分解为子区域的简单任务，并引入 complementary regional diffusion 实现区域-wise 组合生成，同时通过闭环文本引导提升泛化能力。实验结果表明，RPG 超越了 DALL-E 3 和 SDXL，在多类别对象组合及文本-图像语义对齐方面表现出色，并兼容多种 MLLM 和扩散模型架构。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024. Project:\n  https://github.com/YangLing0818/RPG-DiffusionMaster",
      "pdf_url": "http://arxiv.org/pdf/2401.11708v3",
      "published_date": "2024-01-22 06:16:29 UTC",
      "updated_date": "2024-05-05 04:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:34:39.480902"
    },
    {
      "arxiv_id": "2401.11705v1",
      "title": "Domain-Aware Cross-Attention for Cross-domain Recommendation",
      "title_zh": "领域感知交叉注意力机制用于跨域推荐",
      "authors": [
        "Yuhao Luo",
        "Shiwei Ma",
        "Mingjun Nie",
        "Changping Peng",
        "Zhangang Lin",
        "Jingping Shao",
        "Qianfang Xu"
      ],
      "abstract": "Cross-domain recommendation (CDR) is an important method to improve\nrecommender system performance, especially when observations in target domains\nare sparse. However, most existing cross-domain recommendations fail to fully\nutilize the target domain's special features and are hard to be generalized to\nnew domains. The designed network is complex and is not suitable for rapid\nindustrial deployment. Our method introduces a two-step domain-aware\ncross-attention, extracting transferable features of the source domain from\ndifferent granularity, which allows the efficient expression of both domain and\nuser interests. In addition, we simplify the training process, and our model\ncan be easily deployed on new domains. We conduct experiments on both public\ndatasets and industrial datasets, and the experimental results demonstrate the\neffectiveness of our method. We have also deployed the model in an online\nadvertising system and observed significant improvements in both\nClick-Through-Rate (CTR) and effective cost per mille (ECPM).",
      "tldr_zh": "这项研究针对跨域推荐（Cross-domain Recommendation, CDR）的问题，提出了一种两步域感知跨注意力（domain-aware cross-attention）方法，以从不同粒度提取源域的可转移特征，从而高效表达域特性和用户兴趣。相比现有方法，该方法简化了训练过程，便于快速部署到新域，同时避免了复杂网络的局限性。实验在公共和工业数据集上验证了其有效性，并在在线广告系统中实际应用后，显著提升了 Click-Through-Rate (CTR) 和 effective cost per mille (ECPM)。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2401.11705v1",
      "published_date": "2024-01-22 06:12:48 UTC",
      "updated_date": "2024-01-22 06:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:34:50.895902"
    },
    {
      "arxiv_id": "2402.01681v3",
      "title": "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications",
      "title_zh": "Emojis Decoded：利用 ChatGPT 提升社交媒体通信中的理解",
      "authors": [
        "Yuhang Zhou",
        "Paiheng Xu",
        "Xiyao Wang",
        "Xuan Lu",
        "Ge Gao",
        "Wei Ai"
      ],
      "abstract": "Emojis, which encapsulate semantics beyond mere words or phrases, have become\nprevalent in social network communications. This has spurred increasing\nscholarly interest in exploring their attributes and functionalities. However,\nemoji-related research and application face two primary challenges. First,\nresearchers typically rely on crowd-sourcing to annotate emojis in order to\nunderstand their sentiments, usage intentions, and semantic meanings. Second,\nsubjective interpretations by users can often lead to misunderstandings of\nemojis and cause the communication barrier. Large Language Models (LLMs) have\nachieved significant success in various annotation tasks, with ChatGPT\ndemonstrating expertise across multiple domains. In our study, we assess\nChatGPT's effectiveness in handling previously annotated and downstream tasks.\nOur objective is to validate the hypothesis that ChatGPT can serve as a viable\nalternative to human annotators in emoji research and that its ability to\nexplain emoji meanings can enhance clarity and transparency in online\ncommunications. Our findings indicate that ChatGPT has extensive knowledge of\nemojis. It is adept at elucidating the meaning of emojis across various\napplication scenarios and demonstrates the potential to replace human\nannotators in a range of tasks.",
      "tldr_zh": "这篇论文探讨了 Emojis 在社交媒体通信中的作用及其研究挑战，包括依赖众包标注和用户主观解释导致的误解问题。研究评估了 ChatGPT 在处理 emoji 标注任务和下游应用中的有效性，旨在验证 ChatGPT 能否替代人类标注者并通过解释 emoji 含义提升沟通透明度。结果表明，ChatGPT 拥有广泛的 emoji 知识，能够在各种场景中准确阐释其语义，并展示出取代人类标注者的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the 19th International AAAI Conference on Web and Social\n  Media (ICWSM 2025)",
      "pdf_url": "http://arxiv.org/pdf/2402.01681v3",
      "published_date": "2024-01-22 06:02:39 UTC",
      "updated_date": "2025-04-07 15:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:35:02.591997"
    },
    {
      "arxiv_id": "2401.11698v1",
      "title": "Admission Prediction in Undergraduate Applications: an Interpretable Deep Learning Approach",
      "title_zh": "本科申请中的录取预测：一种可解释的深度学习方法",
      "authors": [
        "Amisha Priyadarshini",
        "Barbara Martinez-Neda",
        "Sergio Gago-Masague"
      ],
      "abstract": "This article addresses the challenge of validating the admission committee's\ndecisions for undergraduate admissions. In recent years, the traditional review\nprocess has struggled to handle the overwhelmingly large amount of applicants'\ndata. Moreover, this traditional assessment often leads to human bias, which\nmight result in discrimination among applicants. Although classical machine\nlearning-based approaches exist that aim to verify the quantitative assessment\nmade by the application reviewers, these methods lack scalability and suffer\nfrom performance issues when a large volume of data is in place. In this\ncontext, we propose deep learning-based classifiers, namely Feed-Forward and\nInput Convex neural networks, which overcome the challenges faced by the\nexisting methods. Furthermore, we give additional insights into our model by\nincorporating an interpretability module, namely LIME. Our training and test\ndatasets comprise applicants' data with a wide range of variables and\ninformation. Our models achieve higher accuracy compared to the best-performing\ntraditional machine learning-based approach by a considerable margin of 3.03\\%.\nAdditionally, we show the sensitivity of different features and their relative\nimpacts on the overall admission decision using the LIME technique.",
      "tldr_zh": "这篇文章针对本科生录取决策的验证问题，提出了一种可解释的深度学习方法，以解决传统评估过程在处理大量申请数据时存在的偏见和可扩展性挑战。作者使用了 Feed-Forward neural networks 和 Input Convex neural networks 作为分类器，并通过 LIME 模块提供模型的可解释性，从而分析特征的敏感性和对录取决策的影响。实验结果显示，该方法比最佳传统机器学习方法准确率提高了 3.03%，为公平且高效的录取预测提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for Transdisciplinary AI 2023 conference",
      "pdf_url": "http://arxiv.org/pdf/2401.11698v1",
      "published_date": "2024-01-22 05:44:43 UTC",
      "updated_date": "2024-01-22 05:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:35:15.444903"
    },
    {
      "arxiv_id": "2402.16866v1",
      "title": "Computation Rate Maximization for Wireless Powered Edge Computing With Multi-User Cooperation",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Xing Zhang",
        "Bo Lei",
        "Qianying Zhao",
        "Min Wei",
        "Zheyan Qu",
        "Wenbo Wang"
      ],
      "abstract": "The combination of mobile edge computing (MEC) and radio frequency-based\nwireless power transfer (WPT) presents a promising technique for providing\nsustainable energy supply and computing services at the network edge. This\nstudy considers a wireless-powered mobile edge computing system that includes a\nhybrid access point (HAP) equipped with a computing unit and multiple Internet\nof Things (IoT) devices. In particular, we propose a novel muti-user\ncooperation scheme to improve computation performance, where collaborative\nclusters are dynamically formed. Each collaborative cluster comprises a source\ndevice (SD) and an auxiliary device (AD), where the SD can partition the\ncomputation task into various segments for local processing, offloading to the\nHAP, and remote execution by the AD with the assistance of the HAP.\nSpecifically, we aims to maximize the weighted sum computation rate (WSCR) of\nall the IoT devices in the network. This involves jointly optimizing\ncollaboration, time and data allocation among multiple IoT devices and the HAP,\nwhile considering the energy causality property and the minimum data processing\nrequirement of each device. Initially, an optimization algorithm based on the\ninterior-point method is designed for time and data allocation. Subsequently, a\npriority-based iterative algorithm is developed to search for a near-optimal\nsolution to the multi-user collaboration scheme. Finally, a deep learning-based\napproach is devised to further accelerate the algorithm's operation, building\nupon the initial two algorithms. Simulation results show that the performance\nof the proposed algorithms is comparable to that of the exhaustive search\nmethod, and the deep learning-based algorithm significantly reduces the\nexecution time of the algorithm.",
      "tldr_zh": "本研究探讨了无线供电边缘计算系统，结合移动边缘计算 (MEC) 和无线功率传输 (WPT)，旨在为混合访问点 (HAP) 和多个物联网 (IoT) 设备提供可持续计算服务。论文提出了一种多用户合作方案，通过动态形成协作集群（每个集群包括源设备 (SD) 和辅助设备 (AD)），并优化任务分区、本地处理、卸载和远程执行，以最大化所有 IoT 设备的加权总计算率 (WSCR)，同时考虑能量因果性 (energy causality) 和最小数据处理要求。实验结果显示，所设计的基于内点法和优先级迭代算法的优化方法性能与穷举搜索相当，而结合深度学习的方法显著缩短了算法执行时间。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Accepted to IEEE Open Journal of the Communications Society",
      "pdf_url": "http://arxiv.org/pdf/2402.16866v1",
      "published_date": "2024-01-22 05:22:19 UTC",
      "updated_date": "2024-01-22 05:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:35:28.758927"
    },
    {
      "arxiv_id": "2401.11674v1",
      "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhu",
        "Kang Li",
        "Lequan Yu",
        "Pheng-Ann Heng"
      ],
      "abstract": "Recent studies have made remarkable progress in histopathology\nclassification. Based on current successes, contemporary works proposed to\nfurther upgrade the model towards a more generalizable and robust direction\nthrough incrementally learning from the sequentially delivered domains. Unlike\nprevious parameter isolation based approaches that usually demand massive\ncomputation resources during model updating, we present a memory-efficient\nprompt tuning framework to cultivate model generalization potential in\neconomical memory cost. For each incoming domain, we reuse the existing\nparameters of the initial classification model and attach lightweight trainable\nprompts into it for customized tuning. Considering the domain heterogeneity, we\nperform decoupled prompt tuning, where we adopt a domain-specific prompt for\neach domain to independently investigate its distinctive characteristics, and\none domain-invariant prompt shared across all domains to continually explore\nthe common content embedding throughout time. All domain-specific prompts will\nbe appended to the prompt bank and isolated from further changes to prevent\nforgetting the distinctive features of early-seen domains. While the\ndomain-invariant prompt will be passed on and iteratively evolve by\nstyle-augmented prompt refining to improve model generalization capability over\ntime. In specific, we construct a graph with existing prompts and build a\nstyle-augmented graph attention network to guide the domain-invariant prompt\nexploring the overlapped latent embedding among all delivered domains for more\ndomain generic representations. We have extensively evaluated our framework\nwith two histopathology tasks, i.e., breast cancer metastasis classification\nand epithelium-stroma tissue classification, where our approach yielded\nsuperior performance and memory efficiency over the competing methods.",
      "tldr_zh": "本研究提出了一种内存高效的提示调整（prompt tuning）框架，用于增量学习（incremental learning）以提升组织病理学分类的泛化性和鲁棒性。框架通过重用初始分类模型的参数，并在每个新领域附加轻量级的可训练提示，包括领域特定提示（domain-specific prompt）来捕捉独特特征，以及共享的领域不变提示（domain-invariant prompt）来探索共同内容。所有领域特定提示被存储在提示银行中并隔离，以防止遗忘早期领域特征，而领域不变提示则通过风格增强的图注意力网络（style-augmented graph attention network）进行迭代精炼，以优化跨领域表示。实验结果显示，该框架在乳腺癌转移分类（breast cancer metastasis classification）和上皮-基质组织分类（epithelium-stroma tissue classification）任务上，优于竞争方法，并显著降低了内存消耗。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.11674v1",
      "published_date": "2024-01-22 03:24:45 UTC",
      "updated_date": "2024-01-22 03:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:35:40.863911"
    },
    {
      "arxiv_id": "2401.13699v2",
      "title": "Generative AI-Driven Human Digital Twin in IoT-Healthcare: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayuan Chen",
        "You Shi",
        "Changyan Yi",
        "Hongyang Du",
        "Jiawen Kang",
        "Dusit Niyato"
      ],
      "abstract": "The Internet of things (IoT) can significantly enhance the quality of human\nlife, specifically in healthcare, attracting extensive attentions to\nIoT-healthcare services. Meanwhile, the human digital twin (HDT) is proposed as\nan innovative paradigm that can comprehensively characterize the replication of\nthe individual human body in the digital world and reflect its physical status\nin real time. Naturally, HDT is envisioned to empower IoT-healthcare beyond the\napplication of healthcare monitoring by acting as a versatile and vivid human\ndigital testbed, simulating the outcomes and guiding the practical treatments.\nHowever, successfully establishing HDT requires high-fidelity virtual modeling\nand strong information interactions but possibly with scarce, biased and noisy\ndata. Fortunately, a recent popular technology called generative artificial\nintelligence (GAI) may be a promising solution because it can leverage advanced\nAI algorithms to automatically create, manipulate, and modify valuable while\ndiverse data. This survey particularly focuses on the implementation of\nGAI-driven HDT in IoT-healthcare. We start by introducing the background of\nIoT-healthcare and the potential of GAI-driven HDT. Then, we delve into the\nfundamental techniques and present the overall framework of GAI-driven HDT.\nAfter that, we explore the realization of GAI-driven HDT in detail, including\nGAI-enabled data acquisition, communication, data management, digital modeling,\nand data analysis. Besides, we discuss typical IoT-healthcare applications that\ncan be revolutionized by GAI-driven HDT, namely personalized health monitoring\nand diagnosis, personalized prescription, and personalized rehabilitation.\nFinally, we conclude this survey by highlighting some future research\ndirections.",
      "tldr_zh": "这篇调查综述探讨了生成式人工智能(Generative AI, GAI)驱动的人体数字孪生(Human Digital Twin, HDT)在IoT-Healthcare中的应用，旨在通过高保真建模和数据交互解决医疗数据稀缺、偏差和噪声等问题。论文介绍了GAI的基本技术和整体框架，包括数据获取、通信、管理、数字建模及分析，实现HDT在个性化健康监控、诊断、处方和康复等领域的革新。最终，该研究强调了GAI驱动HDT的潜力，并指出了未来研究方向，如增强数据交互和实际部署挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13699v2",
      "published_date": "2024-01-22 03:17:41 UTC",
      "updated_date": "2024-06-28 11:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:35:51.724988"
    },
    {
      "arxiv_id": "2401.11669v1",
      "title": "An Improved Grey Wolf Optimization Algorithm for Heart Disease Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sihan Niu",
        "Yifan Zhou",
        "Zhikai Li",
        "Shuyao Huang",
        "Yujun Zhou"
      ],
      "abstract": "This paper presents a unique solution to challenges in medical image\nprocessing by incorporating an adaptive curve grey wolf optimization (ACGWO)\nalgorithm into neural network backpropagation. Neural networks show potential\nin medical data but suffer from issues like overfitting and lack of\ninterpretability due to imbalanced and scarce data. Traditional Gray Wolf\nOptimization (GWO) also has its drawbacks, such as a lack of population\ndiversity and premature convergence. This paper addresses these problems by\nintroducing an adaptive algorithm, enhancing the standard GWO with a sigmoid\nfunction. This algorithm was extensively compared to four leading algorithms\nusing six well-known test functions, outperforming them effectively. Moreover,\nby utilizing the ACGWO, we increase the robustness and generalization of the\nneural network, resulting in more interpretable predictions. Applied to the\npublicly accessible Cleveland Heart Disease dataset, our technique surpasses\nten other methods, achieving 86.8% accuracy, indicating its potential for\nefficient heart disease prediction in the clinical setting.",
      "tldr_zh": "这篇论文提出了一种改进的Grey Wolf Optimization算法（ACGWO），通过引入sigmoid函数来解决传统GWO的种群多样性不足和过早收敛问题，从而提升神经网络在医疗图像处理中的性能，特别是针对心脏病预测的过拟合和可解释性挑战。\nACGWO算法在六种知名测试函数上与四种领先算法进行比较，表现出显著优越性，并增强了神经网络的鲁棒性和泛化能力。\n最终，该方法应用于公开的Cleveland心脏病数据集，实现了86.8%的准确率，优于其他十种方法，展示了其在临床心脏病预测中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11669v1",
      "published_date": "2024-01-22 03:07:24 UTC",
      "updated_date": "2024-01-22 03:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:36:03.979961"
    },
    {
      "arxiv_id": "2401.11666v1",
      "title": "P2DT: Mitigating Forgetting in task-incremental Learning with progressive prompt Decision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Wang",
        "Xiaoyang Qu",
        "Jing Xiao",
        "Bokui Chen",
        "Jianzong Wang"
      ],
      "abstract": "Catastrophic forgetting poses a substantial challenge for managing\nintelligent agents controlled by a large model, causing performance degradation\nwhen these agents face new tasks. In our work, we propose a novel solution -\nthe Progressive Prompt Decision Transformer (P2DT). This method enhances a\ntransformer-based model by dynamically appending decision tokens during new\ntask training, thus fostering task-specific policies. Our approach mitigates\nforgetting in continual and offline reinforcement learning scenarios. Moreover,\nP2DT leverages trajectories collected via traditional reinforcement learning\nfrom all tasks and generates new task-specific tokens during training, thereby\nretaining knowledge from previous studies. Preliminary results demonstrate that\nour model effectively alleviates catastrophic forgetting and scales well with\nincreasing task environments.",
      "tldr_zh": "该研究针对任务增量学习中的 Catastrophic forgetting 问题，提出了一种新方法 Progressive Prompt Decision Transformer (P2DT)，通过在训练新任务时动态添加 decision tokens 来增强 transformer-based 模型，从而生成任务特定的策略。P2DT 利用所有任务的 trajectories 收集自传统 reinforcement learning，并在训练过程中创建新任务特定 tokens，以保留先前知识并缓解 forgetting。该方法在 continual 和 offline reinforcement learning 场景中表现出色，初步实验结果表明它能有效减少性能下降，并适应越来越多的任务环境。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 49th IEEE International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.11666v1",
      "published_date": "2024-01-22 02:58:53 UTC",
      "updated_date": "2024-01-22 02:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:36:15.517922"
    },
    {
      "arxiv_id": "2401.11665v3",
      "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Zheng",
        "Wei Deng",
        "Christian Moya",
        "Guang Lin"
      ],
      "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach\nfrom Gaussian posterior sampling to encompass more general smooth posteriors.\nHowever, it still encounters scalability issues in high-dimensional problems\nwhen demanding high accuracy. To address this, we propose an approximate\nThompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where\nthe latter is the go-to workhorse for simulations of high-dimensional\nposteriors. Based on the standard smoothness and log-concavity conditions, we\nstudy the accelerated posterior concentration and sampling using a specific\npotential function. This design improves the sample complexity for realizing\nlogarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde\nO}(\\sqrt{d})$. The scalability and robustness of our algorithm are also\nempirically validated through synthetic experiments in high-dimensional bandit\nproblems.",
      "tldr_zh": "这篇论文提出了一种加速的 Approximate Thompson Sampling 策略，使用 Underdamped Langevin Monte Carlo 来扩展后验采样从 Gaussian posterior 到更一般的平滑后验，解决高维问题中的可扩展性挑战。基于光滑性和 log-concavity 条件，该方法通过特定潜在函数优化了样本复杂度，将实现对数遗憾的复杂度从 \\(\\mathcal{\\tilde O}(d)\\) 改进到 \\(\\mathcal{\\tilde O}(\\sqrt{d})\\)。实验结果在高维 Bandit 问题中验证了该算法的鲁棒性和可扩展性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "52 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.11665v3",
      "published_date": "2024-01-22 02:54:58 UTC",
      "updated_date": "2024-06-21 01:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:36:28.862715"
    },
    {
      "arxiv_id": "2401.11664v1",
      "title": "Zero-Space Cost Fault Tolerance for Transformer-based Language Models on ReRAM",
      "title_zh": "翻译失败",
      "authors": [
        "Bingbing Li",
        "Geng Yuan",
        "Zigeng Wang",
        "Shaoyi Huang",
        "Hongwu Peng",
        "Payman Behnam",
        "Wujie Wen",
        "Hang Liu",
        "Caiwen Ding"
      ],
      "abstract": "Resistive Random Access Memory (ReRAM) has emerged as a promising platform\nfor deep neural networks (DNNs) due to its support for parallel in-situ\nmatrix-vector multiplication. However, hardware failures, such as\nstuck-at-fault defects, can result in significant prediction errors during\nmodel inference. While additional crossbars can be used to address these\nfailures, they come with storage overhead and are not efficient in terms of\nspace, energy, and cost. In this paper, we propose a fault protection mechanism\nthat incurs zero space cost. Our approach includes: 1) differentiable structure\npruning of rows and columns to reduce model redundancy, 2) weight duplication\nand voting for robust output, and 3) embedding duplicated most significant bits\n(MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE\nbenchmark with the BERT model, and experimental results prove its\neffectiveness.",
      "tldr_zh": "本论文针对Resistive Random Access Memory (ReRAM) 上Transformer-based Language Models（如BERT）面临的硬件故障（如stuck-at-fault defects）问题，提出了一种零空间成本的故障容错机制，以避免传统方法的存储开销。机制包括可微结构剪枝(differentiable structure pruning)来减少模型冗余、权重复制和投票(weight duplication and voting)以实现鲁棒输出，以及将重复的最显著位(MSBs)嵌入模型权重。实验在GLUE基准的九个任务上评估，证明了该方法的有效性，提升了模型的可靠性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11664v1",
      "published_date": "2024-01-22 02:50:38 UTC",
      "updated_date": "2024-01-22 02:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:36:40.740279"
    },
    {
      "arxiv_id": "2401.11660v2",
      "title": "Differentiable Tree Search Network",
      "title_zh": "翻译失败",
      "authors": [
        "Dixant Mittal",
        "Wee Sun Lee"
      ],
      "abstract": "In decision-making problems with limited training data, policy functions\napproximated using deep neural networks often exhibit suboptimal performance.\nAn alternative approach involves learning a world model from the limited data\nand determining actions through online search. However, the performance is\nadversely affected by compounding errors arising from inaccuracies in the\nlearned world model. While methods like TreeQN have attempted to address these\ninaccuracies by incorporating algorithmic inductive biases into the neural\nnetwork architectures, the biases they introduce are often weak and\ninsufficient for complex decision-making tasks. In this work, we introduce\nDifferentiable Tree Search Network (D-TSN), a novel neural network architecture\nthat significantly strengthens the inductive bias by embedding the algorithmic\nstructure of a best-first online search algorithm. D-TSN employs a learned\nworld model to conduct a fully differentiable online search. The world model is\njointly optimized with the search algorithm, enabling the learning of a robust\nworld model and mitigating the effect of prediction inaccuracies. Further, we\nnote that a naive incorporation of best-first search could lead to a\ndiscontinuous loss function in the parameter space. We address this issue by\nadopting a stochastic tree expansion policy, formulating search tree expansion\nas another decision-making task, and introducing an effective variance\nreduction technique for the gradient computation. We evaluate D-TSN in an\noffline-RL setting with a limited training data scenario on Procgen games and\ngrid navigation task, and demonstrate that D-TSN outperforms popular model-free\nand model-based baselines.",
      "tldr_zh": "本文提出 Differentiable Tree Search Network (D-TSN)，一种新型神经网络架构，通过嵌入最佳优先在线搜索算法的结构，强化算法归纳偏差，以解决数据有限决策问题中世界模型不准确导致的错误积累问题。D-TSN 使用学习的世界模型进行完全可微在线搜索，并联合优化世界模型，同时采用随机树扩展策略和方差减少技术，以避免参数空间中损失函数的不连续性。相比现有方法如 TreeQN，该框架显著提升了决策性能。在 offline-RL 设置下，D-TSN 在 Procgen 游戏和网格导航任务中超过了流行的无模型和有模型基线，展示了其在数据稀缺场景中的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11660v2",
      "published_date": "2024-01-22 02:33:38 UTC",
      "updated_date": "2024-08-02 07:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:36:52.431162"
    },
    {
      "arxiv_id": "2401.11652v1",
      "title": "OnDev-LCT: On-Device Lightweight Convolutional Transformers towards federated learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chu Myaet Thwal",
        "Minh N. H. Nguyen",
        "Ye Lin Tun",
        "Seong Tae Kim",
        "My T. Thai",
        "Choong Seon Hong"
      ],
      "abstract": "Federated learning (FL) has emerged as a promising approach to\ncollaboratively train machine learning models across multiple edge devices\nwhile preserving privacy. The success of FL hinges on the efficiency of\nparticipating models and their ability to handle the unique challenges of\ndistributed learning. While several variants of Vision Transformer (ViT) have\nshown great potential as alternatives to modern convolutional neural networks\n(CNNs) for centralized training, the unprecedented size and higher\ncomputational demands hinder their deployment on resource-constrained edge\ndevices, challenging their widespread application in FL. Since client devices\nin FL typically have limited computing resources and communication bandwidth,\nmodels intended for such devices must strike a balance between model size,\ncomputational efficiency, and the ability to adapt to the diverse and non-IID\ndata distributions encountered in FL. To address these challenges, we propose\nOnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks\nwith limited training data and resources. Our models incorporate image-specific\ninductive biases through the LCT tokenizer by leveraging efficient depthwise\nseparable convolutions in residual linear bottleneck blocks to extract local\nfeatures, while the multi-head self-attention (MHSA) mechanism in the LCT\nencoder implicitly facilitates capturing global representations of images.\nExtensive experiments on benchmark image datasets indicate that our models\noutperform existing lightweight vision models while having fewer parameters and\nlower computational demands, making them suitable for FL scenarios with data\nheterogeneity and communication bottlenecks.",
      "tldr_zh": "本研究针对Federated Learning (FL) 的挑战，提出OnDev-LCT，一种轻量级卷积Transformer模型，旨在适应资源受限的边缘设备，同时处理非独立同分布（non-IID）数据和通信瓶颈问题。OnDev-LCT 通过LCT tokenizer 利用深度可分离卷积（depthwise separable convolutions）在残差线性瓶颈块中提取局部特征，并结合多头自注意力（MHSA）机制捕获全局图像表示，从而实现模型大小和计算效率的平衡。在基准图像数据集上的广泛实验显示，OnDev-LCT 比现有轻量级视觉模型性能更优，同时参数更少、计算需求更低，使其特别适合FL 场景中的数据异质性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CC",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2401.11652v1",
      "published_date": "2024-01-22 02:17:36 UTC",
      "updated_date": "2024-01-22 02:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:37:05.603932"
    },
    {
      "arxiv_id": "2401.11648v5",
      "title": "Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation",
      "title_zh": "翻译失败",
      "authors": [
        "Heejoon Koo"
      ],
      "abstract": "Predicting next visit diagnosis using Electronic Health Records (EHR) is an\nessential task in healthcare, critical for devising proactive future plans for\nboth healthcare providers and patients. Nonetheless, many preceding studies\nhave not sufficiently addressed the heterogeneous and hierarchical\ncharacteristics inherent in EHR data, inevitably leading to sub-optimal\nperformance. To this end, we propose NECHO, a novel medical code-centric\nmultimodal contrastive EHR learning framework with hierarchical regularisation.\nFirst, we integrate multifaceted information encompassing medical codes,\ndemographics, and clinical notes using a tailored network design and a pair of\nbimodal contrastive losses, all of which pivot around a medical codes\nrepresentation. We also regularise modality-specific encoders using a parental\nlevel information in medical ontology to learn hierarchical structure of EHR\ndata. A series of experiments on MIMIC-III data demonstrates effectiveness of\nour approach.",
      "tldr_zh": "该研究针对电子健康记录 (EHR) 中的异质性和层次特性不足问题，提出了一种新型框架 NECHO，用于预测下次就诊诊断。该框架以医疗代码为中心，整合医疗代码、人口统计数据和临床笔记，通过定制网络设计和双模态对比损失进行多模态对比学习，同时利用医疗本体中的父级信息对编码器进行层次正则化，以更好地捕捉 EHR 数据的结构。实验在 MIMIC-III 数据集上表明，该方法显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EACL 2024 (The 18th Conference of the European Chapter of\n  the Association for Computational Linguistics)",
      "pdf_url": "http://arxiv.org/pdf/2401.11648v5",
      "published_date": "2024-01-22 01:58:32 UTC",
      "updated_date": "2024-05-01 01:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:37:16.910823"
    },
    {
      "arxiv_id": "2401.11647v4",
      "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised Learning",
      "title_zh": "LW-FedSSL：资源高效的逐层联邦自监督学习",
      "authors": [
        "Ye Lin Tun",
        "Chu Myaet Thwal",
        "Huy Q. Le",
        "Minh N. H. Nguyen",
        "Choong Seon Hong"
      ],
      "abstract": "Many studies integrate federated learning (FL) with self-supervised learning\n(SSL) to take advantage of raw data distributed across edge devices. However,\nedge devices often struggle with high computational and communication costs\nimposed by SSL and FL algorithms. With the deployment of more complex and\nlarge-scale models, such as Transformers, these challenges are exacerbated. To\ntackle this, we propose the Layer-Wise Federated Self-Supervised Learning\n(LW-FedSSL) approach, which allows edge devices to incrementally train a small\npart of the model at a time. Specifically, in LW-FedSSL, training is decomposed\ninto multiple stages, with each stage responsible for only a specific layer (or\na block of layers) of the model. Since only a portion of the model is active\nfor training at any given time, LW-FedSSL significantly reduces computational\nrequirements. Additionally, only the active model portion needs to be exchanged\nbetween the FL server and clients, reducing the communication overhead. This\nenables LW-FedSSL to jointly address both computational and communication\nchallenges in FL. Depending on the SSL algorithm used, it can achieve up to a\n$3.34 \\times$ reduction in memory usage, $4.20 \\times$ fewer computational\noperations (GFLOPs), and a $5.07 \\times$ lower communication cost while\nmaintaining performance comparable to its end-to-end training counterpart.\nFurthermore, we explore a progressive training strategy called Prog-FedSSL,\nwhich offers a $1.84\\times$ reduction in GFLOPs and a $1.67\\times$ reduction in\ncommunication costs while maintaining the same memory requirements as\nend-to-end training. While the resource efficiency of Prog-FedSSL is lower than\nthat of LW-FedSSL, its performance improvements make it a viable candidate for\nFL environments with more lenient resource constraints.",
      "tldr_zh": "本论文提出 LW-FedSSL，一种资源高效的层级联邦自监督学习（Federated Self-supervised Learning）方法，旨在解决联邦学习（FL）和自监督学习（SSL）在边缘设备上面临的计算和通信成本高的问题，尤其是在使用复杂模型如 Transformers 时。LW-FedSSL 通过将训练分解为多个阶段，每个阶段仅激活模型的特定层或层块，从而显著降低计算需求和通信开销，实现高达 3.34 倍的内存减少、4.20 倍的 GFLOPs 计算操作减少，以及 5.07 倍的通信成本降低，同时保持与端到端训练相当的性能。此外，论文探索了渐进训练策略 Prog-FedSSL，提供 1.84 倍的 GFLOPs 减少和 1.67 倍的通信成本优化，适用于资源约束较宽松的 FL 环境。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.11647v4",
      "published_date": "2024-01-22 01:57:31 UTC",
      "updated_date": "2025-02-26 05:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:37:31.907074"
    },
    {
      "arxiv_id": "2401.12261v4",
      "title": "Cloud-based XAI Services for Assessing Open Repository Models Under Adversarial Attacks",
      "title_zh": "基于云的 XAI 服务，用于评估对抗性攻击下的开放仓库",
      "authors": [
        "Zerui Wang",
        "Yan Liu"
      ],
      "abstract": "The opacity of AI models necessitates both validation and evaluation before\ntheir integration into services. To investigate these models, explainable AI\n(XAI) employs methods that elucidate the relationship between input features\nand output predictions. The operations of XAI extend beyond the execution of a\nsingle algorithm, involving a series of activities that include preprocessing\ndata, adjusting XAI to align with model parameters, invoking the model to\ngenerate predictions, and summarizing the XAI results. Adversarial attacks are\nwell-known threats that aim to mislead AI models. The assessment complexity,\nespecially for XAI, increases when open-source AI models are subject to\nadversarial attacks, due to various combinations. To automate the numerous\nentities and tasks involved in XAI-based assessments, we propose a cloud-based\nservice framework that encapsulates computing components as microservices and\norganizes assessment tasks into pipelines. The current XAI tools are not\ninherently service-oriented. This framework also integrates open XAI tool\nlibraries as part of the pipeline composition. We demonstrate the application\nof XAI services for assessing five quality attributes of AI models: (1)\ncomputational cost, (2) performance, (3) robustness, (4) explanation deviation,\nand (5) explanation resilience across computer vision and tabular cases. The\nservice framework generates aggregated analysis that showcases the quality\nattributes for more than a hundred combination scenarios.",
      "tldr_zh": "该论文提出一个基于云的XAI（Explainable AI）服务框架，用于评估开源AI模型在敌对攻击（Adversarial attacks）下的性能。该框架将计算组件封装为微服务（microservices），并将评估任务组织成管道（pipelines），以自动化XAI相关活动，包括数据预处理、模型参数调整和结果总结。同时，该框架整合开源XAI工具库，评估AI模型的五个质量属性：计算成本（computational cost）、性能（performance）、稳健性（robustness）、解释偏差（explanation deviation）和解释弹性（explanation resilience）。实验结果显示，该服务框架在计算机视觉和表格数据场景中生成了超过一百种组合的聚合分析，提高了AI模型评估的效率和可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "2024 IEEE International Conference on Software Services Engineering\n  (SSE)",
      "pdf_url": "http://arxiv.org/pdf/2401.12261v4",
      "published_date": "2024-01-22 00:37:01 UTC",
      "updated_date": "2024-10-01 03:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:37:42.223559"
    },
    {
      "arxiv_id": "2401.11633v1",
      "title": "Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to Vision Encoders with Multimodal Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Shipard",
        "Arnold Wiliem",
        "Kien Nguyen Thanh",
        "Wei Xiang",
        "Clinton Fookes"
      ],
      "abstract": "The fusion of vision and language has brought about a transformative shift in\ncomputer vision through the emergence of Vision-Language Models (VLMs).\nHowever, the resource-intensive nature of existing VLMs poses a significant\nchallenge. We need an accessible method for developing the next generation of\nVLMs. To address this issue, we propose Zoom-shot, a novel method for\ntransferring the zero-shot capabilities of CLIP to any pre-trained vision\nencoder. We do this by exploiting the multimodal information (i.e. text and\nimage) present in the CLIP latent space through the use of specifically\ndesigned multimodal loss functions. These loss functions are (1)\ncycle-consistency loss and (2) our novel prompt-guided knowledge distillation\nloss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP's\nzero-shot classification, to capture the interactions between text and image\nfeatures. With our multimodal losses, we train a $\\textbf{linear mapping}$\nbetween the CLIP latent space and the latent space of a pre-trained vision\nencoder, for only a $\\textbf{single epoch}$. Furthermore, Zoom-shot is entirely\nunsupervised and is trained using $\\textbf{unpaired}$ data. We test the\nzero-shot capabilities of a range of vision encoders augmented as new VLMs, on\ncoarse and fine-grained classification datasets, outperforming the previous\nstate-of-the-art in this problem domain. In our ablations, we find Zoom-shot\nallows for a trade-off between data and compute during training; and our\nstate-of-the-art results can be obtained by reducing training from 20% to 1% of\nthe ImageNet training data with 20 epochs. All code and models are available on\nGitHub.",
      "tldr_zh": "该论文提出了一种名为 Zoom-shot 的快速高效方法，用于将 CLIP 的零样本（zero-shot）能力无监督转移到任何预训练视觉编码器上。方法利用 CLIP 潜空间的多模态信息（文本和图像），通过 cycle-consistency loss 和新型 prompt-guided knowledge distillation loss (PG-KD) 作为损失函数，捕捉文本与图像特征的交互，仅需训练一个 epoch 的线性映射。Zoom-shot 采用无配对数据进行训练，并在粗粒度和细粒度分类数据集上，表现优于现有最先进模型。实验结果显示，该方法允许在数据和计算资源之间灵活权衡，甚至使用仅 1% 的 ImageNet 数据即可达到最先进性能，所有代码和模型已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.11633v1",
      "published_date": "2024-01-22 00:00:30 UTC",
      "updated_date": "2024-01-22 00:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:37:53.590144"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 105,
  "processed_papers_count": 105,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T23:38:17.011401"
}