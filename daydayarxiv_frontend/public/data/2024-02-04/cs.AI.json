{
  "date": "2024-02-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-04 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能和机器学习领域，尤其是 Large Language Models (LLMs) 的应用与优化，包括知识图谱、强化学习和图像处理等话题。其中，令人印象深刻的是 UniTSyn 数据集的提出（论文 3），它增强了 LLMs 在程序测试中的能力，以及涉及知名机构如 Salesforce 和 Google 的研究（如论文 11 和 38）。这些论文展示了 LLMs 在多模态任务和高效推理中的潜力，同时其他领域如医疗图像分析和机器人学习也有亮点。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊 AI 和 LLM 相关的内容，再快速掠过其他领域的亮点。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### LLM 和 AI 相关论文\n- **LLM-Enhanced Data Management（LLM 增强数据管理）**  \n  作者包括 Guoliang Li。该论文提出 LLMDB 框架，用于优化数据管理任务，如数据库诊断和查询重写。通过微调和提示工程避免幻觉问题，并使用向量数据库降低成本。主要贡献是提升 LLM 在数据管理中的泛化性和准确性，适用于复杂场景。\n\n- **Can Large Language Models Learn Independent Causal Mechanisms?（大型语言模型是否能学习独立因果机制？）**  \n  作者包括 Michael Witbrock。该研究探索 LLMs 在因果推理中的鲁棒性，引入新架构以处理分布偏移。发现 LLMs 通过部分领域不变机制改善了抽象推理性能，贡献在于提升了 LLMs 的泛化能力，实验显示在因果任务中表现出色。\n\n- **UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing（UniTSyn：一个大规模数据集，用于提升大型语言模型在程序测试中的能力）**  \n  这篇论文印象深刻，作者构建了 270 万对测试数据集，支持五种编程语言。核心是利用 Language Server Protocol 收集数据，并训练自回归模型提升测试生成准确性和代码覆盖率。主要发现是数据集显著改善了 LLMs 在单元测试合成中的表现，代码已开源。\n\n- **Enhancing Transformer RNNs with Multiple Temporal Perspectives（使用多时间视角增强 Transformer RNN）**  \n  作者包括 Mihai Surdeanu。该工作引入多时间视角机制，应用于 RWKV 架构，显著提升序列理解能力。贡献在于以极少参数增加（仅 0.04%）实现性能提升，并在 ICML 2024 研讨会中被接受。\n\n- **FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?（FCoReBench：大型语言模型能否解决挑战性的一阶组合推理问题？）**  \n  作者包括 Mausam 和 Parag Singla。该论文创建了 FCoReBench 数据集，评估 LLMs 在 NP-hard 问题（如图着色）上的性能。提出 SymPro-LM 方法结合符号求解器，显著提升零样本推理准确性。\n\n- **Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language Models（思想协同：激发混合语言模型的效率推理）**  \n  作者包括 Yong Li。该研究提出 SoT 框架，使用小规模模型生成直觉思想，再用大模型校正。贡献是减少 API 成本（38.3%-75.1%），同时提升推理准确性和多样性。\n\n- **Unified Training of Universal Time Series Forecasting Transformers（统一训练的通用时间序列预测 Transformer）**  \n  作者包括 Caiming Xiong 和 Silvio Savarese。该论文引入 Moirai 模型和 LOTSA 数据集，支持跨频率和多变量预测。关键发现是零样本预测性能优于传统方法，代码已开源。\n\n- **Are Large Language Models Table-based Fact-Checkers?（大型语言模型是否是基于表的 Fact-Checkers？）**  \n  该研究探索 LLMs 在表式事实验证中的能力，使用提示工程提升零样本和少样本性能。贡献在于提供新基准和提示策略，减少幻觉问题。\n\n- **LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model（LHRS-Bot：使用 VGI 增强的多模态语言模型在遥感中的应用）**  \n  作者构建 LHRS-Align 数据集和 LHRS-Bot 模型，提升遥感图像理解。发现模型在多尺度对齐中表现出色，适用于复杂地理场景。\n\n- **Knowledge Generation for Zero-shot Knowledge-based VQA（零样本知识图谱问答的知识生成）**  \n  该论文使用 LLMs 生成知识，支持零样本视觉问答。贡献是提升了 K-VQA 的解释性和准确性。\n\n- **Diffusion Model-Based Multiobjective Optimization for Gasoline Blending Scheduling（基于扩散模型的多目标优化，用于汽油混合调度）**  \n  提出 DMO 框架，结合扩散模型优化资源分配。发现能同时最小化响应时间和计算成本。\n\n其他 LLM 相关论文如 15、17、19、31、34、36、38、39、43、48、49、50、51、58、61、63、64、66 等，均探讨 LLMs 在推理、生成和优化中的扩展，但限于篇幅，这里快速掠过。\n\n### 医疗和图像处理论文\n- **A Deep Learning Approach for Brain Tumor Classification and Segmentation Using a Multiscale Convolutional Neural Network（使用多尺度卷积神经网络的脑肿瘤分类和分割深度学习方法）**  \n  作者提出多尺度 CNN 模型，支持 MRI 图像分析。贡献是实现 97.3% 的肿瘤分类准确率，无需预处理。\n\n- **Fully Differentiable Correlation-driven 2D/3D Registration for X-ray to CT Image Fusion（完全可微的相关驱动 2D/3D 配准，用于 X 射线到 CT 图像融合）**  \n  该研究设计双分支 CNN-Transformer 模型，提升图像配准准确性。发现能减少配准误差，在 ISBI 2024 中被接受。\n\n其他医疗论文如 46、53、54 等，聚焦图像生成和诊断优化，但整体影响较小。\n\n### 机器人和自动化论文\n- **A Safe Reinforcement Learning driven Weights-varying Model Predictive Control for Autonomous Vehicle Motion Control（基于安全强化学习的权重可变模型预测控制，用于自动驾驶车辆运动控制）**  \n  提出 RL-WMPC 方法，确保车辆安全路径规划。贡献是提升了控制鲁棒性，即使未训练也能保持最优性能。\n\n- **SIMPL: A Simple and Efficient Multi-agent Motion Prediction Baseline for Autonomous Driving（SIMPL：一个简单高效的多代理运动预测基线，用于自动驾驶）**  \n  作者包括 Shaojie Shen。该论文引入全局特征融合模块，提升预测准确性。发现能在 Argoverse 数据集上超越 SOTA 方法。\n\n其他机器人论文如 13、24、29、33、52 等，涉及导航和预测，但非核心焦点。\n\n### 其他领域快速掠过\n其他论文如 6（博彩市场效率分析）、7（自然启发式传播）、14（联合神经架构用于分词和解析）、16（双层优化）、18（NLP 中的环境角色）、22-28、32、35、37、40-42、44、45、47、55-57、59、60、65、67 等，涵盖优化算法、博弈论和数据分析等领域，但影响力较小。其中，38（TopoX 框架）提供拓扑学习工具，41（Uni-RLHF）构建了强化学习基准，值得注意但不展开讨论。\n\n总之，今天的 arXiv 论文突显了 LLMs 在跨领域应用的潜力，特别是在高效推理和数据增强上。感兴趣的读者可关注 UniTSyn 和相关 LLM 优化工作，以探索前沿进展。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2402.02643v1",
      "title": "LLM-Enhanced Data Management",
      "title_zh": "LLM 增强的数据管理",
      "authors": [
        "Xuanhe Zhou",
        "Xinyang Zhao",
        "Guoliang Li"
      ],
      "abstract": "Machine learning (ML) techniques for optimizing data management problems have\nbeen extensively studied and widely deployed in recent five years. However\ntraditional ML methods have limitations on generalizability (adapting to\ndifferent scenarios) and inference ability (understanding the context).\nFortunately, large language models (LLMs) have shown high generalizability and\nhuman-competitive abilities in understanding context, which are promising for\ndata management tasks (e.g., database diagnosis, database tuning). However,\nexisting LLMs have several limitations: hallucination, high cost, and low\naccuracy for complicated tasks. To address these challenges, we design LLMDB,\nan LLM-enhanced data management paradigm which has generalizability and high\ninference ability while avoiding hallucination, reducing LLM cost, and\nachieving high accuracy. LLMDB embeds domain-specific knowledge to avoid\nhallucination by LLM fine-tuning and prompt engineering. LLMDB reduces the high\ncost of LLMs by vector databases which provide semantic search and caching\nabilities. LLMDB improves the task accuracy by LLM agent which provides\nmultiple-round inference and pipeline executions. We showcase three real-world\nscenarios that LLMDB can well support, including query rewrite, database\ndiagnosis and data analytics. We also summarize the open research challenges of\nLLMDB.",
      "tldr_zh": "这篇论文讨论了传统机器学习（ML）方法在数据管理中的局限性，如泛化性差和推理能力不足，并探讨了大型语言模型（LLMs）的潜力来提升任务如数据库诊断和调优。作者提出 LLMDB 框架，通过 LLM 微调、提示工程嵌入领域特定知识来避免幻觉，利用向量数据库实现语义搜索和缓存以降低成本，并借助 LLM 代理进行多轮推理和管道执行以提高准确性。该框架已在查询重写、数据库诊断和数据分析等真实场景中得到验证，并总结了诸如泛化挑战和成本优化等开放研究问题。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02643v1",
      "published_date": "2024-02-04 23:42:02 UTC",
      "updated_date": "2024-02-04 23:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:58:27.573962"
    },
    {
      "arxiv_id": "2402.02636v2",
      "title": "Can Large Language Models Learn Independent Causal Mechanisms?",
      "title_zh": "大语言模型能否学习独立的因果机制？",
      "authors": [
        "Gaël Gendron",
        "Bao Trung Nguyen",
        "Alex Yuxuan Peng",
        "Michael Witbrock",
        "Gillian Dobbie"
      ],
      "abstract": "Despite impressive performance on language modelling and complex reasoning\ntasks, Large Language Models (LLMs) fall short on the same tasks in uncommon\nsettings or with distribution shifts, exhibiting a lack of generalisation\nability. By contrast, systems such as causal models, that learn abstract\nvariables and causal relationships, can demonstrate increased robustness\nagainst changes in the distribution. One reason for this success is the\nexistence and use of Independent Causal Mechanisms (ICMs) representing\nhigh-level concepts that only sparsely interact. In this work, we apply two\nconcepts from causality to learn ICMs within LLMs. We develop a new LLM\narchitecture composed of multiple sparsely interacting language modelling\nmodules. We show that such causal constraints can improve out-of-distribution\nperformance on abstract and causal reasoning tasks. We also investigate the\nlevel of independence and domain specialisation and show that LLMs rely on\npre-trained partially domain-invariant mechanisms resilient to fine-tuning.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能学习独立因果机制（ICMs），以提升其对分布偏移的泛化能力。论文提出了一种新LLM架构，由多个稀疏互动的语言建模模块组成，借鉴因果性概念来模拟ICMs，从而改善抽象和因果推理任务的分布外性能。实验结果显示，该架构显著增强了LLMs的鲁棒性，并揭示了LLMs依赖于预训练的部分领域不变机制，这些机制对微调具有弹性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "I.2.3; I.2.6; I.2.7; G.3"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 7 pages for the main paper and 13 pages for references and\n  appendices, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02636v2",
      "published_date": "2024-02-04 23:04:02 UTC",
      "updated_date": "2024-09-10 00:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:58:38.498924"
    },
    {
      "arxiv_id": "2402.03396v1",
      "title": "UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng He",
        "Jiabo Huang",
        "Yuyang Rong",
        "Yiwen Guo",
        "Ethan Wang",
        "Hao Chen"
      ],
      "abstract": "The remarkable capability of large language models (LLMs) in generating\nhigh-quality code has drawn increasing attention in the software testing\ncommunity. However, existing code LLMs often demonstrate unsatisfactory\ncapabilities in generating accurate and complete tests since they were trained\non code snippets collected without differentiating between code for testing\npurposes and other code. In this paper, we present a large-scale dataset\nUniTSyn, which is capable of enhancing the prowess of LLMs for Unit Test\nSynthesis. Associating tests with the tested functions is crucial for LLMs to\ninfer the expected behavior and the logic paths to be verified. By leveraging\nLanguage Server Protocol, UniTSyn achieves the challenging goal of collecting\nfocal-test pairs without per-project execution setups or per-language\nheuristics that tend to be fragile and difficult to scale. It contains 2.7\nmillion focal-test pairs across five mainstream programming languages, making\nit possible to be utilized for enhancing the test generation ability of LLMs.\nThe details of UniTSyn can be found in Table 1. Our experiments demonstrate\nthat, by building an autoregressive model based on UniTSyn, we can achieve\nsignificant benefits in learning and understanding unit test representations,\nresulting in improved generation accuracy and code coverage across all\nevaluated programming languages. Code and data will be publicly available.",
      "tldr_zh": "本文研究发现，大型语言模型 (LLMs) 在生成高质量代码方面表现出色，但由于训练数据未区分测试代码，其在单元测试合成 (Unit Test Synthesis) 方面的能力较弱。作者提出 UniTSyn，这是一个大规模数据集，包含 2.7 百万 focal-test pairs，覆盖五种主流编程语言，并通过 Language Server Protocol 实现高效收集，避免了项目执行设置或语言特定启发式方法的局限。实验结果表明，使用 UniTSyn 构建的自回归模型显著提升了 LLMs 在单元测试表示学习、生成准确性和代码覆盖率方面的表现。该数据集和相关代码将公开可用，为增强 LLMs 的程序测试能力提供了重要工具。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03396v1",
      "published_date": "2024-02-04 22:48:05 UTC",
      "updated_date": "2024-02-04 22:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:58:51.831613"
    },
    {
      "arxiv_id": "2402.02625v2",
      "title": "Enhancing Transformer RNNs with Multiple Temporal Perspectives",
      "title_zh": "通过多重时间视角增强 Transformer 循环神经网络",
      "authors": [
        "Razvan-Gabriel Dumitru",
        "Darius Peteleaza",
        "Mihai Surdeanu"
      ],
      "abstract": "We introduce the concept of multiple temporal perspectives, a novel approach\napplicable to Recurrent Neural Network (RNN) architectures for enhancing their\nunderstanding of sequential data. This method involves maintaining diverse\ntemporal views of previously encountered text, significantly enriching the\nlanguage models' capacity to interpret context. To show the efficacy of this\napproach, we incorporate it into the Receptance Weighted Key Value (RWKV)\narchitecture, addressing its inherent challenge of retaining all historical\ninformation within a single hidden state. Notably, this improvement is achieved\nwith a minimal increase in the number of parameters --even as little as\n$0.04\\%$ of the original number of parameters. Further, the additional\nparameters necessary for the multiple temporal perspectives are fine-tuned with\nminimal computational overhead, avoiding the need for a full pre-training. The\nresulting model maintains linear computational complexity during prompt\ninference, ensuring consistent efficiency across various sequence lengths. The\nempirical results and ablation studies included in our research validate the\neffectiveness of our approach, showcasing improved performance across multiple\nbenchmarks. The code, model weights and datasets are open-sourced at:\nhttps://github.com/RazvanDu/TemporalRNNs.",
      "tldr_zh": "本论文提出multiple temporal perspectives的概念，用于增强RNN架构对序列数据的理解能力，通过维护多样化的历史文本时间视图来丰富语言模型的上下文解释。该方法被整合到RWKV模型中，解决了其在单个隐藏状态中保留历史信息的挑战，同时仅增加微小参数（如0.04%）并通过微调实现，无需全预训练。结果表明，该改进保持了线性计算复杂度，并在多个基准上显著提升了性能，相关代码和模型已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures, 4 tables, accepted at ICML 2024 - Next\n  Generation of Sequence Modeling Architectures workshop",
      "pdf_url": "http://arxiv.org/pdf/2402.02625v2",
      "published_date": "2024-02-04 22:12:29 UTC",
      "updated_date": "2024-07-11 20:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:59:03.230801"
    },
    {
      "arxiv_id": "2402.02624v1",
      "title": "A Safe Reinforcement Learning driven Weights-varying Model Predictive Control for Autonomous Vehicle Motion Control",
      "title_zh": "翻译失败",
      "authors": [
        "Baha Zarrouki",
        "Marios Spanakakis",
        "Johannes Betz"
      ],
      "abstract": "Determining the optimal cost function parameters of Model Predictive Control\n(MPC) to optimize multiple control objectives is a challenging and\ntime-consuming task. Multiobjective Bayesian Optimization (BO) techniques solve\nthis problem by determining a Pareto optimal parameter set for an MPC with\nstatic weights. However, a single parameter set may not deliver the most\noptimal closed-loop control performance when the context of the MPC operating\nconditions changes during its operation, urging the need to adapt the cost\nfunction weights at runtime. Deep Reinforcement Learning (RL) algorithms can\nautomatically learn context-dependent optimal parameter sets and dynamically\nadapt for a Weightsvarying MPC (WMPC). However, learning cost function weights\nfrom scratch in a continuous action space may lead to unsafe operating states.\nTo solve this, we propose a novel approach limiting the RL actions within a\nsafe learning space representing a catalog of pre-optimized BO Pareto-optimal\nweight sets. We conceive a RL agent not to learn in a continuous space but to\nproactively anticipate upcoming control tasks and to choose the most optimal\ndiscrete actions, each corresponding to a single set of Pareto optimal weights,\ncontext-dependent. Hence, even an untrained RL agent guarantees a safe and\noptimal performance. Experimental results demonstrate that an untrained RL-WMPC\nshows Pareto-optimal closed-loop behavior and training the RL-WMPC helps\nexhibit a performance beyond the Pareto-front.",
      "tldr_zh": "这篇论文提出了一种安全的强化学习(Deep Reinforcement Learning, RL)驱动的自适应权重模型预测控制(Weights-varying MPC, WMPC)，用于优化自主车辆运动控制中的多个目标。传统多目标Bayesian Optimization (BO)方法虽能找到Pareto最优参数集，但无法适应操作条件变化；为此，论文将RL动作限制在预优化的BO Pareto最优权重集的安全学习空间内，让RL代理选择上下文相关的离散权重集。实验结果表明，即使未经训练的RL-WMPC也能实现Pareto最优闭环性能，而经过训练后，其表现进一步超出Pareto前沿。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02624v1",
      "published_date": "2024-02-04 22:09:28 UTC",
      "updated_date": "2024-02-04 22:09:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:59:15.679837"
    },
    {
      "arxiv_id": "2402.02623v1",
      "title": "Efficient Market Dynamics: Unraveling Informational Efficiency in UK Horse Racing Betting Markets Through Betfair's Time Series Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Narayan Tondapu"
      ],
      "abstract": "Using Betfair's time series data, an analysis of the United Kingdom (UK)\nhorse racing market reveals an interesting paradox: a market with short tails,\nrapidly decaying autocorrelations, and no long-term memory. There seems to be a\nremarkably high level of informational efficiency in betting exchange returns,\nin contrast to financial assets that are characterized by heavy tails and\nvolatility clustering. The generalized Gaussian unconditional distribution with\na light tail point to a market where knowledge is quickly assimilated and\nreflected in prices. This is further supported by the extremely quick fading of\nautocorrelations and the absence of gain-loss asymmetry. Therefore, in addition\nto measuring long-range memory, the Hurst exponent also shows mean reversion, a\nsign that markets respond quickly to fresh information.",
      "tldr_zh": "本研究通过Betfair的时间序列分析，揭示了英国赛马投注市场的信息效率（informational efficiency）特征，该市场表现出短尾（short tails）、快速衰减的自相关性（autocorrelations）和无长期记忆，与金融资产的厚尾和波动性聚类形成鲜明对比。分析结果表明，市场知识被迅速整合到价格中，且不存在利得-损失不对称。Hurst指数进一步证实了均值回归（mean reversion）的现象，证明该市场对新信息响应极快，从而提升了整体效率。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02623v1",
      "published_date": "2024-02-04 21:54:25 UTC",
      "updated_date": "2024-02-04 21:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:59:26.624728"
    },
    {
      "arxiv_id": "2402.05959v1",
      "title": "Nature-Inspired Local Propagation",
      "title_zh": "自然启发的局部传播",
      "authors": [
        "Alessandro Betti",
        "Marco Gori"
      ],
      "abstract": "The spectacular results achieved in machine learning, including the recent\nadvances in generative AI, rely on large data collections. On the opposite,\nintelligent processes in nature arises without the need for such collections,\nbut simply by online processing of the environmental information. In\nparticular, natural learning processes rely on mechanisms where data\nrepresentation and learning are intertwined in such a way to respect\nspatiotemporal locality. This paper shows that such a feature arises from a\npre-algorithmic view of learning that is inspired by related studies in\nTheoretical Physics. We show that the algorithmic interpretation of the derived\n\"laws of learning\", which takes the structure of Hamiltonian equations, reduces\nto Backpropagation when the speed of propagation goes to infinity. This opens\nthe doors to machine learning studies based on full on-line information\nprocessing that are based the replacement of Backpropagation with the proposed\nspatiotemporal local algorithm.",
      "tldr_zh": "这篇论文探讨了机器学习依赖大量数据的问题，并从自然智能中汲取灵感，提出一种基于时空局部性的在线学习方法。作者从理论物理的视角导出“学习定律”，其形式类似于Hamiltonian equations，使数据表示和学习过程相互交织，以实现对环境信息的实时处理。该方法在算法层面表现为局部传播算法，当传播速度趋于无穷大时，会退化为Backpropagation。最终，这为机器学习引入完全在线信息处理机制提供了新途径，潜在地取代传统Backpropagation以提升效率和局部性。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05959v1",
      "published_date": "2024-02-04 21:43:37 UTC",
      "updated_date": "2024-02-04 21:43:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:59:37.852940"
    },
    {
      "arxiv_id": "2402.02611v3",
      "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
      "title_zh": "翻译失败",
      "authors": [
        "Chinmay Mittal",
        "Krishna Kartik",
        "Mausam",
        "Parag Singla"
      ],
      "abstract": "Can the large language models (LLMs) solve challenging first-order\ncombinatorial reasoning problems such as graph coloring, knapsack, and\ncryptarithmetic? By first-order, we mean these problems can be instantiated\nwith potentially an infinite number of problem instances of varying sizes. They\nare also challenging being NP-hard and requiring several reasoning steps to\nreach a solution. While existing work has focused on coming up with datasets\nwith hard benchmarks, there is limited work which exploits the first-order\nnature of the problem structure. To address this challenge, we present\nFCoReBench, a dataset of 40 such challenging problems, along with scripts to\ngenerate problem instances of varying sizes and automatically verify and\ngenerate their solutions. We first observe that LLMs, even when aided by\nsymbolic solvers, perform rather poorly on our dataset, being unable to\nleverage the underlying structure of these problems. We specifically observe a\ndrop in performance with increasing problem size. In response, we propose a new\napproach, SymPro-LM, which combines LLMs with both symbolic solvers and program\ninterpreters, along with feedback from a few solved examples, to achieve huge\nperformance gains. Our proposed approach is robust to changes in the problem\nsize, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM's effectiveness on other logical reasoning benchmarks.",
      "tldr_zh": "本论文评估大型语言模型 (LLMs) 是否能解决一阶组合推理问题（如图着色、背包和密码算术问题），这些问题是 NP-hard 的且可生成无限规模实例。作者引入 FCoReBench 数据集，包含 40 个挑战性问题，并提供脚本生成实例和验证解决方案，结果显示 LLMs 即使结合符号求解器，也无法充分利用问题结构，且性能随问题规模下降。针对此，论文提出 SymPro-LM 方法，将 LLMs 与符号求解器、程序解释器及少量反馈示例结合，实现显著性能提升，且该方法对问题规模鲁棒，并在推理时无需调用 LLMs；此外，实验还验证了其在其他逻辑推理基准上的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02611v3",
      "published_date": "2024-02-04 20:56:09 UTC",
      "updated_date": "2025-03-01 12:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T02:59:53.373275"
    },
    {
      "arxiv_id": "2402.14594v1",
      "title": "Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation",
      "title_zh": "利用检索增强生成改进辅导实践评估",
      "authors": [
        "Zifei FeiFei Han",
        "Jionghao Lin",
        "Ashish Gurung",
        "Danielle R. Thomas",
        "Eason Chen",
        "Conrad Borchers",
        "Shivang Gupta",
        "Kenneth R. Koedinger"
      ],
      "abstract": "One-on-one tutoring is an effective instructional method for enhancing\nlearning, yet its efficacy hinges on tutor competencies. Novice math tutors\noften prioritize content-specific guidance, neglecting aspects such as\nsocial-emotional learning. Social-emotional learning promotes equity and\ninclusion and nurturing relationships with students, which is crucial for\nholistic student development. Assessing the competencies of tutors accurately\nand efficiently can drive the development of tailored tutor training programs.\nHowever, evaluating novice tutor ability during real-time tutoring remains\nchallenging as it typically requires experts-in-the-loop. To address this\nchallenge, this preliminary study aims to harness Generative Pre-trained\nTransformers (GPT), such as GPT-3.5 and GPT-4 models, to automatically assess\ntutors' ability of using social-emotional tutoring strategies. Moreover, this\nstudy also reports on the financial dimensions and considerations of employing\nthese models in real-time and at scale for automated assessment. The current\nstudy examined four prompting strategies: two basic Zero-shot prompt\nstrategies, Tree of Thought prompt, and Retrieval-Augmented Generator (RAG)\nbased prompt. The results indicate that the RAG prompt demonstrated more\naccurate performance (assessed by the level of hallucination and correctness in\nthe generated assessment texts) and lower financial costs than the other\nstrategies evaluated. These findings inform the development of personalized\ntutor training interventions to enhance the the educational effectiveness of\ntutored learning.",
      "tldr_zh": "这篇论文探讨了如何利用 Retrieval-Augmented Generation (RAG) 技术来改善一对一辅导实践的评估，特别是针对新手数学辅导员在社会情感学习方面的能力不足问题，因为这类学习有助于促进公平、包容和学生关系构建。研究采用 Generative Pre-trained Transformers (GPT) 模型（如 GPT-3.5 和 GPT-4），测试了四种提示策略，包括两个 Zero-shot 提示、Tree of Thought 提示和 RAG 基于提示，以实现实时自动评估辅导员能力。结果表明，RAG 提示在减少幻觉、提高评估准确性和降低财务成本方面表现最佳。这些发现有助于开发个性化的辅导员培训干预措施，提升辅导的有效性和整体教育效果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "11 page Workshop paper, AAAI2024 Workshop on AI for Education -\n  Bridging Innovation and Responsibility, Large Language Model, Personalized\n  Tutor Training, Automatic Assessment",
      "pdf_url": "http://arxiv.org/pdf/2402.14594v1",
      "published_date": "2024-02-04 20:42:30 UTC",
      "updated_date": "2024-02-04 20:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:00:04.448117"
    },
    {
      "arxiv_id": "2402.02600v1",
      "title": "Evading Deep Learning-Based Malware Detectors via Obfuscation: A Deep Reinforcement Learning Approach",
      "title_zh": "通过混淆规避基于深度学习的恶意软件检测器：一种",
      "authors": [
        "Brian Etter",
        "James Lee Hu",
        "Mohammedreza Ebrahimi",
        "Weifeng Li",
        "Xin Li",
        "Hsinchun Chen"
      ],
      "abstract": "Adversarial Malware Generation (AMG), the generation of adversarial malware\nvariants to strengthen Deep Learning (DL)-based malware detectors has emerged\nas a crucial tool in the development of proactive cyberdefense. However, the\nmajority of extant works offer subtle perturbations or additions to executable\nfiles and do not explore full-file obfuscation. In this study, we show that an\nopen-source encryption tool coupled with a Reinforcement Learning (RL)\nframework can successfully obfuscate malware to evade state-of-the-art malware\ndetection engines and outperform techniques that use advanced modification\nmethods. Our results show that the proposed method improves the evasion rate\nfrom 27%-49% compared to widely-used state-of-the-art reinforcement\nlearning-based methods.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning 的方法，通过 Obfuscation 技术生成对抗性恶意软件（Adversarial Malware Generation），以规避 Deep Learning-based 恶意软件检测器。不同于现有工作仅进行微小修改，该方法利用开源加密工具结合 Reinforcement Learning (RL) 框架实现全文件混淆，从而提升恶意软件的逃避能力。实验结果表明，该方法相比广泛使用的 RL-based 方法，将逃避率提高了 27%-49%，并优于高级修改技术。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02600v1",
      "published_date": "2024-02-04 20:23:15 UTC",
      "updated_date": "2024-02-04 20:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:00:15.396748"
    },
    {
      "arxiv_id": "2402.02592v2",
      "title": "Unified Training of Universal Time Series Forecasting Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Gerald Woo",
        "Chenghao Liu",
        "Akshat Kumar",
        "Caiming Xiong",
        "Silvio Savarese",
        "Doyen Sahoo"
      ],
      "abstract": "Deep learning for time series forecasting has traditionally operated within a\none-model-per-dataset framework, limiting its potential to leverage the\ngame-changing impact of large pre-trained models. The concept of universal\nforecasting, emerging from pre-training on a vast collection of time series\ndatasets, envisions a single Large Time Series Model capable of addressing\ndiverse downstream forecasting tasks. However, constructing such a model poses\nunique challenges specific to time series data: i) cross-frequency learning,\nii) accommodating an arbitrary number of variates for multivariate time series,\nand iii) addressing the varying distributional properties inherent in\nlarge-scale data. To address these challenges, we present novel enhancements to\nthe conventional time series Transformer architecture, resulting in our\nproposed Masked Encoder-based Universal Time Series Forecasting Transformer\n(Moirai). Trained on our newly introduced Large-scale Open Time Series Archive\n(LOTSA) featuring over 27B observations across nine domains, Moirai achieves\ncompetitive or superior performance as a zero-shot forecaster when compared to\nfull-shot models. Code, data, and model weights can be found at\nhttps://github.com/SalesforceAIResearch/uni2ts.",
      "tldr_zh": "该论文解决了时间序列预测领域的传统问题，即每个数据集使用一个模型，提出了一种统一的训练方法来构建通用时间序列预测 Transformer。作者引入了 Masked Encoder-based Universal Time Series Forecasting Transformer (Moirai) 模型，通过对标准 Transformer 架构进行创新增强，处理跨频率学习、多变量时间序列和大规模数据分布差异等挑战。Moirai 在新创建的 Large-scale Open Time Series Archive (LOTSA) 数据集上训练，该数据集包含超过 27B 观察数据，覆盖九个领域。作为零样本预测器，Moirai 的性能与完全训练模型相当或优于它们，为通用时间序列预测提供了高效解决方案。代码和模型可从 https://github.com/SalesforceAIResearch/uni2ts 获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02592v2",
      "published_date": "2024-02-04 20:00:45 UTC",
      "updated_date": "2024-05-22 11:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:00:29.930752"
    },
    {
      "arxiv_id": "2402.05975v1",
      "title": "A Deep Learning Approach for Brain Tumor Classification and Segmentation Using a Multiscale Convolutional Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Javier Díaz-Pernas",
        "Mario Martínez-Zarzuela",
        "Míriam Antón-Rodríguez",
        "David González-Ortega"
      ],
      "abstract": "In this paper, we present a fully automatic brain tumor segmentation and\nclassification model using a Deep Convolutional Neural Network that includes a\nmultiscale approach. One of the differences of our proposal with respect to\nprevious works is that input images are processed in three spatial scales along\ndifferent processing pathways. This mechanism is inspired in the inherent\noperation of the Human Visual System. The proposed neural model can analyze MRI\nimages containing three types of tumors: meningioma, glioma, and pituitary\ntumor, over sagittal, coronal, and axial views and does not need preprocessing\nof input images to remove skull or vertebral column parts in advance. The\nperformance of our method on a publicly available MRI image dataset of 3064\nslices from 233 patients is compared with previously classical machine learning\nand deep learning published methods. In the comparison, our method remarkably\nobtained a tumor classification accuracy of 0.973, higher than the other\napproaches using the same database.",
      "tldr_zh": "这篇论文提出了一种基于多尺度卷积神经网络（multiscale Convolutional Neural Network）的深度学习方法，用于脑肿瘤的自动分类和分割。模型通过处理输入图像在三个空间尺度上的不同路径，灵感来源于人类视觉系统（Human Visual System），并能分析 MRI 图像中的三种肿瘤（meningioma, glioma, and pituitary tumor）在 sagittal, coronal, and axial views 上，而无需预处理移除颅骨或椎柱部分。在一个包含 3064 个切片来自 233 名患者的公开数据集上，该方法实现了 0.973 的肿瘤分类准确率，优于现有的经典机器学习和深度学习方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.05975v1",
      "published_date": "2024-02-04 17:47:03 UTC",
      "updated_date": "2024-02-04 17:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:00:40.852777"
    },
    {
      "arxiv_id": "2402.02566v1",
      "title": "STAGE: Scalable and Traversability-Aware Graph based Exploration Planner for Dynamically Varying Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Patel",
        "Mario A V Saucedo",
        "Christoforos Kanellakis",
        "George Nikolakopoulos"
      ],
      "abstract": "In this article, we propose a novel navigation framework that leverages a two\nlayered graph representation of the environment for efficient large-scale\nexploration, while it integrates a novel uncertainty awareness scheme to handle\ndynamic scene changes in previously explored areas. The framework is structured\naround a novel goal oriented graph representation, that consists of, i) the\nlocal sub-graph and ii) the global graph layer respectively. The local\nsub-graphs encode local volumetric gain locations as frontiers, based on the\ndirect pointcloud visibility, allowing fast graph building and path planning.\nAdditionally, the global graph is build in an efficient way, using node-edge\ninformation exchange only on overlapping regions of sequential sub-graphs.\nDifferent from the state-of-the-art graph based exploration methods, the\nproposed approach efficiently re-uses sub-graphs built in previous iterations\nto construct the global navigation layer. Another merit of the proposed scheme\nis the ability to handle scene changes (e.g. blocked pathways), adaptively\nupdating the obstructed part of the global graph from traversable to\nnot-traversable. This operation involved oriented sample space of a path\nsegment in the global graph layer, while removing the respective edges from\nconnected nodes of the global graph in cases of obstructions. As such, the\nexploration behavior is directing the robot to follow another route in the\nglobal re-positioning phase through path-way updates in the global graph.\nFinally, we showcase the performance of the method both in simulation runs as\nwell as deployed in real-world scene involving a legged robot carrying camera\nand lidar sensor.",
      "tldr_zh": "本研究提出STAGE，一种可扩展且考虑可通行性的基于graph的探索规划器，旨在处理动态变化环境中的高效导航。该框架采用两层graph表示，包括本地sub-graph（基于点云可见性编码前沿以快速构建路径）和全局graph层（通过顺序sub-graph的重叠区域交换信息高效重用先前数据）。与现有方法不同，STAGE能适应场景变化（如阻塞路径）通过更新全局graph将可通行部分标记为not-traversable，并指导机器人重新规划路线。实验在模拟和真实场景中验证了其性能，使用legged robot携带摄像头和lidar传感器，展示了显著的效率提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02566v1",
      "published_date": "2024-02-04 17:05:27 UTC",
      "updated_date": "2024-02-04 17:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:00:51.853711"
    },
    {
      "arxiv_id": "2402.02564v2",
      "title": "A Truly Joint Neural Architecture for Segmentation and Parsing",
      "title_zh": "一个真正联合的神经架构用于分割和解析",
      "authors": [
        "Danit Yshaayahu Levi",
        "Reut Tsarfaty"
      ],
      "abstract": "Contemporary multilingual dependency parsers can parse a diverse set of\nlanguages, but for Morphologically Rich Languages (MRLs), performance is\nattested to be lower than other languages. The key challenge is that, due to\nhigh morphological complexity and ambiguity of the space-delimited input\ntokens, the linguistic units that act as nodes in the tree are not known in\nadvance. Pre-neural dependency parsers for MRLs subscribed to the joint\nmorpho-syntactic hypothesis, stating that morphological segmentation and\nsyntactic parsing should be solved jointly, rather than as a pipeline where\nsegmentation precedes parsing. However, neural state-of-the-art parsers to date\nuse a strict pipeline. In this paper we introduce a joint neural architecture\nwhere a lattice-based representation preserving all morphological ambiguity of\nthe input is provided to an arc-factored model, which then solves the\nmorphological segmentation and syntactic parsing tasks at once. Our experiments\non Hebrew, a rich and highly ambiguous MRL, demonstrate state-of-the-art\nperformance on parsing, tagging and segmentation of the Hebrew section of UD,\nusing a single model. This proposed architecture is LLM-based and language\nagnostic, providing a solid foundation for MRLs to obtain further performance\nimprovements and bridge the gap with other languages.",
      "tldr_zh": "这篇论文针对形态丰富语言（Morphologically Rich Languages, MRLs）的依赖解析性能问题，提出了一种真正的联合神经架构（joint neural architecture），它使用基于格子（lattice-based）的表示保留输入形态歧义，并通过arc-factored模型同时解决形态分割和句法解析任务。不同于传统的流水线方法，该架构整合了形态和句法处理，提高了处理高复杂性语言的效率。在希伯来语数据集上的实验显示，该模型在解析、标记和分割方面达到了state-of-the-art性能，使用单一LLM-based和language-agnostic模型，为MRLs的进一步优化奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02564v2",
      "published_date": "2024-02-04 16:56:08 UTC",
      "updated_date": "2024-03-02 16:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:01:05.829698"
    },
    {
      "arxiv_id": "2402.02563v4",
      "title": "Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Shang",
        "Yu Li",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Large language models (LLMs) have shown impressive emergent abilities in a\nwide range of tasks, but the associated expensive API cost greatly limits the\nreal application. Previous works like chain-of-thought (CoT) and\ntree-of-thoughts (ToT) have predominately focused on enhancing accuracy, but\noverlook the rapidly increasing API cost, which could be particularly\nproblematic for open-ended real-world tasks with huge solution spaces.\nMotivated by the dual process theory of human cognition, we propose \"Synergy of\nThoughts\"(SoT) to unleash the synergistic potential of hybrid LLMs with\ndifferent scales for efficient reasoning. By default, SoT uses smaller-scale\nlanguage models to generate multiple low-cost intuitive thoughts, which\nresembles the parallel intuitions produced by System 1. We then design a\nconfidence evaluator where the intuitive thoughts are cross-evaluated and\nintroduce a controllable threshold mechanism to decide their mutual conflict.\nIf these intuitive thoughts exhibit conflicts, SoT will invoke the reflective\nreasoning of scaled-up language models to emulate the intervention of System 2,\nwhich will override the intuitive thoughts and rectify the reasoning results.\nThis framework is model-agnostic and training-free, which can be flexibly\nimplemented with various off-the-shelf LLMs. Experiments on six representative\nreasoning tasks show that SoT substantially reduces the API cost by\n38.3%-75.1%, and simultaneously achieves state-of-the-art reasoning accuracy\nand solution diversity. Notably, the average token cost reduction on open-ended\ntasks reaches up to 69.1%.",
      "tldr_zh": "该论文提出 Synergy of Thoughts (SoT) 框架，旨在通过混合大型语言模型（LLMs）和小型模型实现高效推理，解决现有方法如 Chain-of-Thought (CoT) 在 API 成本上的问题。SoT 受人类认知双过程理论启发，使用小型模型生成多个低成本直觉想法（类似 System 1），并通过置信度评估器检测冲突；若冲突存在，则调用大型模型进行反思推理（类似 System 2）以纠正结果。该框架模型无关、无需训练，并在六个代表性任务的实验中，减少 API 成本 38.3%-75.1%，同时实现最先进推理准确性和解决方案多样性，尤其在开放任务中令牌成本平均降低 69.1%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 16 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.02563v4",
      "published_date": "2024-02-04 16:45:01 UTC",
      "updated_date": "2024-08-24 14:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:01:18.317118"
    },
    {
      "arxiv_id": "2402.02552v2",
      "title": "Neur2BiLO: Neural Bilevel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Dumouchelle",
        "Esther Julien",
        "Jannis Kurtz",
        "Elias B. Khalil"
      ],
      "abstract": "Bilevel optimization deals with nested problems in which a leader takes the\nfirst decision to minimize their objective function while accounting for a\nfollower's best-response reaction. Constrained bilevel problems with integer\nvariables are particularly notorious for their hardness. While exact solvers\nhave been proposed for mixed-integer linear bilevel optimization, they tend to\nscale poorly with problem size and are hard to generalize to the non-linear\ncase. On the other hand, problem-specific algorithms (exact and heuristic) are\nlimited in scope. Under a data-driven setting in which similar instances of a\nbilevel problem are solved routinely, our proposed framework, Neur2BiLO, embeds\na neural network approximation of the leader's or follower's value function,\ntrained via supervised regression, into an easy-to-solve mixed-integer program.\nNeur2BiLO serves as a heuristic that produces high-quality solutions extremely\nfast for four applications with linear and non-linear objectives and pure and\nmixed-integer variables.",
      "tldr_zh": "该论文探讨了二层优化（Bilevel optimization）问题，其中领导者需在考虑跟随者最佳响应的情况下最小化其目标函数，尤其针对带有整数变量的约束问题，该类问题难度极高。Neur2BiLO 框架提出了一种数据驱动方法，通过监督回归训练神经网络来近似领导者或跟随者的价值函数，并将其嵌入易于求解的混合整数程序（Mixed-integer program）中，作为一种高效启发式算法。实验结果显示，Neur2BiLO 在四种应用场景中，包括线性/非线性目标和纯/混合整数变量，能够快速生成高质量解决方案，显著提升了问题求解的效率和泛化能力。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02552v2",
      "published_date": "2024-02-04 15:54:37 UTC",
      "updated_date": "2024-11-01 14:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:01:28.983548"
    },
    {
      "arxiv_id": "2402.02549v2",
      "title": "Are Large Language Models Table-based Fact-Checkers?",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Zhang",
        "Qingyi Si",
        "Peng Fu",
        "Zheng Lin",
        "Weiping Wang"
      ],
      "abstract": "Table-based Fact Verification (TFV) aims to extract the entailment relation\nbetween statements and structured tables. Existing TFV methods based on\nsmall-scaled models suffer from insufficient labeled data and weak zero-shot\nability. Recently, the appearance of Large Language Models (LLMs) has gained\nlots of attraction in research fields. They have shown powerful zero-shot and\nin-context learning abilities on several NLP tasks, but their potential on TFV\nis still unknown. In this work, we implement a preliminary study about whether\nLLMs are table-based fact-checkers. In detail, we design diverse prompts to\nexplore how the in-context learning can help LLMs in TFV, i.e., zero-shot and\nfew-shot TFV capability. Besides, we carefully design and construct TFV\ninstructions to study the performance gain brought by the instruction tuning of\nLLMs. Experimental results demonstrate that LLMs can achieve acceptable results\non zero-shot and few-shot TFV with prompt engineering, while instruction-tuning\ncan stimulate the TFV capability significantly. We also make some valuable\nfindings about the format of zero-shot prompts and the number of in-context\nexamples. Finally, we analyze some possible directions to promote the accuracy\nof TFV via LLMs, which is beneficial to further research of table reasoning.",
      "tldr_zh": "本文研究大型语言模型 (LLMs) 是否能作为基于表格的事实验证器 (Table-based Fact Verification, TFV)，旨在解决现有小规模模型在数据不足和零样本能力弱方面的局限。研究者设计了多样提示 (prompts) 来评估 LLMs 的零样本 (zero-shot) 和少样本 (few-shot) TFV 能力，并通过构建 TFV 指令探究指令微调 (instruction tuning) 的性能提升。实验结果表明，LLMs 通过提示工程可实现可接受的验证准确率，而指令微调显著增强了其 TFV 潜力，同时揭示了零样本提示格式和 in-context 示例数量的关键影响。最后，论文分析了利用 LLMs 提升 TFV 准确性的潜在方向，以推动表格推理的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "CSCWD 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02549v2",
      "published_date": "2024-02-04 15:52:59 UTC",
      "updated_date": "2024-11-13 12:37:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:01:42.249950"
    },
    {
      "arxiv_id": "2402.02548v1",
      "title": "\"What's my model inside of?\": Exploring the role of environments for grounded natural language understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Ronen Tamari"
      ],
      "abstract": "In contrast to classical cognitive science which studied brains in isolation,\necological approaches focused on the role of the body and environment in\nshaping cognition. Similarly, in this thesis we adopt an ecological approach to\ngrounded natural language understanding (NLU) research. Grounded language\nunderstanding studies language understanding systems situated in the context of\nevents, actions and precepts in naturalistic/simulated virtual environments.\nWhere classic research tends to focus on designing new models and optimization\nmethods while treating environments as given, we explore the potential of\nenvironment design for improving data collection and model development. We\ndeveloped novel training and annotation approaches for procedural text\nunderstanding based on text-based game environments. We also drew upon embodied\ncognitive linguistics literature to propose a roadmap for grounded NLP\nresearch, and to inform the development of a new benchmark for measuring the\nprogress of large language models on challenging commonsense reasoning tasks.\nWe leveraged the richer supervision provided by text-based game environments to\ndevelop Breakpoint Transformers, a novel approach to modeling intermediate\nsemantic information in long narrative or procedural texts. Finally, we\nintegrated theories on the role of environments in collective human\nintelligence to propose a design for AI-augmented \"social thinking\nenvironments\" for knowledge workers like scientists.",
      "tldr_zh": "本论文从生态学视角探讨环境在基于事件的自然语言理解（grounded NLU）中的作用，强调环境设计如何提升数据收集和模型开发，而非仅依赖模型优化。研究者开发了基于文本游戏环境的训练和标注方法，并提出grounded NLP研究路线图，同时创建了新的基准来评估大型语言模型（LLMs）在常识推理任务上的表现。最终，他们引入Breakpoint Transformers模型来处理长文本的中间语义信息，并设计了AI-augmented“社会思考环境”以支持知识工作者的集体智能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD Thesis",
      "pdf_url": "http://arxiv.org/pdf/2402.02548v1",
      "published_date": "2024-02-04 15:52:46 UTC",
      "updated_date": "2024-02-04 15:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:01:51.706824"
    },
    {
      "arxiv_id": "2402.02547v2",
      "title": "Integration of cognitive tasks into artificial general intelligence test for large models",
      "title_zh": "将认知任务整合到针对大型模型的人工通用智能测试中",
      "authors": [
        "Youzhi Qu",
        "Chen Wei",
        "Penghui Du",
        "Wenxin Che",
        "Chi Zhang",
        "Wanli Ouyang",
        "Yatao Bian",
        "Feiyang Xu",
        "Bin Hu",
        "Kai Du",
        "Haiyan Wu",
        "Jia Liu",
        "Quanying Liu"
      ],
      "abstract": "During the evolution of large models, performance evaluation is necessarily\nperformed to assess their capabilities and ensure safety before practical\napplication. However, current model evaluations mainly rely on specific tasks\nand datasets, lacking a united framework for assessing the multidimensional\nintelligence of large models. In this perspective, we advocate for a\ncomprehensive framework of cognitive science-inspired artificial general\nintelligence (AGI) tests, aimed at fulfilling the testing needs of large models\nwith enhanced capabilities. The cognitive science-inspired AGI tests encompass\nthe full spectrum of intelligence facets, including crystallized intelligence,\nfluid intelligence, social intelligence, and embodied intelligence. To assess\nthe multidimensional intelligence of large models, the AGI tests consist of a\nbattery of well-designed cognitive tests adopted from human intelligence tests,\nand then naturally encapsulates into an immersive virtual community. We propose\nincreasing the complexity of AGI testing tasks commensurate with advancements\nin large models and emphasizing the necessity for the interpretation of test\nresults to avoid false negatives and false positives. We believe that cognitive\nscience-inspired AGI tests will effectively guide the targeted improvement of\nlarge models in specific dimensions of intelligence and accelerate the\nintegration of large models into human society.",
      "tldr_zh": "该论文讨论了当前大型模型（large models）评估方法的局限性，即依赖特定任务和数据集，缺乏统一的框架，并提出一个基于认知科学的 artificial general intelligence (AGI) 测试框架来评估其多维智能。框架涵盖 crystallized intelligence、fluid intelligence、social intelligence 和 embodied intelligence，通过采用人类智能测试的任务并整合到浸没式虚拟社区中，实现全面评估。作者建议随着大型模型的进步逐步增加测试任务的复杂性，并强调解释测试结果以避免假阴性和假阳性，从而指导模型在特定智能维度的针对性改进，并加速其与人类社会的融合。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02547v2",
      "published_date": "2024-02-04 15:50:42 UTC",
      "updated_date": "2024-03-06 02:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:02:05.253711"
    },
    {
      "arxiv_id": "2402.02544v4",
      "title": "LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Dilxat Muhtar",
        "Zhenshi Li",
        "Feng Gu",
        "Xueliang Zhang",
        "Pengfeng Xiao"
      ],
      "abstract": "The revolutionary capabilities of large language models (LLMs) have paved the\nway for multimodal large language models (MLLMs) and fostered diverse\napplications across various specialized domains. In the remote sensing (RS)\nfield, however, the diverse geographical landscapes and varied objects in RS\nimagery are not adequately considered in recent MLLM endeavors. To bridge this\ngap, we construct a large-scale RS image-text dataset, LHRS-Align, and an\ninformative RS-specific instruction dataset, LHRS-Instruct, leveraging the\nextensive volunteered geographic information (VGI) and globally available RS\nimages. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored\nfor RS image understanding through a novel multi-level vision-language\nalignment strategy and a curriculum learning method. Additionally, we introduce\nLHRS-Bench, a benchmark for thoroughly evaluating MLLMs' abilities in RS image\nunderstanding. Comprehensive experiments demonstrate that LHRS-Bot exhibits a\nprofound understanding of RS images and the ability to perform nuanced\nreasoning within the RS domain.",
      "tldr_zh": "本论文针对遥感(RS)领域的图像多样性问题，构建了大规模RS图像-文本数据集LHRS-Align和RS特定指令数据集LHRS-Instruct，利用志愿地理信息(VGI)和全球RS图像来提升多模态大语言模型(MLLMs)的适用性。研究引入了LHRS-Bot模型，通过多级视觉-语言对齐策略和课程学习方法，实现对RS图像的深刻理解和细致推理。实验结果显示，LHRS-Bot在RS图像理解基准LHRS-Bench上表现出色，显著提升了模型在该领域的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "36 pages, 10 figures. Github https://github.com/NJU-LHRS/LHRS-Bot",
      "pdf_url": "http://arxiv.org/pdf/2402.02544v4",
      "published_date": "2024-02-04 15:46:43 UTC",
      "updated_date": "2024-07-16 01:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:02:17.473882"
    },
    {
      "arxiv_id": "2402.02541v1",
      "title": "Knowledge Generation for Zero-shot Knowledge-based VQA",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Cao",
        "Jing Jiang"
      ],
      "abstract": "Previous solutions to knowledge-based visual question answering~(K-VQA)\nretrieve knowledge from external knowledge bases and use supervised learning to\ntrain the K-VQA model. Recently pre-trained LLMs have been used as both a\nknowledge source and a zero-shot QA model for K-VQA and demonstrated promising\nresults. However, these recent methods do not explicitly show the knowledge\nneeded to answer the questions and thus lack interpretability. Inspired by\nrecent work on knowledge generation from LLMs for text-based QA, in this work\nwe propose and test a similar knowledge-generation-based K-VQA method, which\nfirst generates knowledge from an LLM and then incorporates the generated\nknowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA\nbenchmarks and found that our method performs better than previous zero-shot\nK-VQA methods and our generated knowledge is generally relevant and helpful.",
      "tldr_zh": "这篇论文针对知识型视觉问答(K-VQA)提出了一种基于知识生成的方法，以解决现有 zero-shot 方法缺乏解释性的问题。方法首先利用预训练的 LLMs 生成相关知识，然后在 zero-shot 方式下将这些知识整合到 K-VQA 模型中。实验结果显示，该方法在两个 K-VQA 基准上优于先前 zero-shot 方法，且生成的知识通常相关且有助于提升问答准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted as Findings in EACL 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.02541v1",
      "published_date": "2024-02-04 15:41:35 UTC",
      "updated_date": "2024-02-04 15:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:02:29.558494"
    },
    {
      "arxiv_id": "2402.02522v1",
      "title": "Absolute convergence and error thresholds in non-active adaptive sampling",
      "title_zh": "非主动自适应采样中的绝对收敛和错误阈值",
      "authors": [
        "Manuel Vilares Ferro",
        "Victor M. Darriba Bilbao",
        "Jesús Vilares Ferro"
      ],
      "abstract": "Non-active adaptive sampling is a way of building machine learning models\nfrom a training data base which are supposed to dynamically and automatically\nderive guaranteed sample size. In this context and regardless of the strategy\nused in both scheduling and generating of weak predictors, a proposal for\ncalculating absolute convergence and error thresholds is described. We not only\nmake it possible to establish when the quality of the model no longer\nincreases, but also supplies a proximity condition to estimate in absolute\nterms how close it is to achieving such a goal, thus supporting decision making\nfor fine-tuning learning parameters in model selection. The technique proves\nits correctness and completeness with respect to our working hypotheses, in\naddition to strengthening the robustness of the sampling scheme. Tests meet our\nexpectations and illustrate the proposal in the domain of natural language\nprocessing, taking the generation of part-of-speech taggers as case study.",
      "tldr_zh": "这篇论文探讨了 non-active adaptive sampling 中的绝对收敛和错误阈值计算方法，旨在为机器学习模型动态推导出保证的样本大小，而不依赖于弱预测器的调度或生成策略。研究提出了一种技术，不仅能确定模型质量何时不再提升，还提供一个接近条件来估算模型距离目标的绝对差距，从而支持学习参数的微调决策。该方法在假设上证明了正确性和完整性，并在自然语言处理领域（如生成词性标记器）的测试中展示了增强的鲁棒性和预期效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02522v1",
      "published_date": "2024-02-04 15:10:34 UTC",
      "updated_date": "2024-02-04 15:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:02:41.861033"
    },
    {
      "arxiv_id": "2402.06654v1",
      "title": "Conversational Crowdsensing: A Parallel Intelligence Powered Novel Sensing Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengqiu Zhu",
        "Yong Zhao",
        "Bin Chen",
        "Sihang Qiu",
        "Kai Xu",
        "Quanjun Yin",
        "Jincai Huang",
        "Zhong Liu",
        "Fei-Yue Wang"
      ],
      "abstract": "The transition from CPS-based Industry 4.0 to CPSS-based Industry 5.0 brings\nnew requirements and opportunities to current sensing approaches, especially in\nlight of recent progress in Chatbots and Large Language Models (LLMs).\nTherefore, the advancement of parallel intelligence-powered Crowdsensing\nIntelligence (CSI) is witnessed, which is currently advancing towards\nlinguistic intelligence. In this paper, we propose a novel sensing paradigm,\nnamely conversational crowdsensing, for Industry 5.0. It can alleviate workload\nand professional requirements of individuals and promote the organization and\noperation of diverse workforce, thereby facilitating faster response and wider\npopularization of crowdsensing systems. Specifically, we design the\narchitecture of conversational crowdsensing to effectively organize three types\nof participants (biological, robotic, and digital) from diverse communities.\nThrough three levels of effective conversation (i.e., inter-human, human-AI,\nand inter-AI), complex interactions and service functionalities of different\nworkers can be achieved to accomplish various tasks across three sensing phases\n(i.e., requesting, scheduling, and executing). Moreover, we explore the\nfoundational technologies for realizing conversational crowdsensing,\nencompassing LLM-based multi-agent systems, scenarios engineering and\nconversational human-AI cooperation. Finally, we present potential industrial\napplications of conversational crowdsensing and discuss its implications. We\nenvision that conversations in natural language will become the primary\ncommunication channel during crowdsensing process, enabling richer information\nexchange and cooperative problem-solving among humans, robots, and AI.",
      "tldr_zh": "本文提出了一种新型 sensing 范式，名为 conversational crowdsensing，基于平行智能技术，旨在适应 Industry 5.0 的需求，利用 Chatbots 和 LLMs 提升 Crowdsensing Intelligence (CSI)。该方法设计了包括生物、机器人和数字参与者的架构，通过 inter-human、human-AI 和 inter-AI 的三级对话，实现 sensing 过程的请求、调度和执行阶段，提高任务协作效率并减轻个体工作负担。论文探讨了基础技术，如 LLM-based multi-agent systems、scenarios engineering 和 conversational human-AI cooperation，并展示了潜在工业应用。最终，展望自然语言对话将成为 crowdsensing 的主要通信渠道，促进人类、机器人和 AI 间的合作问题解决。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06654v1",
      "published_date": "2024-02-04 15:10:11 UTC",
      "updated_date": "2024-02-04 15:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:02:55.806784"
    },
    {
      "arxiv_id": "2402.02519v1",
      "title": "SIMPL: A Simple and Efficient Multi-agent Motion Prediction Baseline for Autonomous Driving",
      "title_zh": "SIMPL：用于自动驾驶的简单且高效的多智能体运动预测基线",
      "authors": [
        "Lu Zhang",
        "Peiliang Li",
        "Sikang Liu",
        "Shaojie Shen"
      ],
      "abstract": "This paper presents a Simple and effIcient Motion Prediction baseLine (SIMPL)\nfor autonomous vehicles. Unlike conventional agent-centric methods with high\naccuracy but repetitive computations and scene-centric methods with compromised\naccuracy and generalizability, SIMPL delivers real-time, accurate motion\npredictions for all relevant traffic participants. To achieve improvements in\nboth accuracy and inference speed, we propose a compact and efficient global\nfeature fusion module that performs directed message passing in a symmetric\nmanner, enabling the network to forecast future motion for all road users in a\nsingle feed-forward pass and mitigating accuracy loss caused by viewpoint\nshifting. Additionally, we investigate the continuous trajectory\nparameterization using Bernstein basis polynomials in trajectory decoding,\nallowing evaluations of states and their higher-order derivatives at any\ndesired time point, which is valuable for downstream planning tasks. As a\nstrong baseline, SIMPL exhibits highly competitive performance on Argoverse 1 &\n2 motion forecasting benchmarks compared with other state-of-the-art methods.\nFurthermore, its lightweight design and low inference latency make SIMPL highly\nextensible and promising for real-world onboard deployment. We open-source the\ncode at https://github.com/HKUST-Aerial-Robotics/SIMPL.",
      "tldr_zh": "本论文提出SIMPL，一种简单高效的多智能体运动预测基线，用于自动驾驶车辆。它通过一个紧凑的全局特征融合模块实现对称定向消息传递（directed message passing），允许在单次前向传递中为所有道路用户提供实时准确的运动预测，同时减少视点转换导致的准确性损失。论文还探讨使用Bernstein basis polynomials进行连续轨迹参数化，以评估任意时间点的状态及其高阶导数，支持下游规划任务。在Argoverse 1 & 2基准测试中，SIMPL与最先进方法相比表现出高度竞争的性能，且其轻量设计和低推断延迟使其适合实际部署。开源代码已在GitHub上发布。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Code is available at https://github.com/HKUST-Aerial-Robotics/SIMPL",
      "pdf_url": "http://arxiv.org/pdf/2402.02519v1",
      "published_date": "2024-02-04 15:07:49 UTC",
      "updated_date": "2024-02-04 15:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:03:05.984533"
    },
    {
      "arxiv_id": "2402.02516v1",
      "title": "Adaptive scheduling for adaptive sampling in POS taggers construction",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Vilares Ferro",
        "Victor M. Darriba Bilbao",
        "Jesús Vilares Ferro"
      ],
      "abstract": "We introduce an adaptive scheduling for adaptive sampling as a novel way of\nmachine learning in the construction of part-of-speech taggers. The goal is to\nspeed up the training on large data sets, without significant loss of\nperformance with regard to an optimal configuration. In contrast to previous\nmethods using a random, fixed or regularly rising spacing between the\ninstances, ours analyzes the shape of the learning curve geometrically in\nconjunction with a functional model to increase or decrease it at any time. The\nalgorithm proves to be formally correct regarding our working hypotheses.\nNamely, given a case, the following one is the nearest ensuring a net gain of\nlearning ability from the former, it being possible to modulate the level of\nrequirement for this condition. We also improve the robustness of sampling by\npaying greater attention to those regions of the training data base subject to\na temporary inflation in performance, thus preventing the learning from\nstopping prematurely.\n  The proposal has been evaluated on the basis of its reliability to identify\nthe convergence of models, corroborating our expectations. While a concrete\nhalting condition is used for testing, users can choose any condition\nwhatsoever to suit their own specific needs.",
      "tldr_zh": "本研究提出了一种自适应调度(adaptive scheduling)方法，用于在构建词性标注器(POS taggers)时进行自适应采样(adaptive sampling)，旨在加速大型数据集的训练，同时保持性能接近最优配置。该方法通过几何分析学习曲线(learning curve)并结合功能模型动态调整采样间隔，与传统随机或固定间隔方法不同，能确保每个后续采样带来净学习收益，并增强对性能提升区域的关注以防止提前停止学习。实验验证了该算法在识别模型收敛(convergence)方面的可靠性和鲁棒性，用户可根据需求自定义停止条件，为高效机器学习提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pager, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02516v1",
      "published_date": "2024-02-04 15:02:17 UTC",
      "updated_date": "2024-02-04 15:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:03:17.617027"
    },
    {
      "arxiv_id": "2402.02515v1",
      "title": "Modeling of learning curves with applications to pos tagging",
      "title_zh": "学习曲线的建模及其在词性标注中的应用",
      "authors": [
        "Manuel Vilares Ferro",
        "Victor M. Darriba Bilbao",
        "Francisco J. Ribadas Pena"
      ],
      "abstract": "An algorithm to estimate the evolution of learning curves on the whole of a\ntraining data base, based on the results obtained from a portion and using a\nfunctional strategy, is introduced. We approximate iteratively the sought value\nat the desired time, independently of the learning technique used and once a\npoint in the process, called prediction level, has been passed. The proposal\nproves to be formally correct with respect to our working hypotheses and\nincludes a reliable proximity condition. This allows the user to fix a\nconvergence threshold with respect to the accuracy finally achievable, which\nextends the concept of stopping criterion and seems to be effective even in the\npresence of distorting observations.\n  Our aim is to evaluate the training effort, supporting decision making in\norder to reduce the need for both human and computational resources during the\nlearning process. The proposal is of interest in at least three operational\nprocedures. The first is the anticipation of accuracy gain, with the purpose of\nmeasuring how much work is needed to achieve a certain degree of performance.\nThe second relates the comparison of efficiency between systems at training\ntime, with the objective of completing this task only for the one that best\nsuits our requirements. The prediction of accuracy is also a valuable item of\ninformation for customizing systems, since we can estimate in advance the\nimpact of settings on both the performance and the development costs. Using the\ngeneration of part-of-speech taggers as an example application, the\nexperimental results are consistent with our expectations.",
      "tldr_zh": "本论文提出了一种算法，用于基于部分训练数据的结果估算整个训练数据库的学习 curves 的演化。该算法采用 functional strategy 进行迭代逼近，允许在通过 prediction level 后独立于具体学习技术地预测最终准确率，并提供可靠的接近条件以设置收敛阈值，从而扩展停止准则并减少干扰观察的影响。主要目的是评估训练努力，支持决策以优化人力和计算资源；在 POS tagging 的应用中，实验结果显示该方法能有效预测准确率增益、比较系统效率，并辅助系统自定义。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02515v1",
      "published_date": "2024-02-04 15:00:52 UTC",
      "updated_date": "2024-02-04 15:00:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:03:29.252974"
    },
    {
      "arxiv_id": "2402.02513v1",
      "title": "Early stopping by correlating online indicators in neural networks",
      "title_zh": "通过相关在线",
      "authors": [
        "Manuel Vilares Ferro",
        "Yerai Doval Mosquera",
        "Francisco J. Ribadas Pena",
        "Victor M. Darriba Bilbao"
      ],
      "abstract": "In order to minimize the generalization error in neural networks, a novel\ntechnique to identify overfitting phenomena when training the learner is\nformally introduced. This enables support of a reliable and trustworthy early\nstopping condition, thus improving the predictive power of that type of\nmodeling. Our proposal exploits the correlation over time in a collection of\nonline indicators, namely characteristic functions for indicating if a set of\nhypotheses are met, associated with a range of independent stopping conditions\nbuilt from a canary judgment to evaluate the presence of overfitting. That way,\nwe provide a formal basis for decision making in terms of interrupting the\nlearning process.\n  As opposed to previous approaches focused on a single criterion, we take\nadvantage of subsidiarities between independent assessments, thus seeking both\na wider operating range and greater diagnostic reliability. With a view to\nillustrating the effectiveness of the halting condition described, we choose to\nwork in the sphere of natural language processing, an operational continuum\nincreasingly based on machine learning. As a case study, we focus on parser\ngeneration, one of the most demanding and complex tasks in the domain. The\nselection of cross-validation as a canary function enables an actual comparison\nwith the most representative early stopping conditions based on overfitting\nidentification, pointing to a promising start toward an optimal bias and\nvariance control.",
      "tldr_zh": "该论文提出了一种新颖的技术，通过分析神经网络训练中的在线指标相关性，来识别过拟合现象并实现可靠的 early stopping，从而最小化泛化错误并提升模型预测能力。该方法利用一组特征函数作为在线指标，结合多个独立的 stopping conditions 和 canary judgment，对过拟合进行评估，比传统的单一标准方法更具互补性和诊断可靠性。在自然语言处理领域的解析器生成任务中，实验结果显示，该方法通过交叉验证与其他 early stopping 条件比较，实现了更好的偏差和方差控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02513v1",
      "published_date": "2024-02-04 14:57:20 UTC",
      "updated_date": "2024-02-04 14:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:03:42.479850"
    },
    {
      "arxiv_id": "2402.03390v1",
      "title": "PixelGen: Rethinking Embedded Camera Systems",
      "title_zh": "PixelGen：重新思考嵌入式相机系统",
      "authors": [
        "Kunjun Li",
        "Manoj Gulati",
        "Steven Waskito",
        "Dhairya Shah",
        "Shantanu Chakrabarty",
        "Ambuj Varshney"
      ],
      "abstract": "Embedded camera systems are ubiquitous, representing the most widely deployed\nexample of a wireless embedded system. They capture a representation of the\nworld - the surroundings illuminated by visible or infrared light. Despite\ntheir widespread usage, the architecture of embedded camera systems has\nremained unchanged, which leads to limitations. They visualize only a tiny\nportion of the world. Additionally, they are energy-intensive, leading to\nlimited battery lifespan. We present PixelGen, which re-imagines embedded\ncamera systems. Specifically, PixelGen combines sensors, transceivers, and\nlow-resolution image and infrared vision sensors to capture a broader world\nrepresentation. They are deliberately chosen for their simplicity, low bitrate,\nand power consumption, culminating in an energy-efficient platform. We show\nthat despite the simplicity, the captured data can be processed using\ntransformer-based image and language models to generate novel representations\nof the environment. For example, we demonstrate that it can allow the\ngeneration of high-definition images, while the camera utilises low-power,\nlow-resolution monochrome cameras. Furthermore, the capabilities of PixelGen\nextend beyond traditional photography, enabling visualization of phenomena\ninvisible to conventional cameras, such as sound waves. PixelGen can enable\nnumerous novel applications, and we demonstrate that it enables unique\nvisualization of the surroundings that are then projected on extended reality\nheadsets. We believe, PixelGen goes beyond conventional cameras and opens new\navenues for research and photography.",
      "tldr_zh": "该论文重新审视嵌入式相机系统（Embedded Camera Systems）的局限性，包括视野狭窄和高能耗问题。作者提出 PixelGen，一种创新框架，通过结合传感器、收发器和低分辨率图像及红外视觉传感器，实现简单、低比特率和高能效的设计。利用 Transformer-based 图像和语言模型处理捕获的数据，PixelGen 能够生成高分辨率图像，并可视化传统相机无法捕捉的现象，如声波。该系统扩展了相机应用潜力，例如在扩展现实（Extended Reality）头盔上投影新型环境可视化，并为研究和摄影领域开辟新方向。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.NI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03390v1",
      "published_date": "2024-02-04 14:41:56 UTC",
      "updated_date": "2024-02-04 14:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:03:55.580241"
    },
    {
      "arxiv_id": "2402.02500v3",
      "title": "Point Cloud Matters: Rethinking the Impact of Different Observation Spaces on Robot Learning",
      "title_zh": "点云至关重要：重新审视不同观察空间对机器人学习的影响",
      "authors": [
        "Haoyi Zhu",
        "Yating Wang",
        "Di Huang",
        "Weicai Ye",
        "Wanli Ouyang",
        "Tong He"
      ],
      "abstract": "In robot learning, the observation space is crucial due to the distinct\ncharacteristics of different modalities, which can potentially become a\nbottleneck alongside policy design. In this study, we explore the influence of\nvarious observation spaces on robot learning, focusing on three predominant\nmodalities: RGB, RGB-D, and point cloud. We introduce OBSBench, a benchmark\ncomprising two simulators and 125 tasks, along with standardized pipelines for\nvarious encoders and policy baselines. Extensive experiments on diverse\ncontact-rich manipulation tasks reveal a notable trend: point cloud-based\nmethods, even those with the simplest designs, frequently outperform their RGB\nand RGB-D counterparts. This trend persists in both scenarios: training from\nscratch and utilizing pre-training. Furthermore, our findings demonstrate that\npoint cloud observations often yield better policy performance and\nsignificantly stronger generalization capabilities across various geometric and\nvisual conditions. These outcomes suggest that the 3D point cloud is a valuable\nobservation modality for intricate robotic tasks. We also suggest that\nincorporating both appearance and coordinate information can enhance the\nperformance of point cloud methods. We hope our work provides valuable insights\nand guidance for designing more generalizable and robust robotic models. Codes\nare available at https://github.com/HaoyiZhu/PointCloudMatters.",
      "tldr_zh": "本研究探讨了不同观察空间（RGB、RGB-D 和 point cloud）对机器人学习的影响，强调 point cloud 的潜在优势。作者引入 OBSBench 基准，包括两个模拟器和 125 个任务，以及标准化编码器和策略基线，通过广泛实验发现 point cloud 方法即使设计简单，也在接触丰富操作任务中显著优于 RGB 和 RGB-D 方法，并在从零训练和预训练场景下展现出更好的策略性能和泛化能力。这些发现表明 point cloud 作为观察模态对复杂机器人任务至关重要，并建议结合外观和坐标信息进一步提升性能，为设计更鲁棒的机器人模型提供指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) Track on Datasets and Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2402.02500v3",
      "published_date": "2024-02-04 14:18:45 UTC",
      "updated_date": "2024-10-22 09:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:04:05.282752"
    },
    {
      "arxiv_id": "2402.02498v2",
      "title": "Fully Differentiable Correlation-driven 2D/3D Registration for X-ray to CT Image Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Minheng Chen",
        "Zhirun Zhang",
        "Shuheng Gu",
        "Zhangyang Ge",
        "Youyong Kong"
      ],
      "abstract": "Image-based rigid 2D/3D registration is a critical technique for fluoroscopic\nguided surgical interventions. In recent years, some learning-based fully\ndifferentiable methods have produced beneficial outcomes while the process of\nfeature extraction and gradient flow transmission still lack controllability\nand interpretability. To alleviate these problems, in this work, we propose a\nnovel fully differentiable correlation-driven network using a dual-branch\nCNN-transformer encoder which enables the network to extract and separate\nlow-frequency global features from high-frequency local features. A\ncorrelation-driven loss is further proposed for low-frequency feature and\nhigh-frequency feature decomposition based on embedded information. Besides, a\ntraining strategy that learns to approximate a convex-shape similarity function\nis applied in our work. We test our approach on a in-house datasetand show that\nit outperforms both existing fully differentiable learning-based registration\napproaches and the conventional optimization-based baseline.",
      "tldr_zh": "本文提出了一种全微分相关驱动（Fully Differentiable Correlation-driven）网络，用于X射线到CT图像融合中的刚性2D/3D注册，旨在解决现有学习方法在特征提取和梯度流动的可控性及可解释性不足的问题。该网络采用双分支CNN-Transformer编码器来提取并分离低频全局特征和高频局部特征，并引入相关驱动损失（Correlation-driven loss）基于嵌入信息进行特征分解，同时应用一种训练策略来逼近凸形相似性函数。在内部数据集上的实验表明，该方法优于现有全微分学习方法和传统优化基线，提高了注册性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ISBI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02498v2",
      "published_date": "2024-02-04 14:12:51 UTC",
      "updated_date": "2024-03-15 08:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:04:18.176851"
    },
    {
      "arxiv_id": "2402.02479v2",
      "title": "BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurav Pandey",
        "Yatin Nandwani",
        "Tahira Naseem",
        "Mayank Mishra",
        "Guangxuan Xu",
        "Dinesh Raghu",
        "Sachindra Joshi",
        "Asim Munawar",
        "Ramón Fernandez Astudillo"
      ],
      "abstract": "Distribution matching methods for language model alignment such as Generation\nwith Distributional Control (GDC) and Distributional Policy Gradient (DPG) have\nnot received the same level of attention in reinforcement learning from human\nfeedback (RLHF) as contrastive methods such as Sequence Likelihood Calibration\n(SLiC), Direct Preference Optimization (DPO) and its variants. We identify high\nvariance of the gradient estimate as the primary reason for the lack of success\nof these methods and propose a self-normalized baseline to reduce the variance.\nWe further generalize the target distribution in DPG, GDC and DPO by using\nBayes' rule to define the reward-conditioned posterior. The resulting approach,\nreferred to as BRAIn - Bayesian Reward-conditioned Amortized Inference acts as\na bridge between distribution matching methods and DPO and significantly\noutperforms prior art in summarization and Antropic HH tasks.",
      "tldr_zh": "该论文探讨了分布匹配方法（如 GDC 和 DPG）在强化学习从人类反馈（RLHF）中的应用问题，这些方法因梯度估计的高方差而不如对比方法（如 SLiC 和 DPO）受欢迎。作者提出了一种自归一化基线来降低方差，并使用贝叶斯规则（Bayes' rule）定义奖励条件后验，从而推广 DPG、GDC 和 DPO 的目标分布。结果，新的 BRAIn 方法（Bayesian Reward-conditioned Amortized Inference）桥接了分布匹配方法与 DPO，在摘要任务和 Anthropic HH 任务中显著优于现有技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2402.02479v2",
      "published_date": "2024-02-04 13:16:29 UTC",
      "updated_date": "2024-06-10 10:18:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:04:31.495041"
    },
    {
      "arxiv_id": "2402.02478v1",
      "title": "Why are hyperbolic neural networks effective? A study on hierarchical representation capability",
      "title_zh": "为什么双曲神经网络有效？ 关于层次表示能力的研究所",
      "authors": [
        "Shicheng Tan",
        "Huanjing Zhao",
        "Shu Zhao",
        "Yanping Zhang"
      ],
      "abstract": "Hyperbolic Neural Networks (HNNs), operating in hyperbolic space, have been\nwidely applied in recent years, motivated by the existence of an optimal\nembedding in hyperbolic space that can preserve data hierarchical relationships\n(termed Hierarchical Representation Capability, HRC) more accurately than\nEuclidean space. However, there is no evidence to suggest that HNNs can achieve\nthis theoretical optimal embedding, leading to much research being built on\nflawed motivations. In this paper, we propose a benchmark for evaluating HRC\nand conduct a comprehensive analysis of why HNNs are effective through\nlarge-scale experiments. Inspired by the analysis results, we propose several\npre-training strategies to enhance HRC and improve the performance of\ndownstream tasks, further validating the reliability of the analysis.\nExperiments show that HNNs cannot achieve the theoretical optimal embedding.\nThe HRC is significantly affected by the optimization objectives and\nhierarchical structures, and enhancing HRC through pre-training strategies can\nsignificantly improve the performance of HNNs.",
      "tldr_zh": "本文研究了 Hyperbolic Neural Networks (HNNs) 的有效性，焦点在于其 Hierarchical Representation Capability (HRC)，质疑 HNNs 是否能实现理论上更优的层次关系嵌入。作者提出一个 HRC 基准，通过大规模实验分析发现，HNNs 无法达到理论最优嵌入，且其性能受优化目标和层次结构显著影响。基于这些分析结果，论文引入预训练策略来增强 HRC，从而显著提高下游任务的性能，并验证了分析的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02478v1",
      "published_date": "2024-02-04 13:15:59 UTC",
      "updated_date": "2024-02-04 13:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:04:43.708187"
    },
    {
      "arxiv_id": "2402.02468v2",
      "title": "Fast Peer Adaptation with Context-aware Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Long Ma",
        "Yuanfei Wang",
        "Fangwei Zhong",
        "Song-Chun Zhu",
        "Yizhou Wang"
      ],
      "abstract": "Fast adapting to unknown peers (partners or opponents) with different\nstrategies is a key challenge in multi-agent games. To do so, it is crucial for\nthe agent to probe and identify the peer's strategy efficiently, as this is the\nprerequisite for carrying out the best response in adaptation. However,\nexploring the strategies of unknown peers is difficult, especially when the\ngames are partially observable and have a long horizon. In this paper, we\npropose a peer identification reward, which rewards the learning agent based on\nhow well it can identify the behavior pattern of the peer over the historical\ncontext, such as the observation over multiple episodes. This reward motivates\nthe agent to learn a context-aware policy for effective exploration and fast\nadaptation, i.e., to actively seek and collect informative feedback from peers\nwhen uncertain about their policies and to exploit the context to perform the\nbest response when confident. We evaluate our method on diverse testbeds that\ninvolve competitive (Kuhn Poker), cooperative (PO-Overcooked), or mixed\n(Predator-Prey-W) games with peer agents. We demonstrate that our method\ninduces more active exploration behavior, achieving faster adaptation and\nbetter outcomes than existing methods.",
      "tldr_zh": "这篇论文针对多智能体游戏中快速适应未知对等体（伙伴或对手）的挑战，提出了一种基于 peer identification reward 的方法。该奖励机制根据历史上下文（如多回合观察）奖励代理，以更好地识别对等体的行为模式，从而学习一个 context-aware policy，用于在不确定时主动探索信息，在确定时执行最佳响应。实验在竞争性（Kuhn Poker）、合作性（PO-Overcooked）和混合（Predator-Prey-W）游戏中验证了该方法，促进了更主动的探索行为，并实现了比现有方法更快的适应和更好的整体结果。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2024. 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.02468v2",
      "published_date": "2024-02-04 13:02:27 UTC",
      "updated_date": "2024-08-09 08:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:04:55.341800"
    },
    {
      "arxiv_id": "2402.02464v3",
      "title": "A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangyang Gao",
        "Daize Dong",
        "Cheng Tan",
        "Jun Xia",
        "Bozhen Hu",
        "Stan Z. Li"
      ],
      "abstract": "Can we model Non-Euclidean graphs as pure language or even Euclidean vectors\nwhile retaining their inherent information? The Non-Euclidean property have\nposed a long term challenge in graph modeling. Despite recent graph neural\nnetworks and graph transformers efforts encoding graphs as Euclidean vectors,\nrecovering the original graph from vectors remains a challenge. In this paper,\nwe introduce GraphsGPT, featuring an Graph2Seq encoder that transforms\nNon-Euclidean graphs into learnable Graph Words in the Euclidean space, along\nwith a GraphGPT decoder that reconstructs the original graph from Graph Words\nto ensure information equivalence. We pretrain GraphsGPT on $100$M molecules\nand yield some interesting findings: (1) The pretrained Graph2Seq excels in\ngraph representation learning, achieving state-of-the-art results on $8/9$\ngraph classification and regression tasks. (2) The pretrained GraphGPT serves\nas a strong graph generator, demonstrated by its strong ability to perform both\nfew-shot and conditional graph generation. (3) Graph2Seq+GraphGPT enables\neffective graph mixup in the Euclidean space, overcoming previously known\nNon-Euclidean challenges. (4) The edge-centric pretraining framework GraphsGPT\ndemonstrates its efficacy in graph domain tasks, excelling in both\nrepresentation and generation. Code is available at\n\\href{https://github.com/A4Bio/GraphsGPT}{GitHub}.",
      "tldr_zh": "这篇论文提出了 GraphsGPT 框架，使用纯 Transformer 将 Non-Euclidean 图转化为 Euclidean 空间的 Graph Words，通过 Graph2Seq 编码器进行转换和 GraphGPT 解码器重建原图，以确保信息等价。模型在 100M 分子数据集上预训练后，Graph2Seq 在 9 个图分类和回归任务中取得了 8 个状态-of-the-art (SOTA) 结果。GraphGPT 展示了强大的图生成能力，支持少样本和条件生成，同时 Graph2Seq 与 GraphGPT 的结合克服了 Non-Euclidean 挑战，实现有效的欧空间图混合。整体框架证明了其在图表示学习和生成任务中的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02464v3",
      "published_date": "2024-02-04 12:29:40 UTC",
      "updated_date": "2024-05-29 05:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:05:07.951620"
    },
    {
      "arxiv_id": "2402.02460v2",
      "title": "Review of multimodal machine learning approaches in healthcare",
      "title_zh": "医疗保健中多模态机器学习方法的综述",
      "authors": [
        "Felix Krones",
        "Umar Marikkar",
        "Guy Parsons",
        "Adam Szmul",
        "Adam Mahdi"
      ],
      "abstract": "Machine learning methods in healthcare have traditionally focused on using\ndata from a single modality, limiting their ability to effectively replicate\nthe clinical practice of integrating multiple sources of information for\nimproved decision making. Clinicians typically rely on a variety of data\nsources including patients' demographic information, laboratory data, vital\nsigns and various imaging data modalities to make informed decisions and\ncontextualise their findings. Recent advances in machine learning have\nfacilitated the more efficient incorporation of multimodal data, resulting in\napplications that better represent the clinician's approach. Here, we provide a\nreview of multimodal machine learning approaches in healthcare, offering a\ncomprehensive overview of recent literature. We discuss the various data\nmodalities used in clinical diagnosis, with a particular emphasis on imaging\ndata. We evaluate fusion techniques, explore existing multimodal datasets and\nexamine common training strategies.",
      "tldr_zh": "本综述论文审视了多模态机器学习（multimodal machine learning）在医疗领域的应用，指出传统方法仅依赖单一模态数据（如人口统计信息、实验室数据、生命体征或成像数据），从而限制了模拟临床决策的有效性。论文强调了最近的机器学习进展如何促进多源数据的整合，更好地反映临床实践，并讨论了各种数据模态、融合技术（fusion techniques）、现有数据集以及常见训练策略。总体上，该研究为提升医疗决策的准确性和全面性提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.02460v2",
      "published_date": "2024-02-04 12:21:38 UTC",
      "updated_date": "2024-02-12 01:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:05:18.462642"
    },
    {
      "arxiv_id": "2403.09673v2",
      "title": "FoldToken: Learning Protein Language via Vector Quantization and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangyang Gao",
        "Cheng Tan",
        "Jue Wang",
        "Yufei Huang",
        "Lirong Wu",
        "Stan Z. Li"
      ],
      "abstract": "Is there a foreign language describing protein sequences and structures\nsimultaneously? Protein structures, represented by continuous 3D points, have\nlong posed a challenge due to the contrasting modeling paradigms of discrete\nsequences. We introduce \\textbf{FoldTokenizer} to represent protein\nsequence-structure as discrete symbols. This innovative approach involves\nprojecting residue types and structures into a discrete space, guided by a\nreconstruction loss for information preservation. We refer to the learned\ndiscrete symbols as \\textbf{FoldToken}, and the sequence of FoldTokens serves\nas a new protein language, transforming the protein sequence-structure into a\nunified modality. We apply the created protein language on general backbone\ninpainting and antibody design tasks, building the first GPT-style model\n(\\textbf{FoldGPT}) for sequence-structure co-generation with promising results.\nKey to our success is the substantial enhancement of the vector quantization\nmodule, Soft Conditional Vector Quantization (\\textbf{SoftCVQ}).",
      "tldr_zh": "这篇论文提出了 FoldTokenizer，一种创新方法，通过 Vector Quantization 将蛋白质序列和结构投影到离散空间中，使用重建损失来保留信息，从而创建了名为 FoldToken 的统一蛋白质语言。FoldToken 序列化了蛋白质的序列-结构模态，便于共同建模。论文进一步构建了首个 GPT 风格模型 FoldGPT，并应用其于蛋白质主链修复和抗体设计任务，取得了有前景的生成结果，其中关键在于改进的 Soft Conditional Vector Quantization (SoftCVQ) 模块。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09673v2",
      "published_date": "2024-02-04 12:18:51 UTC",
      "updated_date": "2024-03-19 05:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:05:30.971080"
    },
    {
      "arxiv_id": "2402.02452v2",
      "title": "XAI-CF -- Examining the Role of Explainable Artificial Intelligence in Cyber Forensics",
      "title_zh": "XAI-CF -- 考察可解释人工智能在网络取证中的作用",
      "authors": [
        "Shahid Alam",
        "Zeynep Altiparmak"
      ],
      "abstract": "With the rise of complex cyber devices Cyber Forensics (CF) is facing many\nnew challenges. For example, there are dozens of systems running on\nsmartphones, each with more than millions of downloadable applications. Sifting\nthrough this large amount of data and making sense requires new techniques,\nsuch as from the field of Artificial Intelligence (AI). To apply these\ntechniques successfully in CF, we need to justify and explain the results to\nthe stakeholders of CF, such as forensic analysts and members of the court, for\nthem to make an informed decision. If we want to apply AI successfully in CF,\nthere is a need to develop trust in AI systems. Some other factors in accepting\nthe use of AI in CF are to make AI authentic, interpretable, understandable,\nand interactive. This way, AI systems will be more acceptable to the public and\nensure alignment with legal standards. An explainable AI (XAI) system can play\nthis role in CF, and we call such a system XAI-CF. XAI-CF is indispensable and\nis still in its infancy. In this paper, we explore and make a case for the\nsignificance and advantages of XAI-CF. We strongly emphasize the need to build\na successful and practical XAI-CF system and discuss some of the main\nrequirements and prerequisites of such a system. We present a formal definition\nof the terms CF and XAI-CF and a comprehensive literature review of previous\nworks that apply and utilize XAI to build and increase trust in CF. We discuss\nsome challenges facing XAI-CF. We also provide some concrete solutions to these\nchallenges. We identify key insights and future research directions for\nbuilding XAI applications for CF. This paper is an effort to explore and\nfamiliarize the readers with the role of XAI applications in CF, and we believe\nthat our work provides a promising basis for future researchers interested in\nXAI-CF.",
      "tldr_zh": "本论文探讨了在网络取证（Cyber Forensics, CF）领域应用可解释人工智能（Explainable Artificial Intelligence, XAI）的必要性，以应对数据量大和复杂性带来的挑战。作者提出XAI-CF系统，通过解释AI决策来提升对取证分析师和法庭stakeholders的信任，确保AI系统更具真实性、易解释性和互动性。论文提供了CF和XAI-CF的正式定义、文献回顾、面临的关键挑战（如构建信任和法律合规性）以及潜在解决方案，并指出了未来研究方向，为开发可靠的XAI-CF应用奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02452v2",
      "published_date": "2024-02-04 11:42:16 UTC",
      "updated_date": "2024-02-07 09:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:05:42.747651"
    },
    {
      "arxiv_id": "2402.02441v5",
      "title": "TopoX: A Suite of Python Packages for Machine Learning on Topological Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Hajij",
        "Mathilde Papillon",
        "Florian Frantzen",
        "Jens Agerberg",
        "Ibrahem AlJabea",
        "Rubén Ballester",
        "Claudio Battiloro",
        "Guillermo Bernárdez",
        "Tolga Birdal",
        "Aiden Brent",
        "Peter Chin",
        "Sergio Escalera",
        "Simone Fiorellino",
        "Odin Hoff Gardaa",
        "Gurusankar Gopalakrishnan",
        "Devendra Govil",
        "Josef Hoppe",
        "Maneel Reddy Karri",
        "Jude Khouja",
        "Manuel Lecha",
        "Neal Livesay",
        "Jan Meißner",
        "Soham Mukherjee",
        "Alexander Nikitin",
        "Theodore Papamarkou",
        "Jaro Prílepok",
        "Karthikeyan Natesan Ramamurthy",
        "Paul Rosen",
        "Aldo Guzmán-Sáenz",
        "Alessandro Salatiello",
        "Shreyas N. Samaga",
        "Simone Scardapane",
        "Michael T. Schaub",
        "Luca Scofano",
        "Indro Spinelli",
        "Lev Telyatnikov",
        "Quang Truong",
        "Robin Walters",
        "Maosheng Yang",
        "Olga Zaghen",
        "Ghada Zamzmi",
        "Ali Zia",
        "Nina Miolane"
      ],
      "abstract": "We introduce TopoX, a Python software suite that provides reliable and\nuser-friendly building blocks for computing and machine learning on topological\ndomains that extend graphs: hypergraphs, simplicial, cellular, path and\ncombinatorial complexes. TopoX consists of three packages: TopoNetX facilitates\nconstructing and computing on these domains, including working with nodes,\nedges and higher-order cells; TopoEmbedX provides methods to embed topological\ndomains into vector spaces, akin to popular graph-based embedding algorithms\nsuch as node2vec; TopoModelX is built on top of PyTorch and offers a\ncomprehensive toolbox of higher-order message passing functions for neural\nnetworks on topological domains. The extensively documented and unit-tested\nsource code of TopoX is available under MIT license at\nhttps://pyt-team.github.io/}{https://pyt-team.github.io/.",
      "tldr_zh": "我们介绍了 TopoX，这是一个 Python 软件套件，旨在为拓扑域（如 hypergraphs、simplicial complexes 和 cellular complexes）上的计算和 machine learning 提供可靠且用户友好的工具。TopoX 包括三个核心包：TopoNetX 用于构建和计算拓扑域，包括节点、edges 和更高阶单元；TopoEmbedX 提供将这些域嵌入向量空间的方法，类似于 node2vec 等 graph-based 算法；TopoModelX 基于 PyTorch，提供了全面的 higher-order message passing 函数，支持拓扑域上的神经网络。该套件开源（MIT 许可），并附带详细文档和单元测试，便于研究者和开发者应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02441v5",
      "published_date": "2024-02-04 10:41:40 UTC",
      "updated_date": "2024-12-09 02:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:05:56.470883"
    },
    {
      "arxiv_id": "2402.02439v2",
      "title": "DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching",
      "title_zh": "DiffStitch：通过基于扩散的轨迹",
      "authors": [
        "Guanghe Li",
        "Yixiang Shan",
        "Zhengbang Zhu",
        "Ting Long",
        "Weinan Zhang"
      ],
      "abstract": "In offline reinforcement learning (RL), the performance of the learned policy\nhighly depends on the quality of offline datasets. However, in many cases, the\noffline dataset contains very limited optimal trajectories, which poses a\nchallenge for offline RL algorithms as agents must acquire the ability to\ntransit to high-reward regions. To address this issue, we introduce\nDiffusion-based Trajectory Stitching (DiffStitch), a novel diffusion-based data\naugmentation pipeline that systematically generates stitching transitions\nbetween trajectories. DiffStitch effectively connects low-reward trajectories\nwith high-reward trajectories, forming globally optimal trajectories to address\nthe challenges faced by offline RL algorithms. Empirical experiments conducted\non D4RL datasets demonstrate the effectiveness of DiffStitch across RL\nmethodologies. Notably, DiffStitch demonstrates substantial enhancements in the\nperformance of one-step methods (IQL), imitation learning methods (TD3+BC), and\ntrajectory optimization methods (DT).",
      "tldr_zh": "该研究针对离线强化学习（offline reinforcement learning）中数据集缺乏最佳轨迹的问题，提出了一种名为 DiffStitch 的新方法，利用扩散模型（diffusion-based）生成轨迹拼接过渡（Trajectory Stitching），从而有效连接低回报轨迹和高回报轨迹，形成全局最优轨迹。DiffStitch 通过数据增强管道增强了算法的性能，在 D4RL 数据集上的实验显示，它显著提升了多种 RL 方法的表现，包括 one-step methods (IQL)、imitation learning methods (TD3+BC) 和 trajectory optimization methods (DT)。这项创新为改进离线 RL 的数据利用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02439v2",
      "published_date": "2024-02-04 10:30:23 UTC",
      "updated_date": "2024-02-22 00:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:06:07.005752"
    },
    {
      "arxiv_id": "2402.03388v2",
      "title": "Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constraint",
      "title_zh": "翻译失败",
      "authors": [
        "Harshita Chopra",
        "Atanu R. Sinha",
        "Sunav Choudhary",
        "Ryan A. Rossi",
        "Paavan Kumar Indela",
        "Veda Pranav Parwatala",
        "Srinjayee Paul",
        "Aurghya Maiti"
      ],
      "abstract": "Users' behavioral footprints online enable firms to discover behavior-based\nuser segments (or, segments) and deliver segment specific messages to users.\nFollowing the discovery of segments, delivery of messages to users through\npreferred media channels like Facebook and Google can be challenging, as only a\nportion of users in a behavior segment find match in a medium, and only a\nfraction of those matched actually see the message (exposure). Even high\nquality discovery becomes futile when delivery fails. Many sophisticated\nalgorithms exist for discovering behavioral segments; however, these ignore the\ndelivery component. The problem is compounded because (i) the discovery is\nperformed on the behavior data space in firms' data (e.g., user clicks), while\nthe delivery is predicated on the static data space (e.g., geo, age) as defined\nby media; and (ii) firms work under budget constraint. We introduce a\nstochastic optimization based algorithm for delivery optimized discovery of\nbehavioral user segmentation and offer new metrics to address the joint\noptimization. We leverage optimization under a budget constraint for delivery\ncombined with a learning-based component for discovery. Extensive experiments\non a public dataset from Google and a proprietary dataset show the\neffectiveness of our approach by simultaneously improving delivery metrics,\nreducing budget spend and achieving strong predictive performance in discovery.",
      "tldr_zh": "该论文探讨了在预算约束下，利用用户行为数据进行行为用户细分（behavioral user segmentation）的发现，并优化消息传递的问题，以解决现有算法忽略传递组件导致的效率低下。研究引入了一种基于随机优化（stochastic optimization）的算法，结合预算约束优化和学习-based组件，实现发现与传递的联合优化，并提出新指标来评估整体效果。在Google公共数据集和专有数据集上的实验表明，该方法显著改善了传递指标、减少了预算支出，同时保持了强劲的预测性能。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03388v2",
      "published_date": "2024-02-04 10:18:33 UTC",
      "updated_date": "2024-03-15 08:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:06:19.554218"
    },
    {
      "arxiv_id": "2402.02423v2",
      "title": "Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback",
      "title_zh": "Uni-RLHF：通用平台和基准测试套件，用于具有多样化人类反馈的强化学习",
      "authors": [
        "Yifu Yuan",
        "Jianye Hao",
        "Yi Ma",
        "Zibin Dong",
        "Hebin Liang",
        "Jinyi Liu",
        "Zhixin Feng",
        "Kai Zhao",
        "Yan Zheng"
      ],
      "abstract": "Reinforcement Learning with Human Feedback (RLHF) has received significant\nattention for performing tasks without the need for costly manual reward design\nby aligning human preferences. It is crucial to consider diverse human feedback\ntypes and various learning methods in different environments. However,\nquantifying progress in RLHF with diverse feedback is challenging due to the\nlack of standardized annotation platforms and widely used unified benchmarks.\nTo bridge this gap, we introduce Uni-RLHF, a comprehensive system\nimplementation tailored for RLHF. It aims to provide a complete workflow from\nreal human feedback, fostering progress in the development of practical\nproblems. Uni-RLHF contains three packages: 1) a universal multi-feedback\nannotation platform, 2) large-scale crowdsourced feedback datasets, and 3)\nmodular offline RLHF baseline implementations. Uni-RLHF develops a\nuser-friendly annotation interface tailored to various feedback types,\ncompatible with a wide range of mainstream RL environments. We then establish a\nsystematic pipeline of crowdsourced annotations, resulting in large-scale\nannotated datasets comprising more than 15 million steps across 30+ popular\ntasks. Through extensive experiments, the results in the collected datasets\ndemonstrate competitive performance compared to those from well-designed manual\nrewards. We evaluate various design choices and offer insights into their\nstrengths and potential areas of improvement. We wish to build valuable\nopen-source platforms, datasets, and baselines to facilitate the development of\nmore robust and reliable RLHF solutions based on realistic human feedback. The\nwebsite is available at https://uni-rlhf.github.io/.",
      "tldr_zh": "这篇论文引入Uni-RLHF，一个通用平台和基准套件，旨在解决Reinforcement Learning with Human Feedback (RLHF)中多样化人类反馈的标准化问题，从而避免昂贵的手动奖励设计。Uni-RLHF包括一个用户友好的多反馈标注平台、大规模众包反馈数据集（超过1500万步，覆盖30+流行任务），以及模块化的离线RLHF基准实现。实验结果显示，该系统在收集的数据集上表现出与手动奖励相当的竞争性能，并提供了各种设计选择的评估和改进见解。该平台通过开源资源和真实人类反馈，支持更可靠的RLHF发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024. The website is\n  available at https://uni-rlhf.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.02423v2",
      "published_date": "2024-02-04 09:40:22 UTC",
      "updated_date": "2024-03-25 13:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:06:33.712759"
    },
    {
      "arxiv_id": "2402.02420v3",
      "title": "Factuality of Large Language Models: A Survey",
      "title_zh": "大型语言模型的事实性：综述",
      "authors": [
        "Yuxia Wang",
        "Minghan Wang",
        "Muhammad Arslan Manzoor",
        "Fei Liu",
        "Georgi Georgiev",
        "Rocktim Jyoti Das",
        "Preslav Nakov"
      ],
      "abstract": "Large language models (LLMs), especially when instruction-tuned for chat,\nhave become part of our daily lives, freeing people from the process of\nsearching, extracting, and integrating information from multiple sources by\noffering a straightforward answer to a variety of questions in a single place.\nUnfortunately, in many cases, LLM responses are factually incorrect, which\nlimits their applicability in real-world scenarios. As a result, research on\nevaluating and improving the factuality of LLMs has attracted a lot of\nattention recently. In this survey, we critically analyze existing work with\nthe aim to identify the major challenges and their associated causes, pointing\nout to potential solutions for improving the factuality of LLMs, and analyzing\nthe obstacles to automated factuality evaluation for open-ended text\ngeneration. We further offer an outlook on where future research should go.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 的事实性问题，特别是指令调整后的聊天模型常产生事实错误，从而限制了它们在真实场景中的应用。论文通过批判性分析现有研究，识别了LLMs事实性的主要挑战及其原因，包括信息来源整合不足，并提出了潜在解决方案，如改进评估方法和增强生成机制。同时，论文分析了自动事实性评估在开放式文本生成中的障碍，并展望了未来研究方向，以提升LLMs的可靠性和实际价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 figure and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.02420v3",
      "published_date": "2024-02-04 09:36:31 UTC",
      "updated_date": "2024-10-31 04:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:06:44.499644"
    },
    {
      "arxiv_id": "2402.02416v5",
      "title": "Aligner: Efficient Alignment by Learning to Correct",
      "title_zh": "Aligner：通过学习修正实现高效对齐",
      "authors": [
        "Jiaming Ji",
        "Boyuan Chen",
        "Hantao Lou",
        "Donghai Hong",
        "Borong Zhang",
        "Xuehai Pan",
        "Juntao Dai",
        "Tianyi Qiu",
        "Yaodong Yang"
      ],
      "abstract": "With the rapid development of large language models (LLMs) and ever-evolving\npractical requirements, finding an efficient and effective alignment method has\nnever been more critical. However, the tension between the complexity of\ncurrent alignment methods and the need for rapid iteration in deployment\nscenarios necessitates the development of a model-agnostic alignment approach\nthat can operate under these constraints. In this paper, we introduce Aligner,\na novel and simple alignment paradigm that learns the correctional residuals\nbetween preferred and dispreferred answers using a small model. Designed as a\nmodel-agnostic, plug-and-play module, Aligner can be directly applied to\nvarious open-source and API-based models with only one-off training, making it\nsuitable for rapid iteration. Notably, Aligner can be applied to any powerful,\nlarge-scale upstream models. Moreover, it can even iteratively bootstrap the\nupstream models using corrected responses as synthetic human preference data,\nbreaking through the model's performance ceiling. Our experiments demonstrate\nperformance improvements by deploying the same Aligner model across 11\ndifferent LLMs, evaluated on the 3H dimensions (helpfulness, harmlessness, and\nhonesty). Specifically, Aligner-7B has achieved an average improvement of 68.9%\nin helpfulness and 23.8% in harmlessness across the tested LLMs while also\neffectively reducing hallucination. In the Alpaca-Eval leaderboard, stacking\nAligner-2B on GPT-4 Turbo improved its LC Win Rate from 55.0% to 58.3%,\nsurpassing GPT-4 Omni's 57.5% Win Rate (community report).",
      "tldr_zh": "本文提出Aligner，一种高效的对齐方法，通过学习首选和非首选答案之间的correctional residuals，使用小模型来实现模型无关的即插即用模块，仅需一次性训练即可应用于各种LLMs。Aligner不仅能直接提升开源和API-based模型的性能，还可以通过合成的人类偏好数据迭代提升上游模型，突破性能上限。实验显示，在11个LLMs上部署Aligner-7B后，帮助性平均提升68.9%、无害性提升23.8%、并减少hallucination；在Alpaca-Eval排行榜中，将Aligner-2B叠加到GPT-4 Turbo上，将LC Win Rate从55.0%提高到58.3%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024 Oral Presentation",
      "pdf_url": "http://arxiv.org/pdf/2402.02416v5",
      "published_date": "2024-02-04 09:24:51 UTC",
      "updated_date": "2024-11-02 10:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:06:57.470724"
    },
    {
      "arxiv_id": "2402.03386v1",
      "title": "A generalized decision tree ensemble based on the NeuralNetworks architecture: Distributed Gradient Boosting Forest (DGBF)",
      "title_zh": "翻译失败",
      "authors": [
        "Ángel Delgado-Panadero",
        "José Alberto Benítez-Andrades",
        "María Teresa García-Ordás"
      ],
      "abstract": "Tree ensemble algorithms as RandomForest and GradientBoosting are currently\nthe dominant methods for modeling discrete or tabular data, however, they are\nunable to perform a hierarchical representation learning from raw data as\nNeuralNetworks does thanks to its multi-layered structure, which is a key\nfeature for DeepLearning problems and modeling unstructured data. This\nlimitation is due to the fact that tree algorithms can not be trained with\nback-propagation because of their mathematical nature. However, in this work,\nwe demonstrate that the mathematical formulation of bagging and boosting can be\ncombined together to define a graph-structured-tree-ensemble algorithm with a\ndistributed representation learning process between trees naturally (without\nusing back-propagation). We call this novel approach Distributed Gradient\nBoosting Forest (DGBF) and we demonstrate that both RandomForest and\nGradientBoosting can be expressed as particular graph architectures of DGBT.\nFinally, we see that the distributed learning outperforms both RandomForest and\nGradientBoosting in 7 out of 9 datasets.",
      "tldr_zh": "该研究指出了传统树集成算法如 RandomForest 和 GradientBoosting 在处理离散或表格数据时无法像 Neural Networks 那样进行分层表示学习的主要局限性，因为它们不能使用 back-propagation 进行训练。为解决此问题，作者提出了一种新型方法 Distributed Gradient Boosting Forest (DGBF)，它通过结合 bagging 和 boosting 的数学公式，构建一个图结构树集成算法，实现树之间自然分布式的表示学习过程。DGBF 可以将 RandomForest 和 GradientBoosting 视为其特定图架构的实例，并在 9 个数据集中的 7 个上表现出优于现有方法的性能。总的来说，这一方法为树集成算法扩展到更复杂的表示学习任务提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03386v1",
      "published_date": "2024-02-04 09:22:52 UTC",
      "updated_date": "2024-02-04 09:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:07:08.921189"
    },
    {
      "arxiv_id": "2402.03384v1",
      "title": "Survival and grade of the glioma prediction using transfer learning",
      "title_zh": "翻译失败",
      "authors": [
        "Santiago Valbuena Rubio",
        "María Teresa García-Ordás",
        "Oscar García-Olalla Olivera",
        "Héctor Alaiz-Moretón",
        "Maria-Inmaculada González-Alonso",
        "José Alberto Benítez-Andrades"
      ],
      "abstract": "Glioblastoma is a highly malignant brain tumor with a life expectancy of only\n3 to 6 months without treatment. Detecting and predicting its survival and\ngrade accurately are crucial. This study introduces a novel approach using\ntransfer learning techniques. Various pre-trained networks, including\nEfficientNet, ResNet, VGG16, and Inception, were tested through exhaustive\noptimization to identify the most suitable architecture. Transfer learning was\napplied to fine-tune these models on a glioblastoma image dataset, aiming to\nachieve two objectives: survival and tumor grade prediction.The experimental\nresults show 65% accuracy in survival prediction, classifying patients into\nshort, medium, or long survival categories. Additionally, the prediction of\ntumor grade achieved an accuracy of 97%, accurately differentiating low-grade\ngliomas (LGG) and high-grade gliomas (HGG). The success of the approach is\nattributed to the effectiveness of transfer learning, surpassing the current\nstate-of-the-art methods. In conclusion, this study presents a promising method\nfor predicting the survival and grade of glioblastoma. Transfer learning\ndemonstrates its potential in enhancing prediction models, particularly in\nscenarios with limited large datasets. These findings hold promise for\nimproving diagnostic and treatment approaches for glioblastoma patients.",
      "tldr_zh": "这篇论文提出了一种利用 transfer learning 的新方法来预测胶质瘤（Glioblastoma）的生存率和肿瘤等级，通过测试 EfficientNet、ResNet、VGG16 和 Inception 等预训练网络，并在胶质瘤图像数据集上进行微调优化。实验结果显示，该方法在生存预测方面达到了65%的准确率，将患者分类为短、中或长生存类别；在肿瘤等级预测方面，准确率高达97%，成功区分低级胶质瘤 (LGG) 和高级胶质瘤 (HGG)。总体上，该研究证明了 transfer learning 在数据有限场景下的优势，有望提升胶质瘤的诊断和治疗效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03384v1",
      "published_date": "2024-02-04 09:07:07 UTC",
      "updated_date": "2024-02-04 09:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:07:21.959280"
    },
    {
      "arxiv_id": "2402.02401v1",
      "title": "AI-Generated Content Enhanced Computer-Aided Diagnosis Model for Thyroid Nodules: A ChatGPT-Style Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Jincao Yao",
        "Yunpeng Wang",
        "Zhikai Lei",
        "Kai Wang",
        "Xiaoxian Li",
        "Jianhua Zhou",
        "Xiang Hao",
        "Jiafei Shen",
        "Zhenping Wang",
        "Rongrong Ru",
        "Yaqing Chen",
        "Yahan Zhou",
        "Chen Chen",
        "Yanming Zhang",
        "Ping Liang",
        "Dong Xu"
      ],
      "abstract": "An artificial intelligence-generated content-enhanced computer-aided\ndiagnosis (AIGC-CAD) model, designated as ThyGPT, has been developed. This\nmodel, inspired by the architecture of ChatGPT, could assist radiologists in\nassessing the risk of thyroid nodules through semantic-level human-machine\ninteraction. A dataset comprising 19,165 thyroid nodule ultrasound cases from\nZhejiang Cancer Hospital was assembled to facilitate the training and\nvalidation of the model. After training, ThyGPT could automatically evaluate\nthyroid nodule and engage in effective communication with physicians through\nhuman-computer interaction. The performance of ThyGPT was rigorously quantified\nusing established metrics such as the receiver operating characteristic (ROC)\ncurve, area under the curve (AUC), sensitivity, and specificity. The empirical\nfindings revealed that radiologists, when supplemented with ThyGPT, markedly\nsurpassed the diagnostic acumen of their peers utilizing traditional methods as\nwell as the performance of the model in isolation. These findings suggest that\nAIGC-CAD systems, exemplified by ThyGPT, hold the promise to fundamentally\ntransform the diagnostic workflows of radiologists in forthcoming years.",
      "tldr_zh": "本研究开发了ThyGPT，一种受ChatGPT启发的AI-Generated Content Enhanced Computer-Aided Diagnosis (AIGC-CAD)模型，用于辅助放射科医生通过语义级人机交互评估甲状腺结节的风险。模型利用一个包含19,165例甲状腺结节超声病例的数据集进行训练和验证，能够自动评估结节并实现有效的人机沟通。实验结果显示，ThyGPT显著提升了医生的诊断性能，在receiver operating characteristic (ROC)曲线、area under the curve (AUC)、sensitivity和specificity等指标上优于传统方法和独立模型，表明此类系统有望变革未来的放射诊断流程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02401v1",
      "published_date": "2024-02-04 08:24:13 UTC",
      "updated_date": "2024-02-04 08:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:07:34.308291"
    },
    {
      "arxiv_id": "2402.02399v2",
      "title": "FreDF: Learning to Forecast in the Frequency Domain",
      "title_zh": "FreDF：学习在频域进行预测",
      "authors": [
        "Hao Wang",
        "Licheng Pan",
        "Zhichao Chen",
        "Degui Yang",
        "Sen Zhang",
        "Yifei Yang",
        "Xinggao Liu",
        "Haoxuan Li",
        "Dacheng Tao"
      ],
      "abstract": "Time series modeling presents unique challenges due to autocorrelation in\nboth historical data and future sequences. While current research predominantly\naddresses autocorrelation within historical data, the correlations among future\nlabels are often overlooked. Specifically, modern forecasting models primarily\nadhere to the Direct Forecast (DF) paradigm, generating multi-step forecasts\nindependently and disregarding label autocorrelation over time. In this work,\nwe demonstrate that the learning objective of DF is biased in the presence of\nlabel autocorrelation. To address this issue, we propose the Frequency-enhanced\nDirect Forecast (FreDF), which mitigates label autocorrelation by learning to\nforecast in the frequency domain, thereby reducing estimation bias. Our\nexperiments show that FreDF significantly outperforms existing state-of-the-art\nmethods and is compatible with a variety of forecast models. Code is available\nat https://github.com/Master-PLC/FreDF.",
      "tldr_zh": "本研究指出，时间序列建模中，未来标签的自相关性常被忽略，导致 Direct Forecast (DF) 范式的学习目标出现偏差，而现有模型通常独立生成多步预测。作者提出 Frequency-enhanced Direct Forecast (FreDF)，通过在 Frequency domain 中学习预测来缓解标签自相关性，从而减少估计偏差。实验结果显示，FreDF 显著优于现有最先进方法，并可与多种预测模型兼容。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.02399v2",
      "published_date": "2024-02-04 08:23:41 UTC",
      "updated_date": "2025-05-06 06:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:07:44.977723"
    },
    {
      "arxiv_id": "2402.02392v3",
      "title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ollie Liu",
        "Deqing Fu",
        "Dani Yogatama",
        "Willie Neiswanger"
      ],
      "abstract": "The potential of large language models (LLMs) as decision support tools is\nincreasingly being explored in fields such as business, engineering, and\nmedicine, which often face challenging tasks of decision-making under\nuncertainty. In this paper, we show that directly prompting LLMs on these types\nof decision-making problems can yield poor results, especially as the problem\ncomplexity increases. To aid in these tasks, we propose DeLLMa (Decision-making\nLarge Language Model assistant), a framework designed to enhance\ndecision-making accuracy in uncertain environments. DeLLMa involves a\nmulti-step reasoning procedure that integrates recent best practices in scaling\ninference-time reasoning, drawing upon principles from decision theory and\nutility theory, to provide an accurate and human-auditable decision-making\nprocess. We validate our procedure on multiple realistic decision-making\nenvironments, demonstrating that DeLLMa can consistently enhance the\ndecision-making performance of leading language models, and achieve up to a 40%\nincrease in accuracy over competing methods. Additionally, we show how\nperformance improves when scaling compute at test time, and carry out human\nevaluations to benchmark components of DeLLMa.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在不确定性决策中的潜力，但发现直接提示LLMs会导致表现不佳，尤其在问题复杂度增加时。为解决这一问题，研究提出DeLLMa框架，一个多步骤推理过程，结合推理最佳实践、decision theory和utility theory，提供准确且可审计的决策支持。实验在多个现实决策环境中验证，DeLLMa显著提升了领先语言模型的性能，准确率较竞争方法提高高达40%。此外，研究还展示了测试时扩展计算如何进一步改善表现，并通过人类评估验证了框架的组件。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02392v3",
      "published_date": "2024-02-04 08:11:45 UTC",
      "updated_date": "2024-10-11 17:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:07:55.890797"
    },
    {
      "arxiv_id": "2402.02389v2",
      "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbin Wei",
        "Qiushi Huang",
        "James T. Kwok",
        "Yu Zhang"
      ],
      "abstract": "Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph\nincompleteness and supporting downstream applications. Many models have been\nproposed for KGC. They can be categorized into two main classes: triple-based\nand text-based approaches. Triple-based methods struggle with long-tail\nentities due to limited structural information and imbalanced entity\ndistributions. Text-based methods alleviate this issue but require costly\ntraining for language models and specific finetuning for knowledge graphs,\nwhich limits their efficiency. To alleviate these limitations, in this paper,\nwe propose KICGPT, a framework that integrates a large language model (LLM) and\na triple-based KGC retriever. It alleviates the long-tail problem without\nincurring additional training overhead. KICGPT uses an in-context learning\nstrategy called Knowledge Prompt, which encodes structural knowledge into\ndemonstrations to guide the LLM. Empirical results on benchmark datasets\ndemonstrate the effectiveness of KICGPT with smaller training overhead and no\nfinetuning.",
      "tldr_zh": "知识图谱补全 (KGC) 是解决知识图谱不完整性的关键任务，但现有方法存在局限：基于三元组的方法难以处理长尾实体，而基于文本的方法需高成本训练和微调。  \n本文提出 KICGPT 框架，将大型语言模型 (LLM) 与基于三元组的 KGC 检索器整合，使用 Knowledge Prompt 的上下文学习策略，将结构知识编码进演示中指导 LLM，从而缓解长尾问题而不需额外训练开销。  \n实证结果表明，KICGPT 在基准数据集上表现出色，训练开销更小且无需微调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2023 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.02389v2",
      "published_date": "2024-02-04 08:01:07 UTC",
      "updated_date": "2024-02-23 09:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:08:10.112641"
    },
    {
      "arxiv_id": "2402.02388v1",
      "title": "Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Niu",
        "Weihao Zhang",
        "Rong Zhao"
      ],
      "abstract": "Agent-based models (ABMs) stand as an essential paradigm for proposing and\nvalidating hypothetical solutions or policies aimed at addressing challenges\nposed by complex systems and achieving various objectives. This process demands\nlabor-intensive endeavors and multidisciplinary expertise. Large language\nmodels (LLMs) encapsulating cross-domain knowledge and programming proficiency\ncould potentially alleviate the difficulty of this process. However, LLMs excel\nin handling sequential information, making it challenging for analyzing the\nintricate interactions and nonlinear dynamics inherent in ABMs. Additionally,\ndue to the lack of self-evaluation capability of LLMs, relying solely on LLMs\nis insufficient to effectively accomplish this process. In this paper, we\npresent SAGE, a general solution-oriented ABM generation framework designed for\nautomatic modeling and generating solutions for targeted problems. Unlike\napproaches reliant on expert handcrafting or resource-intensive neural network\ntraining, SAGE establishes a verifier-assisted iterative in-context learning\nprocess employing large language models (LLMs) to leverages their inherent\ncross-domain knowledge for tackling intricate demands from diverse domain\nscenarios. In SAGE, we introduce an semi-structured conceptual representation\nexpliciting the intricate structures of ABMs and an objective representation to\nguide LLMs in modeling scenarios and proposing hypothetical solutions through\nin-context learning. To ensure the model executability and solution\nfeasibility, SAGE devises a two-level verifier with chain-of-thought prompting\ntailored to the complex interactions and non-linear dynamics of ABMs, driving\nthe iterative generation optimization. Moreover, we construct an evaluation\ndataset of solution-oriented ABMs from open sources.It contains practical\nmodels across various domains.",
      "tldr_zh": "这篇论文提出了SAGE框架，一种通用的解决方案导向Agent-based Models (ABMs)生成方法，利用Large Language Models (LLMs)通过Verifier-assisted Iterative In-context Learning来自动建模复杂系统问题并提出假设解决方案。框架引入半结构化概念表示和目标表示来指导LLMs处理ABMs的复杂交互和非线性动态，同时采用两级验证器结合Chain-of-Thought提示进行迭代优化，确保模型的可执行性和解决方案的可行性。为评估SAGE，论文构建了一个跨领域的开源ABMs数据集，展示了其在多领域场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02388v1",
      "published_date": "2024-02-04 07:59:06 UTC",
      "updated_date": "2024-02-04 07:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:08:20.925716"
    },
    {
      "arxiv_id": "2402.02385v1",
      "title": "A Survey on Robotics with Foundation Models: toward Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Xu",
        "Kun Wu",
        "Junjie Wen",
        "Jinming Li",
        "Ning Liu",
        "Zhengping Che",
        "Jian Tang"
      ],
      "abstract": "While the exploration for embodied AI has spanned multiple decades, it\nremains a persistent challenge to endow agents with human-level intelligence,\nincluding perception, learning, reasoning, decision-making, control, and\ngeneralization capabilities, so that they can perform general-purpose tasks in\nopen, unstructured, and dynamic environments. Recent advances in computer\nvision, natural language processing, and multi-modality learning have shown\nthat the foundation models have superhuman capabilities for specific tasks.\nThey not only provide a solid cornerstone for integrating basic modules into\nembodied AI systems but also shed light on how to scale up robot learning from\na methodological perspective. This survey aims to provide a comprehensive and\nup-to-date overview of foundation models in robotics, focusing on autonomous\nmanipulation and encompassing high-level planning and low-level control.\nMoreover, we showcase their commonly used datasets, simulators, and benchmarks.\nImportantly, we emphasize the critical challenges intrinsic to this field and\ndelineate potential avenues for future research, contributing to advancing the\nfrontier of academic and industrial discourse.",
      "tldr_zh": "这篇调查综述了基础模型在机器人领域的应用，旨在推进具身AI（Embodied AI），使机器人具备人类级别的感知、学习、推理、决策和控制能力。论文重点讨论了基础模型如何作为核心构建块整合到机器人系统中，包括自主操作、高级规划和低级控制，并介绍了常用数据集、模拟器和基准。最终，它强调了领域内在的挑战，如泛化能力和动态环境适应，并为未来研究指出了潜在方向。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02385v1",
      "published_date": "2024-02-04 07:55:01 UTC",
      "updated_date": "2024-02-04 07:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:08:34.396259"
    },
    {
      "arxiv_id": "2402.02381v1",
      "title": "Empowering Computing and Networks Convergence System with Distributed Cooperative Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Yujiao Hu",
        "Qingmin Jia",
        "Meng Shen",
        "Renchao Xie",
        "Tao Huang",
        "F. Richard Yu"
      ],
      "abstract": "The emergence of intelligent applications and recent advances in the fields\nof computing and networks are driving the development of computing and networks\nconvergence (CNC) system. However, existing researches failed to achieve\ncomprehensive scheduling optimization of computing and network resources. This\nshortfall results in some requirements of computing requests unable to be\nguaranteed in an end-to-end service pattern, negatively impacting the\ndevelopment of CNC systems. In this article, we propose a distributed\ncooperative routing framework for the CNC system to ensure the deadline\nrequirements and minimize the computation cost of requests. The framework\nincludes trading plane, management plane, control plane and forwarding plane.\nThe cross-plane cooperative end-to-end routing schemes consider both\ncomputation efficiency of heterogeneous servers and the network congestion\ndegrees while making routing plan, thereby determining where to execute\nrequests and corresponding routing paths. Simulations results substantiates the\nperformance of our routing schemes in scheduling computing requests in the CNC\nsystem.",
      "tldr_zh": "本文针对计算和网络融合 (CNC) 系统存在的资源调度优化不足问题，提出了一种分布式协作路由框架，以确保计算请求的截止期限并最小化计算成本。该框架包括 trading plane、管理 plane、control plane 和 forwarding plane，通过跨平面的端到端路由方案，综合考虑异构服务器的计算效率和网络拥塞度来决定请求执行位置和路由路径。与现有方法相比，该框架实现了更全面的资源调度优化。模拟结果证明，该方案在 CNC 系统中的性能显著提升。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Submit to IEEE Network",
      "pdf_url": "http://arxiv.org/pdf/2402.02381v1",
      "published_date": "2024-02-04 07:44:06 UTC",
      "updated_date": "2024-02-04 07:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:08:46.082584"
    },
    {
      "arxiv_id": "2402.02380v3",
      "title": "Evaluating Large Language Models in Analysing Classroom Dialogue",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Long",
        "Haifeng Luo",
        "Yu Zhang"
      ],
      "abstract": "This study explores the application of Large Language Models (LLMs),\nspecifically GPT-4, in the analysis of classroom dialogue, a crucial research\ntask for both teaching diagnosis and quality improvement. Recognizing the\nknowledge-intensive and labor-intensive nature of traditional qualitative\nmethods in educational research, this study investigates the potential of LLM\nto streamline and enhance the analysis process. The study involves datasets\nfrom a middle school, encompassing classroom dialogues across mathematics and\nChinese classes. These dialogues were manually coded by educational experts and\nthen analyzed using a customised GPT-4 model. This study focuses on comparing\nmanual annotations with the outputs of GPT-4 to evaluate its efficacy in\nanalyzing educational dialogues. Time efficiency, inter-coder agreement, and\ninter-coder reliability between human coders and GPT-4 are evaluated. Results\nindicate substantial time savings with GPT-4, and a high degree of consistency\nin coding between the model and human coders, with some discrepancies in\nspecific codes. These findings highlight the strong potential of LLM in\nteaching evaluation and facilitation.",
      "tldr_zh": "这篇论文评估了Large Language Models (LLMs)，特别是GPT-4，在分析课堂对话中的应用，以提升教学诊断和质量改进效率。研究使用中学数学和语文课堂数据，通过专家手动编码与定制GPT-4模型的输出进行比较，评估了时间效率、inter-coder agreement和inter-coder reliability。结果显示，GPT-4显著节省了分析时间，与人类编码者的一致性较高，但某些特定代码存在差异。这些发现突显了LLMs在教育研究中的强大潜力，为自动化教学评估提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02380v3",
      "published_date": "2024-02-04 07:39:06 UTC",
      "updated_date": "2024-02-23 02:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:08:58.022616"
    },
    {
      "arxiv_id": "2403.09671v2",
      "title": "CoRaiS: Lightweight Real-Time Scheduler for Multi-Edge Cooperative Computing",
      "title_zh": "CoRaiS：多边缘协作计算的轻量级实时调度器",
      "authors": [
        "Yujiao Hu",
        "Qingmin Jia",
        "Jinchao Chen",
        "Yuan Yao",
        "Yan Pan",
        "Renchao Xie",
        "F. Richard Yu"
      ],
      "abstract": "Multi-edge cooperative computing that combines constrained resources of\nmultiple edges into a powerful resource pool has the potential to deliver great\nbenefits, such as a tremendous computing power, improved response time, more\ndiversified services. However, the mass heterogeneous resources composition and\nlack of scheduling strategies make the modeling and cooperating of multi-edge\ncomputing system particularly complicated. This paper first proposes a\nsystem-level state evaluation model to shield the complex hardware\nconfigurations and redefine the different service capabilities at heterogeneous\nedges. Secondly, an integer linear programming model is designed to cater for\noptimally dispatching the distributed arriving requests. Finally, a\nlearning-based lightweight real-time scheduler, CoRaiS, is proposed. CoRaiS\nembeds the real-time states of multi-edge system and requests information, and\ncombines the embeddings with a policy network to schedule the requests, so that\nthe response time of all requests can be minimized. Evaluation results verify\nthat CoRaiS can make a high-quality scheduling decision in real time, and can\nbe generalized to other multi-edge computing system, regardless of system\nscales. Characteristic validation also demonstrates that CoRaiS successfully\nlearns to balance loads, perceive real-time state and recognize heterogeneity\nwhile scheduling.",
      "tldr_zh": "这篇论文针对多边际合作计算(Multi-Edge Cooperative Computing)的资源调度挑战，提出了一种轻量级实时调度器CoRaiS，以整合异构资源并优化请求分发。论文首先设计了系统级状态评估模型和整数线性规划(Integer Linear Programming)模型来屏蔽硬件复杂性并重新定义服务能力，然后通过嵌入实时系统状态、请求信息和策略网络(Policy Network)来最小化所有请求的响应时间。实验结果显示，CoRaiS能在实时环境中实现高质量决策，并泛化到不同规模的系统，同时学会平衡负载、感知实时状态和识别异构性。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by IEEE Internet of Things Journal",
      "pdf_url": "http://arxiv.org/pdf/2403.09671v2",
      "published_date": "2024-02-04 07:21:45 UTC",
      "updated_date": "2024-05-20 08:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:09:10.678702"
    },
    {
      "arxiv_id": "2402.02367v2",
      "title": "Exploring Intrinsic Properties of Medical Images for Self-Supervised Binary Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Pranav Singh",
        "Jacopo Cirrone"
      ],
      "abstract": "Recent advancements in self-supervised learning have unlocked the potential\nto harness unlabeled data for auxiliary tasks, facilitating the learning of\nbeneficial priors. This has been particularly advantageous in fields like\nmedical image analysis, where labeled data are scarce. Although effective for\nclassification tasks, this methodology has shown limitations in more complex\napplications, such as medical image segmentation. In this paper, we introduce\nMedical imaging Enhanced with Dynamic Self-Adaptive Semantic Segmentation\n(MedSASS), a dedicated self-supervised framework tailored for medical image\nsegmentation. We evaluate MedSASS against existing state-of-the-art methods\nacross four diverse medical datasets, showcasing its superiority. MedSASS\noutperforms existing CNN-based self-supervised methods by 3.83% and matches the\nperformance of ViT-based methods. Furthermore, when MedSASS is trained\nend-to-end, covering both encoder and decoder, it demonstrates significant\nimprovements of 14.4% for CNNs and 6% for ViT-based architectures compared to\nexisting state-of-the-art self-supervised strategies.",
      "tldr_zh": "该研究探讨了自监督学习（Self-Supervised Learning）在医疗图像中的内在属性，以提升二元语义分割任务的性能，针对标签数据稀缺的问题提出MedSASS框架。\nMedSASS是一种动态自适应语义分割框架，专为医疗图像设计，通过优化自监督策略在四个多样化数据集上进行评估。\n实验结果显示，MedSASS比现有CNN-based方法提高了3.83%，并与ViT-based方法相当；当端到端训练时，它进一步提升CNNs的性能14.4%和ViT-based架构的6%，展示了显著的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "30 pages, 10 figures, and 10 tables. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2402.02367v2",
      "published_date": "2024-02-04 06:39:01 UTC",
      "updated_date": "2024-04-27 18:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:09:21.847312"
    },
    {
      "arxiv_id": "2402.02364v2",
      "title": "Loss Landscape Degeneracy Drives Stagewise Development in Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Hoogland",
        "George Wang",
        "Matthew Farrugia-Roberts",
        "Liam Carroll",
        "Susan Wei",
        "Daniel Murfet"
      ],
      "abstract": "Deep learning involves navigating a high-dimensional loss landscape over the\nneural network parameter space. Over the course of training, complex\ncomputational structures form and re-form inside the neural network, leading to\nshifts in input/output behavior. It is a priority for the science of deep\nlearning to uncover principles governing the development of neural network\nstructure and behavior. Drawing on the framework of singular learning theory,\nwe propose that model development is deeply linked to degeneracy in the local\ngeometry of the loss landscape. We investigate this link by monitoring loss\nlandscape degeneracy throughout training, as quantified by the local learning\ncoefficient, for a transformer language model and an in-context linear\nregression transformer. We show that training can be divided into distinct\nperiods of change in loss landscape degeneracy, and that these changes in\ndegeneracy coincide with significant changes in the internal computational\nstructure and the input/output behavior of the transformers. This finding\nunderscores the potential of a degeneracy-based perspective for understanding\nmodern deep learning.",
      "tldr_zh": "本研究探讨了深度学习中损失景观退化（loss landscape degeneracy）如何驱动 Transformer 模型的阶段性发展。作者基于奇异学习理论（singular learning theory）框架，通过监控局部学习系数（local learning coefficient）来量化训练过程中的损失景观变化，发现训练可分为多个阶段，这些阶段与模型的内部计算结构和输入/输出行为显著相关。该发现为理解深度学习的神经网络发展提供了新的退化视角，有助于揭示其复杂动态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Material on essential dynamics from v1 of this preprint has been\n  removed from v2 and developed in arXiv:2501.17745",
      "pdf_url": "http://arxiv.org/pdf/2402.02364v2",
      "published_date": "2024-02-04 06:23:05 UTC",
      "updated_date": "2025-02-13 07:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:09:33.467955"
    },
    {
      "arxiv_id": "2402.02362v1",
      "title": "Unification of Symmetries Inside Neural Networks: Transformer, Feedforward and Neural ODE",
      "title_zh": "神经网络内部对称性的统一：Transformer、Feedforward 和 Neural ODE",
      "authors": [
        "Koji Hashimoto",
        "Yuji Hirono",
        "Akiyoshi Sannai"
      ],
      "abstract": "Understanding the inner workings of neural networks, including transformers,\nremains one of the most challenging puzzles in machine learning. This study\nintroduces a novel approach by applying the principles of gauge symmetries, a\nkey concept in physics, to neural network architectures. By regarding model\nfunctions as physical observables, we find that parametric redundancies of\nvarious machine learning models can be interpreted as gauge symmetries. We\nmathematically formulate the parametric redundancies in neural ODEs, and find\nthat their gauge symmetries are given by spacetime diffeomorphisms, which play\na fundamental role in Einstein's theory of gravity. Viewing neural ODEs as a\ncontinuum version of feedforward neural networks, we show that the parametric\nredundancies in feedforward neural networks are indeed lifted to\ndiffeomorphisms in neural ODEs. We further extend our analysis to transformer\nmodels, finding natural correspondences with neural ODEs and their gauge\nsymmetries. The concept of gauge symmetries sheds light on the complex behavior\nof deep learning models through physics and provides us with a unifying\nperspective for analyzing various machine learning architectures.",
      "tldr_zh": "本研究将物理学中的 gauge symmetries 应用于神经网络架构，通过将模型函数视为物理可观测量，来解释各种机器学习模型的参数冗余。研究者数学地制定了 neural ODEs 的参数冗余，发现其 gauge symmetries 对应于 spacetime diffeomorphisms，与爱因斯坦引力理论密切相关。进一步地将 neural ODEs 视为 feedforward neural networks 的连续版本，证明 feedforward 网络的参数冗余在 neural ODEs 中提升为微分同胚，并扩展分析到 transformer 模型，揭示其与 neural ODEs 及其 gauge symmetries 的自然对应关系。总体上，这一框架为理解深度学习模型的复杂行为提供了统一的物理学视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "hep-th",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02362v1",
      "published_date": "2024-02-04 06:11:54 UTC",
      "updated_date": "2024-02-04 06:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:09:45.751607"
    },
    {
      "arxiv_id": "2402.05952v1",
      "title": "Advancing Graph Representation Learning with Large Language Models: A Comprehensive Survey of Techniques",
      "title_zh": "利用大语言模型推进图表示学习：技术全面综述",
      "authors": [
        "Qiheng Mao",
        "Zemin Liu",
        "Chenghao Liu",
        "Zhuo Li",
        "Jianling Sun"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with Graph Representation\nLearning (GRL) marks a significant evolution in analyzing complex data\nstructures. This collaboration harnesses the sophisticated linguistic\ncapabilities of LLMs to improve the contextual understanding and adaptability\nof graph models, thereby broadening the scope and potential of GRL. Despite a\ngrowing body of research dedicated to integrating LLMs into the graph domain, a\ncomprehensive review that deeply analyzes the core components and operations\nwithin these models is notably lacking. Our survey fills this gap by proposing\na novel taxonomy that breaks down these models into primary components and\noperation techniques from a novel technical perspective. We further dissect\nrecent literature into two primary components including knowledge extractors\nand organizers, and two operation techniques including integration and training\nstratigies, shedding light on effective model design and training strategies.\nAdditionally, we identify and explore potential future research avenues in this\nnascent yet underexplored field, proposing paths for continued progress.",
      "tldr_zh": "这篇调查综述探讨了Large Language Models (LLMs)与Graph Representation Learning (GRL)的整合如何提升复杂数据结构的分析能力，通过利用LLMs的语言处理优势来增强图模型的上下文理解和适应性。论文提出一个新颖的分类法，将相关模型分解为两大核心组件——knowledge extractors和organizers，以及两大操作技术——integration和training strategies，从而为模型设计和训练提供深入分析和有效策略。尽管该领域研究迅速增长，该综述填补了现有空白，并指出了未来研究方向，如进一步优化整合方法和探索新兴应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05952v1",
      "published_date": "2024-02-04 05:51:14 UTC",
      "updated_date": "2024-02-04 05:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:09:57.882144"
    },
    {
      "arxiv_id": "2402.14600v1",
      "title": "Diffusion Model-Based Multiobjective Optimization for Gasoline Blending Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Fang",
        "Wei Du",
        "Renchu He",
        "Yang Tang",
        "Yaochu Jin",
        "Gary G. Yen"
      ],
      "abstract": "Gasoline blending scheduling uses resource allocation and operation\nsequencing to meet a refinery's production requirements. The presence of\nnonlinearity, integer constraints, and a large number of decision variables\nadds complexity to this problem, posing challenges for traditional and\nevolutionary algorithms. This paper introduces a novel multiobjective\noptimization approach driven by a diffusion model (named DMO), which is\ndesigned specifically for gasoline blending scheduling. To address integer\nconstraints and generate feasible schedules, the diffusion model creates\nmultiple intermediate distributions between Gaussian noise and the feasible\ndomain. Through iterative processes, the solutions transition from Gaussian\nnoise to feasible schedules while optimizing the objectives using the gradient\ndescent method. DMO achieves simultaneous objective optimization and constraint\nadherence. Comparative tests are conducted to evaluate DMO's performance across\nvarious scales. The experimental results demonstrate that DMO surpasses\nstate-of-the-art multiobjective evolutionary algorithms in terms of efficiency\nwhen solving gasoline blending scheduling problems.",
      "tldr_zh": "本文提出了一种基于Diffusion Model的多目标优化方法（DMO），针对汽油混合调度的复杂问题，包括非线性、整数约束和大量决策变量。DMO通过在高斯噪声和可行域之间创建中间分布，并采用迭代过程结合梯度下降方法，实现目标优化与约束遵守的同步。实验结果显示，DMO在各种规模的汽油混合调度问题上，效率超过了现有的多目标进化算法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.14600v1",
      "published_date": "2024-02-04 05:46:28 UTC",
      "updated_date": "2024-02-04 05:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:10:10.582651"
    },
    {
      "arxiv_id": "2402.02345v2",
      "title": "Stereographic Spherical Sliced Wasserstein Distances",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Tran",
        "Yikun Bai",
        "Abihith Kothapalli",
        "Ashkan Shahbazi",
        "Xinran Liu",
        "Rocio Diaz Martin",
        "Soheil Kolouri"
      ],
      "abstract": "Comparing spherical probability distributions is of great interest in various\nfields, including geology, medical domains, computer vision, and deep\nrepresentation learning. The utility of optimal transport-based distances, such\nas the Wasserstein distance, for comparing probability measures has spurred\nactive research in developing computationally efficient variations of these\ndistances for spherical probability measures. This paper introduces a\nhigh-speed and highly parallelizable distance for comparing spherical measures\nusing the stereographic projection and the generalized Radon transform, which\nwe refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance.\nWe carefully address the distance distortion caused by the stereographic\nprojection and provide an extensive theoretical analysis of our proposed metric\nand its rotationally invariant variation. Finally, we evaluate the performance\nof the proposed metrics and compare them with recent baselines in terms of both\nspeed and accuracy through a wide range of numerical studies, including\ngradient flows and self-supervised learning. Our code is available at\nhttps://github.com/mint-vu/s3wd.",
      "tldr_zh": "这篇论文引入了Stereographic Spherical Sliced Wasserstein (S3W) 距离，一种高效且高度可并行化的方法，用于比较球面概率分布，解决了传统Wasserstein距离在计算上的挑战。论文通过Stereographic Projection和Generalized Radon Transform来处理投影导致的距离扭曲，并提供了全面的理论分析，包括旋转不变变体。实验结果表明，S3W距离在速度和准确性上优于现有基线，在梯度流和自监督学习等应用中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICML 2024 (Spotlight). Project page:\n  https://abi-kothapalli.github.io/s3w/",
      "pdf_url": "http://arxiv.org/pdf/2402.02345v2",
      "published_date": "2024-02-04 05:03:06 UTC",
      "updated_date": "2024-06-09 18:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:10:22.797776"
    },
    {
      "arxiv_id": "2402.02342v5",
      "title": "MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Arsalan Sharifnassab",
        "Saber Salehkaleybar",
        "Richard Sutton"
      ],
      "abstract": "This paper addresses the challenge of optimizing meta-parameters (i.e.,\nhyperparameters) in machine learning algorithms, a critical factor influencing\ntraining efficiency and model performance. Moving away from the computationally\nexpensive traditional meta-parameter search methods, we introduce MetaOptimize\nframework that dynamically adjusts meta-parameters, particularly step sizes\n(also known as learning rates), during training. More specifically,\nMetaOptimize can wrap around any first-order optimization algorithm, tuning\nstep sizes on the fly to minimize a specific form of regret that accounts for\nlong-term effect of step sizes on training, through a discounted sum of future\nlosses. We also introduce low complexity variants of MetaOptimize that, in\nconjunction with its adaptability to multiple optimization algorithms,\ndemonstrate performance competitive to those of best hand-crafted learning rate\nschedules across various machine learning applications.",
      "tldr_zh": "本研究针对机器学习算法中元参数（meta-parameters，如步长或学习率）的优化问题，提出了一种高效框架MetaOptimize，以取代计算开销大的传统搜索方法。MetaOptimize框架能够动态调整步长和其他元参数，通过最小化一种考虑长期影响的regret形式（即折扣未来损失的总和），并兼容任何一阶优化算法。实验结果显示，该框架的低复杂度变体在多种机器学习应用中，其性能与最佳手工学习率调度相当，展示了其适应性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02342v5",
      "published_date": "2024-02-04 04:55:54 UTC",
      "updated_date": "2024-10-04 01:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:10:34.839770"
    },
    {
      "arxiv_id": "2402.02339v1",
      "title": "Uncertainty-Aware Testing-Time Optimization for 3D Human Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Ti Wang",
        "Mengyuan Liu",
        "Hong Liu",
        "Bin Ren",
        "Yingxuan You",
        "Wenhao Li",
        "Nicu Sebe",
        "Xia Li"
      ],
      "abstract": "Although data-driven methods have achieved success in 3D human pose\nestimation, they often suffer from domain gaps and exhibit limited\ngeneralization. In contrast, optimization-based methods excel in fine-tuning\nfor specific cases but are generally inferior to data-driven methods in overall\nperformance. We observe that previous optimization-based methods commonly rely\non projection constraint, which only ensures alignment in 2D space, potentially\nleading to the overfitting problem. To address this, we propose an\nUncertainty-Aware testing-time Optimization (UAO) framework, which keeps the\nprior information of pre-trained model and alleviates the overfitting problem\nusing the uncertainty of joints. Specifically, during the training phase, we\ndesign an effective 2D-to-3D network for estimating the corresponding 3D pose\nwhile quantifying the uncertainty of each 3D joint. For optimization during\ntesting, the proposed optimization framework freezes the pre-trained model and\noptimizes only a latent state. Projection loss is then employed to ensure the\ngenerated poses are well aligned in 2D space for high-quality optimization.\nFurthermore, we utilize the uncertainty of each joint to determine how much\neach joint is allowed for optimization. The effectiveness and superiority of\nthe proposed framework are validated through extensive experiments on two\nchallenging datasets: Human3.6M and MPI-INF-3DHP. Notably, our approach\noutperforms the previous best result by a large margin of 4.5% on Human3.6M.\nOur source code will be open-sourced.",
      "tldr_zh": "该论文针对 3D Human Pose Estimation 中的领域间隙和泛化问题，提出 Uncertainty-Aware Testing-Time Optimization (UAO) 框架，以缓解依赖投影约束导致的过拟合问题。UAO 在训练阶段设计一个 2D-to-3D 网络来估计 3D 姿势并量化每个关节的不确定性；在测试阶段，冻结预训练模型，仅优化潜在状态，并利用关节不确定性控制优化程度，同时通过投影损失确保 2D 空间对齐。实验结果显示，该框架在 Human3.6M 数据集上比现有最佳方法提升 4.5%，并在 MPI-INF-3DHP 数据集上表现出色，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02339v1",
      "published_date": "2024-02-04 04:28:02 UTC",
      "updated_date": "2024-02-04 04:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:10:51.299946"
    },
    {
      "arxiv_id": "2402.02334v2",
      "title": "Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning",
      "title_zh": "算术特征交互对于深度表格学习是必需的",
      "authors": [
        "Yi Cheng",
        "Renjun Hu",
        "Haochao Ying",
        "Xing Shi",
        "Jian Wu",
        "Wei Lin"
      ],
      "abstract": "Until recently, the question of the effective inductive bias of deep models\non tabular data has remained unanswered. This paper investigates the hypothesis\nthat arithmetic feature interaction is necessary for deep tabular learning. To\ntest this point, we create a synthetic tabular dataset with a mild feature\ninteraction assumption and examine a modified transformer architecture enabling\narithmetical feature interactions, referred to as AMFormer. Results show that\nAMFormer outperforms strong counterparts in fine-grained tabular data modeling,\ndata efficiency in training, and generalization. This is attributed to its\nparallel additive and multiplicative attention operators and prompt-based\noptimization, which facilitate the separation of tabular samples in an extended\nspace with arithmetically-engineered features. Our extensive experiments on\nreal-world data also validate the consistent effectiveness, efficiency, and\nrationale of AMFormer, suggesting it has established a strong inductive bias\nfor deep learning on tabular data. Code is available at\nhttps://github.com/aigc-apps/AMFormer.",
      "tldr_zh": "本研究探讨了算术特征交互(arithmetic feature interaction)在深度表格学习中的必要性，通过创建一个合成表格数据集来验证这一假设。作者提出了一种修改的Transformer架构，名为AMFormer，它通过并行加法和乘法注意力操作以及基于提示的优化，实现了算术特征交互，从而提升了细粒度数据建模、训练数据效率和泛化能力。在合成和真实世界数据集上的广泛实验显示，AMFormer优于强基线模型，证明了其作为深度表格学习强有力归纳偏差的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 8 figures, to be published to AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02334v2",
      "published_date": "2024-02-04 04:07:39 UTC",
      "updated_date": "2024-03-19 11:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:10:59.431200"
    },
    {
      "arxiv_id": "2402.02330v2",
      "title": "Enhance Reasoning for Large Language Models in the Game Werewolf",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Wu",
        "Liwen Zhu",
        "Tao Yang",
        "Shiwei Xu",
        "Qiang Fu",
        "Yang Wei",
        "Haobo Fu"
      ],
      "abstract": "This paper presents an innovative framework that integrates Large Language\nModels (LLMs) with an external Thinker module to enhance the reasoning\ncapabilities of LLM-based agents. Unlike augmenting LLMs with prompt\nengineering, Thinker directly harnesses knowledge from databases and employs\nvarious optimization techniques. The framework forms a reasoning hierarchy\nwhere LLMs handle intuitive System-1 tasks such as natural language processing,\nwhile the Thinker focuses on cognitive System-2 tasks that require complex\nlogical analysis and domain-specific knowledge. Our framework is presented\nusing a 9-player Werewolf game that demands dual-system reasoning. We introduce\na communication protocol between LLMs and the Thinker, and train the Thinker\nusing data from 18800 human sessions and reinforcement learning. Experiments\ndemonstrate the framework's effectiveness in deductive reasoning, speech\ngeneration, and online game evaluation. Additionally, we fine-tune a 6B LLM to\nsurpass GPT4 when integrated with the Thinker. This paper also contributes the\nlargest dataset for social deduction games to date.",
      "tldr_zh": "这篇论文提出了一种创新框架，将 Large Language Models (LLMs) 与外部 Thinker 模块整合，提升 LLM 代理在 Werewolf 游戏中的推理能力。框架构建了一个推理层次结构，其中 LLMs 处理直观的 System-1 任务（如自然语言处理），而 Thinker 专注于认知的 System-2 任务（如复杂逻辑分析和领域特定知识），并直接从数据库获取知识并应用优化技术。研究者引入了 LLMs 和 Thinker 之间的通信协议，并使用 18800 人类会话数据和 reinforcement learning 训练 Thinker。实验结果显示，该框架在演绎推理、演讲生成和在线游戏评估中表现出色，且微调一个 6B LLM 与 Thinker 结合后超越 GPT4，同时贡献了迄今为止最大的社会推演游戏数据集。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02330v2",
      "published_date": "2024-02-04 03:47:10 UTC",
      "updated_date": "2024-03-29 09:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:11:13.781755"
    },
    {
      "arxiv_id": "2402.03379v1",
      "title": "Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing",
      "title_zh": "翻译失败",
      "authors": [
        "Yinqiu Huang",
        "Shuli Wang",
        "Min Gao",
        "Xue Wei",
        "Changhao Li",
        "Chuan Luo",
        "Yinhua Zhu",
        "Xiong Xiao",
        "Yi Luo"
      ],
      "abstract": "Uplift modeling, vital in online marketing, seeks to accurately measure the\nimpact of various strategies, such as coupons or discounts, on different users\nby predicting the Individual Treatment Effect (ITE). In an e-commerce setting,\nuser behavior follows a defined sequential chain, including impression, click,\nand conversion. Marketing strategies exert varied uplift effects at each stage\nwithin this chain, impacting metrics like click-through and conversion rate.\nDespite its utility, existing research has neglected to consider the inter-task\nacross all stages impacts within a specific treatment and has insufficiently\nutilized the treatment information, potentially introducing substantial bias\ninto subsequent marketing decisions. We identify these two issues as the\nchain-bias problem and the treatment-unadaptive problem. This paper introduces\nthe Entire Chain UPlift method with context-enhanced learning (ECUP), devised\nto tackle these issues. ECUP consists of two primary components: 1) the Entire\nChain-Enhanced Network, which utilizes user behavior patterns to estimate ITE\nthroughout the entire chain space, models the various impacts of treatments on\neach task, and integrates task prior information to enhance context awareness\nacross all stages, capturing the impact of treatment on different tasks, and 2)\nthe Treatment-Enhanced Network, which facilitates fine-grained treatment\nmodeling through bit-level feature interactions, thereby enabling adaptive\nfeature adjustment. Extensive experiments on public and industrial datasets\nvalidate ECUPs effectiveness. Moreover, ECUP has been deployed on the Meituan\nfood delivery platform, serving millions of daily active users, with the\nrelated dataset released for future research.",
      "tldr_zh": "该论文针对在线营销中的 Uplift Modeling 问题，提出了一种新的方法 Entire Chain UPlift with context-enhanced learning (ECUP)，旨在准确预测 Individual Treatment Effect (ITE) 并解决 chain-bias 和 treatment-unadaptive 问题。ECUP 包括两个核心组件：Entire Chain-Enhanced Network，利用用户行为链（如 impression、click 和 conversion）来估计整个链上的 ITE，并整合任务先验信息提升跨阶段上下文意识；Treatment-Enhanced Network，通过位级特征交互实现细粒度治疗建模和自适应调整。实验在公共和工业数据集上验证了 ECUP 的有效性，并在 Meituan 食品配送平台实际部署，服务数百万用户，同时发布了相关数据集以促进未来研究。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03379v1",
      "published_date": "2024-02-04 03:30:25 UTC",
      "updated_date": "2024-02-04 03:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:11:24.441771"
    },
    {
      "arxiv_id": "2402.02314v3",
      "title": "Selecting Large Language Model to Fine-tune via Rectified Scaling Law",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Lin",
        "Baizhou Huang",
        "Haotian Ye",
        "Qinyu Chen",
        "Zihao Wang",
        "Sujian Li",
        "Jianzhu Ma",
        "Xiaojun Wan",
        "James Zou",
        "Yitao Liang"
      ],
      "abstract": "The ever-growing ecosystem of LLMs has posed a challenge in selecting the\nmost appropriate pre-trained model to fine-tune amidst a sea of options. Given\nconstrained resources, fine-tuning all models and making selections afterward\nis unrealistic. In this work, we formulate this resource-constrained selection\ntask into predicting fine-tuning performance and illustrate its natural\nconnection with Scaling Law. Unlike pre-training, we find that the fine-tuning\nscaling curve includes not just the well-known \"power phase\" but also the\npreviously unobserved \"pre-power phase\". We also explain why existing Scaling\nLaw fails to capture this phase transition phenomenon both theoretically and\nempirically. To address this, we introduce the concept of \"pre-learned data\nsize\" into our Rectified Scaling Law, which overcomes theoretical limitations\nand fits experimental results much better. By leveraging our law, we propose a\nnovel LLM selection algorithm that selects the near-optimal model with hundreds\nof times less resource consumption, while other methods may provide negatively\ncorrelated selection. The project page is available at\nrectified-scaling-law.github.io.",
      "tldr_zh": "该研究针对资源受限场景下选择合适的 Large Language Model (LLM) 进行微调的问题，提出了一种基于 Rectified Scaling Law 的方法，通过预测微调性能来优化模型选择。研究发现，微调的缩放曲线不仅包括传统的“power phase”，还存在之前未观察到的“pre-power phase”，并解释了现有 Scaling Law 在捕捉这一阶段转换时的理论和经验局限性。为此，他们引入“pre-learned data size”的概念来改进 Scaling Law，使其更准确地拟合实验数据。最终，基于 Rectified Scaling Law 开发的算法能以数百倍更少的资源消耗选择近似最优模型，比其他方法更有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02314v3",
      "published_date": "2024-02-04 01:55:00 UTC",
      "updated_date": "2024-05-28 16:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:11:36.268406"
    },
    {
      "arxiv_id": "2402.05121v3",
      "title": "Large Language Model for Table Processing: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Weizheng Lu",
        "Jing Zhang",
        "Ju Fan",
        "Zihao Fu",
        "Yueguo Chen",
        "Xiaoyong Du"
      ],
      "abstract": "Tables, typically two-dimensional and structured to store large amounts of\ndata, are essential in daily activities like database queries, spreadsheet\nmanipulations, web table question answering, and image table information\nextraction. Automating these table-centric tasks with Large Language Models\n(LLMs) or Visual Language Models (VLMs) offers significant public benefits,\ngarnering interest from academia and industry. This survey provides a\ncomprehensive overview of table-related tasks, examining both user scenarios\nand technical aspects. It covers traditional tasks like table question\nanswering as well as emerging fields such as spreadsheet manipulation and table\ndata analysis. We summarize the training techniques for LLMs and VLMs tailored\nfor table processing. Additionally, we discuss prompt engineering, particularly\nthe use of LLM-powered agents, for various table-related tasks. Finally, we\nhighlight several challenges, including diverse user input when serving and\nslow thinking using chain-of-thought.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 和 Visual Language Models (VLMs) 在表格处理中的应用，包括数据库查询、电子表格操作、表格问答和数据分析等任务。论文提供了这些任务的全面概述，总结了针对表格的模型训练技术，以及提示工程（如 LLM 驱动代理）的使用，以提升自动化效率。最终，它指出了关键挑战，如多样化用户输入和服务难题，以及 chain-of-thought 推理的缓慢性，并强调了这些技术在学术和工业领域的潜在益处。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05121v3",
      "published_date": "2024-02-04 00:47:53 UTC",
      "updated_date": "2024-10-24 07:26:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:11:47.612140"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 67,
  "processed_papers_count": 67,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T03:12:14.414462"
}