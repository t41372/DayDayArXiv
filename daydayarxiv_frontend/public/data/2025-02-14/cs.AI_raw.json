[
  {
    "arxiv_id": "2503.11663v1",
    "title": "MEADOW: Memory-efficient Dataflow and Data Packing for Low Power Edge LLMs",
    "authors": [
      "Abhishek Moitra",
      "Arkapravo Ghosh",
      "Shrey Agarwal",
      "Aporva Amarnath",
      "Karthik Swaminathan",
      "Priyadarshini Panda"
    ],
    "abstract": "The computational and memory challenges of large language models (LLMs) have\nsparked several optimization approaches towards their efficient implementation.\nWhile prior LLM-targeted quantization, and prior works on sparse acceleration\nhave significantly mitigated the memory and computation bottleneck, they do so\nassuming high power platforms such as GPUs and server-class FPGAs with large\noff-chip memory bandwidths and employ a generalized matrix multiplication\n(GEMM) execution of all the layers in the decoder. In such a GEMM-based\nexecution, data is fetched from an off-chip memory, computed and stored back.\nHowever, at reduced off-chip memory capacities, as is the case with low-power\nedge devices, this implementation strategy significantly increases the\nattention computation latency owing to the repeated storage and fetch of large\nintermediate tokens to and from the off-chip memory. Moreover, fetching the\nweight matrices from a bandwidth constrained memory further aggravates the\nmemory bottleneck problem. To this end, we introduce MEADOW, a framework that\nsignificantly reduces the off-chip memory access for LLMs with a novel\ntoken-parallel head-sequential (TPHS) dataflow. Additionally, MEADOW applies\nweight packing that performs loss-less decomposition of large weight matrices\nto their unique elements thereby, reducing the enormous weight fetch latency.\nMEADOW demonstrates 1.5x and 2.5x lower decode and prefill latency,\nrespectively, compared to a GEMM-based LLM implementation on the low power\nXilinx ZCU102 FPGA platform that consumes less than 10W. Additionally, MEADOW\nachieves an end-to-end latency improvement of over 40%, compared to prior LLM\noptimization works.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "12 pages, 13 figures. Accepted to The Eighth Annual Conference on\n  Machine Learning and Systems (MLSys), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.11663v1",
    "published_date": "2025-02-14 23:50:37 UTC",
    "updated_date": "2025-02-14 23:50:37 UTC"
  },
  {
    "arxiv_id": "2503.11662v2",
    "title": "Lorecast: Layout-Aware Performance and Power Forecasting from Natural Language",
    "authors": [
      "Runzhi Wang",
      "Prianka Sengupta",
      "Cristhian Roman-Vicharra",
      "Yiran Chen",
      "Jiang Hu"
    ],
    "abstract": "In chip design planning, obtaining reliable performance and power forecasts\nfor various design options is of critical importance. Traditionally, this\ninvolves using system-level models, which often lack accuracy, or trial\nsynthesis, which is both labor-intensive and time-consuming. We introduce a new\nmethodology, called Lorecast, which accepts English prompts as input to rapidly\ngenerate layout-aware performance and power estimates. This approach bypasses\nthe need for HDL code development and synthesis, making it both fast and\nuser-friendly. Experimental results demonstrate that Lorecast achieves accuracy\nwithin a few percent of error compared to post-layout analysis, while\nsignificantly reducing turnaround time.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.11662v2",
    "published_date": "2025-02-14 23:08:39 UTC",
    "updated_date": "2025-04-22 19:01:42 UTC"
  },
  {
    "arxiv_id": "2502.10596v2",
    "title": "Post-training an LLM for RAG? Train on Self-Generated Demonstrations",
    "authors": [
      "Matthew Finlayson",
      "Ilia Kulikov",
      "Daniel M. Bikel",
      "Barlas Oguz",
      "Xilun Chen",
      "Aasish Pappu"
    ],
    "abstract": "Large language models (LLMs) often struggle with knowledge intensive NLP\ntasks, such as answering \"Who won the latest World Cup?\" because the knowledge\nthey learn during training may be insufficient or outdated. Conditioning\ngeneration on retrieved documents -- a technique known as retrieval augmented\ngeneration (RAG) -- mitigates these shortcomings by allowing the model to\nleverage in-context information. Practitioners can improve LLM RAG performance\nby fine-tuning on retrieval-augmented instructions, but must beware that this\ncan cause undesirable model behaviors like hallucinations. We attribute this\ndegradation to the fact that the training data is likely to be\nout-of-distribution for the model and may suffer from quality issues, such as\nmisalignment between retrievals and target responses (since retrievals are\nfrequently added post-hoc). We propose a recipe for training RAG-enabled LLMs\nusing self-generated demonstrations, thereby avoiding training on\nout-of-distribution text and integrating retrievals into the LLM responses. We\nevaluate our method on knowledge intensive question answering (QA) tasks and\nshow that our method teaches LLMs to properly handle in-context retrievals and\nabstain from questions it will likely get wrong. Compared to conventional RA-IT\nmethods, our method prevents model degradation in non-RAG settings while\nexhibiting superior QA performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10596v2",
    "published_date": "2025-02-14 23:00:49 UTC",
    "updated_date": "2025-03-01 06:33:01 UTC"
  },
  {
    "arxiv_id": "2502.10587v1",
    "title": "Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression",
    "authors": [
      "Megh Shukla",
      "Aziz Shameem",
      "Mathieu Salzmann",
      "Alexandre Alahi"
    ],
    "abstract": "Deep heteroscedastic regression models the mean and covariance of the target\ndistribution through neural networks. The challenge arises from\nheteroscedasticity, which implies that the covariance is sample dependent and\nis often unknown. Consequently, recent methods learn the covariance through\nunsupervised frameworks, which unfortunately yield a trade-off between\ncomputational complexity and accuracy. While this trade-off could be alleviated\nthrough supervision, obtaining labels for the covariance is non-trivial. Here,\nwe study self-supervised covariance estimation in deep heteroscedastic\nregression. We address two questions: (1) How should we supervise the\ncovariance assuming ground truth is available? (2) How can we obtain pseudo\nlabels in the absence of the ground-truth? We address (1) by analysing two\npopular measures: the KL Divergence and the 2-Wasserstein distance.\nSubsequently, we derive an upper bound on the 2-Wasserstein distance between\nnormal distributions with non-commutative covariances that is stable to\noptimize. We address (2) through a simple neighborhood based heuristic\nalgorithm which results in surprisingly effective pseudo labels for the\ncovariance. Our experiments over a wide range of synthetic and real datasets\ndemonstrate that the proposed 2-Wasserstein bound coupled with pseudo label\nannotations results in a computationally cheaper yet accurate deep\nheteroscedastic regression.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10587v1",
    "published_date": "2025-02-14 22:37:11 UTC",
    "updated_date": "2025-02-14 22:37:11 UTC"
  },
  {
    "arxiv_id": "2502.10581v2",
    "title": "Do We Need to Verify Step by Step? Rethinking Process Supervision from a Theoretical Perspective",
    "authors": [
      "Zeyu Jia",
      "Alexander Rakhlin",
      "Tengyang Xie"
    ],
    "abstract": "As large language models have evolved, it has become crucial to distinguish\nbetween process supervision and outcome supervision -- two key reinforcement\nlearning approaches to complex reasoning tasks. While process supervision\noffers intuitive advantages for long-term credit assignment, the precise\nrelationship between these paradigms has remained an open question.\nConventional wisdom suggests that outcome supervision is fundamentally more\nchallenging due to the trajectory-level coverage problem, leading to\nsignificant investment in collecting fine-grained process supervision data.\n  In this paper, we take steps towards resolving this debate. Our main theorem\nshows that, under standard data coverage assumptions, reinforcement learning\nthrough outcome supervision is no more statistically difficult than through\nprocess supervision, up to polynomial factors in horizon. At the core of this\nresult lies the novel Change of Trajectory Measure Lemma -- a technical tool\nthat bridges return-based trajectory measure and step-level distribution shift.\nFurthermore, for settings with access to a verifier or a rollout capability, we\nprove that any policy's advantage function can serve as an optimal process\nreward model, providing a direct connection between outcome and process\nsupervision. These findings suggest that the empirically observed performance\ngap -- if any -- between outcome and process supervision likely stems from\nalgorithmic limitations rather than inherent statistical difficulties,\npotentially transforming how we approach data collection and algorithm design\nfor reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10581v2",
    "published_date": "2025-02-14 22:21:56 UTC",
    "updated_date": "2025-03-26 22:45:31 UTC"
  },
  {
    "arxiv_id": "2502.10577v1",
    "title": "Man Made Language Models? Evaluating LLMs' Perpetuation of Masculine Generics Bias",
    "authors": [
      "Enzo Doyen",
      "Amalia Todirascu"
    ],
    "abstract": "Large language models (LLMs) have been shown to propagate and even amplify\ngender bias, in English and other languages, in specific or constrained\ncontexts. However, no studies so far have focused on gender biases conveyed by\nLLMs' responses to generic instructions, especially with regard to masculine\ngenerics (MG). MG are a linguistic feature found in many gender-marked\nlanguages, denoting the use of the masculine gender as a \"default\" or\nsupposedly neutral gender to refer to mixed group of men and women, or of a\nperson whose gender is irrelevant or unknown. Numerous psycholinguistics\nstudies have shown that MG are not neutral and induce gender bias. This work\naims to analyze the use of MG by both proprietary and local LLMs in responses\nto generic instructions and evaluate their MG bias rate. We focus on French and\ncreate a human noun database from existing lexical resources. We filter\nexisting French instruction datasets to retrieve generic instructions and\nanalyze the responses of 6 different LLMs. Overall, we find that\n$\\approx$39.5\\% of LLMs' responses to generic instructions are MG-biased\n($\\approx$73.1\\% across responses with human nouns). Our findings also reveal\nthat LLMs are reluctant to using gender-fair language spontaneously.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10577v1",
    "published_date": "2025-02-14 22:05:54 UTC",
    "updated_date": "2025-02-14 22:05:54 UTC"
  },
  {
    "arxiv_id": "2502.10573v1",
    "title": "An Innovative Next Activity Prediction Approach Using Process Entropy and DAW-Transformer",
    "authors": [
      "Hadi Zare",
      "Mostafa Abbasi",
      "Maryam Ahang",
      "Homayoun Najjaran"
    ],
    "abstract": "Purpose - In Business Process Management (BPM), accurate prediction of the\nnext activities is vital for operational efficiency and decision-making.\nCurrent Artificial Intelligence (AI)/Machine Learning (ML) models struggle with\nthe complexity and evolving nature of business process event logs, balancing\naccuracy and interpretability. This paper proposes an entropy-driven model\nselection approach and DAW-Transformer, which stands for Dynamic\nAttribute-Aware Transformer, to integrate all attributes with a dynamic window\nfor better accuracy.\n  Design/methodology/approach - This paper introduces a novel next-activity\nprediction approach that uses process entropy to assess the complexity of event\nlogs and dynamically select the most suitable ML model. A new transformer-based\narchitecture with multi-head attention and dynamic windowing mechanism,\nDAW-Transformer, is proposed to capture long-range dependencies and utilize all\nrelevant event log attributes. Experiments were conducted on six public\ndatasets, and the performance was evaluated with process entropy.\n  Finding - The results demonstrate the effectiveness of the approach across\nthese publicly available datasets. DAW-Transformer achieved superior\nperformance, especially on high-entropy datasets such as Sepsis exceeding\nLimited window Multi-Transformers by 4.69% and a benchmark CNN-LSTM-SAtt model\nby 3.07%. For low-entropy datasets like Road Traffic Fine, simpler, more\ninterpretable algorithms like Random Forest performed nearly as well as the\nmore complex DAW-Transformer and offered better handling of imbalanced data and\nimproved explainability.\n  Originality/ value - This work's novelty lies in the proposed\nDAW-Transformer, with a dynamic window and considering all relevant attributes.\nAlso, entropy-driven selection methods offer a robust, accurate, and\ninterpretable solution for next-activity prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10573v1",
    "published_date": "2025-02-14 22:02:00 UTC",
    "updated_date": "2025-02-14 22:02:00 UTC"
  },
  {
    "arxiv_id": "2502.10569v1",
    "title": "HADL Framework for Noise Resilient Long-Term Time Series Forecasting",
    "authors": [
      "Aditya Dey",
      "Jonas Kusch",
      "Fadi Al Machot"
    ],
    "abstract": "Long-term time series forecasting is critical in domains such as finance,\neconomics, and energy, where accurate and reliable predictions over extended\nhorizons drive strategic decision-making. Despite the progress in machine\nlearning-based models, the impact of temporal noise in extended lookback\nwindows remains underexplored, often degrading model performance and\ncomputational efficiency. In this paper, we propose a novel framework that\naddresses these challenges by integrating the Discrete Wavelet Transform (DWT)\nand Discrete Cosine Transform (DCT) to perform noise reduction and extract\nrobust long-term features. These transformations enable the separation of\nmeaningful temporal patterns from noise in both the time and frequency domains.\nTo complement this, we introduce a lightweight low-rank linear prediction layer\nthat not only reduces the influence of residual noise but also improves memory\nefficiency. Our approach demonstrates competitive robustness to noisy input,\nsignificantly reduces computational complexity, and achieves competitive or\nstate-of-the-art forecasting performance across diverse benchmark datasets.\nExtensive experiments reveal that the proposed framework is particularly\neffective in scenarios with high noise levels or irregular patterns, making it\nwell suited for real-world forecasting tasks. The code is available in\nhttps://github.com/forgee-master/HADL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10569v1",
    "published_date": "2025-02-14 21:41:42 UTC",
    "updated_date": "2025-02-14 21:41:42 UTC"
  },
  {
    "arxiv_id": "2502.10568v1",
    "title": "Observer-Aware Probabilistic Planning Under Partial Observability",
    "authors": [
      "Salomé Lepers",
      "Vincent Thomas",
      "Olivier Buffet"
    ],
    "abstract": "In this article, we are interested in planning problems where the agent is\naware of the presence of an observer, and where this observer is in a partial\nobservability situation. The agent has to choose its strategy so as to optimize\nthe information transmitted by observations. Building on observer-aware Markov\ndecision processes (OAMDPs), we propose a framework to handle this type of\nproblems and thus formalize properties such as legibility, explicability and\npredictability. This extension of OAMDPs to partial observability can not only\nhandle more realistic problems, but also permits considering dynamic hidden\nvariables of interest. These dynamic target variables allow, for instance,\nworking with predictability, or with legibility problems where the goal might\nchange during execution. We discuss theoretical properties of PO-OAMDPs and,\nexperimenting with benchmark problems, we analyze HSVI's convergence behavior\nwith dedicated initializations and study the resulting strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 13 figures. Complete version of AAMAS 2025 extended\n  abstract",
    "pdf_url": "http://arxiv.org/pdf/2502.10568v1",
    "published_date": "2025-02-14 21:41:04 UTC",
    "updated_date": "2025-02-14 21:41:04 UTC"
  },
  {
    "arxiv_id": "2502.10567v1",
    "title": "Efficient Hierarchical Contrastive Self-supervising Learning for Time Series Classification via Importance-aware Resolution Selection",
    "authors": [
      "Kevin Garcia",
      "Juan Manuel Perez",
      "Yifeng Gao"
    ],
    "abstract": "Recently, there has been a significant advancement in designing\nSelf-Supervised Learning (SSL) frameworks for time series data to reduce the\ndependency on data labels. Among these works, hierarchical contrastive\nlearning-based SSL frameworks, which learn representations by contrasting data\nembeddings at multiple resolutions, have gained considerable attention. Due to\ntheir ability to gather more information, they exhibit better generalization in\nvarious downstream tasks. However, when the time series data length is\nsignificant long, the computational cost is often significantly higher than\nthat of other SSL frameworks. In this paper, to address this challenge, we\npropose an efficient way to train hierarchical contrastive learning models.\nInspired by the fact that each resolution's data embedding is highly dependent,\nwe introduce importance-aware resolution selection based training framework to\nreduce the computational cost. In the experiment, we demonstrate that the\nproposed method significantly improves training time while preserving the\noriginal model's integrity in extensive time series classification performance\nevaluations. Our code could be found here, https://github.com/KEEBVIN/IARS",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "Appears in IEEEBigData-2024",
    "pdf_url": "http://arxiv.org/pdf/2502.10567v1",
    "published_date": "2025-02-14 21:32:50 UTC",
    "updated_date": "2025-02-14 21:32:50 UTC"
  },
  {
    "arxiv_id": "2502.10559v1",
    "title": "SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in 3D MRIs of the Knee Joint",
    "authors": [
      "Danielle L. Ferreira",
      "Bruno A. A. Nunes",
      "Xuzhe Zhang",
      "Laura Carretero Gomez",
      "Maggie Fung",
      "Ravi Soni"
    ],
    "abstract": "Accurate morphometric assessment of cartilage-such as thickness/volume-via\nMRI is essential for monitoring knee osteoarthritis. Segmenting cartilage\nremains challenging and dependent on extensive expert-annotated datasets, which\nare heavily subjected to inter-reader variability. Recent advancements in\nVisual Foundational Models (VFM), especially memory-based approaches, offer\nopportunities for improving generalizability and robustness. This study\nintroduces a deep learning (DL) method for cartilage and meniscus segmentation\nfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awareness\nand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) during\ntraining and applied a segmentation mask propagation technique to enhance\nannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, two\nautomatic transformer-based models (SaMRI2D and SaMRI3D), and a\ntransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from\n270 patients using public and internal datasets and evaluated on 57 external\ncases, including multi-radiologist annotations and different data acquisitions.\nModel performance was assessed against reference standards using Dice Score\n(DSC) and Intersection over Union (IoU), with additional morphometric\nevaluations to further quantify segmentation accuracy. SAMRI-2 model, trained\nwith HSS, outperformed all other models, achieving an average DSC improvement\nof 5 points, with a peak improvement of 12 points for tibial cartilage. It also\ndemonstrated the lowest cartilage thickness errors, reducing discrepancies by\nup to threefold. Notably, SAMRI-2 maintained high performance with as few as\nthree user clicks per volume, reducing annotation effort while ensuring\nanatomical precision. This memory-based VFM with spatial awareness offers a\nnovel approach for reliable AI-assisted knee MRI segmentation, advancing DL in\nmusculoskeletal imaging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10559v1",
    "published_date": "2025-02-14 21:18:01 UTC",
    "updated_date": "2025-02-14 21:18:01 UTC"
  },
  {
    "arxiv_id": "2502.10554v1",
    "title": "Benchmarking the rationality of AI decision making using the transitivity axiom",
    "authors": [
      "Kiwon Song",
      "James M. Jennings III",
      "Clintin P. Davis-Stober"
    ],
    "abstract": "Fundamental choice axioms, such as transitivity of preference, provide\ntestable conditions for determining whether human decision making is rational,\ni.e., consistent with a utility representation. Recent work has demonstrated\nthat AI systems trained on human data can exhibit similar reasoning biases as\nhumans and that AI can, in turn, bias human judgments through AI recommendation\nsystems. We evaluate the rationality of AI responses via a series of choice\nexperiments designed to evaluate transitivity of preference in humans. We\nconsidered ten versions of Meta's Llama 2 and 3 LLM models. We applied Bayesian\nmodel selection to evaluate whether these AI-generated choices violated two\nprominent models of transitivity. We found that the Llama 2 and 3 models\ngenerally satisfied transitivity, but when violations did occur, occurred only\nin the Chat/Instruct versions of the LLMs. We argue that rationality axioms,\nsuch as transitivity of preference, can be useful for evaluating and\nbenchmarking the quality of AI-generated responses and provide a foundation for\nunderstanding computational rationality in AI systems more generally.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.10554v1",
    "published_date": "2025-02-14 20:56:40 UTC",
    "updated_date": "2025-02-14 20:56:40 UTC"
  },
  {
    "arxiv_id": "2502.10552v1",
    "title": "Synthesis of Dynamic Masks for Information-Theoretic Opacity in Stochastic Systems",
    "authors": [
      "Sumukha Udupa",
      "Chongyang Shi",
      "Jie Fu"
    ],
    "abstract": "In this work, we investigate the synthesis of dynamic information releasing\nmechanisms, referred to as ''masks'', to minimize information leakage from a\nstochastic system to an external observer. Specifically, for a stochastic\nsystem, an observer aims to infer whether the final state of the system\ntrajectory belongs to a set of secret states. The dynamic mask seeks to\nregulate sensor information in order to maximize the observer's uncertainty\nabout the final state, a property known as final-state opacity. While existing\nsupervisory control literature on dynamic masks primarily addresses qualitative\nopacity, we propose quantifying opacity in stochastic systems by conditional\nentropy, which is a measure of information leakage in information security. We\nthen formulate a constrained optimization problem to synthesize a dynamic mask\nthat maximizes final-state opacity under a total cost constraint on masking. To\nsolve this constrained optimal dynamic mask synthesis problem, we develop a\nnovel primal-dual policy gradient method. Additionally, we present a technique\nfor computing the gradient of conditional entropy with respect to the masking\npolicy parameters, leveraging observable operators in hidden Markov models. To\ndemonstrate the effectiveness of our approach, we apply our method to an\nillustrative example and a stochastic grid world scenario, showing how our\nalgorithm optimally enforces final-state opacity under cost constraints.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "11 pages, 6 figures, accepted to ICCPS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10552v1",
    "published_date": "2025-02-14 20:53:22 UTC",
    "updated_date": "2025-02-14 20:53:22 UTC"
  },
  {
    "arxiv_id": "2502.10550v1",
    "title": "Memory, Benchmark & Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning",
    "authors": [
      "Egor Cherepanov",
      "Nikita Kachaev",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "abstract": "Memory is crucial for enabling agents to tackle complex tasks with temporal\nand spatial dependencies. While many reinforcement learning (RL) algorithms\nincorporate memory, the field lacks a universal benchmark to assess an agent's\nmemory capabilities across diverse scenarios. This gap is particularly evident\nin tabletop robotic manipulation, where memory is essential for solving tasks\nwith partial observability and ensuring robust performance, yet no standardized\nbenchmarks exist. To address this, we introduce MIKASA (Memory-Intensive Skills\nAssessment Suite for Agents), a comprehensive benchmark for memory RL, with\nthree key contributions: (1) we propose a comprehensive classification\nframework for memory-intensive RL tasks, (2) we collect MIKASA-Base - a unified\nbenchmark that enables systematic evaluation of memory-enhanced agents across\ndiverse scenarios, and (3) we develop MIKASA-Robo - a novel benchmark of 32\ncarefully designed memory-intensive tasks that assess memory capabilities in\ntabletop robotic manipulation. Our contributions establish a unified framework\nfor advancing memory RL research, driving the development of more reliable\nsystems for real-world applications. The code is available at\nhttps://sites.google.com/view/memorybenchrobots/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "38 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10550v1",
    "published_date": "2025-02-14 20:46:19 UTC",
    "updated_date": "2025-02-14 20:46:19 UTC"
  },
  {
    "arxiv_id": "2502.10546v1",
    "title": "Learning to be Smooth: An End-to-End Differentiable Particle Smoother",
    "authors": [
      "Ali Younis",
      "Erik B. Sudderth"
    ],
    "abstract": "For challenging state estimation problems arising in domains like vision and\nrobotics, particle-based representations attractively enable temporal reasoning\nabout multiple posterior modes. Particle smoothers offer the potential for more\naccurate offline data analysis by propagating information both forward and\nbackward in time, but have classically required human-engineered dynamics and\nobservation models. Extending recent advances in discriminative training of\nparticle filters, we develop a framework for low-variance propagation of\ngradients across long time sequences when training particle smoothers. Our\n\"two-filter'' smoother integrates particle streams that are propagated forward\nand backward in time, while incorporating stratification and importance weights\nin the resampling step to provide low-variance gradient estimates for neural\nnetwork dynamics and observation models. The resulting mixture density particle\nsmoother is substantially more accurate than state-of-the-art particle filters,\nas well as search-based baselines, for city-scale global vehicle localization\nfrom real-world videos and maps.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-Eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2502.10546v1",
    "published_date": "2025-02-14 20:26:54 UTC",
    "updated_date": "2025-02-14 20:26:54 UTC"
  },
  {
    "arxiv_id": "2502.10536v1",
    "title": "PolyPath: Adapting a Large Multimodal Model for Multi-slide Pathology Report Generation",
    "authors": [
      "Faruk Ahmed",
      "Lin Yang",
      "Tiam Jaroensri",
      "Andrew Sellergren",
      "Yossi Matias",
      "Avinatan Hassidim",
      "Greg S. Corrado",
      "Dale R. Webster",
      "Shravya Shetty",
      "Shruthi Prabhakara",
      "Yun Liu",
      "Daniel Golden",
      "Ellery Wulczyn",
      "David F. Steiner"
    ],
    "abstract": "The interpretation of histopathology cases underlies many important\ndiagnostic and treatment decisions in medicine. Notably, this process typically\nrequires pathologists to integrate and summarize findings across multiple\nslides per case. Existing vision-language capabilities in computational\npathology have so far been largely limited to small regions of interest, larger\nregions at low magnification, or single whole-slide images (WSIs). This limits\ninterpretation of findings that span multiple high-magnification regions across\nmultiple WSIs. By making use of Gemini 1.5 Flash, a large multimodal model\n(LMM) with a 1-million token context window, we demonstrate the ability to\ngenerate bottom-line diagnoses from up to 40,000 768x768 pixel image patches\nfrom multiple WSIs at 10X magnification. This is the equivalent of up to 11\nhours of video at 1 fps. Expert pathologist evaluations demonstrate that the\ngenerated report text is clinically accurate and equivalent to or preferred\nover the original reporting for 68% (95% CI: [60%, 76%]) of multi-slide\nexamples with up to 5 slides. While performance decreased for examples with 6\nor more slides, this study demonstrates the promise of leveraging the\nlong-context capabilities of modern LMMs for the uniquely challenging task of\nmedical report generation where each case can contain thousands of image\npatches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 main pages, 21 pages in total",
    "pdf_url": "http://arxiv.org/pdf/2502.10536v1",
    "published_date": "2025-02-14 20:09:13 UTC",
    "updated_date": "2025-02-14 20:09:13 UTC"
  },
  {
    "arxiv_id": "2502.15765v1",
    "title": "Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow",
    "authors": [
      "Behrooz Azarkhalili",
      "Maxwell Libbrecht"
    ],
    "abstract": "This paper introduces Generalized Attention Flow (GAF), a novel feature\nattribution method for Transformer-based models to address the limitations of\ncurrent approaches. By extending Attention Flow and replacing attention weights\nwith the generalized Information Tensor, GAF integrates attention weights,\ntheir gradients, the maximum flow problem, and the barrier method to enhance\nthe performance of feature attributions. The proposed method exhibits key\ntheoretical properties and mitigates the shortcomings of prior techniques that\nrely solely on simple aggregation of attention weights. Our comprehensive\nbenchmarking on sequence classification tasks demonstrates that a specific\nvariant of GAF consistently outperforms state-of-the-art feature attribution\nmethods in most evaluation settings, providing a more reliable interpretation\nof Transformer model outputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15765v1",
    "published_date": "2025-02-14 19:50:58 UTC",
    "updated_date": "2025-02-14 19:50:58 UTC"
  },
  {
    "arxiv_id": "2502.10526v2",
    "title": "Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks",
    "authors": [
      "Venkatesh Sivaraman",
      "Anika Vaishampayan",
      "Xiaotong Li",
      "Brian R Buck",
      "Ziyong Ma",
      "Richard D Boyce",
      "Adam Perer"
    ],
    "abstract": "Temporal predictive models have the potential to improve decisions in health\ncare, public services, and other domains, yet they often fail to effectively\nsupport decision-makers. Prior literature shows that many misalignments between\nmodel behavior and decision-makers' expectations stem from issues of model\nspecification, namely how, when, and for whom predictions are made. However,\nmodel specifications for predictive tasks are highly technical and difficult\nfor non-data-scientist stakeholders to interpret and critique. To address this\nchallenge we developed Tempo, an interactive system that helps data scientists\nand domain experts collaboratively iterate on model specifications. Using\nTempo's simple yet precise temporal query language, data scientists can quickly\nprototype specifications with greater transparency about pre-processing\nchoices. Moreover, domain experts can assess performance within data subgroups\nto validate that models behave as expected. Through three case studies, we\ndemonstrate how Tempo helps multidisciplinary teams quickly prune infeasible\nspecifications and identify more promising directions to explore.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Appearing at CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10526v2",
    "published_date": "2025-02-14 19:44:37 UTC",
    "updated_date": "2025-02-20 17:56:42 UTC"
  },
  {
    "arxiv_id": "2502.10522v1",
    "title": "GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs",
    "authors": [
      "Shima Khoshraftar",
      "Niaz Abedini",
      "Amir Hajian"
    ],
    "abstract": "The application of large language models (LLMs) to graph data has attracted a\nlot of attention recently. LLMs allow us to use deep contextual embeddings from\npretrained models in text-attributed graphs, where shallow embeddings are often\nused for the text attributes of nodes. However, it is still challenging to\nefficiently encode the graph structure and features into a sequential form for\nuse by LLMs. In addition, the performance of an LLM alone, is highly dependent\non the structure of the input prompt, which limits their effectiveness as a\nreliable approach and often requires iterative manual adjustments that could be\nslow, tedious and difficult to replicate programmatically. In this paper, we\npropose GraphiT (Graphs in Text), a framework for encoding graphs into a\ntextual format and optimizing LLM prompts for graph prediction tasks. Here we\nfocus on node classification for text-attributed graphs. We encode the graph\ndata for every node and its neighborhood into a concise text to enable LLMs to\nbetter utilize the information in the graph. We then further programmatically\noptimize the LLM prompts using the DSPy framework to automate this step and\nmake it more efficient and reproducible. GraphiT outperforms our LLM-based\nbaselines on three datasets and we show how the optimization step in GraphiT\nleads to measurably better results without manual prompt tweaking. We also\ndemonstrated that our graph encoding approach is competitive to other graph\nencoding methods while being less expensive because it uses significantly less\ntokens for the same task.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10522v1",
    "published_date": "2025-02-14 19:38:41 UTC",
    "updated_date": "2025-02-14 19:38:41 UTC"
  },
  {
    "arxiv_id": "2502.10517v1",
    "title": "KernelBench: Can LLMs Write Efficient GPU Kernels?",
    "authors": [
      "Anne Ouyang",
      "Simon Guo",
      "Simran Arora",
      "Alex L. Zhang",
      "William Hu",
      "Christopher Ré",
      "Azalia Mirhoseini"
    ],
    "abstract": "Efficient GPU kernels are crucial for building performant machine learning\narchitectures, but writing them is a time-consuming challenge that requires\nsignificant expertise; therefore, we explore using language models (LMs) to\nautomate kernel generation. We introduce KernelBench, an open-source framework\nfor evaluating LMs' ability to write fast and correct kernels on a suite of 250\ncarefully selected PyTorch ML workloads. KernelBench represents a real-world\nengineering environment and making progress on the introduced benchmark\ndirectly translates to faster practical kernels. We introduce a new evaluation\nmetric fast_p, which measures the percentage of generated kernels that are\nfunctionally correct and offer a speedup greater than an adjustable threshold p\nover baseline. Our experiments across various state-of-the-art models and\ntest-time methods show that frontier reasoning models perform the best out of\nthe box but still fall short overall, matching the PyTorch baseline in less\nthan 20% of the cases. While we show that results can improve by leveraging\nexecution and profiling feedback during iterative refinement, KernelBench\nremains a challenging benchmark, with its difficulty increasing as we raise\nspeedup threshold p.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10517v1",
    "published_date": "2025-02-14 19:30:53 UTC",
    "updated_date": "2025-02-14 19:30:53 UTC"
  },
  {
    "arxiv_id": "2502.10389v1",
    "title": "Region-Adaptive Sampling for Diffusion Transformers",
    "authors": [
      "Ziming Liu",
      "Yifan Yang",
      "Chengruidong Zhang",
      "Yiqi Zhang",
      "Lili Qiu",
      "Yang You",
      "Yuqing Yang"
    ],
    "abstract": "Diffusion models (DMs) have become the leading choice for generative tasks\nacross diverse domains. However, their reliance on multiple sequential forward\npasses significantly limits real-time performance. Previous acceleration\nmethods have primarily focused on reducing the number of sampling steps or\nreusing intermediate results, failing to leverage variations across spatial\nregions within the image due to the constraints of convolutional U-Net\nstructures. By harnessing the flexibility of Diffusion Transformers (DiTs) in\nhandling variable number of tokens, we introduce RAS, a novel, training-free\nsampling strategy that dynamically assigns different sampling ratios to regions\nwithin an image based on the focus of the DiT model. Our key observation is\nthat during each sampling step, the model concentrates on semantically\nmeaningful regions, and these areas of focus exhibit strong continuity across\nconsecutive steps. Leveraging this insight, RAS updates only the regions\ncurrently in focus, while other regions are updated using cached noise from the\nprevious step. The model's focus is determined based on the output from the\npreceding step, capitalizing on the temporal consistency we observed. We\nevaluate RAS on Stable Diffusion 3 and Lumina-Next-T2I, achieving speedups up\nto 2.36x and 2.51x, respectively, with minimal degradation in generation\nquality. Additionally, a user study reveals that RAS delivers comparable\nqualities under human evaluation while achieving a 1.6x speedup. Our approach\nmakes a significant step towards more efficient diffusion transformers,\nenhancing their potential for real-time applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10389v1",
    "published_date": "2025-02-14 18:59:36 UTC",
    "updated_date": "2025-02-14 18:59:36 UTC"
  },
  {
    "arxiv_id": "2502.10385v1",
    "title": "Simplifying DINO via Coding Rate Regularization",
    "authors": [
      "Ziyang Wu",
      "Jingyuan Zhang",
      "Druv Pai",
      "XuDong Wang",
      "Chandan Singh",
      "Jianwei Yang",
      "Jianfeng Gao",
      "Yi Ma"
    ],
    "abstract": "DINO and DINOv2 are two model families being widely used to learn\nrepresentations from unlabeled imagery data at large scales. Their learned\nrepresentations often enable state-of-the-art performance for downstream tasks,\nsuch as image classification and segmentation. However, they employ many\nempirically motivated design choices and their training pipelines are highly\ncomplex and unstable -- many hyperparameters need to be carefully tuned to\nensure that the representations do not collapse -- which poses considerable\ndifficulty to improving them or adapting them to new domains. In this work, we\nposit that we can remove most such-motivated idiosyncrasies in the pre-training\npipelines, and only need to add an explicit coding rate term in the loss\nfunction to avoid collapse of the representations. As a result, we obtain\nhighly simplified variants of the DINO and DINOv2 which we call SimDINO and\nSimDINOv2, respectively. Remarkably, these simplified models are more robust to\ndifferent design choices, such as network architecture and hyperparameters, and\nthey learn even higher-quality representations, measured by performance on\ndownstream tasks, offering a Pareto improvement over the corresponding DINO and\nDINOv2 models. This work highlights the potential of using simplifying design\nprinciples to improve the empirical practice of deep learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10385v1",
    "published_date": "2025-02-14 18:58:04 UTC",
    "updated_date": "2025-02-14 18:58:04 UTC"
  },
  {
    "arxiv_id": "2502.10383v1",
    "title": "Representation and Interpretation in Artificial and Natural Computing",
    "authors": [
      "Luis A. Pineda"
    ],
    "abstract": "Artificial computing machinery transforms representations through an\nobjective process, to be interpreted subjectively by humans, so the machine and\nthe interpreter are different entities, but in the putative natural computing\nboth processes are performed by the same agent. The method or process that\ntransforms a representation is called here \\emph{the mode of computing}. The\nmode used by digital computers is the algorithmic one, but there are others,\nsuch as quantum computers and diverse forms of non-conventional computing, and\nthere is an open-ended set of representational formats and modes that could be\nused in artificial and natural computing. A mode based on a notion of computing\ndifferent from Turing's may perform feats beyond what the Turing Machine does\nbut the modes would not be of the same kind and could not be compared. For a\nmode of computing to be more powerful than the algorithmic one, it ought to\ncompute functions lacking an effective algorithm, and Church Thesis would not\nhold. Here, a thought experiment including a computational demon using a\nhypothetical mode for such an effect is presented. If there is natural\ncomputing, there is a mode of natural computing whose properties may be causal\nto the phenomenological experience. Discovering it would come with solving the\nhard problem of consciousness; but if it turns out that such a mode does not\nexist, there is no such thing as natural computing, and the mind is not a\ncomputational process.",
    "categories": [
      "cs.AI",
      "F.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10383v1",
    "published_date": "2025-02-14 18:57:29 UTC",
    "updated_date": "2025-02-14 18:57:29 UTC"
  },
  {
    "arxiv_id": "2502.10373v1",
    "title": "OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models",
    "authors": [
      "William Chen",
      "Jinchuan Tian",
      "Yifan Peng",
      "Brian Yan",
      "Chao-Han Huck Yang",
      "Shinji Watanabe"
    ],
    "abstract": "Neural scaling laws offer valuable insights for designing robust sequence\nprocessing architectures. While these laws have been extensively characterized\nin other modalities, their behavior in speech remains comparatively\nunderexplored. In this work, we introduce OWLS, an open-access, reproducible\nsuite of multilingual speech recognition and translation models spanning 0.25B\nto 18B parameters, with the 18B version being the largest speech model, to the\nbest of our knowledge. OWLS leverages up to 360K hours of public speech data\nacross 150 languages, enabling a systematic investigation into how data, model,\nand compute scaling each influence performance in multilingual speech tasks. We\nuse OWLS to derive neural scaling laws, showing how final performance can be\nreliably predicted when scaling. One of our key findings is that scaling\nenhances performance on low-resource languages/dialects, helping to mitigate\nbias and improve the accessibility of speech technologies. Finally, we show how\nOWLS can be used to power new research directions by discovering emergent\nabilities in large-scale speech models. Model checkpoints will be released on\nhttps://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8d\nfor future studies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10373v1",
    "published_date": "2025-02-14 18:51:40 UTC",
    "updated_date": "2025-02-14 18:51:40 UTC"
  },
  {
    "arxiv_id": "2502.10363v3",
    "title": "BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds",
    "authors": [
      "Huayi Wang",
      "Zirui Wang",
      "Junli Ren",
      "Qingwei Ben",
      "Tao Huang",
      "Weinan Zhang",
      "Jiangmiao Pang"
    ],
    "abstract": "Traversing risky terrains with sparse footholds poses a significant challenge\nfor humanoid robots, requiring precise foot placements and stable locomotion.\nExisting learning-based approaches often struggle on such complex terrains due\nto sparse foothold rewards and inefficient learning processes. To address these\nchallenges, we introduce BeamDojo, a reinforcement learning (RL) framework\ndesigned for enabling agile humanoid locomotion on sparse footholds. BeamDojo\nbegins by introducing a sampling-based foothold reward tailored for polygonal\nfeet, along with a double critic to balancing the learning process between\ndense locomotion rewards and sparse foothold rewards. To encourage sufficient\ntrial-and-error exploration, BeamDojo incorporates a two-stage RL approach: the\nfirst stage relaxes the terrain dynamics by training the humanoid on flat\nterrain while providing it with task-terrain perceptive observations, and the\nsecond stage fine-tunes the policy on the actual task terrain. Moreover, we\nimplement a onboard LiDAR-based elevation map to enable real-world deployment.\nExtensive simulation and real-world experiments demonstrate that BeamDojo\nachieves efficient learning in simulation and enables agile locomotion with\nprecise foot placement on sparse footholds in the real world, maintaining a\nhigh success rate even under significant external disturbances.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at RSS 2025. Project website:\n  https://why618188.github.io/beamdojo",
    "pdf_url": "http://arxiv.org/pdf/2502.10363v3",
    "published_date": "2025-02-14 18:42:42 UTC",
    "updated_date": "2025-04-27 13:49:42 UTC"
  },
  {
    "arxiv_id": "2502.10339v1",
    "title": "STAR: Spectral Truncation and Rescale for Model Merging",
    "authors": [
      "Yu-Ang Lee",
      "Ching-Yun Ko",
      "Tejaswini Pedapati",
      "I-Hsin Chung",
      "Mi-Yen Yeh",
      "Pin-Yu Chen"
    ],
    "abstract": "Model merging is an efficient way of obtaining a multi-task model from\nseveral pretrained models without further fine-tuning, and it has gained\nattention in various domains, including natural language processing (NLP).\nDespite the efficiency, a key challenge in model merging is the seemingly\ninevitable decrease in task performance as the number of models increases. In\nthis paper, we propose $\\mathbf{S}$pectral $\\mathbf{T}$runcation $\\mathbf{A}$nd\n$\\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' by\ntruncating small components in the respective spectral spaces, which is\nfollowed by an automatic parameter rescaling scheme to retain the nuclear norm\nof the original matrix. STAR requires no additional inference on original\ntraining data and is robust to hyperparamater choice. We demonstrate the\neffectiveness of STAR through extensive model merging cases on diverse NLP\ntasks. Specifically, STAR works robustly across varying model sizes, and can\noutperform baselines by 4.2$\\%$ when merging 12 models on Flan-T5. Our code is\npublicly available at https://github.com/IBM/STAR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10339v1",
    "published_date": "2025-02-14 17:59:58 UTC",
    "updated_date": "2025-02-14 17:59:58 UTC"
  },
  {
    "arxiv_id": "2502.10338v1",
    "title": "Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering",
    "authors": [
      "Nick Ferguson",
      "Liane Guillou",
      "Alan Bundy",
      "Kwabena Nuamah"
    ],
    "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face\nchallenges in Question Answering (QA) tasks requiring complex, multi-step\nreasoning. We outline the types of reasoning required in some of these tasks,\nand reframe them in terms of meta-level reasoning (akin to high-level strategic\nreasoning or planning) and object-level reasoning (embodied in lower-level\ntasks such as mathematical reasoning). Franklin, a novel dataset with\nrequirements of meta- and object-level reasoning, is introduced and used along\nwith three other datasets to evaluate four LLMs at question answering tasks\nrequiring multiple steps of reasoning. Results from human annotation studies\nsuggest LLMs demonstrate meta-level reasoning with high frequency, but struggle\nwith object-level reasoning tasks in some of the datasets used. Additionally,\nevidence suggests that LLMs find the object-level reasoning required for the\nquestions in the Franklin dataset challenging, yet they do exhibit strong\nperformance with respect to the meta-level reasoning requirements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages. Accepted to the Workshop on Planning in the Era of LLMs\n  (LM4Plan @ AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.10338v1",
    "published_date": "2025-02-14 17:55:43 UTC",
    "updated_date": "2025-02-14 17:55:43 UTC"
  },
  {
    "arxiv_id": "2502.10497v1",
    "title": "Hallucinations and Truth: A Comprehensive Accuracy Evaluation of RAG, LoRA and DoRA",
    "authors": [
      "Mohammad Baqar",
      "Rajat Khanda"
    ],
    "abstract": "Recent advancements in Generative AI have significantly improved the\nefficiency and adaptability of natural language processing (NLP) systems,\nparticularly through Retrieval-Augmented Generation (RAG), Low-Rank Adaptation\n(LoRA), and Weight-Decomposed Low-Rank Adaptation (DoRA). RAG integrates\nexternal knowledge to enhance factual consistency in generative outputs, while\nLoRA enables parameter-efficient fine-tuning of large language models (LLMs).\nDoRA further refines this process by optimizing fine-tuning through adaptive\nparameter ranking and domain-aware weight adjustments, improving learning\nefficiency while maintaining inference performance.\n  This paper presents a large-scale empirical evaluation of RAG, LoRA, and\nDoRA, with model fine-tuning and generation performance assessed on 20,000\nFAQ-based queries, while the knowledge base spans 400,000 entries. The study\nanalyzes key performance metrics such as accuracy, relevance, and inference\nlatency. Experimental results demonstrate that DoRA achieves the highest\naccuracy (90.1%), relevance score (0.88), and lowest latency (110 ms per\nquery), outperforming both LoRA and RAG in real-world, domain-specific\ngenerative AI applications.\n  Furthermore, this study examines the trade-offs between fine-tuning\nefficiency, computational cost, and real-time adaptability across different\nmodels. Findings highlight RAG's effectiveness in knowledge grounding, LoRA's\ncost-efficient domain adaptation, and DoRA's ability to balance fine-tuning\nefficiency with model precision. These insights provide practical guidance for\ndeploying AI-driven generative systems in accuracy-critical domains such as\nhealthcare, finance, and legal services, ensuring scalability, reliability, and\noptimal performance in dynamic environments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 Pages",
    "pdf_url": "http://arxiv.org/pdf/2502.10497v1",
    "published_date": "2025-02-14 17:38:25 UTC",
    "updated_date": "2025-02-14 17:38:25 UTC"
  },
  {
    "arxiv_id": "2502.10325v1",
    "title": "Process Reward Models for LLM Agents: Practical Framework and Directions",
    "authors": [
      "Sanjiban Choudhury"
    ],
    "abstract": "We introduce Agent Process Reward Models (AgentPRM), a simple and scalable\nframework for training LLM agents to continually improve through interactions.\nAgentPRM follows a lightweight actor-critic paradigm, using Monte Carlo\nrollouts to compute reward targets and optimize policies. It requires minimal\nmodifications to existing RLHF pipelines, making it easy to integrate at scale.\nBeyond AgentPRM, we propose InversePRM, which learns process rewards directly\nfrom demonstrations without explicit outcome supervision. We also explore key\nchallenges and opportunities, including exploration, process reward shaping,\nand model-predictive reasoning. We evaluate on ALFWorld benchmark, show that\nsmall 3B models trained with AgentPRM and InversePRM outperform strong GPT-4o\nbaselines, and analyze test-time scaling, reward hacking, and more. Our code is\navailable at: https://github.com/sanjibanc/agent_prm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10325v1",
    "published_date": "2025-02-14 17:34:28 UTC",
    "updated_date": "2025-02-14 17:34:28 UTC"
  },
  {
    "arxiv_id": "2502.10311v1",
    "title": "ExplainReduce: Summarising local explanations via proxies",
    "authors": [
      "Lauri Seppäläinen",
      "Mudong Guo",
      "Kai Puolamäki"
    ],
    "abstract": "Most commonly used non-linear machine learning methods are closed-box models,\nuninterpretable to humans. The field of explainable artificial intelligence\n(XAI) aims to develop tools to examine the inner workings of these closed\nboxes. An often-used model-agnostic approach to XAI involves using simple\nmodels as local approximations to produce so-called local explanations;\nexamples of this approach include LIME, SHAP, and SLISEMAP. This paper shows\nhow a large set of local explanations can be reduced to a small \"proxy set\" of\nsimple models, which can act as a generative global explanation. This reduction\nprocedure, ExplainReduce, can be formulated as an optimisation problem and\napproximated efficiently using greedy heuristics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages with a 7 page appendix, 7 + 5 figures, 2 tables. The\n  datasets and source code used in the paper are available at\n  https://github.com/edahelsinki/explainreduce",
    "pdf_url": "http://arxiv.org/pdf/2502.10311v1",
    "published_date": "2025-02-14 17:14:02 UTC",
    "updated_date": "2025-02-14 17:14:02 UTC"
  },
  {
    "arxiv_id": "2502.10308v1",
    "title": "LLM-Powered Preference Elicitation in Combinatorial Assignment",
    "authors": [
      "Ermis Soumalias",
      "Yanchen Jiang",
      "Kehang Zhu",
      "Michael Curry",
      "Sven Seuken",
      "David C. Parkes"
    ],
    "abstract": "We study the potential of large language models (LLMs) as proxies for humans\nto simplify preference elicitation (PE) in combinatorial assignment. While\ntraditional PE methods rely on iterative queries to capture preferences, LLMs\noffer a one-shot alternative with reduced human effort. We propose a framework\nfor LLM proxies that can work in tandem with SOTA ML-powered preference\nelicitation schemes. Our framework handles the novel challenges introduced by\nLLMs, such as response variability and increased computational costs. We\nexperimentally evaluate the efficiency of LLM proxies against human queries in\nthe well-studied course allocation domain, and we investigate the model\ncapabilities required for success. We find that our approach improves\nallocative efficiency by up to 20%, and these results are robust across\ndifferent LLMs and to differences in quality and accuracy of reporting.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10308v1",
    "published_date": "2025-02-14 17:12:20 UTC",
    "updated_date": "2025-02-14 17:12:20 UTC"
  },
  {
    "arxiv_id": "2502.12182v1",
    "title": "Towards Transparent and Accurate Plasma State Monitoring at JET",
    "authors": [
      "Andrin Bürli",
      "Alessandro Pau",
      "Thomas Koller",
      "Olivier Sauter",
      "JET Contributors"
    ],
    "abstract": "Controlling and monitoring plasma within a tokamak device is complex and\nchallenging. Plasma off-normal events, such as disruptions, are hindering\nsteady-state operation. For large devices, they can even endanger the machine's\nintegrity and it represents in general one of the most serious concerns for the\nexploitation of the tokamak concept for future power plants. Effective plasma\nstate monitoring carries the potential to enable an understanding of such\nphenomena and their evolution which is crucial for the successful operation of\ntokamaks. This paper presents the application of a transparent and data-driven\nmethodology to monitor the plasma state in a tokamak. Compared to previous\nstudies in the field, supervised and unsupervised learning techniques are\ncombined. The dataset consisted of 520 expert-validated discharges from JET.\nThe goal was to provide an interpretable plasma state representation for the\nJET operational space by leveraging multi-task learning for the first time in\nthe context of plasma state monitoring. When evaluated as disruption\npredictors, a sequence-based approach showed significant improvements compared\nto the state-based models. The best resulting network achieved a promising\ncross-validated success rate when combined with a physical indicator and\naccounting for nearby instabilities. Qualitative evaluations of the learned\nlatent space uncovered operational and disruptive regions as well as patterns\nrelated to learned dynamics and global feature importance. The applied\nmethodology provides novel possibilities for the definition of triggers to\nswitch between different control scenarios, data analysis, and learning as well\nas exploring latent dynamics for plasma state monitoring. It also showed\npromising quantitative and qualitative results with warning times suitable for\navoidance purposes and distributions that are consistent with known physical\nmechanisms.",
    "categories": [
      "physics.plasm-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.plasm-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12182v1",
    "published_date": "2025-02-14 17:09:03 UTC",
    "updated_date": "2025-02-14 17:09:03 UTC"
  },
  {
    "arxiv_id": "2502.10303v1",
    "title": "Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMinds Innovations",
    "authors": [
      "Abdelrhman Shaheen",
      "Anas Badr",
      "Ali Abohendy",
      "Hatem Alsaadawy",
      "Nadine Alsayad"
    ],
    "abstract": "Reinforcement Learning (RL) has been widely used in many applications,\nparticularly in gaming, which serves as an excellent training ground for AI\nmodels. Google DeepMind has pioneered innovations in this field, employing\nreinforcement learning algorithms, including model-based, model-free, and deep\nQ-network approaches, to create advanced AI models such as AlphaGo, AlphaGo\nZero, and MuZero. AlphaGo, the initial model, integrates supervised learning\nand reinforcement learning to master the game of Go, surpassing professional\nhuman players. AlphaGo Zero refines this approach by eliminating reliance on\nhuman gameplay data, instead utilizing self-play for enhanced learning\nefficiency. MuZero further extends these advancements by learning the\nunderlying dynamics of game environments without explicit knowledge of the\nrules, achieving adaptability across various games, including complex Atari\ngames. This paper reviews the significance of reinforcement learning\napplications in Atari and strategy-based games, analyzing these three models,\ntheir key innovations, training processes, challenges encountered, and\nimprovements made. Additionally, we discuss advancements in the field of\ngaming, including MiniZero and multi-agent models, highlighting future\ndirections and emerging AI models from Google DeepMind.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10303v1",
    "published_date": "2025-02-14 17:06:34 UTC",
    "updated_date": "2025-02-14 17:06:34 UTC"
  },
  {
    "arxiv_id": "2502.10495v1",
    "title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models",
    "authors": [
      "Zhonghao Yang",
      "Linye Lyu",
      "Xuanhang Chang",
      "Daojing He",
      "YU LI"
    ],
    "abstract": "In the rapidly evolving landscape of image generation, Latent Diffusion\nModels (LDMs) have emerged as powerful tools, enabling the creation of highly\nrealistic images. However, this advancement raises significant concerns\nregarding copyright infringement and the potential misuse of generated content.\nCurrent watermarking techniques employed in LDMs often embed constant signals\nto the generated images that compromise their stealthiness, making them\nvulnerable to detection by malicious attackers. In this paper, we introduce\nSWA-LDM, a novel approach that enhances watermarking by randomizing the\nembedding process, effectively eliminating detectable patterns while preserving\nimage quality and robustness. Our proposed watermark presence attack reveals\nthe inherent vulnerabilities of existing latent-based watermarking methods,\ndemonstrating how easily these can be exposed. Through comprehensive\nexperiments, we validate that SWA-LDM not only fortifies watermark stealthiness\nbut also maintains competitive performance in watermark robustness and visual\nfidelity. This work represents a pivotal step towards securing LDM-generated\nimages against unauthorized use, ensuring both copyright protection and content\nintegrity in an era where digital image authenticity is paramount.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10495v1",
    "published_date": "2025-02-14 16:55:45 UTC",
    "updated_date": "2025-02-14 16:55:45 UTC"
  },
  {
    "arxiv_id": "2502.10284v1",
    "title": "A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems",
    "authors": [
      "Binglei Zhao",
      "Houying Qi",
      "Guang Xu",
      "Mian Ma",
      "Xiwei Zhao",
      "Feng Mei",
      "Sulong Xu",
      "Jinghe Hu"
    ],
    "abstract": "Large-scale recommendation systems often adopt cascading architecture\nconsisting of retrieval, pre-ranking, ranking, and re-ranking stages. With\nstrict latency requirements, pre-ranking utilizes lightweight models to perform\na preliminary selection from massive retrieved candidates. However, recent\nworks focus solely on improving consistency with ranking, relying exclusively\non downstream stages. Since downstream input is derived from the pre-ranking\noutput, they will exacerbate the sample selection bias (SSB) issue and Matthew\neffect, leading to sub-optimal results. To address the limitation, we propose a\nnovel Hybrid Cross-Stage Coordination Pre-ranking model (HCCP) to integrate\ninformation from upstream (retrieval) and downstream (ranking, re-ranking)\nstages. Specifically, cross-stage coordination refers to the pre-ranking's\nadaptability to the entire stream and the role of serving as a more effective\nbridge between upstream and downstream. HCCP consists of Hybrid Sample\nConstruction and Hybrid Objective Optimization. Hybrid sample construction\ncaptures multi-level unexposed data from the entire stream and rearranges them\nto become the optimal guiding \"ground truth\" for pre-ranking learning. Hybrid\nobjective optimization contains the joint optimization of consistency and\nlong-tail precision through our proposed Margin InfoNCE loss. It is\nspecifically designed to learn from such hybrid unexposed samples, improving\nthe overall performance and mitigating the SSB issue. The appendix describes a\nproof of the efficacy of the proposed loss in selecting potential positives.\nExtensive offline and online experiments indicate that HCCP outperforms SOTA\nmethods by improving cross-stage coordination. It contributes up to 14.9% UCVR\nand 1.3% UCTR in the JD E-commerce recommendation system. Concerning code\nprivacy, we provide a pseudocode for reference.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10284v1",
    "published_date": "2025-02-14 16:42:54 UTC",
    "updated_date": "2025-02-14 16:42:54 UTC"
  },
  {
    "arxiv_id": "2502.10273v1",
    "title": "Probing Perceptual Constancy in Large Vision Language Models",
    "authors": [
      "Haoran Sun",
      "Suyang Yu",
      "Yijiang Li",
      "Qingying Gao",
      "Haiyun Lyu",
      "Hokin Deng",
      "Dezhi Luo"
    ],
    "abstract": "Perceptual constancy is the ability to maintain stable perceptions of objects\ndespite changes in sensory input, such as variations in distance, angle, or\nlighting. This ability is crucial for recognizing visual information in a\ndynamic world, making it essential for Vision-Language Models (VLMs). However,\nwhether VLMs are currently and theoretically capable of mastering this ability\nremains underexplored. In this study, we evaluated 33 VLMs using 253\nexperiments across three domains: color, size, and shape constancy. The\nexperiments included single-image and video adaptations of classic cognitive\ntasks, along with novel tasks in in-the-wild conditions, to evaluate the\nmodels' recognition of object properties under varying conditions. We found\nsignificant variability in VLM performance, with models performance in shape\nconstancy clearly dissociated from that of color and size constancy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10273v1",
    "published_date": "2025-02-14 16:31:43 UTC",
    "updated_date": "2025-02-14 16:31:43 UTC"
  },
  {
    "arxiv_id": "2502.10266v1",
    "title": "Are Large Language Models the future crowd workers of Linguistics?",
    "authors": [
      "Iris Ferrazzo"
    ],
    "abstract": "Data elicitation from human participants is one of the core data collection\nstrategies used in empirical linguistic research. The amount of participants in\nsuch studies may vary considerably, ranging from a handful to crowdsourcing\ndimensions. Even if they provide resourceful extensive data, both of these\nsettings come alongside many disadvantages, such as low control of\nparticipants' attention during task completion, precarious working conditions\nin crowdsourcing environments, and time-consuming experimental designs. For\nthese reasons, this research aims to answer the question of whether Large\nLanguage Models (LLMs) may overcome those obstacles if included in empirical\nlinguistic pipelines. Two reproduction case studies are conducted to gain\nclarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forced\nelicitation tasks, originally designed for human participants, are reproduced\nin the proposed framework with the help of OpenAI's GPT-4o-mini model. Its\nperformance with our zero-shot prompting baseline shows the effectiveness and\nhigh versatility of LLMs, that tend to outperform human informants in\nlinguistic tasks. The findings of the second replication further highlight the\nneed to explore additional prompting techniques, such as Chain-of-Thought (CoT)\nprompting, which, in a second follow-up experiment, demonstrates higher\nalignment to human performance on both critical and filler items. Given the\nlimited scale of this study, it is worthwhile to further explore the\nperformance of LLMs in empirical Linguistics and in other future applications\nin the humanities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10266v1",
    "published_date": "2025-02-14 16:23:39 UTC",
    "updated_date": "2025-02-14 16:23:39 UTC"
  },
  {
    "arxiv_id": "2502.15764v1",
    "title": "High-Throughput Computational Screening and Interpretable Machine Learning of Metal-organic Frameworks for Iodine Capture",
    "authors": [
      "Haoyi Tan",
      "Yukun Teng",
      "Guangcun Shan"
    ],
    "abstract": "The removal of leaked radioactive iodine isotopes in humid environments holds\nsignificant importance in nuclear waste management and nuclear accident\nmitigation. In this study, high-throughput computational screening and machine\nlearning were combined to reveal the iodine capture performance of 1816\nmetal-organic framework (MOF) materials under humid air conditions. Firstly,\nthe relationship between the structural characteristics of MOFs and their\nadsorption properties was explored, with the aim of identifying the optimal\nstructural parameters for iodine capture. Subsequently, two machine learning\nregression algorithms - Random Forest and CatBoost, were employed to predict\nthe iodine adsorption capabilities of MOFs. In addition to 6 structural\nfeatures, 25 molecular features and 8 chemical features were incorporated to\nenhance the prediction accuracy of the machine learning algorithms. Feature\nimportance was assessed to determine the relative influence of various features\non iodine adsorption performance, in which the Henry's coefficient and heat of\nadsorption to iodine were found the two most crucial chemical factors.\nFurthermore, four types of molecular fingerprints were introduced for providing\ncomprehensive and detailed structural information of MOF materials. The top 20\nmost significant MACCS molecular fingerprints were picked out, revealing that\nthe presence of six-membered ring structures and nitrogen atoms in the MOFs\nwere the key structural factors that enhanced iodine adsorption, followed by\nthe existence of oxygen atoms. This work combined high-throughput computation,\nmachine learning, and molecular fingerprints to comprehensively elucidate the\nmultifaceted factors influencing the iodine adsorption performance of MOFs,\noffering profound insightful guidelines for screening and structural design of\nadvanced MOF materials.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "13 page,6 figures, submitted to npjCM",
    "pdf_url": "http://arxiv.org/pdf/2502.15764v1",
    "published_date": "2025-02-14 16:22:28 UTC",
    "updated_date": "2025-02-14 16:22:28 UTC"
  },
  {
    "arxiv_id": "2502.10263v1",
    "title": "Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers",
    "authors": [
      "Aivin V. Solatorio",
      "Rafael Macalaba",
      "James Liounis"
    ],
    "abstract": "Tracking how data is mentioned and used in research papers provides critical\ninsights for improving data discoverability, quality, and production. However,\nmanually identifying and classifying dataset mentions across vast academic\nliterature is resource-intensive and not scalable. This paper presents a\nmachine learning framework that automates dataset mention detection across\nresearch domains by leveraging large language models (LLMs), synthetic data,\nand a two-stage fine-tuning process. We employ zero-shot extraction from\nresearch papers, an LLM-as-a-Judge for quality assessment, and a reasoning\nagent for refinement to generate a weakly supervised synthetic dataset. The\nPhi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed by\nfine-tuning on a manually annotated subset. At inference, a ModernBERT-based\nclassifier efficiently filters dataset mentions, reducing computational\noverhead while maintaining high recall. Evaluated on a held-out manually\nannotated sample, our fine-tuned model outperforms NuExtract-v1.5 and\nGLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight how\nLLM-generated synthetic data can effectively address training data scarcity,\nimproving generalization in low-resource settings. This framework offers a\npathway toward scalable monitoring of dataset usage, enhancing transparency,\nand supporting researchers, funders, and policymakers in identifying data gaps\nand strengthening data accessibility for informed decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project GitHub repository at https://github.com/worldbank/ai4data-use",
    "pdf_url": "http://arxiv.org/pdf/2502.10263v1",
    "published_date": "2025-02-14 16:16:02 UTC",
    "updated_date": "2025-02-14 16:16:02 UTC"
  },
  {
    "arxiv_id": "2502.15763v1",
    "title": "Hybrid Offline-online Scheduling Method for Large Language Model Inference Optimization",
    "authors": [
      "Bowen Pang",
      "Kai Li",
      "Ruifeng She",
      "Feifan Wang"
    ],
    "abstract": "With the development of large language models (LLMs), it has become\nincreasingly important to optimize hardware usage and improve throughput. In\nthis paper, we study the inference optimization of the serving system that\ndeploys LLMs. To optimize system throughput and maximize hardware utilization,\nwe formulate the inference optimization problem as a mixed-integer programming\n(MIP) model and propose a hybrid offline-online method as solution. The offline\nmethod improves large-scale inference systems by introducing a Minimizing\nMakespan Bin Packing Problem. We further provide a theoretical lower bound\ncomputation method. Then, we propose an online sorting and preemptive\nscheduling method to better utilize hardware. In the online iteration\nscheduling process, a Lagrangian method is applied to evaluate the cost\nefficiency of inserting prefill stages versus decode stages at each iteration\nand dynamically determine when to preempt decoding tasks and insert prefill\ntasks. Experiments using real-world data from the LLaMA-65B model and the GSM8K\ndataset demonstrate that system utilization improves from 80.2% to 89.1%, and\nthe total inference time decreases from 201.00 to 190.58 seconds. A 100-cases\nstudy shows that our method consistently outperforms the baseline method and\nimproves the utilization rate by 8.0% on average. Finally, we discuss potential\nfuture extensions, including stochastic modeling, reinforcement learning-based\nschedulers, and dynamic decision-making strategies for system throughput and\nhardware utilization.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15763v1",
    "published_date": "2025-02-14 16:00:00 UTC",
    "updated_date": "2025-02-14 16:00:00 UTC"
  },
  {
    "arxiv_id": "2502.10239v1",
    "title": "Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices",
    "authors": [
      "Mohamed Aboelenien Ahmed",
      "Kilian Pfeiffer",
      "Ramin Khalili",
      "Heba Khdr",
      "Jörg Henkel"
    ],
    "abstract": "Federated fine-tuning offers a promising approach for tuning Large Language\nModels (LLMs) on edge devices while preserving data privacy. However,\nfine-tuning these models on edge devices remains challenging due to high\nmemory, communication, and computational demands. Zero-order optimization with\ntask alignment provides a potential solution, enabling fine-tuning with\ninference-level memory requirements but requires a longer convergence time. In\nthis paper, we propose Federated Split-Perturbation Zero-order Optimization\n(FedSPZO) that divides the network into two blocks, applying a different number\nof perturbations per block in a computationally effective way, achieving faster\nconvergence. Our evaluation shows a $2.5 - 7\\times $ reduction in computation\noverhead compared to zero-order state of the art techniques in federated\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10239v1",
    "published_date": "2025-02-14 15:49:02 UTC",
    "updated_date": "2025-02-14 15:49:02 UTC"
  },
  {
    "arxiv_id": "2502.10236v2",
    "title": "Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control",
    "authors": [
      "Thomas Jiralerspong",
      "Berton Earnshaw",
      "Jason Hartford",
      "Yoshua Bengio",
      "Luca Scimeca"
    ],
    "abstract": "Diffusion Probabilistic Models (DPMs) are powerful generative models that\nhave achieved unparalleled success in a number of generative tasks. In this\nwork, we aim to build inductive biases into the training and sampling of\ndiffusion models to better accommodate the target distribution of the data to\nmodel. For topologically structured data, we devise a frequency-based noising\noperator to purposefully manipulate, and set, these inductive biases. We first\nshow that appropriate manipulations of the noising forward process can lead\nDPMs to focus on particular aspects of the distribution to learn. We show that\ndifferent datasets necessitate different inductive biases, and that appropriate\nfrequency-based noise control induces increased generative performance compared\nto standard diffusion. Finally, we demonstrate the possibility of ignoring\ninformation at particular frequencies while learning. We show this in an image\ncorruption and recovery task, where we train a DPM to recover the original\ntarget distribution after severe noise corruption.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as workshop paper at DeLTa and FPI workshops, ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10236v2",
    "published_date": "2025-02-14 15:46:37 UTC",
    "updated_date": "2025-03-12 18:40:15 UTC"
  },
  {
    "arxiv_id": "2502.10226v1",
    "title": "A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation",
    "authors": [
      "Redha Taguelmimt",
      "Samir Aknine",
      "Djamila Boukredera",
      "Narayan Changder",
      "Tuomas Sandholm"
    ],
    "abstract": "Coalition structure generation (CSG), i.e. the problem of optimally\npartitioning a set of agents into coalitions to maximize social welfare, is a\nfundamental computational problem in multiagent systems. This problem is\nimportant for many applications where small run times are necessary, including\ntransportation and disaster response. In this paper, we develop SALDAE, a\nmultiagent path finding algorithm for CSG that operates on a graph of coalition\nstructures. Our algorithm utilizes a variety of heuristics and strategies to\nperform the search and guide it. It is an anytime algorithm that can handle\nlarge problems with hundreds and thousands of agents. We show empirically on\nnine standard value distributions, including disaster response and electric\nvehicle allocation benchmarks, that our algorithm enables a rapid finding of\nhigh-quality solutions and compares favorably with other state-of-the-art\nmethods.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "93A16, 68T01",
      "I.2; F.2"
    ],
    "primary_category": "cs.MA",
    "comment": "Long and updated version to the published paper in the Proceedings of\n  the 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.10226v1",
    "published_date": "2025-02-14 15:21:27 UTC",
    "updated_date": "2025-02-14 15:21:27 UTC"
  },
  {
    "arxiv_id": "2502.10216v1",
    "title": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
    "authors": [
      "Dong Wang",
      "Haris Šikić",
      "Lothar Thiele",
      "Olga Saukh"
    ],
    "abstract": "We introduce model folding, a novel data-free model compression technique\nthat merges structurally similar neurons across layers, significantly reducing\nthe model size without the need for fine-tuning or access to training data.\nUnlike existing methods, model folding preserves data statistics during\ncompression by leveraging k-means clustering, and using novel data-free\ntechniques to prevent variance collapse or explosion. Our theoretical framework\nand experiments across standard benchmarks, including ResNet18 and LLaMA-7B,\ndemonstrate that model folding achieves comparable performance to data-driven\ncompression techniques and outperforms recently proposed data-free methods,\nespecially at high sparsity levels. This approach is particularly effective for\ncompressing large-scale models, making it suitable for deployment in\nresource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by The Thirteenth International\n  Conference on Learning Representations(ICLR), 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10216v1",
    "published_date": "2025-02-14 15:10:43 UTC",
    "updated_date": "2025-02-14 15:10:43 UTC"
  },
  {
    "arxiv_id": "2502.10215v1",
    "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
    "authors": [
      "Hanna M. Dettki",
      "Brenden M. Lake",
      "Charley M. Wu",
      "Bob Rehder"
    ],
    "abstract": "Causal reasoning is a core component of intelligence. Large language models\n(LLMs) have shown impressive capabilities in generating human-like text,\nraising questions about whether their responses reflect true understanding or\nstatistical patterns. We compared causal reasoning in humans and four LLMs\nusing tasks based on collider graphs, rating the likelihood of a query variable\noccurring given evidence from other variables. We find that LLMs reason\ncausally along a spectrum from human-like to normative inference, with\nalignment shifting based on model, context, and task. Overall, GPT-4o and\nClaude showed the most normative behavior, including \"explaining away\", whereas\nGemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected\nindependence of causes - Claude the least - they exhibited strong associative\nreasoning and predictive inference when assessing the likelihood of the effect\ngiven its causes. These findings underscore the need to assess AI biases as\nthey increasingly assist human decision-making.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10215v1",
    "published_date": "2025-02-14 15:09:15 UTC",
    "updated_date": "2025-02-14 15:09:15 UTC"
  },
  {
    "arxiv_id": "2503.05712v1",
    "title": "Automatic Evaluation Metrics for Artificially Generated Scientific Research",
    "authors": [
      "Niklas Höpner",
      "Leon Eshuijs",
      "Dimitrios Alivanistos",
      "Giacomo Zamprogno",
      "Ilaria Tiddi"
    ],
    "abstract": "Foundation models are increasingly used in scientific research, but\nevaluating AI-generated scientific work remains challenging. While expert\nreviews are costly, large language models (LLMs) as proxy reviewers have proven\nto be unreliable. To address this, we investigate two automatic evaluation\nmetrics, specifically citation count prediction and review score prediction. We\nparse all papers of OpenReview and augment each submission with its citation\ncount, reference, and research hypothesis. Our findings reveal that citation\ncount prediction is more viable than review score prediction, and predicting\nscores is more difficult purely from the research hypothesis than from the full\npaper. Furthermore, we show that a simple prediction model based solely on\ntitle and abstract outperforms LLM-based reviewers, though it still falls short\nof human-level consistency.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05712v1",
    "published_date": "2025-02-14 14:56:14 UTC",
    "updated_date": "2025-02-14 14:56:14 UTC"
  },
  {
    "arxiv_id": "2502.10201v1",
    "title": "Prediction hubs are context-informed frequent tokens in LLMs",
    "authors": [
      "Beatrix M. G. Nielsen",
      "Iuri Macocco",
      "Marco Baroni"
    ],
    "abstract": "Hubness, the tendency for few points to be among the nearest neighbours of a\ndisproportionate number of other points, commonly arises when applying standard\ndistance measures to high-dimensional data, often negatively impacting\ndistance-based analysis. As autoregressive large language models (LLMs) operate\non high-dimensional representations, we ask whether they are also affected by\nhubness. We first show, theoretically, that the only representation comparison\noperation performed by LLMs, namely that between context and unembedding\nvectors to determine continuation probabilities, is not characterized by the\nconcentration of distances phenomenon that typically causes the appeareance of\nnuisance hubness. We then empirically show that this comparison still leads to\na high degree of hubness, but the hubs in this case do not constitute a\ndisturbance. They are rather the result of context-modulated frequent tokens\noften appearing in the pool of likely candidates for next token prediction. On\nthe other hand, when other distance computations involving LLM representations\nare performed, we do not have the same theoretical guarantees, and, indeed, we\nsee nuisance hubs appear. In summary, our work highlights, on the one hand, how\nhubness, while omnipresent in high-dimensional spaces, is not always a negative\nproperty that needs to be mitigated, and, on the other hand, it shows that\nvarious widely-used LLMs have developed a guessing strategy that consists in\nconstantly assigning a high probability to frequent tokens.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10201v1",
    "published_date": "2025-02-14 14:52:41 UTC",
    "updated_date": "2025-02-14 14:52:41 UTC"
  },
  {
    "arxiv_id": "2502.10200v1",
    "title": "Dynamic Reinforcement Learning for Actors",
    "authors": [
      "Katsunari Shibata"
    ],
    "abstract": "Dynamic Reinforcement Learning (Dynamic RL), proposed in this paper, directly\ncontrols system dynamics, instead of the actor (action-generating neural\nnetwork) outputs at each moment, bringing about a major qualitative shift in\nreinforcement learning (RL) from static to dynamic. The actor is initially\ndesigned to generate chaotic dynamics through the loop with its environment,\nenabling the agent to perform flexible and deterministic exploration. Dynamic\nRL controls global system dynamics using a local index called \"sensitivity,\"\nwhich indicates how much the input neighborhood contracts or expands into the\ncorresponding output neighborhood through each neuron's processing. While\nsensitivity adjustment learning (SAL) prevents excessive convergence of the\ndynamics, sensitivity-controlled reinforcement learning (SRL) adjusts them --\nto converge more to improve reproducibility around better state transitions\nwith positive TD error and to diverge more to enhance exploration around worse\ntransitions with negative TD error. Dynamic RL was applied only to the actor in\nan Actor-Critic RL architecture while applying it to the critic remains a\nchallenge. It was tested on two dynamic tasks and functioned effectively\nwithout external exploration noise or backward computation through time.\nMoreover, it exhibited excellent adaptability to new environments, although\nsome problems remain. Drawing parallels between 'exploration' and 'thinking,'\nthe author hypothesizes that \"exploration grows into thinking through learning\"\nand believes this RL could be a key technique for the emergence of thinking,\nincluding inspiration that cannot be reconstructed from massive existing text\ndata. Finally, despite being presumptuous, the author presents the argument\nthat this research should not proceed due to its potentially fatal risks,\naiming to encourage discussion.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10200v1",
    "published_date": "2025-02-14 14:50:05 UTC",
    "updated_date": "2025-02-14 14:50:05 UTC"
  },
  {
    "arxiv_id": "2502.10197v1",
    "title": "MathConstruct: Challenging LLM Reasoning with Constructive Proofs",
    "authors": [
      "Mislav Balunović",
      "Jasper Dekoninck",
      "Nikola Jovanović",
      "Ivo Petrov",
      "Martin Vechev"
    ],
    "abstract": "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10197v1",
    "published_date": "2025-02-14 14:44:22 UTC",
    "updated_date": "2025-02-14 14:44:22 UTC"
  },
  {
    "arxiv_id": "2502.10195v1",
    "title": "Exploring the Camera Bias of Person Re-identification",
    "authors": [
      "Myungseo Song",
      "Jin-Woo Park",
      "Jong-Seok Lee"
    ],
    "abstract": "We empirically investigate the camera bias of person re-identification (ReID)\nmodels. Previously, camera-aware methods have been proposed to address this\nissue, but they are largely confined to training domains of the models. We\nmeasure the camera bias of ReID models on unseen domains and reveal that camera\nbias becomes more pronounced under data distribution shifts. As a debiasing\nmethod for unseen domain data, we revisit feature normalization on embedding\nvectors. While the normalization has been used as a straightforward solution,\nits underlying causes and broader applicability remain unexplored. We analyze\nwhy this simple method is effective at reducing bias and show that it can be\napplied to detailed bias factors such as low-level image properties and body\nangle. Furthermore, we validate its generalizability across various models and\nbenchmarks, highlighting its potential as a simple yet effective test-time\npostprocessing method for ReID. In addition, we explore the inherent risk of\ncamera bias in unsupervised learning of ReID models. The unsupervised models\nremain highly biased towards camera labels even for seen domain data,\nindicating substantial room for improvement. Based on observations of the\nnegative impact of camera-biased pseudo labels on training, we suggest simple\ntraining strategies to mitigate the bias. By applying these strategies to\nexisting unsupervised learning algorithms, we show that significant performance\nimprovements can be achieved with minor modifications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2502.10195v1",
    "published_date": "2025-02-14 14:39:24 UTC",
    "updated_date": "2025-02-14 14:39:24 UTC"
  },
  {
    "arxiv_id": "2502.10193v1",
    "title": "Merging public elementary schools to reduce racial/ethnic segregation",
    "authors": [
      "Madison Landry",
      "Nabeel Gillani"
    ],
    "abstract": "Diverse schools can help address implicit biases and increase empathy, mutual\nrespect, and reflective thought by fostering connections between students from\ndifferent racial/ethnic, socioeconomic, and other backgrounds. Unfortunately,\ndemographic segregation remains rampant in US public schools, despite over 70\nyears since the passing of federal legislation formally outlawing segregation\nby race. However, changing how students are assigned to schools can help foster\nmore integrated learning environments. In this paper, we explore \"school\nmergers\" as one such under-explored, yet promising, student assignment policy\nchange. School mergers involve merging the school attendance boundaries, or\ncatchment areas, of schools and subsequently changing the grades each school\noffers. We develop an algorithm to simulate elementary school mergers across\n200 large school districts serving 4.5 million elementary school students and\nfind that pairing or tripling schools in this way could reduce racial/ethnic\nsegregation by a median relative 20% -- and as much as nearly 60% in some\ndistricts -- while increasing driving times to schools by an average of a few\nminutes each way. Districts with many interfaces between\nracially/ethnically-disparate neighborhoods tend to be prime candidates for\nmergers. We also compare the expected results of school mergers to other\ntypical integration policies, like redistricting, and find that different\npolicies may be more or less suitable in different places. Finally, we make our\nresults available through a public dashboard for policymakers and community\nmembers to explore further (https://mergers.schooldiversity.org). Together, our\nstudy offers new findings and tools to support integration policy-making across\nUS public school districts.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Forthcoming in PNAS Nexus",
    "pdf_url": "http://arxiv.org/pdf/2502.10193v1",
    "published_date": "2025-02-14 14:36:28 UTC",
    "updated_date": "2025-02-14 14:36:28 UTC"
  },
  {
    "arxiv_id": "2502.10178v1",
    "title": "From Markov to Laplace: How Mamba In-Context Learns Markov Chains",
    "authors": [
      "Marco Bondaschi",
      "Nived Rajaraman",
      "Xiuying Wei",
      "Kannan Ramchandran",
      "Razvan Pascanu",
      "Caglar Gulcehre",
      "Michael Gastpar",
      "Ashok Vardhan Makkuva"
    ],
    "abstract": "While transformer-based language models have driven the AI revolution thus\nfar, their computational complexity has spurred growing interest in viable\nalternatives, such as structured state space sequence models (SSMs) and\nSelective SSMs. Among these, Mamba (S6) and its variant Mamba-2 have shown\nremarkable inference speed ups over transformers while achieving comparable or\nsuperior performance on complex language modeling tasks. However, despite these\narchitectural innovations and empirical successes, the fundamental learning\ncapabilities of Mamba remain poorly understood. In this paper, we address this\ngap by studying in-context learning (ICL) on Markov chains and uncovering a\nsurprising phenomenon: unlike transformers, even a single-layer Mamba\nefficiently learns the in-context Laplacian smoothing estimator, which is both\nBayes and minimax optimal, for all Markovian orders. To explain this, we\ntheoretically characterize the representation capacity of Mamba and reveal the\nfundamental role of convolution in enabling it to represent the optimal\nLaplacian smoothing. These theoretical insights align strongly with empirical\nresults and, to the best of our knowledge, represent the first formal\nconnection between Mamba and optimal statistical estimators. Finally, we\noutline promising research directions inspired by these findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10178v1",
    "published_date": "2025-02-14 14:13:55 UTC",
    "updated_date": "2025-02-14 14:13:55 UTC"
  },
  {
    "arxiv_id": "2502.10177v2",
    "title": "STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning",
    "authors": [
      "Mingcong Lei",
      "Yiming Zhao",
      "Ge Wang",
      "Zhixin Mai",
      "Shuguang Cui",
      "Yatong Han",
      "Jinke Ren"
    ],
    "abstract": "A key objective of embodied intelligence is enabling agents to perform\nlong-horizon tasks in dynamic environments while maintaining robust\ndecision-making and adaptability. To achieve this goal, we propose the\nSpatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task\nplanning and execution by integrating spatio-temporal memory. STMA is built\nupon three critical components: (1) a spatio-temporal memory module that\ncaptures historical and environmental changes in real time, (2) a dynamic\nknowledge graph that facilitates adaptive spatial reasoning, and (3) a\nplanner-critic mechanism that iteratively refines task strategies. We evaluate\nSTMA in the TextWorld environment on 32 tasks, involving multi-step planning\nand exploration under varying levels of complexity. Experimental results\ndemonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%\nincrease in average score compared to the state-of-the-art model. The results\nhighlight the effectiveness of spatio-temporal memory in advancing the memory\ncapabilities of embodied agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10177v2",
    "published_date": "2025-02-14 14:12:09 UTC",
    "updated_date": "2025-03-02 08:14:27 UTC"
  },
  {
    "arxiv_id": "2502.10174v1",
    "title": "Technical Risks of (Lethal) Autonomous Weapons Systems",
    "authors": [
      "Heramb Podar",
      "Alycia Colijn"
    ],
    "abstract": "The autonomy and adaptability of (Lethal) Autonomous Weapons Systems, (L)AWS\nin short, promise unprecedented operational capabilities, but they also\nintroduce profound risks that challenge the principles of control,\naccountability, and stability in international security. This report outlines\nthe key technological risks associated with (L)AWS deployment, emphasizing\ntheir unpredictability, lack of transparency, and operational unreliability,\nwhich can lead to severe unintended consequences.\n  Key Takeaways:\n  1. Proposed advantages of (L)AWS can only be achieved through objectification\nand classification, but a range of systematic risks limit the reliability and\npredictability of classifying algorithms.\n  2. These systematic risks include the black-box nature of AI decision-making,\nsusceptibility to reward hacking, goal misgeneralization and potential for\nemergent behaviors that escape human control.\n  3. (L)AWS could act in ways that are not just unexpected but also\nuncontrollable, undermining mission objectives and potentially escalating\nconflicts.\n  4. Even rigorously tested systems may behave unpredictably and harmfully in\nreal-world conditions, jeopardizing both strategic stability and humanitarian\nprinciples.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10174v1",
    "published_date": "2025-02-14 14:09:43 UTC",
    "updated_date": "2025-02-14 14:09:43 UTC"
  },
  {
    "arxiv_id": "2502.10162v1",
    "title": "Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions",
    "authors": [
      "Lei Cheng",
      "Junpeng Zhang",
      "Qihan Ren",
      "Quanshi Zhang"
    ],
    "abstract": "This paper aims to analyze the generalization power of deep neural networks\n(DNNs) from the perspective of interactions. Unlike previous analysis of a\nDNN's generalization power in a highdimensional feature space, we find that the\ngeneralization power of a DNN can be explained as the generalization power of\nthe interactions. We found that the generalizable interactions follow a\ndecay-shaped distribution, while non-generalizable interactions follow a\nspindle-shaped distribution. Furthermore, our theory can effectively\ndisentangle these two types of interactions from a DNN. We have verified that\nour theory can well match real interactions in a DNN in experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2407.19198",
    "pdf_url": "http://arxiv.org/pdf/2502.10162v1",
    "published_date": "2025-02-14 13:46:14 UTC",
    "updated_date": "2025-02-14 13:46:14 UTC"
  },
  {
    "arxiv_id": "2502.10157v2",
    "title": "SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation",
    "authors": [
      "Lei Huang",
      "Hao Guo",
      "Linzhi Peng",
      "Long Zhang",
      "Xiaoteng Wang",
      "Daoyuan Wang",
      "Shichao Wang",
      "Jinpeng Wang",
      "Lei Wang",
      "Sheng Chen"
    ],
    "abstract": "We introduce SessionRec, a novel next-session prediction paradigm (NSPP) for\ngenerative sequential recommendation, addressing the fundamental misalignment\nbetween conventional next-item prediction paradigm (NIPP) and real-world\nrecommendation scenarios. Unlike NIPP's item-level autoregressive generation\nthat contradicts actual session-based user interactions, our framework\nintroduces a session-aware representation learning through hierarchical\nsequence aggregation (intra/inter-session), reducing attention computation\ncomplexity while enabling implicit modeling of massive negative interactions,\nand a session-based prediction objective that better captures users' diverse\ninterests through multi-item recommendation in next sessions. Moreover, we\nfound that incorporating a rank loss for items within the session under the\nnext session prediction paradigm can significantly improve the ranking\neffectiveness of generative sequence recommendation models. We also verified\nthat SessionRec exhibits clear power-law scaling laws similar to those observed\nin LLMs. Extensive experiments conducted on public datasets and online A/B test\nin Meituan App demonstrate the effectiveness of SessionRec. The proposed\nparadigm establishes new foundations for developing industrial-scale generative\nrecommendation systems through its model-agnostic architecture and\ncomputational efficiency.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10157v2",
    "published_date": "2025-02-14 13:36:20 UTC",
    "updated_date": "2025-02-18 02:41:53 UTC"
  },
  {
    "arxiv_id": "2502.10154v1",
    "title": "Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries",
    "authors": [
      "Serkan Sulun",
      "Paula Viana",
      "Matthew E. P. Davies"
    ],
    "abstract": "We introduce EMSYNC, a video-based symbolic music generation model that\naligns music with a video's emotional content and temporal boundaries. It\nfollows a two-stage framework, where a pretrained video emotion classifier\nextracts emotional features, and a conditional music generator produces MIDI\nsequences guided by both emotional and temporal cues. We introduce boundary\noffsets, a novel temporal conditioning mechanism that enables the model to\nanticipate and align musical chords with scene cuts. Unlike existing models,\nour approach retains event-based encoding, ensuring fine-grained timing control\nand expressive musical nuances. We also propose a mapping scheme to bridge the\nvideo emotion classifier, which produces discrete emotion categories, with the\nemotion-conditioned MIDI generator, which operates on continuous-valued\nvalence-arousal inputs. In subjective listening tests, EMSYNC outperforms\nstate-of-the-art models across all subjective metrics, for music theory-aware\nparticipants as well as the general listeners.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS",
      "eess.IV"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to International Joint Conference on Artificial\n  Intelligence (IJCAI) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10154v1",
    "published_date": "2025-02-14 13:32:59 UTC",
    "updated_date": "2025-02-14 13:32:59 UTC"
  },
  {
    "arxiv_id": "2502.10148v2",
    "title": "Cooperative Multi-Agent Planning with Adaptive Skill Synthesis",
    "authors": [
      "Zhiyuan Li",
      "Wenshuai Zhao",
      "Joni Pajarinen"
    ],
    "abstract": "Despite much progress in training distributed artificial intelligence (AI),\nbuilding cooperative multi-agent systems with multi-agent reinforcement\nlearning (MARL) faces challenges in sample efficiency, interpretability, and\ntransferability. Unlike traditional learning-based methods that require\nextensive interaction with the environment, large language models (LLMs)\ndemonstrate remarkable capabilities in zero-shot planning and complex\nreasoning. However, existing LLM-based approaches heavily rely on text-based\nobservations and struggle with the non-Markovian nature of multi-agent\ninteractions under partial observability. We present COMPASS, a novel\nmulti-agent architecture that integrates vision-language models (VLMs) with a\ndynamic skill library and structured communication for decentralized\nclosed-loop decision-making. The skill library, bootstrapped from\ndemonstrations, evolves via planner-guided tasks to enable adaptive strategies.\nCOMPASS propagates entity information through multi-hop communication under\npartial observability. Evaluations on the improved StarCraft Multi-Agent\nChallenge (SMACv2) demonstrate COMPASS's strong performance against\nstate-of-the-art MARL baselines across both symmetric and asymmetric scenarios.\nNotably, in the symmetric Protoss 5v5 task, COMPASS achieved a 57\\% win rate,\nrepresenting a 30 percentage point advantage over QMIX (27\\%). Project page can\nbe found at https://stellar-entremet-1720bb.netlify.app/.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10148v2",
    "published_date": "2025-02-14 13:23:18 UTC",
    "updated_date": "2025-05-06 11:03:22 UTC"
  },
  {
    "arxiv_id": "2502.10491v1",
    "title": "F-StrIPE: Fast Structure-Informed Positional Encoding for Symbolic Music Generation",
    "authors": [
      "Manvi Agarwal",
      "Changhong Wang",
      "Gael Richard"
    ],
    "abstract": "While music remains a challenging domain for generative models like\nTransformers, recent progress has been made by exploiting suitable\nmusically-informed priors. One technique to leverage information about musical\nstructure in Transformers is inserting such knowledge into the positional\nencoding (PE) module. However, Transformers carry a quadratic cost in sequence\nlength. In this paper, we propose F-StrIPE, a structure-informed PE scheme that\nworks in linear complexity. Using existing kernel approximation techniques\nbased on random features, we show that F-StrIPE is a generalization of\nStochastic Positional Encoding (SPE). We illustrate the empirical merits of\nF-StrIPE using melody harmonization for symbolic music.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10491v1",
    "published_date": "2025-02-14 13:15:18 UTC",
    "updated_date": "2025-02-14 13:15:18 UTC"
  },
  {
    "arxiv_id": "2502.10490v1",
    "title": "A Robust Attack: Displacement Backdoor Attack",
    "authors": [
      "Yong Li",
      "Han Gao"
    ],
    "abstract": "As artificial intelligence becomes more prevalent in our lives, people are\nenjoying the convenience it brings, but they are also facing hidden threats,\nsuch as data poisoning and adversarial attacks. These threats can have\ndisastrous consequences for the application of artificial intelligence,\nespecially for some applications that take effect immediately, such as\nautonomous driving and medical fields. Among these threats, backdoor attacks\nhave left a deep impression on people with their concealment and simple\ndeployment, making them a threat that cannot be ignored, however, in the\nprocess of deploying the backdoor model, the backdoor attack often has some\nreasons that make it unsatisfactory in real-world applications, such as jitter\nand brightness changes. Based on this, we propose a highly robust backdoor\nattack that shifts the target sample and combines it with itself to form a\nbackdoor sample, the Displacement Backdoor Attack(DBA). Experimental results\nshow that the DBA attack can resist data augmentation that simulates real-world\ndifferences, such as rotation and cropping.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "64",
      "J.0"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2405.16488",
    "pdf_url": "http://arxiv.org/pdf/2502.10490v1",
    "published_date": "2025-02-14 13:15:13 UTC",
    "updated_date": "2025-02-14 13:15:13 UTC"
  },
  {
    "arxiv_id": "2502.10125v1",
    "title": "Learning Relational Tabular Data without Shared Features",
    "authors": [
      "Zhaomin Wu",
      "Shida Wang",
      "Ziyang Wang",
      "Bingsheng He"
    ],
    "abstract": "Learning relational tabular data has gained significant attention recently,\nbut most studies focus on single tables, overlooking the potential of\ncross-table learning. Cross-table learning, especially in scenarios where\ntables lack shared features and pre-aligned data, offers vast opportunities but\nalso introduces substantial challenges. The alignment space is immense, and\ndetermining accurate alignments between tables is highly complex. We propose\nLatent Entity Alignment Learning (Leal), a novel framework enabling effective\ncross-table training without requiring shared features or pre-aligned data.\nLeal operates on the principle that properly aligned data yield lower loss than\nmisaligned data, a concept embodied in its soft alignment mechanism. This\nmechanism is coupled with a differentiable cluster sampler module, ensuring\nefficient scaling to large relational tables. Furthermore, we provide a\ntheoretical proof of the cluster sampler's approximation capacity. Extensive\nexperiments on five real-world and five synthetic datasets show that Leal\nachieves up to a 26.8% improvement in predictive performance compared to\nstate-of-the-art methods, demonstrating its effectiveness and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10125v1",
    "published_date": "2025-02-14 12:51:07 UTC",
    "updated_date": "2025-02-14 12:51:07 UTC"
  },
  {
    "arxiv_id": "2502.10489v1",
    "title": "LiveVal: Time-aware Data Valuation via Adaptive Reference Points",
    "authors": [
      "Jie Xu",
      "Zihan Wu",
      "Cong Wang",
      "Xiaohua Jia"
    ],
    "abstract": "Time-aware data valuation enhances training efficiency and model robustness,\nas early detection of harmful samples could prevent months of wasted\ncomputation. However, existing methods rely on model retraining or convergence\nassumptions or fail to capture long-term training dynamics.\n  We propose LiveVal, an efficient time-aware data valuation method with three\nkey designs:\n  1) seamless integration with SGD training for efficient data contribution\nmonitoring; 2) reference-based valuation with normalization for reliable\nbenchmark establishment; and 3) adaptive reference point selection for\nreal-time updating with optimized memory usage.\n  We establish theoretical guarantees for LiveVal's stability and prove that\nits valuations are bounded and directionally aligned with optimization\nprogress. Extensive experiments demonstrate that LiveVal provides efficient\ndata valuation across different modalities and model scales, achieving 180\nspeedup over traditional methods while maintaining robust detection\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10489v1",
    "published_date": "2025-02-14 12:41:20 UTC",
    "updated_date": "2025-02-14 12:41:20 UTC"
  },
  {
    "arxiv_id": "2502.10118v1",
    "title": "Image Embedding Sampling Method for Diverse Captioning",
    "authors": [
      "Sania Waheed",
      "Na Min An"
    ],
    "abstract": "Image Captioning for state-of-the-art VLMs has significantly improved over\ntime; however, this comes at the cost of increased computational complexity,\nmaking them less accessible for resource-constrained applications such as\nmobile devices and assistive technologies. Alternatively, smaller VLMs\nprioritize high-level scene descriptions, overlooking finer details that\ncontribute to a richer understanding of an image. In this paper, we introduce a\ntraining-free framework that enhances caption diversity and informativeness by\nexplicitly attending to distinct image regions using a comparably small VLM,\nBLIP, as the backbone. Our approach leverages structured segmentation to\nproduce hierarchical representations that capture both global and localized\nsemantics. Without requiring additional model training, we demonstrate that our\nmethod allows smaller VLMs to achieve performance comparable to larger models\nin terms of image-caption alignment, semantic integrity, and diversity. We\nevaluate our framework on MSCOCO, Flickr30k, and Nocaps test datasets,\nachieving a Div-2 score of 0.735, 0.750, and 0.748 for each dataset\nrespectively, while maintaining strong image-caption relevancy and semantic\nintegrity with the human-annotated captions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.10118v1",
    "published_date": "2025-02-14 12:33:19 UTC",
    "updated_date": "2025-02-14 12:33:19 UTC"
  },
  {
    "arxiv_id": "2502.12181v3",
    "title": "3D ReX: Causal Explanations in 3D Neuroimaging Classification",
    "authors": [
      "Melane Navaratnarajah",
      "Sophie A. Martin",
      "David A. Kelly",
      "Nathan Blake",
      "Hana Chockler"
    ],
    "abstract": "Explainability remains a significant problem for AI models in medical\nimaging, making it challenging for clinicians to trust AI-driven predictions.\nWe introduce 3D ReX, the first causality-based post-hoc explainability tool for\n3D models. 3D ReX uses the theory of actual causality to generate\nresponsibility maps which highlight the regions most crucial to the model's\ndecision. We test 3D ReX on a stroke detection model, providing insight into\nthe spatial distribution of features relevant to stroke.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Presented in the 2nd Workshop on Imageomics (Imageomics-AAAI-25),\n  Discovering Biological Knowledge from Images using AI, held as part of\n  AAAI-2025",
    "pdf_url": "http://arxiv.org/pdf/2502.12181v3",
    "published_date": "2025-02-14 12:10:07 UTC",
    "updated_date": "2025-04-29 14:51:22 UTC"
  },
  {
    "arxiv_id": "2502.10097v1",
    "title": "Causal Information Prioritization for Efficient Reinforcement Learning",
    "authors": [
      "Hongye Cao",
      "Fan Feng",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao"
    ],
    "abstract": "Current Reinforcement Learning (RL) methods often suffer from\nsample-inefficiency, resulting from blind exploration strategies that neglect\ncausal relationships among states, actions, and rewards. Although recent causal\napproaches aim to address this problem, they lack grounded modeling of\nreward-guided causal understanding of states and actions for goal-orientation,\nthus impairing learning efficiency. To tackle this issue, we propose a novel\nmethod named Causal Information Prioritization (CIP) that improves sample\nefficiency by leveraging factored MDPs to infer causal relationships between\ndifferent dimensions of states and actions with respect to rewards, enabling\nthe prioritization of causal information. Specifically, CIP identifies and\nleverages causal relationships between states and rewards to execute\ncounterfactual data augmentation to prioritize high-impact state features under\nthe causal understanding of the environments. Moreover, CIP integrates a\ncausality-aware empowerment learning objective, which significantly enhances\nthe agent's execution of reward-guided actions for more efficient exploration\nin complex environments. To fully assess the effectiveness of CIP, we conduct\nextensive experiments across 39 tasks in 5 diverse continuous control\nenvironments, encompassing both locomotion and manipulation skills learning\nwith pixel-based and sparse reward settings. Experimental results demonstrate\nthat CIP consistently outperforms existing RL methods across a wide range of\nscenarios.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10097v1",
    "published_date": "2025-02-14 11:44:17 UTC",
    "updated_date": "2025-02-14 11:44:17 UTC"
  },
  {
    "arxiv_id": "2502.10092v1",
    "title": "A novel approach to data generation in generative model",
    "authors": [
      "JaeHong Kim",
      "Jaewon Shim"
    ],
    "abstract": "Variational Autoencoders (VAEs) and other generative models are widely\nemployed in artificial intelligence to synthesize new data. However, current\napproaches rely on Euclidean geometric assumptions and statistical\napproximations that fail to capture the structured and emergent nature of data\ngeneration. This paper introduces the Convergent Fusion Paradigm (CFP) theory,\na novel geometric framework that redefines data generation by integrating\ndimensional expansion accompanied by qualitative transformation. By modifying\nthe latent space geometry to interact with emergent high-dimensional\nstructures, CFP theory addresses key challenges such as identifiability issues\nand unintended artifacts like hallucinations in Large Language Models (LLMs).\nCFP theory is based on two key conceptual hypotheses that redefine how\ngenerative models structure relationships between data and algorithms. Through\nthe lens of CFP theory, we critically examine existing metric-learning\napproaches. CFP theory advances this perspective by introducing time-reversed\nmetric embeddings and structural convergence mechanisms, leading to a novel\ngeometric approach that better accounts for data generation as a structured\nepistemic process. Beyond its computational implications, CFP theory provides\nphilosophical insights into the ontological underpinnings of data generation.\nBy offering a systematic framework for high-dimensional learning dynamics, CFP\ntheory contributes to establishing a theoretical foundation for understanding\nthe data-relationship structures in AI. Finally, future research in CFP theory\nwill be led to its implications for fully realizing qualitative\ntransformations, introducing the potential of Hilbert space in generative\nmodeling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "00A30 (Primary), 68T99 (Secondary)",
      "I.2.3; F.4.1"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 2 tables, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10092v1",
    "published_date": "2025-02-14 11:27:02 UTC",
    "updated_date": "2025-02-14 11:27:02 UTC"
  },
  {
    "arxiv_id": "2502.10090v1",
    "title": "Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models",
    "authors": [
      "Chenrui Tie",
      "Shengxiang Sun",
      "Jinxuan Zhu",
      "Yiwei Liu",
      "Jingxiang Guo",
      "Yue Hu",
      "Haonan Chen",
      "Junting Chen",
      "Ruihai Wu",
      "Lin Shao"
    ],
    "abstract": "Humans possess an extraordinary ability to understand and execute complex\nmanipulation tasks by interpreting abstract instruction manuals. For robots,\nhowever, this capability remains a substantial challenge, as they cannot\ninterpret abstract instructions and translate them into executable actions. In\nthis paper, we present Manual2Skill, a novel framework that enables robots to\nperform complex assembly tasks guided by high-level manual instructions. Our\napproach leverages a Vision-Language Model (VLM) to extract structured\ninformation from instructional images and then uses this information to\nconstruct hierarchical assembly graphs. These graphs represent parts,\nsubassemblies, and the relationships between them. To facilitate task\nexecution, a pose estimation model predicts the relative 6D poses of components\nat each assembly step. At the same time, a motion planning module generates\nactionable sequences for real-world robotic implementation. We demonstrate the\neffectiveness of Manual2Skill by successfully assembling several real-world\nIKEA furniture items. This application highlights its ability to manage\nlong-horizon manipulation tasks with both efficiency and precision,\nsignificantly enhancing the practicality of robot learning from instruction\nmanuals. This work marks a step forward in advancing robotic systems capable of\nunderstanding and executing complex manipulation tasks in a manner akin to\nhuman capabilities.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10090v1",
    "published_date": "2025-02-14 11:25:24 UTC",
    "updated_date": "2025-02-14 11:25:24 UTC"
  },
  {
    "arxiv_id": "2502.10089v1",
    "title": "A Hybrid Edge Classifier: Combining TinyML-Optimised CNN with RRAM-CMOS ACAM for Energy-Efficient Inference",
    "authors": [
      "Kieran Woodward",
      "Eiman Kanjo",
      "Georgios Papandroulidakis",
      "Shady Agwa",
      "Themis Prodromakis"
    ],
    "abstract": "In recent years, the development of smart edge computing systems to process\ninformation locally is on the rise. Many near-sensor machine learning (ML)\napproaches have been implemented to introduce accurate and energy efficient\ntemplate matching operations in resource-constrained edge sensing systems, such\nas wearables. To introduce novel solutions that can be viable for extreme edge\ncases, hybrid solutions combining conventional and emerging technologies have\nstarted to be proposed. Deep Neural Networks (DNN) optimised for edge\napplication alongside new approaches of computing (both device and architecture\n-wise) could be a strong candidate in implementing edge ML solutions that aim\nat competitive accuracy classification while using a fraction of the power of\nconventional ML solutions. In this work, we are proposing a hybrid\nsoftware-hardware edge classifier aimed at the extreme edge near-sensor\nsystems. The classifier consists of two parts: (i) an optimised digital tinyML\nnetwork, working as a front-end feature extractor, and (ii) a back-end\nRRAM-CMOS analogue content addressable memory (ACAM), working as a final stage\ntemplate matching system. The combined hybrid system exhibits a competitive\ntrade-off in accuracy versus energy metric with $E_{front-end}$ = $96.23 nJ$\nand $E_{back-end}$ = $1.45 nJ$ for each classification operation compared with\n78.06$\\mu$J for the original teacher model, representing a 792-fold reduction,\nmaking it a viable solution for extreme edge applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10089v1",
    "published_date": "2025-02-14 11:21:36 UTC",
    "updated_date": "2025-02-14 11:21:36 UTC"
  },
  {
    "arxiv_id": "2502.10487v1",
    "title": "Fast Proxies for LLM Robustness Evaluation",
    "authors": [
      "Tim Beyer",
      "Jan Schuchardt",
      "Leo Schwinn",
      "Stephan Günnemann"
    ],
    "abstract": "Evaluating the robustness of LLMs to adversarial attacks is crucial for safe\ndeployment, yet current red-teaming methods are often prohibitively expensive.\nWe compare the ability of fast proxy metrics to predict the real-world\nrobustness of an LLM against a simulated attacker ensemble. This allows us to\nestimate a model's robustness to computationally expensive attacks without\nrequiring runs of the attacks themselves. Specifically, we consider\ngradient-descent-based embedding-space attacks, prefilling attacks, and direct\nprompting. Even though direct prompting in particular does not achieve high\nASR, we find that it and embedding-space attacks can predict attack success\nrates well, achieving $r_p=0.87$ (linear) and $r_s=0.94$ (Spearman rank)\ncorrelations with the full attack ensemble while reducing computational cost by\nthree orders of magnitude.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10487v1",
    "published_date": "2025-02-14 11:15:27 UTC",
    "updated_date": "2025-02-14 11:15:27 UTC"
  },
  {
    "arxiv_id": "2502.10077v1",
    "title": "Towards Empowerment Gain through Causal Structure Learning in Model-Based RL",
    "authors": [
      "Hongye Cao",
      "Fan Feng",
      "Meng Fang",
      "Shaokang Dong",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao"
    ],
    "abstract": "In Model-Based Reinforcement Learning (MBRL), incorporating causal structures\ninto dynamics models provides agents with a structured understanding of the\nenvironments, enabling efficient decision. Empowerment as an intrinsic\nmotivation enhances the ability of agents to actively control their\nenvironments by maximizing the mutual information between future states and\nactions. We posit that empowerment coupled with causal understanding can\nimprove controllability, while enhanced empowerment gain can further facilitate\ncausal reasoning in MBRL. To improve learning efficiency and controllability,\nwe propose a novel framework, Empowerment through Causal Learning (ECL), where\nan agent with the awareness of causal dynamics models achieves\nempowerment-driven exploration and optimizes its causal structure for task\nlearning. Specifically, ECL operates by first training a causal dynamics model\nof the environment based on collected data. We then maximize empowerment under\nthe causal structure for exploration, simultaneously using data gathered\nthrough exploration to update causal dynamics model to be more controllable\nthan dense dynamics model without causal structure. In downstream task\nlearning, an intrinsic curiosity reward is included to balance the causality,\nmitigating overfitting. Importantly, ECL is method-agnostic and is capable of\nintegrating various causal discovery methods. We evaluate ECL combined with 3\ncausal discovery methods across 6 environments including pixel-based tasks,\ndemonstrating its superior performance compared to other causal MBRL methods,\nin terms of causal discovery, sample efficiency, and asymptotic performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10077v1",
    "published_date": "2025-02-14 10:59:09 UTC",
    "updated_date": "2025-02-14 10:59:09 UTC"
  },
  {
    "arxiv_id": "2502.10063v1",
    "title": "Strassen Multisystolic Array Hardware Architectures",
    "authors": [
      "Trevor E. Pogue",
      "Nicola Nicolici"
    ],
    "abstract": "While Strassen's matrix multiplication algorithm reduces the complexity of\nnaive matrix multiplication, general-purpose hardware is not suitable for\nachieving the algorithm's promised theoretical speedups. This leaves the\nquestion of if it could be better exploited in custom hardware architectures\ndesigned specifically for executing the algorithm. However, there is limited\nprior work on this and it is not immediately clear how to derive such\narchitectures or if they can ultimately lead to real improvements. We bridge\nthis gap, presenting and evaluating new systolic array architectures that\nefficiently translate the theoretical complexity reductions of Strassen's\nalgorithm directly into hardware resource savings. Furthermore, the\narchitectures are multisystolic array designs that can multiply smaller\nmatrices with higher utilization than single-systolic array designs. The\nproposed designs implemented on FPGA reduce DSP requirements by a factor of\n$1.14^r$ for $r$ implemented Strassen recursion levels, and otherwise require\noverall similar soft logic resources when instantiated to support matrix sizes\ndown to 32x32 and 24x24 at 1-2 levels of Strassen recursion, respectively. We\nevaluate the proposed designs both in isolation and in an end-to-end machine\nlearning accelerator compared to baseline designs and prior works, achieving\nstate-of-the-art performance.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted for publication in IEEE Transactions on Very Large Scale\n  Integration (VLSI) Systems; Associated source code available on GitHub at\n  https://github.com/trevorpogue/algebraic-nnhw",
    "pdf_url": "http://arxiv.org/pdf/2502.10063v1",
    "published_date": "2025-02-14 10:40:32 UTC",
    "updated_date": "2025-02-14 10:40:32 UTC"
  },
  {
    "arxiv_id": "2502.10062v1",
    "title": "Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints",
    "authors": [
      "Xiaoshan Lin",
      "Roberto Tron"
    ],
    "abstract": "This work addresses the problem of multi-robot coordination under unknown\nrobot transition models, ensuring that tasks specified by Time Window Temporal\nLogic are satisfied with user-defined probability thresholds. We present a\nbi-level framework that integrates (i) high-level task allocation, where tasks\nare assigned based on the robots' estimated task completion probabilities and\nexpected rewards, and (ii) low-level distributed policy learning and execution,\nwhere robots independently optimize auxiliary rewards while fulfilling their\nassigned tasks. To handle uncertainty in robot dynamics, our approach leverages\nreal-time task execution data to iteratively refine expected task completion\nprobabilities and rewards, enabling adaptive task allocation without explicit\nrobot transition models. We theoretically validate the proposed algorithm,\ndemonstrating that the task assignments meet the desired probability thresholds\nwith high confidence. Finally, we demonstrate the effectiveness of our\nframework through comprehensive simulations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted as a full paper at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10062v1",
    "published_date": "2025-02-14 10:39:21 UTC",
    "updated_date": "2025-02-14 10:39:21 UTC"
  },
  {
    "arxiv_id": "2503.05711v1",
    "title": "Labeling Synthetic Content: User Perceptions of Warning Label Designs for AI-generated Content on Social Media",
    "authors": [
      "Dilrukshi Gamage",
      "Dilki Sewwandi",
      "Min Zhang",
      "Arosha Bandara"
    ],
    "abstract": "In this research, we explored the efficacy of various warning label designs\nfor AI-generated content on social media platforms e.g., deepfakes. We devised\nand assessed ten distinct label design samples that varied across the\ndimensions of sentiment, color/iconography, positioning, and level of detail.\nOur experimental study involved 911 participants randomly assigned to these ten\nlabel designs and a control group evaluating social media content. We explored\ntheir perceptions relating to 1. Belief in the content being AI-generated, 2.\nTrust in the labels and 3. Social Media engagement perceptions of the content.\nThe results demonstrate that the presence of labels had a significant effect on\nthe users belief that the content is AI generated, deepfake, or edited by AI.\nHowever their trust in the label significantly varied based on the label\ndesign. Notably, having labels did not significantly change their engagement\nbehaviors, such as like, comment, and sharing. However, there were significant\ndifferences in engagement based on content type: political and entertainment.\nThis investigation contributes to the field of human computer interaction by\ndefining a design space for label implementation and providing empirical\nsupport for the strategic use of labels to mitigate the risks associated with\nsynthetically generated media.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "H.4.0; J.7; H.5.1"
    ],
    "primary_category": "cs.HC",
    "comment": "This is a pre print longer version of a paper accepted to CHI 2025;\n  after rebuttal we had to short the paper to 25 pages. Currently its in\n  overleaf manuscript format with one column. All data for the file is in the\n  osf link",
    "pdf_url": "http://arxiv.org/pdf/2503.05711v1",
    "published_date": "2025-02-14 10:35:42 UTC",
    "updated_date": "2025-02-14 10:35:42 UTC"
  },
  {
    "arxiv_id": "2503.16442v1",
    "title": "Situational Agency: The Framework for Designing Behavior in Agent-based art",
    "authors": [
      "Ary-Yue Huang",
      "Varvara Guljajeva"
    ],
    "abstract": "In the context of artificial life art and agent-based art, this paper draws\non Simon Penny's {\\itshape Aesthetic of Behavior} theory and Sofian Audry's\ndiscussions on behavior computation to examine how artists design agent\nbehaviors and the ensuing aesthetic experiences. We advocate for integrating\nthe environment in which agents operate as the context for behavioral design,\npositing that the environment emerges through continuous interactions among\nagents, audiences, and other entities, forming an evolving network of meanings\ngenerated by these interactions. Artists create contexts by deploying and\nguiding these computational systems, audience participation, and agent\nbehaviors through artist strategies. This framework is developed by analysing\ntwo categories of agent-based artworks, exploring the intersection of\ncomputational systems, audience participation, and artistic strategies in\ncreating aesthetic experiences. This paper seeks to provide a contextual\nfoundation and framework for designing agents' behaviors by conducting a\ncomparative study focused on behavioural design strategies by the artists.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "J.5"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages,5 figures, accetped by 30th International Symposium on\n  Electronic Art (ISEA)",
    "pdf_url": "http://arxiv.org/pdf/2503.16442v1",
    "published_date": "2025-02-14 10:14:09 UTC",
    "updated_date": "2025-02-14 10:14:09 UTC"
  },
  {
    "arxiv_id": "2502.10050v1",
    "title": "A Survey on LLM-powered Agents for Recommender Systems",
    "authors": [
      "Qiyao Peng",
      "Hongtao Liu",
      "Hua Huang",
      "Qing Yang",
      "Minglai Shao"
    ],
    "abstract": "Recommender systems are essential components of many online platforms, yet\ntraditional approaches still struggle with understanding complex user\npreferences and providing explainable recommendations. The emergence of Large\nLanguage Model (LLM)-powered agents offers a promising approach by enabling\nnatural language interactions and interpretable reasoning, potentially\ntransforming research in recommender systems. This survey provides a systematic\nreview of the emerging applications of LLM-powered agents in recommender\nsystems. We identify and analyze three key paradigms in current research: (1)\nRecommender-oriented approaches, which leverage intelligent agents to enhance\nthe fundamental recommendation mechanisms; (2) Interaction-oriented approaches,\nwhich facilitate dynamic user engagement through natural dialogue and\ninterpretable suggestions; and (3) Simulation-oriented approaches, which employ\nmulti-agent frameworks to model complex user-item interactions and system\ndynamics. Beyond paradigm categorization, we analyze the architectural\nfoundations of LLM-powered recommendation agents, examining their essential\ncomponents: profile construction, memory management, strategic planning, and\naction execution. Our investigation extends to a comprehensive analysis of\nbenchmark datasets and evaluation frameworks in this domain. This systematic\nexamination not only illuminates the current state of LLM-powered agent\nrecommender systems but also charts critical challenges and promising research\ndirections in this transformative field.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10050v1",
    "published_date": "2025-02-14 09:57:07 UTC",
    "updated_date": "2025-02-14 09:57:07 UTC"
  },
  {
    "arxiv_id": "2502.10047v1",
    "title": "Janus: Collaborative Vision Transformer Under Dynamic Network Environment",
    "authors": [
      "Linyi Jiang",
      "Silvery D. Fu",
      "Yifei Zhu",
      "Bo Li"
    ],
    "abstract": "Vision Transformers (ViTs) have outperformed traditional Convolutional Neural\nNetwork architectures and achieved state-of-the-art results in various computer\nvision tasks. Since ViTs are computationally expensive, the models either have\nto be pruned to run on resource-limited edge devices only or have to be\nexecuted on remote cloud servers after receiving the raw data transmitted over\nfluctuating networks. The resulting degraded performance or high latency all\nhinder their widespread applications. In this paper, we present Janus, the\nfirst framework for low-latency cloud-device collaborative Vision Transformer\ninference over dynamic networks. Janus overcomes the intrinsic model\nlimitations of ViTs and realizes collaboratively executing ViT models on both\ncloud and edge devices, achieving low latency, high accuracy, and low\ncommunication overhead. Specifically, Janus judiciously combines token pruning\ntechniques with a carefully designed fine-to-coarse model splitting policy and\nnon-static mixed pruning policy. It attains a balance between accuracy and\nlatency by dynamically selecting the optimal pruning level and split point.\nExperimental results across various tasks demonstrate that Janus enhances\nthroughput by up to 5.15 times and reduces latency violation ratios by up to\n98.7% when compared with baseline approaches under various network\nenvironments.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted for publication in IEEE INFOCOM 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10047v1",
    "published_date": "2025-02-14 09:49:52 UTC",
    "updated_date": "2025-02-14 09:49:52 UTC"
  },
  {
    "arxiv_id": "2502.10044v1",
    "title": "Unsupervised Entity Alignment Based on Personalized Discriminative Rooted Tree",
    "authors": [
      "Yaming Yang",
      "Zhe Wang",
      "Ziyu Guan",
      "Wei Zhao",
      "Xinyan Huang",
      "Xiaofei He"
    ],
    "abstract": "Entity Alignment (EA) is to link potential equivalent entities across\ndifferent knowledge graphs (KGs). Most existing EA methods are supervised as\nthey require the supervision of seed alignments, i.e., manually specified\naligned entity pairs. Very recently, several EA studies have made some attempts\nto get rid of seed alignments. Despite achieving preliminary progress, they\nstill suffer two limitations: (1) The entity embeddings produced by their\nGNN-like encoders lack personalization since some of the aggregation subpaths\nare shared between different entities. (2) They cannot fully alleviate the\ndistribution distortion issue between candidate KGs due to the absence of the\nsupervised signal. In this work, we propose a novel unsupervised entity\nalignment approach called UNEA to address the above two issues. First, we\nparametrically sample a tree neighborhood rooted at each entity, and\naccordingly develop a tree attention aggregation mechanism to extract a\npersonalized embedding for each entity. Second, we introduce an auxiliary task\nof maximizing the mutual information between the input and the output of the KG\nencoder, to regularize the model and prevent the distribution distortion.\nExtensive experiments show that our UNEA achieves a new state-of-the-art for\nthe unsupervised EA task, and can even outperform many existing supervised EA\nbaselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10044v1",
    "published_date": "2025-02-14 09:45:39 UTC",
    "updated_date": "2025-02-14 09:45:39 UTC"
  },
  {
    "arxiv_id": "2502.10038v2",
    "title": "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning",
    "authors": [
      "Jiawei Cheng",
      "Jingyuan Wang",
      "Yichuan Zhang",
      "Jiahao Ji",
      "Yuanshao Zhu",
      "Zhibo Zhang",
      "Xiangyu Zhao"
    ],
    "abstract": "POI representation learning plays a crucial role in handling tasks related to\nuser mobility data. Recent studies have shown that enriching POI\nrepresentations with multimodal information can significantly enhance their\ntask performance. Previously, the textual information incorporated into POI\nrepresentations typically involved only POI categories or check-in content,\nleading to relatively weak textual features in existing methods. In contrast,\nlarge language models (LLMs) trained on extensive text data have been found to\npossess rich textual knowledge. However leveraging such knowledge to enhance\nPOI representation learning presents two key challenges: first, how to extract\nPOI-related knowledge from LLMs effectively, and second, how to integrate the\nextracted information to enhance POI representations. To address these\nchallenges, we propose POI-Enhancer, a portable framework that leverages LLMs\nto improve POI representations produced by classic POI learning models. We\nfirst design three specialized prompts to extract semantic information from\nLLMs efficiently. Then, the Dual Feature Alignment module enhances the quality\nof the extracted information, while the Semantic Feature Fusion module\npreserves its integrity. The Cross Attention Fusion module then fully\nadaptively integrates such high-quality information into POI representations\nand Multi-View Contrastive Learning further injects human-understandable\nsemantic information into these representations. Extensive experiments on three\nreal-world datasets demonstrate the effectiveness of our framework, showing\nsignificant improvements across all baseline representations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 25",
    "pdf_url": "http://arxiv.org/pdf/2502.10038v2",
    "published_date": "2025-02-14 09:34:24 UTC",
    "updated_date": "2025-03-04 00:19:42 UTC"
  },
  {
    "arxiv_id": "2502.12180v1",
    "title": "ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis",
    "authors": [
      "Xinpeng Wang",
      "Rong Zhou",
      "Han Xie",
      "Xiaoying Tang",
      "Lifang He",
      "Carl Yang"
    ],
    "abstract": "Multimodal Federated Learning (MFL) has emerged as a promising approach for\ncollaboratively training multimodal models across distributed clients,\nparticularly in healthcare domains. In the context of brain imaging analysis,\nmodality incompleteness presents a significant challenge, where some\ninstitutions may lack specific imaging modalities (e.g., PET, MRI, or CT) due\nto privacy concerns, device limitations, or data availability issues. While\nexisting work typically assumes modality completeness or oversimplifies\nmissing-modality scenarios, we simulate a more realistic setting by considering\nboth client-level and instance-level modality incompleteness in this study.\nBuilding on this realistic simulation, we propose ClusMFL, a novel MFL\nframework that leverages feature clustering for cross-institutional brain\nimaging analysis under modality incompleteness. Specifically, ClusMFL utilizes\nthe FINCH algorithm to construct a pool of cluster centers for the feature\nembeddings of each modality-label pair, effectively capturing fine-grained data\ndistributions. These cluster centers are then used for feature alignment within\neach modality through supervised contrastive learning, while also acting as\nproxies for missing modalities, allowing cross-modal knowledge transfer.\nFurthermore, ClusMFL employs a modality-aware aggregation strategy, further\nenhancing the model's performance in scenarios with severe modality\nincompleteness. We evaluate the proposed framework on the ADNI dataset,\nutilizing structural MRI and PET scans. Extensive experimental results\ndemonstrate that ClusMFL achieves state-of-the-art performance compared to\nvarious baseline methods across varying levels of modality incompleteness,\nproviding a scalable solution for cross-institutional brain imaging analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12180v1",
    "published_date": "2025-02-14 09:33:59 UTC",
    "updated_date": "2025-02-14 09:33:59 UTC"
  },
  {
    "arxiv_id": "2502.12179v1",
    "title": "Identifiable Steering via Sparse Autoencoding of Multi-Concept Shifts",
    "authors": [
      "Shruti Joshi",
      "Andrea Dittadi",
      "Sébastien Lachapelle",
      "Dhanya Sridhar"
    ],
    "abstract": "Steering methods manipulate the representations of large language models\n(LLMs) to induce responses that have desired properties, e.g., truthfulness,\noffering a promising approach for LLM alignment without the need for\nfine-tuning. Traditionally, steering has relied on supervision, such as from\ncontrastive pairs of prompts that vary in a single target concept, which is\ncostly to obtain and limits the speed of steering research. An appealing\nalternative is to use unsupervised approaches such as sparse autoencoders\n(SAEs) to map LLM embeddings to sparse representations that capture\nhuman-interpretable concepts. However, without further assumptions, SAEs may\nnot be identifiable: they could learn latent dimensions that entangle multiple\nconcepts, leading to unintentional steering of unrelated properties. We\nintroduce Sparse Shift Autoencoders (SSAEs) that instead map the differences\nbetween embeddings to sparse representations. Crucially, we show that SSAEs are\nidentifiable from paired observations that vary in \\textit{multiple unknown\nconcepts}, leading to accurate steering of single concepts without the need for\nsupervision. We empirically demonstrate accurate steering across semi-synthetic\nand real-world language datasets using Llama-3.1 embeddings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.12179v1",
    "published_date": "2025-02-14 08:49:41 UTC",
    "updated_date": "2025-02-14 08:49:41 UTC"
  },
  {
    "arxiv_id": "2502.10012v1",
    "title": "Dream to Drive: Model-Based Vehicle Control Using Analytic World Models",
    "authors": [
      "Asen Nachkov",
      "Danda Pani Paudel",
      "Jan-Nico Zaech",
      "Davide Scaramuzza",
      "Luc Van Gool"
    ],
    "abstract": "Differentiable simulators have recently shown great promise for training\nautonomous vehicle controllers. Being able to backpropagate through them, they\ncan be placed into an end-to-end training loop where their known dynamics turn\ninto useful priors for the policy to learn, removing the typical black box\nassumption of the environment. So far, these systems have only been used to\ntrain policies. However, this is not the end of the story in terms of what they\ncan offer. Here, for the first time, we use them to train world models.\nSpecifically, we present three new task setups that allow us to learn next\nstate predictors, optimal planners, and optimal inverse states. Unlike analytic\npolicy gradients (APG), which requires the gradient of the next simulator state\nwith respect to the current actions, our proposed setups rely on the gradient\nof the next state with respect to the current state. We call this approach\nAnalytic World Models (AWMs) and showcase its applications, including how to\nuse it for planning in the Waymax simulator. Apart from pushing the limits of\nwhat is possible with such simulators, we offer an improved training recipe\nthat increases performance on the large-scale Waymo Open Motion dataset by up\nto 12% compared to baselines at essentially no additional cost.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10012v1",
    "published_date": "2025-02-14 08:46:49 UTC",
    "updated_date": "2025-02-14 08:46:49 UTC"
  },
  {
    "arxiv_id": "2502.10486v1",
    "title": "VLM-Guard: Safeguarding Vision-Language Models via Fulfilling Safety Alignment Gap",
    "authors": [
      "Qin Liu",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "abstract": "The emergence of vision language models (VLMs) comes with increased safety\nconcerns, as the incorporation of multiple modalities heightens vulnerability\nto attacks. Although VLMs can be built upon LLMs that have textual safety\nalignment, it is easily undermined when the vision modality is integrated. We\nattribute this safety challenge to the modality gap, a separation of image and\ntext in the shared representation space, which blurs the distinction between\nharmful and harmless queries that is evident in LLMs but weakened in VLMs. To\navoid safety decay and fulfill the safety alignment gap, we propose VLM-Guard,\nan inference-time intervention strategy that leverages the LLM component of a\nVLM as supervision for the safety alignment of the VLM. VLM-Guard projects the\nrepresentations of VLM into the subspace that is orthogonal to the safety\nsteering direction that is extracted from the safety-aligned LLM. Experimental\nresults on three malicious instruction settings show the effectiveness of\nVLM-Guard in safeguarding VLM and fulfilling the safety alignment gap between\nVLM and its LLM component.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.10486v1",
    "published_date": "2025-02-14 08:44:43 UTC",
    "updated_date": "2025-02-14 08:44:43 UTC"
  },
  {
    "arxiv_id": "2502.09994v1",
    "title": "Decision Information Meets Large Language Models: The Future of Explainable Operations Research",
    "authors": [
      "Yansen Zhang",
      "Qingcan Kang",
      "Wing Yin Yu",
      "Hailei Gong",
      "Xiaojin Fu",
      "Xiongwei Han",
      "Tao Zhong",
      "Chen Ma"
    ],
    "abstract": "Operations Research (OR) is vital for decision-making in many industries.\nWhile recent OR methods have seen significant improvements in automation and\nefficiency through integrating Large Language Models (LLMs), they still\nstruggle to produce meaningful explanations. This lack of clarity raises\nconcerns about transparency and trustworthiness in OR applications. To address\nthese challenges, we propose a comprehensive framework, Explainable Operations\nResearch (EOR), emphasizing actionable and understandable explanations\naccompanying optimization. The core of EOR is the concept of Decision\nInformation, which emerges from what-if analysis and focuses on evaluating the\nimpact of complex constraints (or parameters) changes on decision-making.\nSpecifically, we utilize bipartite graphs to quantify the changes in the OR\nmodel and adopt LLMs to improve the explanation capabilities. Additionally, we\nintroduce the first industrial benchmark to rigorously evaluate the\neffectiveness of explanations and analyses in OR, establishing a new standard\nfor transparency and clarity in the field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09994v1",
    "published_date": "2025-02-14 08:25:06 UTC",
    "updated_date": "2025-02-14 08:25:06 UTC"
  },
  {
    "arxiv_id": "2502.09990v2",
    "title": "X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability",
    "authors": [
      "Xiaoya Lu",
      "Dongrui Liu",
      "Yi Yu",
      "Luxin Xu",
      "Jing Shao"
    ],
    "abstract": "Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09990v2",
    "published_date": "2025-02-14 08:22:51 UTC",
    "updated_date": "2025-03-06 15:38:31 UTC"
  },
  {
    "arxiv_id": "2502.10485v1",
    "title": "Forecasting time series with constraints",
    "authors": [
      "Nathan Doumèche",
      "Francis Bach",
      "Éloi Bedek",
      "Gérard Biau",
      "Claire Boyer",
      "Yannig Goude"
    ],
    "abstract": "Time series forecasting presents unique challenges that limit the\neffectiveness of traditional machine learning algorithms. To address these\nlimitations, various approaches have incorporated linear constraints into\nlearning algorithms, such as generalized additive models and hierarchical\nforecasting. In this paper, we propose a unified framework for integrating and\ncombining linear constraints in time series forecasting. Within this framework,\nwe show that the exact minimizer of the constrained empirical risk can be\ncomputed efficiently using linear algebra alone. This approach allows for\nhighly scalable implementations optimized for GPUs. We validate the proposed\nmethodology through extensive benchmarking on real-world tasks, including\nelectricity demand forecasting and tourism forecasting, achieving\nstate-of-the-art performance.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.AP",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10485v1",
    "published_date": "2025-02-14 08:18:17 UTC",
    "updated_date": "2025-02-14 08:18:17 UTC"
  },
  {
    "arxiv_id": "2502.09977v2",
    "title": "LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs -- No Silver Bullet for LC or RAG Routing",
    "authors": [
      "Kuan Li",
      "Liwen Zhang",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Shuai Wang",
      "Minhao Cheng"
    ],
    "abstract": "Effectively incorporating external knowledge into Large Language Models\n(LLMs) is crucial for enhancing their capabilities and addressing real-world\nneeds. Retrieval-Augmented Generation (RAG) offers an effective method for\nachieving this by retrieving the most relevant fragments into LLMs. However,\nthe advancements in context window size for LLMs offer an alternative approach,\nraising the question of whether RAG remains necessary for effectively handling\nexternal knowledge. Several existing studies provide inconclusive comparisons\nbetween RAG and long-context (LC) LLMs, largely due to limitations in the\nbenchmark designs. In this paper, we present LaRA, a novel benchmark\nspecifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses\n2326 test cases across four practical QA task categories and three types of\nnaturally occurring long texts. Through systematic evaluation of seven\nopen-source and four proprietary LLMs, we find that the optimal choice between\nRAG and LC depends on a complex interplay of factors, including the model's\nparameter size, long-text capabilities, context length, task type, and the\ncharacteristics of the retrieved chunks. Our findings provide actionable\nguidelines for practitioners to effectively leverage both RAG and LC approaches\nin developing and deploying LLM applications. Our code and dataset is provided\nat:\n\\href{https://github.com/Alibaba-NLP/LaRA}{\\textbf{https://github.com/Alibaba-NLP/LaRA}}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09977v2",
    "published_date": "2025-02-14 08:04:22 UTC",
    "updated_date": "2025-03-05 08:48:25 UTC"
  },
  {
    "arxiv_id": "2502.09974v1",
    "title": "Has My System Prompt Been Used? Large Language Model Prompt Membership Inference",
    "authors": [
      "Roman Levin",
      "Valeriia Cherepanova",
      "Abhimanyu Hans",
      "Avi Schwarzschild",
      "Tom Goldstein"
    ],
    "abstract": "Prompt engineering has emerged as a powerful technique for optimizing large\nlanguage models (LLMs) for specific applications, enabling faster prototyping\nand improved performance, and giving rise to the interest of the community in\nprotecting proprietary system prompts. In this work, we explore a novel\nperspective on prompt privacy through the lens of membership inference. We\ndevelop Prompt Detective, a statistical method to reliably determine whether a\ngiven system prompt was used by a third-party language model. Our approach\nrelies on a statistical test comparing the distributions of two groups of model\noutputs corresponding to different system prompts. Through extensive\nexperiments with a variety of language models, we demonstrate the effectiveness\nof Prompt Detective for prompt membership inference. Our work reveals that even\nminor changes in system prompts manifest in distinct response distributions,\nenabling us to verify prompt usage with statistical significance.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09974v1",
    "published_date": "2025-02-14 08:00:42 UTC",
    "updated_date": "2025-02-14 08:00:42 UTC"
  },
  {
    "arxiv_id": "2502.09971v1",
    "title": "Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression",
    "authors": [
      "Siqi Wu",
      "Yinda Chen",
      "Dong Liu",
      "Zhihai He"
    ],
    "abstract": "In this paper, we study how to synthesize a dynamic reference from an\nexternal dictionary to perform conditional coding of the input image in the\nlatent domain and how to learn the conditional latent synthesis and coding\nmodules in an end-to-end manner. Our approach begins by constructing a\nuniversal image feature dictionary using a multi-stage approach involving\nmodified spatial pyramid pooling, dimension reduction, and multi-scale feature\nclustering. For each input image, we learn to synthesize a conditioning latent\nby selecting and synthesizing relevant features from the dictionary, which\nsignificantly enhances the model's capability in capturing and exploring image\nsource correlation. This conditional latent synthesis involves a\ncorrelation-based feature matching and alignment strategy, comprising a\nConditional Latent Matching (CLM) module and a Conditional Latent Synthesis\n(CLS) module. The synthesized latent is then used to guide the encoding\nprocess, allowing for more efficient compression by exploiting the correlation\nbetween the input image and the reference dictionary. According to our\ntheoretical analysis, the proposed conditional latent coding (CLC) method is\nrobust to perturbations in the external dictionary samples and the selected\nconditioning latent, with an error bound that scales logarithmically with the\ndictionary size, ensuring stability even with large and diverse dictionaries.\nExperimental results on benchmark datasets show that our new method improves\nthe coding performance by a large margin (up to 1.2 dB) with a very small\noverhead of approximately 0.5\\% bits per pixel. Our code is publicly available\nat https://github.com/ydchen0806/CLC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09971v1",
    "published_date": "2025-02-14 07:56:21 UTC",
    "updated_date": "2025-02-14 07:56:21 UTC"
  },
  {
    "arxiv_id": "2502.09969v2",
    "title": "Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning",
    "authors": [
      "Ishika Agarwal",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Influence functions provide crucial insights into model training, but\nexisting methods suffer from large computational costs and limited\ngeneralization. Particularly, recent works have proposed various metrics and\nalgorithms to calculate the influence of data using language models, which do\nnot scale well with large models and datasets. This is because of the expensive\nforward and backward passes required for computation, substantial memory\nrequirements to store large models, and poor generalization of influence\nestimates to new data. In this paper, we explore the use of small neural\nnetworks -- which we refer to as the InfluenceNetwork -- to estimate influence\nvalues, achieving up to 99% cost reduction. Our evaluation demonstrates that\ninfluence values can be estimated with models just 0.0027% the size of full\nlanguage models (we use 7B and 8B versions). We apply our algorithm of\nestimating influence values (called NN-CIFT: Neural Networks for effiCient\nInstruction Fine-Tuning) to the downstream task of subset selection for general\ninstruction fine-tuning. In our study, we include four state-of-the-art\ninfluence functions and show no compromise in performance, despite large\nspeedups, between NN-CIFT and the original influence functions. We provide an\nin-depth hyperparameter analyses of NN-CIFT. The code for our method can be\nfound here: https://github.com/agarwalishika/NN-CIFT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09969v2",
    "published_date": "2025-02-14 07:55:47 UTC",
    "updated_date": "2025-02-17 16:26:47 UTC"
  },
  {
    "arxiv_id": "2502.14880v1",
    "title": "KKA: Improving Vision Anomaly Detection through Anomaly-related Knowledge from Large Language Models",
    "authors": [
      "Dong Chen",
      "Zhengqing Hu",
      "Peiguang Fan",
      "Yueting Zhuang",
      "Yafei Li",
      "Qidong Liu",
      "Xiaoheng Jiang",
      "Mingliang Xu"
    ],
    "abstract": "Vision anomaly detection, particularly in unsupervised settings, often\nstruggles to distinguish between normal samples and anomalies due to the wide\nvariability in anomalies. Recently, an increasing number of studies have\nfocused on generating anomalies to help detectors learn more effective\nboundaries between normal samples and anomalies. However, as the generated\nanomalies are often derived from random factors, they frequently lack realism.\nAdditionally, randomly generated anomalies typically offer limited support in\nconstructing effective boundaries, as most differ substantially from normal\nsamples and lie far from the boundary. To address these challenges, we propose\nKey Knowledge Augmentation (KKA), a method that extracts anomaly-related\nknowledge from large language models (LLMs). More specifically, KKA leverages\nthe extensive prior knowledge of LLMs to generate meaningful anomalies based on\nnormal samples. Then, KKA classifies the generated anomalies as easy anomalies\nand hard anomalies according to their similarity to normal samples. Easy\nanomalies exhibit significant differences from normal samples, whereas hard\nanomalies closely resemble normal samples. KKA iteratively updates the\ngenerated anomalies, and gradually increasing the proportion of hard anomalies\nto enable the detector to learn a more effective boundary. Experimental results\nshow that the proposed method significantly improves the performance of various\nvision anomaly detectors while maintaining low generation costs. The code for\nCMG can be found at https://github.com/Anfeather/KKA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14880v1",
    "published_date": "2025-02-14 07:46:49 UTC",
    "updated_date": "2025-02-14 07:46:49 UTC"
  },
  {
    "arxiv_id": "2502.15762v1",
    "title": "SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning",
    "authors": [
      "Alain Hennebelle",
      "Qifan Dieng",
      "Leila Ismail",
      "Rajkumar Buyya"
    ],
    "abstract": "The Internet of Things (IoT) revolutionizes smart city domains such as\nhealthcare, transportation, industry, and education. The Internet of Medical\nThings (IoMT) is gaining prominence, particularly in smart hospitals and Remote\nPatient Monitoring (RPM). The vast volume of data generated by IoMT devices\nshould be analyzed in real-time for health surveillance, prognosis, and\nprediction of diseases. Current approaches relying on Cloud computing to\nprovide the necessary computing and storage capabilities do not scale for these\nlatency-sensitive applications. Edge computing emerges as a solution by\nbringing cloud services closer to IoMT devices. This paper introduces\nSmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloud\ncomputing system for diabetes prediction. This work addresses latency concerns\nand demonstrates the efficacy of edge resources in healthcare applications\nwithin an end-to-end system. The system leverages various risk factors for\ndiabetes prediction. We propose an Edge and Cloud-enabled framework to deploy\nthe proposed diabetes prediction models on various configurations using edge\nnodes and main cloud servers. Performance metrics are evaluated using, latency,\naccuracy, and response time. By using ensemble machine learning voting\nalgorithms we can improve the prediction accuracy by 5% versus a single model\nprediction.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "68T01, 68T09, 68M14, 68W10, 68W15",
      "C.2.4; C.4; C.5; D.2.2; D.2.11; I.2.5; I.2.6; I.2.11; J.0; J.7"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15762v1",
    "published_date": "2025-02-14 07:42:17 UTC",
    "updated_date": "2025-02-14 07:42:17 UTC"
  },
  {
    "arxiv_id": "2503.16441v1",
    "title": "Safe and Efficient Social Navigation through Explainable Safety Regions Based on Topological Features",
    "authors": [
      "Victor Toscano-Duran",
      "Sara Narteni",
      "Alberto Carlevaro",
      "Rocio Gonzalez-Diaz",
      "Maurizio Mongelli",
      "Jerome Guzzi"
    ],
    "abstract": "The recent adoption of artificial intelligence (AI) in robotics has driven\nthe development of algorithms that enable autonomous systems to adapt to\ncomplex social environments. In particular, safe and efficient social\nnavigation is a key challenge, requiring AI not only to avoid collisions and\ndeadlocks but also to interact intuitively and predictably with its\nsurroundings. To date, methods based on probabilistic models and the generation\nof conformal safety regions have shown promising results in defining safety\nregions with a controlled margin of error, primarily relying on classification\napproaches and explicit rules to describe collision-free navigation conditions.\n  This work explores how topological features contribute to explainable safety\nregions in social navigation. Instead of using behavioral parameters, we\nleverage topological data analysis to classify and characterize different\nsimulation behaviors. First, we apply global rule-based classification to\ndistinguish between safe (collision-free) and unsafe scenarios based on\ntopological properties. Then, we define safety regions, $S_\\varepsilon$, in the\ntopological feature space, ensuring a maximum classification error of\n$\\varepsilon$. These regions are built with adjustable SVM classifiers and\norder statistics, providing robust decision boundaries. Local rules extracted\nfrom these regions enhance interpretability, keeping the decision-making\nprocess transparent.\n  Our approach initially separates simulations with and without collisions,\noutperforming methods that not incorporate topological features. It offers a\ndeeper understanding of robot interactions within a navigable space. We further\nrefine safety regions to ensure deadlock-free simulations and integrate both\naspects to define a compliant simulation space that guarantees safe and\nefficient navigation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "math.GN"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16441v1",
    "published_date": "2025-02-14 07:29:13 UTC",
    "updated_date": "2025-02-14 07:29:13 UTC"
  },
  {
    "arxiv_id": "2502.09956v1",
    "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models",
    "authors": [
      "Belinda Mo",
      "Kyssen Yu",
      "Joshua Kazdan",
      "Proud Mpala",
      "Lisa Yu",
      "Chris Cundy",
      "Charilaos Kanatsoulis",
      "Sanmi Koyejo"
    ],
    "abstract": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09956v1",
    "published_date": "2025-02-14 07:28:08 UTC",
    "updated_date": "2025-02-14 07:28:08 UTC"
  },
  {
    "arxiv_id": "2502.09955v1",
    "title": "Diverse Inference and Verification for Advanced Reasoning",
    "authors": [
      "Iddo Drori",
      "Gaston Longhitano",
      "Mao Mao",
      "Seunghwan Hyun",
      "Yuke Zhang",
      "Sungjun Park",
      "Zachary Meeks",
      "Xin-Yu Zhang",
      "Ben Segev",
      "Howard Yong",
      "Nakul Verma",
      "Avi Shporer",
      "Alon Amit",
      "Madeleine Udell"
    ],
    "abstract": "Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significant\nprogress in mathematics and coding, yet find challenging advanced tasks such as\nInternational Mathematical Olympiad (IMO) combinatorics problems, Abstraction\nand Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions.\nWe use a diverse inference approach that combines multiple models and methods\nat test time. We find that verifying mathematics and code problems, and\nrejection sampling on other problems is simple and effective. We automatically\nverify correctness of solutions to IMO problems by Lean, and ARC puzzles by\ncode, and find that best-of-N effectively answers HLE questions. Our approach\nincreases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%,\naccuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that\n948 humans could not and 26.5% of ARC puzzles that o3 high compute does not.\nTest-time simulations, reinforcement learning, and meta-learning with inference\nfeedback improve generalization by adapting agent graph representations and\nvarying prompts, code, and datasets. Our approach is reliable, robust, and\nscalable, and in the spirit of reproducible research, we will make it publicly\navailable upon publication.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "165 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.09955v1",
    "published_date": "2025-02-14 07:22:25 UTC",
    "updated_date": "2025-02-14 07:22:25 UTC"
  },
  {
    "arxiv_id": "2502.09952v1",
    "title": "Using MRNet to Predict Lunar Rock Categories Detected by Chang'e 5 Probe",
    "authors": [
      "Jin Cui",
      "Yifei Zou",
      "Siyuan Zhang"
    ],
    "abstract": "China's Chang'e 5 mission has been a remarkable success, with the chang'e 5\nlander traveling on the Oceanus Procellarum to collect images of the lunar\nsurface. Over the past half century, people have brought back some lunar rock\nsamples, but its quantity does not meet the need for research. Under current\ncircumstances, people still mainly rely on the analysis of rocks on the lunar\nsurface through the detection of lunar rover. The Oceanus Procellarum, chosen\nby Chang'e 5 mission, contains various kind of rock species. Therefore, we\nfirst applied to the National Astronomical Observatories of the China under the\nChinese Academy of Sciences for the Navigation and Terrain Camera (NaTeCam) of\nthe lunar surface image, and established a lunar surface rock image data set\nCE5ROCK. The data set contains 100 images, which randomly divided into\ntraining, validation and test set. Experimental results show that the\nidentification accuracy testing on convolutional neural network (CNN) models\nlike AlexNet or MobileNet is about to 40.0%. In order to make full use of the\nglobal information in Moon images, this paper proposes the MRNet (MoonRockNet)\nnetwork architecture. The encoding structure of the network uses VGG16 for\nfeature extraction, and the decoding part adds dilated convolution and commonly\nused U-Net structure on the original VGG16 decoding structure, which is more\nconducive to identify more refined but more sparsely distributed types of lunar\nrocks. We have conducted extensive experiments on the established CE5ROCK data\nset, and the experimental results show that MRNet can achieve more accurate\nrock type identification, and outperform other existing mainstream algorithms\nin the identification performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at the 8th International Conference on Advances in\n  Machinery, Material Science and Engineering Application (MMSE 2022)",
    "pdf_url": "http://arxiv.org/pdf/2502.09952v1",
    "published_date": "2025-02-14 07:12:19 UTC",
    "updated_date": "2025-02-14 07:12:19 UTC"
  },
  {
    "arxiv_id": "2502.09947v1",
    "title": "Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model",
    "authors": [
      "Jin Cui",
      "Alexander Capstick",
      "Payam Barnaghi",
      "Gregory Scott"
    ],
    "abstract": "In the analysis of remote healthcare monitoring data, time series\nrepresentation learning offers substantial value in uncovering deeper patterns\nof patient behavior, especially given the fine temporal granularity of the\ndata. In this study, we focus on a dataset of home activity records from people\nliving with Dementia. We propose a two-stage self-supervised learning approach.\nThe first stage involves converting time-series activities into text strings,\nwhich are then encoded by a fine-tuned language model. In the second stage,\nthese time-series vectors are bi-dimensionalized for applying PageRank method,\nto analyze latent state transitions to quantitatively assess participants\nbehavioral patterns and identify activity biases. These insights, combined with\ndiagnostic data, aim to support personalized care interventions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 workshop Time Series in the Age of Large Models. arXiv\n  admin note: substantial text overlap with arXiv:2502.09173",
    "pdf_url": "http://arxiv.org/pdf/2502.09947v1",
    "published_date": "2025-02-14 06:53:52 UTC",
    "updated_date": "2025-02-14 06:53:52 UTC"
  },
  {
    "arxiv_id": "2502.09933v4",
    "title": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?",
    "authors": [
      "Kai Yan",
      "Zhan Ling",
      "Kang Liu",
      "Yifan Yang",
      "Ting-Han Fan",
      "Lingfeng Shen",
      "Zhengyin Du",
      "Jiecao Chen"
    ],
    "abstract": "The ability to recognize patterns from examples and apply them to new ones is\na primal ability for general intelligence, and is widely studied by psychology\nand AI researchers. Many benchmarks have been proposed to measure such ability\nfor Large Language Models (LLMs); however, they focus on few-shot (usually <10)\nsetting and lack evaluation for aggregating many pieces of information from\nlong contexts. On the other hand, the ever-growing context length of LLMs have\nbrought forth the novel paradigm of many-shot In-Context Learning (ICL), which\naddresses new tasks with hundreds to thousands of examples without expensive\nand inefficient fine-tuning. However, many-shot evaluations often focus on\nclassification, and popular long-context LLM tasks such as Needle-In-A-Haystack\n(NIAH) seldom require complicated intelligence for integrating many pieces of\ninformation. To fix the issues from both worlds, we propose MIR-Bench, the\nfirst many-shot in-context reasoning benchmark for pattern recognition that\nasks LLM to predict output via input-output examples from underlying functions\nwith diverse data format. Based on MIR-Bench, we study many novel problems for\nmany-shot in-context reasoning, and acquired many insightful findings including\nscaling effect, robustness, inductive vs. transductive reasoning, retrieval\nAugmented Generation (RAG), coding for inductive reasoning, cross-domain\ngeneralizability, etc.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages, 11 figures. The last version adds more experiments and\n  modifies name for better summary of the work",
    "pdf_url": "http://arxiv.org/pdf/2502.09933v4",
    "published_date": "2025-02-14 06:05:12 UTC",
    "updated_date": "2025-05-16 06:10:15 UTC"
  },
  {
    "arxiv_id": "2502.09931v1",
    "title": "TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation",
    "authors": [
      "Ju-Hyeon Nam",
      "Nur Suriza Syazwany",
      "Sang-Chul Lee"
    ],
    "abstract": "Skip connection engineering is primarily employed to address the semantic gap\nbetween the encoder and decoder, while also integrating global dependencies to\nunderstand the relationships among complex anatomical structures in medical\nimage segmentation. Although several models have proposed transformer-based\napproaches to incorporate global dependencies within skip connections, they\noften face limitations in capturing detailed local features with high\ncomputational complexity. In contrast, graph neural networks (GNNs) exploit\ngraph structures to effectively capture local and global features. Leveraging\nthese properties, we introduce an attentional cross-scale graph neural network\n(ACS-GNN), which enhances the skip connection framework by converting\ncross-scale feature maps into a graph structure and capturing complex\nanatomical structures through node attention. Additionally, we observed that\ndeep learning models often produce uninformative feature maps, which degrades\nthe quality of spatial attention maps. To address this problem, we integrated\nentropy-driven feature selection (EFS) with spatial attention, calculating an\nentropy score for each channel and filtering out high-entropy feature maps. Our\ninnovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatial\nattentio} to effectively enhance domain generalizability across various\nmodalities by leveraging GNNs alongside a reliable spatial attention map,\nensuring more robust features within the skip connection. Through comprehensive\nexperiments and analysis, TransGUNet achieved superior segmentation performance\non six seen and eight unseen datasets, demonstrating significantly higher\nefficiency compared to previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.09931v1",
    "published_date": "2025-02-14 05:54:13 UTC",
    "updated_date": "2025-02-14 05:54:13 UTC"
  },
  {
    "arxiv_id": "2502.09928v1",
    "title": "Deep Tree Tensor Networks for Image Recognition",
    "authors": [
      "Chang Nie",
      "Junfang Chen",
      "Yajie Chen"
    ],
    "abstract": "Originating in quantum physics, tensor networks (TNs) have been widely\nadopted as exponential machines and parameter decomposers for recognition\ntasks. Typical TN models, such as Matrix Product States (MPS), have not yet\nachieved successful application in natural image processing. When employed,\nthey primarily serve to compress parameters within off-the-shelf networks, thus\nlosing their distinctive capability to enhance exponential-order feature\ninteractions. This paper introduces a novel architecture named\n\\textit{\\textbf{D}eep \\textbf{T}ree \\textbf{T}ensor \\textbf{N}etwork} (DTTN),\nwhich captures $2^L$-order multiplicative interactions across features through\nmultilinear operations, while essentially unfolding into a \\emph{tree}-like TN\ntopology with the parameter-sharing property. DTTN is stacked with multiple\nantisymmetric interacting modules (AIMs), and this design facilitates efficient\nimplementation. Moreover, we theoretically reveal the equivalency among\nquantum-inspired TN models and polynomial and multilinear networks under\ncertain conditions, and we believe that DTTN can inspire more interpretable\nstudies in this field. We evaluate the proposed model against a series of\nbenchmarks and achieve excellent performance compared to its peers and\ncutting-edge architectures. Our code will soon be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09928v1",
    "published_date": "2025-02-14 05:41:33 UTC",
    "updated_date": "2025-02-14 05:41:33 UTC"
  },
  {
    "arxiv_id": "2502.09927v1",
    "title": "Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence",
    "authors": [
      "Granite Vision Team",
      "Leonid Karlinsky",
      "Assaf Arbelle",
      "Abraham Daniels",
      "Ahmed Nassar",
      "Amit Alfassi",
      "Bo Wu",
      "Eli Schwartz",
      "Dhiraj Joshi",
      "Jovana Kondic",
      "Nimrod Shabtay",
      "Pengyuan Li",
      "Roei Herzig",
      "Shafiq Abedin",
      "Shaked Perek",
      "Sivan Harary",
      "Udi Barzelay",
      "Adi Raz Goldfarb",
      "Aude Oliva",
      "Ben Wieles",
      "Bishwaranjan Bhattacharjee",
      "Brandon Huang",
      "Christoph Auer",
      "Dan Gutfreund",
      "David Beymer",
      "David Wood",
      "Hilde Kuehne",
      "Jacob Hansen",
      "Joseph Shtok",
      "Ken Wong",
      "Luis Angel Bathen",
      "Mayank Mishra",
      "Maksym Lysak",
      "Michele Dolfi",
      "Mikhail Yurochkin",
      "Nikolaos Livathinos",
      "Nimrod Harel",
      "Ophir Azulai",
      "Oshri Naparstek",
      "Rafael Teixeira de Lima",
      "Rameswar Panda",
      "Sivan Doveh",
      "Shubham Gupta",
      "Subhro Das",
      "Syed Zawad",
      "Yusik Kim",
      "Zexue He",
      "Alexander Brooks",
      "Gabe Goodhart",
      "Anita Govindjee",
      "Derek Leist",
      "Ibrahim Ibrahim",
      "Aya Soffer",
      "David Cox",
      "Kate Soule",
      "Luis Lastras",
      "Nirmit Desai",
      "Shila Ofek-koifman",
      "Sriram Raghavan",
      "Tanveer Syeda-Mahmood",
      "Peter Staar",
      "Tal Drory",
      "Rogerio Feris"
    ],
    "abstract": "We introduce Granite Vision, a lightweight large language model with vision\ncapabilities, specifically designed to excel in enterprise use cases,\nparticularly in visual document understanding. Our model is trained on a\ncomprehensive instruction-following dataset, including document-related tasks,\nsuch as content extraction from tables, charts, diagrams, sketches, and\ninfographics, as well as general image tasks. The architecture of Granite\nVision is centered around visual modality alignment with a decoder-only, 2\nbillion parameter Granite large language model. Additionally, we introduce a\ndedicated safety classification approach in test-time that leverages a sparse\nset of attention vectors to identify potential harmful inputs. Despite its\nlightweight architecture, Granite Vision achieves strong results in standard\nbenchmarks related to visual document understanding, as well as on the LiveXiv\nbenchmark, which is designed to avoid test set contamination by using a\nconstantly updated corpus of recently published Arxiv papers. We are releasing\nthe model under the Apache-2 license, allowing for both research and commercial\nuse, while offering complete visibility into the training data and other\nrelevant details. See https://huggingface.co/ibm-granite/ for model weights.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09927v1",
    "published_date": "2025-02-14 05:36:32 UTC",
    "updated_date": "2025-02-14 05:36:32 UTC"
  },
  {
    "arxiv_id": "2502.09925v1",
    "title": "TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types",
    "authors": [
      "Jiankang Chen",
      "Tianke Zhang",
      "Changyi Liu",
      "Haojie Ding",
      "Yaya Shi",
      "Feng Cheng",
      "Huihui Xiao",
      "Bin Wen",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang"
    ],
    "abstract": "Multimodal visual language models are gaining prominence in open-world\napplications, driven by advancements in model architectures, training\ntechniques, and high-quality data. However, their performance is often limited\nby insufficient task-specific data, leading to poor generalization and biased\noutputs. Existing efforts to increase task diversity in fine-tuning datasets\nare hindered by the labor-intensive process of manual task labeling, which\ntypically produces only a few hundred task types. To address this, we propose\nTaskGalaxy, a large-scale multimodal instruction fine-tuning dataset comprising\n19,227 hierarchical task types and 413,648 samples. TaskGalaxy utilizes GPT-4o\nto enrich task diversity by expanding from a small set of manually defined\ntasks, with CLIP and GPT-4o filtering those that best match open-source images,\nand generating relevant question-answer pairs. Multiple models are employed to\nensure sample quality. This automated process enhances both task diversity and\ndata quality, reducing manual intervention. Incorporating TaskGalaxy into\nLLaVA-v1.5 and InternVL-Chat-v1.0 models shows substantial performance\nimprovements across 16 benchmarks, demonstrating the critical importance of\ntask diversity. TaskGalaxy is publicly released at\nhttps://github.com/Kwai-YuanQi/TaskGalaxy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09925v1",
    "published_date": "2025-02-14 05:32:46 UTC",
    "updated_date": "2025-02-14 05:32:46 UTC"
  },
  {
    "arxiv_id": "2502.09920v1",
    "title": "Machine Learning for Phase Estimation in Satellite-to-Earth Quantum Communication",
    "authors": [
      "Nathan K Long",
      "Robert Malaney",
      "Kenneth J Grant"
    ],
    "abstract": "A global continuous-variable quantum key distribution (CV-QKD) network can be\nestablished using a series of satellite-to-Earth channels. Increased\nperformance in such a network is provided by performing coherent measurement of\nthe optical quantum signals using a real local oscillator, calibrated locally\nby encoding known information on transmitted reference pulses and using signal\nphase error estimation algorithms. The speed and accuracy of the signal phase\nerror estimation algorithm are vital to practical CV-QKD implementation. Our\nwork provides a framework to analyze long short-term memory neural network (NN)\narchitecture parameterization, with respect to the quantum Cram\\'er-Rao\nuncertainty bound of the signal phase error estimation, with a focus on\nreducing the model complexity. More specifically, we demonstrate that signal\nphase error estimation can be achieved using a low-complexity NN architecture,\nwithout significantly sacrificing accuracy. Our results significantly improve\nthe real-time performance of practical CV-QKD systems deployed over\nsatellite-to-Earth channels, thereby contributing to the ongoing development of\nthe Quantum Internet.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09920v1",
    "published_date": "2025-02-14 05:07:59 UTC",
    "updated_date": "2025-02-14 05:07:59 UTC"
  },
  {
    "arxiv_id": "2502.09919v1",
    "title": "AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset",
    "authors": [
      "Ebrahim Farahmand",
      "Reza Rahimi Azghan",
      "Nooshin Taheri Chatrudi",
      "Eric Kim",
      "Gautham Krishna Gudur",
      "Edison Thomaz",
      "Giulia Pedrielli",
      "Pavan Turaga",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Diabetes is a chronic metabolic disorder characterized by persistently high\nblood glucose levels (BGLs), leading to severe complications such as\ncardiovascular disease, neuropathy, and retinopathy. Predicting BGLs enables\npatients to maintain glucose levels within a safe range and allows caregivers\nto take proactive measures through lifestyle modifications. Continuous Glucose\nMonitoring (CGM) systems provide real-time tracking, offering a valuable tool\nfor monitoring BGLs. However, accurately forecasting BGLs remains challenging\ndue to fluctuations due to physical activity, diet, and other factors. Recent\ndeep learning models show promise in improving BGL prediction. Nonetheless,\nforecasting BGLs accurately from multimodal, irregularly sampled data over long\nprediction horizons remains a challenging research problem. In this paper, we\npropose AttenGluco, a multimodal Transformer-based framework for long-term\nblood glucose prediction. AttenGluco employs cross-attention to effectively\nintegrate CGM and activity data, addressing challenges in fusing data with\ndifferent sampling rates. Moreover, it employs multi-scale attention to capture\nlong-term dependencies in temporal data, enhancing forecasting accuracy. To\nevaluate the performance of AttenGluco, we conduct forecasting experiments on\nthe recently released AIREADI dataset, analyzing its predictive accuracy across\ndifferent subject cohorts including healthy individuals, people with\nprediabetes, and those with type 2 diabetes. Furthermore, we investigate its\nperformance improvements and forgetting behavior as new cohorts are introduced.\nOur evaluations show that AttenGluco improves all error metrics, such as root\nmean square error (RMSE), mean absolute error (MAE), and correlation, compared\nto the multimodal LSTM model. AttenGluco outperforms this baseline model by\nabout 10% and 15% in terms of RMSE and MAE, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09919v1",
    "published_date": "2025-02-14 05:07:38 UTC",
    "updated_date": "2025-02-14 05:07:38 UTC"
  },
  {
    "arxiv_id": "2502.09913v1",
    "title": "AutoS$^2$earch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search",
    "authors": [
      "Zhengqiu Zhu",
      "Yatai Ji",
      "Jiaheng Huang",
      "Yong Zhao",
      "Sihang Qiu",
      "Rusheng Ju"
    ],
    "abstract": "Web-based management systems have been widely used in risk control and\nindustrial safety. However, effectively integrating source search capabilities\ninto these systems, to enable decision-makers to locate and address the hazard\n(e.g., gas leak detection) remains a challenge. While prior efforts have\nexplored using web crowdsourcing and AI algorithms for source search decision\nsupport, these approaches suffer from overheads in recruiting human\nparticipants and slow response times in time-sensitive situations. To address\nthis, we introduce AutoS$^2$earch, a novel framework leveraging large models\nfor zero-shot source search in web applications. AutoS$^2$earch operates on a\nsimplified visual environment projected through a web-based display, utilizing\na chain-of-thought prompt designed to emulate human reasoning. The multi-modal\nlarge language model (MLLMs) dynamically converts visual observations into\nlanguage descriptions, enabling the LLM to perform linguistic reasoning on four\ndirectional choices. Extensive experiments demonstrate that AutoS$^2$earch\nachieves performance nearly equivalent to human-AI collaborative source search\nwhile eliminating dependency on crowdsourced labor. Our work offers valuable\ninsights in using web engineering to design such autonomous systems in other\nindustrial applications.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09913v1",
    "published_date": "2025-02-14 04:58:28 UTC",
    "updated_date": "2025-02-14 04:58:28 UTC"
  },
  {
    "arxiv_id": "2502.09903v1",
    "title": "The Ann Arbor Architecture for Agent-Oriented Programming",
    "authors": [
      "Wei Dong"
    ],
    "abstract": "In this paper, we reexamine prompt engineering for large language models\nthrough the lens of automata theory. We argue that language models function as\nautomata and, like all automata, should be programmed in the languages they\naccept, a unified collection of all natural and formal languages. Therefore,\ntraditional software engineering practices--conditioned on the clear separation\nof programming languages and natural languages--must be rethought. We introduce\nthe Ann Arbor Architecture, a conceptual framework for agent-oriented\nprogramming of language models, as a higher-level abstraction over raw token\ngeneration, and provide a new perspective on in-context learning. Based on this\nframework, we present the design of our agent platform Postline, and report on\nour initial experiments in agent training.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09903v1",
    "published_date": "2025-02-14 04:21:36 UTC",
    "updated_date": "2025-02-14 04:21:36 UTC"
  },
  {
    "arxiv_id": "2502.09897v1",
    "title": "Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond",
    "authors": [
      "Kehan Guo",
      "Yili Shen",
      "Gisela Abigail Gonzalez-Montiel",
      "Yue Huang",
      "Yujun Zhou",
      "Mihir Surve",
      "Zhichun Guo",
      "Prayel Das",
      "Nitesh V Chawla",
      "Olaf Wiest",
      "Xiangliang Zhang"
    ],
    "abstract": "The rapid advent of machine learning (ML) and artificial intelligence (AI)\nhas catalyzed major transformations in chemistry, yet the application of these\nmethods to spectroscopic and spectrometric data, referred to as Spectroscopy\nMachine Learning (SpectraML), remains relatively underexplored. Modern\nspectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growing\nvolume of high-dimensional data, creating a pressing need for automated and\nintelligent analysis beyond traditional expert-based workflows. In this survey,\nwe provide a unified review of SpectraML, systematically examining\nstate-of-the-art approaches for both forward tasks (molecule-to-spectrum\nprediction) and inverse tasks (spectrum-to-molecule inference). We trace the\nhistorical evolution of ML in spectroscopy, from early pattern recognition to\nthe latest foundation models capable of advanced reasoning, and offer a\ntaxonomy of representative neural architectures, including graph-based and\ntransformer-based methods. Addressing key challenges such as data quality,\nmultimodal integration, and computational scalability, we highlight emerging\ndirections such as synthetic data generation, large-scale pretraining, and few-\nor zero-shot learning. To foster reproducible research, we also release an\nopen-source repository containing recent papers and their corresponding curated\ndatasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our survey\nserves as a roadmap for researchers, guiding progress at the intersection of\nspectroscopy and AI.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09897v1",
    "published_date": "2025-02-14 04:07:25 UTC",
    "updated_date": "2025-02-14 04:07:25 UTC"
  },
  {
    "arxiv_id": "2502.12176v1",
    "title": "Ten Challenging Problems in Federated Foundation Models",
    "authors": [
      "Tao Fan",
      "Hanlin Gu",
      "Xuemei Cao",
      "Chee Seng Chan",
      "Qian Chen",
      "Yiqiang Chen",
      "Yihui Feng",
      "Yang Gu",
      "Jiaxiang Geng",
      "Bing Luo",
      "Shuoling Liu",
      "Win Kent Ong",
      "Chao Ren",
      "Jiaqi Shao",
      "Chuan Sun",
      "Xiaoli Tang",
      "Hong Xi Tae",
      "Yongxin Tong",
      "Shuyue Wei",
      "Fan Wu",
      "Wei Xi",
      "Mingcong Xu",
      "He Yang",
      "Xin Yang",
      "Jiangpeng Yan",
      "Hao Yu",
      "Han Yu",
      "Teng Zhang",
      "Yifei Zhang",
      "Xiaojin Zhang",
      "Zhenzhe Zheng",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "abstract": "Federated Foundation Models (FedFMs) represent a distributed learning\nparadigm that fuses general competences of foundation models as well as\nprivacy-preserving capabilities of federated learning. This combination allows\nthe large foundation models and the small local domain models at the remote\nclients to learn from each other in a teacher-student learning setting. This\npaper provides a comprehensive summary of the ten challenging problems inherent\nin FedFMs, encompassing foundational theory, utilization of private data,\ncontinual learning, unlearning, Non-IID and graph data, bidirectional knowledge\ntransfer, incentive mechanism design, game mechanism design, model\nwatermarking, and efficiency. The ten challenging problems manifest in five\npivotal aspects: ``Foundational Theory,\" which aims to establish a coherent and\nunifying theoretical framework for FedFMs. ``Data,\" addressing the difficulties\nin leveraging domain-specific knowledge from private data while maintaining\nprivacy; ``Heterogeneity,\" examining variations in data, model, and\ncomputational resources across clients; ``Security and Privacy,\" focusing on\ndefenses against malicious attacks and model theft; and ``Efficiency,\"\nhighlighting the need for improvements in training, communication, and\nparameter efficiency. For each problem, we offer a clear mathematical\ndefinition on the objective function, analyze existing methods, and discuss the\nkey challenges and potential solutions. This in-depth exploration aims to\nadvance the theoretical foundations of FedFMs, guide practical implementations,\nand inspire future research to overcome these obstacles, thereby enabling the\nrobust, efficient, and privacy-preserving FedFMs in various real-world\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12176v1",
    "published_date": "2025-02-14 04:01:15 UTC",
    "updated_date": "2025-02-14 04:01:15 UTC"
  },
  {
    "arxiv_id": "2502.09891v1",
    "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
    "authors": [
      "Shu Wang",
      "Yixiang Fang",
      "Yingli Zhou",
      "Xilin Liu",
      "Yuchi Ma"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has proven effective in integrating\nexternal knowledge into large language models (LLMs) for question-answer (QA)\ntasks. The state-of-the-art RAG approaches often use the graph data as the\nexternal data since they capture the rich semantic information and link\nrelationships between entities. However, existing graph-based RAG approaches\ncannot accurately identify the relevant information from the graph and also\nconsume large numbers of tokens in the online retrieval process. To address\nthese issues, we introduce a novel graph-based RAG approach, called Attributed\nCommunity-based Hierarchical RAG (ArchRAG), by augmenting the question using\nattributed communities, and also introducing a novel LLM-based hierarchical\nclustering method. To retrieve the most relevant information from the graph for\nthe question, we build a novel hierarchical index structure for the attributed\ncommunities and develop an effective online retrieval method. Experimental\nresults demonstrate that ArchRAG outperforms existing methods in terms of both\naccuracy and token cost.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09891v1",
    "published_date": "2025-02-14 03:28:36 UTC",
    "updated_date": "2025-02-14 03:28:36 UTC"
  },
  {
    "arxiv_id": "2502.09889v1",
    "title": "Evaluating and Improving Graph-based Explanation Methods for Multi-Agent Coordination",
    "authors": [
      "Siva Kailas",
      "Shalin Jain",
      "Harish Ravichandar"
    ],
    "abstract": "Graph Neural Networks (GNNs), developed by the graph learning community, have\nbeen adopted and shown to be highly effective in multi-robot and multi-agent\nlearning. Inspired by this successful cross-pollination, we investigate and\ncharacterize the suitability of existing GNN explanation methods for explaining\nmulti-agent coordination. We find that these methods have the potential to\nidentify the most-influential communication channels that impact the team's\nbehavior. Informed by our initial analyses, we propose an attention entropy\nregularization term that renders GAT-based policies more amenable to existing\ngraph-based explainers. Intuitively, minimizing attention entropy incentivizes\nagents to limit their attention to the most influential or impactful agents,\nthereby easing the challenge faced by the explainer. We theoretically ground\nthis intuition by showing that minimizing attention entropy increases the\ndisparity between the explainer-generated subgraph and its complement.\nEvaluations across three tasks and three team sizes i) provides insights into\nthe effectiveness of existing explainers, and ii) demonstrates that our\nproposed regularization consistently improves explanation quality without\nsacrificing task performance.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "19 pages, 8 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.09889v1",
    "published_date": "2025-02-14 03:25:45 UTC",
    "updated_date": "2025-02-14 03:25:45 UTC"
  },
  {
    "arxiv_id": "2502.09886v1",
    "title": "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos",
    "authors": [
      "Weirui Ye",
      "Fangchen Liu",
      "Zheng Ding",
      "Yang Gao",
      "Oleh Rybkin",
      "Pieter Abbeel"
    ],
    "abstract": "Simulation offers a promising approach for cheaply scaling training data for\ngeneralist policies. To scalably generate data from diverse and realistic\ntasks, existing algorithms either rely on large language models (LLMs) that may\nhallucinate tasks not interesting for robotics; or digital twins, which require\ncareful real-to-sim alignment and are hard to scale. To address these\nchallenges, we introduce Video2Policy, a novel framework that leverages\ninternet RGB videos to reconstruct tasks based on everyday human behavior. Our\napproach comprises two phases: (1) task generation in simulation from videos;\nand (2) reinforcement learning utilizing in-context LLM-generated reward\nfunctions iteratively. We demonstrate the efficacy of Video2Policy by\nreconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,\nwhich depicts diverse and complex human behaviors on 9 different tasks. Our\nmethod can successfully train RL policies on such tasks, including complex and\nchallenging tasks such as throwing. Finally, we show that the generated\nsimulation data can be scaled up for training a general policy, and it can be\ntransferred back to the real robot in a Real2Sim2Real way.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09886v1",
    "published_date": "2025-02-14 03:22:03 UTC",
    "updated_date": "2025-02-14 03:22:03 UTC"
  },
  {
    "arxiv_id": "2502.09885v1",
    "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis",
    "authors": [
      "YongKyung Oh",
      "Seungsu Kam",
      "Jonghun Lee",
      "Dong-Young Lim",
      "Sungil Kim",
      "Alex Bui"
    ],
    "abstract": "Time series modeling and analysis has become critical in various domains.\nConventional methods such as RNNs and Transformers, while effective for\ndiscrete-time and regularly sampled data, face significant challenges in\ncapturing the continuous dynamics and irregular sampling patterns inherent in\nreal-world scenarios. Neural Differential Equations (NDEs) represent a paradigm\nshift by combining the flexibility of neural networks with the mathematical\nrigor of differential equations. This paper presents a comprehensive review of\nNDE-based methods for time series analysis, including neural ordinary\ndifferential equations, neural controlled differential equations, and neural\nstochastic differential equations. We provide a detailed discussion of their\nmathematical formulations, numerical methods, and applications, highlighting\ntheir ability to model continuous-time dynamics. Furthermore, we address key\nchallenges and future research directions. This survey serves as a foundation\nfor researchers and practitioners seeking to leverage NDEs for advanced time\nseries analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09885v1",
    "published_date": "2025-02-14 03:21:04 UTC",
    "updated_date": "2025-02-14 03:21:04 UTC"
  },
  {
    "arxiv_id": "2502.09884v2",
    "title": "Nonasymptotic CLT and Error Bounds for Two-Time-Scale Stochastic Approximation",
    "authors": [
      "Seo Taek Kong",
      "Sihan Zeng",
      "Thinh T. Doan",
      "R. Srikant"
    ],
    "abstract": "We consider linear two-time-scale stochastic approximation algorithms driven\nby martingale noise. Recent applications in machine learning motivate the need\nto understand finite-time error rates, but conventional stochastic\napproximation analysis focus on either asymptotic convergence in distribution\nor finite-time bounds that are far from optimal. Prior work on asymptotic\ncentral limit theorems (CLTs) suggest that two-time-scale algorithms may be\nable to achieve $1/\\sqrt{n}$ error in expectation, with a constant given by the\nexpected norm of the limiting Gaussian vector. However, the best known\nfinite-time rates are much slower. We derive the first non-asymptotic central\nlimit theorem with respect to the Wasserstein-1 distance for two-time-scale\nstochastic approximation with Polyak-Ruppert averaging. As a corollary, we show\nthat expected error achieved by Polyak-Ruppert averaging decays at rate\n$1/\\sqrt{n}$, which significantly improves on the rates of convergence in prior\nworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09884v2",
    "published_date": "2025-02-14 03:20:30 UTC",
    "updated_date": "2025-04-23 21:59:54 UTC"
  },
  {
    "arxiv_id": "2502.09874v2",
    "title": "FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation",
    "authors": [
      "Peng Ling",
      "Wenxiao Xiong"
    ],
    "abstract": "Nuclear instance segmentation has played a critical role in pathology image\nanalysis. The main challenges arise from the difficulty in accurately\nsegmenting instances and the high cost of precise mask-level annotations for\nfully-supervised training.In this work, we propose a fourier guidance framework\nfor solving the weakly-supervised nuclear instance segmentation problem. In\nthis framework, we construct a fourier guidance module to fuse the priori\ninformation into the training process of the model, which facilitates the model\nto capture the relevant features of the nuclear. Meanwhile, in order to further\nimprove the model's ability to represent the features of nuclear, we propose\nthe guide-based instance level contrastive module. This module makes full use\nof the framework's own properties and guide information to effectively enhance\nthe representation features of nuclear. We show on two public datasets that our\nmodel can outperform current SOTA methods under fully-supervised design, and in\nweakly-supervised experiments, with only a small amount of labeling our model\nstill maintains close to the performance under full supervision.In addition, we\nalso perform generalization experiments on a private dataset, and without any\nlabeling, our model is able to segment nuclear images that have not been seen\nduring training quite effectively. As open science, all codes and pre-trained\nmodels are available at https://github.com/LQY404/FrGNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09874v2",
    "published_date": "2025-02-14 02:51:25 UTC",
    "updated_date": "2025-02-18 05:10:50 UTC"
  },
  {
    "arxiv_id": "2502.09870v1",
    "title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies",
    "authors": [
      "Alicia DeVrio",
      "Myra Cheng",
      "Lisa Egede",
      "Alexandra Olteanu",
      "Su Lin Blodgett"
    ],
    "abstract": "Recent attention to anthropomorphism -- the attribution of human-like\nqualities to non-human objects or entities -- of language technologies like\nLLMs has sparked renewed discussions about potential negative impacts of\nanthropomorphism. To productively discuss the impacts of this anthropomorphism\nand in what contexts it is appropriate, we need a shared vocabulary for the\nvast variety of ways that language can be anthropomorphic. In this work, we\ndraw on existing literature and analyze empirical cases of user interactions\nwith language technologies to develop a taxonomy of textual expressions that\ncan contribute to anthropomorphism. We highlight challenges and tensions\ninvolved in understanding linguistic anthropomorphism, such as how all language\nis fundamentally human and how efforts to characterize and shift perceptions of\nhumanness in machines can also dehumanize certain humans. We discuss ways that\nour taxonomy supports more precise and effective discussions of and decisions\nabout anthropomorphism of language technologies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 1 figure, to appear at CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09870v1",
    "published_date": "2025-02-14 02:43:46 UTC",
    "updated_date": "2025-02-14 02:43:46 UTC"
  },
  {
    "arxiv_id": "2502.09866v1",
    "title": "How Users Who are Blind or Low Vision Play Mobile Games: Perceptions, Challenges, and Strategies",
    "authors": [
      "Zihe Ran",
      "Xiyu Li",
      "Qing Xiao",
      "Xianzhe Fan",
      "Franklin Mingzhe Li",
      "Yanyun Wang",
      "Zhicong Lu"
    ],
    "abstract": "As blind and low-vision (BLV) players engage more deeply with games,\naccessibility features have become essential. While some research has explored\ntools and strategies to enhance game accessibility, the specific experiences of\nthese players with mobile games remain underexamined. This study addresses this\ngap by investigating how BLV users experience mobile games with varying\naccessibility levels. Through interviews with 32 experienced BLV mobile\nplayers, we explore their perceptions, challenges, and strategies for engaging\nwith mobile games. Our findings reveal that BLV players turn to mobile games to\nalleviate boredom, achieve a sense of accomplishment, and build social\nconnections, but face barriers depending on the game's accessibility level. We\nalso compare mobile games to other forms of gaming, highlighting the relative\nadvantages of mobile games, such as the inherent accessibility of smartphones.\nThis study contributes to understanding BLV mobile gaming experiences and\nprovides insights for enhancing accessible mobile game design.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 3 figures, Accepted by CHI '25",
    "pdf_url": "http://arxiv.org/pdf/2502.09866v1",
    "published_date": "2025-02-14 02:27:53 UTC",
    "updated_date": "2025-02-14 02:27:53 UTC"
  },
  {
    "arxiv_id": "2502.09861v1",
    "title": "A Scoresheet for Explainable AI",
    "authors": [
      "Michael Winikoff",
      "John Thangarajah",
      "Sebastian Rodriguez"
    ],
    "abstract": "Explainability is important for the transparency of autonomous and\nintelligent systems and for helping to support the development of appropriate\nlevels of trust. There has been considerable work on developing approaches for\nexplaining systems and there are standards that specify requirements for\ntransparency. However, there is a gap: the standards are too high-level and do\nnot adequately specify requirements for explainability. This paper develops a\nscoresheet that can be used to specify explainability requirements or to assess\nthe explainability aspects provided for particular applications. The scoresheet\nis developed by considering the requirements of a range of stakeholders and is\napplicable to Multiagent Systems as well as other AI technologies. We also\nprovide guidance for how to use the scoresheet and illustrate its generality\nand usefulness by applying it to a range of applications.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear at AAMAS 2025 - arXiv version also includes appendices",
    "pdf_url": "http://arxiv.org/pdf/2502.09861v1",
    "published_date": "2025-02-14 02:08:10 UTC",
    "updated_date": "2025-02-14 02:08:10 UTC"
  },
  {
    "arxiv_id": "2502.09858v1",
    "title": "Automated Hypothesis Validation with Agentic Sequential Falsifications",
    "authors": [
      "Kexin Huang",
      "Ying Jin",
      "Ryan Li",
      "Michael Y. Li",
      "Emmanuel Candès",
      "Jure Leskovec"
    ],
    "abstract": "Hypotheses are central to information acquisition, decision-making, and\ndiscovery. However, many real-world hypotheses are abstract, high-level\nstatements that are difficult to validate directly. This challenge is further\nintensified by the rise of hypothesis generation from Large Language Models\n(LLMs), which are prone to hallucination and produce hypotheses in volumes that\nmake manual validation impractical. Here we propose Popper, an agentic\nframework for rigorous automated validation of free-form hypotheses. Guided by\nKarl Popper's principle of falsification, Popper validates a hypothesis using\nLLM agents that design and execute falsification experiments targeting its\nmeasurable implications. A novel sequential testing framework ensures strict\nType-I error control while actively gathering evidence from diverse\nobservations, whether drawn from existing data or newly conducted procedures.\nWe demonstrate Popper on six domains including biology, economics, and\nsociology. Popper delivers robust error control, high power, and scalability.\nFurthermore, compared to human scientists, Popper achieved comparable\nperformance in validating complex biological hypotheses while reducing time by\n10 folds, providing a scalable, rigorous solution for hypothesis validation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09858v1",
    "published_date": "2025-02-14 01:46:00 UTC",
    "updated_date": "2025-02-14 01:46:00 UTC"
  },
  {
    "arxiv_id": "2502.10482v2",
    "title": "A Self-Supervised Reinforcement Learning Approach for Fine-Tuning Large Language Models Using Cross-Attention Signals",
    "authors": [
      "Andrew Kiruluta",
      "Andreas Lemos",
      "Priscilla Burity"
    ],
    "abstract": "We propose a novel reinforcement learning framework for post training large\nlanguage models that does not rely on human in the loop feedback. Instead, our\napproach uses cross attention signals within the model itself to derive a self\nsupervised reward, thereby guiding iterative fine tuning of the model policy.\nBy analyzing how the model attends to the input prompt during generation, we\nconstruct measures of prompt coverage, focus, and coherence. We then use these\nmeasures to rank or score candidate responses, providing a reward signal that\nencourages the model to produce well aligned, on topic text. In empirical\ncomparisons against standard policy gradient methods and RL fine tuning with\nsynthetic preference models, our method shows significant gains in prompt\nrelevance and consistency over a non RL baseline. While it does not yet match\nthe performance of fully human supervised RLHF systems, it highlights an\nimportant direction for scaling alignment with minimal human labeling. We\nprovide a detailed analysis, discuss potential limitations, and outline future\nwork for combining cross-attention based signals with smaller amounts of human\nfeedback.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10482v2",
    "published_date": "2025-02-14 01:44:04 UTC",
    "updated_date": "2025-04-16 18:56:58 UTC"
  },
  {
    "arxiv_id": "2502.09854v1",
    "title": "Efficient Multitask Learning in Small Language Models Through Upside-Down Reinforcement Learning",
    "authors": [
      "Yu-Chen Lin",
      "Sanat Sharma",
      "Hari Manikandan",
      "Jayant Kumar",
      "Tracy Holloway King",
      "Jing Zheng"
    ],
    "abstract": "In this work, we demonstrate that small language models (SLMs), specifically\na 100M parameter GPT-2 model, can achieve competitive performance in multitask\nprompt generation tasks while requiring only a fraction of the computational\nresources needed by large language models (LLMs). Through a novel combination\nof upside-down reinforcement learning and synthetic data distillation from a\npowerful LLM, Llama-3, we train an SLM that achieves relevance scores within 5%\nof state-of-the-art models, including Llama-3, Qwen2, and Mistral, despite\nbeing up to 80 times smaller, making it highly suitable for\nresource-constrained and real-time applications. This study highlights the\npotential of SLMs as efficient multitask learners in multimodal settings,\nproviding a promising alternative to LLMs for scalable, low-latency\ndeployments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09854v1",
    "published_date": "2025-02-14 01:39:45 UTC",
    "updated_date": "2025-02-14 01:39:45 UTC"
  },
  {
    "arxiv_id": "2502.09843v1",
    "title": "MuDoC: An Interactive Multimodal Document-grounded Conversational AI System",
    "authors": [
      "Karan Taneja",
      "Ashok K. Goel"
    ],
    "abstract": "Multimodal AI is an important step towards building effective tools to\nleverage multiple modalities in human-AI communication. Building a multimodal\ndocument-grounded AI system to interact with long documents remains a\nchallenge. Our work aims to fill the research gap of directly leveraging\ngrounded visuals from documents alongside textual content in documents for\nresponse generation. We present an interactive conversational AI agent 'MuDoC'\nbased on GPT-4o to generate document-grounded responses with interleaved text\nand figures. MuDoC's intelligent textbook interface promotes trustworthiness\nand enables verification of system responses by allowing instant navigation to\nsource text and figures in the documents. We also discuss qualitative\nobservations based on MuDoC responses highlighting its strengths and\nlimitations.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 3 figures, AAAI-MAKE 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.09843v1",
    "published_date": "2025-02-14 01:05:51 UTC",
    "updated_date": "2025-02-14 01:05:51 UTC"
  },
  {
    "arxiv_id": "2502.09838v3",
    "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation",
    "authors": [
      "Tianwei Lin",
      "Wenqiao Zhang",
      "Sijing Li",
      "Yuqian Yuan",
      "Binhe Yu",
      "Haoyuan Li",
      "Wanggui He",
      "Hao Jiang",
      "Mengze Li",
      "Xiaohui Song",
      "Siliang Tang",
      "Jun Xiao",
      "Hui Lin",
      "Yueting Zhuang",
      "Beng Chin Ooi"
    ],
    "abstract": "We present HealthGPT, a powerful Medical Large Vision-Language Model\n(Med-LVLM) that integrates medical visual comprehension and generation\ncapabilities within a unified autoregressive paradigm. Our bootstrapping\nphilosophy is to progressively adapt heterogeneous comprehension and generation\nknowledge to pre-trained large language models (LLMs). This is achieved through\na novel heterogeneous low-rank adaptation (H-LoRA) technique, which is\ncomplemented by a tailored hierarchical visual perception approach and a\nthree-stage learning strategy. To effectively learn the HealthGPT, we devise a\ncomprehensive medical domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate exceptional performance and\nscalability of HealthGPT in medical visual unified tasks. Our project can be\naccessed at https://github.com/DCDmllm/HealthGPT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Comments: added project page",
    "pdf_url": "http://arxiv.org/pdf/2502.09838v3",
    "published_date": "2025-02-14 00:42:36 UTC",
    "updated_date": "2025-02-21 17:39:29 UTC"
  },
  {
    "arxiv_id": "2502.12175v1",
    "title": "Spatiotemporal Graph Neural Networks in short term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?",
    "authors": [
      "Quoc Viet Nguyen",
      "Joaquin Delgado Fernandez",
      "Sergio Potenciano Menci"
    ],
    "abstract": "Short term Load Forecasting (STLF) plays an important role in traditional and\nmodern power systems. Most STLF models predominantly exploit temporal\ndependencies from historical data to predict future consumption. Nowadays, with\nthe widespread deployment of smart meters, their data can contain\nspatiotemporal dependencies. In particular, their consumption data is not only\ncorrelated to historical values but also to the values of neighboring smart\nmeters. This new characteristic motivates researchers to explore and experiment\nwith new models that can effectively integrate spatiotemporal interrelations to\nincrease forecasting performance. Spatiotemporal Graph Neural Networks (STGNNs)\ncan leverage such interrelations by modeling relationships between smart meters\nas a graph and using these relationships as additional features to predict\nfuture energy consumption. While extensively studied in other spatiotemporal\nforecasting domains such as traffic, environments, or renewable energy\ngeneration, their application to load forecasting remains relatively\nunexplored, particularly in scenarios where the graph structure is not\ninherently available. This paper overviews the current literature focusing on\nSTGNNs with application in STLF. Additionally, from a technical perspective, it\nalso benchmarks selected STGNN models for STLF at the residential and aggregate\nlevels. The results indicate that incorporating graph features can improve\nforecasting accuracy at the residential level; however, this effect is not\nreflected at the aggregate level",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2502.12175v1",
    "published_date": "2025-02-14 00:16:47 UTC",
    "updated_date": "2025-02-14 00:16:47 UTC"
  },
  {
    "arxiv_id": "2502.09829v1",
    "title": "Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection",
    "authors": [
      "Abrar Anwar",
      "Rohan Gupta",
      "Zain Merchant",
      "Sayan Ghosh",
      "Willie Neiswanger",
      "Jesse Thomason"
    ],
    "abstract": "Evaluating learned robot control policies to determine their physical\ntask-level capabilities costs experimenter time and effort. The growing number\nof policies and tasks exacerbates this issue. It is impractical to test every\npolicy on every task multiple times; each trial requires a manual environment\nreset, and each task change involves re-arranging objects or even changing\nrobots. Naively selecting a random subset of tasks and policies to evaluate is\na high-cost solution with unreliable, incomplete results. In this work, we\nformulate robot evaluation as an active testing problem. We propose to model\nthe distribution of robot performance across all tasks and policies as we\nsequentially execute experiments. Tasks often share similarities that can\nreveal potential relationships in policy behavior, and we show that natural\nlanguage is a useful prior in modeling these relationships between tasks. We\nthen leverage this formulation to reduce the experimenter effort by using a\ncost-aware expected information gain heuristic to efficiently select\ninformative trials. Our framework accommodates both continuous and discrete\nperformance outcomes. We conduct experiments on existing evaluation data from\nreal robots and simulations. By prioritizing informative trials, our framework\nreduces the cost of calculating evaluation metrics for robot policies across\nmany tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09829v1",
    "published_date": "2025-02-14 00:07:02 UTC",
    "updated_date": "2025-02-14 00:07:02 UTC"
  }
]