[
  {
    "arxiv_id": "2412.16791v1",
    "title": "Enhancing web traffic attacks identification through ensemble methods and feature selection",
    "authors": [
      "Daniel Urda",
      "Branly Martínez",
      "Nuño Basurto",
      "Meelis Kull",
      "Ángel Arroyo",
      "Álvaro Herrero"
    ],
    "abstract": "Websites, as essential digital assets, are highly vulnerable to cyberattacks\nbecause of their high traffic volume and the significant impact of breaches.\nThis study aims to enhance the identification of web traffic attacks by\nleveraging machine learning techniques. A methodology was proposed to extract\nrelevant features from HTTP traces using the CSIC2010 v2 dataset, which\nsimulates e-commerce web traffic. Ensemble methods, such as Random Forest and\nExtreme Gradient Boosting, were employed and compared against baseline\nclassifiers, including k-nearest Neighbor, LASSO, and Support Vector Machines.\nThe results demonstrate that the ensemble methods outperform baseline\nclassifiers by approximately 20% in predictive accuracy, achieving an Area\nUnder the ROC Curve (AUC) of 0.989. Feature selection methods such as\nInformation Gain, LASSO, and Random Forest further enhance the robustness of\nthese models. This study highlights the efficacy of ensemble models in\nimproving attack detection while minimizing performance variability, offering a\npractical framework for securing web traffic in diverse application contexts.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16791v1",
    "published_date": "2024-12-21 22:13:30 UTC",
    "updated_date": "2024-12-21 22:13:30 UTC"
  },
  {
    "arxiv_id": "2412.16788v2",
    "title": "DCOR: Anomaly Detection in Attributed Networks via Dual Contrastive Learning Reconstruction",
    "authors": [
      "Hossein Rafieizadeh",
      "Hadi Zare",
      "Mohsen Ghassemi Parsa",
      "Hadi Davardoust",
      "Meshkat Shariat Bagheri"
    ],
    "abstract": "Anomaly detection using a network-based approach is one of the most efficient\nways to identify abnormal events such as fraud, security breaches, and system\nfaults in a variety of applied domains. While most of the earlier works address\nthe complex nature of graph-structured data and predefined anomalies, the\nimpact of data attributes and emerging anomalies are often neglected. This\npaper introduces DCOR, a novel approach on attributed networks that integrates\nreconstruction-based anomaly detection with Contrastive Learning. Utilizing a\nGraph Neural Network (GNN) framework, DCOR contrasts the reconstructed\nadjacency and feature matrices from both the original and augmented graphs to\ndetect subtle anomalies. We employed comprehensive experimental studies on\nbenchmark datasets through standard evaluation measures. The results show that\nDCOR significantly outperforms state-of-the-art methods. Obtained results\ndemonstrate the efficacy of proposed approach in attributed networks with the\npotential of uncovering new patterns of anomalies.",
    "categories": [
      "cs.AI",
      "05C82 05C82 05C82 05C82",
      "I.2.6; G.2.2"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the Thirteenth International Conference on Complex\n  Networks and Their Applications",
    "pdf_url": "http://arxiv.org/pdf/2412.16788v2",
    "published_date": "2024-12-21 22:02:06 UTC",
    "updated_date": "2025-01-20 20:17:59 UTC"
  },
  {
    "arxiv_id": "2412.16772v1",
    "title": "Assessing Social Alignment: Do Personality-Prompted Large Language Models Behave Like Humans?",
    "authors": [
      "Ivan Zakazov",
      "Mikolaj Boronski",
      "Lorenzo Drudi",
      "Robert West"
    ],
    "abstract": "The ongoing revolution in language modelling has led to various novel\napplications, some of which rely on the emerging \"social abilities\" of large\nlanguage models (LLMs). Already, many turn to the new \"cyber friends\" for\nadvice during pivotal moments of their lives and trust them with their deepest\nsecrets, implying that accurate shaping of LLMs' \"personalities\" is paramount.\nLeveraging the vast diversity of data on which LLMs are pretrained,\nstate-of-the-art approaches prompt them to adopt a particular personality. We\nask (i) if personality-prompted models behave (i.e. \"make\" decisions when\npresented with a social situation) in line with the ascribed personality, and\n(ii) if their behavior can be finely controlled. We use classic psychological\nexperiments - the Milgram Experiment and the Ultimatum Game - as social\ninteraction testbeds and apply personality prompting to GPT-3.5/4/4o-mini/4o.\nOur experiments reveal failure modes of the prompt-based modulation of the\nmodels' \"behavior\", thus challenging the feasibility of personality prompting\nwith today's LLMs.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to NeurIPS 2024 Workshop on Behavioral Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2412.16772v1",
    "published_date": "2024-12-21 20:58:19 UTC",
    "updated_date": "2024-12-21 20:58:19 UTC"
  },
  {
    "arxiv_id": "2412.16768v1",
    "title": "A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits",
    "authors": [
      "Elham Musaaed",
      "Nabil Hewahi",
      "Abdulla Alasaadi"
    ],
    "abstract": "In recent years, ML algorithms have been shown to be useful for predicting\ndiseases based on health data and posed a potential application area for these\nalgorithms such as modeling of diseases. The majority of these applications\nemploy supervised rather than unsupervised ML algorithms. In addition, each\nyear, the amount of data in medical science grows rapidly. Moreover, these data\ninclude clinical and Patient-Related Factors (PRF), such as height, weight,\nage, other physical characteristics, blood sugar, lipids, insulin, etc., all of\nwhich will change continually over time. Analysis of historical data can help\nidentify disease risk factors and their interactions, which is useful for\ndisease diagnosis and prediction. This wealth of valuable information in these\ndata will help doctors diagnose accurately and people can become more aware of\nthe risk factors and key indicators to act proactively. The purpose of this\nstudy is to use six supervised ML approaches to fill this gap by conducting a\ncomprehensive experiment to investigate the correlation between PRF and\nDiabetes, Stroke, Heart Disease (HD), and Kidney Disease (KD). Moreover, it\nwill investigate the link between Diabetes, Stroke, and KD and PRF with HD.\nFurther, the research aims to compare and evaluate various ML algorithms for\nclassifying diseases based on the PRF. Additionally, it aims to compare and\nevaluate ML algorithms for classifying HD based on PRF as well as Diabetes,\nStroke, Asthma, Skin Cancer, and KD as attributes. Lastly, HD predictions will\nbe provided through a Web-based application on the most accurate classifier,\nwhich allows the users to input their values and predict the output.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16768v1",
    "published_date": "2024-12-21 20:46:40 UTC",
    "updated_date": "2024-12-21 20:46:40 UTC"
  },
  {
    "arxiv_id": "2412.16766v2",
    "title": "A Protocol for KG Construction Tasks Involving Users",
    "authors": [
      "Ademar Crotti Junior",
      "Christophe Debruyne"
    ],
    "abstract": "Knowledge graph construction (KGC) from (semi-)structured data is\nchallenging, and facilitating user involvement is an issue frequently brought\nup within this community. We cannot deny the progress we have made with respect\nto (declarative) knowledge graph construction languages and tools to help build\nsuch mappings. However, it is surprising that no two studies report on similar\nprotocols. This heterogeneity does not allow for comparing KGC languages,\ntechniques, and tools. This paper first analyses studies involving users to\nidentify the points of comparison. These gaps include a lack of systematic\nconsistency in task design, participant selection, and evaluation metrics.\nMoreover, there needs to be a systematic way of analyzing the data and\nreporting the findings, which is also lacking. We thus propose and introduce a\nuser protocol for KGC designed to address this challenge. Where possible, we\ndraw and take elements from the literature we deem fit for such a protocol. The\nprotocol, as such, allows for the comparison of languages and techniques for\nthe RDF Mapping Language (RML) core functionality, which is covered by most of\nthe other state-of-the-art techniques and tools. We also propose how the\nprotocol can be amended to compare extensions (of RML). This protocol provides\nan important step towards a more comparable evaluation of KGC user studies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.HC",
    "comment": "For associated repository, see\n  https://github.com/chrdebru/kgc-user-study-protocol",
    "pdf_url": "http://arxiv.org/pdf/2412.16766v2",
    "published_date": "2024-12-21 20:26:20 UTC",
    "updated_date": "2025-05-12 18:45:46 UTC"
  },
  {
    "arxiv_id": "2412.16764v1",
    "title": "Towards Selection and Transition Between Behavior-Based Neural Networks for Automated Driving",
    "authors": [
      "Iqra Aslam",
      "Igor Anpilogov",
      "Andreas Rausch"
    ],
    "abstract": "Autonomous driving technology is progressing rapidly, largely due to complex\nEnd To End systems based on deep neural networks. While these systems are\neffective, their complexity can make it difficult to understand their behavior,\nraising safety concerns. This paper presents a new solution a Behavior Selector\nthat uses multiple smaller artificial neural networks (ANNs) to manage\ndifferent driving tasks, such as lane following and turning. Rather than\nrelying on a single large network, which can be burdensome, require extensive\ntraining data, and is hard to understand, the developed approach allows the\nsystem to dynamically select the appropriate neural network for each specific\nbehavior (e.g., turns) in real time. We focus on ensuring smooth transitions\nbetween behaviors while considering the vehicles current speed and orientation\nto improve stability and safety. The proposed system has been tested using the\nAirSim simulation environment, demonstrating its effectiveness.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16764v1",
    "published_date": "2024-12-21 20:23:05 UTC",
    "updated_date": "2024-12-21 20:23:05 UTC"
  },
  {
    "arxiv_id": "2412.16762v1",
    "title": "A Method for the Runtime Validation of AI-based Environment Perception in Automated Driving System",
    "authors": [
      "Iqra Aslam",
      "Abhishek Buragohain",
      "Daniel Bamal",
      "Adina Aniculaesei",
      "Meng Zhang",
      "Andreas Rausch"
    ],
    "abstract": "Environment perception is a fundamental part of the dynamic driving task\nexecuted by Autonomous Driving Systems (ADS). Artificial Intelligence\n(AI)-based approaches have prevailed over classical techniques for realizing\nthe environment perception. Current safety-relevant standards for automotive\nsystems, International Organization for Standardization (ISO) 26262 and ISO\n21448, assume the existence of comprehensive requirements specifications. These\nspecifications serve as the basis on which the functionality of an automotive\nsystem can be rigorously tested and checked for compliance with safety\nregulations. However, AI-based perception systems do not have complete\nrequirements specification. Instead, large datasets are used to train AI-based\nperception systems. This paper presents a function monitor for the functional\nruntime monitoring of a two-folded AI-based environment perception for ADS,\nbased respectively on camera and LiDAR sensors. To evaluate the applicability\nof the function monitor, we conduct a qualitative scenario-based evaluation in\na controlled laboratory environment using a model car. The evaluation results\nthen are discussed to provide insights into the monitor's performance and its\nsuitability for real-world applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16762v1",
    "published_date": "2024-12-21 20:21:49 UTC",
    "updated_date": "2024-12-21 20:21:49 UTC"
  },
  {
    "arxiv_id": "2412.16751v2",
    "title": "The Master Key Filters Hypothesis: Deep Filters Are General",
    "authors": [
      "Zahra Babaiee",
      "Peyman M. Kiasari",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "abstract": "This paper challenges the prevailing view that convolutional neural network\n(CNN) filters become increasingly specialized in deeper layers. Motivated by\nrecent observations of clusterable repeating patterns in depthwise separable\nCNNs (DS-CNNs) trained on ImageNet, we extend this investigation across various\ndomains and datasets. Our analysis of DS-CNNs reveals that deep filters\nmaintain generality, contradicting the expected transition to class-specific\nfilters. We demonstrate the generalizability of these filters through transfer\nlearning experiments, showing that frozen filters from models trained on\ndifferent datasets perform well and can be further improved when sourced from\nlarger datasets. Our findings indicate that spatial features learned by\ndepthwise separable convolutions remain generic across all layers, domains, and\narchitectures. This research provides new insights into the nature of\ngeneralization in neural networks, particularly in DS-CNNs, and has significant\nimplications for transfer learning and model design.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16751v2",
    "published_date": "2024-12-21 20:04:23 UTC",
    "updated_date": "2025-02-03 16:58:12 UTC"
  },
  {
    "arxiv_id": "2412.16746v4",
    "title": "Beyond Partisan Leaning: A Comparative Analysis of Political Bias in Large Language Models",
    "authors": [
      "Tai-Quan Peng",
      "Kaiqi Yang",
      "Sanguk Lee",
      "Hang Li",
      "Yucheng Chu",
      "Yuping Lin",
      "Hui Liu"
    ],
    "abstract": "As large language models (LLMs) become increasingly embedded in civic,\neducational, and political information environments, concerns about their\npotential political bias have grown. Prior research often evaluates such bias\nthrough simulated personas or predefined ideological typologies, which may\nintroduce artificial framing effects or overlook how models behave in general\nuse scenarios. This study adopts a persona-free, topic-specific approach to\nevaluate political behavior in LLMs, reflecting how users typically interact\nwith these systems-without ideological role-play or conditioning. We introduce\na two-dimensional framework: one axis captures partisan orientation on highly\npolarized topics (e.g., abortion, immigration), and the other assesses\nsociopolitical engagement on less polarized issues (e.g., climate change,\nforeign policy). Using survey-style prompts drawn from the ANES and Pew\nResearch Center, we analyze responses from 43 LLMs developed in the U.S.,\nEurope, China, and the Middle East. We propose an entropy-weighted bias score\nto quantify both the direction and consistency of partisan alignment, and\nidentify four behavioral clusters through engagement profiles. Findings show\nmost models lean center-left or left ideologically and vary in their\nnonpartisan engagement patterns. Model scale and openness are not strong\npredictors of behavior, suggesting that alignment strategy and institutional\ncontext play a more decisive role in shaping political expression.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16746v4",
    "published_date": "2024-12-21 19:42:40 UTC",
    "updated_date": "2025-05-10 15:25:28 UTC"
  },
  {
    "arxiv_id": "2412.16728v1",
    "title": "Reasoning about Actual Causes in Nondeterministic Domains -- Extended Version",
    "authors": [
      "Shakil M. Khan",
      "Yves Lespérance",
      "Maryam Rostamigiv"
    ],
    "abstract": "Reasoning about the causes behind observations is crucial to the\nformalization of rationality. While extensive research has been conducted on\nroot cause analysis, most studies have predominantly focused on deterministic\nsettings. In this paper, we investigate causation in more realistic\nnondeterministic domains, where the agent does not have any control on and may\nnot know the choices that are made by the environment. We build on recent\npreliminary work on actual causation in the nondeterministic situation calculus\nto formalize more sophisticated forms of reasoning about actual causes in such\ndomains. We investigate the notions of ``Certainly Causes'' and ``Possibly\nCauses'' that enable the representation of actual cause for agent actions in\nthese domains. We then show how regression in the situation calculus can be\nextended to reason about such notions of actual causes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16728v1",
    "published_date": "2024-12-21 18:35:25 UTC",
    "updated_date": "2024-12-21 18:35:25 UTC"
  },
  {
    "arxiv_id": "2412.16725v1",
    "title": "Argumentation Computation with Large Language Models : A Benchmark Study",
    "authors": [
      "Zhaoqun Li",
      "Xiaotong Fang",
      "Chen Chen",
      "Mengze Li",
      "Beishui Liao"
    ],
    "abstract": "In recent years, large language models (LLMs) have made significant\nadvancements in neuro-symbolic computing. However, the combination of LLM with\nargumentation computation remains an underexplored domain, despite its\nconsiderable potential for real-world applications requiring defeasible\nreasoning. In this paper, we aim to investigate the capability of LLMs in\ndetermining the extensions of various abstract argumentation semantics. To\nachieve this, we develop and curate a benchmark comprising diverse abstract\nargumentation frameworks, accompanied by detailed explanations of algorithms\nfor computing extensions. Subsequently, we fine-tune LLMs on the proposed\nbenchmark, focusing on two fundamental extension-solving tasks. As a\ncomparative baseline, LLMs are evaluated using a chain-of-thought approach,\nwhere they struggle to accurately compute semantics. In the experiments, we\ndemonstrate that the process explanation plays a crucial role in semantics\ncomputation learning. Models trained with explanations show superior\ngeneralization accuracy compared to those trained solely with question-answer\npairs. Furthermore, by leveraging the self-explanation capabilities of LLMs,\nour approach provides detailed illustrations that mitigate the lack of\ntransparency typically associated with neural networks. Our findings contribute\nto the broader understanding of LLMs' potential in argumentation computation,\noffering promising avenues for further research in this domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16725v1",
    "published_date": "2024-12-21 18:23:06 UTC",
    "updated_date": "2024-12-21 18:23:06 UTC"
  },
  {
    "arxiv_id": "2412.16724v1",
    "title": "Coupling Neural Networks and Physics Equations For Li-Ion Battery State-of-Charge Prediction",
    "authors": [
      "Giovanni Pollo",
      "Alessio Burrello",
      "Enrico Macii",
      "Massimo Poncino",
      "Sara Vinco",
      "Daniele Jahier Pagliari"
    ],
    "abstract": "Estimating the evolution of the battery's State of Charge (SoC) in response\nto its usage is critical for implementing effective power management policies\nand for ultimately improving the system's lifetime. Most existing estimation\nmethods are either physics-based digital twins of the battery or data-driven\nmodels such as Neural Networks (NNs). In this work, we propose two new\ncontributions in this domain. First, we introduce a novel NN architecture\nformed by two cascaded branches: one to predict the current SoC based on sensor\nreadings, and one to estimate the SoC at a future time as a function of the\nload behavior. Second, we integrate battery dynamics equations into the\ntraining of our NN, merging the physics-based and data-driven approaches, to\nimprove the models' generalization over variable prediction horizons. We\nvalidate our approach on two publicly accessible datasets, showing that our\nPhysics-Informed Neural Networks (PINNs) outperform purely data-driven ones\nwhile also obtaining superior prediction accuracy with a smaller architecture\nwith respect to the state-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16724v1",
    "published_date": "2024-12-21 18:19:12 UTC",
    "updated_date": "2024-12-21 18:19:12 UTC"
  },
  {
    "arxiv_id": "2412.16720v1",
    "title": "OpenAI o1 System Card",
    "authors": [
      "OpenAI",
      ":",
      "Aaron Jaech",
      "Adam Kalai",
      "Adam Lerer",
      "Adam Richardson",
      "Ahmed El-Kishky",
      "Aiden Low",
      "Alec Helyar",
      "Aleksander Madry",
      "Alex Beutel",
      "Alex Carney",
      "Alex Iftimie",
      "Alex Karpenko",
      "Alex Tachard Passos",
      "Alexander Neitz",
      "Alexander Prokofiev",
      "Alexander Wei",
      "Allison Tam",
      "Ally Bennett",
      "Ananya Kumar",
      "Andre Saraiva",
      "Andrea Vallone",
      "Andrew Duberstein",
      "Andrew Kondrich",
      "Andrey Mishchenko",
      "Andy Applebaum",
      "Angela Jiang",
      "Ashvin Nair",
      "Barret Zoph",
      "Behrooz Ghorbani",
      "Ben Rossen",
      "Benjamin Sokolowsky",
      "Boaz Barak",
      "Bob McGrew",
      "Borys Minaiev",
      "Botao Hao",
      "Bowen Baker",
      "Brandon Houghton",
      "Brandon McKinzie",
      "Brydon Eastman",
      "Camillo Lugaresi",
      "Cary Bassin",
      "Cary Hudson",
      "Chak Ming Li",
      "Charles de Bourcy",
      "Chelsea Voss",
      "Chen Shen",
      "Chong Zhang",
      "Chris Koch",
      "Chris Orsinger",
      "Christopher Hesse",
      "Claudia Fischer",
      "Clive Chan",
      "Dan Roberts",
      "Daniel Kappler",
      "Daniel Levy",
      "Daniel Selsam",
      "David Dohan",
      "David Farhi",
      "David Mely",
      "David Robinson",
      "Dimitris Tsipras",
      "Doug Li",
      "Dragos Oprica",
      "Eben Freeman",
      "Eddie Zhang",
      "Edmund Wong",
      "Elizabeth Proehl",
      "Enoch Cheung",
      "Eric Mitchell",
      "Eric Wallace",
      "Erik Ritter",
      "Evan Mays",
      "Fan Wang",
      "Felipe Petroski Such",
      "Filippo Raso",
      "Florencia Leoni",
      "Foivos Tsimpourlas",
      "Francis Song",
      "Fred von Lohmann",
      "Freddie Sulit",
      "Geoff Salmon",
      "Giambattista Parascandolo",
      "Gildas Chabot",
      "Grace Zhao",
      "Greg Brockman",
      "Guillaume Leclerc",
      "Hadi Salman",
      "Haiming Bao",
      "Hao Sheng",
      "Hart Andrin",
      "Hessam Bagherinezhad",
      "Hongyu Ren",
      "Hunter Lightman",
      "Hyung Won Chung",
      "Ian Kivlichan",
      "Ian O'Connell",
      "Ian Osband",
      "Ignasi Clavera Gilaberte",
      "Ilge Akkaya",
      "Ilya Kostrikov",
      "Ilya Sutskever",
      "Irina Kofman",
      "Jakub Pachocki",
      "James Lennon",
      "Jason Wei",
      "Jean Harb",
      "Jerry Twore",
      "Jiacheng Feng",
      "Jiahui Yu",
      "Jiayi Weng",
      "Jie Tang",
      "Jieqi Yu",
      "Joaquin Quiñonero Candela",
      "Joe Palermo",
      "Joel Parish",
      "Johannes Heidecke",
      "John Hallman",
      "John Rizzo",
      "Jonathan Gordon",
      "Jonathan Uesato",
      "Jonathan Ward",
      "Joost Huizinga",
      "Julie Wang",
      "Kai Chen",
      "Kai Xiao",
      "Karan Singhal",
      "Karina Nguyen",
      "Karl Cobbe",
      "Katy Shi",
      "Kayla Wood",
      "Kendra Rimbach",
      "Keren Gu-Lemberg",
      "Kevin Liu",
      "Kevin Lu",
      "Kevin Stone",
      "Kevin Yu",
      "Lama Ahmad",
      "Lauren Yang",
      "Leo Liu",
      "Leon Maksin",
      "Leyton Ho",
      "Liam Fedus",
      "Lilian Weng",
      "Linden Li",
      "Lindsay McCallum",
      "Lindsey Held",
      "Lorenz Kuhn",
      "Lukas Kondraciuk",
      "Lukasz Kaiser",
      "Luke Metz",
      "Madelaine Boyd",
      "Maja Trebacz",
      "Manas Joglekar",
      "Mark Chen",
      "Marko Tintor",
      "Mason Meyer",
      "Matt Jones",
      "Matt Kaufer",
      "Max Schwarzer",
      "Meghan Shah",
      "Mehmet Yatbaz",
      "Melody Y. Guan",
      "Mengyuan Xu",
      "Mengyuan Yan",
      "Mia Glaese",
      "Mianna Chen",
      "Michael Lampe",
      "Michael Malek",
      "Michele Wang",
      "Michelle Fradin",
      "Mike McClay",
      "Mikhail Pavlov",
      "Miles Wang",
      "Mingxuan Wang",
      "Mira Murati",
      "Mo Bavarian",
      "Mostafa Rohaninejad",
      "Nat McAleese",
      "Neil Chowdhury",
      "Neil Chowdhury",
      "Nick Ryder",
      "Nikolas Tezak",
      "Noam Brown",
      "Ofir Nachum",
      "Oleg Boiko",
      "Oleg Murk",
      "Olivia Watkins",
      "Patrick Chao",
      "Paul Ashbourne",
      "Pavel Izmailov",
      "Peter Zhokhov",
      "Rachel Dias",
      "Rahul Arora",
      "Randall Lin",
      "Rapha Gontijo Lopes",
      "Raz Gaon",
      "Reah Miyara",
      "Reimar Leike",
      "Renny Hwang",
      "Rhythm Garg",
      "Robin Brown",
      "Roshan James",
      "Rui Shu",
      "Ryan Cheu",
      "Ryan Greene",
      "Saachi Jain",
      "Sam Altman",
      "Sam Toizer",
      "Sam Toyer",
      "Samuel Miserendino",
      "Sandhini Agarwal",
      "Santiago Hernandez",
      "Sasha Baker",
      "Scott McKinney",
      "Scottie Yan",
      "Shengjia Zhao",
      "Shengli Hu",
      "Shibani Santurkar",
      "Shraman Ray Chaudhuri",
      "Shuyuan Zhang",
      "Siyuan Fu",
      "Spencer Papay",
      "Steph Lin",
      "Suchir Balaji",
      "Suvansh Sanjeev",
      "Szymon Sidor",
      "Tal Broda",
      "Aidan Clark",
      "Tao Wang",
      "Taylor Gordon",
      "Ted Sanders",
      "Tejal Patwardhan",
      "Thibault Sottiaux",
      "Thomas Degry",
      "Thomas Dimson",
      "Tianhao Zheng",
      "Timur Garipov",
      "Tom Stasi",
      "Trapit Bansal",
      "Trevor Creech",
      "Troy Peterson",
      "Tyna Eloundou",
      "Valerie Qi",
      "Vineet Kosaraju",
      "Vinnie Monaco",
      "Vitchyr Pong",
      "Vlad Fomenko",
      "Weiyi Zheng",
      "Wenda Zhou",
      "Wes McCabe",
      "Wojciech Zaremba",
      "Yann Dubois",
      "Yinghai Lu",
      "Yining Chen",
      "Young Cha",
      "Yu Bai",
      "Yuchen He",
      "Yuchen Zhang",
      "Yunyun Wang",
      "Zheng Shao",
      "Zhuohan Li"
    ],
    "abstract": "The o1 model series is trained with large-scale reinforcement learning to\nreason using chain of thought. These advanced reasoning capabilities provide\nnew avenues for improving the safety and robustness of our models. In\nparticular, our models can reason about our safety policies in context when\nresponding to potentially unsafe prompts, through deliberative alignment. This\nleads to state-of-the-art performance on certain benchmarks for risks such as\ngenerating illicit advice, choosing stereotyped responses, and succumbing to\nknown jailbreaks. Training models to incorporate a chain of thought before\nanswering has the potential to unlock substantial benefits, while also\nincreasing potential risks that stem from heightened intelligence. Our results\nunderscore the need for building robust alignment methods, extensively\nstress-testing their efficacy, and maintaining meticulous risk management\nprotocols. This report outlines the safety work carried out for the OpenAI o1\nand OpenAI o1-mini models, including safety evaluations, external red teaming,\nand Preparedness Framework evaluations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16720v1",
    "published_date": "2024-12-21 18:04:31 UTC",
    "updated_date": "2024-12-21 18:04:31 UTC"
  },
  {
    "arxiv_id": "2412.16719v2",
    "title": "Lillama: Large Language Models Compression via Low-Rank Feature Distillation",
    "authors": [
      "Yaya Sy",
      "Christophe Cerisara",
      "Irina Illina"
    ],
    "abstract": "Current LLM structured pruning methods typically involve two steps: (1)\ncompression with calibration data and (2) costly continued pretraining on\nbillions of tokens to recover lost performance. This second step is necessary\nas the first significantly impacts model accuracy. Prior research suggests\npretrained Transformer weights aren't inherently low-rank, unlike their\nactivations, which may explain this drop. Based on this observation, we propose\nLillama, a compression method that locally distills activations with low-rank\nweights. Using SVD for initialization and a joint loss combining teacher and\nstudent activations, we accelerate convergence and reduce memory use with local\ngradient updates. Lillama compresses Mixtral-8x7B within minutes on a single\nA100 GPU, removing 10 billion parameters while retaining over 95% of its\noriginal performance. Phi-2 3B can be compressed by 40% with just 13 million\ncalibration tokens, resulting in a small model that competes with recent models\nof similar size. The method generalizes well to non-transformer architectures,\ncompressing Mamba-3B by 20% while maintaining 99% performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16719v2",
    "published_date": "2024-12-21 18:04:01 UTC",
    "updated_date": "2024-12-28 17:45:12 UTC"
  },
  {
    "arxiv_id": "2412.16715v1",
    "title": "From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer",
    "authors": [
      "Zijiang Yang",
      "Zhongwei Qiu",
      "Tiancheng Lin",
      "Hanqing Chao",
      "Wanxing Chang",
      "Yelin Yang",
      "Yunshuo Zhang",
      "Wenpei Jiao",
      "Yixuan Shen",
      "Wenbin Liu",
      "Dongmei Fu",
      "Dakai Jin",
      "Ke Yan",
      "Le Lu",
      "Hui Jiang",
      "Yun Bian"
    ],
    "abstract": "It is clinically crucial and potentially very beneficial to be able to\nanalyze and model directly the spatial distributions of cells in histopathology\nwhole slide images (WSI). However, most existing WSI datasets lack cell-level\nannotations, owing to the extremely high cost over giga-pixel images. Thus, it\nremains an open question whether deep learning models can directly and\neffectively analyze WSIs from the semantic aspect of cell distributions. In\nthis work, we construct a large-scale WSI dataset with more than 5 billion\ncell-level annotations, termed WSI-Cell5B, and a novel hierarchical Cell Cloud\nTransformer (CCFormer) to tackle these challenges. WSI-Cell5B is based on 6,998\nWSIs of 11 cancers from The Cancer Genome Atlas Program, and all WSIs are\nannotated per cell by coordinates and types. To the best of our knowledge,\nWSI-Cell5B is the first WSI-level large-scale dataset integrating cell-level\nannotations. On the other hand, CCFormer formulates the collection of cells in\neach WSI as a cell cloud and models cell spatial distribution. Specifically,\nNeighboring Information Embedding (NIE) is proposed to characterize the\ndistribution of cells within the neighborhood of each cell, and a novel\nHierarchical Spatial Perception (HSP) module is proposed to learn the spatial\nrelationship among cells in a bottom-up manner. The clinical analysis indicates\nthat WSI-Cell5B can be used to design clinical evaluation metrics based on\ncounting cells that effectively assess the survival risk of patients. Extensive\nexperiments on survival prediction and cancer staging show that learning from\ncell spatial distribution alone can already achieve state-of-the-art (SOTA)\nperformance, i.e., CCFormer strongly outperforms other competing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16715v1",
    "published_date": "2024-12-21 17:57:12 UTC",
    "updated_date": "2024-12-21 17:57:12 UTC"
  },
  {
    "arxiv_id": "2412.19833v1",
    "title": "Multi-atlas Ensemble Graph Neural Network Model For Major Depressive Disorder Detection Using Functional MRI Data",
    "authors": [
      "Nojod M. Alotaibi",
      "Areej M. Alhothali",
      "Manar S. Ali"
    ],
    "abstract": "Major depressive disorder (MDD) is one of the most common mental disorders,\nwith significant impacts on many daily activities and quality of life. It\nstands as one of the most common mental disorders globally and ranks as the\nsecond leading cause of disability. The current diagnostic approach for MDD\nprimarily relies on clinical observations and patient-reported symptoms,\noverlooking the diverse underlying causes and pathophysiological factors\ncontributing to depression. Therefore, scientific researchers and clinicians\nmust gain a deeper understanding of the pathophysiological mechanisms involved\nin MDD. There is growing evidence in neuroscience that depression is a brain\nnetwork disorder, and the use of neuroimaging, such as magnetic resonance\nimaging (MRI), plays a significant role in identifying and treating MDD.\nRest-state functional MRI (rs-fMRI) is among the most popular neuroimaging\ntechniques used to study MDD. Deep learning techniques have been widely applied\nto neuroimaging data to help with early mental health disorder detection.\nRecent years have seen a rise in interest in graph neural networks (GNNs),\nwhich are deep neural architectures specifically designed to handle\ngraph-structured data like rs-fMRI. This research aimed to develop an\nensemble-based GNN model capable of detecting discriminative features from\nrs-fMRI images for the purpose of diagnosing MDD. Specifically, we constructed\nan ensemble model by combining features from multiple brain region segmentation\natlases to capture brain complexity and detect distinct features more\naccurately than single atlas-based models. Further, the effectiveness of our\nmodel is demonstrated by assessing its performance on a large multi-site MDD\ndataset. The best performing model among all folds achieved an accuracy of\n75.80%, a sensitivity of 88.89%, a specificity of 61.84%, a precision of\n71.29%, and an F1-score of 79.12%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "62P10, 68T07, 92B20",
      "I.2.6; J.3"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 2 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.19833v1",
    "published_date": "2024-12-21 17:08:03 UTC",
    "updated_date": "2024-12-21 17:08:03 UTC"
  },
  {
    "arxiv_id": "2412.16699v1",
    "title": "FAP-CD: Fairness-Driven Age-Friendly Community Planning via Conditional Diffusion Generation",
    "authors": [
      "Jinlin Li",
      "Xintong Li",
      "Xiao Zhou"
    ],
    "abstract": "As global populations age rapidly, incorporating age-specific considerations\ninto urban planning has become essential to addressing the urgent demand for\nage-friendly built environments and ensuring sustainable urban development.\nHowever, current practices often overlook these considerations, resulting in\ninadequate and unevenly distributed elderly services in cities. There is a\npressing need for equitable and optimized urban renewal strategies to support\neffective age-friendly planning. To address this challenge, we propose a novel\nframework, Fairness-driven Age-friendly community Planning via Conditional\nDiffusion generation (FAP-CD). FAP-CD leverages a conditioned graph denoising\ndiffusion probabilistic model to learn the joint probability distribution of\naging facilities and their spatial relationships at a fine-grained regional\nlevel. Our framework generates optimized facility distributions by iteratively\nrefining noisy graphs, conditioned on the needs of the elderly during the\ndiffusion process. Key innovations include a demand-fairness pre-training\nmodule that integrates community demand features and facility characteristics\nusing an attention mechanism and min-max optimization, ensuring equitable\nservice distribution across regions. Additionally, a discrete graph structure\ncaptures walkable accessibility within regional road networks, guiding model\nsampling. To enhance information integration, we design a graph denoising\nnetwork with an attribute augmentation module and a hybrid graph message\naggregation module, combining local and global node and edge information.\nEmpirical results across multiple metrics demonstrate the effectiveness of\nFAP-CD in balancing age-friendly needs with regional equity, achieving an\naverage improvement of 41% over competitive baseline models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16699v1",
    "published_date": "2024-12-21 16:57:09 UTC",
    "updated_date": "2024-12-21 16:57:09 UTC"
  },
  {
    "arxiv_id": "2412.16689v1",
    "title": "Formal Language Knowledge Corpus for Retrieval Augmented Generation",
    "authors": [
      "Majd Zayyad",
      "Yossi Adi"
    ],
    "abstract": "The integration of retrieval-augmented techniques with LLMs has shown promise\nin improving performance across various domains. However, their utility in\ntasks requiring advanced reasoning, such as generating and evaluating\nmathematical statements and proofs, remains underexplored. This study explores\nthe use of Lean, a programming language for writing mathematical proofs, to\npopulate the knowledge corpus used by RAG systems. We hope for this to lay the\nfoundation to exploring different methods of using RAGs to improve the\nperformance of LLMs in advanced logical reasoning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16689v1",
    "published_date": "2024-12-21 16:31:41 UTC",
    "updated_date": "2024-12-21 16:31:41 UTC"
  },
  {
    "arxiv_id": "2412.16687v2",
    "title": "Subgoal Discovery Using a Free Energy Paradigm and State Aggregations",
    "authors": [
      "Amirhossein Mesbah",
      "Reshad Hosseini",
      "Seyed Pooya Shariatpanahi",
      "Majid Nili Ahmadabadi"
    ],
    "abstract": "Reinforcement learning (RL) plays a major role in solving complex sequential\ndecision-making tasks. Hierarchical and goal-conditioned RL are promising\nmethods for dealing with two major problems in RL, namely sample inefficiency\nand difficulties in reward shaping. These methods tackle the mentioned problems\nby decomposing a task into simpler subtasks and temporally abstracting a task\nin the action space. One of the key components for task decomposition of these\nmethods is subgoal discovery. We can use the subgoal states to define\nhierarchies of actions and also use them in decomposing complex tasks. Under\nthe assumption that subgoal states are more unpredictable, we propose a free\nenergy paradigm to discover them. This is achieved by using free energy to\nselect between two spaces, the main space and an aggregation space. The $model\n\\; changes$ from neighboring states to a given state shows the unpredictability\nof a given state, and therefore it is used in this paper for subgoal discovery.\nOur empirical results on navigation tasks like grid-world environments show\nthat our proposed method can be applied for subgoal discovery without prior\nknowledge of the task. Our proposed method is also robust to the stochasticity\nof environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16687v2",
    "published_date": "2024-12-21 16:26:47 UTC",
    "updated_date": "2025-02-09 11:24:20 UTC"
  },
  {
    "arxiv_id": "2412.16682v1",
    "title": "The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents",
    "authors": [
      "Feiran Jia",
      "Tong Wu",
      "Xin Qin",
      "Anna Squicciarini"
    ],
    "abstract": "Large Language Model (LLM) agents are increasingly being deployed as\nconversational assistants capable of performing complex real-world tasks\nthrough tool integration. This enhanced ability to interact with external\nsystems and process various data sources, while powerful, introduces\nsignificant security vulnerabilities. In particular, indirect prompt injection\nattacks pose a critical threat, where malicious instructions embedded within\nexternal data sources can manipulate agents to deviate from user intentions.\nWhile existing defenses based on rule constraints, source spotlighting, and\nauthentication protocols show promise, they struggle to maintain robust\nsecurity while preserving task functionality. We propose a novel and orthogonal\nperspective that reframes agent security from preventing harmful actions to\nensuring task alignment, requiring every agent action to serve user objectives.\nBased on this insight, we develop Task Shield, a test-time defense mechanism\nthat systematically verifies whether each instruction and tool call contributes\nto user-specified goals. Through experiments on the AgentDojo benchmark, we\ndemonstrate that Task Shield reduces attack success rates (2.07\\%) while\nmaintaining high task utility (69.79\\%) on GPT-4o.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16682v1",
    "published_date": "2024-12-21 16:17:48 UTC",
    "updated_date": "2024-12-21 16:17:48 UTC"
  },
  {
    "arxiv_id": "2412.16674v1",
    "title": "STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling",
    "authors": [
      "Jieyi Wang",
      "Yue Huang",
      "Zeming Liu",
      "Dexuan Xu",
      "Chuan Wang",
      "Xiaoming Shi",
      "Ruiyuan Guan",
      "Hongxing Wang",
      "Weihua Yue",
      "Yu Huang"
    ],
    "abstract": "Online psychological counseling dialogue systems are trending, offering a\nconvenient and accessible alternative to traditional in-person therapy.\nHowever, existing psychological counseling dialogue systems mainly focus on\nbasic empathetic dialogue or QA with minimal professional knowledge and without\ngoal guidance. In many real-world counseling scenarios, clients often seek\nmulti-type help, such as diagnosis, consultation, therapy, console, and common\nquestions, but existing dialogue systems struggle to combine different dialogue\ntypes naturally. In this paper, we identify this challenge as how to construct\nmixed-type dialogue systems for psychological counseling that enable clients to\nclarify their goals before proceeding with counseling. To mitigate the\nchallenge, we collect a mixed-type counseling dialogues corpus termed STAMPsy,\ncovering five dialogue types, task-oriented dialogue for diagnosis,\nknowledge-grounded dialogue, conversational recommendation, empathetic\ndialogue, and question answering, over 5,000 conversations. Moreover,\nspatiotemporal-aware knowledge enables systems to have world awareness and has\nbeen proven to affect one's mental health. Therefore, we link dialogues in\nSTAMPsy to spatiotemporal state and propose a spatiotemporal-aware mixed-type\npsychological counseling dataset. Additionally, we build baselines on STAMPsy\nand develop an iterative self-feedback psychological dialogue generation\nframework, named Self-STAMPsy. Results indicate that clarifying dialogue goals\nin advance and utilizing spatiotemporal states are effective.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16674v1",
    "published_date": "2024-12-21 15:48:02 UTC",
    "updated_date": "2024-12-21 15:48:02 UTC"
  },
  {
    "arxiv_id": "2412.16673v1",
    "title": "On Enhancing Network Throughput using Reinforcement Learning in Sliced Testbeds",
    "authors": [
      "Daniel Pereira Monteiro",
      "Lucas Nardelli de Freitas Botelho Saar",
      "Larissa Ferreira Rodrigues Moreira",
      "Rodrigo Moreira"
    ],
    "abstract": "Novel applications demand high throughput, low latency, and high reliability\nconnectivity and still pose significant challenges to slicing orchestration\narchitectures. The literature explores network slicing techniques that employ\ncanonical methods, artificial intelligence, and combinatorial optimization to\naddress errors and ensure throughput for network slice data plane. This paper\nintroduces the Enhanced Mobile Broadband (eMBB)-Agent as a new approach that\nuses Reinforcement Learning (RL) in a vertical application to enhance network\nslicing throughput to fit Service-Level Agreements (SLAs). The eMBB-Agent\nanalyzes application transmission variables and proposes actions within a\ndiscrete space to adjust the reception window using a Deep Q-Network (DQN).\nThis paper also presents experimental results that examine the impact of\nfactors such as the channel error rate, DQN model layers, and learning rate on\nmodel convergence and achieved throughput, providing insights on embedding\nintelligence in network slicing.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper already published at Anais do XV Workshop de Pesquisa\n  Experimental da Internet do Futuro (WPEIF)",
    "pdf_url": "http://arxiv.org/pdf/2412.16673v1",
    "published_date": "2024-12-21 15:47:49 UTC",
    "updated_date": "2024-12-21 15:47:49 UTC"
  },
  {
    "arxiv_id": "2412.16662v2",
    "title": "Adversarial Attack Against Images Classification based on Generative Adversarial Networks",
    "authors": [
      "Yahe Yang"
    ],
    "abstract": "Adversarial attacks on image classification systems have always been an\nimportant problem in the field of machine learning, and generative adversarial\nnetworks (GANs), as popular models in the field of image generation, have been\nwidely used in various novel scenarios due to their powerful generative\ncapabilities. However, with the popularity of generative adversarial networks,\nthe misuse of fake image technology has raised a series of security problems,\nsuch as malicious tampering with other people's photos and videos, and invasion\nof personal privacy. Inspired by the generative adversarial networks, this work\nproposes a novel adversarial attack method, aiming to gain insight into the\nweaknesses of the image classification system and improve its anti-attack\nability. Specifically, the generative adversarial networks are used to generate\nadversarial samples with small perturbations but enough to affect the\ndecision-making of the classifier, and the adversarial samples are generated\nthrough the adversarial learning of the training generator and the classifier.\nFrom extensive experiment analysis, we evaluate the effectiveness of the method\non a classical image classification dataset, and the results show that our\nmodel successfully deceives a variety of advanced classifiers while maintaining\nthe naturalness of adversarial samples.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16662v2",
    "published_date": "2024-12-21 15:23:34 UTC",
    "updated_date": "2024-12-24 17:21:50 UTC"
  },
  {
    "arxiv_id": "2412.16656v1",
    "title": "Generalizable Articulated Object Perception with Superpoints",
    "authors": [
      "Qiaojun Yu",
      "Ce Hao",
      "Xibin Yuan",
      "Li Zhang",
      "Liu Liu",
      "Yukang Huo",
      "Rohit Agarwal",
      "Cewu Lu"
    ],
    "abstract": "Manipulating articulated objects with robotic arms is challenging due to the\ncomplex kinematic structure, which requires precise part segmentation for\nefficient manipulation. In this work, we introduce a novel superpoint-based\nperception method designed to improve part segmentation in 3D point clouds of\narticulated objects. We propose a learnable, part-aware superpoint generation\ntechnique that efficiently groups points based on their geometric and semantic\nsimilarities, resulting in clearer part boundaries. Furthermore, by leveraging\nthe segmentation capabilities of the 2D foundation model SAM, we identify the\ncenters of pixel regions and select corresponding superpoints as candidate\nquery points. Integrating a query-based transformer decoder further enhances\nour method's ability to achieve precise part segmentation. Experimental results\non the GAPartNet dataset show that our method outperforms existing\nstate-of-the-art approaches in cross-category part segmentation, achieving AP50\nscores of 77.9% for seen categories (4.4% improvement) and $39.3\\%$ for unseen\ncategories (11.6% improvement), with superior results in 5 out of 9 part\ncategories for seen objects and outperforming all previous methods across all\npart categories for unseen objects.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16656v1",
    "published_date": "2024-12-21 14:57:24 UTC",
    "updated_date": "2024-12-21 14:57:24 UTC"
  },
  {
    "arxiv_id": "2412.16653v1",
    "title": "Internalized Self-Correction for Large Language Models",
    "authors": [
      "Nishanth Upadhyaya",
      "Raghavendra Sridharamurthy"
    ],
    "abstract": "In this article, we introduce 'Internalized Self-Correction' (InSeC) for\nlarge language models (LLMs). While many approaches exist for self-reflection\nat inference time, we propose a novel method that combines ideas from negative\nsampling, self-reflection during training, and inference time. InSeC allows\nLLMs to correct themselves by introducing mistakes and their corresponding\ncorrections during training, thereby converting the learning process into a\ntrue supervised learning task with both positive and negative examples. This\napproach can be extended to improve instruction following and correct\nhallucinations or incorrect sentences generated by LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16653v1",
    "published_date": "2024-12-21 14:53:13 UTC",
    "updated_date": "2024-12-21 14:53:13 UTC"
  },
  {
    "arxiv_id": "2412.16651v2",
    "title": "PB-UAP: Hybrid Universal Adversarial Attack For Image Segmentation",
    "authors": [
      "Yufei Song",
      "Ziqi Zhou",
      "Minghui Li",
      "Xianlong Wang",
      "Hangtao Zhang",
      "Menghao Deng",
      "Wei Wan",
      "Shengshan Hu",
      "Leo Yu Zhang"
    ],
    "abstract": "With the rapid advancement of deep learning, the model robustness has become\na significant research hotspot, \\ie, adversarial attacks on deep neural\nnetworks. Existing works primarily focus on image classification tasks, aiming\nto alter the model's predicted labels. Due to the output complexity and deeper\nnetwork architectures, research on adversarial examples for segmentation models\nis still limited, particularly for universal adversarial perturbations. In this\npaper, we propose a novel universal adversarial attack method designed for\nsegmentation models, which includes dual feature separation and low-frequency\nscattering modules. The two modules guide the training of adversarial examples\nin the pixel and frequency space, respectively. Experiments demonstrate that\nour method achieves high attack success rates surpassing the state-of-the-art\nmethods, and exhibits strong transferability across different models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16651v2",
    "published_date": "2024-12-21 14:46:01 UTC",
    "updated_date": "2025-01-03 15:39:46 UTC"
  },
  {
    "arxiv_id": "2412.16643v1",
    "title": "TimeRAG: BOOSTING LLM Time Series Forecasting via Retrieval-Augmented Generation",
    "authors": [
      "Silin Yang",
      "Dong Wang",
      "Haoqi Zheng",
      "Ruochun Jin"
    ],
    "abstract": "Although the rise of large language models (LLMs) has introduced new\nopportunities for time series forecasting, existing LLM-based solutions require\nexcessive training and exhibit limited transferability. In view of these\nchallenges, we propose TimeRAG, a framework that incorporates\nRetrieval-Augmented Generation (RAG) into time series forecasting LLMs, which\nconstructs a time series knowledge base from historical sequences, retrieves\nreference sequences from the knowledge base that exhibit similar patterns to\nthe query sequence measured by Dynamic Time Warping (DTW), and combines these\nreference sequences and the prediction query as a textual prompt to the time\nseries forecasting LLM. Experiments on datasets from various domains show that\nthe integration of RAG improved the prediction accuracy of the original model\nby 2.97% on average.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16643v1",
    "published_date": "2024-12-21 14:27:38 UTC",
    "updated_date": "2024-12-21 14:27:38 UTC"
  },
  {
    "arxiv_id": "2412.16642v2",
    "title": "L3TC: Leveraging RWKV for Learned Lossless Low-Complexity Text Compression",
    "authors": [
      "Junxuan Zhang",
      "Zhengxue Cheng",
      "Yan Zhao",
      "Shihao Wang",
      "Dajiang Zhou",
      "Guo Lu",
      "Li Song"
    ],
    "abstract": "Learning-based probabilistic models can be combined with an entropy coder for\ndata compression. However, due to the high complexity of learning-based models,\ntheir practical application as text compressors has been largely overlooked. To\naddress this issue, our work focuses on a low-complexity design while\nmaintaining compression performance. We introduce a novel Learned Lossless\nLow-complexity Text Compression method (L3TC). Specifically, we conduct\nextensive experiments demonstrating that RWKV models achieve the fastest\ndecoding speed with a moderate compression ratio, making it the most suitable\nbackbone for our method. Second, we propose an outlier-aware tokenizer that\nuses a limited vocabulary to cover frequent tokens while allowing outliers to\nbypass the prediction and encoding. Third, we propose a novel high-rank\nreparameterization strategy that enhances the learning capability during\ntraining without increasing complexity during inference. Experimental results\nvalidate that our method achieves 48% bit saving compared to gzip compressor.\nBesides, L3TC offers compression performance comparable to other learned\ncompressors, with a 50x reduction in model parameters. More importantly, L3TC\nis the fastest among all learned compressors, providing real-time decoding\nspeeds up to megabytes per second. Our code is available at\nhttps://github.com/alipay/L3TC-leveraging-rwkv-for-learned-lossless-low-complexity-text-compression.git.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.MM",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16642v2",
    "published_date": "2024-12-21 14:24:32 UTC",
    "updated_date": "2024-12-24 04:20:18 UTC"
  },
  {
    "arxiv_id": "2412.16641v4",
    "title": "A Systems Thinking Approach to Algorithmic Fairness",
    "authors": [
      "Chris Lam"
    ],
    "abstract": "Systems thinking provides us with a way to model the algorithmic fairness\nproblem by allowing us to encode prior knowledge and assumptions about where we\nbelieve bias might exist in the data generating process. We can then encode\nthese beliefs as a series of causal graphs, enabling us to link AI/ML systems\nto politics and the law. This allows us to combine techniques from machine\nlearning, causal inference, and system dynamics in order to capture different\nemergent aspects of the fairness problem. We can use systems thinking to help\npolicymakers on both sides of the political aisle to understand the complex\ntrade-offs that exist from different types of fairness policies, providing a\nsociotechnical foundation for designing AI policy that is aligned to their\npolitical agendas and with society's values.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been submitted to the 2025 ACM FAccT conference for\n  review",
    "pdf_url": "http://arxiv.org/pdf/2412.16641v4",
    "published_date": "2024-12-21 14:21:33 UTC",
    "updated_date": "2025-01-20 12:03:45 UTC"
  },
  {
    "arxiv_id": "2412.16633v2",
    "title": "POEX: Understanding and Mitigating Policy Executable Jailbreak Attacks against Embodied AI",
    "authors": [
      "Xuancun Lu",
      "Zhengxian Huang",
      "Xinfeng Li",
      "Xiaoyu ji",
      "Wenyuan Xu"
    ],
    "abstract": "Embodied AI systems are rapidly evolving due to the integration of LLMs as\nplanning modules, which transform complex instructions into executable\npolicies. However, LLMs are vulnerable to jailbreak attacks, which can generate\nmalicious content. This paper investigates the feasibility and rationale behind\napplying traditional LLM jailbreak attacks to EAI systems. We aim to answer\nthree questions: (1) Do traditional LLM jailbreak attacks apply to EAI systems?\n(2) What challenges arise if they do not? and (3) How can we defend against EAI\njailbreak attacks? To this end, we first measure existing LLM-based EAI systems\nusing a newly constructed dataset, i.e., the Harmful-RLbench. Our study\nconfirms that traditional LLM jailbreak attacks are not directly applicable to\nEAI systems and identifies two unique challenges. First, the harmful text does\nnot necessarily constitute harmful policies. Second, even if harmful policies\ncan be generated, they are not necessarily executable by the EAI systems, which\nlimits the potential risk. To facilitate a more comprehensive security\nanalysis, we refine and introduce POEX, a novel red teaming framework that\noptimizes adversarial suffixes to induce harmful yet executable policies\nagainst EAI systems. The design of POEX employs adversarial constraints, policy\nevaluators, and suffix optimization to ensure successful policy execution while\nevading safety detection inside an EAI system. Experiments on the real-world\nrobotic arm and simulator using Harmful-RLbench demonstrate the efficacy,\nhighlighting severe safety vulnerabilities and high transferability across\nmodels. Finally, we propose prompt-based and model-based defenses, achieving an\n85% success rate in mitigating attacks and enhancing safety awareness in EAI\nsystems. Our findings underscore the urgent need for robust security measures\nto ensure the safe deployment of EAI in critical applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.RO",
    "comment": "Homepage: https://poex-eai-jailbreak.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.16633v2",
    "published_date": "2024-12-21 13:58:27 UTC",
    "updated_date": "2025-02-10 08:13:17 UTC"
  },
  {
    "arxiv_id": "2412.16631v1",
    "title": "Deep Learning for Spatio-Temporal Fusion in Land Surface Temperature Estimation: A Comprehensive Survey, Experimental Analysis, and Future Trends",
    "authors": [
      "Sofiane Bouaziz",
      "Adel Hafiane",
      "Raphael Canals",
      "Rachid Nedjai"
    ],
    "abstract": "The rapid advancements in satellite remote sensing have enhanced the\ncapability to monitor and analyze the Earth's surface. Among the many variables\ncaptured through satellite sensors, Land Surface Temperature (LST) plays a\ncritical role in understanding key environmental processes. However, obtaining\nhigh-resolution LST data remains a challenge, as satellite sensors often face a\ntrade-off between spatial and temporal resolutions. In response,\nSpatio-Temporal Fusion (STF) has emerged as a powerful method to integrate two\nsatellite data sources, one providing high spatial but low temporal resolution,\nand the other offering high temporal but low spatial resolution. Although a\nrange of STF techniques have been proposed, from traditional methods to\ncutting-edge deep learning (DL) models, most have focused on surface\nreflectance, with limited application to LST estimation. DL approaches, in\nparticular, show promise in improving the spatial and temporal resolutions of\nLST by capturing complex, non-linear relationships between input and output LST\ndata. This paper offers a comprehensive review of the latest advancements in\nDL-based STF techniques for LST estimation. We analyze key research\ndevelopments, mathematically formulate the STF problem, and introduce a novel\ntaxonomy for DL-based STF methods. Furthermore, we discuss the challenges faced\nby current methods and highlight future research directions. In addition, we\npresent the first open-source benchmark STF dataset for LST estimation,\nconsisting of 51 pairs of MODIS-Landsat images spanning from 2013 to 2024. To\nsupport our findings, we conduct extensive experiments on state-of-the-art\nmethods and present both quantitative and qualitative assessments. This is the\nfirst survey paper focused on DL-based STF for LST estimation. We hope it\nserves as a valuable reference for researchers and paves the way for future\nresearch in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to the Proceedings of IEEE",
    "pdf_url": "http://arxiv.org/pdf/2412.16631v1",
    "published_date": "2024-12-21 13:53:15 UTC",
    "updated_date": "2024-12-21 13:53:15 UTC"
  },
  {
    "arxiv_id": "2412.16626v2",
    "title": "Mamba-SEUNet: Mamba UNet for Monaural Speech Enhancement",
    "authors": [
      "Junyu Wang",
      "Zizhen Lin",
      "Tianrui Wang",
      "Meng Ge",
      "Longbiao Wang",
      "Jianwu Dang"
    ],
    "abstract": "In recent speech enhancement (SE) research, transformer and its variants have\nemerged as the predominant methodologies. However, the quadratic complexity of\nthe self-attention mechanism imposes certain limitations on practical\ndeployment. Mamba, as a novel state-space model (SSM), has gained widespread\napplication in natural language processing and computer vision due to its\nstrong capabilities in modeling long sequences and relatively low computational\ncomplexity. In this work, we introduce Mamba-SEUNet, an innovative architecture\nthat integrates Mamba with U-Net for SE tasks. By leveraging bidirectional\nMamba to model forward and backward dependencies of speech signals at different\nresolutions, and incorporating skip connections to capture multi-scale\ninformation, our approach achieves state-of-the-art (SOTA) performance.\nExperimental results on the VCTK+DEMAND dataset indicate that Mamba-SEUNet\nattains a PESQ score of 3.59, while maintaining low computational complexity.\nWhen combined with the Perceptual Contrast Stretching technique, Mamba-SEUNet\nfurther improves the PESQ score to 3.73.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ICASSP 2025, 5 pages, 1 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.16626v2",
    "published_date": "2024-12-21 13:43:51 UTC",
    "updated_date": "2025-01-02 10:56:07 UTC"
  },
  {
    "arxiv_id": "2412.16624v1",
    "title": "Automated Bleeding Detection and Classification in Wireless Capsule Endoscopy with YOLOv8-X",
    "authors": [
      "Pavan C Shekar",
      "Vivek Kanhangad",
      "Shishir Maheshwari",
      "T Sunil Kumar"
    ],
    "abstract": "Gastrointestinal (GI) bleeding, a critical indicator of digestive system\ndisorders, re quires efficient and accurate detection methods. This paper\npresents our solution to the Auto-WCEBleedGen Version V1 Challenge, where we\nachieved the consolation position. We developed a unified YOLOv8-X model for\nboth detection and classification of bleeding regions in Wireless Capsule\nEndoscopy (WCE) images. Our approach achieved 96.10% classification accuracy\nand 76.8% mean Average Precision (mAP) at 0.5 IoU on the val idation dataset.\nThrough careful dataset curation and annotation, we assembled and trained on\n6,345 diverse images to ensure robust model performance. Our implementa tion\ncode and trained models are publicly available at\nhttps://github.com/pavan98765/Auto-WCEBleedGen.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures, challenge",
    "pdf_url": "http://arxiv.org/pdf/2412.16624v1",
    "published_date": "2024-12-21 13:37:11 UTC",
    "updated_date": "2024-12-21 13:37:11 UTC"
  },
  {
    "arxiv_id": "2412.16616v1",
    "title": "Distributed Inference on Mobile Edge and Cloud: A Data-Cartography based Clustering Approach",
    "authors": [
      "Divya Jyoti Bajpai",
      "Manjesh Kumar Hanawal"
    ],
    "abstract": "The large size of DNNs poses a significant challenge for deployment on\ndevices with limited resources, such as mobile, edge, and IoT platforms. To\naddress this issue, a distributed inference framework can be utilized. In this\nframework, a small-scale DNN (initial layers) is deployed on mobile devices, a\nlarger version on edge devices, and the full DNN on the cloud. Samples with low\ncomplexity (easy) can be processed on mobile, those with moderate complexity\n(medium) on edge devices, and high complexity (hard) samples on the cloud.\nGiven that the complexity of each sample is unknown in advance, the crucial\nquestion in distributed inference is determining the sample complexity for\nappropriate DNN processing. We introduce a novel method named \\our{}, which\nleverages the Data Cartography approach initially proposed for enhancing DNN\ngeneralization. By employing data cartography, we assess sample complexity.\n\\our{} aims to boost accuracy while considering the offloading costs from\nmobile to edge/cloud. Our experimental results on GLUE datasets, covering a\nvariety of NLP tasks, indicate that our approach significantly lowers inference\ncosts by more than 43\\% while maintaining a minimal accuracy drop of less than\n0.5\\% compared to performing all inferences on the cloud. The source code is\navailable at https://anonymous.4open.science/r/DIMEC-1B04.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2410.05338",
    "pdf_url": "http://arxiv.org/pdf/2412.16616v1",
    "published_date": "2024-12-21 13:20:26 UTC",
    "updated_date": "2024-12-21 13:20:26 UTC"
  },
  {
    "arxiv_id": "2412.16614v1",
    "title": "Automated Classification of Cybercrime Complaints using Transformer-based Language Models for Hinglish Texts",
    "authors": [
      "Nanda Rani",
      "Divyanshu Singh",
      "Bikash Saha",
      "Sandeep Kumar Shukla"
    ],
    "abstract": "The rise in cybercrime and the complexity of multilingual and code-mixed\ncomplaints present significant challenges for law enforcement and cybersecurity\nagencies. These organizations need automated, scalable methods to identify\ncrime types, enabling efficient processing and prioritization of large\ncomplaint volumes. Manual triaging is inefficient, and traditional machine\nlearning methods fail to capture the semantic and contextual nuances of textual\ncybercrime complaints. Moreover, the lack of publicly available datasets and\nprivacy concerns hinder the research to present robust solutions. To address\nthese challenges, we propose a framework for automated cybercrime complaint\nclassification. The framework leverages Hinglish-adapted transformers, such as\nHingBERT and HingRoBERTa, to handle code-mixed inputs effectively. We employ\nthe real-world dataset provided by Indian Cybercrime Coordination Centre (I4C)\nduring CyberGuard AI Hackathon 2024. We employ GenAI open source model-based\ndata augmentation method to address class imbalance. We also employ\nprivacy-aware preprocessing to ensure compliance with ethical standards while\nmaintaining data integrity. Our solution achieves significant performance\nimprovements, with HingRoBERTa attaining an accuracy of 74.41% and an F1-score\nof 71.49%. We also develop ready-to-use tool by integrating Django REST backend\nwith a modern frontend. The developed tool is scalable and ready for real-world\ndeployment in platforms like the National Cyber Crime Reporting Portal. This\nwork bridges critical gaps in cybercrime complaint management, offering a\nscalable, privacy-conscious, and adaptable solution for modern cybersecurity\nchallenges.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16614v1",
    "published_date": "2024-12-21 13:17:09 UTC",
    "updated_date": "2024-12-21 13:17:09 UTC"
  },
  {
    "arxiv_id": "2412.16602v1",
    "title": "V\"Mean\"ba: Visual State Space Models only need 1 hidden dimension",
    "authors": [
      "Tien-Yu Chi",
      "Hung-Yueh Chiang",
      "Chi-Chih Chang",
      "Ning-Chi Huang",
      "Kai-Chiang Wu"
    ],
    "abstract": "Vision transformers dominate image processing tasks due to their superior\nperformance. However, the quadratic complexity of self-attention limits the\nscalability of these systems and their deployment on resource-constrained\ndevices. State Space Models (SSMs) have emerged as a solution by introducing a\nlinear recurrence mechanism, which reduces the complexity of sequence modeling\nfrom quadratic to linear. Recently, SSMs have been extended to high-resolution\nvision tasks. Nonetheless, the linear recurrence mechanism struggles to fully\nutilize matrix multiplication units on modern hardware, resulting in a\ncomputational bottleneck. We address this issue by introducing\n\\textit{VMeanba}, a training-free compression method that eliminates the\nchannel dimension in SSMs using mean operations. Our key observation is that\nthe output activations of SSM blocks exhibit low variances across channels. Our\n\\textit{VMeanba} leverages this property to optimize computation by averaging\nactivation maps across the channel to reduce the computational overhead without\ncompromising accuracy. Evaluations on image classification and semantic\nsegmentation tasks demonstrate that \\textit{VMeanba} achieves up to a 1.12x\nspeedup with less than a 3\\% accuracy loss. When combined with 40\\%\nunstructured pruning, the accuracy drop remains under 3\\%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024 Machine Learning for Systems workshop",
    "pdf_url": "http://arxiv.org/pdf/2412.16602v1",
    "published_date": "2024-12-21 12:27:07 UTC",
    "updated_date": "2024-12-21 12:27:07 UTC"
  },
  {
    "arxiv_id": "2412.16599v1",
    "title": "Do Multimodal Language Models Really Understand Direction? A Benchmark for Compass Direction Reasoning",
    "authors": [
      "Hang Yin",
      "Zhifeng Lin",
      "Xin Liu",
      "Bin Sun",
      "Kan Li"
    ],
    "abstract": "Direction reasoning is essential for intelligent systems to understand the\nreal world. While existing work focuses primarily on spatial reasoning, compass\ndirection reasoning remains underexplored. To address this, we propose the\nCompass Direction Reasoning (CDR) benchmark, designed to evaluate the direction\nreasoning capabilities of multimodal language models (MLMs). CDR includes three\ntypes images to test spatial (up, down, left, right) and compass (north, south,\neast, west) directions. Our evaluation reveals that most MLMs struggle with\ndirection reasoning, often performing at random guessing levels. Experiments\nshow that training directly with CDR data yields limited improvements, as it\nrequires an understanding of real-world physical rules. We explore the impact\nof mixdata and CoT fine-tuning methods, which significantly enhance MLM\nperformance in compass direction reasoning by incorporating diverse data and\nstep-by-step reasoning, improving the model's ability to understand direction\nrelationships.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16599v1",
    "published_date": "2024-12-21 12:09:13 UTC",
    "updated_date": "2024-12-21 12:09:13 UTC"
  },
  {
    "arxiv_id": "2412.16594v2",
    "title": "AIGCodeSet: A New Annotated Dataset for AI Generated Code Detection",
    "authors": [
      "Basak Demirok",
      "Mucahid Kutlu"
    ],
    "abstract": "While large language models provide significant convenience for software\ndevelopment, they can lead to ethical issues in job interviews and student\nassignments. Therefore, determining whether a piece of code is written by a\nhuman or generated by an artificial intelligence (AI) model is a critical\nissue. In this study, we present AIGCodeSet, which consists of 2.828\nAI-generated and 4.755 human-written Python codes, created using CodeLlama 34B,\nCodestral 22B, and Gemini 1.5 Flash. In addition, we share the results of our\nexperiments conducted with baseline detection methods. Our experiments show\nthat a Bayesian classifier outperforms the other models.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16594v2",
    "published_date": "2024-12-21 11:53:49 UTC",
    "updated_date": "2025-03-09 10:31:29 UTC"
  },
  {
    "arxiv_id": "2412.16581v1",
    "title": "Effective and Efficient Representation Learning for Flight Trajectories",
    "authors": [
      "Shuo Liu",
      "Wenbin Li",
      "Di Yao",
      "Jingping Bi"
    ],
    "abstract": "Flight trajectory data plays a vital role in the traffic management\ncommunity, especially for downstream tasks such as trajectory prediction,\nflight recognition, and anomaly detection. Existing works often utilize\nhandcrafted features and design models for different tasks individually, which\nheavily rely on domain expertise and are hard to extend. We argue that\ndifferent flight analysis tasks share the same useful features of the\ntrajectory. Jointly learning a unified representation for flight trajectories\ncould be beneficial for improving the performance of various tasks. However,\nflight trajectory representation learning (TRL) faces two primary challenges,\n\\ie unbalanced behavior density and 3D spatial continuity, which disable recent\ngeneral TRL methods. In this paper, we propose Flight2Vec , a flight-specific\nrepresentation learning method to address these challenges. Specifically, a\nbehavior-adaptive patching mechanism is used to inspire the learned\nrepresentation to pay more attention to behavior-dense segments. Moreover, we\nintroduce a motion trend learning technique that guides the model to memorize\nnot only the precise locations, but also the motion trend to generate better\nrepresentations. Extensive experimental results demonstrate that Flight2Vec\nsignificantly improves performance in downstream tasks such as flight\ntrajectory prediction, flight recognition, and anomaly detection.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16581v1",
    "published_date": "2024-12-21 10:59:54 UTC",
    "updated_date": "2024-12-21 10:59:54 UTC"
  },
  {
    "arxiv_id": "2412.16572v1",
    "title": "Breaking the Context Bottleneck on Long Time Series Forecasting",
    "authors": [
      "Chao Ma",
      "Yikai Hou",
      "Xiang Li",
      "Yinggang Sun",
      "Haining Yu",
      "Zhou Fang",
      "Jiaxing Qu"
    ],
    "abstract": "Long-term time-series forecasting is essential for planning and\ndecision-making in economics, energy, and transportation, where long foresight\nis required. To obtain such long foresight, models must be both efficient and\neffective in processing long sequence. Recent advancements have enhanced the\nefficiency of these models; however, the challenge of effectively leveraging\nlonger sequences persists. This is primarily due to the tendency of these\nmodels to overfit when presented with extended inputs, necessitating the use of\nshorter input lengths to maintain tolerable error margins. In this work, we\ninvestigate the multiscale modeling method and propose the Logsparse\nDecomposable Multiscaling (LDM) framework for the efficient and effective\nprocessing of long sequences. We demonstrate that by decoupling patterns at\ndifferent scales in time series, we can enhance predictability by reducing\nnon-stationarity, improve efficiency through a compact long input\nrepresentation, and simplify the architecture by providing clear task\nassignments. Experimental results demonstrate that LDM not only outperforms all\nbaselines in long-term forecasting benchmarks, but also reducing both training\ntime and memory costs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Time series forecasting algorithm based on multi-scale analysis",
    "pdf_url": "http://arxiv.org/pdf/2412.16572v1",
    "published_date": "2024-12-21 10:29:34 UTC",
    "updated_date": "2024-12-21 10:29:34 UTC"
  },
  {
    "arxiv_id": "2412.16565v1",
    "title": "Learning for Cross-Layer Resource Allocation in MEC-Aided Cell-Free Networks",
    "authors": [
      "Chong Zheng",
      "Shiwen He",
      "Yongming Huang",
      "Tony Q. S. Quek"
    ],
    "abstract": "Cross-layer resource allocation over mobile edge computing (MEC)-aided\ncell-free networks can sufficiently exploit the transmitting and computing\nresources to promote the data rate. However, the technical bottlenecks of\ntraditional methods pose significant challenges to cross-layer optimization. In\nthis paper, joint subcarrier allocation and beamforming optimization are\ninvestigated for the MEC-aided cell-free network from the perspective of deep\nlearning to maximize the weighted sum rate. Specifically, we convert the\nunderlying problem into a joint multi-task optimization problem and then\npropose a centralized multi-task self-supervised learning algorithm to solve\nthe problem so as to avoid costly manual labeling. Therein, two novel and\ngeneral loss functions, i.e., negative fraction linear loss and exponential\nlinear loss whose advantages in robustness and target domain have been proved\nand discussed, are designed to enable self-supervised learning. Moreover, we\nfurther design a MEC-enabled distributed multi-task self-supervised learning\n(DMTSSL) algorithm, with low complexity and high scalability to address the\nchallenge of dimensional disaster. Finally, we develop the distance-aware\ntransfer learning algorithm based on the DMTSSL algorithm to handle the dynamic\nscenario with negligible computation cost. Simulation results under $3$rd\ngeneration partnership project 38.901 urban-macrocell scenario demonstrate the\nsuperiority of the proposed algorithms over the baseline algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16565v1",
    "published_date": "2024-12-21 10:18:55 UTC",
    "updated_date": "2024-12-21 10:18:55 UTC"
  },
  {
    "arxiv_id": "2412.16564v1",
    "title": "Predictive Monitoring of Black-Box Dynamical Systems",
    "authors": [
      "Thomas A. Henzinger",
      "Fabian Kresse",
      "Kaushik Mallik",
      "Emily Yu",
      "Đorđe Žikelić"
    ],
    "abstract": "We study the problem of predictive runtime monitoring of black-box dynamical\nsystems with quantitative safety properties. The black-box setting stipulates\nthat the exact semantics of the dynamical system and the controller are\nunknown, and that we are only able to observe the state of the controlled (aka,\nclosed-loop) system at finitely many time points. We present a novel framework\nfor predicting future states of the system based on the states observed in the\npast. The numbers of past states and of predicted future states are parameters\nprovided by the user. Our method is based on a combination of Taylor's\nexpansion and the backward difference operator for numerical differentiation.\nWe also derive an upper bound on the prediction error under the assumption that\nthe system dynamics and the controller are smooth. The predicted states are\nthen used to predict safety violations ahead in time. Our experiments\ndemonstrate practical applicability of our method for complex black-box\nsystems, showing that it is computationally lightweight and yet significantly\nmore accurate than the state-of-the-art predictive safety monitoring\ntechniques.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Submitted to L4DC 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16564v1",
    "published_date": "2024-12-21 10:17:46 UTC",
    "updated_date": "2024-12-21 10:17:46 UTC"
  },
  {
    "arxiv_id": "2412.17867v4",
    "title": "Evaluating and Enhancing LLMs for Multi-turn Text-to-SQL with Multiple Question Types",
    "authors": [
      "Ziming Guo",
      "Chao Ma",
      "Yinggang Sun",
      "Tiancheng Zhao",
      "Guangyao Wang",
      "Hai Huang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nadvanced text-to-SQL systems. However, most LLM-based methods often narrowly\nfocus on SQL generation, neglecting the complexities of real-world\nconversational queries. This oversight can lead to unreliable responses,\nparticularly for ambiguous questions that cannot be directly addressed with\nSQL. To bridge this gap, we propose MMSQL, a comprehensive test suite designed\nto evaluate the question classification and SQL generation capabilities of LLMs\nby simulating real-world scenarios with diverse question types and multi-turn\nQ&A interactions. Using MMSQL, we assessed the performance of popular LLMs,\nincluding both open-source and closed-source models, and identified key factors\nimpacting their performance in such scenarios. Moreover, we introduce an\nLLM-based multi-agent framework that employs specialized agents to identify\nquestion types and determine appropriate answering strategies. Our experiments\ndemonstrate that this approach significantly enhances the model's ability to\nnavigate the complexities of conversational dynamics, effectively handling the\ndiverse and complex nature of user queries. Our dataset and code are publicly\navailable at https://mcxiaoxiao.github.io/MMSQL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "International Joint Conference on Neural Networks 2025 (IJCNN 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.17867v4",
    "published_date": "2024-12-21 10:13:45 UTC",
    "updated_date": "2025-04-08 02:23:17 UTC"
  },
  {
    "arxiv_id": "2412.16559v1",
    "title": "Metagoals Endowing Self-Modifying AGI Systems with Goal Stability or Moderated Goal Evolution: Toward a Formally Sound and Practical Approach",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "We articulate here a series of specific metagoals designed to address the\nchallenge of creating AGI systems that possess the ability to flexibly\nself-modify yet also have the propensity to maintain key invariant properties\nof their goal systems\n  1) a series of goal-stability metagoals aimed to guide a system to a\ncondition in which goal-stability is compatible with reasonably flexible\nself-modification\n  2) a series of moderated-goal-evolution metagoals aimed to guide a system to\na condition in which control of the pace of goal evolution is compatible with\nreasonably flexible self-modification\n  The formulation of the metagoals is founded on fixed-point theorems from\nfunctional analysis, e.g. the Contraction Mapping Theorem and constructive\napproximations to Schauder's Theorem, applied to probabilistic models of system\nbehavior\n  We present an argument that the balancing of self-modification with\nmaintenance of goal invariants will often have other interesting cognitive\nside-effects such as a high degree of self understanding\n  Finally we argue for the practical value of a hybrid metagoal combining\nmoderated-goal-evolution with pursuit of goal-stability -- along with\npotentially other metagoals relating to goal-satisfaction, survival and ongoing\ndevelopment -- in a flexible fashion depending on the situation",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16559v1",
    "published_date": "2024-12-21 09:57:13 UTC",
    "updated_date": "2024-12-21 09:57:13 UTC"
  },
  {
    "arxiv_id": "2412.16557v1",
    "title": "CognTKE: A Cognitive Temporal Knowledge Extrapolation Framework",
    "authors": [
      "Wei Chen",
      "Yuting Wu",
      "Shuhan Wu",
      "Zhiyu Zhang",
      "Mengqi Liao",
      "Youfang Lin",
      "Huaiyu Wan"
    ],
    "abstract": "Reasoning future unknowable facts on temporal knowledge graphs (TKGs) is a\nchallenging task, holding significant academic and practical values for various\nfields. Existing studies exploring explainable reasoning concentrate on\nmodeling comprehensible temporal paths relevant to the query. Yet, these\npath-based methods primarily focus on local temporal paths appearing in recent\ntimes, failing to capture the complex temporal paths in TKG and resulting in\nthe loss of longer historical relations related to the query. Motivated by the\nDual Process Theory in cognitive science, we propose a \\textbf{Cogn}itive\n\\textbf{T}emporal \\textbf{K}nowledge \\textbf{E}xtrapolation framework\n(CognTKE), which introduces a novel temporal cognitive relation directed graph\n(TCR-Digraph) and performs interpretable global shallow reasoning and local\ndeep reasoning over the TCR-Digraph. Specifically, the proposed TCR-Digraph is\nconstituted by retrieving significant local and global historical temporal\nrelation paths associated with the query. In addition, CognTKE presents the\nglobal shallow reasoner and the local deep reasoner to perform global one-hop\ntemporal relation reasoning (System 1) and local complex multi-hop path\nreasoning (System 2) over the TCR-Digraph, respectively. The experimental\nresults on four benchmark datasets demonstrate that CognTKE achieves\nsignificant improvement in accuracy compared to the state-of-the-art baselines\nand delivers excellent zero-shot reasoning ability. \\textit{The code is\navailable at https://github.com/WeiChen3690/CognTKE}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI2025 Accept, 12 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16557v1",
    "published_date": "2024-12-21 09:50:55 UTC",
    "updated_date": "2024-12-21 09:50:55 UTC"
  },
  {
    "arxiv_id": "2412.16552v1",
    "title": "Diffusion Prior Interpolation for Flexibility Real-World Face Super-Resolution",
    "authors": [
      "Jiarui Yang",
      "Tao Dai",
      "Yufei Zhu",
      "Naiqi Li",
      "Jinmin Li",
      "Shutao Xia"
    ],
    "abstract": "Diffusion models represent the state-of-the-art in generative modeling. Due\nto their high training costs, many works leverage pre-trained diffusion models'\npowerful representations for downstream tasks, such as face super-resolution\n(FSR), through fine-tuning or prior-based methods. However, relying solely on\npriors without supervised training makes it challenging to meet the pixel-level\naccuracy requirements of discrimination task. Although prior-based methods can\nachieve high fidelity and high-quality results, ensuring consistency remains a\nsignificant challenge. In this paper, we propose a masking strategy with strong\nand weak constraints and iterative refinement for real-world FSR, termed\nDiffusion Prior Interpolation (DPI). We introduce conditions and constraints on\nconsistency by masking different sampling stages based on the structural\ncharacteristics of the face. Furthermore, we propose a condition Corrector\n(CRT) to establish a reciprocal posterior sampling process, enhancing FSR\nperformance by mutual refinement of conditions and samples. DPI can balance\nconsistency and diversity and can be seamlessly integrated into pre-trained\nmodels. In extensive experiments conducted on synthetic and real datasets,\nalong with consistency validation in face recognition, DPI demonstrates\nsuperiority over SOTA FSR methods. The code is available at\n\\url{https://github.com/JerryYann/DPI}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2412.16552v1",
    "published_date": "2024-12-21 09:28:44 UTC",
    "updated_date": "2024-12-21 09:28:44 UTC"
  },
  {
    "arxiv_id": "2412.16547v1",
    "title": "ActPC-Chem: Discrete Active Predictive Coding for Goal-Guided Algorithmic Chemistry as a Potential Cognitive Kernel for Hyperon & PRIMUS-Based AGI",
    "authors": [
      "Ben Goertzel"
    ],
    "abstract": "We explore a novel paradigm (labeled ActPC-Chem) for biologically inspired,\ngoal-guided artificial intelligence (AI) centered on a form of Discrete Active\nPredictive Coding (ActPC) operating within an algorithmic chemistry of rewrite\nrules. ActPC-Chem is envisioned as a foundational \"cognitive kernel\" for\nadvanced cognitive architectures, such as the OpenCog Hyperon system,\nincorporating essential elements of the PRIMUS cognitive architecture. The\ncentral thesis is that general-intelligence-capable cognitive structures and\ndynamics can emerge in a system where both data and models are represented as\nevolving patterns of metagraph rewrite rules, and where prediction errors,\nintrinsic and extrinsic rewards, and semantic constraints guide the continual\nreorganization and refinement of these rules. Using a virtual \"robot bug\"\nthought experiment, we illustrate how such a system might self-organize to\nhandle challenging tasks involving delayed and context-dependent rewards,\nintegrating causal rule inference (AIRIS) and probabilistic logical abstraction\n(PLN) to discover and exploit conceptual patterns and causal constraints. Next,\nwe describe how continuous predictive coding neural networks, which excel at\nhandling noisy sensory data and motor control signals, can be coherently merged\nwith the discrete ActPC substrate. Finally, we outline how these ideas might be\nextended to create a transformer-like architecture that foregoes traditional\nbackpropagation in favor of rule-based transformations guided by ActPC. This\nlayered architecture, supplemented with AIRIS and PLN, promises structured,\nmulti-modal, and logically consistent next-token predictions and narrative\nsequences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16547v1",
    "published_date": "2024-12-21 09:14:25 UTC",
    "updated_date": "2024-12-21 09:14:25 UTC"
  },
  {
    "arxiv_id": "2412.16543v3",
    "title": "Mathematics and Machine Creativity: A Survey on Bridging Mathematics with AI",
    "authors": [
      "Shizhe Liang",
      "Wei Zhang",
      "Tianyang Zhong",
      "Tianming Liu"
    ],
    "abstract": "This paper presents a comprehensive overview on the applications of\nartificial intelligence (AI) in mathematical research, highlighting the\ntransformative role AI has begun to play in this domain. Traditionally, AI\nadvancements have heavily relied on theoretical foundations provided by\nmathematics and statistics. However, recent developments in AI, particularly in\nreinforcement learning (RL) and large language models (LLMs), have demonstrated\nthe potential for AI to contribute back to mathematics by offering flexible\nalgorithmic frameworks and powerful inductive reasoning capabilities that\nsupport various aspects of mathematical research. This survey aims to establish\na bridge between AI and mathematics, providing insights into the mutual\nbenefits and fostering deeper interdisciplinary understanding.\n  In particular, we argue that while current AI and LLMs may struggle with\ncomplex deductive reasoning, their \"inherent creativity\", the ability to\ngenerate outputs at high throughput based on recognition of shallow patterns,\nholds significant potential to support and inspire mathematical research. This\ncreative capability, often overlooked, could be the key to unlocking new\nperspectives and methodologies in mathematics. Furthermore, we address the lack\nof cross-disciplinary communication: mathematicians may not fully comprehend\nthe latest advances in AI, while AI researchers frequently prioritize benchmark\nperformance over real-world applications in frontier mathematical research.\nThis paper seeks to close that gap, offering a detailed exploration of AI\nfundamentals, its strengths, and its emerging applications in the mathematical\nsciences.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16543v3",
    "published_date": "2024-12-21 08:58:36 UTC",
    "updated_date": "2025-03-25 02:03:07 UTC"
  },
  {
    "arxiv_id": "2412.19832v1",
    "title": "Back To The Future: A Hybrid Transformer-XGBoost Model for Action-oriented Future-proofing Nowcasting",
    "authors": [
      "Ziheng Sun"
    ],
    "abstract": "Inspired by the iconic movie Back to the Future, this paper explores an\ninnovative adaptive nowcasting approach that reimagines the relationship\nbetween present actions and future outcomes. In the movie, characters travel\nthrough time to manipulate past events, aiming to create a better future.\nAnalogously, our framework employs predictive insights about the future to\ninform and adjust present conditions. This dual-stage model integrates the\nforecasting power of Transformers (future visionary) with the interpretability\nand efficiency of XGBoost (decision maker), enabling a seamless loop of future\nprediction and present adaptation. Through experimentation with meteorological\ndatasets, we demonstrate the framework's advantage in achieving more accurate\nforecasting while guiding actionable interventions for real-time applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19832v1",
    "published_date": "2024-12-21 08:53:28 UTC",
    "updated_date": "2024-12-21 08:53:28 UTC"
  },
  {
    "arxiv_id": "2412.16540v1",
    "title": "Prior2Posterior: Model Prior Correction for Long-Tailed Learning",
    "authors": [
      "S Divakar Bhat",
      "Amit More",
      "Mudit Soni",
      "Surbhi Agrawal"
    ],
    "abstract": "Learning-based solutions for long-tailed recognition face difficulties in\ngeneralizing on balanced test datasets. Due to imbalanced data prior, the\nlearned \\textit{a posteriori} distribution is biased toward the most frequent\n(head) classes, leading to an inferior performance on the least frequent (tail)\nclasses. In general, the performance can be improved by removing such a bias by\neliminating the effect of imbalanced prior modeled using the number of class\nsamples (frequencies). We first observe that the \\textit{effective prior} on\nthe classes, learned by the model at the end of the training, can differ from\nthe empirical prior obtained using class frequencies. Thus, we propose a novel\napproach to accurately model the effective prior of a trained model using\n\\textit{a posteriori} probabilities. We propose to correct the imbalanced prior\nby adjusting the predicted \\textit{a posteriori} probabilities\n(Prior2Posterior: P2P) using the calculated prior in a post-hoc manner after\nthe training, and show that it can result in improved model performance. We\npresent theoretical analysis showing the optimality of our approach for models\ntrained with naive cross-entropy loss as well as logit adjusted loss. Our\nexperiments show that the proposed approach achieves new state-of-the-art\n(SOTA) on several benchmark datasets from the long-tail literature in the\ncategory of logit adjustment methods. Further, the proposed approach can be\nused to inspect any existing method to capture the \\textit{effective prior} and\nremove any residual bias to improve its performance, post-hoc, without model\nretraining. We also show that by using the proposed post-hoc approach, the\nperformance of many existing methods can be improved further.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16540v1",
    "published_date": "2024-12-21 08:49:02 UTC",
    "updated_date": "2024-12-21 08:49:02 UTC"
  },
  {
    "arxiv_id": "2412.16539v1",
    "title": "Towards Environmentally Equitable AI",
    "authors": [
      "Mohammad Hajiesmaili",
      "Shaolei Ren",
      "Ramesh K. Sitaraman",
      "Adam Wierman"
    ],
    "abstract": "The skyrocketing demand for artificial intelligence (AI) has created an\nenormous appetite for globally deployed power-hungry servers. As a result, the\nenvironmental footprint of AI systems has come under increasing scrutiny. More\ncrucially, the current way that we exploit AI workloads' flexibility and manage\nAI systems can lead to wildly different environmental impacts across locations,\nincreasingly raising environmental inequity concerns and creating unintended\nsociotechnical consequences. In this paper, we advocate environmental equity as\na priority for the management of future AI systems, advancing the boundaries of\nexisting resource management for sustainable AI and also adding a unique\ndimension to AI fairness. Concretely, we uncover the potential of equity-aware\ngeographical load balancing to fairly re-distribute the environmental cost\nacross different regions, followed by algorithmic challenges. We conclude by\ndiscussing a few future directions to exploit the full potential of system\nmanagement approaches to mitigate AI's environmental inequity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Communications of the ACM. All the authors contributed\n  equally and are listed in alphabetical order of last name",
    "pdf_url": "http://arxiv.org/pdf/2412.16539v1",
    "published_date": "2024-12-21 08:46:19 UTC",
    "updated_date": "2024-12-21 08:46:19 UTC"
  },
  {
    "arxiv_id": "2412.16531v1",
    "title": "From Creation to Curriculum: Examining the role of generative AI in Arts Universities",
    "authors": [
      "Atticus Sims"
    ],
    "abstract": "The age of Artificial Intelligence (AI) is marked by its transformative\n\"generative\" capabilities, distinguishing it from prior iterations. This\nburgeoning characteristic of AI has enabled it to produce new and original\ncontent, inherently showcasing its creative prowess. This shift challenges and\nrequires a recalibration in the realm of arts education, urging a departure\nfrom established pedagogies centered on human-driven image creation. The paper\nmeticulously addresses the integration of AI tools, with a spotlight on Stable\nDiffusion (SD), into university arts curricula. Drawing from practical insights\ngathered from workshops conducted in July 2023, which culminated in an\nexhibition of AI-driven artworks, the paper aims to provide a roadmap for\nseamlessly infusing these tools into academic settings. Given their recent\nemergence, the paper delves into a comprehensive overview of such tools,\nemphasizing the intricate dance between artists, developers, and researchers in\nthe open-source AI art world. This discourse extends to the challenges and\nimperatives faced by educational institutions. It presents a compelling case\nfor the swift adoption of these avant-garde tools, underscoring the paramount\nimportance of equipping students with the competencies required to thrive in an\nAI-augmented artistic landscape.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "K.3.1; J.5"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 5 figures. Based on workshops conducted in July 2023 at\n  Kyoto Seika University",
    "pdf_url": "http://arxiv.org/pdf/2412.16531v1",
    "published_date": "2024-12-21 08:18:43 UTC",
    "updated_date": "2024-12-21 08:18:43 UTC"
  },
  {
    "arxiv_id": "2412.16526v2",
    "title": "Text2midi: Generating Symbolic Music from Captions",
    "authors": [
      "Keshav Bhandari",
      "Abhinaba Roy",
      "Kyra Wang",
      "Geeta Puri",
      "Simon Colton",
      "Dorien Herremans"
    ],
    "abstract": "This paper introduces text2midi, an end-to-end model to generate MIDI files\nfrom textual descriptions. Leveraging the growing popularity of multimodal\ngenerative approaches, text2midi capitalizes on the extensive availability of\ntextual data and the success of large language models (LLMs). Our end-to-end\nsystem harnesses the power of LLMs to generate symbolic music in the form of\nMIDI files. Specifically, we utilize a pretrained LLM encoder to process\ncaptions, which then condition an autoregressive transformer decoder to produce\nMIDI sequences that accurately reflect the provided descriptions. This\nintuitive and user-friendly method significantly streamlines the music creation\nprocess by allowing users to generate music pieces using text prompts. We\nconduct comprehensive empirical evaluations, incorporating both automated and\nhuman studies, that show our model generates MIDI files of high quality that\nare indeed controllable by text captions that may include music theory terms\nsuch as chords, keys, and tempo. We release the code and music samples on our\ndemo page (https://github.com/AMAAI-Lab/Text2midi) for users to interact with\ntext2midi.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, 3 figures, Accepted at the 39th AAAI Conference on\n  Artificial Intelligence (AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.16526v2",
    "published_date": "2024-12-21 08:09:12 UTC",
    "updated_date": "2024-12-31 07:56:59 UTC"
  },
  {
    "arxiv_id": "2412.16522v2",
    "title": "Enhancing Contrastive Learning Inspired by the Philosophy of \"The Blind Men and the Elephant\"",
    "authors": [
      "Yudong Zhang",
      "Ruobing Xie",
      "Jiansheng Chen",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Yu Wang"
    ],
    "abstract": "Contrastive learning is a prevalent technique in self-supervised vision\nrepresentation learning, typically generating positive pairs by applying two\ndata augmentations to the same image. Designing effective data augmentation\nstrategies is crucial for the success of contrastive learning. Inspired by the\nstory of the blind men and the elephant, we introduce JointCrop and JointBlur.\nThese methods generate more challenging positive pairs by leveraging the joint\ndistribution of the two augmentation parameters, thereby enabling contrastive\nlearning to acquire more effective feature representations. To the best of our\nknowledge, this is the first effort to explicitly incorporate the joint\ndistribution of two data augmentation parameters into contrastive learning. As\na plug-and-play framework without additional computational overhead, JointCrop\nand JointBlur enhance the performance of SimCLR, BYOL, MoCo v1, MoCo v2, MoCo\nv3, SimSiam, and Dino baselines with notable improvements.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16522v2",
    "published_date": "2024-12-21 07:50:59 UTC",
    "updated_date": "2025-04-16 09:12:31 UTC"
  },
  {
    "arxiv_id": "2412.16515v1",
    "title": "VSFormer: Value and Shape-Aware Transformer with Prior-Enhanced Self-Attention for Multivariate Time Series Classification",
    "authors": [
      "Wenjie Xi",
      "Rundong Zuo",
      "Alejandro Alvarez",
      "Jie Zhang",
      "Byron Choi",
      "Jessica Lin"
    ],
    "abstract": "Multivariate time series classification is a crucial task in data mining,\nattracting growing research interest due to its broad applications. While many\nexisting methods focus on discovering discriminative patterns in time series,\nreal-world data does not always present such patterns, and sometimes raw\nnumerical values can also serve as discriminative features. Additionally, the\nrecent success of Transformer models has inspired many studies. However, when\napplying to time series classification, the self-attention mechanisms in\nTransformer models could introduce classification-irrelevant features, thereby\ncompromising accuracy. To address these challenges, we propose a novel method,\nVSFormer, that incorporates both discriminative patterns (shape) and numerical\ninformation (value). In addition, we extract class-specific prior information\nderived from supervised information to enrich the positional encoding and\nprovide classification-oriented self-attention learning, thereby enhancing its\neffectiveness. Extensive experiments on all 30 UEA archived datasets\ndemonstrate the superior performance of our method compared to SOTA models.\nThrough ablation studies, we demonstrate the effectiveness of the improved\nencoding layer and the proposed self-attention mechanism. Finally, We provide a\ncase study on a real-world time series dataset without discriminative patterns\nto interpret our model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16515v1",
    "published_date": "2024-12-21 07:31:22 UTC",
    "updated_date": "2024-12-21 07:31:22 UTC"
  },
  {
    "arxiv_id": "2412.16512v1",
    "title": "TrojFlow: Flow Models are Natural Targets for Trojan Attacks",
    "authors": [
      "Zhengyang Qi",
      "Xiaohua Xu"
    ],
    "abstract": "Flow-based generative models (FMs) have rapidly advanced as a method for\nmapping noise to data, its efficient training and sampling process makes it\nwidely applicable in various fields. FMs can be viewed as a variant of\ndiffusion models (DMs). At the same time, previous studies have shown that DMs\nare vulnerable to Trojan/Backdoor attacks, a type of output manipulation attack\ntriggered by a maliciously embedded pattern at model input. We found that\nTrojan attacks on generative models are essentially equivalent to image\ntransfer tasks from the backdoor distribution to the target distribution, the\nunique ability of FMs to fit any two arbitrary distributions significantly\nsimplifies the training and sampling setups for attacking FMs, making them\ninherently natural targets for backdoor attacks. In this paper, we propose\nTrojFlow, exploring the vulnerabilities of FMs through Trojan attacks. In\nparticular, we consider various attack settings and their combinations and\nthoroughly explore whether existing defense methods for DMs can effectively\ndefend against our proposed attack scenarios. We evaluate TrojFlow on CIFAR-10\nand CelebA datasets, our experiments show that our method can compromise FMs\nwith high utility and specificity, and can easily break through existing\ndefense mechanisms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16512v1",
    "published_date": "2024-12-21 07:21:53 UTC",
    "updated_date": "2024-12-21 07:21:53 UTC"
  },
  {
    "arxiv_id": "2412.16504v2",
    "title": "Privacy in Fine-tuning Large Language Models: Attacks, Defenses, and Future Directions",
    "authors": [
      "Hao Du",
      "Shang Liu",
      "Lele Zheng",
      "Yang Cao",
      "Atsuyoshi Nakamura",
      "Lei Chen"
    ],
    "abstract": "Fine-tuning has emerged as a critical process in leveraging Large Language\nModels (LLMs) for specific downstream tasks, enabling these models to achieve\nstate-of-the-art performance across various domains. However, the fine-tuning\nprocess often involves sensitive datasets, introducing privacy risks that\nexploit the unique characteristics of this stage. In this paper, we provide a\ncomprehensive survey of privacy challenges associated with fine-tuning LLMs,\nhighlighting vulnerabilities to various privacy attacks, including membership\ninference, data extraction, and backdoor attacks. We further review defense\nmechanisms designed to mitigate privacy risks in the fine-tuning phase, such as\ndifferential privacy, federated learning, and knowledge unlearning, discussing\ntheir effectiveness and limitations in addressing privacy risks and maintaining\nmodel utility. By identifying key gaps in existing research, we highlight\nchallenges and propose directions to advance the development of\nprivacy-preserving methods for fine-tuning LLMs, promoting their responsible\nuse in diverse applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted by PAKDD2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16504v2",
    "published_date": "2024-12-21 06:41:29 UTC",
    "updated_date": "2025-04-06 10:28:21 UTC"
  },
  {
    "arxiv_id": "2412.16500v3",
    "title": "Speech Retrieval-Augmented Generation without Automatic Speech Recognition",
    "authors": [
      "Do June Min",
      "Karel Mundnich",
      "Andy Lapastora",
      "Erfan Soltanmohammadi",
      "Srikanth Ronanki",
      "Kyu Han"
    ],
    "abstract": "One common approach for question answering over speech data is to first\ntranscribe speech using automatic speech recognition (ASR) and then employ\ntext-based retrieval-augmented generation (RAG) on the transcriptions. While\nthis cascaded pipeline has proven effective in many practical settings, ASR\nerrors can propagate to the retrieval and generation steps. To overcome this\nlimitation, we introduce SpeechRAG, a novel framework designed for\nopen-question answering over spoken data. Our proposed approach fine-tunes a\npre-trained speech encoder into a speech adapter fed into a frozen large\nlanguage model (LLM)--based retrieval model. By aligning the embedding spaces\nof text and speech, our speech retriever directly retrieves audio passages from\ntext-based queries, leveraging the retrieval capacity of the frozen text\nretriever. Our retrieval experiments on spoken question answering datasets show\nthat direct speech retrieval does not degrade over the text-based baseline, and\noutperforms the cascaded systems using ASR. For generation, we use a speech\nlanguage model (SLM) as a generator, conditioned on audio passages rather than\ntranscripts. Without fine-tuning of the SLM, this approach outperforms cascaded\ntext-based models when there is high WER in the transcripts.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16500v3",
    "published_date": "2024-12-21 06:16:04 UTC",
    "updated_date": "2025-01-03 07:18:30 UTC"
  },
  {
    "arxiv_id": "2501.08335v3",
    "title": "MERaLiON-TextLLM: Cross-Lingual Understanding of Large Language Models in Chinese, Indonesian, Malay, and Singlish",
    "authors": [
      "Xin Huang",
      "Tarun Kumar Vangani",
      "Minh Duc Pham",
      "Xunlong Zou",
      "Bin Wang",
      "Zhengyuan Liu",
      "Ai Ti Aw"
    ],
    "abstract": "Multilingual large language models (MLLMs) have shown impressive capabilities\nacross a variety of languages. However, efficacy can differ greatly between\ndifferent language families, especially for those with limited linguistic\nresources. This report presents MERaLiON-TextLLM, a series of open-source\nlanguage models specifically tailored to improve understanding and generation\nin Chinese, Indonesian, Malay, and Singlish. The initial released model is\nbuilt on Llama-3-8B-Base and refined through a meticulously crafted process of\ncontinued pre-training and weight merging. Our approach achieves performance\nimprovements across benchmarks in these languages, exceeding the capabilities\nof the official Llama-3 models. We provide the model checkpoints as a resource\nto support further research and development in cross-lingual language\nunderstanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08335v3",
    "published_date": "2024-12-21 05:50:48 UTC",
    "updated_date": "2025-01-22 02:28:42 UTC"
  },
  {
    "arxiv_id": "2412.16489v1",
    "title": "Deep Reinforcement Learning Based Systems for Safety Critical Applications in Aerospace",
    "authors": [
      "Abedin Sherifi"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI) applications within\naerospace have demonstrated substantial growth, particularly in the context of\ncontrol systems. As High Performance Computing (HPC) platforms continue to\nevolve, they are expected to replace current flight control or engine control\ncomputers, enabling increased computational capabilities. This shift will allow\nreal-time AI applications, such as image processing and defect detection, to be\nseamlessly integrated into monitoring systems, providing real-time awareness\nand enhanced fault detection and accommodation. Furthermore, AI's potential in\naerospace extends to control systems, where its application can range from full\nautonomy to enhancing human control through assistive features. AI,\nparticularly deep reinforcement learning (DRL), can offer significant\nimprovements in control systems, whether for autonomous operation or as an\naugmentative tool.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16489v1",
    "published_date": "2024-12-21 05:17:55 UTC",
    "updated_date": "2024-12-21 05:17:55 UTC"
  },
  {
    "arxiv_id": "2412.16478v1",
    "title": "Enhancing Nighttime Vehicle Detection with Day-to-Night Style Transfer and Labeling-Free Augmentation",
    "authors": [
      "Yunxiang Yang",
      "Hao Zhen",
      "Yongcan Huang",
      "Jidong J. Yang"
    ],
    "abstract": "Existing deep learning-based object detection models perform well under\ndaytime conditions but face significant challenges at night, primarily because\nthey are predominantly trained on daytime images. Additionally, training with\nnighttime images presents another challenge: even human annotators struggle to\naccurately label objects in low-light conditions. This issue is particularly\npronounced in transportation applications, such as detecting vehicles and other\nobjects of interest on rural roads at night, where street lighting is often\nabsent, and headlights may introduce undesirable glare. This study addresses\nthese challenges by introducing a novel framework for labeling-free data\naugmentation, leveraging CARLA-generated synthetic data for day-to-night image\nstyle transfer. Specifically, the framework incorporates the Efficient\nAttention Generative Adversarial Network for realistic day-to-night style\ntransfer and uses CARLA-generated synthetic nighttime images to help the model\nlearn vehicle headlight effects. To evaluate the efficacy of the proposed\nframework, we fine-tuned the YOLO11 model with an augmented dataset\nspecifically curated for rural nighttime environments, achieving significant\nimprovements in nighttime vehicle detection. This novel approach is simple yet\neffective, offering a scalable solution to enhance AI-based detection systems\nin low-visibility environments and extend the applicability of object detection\nmodels to broader real-world contexts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.16478v1",
    "published_date": "2024-12-21 04:13:46 UTC",
    "updated_date": "2024-12-21 04:13:46 UTC"
  },
  {
    "arxiv_id": "2412.16475v1",
    "title": "When Can Proxies Improve the Sample Complexity of Preference Learning?",
    "authors": [
      "Yuchen Zhu",
      "Daniel Augusto de Souza",
      "Zhengyan Shi",
      "Mengyue Yang",
      "Pasquale Minervini",
      "Alexander D'Amour",
      "Matt J. Kusner"
    ],
    "abstract": "We address the problem of reward hacking, where maximising a proxy reward\ndoes not necessarily increase the true reward. This is a key concern for Large\nLanguage Models (LLMs), as they are often fine-tuned on human preferences that\nmay not accurately reflect a true objective. Existing work uses various tricks\nsuch as regularisation, tweaks to the reward model, and reward hacking\ndetectors, to limit the influence that such proxy preferences have on a model.\nLuckily, in many contexts such as medicine, education, and law, a sparse amount\nof expert data is often available. In these cases, it is often unclear whether\nthe addition of proxy data can improve policy learning. We outline a set of\nsufficient conditions on proxy feedback that, if satisfied, indicate that proxy\ndata can provably improve the sample complexity of learning the ground truth\npolicy. These conditions can inform the data collection process for specific\ntasks. The result implies a parameterisation for LLMs that achieves this\nimproved sample complexity. We detail how one can adapt existing architectures\nto yield this improved sample complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16475v1",
    "published_date": "2024-12-21 04:07:17 UTC",
    "updated_date": "2024-12-21 04:07:17 UTC"
  },
  {
    "arxiv_id": "2412.16453v1",
    "title": "The Evolving Usage of GenAI by Computing Students",
    "authors": [
      "Irene Hou",
      "Hannah Vy Nguyen",
      "Owen Man",
      "Stephen MacNeil"
    ],
    "abstract": "Help-seeking is a critical aspect of learning and problem-solving for\ncomputing students. Recent research has shown that many students are aware of\ngenerative AI (GenAI) tools; however, there are gaps in the extent and\neffectiveness of how students use them. With over two years of widespread GenAI\nusage, it is crucial to understand whether students' help-seeking behaviors\nwith these tools have evolved and how. This paper presents findings from a\nrepeated cross-sectional survey conducted among computing students across North\nAmerican universities (n=95). Our results indicate shifts in GenAI usage\npatterns. In 2023, 34.1% of students (n=47) reported never using ChatGPT for\nhelp, ranking it fourth after online searches, peer support, and class forums.\nBy 2024, this figure dropped sharply to 6.3% (n=48), with ChatGPT nearly\nmatching online search as the most commonly used help resource. Despite this\ngrowing prevalence, there has been a decline in students' hourly and daily\nusage of GenAI tools, which may be attributed to a common tendency to\nunderestimate usage frequency. These findings offer new insights into the\nevolving role of GenAI in computing education, highlighting its increasing\nacceptance and solidifying its position as a key help resource.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.3.2"
    ],
    "primary_category": "cs.CY",
    "comment": "2 pages, 1 figure, to be published in SIGCSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16453v1",
    "published_date": "2024-12-21 03:00:04 UTC",
    "updated_date": "2024-12-21 03:00:04 UTC"
  },
  {
    "arxiv_id": "2412.16451v1",
    "title": "Correcting Large Language Model Behavior via Influence Function",
    "authors": [
      "Han Zhang",
      "Zhuo Zhang",
      "Yi Zhang",
      "Yuanzhao Zhai",
      "Hanyang Peng",
      "Yu Lei",
      "Yue Yu",
      "Hui Wang",
      "Bin Liang",
      "Lin Gui",
      "Ruifeng Xu"
    ],
    "abstract": "Recent advancements in AI alignment techniques have significantly improved\nthe alignment of large language models (LLMs) with static human preferences.\nHowever, the dynamic nature of human preferences can render some prior training\ndata outdated or even erroneous, ultimately causing LLMs to deviate from\ncontemporary human preferences and societal norms. Existing methodologies,\nwhether they involve the curation of new data for continual alignment or the\nmanual correction of outdated data for re-alignment, demand costly human\nresources. To address this challenge, we propose a novel approach, Large\nLanguage Model Behavior Correction with Influence Function Recall and\nPost-Training (LANCET), which requires no human involvement. LANCET consists of\ntwo phases: (1) using influence functions to identify the training data that\nsignificantly impact undesirable model outputs, and (2) applying an Influence\nfunction-driven Bregman Optimization (IBO) technique to adjust the model's\nbehavior based on these influence distributions. Our experiments demonstrate\nthat LANCET effectively and efficiently correct inappropriate behaviors of\nLLMs. Furthermore, LANCET can outperform methods that rely on collecting human\npreferences, and it enhances the interpretability of learning human preferences\nwithin LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16451v1",
    "published_date": "2024-12-21 02:50:08 UTC",
    "updated_date": "2024-12-21 02:50:08 UTC"
  },
  {
    "arxiv_id": "2412.16447v1",
    "title": "A Generalizable Anomaly Detection Method in Dynamic Graphs",
    "authors": [
      "Xiao Yang",
      "Xuejiao Zhao",
      "Zhiqi Shen"
    ],
    "abstract": "Anomaly detection aims to identify deviations from normal patterns within\ndata. This task is particularly crucial in dynamic graphs, which are common in\napplications like social networks and cybersecurity, due to their evolving\nstructures and complex relationships. Although recent deep learning-based\nmethods have shown promising results in anomaly detection on dynamic graphs,\nthey often lack of generalizability. In this study, we propose GeneralDyG, a\nmethod that samples temporal ego-graphs and sequentially extracts structural\nand temporal features to address the three key challenges in achieving\ngeneralizability: Data Diversity, Dynamic Feature Capture, and Computational\nCost. Extensive experimental results demonstrate that our proposed GeneralDyG\nsignificantly outperforms state-of-the-art methods on four real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.16447v1",
    "published_date": "2024-12-21 02:38:48 UTC",
    "updated_date": "2024-12-21 02:38:48 UTC"
  },
  {
    "arxiv_id": "2412.16446v1",
    "title": "Sensitive Image Classification by Vision Transformers",
    "authors": [
      "Hanxian He",
      "Campbell Wilson",
      "Thanh Thi Nguyen",
      "Janis Dalins"
    ],
    "abstract": "When it comes to classifying child sexual abuse images, managing similar\ninter-class correlations and diverse intra-class correlations poses a\nsignificant challenge. Vision transformer models, unlike conventional deep\nconvolutional network models, leverage a self-attention mechanism to capture\nglobal interactions among contextual local elements. This allows them to\nnavigate through image patches effectively, avoiding incorrect correlations and\nreducing ambiguity in attention maps, thus proving their efficacy in computer\nvision tasks. Rather than directly analyzing child sexual abuse data, we\nconstructed two datasets: one comprising clean and pornographic images and\nanother with three classes, which additionally include images indicative of\npornography, sourced from Reddit and Google Open Images data. In our\nexperiments, we also employ an adult content image benchmark dataset. These\ndatasets served as a basis for assessing the performance of vision transformer\nmodels in pornographic image classification. In our study, we conducted a\ncomparative analysis between various popular vision transformer models and\ntraditional pre-trained ResNet models. Furthermore, we compared them with\nestablished methods for sensitive image detection such as attention and metric\nlearning based CNN and Bumble. The findings demonstrated that vision\ntransformer networks surpassed the benchmark pre-trained models, showcasing\ntheir superior classification and detection capabilities in this task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at 2024 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC)",
    "pdf_url": "http://arxiv.org/pdf/2412.16446v1",
    "published_date": "2024-12-21 02:34:24 UTC",
    "updated_date": "2024-12-21 02:34:24 UTC"
  },
  {
    "arxiv_id": "2412.16443v1",
    "title": "Has LLM Reached the Scaling Ceiling Yet? Unified Insights into LLM Regularities and Constraints",
    "authors": [
      "Charles Luo"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet\ntheir scalability raises a critical question: Have we reached the scaling\nceiling? This paper addresses this pivotal question by developing a unified\ntheoretical framework that integrates mathematical and statistical insights to\nexplain the scaling dynamics of LLMs. We present: 1. Central Limit Theorem\n(CLT) for Hidden Representations: We show that noise in hidden representations\nscales inversely with context size, explaining stabilization effects and the\nlimits of context length improvements. 2. Bias-Variance Decomposition: We\ndecompose next-token prediction loss into irreducible entropy, capacity-driven\nbias, and finite sample variance, revealing trade-offs where scaling yields\ndiminishing returns. 3. Emergent SNR Thresholds: By defining signal-to-noise\nratio (SNR), we quantify how capabilities emerge abruptly once SNR surpasses a\nthreshold, offering insights into when scaling becomes less effective. Through\nthis framework, we conclude that while LLMs have not reached an absolute\nscaling ceiling, practical constraints are increasingly prominent: diminishing\nreturns, resource inefficiencies, and data limitations. Future progress will\nrequire a shift from brute-force scaling to innovations in architecture, data\nquality, and training paradigms. This work provides a roadmap for guiding the\nefficient development of next-generation LLMs and advancing the field beyond\ntraditional scaling strategies.\n  Keywords: Large Language Models; Scaling Ceiling; Central Limit Theorem;\nBias-Variance Trade-Off; Signal-to-Noise Ratio; Emergent Capabilities",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16443v1",
    "published_date": "2024-12-21 02:19:07 UTC",
    "updated_date": "2024-12-21 02:19:07 UTC"
  },
  {
    "arxiv_id": "2412.16441v2",
    "title": "Towards Graph Foundation Models: Learning Generalities Across Graphs via Task-Trees",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Tianyi Ma",
      "Nitesh V Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Foundation models aim to create general, cross-task, and cross-domain machine\nlearning models by pretraining on large-scale datasets to capture shared\npatterns or concepts, such as contours, colors, textures, and edges in images,\nor tokens, words, and sentences in text. However, identifying generalities\nacross graph-structured data remains a significant challenge, as different\ngraph-based tasks necessitate distinct inductive biases, thereby impeding the\ndevelopment of graph foundation models. To address this challenge, we introduce\na novel approach for learning cross-task generalities in graphs. Specifically,\nwe propose task-trees as basic learning instances to align task spaces (node,\nlink, graph) on graphs. Then, we conduct a theoretical analysis to examine\ntheir stability, transferability, and generalization. Our findings indicate\nthat when a graph neural network (GNN) is pretrained on diverse task-trees\nusing a reconstruction objective, it acquires transferable knowledge, enabling\neffective adaptation to downstream tasks with an appropriate set of fine-tuning\nsamples. To empirically validate this approach, we develop a pretrained graph\nmodel based on task-trees, termed Graph Generality Identifier on Task-Trees\n(GIT). Extensive experiments demonstrate that a single pretrained GIT model can\nbe effectively adapted to over 30 different graphs across five domains via\nfine-tuning, in-context learning, or zero-shot learning. Our data and code are\navailable at https://github.com/Zehong-Wang/GIT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16441v2",
    "published_date": "2024-12-21 02:07:43 UTC",
    "updated_date": "2025-01-30 20:19:28 UTC"
  },
  {
    "arxiv_id": "2412.16431v1",
    "title": "Object Detection Approaches to Identifying Hand Images with High Forensic Values",
    "authors": [
      "Thanh Thi Nguyen",
      "Campbell Wilson",
      "Imad Khan",
      "Janis Dalins"
    ],
    "abstract": "Forensic science plays a crucial role in legal investigations, and the use of\nadvanced technologies, such as object detection based on machine learning\nmethods, can enhance the efficiency and accuracy of forensic analysis. Human\nhands are unique and can leave distinct patterns, marks, or prints that can be\nutilized for forensic examinations. This paper compares various machine\nlearning approaches to hand detection and presents the application results of\nemploying the best-performing model to identify images of significant\nimportance in forensic contexts. We fine-tune YOLOv8 and vision\ntransformer-based object detection models on four hand image datasets,\nincluding the 11k hands dataset with our own bounding boxes annotated by a\nsemi-automatic approach. Two YOLOv8 variants, i.e., YOLOv8 nano (YOLOv8n) and\nYOLOv8 extra-large (YOLOv8x), and two vision transformer variants, i.e.,\nDEtection TRansformer (DETR) and Detection Transformers with Assignment (DETA),\nare employed for the experiments. Experimental results demonstrate that the\nYOLOv8 models outperform DETR and DETA on all datasets. The experiments also\nshow that YOLOv8 approaches result in superior performance compared with\nexisting hand detection methods, which were based on YOLOv3 and YOLOv4 models.\nApplications of our fine-tuned YOLOv8 models for identifying hand images (or\nframes in a video) with high forensic values produce excellent results,\nsignificantly reducing the time required by forensic experts. This implies that\nour approaches can be implemented effectively for real-world applications in\nforensics or related fields.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at 2024 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC)",
    "pdf_url": "http://arxiv.org/pdf/2412.16431v1",
    "published_date": "2024-12-21 01:37:54 UTC",
    "updated_date": "2024-12-21 01:37:54 UTC"
  },
  {
    "arxiv_id": "2412.16429v2",
    "title": "LearnLM: Improving Gemini for Learning",
    "authors": [
      "LearnLM Team",
      "Abhinit Modi",
      "Aditya Srikanth Veerubhotla",
      "Aliya Rysbek",
      "Andrea Huber",
      "Brett Wiltshire",
      "Brian Veprek",
      "Daniel Gillick",
      "Daniel Kasenberg",
      "Derek Ahmed",
      "Irina Jurenka",
      "James Cohan",
      "Jennifer She",
      "Julia Wilkowski",
      "Kaiz Alarakyia",
      "Kevin R. McKee",
      "Lisa Wang",
      "Markus Kunesch",
      "Mike Schaekermann",
      "Miruna Pîslar",
      "Nikhil Joshi",
      "Parsa Mahmoudieh",
      "Paul Jhun",
      "Sara Wiltberger",
      "Shakir Mohamed",
      "Shashank Agarwal",
      "Shubham Milind Phal",
      "Sun Jae Lee",
      "Theofilos Strinopoulos",
      "Wei-Jen Ko",
      "Amy Wang",
      "Ankit Anand",
      "Avishkar Bhoopchand",
      "Dan Wild",
      "Divya Pandya",
      "Filip Bar",
      "Garth Graham",
      "Holger Winnemoeller",
      "Mahvish Nagda",
      "Prateek Kolhar",
      "Renee Schneider",
      "Shaojian Zhu",
      "Stephanie Chan",
      "Steve Yadlowsky",
      "Viknesh Sounderajah",
      "Yannis Assael"
    ],
    "abstract": "Today's generative AI systems are tuned to present information by default\nrather than engage users in service of learning as a human tutor would. To\naddress the wide range of potential education use cases for these systems, we\nreframe the challenge of injecting pedagogical behavior as one of\n\\textit{pedagogical instruction following}, where training and evaluation\nexamples include system-level instructions describing the specific pedagogy\nattributes present or desired in subsequent model turns. This framing avoids\ncommitting our models to any particular definition of pedagogy, and instead\nallows teachers or developers to specify desired model behavior. It also clears\na path to improving Gemini models for learning -- by enabling the addition of\nour pedagogical data to post-training mixtures -- alongside their rapidly\nexpanding set of capabilities. Both represent important changes from our\ninitial tech report. We show how training with pedagogical instruction\nfollowing produces a LearnLM model (available on Google AI Studio) that is\npreferred substantially by expert raters across a diverse set of learning\nscenarios, with average preference strengths of 31\\% over GPT-4o, 11\\% over\nClaude 3.5, and 13\\% over the Gemini 1.5 Pro model LearnLM was based on.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16429v2",
    "published_date": "2024-12-21 01:34:05 UTC",
    "updated_date": "2024-12-25 06:12:22 UTC"
  },
  {
    "arxiv_id": "2412.16428v2",
    "title": "Data-Driven Fairness Generalization for Deepfake Detection",
    "authors": [
      "Uzoamaka Ezeakunne",
      "Chrisantus Eze",
      "Xiuwen Liu"
    ],
    "abstract": "Despite the progress made in deepfake detection research, recent studies have\nshown that biases in the training data for these detectors can result in\nvarying levels of performance across different demographic groups, such as race\nand gender. These disparities can lead to certain groups being unfairly\ntargeted or excluded. Traditional methods often rely on fair loss functions to\naddress these issues, but they under-perform when applied to unseen datasets,\nhence, fairness generalization remains a challenge. In this work, we propose a\ndata-driven framework for tackling the fairness generalization problem in\ndeepfake detection by leveraging synthetic datasets and model optimization. Our\napproach focuses on generating and utilizing synthetic data to enhance fairness\nacross diverse demographic groups. By creating a diverse set of synthetic\nsamples that represent various demographic groups, we ensure that our model is\ntrained on a balanced and representative dataset. This approach allows us to\ngeneralize fairness more effectively across different domains. We employ a\ncomprehensive strategy that leverages synthetic data, a loss sharpness-aware\noptimization pipeline, and a multi-task learning framework to create a more\nequitable training environment, which helps maintain fairness across both\nintra-dataset and cross-dataset evaluations. Extensive experiments on benchmark\ndeepfake detection datasets demonstrate the efficacy of our approach,\nsurpassing state-of-the-art approaches in preserving fairness during\ncross-dataset evaluation. Our results highlight the potential of synthetic\ndatasets in achieving fairness generalization, providing a robust solution for\nthe challenges faced in deepfake detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICAART 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16428v2",
    "published_date": "2024-12-21 01:28:35 UTC",
    "updated_date": "2024-12-31 07:15:01 UTC"
  },
  {
    "arxiv_id": "2412.16425v1",
    "title": "Patherea: Cell Detection and Classification for the 2020s",
    "authors": [
      "Dejan Štepec",
      "Maja Jerše",
      "Snežana Đokić",
      "Jera Jeruc",
      "Nina Zidar",
      "Danijel Skočaj"
    ],
    "abstract": "This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to Medical Image Analysis",
    "pdf_url": "http://arxiv.org/pdf/2412.16425v1",
    "published_date": "2024-12-21 01:23:58 UTC",
    "updated_date": "2024-12-21 01:23:58 UTC"
  },
  {
    "arxiv_id": "2412.16423v1",
    "title": "Technical Report: Small Language Model for Japanese Clinical and Medicine",
    "authors": [
      "Shogo Watanabe"
    ],
    "abstract": "This report presents a small language model (SLM) for Japanese clinical and\nmedicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese\ntext classified to be of high-quality. Moreover, NCVC-slm-1 was augmented with\nrespect to clinical and medicine content that includes the variety of diseases,\ndrugs, and examinations. Using a carefully designed pre-processing, a\nspecialized morphological analyzer and tokenizer, this small and light-weight\nmodel performed not only to generate text but also indicated the feasibility of\nunderstanding clinical and medicine text. In comparison to other large language\nmodels, a fine-tuning NCVC-slm-1 demonstrated the highest scores on 6 tasks of\ntotal 8 on JMED-LLM. According to this result, SLM indicated the feasibility of\nperforming several downstream tasks in the field of clinical and medicine.\nHopefully, NCVC-slm-1 will be contributed to develop and accelerate the field\nof clinical and medicine for a bright future.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16423v1",
    "published_date": "2024-12-21 01:12:48 UTC",
    "updated_date": "2024-12-21 01:12:48 UTC"
  },
  {
    "arxiv_id": "2412.16411v1",
    "title": "Knowledge as a Breaking of Ergodicity",
    "authors": [
      "Yang He",
      "Vassiliy Lubchenko"
    ],
    "abstract": "We construct a thermodynamic potential that can guide training of a\ngenerative model defined on a set of binary degrees of freedom. We argue that\nupon reduction in description, so as to make the generative model\ncomputationally-manageable, the potential develops multiple minima. This is\nmirrored by the emergence of multiple minima in the free energy proper of the\ngenerative model itself. The variety of training samples that employ N binary\ndegrees of freedom is ordinarily much lower than the size 2^N of the full phase\nspace. The non-represented configurations, we argue, should be thought of as\ncomprising a high-temperature phase separated by an extensive energy gap from\nthe configurations composing the training set. Thus, training amounts to\nsampling a free energy surface in the form of a library of distinct bound\nstates, each of which breaks ergodicity. The ergodicity breaking prevents\nescape into the near continuum of states comprising the high-temperature phase;\nthus it is necessary for proper functionality. It may however have the side\neffect of limiting access to patterns that were underrepresented in the\ntraining set. At the same time, the ergodicity breaking within the library\ncomplicates both learning and retrieval. As a remedy, one may concurrently\nemploy multiple generative models -- up to one model per free energy minimum.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "cs.CC",
      "stat.ML",
      "I.2.4, F.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "51 pages, 12 figures, accepted to Neural Computation",
    "pdf_url": "http://arxiv.org/pdf/2412.16411v1",
    "published_date": "2024-12-21 00:30:07 UTC",
    "updated_date": "2024-12-21 00:30:07 UTC"
  },
  {
    "arxiv_id": "2412.16409v1",
    "title": "Uncertainty Quantification in Continual Open-World Learning",
    "authors": [
      "Amanda S. Rios",
      "Ibrahima J. Ndiour",
      "Parual Datta",
      "Jaroslaw Sydir",
      "Omesh Tickoo",
      "Nilesh Ahuja"
    ],
    "abstract": "AI deployed in the real-world should be capable of autonomously adapting to\nnovelties encountered after deployment. Yet, in the field of continual\nlearning, the reliance on novelty and labeling oracles is commonplace albeit\nunrealistic. This paper addresses a challenging and under-explored problem: a\ndeployed AI agent that continuously encounters unlabeled data - which may\ninclude both unseen samples of known classes and samples from novel (unknown)\nclasses - and must adapt to it continuously. To tackle this challenge, we\npropose our method COUQ \"Continual Open-world Uncertainty Quantification\", an\niterative uncertainty estimation algorithm tailored for learning in generalized\ncontinual open-world multi-class settings. We rigorously apply and evaluate\nCOUQ on key sub-tasks in the Continual Open-World: continual novelty detection,\nuncertainty guided active learning, and uncertainty guided pseudo-labeling for\nsemi-supervised CL. We demonstrate the effectiveness of our method across\nmultiple datasets, ablations, backbones and performance superior to\nstate-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "I.2; I.4"
    ],
    "primary_category": "cs.LG",
    "comment": "Manuscript Under Review (full-length); Related 4-page manuscripts\n  accepted at Neurips 2024 Non-Archival Workshops\n  https://sites.google.com/view/continual-fomo-workshop and\n  https://imol-workshop.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.16409v1",
    "published_date": "2024-12-21 00:09:20 UTC",
    "updated_date": "2024-12-21 00:09:20 UTC"
  }
]