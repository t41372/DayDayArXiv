{
  "date": "2024-09-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-09 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型优化、多模态处理、强化学习和异常检测等领域，重点包括 LLM 在代码生成和多任务学习中的应用，以及知名学者如 Zhuoran Yang 的理论分析；令人印象深刻的文章有 HyperAgent 的多代理软件工程系统和 SongCreator 的音乐生成模型，它们展示了 AI 在实际应用中的创新潜力。\n\n以下是今日论文的简要摘要，我会优先讨论重要、创新性强的论文（如涉及 LLM、强化学习和多模态的），并快速掠过较常规或应用性较弱的文章。每篇论文标题以“中文 + 英文”形式列出，焦点放在核心贡献和发现上。\n\n### 重点论文讨论\n- **HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale（HyperAgent: 通用软件工程代理用于大规模代码任务）**  \n  这篇论文提出 HyperAgent，一个多代理系统，包括 Planner、Navigator、Code Editor 和 Executor 代理，用于处理各种编程语言的代码任务。该系统模仿人类开发流程，在 GitHub 问题解决、代码生成和程序修复上超越了基线方法，显著提高了代码任务的效率和准确性。\n\n- **Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers（揭示归纳头：Transformer 的可证明训练动态和特征学习）**  \n  作者 Zhuoran Yang 分析了 Transformer 在 in-context learning 中的机制，证明了归纳头（induction head）机制如何通过两个注意力层和前馈网络学习特征。该研究为 LLM 的训练动态提供了理论基础，实验验证了其在 n-gram 数据上的有效性。\n\n- **Doppelgänger's Watch: A Split Objective Approach to Large Language Models（Doppelgänger 的监视：针对 LLM 的分裂目标方法）**  \n  论文引入双重架构（bicameral architecture），将 LLM 的生成监督与帮助性分开，使用一个并行模块预测 token 的监督分数。该方法理论上提升了 LLM 的生成质量，适用于序列建模任务。\n\n- **SongCreator: Lyrics-based Universal Song Generation（SongCreator: 基于歌词的通用歌曲生成）**  \n  该工作开发了 SongCreator 系统，利用双序列语言模型（DSLM）和注意力掩码策略，从歌词生成带人声和伴奏的歌曲。实验显示它在多种任务上达到 SOTA 性能，能独立控制声学条件，适用于音乐 AI 应用。\n\n- **Neural MP: A Generalist Neural Motion Planner（Neural MP: 通用神经运动规划器）**  \n  论文提出一种基于 DRL 的运动规划框架，使用策略蒸馏和优化在复杂场景中生成路径。相比传统方法，它在真实世界任务中提高了成功率，适用于机器人和自动驾驶。\n\n- **MLLM-LLaVA-FL: Multimodal Large Language Model Assisted Federated Learning（MLLM-LLaVA-FL: 多模态 LLM 辅助的联邦学习）**  \n  作者如 Yiran Chen 设计了联邦学习框架，使用 MLLM 处理数据异质性和长尾分布，通过预训练和全局对齐提升性能。该方法在异构数据上表现出色，避免了隐私泄露风险。\n\n- **TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors（TERD: 保护扩散模型免受后门的统一框架）**  \n  该论文提出 TERD 框架，使用触发器逆转和噪声空间检测来防御扩散模型的后门攻击，实现了 100% 的 TPR 和 TNR，适用于图像生成的安全增强。\n\n- **Seek and Solve Reasoning for Table Question Answering（用于表格问答的搜索与求解推理）**  \n  论文引入 Seek-and-Solve 推理管道，结合检索和生成阶段，提高了 LLM 在表格问答中的性能。通过 SS-CoT 提示，显著提升了复杂任务的准确性和可靠性。\n\n其他相关论文，如 PersonaTalk（视觉配音中的个性化建模）和 State-Novelty Guided Action Persistence（强化学习中的状态新颖性引导），也展示了 AI 在多模态和决策优化中的潜力，但细节较上述更简略。\n\n### 快速掠过其他论文\n以下论文主题较常规或应用性较弱，我仅简要概述核心贡献：\n- **Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty（感知不确定性下的概率安全导航规划）**  \n  提出 PaRCE 方法评估模型熟悉度，提高了无人车辆在不确定环境中的导航安全。\n- **Recall: Empowering Multimodal Embedding for Edge Devices（Recall: 为边缘设备增强多模态嵌入）**  \n  开发了 Recall 系统，通过粗粒度嵌入和查询过滤，提升边缘设备的检索效率。\n- **Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer（无监督音乐音频音色转移的潜在扩散桥）**  \n  使用双扩散模型实现音色转移，实验显示它在音色保持和旋律保留上优于基线。\n- **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity（基于梯度任务亲和性估计的可扩展多任务学习）**  \n  引入 Grad-TAG 算法，高效估计任务亲和性，提高了多任务学习的性能。\n- **Deep Generative Model for Mechanical System Configuration Design（机械系统配置设计的深度生成模型）**  \n  提出 Transformer 模型辅助搜索优化机械设计，显著加速了齿轮系统合成。\n- **Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models（fMRI 证据支持语言模型的两阶段抽象过程）**  \n  通过脑成像验证 LLM 的抽象过程，强调中间层的特征学习。\n- **Real-Time Human Action Recognition on Embedded Platforms（嵌入式平台的实时人体动作识别）**  \n  设计 IMFE 模块，实现了 30 FPS 的实时动作识别，适用于资源受限设备。\n- **Promptable Closed-loop Traffic Simulation（可提示的闭环交通模拟）**  \n  提出 ProSim 框架，支持多模态提示生成交通场景，提升了模拟的控制性和准确性。\n\n剩余论文（如涉及量子计算、医学 AI 或常规图像处理的）大多为领域特定优化或基准测试，我在此不展开讨论，以控制篇幅。这些论文的贡献包括新数据集（如 MessIRve）和算法改进（如 AD-Net），但整体影响力较小。\n\n总之，今天的 arXiv 论文突显了 AI 在实际应用中的潜力，特别是在 LLM 和多模态领域的创新。感兴趣的读者可关注上述重点文章，探索更多细节！如果有特定主题，欢迎反馈。",
  "papers": [
    {
      "arxiv_id": "2409.06111v4",
      "title": "Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Pohland",
        "Claire Tomlin"
      ],
      "abstract": "Perception-based navigation systems are useful for unmanned ground vehicle\n(UGV) navigation in complex terrains, where traditional depth-based navigation\nschemes are insufficient. However, these data-driven methods are highly\ndependent on their training data and can fail in surprising and dramatic ways\nwith little warning. To ensure the safety of the vehicle and the surrounding\nenvironment, it is imperative that the navigation system is able to recognize\nthe predictive uncertainty of the perception model and respond safely and\neffectively in the face of uncertainty. In an effort to enable safe navigation\nunder perception uncertainty, we develop a probabilistic and\nreconstruction-based competency estimation (PaRCE) method to estimate the\nmodel's level of familiarity with an input image as a whole and with specific\nregions in the image. We find that the overall competency score can correctly\npredict correctly classified, misclassified, and out-of-distribution (OOD)\nsamples. We also confirm that the regional competency maps can accurately\ndistinguish between familiar and unfamiliar regions across images. We then use\nthis competency information to develop a planning and control scheme that\nenables effective navigation while maintaining a low probability of error. We\nfind that the competency-aware scheme greatly reduces the number of collisions\nwith unfamiliar obstacles, compared to a baseline controller with no competency\nawareness. Furthermore, the regional competency information is very valuable in\nenabling efficient navigation.",
      "tldr_zh": "这篇论文针对感知不确定性（Perception Uncertainty）下的无人地面车辆（UGV）导航问题，提出了一种 Competency-Aware Planning 方法，以确保导航的安全性。该方法引入了概率和基于重构的competency估计（PaRCE），用于评估模型对输入图像整体以及特定区域的熟悉程度，并能准确预测正确分类、误分类和OOD（Out-of-Distribution）样本。实验结果显示，基于competency信息的规划和控制方案显著减少了与不熟悉障碍物的碰撞，同时提高了导航效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06111v4",
      "published_date": "2024-09-09 23:34:24 UTC",
      "updated_date": "2025-01-28 21:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:19:08.392285"
    },
    {
      "arxiv_id": "2409.06107v1",
      "title": "Doppelgänger's Watch: A Split Objective Approach to Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shervin Ghasemlou",
        "Ashish Katiyar",
        "Aparajita Saraf",
        "Seungwhan Moon",
        "Mangesh Pujari",
        "Pinar Donmez",
        "Babak Damavandi",
        "Anuj Kumar"
      ],
      "abstract": "In this paper, we investigate the problem of \"generation supervision\" in\nlarge language models, and present a novel bicameral architecture to separate\nsupervision signals from their core capability, helpfulness. Doppelg\\\"anger, a\nnew module parallel to the underlying language model, supervises the generation\nof each token, and learns to concurrently predict the supervision score(s) of\nthe sequences up to and including each token. In this work, we present the\ntheoretical findings, and leave the report on experimental results to a\nforthcoming publication.",
      "tldr_zh": "这篇论文探讨了大型语言模型（large language models）中的生成监督（generation supervision）问题，提出了一种双重架构（bicameral architecture）来分离监督信号与核心能力，如helpfulness。Doppelgänger 模块作为与底层语言模型并行的组件，负责监督每个 token 的生成，同时预测序列至该 token 的监督分数。该方法提供了理论发现，为提升模型性能奠定基础，实验结果将在后续出版中报告。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06107v1",
      "published_date": "2024-09-09 23:22:27 UTC",
      "updated_date": "2024-09-09 23:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:19:20.620428"
    },
    {
      "arxiv_id": "2409.15342v1",
      "title": "Recall: Empowering Multimodal Embedding for Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Dongqi Cai",
        "Shangguang Wang",
        "Chen Peng",
        "Zeling Zhang",
        "Mengwei Xu"
      ],
      "abstract": "Human memory is inherently prone to forgetting. To address this, multimodal\nembedding models have been introduced, which transform diverse real-world data\ninto a unified embedding space. These embeddings can be retrieved efficiently,\naiding mobile users in recalling past information. However, as model complexity\ngrows, so do its resource demands, leading to reduced throughput and heavy\ncomputational requirements that limit mobile device implementation. In this\npaper, we introduce RECALL, a novel on-device multimodal embedding system\noptimized for resource-limited mobile environments. RECALL achieves\nhigh-throughput, accurate retrieval by generating coarse-grained embeddings and\nleveraging query-based filtering for refined retrieval. Experimental results\ndemonstrate that RECALL delivers high-quality embeddings with superior\nthroughput, all while operating unobtrusively with minimal memory and energy\nconsumption.",
      "tldr_zh": "本论文探讨了多模态嵌入(multimodal embedding)模型在移动设备上的挑战，旨在解决模型复杂度增加导致的资源需求高、吞吐量低等问题，以辅助用户高效回忆信息。研究引入RECALL系统，一种针对资源有限的边缘设备(edge devices)优化的新型嵌入系统，通过生成粗粒度嵌入和基于查询的过滤(query-based filtering)实现精确、高效的检索。实验结果显示，RECALL提供高质量嵌入，具有卓越的吞吐量，同时在内存和能源消耗上保持最低水平。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15342v1",
      "published_date": "2024-09-09 22:34:19 UTC",
      "updated_date": "2024-09-09 22:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:19:31.212571"
    },
    {
      "arxiv_id": "2409.06096v4",
      "title": "Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Mancusi",
        "Yurii Halychanskyi",
        "Kin Wai Cheuk",
        "Eloi Moliner",
        "Chieh-Hsin Lai",
        "Stefan Uhlich",
        "Junghyun Koo",
        "Marco A. Martínez-Ramírez",
        "Wei-Hsiang Liao",
        "Giorgio Fabbro",
        "Yuki Mitsufuji"
      ],
      "abstract": "Music timbre transfer is a challenging task that involves modifying the\ntimbral characteristics of an audio signal while preserving its melodic\nstructure. In this paper, we propose a novel method based on dual diffusion\nbridges, trained using the CocoChorales Dataset, which consists of unpaired\nmonophonic single-instrument audio data. Each diffusion model is trained on a\nspecific instrument with a Gaussian prior. During inference, a model is\ndesignated as the source model to map the input audio to its corresponding\nGaussian prior, and another model is designated as the target model to\nreconstruct the target audio from this Gaussian prior, thereby facilitating\ntimbre transfer. We compare our approach against existing unsupervised timbre\ntransfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental\nresults demonstrate that our method achieves both better Fr\\'echet Audio\nDistance (FAD) and melody preservation, as reflected by lower pitch distances\n(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise\nlevel from the Gaussian prior, $\\sigma$, can be adjusted to control the degree\nof melody preservation and amount of timbre transferred.",
      "tldr_zh": "本研究提出了一种基于双扩散桥（dual diffusion bridges）的新方法，用于无监督音乐音色转移（timbre transfer），旨在修改音频的音色特征同时保留其旋律结构。方法使用 CocoChorales Dataset 中的未配对单声道单乐器音频数据训练，每个扩散模型针对特定乐器与高斯先验（Gaussian prior）结合，在推理阶段通过源模型映射输入音频并由目标模型重建实现转移。实验结果显示，与 VAEGAN 和 Gaussian Flow Bridges (GFB) 相比，该方法在 Fréchet Audio Distance (FAD) 和音高距离 (DPD) 上表现出色，实现了更好的音色转移和旋律保留；此外，通过调整高斯先验的噪声水平 σ，可以灵活控制旋律保留程度和音色转移量。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06096v4",
      "published_date": "2024-09-09 22:16:48 UTC",
      "updated_date": "2025-01-07 10:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:19:44.801204"
    },
    {
      "arxiv_id": "2409.06091v2",
      "title": "Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity",
      "title_zh": "可扩展的多任务学习：使用基于梯度的任务亲和性估计",
      "authors": [
        "Dongyue Li",
        "Aneesh Sharma",
        "Hongyang R. Zhang"
      ],
      "abstract": "Multitask learning is a widely used paradigm for training models on diverse\ntasks, with applications ranging from graph neural networks to language model\nfine-tuning. Since tasks may interfere with each other, a key notion for\nmodeling their relationships is task affinity. This includes pairwise task\naffinity, computed among pairs of tasks, and higher-order affinity, computed\namong subsets of tasks. Naively computing either of them requires repeatedly\ntraining on data from various task combinations, which is computationally\nintensive. We present a new algorithm Grad-TAG that can estimate task\naffinities without this repeated training.\n  The key idea of Grad-TAG is to train a \"base\" model for all tasks and then\nuse a linearization technique to estimate the loss of the model for a specific\ntask combination. The linearization works by computing a gradient-based\napproximation of the loss, using low-dimensional projections of gradients as\nfeatures in a logistic regression to predict labels for the task combination.\nWe show that the linearized model can provably approximate the loss when the\ngradient-based approximation is accurate, and also empirically verify that on\nseveral large models. Then, given the estimated task affinity, we design a\nsemi-definite program for clustering similar tasks by maximizing the average\ndensity of clusters.\n  We evaluate Grad-TAG's performance across seven datasets, including\nmulti-label classification on graphs, and instruction fine-tuning of language\nmodels. Our task affinity estimates are within 2.7% distance to the true\naffinities while needing only 3% of FLOPs in full training. On our largest\ngraph with 21M edges and 500 labeling tasks, our algorithm delivers estimates\nwithin 5% distance to the true affinities, using only 112 GPU hours. Our\nresults show that Grad-TAG achieves excellent performance and runtime tradeoffs\ncompared to existing approaches.",
      "tldr_zh": "本研究提出了一种可扩展的多任务学习方法，通过梯度-based 估计任务亲和性（Task Affinity）的算法 Grad-TAG，解决了传统方法需反复训练任务组合的计算密集问题。Grad-TAG 的核心在于训练一个基础模型，然后使用线性化技术（如梯度低维投影和逻辑回归）来近似特定任务组合的损失，并设计半正定程序（Semi-definite Program）聚类相似任务以最大化聚类密度。实验在七个数据集上验证，包括图神经网络的多标签分类和语言模型的指令微调，结果显示任务亲和性估计与真实值距离在2.7%以内，仅需全训练的3% FLOPs，并在最大数据集上使用112 GPU hours实现5%以内的准确估计，与现有方法相比显著提升了性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages. Appeared in KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06091v2",
      "published_date": "2024-09-09 21:59:27 UTC",
      "updated_date": "2024-11-20 22:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:19:56.795390"
    },
    {
      "arxiv_id": "2409.06077v2",
      "title": "MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization",
      "title_zh": "MTLSO：一种用于逻辑综合优化的多任务学习方法",
      "authors": [
        "Faezeh Faez",
        "Raika Karimi",
        "Yingxue Zhang",
        "Xing Li",
        "Lei Chen",
        "Mingxuan Yuan",
        "Mahdi Biparva"
      ],
      "abstract": "Electronic Design Automation (EDA) is essential for IC design and has\nrecently benefited from AI-based techniques to improve efficiency. Logic\nsynthesis, a key EDA stage, transforms high-level hardware descriptions into\noptimized netlists. Recent research has employed machine learning to predict\nQuality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis\nrecipes. However, the severe scarcity of data due to a very limited number of\navailable AIGs results in overfitting, significantly hindering performance.\nAdditionally, the complexity and large number of nodes in AIGs make plain GNNs\nless effective for learning expressive graph-level representations. To tackle\nthese challenges, we propose MTLSO - a Multi-Task Learning approach for Logic\nSynthesis Optimization. On one hand, it maximizes the use of limited data by\ntraining the model across different tasks. This includes introducing an\nauxiliary task of binary multi-label graph classification alongside the primary\nregression task, allowing the model to benefit from diverse supervision\nsources. On the other hand, we employ a hierarchical graph representation\nlearning strategy to improve the model's capacity for learning expressive\ngraph-level representations of large AIGs, surpassing traditional plain GNNs.\nExtensive experiments across multiple datasets and against state-of-the-art\nbaselines demonstrate the superiority of our method, achieving an average\nperformance gain of 8.22\\% for delay and 5.95\\% for area.",
      "tldr_zh": "这篇论文提出了 MTLSO，一种多任务学习 (Multi-Task Learning) 方法，用于优化逻辑合成 (Logic Synthesis)，以解决电子设计自动化 (EDA) 中数据稀缺导致的过拟合问题以及 And-Inverter Graphs (AIGs) 的复杂性使普通 GNNs 学习效果不佳的挑战。MTLSO 通过结合主要回归任务和辅助二元多标签图分类任务，最大化有限数据的利用，并采用分层图表示学习 (hierarchical graph representation learning) 来提升对大型 AIGs 的表达性图级表示。实验结果显示，该方法在多个数据集上比最先进基线提升了 8.22% 的延迟性能和 5.95% 的面积性能，为 EDA 中的 AI 技术提供了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06077v2",
      "published_date": "2024-09-09 21:20:36 UTC",
      "updated_date": "2024-10-31 19:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:20:09.555756"
    },
    {
      "arxiv_id": "2409.14565v1",
      "title": "Combating Spatial Disorientation in a Dynamic Self-Stabilization Task Using AI Assistants",
      "title_zh": "利用 AI 助手对抗动态自稳定任务中的空间迷向",
      "authors": [
        "Sheikh Mannan",
        "Paige Hansen",
        "Vivekanand Pandey Vimal",
        "Hannah N. Davies",
        "Paul DiZio",
        "Nikhil Krishnaswamy"
      ],
      "abstract": "Spatial disorientation is a leading cause of fatal aircraft accidents. This\npaper explores the potential of AI agents to aid pilots in maintaining balance\nand preventing unrecoverable losses of control by offering cues and corrective\nmeasures that ameliorate spatial disorientation. A multi-axis rotation system\n(MARS) was used to gather data from human subjects self-balancing in a\nspaceflight analog condition. We trained models over this data to create\n\"digital twins\" that exemplified performance characteristics of humans with\ndifferent proficiency levels. We then trained various reinforcement learning\nand deep learning models to offer corrective cues if loss of control is\npredicted. Digital twins and assistant models then co-performed a virtual\ninverted pendulum (VIP) programmed with identical physics. From these\nsimulations, we picked the 5 best-performing assistants based on task metrics\nsuch as crash frequency and mean distance from the direction of balance. These\nwere used in a co-performance study with 20 new human subjects performing a\nversion of the VIP task with degraded spatial information. We show that certain\nAI assistants were able to improve human performance and that\nreinforcement-learning based assistants were objectively more effective but\nrated as less trusted and preferable by humans.",
      "tldr_zh": "本研究探讨了 AI 助手在对抗空间迷向（Spatial Disorientation）中的作用，以帮助飞行员通过提供提示和纠正措施来维持平衡并防止失控。研究团队使用多轴旋转系统（MARS）收集人类数据，训练“数字孪生”模型模拟不同熟练度水平，并开发强化学习和深度学习模型在虚拟倒置摆（VIP）任务中提供辅助。实验结果显示，某些 AI 助手显著改善了人类性能，但基于强化学习的助手虽更客观有效，却被受试者评为较不信任和不优先选用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, To be published in the International Conference on\n  Human-Agent Interaction (HAI '24) proceedings",
      "pdf_url": "http://arxiv.org/pdf/2409.14565v1",
      "published_date": "2024-09-09 21:06:22 UTC",
      "updated_date": "2024-09-09 21:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:20:31.476766"
    },
    {
      "arxiv_id": "2409.06067v2",
      "title": "MLLM-LLaVA-FL: Multimodal Large Language Model Assisted Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyi Zhang",
        "Hao Frank Yang",
        "Ang Li",
        "Xin Guo",
        "Pu Wang",
        "Haiming Wang",
        "Yiran Chen",
        "Hai Li"
      ],
      "abstract": "Previous studies on federated learning (FL) often encounter performance\ndegradation due to data heterogeneity among different clients. In light of the\nrecent advances in multimodal large language models (MLLMs), such as GPT-4v and\nLLaVA, which demonstrate their exceptional proficiency in multimodal tasks,\nsuch as image captioning and multimodal question answering. We introduce a\nnovel federated learning framework, named Multimodal Large Language Model\nAssisted Federated Learning (MLLM-LLaVA-FL), which employs powerful MLLMs at\nthe server end to address the heterogeneous and long-tailed challenges. Owing\nto the advanced cross-modality representation capabilities and the extensive\nopen-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing\nthe extensive, yet previously underexploited, open-source data accessible from\nwebsites and powerful server-side computational resources. Hence, the\nMLLM-LLaVA-FL not only enhances the performance but also avoids increasing the\nrisk of privacy leakage and the computational burden on local devices,\ndistinguishing it from prior methodologies. Our framework has three key stages.\nInitially, we conduct global visual-text pretraining of the model. This\npretraining is facilitated by utilizing the extensive open-source data\navailable online, with the assistance of MLLMs. Subsequently, the pretrained\nmodel is distributed among various clients for local training. Finally, once\nthe locally trained models are transmitted back to the server, a global\nalignment is carried out under the supervision of MLLMs to further enhance the\nperformance. Experimental evaluations on established benchmarks, show that our\nframework delivers promising performance in the typical scenarios with data\nheterogeneity and long-tail distribution across different clients in FL.",
      "tldr_zh": "该研究提出了一种名为 MLLM-LLaVA-FL 的新型联邦学习 (FL) 框架，利用多模态大型语言模型 (MLLMs) 如 GPT-4v 和 LLaVA 在服务器端辅助处理数据异质性和长尾分布问题。框架分为三个关键阶段：首先，通过 MLLMs 利用开源数据进行全球视觉-文本预训练；其次，将预训练模型分发给客户端进行本地训练；最后，在服务器端进行全球对齐以进一步优化性能。该方法不仅显著提升了 FL 在异质数据场景下的表现，实验在标准基准上显示出色的结果，还避免了隐私泄露风险和本地计算负担的增加。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.06067v2",
      "published_date": "2024-09-09 21:04:16 UTC",
      "updated_date": "2024-12-02 10:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:20:33.678714"
    },
    {
      "arxiv_id": "2409.06029v2",
      "title": "SongCreator: Lyrics-based Universal Song Generation",
      "title_zh": "SongCreator: 基于歌词的通用歌曲生成",
      "authors": [
        "Shun Lei",
        "Yixuan Zhou",
        "Boshi Tang",
        "Max W. Y. Lam",
        "Feng Liu",
        "Hangyu Liu",
        "Jingcheng Wu",
        "Shiyin Kang",
        "Zhiyong Wu",
        "Helen Meng"
      ],
      "abstract": "Music is an integral part of human culture, embodying human intelligence and\ncreativity, of which songs compose an essential part. While various aspects of\nsong generation have been explored by previous works, such as singing voice,\nvocal composition and instrumental arrangement, etc., generating songs with\nboth vocals and accompaniment given lyrics remains a significant challenge,\nhindering the application of music generation models in the real world. In this\nlight, we propose SongCreator, a song-generation system designed to tackle this\nchallenge. The model features two novel designs: a meticulously designed\ndual-sequence language model (DSLM) to capture the information of vocals and\naccompaniment for song generation, and a series of attention mask strategies\nfor DSLM, which allows our model to understand, generate and edit songs, making\nit suitable for various songrelated generation tasks by utilizing specific\nattention masks. Extensive experiments demonstrate the effectiveness of\nSongCreator by achieving state-of-the-art or competitive performances on all\neight tasks. Notably, it surpasses previous works by a large margin in\nlyrics-to-song and lyrics-to-vocals. Additionally, it is able to independently\ncontrol the acoustic conditions of the vocals and accompaniment in the\ngenerated song through different audio prompts, exhibiting its potential\napplicability. Our samples are available at\nhttps://thuhcsi.github.io/SongCreator/.",
      "tldr_zh": "该研究提出SongCreator，一种基于歌词的通用歌曲生成系统，旨在解决生成包含声乐和伴奏的完整歌曲的挑战。系统采用双序列语言模型（DSLM）来捕捉声乐和伴奏的信息，并引入一系列注意力掩码策略（attention mask strategies），使模型能够理解、生成和编辑歌曲，并适应多种歌曲相关任务。实验结果显示，SongCreator在八个任务上达到最先进或竞争性性能，尤其在lyrics-to-song和lyrics-to-vocals任务上大幅超越现有方法；此外，它能通过音频提示独立控制声乐和伴奏的声学条件，展示出实际应用的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.06029v2",
      "published_date": "2024-09-09 19:37:07 UTC",
      "updated_date": "2024-10-30 20:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:20:44.458922"
    },
    {
      "arxiv_id": "2409.16299v2",
      "title": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Nhat Phan",
        "Tien N. Nguyen",
        "Phong X. Nguyen",
        "Nghi D. Q. Bui"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized software engineering (SE),\nshowcasing remarkable proficiency in various coding tasks. Despite recent\nadvancements that have enabled the creation of autonomous software agents\nutilizing LLMs for end-to-end development tasks, these systems are typically\ndesigned for specific SE functions. We introduce HyperAgent, an innovative\ngeneralist multi-agent system designed to tackle a wide range of SE tasks\nacross different programming languages by mimicking the workflows of human\ndevelopers. HyperAgent features four specialized agents-Planner, Navigator,\nCode Editor, and Executor-capable of handling the entire lifecycle of SE tasks,\nfrom initial planning to final verification. HyperAgent sets new benchmarks in\ndiverse SE tasks, including GitHub issue resolution on the renowned SWE-Bench\nbenchmark, outperforming robust baselines. Furthermore, HyperAgent demonstrates\nexceptional performance in repository-level code generation (RepoExec) and\nfault localization and program repair (Defects4J), often surpassing\nstate-of-the-art baselines.",
      "tldr_zh": "本文提出 HyperAgent，一种通用多智能体系统，旨在处理各种软件工程(SE)任务，包括不同编程语言的编码问题，并模仿人类开发者的工作流程。HyperAgent 由四个专门代理组成：Planner（规划者）、Navigator（导航者）、Code Editor（代码编辑器）和 Executor（执行者），负责从初始规划到最终验证的整个任务生命周期。与现有系统不同，它能灵活应对多种 SE 函数。实验结果显示，HyperAgent 在 SWE-Bench、RepoExec 和 Defects4J 等基准测试中显著超越基线模型，特别是在 GitHub 问题解决、仓库级代码生成和故障定位及程序修复方面。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "49 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.16299v2",
      "published_date": "2024-09-09 19:35:34 UTC",
      "updated_date": "2024-11-05 17:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:20:56.345694"
    },
    {
      "arxiv_id": "2409.06016v3",
      "title": "Deep Generative Model for Mechanical System Configuration Design",
      "title_zh": "针对机械系统配置设计的深度生成模型",
      "authors": [
        "Yasaman Etesam",
        "Hyunmin Cheong",
        "Mohammadmehdi Ataei",
        "Pradeep Kumar Jayaraman"
      ],
      "abstract": "Generative AI has made remarkable progress in addressing various design\nchallenges. One prominent area where generative AI could bring significant\nvalue is in engineering design. In particular, selecting an optimal set of\ncomponents and their interfaces to create a mechanical system that meets design\nrequirements is one of the most challenging and time-consuming tasks for\nengineers. This configuration design task is inherently challenging due to its\ncategorical nature, multiple design requirements a solution must satisfy, and\nthe reliance on physics simulations for evaluating potential solutions. These\ncharacteristics entail solving a combinatorial optimization problem with\nmultiple constraints involving black-box functions. To address this challenge,\nwe propose a deep generative model to predict the optimal combination of\ncomponents and interfaces for a given design problem. To demonstrate our\napproach, we solve a gear train synthesis problem by first creating a synthetic\ndataset using a grammar, a parts catalogue, and a physics simulator. We then\ntrain a Transformer using this dataset, named GearFormer, which can not only\ngenerate quality solutions on its own, but also augment search methods such as\nan evolutionary algorithm and Monte Carlo tree search. We show that GearFormer\noutperforms such search methods on their own in terms of satisfying the\nspecified design requirements with orders of magnitude faster generation time.\nAdditionally, we showcase the benefit of hybrid methods that leverage both\nGearFormer and search methods, which further improve the quality of the\nsolutions.",
      "tldr_zh": "这篇论文提出了一种 Deep Generative Model，用于机械系统配置设计，以解决组件选择、接口优化以及多重约束的组合优化挑战。研究者通过创建合成数据集（基于语法、零件目录和物理模拟器）并训练名为 GearFormer 的 Transformer 模型，来预测最优组件和接口组合；该模型不仅能独立生成高质量解决方案，还能增强搜索方法如 Evolutionary Algorithm 和 Monte Carlo Tree Search。实验结果表明，GearFormer 比传统搜索方法更快地满足设计要求，生成时间提高数倍，且混合方法进一步提升了解决方案的质量。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2409.06016v3",
      "published_date": "2024-09-09 19:15:45 UTC",
      "updated_date": "2025-01-23 21:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:21:08.321119"
    },
    {
      "arxiv_id": "2409.05994v1",
      "title": "MessIRve: A Large-Scale Spanish Information Retrieval Dataset",
      "title_zh": "MessIRve：大规模西班牙语信息检索数据集",
      "authors": [
        "Francisco Valentini",
        "Viviana Cotik",
        "Damián Furman",
        "Ivan Bercovich",
        "Edgar Altszyler",
        "Juan Manuel Pérez"
      ],
      "abstract": "Information retrieval (IR) is the task of finding relevant documents in\nresponse to a user query. Although Spanish is the second most spoken native\nlanguage, current IR benchmarks lack Spanish data, hindering the development of\ninformation access tools for Spanish speakers. We introduce MessIRve, a\nlarge-scale Spanish IR dataset with around 730 thousand queries from Google's\nautocomplete API and relevant documents sourced from Wikipedia. MessIRve's\nqueries reflect diverse Spanish-speaking regions, unlike other datasets that\nare translated from English or do not consider dialectal variations. The large\nsize of the dataset allows it to cover a wide variety of topics, unlike smaller\ndatasets. We provide a comprehensive description of the dataset, comparisons\nwith existing datasets, and baseline evaluations of prominent IR models. Our\ncontributions aim to advance Spanish IR research and improve information access\nfor Spanish speakers.",
      "tldr_zh": "该论文介绍了 MessIRve，这是一个大规模的西班牙语 Information Retrieval (IR) 数据集，包含约 73 万个查询（源自 Google 的 autocomplete API）和相关文档（来自 Wikipedia），旨在解决现有 IR 基准中缺乏西班牙语数据的不足。MessIRve 的查询反映了不同西班牙语地区的方言多样性，与从英语翻译或其他忽略变体的数据集不同，从而覆盖更广泛的主题。研究者提供了数据集的全面描述、与其他数据集的比较，以及对主要 IR 模型的基线评估，以推进西班牙语 IR 研究并提升西班牙语用户的的信息访问体验。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05994v1",
      "published_date": "2024-09-09 18:45:04 UTC",
      "updated_date": "2024-09-09 18:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:21:20.424821"
    },
    {
      "arxiv_id": "2409.13726v1",
      "title": "Multilingual Dyadic Interaction Corpus NoXi+J: Toward Understanding Asian-European Non-verbal Cultural Characteristics and their Influences on Engagement",
      "title_zh": "翻译失败",
      "authors": [
        "Marius Funk",
        "Shogo Okada",
        "Elisabeth André"
      ],
      "abstract": "Non-verbal behavior is a central challenge in understanding the dynamics of a\nconversation and the affective states between interlocutors arising from the\ninteraction. Although psychological research has demonstrated that non-verbal\nbehaviors vary across cultures, limited computational analysis has been\nconducted to clarify these differences and assess their impact on engagement\nrecognition. To gain a greater understanding of engagement and non-verbal\nbehaviors among a wide range of cultures and language spheres, in this study we\nconduct a multilingual computational analysis of non-verbal features and\ninvestigate their role in engagement and engagement prediction. To achieve this\ngoal, we first expanded the NoXi dataset, which contains interaction data from\nparticipants living in France, Germany, and the United Kingdom, by collecting\nsession data of dyadic conversations in Japanese and Chinese, resulting in the\nenhanced dataset NoXi+J. Next, we extracted multimodal non-verbal features,\nincluding speech acoustics, facial expressions, backchanneling and gestures,\nvia various pattern recognition techniques and algorithms. Then, we conducted a\nstatistical analysis of listening behaviors and backchannel patterns to\nidentify culturally dependent and independent features in each language and\ncommon features among multiple languages. These features were also correlated\nwith the engagement shown by the interlocutors. Finally, we analyzed the\ninfluence of cultural differences in the input features of LSTM models trained\nto predict engagement for five language datasets. A SHAP analysis combined with\ntransfer learning confirmed a considerable correlation between the importance\nof input features for a language set and the significant cultural\ncharacteristics analyzed.",
      "tldr_zh": "这篇论文扩展了 NoXi 数据集，创建了 NoXi+J 语料库，通过收集日语和中文的二人互动数据，研究亚洲和欧洲文化在非语言行为（如语音声学、面部表情、回声和手势）上的差异及其对参与度的影响。研究者提取多模态非语言特征，并进行统计分析，识别了文化依赖和独立特征，并将这些特征与参与度相关联。最终，使用 LSTM 模型结合 SHAP 分析和迁移学习，证实了文化差异对参与度预测特征的重要性，为跨文化互动理解提供了计算分析基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages. 6 figures. International Conference on Multimodal\n  Interaction, November 4-8, 2024, San Jose, Costa Rica",
      "pdf_url": "http://arxiv.org/pdf/2409.13726v1",
      "published_date": "2024-09-09 18:37:34 UTC",
      "updated_date": "2024-09-09 18:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:21:32.954749"
    },
    {
      "arxiv_id": "2409.10559v1",
      "title": "Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers",
      "title_zh": "揭示 Induction Heads：在 Transformers 中可证明的训练动态和特征学习",
      "authors": [
        "Siyu Chen",
        "Heejune Sheen",
        "Tianhao Wang",
        "Zhuoran Yang"
      ],
      "abstract": "In-context learning (ICL) is a cornerstone of large language model (LLM)\nfunctionality, yet its theoretical foundations remain elusive due to the\ncomplexity of transformer architectures. In particular, most existing work only\ntheoretically explains how the attention mechanism facilitates ICL under\ncertain data models. It remains unclear how the other building blocks of the\ntransformer contribute to ICL. To address this question, we study how a\ntwo-attention-layer transformer is trained to perform ICL on $n$-gram Markov\nchain data, where each token in the Markov chain statistically depends on the\nprevious $n$ tokens. We analyze a sophisticated transformer model featuring\nrelative positional embedding, multi-head softmax attention, and a feed-forward\nlayer with normalization. We prove that the gradient flow with respect to a\ncross-entropy ICL loss converges to a limiting model that performs a\ngeneralized version of the induction head mechanism with a learned feature,\nresulting from the congruous contribution of all the building blocks. In the\nlimiting model, the first attention layer acts as a $\\mathit{copier}$, copying\npast tokens within a given window to each position, and the feed-forward\nnetwork with normalization acts as a $\\mathit{selector}$ that generates a\nfeature vector by only looking at informationally relevant parents from the\nwindow. Finally, the second attention layer is a $\\mathit{classifier}$ that\ncompares these features with the feature at the output position, and uses the\nresulting similarity scores to generate the desired output. Our theory is\nfurther validated by experiments.",
      "tldr_zh": "这篇论文揭示了 Transformer 模型在 in-context learning (ICL) 中的训练动态和特征学习机制，特别针对 n-gram Markov chain 数据进行了理论分析。研究证明，通过梯度流优化，一个两层注意力 Transformer（包括相对位置嵌入、多头注意力层和前馈网络）会收敛到一个广义的 induction head 机制，其中第一个注意力层作为 copier 复制过去窗口内的 token，前馈网络作为 selector 选择相关特征，第二个注意力层作为 classifier 通过比较相似度生成输出。该机制展示了 Transformer 各组成部分的协同作用，最终提升了 ICL 的性能。实验结果进一步验证了这一理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "100 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.10559v1",
      "published_date": "2024-09-09 18:10:26 UTC",
      "updated_date": "2024-09-09 18:10:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:21:44.243911"
    },
    {
      "arxiv_id": "2409.05864v1",
      "title": "Neural MP: A Generalist Neural Motion Planner",
      "title_zh": "翻译失败",
      "authors": [
        "Murtaza Dalal",
        "Jiahui Yang",
        "Russell Mendonca",
        "Youssef Khaky",
        "Ruslan Salakhutdinov",
        "Deepak Pathak"
      ],
      "abstract": "The current paradigm for motion planning generates solutions from scratch for\nevery new problem, which consumes significant amounts of time and computational\nresources. For complex, cluttered scenes, motion planning approaches can often\ntake minutes to produce a solution, while humans are able to accurately and\nsafely reach any goal in seconds by leveraging their prior experience. We seek\nto do the same by applying data-driven learning at scale to the problem of\nmotion planning. Our approach builds a large number of complex scenes in\nsimulation, collects expert data from a motion planner, then distills it into a\nreactive generalist policy. We then combine this with lightweight optimization\nto obtain a safe path for real world deployment. We perform a thorough\nevaluation of our method on 64 motion planning tasks across four diverse\nenvironments with randomized poses, scenes and obstacles, in the real world,\ndemonstrating an improvement of 23%, 17% and 79% motion planning success rate\nover state of the art sampling, optimization and learning based planning\nmethods. Video results available at mihdalal.github.io/neuralmotionplanner",
      "tldr_zh": "该论文提出Neural MP，一种通用的神经运动规划器，通过大规模数据驱动学习来解决传统运动规划效率低的问题。方法包括在模拟环境中构建复杂场景、收集专家数据并提炼成反应式通用策略，然后结合轻量级优化以生成安全的真实世界路径。在真实世界评估中，该方法在64个任务上覆盖四个多样化环境，成功率分别比最先进的采样、优化和基于学习的规划方法提高了23%、17%和79%。这项工作展示了数据驱动方法在提升运动规划可靠性的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Website at mihdalal.github.io/neuralmotionplanner. Main paper: 7\n  pages, 4 figures, 2 tables. Appendix: 9 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.05864v1",
      "published_date": "2024-09-09 17:59:45 UTC",
      "updated_date": "2024-09-09 17:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:21:56.001794"
    },
    {
      "arxiv_id": "2409.05863v1",
      "title": "Promptable Closed-loop Traffic Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhan Tan",
        "Boris Ivanovic",
        "Yuxiao Chen",
        "Boyi Li",
        "Xinshuo Weng",
        "Yulong Cao",
        "Philipp Krähenbühl",
        "Marco Pavone"
      ],
      "abstract": "Simulation stands as a cornerstone for safe and efficient autonomous driving\ndevelopment. At its core a simulation system ought to produce realistic,\nreactive, and controllable traffic patterns. In this paper, we propose ProSim,\na multimodal promptable closed-loop traffic simulation framework. ProSim allows\nthe user to give a complex set of numerical, categorical or textual prompts to\ninstruct each agent's behavior and intention. ProSim then rolls out a traffic\nscenario in a closed-loop manner, modeling each agent's interaction with other\ntraffic participants. Our experiments show that ProSim achieves high prompt\ncontrollability given different user prompts, while reaching competitive\nperformance on the Waymo Sim Agents Challenge when no prompt is given. To\nsupport research on promptable traffic simulation, we create\nProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with\nover 10M text prompts for over 520k real-world driving scenarios. We will\nrelease code of ProSim as well as data and labeling tools of\nProSim-Instruct-520k at https://ariostgx.github.io/ProSim.",
      "tldr_zh": "本研究提出ProSim，一种多模态可提示的闭环交通模拟框架，用于支持自动驾驶开发，确保模拟场景真实、反应性和可控。ProSim允许用户通过数字、分类或文本提示来指导每个代理的行为和意图，并在闭环系统中模拟代理间的互动。实验结果显示，ProSim在不同提示下实现了高可控性，并在Waymo Sim Agents Challenge中无提示时表现出竞争性性能。该框架还创建了ProSim-Instruct-520k数据集，包含超过520k真实驾驶场景和10M文本提示，并将发布相关代码和工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CoRL 2024. Website available at\n  https://ariostgx.github.io/ProSim",
      "pdf_url": "http://arxiv.org/pdf/2409.05863v1",
      "published_date": "2024-09-09 17:59:15 UTC",
      "updated_date": "2024-09-09 17:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:22:07.669626"
    },
    {
      "arxiv_id": "2409.05846v1",
      "title": "An Introduction to Quantum Reinforcement Learning (QRL)",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Yen-Chi Chen"
      ],
      "abstract": "Recent advancements in quantum computing (QC) and machine learning (ML) have\nsparked considerable interest in the integration of these two cutting-edge\nfields. Among the various ML techniques, reinforcement learning (RL) stands out\nfor its ability to address complex sequential decision-making problems. RL has\nalready demonstrated substantial success in the classical ML community. Now,\nthe emerging field of Quantum Reinforcement Learning (QRL) seeks to enhance RL\nalgorithms by incorporating principles from quantum computing. This paper\noffers an introduction to this exciting area for the broader AI and ML\ncommunity.",
      "tldr_zh": "这篇论文介绍了 Quantum Reinforcement Learning (QRL)，一种将量子计算 (QC) 原理融入强化学习 (RL) 的新兴领域，以提升 RL 在处理复杂顺序决策问题方面的性能。论文强调，QRL 构建于经典 RL 的成功基础上，通过量子机制增强算法的效率和能力。总体而言，它为 AI 和 ML 社区提供了 QRL 的入门指南，帮助读者理解这一交叉领域的潜力和发展方向。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "Accepted by The 15th International Conference on ICT Convergence -\n  ICTC 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05846v1",
      "published_date": "2024-09-09 17:45:37 UTC",
      "updated_date": "2024-09-09 17:45:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:22:19.591972"
    },
    {
      "arxiv_id": "2409.05831v1",
      "title": "Applying Attribution Explanations in Truth-Discovery Quantitative Bipolar Argumentation Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Yin",
        "Nico Potyka",
        "Francesca Toni"
      ],
      "abstract": "Explaining the strength of arguments under gradual semantics is receiving\nincreasing attention. For example, various studies in the literature offer\nexplanations by computing the attribution scores of arguments or edges in\nQuantitative Bipolar Argumentation Frameworks (QBAFs). These explanations,\nknown as Argument Attribution Explanations (AAEs) and Relation Attribution\nExplanations (RAEs), commonly employ removal-based and Shapley-based techniques\nfor computing the attribution scores. While AAEs and RAEs have proven useful in\nseveral applications with acyclic QBAFs, they remain largely unexplored for\ncyclic QBAFs. Furthermore, existing applications tend to focus solely on either\nAAEs or RAEs, but do not compare them directly. In this paper, we apply both\nAAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess the\ntrustworthiness of sources (e.g., websites) and their claims (e.g., the\nseverity of a virus), and feature complex cycles. We find that both AAEs and\nRAEs can provide interesting explanations and can give non-trivial and\nsurprising insights.",
      "tldr_zh": "本研究探讨了在Truth Discovery Quantitative Bipolar Argumentation Frameworks (TD-QBAFs)中应用Attribution Explanations，包括Argument Attribution Explanations (AAEs)和Relation Attribution Explanations (RAEs)，这些解释利用removal-based和Shapley-based技术来评估论证强度。论文首次将AAEs和RAEs应用于包含复杂循环的TD-QBAFs，用于评估来源（如网站）和声明（如病毒严重性）的可信度，并直接比较了两种解释方法。结果显示，AAEs和RAEs能够提供有趣、非平凡的见解，帮助揭示来源信任度的潜在因素。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted at ArgXAI Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05831v1",
      "published_date": "2024-09-09 17:36:39 UTC",
      "updated_date": "2024-09-09 17:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:22:32.455556"
    },
    {
      "arxiv_id": "2409.05938v1",
      "title": "DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning",
      "title_zh": "DeepFM-Crispr：通过深度学习预测 CRISPR 靶向效果",
      "authors": [
        "Condy Bao",
        "Fuxiao Liu"
      ],
      "abstract": "Since the advent of CRISPR-Cas9, a groundbreaking gene-editing technology\nthat enables precise genomic modifications via a short RNA guide sequence,\nthere has been a marked increase in the accessibility and application of this\ntechnology across various fields. The success of CRISPR-Cas9 has spurred\nfurther investment and led to the discovery of additional CRISPR systems,\nincluding CRISPR-Cas13. Distinct from Cas9, which targets DNA, Cas13 targets\nRNA, offering unique advantages for gene modulation. We focus on Cas13d, a\nvariant known for its collateral activity where it non-specifically cleaves\nadjacent RNA molecules upon activation, a feature critical to its function. We\nintroduce DeepFM-Crispr, a novel deep learning model developed to predict the\non-target efficiency and evaluate the off-target effects of Cas13d. This model\nharnesses a large language model to generate comprehensive representations rich\nin evolutionary and structural data, thereby enhancing predictions of RNA\nsecondary structures and overall sgRNA efficacy. A transformer-based\narchitecture processes these inputs to produce a predictive efficacy score.\nComparative experiments show that DeepFM-Crispr not only surpasses traditional\nmodels but also outperforms recent state-of-the-art deep learning methods in\nterms of prediction accuracy and reliability.",
      "tldr_zh": "本研究提出 DeepFM-Crispr，一种基于深度学习的模型，用于预测 CRISPR-Cas13d 的 on-target 效率和 off-target 效果，以提升基因编辑技术的精确性。该模型利用大型语言模型生成富含进化及结构数据的 RNA 次级结构表示，并通过 Transformer-based 架构处理输入，输出 sgRNA 效能预测分数。实验结果显示，DeepFM-Crispr 在预测准确性和可靠性上超过了传统模型和现有深度学习方法，为 CRISPR-Cas13d 的应用提供了更可靠的评估工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "11 page, 2 figures, accepted to ICMLA 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05938v1",
      "published_date": "2024-09-09 17:33:54 UTC",
      "updated_date": "2024-09-09 17:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:22:44.413516"
    },
    {
      "arxiv_id": "2409.05808v2",
      "title": "The Future of Software Testing: AI-Powered Test Case Generation and Validation",
      "title_zh": "软件测试的未来：AI驱动的测试用例生成和验证",
      "authors": [
        "Mohammad Baqar",
        "Rajat Khanda"
      ],
      "abstract": "Software testing is a crucial phase in the software development lifecycle\n(SDLC), ensuring that products meet necessary functional, performance, and\nquality benchmarks before release. Despite advancements in automation,\ntraditional methods of generating and validating test cases still face\nsignificant challenges, including prolonged timelines, human error, incomplete\ntest coverage, and high costs of manual intervention. These limitations often\nlead to delayed product launches and undetected defects that compromise\nsoftware quality and user satisfaction. The integration of artificial\nintelligence (AI) into software testing presents a promising solution to these\npersistent challenges. AI-driven testing methods automate the creation of\ncomprehensive test cases, dynamically adapt to changes, and leverage machine\nlearning to identify high-risk areas in the codebase. This approach enhances\nregression testing efficiency while expanding overall test coverage.\nFurthermore, AI-powered tools enable continuous testing and self-healing test\ncases, significantly reducing manual oversight and accelerating feedback loops,\nultimately leading to faster and more reliable software releases. This paper\nexplores the transformative potential of AI in improving test case generation\nand validation, focusing on its ability to enhance efficiency, accuracy, and\nscalability in testing processes. It also addresses key challenges associated\nwith adapting AI for testing, including the need for high quality training\ndata, ensuring model transparency, and maintaining a balance between automation\nand human oversight. Through case studies and examples of real-world\napplications, this paper illustrates how AI can significantly enhance testing\nefficiency across both legacy and modern software systems.",
      "tldr_zh": "本论文探讨了软件测试在软件开发生命周期(SDLC)中的关键作用，以及传统测试方法面临的挑战，如测试用例生成和验证的耗时长、人为错误、不完整覆盖和高成本问题，导致软件质量和用户满意度下降。论文提出利用人工智能(AI)驱动的方法，包括自动化测试用例生成、机器学习识别高风险代码区域、动态适应变化以及实现连续测试和自愈测试用例，从而提升回归测试效率、扩展测试覆盖并加速软件发布。研究通过案例分析展示了AI在遗留和现代系统中的实际应用，同时强调了挑战，如需要高质量训练数据、确保模型透明度，以及平衡自动化与人工监督，以实现更高效、准确和可扩展的测试过程。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Version 2, 19 Pages",
      "pdf_url": "http://arxiv.org/pdf/2409.05808v2",
      "published_date": "2024-09-09 17:12:40 UTC",
      "updated_date": "2025-05-10 01:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:22:56.509760"
    },
    {
      "arxiv_id": "2409.05806v3",
      "title": "CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jizhan Fang",
        "Tianhe Lu",
        "Yunzhi Yao",
        "Ziyan Jiang",
        "Xin Xu",
        "Ningyu Zhang",
        "Huajun Chen"
      ],
      "abstract": "Chinese, as a linguistic system rich in depth and complexity, is\ncharacterized by distinctive elements such as ancient poetry, proverbs, idioms,\nand other cultural constructs. However, current Large Language Models (LLMs)\nface limitations in these specialized domains, highlighting the need for the\ndevelopment of comprehensive datasets that can assess, continuously update, and\nprogressively improve these culturally-grounded linguistic competencies through\ntargeted training optimizations. To address this gap, we introduce CKnowEdit,\nthe first-ever Chinese knowledge editing dataset designed to correct\nlinguistic, factual, and logical errors in LLMs. We collect seven types of\nknowledge from a wide range of sources, including classical texts, idioms, and\ncontent from Baidu Tieba Ruozhiba, taking into account the unique polyphony,\nantithesis, and logical structures inherent in the Chinese language. By\nanalyzing this dataset, we highlight the challenges current LLMs face in\nmastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge\nediting techniques reveals opportunities to advance the correction of Chinese\nknowledge. Code and dataset are available at\nhttps://github.com/zjunlp/EasyEdit.",
      "tldr_zh": "该论文引入了CKnowEdit，这是一个全新的中文知识编辑数据集，旨在纠正Large Language Models (LLMs)中的语言、事实和逻辑错误，特别关注中文的复杂特性如古诗、谚语和成语。数据集从古典文本、成语以及Baidu Tieba Ruozhiba等来源收集七种知识类型，并考虑了中文的复调、对偶和逻辑结构。通过分析CKnowEdit，研究者突出了LLMs在掌握中文方面的挑战，并评估了现有知识编辑技术的潜力，为改进这些模型的文化适应性提供了机会。代码和数据集可在GitHub上获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Ongoing work; project website is available at\n  https://zjunlp.github.io/project/CKnowEdit code and dataset are available at\n  https://github.com/zjunlp/EasyEdit",
      "pdf_url": "http://arxiv.org/pdf/2409.05806v3",
      "published_date": "2024-09-09 17:11:51 UTC",
      "updated_date": "2025-02-24 11:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:23:08.632936"
    },
    {
      "arxiv_id": "2409.05798v4",
      "title": "Enhancing Preference-based Linear Bandits via Human Response Time",
      "title_zh": "翻译失败",
      "authors": [
        "Shen Li",
        "Yuyang Zhang",
        "Zhaolin Ren",
        "Claire Liang",
        "Na Li",
        "Julie A. Shah"
      ],
      "abstract": "Interactive preference learning systems infer human preferences by presenting\nqueries as pairs of options and collecting binary choices. Although binary\nchoices are simple and widely used, they provide limited information about\npreference strength. To address this, we leverage human response times, which\nare inversely related to preference strength, as an additional signal. We\npropose a computationally efficient method that combines choices and response\ntimes to estimate human utility functions, grounded in the EZ diffusion model\nfrom psychology. Theoretical and empirical analyses show that for queries with\nstrong preferences, response times complement choices by providing extra\ninformation about preference strength, leading to significantly improved\nutility estimation. We incorporate this estimator into preference-based linear\nbandits for fixed-budget best-arm identification. Simulations on three\nreal-world datasets demonstrate that using response times significantly\naccelerates preference learning compared to choice-only approaches. Additional\nmaterials, such as code, slides, and talk video, are available at\nhttps://shenlirobot.github.io/pages/NeurIPS24.html",
      "tldr_zh": "这篇论文提出了一种增强基于偏好的线性 Bandits 方法，通过利用人类响应时间（作为偏好强度的额外信号）来改善交互式偏好学习。作者开发了一种高效算法，将二元选择与响应时间结合，使用 EZ diffusion model 估计人类效用函数。理论分析显示，响应时间为强偏好查询提供补充信息，从而显著提升效用估计的准确性。该方法被整合到固定预算的最佳臂识别任务中，实验在三个真实数据集上证明，与仅使用选择的方案相比，它加速了偏好学习过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "econ.EM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 (Oral) camera ready",
      "pdf_url": "http://arxiv.org/pdf/2409.05798v4",
      "published_date": "2024-09-09 17:02:47 UTC",
      "updated_date": "2025-01-02 12:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:23:20.312198"
    },
    {
      "arxiv_id": "2409.15338v1",
      "title": "Explainable AI: Definition and attributes of a good explanation for health AI",
      "title_zh": "可",
      "authors": [
        "Evangelia Kyrimi",
        "Scott McLachlan",
        "Jared M Wohlgemut",
        "Zane B Perkins",
        "David A. Lagnado",
        "William Marsh",
        "the ExAIDSS Expert Group"
      ],
      "abstract": "Proposals of artificial intelligence (AI) solutions based on increasingly\ncomplex and accurate predictive models are becoming ubiquitous across many\ndisciplines. As the complexity of these models grows, transparency and users'\nunderstanding often diminish. This suggests that accurate prediction alone is\ninsufficient for making an AI-based solution truly useful. In the development\nof healthcare systems, this introduces new issues related to accountability and\nsafety. Understanding how and why an AI system makes a recommendation may\nrequire complex explanations of its inner workings and reasoning processes.\nAlthough research on explainable AI (XAI) has significantly increased in recent\nyears and there is high demand for XAI in medicine, defining what constitutes a\ngood explanation remains ad hoc, and providing adequate explanations continues\nto be challenging. To fully realize the potential of AI, it is critical to\naddress two fundamental questions about explanations for safety-critical AI\napplications, such as health-AI: (1) What is an explanation in health-AI? and\n(2) What are the attributes of a good explanation in health-AI? In this study,\nwe examined published literature and gathered expert opinions through a\ntwo-round Delphi study. The research outputs include (1) a definition of what\nconstitutes an explanation in health-AI and (2) a comprehensive list of\nattributes that characterize a good explanation in health-AI.",
      "tldr_zh": "本研究探讨了Explainable AI (XAI)在健康AI领域的核心问题，强调AI模型的复杂性导致透明度和用户理解力下降，这在医疗应用中会引发责任和安全风险。通过文献审查和两轮Delphi研究，研究者定义了健康AI中什么是有效的解释，并列出了好解释的全面属性列表，包括准确性、可理解性和相关性等。这些成果为开发安全可靠的健康AI提供了关键指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15338v1",
      "published_date": "2024-09-09 16:56:31 UTC",
      "updated_date": "2024-09-09 16:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:23:33.022251"
    },
    {
      "arxiv_id": "2409.05786v1",
      "title": "Leveraging Object Priors for Point Tracking",
      "title_zh": "利用对象先验进行点跟踪",
      "authors": [
        "Bikram Boote",
        "Anh Thai",
        "Wenqi Jia",
        "Ozgur Kara",
        "Stefan Stojanov",
        "James M. Rehg",
        "Sangmin Lee"
      ],
      "abstract": "Point tracking is a fundamental problem in computer vision with numerous\napplications in AR and robotics. A common failure mode in long-term point\ntracking occurs when the predicted point leaves the object it belongs to and\nlands on the background or another object. We identify this as the failure to\ncorrectly capture objectness properties in learning to track. To address this\nlimitation of prior work, we propose a novel objectness regularization approach\nthat guides points to be aware of object priors by forcing them to stay inside\nthe the boundaries of object instances. By capturing objectness cues at\ntraining time, we avoid the need to compute object masks during testing. In\naddition, we leverage contextual attention to enhance the feature\nrepresentation for capturing objectness at the feature level more effectively.\nAs a result, our approach achieves state-of-the-art performance on three point\ntracking benchmarks, and we further validate the effectiveness of our\ncomponents via ablation studies. The source code is available at:\nhttps://github.com/RehgLab/tracking_objectness",
      "tldr_zh": "该论文针对点跟踪（point tracking）在计算机视觉中的常见问题，即预测点离开所属对象而导致的跟踪失败，提出了一种利用对象先验（object priors）的创新方法。研究引入对象性正则化（objectness regularization）技术，通过在训练时强制点保持在对象实例边界内，增强跟踪模型对对象属性的捕捉，同时避免测试时需要计算对象掩码；此外，还整合上下文注意力（contextual attention）来优化特征表示，提高对象性识别的效率。实验结果显示，该方法在三个点跟踪基准上实现了最先进性能，并通过消融研究验证了各组件的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 ILR Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.05786v1",
      "published_date": "2024-09-09 16:48:42 UTC",
      "updated_date": "2024-09-09 16:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:23:46.729008"
    },
    {
      "arxiv_id": "2409.05785v4",
      "title": "NeurLZ: An Online Neural Learning-Based Method to Enhance Scientific Lossy Compression",
      "title_zh": "NeurLZ：一种基于在线神经学习的方法以增强科学有损压缩",
      "authors": [
        "Wenqi Jia",
        "Zhewen Hu",
        "Youyuan Liu",
        "Boyuan Zhang",
        "Jinzhen Wang",
        "Jinyang Liu",
        "Wei Niu",
        "Stavros Kalafatis",
        "Junzhou Huang",
        "Sian Jin",
        "Daoce Wang",
        "Jiannan Tian",
        "Miao Yin"
      ],
      "abstract": "Large-scale scientific simulations generate massive datasets, posing\nchallenges for storage and I/O. Traditional lossy compression struggles to\nadvance more in balancing compression ratio, data quality, and adaptability to\ndiverse scientific data features. While deep learning-based solutions have been\nexplored, their common practice of relying on large models and offline training\nlimits adaptability to dynamic data characteristics and computational\nefficiency. To address these challenges, we propose NeurLZ, a neural method\ndesigned to enhance lossy compression by integrating online learning,\ncross-field learning, and robust error regulation. Key innovations of NeurLZ\ninclude: (1) compression-time online neural learning with lightweight skipping\nDNN models, adapting to residual errors without costly offline pertaining, (2)\nthe error-mitigating capability, recovering fine details from compression\nerrors overlooked by conventional compressors, (3) $1\\times$ and $2\\times$\nerror-regulation modes, ensuring strict adherence to $1\\times$ user-input error\nbounds strictly or relaxed 2$\\times$ bounds for better overall quality, and (4)\ncross-field learning leveraging inter-field correlations in scientific data to\nimprove conventional methods. Comprehensive evaluations on representative HPC\ndatasets, e.g., Nyx, Miranda, Hurricane, against state-of-the-art compressors\nshow NeurLZ's effectiveness. During the first five learning epochs, NeurLZ\nachieves an 89% bit rate reduction, with further optimization yielding up to\naround 94% reduction at equivalent distortion, significantly outperforming\nexisting methods, demonstrating NeurLZ's superior performance in enhancing\nscientific lossy compression as a scalable and efficient solution.",
      "tldr_zh": "该论文提出NeurLZ，一种基于在线神经学习的方法，用于提升科学损失压缩的性能，通过集成在线学习、跨字段学习和鲁棒错误调节，解决传统压缩在压缩比、数据质量和适应性上的局限。NeurLZ的关键创新包括使用轻量级跳过DNN模型进行压缩时的在线适应、错误缓解能力以恢复细微细节，以及1×和2×错误调节模式来确保用户指定的错误边界。实验在HPC数据集（如Nyx、Miranda和Hurricane）上显示，NeurLZ在前五个学习周期实现89%的比特率减少，进一步优化到94%，显著优于现有压缩方法，提供了一个可扩展、高效的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "ICS 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.05785v4",
      "published_date": "2024-09-09 16:48:09 UTC",
      "updated_date": "2025-04-18 04:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:23:56.776727"
    },
    {
      "arxiv_id": "2409.07497v1",
      "title": "OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System",
      "title_zh": "OneEdit: 一种神经符号协作知识编辑系统",
      "authors": [
        "Ningyu Zhang",
        "Zekun Xi",
        "Yujie Luo",
        "Peng Wang",
        "Bozhong Tian",
        "Yunzhi Yao",
        "Jintian Zhang",
        "Shumin Deng",
        "Mengshu Sun",
        "Lei Liang",
        "Zhiqiang Zhang",
        "Xiaowei Zhu",
        "Jun Zhou",
        "Huajun Chen"
      ],
      "abstract": "Knowledge representation has been a central aim of AI since its inception.\nSymbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can\nboth represent knowledge. KGs provide highly accurate and explicit knowledge\nrepresentation, but face scalability issue; while LLMs offer expansive coverage\nof knowledge, but incur significant training costs and struggle with precise\nand reliable knowledge manipulation. To this end, we introduce OneEdit, a\nneural-symbolic prototype system for collaborative knowledge editing using\nnatural language, which facilitates easy-to-use knowledge management with KG\nand LLM. OneEdit consists of three modules: 1) The Interpreter serves for user\ninteraction with natural language; 2) The Controller manages editing requests\nfrom various users, leveraging the KG with rollbacks to handle knowledge\nconflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the\nknowledge from the Controller to edit KG and LLM. We conduct experiments on two\nnew datasets with KGs which demonstrate that OneEdit can achieve superior\nperformance.",
      "tldr_zh": "该研究提出 OneEdit，一种神经-符号混合系统，用于通过自然语言实现 KGs（Knowledge Graphs）和 LLMs（Large Language Models）的协作知识编辑，旨在解决 KGs 可扩展性差和 LLMs 在精确知识操作上的局限性。OneEdit 由三个模块组成：Interpreter 处理用户自然语言交互、Controller 管理编辑请求并使用 KGs 处理冲突和攻击（支持回滚）、Editor 利用这些知识编辑 KGs 和 LLMs。该系统在两个新数据集上进行实验，展示了优越的性能，提升了知识管理的准确性和易用性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "LLM+KG@VLDB2024, code is available at\n  https://github.com/zjunlp/OneEdit",
      "pdf_url": "http://arxiv.org/pdf/2409.07497v1",
      "published_date": "2024-09-09 16:46:47 UTC",
      "updated_date": "2024-09-09 16:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:24:07.958722"
    },
    {
      "arxiv_id": "2409.05773v2",
      "title": "Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera",
      "title_zh": "从机器到音乐家的创造力和视觉交流：通过机器人相机分享乐谱",
      "authors": [
        "Ross Greer",
        "Laura Fleig",
        "Shlomo Dubnov"
      ],
      "abstract": "This paper explores the integration of visual communication and musical\ninteraction by implementing a robotic camera within a \"Guided Harmony\" musical\ngame. We aim to examine co-creative behaviors between human musicians and\nrobotic systems. Our research explores existing methodologies like\nimprovisational game pieces and extends these concepts to include robotic\nparticipation using a PTZ camera. The robotic system interprets and responds to\nnonverbal cues from musicians, creating a collaborative and adaptive musical\nexperience. This initial case study underscores the importance of intuitive\nvisual communication channels. We also propose future research directions,\nincluding parameters for refining the visual cue toolkit and data collection\nmethods to understand human-machine co-creativity further. Our findings\ncontribute to the broader understanding of machine intelligence in augmenting\nhuman creativity, particularly in musical settings.",
      "tldr_zh": "这篇论文探讨了机器与音乐家之间的视觉通信和共同创造行为，通过在“Guided Harmony”音乐游戏中引入PTZ camera机器人摄像机来实现共享乐谱。研究扩展了即兴游戏片段的方法，让机器人系统解释并响应音乐家的非语言线索，从而创建协作性和适应性的音乐体验。初步案例研究强调了直观视觉通信渠道的重要性，并提出未来研究方向，如优化视觉线索工具包参数和数据收集方法，以进一步理解人机共同创造力。该工作有助于加深对机器智能在增强人类创造力方面的认识，尤其在音乐环境中。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05773v2",
      "published_date": "2024-09-09 16:34:36 UTC",
      "updated_date": "2024-10-28 01:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:24:20.180854"
    },
    {
      "arxiv_id": "2409.05771v1",
      "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
      "title_zh": "fMRI 证据支持语言模型中的两阶段抽象过程",
      "authors": [
        "Emily Cheng",
        "Richard J. Antonello"
      ],
      "abstract": "Research has repeatedly demonstrated that intermediate hidden states\nextracted from large language models are able to predict measured brain\nresponse to natural language stimuli. Yet, very little is known about the\nrepresentation properties that enable this high prediction performance. Why is\nit the intermediate layers, and not the output layers, that are most capable\nfor this unique and highly general transfer task? In this work, we show that\nevidence from language encoding models in fMRI supports the existence of a\ntwo-phase abstraction process within LLMs. We use manifold learning methods to\nshow that this abstraction process naturally arises over the course of training\na language model and that the first \"composition\" phase of this abstraction\nprocess is compressed into fewer layers as training continues. Finally, we\ndemonstrate a strong correspondence between layerwise encoding performance and\nthe intrinsic dimensionality of representations from LLMs. We give initial\nevidence that this correspondence primarily derives from the inherent\ncompositionality of LLMs and not their next-word prediction properties.",
      "tldr_zh": "本研究利用 fMRI 证据支持大型语言模型（LLMs）中存在一个两阶段抽象过程，即第一阶段的“composition”组合过程。研究者通过流形学习（manifold learning）方法分析发现，这一抽象过程在模型训练过程中自然出现，且第一阶段被压缩到更少的层级。结果显示，LLMs 的层级编码性能与表示的内在维度（intrinsic dimensionality）有强烈对应，这一对应主要源于模型的 inherent compositionality 而非 next-word prediction 属性。该发现有助于深化对 LLMs 内部表示机制的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution from both authors. Submitted to NeurIPS NeuroAI\n  workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05771v1",
      "published_date": "2024-09-09 16:33:16 UTC",
      "updated_date": "2024-09-09 16:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:24:31.784048"
    },
    {
      "arxiv_id": "2409.06493v1",
      "title": "Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Jena",
        "Ali Taghibakhshi",
        "Sahil Jain",
        "Gerald Shen",
        "Nima Tajbakhsh",
        "Arash Vahdat"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have become prominent tools for\ngenerating high-fidelity images from text prompts. However, when trained on\nunfiltered internet data, these models can produce unsafe, incorrect, or\nstylistically undesirable images that are not aligned with human preferences.\nTo address this, recent approaches have incorporated human preference datasets\nto fine-tune T2I models or to optimize reward functions that capture these\npreferences. Although effective, these methods are vulnerable to reward\nhacking, where the model overfits to the reward function, leading to a loss of\ndiversity in the generated images. In this paper, we prove the inevitability of\nreward hacking and study natural regularization techniques like KL divergence\nand LoRA scaling, and their limitations for diffusion models. We also introduce\nAnnealed Importance Guidance (AIG), an inference-time regularization inspired\nby Annealed Importance Sampling, which retains the diversity of the base model\nwhile achieving Pareto-Optimal reward-diversity tradeoffs. Our experiments\ndemonstrate the benefits of AIG for Stable Diffusion models, striking the\noptimal balance between reward optimization and image diversity. Furthermore, a\nuser study confirms that AIG improves diversity and quality of generated images\nacross different model architectures and reward functions.",
      "tldr_zh": "本研究探讨了Text-to-Image Diffusion Models在生成图像时，如何在奖励优化与图像多样性之间实现最优权衡。论文证明了奖励黑客（reward hacking）的必然性，即模型过拟合奖励函数导致多样性丧失，并分析了KL divergence和LoRA scaling等正则化技术的局限性。随后，引入了Annealed Importance Guidance (AIG)，一种基于Annealed Importance Sampling的推理时正则化方法，能保留基础模型的多样性，同时实现Pareto-Optimal的奖励-多样性 tradeoff。实验结果显示，AIG显著提升了Stable Diffusion模型的图像质量和多样性，用户研究进一步证实其在不同模型架构和奖励函数下的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.06493v1",
      "published_date": "2024-09-09 16:27:26 UTC",
      "updated_date": "2024-09-09 16:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:24:45.350690"
    },
    {
      "arxiv_id": "2409.05749v1",
      "title": "ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL",
      "title_zh": "翻译失败",
      "authors": [
        "Safwen Naimi",
        "Wassim Bouachir",
        "Guillaume-Alexandre Bilodeau"
      ],
      "abstract": "To extract robust and generalizable skeleton action recognition features,\nlarge amounts of well-curated data are typically required, which is a\nchallenging task hindered by annotation and computation costs. Therefore,\nunsupervised representation learning is of prime importance to leverage\nunlabeled skeleton data. In this work, we investigate unsupervised\nrepresentation learning for skeleton action recognition. For this purpose, we\ndesigned a lightweight convolutional transformer framework, named ReL-SAR,\nexploiting the complementarity of convolutional and attention layers for\njointly modeling spatial and temporal cues in skeleton sequences. We also use a\nSelection-Permutation strategy for skeleton joints to ensure more informative\ndescriptions from skeletal data. Finally, we capitalize on Bootstrap Your Own\nLatent (BYOL) to learn robust representations from unlabeled skeleton sequence\ndata. We achieved very competitive results on limited-size datasets: MCAD,\nIXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method\nagainst state-of-the-art methods in terms of both performance and computational\nefficiency. To ensure reproducibility and reusability, the source code\nincluding all implementation parameters is provided at:\nhttps://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL",
      "tldr_zh": "该研究针对骨骼动作识别提出了一种无监督表示学习方法ReL-SAR，利用Convolutional Transformers结合卷积和注意力层，来共同建模骨骼序列的空间和时间线索。框架还引入Selection-Permutation策略来优化骨骼关节的描述，并采用Bootstrap Your Own Latent (BYOL)从无标签数据中学习鲁棒表示。实验结果显示，ReL-SAR在MCAD、IXMAS、JHMDB和NW-UCLA数据集上取得了与最先进方法相当的性能，同时提高了计算效率；源代码已在GitHub上公开以支持可重复性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.05749v1",
      "published_date": "2024-09-09 16:03:26 UTC",
      "updated_date": "2024-09-09 16:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:24:55.912810"
    },
    {
      "arxiv_id": "2409.05747v1",
      "title": "A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System",
      "title_zh": "翻译失败",
      "authors": [
        "B. Sankar",
        "Dibakar Sen"
      ],
      "abstract": "This paper presents a novel conversational AI-enabled active ideation\ninterface as a creative idea-generation tool to assist novice designers in\nmitigating the initial latency and ideation bottlenecks that are commonly\nobserved. It is a dynamic, interactive, and contextually responsive approach,\nactively involving a large language model (LLM) from the domain of natural\nlanguage processing (NLP) in artificial intelligence (AI) to produce multiple\nstatements of potential ideas for different design problems. Integrating such\nAI models with ideation creates what we refer to as an Active Ideation\nscenario, which helps foster continuous dialogue-based interaction,\ncontext-sensitive conversation, and prolific idea generation. A pilot study was\nconducted with thirty novice designers to generate ideas for given problems\nusing traditional methods and the new CAI-based interface. The key parameters\nof fluency, novelty, and variety were used to compare the outcomes\nqualitatively by a panel of experts. The findings demonstrated the\neffectiveness of the proposed tool for generating prolific, diverse and novel\nideas. The interface was enhanced by incorporating a prompt-engineered\nstructured dialogue style for each ideation stage to make it uniform and more\nconvenient for the designers. The resulting responses of such a structured CAI\ninterface were found to be more succinct and aligned towards the subsequent\ndesign stage, namely conceptualization. The paper thus established the rich\npotential of using Generative AI (Gen-AI) for the early ill-structured phase of\nthe creative product design process.",
      "tldr_zh": "这篇论文提出了一种新型的结构化 Conversational AI (CAI) 系统，作为创意构想工具，帮助新手设计师克服初始延迟和构想瓶颈，通过 Large Language Model (LLM) 和自然语言处理 (NLP) 技术实现主动互动和多样化想法生成。研究通过一项试点实验，让 30 名设计师使用传统方法和 CAI 接口生成想法，并基于 fluency、novelty 和 variety 参数进行定性比较，结果显示 CAI 接口显著提高了想法的丰富性、多样性和新颖性。论文进一步优化了接口的提示工程结构化对话风格，使其更简洁地支持后续设计阶段如概念化，并强调了 Generative AI (Gen-AI) 在创意产品设计早期非结构化阶段的巨大潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; J.6"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 16 figures, AIEDAM Journal Article",
      "pdf_url": "http://arxiv.org/pdf/2409.05747v1",
      "published_date": "2024-09-09 16:02:27 UTC",
      "updated_date": "2024-09-09 16:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:25:10.365165"
    },
    {
      "arxiv_id": "2409.05735v2",
      "title": "A System and Benchmark for LLM-based Q&A on Heterogeneous Data",
      "title_zh": "一种基于LLM的异构数据问答系统和基准",
      "authors": [
        "Achille Fokoue",
        "Srideepika Jayaraman",
        "Elham Khabiri",
        "Jeffrey O. Kephart",
        "Yingjie Li",
        "Dhruv Shah",
        "Youssef Drissi",
        "Fenno F. Heath III",
        "Anu Bhamidipaty",
        "Fateh A. Tipu",
        "Robert J. Baseman"
      ],
      "abstract": "In many industrial settings, users wish to ask questions whose answers may be\nfound in structured data sources such as a spreadsheets, databases, APIs, or\ncombinations thereof. Often, the user doesn't know how to identify or access\nthe right data source. This problem is compounded even further if multiple (and\npotentially siloed) data sources must be assembled to derive the answer.\nRecently, various Text-to-SQL applications that leverage Large Language Models\n(LLMs) have addressed some of these problems by enabling users to ask questions\nin natural language. However, these applications remain impractical in\nrealistic industrial settings because they fail to cope with the data source\nheterogeneity that typifies such environments. In this paper, we address\nheterogeneity by introducing the siwarex platform, which enables seamless\nnatural language access to both databases and APIs. To demonstrate the\neffectiveness of siwarex, we extend the popular Spider dataset and benchmark by\nreplacing some of its tables by data retrieval APIs. We find that siwarex does\na good job of coping with data source heterogeneity. Our modified Spider\nbenchmark will soon be available to the research community",
      "tldr_zh": "本研究提出 siwarex 系统，这是一个基于 Large Language Models (LLMs) 的平台，允许用户通过自然语言查询异构数据源，如数据库、API 和电子表格，从而解决用户难以识别或整合多源数据的难题。siwarex 扩展了 Spider 数据集和基准，将部分表替换为数据检索 API，以评估其在处理数据源异构性方面的性能。实验结果表明，siwarex 有效应对了这些挑战，并计划向研究社区公开修改后的 Spider 基准。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05735v2",
      "published_date": "2024-09-09 15:44:39 UTC",
      "updated_date": "2024-09-10 21:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:25:19.968131"
    },
    {
      "arxiv_id": "2409.05731v3",
      "title": "What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Kaufman",
        "Aaron Broukhim",
        "David Kirsh",
        "Nadir Weibel"
      ],
      "abstract": "Explanations for autonomous vehicle (AV) decisions may build trust, however,\nexplanations can contain errors. In a simulated driving study (n = 232), we\ntested how AV explanation errors, driving context characteristics (perceived\nharm and driving difficulty), and personal traits (prior trust and expertise)\naffected a passenger's comfort in relying on an AV, preference for control,\nconfidence in the AV's ability, and explanation satisfaction. Errors negatively\naffected all outcomes. Surprisingly, despite identical driving, explanation\nerrors reduced ratings of the AV's driving ability. Severity and potential harm\namplified the negative impact of errors. Contextual harm and driving difficulty\ndirectly impacted outcome ratings and influenced the relationship between\nerrors and outcomes. Prior trust and expertise were positively associated with\noutcome ratings. Results emphasize the need for accurate, contextually\nadaptive, and personalized AV explanations to foster trust, reliance,\nsatisfaction, and confidence. We conclude with design, research, and deployment\nrecommendations for trustworthy AV explanation systems.",
      "tldr_zh": "本研究通过一项模拟驾驶实验（n=232），探讨了自动驾驶车辆 (AV) 决策解释错误、驾驶情境（感知危害和难度）以及个人特质（先前信任和专业知识）对乘客舒适度、依赖性、满意度和驾驶信心等因素的影响。结果显示，解释错误会负面影响所有评估指标，甚至降低对 AV 驾驶能力的整体评价，且错误的负面效应会因严重性和潜在危害而放大。驾驶情境的危害和难度直接影响结果，并调节错误与结果的关系，而先前信任和专业知识则与积极评价相关。该研究强调需要开发准确、适应情境和个性化的 AV 解释系统，并提出设计、研究和部署方面的推荐，以提升用户信任和系统可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, Accepted to CHI Conference on Human Factors in Computing\n  Systems (CHI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.05731v3",
      "published_date": "2024-09-09 15:41:53 UTC",
      "updated_date": "2025-01-28 21:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:25:32.559531"
    },
    {
      "arxiv_id": "2409.05721v1",
      "title": "Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding",
      "title_zh": "视觉基础对话中带有话语感知理解引导的指称表达生成",
      "authors": [
        "Bram Willemsen",
        "Gabriel Skantze"
      ],
      "abstract": "We propose an approach to referring expression generation (REG) in visually\ngrounded dialogue that is meant to produce referring expressions (REs) that are\nboth discriminative and discourse-appropriate. Our method constitutes a\ntwo-stage process. First, we model REG as a text- and image-conditioned\nnext-token prediction task. REs are autoregressively generated based on their\npreceding linguistic context and a visual representation of the referent.\nSecond, we propose the use of discourse-aware comprehension guiding as part of\na generate-and-rerank strategy through which candidate REs generated with our\nREG model are reranked based on their discourse-dependent discriminatory power.\nResults from our human evaluation indicate that our proposed two-stage approach\nis effective in producing discriminative REs, with higher performance in terms\nof text-image retrieval accuracy for reranked REs compared to those generated\nusing greedy decoding.",
      "tldr_zh": "该研究提出了一种针对视觉基础对话（visually grounded dialogue）的指称表达式生成（Referring Expression Generation, REG）方法，旨在生成既具有区分性又符合语境的指称表达式（REs）。方法采用两阶段过程：首先，将 REG 建模为基于文本和图像的自回归下一个标记预测任务，根据前置语言上下文和参照物的视觉表示生成 REs；其次，通过语境感知理解引导（discourse-aware comprehension guiding）作为生成和重新排序策略，对候选 REs 基于其语境相关区分能力进行重新排序。人类评估结果显示，该方法有效提升了 REs 的区分性能，重新排序后的 REs 在文本-图像检索准确性上优于贪婪解码生成的版本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at INLG 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05721v1",
      "published_date": "2024-09-09 15:33:07 UTC",
      "updated_date": "2024-09-09 15:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:25:44.385792"
    },
    {
      "arxiv_id": "2409.05701v3",
      "title": "pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning",
      "title_zh": "pFedGPA：基于扩散的生成式参数聚合用于个性化联邦学习",
      "authors": [
        "Jiahao Lai",
        "Jiaqi Li",
        "Jian Xu",
        "Yanru Wu",
        "Boshi Tang",
        "Siqi Chen",
        "Yongfeng Huang",
        "Wenbo Ding",
        "Yang Li"
      ],
      "abstract": "Federated Learning (FL) offers a decentralized approach to model training,\nwhere data remains local and only model parameters are shared between the\nclients and the central server. Traditional methods, such as Federated\nAveraging (FedAvg), linearly aggregate these parameters which are usually\ntrained on heterogeneous data distributions, potentially overlooking the\ncomplex, high-dimensional nature of the parameter space. This can result in\ndegraded performance of the aggregated model. While personalized FL approaches\ncan mitigate the heterogeneous data issue to some extent, the limitation of\nlinear aggregation remains unresolved. To alleviate this issue, we investigate\nthe generative approach of diffusion model and propose a novel generative\nparameter aggregation framework for personalized FL, \\texttt{pFedGPA}. In this\nframework, we deploy a diffusion model on the server to integrate the diverse\nparameter distributions and propose a parameter inversion method to efficiently\ngenerate a set of personalized parameters for each client. This inversion\nmethod transforms the uploaded parameters into a latent code, which is then\naggregated through denoising sampling to produce the final personalized\nparameters. By encoding the dependence of a client's model parameters on the\nspecific data distribution using the high-capacity diffusion model,\n\\texttt{pFedGPA} can effectively decouple the complexity of the overall\ndistribution of all clients' model parameters from the complexity of each\nindividual client's parameter distribution. Our experimental results\nconsistently demonstrate the superior performance of the proposed method across\nmultiple datasets, surpassing baseline approaches.",
      "tldr_zh": "该论文提出了一种名为 pFedGPA 的生成式参数聚合框架，用于个性化 Federated Learning (FL)，旨在解决传统方法如 Federated Averaging (FedAvg) 在处理异构数据分布时因线性聚合导致的性能下降问题。通过在服务器上部署 diffusion model，pFedGPA 整合了客户端的多样参数分布，并引入参数 inversion 方法，将上传参数转化为潜在代码，再通过 denoising sampling 生成个性化的参数，从而有效解耦整体和个体的参数复杂性。实验结果显示，该方法在多个数据集上超越了基线方法，证明了其在提升 FL 性能方面的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05701v3",
      "published_date": "2024-09-09 15:13:56 UTC",
      "updated_date": "2025-02-11 17:14:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:25:56.519848"
    },
    {
      "arxiv_id": "2409.05698v1",
      "title": "MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyu Wang",
        "Tiejun Ma"
      ],
      "abstract": "It is widely acknowledged that extracting market sentiments from news data\nbenefits market predictions. However, existing methods of using financial\nsentiments remain simplistic, relying on equal-weight and static aggregation to\nmanage sentiments from multiple news items. This leads to a critical issue\ntermed ``Aggregated Sentiment Homogenization'', which has been explored through\nour analysis of a large financial news dataset from industry practice. This\nphenomenon occurs when aggregating numerous sentiments, causing representations\nto converge towards the mean values of sentiment distributions and thereby\nsmoothing out unique and important information. Consequently, the aggregated\nsentiment representations lose much predictive value of news data. To address\nthis problem, we introduce the Market Attention-weighted News Aggregation\nNetwork (MANA-Net), a novel method that leverages a dynamic market-news\nattention mechanism to aggregate news sentiments for market prediction.\nMANA-Net learns the relevance of news sentiments to price changes and assigns\nvarying weights to individual news items. By integrating the news aggregation\nstep into the networks for market prediction, MANA-Net allows for trainable\nsentiment representations that are optimized directly for prediction. We\nevaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with\nfinancial news spanning from 2003 to 2018. Experimental results demonstrate\nthat MANA-Net outperforms various recent market prediction methods, enhancing\nProfit & Loss by 1.1% and the daily Sharpe ratio by 0.252.",
      "tldr_zh": "该研究指出了现有金融新闻情绪聚合方法存在“Aggregated Sentiment Homogenization”问题，即使用等权重静态聚合导致情绪信息同质化和预测价值丢失。针对此，作者提出 MANA-Net（Market Attention-weighted News Aggregation Network），一种动态市场-新闻注意力机制，用于为新闻情绪分配可变权重，并将其集成到市场预测网络中进行优化训练。在 S&P 500 和 NASDAQ 100 指数的实验中，MANA-Net 比现有方法提升 Profit & Loss 1.1% 和每日 Sharpe ratio 0.252%，从而增强了市场预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM 24",
      "pdf_url": "http://arxiv.org/pdf/2409.05698v1",
      "published_date": "2024-09-09 15:12:24 UTC",
      "updated_date": "2024-09-09 15:12:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:26:08.159193"
    },
    {
      "arxiv_id": "2409.05677v2",
      "title": "RIRAG: Regulatory Information Retrieval and Answer Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tuba Gokhan",
        "Kexin Wang",
        "Iryna Gurevych",
        "Ted Briscoe"
      ],
      "abstract": "Regulatory documents, issued by governmental regulatory bodies, establish\nrules, guidelines, and standards that organizations must adhere to for legal\ncompliance. These documents, characterized by their length, complexity and\nfrequent updates, are challenging to interpret, requiring significant\nallocation of time and expertise on the part of organizations to ensure ongoing\ncompliance. Regulatory Natural Language Processing (RegNLP) is a\nmultidisciplinary field aimed at simplifying access to and interpretation of\nregulatory rules and obligations. We introduce a task of generating\nquestion-passages pairs, where questions are automatically created and paired\nwith relevant regulatory passages, facilitating the development of regulatory\nquestion-answering systems. We create the ObliQA dataset, containing 27,869\nquestions derived from the collection of Abu Dhabi Global Markets (ADGM)\nfinancial regulation documents, design a baseline Regulatory Information\nRetrieval and Answer Generation (RIRAG) system and evaluate it with RePASs, a\nnovel evaluation metric that tests whether generated answers accurately capture\nall relevant obligations while avoiding contradictions.",
      "tldr_zh": "该论文探讨了监管文档的复杂性和合规挑战，介绍了 Regulatory Natural Language Processing (RegNLP) 领域的新任务：生成问题-段落对，以支持监管问答系统。研究者创建了 ObliQA 数据集，包含 27,869 个从 Abu Dhabi Global Markets (ADGM) 金融监管文档中衍生的问题，并设计了基线系统 RIRAG，用于监管信息检索和答案生成。同时，他们提出了一种新评估指标 RePASs，以验证生成的答案是否准确捕捉所有相关义务并避免矛盾，从而提升监管信息的可访问性和解释性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05677v2",
      "published_date": "2024-09-09 14:44:19 UTC",
      "updated_date": "2024-12-02 18:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:26:19.775155"
    },
    {
      "arxiv_id": "2409.05674v2",
      "title": "Evaluation of real-time transcriptions using end-to-end ASR models",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Arriaga",
        "Alejandro Pozo",
        "Javier Conde",
        "Alvaro Alonso"
      ],
      "abstract": "Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly\nevolved in the last few years. Traditional architectures based on pipelines\nhave been replaced by joint end-to-end (E2E) architectures that simplify and\nstreamline the model training process. In addition, new AI training methods,\nsuch as weak-supervised learning have reduced the need for high-quality audio\ndatasets for model training. However, despite all these advancements, little to\nno research has been done on real-time transcription. In real-time scenarios,\nthe audio is not pre-recorded, and the input audio must be fragmented to be\nprocessed by the ASR systems. To achieve real-time requirements, these\nfragments must be as short as possible to reduce latency. However, audio cannot\nbe split at any point as dividing an utterance into two separate fragments will\ngenerate an incorrect transcription. Also, shorter fragments provide less\ncontext for the ASR model. For this reason, it is necessary to design and test\ndifferent splitting algorithms to optimize the quality and delay of the\nresulting transcription. In this paper, three audio splitting algorithms are\nevaluated with different ASR models to determine their impact on both the\nquality of the transcription and the end-to-end delay. The algorithms are\nfragmentation at fixed intervals, voice activity detection (VAD), and\nfragmentation with feedback. The results are compared to the performance of the\nsame model, without audio fragmentation, to determine the effects of this\ndivision. The results show that VAD fragmentation provides the best quality\nwith the highest delay, whereas fragmentation at fixed intervals provides the\nlowest quality and the lowest delay. The newly proposed feedback algorithm\nexchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,\nto the VAD splitting.",
      "tldr_zh": "这篇论文评估了端到端（E2E）ASR模型在实时转录中的性能，重点探讨音频碎片化对转录质量和延迟的影响。研究比较了三种音频分割算法：固定间隔分割、语音活动检测（VAD）和带反馈的分割算法，以不同ASR模型为基础进行测试。结果表明，VAD算法提供最高转录质量但延迟最大，而固定间隔算法则质量最低但延迟最小；新提出的带反馈算法在增加2-4%的WER的同时，可减少1.5-2秒的端到端延迟，从而为实时ASR优化提供了平衡策略。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.SD",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.05674v2",
      "published_date": "2024-09-09 14:41:57 UTC",
      "updated_date": "2024-09-11 10:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:26:32.647684"
    },
    {
      "arxiv_id": "2409.05672v2",
      "title": "Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Shen",
        "Haomin Wen",
        "Leman Akoglu"
      ],
      "abstract": "Outlier detection (OD) has a vast literature as it finds numerous real-world\napplications. Being an inherently unsupervised task, model selection is a key\nbottleneck for OD without label supervision. Despite many OD techniques are\navailable to choose from, algorithm and hyperparameter selection remain\nchallenging for OD, limiting its effective use in practice. In this paper, we\npresent FoMo-0D, a pre-trained Foundation Model for zero/0-shot OD on tabular\ndata, which bypasses the hurdle of model selection. To overcome the difficulty\nof labeled data collection, FoMo-0D is trained on synthetic data and can\ndirectly predict the (outlier/inlier) label of test samples without parameter\nfine-tuning -- making the need obsolete for choosing an algorithm/architecture\nand tuning its associated hyperparameters when given a new OD dataset.\nExtensive experiments on 57 real-world datasets against 26 baselines show that\nFoMo-0D significantly outperforms the vast majority of the baselines and is\nstatistically no different from the 2nd best method, with an average inference\ntime of 7.7 ms per sample, offering at least 7x speed-up compared to previous\nmethods. To facilitate future research, our implementations and checkpoints are\nopenly available at https://anonymous.4open.science/r/PFN40D.",
      "tldr_zh": "这篇论文解决了异常检测（Outlier Detection, OD）的模型选择难题，提出FoMo-0D，一个基于Prior-data Fitted Networks的预训练Foundation Model，用于zero-shot OD on tabular data。FoMo-0D利用合成数据进行训练，无需参数微调即可直接预测测试样本的（outlier/inlier）标签，从而绕过算法和超参数调优的挑战。在57个真实数据集上的实验中，FoMo-0D显著优于26个基线方法，与第二佳方法无统计学差异，同时平均推理时间仅7.7 ms per sample，提供至少7倍的速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.05672v2",
      "published_date": "2024-09-09 14:41:24 UTC",
      "updated_date": "2025-02-06 19:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:26:44.612514"
    },
    {
      "arxiv_id": "2409.05662v2",
      "title": "Real-Time Human Action Recognition on Embedded Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Wang",
        "Zichen Wang",
        "Peiqi Gao",
        "Mingzhen Li",
        "Jaehwan Jeong",
        "Yihang Xu",
        "Yejin Lee",
        "Carolyn M. Baum",
        "Lisa Tabor Connor",
        "Chenyang Lu"
      ],
      "abstract": "With advancements in computer vision and deep learning, video-based human\naction recognition (HAR) has become practical. However, due to the complexity\nof the computation pipeline, running HAR on live video streams incurs excessive\ndelays on embedded platforms. This work tackles the real-time performance\nchallenges of HAR with four contributions: 1) an experimental study identifying\na standard Optical Flow (OF) extraction technique as the latency bottleneck in\na state-of-the-art HAR pipeline, 2) an exploration of the latency-accuracy\ntradeoff between the standard and deep learning approaches to OF extraction,\nwhich highlights the need for a novel, efficient motion feature extractor, 3)\nthe design of Integrated Motion Feature Extractor (IMFE), a novel single-shot\nneural network architecture for motion feature extraction with drastic\nimprovement in latency, 4) the development of RT-HARE, a real-time HAR system\ntailored for embedded platforms. Experimental results on an Nvidia Jetson\nXavier NX platform demonstrated that RT-HARE realizes real-time HAR at a video\nframe rate of 30 frames per second while delivering high levels of recognition\naccuracy.",
      "tldr_zh": "该研究针对嵌入式平台上的人体动作识别 (HAR) 的实时性能挑战，进行了四方面贡献：首先，通过实验识别了标准 Optical Flow (OF) 提取作为 HAR 管道中的延迟瓶颈；其次，探讨了标准和深度学习方法在 OF 提取中的延迟-准确性权衡，突显了高效运动特征提取器的需求；第三，设计了 Integrated Motion Feature Extractor (IMFE)，一种单次拍摄的神经网络架构，大幅降低了延迟；第四，开发了 RT-HARE 系统，实现嵌入式平台的实时 HAR。在 Nvidia Jetson Xavier NX 上实验表明，RT-HARE 达到了 30 帧/秒的视频帧率，同时保持高识别准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05662v2",
      "published_date": "2024-09-09 14:35:23 UTC",
      "updated_date": "2024-09-11 14:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:26:55.864288"
    },
    {
      "arxiv_id": "2409.05655v3",
      "title": "Interactive incremental learning of generalizable skills with local trajectory modulation",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Knauer",
        "Alin Albu-Schäffer",
        "Freek Stulp",
        "João Silvério"
      ],
      "abstract": "The problem of generalization in learning from demonstration (LfD) has\nreceived considerable attention over the years, particularly within the context\nof movement primitives, where a number of approaches have emerged. Recently,\ntwo important approaches have gained recognition. While one leverages\nvia-points to adapt skills locally by modulating demonstrated trajectories,\nanother relies on so-called task-parameterized models that encode movements\nwith respect to different coordinate systems, using a product of probabilities\nfor generalization. While the former are well-suited to precise, local\nmodulations, the latter aim at generalizing over large regions of the workspace\nand often involve multiple objects. Addressing the quality of generalization by\nleveraging both approaches simultaneously has received little attention. In\nthis work, we propose an interactive imitation learning framework that\nsimultaneously leverages local and global modulations of trajectory\ndistributions. Building on the kernelized movement primitives (KMP) framework,\nwe introduce novel mechanisms for skill modulation from direct human corrective\nfeedback. Our approach particularly exploits the concept of via-points to\nincrementally and interactively 1) improve the model accuracy locally, 2) add\nnew objects to the task during execution and 3) extend the skill into regions\nwhere demonstrations were not provided. We evaluate our method on a bearing\nring-loading task using a torque-controlled, 7-DoF, DLR SARA robot.",
      "tldr_zh": "本研究针对从演示学习(LfD)中的泛化问题，提出了一种交互式模仿学习框架，该框架同时利用局部和全局轨迹分布调制。基于Kernelized Movement Primitives (KMP)，该方法引入新机制，通过人类纠正反馈和via-points概念，实现模型精度的增量式改进、任务中新增对象的添加，以及技能扩展到未演示区域。实验在DLR SARA机器人上进行的轴承环加载任务中验证了该框架的有效性，展示了其在提升技能泛化方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE Robotics and Automation Letters (RA-L), 16 pages, 19\n  figures, 6 tables. See\n  https://github.com/DLR-RM/interactive-incremental-learning for further\n  information and video",
      "pdf_url": "http://arxiv.org/pdf/2409.05655v3",
      "published_date": "2024-09-09 14:22:19 UTC",
      "updated_date": "2025-02-21 08:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:27:07.693433"
    },
    {
      "arxiv_id": "2409.05650v3",
      "title": "Replay Consolidation with Label Propagation for Continual Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo De Monte",
        "Davide Dalle Pezze",
        "Marina Ceccon",
        "Francesco Pasti",
        "Francesco Paissan",
        "Elisabetta Farella",
        "Gian Antonio Susto",
        "Nicola Bellotto"
      ],
      "abstract": "Continual Learning (CL) aims to learn new data while remembering previously\nacquired knowledge. In contrast to CL for image classification, CL for Object\nDetection faces additional challenges such as the missing annotations problem.\nIn this scenario, images from previous tasks may contain instances of unknown\nclasses that could reappear as labeled in future tasks, leading to task\ninterference in replay-based approaches. Consequently, most approaches in the\nliterature have focused on distillation-based techniques, which are effective\nwhen there is a significant class overlap between tasks. In our work, we\npropose an alternative to distillation-based approaches with a novel approach\ncalled Replay Consolidation with Label Propagation for Object Detection\n(RCLPOD). RCLPOD enhances the replay memory by improving the quality of the\nstored samples through a technique that promotes class balance while also\nimproving the quality of the ground truth associated with these samples through\na technique called label propagation. RCLPOD outperforms existing techniques on\nwell-established benchmarks such as VOC and COC. Moreover, our approach is\ndeveloped to work with modern architectures like YOLOv8, making it suitable for\ndynamic, real-world applications such as autonomous driving and robotics, where\ncontinuous learning and resource efficiency are essential.",
      "tldr_zh": "这篇论文针对 Continual Learning 在 Object Detection 中的挑战（如缺少注释和任务干扰），提出了一种新方法 Replay Consolidation with Label Propagation for Object Detection (RCLPOD)。RCLPOD 通过提升 replay memory 的样本质量，包括促进类平衡和使用 label propagation 技术改进 ground truth，从而缓解任务间的知识干扰。实验结果显示，该方法在 VOC 和 COCO 基准上优于现有技术，并与现代架构如 YOLOv8 兼容，适用于自主驾驶和机器人等需要连续学习和资源效率的实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05650v3",
      "published_date": "2024-09-09 14:16:27 UTC",
      "updated_date": "2025-03-04 10:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:27:21.970828"
    },
    {
      "arxiv_id": "2409.05636v1",
      "title": "3D-SAR Tomography and Machine Learning for High-Resolution Tree Height Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Grace Colverd",
        "Jumpei Takami",
        "Laura Schade",
        "Karol Bot",
        "Joseph A. Gallego-Mejia"
      ],
      "abstract": "Accurately estimating forest biomass is crucial for global carbon cycle\nmodelling and climate change mitigation. Tree height, a key factor in biomass\ncalculations, can be measured using Synthetic Aperture Radar (SAR) technology.\nThis study applies machine learning to extract forest height data from two SAR\nproducts: Single Look Complex (SLC) images and tomographic cubes, in\npreparation for the ESA Biomass Satellite mission. We use the TomoSense\ndataset, containing SAR and LiDAR data from Germany's Eifel National Park, to\ndevelop and evaluate height estimation models. Our approach includes classical\nmethods, deep learning with a 3D U-Net, and Bayesian-optimized techniques. By\ntesting various SAR frequencies and polarimetries, we establish a baseline for\nfuture height and biomass modelling. Best-performing models predict forest\nheight to be within 2.82m mean absolute error for canopies around 30m,\nadvancing our ability to measure global carbon stocks and support climate\naction.",
      "tldr_zh": "本研究利用 Synthetic Aperture Radar (SAR) 技术和机器学习方法，针对森林树高的高分辨率估计，以支持全球碳循环建模和气候变化缓解。研究基于 TomoSense 数据集（包括德国 Eifel 国家公园的 SAR 和 LiDAR 数据），从 Single Look Complex (SLC) 图像和 tomographic cubes 中提取高度信息，采用经典方法、3D U-Net 深度学习以及 Bayesian-optimized 技术，并测试各种 SAR 频率和 polarimetries。结果显示，最佳模型在约 30m 树冠高度的预测中达到 2.82m 的平均绝对误差，为 ESA Biomass Satellite 任务建立基线，并提升全球碳储量测量和气候行动的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05636v1",
      "published_date": "2024-09-09 14:07:38 UTC",
      "updated_date": "2024-09-09 14:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:27:33.501689"
    },
    {
      "arxiv_id": "2409.05620v1",
      "title": "Joint Input and Output Coordination for Class-Incremental Learning",
      "title_zh": "类增量学习的联合输入输出协调",
      "authors": [
        "Shuai Wang",
        "Yibing Zhan",
        "Yong Luo",
        "Han Hu",
        "Wei Yu",
        "Yonggang Wen",
        "Dacheng Tao"
      ],
      "abstract": "Incremental learning is nontrivial due to severe catastrophic forgetting.\nAlthough storing a small amount of data on old tasks during incremental\nlearning is a feasible solution, current strategies still do not 1) adequately\naddress the class bias problem, and 2) alleviate the mutual interference\nbetween new and old tasks, and 3) consider the problem of class bias within\ntasks. This motivates us to propose a joint input and output coordination\n(JIOC) mechanism to address these issues. This mechanism assigns different\nweights to different categories of data according to the gradient of the output\nscore, and uses knowledge distillation (KD) to reduce the mutual interference\nbetween the outputs of old and new tasks. The proposed mechanism is general and\nflexible, and can be incorporated into different incremental learning\napproaches that use memory storage. Extensive experiments show that our\nmechanism can significantly improve their performance.",
      "tldr_zh": "该论文针对增量学习（Incremental Learning）中的灾难性遗忘（Catastrophic Forgetting）问题，提出了一种联合输入和输出协调机制（Joint Input and Output Coordination, JIOC）。JIOC 通过根据输出分数梯度为不同类别数据分配权重，并利用知识蒸馏（Knowledge Distillation, KD）来减少新旧任务之间的相互干扰，同时解决任务内部的类别偏差问题。该机制通用灵活，可整合到各种使用内存存储的增量学习方法中；实验结果显示，它能显著提升这些方法的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figues. Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05620v1",
      "published_date": "2024-09-09 13:55:07 UTC",
      "updated_date": "2024-09-09 13:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:27:44.032950"
    },
    {
      "arxiv_id": "2409.05611v1",
      "title": "Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwu Lei",
        "Silin Chen",
        "Bohan Wang",
        "Zhengkai Jiang",
        "Ningmu Zou"
      ],
      "abstract": "Most unsupervised anomaly detection methods based on representations of\nnormal samples to distinguish anomalies have recently made remarkable progress.\nHowever, existing methods only learn a single decision boundary for\ndistinguishing the samples within the training dataset, neglecting the\nvariation in feature distribution for normal samples even in the same category\nin the real world. Furthermore, it was not considered that a distribution bias\nstill exists between the test set and the train set. Therefore, we propose an\nAdapted-MoE which contains a routing network and a series of expert models to\nhandle multiple distributions of same-category samples by divide and conquer.\nSpecifically, we propose a routing network based on representation learning to\nroute same-category samples into the subclasses feature space. Then, a series\nof expert models are utilized to learn the representation of various normal\nsamples and construct several independent decision boundaries. We propose the\ntest-time adaption to eliminate the bias between the unseen test sample\nrepresentation and the feature distribution learned by the expert model. Our\nexperiments are conducted on a dataset that provides multiple subclasses from\nthree categories, namely Texture AD benchmark. The Adapted-MoE significantly\nimproves the performance of the baseline model, achieving 2.18%-7.20% and\n1.57%-16.30% increase in I-AUROC and P-AUROC, which outperforms the current\nstate-of-the-art methods. Our code is available at https://github.com/.",
      "tldr_zh": "本文提出 Adapted-MoE，一种基于 Mixture of Experts 的无监督异常检测方法，针对同一类别样本特征分布变异和训练测试集分布偏差问题，通过路由网络将样本路由到子类特征空间，并使用一系列专家模型构建独立决策边界。方法还引入测试时适应（Test-Time Adaption）来消除测试样本表示与专家模型学到的特征分布之间的偏差。在 Texture AD benchmark 数据集上实验表明，Adapted-MoE 相比基线模型将 I-AUROC 提高了 2.18%-7.20%，P-AUROC 提高了 1.57%-16.30%，优于当前最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05611v1",
      "published_date": "2024-09-09 13:49:09 UTC",
      "updated_date": "2024-09-09 13:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:27:57.297345"
    },
    {
      "arxiv_id": "2409.05595v2",
      "title": "SynMorph: Generating Synthetic Face Morphing Dataset with Mated Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "abstract": "Face morphing attack detection (MAD) algorithms have become essential to\novercome the vulnerability of face recognition systems. To solve the lack of\nlarge-scale and public-available datasets due to privacy concerns and\nrestrictions, in this work we propose a new method to generate a synthetic face\nmorphing dataset with 2450 identities and more than 100k morphs. The proposed\nsynthetic face morphing dataset is unique for its high-quality samples,\ndifferent types of morphing algorithms, and the generalization for both single\nand differential morphing attack detection algorithms. For experiments, we\napply face image quality assessment and vulnerability analysis to evaluate the\nproposed synthetic face morphing dataset from the perspective of biometric\nsample quality and morphing attack potential on face recognition systems. The\nresults are benchmarked with an existing SOTA synthetic dataset and a\nrepresentative non-synthetic and indicate improvement compared with the SOTA.\nAdditionally, we design different protocols and study the applicability of\nusing the proposed synthetic dataset on training morphing attack detection\nalgorithms.",
      "tldr_zh": "本论文提出 SynMorph 方法，生成一个合成人脸变形数据集，包含 2450 个身份和超过 10 万个变形样本，以解决人脸识别系统中的人脸变形攻击检测 (MAD) 算法因隐私问题而缺乏大规模公开数据集的问题。  \n该数据集独特之处在于高质量样本、多种变形算法类型，并支持单人和差异变形攻击检测算法的泛化应用。  \n通过人脸图像质量评估和脆弱性分析，实验结果表明该数据集在生物特征样本质量和变形攻击潜力上优于现有 SOTA 合成数据集和非合成基准。  \n此外，论文设计了不同协议，探讨了使用该合成数据集训练 MAD 算法的可行性，为相关研究提供新工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This preprint has been further published in IEEE Access. Print ISSN:\n  2169-3536. Online ISSN: 2169-3536. Digital Object Identifier:\n  10.1109/ACCESS.2025.3548957",
      "pdf_url": "http://arxiv.org/pdf/2409.05595v2",
      "published_date": "2024-09-09 13:29:53 UTC",
      "updated_date": "2025-03-22 17:21:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:28:08.746221"
    },
    {
      "arxiv_id": "2409.05592v1",
      "title": "ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language",
      "title_zh": "ExDDI：",
      "authors": [
        "Zhaoyue Sun",
        "Jiazheng Li",
        "Gabriele Pergola",
        "Yulan He"
      ],
      "abstract": "Predicting unknown drug-drug interactions (DDIs) is crucial for improving\nmedication safety. Previous efforts in DDI prediction have typically focused on\nbinary classification or predicting DDI categories, with the absence of\nexplanatory insights that could enhance trust in these predictions. In this\nwork, we propose to generate natural language explanations for DDI predictions,\nenabling the model to reveal the underlying pharmacodynamics and\npharmacokinetics mechanisms simultaneously as making the prediction. To do\nthis, we have collected DDI explanations from DDInter and DrugBank and\ndeveloped various models for extensive experiments and analysis. Our models can\nprovide accurate explanations for unknown DDIs between known drugs. This paper\ncontributes new tools to the field of DDI prediction and lays a solid\nfoundation for further research on generating explanations for DDI predictions.",
      "tldr_zh": "本文提出ExDDI方法，通过生成自然语言解释来提升药物间相互作用（DDIs）预测的透明度和可靠性，同时揭示潜在的药效学（pharmacodynamics）和药代动力学（pharmacokinetics）机制。研究团队从DDInter和DrugBank收集DDI解释数据，并开发多种模型进行实验分析，这些模型能够准确解释已知药物间的未知DDIs。总体而言，此工作为DDI预测领域提供了新工具，并为生成解释的进一步研究奠定了坚实基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.05592v1",
      "published_date": "2024-09-09 13:23:14 UTC",
      "updated_date": "2024-09-09 13:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:28:20.335733"
    },
    {
      "arxiv_id": "2409.05591v3",
      "title": "MemoRAG: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjin Qian",
        "Zheng Liu",
        "Peitian Zhang",
        "Kelong Mao",
        "Defu Lian",
        "Zhicheng Dou",
        "Tiejun Huang"
      ],
      "abstract": "Processing long contexts presents a significant challenge for large language\nmodels (LLMs). While recent advancements allow LLMs to handle much longer\ncontexts than before (e.g., 32K or 128K tokens), it is computationally\nexpensive and can still be insufficient for many applications.\nRetrieval-Augmented Generation (RAG) is considered a promising strategy to\naddress this problem. However, conventional RAG methods face inherent\nlimitations because of two underlying requirements: 1) explicitly stated\nqueries, and 2) well-structured knowledge. These conditions, however, do not\nhold in general long-context processing tasks.\n  In this work, we propose MemoRAG, a novel RAG framework empowered by global\nmemory-augmented retrieval. MemoRAG features a dual-system architecture. First,\nit employs a light but long-range system to create a global memory of the long\ncontext. Once a task is presented, it generates draft answers, providing useful\nclues for the retrieval tools to locate relevant information within the long\ncontext. Second, it leverages an expensive but expressive system, which\ngenerates the final answer based on the retrieved information. Building upon\nthis fundamental framework, we realize the memory module in the form of KV\ncompression, and reinforce its memorization and cluing capacity from the\nGeneration quality's Feedback (a.k.a. RLGF). In our experiments, MemoRAG\nachieves superior performances across a variety of long-context evaluation\ntasks, not only complex scenarios where traditional RAG methods struggle, but\nalso simpler ones where RAG is typically applied.",
      "tldr_zh": "该论文提出MemoRAG，一种通过全局记忆增强检索（global memory-enhanced retrieval）来提升大型语言模型（LLMs）处理长上下文能力的RAG框架，以解决传统RAG对显式查询和结构化知识的依赖问题。MemoRAG采用双系统架构：首先，使用轻量长范围系统创建长上下文的全局记忆，并生成草稿答案以指导检索；其次，利用昂贵但表达力强的系统基于检索信息产生最终答案，同时通过KV compression和从生成质量反馈（RLGF）强化记忆模块的效能。实验结果显示，MemoRAG在各种长上下文任务中表现出色，不仅在复杂场景中超越传统RAG方法，在简单任务中也表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "theWebConf 2025. Codes and models are in\n  https://github.com/qhjqhj00/MemoRAG",
      "pdf_url": "http://arxiv.org/pdf/2409.05591v3",
      "published_date": "2024-09-09 13:20:31 UTC",
      "updated_date": "2025-04-09 09:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:28:32.551281"
    },
    {
      "arxiv_id": "2409.05586v1",
      "title": "Interpretable Responsibility Sharing as a Heuristic for Task and Motion Planning",
      "title_zh": "可解释的责任共享作为任务与运动规划的启发式方法",
      "authors": [
        "Arda Sarp Yenicesu",
        "Sepehr Nourmohammadi",
        "Berk Cicek",
        "Ozgur S. Oguz"
      ],
      "abstract": "This article introduces a novel heuristic for Task and Motion Planning (TAMP)\nnamed Interpretable Responsibility Sharing (IRS), which enhances planning\nefficiency in domestic robots by leveraging human-constructed environments and\ninherent biases. Utilizing auxiliary objects (e.g., trays and pitchers), which\nare commonly found in household settings, IRS systematically incorporates these\nelements to simplify and optimize task execution. The heuristic is rooted in\nthe novel concept of Responsibility Sharing (RS), where auxiliary objects share\nthe task's responsibility with the embodied agent, dividing complex tasks into\nmanageable sub-problems. This division not only reflects human usage patterns\nbut also aids robots in navigating and manipulating within human spaces more\neffectively. By integrating Optimized Rule Synthesis (ORS) for decision-making,\nIRS ensures that the use of auxiliary objects is both strategic and\ncontext-aware, thereby improving the interpretability and effectiveness of\nrobotic planning. Experiments conducted across various household tasks\ndemonstrate that IRS significantly outperforms traditional methods by reducing\nthe effort required in task execution and enhancing the overall decision-making\nprocess. This approach not only aligns with human intuitive methods but also\noffers a scalable solution adaptable to diverse domestic environments. Code is\navailable at https://github.com/asyncs/IRS.",
      "tldr_zh": "该论文提出了一种新启发式方法Interpretable Responsibility Sharing (IRS)，用于提升Task and Motion Planning (TAMP)在家用机器人中的规划效率，通过利用辅助对象（如托盘和水壶）来模拟人类环境中的固有偏差。IRS的核心概念是Responsibility Sharing (RS)，让辅助对象与机器人共享任务责任，将复杂任务分解为可管理的子问题，并整合Optimized Rule Synthesis (ORS)以实现战略性和上下文感知的决策。实验结果显示，IRS在各种家用任务中显著优于传统方法，减少了任务执行所需努力，并提升了机器人的决策可解释性和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05586v1",
      "published_date": "2024-09-09 13:15:53 UTC",
      "updated_date": "2024-09-09 13:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:28:45.192103"
    },
    {
      "arxiv_id": "2409.05585v1",
      "title": "Latent 3D Brain MRI Counterfactual",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Peng",
        "Tian Xia",
        "Fabio De Sousa Ribeiro",
        "Tomas Bosschieter",
        "Ehsan Adeli",
        "Qingyu Zhao",
        "Ben Glocker",
        "Kilian M. Pohl"
      ],
      "abstract": "The number of samples in structural brain MRI studies is often too small to\nproperly train deep learning models. Generative models show promise in\naddressing this issue by effectively learning the data distribution and\ngenerating high-fidelity MRI. However, they struggle to produce diverse,\nhigh-quality data outside the distribution defined by the training data. One\nway to address the issue is using causal models developed for 3D volume\ncounterfactuals. However, accurately modeling causality in high-dimensional\nspaces is a challenge so that these models generally generate 3D brain MRIS of\nlower quality. To address these challenges, we propose a two-stage method that\nconstructs a Structural Causal Model (SCM) within the latent space. In the\nfirst stage, we employ a VQ-VAE to learn a compact embedding of the MRI volume.\nSubsequently, we integrate our causal model into this latent space and execute\na three-step counterfactual procedure using a closed-form Generalized Linear\nModel (GLM). Our experiments conducted on real-world high-resolution MRI data\n(1mm) demonstrate that our method can generate high-quality 3D MRI\ncounterfactuals.",
      "tldr_zh": "本研究针对结构性脑 MRI 研究中样本量不足的问题，提出一种两阶段方法，在潜在空间中构建结构因果模型 (SCM) 以生成高质量 3D MRI 逆事实 (counterfactuals)。首先，使用 VQ-VAE 学习 MRI 体积的紧凑嵌入；随后，在潜在空间中集成因果模型，并通过闭式形式广义线性模型 (GLM) 执行三步逆事实过程。实验在真实高分辨率 (1mm) MRI 数据上验证，该方法能有效产生多样且高质量的 3D 脑 MRI 数据，提高深度学习模型的训练效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05585v1",
      "published_date": "2024-09-09 13:15:03 UTC",
      "updated_date": "2024-09-09 13:15:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:28:57.465001"
    },
    {
      "arxiv_id": "2409.05573v1",
      "title": "Learning to Model Graph Structural Information on MLPs via Graph Structure Self-Contrasting",
      "title_zh": "翻译失败",
      "authors": [
        "Lirong Wu",
        "Haitao Lin",
        "Guojiang Zhao",
        "Cheng Tan",
        "Stan Z. Li"
      ],
      "abstract": "Recent years have witnessed great success in handling graph-related tasks\nwith Graph Neural Networks (GNNs). However, most existing GNNs are based on\nmessage passing to perform feature aggregation and transformation, where the\nstructural information is explicitly involved in the forward propagation by\ncoupling with node features through graph convolution at each layer. As a\nresult, subtle feature noise or structure perturbation may cause severe error\npropagation, resulting in extremely poor robustness. In this paper, we rethink\nthe roles played by graph structural information in graph data training and\nidentify that message passing is not the only path to modeling structural\ninformation. Inspired by this, we propose a simple but effective Graph\nStructure Self-Contrasting (GSSC) framework that learns graph structural\ninformation without message passing. The proposed framework is based purely on\nMulti-Layer Perceptrons (MLPs), where the structural information is only\nimplicitly incorporated as prior knowledge to guide the computation of\nsupervision signals, substituting the explicit message propagation as in GNNs.\nSpecifically, it first applies structural sparsification to remove potentially\nuninformative or noisy edges in the neighborhood, and then performs structural\nself-contrasting in the sparsified neighborhood to learn robust node\nrepresentations. Finally, structural sparsification and self-contrasting are\nformulated as a bi-level optimization problem and solved in a unified\nframework. Extensive experiments have qualitatively and quantitatively\ndemonstrated that the GSSC framework can produce truly encouraging performance\nwith better generalization and robustness than other leading competitors.",
      "tldr_zh": "本文提出了一种名为 Graph Structure Self-Contrasting (GSSC) 的框架，用于在 Multi-Layer Perceptrons (MLPs) 上学习图结构信息，而非依赖传统的消息传递 (message passing) 机制，以解决 Graph Neural Networks (GNNs) 在噪声或结构扰动下鲁棒性差的问题。GSSC 通过 structural sparsification 移除潜在的无信息或噪声边，然后在稀疏邻域上进行 structural self-contrasting 来生成鲁棒的节点表示，并将这些过程整合为一个 bi-level optimization 问题。实验结果显示，该框架在图数据任务中表现出色，具有更好的泛化和鲁棒性，优于领先的竞争方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05573v1",
      "published_date": "2024-09-09 12:56:02 UTC",
      "updated_date": "2024-09-09 12:56:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:29:19.609774"
    },
    {
      "arxiv_id": "2409.05565v1",
      "title": "On the Convergence of Sigmoid and tanh Fuzzy General Grey Cognitive Maps",
      "title_zh": "关于 Sigmoid 和 tanh 模糊一般灰色认知地图的收敛性",
      "authors": [
        "Xudong Gao",
        "Xiao Guang Gao",
        "Jia Rong",
        "Ni Li",
        "Yifeng Niu",
        "Jun Chen"
      ],
      "abstract": "Fuzzy General Grey Cognitive Map (FGGCM) and Fuzzy Grey Cognitive Map (FGCM)\nare extensions of Fuzzy Cognitive Map (FCM) in terms of uncertainty. FGGCM\nallows for the processing of general grey number with multiple intervals,\nenabling FCM to better address uncertain situations. Although the convergence\nof FCM and FGCM has been discussed in many literature, the convergence of FGGCM\nhas not been thoroughly explored. This paper aims to fill this research gap.\nFirst, metrics for the general grey number space and its vector space is given\nand proved using the Minkowski inequality. By utilizing the characteristic that\nCauchy sequences are convergent sequences, the completeness of these two space\nis demonstrated. On this premise, utilizing Banach fixed point theorem and\nBrowder-Gohde-Kirk fixed point theorem, combined with Lagrange's mean value\ntheorem and Cauchy's inequality, deduces the sufficient conditions for FGGCM to\nconverge to a unique fixed point when using tanh and sigmoid functions as\nactivation functions. The sufficient conditions for the kernels and greyness of\nFGGCM to converge to a unique fixed point are also provided separately.\nFinally, based on Web Experience and Civil engineering FCM, designed\ncorresponding FGGCM with sigmoid and tanh as activation functions by modifying\nthe weights to general grey numbers. By comparing with the convergence theorems\nof FCM and FGCM, the effectiveness of the theorems proposed in this paper was\nverified. It was also demonstrated that the convergence theorems of FCM are\nspecial cases of the theorems proposed in this paper. The study for convergence\nof FGGCM is of great significance for guiding the learning algorithm of FGGCM,\nwhich is needed for designing FGGCM with specific fixed points, lays a solid\ntheoretical foundation for the application of FGGCM in fields such as control,\nprediction, and decision support systems.",
      "tldr_zh": "本论文探讨了 Fuzzy General Grey Cognitive Maps (FGGCM) 的收敛性，扩展了 Fuzzy Cognitive Map (FCM) 以更好地处理不确定性，特别是使用 sigmoid 和 tanh 作为激活函数。研究首先定义了通用灰色数字空间的度量并证明其完整性，然后通过 Banach 定点定理、Browder-Gohde-Kirk 定点定理以及 Lagrange 中值定理和 Cauchy 不等式，推导出 FGGCM 收敛到唯一固定点的充分条件，并分别提供了核和灰度收敛的条件。实验基于 Web Experience 和 Civil Engineering FCM 设计了相应 FGGCM，并验证了这些定理的有效性，证明了 FCM 收敛定理是其特例，从而为 FGGCM 的学习算法和在控制、预测及决策支持系统中的应用奠定坚实基础。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05565v1",
      "published_date": "2024-09-09 12:46:03 UTC",
      "updated_date": "2024-09-09 12:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:29:22.929924"
    },
    {
      "arxiv_id": "2409.05564v1",
      "title": "LEROjD: Lidar Extended Radar-Only Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Palmer",
        "Martin Krüger",
        "Stefan Schütte",
        "Richard Altendorfer",
        "Ganesh Adam",
        "Torsten Bertram"
      ],
      "abstract": "Accurate 3D object detection is vital for automated driving. While lidar\nsensors are well suited for this task, they are expensive and have limitations\nin adverse weather conditions. 3+1D imaging radar sensors offer a\ncost-effective, robust alternative but face challenges due to their low\nresolution and high measurement noise. Existing 3+1D imaging radar datasets\ninclude radar and lidar data, enabling cross-modal model improvements. Although\nlidar should not be used during inference, it can aid the training of\nradar-only object detectors. We explore two strategies to transfer knowledge\nfrom the lidar to the radar domain and radar-only object detectors: 1.\nmulti-stage training with sequential lidar point cloud thin-out, and 2.\ncross-modal knowledge distillation. In the multi-stage process, three thin-out\nmethods are examined. Our results show significant performance gains of up to\n4.2 percentage points in mean Average Precision with multi-stage training and\nup to 3.9 percentage points with knowledge distillation by initializing the\nstudent with the teacher's weights. The main benefit of these approaches is\ntheir applicability to other 3D object detection networks without altering\ntheir architecture, as we show by analyzing it on two different object\ndetectors. Our code is available at https://github.com/rst-tu-dortmund/lerojd",
      "tldr_zh": "这篇论文提出LEROjD框架，旨在通过从Lidar到雷达的知识转移，提升3+1D成像雷达的物体检测性能，以应对其低分辨率和高噪声挑战。研究探索了两种策略：多阶段训练（包括顺序Lidar点云稀释方法）和跨模态知识蒸馏，从而在不改变检测网络架构的情况下训练雷达-only模型。实验结果显示，多阶段训练提高了mean Average Precision高达4.2百分点，知识蒸馏则提高了高达3.9百分点，并证明了这些方法的通用性。代码已在GitHub开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication as ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05564v1",
      "published_date": "2024-09-09 12:43:25 UTC",
      "updated_date": "2024-09-09 12:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:29:33.627701"
    },
    {
      "arxiv_id": "2409.05559v1",
      "title": "CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei He",
        "Feng Lu"
      ],
      "abstract": "Large language models (LLMs) have been utilized in solving diverse reasoning\ntasks, encompassing common sense, arithmetic and deduction tasks. However, with\ndifficulties of reversing thinking patterns and irrelevant premises, how to\ndetermine the authenticity of the cause in abductive logical reasoning remains\nunderexplored. Inspired by hypothesis and verification method and\nidentification of irrelevant information in human thinking process, we propose\na new framework for LLMs abductive logical reasoning called CauseJudger (CJ),\nwhich identifies the authenticity of possible cause by transforming thinking\nfrom reverse to forward and removing irrelevant information. In addition, we\nconstruct an abductive logical reasoning dataset for decision task called\nCauseLogics, which contains 200,000 tasks of varying reasoning lengths. Our\nexperiments show the efficiency of CJ with overall experiments and ablation\nexperiments as well as case studies on our dataset and reconstructed public\ndataset. Notably, CJ's implementation is efficient, requiring only two calls to\nLLM. Its impact is profound: when using gpt-3.5, CJ achieves a maximum\ncorrectness improvement of 41% compared to Zero-Shot-CoT. Moreover, with gpt-4,\nCJ attains an accuracy exceeding 90% across all datasets.",
      "tldr_zh": "本文提出 CauseJudger (CJ) 框架，利用大型语言模型 (LLMs) 通过将逆向思维转为正向思维并去除无关信息，来识别溯因逻辑推理中原因的真实性，受到了人类假设与验证方法的启发。研究者构建了名为 CauseLogics 的数据集，包含20万条不同推理长度的任务，用于评估 CJ 的性能。实验结果显示，CJ 仅需两次 LLM 调用即可高效运行，使用 gpt-3.5 时比 Zero-Shot-CoT 正确率提高最多41%，而使用 gpt-4 时在所有数据集上准确率超过90%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05559v1",
      "published_date": "2024-09-09 12:30:43 UTC",
      "updated_date": "2024-09-09 12:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:29:45.475190"
    },
    {
      "arxiv_id": "2409.05558v1",
      "title": "Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs",
      "title_zh": "翻译失败",
      "authors": [
        "Yahya Jabary",
        "Andreas Plesner",
        "Turlan Kuzhagaliyev",
        "Roger Wattenhofer"
      ],
      "abstract": "Modern CAPTCHAs rely heavily on vision tasks that are supposedly hard for\ncomputers but easy for humans. However, advances in image recognition models\npose a significant threat to such CAPTCHAs. These models can easily be fooled\nby generating some well-hidden \"random\" noise and adding it to the image, or\nhiding objects in the image. However, these methods are model-specific and thus\ncan not aid CAPTCHAs in fooling all models. We show in this work that by\nallowing for more significant changes to the images while preserving the\nsemantic information and keeping it solvable by humans, we can fool many\nstate-of-the-art models. Specifically, we demonstrate that by adding masks of\nvarious intensities the Accuracy @ 1 (Acc@1) drops by more than 50%-points for\nall models, and supposedly robust models such as vision transformers see an\nAcc@1 drop of 80%-points.\n  These masks can therefore effectively fool modern image classifiers, thus\nshowing that machines have not caught up with humans -- yet.",
      "tldr_zh": "本研究重新审视了 adversarial examples 在 CAPTCHAs 中的应用，指出现代 CAPTCHAs 依赖于计算机难以识别的视觉任务，但先进图像识别模型易受特定噪声干扰。论文提出一种新方法，通过在图像上添加各种强度的 masks，同时保留语义信息并确保人类可解，来有效欺骗模型。实验结果显示，这种方法使多种状态模型的 Acc@1 准确率下降超过 50%，而对 vision transformers 等鲁棒模型的准确率甚至下降 80%，从而证明机器在视觉任务上仍落后于人类。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.05558v1",
      "published_date": "2024-09-09 12:29:53 UTC",
      "updated_date": "2024-09-09 12:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:29:56.881755"
    },
    {
      "arxiv_id": "2409.05556v1",
      "title": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning",
      "title_zh": "SciAgents：通过多智能体智能图推理自动化科学发现",
      "authors": [
        "Alireza Ghafarollahi",
        "Markus J. Buehler"
      ],
      "abstract": "A key challenge in artificial intelligence is the creation of systems capable\nof autonomously advancing scientific understanding by exploring novel domains,\nidentifying complex patterns, and uncovering previously unseen connections in\nvast scientific data. In this work, we present SciAgents, an approach that\nleverages three core concepts: (1) the use of large-scale ontological knowledge\ngraphs to organize and interconnect diverse scientific concepts, (2) a suite of\nlarge language models (LLMs) and data retrieval tools, and (3) multi-agent\nsystems with in-situ learning capabilities. Applied to biologically inspired\nmaterials, SciAgents reveals hidden interdisciplinary relationships that were\npreviously considered unrelated, achieving a scale, precision, and exploratory\npower that surpasses traditional human-driven research methods. The framework\nautonomously generates and refines research hypotheses, elucidating underlying\nmechanisms, design principles, and unexpected material properties. By\nintegrating these capabilities in a modular fashion, the intelligent system\nyields material discoveries, critique and improve existing hypotheses, retrieve\nup-to-date data about existing research, and highlights their strengths and\nlimitations. Our case studies demonstrate scalable capabilities to combine\ngenerative AI, ontological representations, and multi-agent modeling,\nharnessing a `swarm of intelligence' similar to biological systems. This\nprovides new avenues for materials discovery and accelerates the development of\nadvanced materials by unlocking Nature's design principles.",
      "tldr_zh": "本文提出 SciAgents，一种通过多智能体智能图推理自动推进科学发现的框架，旨在探索新领域、识别复杂模式并揭示隐藏连接。框架核心包括利用大规模 ontological knowledge graphs 组织科学概念、结合 LLMs 和数据检索工具，以及多智能体 systems 具备现场学习能力。在应用于生物启发材料时，SciAgents 揭示了之前未被注意的跨学科关系，自主生成并完善研究假设，实现了比传统方法更高的规模、精度和探索力。该系统通过模块化整合，加速材料发现、批判现有假设并突出其优缺点，为解锁自然设计原则提供了新途径。",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "cond-mat.mtrl-sci",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05556v1",
      "published_date": "2024-09-09 12:25:10 UTC",
      "updated_date": "2024-09-09 12:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:30:09.660821"
    },
    {
      "arxiv_id": "2409.05531v3",
      "title": "HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment",
      "title_zh": "HMAFlow：通过分层运动场对齐学习更准确的光流",
      "authors": [
        "Dianbo Ma",
        "Kousuke Imamura",
        "Ziyan Gao",
        "Xiangjie Wang",
        "Satoshi Yamane"
      ],
      "abstract": "Optical flow estimation is a fundamental and long-standing visual task. In\nthis work, we present a novel method, dubbed HMAFlow, to improve optical flow\nestimation in challenging scenes, particularly those involving small objects.\nThe proposed model mainly consists of two core components: a Hierarchical\nMotion Field Alignment (HMA) module and a Correlation Self-Attention (CSA)\nmodule. In addition, we rebuild 4D cost volumes by employing a Multi-Scale\nCorrelation Search (MCS) layer and replacing average pooling in common cost\nvolumes with a search strategy utilizing multiple search ranges. Experimental\nresults demonstrate that our model achieves the best generalization performance\ncompared to other state-of-the-art methods. Specifically, compared with RAFT,\nour method achieves relative error reductions of 14.2% and 3.4% on the clean\npass and final pass of the Sintel online benchmark, respectively. On the KITTI\ntest benchmark, HMAFlow surpasses RAFT and GMA in the Fl-all metric by relative\nmargins of 6.8% and 7.7%, respectively. To facilitate future research, our code\nwill be made available at https://github.com/BooTurbo/HMAFlow.",
      "tldr_zh": "这篇论文提出了HMAFlow，一种通过Hierarchical Motion Field Alignment改进光学流估计的方法，特别针对挑战性场景如小物体运动。核心组件包括Hierarchical Motion Field Alignment (HMA)模块、Correlation Self-Attention (CSA)模块，以及使用Multi-Scale Correlation Search (MCS)层重建4D成本体积，以增强搜索策略并替换传统平均池化。实验结果显示，HMAFlow在Sintel基准上比RAFT方法减少14.2%和3.4%的相对错误，在KITTI基准的Fl-all指标上分别超过RAFT和GMA 6.8%和7.7%。该方法展示了最佳的泛化性能，并已开源代码以促进后续研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.05531v3",
      "published_date": "2024-09-09 11:43:35 UTC",
      "updated_date": "2024-11-15 05:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:30:21.414918"
    },
    {
      "arxiv_id": "2409.05524v1",
      "title": "An encoding of argumentation problems using quadratic unconstrained binary optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Baioletti",
        "Francesco Santini"
      ],
      "abstract": "In this paper, we develop a way to encode several NP-Complete problems in\nAbstract Argumentation to Quadratic Unconstrained Binary Optimization (QUBO)\nproblems. In this form, a solution for a QUBO problem involves minimizing a\nquadratic function over binary variables (0/1), where the coefficients can be\nrepresented by a symmetric square matrix (or an equivalent upper triangular\nversion). With the QUBO formulation, exploiting new computing architectures,\nsuch as Quantum and Digital Annealers, is possible. A more conventional\napproach consists of developing approximate solvers, which, in this case, are\nused to tackle the intrinsic complexity. We performed tests to prove the\ncorrectness and applicability of classical problems in Argumentation and\nenforcement of argument sets. We compared our approach to two other approximate\nsolvers in the literature during tests. In the final experimentation, we used a\nSimulated Annealing algorithm on a local machine. Also, we tested a Quantum\nAnnealer from the D-Wave Ocean SDK and the Leap Quantum Cloud Service.",
      "tldr_zh": "本论文提出了一种将抽象论证(Abstract Argumentation)中的几个NP-Complete问题编码为Quadratic Unconstrained Binary Optimization (QUBO)问题的方法，该编码使用二进制变量（0/1）最小化一个二次函数。作者通过QUBO形式，实现了对量子退火器(Quantum Annealers)和数字退火器等新计算架构的利用，并开发了近似求解器来应对问题复杂度。实验验证了该方法的正确性和适用性，包括与现有求解器比较，以及使用Simulated Annealing算法和D-Wave的Quantum Annealer进行测试，结果显示了其在论证问题求解中的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05524v1",
      "published_date": "2024-09-09 11:29:46 UTC",
      "updated_date": "2024-09-09 11:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:30:33.579813"
    },
    {
      "arxiv_id": "2409.05521v1",
      "title": "Harmonic Reasoning in Large Language Models",
      "title_zh": "大型语言模型中的和声推理",
      "authors": [
        "Anna Kruspe"
      ],
      "abstract": "Large Language Models (LLMs) are becoming very popular and are used for many\ndifferent purposes, including creative tasks in the arts. However, these models\nsometimes have trouble with specific reasoning tasks, especially those that\ninvolve logical thinking and counting. This paper looks at how well LLMs\nunderstand and reason when dealing with musical tasks like figuring out notes\nfrom intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o\nto see how they handle these tasks. Our results show that while LLMs do well\nwith note intervals, they struggle with more complicated tasks like recognizing\nchords and scales. This points out clear limits in current LLM abilities and\nshows where we need to make them better, which could help improve how they\nthink and work in both artistic and other complex areas. We also provide an\nautomatically generated benchmark data set for the described tasks.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在音乐推理任务中的表现，特别是处理音程、和弦和音阶等 harmonic reasoning 问题。研究者测试了 GPT-3.5 和 GPT-4o，发现这些模型在简单音程任务上表现出色，但对更复杂的和弦和音阶识别存在显著困难。论文突出了 LLMs 的局限性，并提供了一个自动生成的基准数据集，以指导未来模型改进，提升其在艺术和复杂领域的逻辑推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05521v1",
      "published_date": "2024-09-09 11:28:02 UTC",
      "updated_date": "2024-09-09 11:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:30:44.958735"
    },
    {
      "arxiv_id": "2409.13724v1",
      "title": "Logically Consistent Language Models via Neuro-Symbolic Integration",
      "title_zh": "通过神经符号集成的逻辑一致语言模型",
      "authors": [
        "Diego Calanzone",
        "Stefano Teso",
        "Antonio Vergari"
      ],
      "abstract": "Large language models (LLMs) are a promising venue for natural language\nunderstanding and generation. However, current LLMs are far from reliable: they\nare prone to generating non-factual information and, more crucially, to\ncontradicting themselves when prompted to reason about relations between\nentities of the world. These problems are currently addressed with large scale\nfine-tuning or by delegating reasoning to external tools. In this work, we\nstrive for a middle ground and introduce a loss based on neuro-symbolic\nreasoning that teaches an LLM to be logically consistent with an external set\nof facts and rules and improves self-consistency even when the LLM is\nfine-tuned on a limited set of facts. Our approach also allows to easily\ncombine multiple logical constraints at once in a principled way, delivering\nLLMs that are more consistent w.r.t. all constraints and improve over several\nbaselines w.r.t. a given constraint. Moreover, our method allows LLMs to\nextrapolate to unseen but semantically similar factual knowledge, represented\nin unseen datasets, more systematically.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 易于生成非事实信息和自相矛盾的问题，提出了一种基于神经符号集成 (Neuro-Symbolic Integration) 的损失函数方法。该方法通过整合外部事实和规则，训练 LLM 实现逻辑一致性和自一致性，即使在有限事实集上微调也能有效提升性能。同时，该方法支持轻松组合多个逻辑约束，提高模型对所有约束的遵守，并在基线模型上表现出色。实验结果表明，训练后的 LLM 能够更系统地外推到未见数据集中的语义相似知识。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13724v1",
      "published_date": "2024-09-09 10:52:57 UTC",
      "updated_date": "2024-09-09 10:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:30:57.208682"
    },
    {
      "arxiv_id": "2409.09074v1",
      "title": "Fair Reinforcement Learning Algorithm for PV Active Control in LV Distribution Networks",
      "title_zh": "针对低压配电网络中",
      "authors": [
        "Maurizio Vassallo",
        "Amina Benzerga",
        "Alireza Bahmanyar",
        "Damien Ernst"
      ],
      "abstract": "The increasing adoption of distributed energy resources, particularly\nphotovoltaic (PV) panels, has presented new and complex challenges for power\nnetwork control. With the significant energy production from PV panels, voltage\nissues in the network have become a problem. Currently, PV smart inverters\n(SIs) are used to mitigate the voltage problems by controlling their active\npower generation and reactive power injection or absorption. However, reducing\nthe active power output of PV panels can be perceived as unfair to some\ncustomers, discouraging future installations. To solve this issue, in this\npaper, a reinforcement learning technique is proposed to address voltage issues\nin a distribution network, while considering fairness in active power\ncurtailment among customers. The feasibility of the proposed approach is\nexplored through experiments, demonstrating its ability to effectively control\nvoltage in a fair and efficient manner.",
      "tldr_zh": "本文提出了一种公平的强化学习（reinforcement learning）算法，用于在低压（LV）分布网络中控制光伏（PV）面板的有功功率输出。该算法旨在解决PV面板导致的电压问题，同时确保有功功率削减（active power curtailment）在客户之间公平分配，避免对某些用户的不公。实验结果证明，该方法能够有效管理网络电压，并以高效且公平的方式缓解相关挑战。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09074v1",
      "published_date": "2024-09-09 10:51:08 UTC",
      "updated_date": "2024-09-09 10:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:31:08.390289"
    },
    {
      "arxiv_id": "2409.05495v1",
      "title": "Using machine learning for fault detection in lighthouse light sensors",
      "title_zh": "使用机器学习进行灯塔灯光传感器的故障检测",
      "authors": [
        "Michael Kampouridis",
        "Nikolaos Vastardis",
        "George Rayment"
      ],
      "abstract": "Lighthouses play a crucial role in ensuring maritime safety by signaling\nhazardous areas such as dangerous coastlines, shoals, reefs, and rocks, along\nwith aiding harbor entries and aerial navigation. This is achieved through the\nuse of photoresistor sensors that activate or deactivate based on the time of\nday. However, a significant issue is the potential malfunction of these\nsensors, leading to the gradual misalignment of the light's operational timing.\nThis paper introduces an innovative machine learning-based approach for\nautomatically detecting such malfunctions. We evaluate four distinct\nalgorithms: decision trees, random forest, extreme gradient boosting, and\nmulti-layer perceptron. Our findings indicate that the multi-layer perceptron\nis the most effective, capable of detecting timing discrepancies as small as\n10-15 minutes. This accuracy makes it a highly efficient tool for automating\nthe detection of faults in lighthouse light sensors.",
      "tldr_zh": "本研究针对灯塔光传感器（photoresistor sensors）的故障问题提出了一种基于机器学习的自动检测方法，因为这些传感器可能导致灯光操作时间错位，影响海洋安全。研究评估了四种算法，包括 decision trees、random forest、extreme gradient boosting 和 multi-layer perceptron，结果表明 multi-layer perceptron 表现最佳，能精确检测出 10-15 分钟的时差。总体而言，这一方法为灯塔维护提供了高效的自动化工具，提升了故障检测的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05495v1",
      "published_date": "2024-09-09 10:47:41 UTC",
      "updated_date": "2024-09-09 10:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:31:21.062670"
    },
    {
      "arxiv_id": "2409.05929v4",
      "title": "M3-Jepa: Multimodal Alignment via Multi-directional MoE based on the JEPA framework",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyang Lei",
        "Xiaolong Cheng",
        "Dan Wang",
        "Kun Fan",
        "Qi Qin",
        "Huazhen Huang",
        "Yetao Wu",
        "Qingqing Gu",
        "Zhonglin Jiang",
        "Yong Chen",
        "Luo Ji"
      ],
      "abstract": "Current multimodal alignment strategies primarily use single or unified\nmodality encoders, while optimizing the alignment on the original token space.\nSuch a framework is easy to implement and incorporate with the pretrained\nknowledge, but might result in information bias. To deal with such issues, the\njoint encoding predictive architecture (JEPA) learns the alignment loss on the\nlatent space, with a predictor to convert the input encoding to the output\nlatent space. However, the application of JEPA in multimodal scenarios is\nlimited so far. In this paper, we introduce M3-Jepa, a scalable multimodal\nalignment framework, with the predictor implemented by a multi-directional\nmixture of experts (MoE). We demonstrate the framework can maximize the mutual\ninformation with information theory derivations, by alternating the\noptimization between different uni-directional tasks. By thoroughly designed\nexperiments, we show that M3-Jepa can obtain state-of-the-art performance on\ndifferent modalities and tasks, generalize to unseen datasets and domains, and\nis computationally efficient in training and inference. Our study indicates\nthat M3-Jepa might provide a new paradigm to self-supervised learning and\nopen-world modeling.",
      "tldr_zh": "该研究针对当前多模态对齐策略的信息偏差问题，提出了 M3-Jepa 框架，该框架基于 JEPA 架构，使用 multi-directional mixture of experts (MoE) 作为预测器，在潜在空间上学习对齐损失，并通过交替优化不同单向任务来最大化互信息。M3-Jepa 通过信息理论推导确保了模态间的有效对齐，并在各种模态和任务上实现了 state-of-the-art 性能，同时表现出色泛化能力和计算效率。总体而言，该框架可能为 self-supervised learning 和 open-world modeling 提供一个新的范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 4 figures. Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.05929v4",
      "published_date": "2024-09-09 10:40:50 UTC",
      "updated_date": "2025-05-05 16:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:31:34.766967"
    },
    {
      "arxiv_id": "2409.05486v2",
      "title": "Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Camilo Thorne",
        "Christian Druckenbrodt",
        "Kinga Szarkowska",
        "Deepika Goyal",
        "Pranita Marajan",
        "Vijay Somanath",
        "Corey Harper",
        "Mao Yan",
        "Tony Scerri"
      ],
      "abstract": "arXiv admin comment: This version has been removed by arXiv administrators as\nthe submitter did not have the rights to agree to the license at the time of\nsubmission",
      "tldr_zh": "抱歉，该论文摘要已被 arXiv 管理员移除，因为提交者未获得许可授权。因此，我无法访问原始内容，无法提取论文的核心贡献、方法或发现。建议您查看论文的最新版本或联系作者获取相关信息。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This document was submitted without obtaining all necessary\n  permissions and therefore needs to be withdrawn. The corresponding author\n  apologizes for any inconvenience this might cause",
      "pdf_url": "http://arxiv.org/pdf/2409.05486v2",
      "published_date": "2024-09-09 10:30:00 UTC",
      "updated_date": "2024-09-17 11:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:31:43.815247"
    },
    {
      "arxiv_id": "2409.05484v2",
      "title": "CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Seungheun Baek",
        "Soyon Park",
        "Yan Ting Chok",
        "Junhyun Lee",
        "Jueon Park",
        "Mogan Gim",
        "Jaewoo Kang"
      ],
      "abstract": "Predicting cellular responses to various perturbations is a critical focus in\ndrug discovery and personalized therapeutics, with deep learning models playing\na significant role in this endeavor. Single-cell datasets contain technical\nartifacts that may hinder the predictability of such models, which poses\nquality control issues highly regarded in this area. To address this, we\npropose CRADLE-VAE, a causal generative framework tailored for single-cell gene\nperturbation modeling, enhanced with counterfactual reasoning-based artifact\ndisentanglement. Throughout training, CRADLE-VAE models the underlying latent\ndistribution of technical artifacts and perturbation effects present in\nsingle-cell datasets. It employs counterfactual reasoning to effectively\ndisentangle such artifacts by modulating the latent basal spaces and learns\nrobust features for generating cellular response data with improved quality.\nExperimental results demonstrate that this approach improves not only treatment\neffect estimation performance but also generative quality as well. The\nCRADLE-VAE codebase is publicly available at\nhttps://github.com/dmis-lab/CRADLE-VAE.",
      "tldr_zh": "本文提出 CRADLE-VAE，一种基于因果生成框架的模型，用于提升单细胞基因扰动建模，通过 counterfactual reasoning-based artifact disentanglement 处理数据集中的技术 artifacts。CRADLE-VAE 在训练过程中模拟潜在分布，采用反事实推理分离 artifacts 和扰动效果，并通过调节潜在基底空间学习鲁棒特征，以生成更高质量的细胞响应数据。实验结果表明，该方法显著改善了治疗效果估计性能和生成质量，并提供了开源代码（https://github.com/dmis-lab/CRADLE-VAE）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05484v2",
      "published_date": "2024-09-09 10:29:28 UTC",
      "updated_date": "2024-09-10 02:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:31:57.454708"
    },
    {
      "arxiv_id": "2409.05466v2",
      "title": "Proto-OOD: Enhancing OOD Object Detection with Prototype Feature Similarity",
      "title_zh": "Proto-OOD：利用原型特征相似度增强 OOD 对象检测",
      "authors": [
        "Junkun Chen",
        "Jilin Mei",
        "Liang Chen",
        "Fangzhou Zhao",
        "Yan Xing",
        "Yu Hu"
      ],
      "abstract": "Neural networks that are trained on limited category samples often mispredict\nout-of-distribution (OOD) objects. We observe that features of the same\ncategory are more tightly clustered in feature space, while those of different\ncategories are more dispersed. Based on this, we propose using prototype\nsimilarity for OOD detection. Drawing on widely used prototype features in\nfew-shot learning, we introduce a novel OOD detection network structure\n(Proto-OOD). Proto-OOD enhances the representativeness of category prototypes\nusing contrastive loss and detects OOD data by evaluating the similarity\nbetween input features and category prototypes. During training, Proto-OOD\ngenerates OOD samples for training the similarity module with a negative\nembedding generator. When Pascal VOC are used as the in-distribution dataset\nand MS-COCO as the OOD dataset, Proto-OOD significantly reduces the FPR (false\npositive rate). Moreover, considering the limitations of existing evaluation\nmetrics, we propose a more reasonable evaluation protocol. The code will be\nreleased.",
      "tldr_zh": "这篇论文针对神经网络在有限类别训练下对 Out-of-Distribution (OOD) 对象的误预测问题，提出了一种基于原型特征相似度的增强方法。作者引入了 Proto-OOD 网络结构，利用 Contrastive Loss 提升类别原型的代表性，并通过输入特征与原型相似度评估来检测 OOD 数据，同时使用负嵌入生成器生成训练样本。实验结果显示，在 Pascal VOC 作为 in-distribution 数据集和 MS-COCO 作为 OOD 数据集时，Proto-OOD 显著降低了 FPR，并提出了一种更合理的评估协议，代码将发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05466v2",
      "published_date": "2024-09-09 09:48:27 UTC",
      "updated_date": "2025-01-28 05:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:32:09.519216"
    },
    {
      "arxiv_id": "2409.05457v1",
      "title": "Visualizing Extensions of Argumentation Frameworks as Layered Graphs",
      "title_zh": "将论证框架的扩展可视化为分层图",
      "authors": [
        "Martin Nöllenburg",
        "Christian Pirker",
        "Anna Rapberger",
        "Stefan Woltran",
        "Jules Wulms"
      ],
      "abstract": "The visualization of argumentation frameworks (AFs) is crucial for enabling a\nwide applicability of argumentative tools. However, their visualization is\noften considered only as an accompanying part of tools for computing semantics\nand standard graphical representations are used. We introduce a new\nvisualization technique that draws an AF, together with an extension (as part\nof the input), as a 3-layer graph layout. Our technique supports the user to\nmore easily explore the visualized AF, better understand extensions, and verify\nalgorithms for computing semantics. To optimize the visual clarity and\naesthetics of this layout, we propose to minimize edge crossings in our 3-layer\ndrawing. We do so by an exact ILP-based approach, but also propose a fast\nheuristic pipeline. Via a quantitative evaluation, we show that the heuristic\nis feasible even for large instances, while producing at most twice as many\ncrossings as an optimal drawing in most cases.",
      "tldr_zh": "该论文探讨了论证框架 (AFs) 的可视化问题，以提升论证工具的实用性。研究者提出一种新颖的可视化技术，将 AF 和其扩展表示为 3-layer graph layout，帮助用户更轻松地探索 AF、理解扩展，并验证计算语义的算法。为优化布局的视觉清晰度，他们采用精确的 ILP-based 方法和一个快速启发式管道来最小化边交叉。实验评估显示，该启发式方法在大规模实例上可行，且产生的交叉数通常不超过最优布局的两倍。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05457v1",
      "published_date": "2024-09-09 09:29:53 UTC",
      "updated_date": "2024-09-09 09:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:32:20.402867"
    },
    {
      "arxiv_id": "2409.05435v1",
      "title": "Semifactual Explanations for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jasmina Gajcin",
        "Jovan Jeromela",
        "Ivana Dusparic"
      ],
      "abstract": "Reinforcement Learning (RL) is a learning paradigm in which the agent learns\nfrom its environment through trial and error. Deep reinforcement learning (DRL)\nalgorithms represent the agent's policies using neural networks, making their\ndecisions difficult to interpret. Explaining the behaviour of DRL agents is\nnecessary to advance user trust, increase engagement, and facilitate\nintegration with real-life tasks. Semifactual explanations aim to explain an\noutcome by providing \"even if\" scenarios, such as \"even if the car were moving\ntwice as slowly, it would still have to swerve to avoid crashing\". Semifactuals\nhelp users understand the effects of different factors on the outcome and\nsupport the optimisation of resources. While extensively studied in psychology\nand even utilised in supervised learning, semifactuals have not been used to\nexplain the decisions of RL systems. In this work, we develop a first approach\nto generating semifactual explanations for RL agents. We start by defining five\nproperties of desirable semifactual explanations in RL and then introducing\nSGRL-Rewind and SGRL-Advance, the first algorithms for generating semifactual\nexplanations in RL. We evaluate the algorithms in two standard RL environments\nand find that they generate semifactuals that are easier to reach, represent\nthe agent's policy better, and are more diverse compared to baselines. Lastly,\nwe conduct and analyse a user study to assess the participant's perception of\nsemifactual explanations of the agent's actions.",
      "tldr_zh": "本文提出了一种针对强化学习 (RL) 的 Semifactual explanations 方法，以解释深度强化学习 (DRL) 代理的决策行为，从而提升用户信任和实际应用。作者首先定义了五个理想的 Semifactual explanations 属性，包括易达性、政策代表性和多样性，并开发了 SGRL-Rewind 和 SGRL-Advance 算法，用于生成“even if”场景的解释。实验在两个标准 RL 环境中显示，这些算法生成的解释比基线更易实现、更准确且多样化。最后，用户研究表明，这种解释方式显著改善了参与者对代理行为的感知。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.05435v1",
      "published_date": "2024-09-09 08:37:47 UTC",
      "updated_date": "2024-09-09 08:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:32:43.754277"
    },
    {
      "arxiv_id": "2409.05433v1",
      "title": "State-Novelty Guided Action Persistence in Deep Reinforcement Learning",
      "title_zh": "基于状态新奇度指导",
      "authors": [
        "Jianshu Hu",
        "Paul Weng",
        "Yutong Ban"
      ],
      "abstract": "While a powerful and promising approach, deep reinforcement learning (DRL)\nstill suffers from sample inefficiency, which can be notably improved by\nresorting to more sophisticated techniques to address the\nexploration-exploitation dilemma. One such technique relies on action\npersistence (i.e., repeating an action over multiple steps). However, previous\nwork exploiting action persistence either applies a fixed strategy or learns\nadditional value functions (or policy) for selecting the repetition number. In\nthis paper, we propose a novel method to dynamically adjust the action\npersistence based on the current exploration status of the state space. In such\na way, our method does not require training of additional value functions or\npolicy. Moreover, the use of a smooth scheduling of the repeat probability\nallows a more effective balance between exploration and exploitation.\nFurthermore, our method can be seamlessly integrated into various basic\nexploration strategies to incorporate temporal persistence. Finally, extensive\nexperiments on different DMControl tasks demonstrate that our state-novelty\nguided action persistence method significantly improves the sample efficiency.",
      "tldr_zh": "这篇论文针对深度强化学习(DRL)中的样本效率问题，提出了一种基于状态新颖性(state-novelty)引导的行动持久性(action persistence)方法，通过动态调整行动重复次数来优化探索-利用(exploration-exploitation)困境。该方法无需额外训练价值函数或策略，而是使用平滑的重复概率调度，实现探索和利用的更好平衡，并可无缝整合到各种基本探索策略中。实验结果显示，在不同 DMControl 任务上，该方法显著提高了样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.05433v1",
      "published_date": "2024-09-09 08:34:22 UTC",
      "updated_date": "2024-09-09 08:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:32:44.961032"
    },
    {
      "arxiv_id": "2409.05925v2",
      "title": "Assessing SPARQL capabilities of Large Language Models",
      "title_zh": "评估大语言模型的 SPARQL 能力",
      "authors": [
        "Lars-Peter Meyer",
        "Johannes Frey",
        "Felix Brei",
        "Natanael Arndt"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)\noffers significant synergistic potential for knowledge-driven applications. One\npossible integration is the interpretation and generation of formal languages,\nsuch as those used in the Semantic Web, with SPARQL being a core technology for\naccessing KGs. In this paper, we focus on measuring out-of-the box capabilities\nof LLMs to work with SPARQL and more specifically with SPARQL SELECT queries\napplying a quantitative approach.\n  We implemented various benchmarking tasks in the LLM-KG-Bench framework for\nautomated execution and evaluation with several LLMs. The tasks assess\ncapabilities along the dimensions of syntax, semantic read, semantic create,\nand the role of knowledge graph prompt inclusion.\n  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,\nand Claude models. Our findings indicate that working with SPARQL SELECT\nqueries is still challenging for LLMs and heavily depends on the specific LLM\nas well as the complexity of the task. While fixing basic syntax errors seems\nto pose no problems for the best of the current LLMs evaluated, creating\nsemantically correct SPARQL SELECT queries is difficult in several cases.",
      "tldr_zh": "这篇论文评估了大型语言模型(LLMs)处理 SPARQL 查询的能力，特别是 SPARQL SELECT 查询的 out-of-the-box 性能，使用定量方法。\n研究者在 LLM-KG-Bench 框架中实现了各种基准任务，涵盖语法、语义读取、语义创建以及知识图谱提示的作用维度，并对 GPT、Gemini 和 Claude 模型进行了评估。\n结果表明，LLMs 在修复基本 SPARQL 语法错误上表现良好，但创建语义正确的查询仍面临挑战，且性能高度依赖于特定模型和任务复杂度。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "Peer reviewed and published at NLP4KGc @ Semantics 2024, see original\n  publication at https://ceur-ws.org/Vol-3874/paper3.pdf . Updated Metadata",
      "pdf_url": "http://arxiv.org/pdf/2409.05925v2",
      "published_date": "2024-09-09 08:29:39 UTC",
      "updated_date": "2025-04-04 11:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:32:57.120879"
    },
    {
      "arxiv_id": "2409.05420v1",
      "title": "AD-Net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation",
      "title_zh": "AD-Net：基于注意力的空洞卷积残差网络，",
      "authors": [
        "Asim Naveed",
        "Syed S. Naqvi",
        "Tariq M. Khan",
        "Shahzaib Iqbal",
        "M. Yaqoob Wani",
        "Haroon Ahmed Khan"
      ],
      "abstract": "In computer-aided diagnosis tools employed for skin cancer treatment and\nearly diagnosis, skin lesion segmentation is important. However, achieving\nprecise segmentation is challenging due to inherent variations in appearance,\ncontrast, texture, and blurry lesion boundaries. This research presents a\nrobust approach utilizing a dilated convolutional residual network, which\nincorporates an attention-based spatial feature enhancement block (ASFEB) and\nemploys a guided decoder strategy. In each dilated convolutional residual\nblock, dilated convolution is employed to broaden the receptive field with\nvarying dilation rates. To improve the spatial feature information of the\nencoder, we employed an attention-based spatial feature enhancement block in\nthe skip connections. The ASFEB in our proposed method combines feature maps\nobtained from average and maximum-pooling operations. These combined features\nare then weighted using the active outcome of global average pooling and\nconvolution operations. Additionally, we have incorporated a guided decoder\nstrategy, where each decoder block is optimized using an individual loss\nfunction to enhance the feature learning process in the proposed AD-Net. The\nproposed AD-Net presents a significant benefit by necessitating fewer model\nparameters compared to its peer methods. This reduction in parameters directly\nimpacts the number of labeled data required for training, facilitating faster\nconvergence during the training process. The effectiveness of the proposed\nAD-Net was evaluated using four public benchmark datasets. We conducted a\nWilcoxon signed-rank test to verify the efficiency of the AD-Net. The outcomes\nsuggest that our method surpasses other cutting-edge methods in performance,\neven without the implementation of data augmentation strategies.",
      "tldr_zh": "这篇论文提出 AD-Net，一种基于 dilated convolutional residual network 的皮肤病变分割方法，旨在应对皮肤病变的外观、对比度、纹理变化和模糊边界等挑战。AD-Net 整合了 Attention-based Spatial Feature Enhancement Block (ASFEB) 来增强编码器的空间特征，通过结合平均池化和最大池化特征并进行加权优化，以及采用 guided decoder 策略，每个解码器块使用独立损失函数来提升特征学习。实验结果显示，AD-Net 在四个公共基准数据集上显著优于其他先进方法，即使不使用数据增强策略，且其模型参数更少，训练收敛更快。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05420v1",
      "published_date": "2024-09-09 08:21:17 UTC",
      "updated_date": "2024-09-09 08:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:33:09.236282"
    },
    {
      "arxiv_id": "2409.13723v3",
      "title": "Explainable Artificial Intelligence (XAI) for Malware Analysis: A Survey of Techniques, Applications, and Open Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Harikha Manthena",
        "Shaghayegh Shajarian",
        "Jeffrey Kimmell",
        "Mahmoud Abdelsalam",
        "Sajad Khorsandroo",
        "Maanak Gupta"
      ],
      "abstract": "Machine learning (ML) has rapidly advanced in recent years, revolutionizing\nfields such as finance, medicine, and cybersecurity. In malware detection,\nML-based approaches have demonstrated high accuracy; however, their lack of\ntransparency poses a significant challenge. Traditional black-box models often\nfail to provide interpretable justifications for their predictions, limiting\ntheir adoption in security-critical environments where understanding the\nreasoning behind a detection is essential for threat mitigation and response.\nExplainable AI (XAI) addresses this gap by enhancing model interpretability\nwhile maintaining strong detection capabilities. This survey presents a\ncomprehensive review of state-of-the-art ML techniques for malware analysis,\nwith a specific focus on explainability methods. We examine existing XAI\nframeworks, their application in malware classification and detection, and the\nchallenges associated with making malware detection models more interpretable.\nAdditionally, we explore recent advancements and highlight open research\nchallenges in the field of explainable malware analysis. By providing a\nstructured overview of XAI-driven malware detection approaches, this survey\nserves as a valuable resource for researchers and practitioners seeking to\nbridge the gap between ML performance and explainability in cybersecurity.",
      "tldr_zh": "这篇调查论文探讨了Explainable AI (XAI)在恶意软件分析中的应用，旨在解决Machine Learning (ML)模型在网络安全中的透明度问题，例如黑盒模型无法提供可解释的预测理由。作者回顾了现有的XAI框架、技术及其在恶意软件分类和检测中的实际应用，同时分析了提升模型可解释性的挑战，如领域知识缺口和性能权衡。调查还总结了最近进展和开放研究问题，为研究者和从业者提供资源，帮助在ML性能与可解释性之间实现平衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13723v3",
      "published_date": "2024-09-09 08:19:33 UTC",
      "updated_date": "2025-04-03 22:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:33:20.969891"
    },
    {
      "arxiv_id": "2409.05414v1",
      "title": "CipherDM: Secure Three-Party Inference for Diffusion Model Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhao",
        "Xiaojun Chen",
        "Xudong Chen",
        "He Li",
        "Tingyu Fan",
        "Zhendong Zhao"
      ],
      "abstract": "Diffusion Models (DMs) achieve state-of-the-art synthesis results in image\ngeneration and have been applied to various fields. However, DMs sometimes\nseriously violate user privacy during usage, making the protection of privacy\nan urgent issue. Using traditional privacy computing schemes like Secure\nMulti-Party Computation (MPC) directly in DMs faces significant computation and\ncommunication challenges. To address these issues, we propose CipherDM, the\nfirst novel, versatile and universal framework applying MPC technology to DMs\nfor secure sampling, which can be widely implemented on multiple DM based\ntasks. We thoroughly analyze sampling latency breakdown, find time-consuming\nparts and design corresponding secure MPC protocols for computing nonlinear\nactivations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular\narchitectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers.\nCompared to direct implementation on SPU, our approach improves running time by\napproximately 1.084\\times \\sim 2.328\\times, and reduces communication costs by\napproximately 1.212\\times \\sim 1.791\\times.",
      "tldr_zh": "Diffusion Models (DMs) 在图像生成领域表现出色，但在使用过程中可能严重侵犯用户隐私，因此隐私保护成为迫切问题。研究提出 CipherDM，一种新型通用框架，将 Secure Multi-Party Computation (MPC) 技术应用于 DMs 的安全采样，支持三方推理并针对非线性激活函数如 SoftMax、SiLU 和 Mish 设计了专用协议。实验结果显示，在 DDPM、DDIM 等架构上使用 MNIST 数据集和 SD 模型时，CipherDM 相比直接 SPU 实现，提高了约 1.084× 到 2.328× 的运行时间，并减少了约 1.212× 到 1.791× 的通信成本，从而为隐私保护的 DMs 应用提供了高效解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05414v1",
      "published_date": "2024-09-09 08:16:17 UTC",
      "updated_date": "2024-09-09 08:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:33:34.052785"
    },
    {
      "arxiv_id": "2409.05405v2",
      "title": "A Survey of Multimodal Composite Editing and Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Suyan Li",
        "Fuxiang Huang",
        "Lei Zhang"
      ],
      "abstract": "In the real world, where information is abundant and diverse across different\nmodalities, understanding and utilizing various data types to improve retrieval\nsystems is a key focus of research. Multimodal composite retrieval integrates\ndiverse modalities such as text, image and audio, etc. to provide more\naccurate, personalized, and contextually relevant results. To facilitate a\ndeeper understanding of this promising direction, this survey explores\nmultimodal composite editing and retrieval in depth, covering image-text\ncomposite editing, image-text composite retrieval, and other multimodal\ncomposite retrieval. In this survey, we systematically organize the application\nscenarios, methods, benchmarks, experiments, and future directions. Multimodal\nlearning is a hot topic in large model era, and have also witnessed some\nsurveys in multimodal learning and vision-language models with transformers\npublished in the PAMI journal. To the best of our knowledge, this survey is the\nfirst comprehensive review of the literature on multimodal composite retrieval,\nwhich is a timely complement of multimodal fusion to existing reviews. To help\nreaders' quickly track this field, we build the project page for this survey,\nwhich can be found at\nhttps://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.",
      "tldr_zh": "这篇调查论文（A Survey of Multimodal Composite Editing and Retrieval）系统地探讨了多模态复合编辑和检索，聚焦于整合文本、图像、音频等多样模态数据，以提升检索系统的准确性和相关性。该调查涵盖了图像-text composite editing、图像-text composite retrieval 以及其他多模态复合检索的应用场景、方法、基准、实验和未来方向，并强调这是首个全面回顾此领域的文献，为现有的多模态学习和视觉语言模型调查提供及时补充。为了便于跟踪，该论文提供了项目页面（https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 3 figures, and 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.05405v2",
      "published_date": "2024-09-09 08:06:50 UTC",
      "updated_date": "2024-09-11 02:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:33:45.187818"
    },
    {
      "arxiv_id": "2409.05402v1",
      "title": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Zhao",
        "Tiehua Zhang",
        "Zijian Yi",
        "Zhishu Shen"
      ],
      "abstract": "Hypergraphs are increasingly utilized in both unimodal and multimodal data\nscenarios due to their superior ability to model and extract higher-order\nrelationships among nodes, compared to traditional graphs. However, current\nhypergraph models are encountering challenges related to imbalanced data, as\nthis imbalance can lead to biases in the model towards the more prevalent\nclasses. While the existing techniques, such as GraphSMOTE, have improved\nclassification accuracy for minority samples in graph data, they still fall\nshort when addressing the unique structure of hypergraphs. Inspired by SMOTE\nconcept, we propose HyperSMOTE as a solution to alleviate the class imbalance\nissue in hypergraph learning. This method involves a two-step process:\ninitially synthesizing minority class nodes, followed by the nodes integration\ninto the original hypergraph. We synthesize new nodes based on samples from\nminority classes and their neighbors. At the same time, in order to solve the\nproblem on integrating the new node into the hypergraph, we train a decoder\nbased on the original hypergraph incidence matrix to adaptively associate the\naugmented node to hyperedges. We conduct extensive evaluation on multiple\nsingle-modality datasets, such as Cora, Cora-CA and Citeseer, as well as\nmultimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE,\nshowing an average performance gain of 3.38% and 2.97% on accuracy,\nrespectively.",
      "tldr_zh": "本研究针对超图（hypergraphs）学习中的类不平衡问题，提出了一种基于超图的过采样方法HyperSMOTE，以缓解模型对多数类的偏见。HyperSMOTE 借鉴 SMOTE 概念，通过两步过程：首先基于少数类样本及其邻居合成新节点，其次训练一个基于原超图关联矩阵的解码器，将这些新节点自适应地整合到超图中。实验在单模态数据集（如 Cora、Cora-CA 和 Citeseer）以及多模态数据集（如 MELD）上进行，结果显示准确率平均提升 3.38% 和 2.97%，证明了该方法在提升超图节点分类性能方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05402v1",
      "published_date": "2024-09-09 08:01:28 UTC",
      "updated_date": "2024-09-09 08:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:33:57.600269"
    },
    {
      "arxiv_id": "2409.05396v1",
      "title": "FacialFlowNet: Advancing Facial Optical Flow Estimation with a Diverse Dataset and a Decomposed Model",
      "title_zh": "FacialFlowNet：通过",
      "authors": [
        "Jianzhi Lu",
        "Ruian He",
        "Shili Zhou",
        "Weimin Tan",
        "Bo Yan"
      ],
      "abstract": "Facial movements play a crucial role in conveying altitude and intentions,\nand facial optical flow provides a dynamic and detailed representation of it.\nHowever, the scarcity of datasets and a modern baseline hinders the progress in\nfacial optical flow research. This paper proposes FacialFlowNet (FFN), a novel\nlarge-scale facial optical flow dataset, and the Decomposed Facial Flow Model\n(DecFlow), the first method capable of decomposing facial flow. FFN comprises\n9,635 identities and 105,970 image pairs, offering unprecedented diversity for\ndetailed facial and head motion analysis. DecFlow features a facial\nsemantic-aware encoder and a decomposed flow decoder, excelling in accurately\nestimating and decomposing facial flow into head and expression components.\nComprehensive experiments demonstrate that FFN significantly enhances the\naccuracy of facial flow estimation across various optical flow methods,\nachieving up to an 11% reduction in Endpoint Error (EPE) (from 3.91 to 3.48).\nMoreover, DecFlow, when coupled with FFN, outperforms existing methods in both\nsynthetic and real-world scenarios, enhancing facial expression analysis. The\ndecomposed expression flow achieves a substantial accuracy improvement of 18%\n(from 69.1% to 82.1%) in micro-expressions recognition. These contributions\nrepresent a significant advancement in facial motion analysis and optical flow\nestimation. Codes and datasets can be found.",
      "tldr_zh": "该论文针对面部光流估计面临的资料稀缺和基准不足问题，提出了FacialFlowNet (FFN)数据集和Decomposed Facial Flow Model (DecFlow)。FFN包含9,635个身份和105,970个图像对，提供多样化的面部和头部运动分析资源。DecFlow采用面部语义感知编码器和分解流解码器，能够准确估计并将面部光流分解为头部和表情组件。实验结果显示，FFN显著提升了光流估计精度，Endpoint Error (EPE)降低11%（从3.91到3.48），而DecFlow结合FFN在微表情识别中准确率提高18%（从69.1%到82.1%）。这些贡献推动了面部运动分析和光流估计领域的进步。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ACMMM2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05396v1",
      "published_date": "2024-09-09 07:49:13 UTC",
      "updated_date": "2024-09-09 07:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:34:12.600166"
    },
    {
      "arxiv_id": "2409.05395v2",
      "title": "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Pantazopoulos",
        "Malvina Nikandrou",
        "Alessandro Suglia",
        "Oliver Lemon",
        "Arash Eshghi"
      ],
      "abstract": "This study explores replacing Transformers in Visual Language Models (VLMs)\nwith Mamba, a recent structured state space model (SSM) that demonstrates\npromising performance in sequence modeling. We test models up to 3B parameters\nunder controlled conditions, showing that Mamba-based VLMs outperforms\nTransformers-based VLMs in captioning, question answering, and reading\ncomprehension. However, we find that Transformers achieve greater performance\nin visual grounding and the performance gap widens with scale. We explore two\nhypotheses to explain this phenomenon: 1) the effect of task-agnostic visual\nencoding on the updates of the hidden states, and 2) the difficulty in\nperforming visual grounding from the perspective of in-context multimodal\nretrieval. Our results indicate that a task-aware encoding yields minimal\nperformance gains on grounding, however, Transformers significantly outperform\nMamba at in-context multimodal retrieval. Overall, Mamba shows promising\nperformance on tasks where the correct output relies on a summary of the image\nbut struggles when retrieval of explicit information from the context is\nrequired.",
      "tldr_zh": "这篇论文比较了在视觉语言模型(VLMs)中使用 Transformers 和 Structured State Space Models (SSMs) 如 Mamba 的性能，通过测试高达 3B 参数的模型。实验结果显示，Mamba-based VLMs 在 captioning、question answering 和 reading comprehension 任务上优于 Transformers-based VLMs。相反，Transformers 在 visual grounding 任务上表现出色，且性能差距随模型规模扩大。研究探讨了两个假设，包括任务无关视觉编码对隐藏状态更新的影响，以及 in-context multimodal retrieval 的难度，最终发现 Mamba 更适合需要图像总结的任务，但弱于检索显式信息。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05395v2",
      "published_date": "2024-09-09 07:49:09 UTC",
      "updated_date": "2024-10-01 08:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:34:22.704802"
    },
    {
      "arxiv_id": "2409.05385v3",
      "title": "Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyun Hong",
        "Yan Shao",
        "Zhilin Wang",
        "Manni Duan",
        "Jin Xiongnan"
      ],
      "abstract": "The development of LLMs has greatly enhanced the intelligence and fluency of\nquestion answering, while the emergence of retrieval enhancement has enabled\nmodels to better utilize external information. However, the presence of noise\nand errors in retrieved information poses challenges to the robustness of LLMs.\nIn this work, to evaluate the model's performance under multiple interferences,\nwe first construct a dataset based on machine reading comprehension datasets\nsimulating various scenarios, including critical information absence, noise,\nand conflicts. To address the issue of model accuracy decline caused by noisy\nexternal information, we propose a data augmentation-based fine-tuning method\nto enhance LLM's robustness against noise. Additionally, contrastive learning\napproach is utilized to preserve the model's discrimination capability of\nexternal information. We have conducted experiments on both existing LLMs and\nour approach, the results are evaluated by GPT-4, which indicates that our\nproposed methods improve model robustness while strengthening the model's\ndiscrimination capability.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在知识密集型问答中的鲁棒性问题，探讨了检索增强技术带来的外部信息噪声和错误干扰。作者构建了一个基于机器阅读理解数据集的模拟场景数据集，包括关键信息缺失、噪声和冲突等情况，并提出了一种数据增强-based fine-tuning 方法来提升LLMs对噪声的鲁棒性，同时结合contrastive learning 技术以保持模型对外部信息的辨别能力。实验结果经GPT-4评估显示，该方法显著提高了模型的鲁棒性和辨别性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted by NLPCC-2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05385v3",
      "published_date": "2024-09-09 07:32:30 UTC",
      "updated_date": "2024-09-18 01:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:34:32.654238"
    },
    {
      "arxiv_id": "2409.05384v1",
      "title": "Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Ge",
        "Kangkai Zhang",
        "Haolin Liu",
        "Yingying Hua",
        "Shengwei Zhao",
        "Xin Jin",
        "Hao Wen"
      ],
      "abstract": "In spite of great success in many image recognition tasks achieved by recent\ndeep models, directly applying them to recognize low-resolution images may\nsuffer from low accuracy due to the missing of informative details during\nresolution degradation. However, these images are still recognizable for\nsubjects who are familiar with the corresponding high-resolution ones. Inspired\nby that, we propose a teacher-student learning approach to facilitate\nlow-resolution image recognition via hybrid order relational knowledge\ndistillation. The approach refers to three streams: the teacher stream is\npretrained to recognize high-resolution images in high accuracy, the student\nstream is learned to identify low-resolution images by mimicking the teacher's\nbehaviors, and the extra assistant stream is introduced as bridge to help\nknowledge transfer across the teacher to the student. To extract sufficient\nknowledge for reducing the loss in accuracy, the learning of student is\nsupervised with multiple losses, which preserves the similarities in various\norder relational structures. In this way, the capability of recovering missing\ndetails of familiar low-resolution images can be effectively enhanced, leading\nto a better knowledge transfer. Extensive experiments on metric learning,\nlow-resolution image classification and low-resolution face recognition tasks\nshow the effectiveness of our approach, while taking reduced models.",
      "tldr_zh": "该论文提出了一种 teacher-student 学习方法，用于提升低分辨率图像识别的准确率，解决深度模型在细节丢失问题上的不足。方法包括 teacher 流（预训练的高分辨率图像识别）、student 流（学习低分辨率图像识别）和 assistant 流（作为知识转移桥梁），通过 hybrid order relational knowledge distillation 提取并保留各种阶关系结构的相似性。实验结果显示，该方法在度量学习、低分辨率图像分类和低分辨率人脸识别任务上表现出色，同时减小了模型规模。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2020",
      "pdf_url": "http://arxiv.org/pdf/2409.05384v1",
      "published_date": "2024-09-09 07:32:18 UTC",
      "updated_date": "2024-09-09 07:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:34:45.177615"
    },
    {
      "arxiv_id": "2409.05383v1",
      "title": "Deep Learning for Video Anomaly Detection: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Wu",
        "Chengyu Pan",
        "Yuting Yan",
        "Guansong Pang",
        "Peng Wang",
        "Yanning Zhang"
      ],
      "abstract": "Video anomaly detection (VAD) aims to discover behaviors or events deviating\nfrom the normality in videos. As a long-standing task in the field of computer\nvision, VAD has witnessed much good progress. In the era of deep learning, with\nthe explosion of architectures of continuously growing capability and capacity,\na great variety of deep learning based methods are constantly emerging for the\nVAD task, greatly improving the generalization ability of detection algorithms\nand broadening the application scenarios. Therefore, such a multitude of\nmethods and a large body of literature make a comprehensive survey a pressing\nnecessity. In this paper, we present an extensive and comprehensive research\nreview, covering the spectrum of five different categories, namely,\nsemi-supervised, weakly supervised, fully supervised, unsupervised and open-set\nsupervised VAD, and we also delve into the latest VAD works based on\npre-trained large models, remedying the limitations of past reviews in terms of\nonly focusing on semi-supervised VAD and small model based methods. For the VAD\ntask with different levels of supervision, we construct a well-organized\ntaxonomy, profoundly discuss the characteristics of different types of methods,\nand show their performance comparisons. In addition, this review involves the\npublic datasets, open-source codes, and evaluation metrics covering all the\naforementioned VAD tasks. Finally, we provide several important research\ndirections for the VAD community.",
      "tldr_zh": "这篇论文对基于深度学习的视频异常检测 (Video Anomaly Detection, VAD) 进行了全面综述，涵盖半监督、弱监督、全监督、无监督和开放集监督五类方法，以及基于预训练大模型的最新进展，弥补了以往综述的局限性。论文构建了分类体系，深入讨论了不同方法的特性、性能比较，并总结了公共数据集、开源代码和评估指标。最终，它为VAD社区提供了重要的未来研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2409.05383v1",
      "published_date": "2024-09-09 07:31:16 UTC",
      "updated_date": "2024-09-09 07:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:34:56.639914"
    },
    {
      "arxiv_id": "2409.15337v1",
      "title": "Revisiting the Solution of Meta KDD Cup 2024: CRAG",
      "title_zh": "重访 Meta KDD Cup 2024 的解决方案：CRAG",
      "authors": [
        "Jie Ouyang",
        "Yucong Luo",
        "Mingyue Cheng",
        "Daoyu Wang",
        "Shuo Yu",
        "Qi Liu",
        "Enhong Chen"
      ],
      "abstract": "This paper presents the solution of our team APEX in the Meta KDD CUP 2024:\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\nmore comprehensive assessment of RAG performance and contributes to advancing\nresearch in this field. We propose a routing-based domain and dynamic adaptive\nRAG pipeline, which performs specific processing for the diverse and dynamic\nnature of the question in all three stages: retrieval, augmentation, and\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\nTask 2&3 on the final competition leaderboard. Our implementation is available\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.",
      "tldr_zh": "这篇论文回顾了团队 APEX 在 Meta KDD Cup 2024 的解决方案，名为 CRAG，这是一个全面的 Retrieval-Augmented Generation (RAG) 基准测试，用于解决现有 QA 基准在评估 RAG 系统多样性和动态挑战方面的局限性。作者提出了一种 routing-based domain and dynamic adaptive RAG pipeline，在检索、augmentation 和 generation 三个阶段进行特定处理，以适应问题的动态特性。该方法在 CRAG 基准上表现出色，在任务 2 和 3 上排名第二，并提供了开源实现（https://github.com/USTCAGI/CRAG-in-KDD-Cup2024），有助于推动 RAG 研究的发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15337v1",
      "published_date": "2024-09-09 07:28:14 UTC",
      "updated_date": "2024-09-09 07:28:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:35:20.096767"
    },
    {
      "arxiv_id": "2409.05379v1",
      "title": "PersonaTalk: Bring Attention to Your Persona in Visual Dubbing",
      "title_zh": "翻译失败",
      "authors": [
        "Longhao Zhang",
        "Shuang Liang",
        "Zhipeng Ge",
        "Tianshu Hu"
      ],
      "abstract": "For audio-driven visual dubbing, it remains a considerable challenge to\nuphold and highlight speaker's persona while synthesizing accurate lip\nsynchronization. Existing methods fall short of capturing speaker's unique\nspeaking style or preserving facial details. In this paper, we present\nPersonaTalk, an attention-based two-stage framework, including geometry\nconstruction and face rendering, for high-fidelity and personalized visual\ndubbing. In the first stage, we propose a style-aware audio encoding module\nthat injects speaking style into audio features through a cross-attention\nlayer. The stylized audio features are then used to drive speaker's template\ngeometry to obtain lip-synced geometries. In the second stage, a dual-attention\nface renderer is introduced to render textures for the target geometries. It\nconsists of two parallel cross-attention layers, namely Lip-Attention and\nFace-Attention, which respectively sample textures from different reference\nframes to render the entire face. With our innovative design, intricate facial\ndetails can be well preserved. Comprehensive experiments and user studies\ndemonstrate our advantages over other state-of-the-art methods in terms of\nvisual quality, lip-sync accuracy and persona preservation. Furthermore, as a\nperson-generic framework, PersonaTalk can achieve competitive performance as\nstate-of-the-art person-specific methods. Project Page:\nhttps://grisoon.github.io/PersonaTalk/.",
      "tldr_zh": "该研究提出PersonaTalk，一种基于注意力的两阶段框架，用于音频驱动的visual dubbing，以突出说话者的个性并实现精确唇部同步。框架首先通过style-aware audio encoding模块利用cross-attention层注入说话风格到音频特征中，驱动说话者模板几何生成唇部同步的几何结构；随后，引入dual-attention face renderer，包括Lip-Attention和Face-Attention，从不同参考帧采样纹理以保留面部细节。实验和用户研究表明，PersonaTalk在visual quality、唇同步准确性和persona preservation方面优于现有方法，且作为person-generic框架，其性能可与state-of-the-art person-specific方法竞争。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at SIGGRAPH Asia 2024 (Conference Track)",
      "pdf_url": "http://arxiv.org/pdf/2409.05379v1",
      "published_date": "2024-09-09 07:23:28 UTC",
      "updated_date": "2024-09-09 07:23:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:35:21.983783"
    },
    {
      "arxiv_id": "2409.05370v1",
      "title": "KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yingshu Li",
        "Zhanyu Wang",
        "Yunyi Liu",
        "Lei Wang",
        "Lingqiao Liu",
        "Luping Zhou"
      ],
      "abstract": "Harnessing the robust capabilities of Large Language Models (LLMs) for\nnarrative generation, logical reasoning, and common-sense knowledge\nintegration, this study delves into utilizing LLMs to enhance automated\nradiology report generation (R2Gen). Despite the wealth of knowledge within\nLLMs, efficiently triggering relevant knowledge within these large models for\nspecific tasks like R2Gen poses a critical research challenge. This paper\npresents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration\nframework based on LLMs. Utilizing a frozen LLM to generate reports, the\nframework integrates a knowledge graph to unlock chest disease-related\nknowledge within the LLM to enhance the clinical utility of generated reports.\nThis is achieved by leveraging the knowledge graph to distill disease-related\nfeatures in a designed way. Since a radiology report encompasses both normal\nand disease-related findings, the extracted graph-enhanced disease-related\nfeatures are integrated with regional image features, attending to both\naspects. We explore two fusion methods to automatically prioritize and select\nthe most relevant features. The fused features are employed by LLM to generate\nreports that are more sensitive to diseases and of improved quality. Our\napproach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.",
      "tldr_zh": "本研究提出 KARGEN 框架，利用大型语言模型 (LLMs) 增强放射学报告自动生成 (R2Gen)，通过整合知识图谱来提取胸部疾病相关特征，解决 LLMs 在特定任务中知识激活的挑战。框架将提取的图谱增强特征与图像区域特征融合，并探索两种融合方法来优先选择相关特征，从而生成更高质量且对疾病更敏感的报告。在 MIMIC-CXR 和 IU-Xray 数据集上的实验结果显示，该方法表现出色，显著提升了报告的临床实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05370v1",
      "published_date": "2024-09-09 06:57:22 UTC",
      "updated_date": "2024-09-09 06:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:35:33.068770"
    },
    {
      "arxiv_id": "2409.05358v2",
      "title": "BAMDP Shaping: a Unified Framework for Intrinsic Motivation and Reward Shaping",
      "title_zh": "BAMDP Shaping：一种用于内在动机和奖励整形的统一框架",
      "authors": [
        "Aly Lidayan",
        "Michael Dennis",
        "Stuart Russell"
      ],
      "abstract": "Intrinsic motivation and reward shaping guide reinforcement learning (RL)\nagents by adding pseudo-rewards, which can lead to useful emergent behaviors.\nHowever, they can also encourage counterproductive exploits, e.g., fixation\nwith noisy TV screens. Here we provide a theoretical model which anticipates\nthese behaviors, and provides broad criteria under which adverse effects can be\nbounded. We characterize all pseudo-rewards as reward shaping in Bayes-Adaptive\nMarkov Decision Processes (BAMDPs), which formulates the problem of learning in\nMDPs as an MDP over the agent's knowledge. Optimal exploration maximizes BAMDP\nstate value, which we decompose into the value of the information gathered and\nthe prior value of the physical state. Psuedo-rewards guide RL agents by\nrewarding behavior that increases these value components, while they hinder\nexploration when they align poorly with the actual value. We extend\npotential-based shaping theory to prove BAMDP Potential-based shaping Functions\n(BAMPFs) are immune to reward-hacking (convergence to behaviors maximizing\ncomposite rewards to the detriment of real rewards) in meta-RL, and show\nempirically how a BAMPF helps a meta-RL agent learn optimal RL algorithms for a\nBernoulli Bandit domain. We finally prove that BAMPFs with bounded monotone\nincreasing potentials also resist reward-hacking in the regular RL setting. We\nshow that it is straightforward to retrofit or design new pseudo-reward terms\nin this form, and provide an empirical demonstration in the Mountain Car\nenvironment.",
      "tldr_zh": "这篇论文提出了一种统一的框架BAMDP Shaping，用于整合内在动机和奖励整形，以指导强化学习（RL）代理的行为，同时预测并限制伪奖励可能导致的负面效果，如代理对噪音的 fixation。框架将伪奖励表征为贝叶斯自适应马尔可夫决策过程（BAMDP）中的奖励整形，将BAMDP状态价值分解为信息价值和物理状态先验价值，从而确保伪奖励与实际价值对齐。作者证明了BAMDP基于潜力的整形函数（BAMPFs）在元RL和常规RL设置中免疫奖励黑客行为，并通过实证实验在Bernoulli Bandit和Mountain Car环境中展示了其帮助代理学习最佳RL算法的效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.05358v2",
      "published_date": "2024-09-09 06:39:56 UTC",
      "updated_date": "2025-03-22 02:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:35:57.261873"
    },
    {
      "arxiv_id": "2409.05347v2",
      "title": "TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Imteaj",
        "Md Zarif Hossain",
        "Saika Zaman",
        "Abdur R. Shahid"
      ],
      "abstract": "The rapid advancement and increasing complexity of pretrained models,\nexemplified by CLIP, offer significant opportunities as well as challenges for\nFederated Learning (FL), a critical component of privacy-preserving artificial\nintelligence. This research delves into the intricacies of integrating large\nfoundation models like CLIP within FL frameworks to enhance privacy,\nefficiency, and adaptability across heterogeneous data landscapes. It\nspecifically addresses the challenges posed by non-IID data distributions, the\ncomputational and communication overheads of leveraging such complex models,\nand the skewed representation of classes within datasets. We propose\nTriplePlay, a framework that integrates CLIP as an adapter to enhance FL's\nadaptability and performance across diverse data distributions. This approach\naddresses the long-tail distribution challenge to ensure fairness while\nreducing resource demands through quantization and low-rank adaptation\ntechniques.Our simulation results demonstrate that TriplePlay effectively\ndecreases GPU usage costs and speeds up the learning process, achieving\nconvergence with reduced communication overhead.",
      "tldr_zh": "该研究探讨了在联邦学习(Federated Learning, FL)中整合大型预训练模型如CLIP的挑战，特别是针对non-IID数据分布、计算通信开销和类别偏差问题。TriplePlay框架提出将CLIP用作适配器，以提升FL的适应性和性能，同时通过quantization和low-rank adaptation技术处理长尾分布，确保公平性和资源效率。实验结果显示，TriplePlay显著降低了GPU使用成本，加速了学习过程，并减少了通信开销，从而实现了更高效的隐私保护AI。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05347v2",
      "published_date": "2024-09-09 06:04:42 UTC",
      "updated_date": "2024-10-08 04:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:35:56.124076"
    },
    {
      "arxiv_id": "2409.05346v1",
      "title": "GDFlow: Anomaly Detection with NCDE-based Normalizing Flow for Advanced Driver Assistance System",
      "title_zh": "翻译失败",
      "authors": [
        "Kangjun Lee",
        "Minha Kim",
        "Youngho Jun",
        "Simon S. Woo"
      ],
      "abstract": "For electric vehicles, the Adaptive Cruise Control (ACC) in Advanced Driver\nAssistance Systems (ADAS) is designed to assist braking based on driving\nconditions, road inclines, predefined deceleration strengths, and user braking\npatterns. However, the driving data collected during the development of ADAS\nare generally limited and lack diversity. This deficiency leads to late or\naggressive braking for different users. Crucially, it is necessary to\neffectively identify anomalies, such as unexpected or inconsistent braking\npatterns in ADAS, especially given the challenge of working with unlabelled,\nlimited, and noisy datasets from real-world electric vehicles. In order to\ntackle the aforementioned challenges in ADAS, we propose Graph Neural\nControlled Differential Equation Normalizing Flow (GDFlow), a model that\nleverages Normalizing Flow (NF) with Neural Controlled Differential Equations\n(NCDE) to learn the distribution of normal driving patterns continuously.\nCompared to the traditional clustering or anomaly detection algorithms, our\napproach effectively captures the spatio-temporal information from different\nsensor data and more accurately models continuous changes in driving patterns.\nAdditionally, we introduce a quantile-based maximum likelihood objective to\nimprove the likelihood estimate of the normal data near the boundary of the\ndistribution, enhancing the model's ability to distinguish between normal and\nanomalous patterns. We validate GDFlow using real-world electric vehicle\ndriving data that we collected from Hyundai IONIQ5 and GV80EV, achieving\nstate-of-the-art performance compared to six baselines across four dataset\nconfigurations of different vehicle types and drivers. Furthermore, our model\noutperforms the latest anomaly detection methods across four time series\nbenchmark datasets. Our approach demonstrates superior efficiency in inference\ntime compared to existing methods.",
      "tldr_zh": "这篇论文针对先进驾驶辅助系统 (ADAS) 中的自适应巡航控制 (ACC)，提出 GDFlow 模型，以解决电动车数据有限、缺乏多样性导致的制动异常问题。GDFlow 利用 Neural Controlled Differential Equations (NCDE) 结合 Normalizing Flow (NF) 来持续学习正常驾驶模式的分布，并通过捕捉时空信息和引入基于分位数的最大似然目标，提升对异常模式的识别准确性。实验结果显示，GDFlow 在 Hyundai IONIQ5 和 GV80EV 的真实数据上优于六种基线方法，并在四个时间序列基准数据集上实现最先进性能，同时在推理时间上更高效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05346v1",
      "published_date": "2024-09-09 06:04:41 UTC",
      "updated_date": "2024-09-09 06:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:36:09.668043"
    },
    {
      "arxiv_id": "2409.05344v2",
      "title": "GOPT: Generalizable Online 3D Bin Packing via Transformer-based Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Heng Xiong",
        "Changrong Guo",
        "Jian Peng",
        "Kai Ding",
        "Wenjie Chen",
        "Xuchong Qiu",
        "Long Bai",
        "Jianfeng Xu"
      ],
      "abstract": "Robotic object packing has broad practical applications in the logistics and\nautomation industry, often formulated by researchers as the online 3D Bin\nPacking Problem (3D-BPP). However, existing DRL-based methods primarily focus\non enhancing performance in limited packing environments while neglecting the\nability to generalize across multiple environments characterized by different\nbin dimensions. To this end, we propose GOPT, a generalizable online 3D Bin\nPacking approach via Transformer-based deep reinforcement learning (DRL).\nFirst, we design a Placement Generator module to yield finite subspaces as\nplacement candidates and the representation of the bin. Second, we propose a\nPacking Transformer, which fuses the features of the items and bin, to identify\nthe spatial correlation between the item to be packed and available sub-spaces\nwithin the bin. Coupling these two components enables GOPT's ability to perform\ninference on bins of varying dimensions. We conduct extensive experiments and\ndemonstrate that GOPT not only achieves superior performance against the\nbaselines, but also exhibits excellent generalization capabilities.\nFurthermore, the deployment with a robot showcases the practical applicability\nof our method in the real world. The source code will be publicly available at\nhttps://github.com/Xiong5Heng/GOPT.",
      "tldr_zh": "该论文提出GOPT，一种基于Transformer的深度强化学习（DRL）方法，用于解决在线3D Bin Packing Problem（3D-BPP），旨在提升机器人物体打包在不同箱子尺寸环境下的泛化能力。GOPT包括Placement Generator模块，用于生成放置候选空间和箱子表示，以及Packing Transformer模块，通过融合物品和箱子特征来识别物品与可用子空间的空间相关性，从而实现对变异箱子的推理。实验结果显示，GOPT在性能上优于基线模型，并展现出优秀的泛化能力；此外，该方法已在真实机器人上成功部署，证明其实际应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures. This paper has been accepted by IEEE Robotics and\n  Automation Letters",
      "pdf_url": "http://arxiv.org/pdf/2409.05344v2",
      "published_date": "2024-09-09 06:02:17 UTC",
      "updated_date": "2024-09-12 08:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:36:20.753794"
    },
    {
      "arxiv_id": "2409.05336v1",
      "title": "Early-exit Convolutional Neural Networks",
      "title_zh": "提前退出的卷积神经网络",
      "authors": [
        "Edanur Demir",
        "Emre Akbas"
      ],
      "abstract": "This paper is aimed at developing a method that reduces the computational\ncost of convolutional neural networks (CNN) during inference. Conventionally,\nthe input data pass through a fixed neural network architecture. However, easy\nexamples can be classified at early stages of processing and conventional\nnetworks do not take this into account. In this paper, we introduce 'Early-exit\nCNNs', EENets for short, which adapt their computational cost based on the\ninput by stopping the inference process at certain exit locations. In EENets,\nthere are a number of exit blocks each of which consists of a confidence branch\nand a softmax branch. The confidence branch computes the confidence score of\nexiting (i.e. stopping the inference process) at that location; while the\nsoftmax branch outputs a classification probability vector. Both branches are\nlearnable and their parameters are separate. During training of EENets, in\naddition to the classical classification loss, the computational cost of\ninference is taken into account as well. As a result, the network adapts its\nmany confidence branches to the inputs so that less computation is spent for\neasy examples. Inference works as in conventional feed-forward networks,\nhowever, when the output of a confidence branch is larger than a certain\nthreshold, the inference stops for that specific example. The idea of EENets is\napplicable to available CNN architectures such as ResNets. Through\ncomprehensive experiments on MNIST, SVHN, CIFAR10 and Tiny-ImageNet datasets,\nwe show that early-exit (EE) ResNets achieve similar accuracy with their non-EE\nversions while reducing the computational cost to 20% of the original. Code is\navailable at https://github.com/eksuas/eenets.pytorch",
      "tldr_zh": "这篇论文提出了一种名为 Early-exit CNNs (EENets) 的方法，以减少卷积神经网络 (CNN) 在推理过程中的计算成本，通过允许网络根据输入难度在早期出口位置停止处理。EENets 在架构中加入多个出口块，每个块包含信心分支（计算退出信心分数）和 softmax 分支（输出分类概率向量），并在训练时结合分类损失和计算成本优化，使简单样本减少计算量。实验结果显示，在 MNIST、SVHN、CIFAR10 和 Tiny-ImageNet 数据集上，Early-exit ResNets 保持了与原始 ResNets 相似的准确率，同时将计算成本降低至原有的 20%。这为高效的神经网络推理提供了实用框架，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05336v1",
      "published_date": "2024-09-09 05:29:38 UTC",
      "updated_date": "2024-09-09 05:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:36:33.691708"
    },
    {
      "arxiv_id": "2409.05335v1",
      "title": "A Multi-Modal Deep Learning Based Approach for House Price Prediction",
      "title_zh": "一种基于多模态深度学习的方法用于房价",
      "authors": [
        "Md Hasebul Hasan",
        "Md Abid Jahan",
        "Mohammed Eunus Ali",
        "Yuan-Fang Li",
        "Timos Sellis"
      ],
      "abstract": "Accurate prediction of house price, a vital aspect of the residential real\nestate sector, is of substantial interest for a wide range of stakeholders.\nHowever, predicting house prices is a complex task due to the significant\nvariability influenced by factors such as house features, location,\nneighborhood, and many others. Despite numerous attempts utilizing a wide array\nof algorithms, including recent deep learning techniques, to predict house\nprices accurately, existing approaches have fallen short of considering a wide\nrange of factors such as textual and visual features. This paper addresses this\ngap by comprehensively incorporating attributes, such as features, textual\ndescriptions, geo-spatial neighborhood, and house images, typically showcased\nin real estate listings in a house price prediction system. Specifically, we\npropose a multi-modal deep learning approach that leverages different types of\ndata to learn more accurate representation of the house. In particular, we\nlearn a joint embedding of raw house attributes, geo-spatial neighborhood, and\nmost importantly from textual description and images representing the house;\nand finally use a downstream regression model to predict the house price from\nthis jointly learned embedding vector. Our experimental results with a\nreal-world dataset show that the text embedding of the house advertisement\ndescription and image embedding of the house pictures in addition to raw\nattributes and geo-spatial embedding, can significantly improve the house price\nprediction accuracy. The relevant source code and dataset are publicly\naccessible at the following URL: https://github.com/4P0N/mhpp",
      "tldr_zh": "该论文针对房价预测的复杂性，提出了一种基于 multi-modal deep learning 的方法，以整合房屋属性、文本描述、geo-spatial neighborhood 和图像等多类型数据。方法通过学习这些数据的 joint embedding 向量，然后利用下游 regression model 来实现更准确的房价预测。实验结果显示，加入文本和图像嵌入显著提高了预测准确性，使用真实数据集验证了其有效性，并公开了源代码和数据集以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.05335v1",
      "published_date": "2024-09-09 05:26:33 UTC",
      "updated_date": "2024-09-09 05:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:36:43.764906"
    },
    {
      "arxiv_id": "2409.11416v1",
      "title": "The Unseen AI Disruptions for Power Grids: LLM-Induced Transients",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhuo Li",
        "Mariam Mughees",
        "Yize Chen",
        "Yunwei Ryan Li"
      ],
      "abstract": "Recent breakthroughs of large language models (LLMs) have exhibited superior\ncapability across major industries and stimulated multi-hundred-billion-dollar\ninvestment in AI-centric data centers in the next 3-5 years. This, in turn,\nbring the increasing concerns on sustainability and AI-related energy usage.\nHowever, there is a largely overlooked issue as challenging and critical as AI\nmodel and infrastructure efficiency: the disruptive dynamic power consumption\nbehaviour. With fast, transient dynamics, AI infrastructure features ultra-low\ninertia, sharp power surge and dip, and a significant peak-idle power ratio.\nThe power scale covers from several hundred watts to megawatts, even to\ngigawatts. These never-seen-before characteristics make AI a very unique load\nand pose threats to the power grid reliability and resilience. To reveal this\nhidden problem, this paper examines the scale of AI power consumption, analyzes\nAI transient behaviour in various scenarios, develops high-level mathematical\nmodels to depict AI workload behaviour and discusses the multifaceted\nchallenges and opportunities they potentially bring to existing power grids.\nObserving the rapidly evolving machine learning (ML) and AI technologies, this\nwork emphasizes the critical need for interdisciplinary approaches to ensure\nreliable and sustainable AI infrastructure development, and provides a starting\npoint for researchers and practitioners to tackle such challenges.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）快速发展对电力系统的潜在破坏性影响，特别是AI基础设施的瞬变动态行为，如超低惯性、急剧功率涌升（surge）和下降（dip），以及显著的峰值-空闲功率比，这些特性使AI负载成为电网可靠性和弹性的新威胁。论文分析了AI电力消耗的规模（从数百瓦到吉瓦）、各种场景下的瞬变行为，并开发了高级数学模型来描述AI工作负载的行为。最终，它讨论了这些问题带来的多方面挑战和机会，强调需要跨学科方法来确保AI基础设施的可靠性和可持续性，并为研究人员提供了一个起点来应对这些挑战。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PF",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AR",
      "comment": "21 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.11416v1",
      "published_date": "2024-09-09 05:22:01 UTC",
      "updated_date": "2024-09-09 05:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:36:56.964809"
    },
    {
      "arxiv_id": "2409.07493v1",
      "title": "Complex Emotion Recognition System using basic emotions via Facial Expression, EEG, and ECG Signals: a review",
      "title_zh": "翻译失败",
      "authors": [
        "Javad Hassannataj Joloudari",
        "Mohammad Maftoun",
        "Bahareh Nakisa",
        "Roohallah Alizadehsani",
        "Meisam Yadollahzadeh-Tabari"
      ],
      "abstract": "The Complex Emotion Recognition System (CERS) deciphers complex emotional\nstates by examining combinations of basic emotions expressed, their\ninterconnections, and the dynamic variations. Through the utilization of\nadvanced algorithms, CERS provides profound insights into emotional dynamics,\nfacilitating a nuanced understanding and customized responses. The attainment\nof such a level of emotional recognition in machines necessitates the knowledge\ndistillation and the comprehension of novel concepts akin to human cognition.\nThe development of AI systems for discerning complex emotions poses a\nsubstantial challenge with significant implications for affective computing.\nFurthermore, obtaining a sizable dataset for CERS proves to be a daunting task\ndue to the intricacies involved in capturing subtle emotions, necessitating\nspecialized methods for data collection and processing. Incorporating\nphysiological signals such as Electrocardiogram (ECG) and Electroencephalogram\n(EEG) can notably enhance CERS by furnishing valuable insights into the user's\nemotional state, enhancing the quality of datasets, and fortifying system\ndependability. A comprehensive literature review was conducted in this study to\nassess the efficacy of machine learning, deep learning, and meta-learning\napproaches in both basic and complex emotion recognition utilizing EEG, ECG\nsignals, and facial expression datasets. The chosen research papers offer\nperspectives on potential applications, clinical implications, and results of\nCERSs, with the objective of promoting their acceptance and integration into\nclinical decision-making processes. This study highlights research gaps and\nchallenges in understanding CERSs, encouraging further investigation by\nrelevant studies and organizations. Lastly, the significance of meta-learning\napproaches in improving CERS performance and guiding future research endeavors\nis underscored.",
      "tldr_zh": "本综述探讨了Complex Emotion Recognition System (CERS)，一种通过面部表情、EEG和ECG信号识别基本情绪及其组合来解析复杂情绪状态的系统。研究评估了机器学习、deep learning和meta-learning等算法在基本和复杂情绪识别中的效能，并强调整合生理信号（如EEG和ECG）能提升数据集质量和系统可靠性。论文突出了数据集收集的挑战、临床应用潜力，以及meta-learning在改进CERS性能方面的作用，呼吁进一步研究填补现有空白。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "29 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.07493v1",
      "published_date": "2024-09-09 05:06:10 UTC",
      "updated_date": "2024-09-09 05:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:37:08.952113"
    },
    {
      "arxiv_id": "2409.05325v1",
      "title": "Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Deshwal",
        "Sait Cakmak",
        "Yuhou Xia",
        "David Eriksson"
      ],
      "abstract": "Bayesian optimization (BO) is a powerful approach to sample-efficient\noptimization of black-box functions. However, in settings with very few\nfunction evaluations, a successful application of BO may require transferring\ninformation from historical experiments. These related experiments may not have\nexactly the same tunable parameters (search spaces), motivating the need for BO\nwith transfer learning for heterogeneous search spaces. In this paper, we\npropose two methods for this setting. The first approach leverages a Gaussian\nprocess (GP) model with a conditional kernel to transfer information between\ndifferent search spaces. Our second approach treats the missing parameters as\nhyperparameters of the GP model that can be inferred jointly with the other GP\nhyperparameters or set to fixed values. We show that these two methods perform\nwell on several benchmark problems.",
      "tldr_zh": "这篇论文针对异构搜索空间（heterogeneous search spaces）中的Bayesian optimization (BO) 提出两种样本高效的转移学习方法，以从历史实验中转移信息。第一种方法利用Gaussian process (GP) 模型的条件核来实现不同搜索空间之间的信息转移。第二种方法将缺失参数视为GP模型的超参数，并与其它超参数一起推断或固定。这些方法在多个基准问题上表现出色，提高了BO的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05325v1",
      "published_date": "2024-09-09 04:36:06 UTC",
      "updated_date": "2024-09-09 04:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:37:20.802744"
    },
    {
      "arxiv_id": "2409.05319v1",
      "title": "Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Li",
        "Khalid Zaman",
        "Xingfeng Li",
        "Masato Akagi",
        "Masashi Unoki"
      ],
      "abstract": "Early detection of factory machinery malfunctions is crucial in industrial\napplications. In machine anomalous sound detection (ASD), different machines\nexhibit unique vibration-frequency ranges based on their physical properties.\nMeanwhile, the human auditory system is adept at tracking both temporal and\nspectral dynamics of machine sounds. Consequently, integrating the\ncomputational auditory models of the human auditory system with\nmachine-specific properties can be an effective approach to machine ASD. We\nfirst quantified the frequency importances of four types of machines using the\nFisher ratio (F-ratio). The quantified frequency importances were then used to\ndesign machine-specific non-uniform filterbanks (NUFBs), which extract the log\nnon-uniform spectrum (LNS) feature. The designed NUFBs have a narrower\nbandwidth and higher filter distribution density in frequency regions with\nrelatively high F-ratios. Finally, spectral and temporal modulation\nrepresentations derived from the LNS feature were proposed. These proposed LNS\nfeature and modulation representations are input into an autoencoder\nneural-network-based detector for ASD. The quantification results from the\ntraining set of the Malfunctioning Industrial Machine Investigation and\nInspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the\ndistinguishing information between normal and anomalous sounds of different\nmachines is encoded non-uniformly in the frequency domain. By highlighting\nthese important frequency regions using NUFBs, the LNS feature can\nsignificantly enhance performance using the metric of AUC (area under the\nreceiver operating characteristic curve) under various SNR conditions.\nFurthermore, modulation representations can further improve performance.\nSpecifically, temporal modulation is effective for fans, pumps, and sliders,\nwhile spectral modulation is particularly effective for valves.",
      "tldr_zh": "该研究针对机器异常声音检测 (ASD)，提出了一种整合人类听觉模型和机器特定属性的方法，以早期识别工厂机械故障。方法首先使用 Fisher ratio (F-ratio) 量化四种机器的频率重要性，设计机器特定的非均匀滤波器组 (NUFBs) 来提取 log non-uniform spectrum (LNS) 特征，并从中衍生谱和时谱调制表示，这些特征随后输入基于 autoencoder 的神经网络检测器。实验结果显示，在 Malfunctioning Industrial Machine Investigation and Inspection 数据集上，LNS 特征显著提高了 AUC 指标的性能，尤其在各种信噪比 (SNR) 条件下；此外，时谱调制对风扇、泵和滑块特别有效，而谱调制则适用于阀门。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05319v1",
      "published_date": "2024-09-09 04:27:17 UTC",
      "updated_date": "2024-09-09 04:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:37:34.662980"
    },
    {
      "arxiv_id": "2409.05314v3",
      "title": "Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications",
      "title_zh": "Tele-LLMs：针对电信领域的一系列专业化大型语言模型",
      "authors": [
        "Ali Maatouk",
        "Kenny Chirino Ampudia",
        "Rex Ying",
        "Leandros Tassiulas"
      ],
      "abstract": "The emergence of large language models (LLMs) has significantly impacted\nvarious fields, from natural language processing to sectors like medicine and\nfinance. However, despite their rapid proliferation, the applications of LLMs\nin telecommunications remain limited, often relying on general-purpose models\nthat lack domain-specific specialization. This lack of specialization results\nin underperformance, particularly when dealing with telecommunications-specific\ntechnical terminology and their associated mathematical representations. This\npaper addresses this gap by first creating and disseminating Tele-Data, a\ncomprehensive dataset of telecommunications material curated from relevant\nsources, and Tele-Eval, a large-scale question-and-answer dataset tailored to\nthe domain. Through extensive experiments, we explore the most effective\ntraining techniques for adapting LLMs to the telecommunications domain, ranging\nfrom examining the division of expertise across various telecommunications\naspects to employing parameter-efficient techniques. We also investigate how\nmodels of different sizes behave during adaptation and analyze the impact of\ntheir training data on this behavior. Leveraging these findings, we develop and\nopen-source Tele-LLMs, the first series of language models ranging from 1B to\n8B parameters, specifically tailored for telecommunications. Our evaluations\ndemonstrate that these models outperform their general-purpose counterparts on\nTele-Eval and telecommunications-related literature tasks while retaining their\npreviously acquired capabilities, thus avoiding the catastrophic forgetting\nphenomenon.",
      "tldr_zh": "该研究指出，大型语言模型（LLMs）在电信领域的应用受限于通用模型的领域专业性不足，导致在处理电信术语和数学表示时表现不佳。为解决此问题，论文首先构建了Tele-Data（一个电信材料的综合数据集）和Tele-Eval（一个针对电信的问答数据集）。通过广泛实验，探索了适应LLMs的训练技巧，包括专业划分、参数高效技术以及模型大小的影响。最终，开发并开源了Tele-LLMs系列模型（从1B到8B参数），这些模型在Tele-Eval和电信相关任务上优于通用模型，同时避免了灾难性遗忘，保留了原有能力。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05314v3",
      "published_date": "2024-09-09 03:58:51 UTC",
      "updated_date": "2025-05-05 04:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:37:45.333580"
    },
    {
      "arxiv_id": "2409.05305v3",
      "title": "Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Zakaria Patel",
        "Sebastian J. Wetzel"
      ],
      "abstract": "It has been demonstrated in many scientific fields that artificial neural\nnetworks like autoencoders or Siamese networks encode meaningful concepts in\ntheir latent spaces. However, there does not exist a comprehensive framework\nfor retrieving this information in a human-readable form without prior\nknowledge. In order to extract these concepts, we introduce a framework for\nfinding closed-form interpretations of neurons in latent spaces of artificial\nneural networks. The interpretation framework is based on embedding trained\nneural networks into an equivalence class of functions that encode the same\nconcept. We interpret these neural networks by finding an intersection between\nthe equivalence class and human-readable equations defined by a symbolic search\nspace. The approach is demonstrated by retrieving invariants of matrices and\nconserved quantities of dynamical systems from latent spaces of Siamese neural\nnetworks.",
      "tldr_zh": "本研究提出一个框架，用于从neural network的latent spaces中提取神经元的闭合形式解释，而无需先验知识，从而将编码的概念转化为human-readable形式。该框架基于将训练好的neural networks嵌入等价函数类，并通过符号搜索空间与这些类求交集，实现对潜空间概念的精确解读。实验演示了该方法从Siamese neural networks的latent spaces中成功检索矩阵的不变性(invariants)和动力系统的守恒量( conserved quantities)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Revised to correct minor issues",
      "pdf_url": "http://arxiv.org/pdf/2409.05305v3",
      "published_date": "2024-09-09 03:26:07 UTC",
      "updated_date": "2025-01-17 20:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:37:56.994924"
    },
    {
      "arxiv_id": "2409.09072v1",
      "title": "Joint Model Assignment and Resource Allocation for Cost-Effective Mobile Generative Services",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangwei Gao",
        "Peng Yang",
        "Yuxin Kong",
        "Feng Lyu",
        "Ning Zhang"
      ],
      "abstract": "Artificial Intelligence Generated Content (AIGC) services can efficiently\nsatisfy user-specified content creation demands, but the high computational\nrequirements pose various challenges to supporting mobile users at scale. In\nthis paper, we present our design of an edge-enabled AIGC service provisioning\nsystem to properly assign computing tasks of generative models to edge servers,\nthereby improving overall user experience and reducing content generation\nlatency. Specifically, once the edge server receives user requested task\nprompts, it dynamically assigns appropriate models and allocates computing\nresources based on features of each category of prompts. The generated contents\nare then delivered to users. The key to this system is a proposed probabilistic\nmodel assignment approach, which estimates the quality score of generated\ncontents for each prompt based on category labels. Next, we introduce a\nheuristic algorithm that enables adaptive configuration of both generation\nsteps and resource allocation, according to the various task requests received\nby each generative model on the edge.Simulation results demonstrate that the\ndesigned system can effectively enhance the quality of generated content by up\nto 4.7% while reducing response delay by up to 39.1% compared to benchmarks.",
      "tldr_zh": "这篇论文提出了一种边缘计算启用的 AIGC 服务系统，用于联合模型分配和资源配置，以降低移动生成服务的成本并提升用户体验。具体方法包括概率模型分配方法（probabilistic model assignment），根据提示类别估计生成内容的质量分数，以及一个启发式算法（heuristic algorithm）来动态调整生成步骤和资源分配。模拟结果显示，该系统相较基准方案提高了生成内容质量高达 4.7%，并减少了响应延迟达 39.1%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09072v1",
      "published_date": "2024-09-09 03:20:53 UTC",
      "updated_date": "2024-09-09 03:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:38:09.072056"
    },
    {
      "arxiv_id": "2409.05303v1",
      "title": "Resource-Efficient Generative AI Model Deployment in Mobile Edge Networks",
      "title_zh": "资源高效的生成式 AI 模型在移动边缘网络中的部署",
      "authors": [
        "Yuxin Liang",
        "Peng Yang",
        "Yuanyuan He",
        "Feng Lyu"
      ],
      "abstract": "The surging development of Artificial Intelligence-Generated Content (AIGC)\nmarks a transformative era of the content creation and production. Edge servers\npromise attractive benefits, e.g., reduced service delay and backhaul traffic\nload, for hosting AIGC services compared to cloud-based solutions. However, the\nscarcity of available resources on the edge pose significant challenges in\ndeploying generative AI models. In this paper, by characterizing the resource\nand delay demands of typical generative AI models, we find that the consumption\nof storage and GPU memory, as well as the model switching delay represented by\nI/O delay during the preloading phase, are significant and vary across models.\nThese multidimensional coupling factors render it difficult to make efficient\nedge model deployment decisions. Hence, we present a collaborative edge-cloud\nframework aiming to properly manage generative AI model deployment on the edge.\nSpecifically, we formulate edge model deployment problem considering\nheterogeneous features of models as an optimization problem, and propose a\nmodel-level decision selection algorithm to solve it. It enables pooled\nresource sharing and optimizes the trade-off between resource consumption and\ndelay in edge generative AI model deployment. Simulation results validate the\nefficacy of the proposed algorithm compared with baselines, demonstrating its\npotential to reduce overall costs by providing feature-aware model deployment\ndecisions.",
      "tldr_zh": "该研究探讨了在移动边缘网络中部署生成式AI模型（Generative AI Models）的资源效率问题，针对边缘服务器资源稀缺导致的挑战，如存储、GPU内存消耗和模型切换延迟（I/O delay）。作者提出一个协作边云框架，将部署问题建模为优化问题，并设计了一个模型级决策选择算法，实现资源共享并优化资源消耗与延迟的权衡。模拟结果显示，该算法相较于基线方案可显著降低整体成本，提供基于模型特征的部署决策，从而提升AIGC服务的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05303v1",
      "published_date": "2024-09-09 03:17:28 UTC",
      "updated_date": "2024-09-09 03:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:38:20.631762"
    },
    {
      "arxiv_id": "2409.05294v1",
      "title": "TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors",
      "title_zh": "TERD：一种统一框架，用于保护扩散模型免受后门攻击",
      "authors": [
        "Yichuan Mo",
        "Hui Huang",
        "Mingjie Li",
        "Ang Li",
        "Yisen Wang"
      ],
      "abstract": "Diffusion models have achieved notable success in image generation, but they\nremain highly vulnerable to backdoor attacks, which compromise their integrity\nby producing specific undesirable outputs when presented with a pre-defined\ntrigger. In this paper, we investigate how to protect diffusion models from\nthis dangerous threat. Specifically, we propose TERD, a backdoor defense\nframework that builds unified modeling for current attacks, which enables us to\nderive an accessible reversed loss. A trigger reversion strategy is further\nemployed: an initial approximation of the trigger through noise sampled from a\nprior distribution, followed by refinement through differential multi-step\nsamplers. Additionally, with the reversed trigger, we propose backdoor\ndetection from the noise space, introducing the first backdoor input detection\napproach for diffusion models and a novel model detection algorithm that\ncalculates the KL divergence between reversed and benign distributions.\nExtensive evaluations demonstrate that TERD secures a 100% True Positive Rate\n(TPR) and True Negative Rate (TNR) across datasets of varying resolutions. TERD\nalso demonstrates nice adaptability to other Stochastic Differential Equation\n(SDE)-based models. Our code is available at https://github.com/PKU-ML/TERD.",
      "tldr_zh": "这篇论文针对扩散模型（diffusion models）易受后门攻击（backdoor attacks）的安全风险，提出了一种统一的防御框架 TERD，以保护模型免于特定触发器导致的不期望输出。TERD 通过构建统一的攻击模型并推导出可访问的逆向损失（reversed loss），结合触发器逆向策略——从先验分布采样噪声作为初始近似，并通过差分多步采样器（differential multi-step samplers）进行精炼，实现对后门威胁的有效识别。框架还引入了从噪声空间进行后门输入检测，这是扩散模型的首次此类方法，以及一种基于 KL 散度（KL divergence）的模型检测算法。实验评估显示，TERD 在不同分辨率数据集上实现了 100% 的真正率 (TPR) 和真正负率 (TNR)，并展示了对其他基于随机微分方程 (SDE) 模型的良好适应性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05294v1",
      "published_date": "2024-09-09 03:02:16 UTC",
      "updated_date": "2024-09-09 03:02:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:38:35.365488"
    },
    {
      "arxiv_id": "2409.05292v4",
      "title": "Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Nirmalya Thakur"
      ],
      "abstract": "The world is currently experiencing an outbreak of mpox, which has been\ndeclared a Public Health Emergency of International Concern by WHO. No prior\nwork related to social media mining has focused on the development of a dataset\nof Instagram posts about the mpox outbreak. The work presented in this paper\naims to address this research gap and makes two scientific contributions to\nthis field. First, it presents a multilingual dataset of 60,127 Instagram posts\nabout mpox, published between July 23, 2022, and September 5, 2024. The\ndataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram\nposts about mpox in 52 languages. For each of these posts, the Post ID, Post\nDescription, Date of publication, language, and translated version of the post\n(translation to English was performed using the Google Translate API) are\npresented as separate attributes in the dataset. After developing this dataset,\nsentiment analysis, hate speech detection, and anxiety or stress detection were\nperformed. This process included classifying each post into (i) one of the\nsentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or\nneutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no\nanxiety/stress detected. These results are presented as separate attributes in\nthe dataset. Second, this paper presents the results of performing sentiment\nanalysis, hate speech analysis, and anxiety or stress analysis. The variation\nof the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and\nneutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and\n50.64%, respectively. In terms of hate speech detection, 95.75% of the posts\ndid not contain hate and the remaining 4.25% of the posts contained hate.\nFinally, 72.05% of the posts did not indicate any anxiety/stress, and the\nremaining 27.95% of the posts represented some form of anxiety/stress.",
      "tldr_zh": "这篇论文构建了一个多语言数据集，包含60,127条关于mpox疫情的Instagram帖子，覆盖52种语言，并包括帖子ID、描述、发布日期、语言和英文翻译（使用Google Translate API）。论文的主要贡献是进行sentiment analysis、hate speech detection和anxiety/stress detection，将帖子分类为fear、surprise、joy、sadness、anger、disgust或neutral情感，以及检测仇恨言论和焦虑/压力。分析结果显示，neutral情感占比最高（50.64%），fear占比27.95%，仇恨言论占比4.25%，而anxiety/stress检测率为27.95%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.SI",
        "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05292v4",
      "published_date": "2024-09-09 03:00:53 UTC",
      "updated_date": "2024-10-11 17:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:38:45.657087"
    },
    {
      "arxiv_id": "2409.05286v3",
      "title": "Seek and Solve Reasoning for Table Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ruya Jiang",
        "Chun Wang",
        "Weihong Deng"
      ],
      "abstract": "The complexities of table structures and question logic make table-based\nquestion answering (TQA) tasks challenging for Large Language Models (LLMs),\noften requiring task simplification before solving. This paper reveals that the\nreasoning process during task simplification may be more valuable than the\nsimplified tasks themselves and aims to improve TQA performance by leveraging\nLLMs' reasoning capabilities. We propose a Seek-and-Solve pipeline that\ninstructs the LLM to first seek relevant information and then answer questions,\nintegrating these two stages at the reasoning level into a coherent\nSeek-and-Solve Chain of Thought (SS-CoT). Additionally, we distill a\nsingle-step TQA-solving prompt from this pipeline, using demonstrations with\nSS-CoT paths to guide the LLM in solving complex TQA tasks under In-Context\nLearning settings. Our experiments show that our approaches result in improved\nperformance and reliability while being efficient. Our findings emphasize the\nimportance of eliciting LLMs' reasoning capabilities to handle complex TQA\ntasks effectively.",
      "tldr_zh": "本论文针对表-based question answering (TQA) 的复杂性（如表结构和问题逻辑），提出利用Large Language Models (LLMs) 的推理能力来提升性能，而不是单纯简化任务。研究者开发了Seek-and-Solve pipeline，该方法指导LLM 先寻找相关信息，然后回答问题，并将这两个阶段整合成一个连贯的Seek-and-Solve Chain of Thought (SS-CoT)。此外，他们从该pipeline中提炼出单步TQA解决提示，使用SS-CoT路径的In-Context Learning演示来处理复杂任务。实验结果显示，这种方法显著提高了TQA的性能和可靠性，同时保持高效，并强调了激发LLMs推理能力的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in: ICASSP 2025 - 2025 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP)",
      "pdf_url": "http://arxiv.org/pdf/2409.05286v3",
      "published_date": "2024-09-09 02:41:00 UTC",
      "updated_date": "2025-04-20 13:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:38:57.255747"
    },
    {
      "arxiv_id": "2409.05283v2",
      "title": "On the Relationship between Truth and Political Bias in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Suyash Fulay",
        "William Brannon",
        "Shrestha Mohanty",
        "Cassandra Overney",
        "Elinor Poole-Dayan",
        "Deb Roy",
        "Jad Kabbara"
      ],
      "abstract": "Language model alignment research often attempts to ensure that models are\nnot only helpful and harmless, but also truthful and unbiased. However,\noptimizing these objectives simultaneously can obscure how improving one aspect\nmight impact the others. In this work, we focus on analyzing the relationship\nbetween two concepts essential in both language model alignment and political\nscience: truthfulness and political bias. We train reward models on various\npopular truthfulness datasets and subsequently evaluate their political bias.\nOur findings reveal that optimizing reward models for truthfulness on these\ndatasets tends to result in a left-leaning political bias. We also find that\nexisting open-source reward models (i.e., those trained on standard human\npreference datasets) already show a similar bias and that the bias is larger\nfor larger models. These results raise important questions about the datasets\nused to represent truthfulness, potential limitations of aligning models to be\nboth truthful and politically unbiased, and what language models capture about\nthe relationship between truth and politics.",
      "tldr_zh": "本文研究探讨了语言模型中truthfulness（真实性）和political bias（政治偏见）之间的关系，强调优化truthfulness可能导致political bias的增加。研究团队通过在各种truthfulness数据集上训练reward models，并评估其political bias，发现这些模型倾向于产生left-leaning political bias。结果显示，现有开源reward models也存在类似偏见，且模型规模越大，偏见越明显。这些发现质疑了当前truthfulness数据集的代表性和语言模型同时实现truthful与politically unbiased的潜在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.05283v2",
      "published_date": "2024-09-09 02:28:53 UTC",
      "updated_date": "2024-10-11 20:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:39:08.965664"
    },
    {
      "arxiv_id": "2409.05280v2",
      "title": "RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation",
      "title_zh": "RotCAtt-TransUNet++：用于复杂心脏分割的新型深度神经网络",
      "authors": [
        "Quoc-Bao Nguyen-Le",
        "Tuan-Hy Le",
        "Anh-Triet Do",
        "Quoc-Huy Trinh"
      ],
      "abstract": "Cardiovascular disease remains a predominant global health concern,\nresponsible for a significant portion of mortality worldwide. Accurate\nsegmentation of cardiac medical imaging data is pivotal in mitigating fatality\nrates associated with cardiovascular conditions. However, existing\nstate-of-the-art (SOTA) neural networks, including both CNN-based and\nTransformer-based approaches, exhibit limitations in practical applicability\ndue to their inability to effectively capture inter-slice connections alongside\nintra-slice information. This deficiency is particularly evident in datasets\nfeaturing intricate, long-range details along the z-axis, such as coronary\narteries in axial views. Additionally, SOTA methods fail to differentiate\nnon-cardiac components from myocardium in segmentation, leading to the\n\"spraying\" phenomenon. To address these challenges, we present\nRotCAtt-TransUNet++, a novel architecture tailored for robust segmentation of\ncomplex cardiac structures. Our approach emphasizes modeling global contexts by\naggregating multiscale features with nested skip connections in the encoder. It\nintegrates transformer layers to capture interactions between patches and\nemploys a rotatory attention mechanism to capture connectivity between multiple\nslices (inter-slice information). Additionally, a channel-wise cross-attention\ngate guides the fused multi-scale channel-wise information and features from\ndecoder stages to bridge semantic gaps. Experimental results demonstrate that\nour proposed model outperforms existing SOTA approaches across four cardiac\ndatasets and one abdominal dataset. Importantly, coronary arteries and\nmyocardium are annotated with near-perfect accuracy during inference. An\nablation study shows that the rotatory attention mechanism effectively\ntransforms embedded vectorized patches in the semantic dimensional space,\nenhancing segmentation accuracy.",
      "tldr_zh": "本研究针对心血管疾病的诊断需求，提出了一种新型深度神经网络RotCAtt-TransUNet++，以解决现有SOTA模型（如CNN-based和Transformer-based方法）在心脏图像分割中的局限性，包括无法有效捕捉层间（inter-slice）和层内（intra-slice）信息，以及“spraying”现象导致的非心脏成分误识别。模型通过在编码器中聚合多尺度特征并使用嵌套跳跃连接建模全局上下文，结合Transformer层捕捉patch交互、rotatory attention机制处理多层连接，以及channel-wise cross-attention gate融合多尺度信息以桥接语义差距。实验结果显示，该模型在四个心脏数据集和一个腹部数据集上优于现有SOTA方法，实现了冠状动脉和心肌的近乎完美分割精度；消融研究进一步证实rotatory attention机制显著提升了分割准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.05280v2",
      "published_date": "2024-09-09 02:18:50 UTC",
      "updated_date": "2024-10-23 04:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:39:22.566801"
    },
    {
      "arxiv_id": "2409.05279v1",
      "title": "BrainDecoder: Style-Based Visual Decoding of EEG Signals",
      "title_zh": "BrainDecoder: 基于风格的 EEG 信号视觉解码",
      "authors": [
        "Minsuk Choi",
        "Hiroshi Ishikawa"
      ],
      "abstract": "Decoding neural representations of visual stimuli from electroencephalography\n(EEG) offers valuable insights into brain activity and cognition. Recent\nadvancements in deep learning have significantly enhanced the field of visual\ndecoding of EEG, primarily focusing on reconstructing the semantic content of\nvisual stimuli. In this paper, we present a novel visual decoding pipeline\nthat, in addition to recovering the content, emphasizes the reconstruction of\nthe style, such as color and texture, of images viewed by the subject. Unlike\nprevious methods, this ``style-based'' approach learns in the CLIP spaces of\nimage and text separately, facilitating a more nuanced extraction of\ninformation from EEG signals. We also use captions for text alignment simpler\nthan previously employed, which we find work better. Both quantitative and\nqualitative evaluations show that our method better preserves the style of\nvisual stimuli and extracts more fine-grained semantic information from neural\nsignals. Notably, it achieves significant improvements in quantitative results\nand sets a new state-of-the-art on the popular Brain2Image dataset.",
      "tldr_zh": "本文提出BrainDecoder，一种基于风格的视觉解码方法，用于从EEG信号中重建视觉刺激的内容和风格（如颜色和纹理），从而提供更细粒度的神经表示提取。不同于以往方法，该框架在CLIP的图像和文本空间中分别学习，并采用更简单的标题进行文本对齐，以提升信息提取效率。定量和定性评估表明，BrainDecoder在Brain2Image数据集上显著改善了风格保留和语义信息提取性能，设定了新的最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.05279v1",
      "published_date": "2024-09-09 02:14:23 UTC",
      "updated_date": "2024-09-09 02:14:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:39:33.318723"
    },
    {
      "arxiv_id": "2409.05277v1",
      "title": "Disentangled Representations for Short-Term and Long-Term Person Re-Identification",
      "title_zh": "针对短期和长期人重识别的解耦表示",
      "authors": [
        "Chanho Eom",
        "Wonkyung Lee",
        "Geon Lee",
        "Bumsub Ham"
      ],
      "abstract": "We address the problem of person re-identification (reID), that is,\nretrieving person images from a large dataset, given a query image of the\nperson of interest. A key challenge is to learn person representations robust\nto intra-class variations, as different persons could have the same attribute,\nand persons' appearances look different, e.g., with viewpoint changes. Recent\nreID methods focus on learning person features discriminative only for a\nparticular factor of variations (e.g., human pose), which also requires\ncorresponding supervisory signals (e.g., pose annotations). To tackle this\nproblem, we propose to factorize person images into identity-related and\nunrelated features. Identity-related features contain information useful for\nspecifying a particular person (e.g., clothing), while identity-unrelated ones\nhold other factors (e.g., human pose). To this end, we propose a new generative\nadversarial network, dubbed identity shuffle GAN (IS-GAN). It disentangles\nidentity-related and unrelated features from person images through an\nidentity-shuffling technique that exploits identification labels alone without\nany auxiliary supervisory signals. We restrict the distribution of\nidentity-unrelated features or encourage the identity-related and unrelated\nfeatures to be uncorrelated, facilitating the disentanglement process.\nExperimental results validate the effectiveness of IS-GAN, showing\nstate-of-the-art performance on standard reID benchmarks, including\nMarket-1501, CUHK03, and DukeMTMC-reID. We further demonstrate the advantages\nof disentangling person representations on a long-term reID task, setting a new\nstate of the art on a Celeb-reID dataset.",
      "tldr_zh": "该论文针对人重新识别（reID）问题，提出了一种分解表示（disentangled representations）的方法，以应对类内变异（如视角变化和属性相似性）。他们设计了identity shuffle GAN (IS-GAN)，通过身份混洗技术仅使用身份标签，就将人图像分解为身份相关特征（如服装）和身份无关特征（如姿势），并通过限制无关特征分布和鼓励特征间不相关来促进分解过程。实验结果显示，IS-GAN 在标准基准如 Market-1501、CUHK03 和 DukeMTMC-reID 上达到了 state-of-the-art 性能，并在长期 reID 任务（如 Celeb-reID 数据集）上设置了新记录，证明了该方法在鲁棒性方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:1910.12003",
      "pdf_url": "http://arxiv.org/pdf/2409.05277v1",
      "published_date": "2024-09-09 02:09:49 UTC",
      "updated_date": "2024-09-09 02:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:39:46.579715"
    },
    {
      "arxiv_id": "2409.05923v1",
      "title": "$\\mathbb{USCD}$: Improving Code Generation of LLMs by Uncertainty-Aware Selective Contrastive Decoding",
      "title_zh": "$\\mathbb{USCD}$：通过不确定性感知的选择性对比解码改善大型语言模型的代码生成",
      "authors": [
        "Shuai Wang",
        "Liang Ding",
        "Li Shen",
        "Yong Luo",
        "Zheng He",
        "Wei Yu",
        "Dacheng Tao"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable capabilities in code\ngeneration. However, the effects of hallucinations (e.g., output noise) make it\nparticularly challenging for LLMs to generate high-quality code in one pass. In\nthis work, we propose a simple and effective \\textbf{u}ncertainty-aware\n\\textbf{s}elective \\textbf{c}ontrastive \\textbf{d}ecoding ($\\mathbb{USCD}$)\nmechanism to improve the quality of one-pass code generation in LLMs and reduce\nthe impact of output noise. To be specific, we first elaborately designed a\nnegative prompt (namely lame prompt) to output noise by removing input-output\nexamples from the standard few-shot prompt. Our preliminary study shows that\nthe Jensen-Shannon divergence (JS divergence) between token distribution\nuncertainty and the output noise is relatively low (approximately $0.25$),\nindicating their high relevance. Then, we selectively eliminate output noise\ninduced by lame prompts based on the uncertainty of the prediction distribution\nfrom the standard prompt. Notably, our proposed plug-and-play mechanism is an\ninference-only method, enjoying appealing flexibility. Extensive experiments on\nwidely used benchmarks, e.g., HumanEval, MBPP, and MultiPL-E, upon several LLMs\n(i.e., Inocder-6b, CodeLlama-7b, WizardCoder-15b, StarCoder, and Llama2-7b),\ndemonstrate that our proposed USCD significantly improves one-pass code\ngeneration, with an average \\textit{pass@$1$} scores increase of 16.59\\%. We\nwill release code and data on GitHub.",
      "tldr_zh": "本研究提出了一种名为 $\\mathbb{USCD}$ 的机制，通过不确定性感知选择性对比解码（Uncertainty-Aware Selective Contrastive Decoding）来提升大语言模型（LLMs）在代码生成中的性能，减少输出噪声的影响。方法包括设计一个负向提示（lame prompt），通过移除标准 few-shot prompt 中的输入输出示例，并利用 Jensen-Shannon divergence (JS divergence) 分析 token 分布不确定性与噪声的相关性（约为 0.25），从而选择性地消除噪声。实验在 HumanEval、MBPP 和 MultiPL-E 等基准上，使用 Inocder-6b、CodeLlama-7b 等模型，显示 $\\mathbb{USCD}$ 使 pass@1 得分平均提高了 16.59%。该机制作为 plug-and-play 的推理-only 方法，具有高度灵活性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "13pages,8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.05923v1",
      "published_date": "2024-09-09 02:07:41 UTC",
      "updated_date": "2024-09-09 02:07:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:39:57.646678"
    },
    {
      "arxiv_id": "2409.05265v1",
      "title": "Learning Submodular Sequencing from Samples",
      "title_zh": "从样本中学习子模序列",
      "authors": [
        "Jing Yuan",
        "Shaojie Tang"
      ],
      "abstract": "This paper addresses the problem of sequential submodular maximization:\nselecting and ranking items in a sequence to optimize some composite submodular\nfunction. In contrast to most of the previous works, which assume access to the\nutility function, we assume that we are given only a set of samples. Each\nsample includes a random sequence of items and its associated utility. We\npresent an algorithm that, given polynomially many samples drawn from a\ntwo-stage uniform distribution, achieves an approximation ratio dependent on\nthe curvature of individual submodular functions. Our results apply in a wide\nvariety of real-world scenarios, such as ranking products in online retail\nplatforms, where complete knowledge of the utility function is often impossible\nto obtain. Our algorithm gives an empirically useful solution in such contexts,\nthus proving that limited data can be of great use in sequencing tasks. From a\ntechnical perspective, our results extend prior work on ``optimization from\nsamples'' by generalizing from optimizing a set function to a\nsequence-dependent function.",
      "tldr_zh": "这篇论文解决了顺序子模函数（submodular）最大化问题，即从样本中学习选择和排序项目以优化复合子模函数，而非直接访问效用函数。作者提出了一种算法，利用从两阶段均匀分布中抽取的多项式数量样本，实现了依赖于单个子模函数曲率（curvature）的近似比率（approximation ratio）。实验结果表明，该方法在实际场景如在线零售平台的商品排名中提供实用的解决方案，并扩展了之前的“从样本优化”（optimization from samples）工作，从集合函数优化扩展到依赖序列的函数，从而证明有限数据在排序任务中的重要价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05265v1",
      "published_date": "2024-09-09 01:33:13 UTC",
      "updated_date": "2024-09-09 01:33:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:40:09.218149"
    },
    {
      "arxiv_id": "2409.05258v1",
      "title": "Towards Automated Machine Learning Research",
      "title_zh": "翻译失败",
      "authors": [
        "Shervin Ardeshir"
      ],
      "abstract": "This paper explores a top-down approach to automating incremental advances in\nmachine learning research through component-level innovation, facilitated by\nLarge Language Models (LLMs). Our framework systematically generates novel\ncomponents, validates their feasibility, and evaluates their performance\nagainst existing baselines. A key distinction of this approach lies in how\nthese novel components are generated. Unlike traditional AutoML and NAS\nmethods, which often rely on a bottom-up combinatorial search over predefined,\nhardcoded base components, our method leverages the cross-domain knowledge\nembedded in LLMs to propose new components that may not be confined to any\nhard-coded predefined set. By incorporating a reward model to prioritize\npromising hypotheses, we aim to improve the efficiency of the hypothesis\ngeneration and evaluation process. We hope this approach offers a new avenue\nfor exploration and contributes to the ongoing dialogue in the field.",
      "tldr_zh": "这篇论文提出了一种自顶向下的框架，利用大型语言模型(LLMs)来自动化机器学习研究的组件级创新，通过系统生成新组件、验证可行性和评估性能来推动渐进式进展。不同于传统AutoML和NAS方法，该框架不局限于预定义的组件，而是借助LLMs的跨领域知识生成更灵活的新假设，并通过奖励模型优先筛选有前景的选项以提高效率。该方法为机器学习研究提供了新的探索路径，并有望促进领域的持续对话。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.05258v1",
      "published_date": "2024-09-09 00:47:30 UTC",
      "updated_date": "2024-09-09 00:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:40:21.508131"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 107,
  "processed_papers_count": 107,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T22:40:46.743234"
}