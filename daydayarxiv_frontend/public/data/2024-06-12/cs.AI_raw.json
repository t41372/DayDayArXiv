[
  {
    "arxiv_id": "2406.08695v1",
    "title": "Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis",
    "authors": [
      "Attrayee Chakraborty",
      "Mandar Karhade"
    ],
    "abstract": "Artificial Intelligence (AI) is being adopted across the world and promises a\nnew revolution in healthcare. While AI-enabled medical devices in North America\ndominate 42.3% of the global market, the use of AI-enabled medical devices in\nother countries is still a story waiting to be unfolded. We aim to delve deeper\ninto global regulatory approaches towards AI use in healthcare, with a focus on\nhow common themes are emerging globally. We compare these themes to the World\nHealth Organization's (WHO) regulatory considerations and principles on ethical\nuse of AI for healthcare applications. Our work seeks to take a global\nperspective on AI policy by analyzing 14 legal jurisdictions including\ncountries representative of various regions in the world (North America, South\nAmerica, South East Asia, Middle East, Africa, Australia, and the\nAsia-Pacific). Our eventual goal is to foster a global conversation on the\nethical use of AI in healthcare and the regulations that will guide it. We\npropose solutions to promote international harmonization of AI regulations and\nexamine the requirements for regulating generative AI, using China and\nSingapore as examples of countries with well-developed policies in this area.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "K.4.1, K.6, K.5.2, J.3"
    ],
    "primary_category": "cs.CY",
    "comment": "32 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.08695v1",
    "published_date": "2024-06-12 23:36:16 UTC",
    "updated_date": "2024-06-12 23:36:16 UTC"
  },
  {
    "arxiv_id": "2406.08691v1",
    "title": "UnO: Unsupervised Occupancy Fields for Perception and Forecasting",
    "authors": [
      "Ben Agro",
      "Quinlan Sykora",
      "Sergio Casas",
      "Thomas Gilles",
      "Raquel Urtasun"
    ],
    "abstract": "Perceiving the world and forecasting its future state is a critical task for\nself-driving. Supervised approaches leverage annotated object labels to learn a\nmodel of the world -- traditionally with object detections and trajectory\npredictions, or temporal bird's-eye-view (BEV) occupancy fields. However, these\nannotations are expensive and typically limited to a set of predefined\ncategories that do not cover everything we might encounter on the road.\nInstead, we learn to perceive and forecast a continuous 4D (spatio-temporal)\noccupancy field with self-supervision from LiDAR data. This unsupervised world\nmodel can be easily and effectively transferred to downstream tasks. We tackle\npoint cloud forecasting by adding a lightweight learned renderer and achieve\nstate-of-the-art performance in Argoverse 2, nuScenes, and KITTI. To further\nshowcase its transferability, we fine-tune our model for BEV semantic occupancy\nforecasting and show that it outperforms the fully supervised state-of-the-art,\nespecially when labeled data is scarce. Finally, when compared to prior\nstate-of-the-art on spatio-temporal geometric occupancy prediction, our 4D\nworld model achieves a much higher recall of objects from classes relevant to\nself-driving.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08691v1",
    "published_date": "2024-06-12 23:22:23 UTC",
    "updated_date": "2024-06-12 23:22:23 UTC"
  },
  {
    "arxiv_id": "2406.08689v3",
    "title": "Security of AI Agents",
    "authors": [
      "Yifeng He",
      "Ethan Wang",
      "Yuyang Rong",
      "Zifei Cheng",
      "Hao Chen"
    ],
    "abstract": "AI agents have been boosted by large language models. AI agents can function\nas intelligent assistants and complete tasks on behalf of their users with\naccess to tools and the ability to execute commands in their environments.\nThrough studying and experiencing the workflow of typical AI agents, we have\nraised several concerns regarding their security. These potential\nvulnerabilities are not addressed by the frameworks used to build the agents,\nnor by research aimed at improving the agents. In this paper, we identify and\ndescribe these vulnerabilities in detail from a system security perspective,\nemphasizing their causes and severe effects. Furthermore, we introduce defense\nmechanisms corresponding to each vulnerability with design and experiments to\nevaluate their viability. Altogether, this paper contextualizes the security\nissues in the current development of AI agents and delineates methods to make\nAI agents safer and more reliable.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "updated version with figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08689v3",
    "published_date": "2024-06-12 23:16:45 UTC",
    "updated_date": "2024-12-17 21:58:19 UTC"
  },
  {
    "arxiv_id": "2406.08688v1",
    "title": "On Security Weaknesses and Vulnerabilities in Deep Learning Systems",
    "authors": [
      "Zhongzheng Lai",
      "Huaming Chen",
      "Ruoxi Sun",
      "Yu Zhang",
      "Minhui Xue",
      "Dong Yuan"
    ],
    "abstract": "The security guarantee of AI-enabled software systems (particularly using\ndeep learning techniques as a functional core) is pivotal against the\nadversarial attacks exploiting software vulnerabilities. However, little\nattention has been paid to a systematic investigation of vulnerabilities in\nsuch systems. A common situation learned from the open source software\ncommunity is that deep learning engineers frequently integrate off-the-shelf or\nopen-source learning frameworks into their ecosystems. In this work, we\nspecifically look into deep learning (DL) framework and perform the first\nsystematic study of vulnerabilities in DL systems through a comprehensive\nanalysis of identified vulnerabilities from Common Vulnerabilities and\nExposures (CVE) and open-source DL tools, including TensorFlow, Caffe, OpenCV,\nKeras, and PyTorch. We propose a two-stream data analysis framework to explore\nvulnerability patterns from various databases. We investigate the unique DL\nframeworks and libraries development ecosystems that appear to be decentralized\nand fragmented. By revisiting the Common Weakness Enumeration (CWE) List, which\nprovides the traditional software vulnerability related practices, we observed\nthat it is more challenging to detect and fix the vulnerabilities throughout\nthe DL systems lifecycle. Moreover, we conducted a large-scale empirical study\nof 3,049 DL vulnerabilities to better understand the patterns of vulnerability\nand the challenges in fixing them. We have released the full replication\npackage at https://github.com/codelzz/Vulnerabilities4DLSystem. We anticipate\nthat our study can advance the development of secure DL systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08688v1",
    "published_date": "2024-06-12 23:04:13 UTC",
    "updated_date": "2024-06-12 23:04:13 UTC"
  },
  {
    "arxiv_id": "2406.08687v1",
    "title": "AlphaZeroES: Direct score maximization outperforms planning loss minimization",
    "authors": [
      "Carlos Martin",
      "Tuomas Sandholm"
    ],
    "abstract": "Planning at execution time has been shown to dramatically improve performance\nfor agents in both single-agent and multi-agent settings. A well-known family\nof approaches to planning at execution time are AlphaZero and its variants,\nwhich use Monte Carlo Tree Search together with a neural network that guides\nthe search by predicting state values and action probabilities. AlphaZero\ntrains these networks by minimizing a planning loss that makes the value\nprediction match the episode return, and the policy prediction at the root of\nthe search tree match the output of the full tree expansion. AlphaZero has been\napplied to both single-agent environments (such as Sokoban) and multi-agent\nenvironments (such as chess and Go) with great success. In this paper, we\nexplore an intriguing question: In single-agent environments, can we outperform\nAlphaZero by directly maximizing the episode score instead of minimizing this\nplanning loss, while leaving the MCTS algorithm and neural architecture\nunchanged? To directly maximize the episode score, we use evolution strategies,\na family of algorithms for zeroth-order blackbox optimization. Our experiments\nindicate that, across multiple environments, directly maximizing the episode\nscore outperforms minimizing the planning loss.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2308.08693",
    "pdf_url": "http://arxiv.org/pdf/2406.08687v1",
    "published_date": "2024-06-12 23:00:59 UTC",
    "updated_date": "2024-06-12 23:00:59 UTC"
  },
  {
    "arxiv_id": "2406.10290v1",
    "title": "MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases",
    "authors": [
      "Rithesh Murthy",
      "Liangwei Yang",
      "Juntao Tan",
      "Tulika Manoj Awalgaonkar",
      "Yilun Zhou",
      "Shelby Heinecke",
      "Sachin Desai",
      "Jason Wu",
      "Ran Xu",
      "Sarah Tan",
      "Jianguo Zhang",
      "Zhiwei Liu",
      "Shirley Kokane",
      "Zuxin Liu",
      "Ming Zhu",
      "Huan Wang",
      "Caiming Xiong",
      "Silvio Savarese"
    ],
    "abstract": "The deployment of Large Language Models (LLMs) and Large Multimodal Models\n(LMMs) on mobile devices has gained significant attention due to the benefits\nof enhanced privacy, stability, and personalization. However, the hardware\nconstraints of mobile devices necessitate the use of models with fewer\nparameters and model compression techniques like quantization. Currently, there\nis limited understanding of quantization's impact on various task performances,\nincluding LLM tasks, LMM tasks, and, critically, trust and safety. There is a\nlack of adequate tools for systematically testing these models on mobile\ndevices. To address these gaps, we introduce MobileAIBench, a comprehensive\nbenchmarking framework for evaluating mobile-optimized LLMs and LMMs.\nMobileAIBench assesses models across different sizes, quantization levels, and\ntasks, measuring latency and resource consumption on real devices. Our two-part\nopen-source framework includes a library for running evaluations on desktops\nand an iOS app for on-device latency and hardware utilization measurements. Our\nthorough analysis aims to accelerate mobile AI research and deployment by\nproviding insights into the performance and feasibility of deploying LLMs and\nLMMs on mobile platforms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10290v1",
    "published_date": "2024-06-12 22:58:12 UTC",
    "updated_date": "2024-06-12 22:58:12 UTC"
  },
  {
    "arxiv_id": "2406.08673v1",
    "title": "HelpSteer2: Open-source dataset for training top-performing reward models",
    "authors": [
      "Zhilin Wang",
      "Yi Dong",
      "Olivier Delalleau",
      "Jiaqi Zeng",
      "Gerald Shen",
      "Daniel Egert",
      "Jimmy J. Zhang",
      "Makesh Narsimhan Sreedhar",
      "Oleksii Kuchaiev"
    ],
    "abstract": "High-quality preference datasets are essential for training reward models\nthat can effectively guide large language models (LLMs) in generating\nhigh-quality responses aligned with human preferences. As LLMs become stronger\nand better aligned, permissively licensed preference datasets, such as Open\nAssistant, HH-RLHF, and HelpSteer need to be updated to remain effective for\nreward modeling. Methods that distil preference data from proprietary LLMs such\nas GPT-4 have restrictions on commercial usage imposed by model providers. To\nimprove upon both generated responses and attribute labeling quality, we\nrelease HelpSteer2, a permissively licensed preference dataset (CC-BY-4.0).\nUsing a powerful internal base model trained on HelpSteer2, we are able to\nachieve the SOTA score (92.0%) on Reward-Bench's primary dataset, outperforming\ncurrently listed open and proprietary models, as of June 12th, 2024. Notably,\nHelpSteer2 consists of only ten thousand response pairs, an order of magnitude\nfewer than existing preference datasets (e.g., HH-RLHF), which makes it highly\nefficient for training reward models. Our extensive experiments demonstrate\nthat reward models trained with HelpSteer2 are effective in aligning LLMs. In\nparticular, we propose SteerLM 2.0, a model alignment approach that can\neffectively make use of the rich multi-attribute score predicted by our reward\nmodels. HelpSteer2 is available at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2 and code is available at\nhttps://github.com/NVIDIA/NeMo-Aligner",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08673v1",
    "published_date": "2024-06-12 22:28:08 UTC",
    "updated_date": "2024-06-12 22:28:08 UTC"
  },
  {
    "arxiv_id": "2406.08666v2",
    "title": "Interventional Causal Discovery in a Mixture of DAGs",
    "authors": [
      "Burak Varıcı",
      "Dmitriy Katz-Rogozhnikov",
      "Dennis Wei",
      "Prasanna Sattigeri",
      "Ali Tajer"
    ],
    "abstract": "Causal interactions among a group of variables are often modeled by a single\ncausal graph. In some domains, however, these interactions are best described\nby multiple co-existing causal graphs, e.g., in dynamical systems or genomics.\nThis paper addresses the hitherto unknown role of interventions in learning\ncausal interactions among variables governed by a mixture of causal systems,\neach modeled by one directed acyclic graph (DAG). Causal discovery from\nmixtures is fundamentally more challenging than single-DAG causal discovery.\nTwo major difficulties stem from (i)~an inherent uncertainty about the\nskeletons of the component DAGs that constitute the mixture and (ii)~possibly\ncyclic relationships across these component DAGs. This paper addresses these\nchallenges and aims to identify edges that exist in at least one component DAG\nof the mixture, referred to as the true edges. First, it establishes matching\nnecessary and sufficient conditions on the size of interventions required to\nidentify the true edges. Next, guided by the necessity results, an adaptive\nalgorithm is designed that learns all true edges using $O(n^2)$ interventions,\nwhere $n$ is the number of nodes. Remarkably, the size of the interventions is\noptimal if the underlying mixture model does not contain cycles across its\ncomponents. More generally, the gap between the intervention size used by the\nalgorithm and the optimal size is quantified. It is shown to be bounded by the\ncyclic complexity number of the mixture model, defined as the size of the\nminimal intervention that can break the cycles in the mixture, which is upper\nbounded by the number of cycles among the ancestors of a node.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2406.08666v2",
    "published_date": "2024-06-12 22:12:03 UTC",
    "updated_date": "2024-12-03 04:22:40 UTC"
  },
  {
    "arxiv_id": "2406.08665v2",
    "title": "Data Augmentation by Fuzzing for Neural Test Generation",
    "authors": [
      "Yifeng He",
      "Jicheng Wang",
      "Yuyang Rong",
      "Hao Chen"
    ],
    "abstract": "Testing is essential to modern software engineering for building reliable\nsoftware. Given the high costs of manually creating test cases, automated test\ncase generation, particularly methods utilizing large language models, has\nbecome increasingly popular. These neural approaches generate semantically\nmeaningful tests that are more maintainable compared with traditional automatic\ntesting methods like fuzzing. However, the diversity and volume of unit tests\nin current datasets are limited. In this paper, we introduce a novel data\naugmentation technique, *FuzzAug*, that introduces the benefits of fuzzing to\nlarge language models to preserve valid program semantics and provide diverse\ninputs. This enhances the model's ability to embed correct inputs that can\nexplore more branches of the function under test. Our evaluations show that\nmodels trained with dataset augmented by FuzzAug increase assertion accuracy by\n5%, improve compilation rate by more than 10%, and generate unit test functions\nwith 5% more branch coverage. This technique demonstrates the potential of\nusing dynamic software testing to improve neural test generation, offering\nsignificant enhancements in neural test generation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Revised version",
    "pdf_url": "http://arxiv.org/pdf/2406.08665v2",
    "published_date": "2024-06-12 22:09:27 UTC",
    "updated_date": "2024-09-13 18:05:46 UTC"
  },
  {
    "arxiv_id": "2406.09459v1",
    "title": "Ad Auctions for LLMs via Retrieval Augmented Generation",
    "authors": [
      "MohammadTaghi Hajiaghayi",
      "Sébastien Lahaie",
      "Keivan Rezaei",
      "Suho Shin"
    ],
    "abstract": "In the field of computational advertising, the integration of ads into the\noutputs of large language models (LLMs) presents an opportunity to support\nthese services without compromising content integrity. This paper introduces\nnovel auction mechanisms for ad allocation and pricing within the textual\noutputs of LLMs, leveraging retrieval-augmented generation (RAG). We propose a\nsegment auction where an ad is probabilistically retrieved for each discourse\nsegment (paragraph, section, or entire output) according to its bid and\nrelevance, following the RAG framework, and priced according to competing bids.\nWe show that our auction maximizes logarithmic social welfare, a new notion of\nwelfare that balances allocation efficiency and fairness, and we characterize\nthe associated incentive-compatible pricing rule. These results are extended to\nmulti-ad allocation per segment. An empirical evaluation validates the\nfeasibility and effectiveness of our approach over several ad auction\nscenarios, and exhibits inherent tradeoffs in metrics as we allow the LLM more\nflexibility to allocate ads.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.09459v1",
    "published_date": "2024-06-12 22:05:51 UTC",
    "updated_date": "2024-06-12 22:05:51 UTC"
  },
  {
    "arxiv_id": "2406.08660v2",
    "title": "Fine-Tuned 'Small' LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in Text Classification",
    "authors": [
      "Martin Juan José Bucher",
      "Marco Martini"
    ],
    "abstract": "Generative AI offers a simple, prompt-based alternative to fine-tuning\nsmaller BERT-style LLMs for text classification tasks. This promises to\neliminate the need for manually labeled training data and task-specific model\ntraining. However, it remains an open question whether tools like ChatGPT can\ndeliver on this promise. In this paper, we show that smaller, fine-tuned LLMs\n(still) consistently and significantly outperform larger, zero-shot prompted\nmodels in text classification. We compare three major generative AI models\n(ChatGPT with GPT-3.5/GPT-4 and Claude Opus) with several fine-tuned LLMs\nacross a diverse set of classification tasks (sentiment, approval/disapproval,\nemotions, party positions) and text categories (news, tweets, speeches). We\nfind that fine-tuning with application-specific training data achieves superior\nperformance in all cases. To make this approach more accessible to a broader\naudience, we provide an easy-to-use toolkit alongside this paper. Our toolkit,\naccompanied by non-technical step-by-step guidance, enables users to select and\nfine-tune BERT-like LLMs for any classification task with minimal technical and\ncomputational effort.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08660v2",
    "published_date": "2024-06-12 21:46:13 UTC",
    "updated_date": "2024-08-16 15:33:23 UTC"
  },
  {
    "arxiv_id": "2406.08656v1",
    "title": "TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and Image-to-Video Generation",
    "authors": [
      "Weixi Feng",
      "Jiachen Li",
      "Michael Saxon",
      "Tsu-jui Fu",
      "Wenhu Chen",
      "William Yang Wang"
    ],
    "abstract": "Video generation has many unique challenges beyond those of image generation.\nThe temporal dimension introduces extensive possible variations across frames,\nover which consistency and continuity may be violated. In this study, we move\nbeyond evaluating simple actions and argue that generated videos should\nincorporate the emergence of new concepts and their relation transitions like\nin real-world videos as time progresses. To assess the Temporal\nCompositionality of video generation models, we propose TC-Bench, a benchmark\nof meticulously crafted text prompts, corresponding ground truth videos, and\nrobust evaluation metrics. The prompts articulate the initial and final states\nof scenes, effectively reducing ambiguities for frame development and\nsimplifying the assessment of transition completion. In addition, by collecting\naligned real-world videos corresponding to the prompts, we expand TC-Bench's\napplicability from text-conditional models to image-conditional ones that can\nperform generative frame interpolation. We also develop new metrics to measure\nthe completeness of component transitions in generated videos, which\ndemonstrate significantly higher correlations with human judgments than\nexisting metrics. Our comprehensive experimental results reveal that most video\ngenerators achieve less than 20% of the compositional changes, highlighting\nenormous space for future improvement. Our analysis indicates that current\nvideo generation models struggle to interpret descriptions of compositional\nchanges and synthesize various components across different time steps.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08656v1",
    "published_date": "2024-06-12 21:41:32 UTC",
    "updated_date": "2024-06-12 21:41:32 UTC"
  },
  {
    "arxiv_id": "2407.09499v1",
    "title": "Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences",
    "authors": [
      "Damien Ferbach",
      "Quentin Bertrand",
      "Avishek Joey Bose",
      "Gauthier Gidel"
    ],
    "abstract": "The rapid progress in generative models has resulted in impressive leaps in\ngeneration quality, blurring the lines between synthetic and real data.\nWeb-scale datasets are now prone to the inevitable contamination by synthetic\ndata, directly impacting the training of future generated models. Already, some\ntheoretical results on self-consuming generative models (a.k.a., iterative\nretraining) have emerged in the literature, showcasing that either model\ncollapse or stability could be possible depending on the fraction of generated\ndata used at each retraining step. However, in practice, synthetic data is\noften subject to human feedback and curated by users before being used and\nuploaded online. For instance, many interfaces of popular text-to-image\ngenerative models, such as Stable Diffusion or Midjourney, produce several\nvariations of an image for a given query which can eventually be curated by the\nusers. In this paper, we theoretically study the impact of data curation on\niterated retraining of generative models and show that it can be seen as an\n\\emph{implicit preference optimization mechanism}. However, unlike standard\npreference optimization, the generative model does not have access to the\nreward function or negative samples needed for pairwise comparisons. Moreover,\nour study doesn't require access to the density function, only to samples. We\nprove that, if the data is curated according to a reward model, then the\nexpected reward of the iterative retraining procedure is maximized. We further\nprovide theoretical results on the stability of the retraining loop when using\na positive fraction of real data at each step. Finally, we conduct illustrative\nexperiments on both synthetic datasets and on CIFAR10 showing that such a\nprocedure amplifies biases of the reward model.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "68T10",
      "I.2.6"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09499v1",
    "published_date": "2024-06-12 21:28:28 UTC",
    "updated_date": "2024-06-12 21:28:28 UTC"
  },
  {
    "arxiv_id": "2406.10289v2",
    "title": "VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable Reasoning",
    "authors": [
      "Cheng Niu",
      "Yang Guan",
      "Yuanhao Wu",
      "Juno Zhu",
      "Juntong Song",
      "Randy Zhong",
      "Kaihua Zhu",
      "Siliang Xu",
      "Shizhe Diao",
      "Tong Zhang"
    ],
    "abstract": "The proliferation of fake news poses a significant threat not only by\ndisseminating misleading information but also by undermining the very\nfoundations of democracy. The recent advance of generative artificial\nintelligence has further exacerbated the challenge of distinguishing genuine\nnews from fabricated stories. In response to this challenge, we introduce\nVeraCT Scan, a novel retrieval-augmented system for fake news detection. This\nsystem operates by extracting the core facts from a given piece of news and\nsubsequently conducting an internet-wide search to identify corroborating or\nconflicting reports. Then sources' credibility is leveraged for information\nverification. Besides determining the veracity of news, we also provide\ntransparent evidence and reasoning to support its conclusions, resulting in the\ninterpretability and trust in the results. In addition to GPT-4 Turbo, Llama-2\n13B is also fine-tuned for news content understanding, information\nverification, and reasoning. Both implementations have demonstrated\nstate-of-the-art accuracy in the realm of fake news detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10289v2",
    "published_date": "2024-06-12 21:23:48 UTC",
    "updated_date": "2024-06-24 23:53:05 UTC"
  },
  {
    "arxiv_id": "2406.08651v1",
    "title": "How to Distinguish AI-Generated Images from Authentic Photographs",
    "authors": [
      "Negar Kamali",
      "Karyn Nakamura",
      "Angelos Chatzimparmpas",
      "Jessica Hullman",
      "Matthew Groh"
    ],
    "abstract": "The high level of photorealism in state-of-the-art diffusion models like\nMidjourney, Stable Diffusion, and Firefly makes it difficult for untrained\nhumans to distinguish between real photographs and AI-generated images. To\naddress this problem, we designed a guide to help readers develop a more\ncritical eye toward identifying artifacts, inconsistencies, and\nimplausibilities that often appear in AI-generated images. The guide is\norganized into five categories of artifacts and implausibilities: anatomical,\nstylistic, functional, violations of physics, and sociocultural. For this\nguide, we generated 138 images with diffusion models, curated 9 images from\nsocial media, and curated 42 real photographs. These images showcase the kinds\nof cues that prompt suspicion towards the possibility an image is AI-generated\nand why it is often difficult to draw conclusions about an image's provenance\nwithout any context beyond the pixels in an image. Human-perceptible artifacts\nare not always present in AI-generated images, but this guide reveals artifacts\nand implausibilities that often emerge. By drawing attention to these kinds of\nartifacts and implausibilities, we aim to better equip people to distinguish\nAI-generated images from real photographs in the future.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "54 pages, 189 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08651v1",
    "published_date": "2024-06-12 21:23:27 UTC",
    "updated_date": "2024-06-12 21:23:27 UTC"
  },
  {
    "arxiv_id": "2406.08644v1",
    "title": "Toward Fully-End-to-End Listened Speech Decoding from EEG Signals",
    "authors": [
      "Jihwan Lee",
      "Aditya Kommineni",
      "Tiantian Feng",
      "Kleanthis Avramidis",
      "Xuan Shi",
      "Sudarsana Kadiri",
      "Shrikanth Narayanan"
    ],
    "abstract": "Speech decoding from EEG signals is a challenging task, where brain activity\nis modeled to estimate salient characteristics of acoustic stimuli. We propose\nFESDE, a novel framework for Fully-End-to-end Speech Decoding from EEG signals.\nOur approach aims to directly reconstruct listened speech waveforms given EEG\nsignals, where no intermediate acoustic feature processing step is required.\nThe proposed method consists of an EEG module and a speech module along with a\nconnector. The EEG module learns to better represent EEG signals, while the\nspeech module generates speech waveforms from model representations. The\nconnector learns to bridge the distributions of the latent spaces of EEG and\nspeech. The proposed framework is both simple and efficient, by allowing\nsingle-step inference, and outperforms prior works on objective metrics. A\nfine-grained phoneme analysis is conducted to unveil model characteristics of\nspeech decoding. The source code is available here: github.com/lee-jhwn/fesde.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "eess.SP",
    "comment": "accepted to Interspeech2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08644v1",
    "published_date": "2024-06-12 21:08:12 UTC",
    "updated_date": "2024-06-12 21:08:12 UTC"
  },
  {
    "arxiv_id": "2406.09458v2",
    "title": "Updating CLIP to Prefer Descriptions Over Captions",
    "authors": [
      "Amir Zur",
      "Elisa Kreiss",
      "Karel D'Oosterlinck",
      "Christopher Potts",
      "Atticus Geiger"
    ],
    "abstract": "Although CLIPScore is a powerful generic metric that captures the similarity\nbetween a text and an image, it fails to distinguish between a caption that is\nmeant to complement the information in an image and a description that is meant\nto replace an image entirely, e.g., for accessibility. We address this\nshortcoming by updating the CLIP model with the Concadia dataset to assign\nhigher scores to descriptions than captions using parameter efficient\nfine-tuning and a loss objective derived from work on causal interpretability.\nThis model correlates with the judgements of blind and low-vision people while\npreserving transfer capabilities and has interpretable structure that sheds\nlight on the caption--description distinction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.09458v2",
    "published_date": "2024-06-12 20:24:51 UTC",
    "updated_date": "2024-10-03 22:10:20 UTC"
  },
  {
    "arxiv_id": "2406.08623v1",
    "title": "Emotion Manipulation Through Music -- A Deep Learning Interactive Visual Approach",
    "authors": [
      "Adel N. Abdalla",
      "Jared Osborne",
      "Razvan Andonie"
    ],
    "abstract": "Music evokes emotion in many people. We introduce a novel way to manipulate\nthe emotional content of a song using AI tools. Our goal is to achieve the\ndesired emotion while leaving the original melody as intact as possible. For\nthis, we create an interactive pipeline capable of shifting an input song into\na diametrically opposed emotion and visualize this result through Russel's\nCircumplex model. Our approach is a proof-of-concept for Semantic Manipulation\nof Music, a novel field aimed at modifying the emotional content of existing\nmusic. We design a deep learning model able to assess the accuracy of our\nmodifications to key, SoundFont instrumentation, and other musical features.\nThe accuracy of our model is in-line with the current state of the art\ntechniques on the 4Q Emotion dataset. With further refinement, this research\nmay contribute to on-demand custom music generation, the automated remixing of\nexisting work, and music playlists tuned for emotional progression.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08623v1",
    "published_date": "2024-06-12 20:12:29 UTC",
    "updated_date": "2024-06-12 20:12:29 UTC"
  },
  {
    "arxiv_id": "2406.08610v1",
    "title": "LayeredDoc: Domain Adaptive Document Restoration with a Layer Separation Approach",
    "authors": [
      "Maria Pilligua",
      "Nil Biescas",
      "Javier Vazquez-Corral",
      "Josep Lladós",
      "Ernest Valveny",
      "Sanket Biswas"
    ],
    "abstract": "The rapid evolution of intelligent document processing systems demands robust\nsolutions that adapt to diverse domains without extensive retraining.\nTraditional methods often falter with variable document types, leading to poor\nperformance. To overcome these limitations, this paper introduces a\ntext-graphic layer separation approach that enhances domain adaptability in\ndocument image restoration (DIR) systems. We propose LayeredDoc, which utilizes\ntwo layers of information: the first targets coarse-grained graphic components,\nwhile the second refines machine-printed textual content. This hierarchical DIR\nframework dynamically adjusts to the characteristics of the input document,\nfacilitating effective domain adaptation. We evaluated our approach both\nqualitatively and quantitatively using a new real-world dataset, LayeredDocDB,\ndeveloped for this study. Initially trained on a synthetically generated\ndataset, our model demonstrates strong generalization capabilities for the DIR\ntask, offering a promising solution for handling variability in real-world\ndata. Our code is accessible on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICDAR 2024 (Athens, Greece) Workshop on Automatically\n  Domain-Adapted and Personalized Document Analysis (ADAPDA)",
    "pdf_url": "http://arxiv.org/pdf/2406.08610v1",
    "published_date": "2024-06-12 19:41:01 UTC",
    "updated_date": "2024-06-12 19:41:01 UTC"
  },
  {
    "arxiv_id": "2406.08607v1",
    "title": "Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference",
    "authors": [
      "Jiabao Ji",
      "Yujian Liu",
      "Yang Zhang",
      "Gaowen Liu",
      "Ramana Rao Kompella",
      "Sijia Liu",
      "Shiyu Chang"
    ],
    "abstract": "As Large Language Models (LLMs) demonstrate extensive capability in learning\nfrom documents, LLM unlearning becomes an increasingly important research area\nto address concerns of LLMs in terms of privacy, copyright, etc. A conventional\nLLM unlearning task typically involves two goals: (1) The target LLM should\nforget the knowledge in the specified forget documents, and (2) it should\nretain the other knowledge that the LLM possesses, for which we assume access\nto a small number of retain documents. To achieve both goals, a mainstream\nclass of LLM unlearning methods introduces an optimization framework with a\ncombination of two objectives - maximizing the prediction loss on the forget\ndocuments while minimizing that on the retain documents, which suffers from two\nchallenges, degenerated output and catastrophic forgetting. In this paper, we\npropose a novel unlearning framework called Unlearning from Logit Difference\n(ULD), which introduces an assistant LLM that aims to achieve the opposite of\nthe unlearning goals: remembering the forget documents and forgetting the\nretain knowledge. ULD then derives the unlearned LLM by computing the logit\ndifference between the target and the assistant LLMs. We show that such\nreversed objectives would naturally resolve both aforementioned challenges\nwhile significantly improving the training efficiency. Extensive experiments\ndemonstrate that our method efficiently achieves the intended forgetting while\npreserving the LLM's overall capabilities, reducing training time by more than\nthreefold. Notably, our method loses 0% of model utility on the ToFU benchmark,\nwhereas baseline methods may sacrifice 17% of utility on average to achieve\ncomparable forget quality. Our code will be publicly available at\nhttps://github.com/UCSB-NLP-Chang/ULD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08607v1",
    "published_date": "2024-06-12 19:26:35 UTC",
    "updated_date": "2024-06-12 19:26:35 UTC"
  },
  {
    "arxiv_id": "2406.08606v2",
    "title": "A Generative Marker Enhanced End-to-End Framework for Argument Mining",
    "authors": [
      "Nilmadhab Das",
      "Vishal Choudhary",
      "V. Vijaya Saradhi",
      "Ashish Anand"
    ],
    "abstract": "Argument Mining (AM) involves identifying and extracting Argumentative\nComponents (ACs) and their corresponding Argumentative Relations (ARs). Most of\nthe prior works have broken down these tasks into multiple sub-tasks. Existing\nend-to-end setups primarily use the dependency parsing approach. This work\nintroduces a generative paradigm-based end-to-end framework argTANL. argTANL\nframes the argumentative structures into label-augmented text, called Augmented\nNatural Language (ANL). This framework jointly extracts both ACs and ARs from a\ngiven argumentative text. Additionally, this study explores the impact of\nArgumentative and Discourse markers on enhancing the model's performance within\nthe proposed framework. Two distinct frameworks, Marker-Enhanced argTANL\n(ME-argTANL) and argTANL with specialized Marker-Based Fine-Tuning, are\nproposed to achieve this. Extensive experiments are conducted on three standard\nAM benchmarks to demonstrate the superior performance of the ME-argTANL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08606v2",
    "published_date": "2024-06-12 19:22:29 UTC",
    "updated_date": "2024-09-08 12:24:11 UTC"
  },
  {
    "arxiv_id": "2406.08603v1",
    "title": "FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion",
    "authors": [
      "George Cazenavette",
      "Avneesh Sud",
      "Thomas Leung",
      "Ben Usman"
    ],
    "abstract": "Due to the high potential for abuse of GenAI systems, the task of detecting\nsynthetic images has recently become of great interest to the research\ncommunity. Unfortunately, existing image-space detectors quickly become\nobsolete as new high-fidelity text-to-image models are developed at blinding\nspeed. In this work, we propose a new synthetic image detector that uses\nfeatures obtained by inverting an open-source pre-trained Stable Diffusion\nmodel. We show that these inversion features enable our detector to generalize\nwell to unseen generators of high visual fidelity (e.g., DALL-E 3) even when\nthe detector is trained only on lower fidelity fake images generated via Stable\nDiffusion. This detector achieves new state-of-the-art across multiple training\nand evaluation setups. Moreover, we introduce a new challenging evaluation\nprotocol that uses reverse image search to mitigate stylistic and thematic\nbiases in the detector evaluation. We show that the resulting evaluation scores\nalign well with detectors' in-the-wild performance, and release these datasets\nas public benchmarks for future research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://fake-inversion.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.08603v1",
    "published_date": "2024-06-12 19:14:58 UTC",
    "updated_date": "2024-06-12 19:14:58 UTC"
  },
  {
    "arxiv_id": "2406.08598v4",
    "title": "Language Model Council: Democratically Benchmarking Foundation Models on Highly Subjective Tasks",
    "authors": [
      "Justin Zhao",
      "Flor Miriam Plaza-del-Arco",
      "Benjamin Genchel",
      "Amanda Cercas Curry"
    ],
    "abstract": "As Large Language Models (LLMs) continue to evolve, evaluating them remains a\npersistent challenge. Many recent evaluations use LLMs as judges to score\noutputs from other LLMs, often relying on a single large model like GPT-4o.\nHowever, using a single LLM judge is prone to intra-model bias, and many tasks\n- such as those related to emotional intelligence, creative writing, and\npersuasiveness - may be too subjective for a single model to judge fairly. We\nintroduce the Language Model Council (LMC), where a group of LLMs collaborate\nto create tests, respond to them, and evaluate each other's responses to\nproduce a ranking in a democratic fashion. Unlike previous approaches that\nfocus on reducing cost or bias by using a panel of smaller models, our work\nexamines the benefits and nuances of a fully inclusive LLM evaluation system.\nIn a detailed case study on emotional intelligence, we deploy a council of 20\nrecent LLMs to rank each other on open-ended responses to interpersonal\nconflicts. Our results show that the LMC produces rankings that are more\nseparable and more robust, and through a user study, we show that they are more\nconsistent with human evaluations than any individual LLM judge. Using all LLMs\nfor judging can be costly, however, so we use Monte Carlo simulations and\nhand-curated sub-councils to study hypothetical council compositions and\ndiscuss the value of the incremental LLM judge.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08598v4",
    "published_date": "2024-06-12 19:05:43 UTC",
    "updated_date": "2025-03-19 04:25:35 UTC"
  },
  {
    "arxiv_id": "2406.09455v1",
    "title": "Pandora: Towards General World Model with Natural Language Actions and Video States",
    "authors": [
      "Jiannan Xiang",
      "Guangyi Liu",
      "Yi Gu",
      "Qiyue Gao",
      "Yuting Ning",
      "Yuheng Zha",
      "Zeyu Feng",
      "Tianhua Tao",
      "Shibo Hao",
      "Yemin Shi",
      "Zhengzhong Liu",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "abstract": "World models simulate future states of the world in response to different\nactions. They facilitate interactive content creation and provides a foundation\nfor grounded, long-horizon reasoning. Current foundation models do not fully\nmeet the capabilities of general world models: large language models (LLMs) are\nconstrained by their reliance on language modality and their limited\nunderstanding of the physical world, while video models lack interactive action\ncontrol over the world simulations. This paper makes a step towards building a\ngeneral world model by introducing Pandora, a hybrid autoregressive-diffusion\nmodel that simulates world states by generating videos and allows real-time\ncontrol with free-text actions. Pandora achieves domain generality, video\nconsistency, and controllability through large-scale pretraining and\ninstruction tuning. Crucially, Pandora bypasses the cost of\ntraining-from-scratch by integrating a pretrained LLM (7B) and a pretrained\nvideo model, requiring only additional lightweight finetuning. We illustrate\nextensive outputs by Pandora across diverse domains (indoor/outdoor,\nnatural/urban, human/robot, 2D/3D, etc.). The results indicate great potential\nof building stronger general world models with larger-scale training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Website: https://world-model.maitrix.org/",
    "pdf_url": "http://arxiv.org/pdf/2406.09455v1",
    "published_date": "2024-06-12 18:55:51 UTC",
    "updated_date": "2024-06-12 18:55:51 UTC"
  },
  {
    "arxiv_id": "2406.08587v2",
    "title": "CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery",
    "authors": [
      "Xiaoshuai Song",
      "Muxi Diao",
      "Guanting Dong",
      "Zhengyang Wang",
      "Yujia Fu",
      "Runqi Qiao",
      "Zhexu Wang",
      "Dayuan Fu",
      "Huangxuan Wu",
      "Bin Liang",
      "Weihao Zeng",
      "Yejie Wang",
      "Zhuoma GongQue",
      "Jianing Yu",
      "Qiuna Tan",
      "Weiran Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated significant potential in\nadvancing various fields of research and society. However, the current\ncommunity of LLMs overly focuses on benchmarks for analyzing specific\nfoundational skills (e.g. mathematics and code generation), neglecting an\nall-round evaluation of the computer science field. To bridge this gap, we\nintroduce CS-Bench, the first multilingual (English, Chinese, French, German)\nbenchmark dedicated to evaluating the performance of LLMs in computer science.\nCS-Bench comprises approximately 10K meticulously curated test samples,\ncovering 26 subfields across 4 key areas of computer science, encompassing\nvarious task forms and divisions of knowledge and reasoning. Utilizing\nCS-Bench, we conduct a comprehensive evaluation of over 30 mainstream LLMs,\nrevealing the relationship between CS performance and model scales. We also\nquantitatively analyze the reasons for failures in existing LLMs and highlight\ndirections for improvements, including knowledge supplementation and\nCS-specific reasoning. Further cross-capability experiments show a high\ncorrelation between LLMs' capabilities in computer science and their abilities\nin mathematics and coding. Moreover, expert LLMs specialized in mathematics and\ncoding also demonstrate strong performances in several CS subfields. Looking\nahead, we envision CS-Bench serving as a cornerstone for LLM applications in\nthe CS field and paving new avenues in assessing LLMs' diverse reasoning\ncapabilities. The CS-Bench data and evaluation code are available at\nhttps://github.com/csbench/csbench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.08587v2",
    "published_date": "2024-06-12 18:47:28 UTC",
    "updated_date": "2025-02-28 15:16:04 UTC"
  },
  {
    "arxiv_id": "2406.09454v1",
    "title": "Advancing High Resolution Vision-Language Models in Biomedicine",
    "authors": [
      "Zekai Chen",
      "Arda Pekis",
      "Kevin Brown"
    ],
    "abstract": "Multi-modal learning has significantly advanced generative AI, especially in\nvision-language modeling. Innovations like GPT-4V and open-source projects such\nas LLaVA have enabled robust conversational agents capable of zero-shot task\ncompletions. However, applying these technologies in the biomedical field\npresents unique challenges. Recent initiatives like LLaVA-Med have started to\nadapt instruction-tuning for biomedical contexts using large datasets such as\nPMC-15M. Our research offers three key contributions: (i) we present a new\ninstruct dataset enriched with medical image-text pairs from Claude3-Opus and\nLLaMA3 70B, (ii) we propose a novel image encoding strategy using hierarchical\nrepresentations to improve fine-grained biomedical visual comprehension, and\n(iii) we develop the Llama3-Med model, which achieves state-of-the-art\nzero-shot performance on biomedical visual question answering benchmarks, with\nan average performance improvement of over 10% compared to previous methods.\nThese advancements provide more accurate and reliable tools for medical\nprofessionals, bridging gaps in current multi-modal conversational assistants\nand promoting further innovations in medical AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.09454v1",
    "published_date": "2024-06-12 18:29:26 UTC",
    "updated_date": "2024-06-12 18:29:26 UTC"
  },
  {
    "arxiv_id": "2406.08575v1",
    "title": "Using Quality Attribute Scenarios for ML Model Test Case Generation",
    "authors": [
      "Rachel Brower-Sinning",
      "Grace A. Lewis",
      "Sebastían Echeverría",
      "Ipek Ozkaya"
    ],
    "abstract": "Testing of machine learning (ML) models is a known challenge identified by\nresearchers and practitioners alike. Unfortunately, current practice for ML\nmodel testing prioritizes testing for model performance, while often neglecting\nthe requirements and constraints of the ML-enabled system that integrates the\nmodel. This limited view of testing leads to failures during integration,\ndeployment, and operations, contributing to the difficulties of moving models\nfrom development to production. This paper presents an approach based on\nquality attribute (QA) scenarios to elicit and define system- and\nmodel-relevant test cases for ML models. The QA-based approach described in\nthis paper has been integrated into MLTE, a process and tool to support ML\nmodel test and evaluation. Feedback from users of MLTE highlights its\neffectiveness in testing beyond model performance and identifying failures\nearly in the development process.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Paper accepted and presented in SAML 2024, the 3rd International\n  Workshop on Software Architecture and Machine Learning, co-located with ICSA\n  2024, the 21st IEEE International Conference on Software Architecture",
    "pdf_url": "http://arxiv.org/pdf/2406.08575v1",
    "published_date": "2024-06-12 18:26:42 UTC",
    "updated_date": "2024-06-12 18:26:42 UTC"
  },
  {
    "arxiv_id": "2406.08570v1",
    "title": "HDNet: Physics-Inspired Neural Network for Flow Estimation based on Helmholtz Decomposition",
    "authors": [
      "Miao Qi",
      "Ramzi Idoughi",
      "Wolfgang Heidrich"
    ],
    "abstract": "Flow estimation problems are ubiquitous in scientific imaging. Often, the\nunderlying flows are subject to physical constraints that can be exploited in\nthe flow estimation; for example, incompressible (divergence-free) flows are\nexpected for many fluid experiments, while irrotational (curl-free) flows arise\nin the analysis of optical distortions and wavefront sensing. In this work, we\npropose a Physics- Inspired Neural Network (PINN) named HDNet, which performs a\nHelmholtz decomposition of an arbitrary flow field, i.e., it decomposes the\ninput flow into a divergence-only and a curl-only component. HDNet can be\ntrained exclusively on synthetic data generated by reverse Helmholtz\ndecomposition, which we call Helmholtz synthesis. As a PINN, HDNet is fully\ndifferentiable and can easily be integrated into arbitrary flow estimation\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08570v1",
    "published_date": "2024-06-12 18:11:32 UTC",
    "updated_date": "2024-06-12 18:11:32 UTC"
  },
  {
    "arxiv_id": "2406.08564v2",
    "title": "Machine Learning-Driven Open-Source Framework for Assessing QoE in Multimedia Networks",
    "authors": [
      "Parsa Hassani Shariat Panahi",
      "Amir Hossein Jalilvand",
      "Abolfazl Diyanat"
    ],
    "abstract": "The Internet is integral to modern life, influencing communication, business,\nand lifestyles globally. As dependence on Internet services grows, the demand\nfor high-quality service delivery increases. Service providers must maintain\nhigh standards of quality of service and quality of experience (QoE) to ensure\nuser satisfaction. QoE, which reflects user satisfaction with service quality,\nis a key metric for multimedia services, yet it is challenging to measure due\nto its subjective nature and the complexities of real-time feedback. This paper\nintroduces a machine learning-based framework for objectively assessing QoE in\nmultimedia networks. The open-source framework complies with the ITU-T P.1203\nstandard. It automates data collection and user satisfaction prediction using\nkey network parameters such as delay, jitter, packet loss, bitrate, and\nthroughput. Using a dataset of over 20,000 records from various network\nconditions, the Random Forest model predicts the mean opinion score with 95.8%\naccuracy. Our framework addresses the limitations of existing QoE models by\nintegrating real-time data collection, machine learning predictions, and\nadherence to international standards. This approach enhances QoE evaluation\naccuracy and allows dynamic network resource management, optimizing performance\nand cost-efficiency. Its open-source nature encourages adaptation and extension\nfor various multimedia services. The findings significantly affect the\ntelecommunications industry in managing and optimizing multimedia services. The\nnetwork centric QoE prediction of the framework offers a scalable solution to\nimprove user satisfaction without the need for content-specific data. Future\nenhancements could include advanced machine learning models and broader\napplicability to digital services. This research contributes a practical,\nstandardized tool for QoE assessment across diverse networks and platforms.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.NI",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08564v2",
    "published_date": "2024-06-12 18:07:06 UTC",
    "updated_date": "2024-09-10 07:30:02 UTC"
  },
  {
    "arxiv_id": "2406.08545v1",
    "title": "RVT-2: Learning Precise Manipulation from Few Demonstrations",
    "authors": [
      "Ankit Goyal",
      "Valts Blukis",
      "Jie Xu",
      "Yijie Guo",
      "Yu-Wei Chao",
      "Dieter Fox"
    ],
    "abstract": "In this work, we study how to build a robotic system that can solve multiple\n3D manipulation tasks given language instructions. To be useful in industrial\nand household domains, such a system should be capable of learning new tasks\nwith few demonstrations and solving them precisely. Prior works, like PerAct\nand RVT, have studied this problem, however, they often struggle with tasks\nrequiring high precision. We study how to make them more effective, precise,\nand fast. Using a combination of architectural and system-level improvements,\nwe propose RVT-2, a multitask 3D manipulation model that is 6X faster in\ntraining and 2X faster in inference than its predecessor RVT. RVT-2 achieves a\nnew state-of-the-art on RLBench, improving the success rate from 65% to 82%.\nRVT-2 is also effective in the real world, where it can learn tasks requiring\nhigh precision, like picking up and inserting plugs, with just 10\ndemonstrations. Visual results, code, and trained model are provided at:\nhttps://robotic-view-transformer-2.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to RSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08545v1",
    "published_date": "2024-06-12 18:00:01 UTC",
    "updated_date": "2024-06-12 18:00:01 UTC"
  },
  {
    "arxiv_id": "2406.08488v1",
    "title": "ICE-G: Image Conditional Editing of 3D Gaussian Splats",
    "authors": [
      "Vishnu Jaganathan",
      "Hannah Hanyun Huang",
      "Muhammad Zubair Irshad",
      "Varun Jampani",
      "Amit Raj",
      "Zsolt Kira"
    ],
    "abstract": "Recently many techniques have emerged to create high quality 3D assets and\nscenes. When it comes to editing of these objects, however, existing approaches\nare either slow, compromise on quality, or do not provide enough customization.\nWe introduce a novel approach to quickly edit a 3D model from a single\nreference view. Our technique first segments the edit image, and then matches\nsemantically corresponding regions across chosen segmented dataset views using\nDINO features. A color or texture change from a particular region of the edit\nimage can then be applied to other views automatically in a semantically\nsensible manner. These edited views act as an updated dataset to further train\nand re-style the 3D scene. The end-result is therefore an edited 3D model. Our\nframework enables a wide variety of editing tasks such as manual local edits,\ncorrespondence based style transfer from any example image, and a combination\nof different styles from multiple example images. We use Gaussian Splats as our\nprimary 3D representation due to their speed and ease of local editing, but our\ntechnique works for other methods such as NeRFs as well. We show through\nmultiple examples that our method produces higher quality results while\noffering fine-grained control of editing. Project page: ice-gaussian.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR AI4CC Workshop 2024. Project page:\n  https://ice-gaussian.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.08488v1",
    "published_date": "2024-06-12 17:59:52 UTC",
    "updated_date": "2024-06-12 17:59:52 UTC"
  },
  {
    "arxiv_id": "2406.08476v2",
    "title": "RMem: Restricted Memory Banks Improve Video Object Segmentation",
    "authors": [
      "Junbao Zhou",
      "Ziqi Pang",
      "Yu-Xiong Wang"
    ],
    "abstract": "With recent video object segmentation (VOS) benchmarks evolving to\nchallenging scenarios, we revisit a simple but overlooked strategy: restricting\nthe size of memory banks. This diverges from the prevalent practice of\nexpanding memory banks to accommodate extensive historical information. Our\nspecially designed \"memory deciphering\" study offers a pivotal insight\nunderpinning such a strategy: expanding memory banks, while seemingly\nbeneficial, actually increases the difficulty for VOS modules to decode\nrelevant features due to the confusion from redundant information. By\nrestricting memory banks to a limited number of essential frames, we achieve a\nnotable improvement in VOS accuracy. This process balances the importance and\nfreshness of frames to maintain an informative memory bank within a bounded\ncapacity. Additionally, restricted memory banks reduce the training-inference\ndiscrepancy in memory lengths compared with continuous expansion. This fosters\nnew opportunities in temporal reasoning and enables us to introduce the\npreviously overlooked \"temporal positional embedding.\" Finally, our insights\nare embodied in \"RMem\" (\"R\" for restricted), a simple yet effective VOS\nmodification that excels at challenging VOS scenarios and establishes new state\nof the art for object state changes (on the VOST dataset) and long videos (on\nthe Long Videos dataset). Our code and demo are available at\nhttps://restricted-memory.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024, Project Page: https://restricted-memory.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.08476v2",
    "published_date": "2024-06-12 17:59:04 UTC",
    "updated_date": "2025-01-14 17:46:01 UTC"
  },
  {
    "arxiv_id": "2406.08474v2",
    "title": "Real2Code: Reconstruct Articulated Objects via Code Generation",
    "authors": [
      "Zhao Mandi",
      "Yijia Weng",
      "Dominik Bauer",
      "Shuran Song"
    ],
    "abstract": "We present Real2Code, a novel approach to reconstructing articulated objects\nvia code generation. Given visual observations of an object, we first\nreconstruct its part geometry using an image segmentation model and a shape\ncompletion model. We then represent the object parts with oriented bounding\nboxes, which are input to a fine-tuned large language model (LLM) to predict\njoint articulation as code. By leveraging pre-trained vision and language\nmodels, our approach scales elegantly with the number of articulated parts, and\ngeneralizes from synthetic training data to real world objects in unstructured\nenvironments. Experimental results demonstrate that Real2Code significantly\noutperforms previous state-of-the-art in reconstruction accuracy, and is the\nfirst approach to extrapolate beyond objects' structural complexity in the\ntraining set, and reconstructs objects with up to 10 articulated parts. When\nincorporated with a stereo reconstruction model, Real2Code also generalizes to\nreal world objects from a handful of multi-view RGB images, without the need\nfor depth or camera information.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08474v2",
    "published_date": "2024-06-12 17:57:06 UTC",
    "updated_date": "2024-06-13 17:38:12 UTC"
  },
  {
    "arxiv_id": "2406.08472v4",
    "title": "RILe: Reinforced Imitation Learning",
    "authors": [
      "Mert Albaba",
      "Sammy Christen",
      "Thomas Langarek",
      "Christoph Gebhardt",
      "Otmar Hilliges",
      "Michael J. Black"
    ],
    "abstract": "Acquiring complex behaviors is essential for artificially intelligent agents,\nyet learning these behaviors in high-dimensional settings poses a significant\nchallenge due to the vast search space. Traditional reinforcement learning (RL)\nrequires extensive manual effort for reward function engineering. Inverse\nreinforcement learning (IRL) uncovers reward functions from expert\ndemonstrations but relies on an iterative process that is often computationally\nexpensive. Imitation learning (IL) provides a more efficient alternative by\ndirectly comparing an agent's actions to expert demonstrations; however, in\nhigh-dimensional environments, such direct comparisons often offer insufficient\nfeedback for effective learning. We introduce RILe (Reinforced Imitation\nLearning), a framework that combines the strengths of imitation learning and\ninverse reinforcement learning to learn a dense reward function efficiently and\nachieve strong performance in high-dimensional tasks. RILe employs a novel\ntrainer-student framework: the trainer learns an adaptive reward function, and\nthe student uses this reward signal to imitate expert behaviors. By dynamically\nadjusting its guidance as the student evolves, the trainer provides nuanced\nfeedback across different phases of learning. Our framework produces\nhigh-performing policies in high-dimensional tasks where direct imitation fails\nto replicate complex behaviors. We validate RILe in challenging robotic\nlocomotion tasks, demonstrating that it significantly outperforms existing\nmethods and achieves near-expert performance across multiple settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08472v4",
    "published_date": "2024-06-12 17:56:31 UTC",
    "updated_date": "2025-04-21 17:59:59 UTC"
  },
  {
    "arxiv_id": "2406.08471v1",
    "title": "Surprise! Using Physiological Stress for Allostatic Regulation Under the Active Inference Framework [Pre-Print]",
    "authors": [
      "Imran Khan",
      "Robert Lowe"
    ],
    "abstract": "Allostasis proposes that long-term viability of a living system is achieved\nthrough anticipatory adjustments of its physiology and behaviour: emphasising\nphysiological and affective stress as an adaptive state of adaptation that\nminimizes long-term prediction errors. More recently, the active inference\nframework (AIF) has also sought to explain action and long-term adaptation\nthrough the minimization of future errors (free energy), through the learning\nof statistical contingencies of the world, offering a formalism for allostatic\nregulation. We suggest that framing prediction errors through the lens of\nbiological hormonal dynamics proposed by allostasis offers a way to integrate\nthese two models together in a biologically-plausible manner. In this paper, we\ndescribe our initial work in developing a model that grounds prediction errors\n(surprisal) into the secretion of a physiological stress hormone (cortisol)\nacting as an adaptive, allostatic mediator on a homeostatically-controlled\nphysiology. We evaluate this using a computational model in simulations using\nan active inference agent endowed with an artificial physiology, regulated\nthrough homeostatic and allostatic control in a stochastic environment. Our\nresults find that allostatic functions of cortisol (stress), secreted as a\nfunction of prediction errors, provide adaptive advantages to the agent's\nlong-term physiological regulation. We argue that the coupling of\ninformation-theoretic prediction errors to low-level, biological hormonal\ndynamics of stress can provide a computationally efficient model to long-term\nregulation for embodied intelligent systems.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08471v1",
    "published_date": "2024-06-12 17:56:15 UTC",
    "updated_date": "2024-06-12 17:56:15 UTC"
  },
  {
    "arxiv_id": "2406.08467v1",
    "title": "DafnyBench: A Benchmark for Formal Software Verification",
    "authors": [
      "Chloe Loughridge",
      "Qinyi Sun",
      "Seth Ahrenbach",
      "Federico Cassano",
      "Chuyue Sun",
      "Ying Sheng",
      "Anish Mudide",
      "Md Rakib Hossain Misu",
      "Nada Amin",
      "Max Tegmark"
    ],
    "abstract": "We introduce DafnyBench, the largest benchmark of its kind for training and\nevaluating machine learning systems for formal software verification. We test\nthe ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough hints\nfor the Dafny formal verification engine to successfully verify over 750\nprograms with about 53,000 lines of code. The best model and prompting scheme\nachieved 68% success rate, and we quantify how this rate improves when retrying\nwith error message feedback and how it deteriorates with the amount of required\ncode and hints. We hope that DafnyBench will enable rapid improvements from\nthis baseline as LLMs and verification techniques grow in quality.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "Code & dataset available at: https://github.com/sun-wendy/DafnyBench",
    "pdf_url": "http://arxiv.org/pdf/2406.08467v1",
    "published_date": "2024-06-12 17:53:31 UTC",
    "updated_date": "2024-06-12 17:53:31 UTC"
  },
  {
    "arxiv_id": "2406.08466v2",
    "title": "Scaling Laws in Linear Regression: Compute, Parameters, and Data",
    "authors": [
      "Licong Lin",
      "Jingfeng Wu",
      "Sham M. Kakade",
      "Peter L. Bartlett",
      "Jason D. Lee"
    ],
    "abstract": "Empirically, large-scale deep learning models often satisfy a neural scaling\nlaw: the test error of the trained model improves polynomially as the model\nsize and data size grow. However, conventional wisdom suggests the test error\nconsists of approximation, bias, and variance errors, where the variance error\nincreases with model size. This disagrees with the general form of neural\nscaling laws, which predict that increasing model size monotonically improves\nperformance.\n  We study the theory of scaling laws in an infinite dimensional linear\nregression setup. Specifically, we consider a model with $M$ parameters as a\nlinear function of sketched covariates. The model is trained by one-pass\nstochastic gradient descent (SGD) using $N$ data. Assuming the optimal\nparameter satisfies a Gaussian prior and the data covariance matrix has a\npower-law spectrum of degree $a>1$, we show that the reducible part of the test\nerror is $\\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which\nincreases with $M$, is dominated by the other errors due to the implicit\nregularization of SGD, thus disappearing from the bound. Our theory is\nconsistent with the empirical neural scaling laws and verified by numerical\nsimulation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08466v2",
    "published_date": "2024-06-12 17:53:29 UTC",
    "updated_date": "2024-10-29 18:10:27 UTC"
  },
  {
    "arxiv_id": "2406.08464v2",
    "title": "Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing",
    "authors": [
      "Zhangchen Xu",
      "Fengqing Jiang",
      "Luyao Niu",
      "Yuntian Deng",
      "Radha Poovendran",
      "Yejin Choi",
      "Bill Yuchen Lin"
    ],
    "abstract": "High-quality instruction data is critical for aligning large language models\n(LLMs). Although some models, such as Llama-3-Instruct, have open weights,\ntheir alignment data remain private, which hinders the democratization of AI.\nHigh human labor costs and a limited, predefined scope for prompting prevent\nexisting open-source data creation methods from scaling effectively,\npotentially limiting the diversity and quality of public alignment datasets. Is\nit possible to synthesize high-quality instruction data at scale by extracting\nit directly from an aligned LLM? We present a self-synthesis method for\ngenerating large-scale alignment data named Magpie. Our key observation is that\naligned LLMs like Llama-3-Instruct can generate a user query when we input only\nthe left-side templates up to the position reserved for user messages, thanks\nto their auto-regressive nature. We use this method to prompt Llama-3-Instruct\nand generate 4 million instructions along with their corresponding responses.\nWe perform a comprehensive analysis of the extracted data and select 300K\nhigh-quality instances. To compare Magpie data with other public instruction\ndatasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the\nperformance of the fine-tuned models. Our results indicate that in some tasks,\nmodels fine-tuned with Magpie perform comparably to the official\nLlama-3-8B-Instruct, despite the latter being enhanced with 10 million data\npoints through supervised fine-tuning (SFT) and subsequent feedback learning.\nWe also show that using Magpie solely for SFT can surpass the performance of\nprevious public datasets utilized for both SFT and preference optimization,\nsuch as direct preference optimization with UltraFeedback. This advantage is\nevident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Link: https://magpie-align.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.08464v2",
    "published_date": "2024-06-12 17:52:30 UTC",
    "updated_date": "2024-10-07 01:45:38 UTC"
  },
  {
    "arxiv_id": "2406.12908v1",
    "title": "Rating Multi-Modal Time-Series Forecasting Models (MM-TSFM) for Robustness Through a Causal Lens",
    "authors": [
      "Kausik Lakkaraju",
      "Rachneet Kaur",
      "Zhen Zeng",
      "Parisa Zehtabi",
      "Sunandita Patra",
      "Biplav Srivastava",
      "Marco Valtorta"
    ],
    "abstract": "AI systems are notorious for their fragility; minor input changes can\npotentially cause major output swings. When such systems are deployed in\ncritical areas like finance, the consequences of their uncertain behavior could\nbe severe. In this paper, we focus on multi-modal time-series forecasting,\nwhere imprecision due to noisy or incorrect data can lead to erroneous\npredictions, impacting stakeholders such as analysts, investors, and traders.\nRecently, it has been shown that beyond numeric data, graphical transformations\ncan be used with advanced visual models to achieve better performance. In this\ncontext, we introduce a rating methodology to assess the robustness of\nMulti-Modal Time-Series Forecasting Models (MM-TSFM) through causal analysis,\nwhich helps us understand and quantify the isolated impact of various\nattributes on the forecasting accuracy of MM-TSFM. We apply our novel rating\nmethod on a variety of numeric and multi-modal forecasting models in a large\nexperimental setup (six input settings of control and perturbations, ten data\ndistributions, time series from six leading stocks in three industries over a\nyear of data, and five time-series forecasters) to draw insights on robust\nforecasting models and the context of their strengths. Within the scope of our\nstudy, our main result is that multi-modal (numeric + visual) forecasting,\nwhich was found to be more accurate than numeric forecasting in previous\nstudies, can also be more robust in diverse settings. Our work will help\ndifferent stakeholders of time-series forecasting understand the models`\nbehaviors along trust (robustness) and accuracy dimensions to select an\nappropriate model for forecasting using our rating method, leading to improved\ndecision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.12908v1",
    "published_date": "2024-06-12 17:39:16 UTC",
    "updated_date": "2024-06-12 17:39:16 UTC"
  },
  {
    "arxiv_id": "2406.08447v1",
    "title": "The Impact of Initialization on LoRA Finetuning Dynamics",
    "authors": [
      "Soufiane Hayou",
      "Nikhil Ghosh",
      "Bin Yu"
    ],
    "abstract": "In this paper, we study the role of initialization in Low Rank Adaptation\n(LoRA) as originally introduced in Hu et al. (2021). Essentially, to start from\nthe pretrained model as initialization for finetuning, one can either\ninitialize B to zero and A to random (default initialization in PEFT package),\nor vice-versa. In both cases, the product BA is equal to zero at\ninitialization, which makes finetuning starts from the pretrained model. These\ntwo initialization schemes are seemingly similar. They should in-principle\nyield the same performance and share the same optimal learning rate. We\ndemonstrate that this is an incorrect intuition and that the first scheme\n(initializing B to zero and A to random) on average yields better performance\ncompared to the other scheme. Our theoretical analysis shows that the reason\nbehind this might be that the first initialization allows the use of larger\nlearning rates (without causing output instability) compared to the second\ninitialization, resulting in more efficient learning of the first scheme. We\nvalidate our results with extensive experiments on LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "TDLR: Different Initializations lead to completely different\n  finetuning dynamics. One initialization (set A random and B zero) is\n  generally better than the natural opposite initialization. arXiv admin note:\n  text overlap with arXiv:2402.12354",
    "pdf_url": "http://arxiv.org/pdf/2406.08447v1",
    "published_date": "2024-06-12 17:38:20 UTC",
    "updated_date": "2024-06-12 17:38:20 UTC"
  },
  {
    "arxiv_id": "2406.08446v2",
    "title": "OLMES: A Standard for Language Model Evaluations",
    "authors": [
      "Yuling Gu",
      "Oyvind Tafjord",
      "Bailey Kuehl",
      "Dany Haddad",
      "Jesse Dodge",
      "Hannaneh Hajishirzi"
    ],
    "abstract": "Progress in AI is often demonstrated by new models claiming improved\nperformance on tasks measuring model capabilities. Evaluating language models\ncan be particularly challenging, as choices of how a model is evaluated on a\ntask can lead to large changes in measured performance. There is no common\nstandard setup, so different models are evaluated on the same tasks in\ndifferent ways, leading to claims about which models perform best not being\nreproducible. We propose OLMES, a completely documented, practical, open\nstandard for reproducible LLM evaluations. In developing this standard, we\nidentify and review the varying factors in evaluation practices adopted by the\ncommunity - such as details of prompt formatting, choice of in-context\nexamples, probability normalizations, and task formulation. In particular,\nOLMES supports meaningful comparisons between smaller base models that require\nthe unnatural \"cloze\" formulation of multiple-choice questions against larger\nmodels that can utilize the original formulation. OLMES includes\nwell-considered, documented recommendations guided by results from existing\nliterature as well as new experiments resolving open questions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.08446v2",
    "published_date": "2024-06-12 17:37:09 UTC",
    "updated_date": "2025-02-11 18:59:26 UTC"
  },
  {
    "arxiv_id": "2406.08434v1",
    "title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
    "authors": [
      "Yutong Wang",
      "Jiali Zeng",
      "Xuebo Liu",
      "Fandong Meng",
      "Jie Zhou",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) have exhibited remarkable performance in various\nnatural language processing tasks. Techniques like instruction tuning have\neffectively enhanced the proficiency of LLMs in the downstream task of machine\ntranslation. However, the existing approaches fail to yield satisfactory\ntranslation outputs that match the quality of supervised neural machine\ntranslation (NMT) systems. One plausible explanation for this discrepancy is\nthat the straightforward prompts employed in these methodologies are unable to\nfully exploit the acquired instruction-following capabilities. To this end, we\npropose the TasTe framework, which stands for translating through\nself-reflection. The self-reflection process includes two stages of inference.\nIn the first stage, LLMs are instructed to generate preliminary translations\nand conduct self-assessments on these translations simultaneously. In the\nsecond stage, LLMs are tasked to refine these preliminary translations\naccording to the evaluation results. The evaluation results in four language\ndirections on the WMT22 benchmark reveal the effectiveness of our approach\ncompared to existing methods. Our work presents a promising approach to unleash\nthe potential of LLMs and enhance their capabilities in MT. The codes and\ndatasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted to the ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2406.08434v1",
    "published_date": "2024-06-12 17:21:21 UTC",
    "updated_date": "2024-06-12 17:21:21 UTC"
  },
  {
    "arxiv_id": "2406.08431v1",
    "title": "Diffusion Soup: Model Merging for Text-to-Image Diffusion Models",
    "authors": [
      "Benjamin Biggs",
      "Arjun Seshadri",
      "Yang Zou",
      "Achin Jain",
      "Aditya Golatkar",
      "Yusheng Xie",
      "Alessandro Achille",
      "Ashwin Swaminathan",
      "Stefano Soatto"
    ],
    "abstract": "We present Diffusion Soup, a compartmentalization method for Text-to-Image\nGeneration that averages the weights of diffusion models trained on sharded\ndata. By construction, our approach enables training-free continual learning\nand unlearning with no additional memory or inference costs, since models\ncorresponding to data shards can be added or removed by re-averaging. We show\nthat Diffusion Soup samples from a point in weight space that approximates the\ngeometric mean of the distributions of constituent datasets, which offers\nanti-memorization guarantees and enables zero-shot style mixing. Empirically,\nDiffusion Soup outperforms a paragon model trained on the union of all data\nshards and achieves a 30% improvement in Image Reward (.34 $\\to$ .44) on domain\nsharded data, and a 59% improvement in IR (.37 $\\to$ .59) on aesthetic data. In\nboth cases, souping also prevails in TIFA score (respectively, 85.5 $\\to$ 86.5\nand 85.6 $\\to$ 86.8). We demonstrate robust unlearning -- removing any\nindividual domain shard only lowers performance by 1% in IR (.45 $\\to$ .44) --\nand validate our theoretical insights on anti-memorization using real data.\nFinally, we showcase Diffusion Soup's ability to blend the distinct styles of\nmodels finetuned on different shards, resulting in the zero-shot generation of\nhybrid styles.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08431v1",
    "published_date": "2024-06-12 17:16:16 UTC",
    "updated_date": "2024-06-12 17:16:16 UTC"
  },
  {
    "arxiv_id": "2406.08428v1",
    "title": "Improving Noise Robustness through Abstractions and its Impact on Machine Learning",
    "authors": [
      "Alfredo Ibias",
      "Karol Capala",
      "Varun Ravi Varma",
      "Anna Drozdz",
      "Jose Sousa"
    ],
    "abstract": "Noise is a fundamental problem in learning theory with huge effects in the\napplication of Machine Learning (ML) methods, due to real world data tendency\nto be noisy. Additionally, introduction of malicious noise can make ML methods\nfail critically, as is the case with adversarial attacks. Thus, finding and\ndeveloping alternatives to improve robustness to noise is a fundamental problem\nin ML. In this paper, we propose a method to deal with noise: mitigating its\neffect through the use of data abstractions. The goal is to reduce the effect\nof noise over the model's performance through the loss of information produced\nby the abstraction. However, this information loss comes with a cost: it can\nresult in an accuracy reduction due to the missing information. First, we\nexplored multiple methodologies to create abstractions, using the training\ndataset, for the specific case of numerical data and binary classification\ntasks. We also tested how these abstractions can affect robustness to noise\nwith several experiments that explore the robustness of an Artificial Neural\nNetwork to noise when trained using raw data \\emph{vs} when trained using\nabstracted data. The results clearly show that using abstractions is a viable\napproach for developing noise robust ML methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08428v1",
    "published_date": "2024-06-12 17:14:44 UTC",
    "updated_date": "2024-06-12 17:14:44 UTC"
  },
  {
    "arxiv_id": "2406.08426v5",
    "title": "Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL",
    "authors": [
      "Zijin Hong",
      "Zheng Yuan",
      "Qinggang Zhang",
      "Hao Chen",
      "Junnan Dong",
      "Feiran Huang",
      "Xiao Huang"
    ],
    "abstract": "Generating accurate SQL from users' natural language questions (text-to-SQL)\nremains a long-standing challenge due to the complexities involved in user\nquestion understanding, database schema comprehension, and SQL generation.\nTraditional text-to-SQL systems, which combine human engineering and deep\nneural networks, have made significant progress. Subsequently, pre-trained\nlanguage models (PLMs) have been developed for text-to-SQL tasks, achieving\npromising results. However, as modern databases and user questions grow more\ncomplex, PLMs with a limited parameter size often produce incorrect SQL. This\nnecessitates more sophisticated and tailored optimization methods, which\nrestricts the application of PLM-based systems. Recently, large language models\n(LLMs) have shown significant capabilities in natural language understanding as\nmodel scale increases. Thus, integrating LLM-based solutions can bring unique\nopportunities, improvements, and solutions to text-to-SQL research. In this\nsurvey, we provide a comprehensive review of existing LLM-based text-to-SQL\nstudies. Specifically, we offer a brief overview of the technical challenges\nand evolutionary process of text-to-SQL. Next, we introduce the datasets and\nmetrics designed to evaluate text-to-SQL systems. Subsequently, we present a\nsystematic analysis of recent advances in LLM-based text-to-SQL. Finally, we\nmake a summarization and discuss the remaining challenges in this field and\nsuggest expectations for future research directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08426v5",
    "published_date": "2024-06-12 17:13:17 UTC",
    "updated_date": "2025-03-13 08:45:35 UTC"
  },
  {
    "arxiv_id": "2406.08425v1",
    "title": "AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images",
    "authors": [
      "Ayush Roy",
      "Payel Pramanik",
      "Dmitrii Kaplun",
      "Sergei Antonov",
      "Ram Sarkar"
    ],
    "abstract": "Accurate nuclei segmentation in histopathological images is crucial for\ncancer diagnosis. Automating this process offers valuable support to clinical\nexperts, as manual annotation is time-consuming and prone to human errors.\nHowever, automating nuclei segmentation presents challenges due to uncertain\ncell boundaries, intricate staining, and diverse structures. In this paper, we\npresent a segmentation approach that combines the U-Net architecture with a\nDenseNet-121 backbone, harnessing the strengths of both to capture\ncomprehensive contextual and spatial information. Our model introduces the\nWavelet-guided channel attention module to enhance cell boundary delineation,\nalong with a learnable weighted global attention module for channel-specific\nattention. The decoder module, composed of an upsample block and convolution\nblock, further refines segmentation in handling staining patterns. The\nexperimental results conducted on two publicly accessible histopathology\ndatasets, namely Monuseg and TNBC, underscore the superiority of our proposed\nmodel, demonstrating its potential to advance histopathological image analysis\nand cancer diagnosis. The code is made available at:\nhttps://github.com/AyushRoy2001/AWGUNET.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08425v1",
    "published_date": "2024-06-12 17:10:27 UTC",
    "updated_date": "2024-06-12 17:10:27 UTC"
  },
  {
    "arxiv_id": "2406.11883v1",
    "title": "Data Petri Nets meet Probabilistic Programming (Extended version)",
    "authors": [
      "Martin Kuhn",
      "Joscha Grüger",
      "Christoph Matheja",
      "Andrey Rivkin"
    ],
    "abstract": "Probabilistic programming (PP) is a programming paradigm that allows for\nwriting statistical models like ordinary programs, performing simulations by\nrunning those programs, and analyzing and refining their statistical behavior\nusing powerful inference engines. This paper takes a step towards leveraging PP\nfor reasoning about data-aware processes. To this end, we present a systematic\ntranslation of Data Petri Nets (DPNs) into a model written in a PP language\nwhose features are supported by most PP systems. We show that our translation\nis sound and provides statistical guarantees for simulating DPNs. Furthermore,\nwe discuss how PP can be used for process mining tasks and report on a\nprototype implementation of our translation. We also discuss further analysis\nscenarios that could be easily approached based on the proposed translation and\navailable PP tools.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11883v1",
    "published_date": "2024-06-12 17:07:35 UTC",
    "updated_date": "2024-06-12 17:07:35 UTC"
  },
  {
    "arxiv_id": "2406.08423v1",
    "title": "State Soup: In-Context Skill Learning, Retrieval and Mixing",
    "authors": [
      "Maciej Pióro",
      "Maciej Wołczyk",
      "Razvan Pascanu",
      "Johannes von Oswald",
      "João Sacramento"
    ],
    "abstract": "A new breed of gated-linear recurrent neural networks has reached\nstate-of-the-art performance on a range of sequence modeling problems. Such\nmodels naturally handle long sequences efficiently, as the cost of processing a\nnew input is independent of sequence length. Here, we explore another advantage\nof these stateful sequence models, inspired by the success of model merging\nthrough parameter interpolation. Building on parallels between fine-tuning and\nin-context learning, we investigate whether we can treat internal states as\ntask vectors that can be stored, retrieved, and then linearly combined,\nexploiting the linearity of recurrence. We study this form of fast model\nmerging on Mamba-2.8b, a pretrained recurrent model, and present preliminary\nevidence that simple linear state interpolation methods suffice to improve\nnext-token perplexity as well as downstream in-context learning task\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08423v1",
    "published_date": "2024-06-12 17:06:07 UTC",
    "updated_date": "2024-06-12 17:06:07 UTC"
  },
  {
    "arxiv_id": "2406.08418v3",
    "title": "OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text",
    "authors": [
      "Qingyun Li",
      "Zhe Chen",
      "Weiyun Wang",
      "Wenhai Wang",
      "Shenglong Ye",
      "Zhenjiang Jin",
      "Guanzhou Chen",
      "Yinan He",
      "Zhangwei Gao",
      "Erfei Cui",
      "Jiashuo Yu",
      "Hao Tian",
      "Jiasheng Zhou",
      "Chao Xu",
      "Bin Wang",
      "Xingjian Wei",
      "Wei Li",
      "Wenjian Zhang",
      "Bo Zhang",
      "Pinlong Cai",
      "Licheng Wen",
      "Xiangchao Yan",
      "Zhenxiang Li",
      "Pei Chu",
      "Yi Wang",
      "Min Dou",
      "Changyao Tian",
      "Xizhou Zhu",
      "Lewei Lu",
      "Yushi Chen",
      "Junjun He",
      "Zhongying Tu",
      "Tong Lu",
      "Yali Wang",
      "Limin Wang",
      "Dahua Lin",
      "Yu Qiao",
      "Botian Shi",
      "Conghui He",
      "Jifeng Dai"
    ],
    "abstract": "Image-text interleaved data, consisting of multiple images and texts arranged\nin a natural document format, aligns with the presentation paradigm of internet\ndata and closely resembles human reading habits. Recent studies have shown that\nsuch data aids multimodal in-context learning and maintains the capabilities of\nlarge language models during multimodal fine-tuning. However, the limited scale\nand diversity of current image-text interleaved data restrict the development\nof multimodal large language models. In this paper, we introduce OmniCorpus, a\n10 billion-scale image-text interleaved dataset. Using an efficient data\nengine, we filter and extract large-scale high-quality documents, which contain\n8.6 billion images and 1,696 billion text tokens. Compared to counterparts\n(e.g., MMC4, OBELICS), our dataset 1) has 15 times larger scales while\nmaintaining good data quality; 2) features more diverse sources, including both\nEnglish and non-English websites as well as video-centric websites; 3) is more\nflexible, easily degradable from an image-text interleaved format to pure text\ncorpus and image-text pairs. Through comprehensive analysis and experiments, we\nvalidate the quality, usability, and effectiveness of the proposed dataset. We\nhope this could provide a solid data foundation for future multimodal model\nresearch. Code and data are released at\nhttps://github.com/OpenGVLab/OmniCorpus.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08418v3",
    "published_date": "2024-06-12 17:01:04 UTC",
    "updated_date": "2024-07-12 08:54:51 UTC"
  },
  {
    "arxiv_id": "2406.08411v2",
    "title": "Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness Communication: Extending the CASA Paradigm",
    "authors": [
      "Xinyan Zhao",
      "Yuan Sun",
      "Wenlin Liu",
      "Chau-Wai Wong"
    ],
    "abstract": "This study is among the first to develop different prototypes of generative\nartificial intelligence (GenAI) chatbots powered by GPT-4 to communicate\nhurricane preparedness information to diverse residents. Drawing from the\nComputers Are Social Actors paradigm and the literature on disaster\nvulnerability and cultural tailoring, we conducted a between-subjects\nexperiment with 441 Black, Hispanic, and Caucasian residents of Florida. Our\nresults suggest that GenAI chatbots varying in tone formality and cultural\ntailoring significantly influence perceptions of their friendliness and\ncredibility, which, in turn, relate to hurricane preparedness outcomes. These\nresults highlight the potential of using GenAI chatbots to improve diverse\ncommunities' disaster preparedness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "68U15"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for Publication in Journal of Computer-Mediated\n  Communication",
    "pdf_url": "http://arxiv.org/pdf/2406.08411v2",
    "published_date": "2024-06-12 16:57:28 UTC",
    "updated_date": "2025-02-02 03:43:34 UTC"
  },
  {
    "arxiv_id": "2406.08407v3",
    "title": "MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos",
    "authors": [
      "Xuehai He",
      "Weixi Feng",
      "Kaizhi Zheng",
      "Yujie Lu",
      "Wanrong Zhu",
      "Jiachen Li",
      "Yue Fan",
      "Jianfeng Wang",
      "Linjie Li",
      "Zhengyuan Yang",
      "Kevin Lin",
      "William Yang Wang",
      "Lijuan Wang",
      "Xin Eric Wang"
    ],
    "abstract": "Multimodal Language Language Models (MLLMs) demonstrate the emerging\nabilities of \"world models\" -- interpreting and reasoning about complex\nreal-world dynamics. To assess these abilities, we posit videos are the ideal\nmedium, as they encapsulate rich representations of real-world dynamics and\ncausalities. To this end, we introduce MMWorld, a new benchmark for\nmulti-discipline, multi-faceted multimodal video understanding. MMWorld\ndistinguishes itself from previous video understanding benchmarks with two\nunique advantages: (1) multi-discipline, covering various disciplines that\noften require domain expertise for comprehensive understanding; (2)\nmulti-faceted reasoning, including explanation, counterfactual thinking, future\nprediction, etc. MMWorld consists of a human-annotated dataset to evaluate\nMLLMs with questions about the whole videos and a synthetic dataset to analyze\nMLLMs within a single modality of perception. Together, MMWorld encompasses\n1,910 videos across seven broad disciplines and 69 subdisciplines, complete\nwith 6,627 question-answer pairs and associated captions. The evaluation\nincludes 2 proprietary and 10 open-source MLLMs, which struggle on MMWorld\n(e.g., GPT-4V performs the best with only 52.3\\% accuracy), showing large room\nfor improvement. Further ablation studies reveal other interesting findings\nsuch as models' different skill sets from humans. We hope MMWorld can serve as\nan essential step towards world model evaluation in videos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08407v3",
    "published_date": "2024-06-12 16:54:54 UTC",
    "updated_date": "2024-07-30 03:15:55 UTC"
  },
  {
    "arxiv_id": "2406.08404v1",
    "title": "Scaling Value Iteration Networks to 5000 Layers for Extreme Long-Term Planning",
    "authors": [
      "Yuhui Wang",
      "Qingyuan Wu",
      "Weida Li",
      "Dylan R. Ashley",
      "Francesco Faccio",
      "Chao Huang",
      "Jürgen Schmidhuber"
    ],
    "abstract": "The Value Iteration Network (VIN) is an end-to-end differentiable\narchitecture that performs value iteration on a latent MDP for planning in\nreinforcement learning (RL). However, VINs struggle to scale to long-term and\nlarge-scale planning tasks, such as navigating a $100\\times 100$ maze -- a task\nwhich typically requires thousands of planning steps to solve. We observe that\nthis deficiency is due to two issues: the representation capacity of the latent\nMDP and the planning module's depth. We address these by augmenting the latent\nMDP with a dynamic transition kernel, dramatically improving its\nrepresentational capacity, and, to mitigate the vanishing gradient problem,\nintroducing an \"adaptive highway loss\" that constructs skip connections to\nimprove gradient flow. We evaluate our method on both 2D maze navigation\nenvironments and the ViZDoom 3D navigation benchmark. We find that our new\nmethod, named Dynamic Transition VIN (DT-VIN), easily scales to 5000 layers and\ncasually solves challenging versions of the above tasks. Altogether, we believe\nthat DT-VIN represents a concrete step forward in performing long-term\nlarge-scale planning in RL environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08404v1",
    "published_date": "2024-06-12 16:52:54 UTC",
    "updated_date": "2024-06-12 16:52:54 UTC"
  },
  {
    "arxiv_id": "2406.08534v2",
    "title": "Optimizing Container Loading and Unloading through Dual-Cycling and Dockyard Rehandle Reduction Using a Hybrid Genetic Algorithm",
    "authors": [
      "Md. Mahfuzur Rahman",
      "Md Abrar Jahin",
      "Md. Saiful Islam",
      "M. F. Mridha"
    ],
    "abstract": "This paper addresses the optimization of container unloading and loading\noperations at ports, integrating quay-crane dual-cycling with dockyard rehandle\nminimization. We present a unified model encompassing both operations: ship\ncontainer unloading and loading by quay crane, and the other is reducing\ndockyard rehandles while loading the ship. We recognize that optimizing one\naspect in isolation can lead to suboptimal outcomes due to interdependencies.\nSpecifically, optimizing unloading sequences for minimal operation time may\ninadvertently increase dockyard rehandles during loading and vice versa. To\naddress this NP-hard problem, we propose a hybrid genetic algorithm (GA)\nQCDC-DR-GA comprising one-dimensional and two-dimensional GA components. Our\nmodel, QCDC-DR-GA, consistently outperforms four state-of-the-art methods in\nmaximizing dual cycles and minimizing dockyard rehandles. Compared to those\nmethods, it reduced 15-20% of total operation time for large vessels.\nStatistical validation through a two-tailed paired t-test confirms the\nsuperiority of QCDC-DR-GA at a 5% significance level. The approach effectively\ncombines QCDC optimization with dockyard rehandle minimization, optimizing the\ntotal unloading-loading time. Results underscore the inefficiency of separately\noptimizing QCDC and dockyard rehandles. Fragmented approaches, such as QCDC\nScheduling Optimized by bi-level GA and GA-ILSRS (Scenario 2), show limited\nimprovement compared to QCDC-DR-GA. As in GA-ILSRS (Scenario 1), neglecting\ndual-cycle optimization leads to inferior performance than QCDC-DR-GA. This\nemphasizes the necessity of simultaneously considering both aspects for optimal\nresource utilization and overall operational efficiency.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08534v2",
    "published_date": "2024-06-12 16:47:45 UTC",
    "updated_date": "2024-12-04 12:53:37 UTC"
  },
  {
    "arxiv_id": "2406.08398v1",
    "title": "cPAPERS: A Dataset of Situated and Multimodal Interactive Conversations in Scientific Papers",
    "authors": [
      "Anirudh Sundar",
      "Jin Xu",
      "William Gay",
      "Christopher Richardson",
      "Larry Heck"
    ],
    "abstract": "An emerging area of research in situated and multimodal interactive\nconversations (SIMMC) includes interactions in scientific papers. Since\nscientific papers are primarily composed of text, equations, figures, and\ntables, SIMMC methods must be developed specifically for each component to\nsupport the depth of inquiry and interactions required by research scientists.\nThis work introduces Conversational Papers (cPAPERS), a dataset of\nconversational question-answer pairs from reviews of academic papers grounded\nin these paper components and their associated references from scientific\ndocuments available on arXiv. We present a data collection strategy to collect\nthese question-answer pairs from OpenReview and associate them with contextual\ninformation from LaTeX source files. Additionally, we present a series of\nbaseline approaches utilizing Large Language Models (LLMs) in both zero-shot\nand fine-tuned configurations to address the cPAPERS dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2406.08398v1",
    "published_date": "2024-06-12 16:46:12 UTC",
    "updated_date": "2024-06-12 16:46:12 UTC"
  },
  {
    "arxiv_id": "2406.08396v1",
    "title": "Neural Blind Source Separation and Diarization for Distant Speech Recognition",
    "authors": [
      "Yoshiaki Bando",
      "Tomohiko Nakamura",
      "Shinji Watanabe"
    ],
    "abstract": "This paper presents a neural method for distant speech recognition (DSR) that\njointly separates and diarizes speech mixtures without supervision by isolated\nsignals. A standard separation method for multi-talker DSR is a statistical\nmultichannel method called guided source separation (GSS). While GSS does not\nrequire signal-level supervision, it relies on speaker diarization results to\nhandle unknown numbers of active speakers. To overcome this limitation, we\nintroduce and train a neural inference model in a weakly-supervised manner,\nemploying the objective function of a statistical separation method. This\ntraining requires only multichannel mixtures and their temporal annotations of\nspeaker activities. In contrast to GSS, the trained model can jointly separate\nand diarize speech mixtures without any auxiliary information. The experiments\nwith the AMI corpus show that our method outperforms GSS with oracle\ndiarization results regarding word error rates. The code is available online.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 3 figures, accepted to INTERSPEECH 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08396v1",
    "published_date": "2024-06-12 16:45:35 UTC",
    "updated_date": "2024-06-12 16:45:35 UTC"
  },
  {
    "arxiv_id": "2406.08391v2",
    "title": "Large Language Models Must Be Taught to Know What They Don't Know",
    "authors": [
      "Sanyam Kapoor",
      "Nate Gruver",
      "Manley Roberts",
      "Katherine Collins",
      "Arka Pal",
      "Umang Bhatt",
      "Adrian Weller",
      "Samuel Dooley",
      "Micah Goldblum",
      "Andrew Gordon Wilson"
    ],
    "abstract": "When using large language models (LLMs) in high-stakes applications, we need\nto know when we can trust their predictions. Some works argue that prompting\nhigh-performance LLMs is sufficient to produce calibrated uncertainties, while\nothers introduce sampling methods that can be prohibitively expensive. In this\nwork, we first argue that prompting on its own is insufficient to achieve good\ncalibration and then show that fine-tuning on a small dataset of correct and\nincorrect answers can create an uncertainty estimate with good generalization\nand small computational overhead. We show that a thousand graded examples are\nsufficient to outperform baseline methods and that training through the\nfeatures of a model is necessary for good performance and tractable for large\nopen-source models when using LoRA. We also investigate the mechanisms that\nenable reliable LLM uncertainty estimation, finding that many models can be\nused as general-purpose uncertainty estimators, applicable not just to their\nown uncertainties but also the uncertainty of other models. Lastly, we show\nthat uncertainty estimates inform human use of LLMs in human-AI collaborative\nsettings through a user study.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2406.08391v2",
    "published_date": "2024-06-12 16:41:31 UTC",
    "updated_date": "2024-12-05 23:48:19 UTC"
  },
  {
    "arxiv_id": "2406.08384v2",
    "title": "Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models",
    "authors": [
      "Javier Nistal",
      "Marco Pasini",
      "Cyran Aouameur",
      "Maarten Grachten",
      "Stefan Lattner"
    ],
    "abstract": "Recent advancements in deep generative models present new opportunities for\nmusic production but also pose challenges, such as high computational demands\nand limited audio quality. Moreover, current systems frequently rely solely on\ntext input and typically focus on producing complete musical pieces, which is\nincompatible with existing workflows in music production. To address these\nissues, we introduce \"Diff-A-Riff,\" a Latent Diffusion Model designed to\ngenerate high-quality instrumental accompaniments adaptable to any musical\ncontext. This model offers control through either audio references, text\nprompts, or both, and produces 48kHz pseudo-stereo audio while significantly\nreducing inference time and memory usage. We demonstrate the model's\ncapabilities through objective metrics and subjective listening tests, with\nextensive examples available on the accompanying website:\nsonycslparis.github.io/diffariff-companion/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.08384v2",
    "published_date": "2024-06-12 16:34:26 UTC",
    "updated_date": "2024-10-30 14:33:27 UTC"
  },
  {
    "arxiv_id": "2406.08374v2",
    "title": "2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction",
    "authors": [
      "Tianqi Chen",
      "Jun Hou",
      "Yinchi Zhou",
      "Huidong Xie",
      "Xiongchao Chen",
      "Qiong Liu",
      "Xueqi Guo",
      "Menghua Xia",
      "James S. Duncan",
      "Chi Liu",
      "Bo Zhou"
    ],
    "abstract": "Positron Emission Tomography (PET) is an important clinical imaging tool but\ninevitably introduces radiation hazards to patients and healthcare providers.\nReducing the tracer injection dose and eliminating the CT acquisition for\nattenuation correction can reduce the overall radiation dose, but often results\nin PET with high noise and bias. Thus, it is desirable to develop 3D methods to\ntranslate the non-attenuation-corrected low-dose PET (NAC-LDPET) into\nattenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models\nhave emerged as a new state-of-the-art deep learning method for image-to-image\ntranslation, better than traditional CNN-based methods. However, due to the\nhigh computation cost and memory burden, it is largely limited to 2D\napplications. To address these challenges, we developed a novel 2.5D Multi-view\nAveraging Diffusion Model (MADM) for 3D image-to-image translation with\napplication on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs\nseparate diffusion models for axial, coronal, and sagittal views, whose outputs\nare averaged in each sampling step to ensure the 3D generation quality from\nmultiple views. To accelerate the 3D sampling process, we also proposed a\nstrategy to use the CNN-based 3D generation as a prior for the diffusion model.\nOur experimental results on human patient studies suggested that MADM can\ngenerate high-quality 3D translation images, outperforming previous CNN-based\nand Diffusion-based baseline methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08374v2",
    "published_date": "2024-06-12 16:22:41 UTC",
    "updated_date": "2024-06-15 15:36:30 UTC"
  },
  {
    "arxiv_id": "2406.08358v1",
    "title": "From a Social Cognitive Perspective: Context-aware Visual Social Relationship Recognition",
    "authors": [
      "Shiwei Wu",
      "Chao Zhang",
      "Joya Chen",
      "Tong Xu",
      "Likang Wu",
      "Yao Hu",
      "Enhong Chen"
    ],
    "abstract": "People's social relationships are often manifested through their\nsurroundings, with certain objects or interactions acting as symbols for\nspecific relationships, e.g., wedding rings, roses, hugs, or holding hands.\nThis brings unique challenges to recognizing social relationships, requiring\nunderstanding and capturing the essence of these contexts from visual\nappearances. However, current methods of social relationship understanding rely\non the basic classification paradigm of detected persons and objects, which\nfails to understand the comprehensive context and often overlooks decisive\nsocial factors, especially subtle visual cues. To highlight the social-aware\ncontext and intricate details, we propose a novel approach that recognizes\n\\textbf{Con}textual \\textbf{So}cial \\textbf{R}elationships (\\textbf{ConSoR})\nfrom a social cognitive perspective. Specifically, to incorporate social-aware\nsemantics, we build a lightweight adapter upon the frozen CLIP to learn social\nconcepts via our novel multi-modal side adapter tuning mechanism. Further, we\nconstruct social-aware descriptive language prompts (e.g., scene, activity,\nobjects, emotions) with social relationships for each image, and then compel\nConSoR to concentrate more intensively on the decisive visual social factors\nvia visual-linguistic contrasting. Impressively, ConSoR outperforms previous\nmethods with a 12.2\\% gain on the People-in-Social-Context (PISC) dataset and a\n9.8\\% increase on the People-in-Photo-Album (PIPA) benchmark. Furthermore, we\nobserve that ConSoR excels at finding critical visual evidence to reveal social\nrelationships.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08358v1",
    "published_date": "2024-06-12 16:02:28 UTC",
    "updated_date": "2024-06-12 16:02:28 UTC"
  },
  {
    "arxiv_id": "2406.08354v1",
    "title": "DocSynthv2: A Practical Autoregressive Modeling for Document Generation",
    "authors": [
      "Sanket Biswas",
      "Rajiv Jain",
      "Vlad I. Morariu",
      "Jiuxiang Gu",
      "Puneet Mathur",
      "Curtis Wigington",
      "Tong Sun",
      "Josep Lladós"
    ],
    "abstract": "While the generation of document layouts has been extensively explored,\ncomprehensive document generation encompassing both layout and content presents\na more complex challenge. This paper delves into this advanced domain,\nproposing a novel approach called DocSynthv2 through the development of a\nsimple yet effective autoregressive structured model. Our model, distinct in\nits integration of both layout and textual cues, marks a step beyond existing\nlayout-generation approaches. By focusing on the relationship between the\nstructural elements and the textual content within documents, we aim to\ngenerate cohesive and contextually relevant documents without any reliance on\nvisual components. Through experimental studies on our curated benchmark for\nthe new task, we demonstrate the ability of our model combining layout and\ntextual information in enhancing the generation quality and relevance of\ndocuments, opening new pathways for research in document creation and automated\ndesign. Our findings emphasize the effectiveness of autoregressive models in\nhandling complex document generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Spotlight (Oral) Acceptance to CVPR 2024 Workshop for Graphic Design\n  Understanding and Generation (GDUG)",
    "pdf_url": "http://arxiv.org/pdf/2406.08354v1",
    "published_date": "2024-06-12 16:00:16 UTC",
    "updated_date": "2024-06-12 16:00:16 UTC"
  },
  {
    "arxiv_id": "2406.08343v1",
    "title": "Continuous-Time Digital Twin with Analogue Memristive Neural Ordinary Differential Equation Solver",
    "authors": [
      "Hegan Chen",
      "Jichang Yang",
      "Jia Chen",
      "Songqi Wang",
      "Shaocong Wang",
      "Dingchen Wang",
      "Xinyu Tian",
      "Yifei Yu",
      "Xi Chen",
      "Yinan Lin",
      "Yangu He",
      "Xiaoshan Wu",
      "Yi Li",
      "Xinyuan Zhang",
      "Ning Lin",
      "Meng Xu",
      "Yi Li",
      "Xumeng Zhang",
      "Zhongrui Wang",
      "Han Wang",
      "Dashan Shang",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Ming Liu"
    ],
    "abstract": "Digital twins, the cornerstone of Industry 4.0, replicate real-world entities\nthrough computer models, revolutionising fields such as manufacturing\nmanagement and industrial automation. Recent advances in machine learning\nprovide data-driven methods for developing digital twins using discrete-time\ndata and finite-depth models on digital computers. However, this approach fails\nto capture the underlying continuous dynamics and struggles with modelling\ncomplex system behaviour. Additionally, the architecture of digital computers,\nwith separate storage and processing units, necessitates frequent data\ntransfers and Analogue-Digital (A/D) conversion, thereby significantly\nincreasing both time and energy costs. Here, we introduce a memristive neural\nordinary differential equation (ODE) solver for digital twins, which is capable\nof capturing continuous-time dynamics and facilitates the modelling of complex\nsystems using an infinite-depth model. By integrating storage and computation\nwithin analogue memristor arrays, we circumvent the von Neumann bottleneck,\nthus enhancing both speed and energy efficiency. We experimentally validate our\napproach by developing a digital twin of the HP memristor, which accurately\nextrapolates its nonlinear dynamics, achieving a 4.2-fold projected speedup and\na 41.4-fold projected decrease in energy consumption compared to\nstate-of-the-art digital hardware, while maintaining an acceptable error\nmargin. Additionally, we demonstrate scalability through experimentally\ngrounded simulations of Lorenz96 dynamics, exhibiting projected performance\nimprovements of 12.6-fold in speed and 189.7-fold in energy efficiency relative\nto traditional digital approaches. By harnessing the capabilities of fully\nanalogue computing, our breakthrough accelerates the development of digital\ntwins, offering an efficient and rapid solution to meet the demands of Industry\n4.0.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08343v1",
    "published_date": "2024-06-12 15:50:35 UTC",
    "updated_date": "2024-06-12 15:50:35 UTC"
  },
  {
    "arxiv_id": "2406.08335v1",
    "title": "A Survey of Pipeline Tools for Data Engineering",
    "authors": [
      "Anthony Mbata",
      "Yaji Sripada",
      "Mingjun Zhong"
    ],
    "abstract": "Currently, a variety of pipeline tools are available for use in data\nengineering. Data scientists can use these tools to resolve data wrangling\nissues associated with data and accomplish some data engineering tasks from\ndata ingestion through data preparation to utilization as input for machine\nlearning (ML). Some of these tools have essential built-in components or can be\ncombined with other tools to perform desired data engineering operations. While\nsome tools are wholly or partly commercial, several open-source tools are\navailable to perform expert-level data engineering tasks. This survey examines\nthe broad categories and examples of pipeline tools based on their design and\ndata engineering intentions. These categories are Extract Transform\nLoad/Extract Load Transform (ETL/ELT), pipelines for Data Integration,\nIngestion, and Transformation, Data Pipeline Orchestration and Workflow\nManagement, and Machine Learning Pipelines. The survey also provides a broad\noutline of the utilization with examples within these broad groups and finally,\na discussion is presented with case studies indicating the usage of pipeline\ntools for data engineering. The studies present some first-user application\nexperiences with sample data, some complexities of the applied pipeline, and a\nsummary note of approaches to using these tools to prepare data for machine\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "stat.CO"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08335v1",
    "published_date": "2024-06-12 15:41:06 UTC",
    "updated_date": "2024-06-12 15:41:06 UTC"
  },
  {
    "arxiv_id": "2406.08334v1",
    "title": "ProTrain: Efficient LLM Training via Memory-Aware Techniques",
    "authors": [
      "Hanmei Yang",
      "Jin Zhou",
      "Yao Fu",
      "Xiaoqun Wang",
      "Ramine Roane",
      "Hui Guan",
      "Tongping Liu"
    ],
    "abstract": "It is extremely memory-hungry to train Large Language Models (LLM). To solve\nthis problem, existing work exploits the combination of CPU and GPU for the\ntraining process, such as ZeRO-Offload. Such a technique largely democratizes\nbillion-scale model training, making it possible to train with few consumer\ngraphics cards. However, based on our observation, existing frameworks often\nprovide coarse-grained memory management and require experienced experts in\nconfiguration tuning, leading to suboptimal hardware utilization and\nperformance. This paper proposes ProTrain, a novel training system that\nintelligently balances memory usage and performance by coordinating memory,\ncomputation, and IO. ProTrain achieves adaptive memory management through\nChunk-Based Model State Management and Block-Wise Activation Management, guided\nby a Memory-Aware Runtime Profiler without user intervention. ProTrain does not\nchange the training algorithm and thus does not compromise accuracy.\nExperiments show that ProTrain improves training throughput by 1.43$\\times$ to\n2.71$\\times$ compared to the SOTA training systems.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08334v1",
    "published_date": "2024-06-12 15:40:06 UTC",
    "updated_date": "2024-06-12 15:40:06 UTC"
  },
  {
    "arxiv_id": "2406.08330v1",
    "title": "It's all about PR -- Smart Benchmarking AI Accelerators using Performance Representatives",
    "authors": [
      "Alexander Louis-Ferdinand Jung",
      "Jannik Steinmetz",
      "Jonathan Gietz",
      "Konstantin Lübeck",
      "Oliver Bringmann"
    ],
    "abstract": "Statistical models are widely used to estimate the performance of commercial\noff-the-shelf (COTS) AI hardware accelerators. However, training of statistical\nperformance models often requires vast amounts of data, leading to a\nsignificant time investment and can be difficult in case of limited hardware\navailability. To alleviate this problem, we propose a novel performance\nmodeling methodology that significantly reduces the number of training samples\nwhile maintaining good accuracy. Our approach leverages knowledge of the target\nhardware architecture and initial parameter sweeps to identify a set of\nPerformance Representatives (PR) for deep neural network (DNN) layers. These\nPRs are then used for benchmarking, building a statistical performance model,\nand making estimations. This targeted approach drastically reduces the number\nof training samples needed, opposed to random sampling, to achieve a better\nestimation accuracy. We achieve a Mean Absolute Percentage Error (MAPE) of as\nlow as 0.02% for single-layer estimations and 0.68% for whole DNN estimations\nwith less than 10000 training samples. The results demonstrate the superiority\nof our method for single-layer estimations compared to models trained with\nrandomly sampled datasets of the same size.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "Accepted version for: SAMOS'24",
    "pdf_url": "http://arxiv.org/pdf/2406.08330v1",
    "published_date": "2024-06-12 15:34:28 UTC",
    "updated_date": "2024-06-12 15:34:28 UTC"
  },
  {
    "arxiv_id": "2406.08316v3",
    "title": "Is Programming by Example solved by LLMs?",
    "authors": [
      "Wen-Ding Li",
      "Kevin Ellis"
    ],
    "abstract": "Programming-by-Examples (PBE) aims to generate an algorithm from input-output\nexamples. Such systems are practically and theoretically important: from an\nend-user perspective, they are deployed to millions of people, and from an AI\nperspective, PBE corresponds to a very general form of few-shot inductive\ninference. Given the success of Large Language Models (LLMs) in code-generation\ntasks, we investigate here the extent to which LLMs can be said to have\n\"solved\" PBE. We experiment on classic domains such as lists and strings, and\nan uncommon graphics programming domain not well represented in typical\npretraining data. We find that pretrained models are not effective at PBE, but\nthat they can be fine-tuned for much higher performance, provided the test\nproblems are in-distribution. We analyze empirically what causes these models\nto succeed and fail, and take steps toward understanding how to achieve better\nout-of-distribution generalization. Collectively these results suggest that\nLLMs make strong progress toward solving the typical suite of PBE tasks,\npotentially increasing the flexibility and applicability of PBE systems, while\nalso identifying ways in which LLMs still fall short.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08316v3",
    "published_date": "2024-06-12 15:16:40 UTC",
    "updated_date": "2024-11-19 17:49:27 UTC"
  },
  {
    "arxiv_id": "2406.08315v2",
    "title": "Improving Policy Optimization via $\\varepsilon$-Retrain",
    "authors": [
      "Luca Marzari",
      "Priya L. Donti",
      "Changliu Liu",
      "Enrico Marchesini"
    ],
    "abstract": "We present $\\varepsilon$-retrain, an exploration strategy encouraging a\nbehavioral preference while optimizing policies with monotonic improvement\nguarantees. To this end, we introduce an iterative procedure for collecting\nretrain areas -- parts of the state space where an agent did not satisfy the\nbehavioral preference. Our method switches between the typical uniform restart\nstate distribution and the retrain areas using a decaying factor $\\varepsilon$,\nallowing agents to retrain on situations where they violated the preference. We\nalso employ formal verification of neural networks to provably quantify the\ndegree to which agents adhere to these behavioral preferences. Experiments over\nhundreds of seeds across locomotion, power network, and navigation tasks show\nthat our method yields agents that exhibit significant performance and sample\nefficiency improvements.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.08315v2",
    "published_date": "2024-06-12 15:16:26 UTC",
    "updated_date": "2025-04-14 14:36:00 UTC"
  },
  {
    "arxiv_id": "2406.08311v2",
    "title": "Causality for Tabular Data Synthesis: A High-Order Structure Causal Benchmark Framework",
    "authors": [
      "Ruibo Tu",
      "Zineb Senane",
      "Lele Cao",
      "Cheng Zhang",
      "Hedvig Kjellström",
      "Gustav Eje Henter"
    ],
    "abstract": "Tabular synthesis models remain ineffective at capturing complex\ndependencies, and the quality of synthetic data is still insufficient for\ncomprehensive downstream tasks, such as prediction under distribution shifts,\nautomated decision-making, and cross-table understanding. A major challenge is\nthe lack of prior knowledge about underlying structures and high-order\nrelationships in tabular data. We argue that a systematic evaluation on\nhigh-order structural information for tabular data synthesis is the first step\ntowards solving the problem. In this paper, we introduce high-order structural\ncausal information as natural prior knowledge and provide a benchmark framework\nfor the evaluation of tabular synthesis models. The framework allows us to\ngenerate benchmark datasets with a flexible range of data generation processes\nand to train tabular synthesis models using these datasets for further\nevaluation. We propose multiple benchmark tasks, high-order metrics, and causal\ninference tasks as downstream tasks for evaluating the quality of synthetic\ndata generated by the trained models. Our experiments demonstrate to leverage\nthe benchmark framework for evaluating the model capability of capturing\nhigh-order structural causal information. Furthermore, our benchmarking results\nprovide an initial assessment of state-of-the-art tabular synthesis models.\nThey have clearly revealed significant gaps between ideal and actual\nperformance and how baseline methods differ. Our benchmark framework is\navailable at URL https://github.com/TURuibo/CauTabBench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08311v2",
    "published_date": "2024-06-12 15:12:49 UTC",
    "updated_date": "2024-07-05 06:44:33 UTC"
  },
  {
    "arxiv_id": "2407.02503v1",
    "title": "Optimizing Deep Reinforcement Learning for Adaptive Robotic Arm Control",
    "authors": [
      "Jonaid Shianifar",
      "Michael Schukat",
      "Karl Mason"
    ],
    "abstract": "In this paper, we explore the optimization of hyperparameters for the Soft\nActor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms using the\nTree-structured Parzen Estimator (TPE) in the context of robotic arm control\nwith seven Degrees of Freedom (DOF). Our results demonstrate a significant\nenhancement in algorithm performance, TPE improves the success rate of SAC by\n10.48 percentage points and PPO by 34.28 percentage points, where models\ntrained for 50K episodes. Furthermore, TPE enables PPO to converge to a reward\nwithin 95% of the maximum reward 76% faster than without TPE, which translates\nto about 40K fewer episodes of training required for optimal performance. Also,\nthis improvement for SAC is 80% faster than without TPE. This study underscores\nthe impact of advanced hyperparameter optimization on the efficiency and\nsuccess of deep reinforcement learning algorithms in complex robotic tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02503v1",
    "published_date": "2024-06-12 15:06:54 UTC",
    "updated_date": "2024-06-12 15:06:54 UTC"
  },
  {
    "arxiv_id": "2406.11882v1",
    "title": "Applications of Explainable artificial intelligence in Earth system science",
    "authors": [
      "Feini Huang",
      "Shijie Jiang",
      "Lu Li",
      "Yongkun Zhang",
      "Ye Zhang",
      "Ruqing Zhang",
      "Qingliang Li",
      "Danxi Li",
      "Wei Shangguan",
      "Yongjiu Dai"
    ],
    "abstract": "In recent years, artificial intelligence (AI) rapidly accelerated its\ninfluence and is expected to promote the development of Earth system science\n(ESS) if properly harnessed. In application of AI to ESS, a significant hurdle\nlies in the interpretability conundrum, an inherent problem of black-box nature\narising from the complexity of AI algorithms. To address this, explainable AI\n(XAI) offers a set of powerful tools that make the models more transparent. The\npurpose of this review is twofold: First, to provide ESS scholars, especially\nnewcomers, with a foundational understanding of XAI, serving as a primer to\ninspire future research advances; second, to encourage ESS professionals to\nembrace the benefits of AI, free from preconceived biases due to its lack of\ninterpretability. We begin with elucidating the concept of XAI, along with\ntypical methods. We then delve into a review of XAI applications in the ESS\nliterature, highlighting the important role that XAI has played in facilitating\ncommunication with AI model decisions, improving model diagnosis, and\nuncovering scientific insights. We identify four significant challenges that\nXAI faces within the ESS, and propose solutions. Furthermore, we provide a\ncomprehensive illustration of multifaceted perspectives. Given the unique\nchallenges in ESS, an interpretable hybrid approach that seamlessly integrates\nAI with domain-specific knowledge appears to be a promising way to enhance the\nutility of AI in ESS. A visionary outlook for ESS envisions a harmonious blend\nwhere process-based models govern the known, AI models explore the unknown, and\nXAI bridges the gap by providing explanations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11882v1",
    "published_date": "2024-06-12 15:05:29 UTC",
    "updated_date": "2024-06-12 15:05:29 UTC"
  },
  {
    "arxiv_id": "2406.08269v2",
    "title": "Analyzing constrained LLM through PDFA-learning",
    "authors": [
      "Matías Carrasco",
      "Franz Mayr",
      "Sergio Yovine",
      "Johny Kidd",
      "Martín Iturbide",
      "Juan Pedro da Silva",
      "Alejo Garat"
    ],
    "abstract": "We define a congruence that copes with null next-symbol probabilities that\narise when the output of a language model is constrained by some means during\ntext generation. We develop an algorithm for efficiently learning the quotient\nwith respect to this congruence and evaluate it on case studies for analyzing\nstatistical properties of LLM.",
    "categories": [
      "cs.FL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.FL",
    "comment": "Workshop Paper",
    "pdf_url": "http://arxiv.org/pdf/2406.08269v2",
    "published_date": "2024-06-12 14:35:19 UTC",
    "updated_date": "2024-06-15 04:00:54 UTC"
  },
  {
    "arxiv_id": "2406.08267v2",
    "title": "A deep cut into Split Federated Self-supervised Learning",
    "authors": [
      "Marcin Przewięźlikowski",
      "Marcin Osial",
      "Bartosz Zieliński",
      "Marek Śmieja"
    ],
    "abstract": "Collaborative self-supervised learning has recently become feasible in highly\ndistributed environments by dividing the network layers between client devices\nand a central server. However, state-of-the-art methods, such as MocoSFL, are\noptimized for network division at the initial layers, which decreases the\nprotection of the client data and increases communication overhead. In this\npaper, we demonstrate that splitting depth is crucial for maintaining privacy\nand communication efficiency in distributed training. We also show that MocoSFL\nsuffers from a catastrophic quality deterioration for the minimal communication\noverhead. As a remedy, we introduce Momentum-Aligned contrastive Split\nFederated Learning (MonAcoSFL), which aligns online and momentum client models\nduring training procedure. Consequently, we achieve state-of-the-art accuracy\nwhile significantly reducing the communication overhead, making MonAcoSFL more\npractical in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "European Conference on Machine Learning (ECML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08267v2",
    "published_date": "2024-06-12 14:35:13 UTC",
    "updated_date": "2025-03-17 16:59:40 UTC"
  },
  {
    "arxiv_id": "2406.08246v1",
    "title": "Leveraging Large Language Models for Web Scraping",
    "authors": [
      "Aman Ahluwalia",
      "Suhrud Wani"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in\nreplicating human tasks and boosting productivity. However, their direct\napplication for data extraction presents limitations due to a prioritisation of\nfluency over factual accuracy and a restricted ability to manipulate specific\ninformation. Therefore to overcome these limitations, this research leverages\nthe knowledge representation power of pre-trained LLMs and the targeted\ninformation access enabled by RAG models, this research investigates a\ngeneral-purpose accurate data scraping recipe for RAG models designed for\nlanguage generation. To capture knowledge in a more modular and interpretable\nway, we use pre trained language models with a latent knowledge retriever,\nwhich allows the model to retrieve and attend over documents from a large\ncorpus. We utilised RAG model architecture and did an in-depth analysis of\ntheir capabilities under three tasks: (i) Semantic Classification of HTML\nelements, (ii) Chunking HTML text for effective understanding, and (iii)\ncomparing results from different LLMs and ranking algorithms. While previous\nwork has developed dedicated architectures and training procedures for HTML\nunderstanding and extraction, we show that LLMs pre-trained on standard natural\nlanguage with an addition of effective chunking, searching and ranking\nalgorithms, can prove to be efficient data scraping tool to extract complex\ndata from unstructured text. Future research directions include addressing the\nchallenges of provenance tracking and dynamic knowledge updates within the\nproposed RAG-based data extraction framework. By overcoming these limitations,\nthis approach holds the potential to revolutionise data extraction from vast\nrepositories of textual information.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08246v1",
    "published_date": "2024-06-12 14:15:15 UTC",
    "updated_date": "2024-06-12 14:15:15 UTC"
  },
  {
    "arxiv_id": "2406.08231v1",
    "title": "Using Deep Convolutional Neural Networks to Detect Rendered Glitches in Video Games",
    "authors": [
      "Carlos Garcia Ling",
      "Konrad Tollmar",
      "Linus Gisslen"
    ],
    "abstract": "In this paper, we present a method using Deep Convolutional Neural Networks\n(DCNNs) to detect common glitches in video games. The problem setting consists\nof an image (800x800 RGB) as input to be classified into one of five defined\nclasses, normal image, or one of four different kinds of glitches (stretched,\nlow resolution, missing and placeholder textures). Using a supervised approach,\nwe train a ShuffleNetV2 using generated data. This work focuses on detecting\ntexture graphical anomalies achieving arguably good performance with an\naccuracy of 86.8\\%, detecting 88\\% of the glitches with a false positive rate\nof 8.7\\%, and with the models being able to generalize and detect glitches even\nin unseen objects. We apply a confidence measure as well to tackle the issue\nwith false positives as well as an effective way of aggregating images to\nachieve better detection in production. The main use of this work is the\npartial automatization of graphical testing in the final stages of video game\ndevelopment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures, AAIDE conference",
    "pdf_url": "http://arxiv.org/pdf/2406.08231v1",
    "published_date": "2024-06-12 13:59:45 UTC",
    "updated_date": "2024-06-12 13:59:45 UTC"
  },
  {
    "arxiv_id": "2406.08226v2",
    "title": "DistilDoc: Knowledge Distillation for Visually-Rich Document Applications",
    "authors": [
      "Jordy Van Landeghem",
      "Subhajit Maity",
      "Ayan Banerjee",
      "Matthew Blaschko",
      "Marie-Francine Moens",
      "Josep Lladós",
      "Sanket Biswas"
    ],
    "abstract": "This work explores knowledge distillation (KD) for visually-rich document\n(VRD) applications such as document layout analysis (DLA) and document image\nclassification (DIC). While VRD research is dependent on increasingly\nsophisticated and cumbersome models, the field has neglected to study\nefficiency via model compression. Here, we design a KD experimentation\nmethodology for more lean, performant models on document understanding (DU)\ntasks that are integral within larger task pipelines. We carefully selected KD\nstrategies (response-based, feature-based) for distilling knowledge to and from\nbackbones with different architectures (ResNet, ViT, DiT) and capacities (base,\nsmall, tiny). We study what affects the teacher-student knowledge gap and find\nthat some methods (tuned vanilla KD, MSE, SimKD with an apt projector) can\nconsistently outperform supervised student training. Furthermore, we design\ndownstream task setups to evaluate covariate shift and the robustness of\ndistilled DLA models on zero-shot layout-aware document visual question\nanswering (DocVQA). DLA-KD experiments result in a large mAP knowledge gap,\nwhich unpredictably translates to downstream robustness, accentuating the need\nto further explore how to efficiently obtain more semantic document layout\nawareness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICDAR 2024 (Athens, Greece)",
    "pdf_url": "http://arxiv.org/pdf/2406.08226v2",
    "published_date": "2024-06-12 13:55:12 UTC",
    "updated_date": "2025-03-12 11:58:36 UTC"
  },
  {
    "arxiv_id": "2406.08223v2",
    "title": "Research Trends for the Interplay between Large Language Models and Knowledge Graphs",
    "authors": [
      "Hanieh Khorashadizadeh",
      "Fatima Zahra Amara",
      "Morteza Ezzabady",
      "Frédéric Ieng",
      "Sanju Tiwari",
      "Nandana Mihindukulasooriya",
      "Jinghua Groppe",
      "Soror Sahri",
      "Farah Benamara",
      "Sven Groppe"
    ],
    "abstract": "This survey investigates the synergistic relationship between Large Language\nModels (LLMs) and Knowledge Graphs (KGs), which is crucial for advancing AI's\ncapabilities in understanding, reasoning, and language processing. It aims to\naddress gaps in current research by exploring areas such as KG Question\nAnswering, ontology generation, KG validation, and the enhancement of KG\naccuracy and consistency through LLMs. The paper further examines the roles of\nLLMs in generating descriptive texts and natural language queries for KGs.\nThrough a structured analysis that includes categorizing LLM-KG interactions,\nexamining methodologies, and investigating collaborative uses and potential\nbiases, this study seeks to provide new insights into the combined potential of\nLLMs and KGs. It highlights the importance of their interaction for improving\nAI applications and outlines future research directions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08223v2",
    "published_date": "2024-06-12 13:52:38 UTC",
    "updated_date": "2024-08-08 13:07:21 UTC"
  },
  {
    "arxiv_id": "2406.08222v2",
    "title": "A Sociotechnical Lens for Evaluating Computer Vision Models: A Case Study on Detecting and Reasoning about Gender and Emotion",
    "authors": [
      "Sha Luo",
      "Sang Jung Kim",
      "Zening Duan",
      "Kaiping Chen"
    ],
    "abstract": "In the evolving landscape of computer vision (CV) technologies, the automatic\ndetection and interpretation of gender and emotion in images is a critical area\nof study. This paper investigates social biases in CV models, emphasizing the\nlimitations of traditional evaluation metrics such as precision, recall, and\naccuracy. These metrics often fall short in capturing the complexities of\ngender and emotion, which are fluid and culturally nuanced constructs. Our\nstudy proposes a sociotechnical framework for evaluating CV models,\nincorporating both technical performance measures and considerations of social\nfairness. Using a dataset of 5,570 images related to vaccination and climate\nchange, we empirically compared the performance of various CV models, including\ntraditional models like DeepFace and FER, and generative models like GPT-4\nVision. Our analysis involved manually validating the gender and emotional\nexpressions in a subset of images to serve as benchmarks. Our findings reveal\nthat while GPT-4 Vision outperforms other models in technical accuracy for\ngender classification, it exhibits discriminatory biases, particularly in\nresponse to transgender and non-binary personas. Furthermore, the model's\nemotion detection skew heavily towards positive emotions, with a notable bias\ntowards associating female images with happiness, especially when prompted by\nmale personas. These findings underscore the necessity of developing more\ncomprehensive evaluation criteria that address both validity and discriminatory\nbiases in CV models. Our proposed framework provides guidelines for researchers\nto critically assess CV tools, ensuring their application in communication\nresearch is both ethical and effective. The significant contribution of this\nstudy lies in its emphasis on a sociotechnical approach, advocating for CV\ntechnologies that support social good and mitigate biases rather than\nperpetuate them.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08222v2",
    "published_date": "2024-06-12 13:52:30 UTC",
    "updated_date": "2024-11-21 18:14:58 UTC"
  },
  {
    "arxiv_id": "2406.08200v3",
    "title": "Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding",
    "authors": [
      "Rui Wang",
      "Liping Chen",
      "Kong AiK Lee",
      "Zhen-Hua Ling"
    ],
    "abstract": "Voice anonymization has been developed as a technique for preserving privacy\nby replacing the speaker's voice in a speech signal with that of a\npseudo-speaker, thereby obscuring the original voice attributes from machine\nrecognition and human perception. In this paper, we focus on altering the voice\nattributes against machine recognition while retaining human perception. We\nreferred to this as the asynchronous voice anonymization. To this end, a speech\ngeneration framework incorporating a speaker disentanglement mechanism is\nemployed to generate the anonymized speech. The speaker attributes are altered\nthrough adversarial perturbation applied on the speaker embedding, while human\nperception is preserved by controlling the intensity of perturbation.\nExperiments conducted on the LibriSpeech dataset showed that the speaker\nattributes were obscured with their human perception preserved for 60.71% of\nthe processed utterances.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accpeted by Interspeech2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08200v3",
    "published_date": "2024-06-12 13:33:24 UTC",
    "updated_date": "2024-11-12 06:46:41 UTC"
  },
  {
    "arxiv_id": "2406.08184v1",
    "title": "MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents",
    "authors": [
      "Luyuan Wang",
      "Yongyu Deng",
      "Yiwei Zha",
      "Guodong Mao",
      "Qinmin Wang",
      "Tianchen Min",
      "Wei Chen",
      "Shoufa Chen"
    ],
    "abstract": "Large language model (LLM)-based mobile agents are increasingly popular due\nto their capability to interact directly with mobile phone Graphic User\nInterfaces (GUIs) and their potential to autonomously manage daily tasks.\nDespite their promising prospects in both academic and industrial sectors,\nlittle research has focused on benchmarking the performance of existing mobile\nagents, due to the inexhaustible states of apps and the vague definition of\nfeasible action sequences. To address this challenge, we propose an efficient\nand user-friendly benchmark, MobileAgentBench, designed to alleviate the burden\nof extensive manual testing. We initially define 100 tasks across 10\nopen-source apps, categorized by multiple levels of difficulty. Subsequently,\nwe evaluate several existing mobile agents, including AppAgent and MobileAgent,\nto thoroughly and systematically compare their performance. All materials are\naccessible on our project webpage: https://MobileAgentBench.github.io,\ncontributing to the advancement of both academic and industrial fields.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08184v1",
    "published_date": "2024-06-12 13:14:50 UTC",
    "updated_date": "2024-06-12 13:14:50 UTC"
  },
  {
    "arxiv_id": "2406.08171v1",
    "title": "Continuous fake media detection: adapting deepfake detectors to new generative techniques",
    "authors": [
      "Francesco Tassone",
      "Luca Maiano",
      "Irene Amerini"
    ],
    "abstract": "Generative techniques continue to evolve at an impressively high rate, driven\nby the hype about these technologies. This rapid advancement severely limits\nthe application of deepfake detectors, which, despite numerous efforts by the\nscientific community, struggle to achieve sufficiently robust performance\nagainst the ever-changing content. To address these limitations, in this paper,\nwe propose an analysis of two continuous learning techniques on a Short and a\nLong sequence of fake media. Both sequences include a complex and heterogeneous\nrange of deepfakes generated from GANs, computer graphics techniques, and\nunknown sources. Our study shows that continual learning could be important in\nmitigating the need for generalizability. In fact, we show that, although with\nsome limitations, continual learning methods help to maintain good performance\nacross the entire training sequence. For these techniques to work in a\nsufficiently robust way, however, it is necessary that the tasks in the\nsequence share similarities. In fact, according to our experiments, the order\nand similarity of the tasks can affect the performance of the models over time.\nTo address this problem, we show that it is possible to group tasks based on\ntheir similarity. This small measure allows for a significant improvement even\nin longer sequences. This result suggests that continual techniques can be\ncombined with the most promising detection methods, allowing them to catch up\nwith the latest generative techniques. In addition to this, we propose an\noverview of how this learning approach can be integrated into a deepfake\ndetection pipeline for continuous integration and continuous deployment\n(CI/CD). This allows you to keep track of different funds, such as social\nnetworks, new generative tools, or third-party datasets, and through the\nintegration of continuous learning, allows constant maintenance of the\ndetectors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08171v1",
    "published_date": "2024-06-12 13:04:06 UTC",
    "updated_date": "2024-06-12 13:04:06 UTC"
  },
  {
    "arxiv_id": "2406.08155v2",
    "title": "QuantMoE-Bench: Examining Post-Training Quantization for Mixture-of-Experts",
    "authors": [
      "Pingzhi Li",
      "Xiaolong Jin",
      "Zhen Tan",
      "Yu Cheng",
      "Tianlong Chen"
    ],
    "abstract": "Mixture-of-Experts (MoE) is a promising way to scale up the learning capacity\nof large language models. It increases the number of parameters while keeping\nFLOPs nearly constant during inference through sparse activation. Yet, it still\nsuffers from significant memory overheads due to the vast parameter size,\nnecessitating model compression techniques. Post-training quantization offers a\npowerful approach for model compression. Existing methods adopt a fixed\nquantization precision for the entire MoE model. This rigid setup can lead to\nsuboptimal performance, without considering the inherent sparse structure. For\nexample, MoE's sparse routing mechanism leads to different activation patterns,\nwhere shared experts are accessed by all tokens while token-conditioned experts\nare selectively activated. This activation disparity suggests different\nquantization requirements, with consistently activated shared experts\npotentially needing higher precision to maintain model quality. In this paper,\nwe study a fine-grained precision setup for MoE quantization. We explore MoE\nstructure-aware quantization heuristics, ranging from coarse (e.g., MoE layers)\nto fine granularity (e.g., linear layers). Our investigations reveal critical\nprinciples, where different MoE structures require varying numbers of bits for\neffective quantization. Conclusions are supported by extensive benchmarking\nacross two representative MoE models and six tasks including commonsense\nreasoning and natural language understanding. We further show that an MoE\nquantized in a fined-grained mixed precision achieved state-of-the-art 65.35%\nperformance on average compared to the baseline 64.30% (i.e., GPTQ). Moreover,\nbased on the findings, we introduce novel data-driven techniques for optimizing\nbit allocation in MoE quantization, including the outlier-aware linear layer\nscorer and MoE block importance predictor.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Our code for reproducing all our experiments is provided at\n  https://github.com/UNITES-Lab/moe-quantization",
    "pdf_url": "http://arxiv.org/pdf/2406.08155v2",
    "published_date": "2024-06-12 12:44:48 UTC",
    "updated_date": "2025-02-25 18:29:54 UTC"
  },
  {
    "arxiv_id": "2406.08148v1",
    "title": "Probing Implicit Bias in Semi-gradient Q-learning: Visualizing the Effective Loss Landscapes via the Fokker--Planck Equation",
    "authors": [
      "Shuyu Yin",
      "Fei Wen",
      "Peilin Liu",
      "Tao Luo"
    ],
    "abstract": "Semi-gradient Q-learning is applied in many fields, but due to the absence of\nan explicit loss function, studying its dynamics and implicit bias in the\nparameter space is challenging. This paper introduces the Fokker--Planck\nequation and employs partial data obtained through sampling to construct and\nvisualize the effective loss landscape within a two-dimensional parameter\nspace. This visualization reveals how the global minima in the loss landscape\ncan transform into saddle points in the effective loss landscape, as well as\nthe implicit bias of the semi-gradient method. Additionally, we demonstrate\nthat saddle points, originating from the global minima in loss landscape, still\nexist in the effective loss landscape under high-dimensional parameter spaces\nand neural network settings. This paper develop a novel approach for probing\nimplicit bias in semi-gradient Q-learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08148v1",
    "published_date": "2024-06-12 12:37:53 UTC",
    "updated_date": "2024-06-12 12:37:53 UTC"
  },
  {
    "arxiv_id": "2406.08134v1",
    "title": "Making AI Intelligible: Philosophical Foundations",
    "authors": [
      "Herman Cappelen",
      "Josh Dever"
    ],
    "abstract": "Can humans and artificial intelligences share concepts and communicate?\n'Making AI Intelligible' shows that philosophical work on the metaphysics of\nmeaning can help answer these questions. Herman Cappelen and Josh Dever use the\nexternalist tradition in philosophy to create models of how AIs and humans can\nunderstand each other. In doing so, they illustrate ways in which that\nphilosophical tradition can be improved.\n  The questions addressed in the book are not only theoretically interesting,\nbut the answers have pressing practical implications. Many important decisions\nabout human life are now influenced by AI. In giving that power to AI, we\npresuppose that AIs can track features of the world that we care about (for\nexample, creditworthiness, recidivism, cancer, and combatants). If AIs can\nshare our concepts, that will go some way towards justifying this reliance on\nAI. This ground-breaking study offers insight into how to take some first steps\ntowards achieving Interpretable AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Book published with Oxford University Press, 184 pages (2021), Open\n  Access",
    "pdf_url": "http://arxiv.org/pdf/2406.08134v1",
    "published_date": "2024-06-12 12:25:04 UTC",
    "updated_date": "2024-06-12 12:25:04 UTC"
  },
  {
    "arxiv_id": "2406.08124v2",
    "title": "Legend: Leveraging Representation Engineering to Annotate Safety Margin for Preference Datasets",
    "authors": [
      "Duanyu Feng",
      "Bowen Qin",
      "Chen Huang",
      "Youcheng Huang",
      "Zheng Zhang",
      "Wenqiang Lei"
    ],
    "abstract": "The success of the reward model in distinguishing between responses with\nsubtle safety differences depends critically on the high-quality preference\ndataset, which should capture the fine-grained nuances of harmful and harmless\nresponses. This motivates the need to develop a dataset involving preference\nmargins, which accurately quantify how harmless one response is compared to\nanother. In this paper, we take the first step to propose an effective and\ncost-efficient framework to promote the margin-enhanced preference dataset\ndevelopment. Our framework, Legend, Leverages representation engineering to\nannotate preference datasets. It constructs the specific direction within the\nLLM's embedding space that represents safety. By leveraging this safety\ndirection, Legend can then leverage the semantic distances of paired responses\nalong this direction to annotate margins automatically. We experimentally\ndemonstrate our effectiveness in both reward modeling and harmless alignment\nfor LLMs. Legend also stands out for its efficiency, requiring only the\ninference time rather than additional training. This efficiency allows for\neasier implementation and scalability, making Legend particularly valuable for\npractical applications in aligning LLMs with safe conversations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Our code is available at https://github.com/colfeng/Legend",
    "pdf_url": "http://arxiv.org/pdf/2406.08124v2",
    "published_date": "2024-06-12 12:06:32 UTC",
    "updated_date": "2024-12-18 03:22:31 UTC"
  },
  {
    "arxiv_id": "2406.08116v2",
    "title": "Supportiveness-based Knowledge Rewriting for Retrieval-augmented Language Modeling",
    "authors": [
      "Zile Qiao",
      "Wei Ye",
      "Yong Jiang",
      "Tong Mo",
      "Pengjun Xie",
      "Weiping Li",
      "Fei Huang",
      "Shikun Zhang"
    ],
    "abstract": "Retrieval-augmented language models (RALMs) have recently shown great\npotential in mitigating the limitations of implicit knowledge in LLMs, such as\nuntimely updating of the latest expertise and unreliable retention of long-tail\nknowledge. However, since the external knowledge base, as well as the\nretriever, can not guarantee reliability, potentially leading to the knowledge\nretrieved not being helpful or even misleading for LLM generation. In this\npaper, we introduce Supportiveness-based Knowledge Rewriting (SKR), a robust\nand pluggable knowledge rewriter inherently optimized for LLM generation.\nSpecifically, we introduce the novel concept of \"supportiveness\"--which\nrepresents how effectively a knowledge piece facilitates downstream tasks--by\nconsidering the perplexity impact of augmented knowledge on the response text\nof a white-box LLM. Based on knowledge supportiveness, we first design a\ntraining data curation strategy for our rewriter model, effectively identifying\nand filtering out poor or irrelevant rewrites (e.g., with low supportiveness\nscores) to improve data efficacy. We then introduce the direct preference\noptimization (DPO) algorithm to align the generated rewrites to optimal\nsupportiveness, guiding the rewriter model to summarize augmented content that\nbetter improves the final response. Comprehensive evaluations across six\npopular knowledge-intensive tasks and four LLMs have demonstrated the\neffectiveness and superiority of SKR. With only 7B parameters, SKR has shown\nbetter knowledge rewriting capability over GPT-4, the current state-of-the-art\ngeneral-purpose LLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08116v2",
    "published_date": "2024-06-12 11:52:35 UTC",
    "updated_date": "2024-10-03 18:22:44 UTC"
  },
  {
    "arxiv_id": "2406.08115v1",
    "title": "Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey",
    "authors": [
      "Feng Liang",
      "Zhen Zhang",
      "Haifeng Lu",
      "Chengming Li",
      "Victor C. M. Leung",
      "Yanyi Guo",
      "Xiping Hu"
    ],
    "abstract": "With rapidly increasing distributed deep learning workloads in large-scale\ndata centers, efficient distributed deep learning framework strategies for\nresource allocation and workload scheduling have become the key to\nhigh-performance deep learning. The large-scale environment with large volumes\nof datasets, models, and computational and communication resources raises\nvarious unique challenges for resource allocation and workload scheduling in\ndistributed deep learning, such as scheduling complexity, resource and workload\nheterogeneity, and fault tolerance. To uncover these challenges and\ncorresponding solutions, this survey reviews the literature, mainly from 2019\nto 2024, on efficient resource allocation and workload scheduling strategies\nfor large-scale distributed DL. We explore these strategies by focusing on\nvarious resource types, scheduling granularity levels, and performance goals\nduring distributed training and inference processes. We highlight critical\nchallenges for each topic and discuss key insights of existing technologies. To\nillustrate practical large-scale resource allocation and workload scheduling in\nreal distributed deep learning scenarios, we use a case study of training large\nlanguage models. This survey aims to encourage computer science, artificial\nintelligence, and communications researchers to understand recent advances and\nexplore future research directions for efficient framework strategies for\nlarge-scale distributed deep learning.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08115v1",
    "published_date": "2024-06-12 11:51:44 UTC",
    "updated_date": "2024-06-12 11:51:44 UTC"
  },
  {
    "arxiv_id": "2406.08112v1",
    "title": "Codecfake: An Initial Dataset for Detecting LLM-based Deepfake Audio",
    "authors": [
      "Yi Lu",
      "Yuankun Xie",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Jianhua Tao",
      "Zhiyong Wang",
      "Xin Qi",
      "Xuefei Liu",
      "Yongwei Li",
      "Yukun Liu",
      "Xiaopeng Wang",
      "Shuchen Shi"
    ],
    "abstract": "With the proliferation of Large Language Model (LLM) based deepfake audio,\nthere is an urgent need for effective detection methods. Previous deepfake\naudio generation methods typically involve a multi-step generation process,\nwith the final step using a vocoder to predict the waveform from handcrafted\nfeatures. However, LLM-based audio is directly generated from discrete neural\ncodecs in an end-to-end generation process, skipping the final step of vocoder\nprocessing. This poses a significant challenge for current audio deepfake\ndetection (ADD) models based on vocoder artifacts. To effectively detect\nLLM-based deepfake audio, we focus on the core of the generation process, the\nconversion from neural codec to waveform. We propose Codecfake dataset, which\nis generated by seven representative neural codec methods. Experiment results\nshow that codec-trained ADD models exhibit a 41.406% reduction in average equal\nerror rate compared to vocoder-trained ADD models on the Codecfake test set.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by INTERSPEECH 2024. arXiv admin note: substantial text\n  overlap with arXiv:2405.04880",
    "pdf_url": "http://arxiv.org/pdf/2406.08112v1",
    "published_date": "2024-06-12 11:47:23 UTC",
    "updated_date": "2024-06-12 11:47:23 UTC"
  },
  {
    "arxiv_id": "2406.08105v3",
    "title": "Prediction of the Realisation of an Information Need: An EEG Study",
    "authors": [
      "Niall McGuire",
      "Dr Yashar Moshfeghi"
    ],
    "abstract": "One of the foundational goals of Information Retrieval (IR) is to satisfy\nsearchers' Information Needs (IN). Understanding how INs physically manifest\nhas long been a complex and elusive process. However, recent studies utilising\nElectroencephalography (EEG) data have provided real-time insights into the\nneural processes associated with INs. Unfortunately, they have yet to\ndemonstrate how this insight can practically benefit the search experience. As\nsuch, within this study, we explore the ability to predict the realisation of\nIN within EEG data across 14 subjects whilst partaking in a Question-Answering\n(Q/A) task. Furthermore, we investigate the combinations of EEG features that\nyield optimal predictive performance, as well as identify regions within the\nQ/A queries where a subject's realisation of IN is more pronounced. The\nfindings from this work demonstrate that EEG data is sufficient for the\nreal-time prediction of the realisation of an IN across all subjects with an\naccuracy of 73.5% (SD 2.6%) and on a per-subject basis with an accuracy of\n90.1% (SD 22.1%). This work helps to close the gap by bridging theoretical\nneuroscientific advancements with tangible improvements in information\nretrieval practices, paving the way for real-time prediction of the realisation\nof IN.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08105v3",
    "published_date": "2024-06-12 11:34:19 UTC",
    "updated_date": "2024-06-18 09:13:04 UTC"
  },
  {
    "arxiv_id": "2406.10287v1",
    "title": "Security Decisions for Cyber-Physical Systems based on Solving Critical Node Problems with Vulnerable Nodes",
    "authors": [
      "Jens Otto",
      "Niels Grüttemeier",
      "Felix Specht"
    ],
    "abstract": "Cyber-physical production systems consist of highly specialized software and\nhardware components. Most components and communication protocols are not built\naccording to the Secure by Design principle. Therefore, their resilience to\ncyberattacks is limited. This limitation can be overcome with common\noperational pictures generated by security monitoring solutions. These pictures\nprovide information about communication relationships of both attacked and\nnon-attacked devices, and serve as a decision-making basis for security\nofficers in the event of cyberattacks. The objective of these decisions is to\nisolate a limited number of devices rather than shutting down the entire\nproduction system. In this work, we propose and evaluate a concept for finding\nthe devices to isolate. Our approach is based on solving the Critical Node Cut\nProblem with Vulnerable Vertices (CNP-V) - an NP-hard computational problem\noriginally motivated by isolating vulnerable people in case of a pandemic. To\nthe best of our knowledge, this is the first work on applying CNP-V in context\nof cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10287v1",
    "published_date": "2024-06-12 11:31:46 UTC",
    "updated_date": "2024-06-12 11:31:46 UTC"
  },
  {
    "arxiv_id": "2406.08100v1",
    "title": "Multimodal Table Understanding",
    "authors": [
      "Mingyu Zheng",
      "Xinwei Feng",
      "Qingyi Si",
      "Qiaoqiao She",
      "Zheng Lin",
      "Wenbin Jiang",
      "Weiping Wang"
    ],
    "abstract": "Although great progress has been made by previous table understanding methods\nincluding recent approaches based on large language models (LLMs), they rely\nheavily on the premise that given tables must be converted into a certain text\nsequence (such as Markdown or HTML) to serve as model input. However, it is\ndifficult to access such high-quality textual table representations in some\nreal-world scenarios, and table images are much more accessible. Therefore, how\nto directly understand tables using intuitive visual information is a crucial\nand urgent challenge for developing more practical applications. In this paper,\nwe propose a new problem, multimodal table understanding, where the model needs\nto generate correct responses to various table-related requests based on the\ngiven table image. To facilitate both the model training and evaluation, we\nconstruct a large-scale dataset named MMTab, which covers a wide spectrum of\ntable images, instructions and tasks. On this basis, we develop Table-LLaVA, a\ngeneralist tabular multimodal large language model (MLLM), which significantly\noutperforms recent open-source MLLM baselines on 23 benchmarks under held-in\nand held-out settings. The code and data is available at this\nhttps://github.com/SpursGoZmy/Table-LLaVA",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 16 figures, ACL 2024 main conference, camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2406.08100v1",
    "published_date": "2024-06-12 11:27:03 UTC",
    "updated_date": "2024-06-12 11:27:03 UTC"
  },
  {
    "arxiv_id": "2406.08099v1",
    "title": "Confidence Interval Estimation of Predictive Performance in the Context of AutoML",
    "authors": [
      "Konstantinos Paraschakis",
      "Andrea Castellani",
      "Giorgos Borboudakis",
      "Ioannis Tsamardinos"
    ],
    "abstract": "Any supervised machine learning analysis is required to provide an estimate\nof the out-of-sample predictive performance. However, it is imperative to also\nprovide a quantification of the uncertainty of this performance in the form of\na confidence or credible interval (CI) and not just a point estimate. In an\nAutoML setting, estimating the CI is challenging due to the ``winner's curse\",\ni.e., the bias of estimation due to cross-validating several machine learning\npipelines and selecting the winning one. In this work, we perform a comparative\nevaluation of 9 state-of-the-art methods and variants in CI estimation in an\nAutoML setting on a corpus of real and simulated datasets. The methods are\ncompared in terms of inclusion percentage (does a 95\\% CI include the true\nperformance at least 95\\% of the time), CI tightness (tighter CIs are\npreferable as being more informative), and execution time. The evaluation is\nthe first one that covers most, if not all, such methods and extends previous\nwork to imbalanced and small-sample tasks. In addition, we present a variant,\ncalled BBC-F, of an existing method (the Bootstrap Bias Correction, or BBC)\nthat maintains the statistical properties of the BBC but is more\ncomputationally efficient. The results support that BBC-F and BBC dominate the\nother methods in all metrics measured.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AutoML 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.08099v1",
    "published_date": "2024-06-12 11:26:29 UTC",
    "updated_date": "2024-06-12 11:26:29 UTC"
  },
  {
    "arxiv_id": "2406.08080v1",
    "title": "AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection",
    "authors": [
      "Pia Pachinger",
      "Janis Goldzycher",
      "Anna Maria Planitzer",
      "Wojciech Kusa",
      "Allan Hanbury",
      "Julia Neidhardt"
    ],
    "abstract": "Model interpretability in toxicity detection greatly profits from token-level\nannotations. However, currently such annotations are only available in English.\nWe introduce a dataset annotated for offensive language detection sourced from\na news forum, notable for its incorporation of the Austrian German dialect,\ncomprising 4,562 user comments. In addition to binary offensiveness\nclassification, we identify spans within each comment constituting vulgar\nlanguage or representing targets of offensive statements. We evaluate\nfine-tuned language models as well as large language models in a zero- and\nfew-shot fashion. The results indicate that while fine-tuned models excel in\ndetecting linguistic peculiarities such as vulgar dialect, large language\nmodels demonstrate superior performance in detecting offensiveness in\nAustroTox. We publish the data and code.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08080v1",
    "published_date": "2024-06-12 11:04:11 UTC",
    "updated_date": "2024-06-12 11:04:11 UTC"
  },
  {
    "arxiv_id": "2406.08074v3",
    "title": "A Concept-Based Explainability Framework for Large Multimodal Models",
    "authors": [
      "Jayneel Parekh",
      "Pegah Khayatan",
      "Mustafa Shukor",
      "Alasdair Newson",
      "Matthieu Cord"
    ],
    "abstract": "Large multimodal models (LMMs) combine unimodal encoders and large language\nmodels (LLMs) to perform multimodal tasks. Despite recent advancements towards\nthe interpretability of these models, understanding internal representations of\nLMMs remains largely a mystery. In this paper, we present a novel framework for\nthe interpretation of LMMs. We propose a dictionary learning based approach,\napplied to the representation of tokens. The elements of the learned dictionary\ncorrespond to our proposed concepts. We show that these concepts are well\nsemantically grounded in both vision and text. Thus we refer to these as\n``multi-modal concepts''. We qualitatively and quantitatively evaluate the\nresults of the learnt concepts. We show that the extracted multimodal concepts\nare useful to interpret representations of test samples. Finally, we evaluate\nthe disentanglement between different concepts and the quality of grounding\nconcepts visually and textually. Our code is publicly available at\nhttps://github.com/mshukor/xl-vlms",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08074v3",
    "published_date": "2024-06-12 10:48:53 UTC",
    "updated_date": "2024-11-30 10:48:21 UTC"
  },
  {
    "arxiv_id": "2406.08070v2",
    "title": "CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models",
    "authors": [
      "Hyungjin Chung",
      "Jeongsol Kim",
      "Geon Yeong Park",
      "Hyelin Nam",
      "Jong Chul Ye"
    ],
    "abstract": "Classifier-free guidance (CFG) is a fundamental tool in modern diffusion\nmodels for text-guided generation. Although effective, CFG has notable\ndrawbacks. For instance, DDIM with CFG lacks invertibility, complicating image\nediting; furthermore, high guidance scales, essential for high-quality outputs,\nfrequently result in issues like mode collapse. Contrary to the widespread\nbelief that these are inherent limitations of diffusion models, this paper\nreveals that the problems actually stem from the off-manifold phenomenon\nassociated with CFG, rather than the diffusion models themselves. More\nspecifically, inspired by the recent advancements of diffusion model-based\ninverse problem solvers (DIS), we reformulate text-guidance as an inverse\nproblem with a text-conditioned score matching loss and develop CFG++, a novel\napproach that tackles the off-manifold challenges inherent in traditional CFG.\nCFG++ features a surprisingly simple fix to CFG, yet it offers significant\nimprovements, including better sample quality for text-to-image generation,\ninvertibility, smaller guidance scales, reduced mode collapse, etc.\nFurthermore, CFG++ enables seamless interpolation between unconditional and\nconditional sampling at lower guidance scales, consistently outperforming\ntraditional CFG at all scales. Moreover, CFG++ can be easily integrated into\nhigh-order diffusion solvers and naturally extends to distilled diffusion\nmodels. Experimental results confirm that our method significantly enhances\nperformance in text-to-image generation, DDIM inversion, editing, and solving\ninverse problems, suggesting a wide-ranging impact and potential applications\nin various fields that utilize text guidance. Project Page:\nhttps://cfgpp-diffusion.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 21 figures. Project Page:\n  https://cfgpp-diffusion.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.08070v2",
    "published_date": "2024-06-12 10:40:10 UTC",
    "updated_date": "2024-09-12 04:39:16 UTC"
  },
  {
    "arxiv_id": "2406.08069v3",
    "title": "Explore-Go: Leveraging Exploration for Generalisation in Deep Reinforcement Learning",
    "authors": [
      "Max Weltevrede",
      "Felix Kaubek",
      "Matthijs T. J. Spaan",
      "Wendelin Böhmer"
    ],
    "abstract": "One of the remaining challenges in reinforcement learning is to develop\nagents that can generalise to novel scenarios they might encounter once\ndeployed. This challenge is often framed in a multi-task setting where agents\ntrain on a fixed set of tasks and have to generalise to new tasks. Recent work\nhas shown that in this setting increased exploration during training can be\nleveraged to increase the generalisation performance of the agent. This makes\nsense when the states encountered during testing can actually be explored\nduring training. In this paper, we provide intuition why exploration can also\nbenefit generalisation to states that cannot be explicitly encountered during\ntraining. Additionally, we propose a novel method Explore-Go that exploits this\nintuition by increasing the number of states on which the agent trains.\nExplore-Go effectively increases the starting state distribution of the agent\nand as a result can be used in conjunction with most existing on-policy or\noff-policy reinforcement learning algorithms. We show empirically that our\nmethod can increase generalisation performance in an illustrative environment\nand on the Procgen benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08069v3",
    "published_date": "2024-06-12 10:39:31 UTC",
    "updated_date": "2024-09-18 10:04:56 UTC"
  },
  {
    "arxiv_id": "2406.08035v2",
    "title": "LVBench: An Extreme Long Video Understanding Benchmark",
    "authors": [
      "Weihan Wang",
      "Zehai He",
      "Wenyi Hong",
      "Yean Cheng",
      "Xiaohan Zhang",
      "Ji Qi",
      "Xiaotao Gu",
      "Shiyu Huang",
      "Bin Xu",
      "Yuxiao Dong",
      "Ming Ding",
      "Jie Tang"
    ],
    "abstract": "Recent progress in multimodal large language models has markedly enhanced the\nunderstanding of short videos (typically under one minute), and several\nevaluation datasets have emerged accordingly. However, these advancements fall\nshort of meeting the demands of real-world applications such as embodied\nintelligence for long-term decision-making, in-depth movie reviews and\ndiscussions, and live sports commentary, all of which require comprehension of\nlong videos spanning several hours. To address this gap, we introduce LVBench,\na benchmark specifically designed for long video understanding. Our dataset\ncomprises publicly sourced videos and encompasses a diverse set of tasks aimed\nat long video comprehension and information extraction. LVBench is designed to\nchallenge multimodal models to demonstrate long-term memory and extended\ncomprehension capabilities. Our extensive evaluations reveal that current\nmultimodal models still underperform on these demanding long video\nunderstanding tasks. Through LVBench, we aim to spur the development of more\nadvanced models capable of tackling the complexities of long video\ncomprehension. Our data and code are publicly available at:\nhttps://lvbench.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08035v2",
    "published_date": "2024-06-12 09:36:52 UTC",
    "updated_date": "2024-10-23 06:37:01 UTC"
  },
  {
    "arxiv_id": "2406.08024v1",
    "title": "Fewer Tokens and Fewer Videos: Extending Video Understanding Abilities in Large Vision-Language Models",
    "authors": [
      "Shimin Chen",
      "Yitian Yuan",
      "Shaoxiang Chen",
      "Zequn Jie",
      "Lin Ma"
    ],
    "abstract": "Amidst the advancements in image-based Large Vision-Language Models\n(image-LVLM), the transition to video-based models (video-LVLM) is hindered by\nthe limited availability of quality video data. This paper addresses the\nchallenge by leveraging the visual commonalities between images and videos to\nefficiently evolve image-LVLMs into video-LVLMs. We present a cost-effective\nvideo-LVLM that enhances model architecture, introduces innovative training\nstrategies, and identifies the most effective types of video instruction data.\nOur innovative weighted token sampler significantly compresses the visual token\nnumbers of each video frame, effectively cutting computational expenses. We\nalso find that judiciously using just 10% of the video data, compared to prior\nvideo-LVLMs, yields impressive results during various training phases.\nMoreover, we delve into the influence of video instruction data in\nlimited-resource settings, highlighting the significance of incorporating video\ntraining data that emphasizes temporal understanding to enhance model\nperformance. The resulting Fewer Tokens and Fewer Videos LVLM (FTFV-LVLM)\nexhibits exceptional performance across video and image benchmarks, validating\nour model's design and training approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08024v1",
    "published_date": "2024-06-12 09:22:45 UTC",
    "updated_date": "2024-06-12 09:22:45 UTC"
  },
  {
    "arxiv_id": "2406.08018v1",
    "title": "SHACL2FOL: An FOL Toolkit for SHACL Decision Problems",
    "authors": [
      "Paolo Pareti"
    ],
    "abstract": "Recent studies on the Shapes Constraint Language (SHACL), a W3C specification\nfor validating RDF graphs, rely on translating the language into first-order\nlogic in order to provide formally-grounded solutions to the validation,\ncontainment and satisfiability decision problems. Continuing on this line of\nresearch, we introduce SHACL2FOL, the first automatic tool that (i) translates\nSHACL documents into FOL sentences and (ii) computes the answer to the two\nstatic analysis problems of satisfiability and containment; it also allow to\ntest the validity of a graph with respect to a set of constraints. By\nintegrating with existing theorem provers, such as E and Vampire, the tool\ncomputes the answer to the aforementioned decision problems and outputs the\ncorresponding first-order logic theories in the standard TPTP format. We\nbelieve this tool can contribute to further theoretical studies of SHACL, by\nproviding an automatic first-order logic interpretation of its semantics, while\nalso benefiting SHACL practitioners, by supplying static analysis capabilities\nto help the creation and management of SHACL constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.08018v1",
    "published_date": "2024-06-12 09:20:25 UTC",
    "updated_date": "2024-06-12 09:20:25 UTC"
  },
  {
    "arxiv_id": "2406.10285v2",
    "title": "I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors",
    "authors": [
      "Zijin Lin",
      "Yue Zhao",
      "Kai Chen",
      "Jinwen He"
    ],
    "abstract": "Deep neural networks (DNNs) have revolutionized the field of computer vision\nlike object detection with their unparalleled performance. However, existing\nresearch has shown that DNNs are vulnerable to adversarial attacks. In the\nphysical world, an adversary could exploit adversarial patches to implement a\nHiding Attack (HA) which patches the target object to make it disappear from\nthe detector, and an Appearing Attack (AA) which fools the detector into\nmisclassifying the patch as a specific object. Recently, many defense methods\nfor detectors have been proposed to mitigate the potential threats of\nadversarial patches. However, such methods still have limitations in\ngeneralization, robustness and efficiency. Most defenses are only effective\nagainst the HA, leaving the detector vulnerable to the AA.\n  In this paper, we propose \\textit{NutNet}, an innovative model for detecting\nadversarial patches, with high generalization, robustness and efficiency. With\nexperiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on\nboth digital and physical domains, the results show that our proposed method\ncan effectively defend against both the HA and AA, with only 0.4\\% sacrifice of\nthe clean performance. We compare NutNet with four baseline defense methods for\ndetectors, and our method exhibits an average defense performance that is over\n2.4 times and 4.7 times higher than existing approaches for HA and AA,\nrespectively. In addition, NutNet only increases the inference time by 8\\%,\nwhich can meet the real-time requirements of the detection systems. Demos of\nNutNet are available at: \\url{https://sites.google.com/view/nutnet}.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10285v2",
    "published_date": "2024-06-12 09:16:19 UTC",
    "updated_date": "2024-06-25 02:11:46 UTC"
  },
  {
    "arxiv_id": "2406.08009v1",
    "title": "OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding",
    "authors": [
      "Yinan Deng",
      "Jiahui Wang",
      "Jingyu Zhao",
      "Jianyu Dou",
      "Yi Yang",
      "Yufeng Yue"
    ],
    "abstract": "In recent years, there has been a surge of interest in open-vocabulary 3D\nscene reconstruction facilitated by visual language models (VLMs), which\nshowcase remarkable capabilities in open-set retrieval. However, existing\nmethods face some limitations: they either focus on learning point-wise\nfeatures, resulting in blurry semantic understanding, or solely tackle\nobject-level reconstruction, thereby overlooking the intricate details of the\nobject's interior. To address these challenges, we introduce OpenObj, an\ninnovative approach to build open-vocabulary object-level Neural Radiance\nFields (NeRF) with fine-grained understanding. In essence, OpenObj establishes\na robust framework for efficient and watertight scene modeling and\ncomprehension at the object-level. Moreover, we incorporate part-level features\ninto the neural fields, enabling a nuanced representation of object interiors.\nThis approach captures object-level instances while maintaining a fine-grained\nunderstanding. The results on multiple datasets demonstrate that OpenObj\nachieves superior performance in zero-shot semantic segmentation and retrieval\ntasks. Additionally, OpenObj supports real-world robotics tasks at multiple\nscales, including global movement and local manipulation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 7figures. Project Url: https://openobj.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.08009v1",
    "published_date": "2024-06-12 08:59:33 UTC",
    "updated_date": "2024-06-12 08:59:33 UTC"
  },
  {
    "arxiv_id": "2406.08002v2",
    "title": "Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning",
    "authors": [
      "Yizhe Huang",
      "Anji Liu",
      "Fanqi Kong",
      "Yaodong Yang",
      "Song-Chun Zhu",
      "Xue Feng"
    ],
    "abstract": "Despite the recent successes of multi-agent reinforcement learning (MARL)\nalgorithms, efficiently adapting to co-players in mixed-motive environments\nremains a significant challenge. One feasible approach is to hierarchically\nmodel co-players' behavior based on inferring their characteristics. However,\nthese methods often encounter difficulties in efficient reasoning and\nutilization of inferred information. To address these issues, we propose\nHierarchical Opponent modeling and Planning (HOP), a novel multi-agent\ndecision-making algorithm that enables few-shot adaptation to unseen policies\nin mixed-motive environments. HOP is hierarchically composed of two modules: an\nopponent modeling module that infers others' goals and learns corresponding\ngoal-conditioned policies, and a planning module that employs Monte Carlo Tree\nSearch (MCTS) to identify the best response. Our approach improves efficiency\nby updating beliefs about others' goals both across and within episodes and by\nusing information from the opponent modeling module to guide planning.\nExperimental results demonstrate that in mixed-motive environments, HOP\nexhibits superior few-shot adaptation capabilities when interacting with\nvarious unseen agents, and excels in self-play scenarios. Furthermore, the\nemergence of social intelligence during our experiments underscores the\npotential of our approach in complex multi-agent environments.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08002v2",
    "published_date": "2024-06-12 08:48:06 UTC",
    "updated_date": "2024-07-12 15:13:43 UTC"
  },
  {
    "arxiv_id": "2406.08527v2",
    "title": "Optimized Feature Generation for Tabular Data via LLMs with Decision Tree Reasoning",
    "authors": [
      "Jaehyun Nam",
      "Kyuyoung Kim",
      "Seunghyuk Oh",
      "Jihoon Tack",
      "Jaehyung Kim",
      "Jinwoo Shin"
    ],
    "abstract": "In tabular prediction tasks, tree-based models combined with automated\nfeature engineering methods often outperform deep learning approaches that rely\non learned representations. While these feature engineering techniques are\neffective, they typically depend on a pre-defined search space and primarily\nuse validation scores for feature selection, thereby missing valuable insights\nfrom previous experiments. To address these limitations, we propose a novel\ntabular learning framework that utilizes large language models (LLMs), termed\nOptimizing Column feature generator with decision Tree reasoning (OCTree). Our\nkey idea is to leverage the reasoning capabilities of LLMs to identify\neffective feature generation rules without manually specifying the search space\nand provide language-based reasoning information highlighting past experiments\nas feedback for iterative rule improvements. We use decision trees to convey\nthis reasoning information, as they can be easily represented in natural\nlanguage, effectively providing knowledge from prior experiments (i.e., the\nimpact of the generated features on performance) to the LLMs. Our empirical\nresults demonstrate that OCTree consistently enhances the performance of\nvarious prediction models across diverse benchmarks, outperforming competing\nautomated feature engineering methods. Code is available at\nhttps://github.com/jaehyun513/OCTree.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.08527v2",
    "published_date": "2024-06-12 08:31:34 UTC",
    "updated_date": "2024-11-18 05:47:10 UTC"
  },
  {
    "arxiv_id": "2406.07990v1",
    "title": "Blowfish: Topological and statistical signatures for quantifying ambiguity in semantic search",
    "authors": [
      "Thomas Roland Barillot",
      "Alex De Castro"
    ],
    "abstract": "This works reports evidence for the topological signatures of ambiguity in\nsentence embeddings that could be leveraged for ranking and/or explanation\npurposes in the context of vector search and Retrieval Augmented Generation\n(RAG) systems. We proposed a working definition of ambiguity and designed an\nexperiment where we have broken down a proprietary dataset into collections of\nchunks of varying size - 3, 5, and 10 lines and used the different collections\nsuccessively as queries and answers sets. It allowed us to test the signatures\nof ambiguity with removal of confounding factors. Our results show that proxy\nambiguous queries (size 10 queries against size 3 documents) display different\ndistributions of homologies 0 and 1 based features than proxy clear queries\n(size 5 queries against size 10 documents). We then discuss those results in\nterms increased manifold complexity and/or approximately discontinuous\nembedding submanifolds. Finally we propose a strategy to leverage those\nfindings as a new scoring strategy of semantic similarities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07990v1",
    "published_date": "2024-06-12 08:26:30 UTC",
    "updated_date": "2024-06-12 08:26:30 UTC"
  },
  {
    "arxiv_id": "2406.07979v2",
    "title": "Heuristic Learning with Graph Neural Networks: A Unified Framework for Link Prediction",
    "authors": [
      "Juzheng Zhang",
      "Lanning Wei",
      "Zhen Xu",
      "Quanming Yao"
    ],
    "abstract": "Link prediction is a fundamental task in graph learning, inherently shaped by\nthe topology of the graph. While traditional heuristics are grounded in graph\ntopology, they encounter challenges in generalizing across diverse graphs.\nRecent research efforts have aimed to leverage the potential of heuristics, yet\na unified formulation accommodating both local and global heuristics remains\nundiscovered. Drawing insights from the fact that both local and global\nheuristics can be represented by adjacency matrix multiplications, we propose a\nunified matrix formulation to accommodate and generalize various heuristics. We\nfurther propose the Heuristic Learning Graph Neural Network (HL-GNN) to\nefficiently implement the formulation. HL-GNN adopts intra-layer propagation\nand inter-layer connections, allowing it to reach a depth of around 20 layers\nwith lower time complexity than GCN. Extensive experiments on the Planetoid,\nAmazon, and OGB datasets underscore the effectiveness and efficiency of HL-GNN.\nIt outperforms existing methods by a large margin in prediction performance.\nAdditionally, HL-GNN is several orders of magnitude faster than\nheuristic-inspired methods while requiring only a few trainable parameters. The\ncase study further demonstrates that the generalized heuristics and learned\nweights are highly interpretable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07979v2",
    "published_date": "2024-06-12 08:05:45 UTC",
    "updated_date": "2024-06-14 10:06:38 UTC"
  },
  {
    "arxiv_id": "2406.07971v2",
    "title": "It Takes Two: On the Seamlessness between Reward and Policy Model in RLHF",
    "authors": [
      "Taiming Lu",
      "Lingfeng Shen",
      "Xinyu Yang",
      "Weiting Tan",
      "Beidi Chen",
      "Huaxiu Yao"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) involves training policy\nmodels (PMs) and reward models (RMs) to align language models with human\npreferences. Instead of focusing solely on PMs and RMs independently, we\npropose to examine their interactions during fine-tuning, introducing the\nconcept of seamlessness. Our study starts with observing the saturation\nphenomenon, where continual improvements in RM and PM do not translate into\nRLHF progress. Our analysis shows that RMs fail to assign proper scores to PM\nresponses, resulting in a 35% mismatch rate with human preferences,\nhighlighting a significant discrepancy between PM and RM. To measure\nseamlessness between PM and RM without human effort, we propose an automatic\nmetric, SEAM. SEAM quantifies the discrepancies between PM and RM judgments\ninduced by data samples. We validate the effectiveness of SEAM in data\nselection and model augmentation. Our experiments demonstrate that (1) using\nSEAM-filtered data for RL training improves RLHF performance by 4.5%, and (2)\nSEAM-guided model augmentation results in a 4% performance improvement over\nstandard augmentation methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07971v2",
    "published_date": "2024-06-12 07:52:17 UTC",
    "updated_date": "2024-06-13 05:13:50 UTC"
  },
  {
    "arxiv_id": "2406.08526v1",
    "title": "IMFL-AIGC: Incentive Mechanism Design for Federated Learning Empowered by Artificial Intelligence Generated Content",
    "authors": [
      "Guangjing Huang",
      "Qiong Wu",
      "Jingyi Li",
      "Xu Chen"
    ],
    "abstract": "Federated learning (FL) has emerged as a promising paradigm that enables\nclients to collaboratively train a shared global model without uploading their\nlocal data. To alleviate the heterogeneous data quality among clients,\nartificial intelligence-generated content (AIGC) can be leveraged as a novel\ndata synthesis technique for FL model performance enhancement. Due to various\ncosts incurred by AIGC-empowered FL (e.g., costs of local model computation and\ndata synthesis), however, clients are usually reluctant to participate in FL\nwithout adequate economic incentives, which leads to an unexplored critical\nissue for enabling AIGC-empowered FL. To fill this gap, we first devise a data\nquality assessment method for data samples generated by AIGC and rigorously\nanalyze the convergence performance of FL model trained using a blend of\nauthentic and AI-generated data samples. We then propose a data quality-aware\nincentive mechanism to encourage clients' participation. In light of\ninformation asymmetry incurred by clients' private multi-dimensional\nattributes, we investigate clients' behavior patterns and derive the server's\noptimal incentive strategies to minimize server's cost in terms of both model\naccuracy loss and incentive payments for both complete and incomplete\ninformation scenarios. Numerical results demonstrate that our proposed\nmechanism exhibits highest training accuracy and reduces up to 53.34% of the\nserver's cost with real-world datasets, compared with existing benchmark\nmechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been accepted by IEEE Transactions on Mobile Computing",
    "pdf_url": "http://arxiv.org/pdf/2406.08526v1",
    "published_date": "2024-06-12 07:47:22 UTC",
    "updated_date": "2024-06-12 07:47:22 UTC"
  },
  {
    "arxiv_id": "2406.07962v2",
    "title": "Toward a Method to Generate Capability Ontologies from Natural Language Descriptions",
    "authors": [
      "Luis Miguel Vieira da Silva",
      "Aljosha Köcher",
      "Felix Gehlhoff",
      "Alexander Fay"
    ],
    "abstract": "To achieve a flexible and adaptable system, capability ontologies are\nincreasingly leveraged to describe functions in a machine-interpretable way.\nHowever, modeling such complex ontological descriptions is still a manual and\nerror-prone task that requires a significant amount of effort and ontology\nexpertise. This contribution presents an innovative method to automate\ncapability ontology modeling using Large Language Models (LLMs), which have\nproven to be well suited for such tasks. Our approach requires only a natural\nlanguage description of a capability, which is then automatically inserted into\na predefined prompt using a few-shot prompting technique. After prompting an\nLLM, the resulting capability ontology is automatically verified through\nvarious steps in a loop with the LLM to check the overall correctness of the\ncapability ontology. First, a syntax check is performed, then a check for\ncontradictions, and finally a check for hallucinations and missing ontology\nelements. Our method greatly reduces manual effort, as only the initial natural\nlanguage description and a final human review and possible correction are\nnecessary, thereby streamlining the capability ontology generation process.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
    "pdf_url": "http://arxiv.org/pdf/2406.07962v2",
    "published_date": "2024-06-12 07:41:44 UTC",
    "updated_date": "2024-10-18 07:34:39 UTC"
  },
  {
    "arxiv_id": "2406.07961v3",
    "title": "Accurate Explanation Model for Image Classifiers using Class Association Embedding",
    "authors": [
      "Ruitao Xie",
      "Jingbang Chen",
      "Limai Jiang",
      "Rui Xiao",
      "Yi Pan",
      "Yunpeng Cai"
    ],
    "abstract": "Image classification is a primary task in data analysis where explainable\nmodels are crucially demanded in various applications. Although amounts of\nmethods have been proposed to obtain explainable knowledge from the black-box\nclassifiers, these approaches lack the efficiency of extracting global\nknowledge regarding the classification task, thus is vulnerable to local traps\nand often leads to poor accuracy. In this study, we propose a generative\nexplanation model that combines the advantages of global and local knowledge\nfor explaining image classifiers. We develop a representation learning method\ncalled class association embedding (CAE), which encodes each sample into a pair\nof separated class-associated and individual codes. Recombining the individual\ncode of a given sample with altered class-associated code leads to a synthetic\nreal-looking sample with preserved individual characters but modified\nclass-associated features and possibly flipped class assignments. A\nbuilding-block coherency feature extraction algorithm is proposed that\nefficiently separates class-associated features from individual ones. The\nextracted feature space forms a low-dimensional manifold that visualizes the\nclassification decision patterns. Explanation on each individual sample can be\nthen achieved in a counter-factual generation manner which continuously\nmodifies the sample in one direction, by shifting its class-associated code\nalong a guided path, until its classification outcome is changed. We compare\nour method with state-of-the-art ones on explaining image classification tasks\nin the form of saliency maps, demonstrating that our method achieves higher\naccuracies. The code is available at https://github.com/xrt11/XAI-CODE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2024 IEEE 40th International Conference on Data\n  Engineering (ICDE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.07961v3",
    "published_date": "2024-06-12 07:41:00 UTC",
    "updated_date": "2024-12-30 07:07:38 UTC"
  },
  {
    "arxiv_id": "2406.08525v1",
    "title": "A Mathematical Certification for Positivity Conditions in Neural Networks with Applications to Partial Monotonicity and Ethical AI",
    "authors": [
      "Alejandro Polo-Molina",
      "David Alfaya",
      "Jose Portela"
    ],
    "abstract": "Artificial Neural Networks (ANNs) have become a powerful tool for modeling\ncomplex relationships in large-scale datasets. However, their black-box nature\nposes ethical challenges. In certain situations, ensuring ethical predictions\nmight require following specific partial monotonic constraints. However,\ncertifying if an already-trained ANN is partially monotonic is challenging.\nTherefore, ANNs are often disregarded in some critical applications, such as\ncredit scoring, where partial monotonicity is required. To address this\nchallenge, this paper presents a novel algorithm (LipVor) that certifies if a\nblack-box model, such as an ANN, is positive based on a finite number of\nevaluations. Therefore, as partial monotonicity can be stated as a positivity\ncondition of the partial derivatives, the LipVor Algorithm can certify whether\nan already trained ANN is partially monotonic. To do so, for every positively\nevaluated point, the Lipschitzianity of the black-box model is used to\nconstruct a specific neighborhood where the function remains positive. Next,\nbased on the Voronoi diagram of the evaluated points, a sufficient condition is\nstated to certify if the function is positive in the domain. Compared to prior\nmethods, our approach is able to mathematically certify if an ANN is partially\nmonotonic without needing constrained ANN's architectures or piece-wise linear\nactivation functions. Therefore, LipVor could open up the possibility of using\nunconstrained ANN in some critical fields. Moreover, some other properties of\nan ANN, such as convexity, can be posed as positivity conditions, and\ntherefore, LipVor could also be applied.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 26A48, 26B30"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.08525v1",
    "published_date": "2024-06-12 07:33:38 UTC",
    "updated_date": "2024-06-12 07:33:38 UTC"
  },
  {
    "arxiv_id": "2406.07954v1",
    "title": "Dataset and Lessons Learned from the 2024 SaTML LLM Capture-the-Flag Competition",
    "authors": [
      "Edoardo Debenedetti",
      "Javier Rando",
      "Daniel Paleka",
      "Silaghi Fineas Florin",
      "Dragos Albastroiu",
      "Niv Cohen",
      "Yuval Lemberg",
      "Reshmi Ghosh",
      "Rui Wen",
      "Ahmed Salem",
      "Giovanni Cherubin",
      "Santiago Zanella-Beguelin",
      "Robin Schmid",
      "Victor Klemm",
      "Takahiro Miki",
      "Chenhao Li",
      "Stefan Kraft",
      "Mario Fritz",
      "Florian Tramèr",
      "Sahar Abdelnabi",
      "Lea Schönherr"
    ],
    "abstract": "Large language model systems face important security risks from maliciously\ncrafted messages that aim to overwrite the system's original instructions or\nleak private data. To study this problem, we organized a capture-the-flag\ncompetition at IEEE SaTML 2024, where the flag is a secret string in the LLM\nsystem prompt. The competition was organized in two phases. In the first phase,\nteams developed defenses to prevent the model from leaking the secret. During\nthe second phase, teams were challenged to extract the secrets hidden for\ndefenses proposed by the other teams. This report summarizes the main insights\nfrom the competition. Notably, we found that all defenses were bypassed at\nleast once, highlighting the difficulty of designing a successful defense and\nthe necessity for additional research to protect LLM systems. To foster future\nresearch in this direction, we compiled a dataset with over 137k multi-turn\nattack chats and open-sourced the platform.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07954v1",
    "published_date": "2024-06-12 07:27:28 UTC",
    "updated_date": "2024-06-12 07:27:28 UTC"
  },
  {
    "arxiv_id": "2406.07948v5",
    "title": "Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization",
    "authors": [
      "Guopeng Lin",
      "Weili Han",
      "Wenqiang Ruan",
      "Ruisheng Zhou",
      "Lushan Song",
      "Bingshuai Li",
      "Yunfeng Shao"
    ],
    "abstract": "Multi-party training frameworks for decision trees based on secure\nmulti-party computation enable multiple parties to train high-performance\nmodels on distributed private data with privacy preservation. The training\nprocess essentially involves frequent dataset splitting according to the\nsplitting criterion (e.g. Gini impurity). However, existing multi-party\ntraining frameworks for decision trees demonstrate communication inefficiency\ndue to the following issues: (1) They suffer from huge communication overhead\nin securely splitting a dataset with continuous attributes. (2) They suffer\nfrom huge communication overhead due to performing almost all the computations\non a large ring to accommodate the secure computations for the splitting\ncriterion.\n  In this paper, we are motivated to present an efficient three-party training\nframework, namely Ents, for decision trees by communication optimization. For\nthe first issue, we present a series of training protocols based on the secure\nradix sort protocols to efficiently and securely split a dataset with\ncontinuous attributes. For the second issue, we propose an efficient share\nconversion protocol to convert shares between a small ring and a large ring to\nreduce the communication overhead incurred by performing almost all the\ncomputations on a large ring. Experimental results from eight widely used\ndatasets show that Ents outperforms state-of-the-art frameworks by $5.5\\times\n\\sim 9.3\\times$ in communication sizes and $3.9\\times \\sim 5.3\\times$ in\ncommunication rounds. In terms of training time, Ents yields an improvement of\n$3.5\\times \\sim 6.7\\times$. To demonstrate its practicality, Ents requires less\nthan three hours to securely train a decision tree on a widely used real-world\ndataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper is the full version of a paper to appear in ACM CCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07948v5",
    "published_date": "2024-06-12 07:13:11 UTC",
    "updated_date": "2024-07-03 06:01:42 UTC"
  },
  {
    "arxiv_id": "2406.07944v2",
    "title": "Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries",
    "authors": [
      "Meiziniu Li",
      "Dongze Li",
      "Jianmeng Liu",
      "Jialun Cao",
      "Yongqiang Tian",
      "Shing-Chi Cheung"
    ],
    "abstract": "Differential testing offers a promising strategy to alleviate the test oracle\nproblem by comparing the test results between alternative implementations.\nHowever, existing differential testing techniques for deep learning (DL)\nlibraries are limited by the key challenges of finding alternative\nimplementations (called counterparts) for a given API and subsequently\ngenerating diverse test inputs. To address the two challenges, this paper\nintroduces DLLens, an LLM-enhanced differential testing technique for DL\nlibraries. To address the first challenge, DLLens incorporates an LLM-based\ncounterpart synthesis workflow, with the insight that the counterpart of a\ngiven DL library API's computation could be successfully synthesized through\ncertain composition and adaptation of the APIs from another DL library. To\naddress the second challenge, DLLens incorporates a static analysis technique\nthat extracts the path constraints from the implementations of a given API and\nits counterpart to guide diverse test input generation. The extraction is\nfacilitated by LLM's knowledge of the concerned DL library and its upstream\nlibraries.\n  We evaluate DLLens on two popular DL libraries, TensorFlow and PyTorch. Our\nevaluation shows that DLLens synthesizes counterparts for 1.84 times as many\nAPIs as those found by state-of-the-art techniques on these libraries.\nMoreover, under the same time budget, DLLens covers 7.23% more branches and\ndetects 1.88 times as many bugs as state-of-the-art techniques on 200 randomly\nsampled APIs. DLLens has successfully detected 71 bugs in recent TensorFlow and\nPyTorch libraries. Among them, 59 are confirmed by developers, including 46\nconfirmed as previously unknown bugs, and 10 of these previously unknown bugs\nhave been fixed in the latest version of TensorFlow and PyTorch.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; I.2.5"
    ],
    "primary_category": "cs.SE",
    "comment": "This work has been accepted by ACM TOSEM. Manuscript under final\n  preparation",
    "pdf_url": "http://arxiv.org/pdf/2406.07944v2",
    "published_date": "2024-06-12 07:06:38 UTC",
    "updated_date": "2025-05-08 15:48:00 UTC"
  },
  {
    "arxiv_id": "2406.07933v2",
    "title": "Large Language Model Unlearning via Embedding-Corrupted Prompts",
    "authors": [
      "Chris Yuhao Liu",
      "Yaxuan Wang",
      "Jeffrey Flanigan",
      "Yang Liu"
    ],
    "abstract": "Large language models (LLMs) have advanced to encompass extensive knowledge\nacross diverse domains. Yet controlling what a large language model should not\nknow is important for ensuring alignment and thus safe use. However, accurately\nand efficiently unlearning knowledge from an LLM remains challenging due to the\npotential collateral damage caused by the fuzzy boundary between retention and\nforgetting, and the large computational requirements for optimization across\nstate-of-the-art models with hundreds of billions of parameters. In this work,\nwe present \\textbf{Embedding-COrrupted (ECO) Prompts}, a lightweight unlearning\nframework for large language models to address both the challenges of knowledge\nentanglement and unlearning efficiency. Instead of relying on the LLM itself to\nunlearn, we enforce an unlearned state during inference by employing a prompt\nclassifier to identify and safeguard prompts to forget. We learn corruptions\nadded to prompt embeddings via zeroth order optimization toward the unlearning\nobjective offline and corrupt prompts flagged by the classifier during\ninference. We find that these embedding-corrupted prompts not only lead to\ndesirable outputs that satisfy the unlearning objective but also closely\napproximate the output from a model that has never been trained on the data\nintended for forgetting. Through extensive experiments on unlearning, we\ndemonstrate the superiority of our method in achieving promising unlearning at\n\\textit{nearly zero side effects} in general domains and domains closely\nrelated to the unlearned ones. Additionally, we highlight the scalability of\nour method to 100 LLMs, ranging from 0.5B to 236B parameters, incurring no\nadditional cost as the number of parameters increases. We have made our code\npublicly available at \\url{https://github.com/chrisliu298/llm-unlearn-eco}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Poster",
    "pdf_url": "http://arxiv.org/pdf/2406.07933v2",
    "published_date": "2024-06-12 06:56:20 UTC",
    "updated_date": "2024-10-31 07:36:39 UTC"
  },
  {
    "arxiv_id": "2406.07929v1",
    "title": "A Generic Layer Pruning Method for Signal Modulation Recognition Deep Learning Models",
    "authors": [
      "Yao Lu",
      "Yutao Zhu",
      "Yuqi Li",
      "Dongwei Xu",
      "Yun Lin",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "abstract": "With the successful application of deep learning in communications systems,\ndeep neural networks are becoming the preferred method for signal\nclassification. Although these models yield impressive results, they often come\nwith high computational complexity and large model sizes, which hinders their\npractical deployment in communication systems. To address this challenge, we\npropose a novel layer pruning method. Specifically, we decompose the model into\nseveral consecutive blocks, each containing consecutive layers with similar\nsemantics. Then, we identify layers that need to be preserved within each block\nbased on their contribution. Finally, we reassemble the pruned blocks and\nfine-tune the compact model. Extensive experiments on five datasets demonstrate\nthe efficiency and effectiveness of our method over a variety of\nstate-of-the-art baselines, including layer pruning and channel pruning\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07929v1",
    "published_date": "2024-06-12 06:46:37 UTC",
    "updated_date": "2024-06-12 06:46:37 UTC"
  },
  {
    "arxiv_id": "2406.07926v1",
    "title": "Efficient Neural Common Neighbor for Temporal Graph Link Prediction",
    "authors": [
      "Xiaohui Zhang",
      "Yanbo Wang",
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "abstract": "Temporal graphs are ubiquitous in real-world scenarios, such as social\nnetwork, trade and transportation. Predicting dynamic links between nodes in a\ntemporal graph is of vital importance. Traditional methods usually leverage the\ntemporal neighborhood of interaction history to generate node embeddings first\nand then aggregate the source and target node embeddings to predict the link.\nHowever, such methods focus on learning individual node representations, but\noverlook the pairwise representation learning nature of link prediction and\nfail to capture the important pairwise features of links such as common\nneighbors (CN). Motivated by the success of Neural Common Neighbor (NCN) for\nstatic graph link prediction, we propose TNCN, a temporal version of NCN for\nlink prediction in temporal graphs. TNCN dynamically updates a temporal\nneighbor dictionary for each node, and utilizes multi-hop common neighbors\nbetween the source and target node to learn a more effective pairwise\nrepresentation. We validate our model on five large-scale real-world datasets\nfrom the Temporal Graph Benchmark (TGB), and find that it achieves new\nstate-of-the-art performance on three of them. Additionally, TNCN demonstrates\nexcellent scalability on large datasets, outperforming popular GNN baselines by\nup to 6.4 times in speed. Our code is available at https:\n//github.com/GraphPKU/TNCN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07926v1",
    "published_date": "2024-06-12 06:45:03 UTC",
    "updated_date": "2024-06-12 06:45:03 UTC"
  },
  {
    "arxiv_id": "2406.07923v1",
    "title": "CTC-aligned Audio-Text Embedding for Streaming Open-vocabulary Keyword Spotting",
    "authors": [
      "Sichen Jin",
      "Youngmoon Jung",
      "Seungjin Lee",
      "Jaeyoung Roh",
      "Changwoo Han",
      "Hoonyoung Cho"
    ],
    "abstract": "This paper introduces a novel approach for streaming openvocabulary keyword\nspotting (KWS) with text-based keyword enrollment. For every input frame, the\nproposed method finds the optimal alignment ending at the frame using\nconnectionist temporal classification (CTC) and aggregates the frame-level\nacoustic embedding (AE) to obtain higher-level (i.e., character, word, or\nphrase) AE that aligns with the text embedding (TE) of the target keyword text.\nAfter that, we calculate the similarity of the aggregated AE and the TE. To the\nbest of our knowledge, this is the first attempt to dynamically align the audio\nand the keyword text on-the-fly to attain the joint audio-text embedding for\nKWS. Despite operating in a streaming fashion, our approach achieves\ncompetitive performance on the LibriPhrase dataset compared to the\nnon-streaming methods with a mere 155K model parameters and a decoding\nalgorithm with time complexity O(U), where U is the length of the target\nkeyword at inference time.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07923v1",
    "published_date": "2024-06-12 06:44:40 UTC",
    "updated_date": "2024-06-12 06:44:40 UTC"
  },
  {
    "arxiv_id": "2406.16925v1",
    "title": "Analyzing Multi-Head Attention on Trojan BERT Models",
    "authors": [
      "Jingwei Wang"
    ],
    "abstract": "This project investigates the behavior of multi-head attention in Transformer\nmodels, specifically focusing on the differences between benign and trojan\nmodels in the context of sentiment analysis. Trojan attacks cause models to\nperform normally on clean inputs but exhibit misclassifications when presented\nwith inputs containing predefined triggers. We characterize attention head\nfunctions in trojan and benign models, identifying specific 'trojan' heads and\nanalyzing their behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16925v1",
    "published_date": "2024-06-12 06:43:59 UTC",
    "updated_date": "2024-06-12 06:43:59 UTC"
  },
  {
    "arxiv_id": "2406.07920v1",
    "title": "Near-Optimal Learning and Planning in Separated Latent MDPs",
    "authors": [
      "Fan Chen",
      "Constantinos Daskalakis",
      "Noah Golowich",
      "Alexander Rakhlin"
    ],
    "abstract": "We study computational and statistical aspects of learning Latent Markov\nDecision Processes (LMDPs). In this model, the learner interacts with an MDP\ndrawn at the beginning of each epoch from an unknown mixture of MDPs. To\nsidestep known impossibility results, we consider several notions of separation\nof the constituent MDPs. The main thrust of this paper is in establishing a\nnearly-sharp *statistical threshold* for the horizon length necessary for\nefficient learning. On the computational side, we show that under a weaker\nassumption of separability under the optimal policy, there is a\nquasi-polynomial algorithm with time complexity scaling in terms of the\nstatistical threshold. We further show a near-matching time complexity lower\nbound under the exponential time hypothesis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "COLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07920v1",
    "published_date": "2024-06-12 06:41:47 UTC",
    "updated_date": "2024-06-12 06:41:47 UTC"
  },
  {
    "arxiv_id": "2406.07917v1",
    "title": "Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks",
    "authors": [
      "Peizhi Niu",
      "Chao Pan",
      "Siheng Chen",
      "Olgica Milenkovic"
    ],
    "abstract": "Graph neural networks (GNNs) have become instrumental in diverse real-world\napplications, offering powerful graph learning capabilities for tasks such as\nsocial networks and medical data analysis. Despite their successes, GNNs are\nvulnerable to adversarial attacks, including membership inference attacks\n(MIA), which threaten privacy by identifying whether a record was part of the\nmodel's training data. While existing research has explored MIA in GNNs under\ngraph inductive learning settings, the more common and challenging graph\ntransductive learning setting remains understudied in this context. This paper\naddresses this gap and proposes an effective two-stage defense, Graph\nTransductive Defense (GTD), tailored to graph transductive learning\ncharacteristics. The gist of our approach is a combination of a train-test\nalternate training schedule and flattening strategy, which successfully reduces\nthe difference between the training and testing loss distributions. Extensive\nempirical results demonstrate the superior performance of our method (a\ndecrease in attack AUROC by $9.42\\%$ and an increase in utility performance by\n$18.08\\%$ on average compared to LBP), highlighting its potential for seamless\nintegration into various classification models with minimal overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07917v1",
    "published_date": "2024-06-12 06:36:37 UTC",
    "updated_date": "2024-06-12 06:36:37 UTC"
  },
  {
    "arxiv_id": "2406.07908v1",
    "title": "Ablation Based Counterfactuals",
    "authors": [
      "Zheng Dai",
      "David K Gifford"
    ],
    "abstract": "Diffusion models are a class of generative models that generate high-quality\nsamples, but at present it is difficult to characterize how they depend upon\ntheir training data. This difficulty raises scientific and regulatory\nquestions, and is a consequence of the complexity of diffusion models and their\nsampling process. To analyze this dependence, we introduce Ablation Based\nCounterfactuals (ABC), a method of performing counterfactual analysis that\nrelies on model ablation rather than model retraining. In our approach, we\ntrain independent components of a model on different but overlapping splits of\na training set. These components are then combined into a single model, from\nwhich the causal influence of any training sample can be removed by ablating a\ncombination of model components. We demonstrate how we can construct a model\nlike this using an ensemble of diffusion models. We then use this model to\nstudy the limits of training data attribution by enumerating full\ncounterfactual landscapes, and show that single source attributability\ndiminishes with increasing training data size. Finally, we demonstrate the\nexistence of unattributable samples.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, appendix included",
    "pdf_url": "http://arxiv.org/pdf/2406.07908v1",
    "published_date": "2024-06-12 06:22:51 UTC",
    "updated_date": "2024-06-12 06:22:51 UTC"
  },
  {
    "arxiv_id": "2406.07900v1",
    "title": "Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations",
    "authors": [
      "Bulat Khaertdinov",
      "Pedro Jeuris",
      "Annanda Sousa",
      "Enrique Hortal"
    ],
    "abstract": "Recent advancements in Deep and Self-Supervised Learning (SSL) have led to\nsubstantial improvements in Speech Emotion Recognition (SER) performance,\nreaching unprecedented levels. However, obtaining sufficient amounts of\naccurately labeled data for training or fine-tuning the models remains a costly\nand challenging task. In this paper, we propose a multi-view SSL pre-training\ntechnique that can be applied to various representations of speech, including\nthe ones generated by large speech models, to improve SER performance in\nscenarios where annotations are limited. Our experiments, based on wav2vec 2.0,\nspectral and paralinguistic features, demonstrate that the proposed framework\nboosts the SER performance, by up to 10% in Unweighted Average Recall, in\nsettings with extremely sparse data annotations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07900v1",
    "published_date": "2024-06-12 06:06:55 UTC",
    "updated_date": "2024-06-12 06:06:55 UTC"
  },
  {
    "arxiv_id": "2406.07897v1",
    "title": "When Do Skills Help Reinforcement Learning? A Theoretical Analysis of Temporal Abstractions",
    "authors": [
      "Zhening Li",
      "Gabriel Poesia",
      "Armando Solar-Lezama"
    ],
    "abstract": "Skills are temporal abstractions that are intended to improve reinforcement\nlearning (RL) performance through hierarchical RL. Despite our intuition about\nthe properties of an environment that make skills useful, a precise\ncharacterization has been absent. We provide the first such characterization,\nfocusing on the utility of deterministic skills in deterministic sparse-reward\nenvironments with finite action spaces. We show theoretically and empirically\nthat RL performance gain from skills is worse in environments where solutions\nto states are less compressible. Additional theoretical results suggest that\nskills benefit exploration more than they benefit learning from existing\nexperience, and that using unexpressive skills such as macroactions may worsen\nRL performance. We hope our findings can guide research on automatic skill\ndiscovery and help RL practitioners better decide when and how to use skills.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 1 figure. Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07897v1",
    "published_date": "2024-06-12 06:01:42 UTC",
    "updated_date": "2024-06-12 06:01:42 UTC"
  },
  {
    "arxiv_id": "2406.07892v2",
    "title": "A Finite-Sample Analysis of an Actor-Critic Algorithm for Mean-Variance Optimization in a Discounted MDP",
    "authors": [
      "Tejaram Sangadi",
      "L. A. Prashanth",
      "Krishna Jagannathan"
    ],
    "abstract": "Motivated by applications in risk-sensitive reinforcement learning, we study\nmean-variance optimization in a discounted reward Markov Decision Process\n(MDP). Specifically, we analyze a Temporal Difference (TD) learning algorithm\nwith linear function approximation (LFA) for policy evaluation. We derive\nfinite-sample bounds that hold (i) in the mean-squared sense and (ii) with high\nprobability under tail iterate averaging, both with and without regularization.\nOur bounds exhibit an exponentially decaying dependence on the initial error\nand a convergence rate of $O(1/t)$ after $t$ iterations. Moreover, for the\nregularized TD variant, our bound holds for a universal step size. Next, we\nintegrate a Simultaneous Perturbation Stochastic Approximation (SPSA)-based\nactor update with an LFA critic and establish an $O(n^{-1/4})$ convergence\nguarantee, where $n$ denotes the iterations of the SPSA-based actor-critic\nalgorithm. These results establish finite-sample theoretical guarantees for\nrisk-sensitive actor-critic methods in reinforcement learning, with a focus on\nvariance as a risk measure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07892v2",
    "published_date": "2024-06-12 05:49:53 UTC",
    "updated_date": "2025-03-12 14:32:31 UTC"
  },
  {
    "arxiv_id": "2406.07888v2",
    "title": "Classification Modeling with RNN-Based, Random Forest, and XGBoost for Imbalanced Data: A Case of Early Crash Detection in ASEAN-5 Stock Markets",
    "authors": [
      "Deri Siswara",
      "Agus M. Soleh",
      "Aji Hamim Wigena"
    ],
    "abstract": "This research aims to evaluate the performance of several Recurrent Neural\nNetwork (RNN) architectures including Simple RNN, Gated Recurrent Units (GRU),\nand Long Short-Term Memory (LSTM), compared to classic algorithms such as\nRandom Forest and XGBoost in building classification models for early crash\ndetection in ASEAN-5 stock markets. The study is examined using imbalanced\ndata, which is common due to the rarity of market crashes. The study analyzes\ndaily data from 2010 to 2023 across the major stock markets of the ASEAN-5\ncountries, including Indonesia, Malaysia, Singapore, Thailand, and Philippines.\nMarket crash is identified as the target variable when the major stock price\nindices fall below the Value at Risk (VaR) thresholds of 5%, 2.5% and 1%.\npredictors involving technical indicators of major local and global markets as\nwell as commodity markets. This study includes 213 predictors with their\nrespective lags (5, 10, 15, 22, 50, 200) and uses a time step of 7, expanding\nthe total number of predictors to 1491. The challenge of data imbalance is\naddressed with SMOTE-ENN. The results show that all RNN-Based architectures\noutperform Random Forest and XGBoost. Among the various RNN architectures,\nSimple RNN stands out as the most superior, mainly due to the data\ncharacteristics that are not overly complex and focus more on short-term\ninformation. This study enhances and extends the range of phenomena observed in\nprevious studies by incorporating variables like different geographical zones\nand time periods, as well as methodological adjustments.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "AM - Accepted Manuscript",
    "pdf_url": "http://arxiv.org/pdf/2406.07888v2",
    "published_date": "2024-06-12 05:35:28 UTC",
    "updated_date": "2024-09-29 12:35:19 UTC"
  },
  {
    "arxiv_id": "2406.07882v3",
    "title": "Designing a Dashboard for Transparency and Control of Conversational AI",
    "authors": [
      "Yida Chen",
      "Aoyu Wu",
      "Trevor DePodesta",
      "Catherine Yeh",
      "Kenneth Li",
      "Nicholas Castillo Marin",
      "Oam Patel",
      "Jan Riecke",
      "Shivam Raval",
      "Olivia Seow",
      "Martin Wattenberg",
      "Fernanda Viégas"
    ],
    "abstract": "Conversational LLMs function as black box systems, leaving users guessing\nabout why they see the output they do. This lack of transparency is potentially\nproblematic, especially given concerns around bias and truthfulness. To address\nthis issue, we present an end-to-end prototype-connecting interpretability\ntechniques with user experience design-that seeks to make chatbots more\ntransparent. We begin by showing evidence that a prominent open-source LLM has\na \"user model\": examining the internal state of the system, we can extract data\nrelated to a user's age, gender, educational level, and socioeconomic status.\nNext, we describe the design of a dashboard that accompanies the chatbot\ninterface, displaying this user model in real time. The dashboard can also be\nused to control the user model and the system's behavior. Finally, we discuss a\nstudy in which users conversed with the instrumented system. Our results\nsuggest that users appreciate seeing internal states, which helped them expose\nbiased behavior and increased their sense of control. Participants also made\nvaluable suggestions that point to future directions for both design and\nmachine learning research. The project page and video demo of our TalkTuner\nsystem are available at https://bit.ly/talktuner-project-page",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Project page: https://bit.ly/talktuner-project-page, 38 pages, 23\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07882v3",
    "published_date": "2024-06-12 05:20:16 UTC",
    "updated_date": "2024-10-14 17:46:28 UTC"
  },
  {
    "arxiv_id": "2406.07879v1",
    "title": "KernelWarehouse: Rethinking the Design of Dynamic Convolution",
    "authors": [
      "Chao Li",
      "Anbang Yao"
    ],
    "abstract": "Dynamic convolution learns a linear mixture of n static kernels weighted with\ntheir input-dependent attentions, demonstrating superior performance than\nnormal convolution. However, it increases the number of convolutional\nparameters by n times, and thus is not parameter efficient. This leads to no\nresearch progress that can allow researchers to explore the setting n>100 (an\norder of magnitude larger than the typical setting n<10) for pushing forward\nthe performance boundary of dynamic convolution while enjoying parameter\nefficiency. To fill this gap, in this paper, we propose KernelWarehouse, a more\ngeneral form of dynamic convolution, which redefines the basic concepts of\n``kernels\", ``assembling kernels\" and ``attention function\" through the lens of\nexploiting convolutional parameter dependencies within the same layer and\nacross neighboring layers of a ConvNet. We testify the effectiveness of\nKernelWarehouse on ImageNet and MS-COCO datasets using various ConvNet\narchitectures. Intriguingly, KernelWarehouse is also applicable to Vision\nTransformers, and it can even reduce the model size of a backbone while\nimproving the model accuracy. For instance, KernelWarehouse (n=4) achieves\n5.61%|3.90%|4.38% absolute top-1 accuracy gain on the\nResNet18|MobileNetV2|DeiT-Tiny backbone, and KernelWarehouse (n=1/4) with\n65.10% model size reduction still achieves 2.29% gain on the ResNet18 backbone.\nThe code and models are available at https://github.com/OSVAI/KernelWarehouse.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work is accepted to ICML 2024. The project page:\n  https://github.com/OSVAI/KernelWarehouse. arXiv admin note: substantial text\n  overlap with arXiv:2308.08361",
    "pdf_url": "http://arxiv.org/pdf/2406.07879v1",
    "published_date": "2024-06-12 05:16:26 UTC",
    "updated_date": "2024-06-12 05:16:26 UTC"
  },
  {
    "arxiv_id": "2406.07877v2",
    "title": "Hierarchical Reinforcement Learning for Swarm Confrontation with High Uncertainty",
    "authors": [
      "Qizhen Wu",
      "Kexin Liu",
      "Lei Chen",
      "Jinhu Lü"
    ],
    "abstract": "In swarm robotics, confrontation including the pursuit-evasion game is a key\nscenario. High uncertainty caused by unknown opponents' strategies, dynamic\nobstacles, and insufficient training complicates the action space into a hybrid\ndecision process. Although the deep reinforcement learning method is\nsignificant for swarm confrontation since it can handle various sizes, as an\nend-to-end implementation, it cannot deal with the hybrid process. Here, we\npropose a novel hierarchical reinforcement learning approach consisting of a\ntarget allocation layer, a path planning layer, and the underlying dynamic\ninteraction mechanism between the two layers, which indicates the quantified\nuncertainty. It decouples the hybrid process into discrete allocation and\ncontinuous planning layers, with a probabilistic ensemble model to quantify the\nuncertainty and regulate the interaction frequency adaptively. Furthermore, to\novercome the unstable training process introduced by the two layers, we design\nan integration training method including pre-training and cross-training, which\nenhances the training efficiency and stability. Experiment results in both\ncomparison, ablation, and real-robot studies validate the effectiveness and\ngeneralization performance of our proposed approach. In our defined experiments\nwith twenty to forty agents, the win rate of the proposed method reaches around\nninety percent, outperforming other traditional methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07877v2",
    "published_date": "2024-06-12 05:12:10 UTC",
    "updated_date": "2024-10-25 08:35:19 UTC"
  },
  {
    "arxiv_id": "2406.07876v1",
    "title": "Small Scale Data-Free Knowledge Distillation",
    "authors": [
      "He Liu",
      "Yikai Wang",
      "Huaping Liu",
      "Fuchun Sun",
      "Anbang Yao"
    ],
    "abstract": "Data-free knowledge distillation is able to utilize the knowledge learned by\na large teacher network to augment the training of a smaller student network\nwithout accessing the original training data, avoiding privacy, security, and\nproprietary risks in real applications. In this line of research, existing\nmethods typically follow an inversion-and-distillation paradigm in which a\ngenerative adversarial network on-the-fly trained with the guidance of the\npre-trained teacher network is used to synthesize a large-scale sample set for\nknowledge distillation. In this paper, we reexamine this common data-free\nknowledge distillation paradigm, showing that there is considerable room to\nimprove the overall training efficiency through a lens of ``small-scale\ninverted data for knowledge distillation\". In light of three empirical\nobservations indicating the importance of how to balance class distributions in\nterms of synthetic sample diversity and difficulty during both data inversion\nand distillation processes, we propose Small Scale Data-free Knowledge\nDistillation SSD-KD. In formulation, SSD-KD introduces a modulating function to\nbalance synthetic samples and a priority sampling function to select proper\nsamples, facilitated by a dynamic replay buffer and a reinforcement learning\nstrategy. As a result, SSD-KD can perform distillation training conditioned on\nan extremely small scale of synthetic samples (e.g., 10X less than the original\ntraining data scale), making the overall training efficiency one or two orders\nof magnitude faster than many mainstream methods while retaining superior or\ncompetitive model performance, as demonstrated on popular image classification\nand semantic segmentation benchmarks. The code is available at\nhttps://github.com/OSVAI/SSD-KD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work is accepted to CVPR 2024. The project page:\n  https://github.com/OSVAI/SSD-KD",
    "pdf_url": "http://arxiv.org/pdf/2406.07876v1",
    "published_date": "2024-06-12 05:09:41 UTC",
    "updated_date": "2024-06-12 05:09:41 UTC"
  },
  {
    "arxiv_id": "2406.07875v2",
    "title": "Carbon Market Simulation with Adaptive Mechanism Design",
    "authors": [
      "Han Wang",
      "Wenhao Li",
      "Hongyuan Zha",
      "Baoxiang Wang"
    ],
    "abstract": "A carbon market is a market-based tool that incentivizes economic agents to\nalign individual profits with the global utility, i.e., reducing carbon\nemissions to tackle climate change. Cap and trade stands as a critical\nprinciple based on allocating and trading carbon allowances (carbon emission\ncredit), enabling economic agents to follow planned emissions and penalizing\nexcess emissions. A central authority is responsible for introducing and\nallocating those allowances in cap and trade. However, the complexity of carbon\nmarket dynamics makes accurate simulation intractable, which in turn hinders\nthe design of effective allocation strategies. To address this, we propose an\nadaptive mechanism design framework, simulating the market using hierarchical,\nmodel-free multi-agent reinforcement learning (MARL). Government agents\nallocate carbon credits, while enterprises engage in economic activities and\ncarbon trading. This framework illustrates agents' behavior comprehensively.\nNumerical results show MARL enables government agents to balance productivity,\nequality, and carbon emissions. Our project is available at\nhttps://github.com/xwanghan/Carbon-Simulator.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07875v2",
    "published_date": "2024-06-12 05:08:51 UTC",
    "updated_date": "2024-06-13 10:29:16 UTC"
  },
  {
    "arxiv_id": "2406.07869v2",
    "title": "Unveiling the Power of Wavelets: A Wavelet-based Kolmogorov-Arnold Network for Hyperspectral Image Classification",
    "authors": [
      "Seyd Teymoor Seydi",
      "Zavareh Bozorgasl",
      "Hao Chen"
    ],
    "abstract": "Hyperspectral image classification is a crucial but challenging task due to\nthe high dimensionality and complex spatial-spectral correlations inherent in\nhyperspectral data. This paper employs Wavelet-based Kolmogorov-Arnold Network\n(wav-kan) architecture tailored for efficient modeling of these intricate\ndependencies. Inspired by the Kolmogorov-Arnold representation theorem, Wav-KAN\nincorporates wavelet functions as learnable activation functions, enabling\nnon-linear mapping of the input spectral signatures. The wavelet-based\nactivation allows Wav-KAN to effectively capture multi-scale spatial and\nspectral patterns through dilations and translations. Experimental evaluation\non three benchmark hyperspectral datasets (Salinas, Pavia, Indian Pines)\ndemonstrates the superior performance of Wav-KAN compared to traditional\nmultilayer perceptrons (MLPs) and the recently proposed Spline-based KAN\n(Spline-KAN) model. In this work we are: (1) conducting more experiments on\nadditional hyperspectral datasets (Pavia University, WHU-Hi, and Urban\nHyperspectral Image) to further validate the generalizability of Wav-KAN; (2)\ndeveloping a multiresolution Wav-KAN architecture to capture scale-invariant\nfeatures; (3) analyzing the effect of dimensional reduction techniques on\nclassification performance; (4) exploring optimization methods for tuning the\nhyperparameters of KAN models; and (5) comparing Wav-KAN with other\nstate-of-the-art models in hyperspectral image classification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07869v2",
    "published_date": "2024-06-12 04:52:40 UTC",
    "updated_date": "2024-10-08 14:42:40 UTC"
  },
  {
    "arxiv_id": "2406.07867v2",
    "title": "Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation",
    "authors": [
      "Se Jin Park",
      "Chae Won Kim",
      "Hyeongseop Rha",
      "Minsu Kim",
      "Joanna Hong",
      "Jeong Hun Yeo",
      "Yong Man Ro"
    ],
    "abstract": "In this paper, we introduce a novel Face-to-Face spoken dialogue model. It\nprocesses audio-visual speech from user input and generates audio-visual speech\nas the response, marking the initial step towards creating an avatar chatbot\nsystem without relying on intermediate text. To this end, we newly introduce\nMultiDialog, the first large-scale multimodal (i.e., audio and visual) spoken\ndialogue corpus containing 340 hours of approximately 9,000 dialogues, recorded\nbased on the open domain dialogue dataset, TopicalChat. The MultiDialog\ncontains parallel audio-visual recordings of conversation partners acting\naccording to the given script with emotion annotations, which we expect to open\nup research opportunities in multimodal synthesis. Our Face-to-Face spoken\ndialogue model incorporates a textually pretrained large language model and\nadapts it into the audio-visual spoken dialogue domain by incorporating\nspeech-text joint pretraining. Through extensive experiments, we validate the\neffectiveness of our model in facilitating a face-to-face conversation. Demo\nand data are available at https://multidialog.github.io and\nhttps://huggingface.co/datasets/IVLLab/MultiDialog, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACL 2024 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2406.07867v2",
    "published_date": "2024-06-12 04:48:36 UTC",
    "updated_date": "2024-08-02 15:05:47 UTC"
  },
  {
    "arxiv_id": "2406.07865v1",
    "title": "FaithFill: Faithful Inpainting for Object Completion Using a Single Reference Image",
    "authors": [
      "Rupayan Mallick",
      "Amr Abdalla",
      "Sarah Adel Bargal"
    ],
    "abstract": "We present FaithFill, a diffusion-based inpainting object completion approach\nfor realistic generation of missing object parts. Typically, multiple reference\nimages are needed to achieve such realistic generation, otherwise the\ngeneration would not faithfully preserve shape, texture, color, and background.\nIn this work, we propose a pipeline that utilizes only a single input reference\nimage -having varying lighting, background, object pose, and/or viewpoint. The\nsingular reference image is used to generate multiple views of the object to be\ninpainted. We demonstrate that FaithFill produces faithful generation of the\nobject's missing parts, together with background/scene preservation, from a\nsingle reference image. This is demonstrated through standard similarity\nmetrics, human judgement, and GPT evaluation. Our results are presented on the\nDreamBooth dataset, and a novel proposed dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07865v1",
    "published_date": "2024-06-12 04:45:33 UTC",
    "updated_date": "2024-06-12 04:45:33 UTC"
  },
  {
    "arxiv_id": "2406.07862v1",
    "title": "Self-Distillation Learning Based on Temporal-Spatial Consistency for Spiking Neural Networks",
    "authors": [
      "Lin Zuo",
      "Yongqi Ding",
      "Mengmeng Jing",
      "Kunshan Yang",
      "Yunqian Yu"
    ],
    "abstract": "Spiking neural networks (SNNs) have attracted considerable attention for\ntheir event-driven, low-power characteristics and high biological\ninterpretability. Inspired by knowledge distillation (KD), recent research has\nimproved the performance of the SNN model with a pre-trained teacher model.\nHowever, additional teacher models require significant computational resources,\nand it is tedious to manually define the appropriate teacher network\narchitecture. In this paper, we explore cost-effective self-distillation\nlearning of SNNs to circumvent these concerns. Without an explicit defined\nteacher, the SNN generates pseudo-labels and learns consistency during\ntraining. On the one hand, we extend the timestep of the SNN during training to\ncreate an implicit temporal ``teacher\" that guides the learning of the original\n``student\", i.e., the temporal self-distillation. On the other hand, we guide\nthe output of the weak classifier at the intermediate stage by the final output\nof the SNN, i.e., the spatial self-distillation. Our temporal-spatial\nself-distillation (TSSD) learning method does not introduce any inference\noverhead and has excellent generalization ability. Extensive experiments on the\nstatic image datasets CIFAR10/100 and ImageNet as well as the neuromorphic\ndatasets CIFAR10-DVS and DVS-Gesture validate the superior performance of the\nTSSD method. This paper presents a novel manner of fusing SNNs with KD,\nproviding insights into high-performance SNN learning methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "I.2.6; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07862v1",
    "published_date": "2024-06-12 04:30:40 UTC",
    "updated_date": "2024-06-12 04:30:40 UTC"
  },
  {
    "arxiv_id": "2406.07860v1",
    "title": "BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain",
    "authors": [
      "Rahul Kumar",
      "Amar Raja Dibbu",
      "Shrutendra Harsola",
      "Vignesh Subrahmaniam",
      "Ashutosh Modi"
    ],
    "abstract": "Several large-scale datasets (e.g., WikiSQL, Spider) for developing natural\nlanguage interfaces to databases have recently been proposed. These datasets\ncover a wide breadth of domains but fall short on some essential domains, such\nas finance and accounting. Given that accounting databases are used worldwide,\nparticularly by non-technical people, there is an imminent need to develop\nmodels that could help extract information from accounting databases via\nnatural language queries. In this resource paper, we aim to fill this gap by\nproposing a new large-scale Text-to-SQL dataset for the accounting and\nfinancial domain: BookSQL. The dataset consists of 100k natural language\nqueries-SQL pairs, and accounting databases of 1 million records. We experiment\nwith and analyze existing state-of-the-art models (including GPT-4) for the\nText-to-SQL task on BookSQL. We find significant performance gaps, thus\npointing towards developing more focused models for this domain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2024; 20 Pages (main + appendix)",
    "pdf_url": "http://arxiv.org/pdf/2406.07860v1",
    "published_date": "2024-06-12 04:22:27 UTC",
    "updated_date": "2024-06-12 04:22:27 UTC"
  },
  {
    "arxiv_id": "2406.07850v1",
    "title": "Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation",
    "authors": [
      "Yiwei Li",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Bin Sun",
      "Shaoxiong Feng",
      "Kan Li"
    ],
    "abstract": "Stochastic sampling strategies such as top-k and top-p have been widely used\nin dialogue generation task. However, as an open-domain chatting system, there\nwill be two different conversation scenarios, i.e. chit-chat and\nknowledge-based question answering. In the former situation, responses\ndiversity is essential due to the one-to-many nature in dialogue. The latter,\non the other hand, requires less randomness given that stochastic decoding\nstrategy entails the risk of generating incorrect information. As a result, an\nadaptive and flexible decoding strategy is needed to cope with these two\nscenarios simultaneously. To this end, we propose the dynamic decoding strategy\n(DDS), which can adjust the decoding space w.r.t. different contexts. In DDS,\nboth sequence-level and token-level adaptive search can be achieved to adjust\nthe decoding process in a unified framework. Besides, our adaptive algorithm\ncan not only be used during model inference, but it can also be applied during\nthe model training stage to further enhance the performance. Comprehensive\nexperiments indicate that the proposed decoding strategy can consistently\nimprove the performance of pre-trained dialogue models when coupled with four\nwell-used stochastic decoding algorithms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.07850v1",
    "published_date": "2024-06-12 03:38:45 UTC",
    "updated_date": "2024-06-12 03:38:45 UTC"
  },
  {
    "arxiv_id": "2406.07848v1",
    "title": "Multi-agent Reinforcement Learning with Deep Networks for Diverse Q-Vectors",
    "authors": [
      "Zhenglong Luo",
      "Zhiyong Chen",
      "James Welsh"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has become a significant research\ntopic due to its ability to facilitate learning in complex environments. In\nmulti-agent tasks, the state-action value, commonly referred to as the Q-value,\ncan vary among agents because of their individual rewards, resulting in a\nQ-vector. Determining an optimal policy is challenging, as it involves more\nthan just maximizing a single Q-value. Various optimal policies, such as a Nash\nequilibrium, have been studied in this context. Algorithms like Nash Q-learning\nand Nash Actor-Critic have shown effectiveness in these scenarios. This paper\nextends this research by proposing a deep Q-networks (DQN) algorithm capable of\nlearning various Q-vectors using Max, Nash, and Maximin strategies. The\neffectiveness of this approach is demonstrated in an environment where dual\nrobotic arms collaborate to lift a pot.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07848v1",
    "published_date": "2024-06-12 03:30:10 UTC",
    "updated_date": "2024-06-12 03:30:10 UTC"
  },
  {
    "arxiv_id": "2406.10279v3",
    "title": "We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs",
    "authors": [
      "Joseph Spracklen",
      "Raveen Wijewickrama",
      "A H M Nazmus Sakib",
      "Anindya Maiti",
      "Bimal Viswanath",
      "Murtuza Jadliwala"
    ],
    "abstract": "The reliance of popular programming languages such as Python and JavaScript\non centralized package repositories and open-source software, combined with the\nemergence of code-generating Large Language Models (LLMs), has created a new\ntype of threat to the software supply chain: package hallucinations. These\nhallucinations, which arise from fact-conflicting errors when generating code\nusing LLMs, represent a novel form of package confusion attack that poses a\ncritical threat to the integrity of the software supply chain. This paper\nconducts a rigorous and comprehensive evaluation of package hallucinations\nacross different programming languages, settings, and parameters, exploring how\na diverse set of models and configurations affect the likelihood of generating\nerroneous package recommendations and identifying the root causes of this\nphenomenon. Using 16 popular LLMs for code generation and two unique prompt\ndatasets, we generate 576,000 code samples in two programming languages that we\nanalyze for package hallucinations. Our findings reveal that that the average\npercentage of hallucinated packages is at least 5.2% for commercial models and\n21.7% for open-source models, including a staggering 205,474 unique examples of\nhallucinated package names, further underscoring the severity and pervasiveness\nof this threat. To overcome this problem, we implement several hallucination\nmitigation strategies and show that they are able to significantly reduce the\nnumber of package hallucinations while maintaining code quality. Our\nexperiments and findings highlight package hallucinations as a persistent and\nsystemic phenomenon while using state-of-the-art LLMs for code generation, and\na significant challenge which deserves the research community's urgent\nattention.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "To appear in the 2025 USENIX Security Symposium. 22 pages, 14\n  figures, 8 tables. Edited from original version for submission to a different\n  conference. No change to original results or findings",
    "pdf_url": "http://arxiv.org/pdf/2406.10279v3",
    "published_date": "2024-06-12 03:29:06 UTC",
    "updated_date": "2025-03-02 21:03:52 UTC"
  },
  {
    "arxiv_id": "2406.07837v3",
    "title": "Scaling Manipulation Learning with Visual Kinematic Chain Prediction",
    "authors": [
      "Xinyu Zhang",
      "Yuhan Liu",
      "Haonan Chang",
      "Abdeslam Boularias"
    ],
    "abstract": "Learning general-purpose models from diverse datasets has achieved great\nsuccess in machine learning. In robotics, however, existing methods in\nmulti-task learning are typically constrained to a single robot and workspace,\nwhile recent work such as RT-X requires a non-trivial action normalization\nprocedure to manually bridge the gap between different action spaces in diverse\nenvironments. In this paper, we propose the visual kinematics chain as a\nprecise and universal representation of quasi-static actions for robot learning\nover diverse environments, which requires no manual adjustment since the visual\nkinematic chains can be automatically obtained from the robot's model and\ncamera parameters. We propose the Visual Kinematics Transformer (VKT), a\nconvolution-free architecture that supports an arbitrary number of camera\nviewpoints, and that is trained with a single objective of forecasting\nkinematic structures through optimal point-set matching. We demonstrate the\nsuperior performance of VKT over BC transformers as a general agent on Calvin,\nRLBench, Open-X, and real robot manipulation tasks. Video demonstrations can be\nfound at https://mlzxy.github.io/visual-kinetic-chain.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "CoRL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07837v3",
    "published_date": "2024-06-12 03:10:27 UTC",
    "updated_date": "2024-10-14 15:17:14 UTC"
  },
  {
    "arxiv_id": "2406.07833v1",
    "title": "Sense Less, Generate More: Pre-training LiDAR Perception with Masked Autoencoders for Ultra-Efficient 3D Sensing",
    "authors": [
      "Sina Tayebati",
      "Theja Tulabandhula",
      "Amit R. Trivedi"
    ],
    "abstract": "In this work, we propose a disruptively frugal LiDAR perception dataflow that\ngenerates rather than senses parts of the environment that are either\npredictable based on the extensive training of the environment or have limited\nconsequence to the overall prediction accuracy. Therefore, the proposed\nmethodology trades off sensing energy with training data for low-power robotics\nand autonomous navigation to operate frugally with sensors, extending their\nlifetime on a single battery charge. Our proposed generative pre-training\nstrategy for this purpose, called as radially masked autoencoding (R-MAE), can\nalso be readily implemented in a typical LiDAR system by selectively activating\nand controlling the laser power for randomly generated angular regions during\non-field operations. Our extensive evaluations show that pre-training with\nR-MAE enables focusing on the radial segments of the data, thereby capturing\nspatial relationships and distances between objects more effectively than\nconventional procedures. Therefore, the proposed methodology not only reduces\nsensing energy but also improves prediction accuracy. For example, our\nextensive evaluations on Waymo, nuScenes, and KITTI datasets show that the\napproach achieves over a 5% average precision improvement in detection tasks\nacross datasets and over a 4% accuracy improvement in transferring domains from\nWaymo and nuScenes to KITTI. In 3D object detection, it enhances small object\ndetection by up to 4.37% in AP at moderate difficulty levels in the KITTI\ndataset. Even with 90% radial masking, it surpasses baseline models by up to\n5.59% in mAP/mAPH across all object classes in the Waymo dataset. Additionally,\nour method achieves up to 3.17% and 2.31% improvements in mAP and NDS,\nrespectively, on the nuScenes dataset, demonstrating its effectiveness with\nboth single and fused LiDAR-camera modalities.\nhttps://github.com/sinatayebati/Radial_MAE.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07833v1",
    "published_date": "2024-06-12 03:02:54 UTC",
    "updated_date": "2024-06-12 03:02:54 UTC"
  },
  {
    "arxiv_id": "2406.07826v1",
    "title": "The Max-Min Formulation of Multi-Objective Reinforcement Learning: From Theory to a Model-Free Algorithm",
    "authors": [
      "Giseung Park",
      "Woohyeon Byeon",
      "Seongmin Kim",
      "Elad Havakuk",
      "Amir Leshem",
      "Youngchul Sung"
    ],
    "abstract": "In this paper, we consider multi-objective reinforcement learning, which\narises in many real-world problems with multiple optimization goals. We\napproach the problem with a max-min framework focusing on fairness among the\nmultiple goals and develop a relevant theory and a practical model-free\nalgorithm under the max-min framework. The developed theory provides a\ntheoretical advance in multi-objective reinforcement learning, and the proposed\nalgorithm demonstrates a notable performance improvement over existing baseline\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07826v1",
    "published_date": "2024-06-12 02:47:54 UTC",
    "updated_date": "2024-06-12 02:47:54 UTC"
  },
  {
    "arxiv_id": "2406.07815v2",
    "title": "Are Large Language Models Good Statisticians?",
    "authors": [
      "Yizhang Zhu",
      "Shiyin Du",
      "Boyan Li",
      "Yuyu Luo",
      "Nan Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of scientific tasks including mathematics, physics, and chemistry.\nDespite their successes, the effectiveness of LLMs in handling complex\nstatistical tasks remains systematically under-explored. To bridge this gap, we\nintroduce StatQA, a new benchmark designed for statistical analysis tasks.\nStatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in\nspecialized statistical tasks and their applicability assessment capabilities,\nparticularly for hypothesis testing methods. We systematically experiment with\nrepresentative LLMs using various prompting strategies and show that even\nstate-of-the-art models such as GPT-4o achieve a best performance of only\n64.83%, indicating significant room for improvement. Notably, while open-source\nLLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit\nmarked improvements, outperforming all in-context learning-based methods (e.g.\nGPT-4o). Moreover, our comparative human experiments highlight a striking\ncontrast in error types between LLMs and humans: LLMs primarily make\napplicability errors, whereas humans mostly make statistical task confusion\nerrors. This divergence highlights distinct areas of proficiency and\ndeficiency, suggesting that combining LLM and human expertise could lead to\ncomplementary strengths, inviting further investigation into their\ncollaborative potential. Our source code and data are available at\nhttps://statqa.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024 D&B. 34 pages, 11 figures, 21 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07815v2",
    "published_date": "2024-06-12 02:23:51 UTC",
    "updated_date": "2024-10-10 06:01:10 UTC"
  },
  {
    "arxiv_id": "2406.07814v1",
    "title": "Collective Constitutional AI: Aligning a Language Model with Public Input",
    "authors": [
      "Saffron Huang",
      "Divya Siddarth",
      "Liane Lovitt",
      "Thomas I. Liao",
      "Esin Durmus",
      "Alex Tamkin",
      "Deep Ganguli"
    ],
    "abstract": "There is growing consensus that language model (LM) developers should not be\nthe sole deciders of LM behavior, creating a need for methods that enable the\nbroader public to collectively shape the behavior of LM systems that affect\nthem. To address this need, we present Collective Constitutional AI (CCAI): a\nmulti-stage process for sourcing and integrating public input into LMs-from\nidentifying a target population to sourcing principles to training and\nevaluating a model. We demonstrate the real-world practicality of this approach\nby creating what is, to our knowledge, the first LM fine-tuned with\ncollectively sourced public input and evaluating this model against a baseline\nmodel trained with established principles from a LM developer. Our quantitative\nevaluations demonstrate several benefits of our approach: the CCAI-trained\nmodel shows lower bias across nine social dimensions compared to the baseline\nmodel, while maintaining equivalent performance on language, math, and\nhelpful-harmless evaluations. Qualitative comparisons of the models suggest\nthat the models differ on the basis of their respective constitutions, e.g.,\nwhen prompted with contentious topics, the CCAI-trained model tends to generate\nresponses that reframe the matter positively instead of a refusal. These\nresults demonstrate a promising, tractable pathway toward publicly informed\ndevelopment of language models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "I.2.7; K.4.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07814v1",
    "published_date": "2024-06-12 02:20:46 UTC",
    "updated_date": "2024-06-12 02:20:46 UTC"
  },
  {
    "arxiv_id": "2406.07812v1",
    "title": "To be Continuous, or to be Discrete, Those are Bits of Questions",
    "authors": [
      "Yiran Wang",
      "Masao Utiyama"
    ],
    "abstract": "Recently, binary representation has been proposed as a novel representation\nthat lies between continuous and discrete representations. It exhibits\nconsiderable information-preserving capability when being used to replace\ncontinuous input vectors. In this paper, we investigate the feasibility of\nfurther introducing it to the output side, aiming to allow models to output\nbinary labels instead. To preserve the structural information on the output\nside along with label information, we extend the previous contrastive hashing\nmethod as structured contrastive hashing. More specifically, we upgrade CKY\nfrom label-level to bit-level, define a new similarity function with span\nmarginal probabilities, and introduce a novel contrastive loss function with a\ncarefully designed instance selection strategy. Our model achieves competitive\nperformance on various structured prediction tasks, and demonstrates that\nbinary representation can be considered a novel representation that further\nbridges the gap between the continuous nature of deep learning and the discrete\nintrinsic property of natural languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL-2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07812v1",
    "published_date": "2024-06-12 02:08:45 UTC",
    "updated_date": "2024-06-12 02:08:45 UTC"
  },
  {
    "arxiv_id": "2406.07811v2",
    "title": "Evolutionary Computation and Explainable AI: A Roadmap to Understandable Intelligent Systems",
    "authors": [
      "Ryan Zhou",
      "Jaume Bacardit",
      "Alexander Brownlee",
      "Stefano Cagnoni",
      "Martin Fyvie",
      "Giovanni Iacca",
      "John McCall",
      "Niki van Stein",
      "David Walker",
      "Ting Hu"
    ],
    "abstract": "Artificial intelligence methods are being increasingly applied across various\ndomains, but their often opaque nature has raised concerns about accountability\nand trust. In response, the field of explainable AI (XAI) has emerged to\naddress the need for human-understandable AI systems. Evolutionary computation\n(EC), a family of powerful optimization and learning algorithms, offers\nsignificant potential to contribute to XAI, and vice versa. This paper provides\nan introduction to XAI and reviews current techniques for explaining machine\nlearning models. We then explore how EC can be leveraged in XAI and examine\nexisting XAI approaches that incorporate EC techniques. Furthermore, we discuss\nthe application of XAI principles within EC itself, investigating how these\nprinciples can illuminate the behavior and outcomes of EC algorithms, their\n(automatic) configuration, and the underlying problem landscapes they optimize.\nFinally, we discuss open challenges in XAI and highlight opportunities for\nfuture research at the intersection of XAI and EC. Our goal is to demonstrate\nEC's suitability for addressing current explainability challenges and to\nencourage further exploration of these methods, ultimately contributing to the\ndevelopment of more understandable and trustworthy ML models and EC algorithms.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "24 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2306.14786",
    "pdf_url": "http://arxiv.org/pdf/2406.07811v2",
    "published_date": "2024-06-12 02:06:24 UTC",
    "updated_date": "2024-10-17 07:00:45 UTC"
  },
  {
    "arxiv_id": "2406.10278v1",
    "title": "Prompt-Based Length Controlled Generation with Multiple Control Types",
    "authors": [
      "Renlong Jie",
      "Xiaojun Meng",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "abstract": "Large language models (LLMs) have attracted great attention given their\nstrong performance on a wide range of NLP tasks. In practice, users often\nexpect generated texts to fall within a specific length range, making length\ncontrolled generation an important topic, especially for GPT-style models.\nExisting length control methods mostly focus on a simple control type of \"equal\nto\" a target length. Different from them, we propose a prompt-based method to\nachieve length controlled generation under different control types with high\naccuracy. In particular, we adopt reinforcement learning (RL) and sample\nfiltering with the reward signal given by rule-based reward models, which\nenhances the length control ability of models by rewarding outputs that follow\ncertain control instructions. In addition, we introduce a standard prompt\nextractor to parse arbitrary users' input into standard control instructions.\nExperiments show that our method significantly improves the accuracy of\nprompt-based length control on popular summarization datasets like CNNDM and\nNYT under multiple control types. Moreover, both the standard prompt extractor\nand RL-tuned model show strong generalization to unseen control prompt\ntemplates.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 findings. arXiv admin note: text overlap with\n  arXiv:2308.12030",
    "pdf_url": "http://arxiv.org/pdf/2406.10278v1",
    "published_date": "2024-06-12 01:49:54 UTC",
    "updated_date": "2024-06-12 01:49:54 UTC"
  },
  {
    "arxiv_id": "2406.07803v2",
    "title": "EmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech",
    "authors": [
      "Deok-Hyeon Cho",
      "Hyung-Seok Oh",
      "Seung-Bin Kim",
      "Sang-Hoon Lee",
      "Seong-Whan Lee"
    ],
    "abstract": "Despite rapid advances in the field of emotional text-to-speech (TTS), recent\nstudies primarily focus on mimicking the average style of a particular emotion.\nAs a result, the ability to manipulate speech emotion remains constrained to\nseveral predefined labels, compromising the ability to reflect the nuanced\nvariations of emotion. In this paper, we propose EmoSphere-TTS, which\nsynthesizes expressive emotional speech by using a spherical emotion vector to\ncontrol the emotional style and intensity of the synthetic speech. Without any\nhuman annotation, we use the arousal, valence, and dominance pseudo-labels to\nmodel the complex nature of emotion via a Cartesian-spherical transformation.\nFurthermore, we propose a dual conditional adversarial network to improve the\nquality of generated speech by reflecting the multi-aspect characteristics. The\nexperimental results demonstrate the model ability to control emotional style\nand intensity with high-quality expressive speech.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Proceedings of Interspeech",
    "pdf_url": "http://arxiv.org/pdf/2406.07803v2",
    "published_date": "2024-06-12 01:40:29 UTC",
    "updated_date": "2024-11-04 21:39:21 UTC"
  },
  {
    "arxiv_id": "2406.07796v2",
    "title": "Battling Botpoop using GenAI for Higher Education: A Study of a Retrieval Augmented Generation Chatbots Impact on Learning",
    "authors": [
      "Maung Thway",
      "Jose Recatala-Gomez",
      "Fun Siong Lim",
      "Kedar Hippalgaonkar",
      "Leonard W. T. Ng"
    ],
    "abstract": "Generative artificial intelligence (GenAI) and large language models (LLMs)\nhave simultaneously opened new avenues for enhancing human learning and\nincreased the prevalence of poor-quality information in student response -\ntermed Botpoop. This study introduces Professor Leodar, a custom-built,\nSinglish-speaking Retrieval Augmented Generation (RAG) chatbot designed to\nenhance educational while reducing Botpoop. Deployed at Nanyang Technological\nUniversity, Singapore, Professor Leodar offers a glimpse into the future of\nAI-assisted learning, offering personalized guidance, 24/7 availability, and\ncontextually relevant information. Through a mixed-methods approach, we examine\nthe impact of Professor Leodar on learning, engagement, and exam preparedness,\nwith 97.1% of participants reporting positive experiences. These findings help\ndefine possible roles of AI in education and highlight the potential of custom\nGenAI chatbots. Our combination of chatbot development, in-class deployment and\noutcomes study offers a benchmark for GenAI educational tools and is a stepping\nstone for redefining the interplay between AI and human learning.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "13 pages, 5 figures, SI with Annexes A, B and C upon request",
    "pdf_url": "http://arxiv.org/pdf/2406.07796v2",
    "published_date": "2024-06-12 01:19:36 UTC",
    "updated_date": "2024-06-22 01:02:54 UTC"
  },
  {
    "arxiv_id": "2406.07794v2",
    "title": "Making Task-Oriented Dialogue Datasets More Natural by Synthetically Generating Indirect User Requests",
    "authors": [
      "Amogh Mannekote",
      "Jinseok Nam",
      "Ziming Li",
      "Jian Gao",
      "Kristy Elizabeth Boyer",
      "Bonnie J. Dorr"
    ],
    "abstract": "Indirect User Requests (IURs), such as \"It's cold in here\" instead of \"Could\nyou please increase the temperature?\" are common in human-human task-oriented\ndialogue and require world knowledge and pragmatic reasoning from the listener.\nWhile large language models (LLMs) can handle these requests effectively,\nsmaller models deployed on virtual assistants often struggle due to resource\nconstraints. Moreover, existing task-oriented dialogue benchmarks lack\nsufficient examples of complex discourse phenomena such as indirectness. To\naddress this, we propose a set of linguistic criteria along with an LLM-based\npipeline for generating realistic IURs to test natural language understanding\n(NLU) and dialogue state tracking (DST) models before deployment in a new\ndomain. We also release IndirectRequests, a dataset of IURs based on the Schema\nGuided Dialog (SGD) corpus, as a comparative testbed for evaluating the\nperformance of smaller models in handling indirect requests.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07794v2",
    "published_date": "2024-06-12 01:18:04 UTC",
    "updated_date": "2024-06-16 21:20:34 UTC"
  },
  {
    "arxiv_id": "2406.07791v8",
    "title": "Judging the Judges: A Systematic Study of Position Bias in LLM-as-a-Judge",
    "authors": [
      "Lin Shi",
      "Chiyu Ma",
      "Wenhua Liang",
      "Xingjian Diao",
      "Weicheng Ma",
      "Soroush Vosoughi"
    ],
    "abstract": "LLM-as-a-Judge has emerged as a promising alternative to human evaluators\nacross various tasks, yet inherent biases - particularly position bias, the\ntendency to favor solutions based on their position within the prompt -\ncompromise its reliability. This exploratory study evaluates position bias in\nLLM judges across pairwise and list-wise comparison settings, introducing three\nmetrics: repetition stability, position consistency, and preference fairness.\nOur experiments, involving 15 LLM judges across MTBench and DevBench with 22\ntasks and approximately 40 solution-generating models, result in over 150,000\nevaluation instances. We identify Judge-Level, Candidate-Level, and Task-Level\nfactors contributing to bias. The findings confirm that position bias is not\ndue to random chance and varies significantly across judges and tasks. While\nposition bias is weakly influenced by the length of prompt components, it is\nstrongly affected by the quality gap between solutions. Our agreement and\ndisagreement analysis among judges further provides insights into the\ndistribution of judging difficulty across the dataset, and highlights the\npotential for dataset modifications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07791v8",
    "published_date": "2024-06-12 01:12:28 UTC",
    "updated_date": "2025-04-17 02:43:35 UTC"
  },
  {
    "arxiv_id": "2406.07790v1",
    "title": "Hierarchical Neural Networks, p-Adic PDEs, and Applications to Image Processing",
    "authors": [
      "W. A. Zúñiga-Galindo",
      "B. A. Zambrano-Luna",
      "Baboucarr Dibba"
    ],
    "abstract": "The first goal of this article is to introduce a new type of p-adic\nreaction-diffusion cellular neural network with delay. We study the stability\nof these networks and provide numerical simulations of their responses. The\nsecond goal is to provide a quick review of the state of the art of p-adic\ncellular neural networks and their applications to image processing.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "eess.IV",
      "math.AP"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07790v1",
    "published_date": "2024-06-12 01:10:32 UTC",
    "updated_date": "2024-06-12 01:10:32 UTC"
  },
  {
    "arxiv_id": "2406.07778v2",
    "title": "A Study of Backdoors in Instruction Fine-tuned Language Models",
    "authors": [
      "Jayaram Raghuram",
      "George Kesidis",
      "David J. Miller"
    ],
    "abstract": "Backdoor data poisoning, inserted within instruction examples used to\nfine-tune a foundation Large Language Model (LLM) for downstream tasks\n(\\textit{e.g.,} sentiment prediction), is a serious security concern due to the\nevasive nature of such attacks. The poisoning is usually in the form of a\n(seemingly innocuous) trigger word or phrase inserted into a very small\nfraction of the fine-tuning samples from a target class. Such backdoor attacks\ncan: alter response sentiment, violate censorship, over-refuse (invoke\ncensorship for legitimate queries), inject false content, or trigger nonsense\nresponses (hallucinations). In this work we investigate the efficacy of\ninstruction fine-tuning backdoor attacks as attack \"hyperparameters\" are varied\nunder a variety of scenarios, considering: the trigger location in the poisoned\nexamples; robustness to change in the trigger location, partial triggers, and\nsynonym substitutions at test time; attack transfer from one (fine-tuning)\ndomain to a related test domain; and clean-label vs. dirty-label poisoning.\nBased on our observations, we propose and evaluate two defenses against these\nattacks: i) a \\textit{during-fine-tuning defense} based on word-frequency\ncounts that assumes the (possibly poisoned) fine-tuning dataset is available\nand identifies the backdoor trigger tokens; and ii) a \\textit{post-fine-tuning\ndefense} based on downstream clean fine-tuning of the backdoored LLM with a\nsmall defense dataset. Finally, we provide a brief survey of related work on\nbackdoor attacks and defenses.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2406.07778v2",
    "published_date": "2024-06-12 00:01:32 UTC",
    "updated_date": "2024-08-21 23:07:49 UTC"
  }
]