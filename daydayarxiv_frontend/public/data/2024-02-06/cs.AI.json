{
  "date": "2024-02-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化（如 LLM 的鲁棒性和应用）、强化学习、多模态处理以及 AI 在科学和安全领域的潜力，其中 \"HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal\" 等文章突出了 AI 安全评估的标准化框架，\"RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback\" 展示了 LLM 在视觉语言任务中的创新应用，而知名学者如 Heng-Tze Cheng 参与的 \"The Essential Role of Causality in Foundation World Models for Embodied AI\" 强调了因果推理在 AI 发展中的关键作用。\n\n下面，我挑选并简要讨论几篇重要或有话题度的论文，先从 LLM 和 AI 安全入手，再聊强化学习和多模态模型，其他论文则快速掠过，以控制篇幅。\n\n- **HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal**  \n  这篇论文提出 HarmBench 框架，用于评估 AI 模型的安全性，特别是对抗攻击的鲁棒性。主要贡献是通过标准化基准测试自动识别 AI 风险，并通过经验验证证明该框架能显著提升模型防御性能，适用于大规模 AI 安全研究。\n\n- **RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback**  \n  论文引入 RL-VLM-F 方法，将强化学习与视觉语言模型结合，用于机器人任务。关键发现是通过反馈机制，模型能生成更精确的奖励函数，提升任务性能，在实验中显著优于传统方法，展示了 LLM 在多模态环境中的潜力。\n\n- **The Essential Role of Causality in Foundation World Models for Embodied AI**  \n  由知名学者 Heng-Tze Cheng 等参与，论文强调因果推理在 Embodied AI 中的核心作用。主要贡献是提出一个理论框架，整合因果模型来模拟物理交互，实验证明这能提升 AI 代理的决策准确性，为未来 AI 系统提供新方向。\n\n- **PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection**  \n  这篇聚焦图神经网络（GNN）的 IP 保护，提出 PreGIP 框架用于水印嵌入。主要发现是通过任务无关的水印机制，保护 GNN 预训练模型免受盗版，同时保持下游任务性能，实验在多个数据集上验证了其有效性。\n\n- **DistiLLM: Towards Streamlined Distillation for Large Language Models**  \n  论文优化了 LLM 的知识蒸馏过程，引入 skew Kullback-Leibler 散度损失。主要贡献是提高蒸馏效率，实验显示新方法在多种任务上加速 4.3 倍，同时保持性能，适用于资源受限的 LLM 部署。\n\n其他论文，如 \"CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling\"（提出级联模型提升降水预测准确性）和 \"Logical recognition method for solving the problem of identification in the Internet of Things\"（使用逻辑方法识别物联网对象），等涉及环境建模和特定应用，但限于篇幅，仅简要提及。这些论文总体展示了 AI 在多样领域的进展，但非核心焦点。今日快报到此结束，期待明天更多见解！",
  "papers": [
    {
      "arxiv_id": "2402.04477v1",
      "title": "Detecting Mode Collapse in Language Models via Narration",
      "title_zh": "翻译失败",
      "authors": [
        "Sil Hamilton"
      ],
      "abstract": "No two authors write alike. Personal flourishes invoked in written\nnarratives, from lexicon to rhetorical devices, imply a particular author--what\nliterary theorists label the implied or virtual author; distinct from the real\nauthor or narrator of a text. Early large language models trained on unfiltered\ntraining sets drawn from a variety of discordant sources yielded incoherent\npersonalities, problematic for conversational tasks but proving useful for\nsampling literature from multiple perspectives. Successes in alignment research\nin recent years have allowed researchers to impose subjectively consistent\npersonae on language models via instruction tuning and reinforcement learning\nfrom human feedback (RLHF), but whether aligned models retain the ability to\nmodel an arbitrary virtual author has received little scrutiny. By studying\n4,374 stories sampled from three OpenAI language models, we show successive\nversions of GPT-3 suffer from increasing degrees of \"mode collapse\" whereby\noverfitting the model during alignment constrains it from generalizing over\nauthorship: models suffering from mode collapse become unable to assume a\nmultiplicity of perspectives. Our method and results are significant for\nresearchers seeking to employ language models in sociological simulations.",
      "tldr_zh": "本研究提出了一种通过分析叙述来检测语言模型中模式坍缩（mode collapse）的方法，探讨对齐训练（alignment research）、instruction tuning 和 reinforcement learning from human feedback (RLHF) 是否限制了模型模拟多种虚拟作者的能力。  \n通过对 4,374 个从三个 OpenAI 语言模型（如 GPT-3 版本）采样的故事进行研究，作者发现后续模型因过度拟合而加剧模式坍缩，导致其无法有效生成多样视角的叙述。  \n这一发现对语言模型在社会学模拟等领域的应用具有重要意义，有助于评估模型的泛化能力和多样性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in the proceedings of the first Workshop on the Scaling\n  Behavior of Large Language Models (EACL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.04477v1",
      "published_date": "2024-02-06 23:52:58 UTC",
      "updated_date": "2024-02-06 23:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:39:55.239054"
    },
    {
      "arxiv_id": "2402.04476v2",
      "title": "Dual-View Visual Contextualization for Web Navigation",
      "title_zh": "双视图视觉语境化用于网页导航",
      "authors": [
        "Jihyung Kil",
        "Chan Hee Song",
        "Boyuan Zheng",
        "Xiang Deng",
        "Yu Su",
        "Wei-Lun Chao"
      ],
      "abstract": "Automatic web navigation aims to build a web agent that can follow language\ninstructions to execute complex and diverse tasks on real-world websites.\nExisting work primarily takes HTML documents as input, which define the\ncontents and action spaces (i.e., actionable elements and operations) of\nwebpages. Nevertheless, HTML documents may not provide a clear task-related\ncontext for each element, making it hard to select the right (sequence of)\nactions. In this paper, we propose to contextualize HTML elements through their\n\"dual views\" in webpage screenshots: each HTML element has its corresponding\nbounding box and visual content in the screenshot. We build upon the insight --\nweb developers tend to arrange task-related elements nearby on webpages to\nenhance user experiences -- and propose to contextualize each element with its\nneighbor elements, using both textual and visual features. The resulting\nrepresentations of HTML elements are more informative for the agent to take\naction. We validate our method on the recently released Mind2Web dataset, which\nfeatures diverse navigation domains and tasks on real-world websites. Our\nmethod consistently outperforms the baseline in all the scenarios, including\ncross-task, cross-website, and cross-domain ones.",
      "tldr_zh": "这篇论文针对自动网页导航问题，提出Dual-View Visual Contextualization方法，通过网页截图的“dual views”（即每个HTML元素的边界框和视觉内容）来增强HTML元素的任务相关上下文。方法基于网页开发者倾向于将任务相关元素放置在附近的洞见，利用文本和视觉特征对邻近元素进行contextualize，从而使网页代理更准确地选择动作序列。在Mind2Web数据集上的实验验证，该方法在跨任务、跨网站和跨领域场景中均优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04476v2",
      "published_date": "2024-02-06 23:52:10 UTC",
      "updated_date": "2024-03-30 05:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:40:07.268711"
    },
    {
      "arxiv_id": "2402.04466v1",
      "title": "Towards Deterministic End-to-end Latency for Medical AI Systems in NVIDIA Holoscan",
      "title_zh": "翻译失败",
      "authors": [
        "Soham Sinha",
        "Shekhar Dwivedi",
        "Mahdi Azizian"
      ],
      "abstract": "The introduction of AI and ML technologies into medical devices has\nrevolutionized healthcare diagnostics and treatments. Medical device\nmanufacturers are keen to maximize the advantages afforded by AI and ML by\nconsolidating multiple applications onto a single platform. However, concurrent\nexecution of several AI applications, each with its own visualization\ncomponents, leads to unpredictable end-to-end latency, primarily due to GPU\nresource contentions. To mitigate this, manufacturers typically deploy separate\nworkstations for distinct AI applications, thereby increasing financial,\nenergy, and maintenance costs. This paper addresses these challenges within the\ncontext of NVIDIA's Holoscan platform, a real-time AI system for streaming\nsensor data and images. We propose a system design optimized for heterogeneous\nGPU workloads, encompassing both compute and graphics tasks. Our design\nleverages CUDA MPS for spatial partitioning of compute workloads and isolates\ncompute and graphics processing onto separate GPUs. We demonstrate significant\nperformance improvements across various end-to-end latency determinism metrics\nthrough empirical evaluation with real-world Holoscan medical device\napplications. For instance, the proposed design reduces maximum latency by\n21-30% and improves latency distribution flatness by 17-25% for up to five\nconcurrent endoscopy tool tracking AI applications, compared to a single-GPU\nbaseline. Against a default multi-GPU setup, our optimizations decrease maximum\nlatency by 35% for up to six concurrent applications by improving GPU\nutilization by 42%. This paper provides clear design insights for AI\napplications in the edge-computing domain including medical systems, where\nperformance predictability of concurrent and heterogeneous GPU workloads is a\ncritical requirement.",
      "tldr_zh": "这篇论文针对 NVIDIA Holoscan 平台中的医疗 AI 系统，解决了多应用并发执行导致的端到端延迟不确定性问题，主要由于 GPU 资源争用。作者提出了一种优化异构 GPU 工作负载的系统设计，利用 CUDA MPS 进行计算 workload 的空间分区，并将计算和图形处理隔离到不同 GPU，以提高延迟的确定性。通过实证评估，设计方案在真实医疗应用中将最大延迟减少 21-30%，延迟分布平滑性提高 17-25%，并相比默认多 GPU 设置降低了 35% 的最大延迟，同时提升了 42% 的 GPU 利用率。该方法为边缘计算中的 AI 应用，如医疗系统，提供关键设计见解，确保性能的可预测性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.OS",
        "C.3; J.7; D.2.11; D.2.10; D.4.8"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04466v1",
      "published_date": "2024-02-06 23:20:34 UTC",
      "updated_date": "2024-02-06 23:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:40:21.228947"
    },
    {
      "arxiv_id": "2402.04464v2",
      "title": "Ten Hard Problems in Artificial Intelligence We Must Get Right",
      "title_zh": "人工智能中我们必须正确解决的十个难题",
      "authors": [
        "Gavin Leech",
        "Simson Garfinkel",
        "Misha Yagudin",
        "Alexander Briand",
        "Aleksandr Zhuravlev"
      ],
      "abstract": "We explore the AI2050 \"hard problems\" that block the promise of AI and cause\nAI risks: (1) developing general capabilities of the systems; (2) assuring the\nperformance of AI systems and their training processes; (3) aligning system\ngoals with human goals; (4) enabling great applications of AI in real life; (5)\naddressing economic disruptions; (6) ensuring the participation of all; (7) at\nthe same time ensuring socially responsible deployment; (8) addressing any\ngeopolitical disruptions that AI causes; (9) promoting sound governance of the\ntechnology; and (10) managing the philosophical disruptions for humans living\nin the age of AI. For each problem, we outline the area, identify significant\nrecent work, and suggest ways forward. [Note: this paper reviews literature\nthrough January 2023.]",
      "tldr_zh": "这篇论文探讨了 AI2050 框架下的人工智能（AI）领域十个关键难题，这些问题不仅阻碍了 AI 的发展潜力，还引发了各种风险，包括：（1）开发系统的 general capabilities；（2）确保 AI systems 和训练过程的性能；（3）实现系统目标与人类目标的 aligning；以及经济中断、社会参与、地缘政治影响、治理和哲学挑战等。论文对每个难题进行了概述，包括相关领域、近期重要工作，并提出了前进建议。总体而言，该研究基于截至 2023 年 1 月的文献，强调了解决这些难题的紧迫性，以推动负责任的 AI 部署和应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "75 + 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.04464v2",
      "published_date": "2024-02-06 23:16:41 UTC",
      "updated_date": "2024-04-19 10:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:40:31.799676"
    },
    {
      "arxiv_id": "2402.04435v1",
      "title": "PreGIP: Watermarking the Pretraining of Graph Neural Networks for Deep Intellectual Property Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Enyan Dai",
        "Minhua Lin",
        "Suhang Wang"
      ],
      "abstract": "Pretraining on Graph Neural Networks (GNNs) has shown great power in\nfacilitating various downstream tasks. As pretraining generally requires huge\namount of data and computational resources, the pretrained GNNs are high-value\nIntellectual Properties (IP) of the legitimate owner. However, adversaries may\nillegally copy and deploy the pretrained GNN models for their downstream tasks.\nThough initial efforts have been made to watermark GNN classifiers for IP\nprotection, these methods require the target classification task for\nwatermarking, and thus are not applicable to self-supervised pretraining of GNN\nmodels. Hence, in this work, we propose a novel framework named PreGIP to\nwatermark the pretraining of GNN encoder for IP protection while maintain the\nhigh-quality of the embedding space. PreGIP incorporates a task-free\nwatermarking loss to watermark the embedding space of pretrained GNN encoder. A\nfinetuning-resistant watermark injection is further deployed. Theoretical\nanalysis and extensive experiments show the effectiveness of {\\method} in IP\nprotection and maintaining high-performance for downstream tasks.",
      "tldr_zh": "该论文提出PreGIP框架，用于在Graph Neural Networks (GNNs)预训练过程中注入水印，以保护其高价值的Intellectual Property (IP)。PreGIP采用task-free watermarking loss和抗微调(finetuning-resistant)水印注入技术，确保嵌入空间的质量不受影响，同时适用于自监督预训练场景。实验和理论分析证明，PreGIP有效防止模型非法复制，并维持下游任务的高性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04435v1",
      "published_date": "2024-02-06 22:13:49 UTC",
      "updated_date": "2024-02-06 22:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:40:42.497947"
    },
    {
      "arxiv_id": "2402.04421v1",
      "title": "Studying Vulnerable Code Entities in R",
      "title_zh": "R 语言中易受攻击代码实体的研究",
      "authors": [
        "Zixiao Zhao",
        "Millon Madhur Das",
        "Fatemeh H. Fard"
      ],
      "abstract": "Pre-trained Code Language Models (Code-PLMs) have shown many advancements and\nachieved state-of-the-art results for many software engineering tasks in the\npast few years. These models are mainly targeted for popular programming\nlanguages such as Java and Python, leaving out many other ones like R. Though R\nhas a wide community of developers and users, there is little known about the\napplicability of Code-PLMs for R. In this preliminary study, we aim to\ninvestigate the vulnerability of Code-PLMs for code entities in R. For this\npurpose, we use an R dataset of code and comment pairs and then apply\nCodeAttack, a black-box attack model that uses the structure of code to\ngenerate adversarial code samples. We investigate how the model can attack\ndifferent entities in R. This is the first step towards understanding the\nimportance of R token types, compared to popular programming languages (e.g.,\nJava). We limit our study to code summarization. Our results show that the most\nvulnerable code entity is the identifier, followed by some syntax tokens\nspecific to R. The results can shed light on the importance of token types and\nhelp in developing models for code summarization and method name prediction for\nthe R language.",
      "tldr_zh": "本研究调查了预训练代码语言模型（Code-PLMs）在R语言中的脆弱性，填补了其在流行语言（如Java和Python）之外的空白。研究者使用R数据集（包含代码和注释对）并应用CodeAttack黑盒攻击模型生成对抗样本，针对代码总结任务分析模型对R代码实体的攻击敏感性。结果显示，标识符（identifier）是最易受攻击的实体，其次是R特有的语法标记，这突显了R标记类型的关键作用。该研究为开发针对R语言的代码总结和方法名预测模型提供了重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 3 figures, and 2 tables. to be published in ICPC 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04421v1",
      "published_date": "2024-02-06 21:39:55 UTC",
      "updated_date": "2024-02-06 21:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:40:54.041690"
    },
    {
      "arxiv_id": "2402.04420v1",
      "title": "Measuring machine learning harms from stereotypes: requires understanding who is being harmed by which errors in what ways",
      "title_zh": "翻译失败",
      "authors": [
        "Angelina Wang",
        "Xuechunzi Bai",
        "Solon Barocas",
        "Su Lin Blodgett"
      ],
      "abstract": "As machine learning applications proliferate, we need an understanding of\ntheir potential for harm. However, current fairness metrics are rarely grounded\nin human psychological experiences of harm. Drawing on the social psychology of\nstereotypes, we use a case study of gender stereotypes in image search to\nexamine how people react to machine learning errors. First, we use survey\nstudies to show that not all machine learning errors reflect stereotypes nor\nare equally harmful. Then, in experimental studies we randomly expose\nparticipants to stereotype-reinforcing, -violating, and -neutral machine\nlearning errors. We find stereotype-reinforcing errors induce more\nexperientially (i.e., subjectively) harmful experiences, while having minimal\nchanges to cognitive beliefs, attitudes, or behaviors. This experiential harm\nimpacts women more than men. However, certain stereotype-violating errors are\nmore experientially harmful for men, potentially due to perceived threats to\nmasculinity. We conclude that harm cannot be the sole guide in fairness\nmitigation, and propose a nuanced perspective depending on who is experiencing\nwhat harm and why.",
      "tldr_zh": "本研究探讨了机器学习（machine learning）应用中刻板印象（stereotypes）导致的危害，强调需要理解哪些群体因何种错误受到何种影响。研究者通过社会心理学视角，以性别刻板印象在图像搜索中的案例为切入点，进行调查和实验，显示并非所有机器学习错误都等同有害，其中强化刻板印象的错误会引发更多主观体验性危害，而对认知信念、态度或行为影响较小。结果表明，女性比男性更容易受到此类危害，但某些违反刻板印象的错误可能对男性更具威胁性，如挑战男性气质。最终，论文提出，公平性缓解（fairness mitigation）不应仅依赖危害指标，而需采用更细致的视角，考虑受影响者的具体经历和原因。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "earlier draft non-archival at EAAMO 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.04420v1",
      "published_date": "2024-02-06 21:39:13 UTC",
      "updated_date": "2024-02-06 21:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:41:07.781830"
    },
    {
      "arxiv_id": "2402.06666v1",
      "title": "Weather Prediction with Diffusion Guided by Realistic Forecast Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanxiang Hua",
        "Yutong He",
        "Chengqian Ma",
        "Alexandra Anderson-Frey"
      ],
      "abstract": "Weather forecasting remains a crucial yet challenging domain, where recently\ndeveloped models based on deep learning (DL) have approached the performance of\ntraditional numerical weather prediction (NWP) models. However, these DL\nmodels, often complex and resource-intensive, face limitations in flexibility\npost-training and in incorporating NWP predictions, leading to reliability\nconcerns due to potential unphysical predictions. In response, we introduce a\nnovel method that applies diffusion models (DM) for weather forecasting. In\nparticular, our method can achieve both direct and iterative forecasting with\nthe same modeling framework. Our model is not only capable of generating\nforecasts independently but also uniquely allows for the integration of NWP\npredictions, even with varying lead times, during its sampling process. The\nflexibility and controllability of our model empowers a more trustworthy DL\nsystem for the general weather community. Additionally, incorporating\npersistence and climatology data further enhances our model's long-term\nforecasting stability. Our empirical findings demonstrate the feasibility and\ngeneralizability of this approach, suggesting a promising direction for future,\nmore sophisticated diffusion models without the need for retraining.",
      "tldr_zh": "该研究针对深度学习（DL）模型在天气预报中的灵活性和可靠性问题，提出了一种基于扩散模型（DM）的创新方法，该方法受现实预报过程指导，能同时实现直接和迭代预报。模型不仅能独立生成预报，还允许整合不同提前时间的数值天气预报（NWP）预测，从而提升预报的可控性和可信度。通过加入持久性和气候数据，该框架进一步提高了长期预报的稳定性。实验结果证明了这一方法的实用性和通用性，为未来更先进的扩散模型提供了无需重新训练的方向。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06666v1",
      "published_date": "2024-02-06 21:28:42 UTC",
      "updated_date": "2024-02-06 21:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:41:18.386541"
    },
    {
      "arxiv_id": "2402.04412v3",
      "title": "The VampPrior Mixture Model",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew A. Stirn",
        "David A. Knowles"
      ],
      "abstract": "Widely used deep latent variable models (DLVMs), in particular Variational\nAutoencoders (VAEs), employ overly simplistic priors on the latent space. To\nachieve strong clustering performance, existing methods that replace the\nstandard normal prior with a Gaussian mixture model (GMM) require defining the\nnumber of clusters to be close to the number of expected ground truth classes\na-priori and are susceptible to poor initializations. We leverage VampPrior\nconcepts (Tomczak and Welling, 2018) to fit a Bayesian GMM prior, resulting in\nthe VampPrior Mixture Model (VMM), a novel prior for DLVMs. In a VAE, the VMM\nattains highly competitive clustering performance on benchmark datasets.\nIntegrating the VMM into scVI (Lopez et al., 2018), a popular scRNA-seq\nintegration method, significantly improves its performance and automatically\narranges cells into clusters with similar biological characteristics.",
      "tldr_zh": "现有深度潜在变量模型（DLVMs），如变分自编码器（VAEs），通常采用过于简单的先验分布，导致聚类性能不足。论文提出VampPrior Mixture Model (VMM)，通过利用VampPrior概念拟合一个贝叶斯高斯混合模型（GMM）先验，解决了现有GMM方法对簇数预定义和初始化敏感的问题。在VAEs中，VMM在基准数据集上实现了高度竞争的聚类性能；此外，将VMM整合到scVI（一个流式细胞测序整合方法）中，显著提升了其性能，并自动将细胞聚类成具有类似生物学特征的群组。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04412v3",
      "published_date": "2024-02-06 21:18:34 UTC",
      "updated_date": "2025-03-11 03:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:41:31.146671"
    },
    {
      "arxiv_id": "2402.04409v1",
      "title": "Towards Fair, Robust and Efficient Client Contribution Evaluation in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Meiying Zhang",
        "Huan Zhao",
        "Sheldon Ebron",
        "Kan Yang"
      ],
      "abstract": "The performance of clients in Federated Learning (FL) can vary due to various\nreasons. Assessing the contributions of each client is crucial for client\nselection and compensation. It is challenging because clients often have\nnon-independent and identically distributed (non-iid) data, leading to\npotentially noisy or divergent updates. The risk of malicious clients amplifies\nthe challenge especially when there's no access to clients' local data or a\nbenchmark root dataset. In this paper, we introduce a novel method called Fair,\nRobust, and Efficient Client Assessment (FRECA) for quantifying client\ncontributions in FL. FRECA employs a framework called FedTruth to estimate the\nglobal model's ground truth update, balancing contributions from all clients\nwhile filtering out impacts from malicious ones. This approach is robust\nagainst Byzantine attacks and incorporates a Byzantine-resilient aggregation\nalgorithm. FRECA is also efficient, as it operates solely on local model\nupdates and requires no validation operations or datasets. Our experimental\nresults show that FRECA can accurately and efficiently quantify client\ncontributions in a robust manner.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning, FL）中客户端贡献评估的挑战，提出了一种公平、鲁棒且高效的方法 FRECA（Fair, Robust, and Efficient Client Assessment）。FRECA 利用 FedTruth 框架来估计全局模型的真实更新，通过平衡客户端贡献并过滤恶意影响（如 Byzantine 攻击），同时采用 Byzantine-resilient 聚合算法，确保评估过程的准确性。该方法仅依赖本地模型更新，无需验证数据集或访问客户端数据，显著提高了效率。实验结果表明，FRECA 能够在 non-iid 数据环境下准确量化客户端贡献，并提升了系统的整体鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04409v1",
      "published_date": "2024-02-06 21:07:12 UTC",
      "updated_date": "2024-02-06 21:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:41:42.365347"
    },
    {
      "arxiv_id": "2402.04400v2",
      "title": "CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Pang",
        "Xinzhuo Jiang",
        "Nishanth Parameshwar Pavinkurve",
        "Krishna S. Kalluri",
        "Elise L. Minto",
        "Jason Patterson",
        "Linying Zhang",
        "George Hripcsak",
        "Gamze Gürsoy",
        "Noémie Elhadad",
        "Karthik Natarajan"
      ],
      "abstract": "Synthetic Electronic Health Records (EHR) have emerged as a pivotal tool in\nadvancing healthcare applications and machine learning models, particularly for\nresearchers without direct access to healthcare data. Although existing\nmethods, like rule-based approaches and generative adversarial networks (GANs),\ngenerate synthetic data that resembles real-world EHR data, these methods often\nuse a tabular format, disregarding temporal dependencies in patient histories\nand limiting data replication. Recently, there has been a growing interest in\nleveraging Generative Pre-trained Transformers (GPT) for EHR data. This enables\napplications like disease progression analysis, population estimation,\ncounterfactual reasoning, and synthetic data generation. In this work, we focus\non synthetic data generation and demonstrate the capability of training a GPT\nmodel using a particular patient representation derived from CEHR-BERT,\nenabling us to generate patient sequences that can be seamlessly converted to\nthe Observational Medical Outcomes Partnership (OMOP) data format.",
      "tldr_zh": "该研究提出CEHR-GPT，一种利用Generative Pre-trained Transformers (GPT)生成合成Electronic Health Records (EHR)的方法，特别关注患者时间线的 chronological 特性，以解决现有方法如基于规则的系统和GANs在忽略时间依赖性和数据复制方面的局限性。通过从CEHR-BERT派生的患者表示训练GPT模型，该框架能够生成可无缝转换为Observational Medical Outcomes Partnership (OMOP)数据格式的患者序列。实验结果表明，这种方法支持疾病进展分析、人口估计和反事实推理等应用，提升了合成EHR的实用性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04400v2",
      "published_date": "2024-02-06 20:58:36 UTC",
      "updated_date": "2024-05-06 01:10:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:41:55.683234"
    },
    {
      "arxiv_id": "2402.04398v2",
      "title": "Learning under Temporal Label Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Sujay Nagaraj",
        "Walter Gerych",
        "Sana Tonekaboni",
        "Anna Goldenberg",
        "Berk Ustun",
        "Thomas Hartvigsen"
      ],
      "abstract": "Many time series classification tasks, where labels vary over time, are\naffected by label noise that also varies over time. Such noise can cause label\nquality to improve, worsen, or periodically change over time. We first propose\nand formalize temporal label noise, an unstudied problem for sequential\nclassification of time series. In this setting, multiple labels are recorded\nover time while being corrupted by a time-dependent noise function. We first\ndemonstrate the importance of modeling the temporal nature of the label noise\nfunction and how existing methods will consistently underperform. We then\npropose methods to train noise-tolerant classifiers by estimating the temporal\nlabel noise function directly from data. We show that our methods lead to\nstate-of-the-art performance under diverse types of temporal label noise on\nreal-world datasets",
      "tldr_zh": "该论文提出了“temporal label noise”这一新问题，即时间序列分类任务中标签噪声随时间变化，可能导致标签质量改善、恶化或周期性波动。研究者证明了现有方法忽略噪声的时序特性会导致性能下降，并提出新方法，通过直接从数据中估计时间相关的标签噪声函数来训练噪声耐受分类器。这种方法在多种temporal label noise类型下，在真实数据集上实现了最先进的分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2402.04398v2",
      "published_date": "2024-02-06 20:56:31 UTC",
      "updated_date": "2025-03-16 09:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:42:06.002814"
    },
    {
      "arxiv_id": "2402.04396v2",
      "title": "QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Tseng",
        "Jerry Chee",
        "Qingyao Sun",
        "Volodymyr Kuleshov",
        "Christopher De Sa"
      ],
      "abstract": "Post-training quantization (PTQ) reduces the memory footprint of LLMs by\nquantizing their weights to low-precision. In this work, we introduce QuIP#, a\nweight-only PTQ method that achieves state-of-the-art results in extreme\ncompression regimes ($\\le$ 4 bits per weight) using three novel techniques.\nFirst, QuIP# improves QuIP's (Chee et al., 2023) incoherence processing by\nusing the randomized Hadamard transform, which is faster and has better\ntheoretical properties. Second, QuIP# uses vector quantization to take\nadvantage of the ball-shaped sub-Gaussian distribution that incoherent weights\npossess: specifically, we introduce a set of hardware-efficient codebooks based\non the highly symmetric $E_8$ lattice, which achieves the optimal 8-dimension\nunit ball packing. Third, QuIP# uses fine-tuning to improve fidelity to the\noriginal model. Our experiments show that QuIP# outperforms existing PTQ\nmethods, enables new behaviors in PTQ scaling, and supports fast inference. Our\ncode can be found at https://github.com/Cornell-RelaxML/quip-sharp.",
      "tldr_zh": "本研究提出 QuIP#，一种先进的 weight-only post-training quantization (PTQ) 方法，用于将大型语言模型 (LLMs) 的权重量化到低精度（≤ 4 bits per weight），以显著减少内存占用。QuIP# 引入三个创新技巧：使用随机 Hadamard transform 改进不相关处理以提升速度和理论性能；基于 E8 lattice 的硬件高效代码本进行向量量化，针对不相关权重的子高斯分布实现最优8维单位球填充；以及 fine-tuning 以提高对原模型的保真度。实验结果显示，QuIP# 优于现有 PTQ 方法，支持新的 PTQ 缩放行为和快速推理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04396v2",
      "published_date": "2024-02-06 20:52:12 UTC",
      "updated_date": "2024-06-04 04:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:42:21.302831"
    },
    {
      "arxiv_id": "2402.04390v3",
      "title": "Densely Multiplied Physics Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Feilong Jiang",
        "Xiaonan Hou",
        "Min Xia"
      ],
      "abstract": "Although physics-informed neural networks (PINNs) have shown great potential\nin dealing with nonlinear partial differential equations (PDEs), it is common\nthat PINNs will suffer from the problem of insufficient precision or obtaining\nincorrect outcomes. Unlike most of the existing solutions trying to enhance the\nability of PINN by optimizing the training process, this paper improved the\nneural network architecture to improve the performance of PINN. We propose a\ndensely multiply PINN (DM-PINN) architecture, which multiplies the output of a\nhidden layer with the outputs of all the behind hidden layers. Without\nintroducing more trainable parameters, this effective mechanism can\nsignificantly improve the accuracy of PINNs. The proposed architecture is\nevaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation,\nBurgers equation and 1D convection equation). Comparisons between the proposed\narchitecture and different PINN structures demonstrate the superior performance\nof the DM-PINN in both accuracy and efficiency.",
      "tldr_zh": "本文提出了一种改进物理信息神经网络（PINNs）的架构，名为密集乘法 PINN（DM-PINN），旨在解决 PINNs 在处理非线性偏微分方程（PDEs）时可能出现的精度不足或错误结果问题。该架构通过将一个隐藏层的输出与所有后续隐藏层的输出相乘来增强模型性能，而不引入额外可训练参数，从而显著提高了准确性。在四个基准示例（Allan-Cahn equation、Helmholtz equation、Burgers equation 和 1D convection equation）上进行的实验表明，DM-PINN 在准确性和效率方面均优于其他 PINN 结构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.04390v3",
      "published_date": "2024-02-06 20:45:31 UTC",
      "updated_date": "2024-10-04 13:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:42:31.221667"
    },
    {
      "arxiv_id": "2402.04382v1",
      "title": "Counterfactual Generation with Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Sopam Dasgupta",
        "Farhad Shakerin",
        "Joaquín Arias",
        "Elmer Salazar",
        "Gopal Gupta"
      ],
      "abstract": "Machine learning models that automate decision-making are increasingly being\nused in consequential areas such as loan approvals, pretrial bail approval,\nhiring, and many more. Unfortunately, most of these models are black-boxes,\ni.e., they are unable to reveal how they reach these prediction decisions. A\nneed for transparency demands justification for such predictions. An affected\nindividual might also desire explanations to understand why a decision was\nmade. Ethical and legal considerations may further require informing the\nindividual of changes in the input attribute that could be made to produce a\ndesirable outcome. This paper focuses on the latter problem of automatically\ngenerating counterfactual explanations. We propose a framework Counterfactual\nGeneration with s(CASP) (CFGS) that utilizes answer set programming (ASP) and\nthe s(CASP) goal-directed ASP system to automatically generate counterfactual\nexplanations from rules generated by rule-based machine learning (RBML)\nalgorithms. In our framework, we show how counterfactual explanations are\ncomputed and justified by imagining worlds where some or all factual\nassumptions are altered/changed. More importantly, we show how we can navigate\nbetween these worlds, namely, go from our original world/scenario where we\nobtain an undesired outcome to the imagined world/scenario where we obtain a\ndesired/favourable outcome.",
      "tldr_zh": "这篇论文针对机器学习模型在决策领域的黑箱问题（如贷款审批和招聘），提出了一种框架 Counterfactual Generation with s(CASP) (CFGS)，利用 Answer Set Programming (ASP) 和 s(CASP) 系统，从基于规则的机器学习 (RBML) 算法生成的规则中自动生成反事实解释。框架通过想象改变事实假设的“世界”来计算和证明这些解释，从而帮助用户理解决策原因。更为重要的是，CFGS 允许在不同假设世界之间导航，从不良结果场景转向期望的良好结果，提供更透明和可解释的决策支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 Pages",
      "pdf_url": "http://arxiv.org/pdf/2402.04382v1",
      "published_date": "2024-02-06 20:39:49 UTC",
      "updated_date": "2024-02-06 20:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:42:44.014859"
    },
    {
      "arxiv_id": "2403.05548v1",
      "title": "Monitoring the evolution of antisemitic discourse on extremist social media using BERT",
      "title_zh": "使用 BERT 监控极端主义社交媒体上反犹太主义言论的演变",
      "authors": [
        "Raza Ul Mustafa",
        "Nathalie Japkowicz"
      ],
      "abstract": "Racism and intolerance on social media contribute to a toxic online\nenvironment which may spill offline to foster hatred, and eventually lead to\nphysical violence. That is the case with online antisemitism, the specific\ncategory of hatred considered in this study. Tracking antisemitic themes and\ntheir associated terminology over time in online discussions could help monitor\nthe sentiments of their participants and their evolution, and possibly offer\navenues for intervention that may prevent the escalation of hatred. Due to the\nlarge volume and constant evolution of online traffic, monitoring conversations\nmanually is impractical. Instead, we propose an automated method that extracts\nantisemitic themes and terminology from extremist social media over time and\ncaptures their evolution. Since supervised learning would be too limited for\nsuch a task, we created an unsupervised online machine learning approach that\nuses large language models to assess the contextual similarity of posts. The\nmethod clusters similar posts together, dividing, and creating additional\nclusters over time when sub-themes emerge from existing ones or new themes\nappear. The antisemitic terminology used within each theme is extracted from\nthe posts in each cluster. Our experiments show that our methodology\noutperforms existing baselines and demonstrates the kind of themes and\nsub-themes it discovers within antisemitic discourse along with their\nassociated terminology. We believe that our approach will be useful for\nmonitoring the evolution of all kinds of hatred beyond antisemitism on social\nplatforms.",
      "tldr_zh": "这篇论文使用BERT监控极端社交媒体上反犹太主义（antisemitic）话语的演变，旨在追踪主题及其术语随时间的变化，以评估参与者情绪并预防仇恨升级。研究提出了一种无监督在线机器学习方法，利用大型语言模型（large language models）评估帖子的上下文相似性，通过动态聚类来识别主题和子主题（sub-themes），并从中提取相关术语。实验结果表明，该方法优于现有基线，并在实际应用中展示了发现的主题及其演变模式，具有潜力扩展到其他仇恨监控领域。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages; 4 figures; 4 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.05548v1",
      "published_date": "2024-02-06 20:34:49 UTC",
      "updated_date": "2024-02-06 20:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:42:55.562990"
    },
    {
      "arxiv_id": "2402.04376v3",
      "title": "Scaling laws for learning with real and surrogate data",
      "title_zh": "使用真实数据和代理数据的学习规模定律",
      "authors": [
        "Ayush Jain",
        "Andrea Montanari",
        "Eren Sasoglu"
      ],
      "abstract": "Collecting large quantities of high-quality data can be prohibitively\nexpensive or impractical, and a bottleneck in machine learning. One may instead\naugment a small set of $n$ data points from the target distribution with data\nfrom more accessible sources, e.g. data collected under different circumstances\nor synthesized by generative models. We refer to such data as `surrogate data'.\nWe study a weighted empirical risk minimization (ERM) approach for integrating\nsurrogate data into training. We analyze mathematically this method under\nseveral classical statistical models, and validate our findings empirically on\ndatasets from different domains. Our main findings are: $(i)$ Integrating\nsurrogate data can significantly reduce the test error on the original\ndistribution. Surprisingly, this can happen even when the surrogate data is\nunrelated to the original ones. We trace back this behavior to the classical\nStein's paradox. $(ii)$ In order to reap the benefit of surrogate data, it is\ncrucial to use optimally weighted ERM. $(iii)$ The test error of models trained\non mixtures of real and surrogate data is approximately described by a scaling\nlaw. This scaling law can be used to predict the optimal weighting scheme, and\nto choose the amount of surrogate data to add.",
      "tldr_zh": "这篇论文探讨了在机器学习中，如何通过代理数据(surrogate data)补充稀缺目标数据来降低测试错误。研究采用加权经验风险最小化(weighted empirical risk minimization, ERM)方法进行分析，发现即使surrogate data与目标数据无关，也能显著改善性能，这归因于Stein's paradox；然而，使用最优加权方案至关重要。论文进一步提出，混合真实和代理数据的测试错误遵循一个scaling law，可用于预测最优权重和代理数据量，从而指导实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Added new experiment and minor changes",
      "pdf_url": "http://arxiv.org/pdf/2402.04376v3",
      "published_date": "2024-02-06 20:30:19 UTC",
      "updated_date": "2024-12-03 23:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:43:07.230671"
    },
    {
      "arxiv_id": "2402.04370v1",
      "title": "Pedestrian crossing decisions can be explained by bounded optimal decision-making under noisy visual perception",
      "title_zh": "翻译失败",
      "authors": [
        "Yueyang Wang",
        "Aravinda Ramakrishnan Srinivasan",
        "Jussi P. P. Jokinen",
        "Antti Oulasvirta",
        "Gustav Markkula"
      ],
      "abstract": "This paper presents a model of pedestrian crossing decisions, based on the\ntheory of computational rationality. It is assumed that crossing decisions are\nboundedly optimal, with bounds on optimality arising from human cognitive\nlimitations. While previous models of pedestrian behaviour have been either\n'black-box' machine learning models or mechanistic models with explicit\nassumptions about cognitive factors, we combine both approaches. Specifically,\nwe model mechanistically noisy human visual perception and assumed rewards in\ncrossing, but we use reinforcement learning to learn bounded optimal behaviour\npolicy. The model reproduces a larger number of known empirical phenomena than\nprevious models, in particular: (1) the effect of the time to arrival of an\napproaching vehicle on whether the pedestrian accepts the gap, the effect of\nthe vehicle's speed on both (2) gap acceptance and (3) pedestrian timing of\ncrossing in front of yielding vehicles, and (4) the effect on this crossing\ntiming of the stopping distance of the yielding vehicle. Notably, our findings\nsuggest that behaviours previously framed as 'biases' in decision-making, such\nas speed-dependent gap acceptance, might instead be a product of rational\nadaptation to the constraints of visual perception. Our approach also permits\nfitting the parameters of cognitive constraints and rewards per individual, to\nbetter account for individual differences. To conclude, by leveraging both RL\nand mechanistic modelling, our model offers novel insights about pedestrian\nbehaviour, and may provide a useful foundation for more accurate and scalable\npedestrian models.",
      "tldr_zh": "本文提出一个基于计算理性理论的行人过马路决策模型，假设决策是bounded optimal decision-making，受人类认知限制影响。模型结合机制建模的嘈杂视觉感知和奖励，使用reinforcement learning (RL)来学习行为策略，从而重现多种经验现象，如车辆到达时间对间隙接受的影响、车辆速度对间隙接受和过马路时机的效果，以及停车距离的作用。研究发现，这些行为可能并非决策偏差，而是对视觉感知约束的理性适应；此外，模型允许针对个体调整认知约束和奖励参数，以更好地解释个体差异。该方法为构建更准确、可扩展的行人行为模型提供了新基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04370v1",
      "published_date": "2024-02-06 20:13:34 UTC",
      "updated_date": "2024-02-06 20:13:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:43:20.194946"
    },
    {
      "arxiv_id": "2402.05140v3",
      "title": "Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Junhong Shen",
        "Neil Tenenholtz",
        "James Brian Hall",
        "David Alvarez-Melis",
        "Nicolo Fusi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\nunderstanding and generating natural language. However, their capabilities wane\nin highly specialized domains underrepresented in the pretraining corpus, such\nas physical and biomedical sciences. This work explores how to repurpose\ngeneral LLMs into effective task solvers for specialized domains. We introduce\na novel, model-agnostic framework for learning custom input tags, which are\nparameterized as continuous vectors appended to the LLM's embedding layer, to\ncondition the LLM. We design two types of input tags: domain tags are used to\ndelimit specialized representations (e.g., chemical formulas) and provide\ndomain-relevant context; function tags are used to represent specific functions\n(e.g., predicting molecular properties) and compress function-solving\ninstructions. We develop a three-stage protocol to learn these tags using\nauxiliary data and domain knowledge. By explicitly disentangling task domains\nfrom task functions, our method enables zero-shot generalization to unseen\nproblems through diverse combinations of the input tags. It also boosts LLM's\nperformance in various specialized domains, such as predicting protein or\nchemical properties and modeling drug-target interactions, outperforming expert\nmodels tailored to these tasks.",
      "tldr_zh": "该研究探讨了如何将通用大语言模型（LLMs）适配到专业领域（如物理和生物医学科学），以解决其在这些领域表现不足的问题。作者提出一个模型无关的框架，使用自定义输入标签（包括domain tags和function tags）作为连续向量附加到LLMs的嵌入层，分别用于提供领域相关上下文和表示特定功能（如预测分子属性）。通过一个三阶段协议，利用辅助数据和领域知识学习这些标签，该方法实现了任务领域的显式分离，从而支持zero-shot generalization，并通过标签组合处理未见问题。实验结果显示，该框架显著提升了LLMs在专业任务（如预测蛋白质或化学属性，以及建模药物-靶点交互）的性能，优于专门设计的专家模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.05140v3",
      "published_date": "2024-02-06 20:11:54 UTC",
      "updated_date": "2024-07-26 01:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:43:31.312882"
    },
    {
      "arxiv_id": "2402.04355v2",
      "title": "PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Lemos",
        "Sammy Sharief",
        "Nikolay Malkin",
        "Salma Salhi",
        "Connor Stone",
        "Laurence Perreault-Levasseur",
        "Yashar Hezaveh"
      ],
      "abstract": "We propose a likelihood-free method for comparing two distributions given\nsamples from each, with the goal of assessing the quality of generative models.\nThe proposed approach, PQMass, provides a statistically rigorous method for\nassessing the performance of a single generative model or the comparison of\nmultiple competing models. PQMass divides the sample space into non-overlapping\nregions and applies chi-squared tests to the number of data samples that fall\nwithin each region, giving a p-value that measures the probability that the bin\ncounts derived from two sets of samples are drawn from the same multinomial\ndistribution. PQMass does not depend on assumptions regarding the density of\nthe true distribution, nor does it rely on training or fitting any auxiliary\nmodels. We evaluate PQMass on data of various modalities and dimensions,\ndemonstrating its effectiveness in assessing the quality, novelty, and\ndiversity of generated samples. We further show that PQMass scales well to\nmoderately high-dimensional data and thus obviates the need for feature\nextraction in practical applications.",
      "tldr_zh": "本研究提出PQMass，一种无假设似然的概率质量估计方法，用于比较两个分布的样本，从而评估生成模型（generative models）的质量。该方法通过将样本空间划分为非重叠区域，并应用chi-squared tests对每个区域的样本数量进行统计测试，生成p-value以判断两个样本集是否来自相同的多项分布（multinomial distribution），而无需依赖真实分布的密度假设或辅助模型的训练。在各种模态和维度的数据上实验表明，PQMass在评估生成样本的质量、新颖性和多样性方面表现出色，并适用于中等高维数据，无需特征提取（feature extraction）。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2402.04355v2",
      "published_date": "2024-02-06 19:39:26 UTC",
      "updated_date": "2025-03-06 05:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:43:42.448897"
    },
    {
      "arxiv_id": "2402.04338v2",
      "title": "Logical recognition method for solving the problem of identification in the Internet of Things",
      "title_zh": "用于解决物联网中识别问题的逻辑识别方法",
      "authors": [
        "Islambek Saymanov"
      ],
      "abstract": "A new area of application of methods of algebra of logic and to valued logic,\nwhich has emerged recently, is the problem of recognizing a variety of objects\nand phenomena, medical or technical diagnostics, constructing modern machines,\nchecking test problems, etc., which can be reduced to constructing an optimal\nextension of the logical function to the entire feature space. For example, in\nlogical recognition systems, logical methods based on discrete analysis and\npropositional calculus based on it are used to build their own recognition\nalgorithms. In the general case, the use of a logical recognition method\nprovides for the presence of logical connections expressed by the optimal\ncontinuation of a k-valued function over the entire feature space, in which the\nvariables are the logical features of the objects or phenomena being\nrecognized. The goal of this work is to develop a logical method for object\nrecognition consisting of a reference table with logical features and classes\nof non-intersecting objects, which are specified as vectors from a given\nfeature space. The method consists of considering the reference table as a\nlogical function that is not defined everywhere and constructing an optimal\ncontinuation of the logical function to the entire feature space, which\ndetermines the extension of classes to the entire space.",
      "tldr_zh": "这篇论文提出了一种基于逻辑代数的识别方法，用于解决物联网中物体识别的问题，特别是通过构建逻辑函数的最优扩展来处理对象和现象的分类。方法将参考表视为部分定义的逻辑函数，并利用 algebra of logic 和 valued logic 来扩展该函数至整个 feature space，从而定义类别的扩展。该方法可应用于医疗诊断、技术诊断等领域，提高识别算法的准确性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "I will rework and improve it and post it again",
      "pdf_url": "http://arxiv.org/pdf/2402.04338v2",
      "published_date": "2024-02-06 19:20:58 UTC",
      "updated_date": "2024-02-13 16:05:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:43:54.441275"
    },
    {
      "arxiv_id": "2402.04335v1",
      "title": "LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text",
      "title_zh": "翻译失败",
      "authors": [
        "Dor Bernsohn",
        "Gil Semo",
        "Yaron Vazana",
        "Gila Hayat",
        "Ben Hagag",
        "Joel Niklaus",
        "Rohit Saha",
        "Kyryl Truskovskyi"
      ],
      "abstract": "In this study, we focus on two main tasks, the first for detecting legal\nviolations within unstructured textual data, and the second for associating\nthese violations with potentially affected individuals. We constructed two\ndatasets using Large Language Models (LLMs) which were subsequently validated\nby domain expert annotators. Both tasks were designed specifically for the\ncontext of class-action cases. The experimental design incorporated fine-tuning\nmodels from the BERT family and open-source LLMs, and conducting few-shot\nexperiments using closed-source LLMs. Our results, with an F1-score of 62.69\\%\n(violation identification) and 81.02\\% (associating victims), show that our\ndatasets and setups can be used for both tasks. Finally, we publicly release\nthe datasets and the code used for the experiments in order to advance further\nresearch in the area of legal natural language processing (NLP).",
      "tldr_zh": "本研究开发了 LegalLens 框架，利用 Large Language Models (LLMs) 来识别非结构化文本中的法律违规，并将这些违规与可能受影响的个体关联，针对集体诉讼案例构建并由领域专家验证的两个数据集。方法包括微调 BERT 家族模型和开源 LLMs，以及进行少样本实验。结果显示，违规识别任务的 F1-score 为 62.69%，关联受害者任务的 F1-score 为 81.02%，证明了框架的有效性。最后，研究公开了数据集和实验代码，以推动法律 Natural Language Processing (NLP) 领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04335v1",
      "published_date": "2024-02-06 19:18:56 UTC",
      "updated_date": "2024-02-06 19:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:44:08.529557"
    },
    {
      "arxiv_id": "2402.04333v3",
      "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Mengzhou Xia",
        "Sadhika Malladi",
        "Suchin Gururangan",
        "Sanjeev Arora",
        "Danqi Chen"
      ],
      "abstract": "Instruction tuning has unlocked powerful capabilities in large language\nmodels (LLMs), effectively using combined datasets to develop generalpurpose\nchatbots. However, real-world applications often require a specialized suite of\nskills (e.g., reasoning). The challenge lies in identifying the most relevant\ndata from these extensive datasets to effectively develop specific\ncapabilities, a setting we frame as targeted instruction tuning. We propose\nLESS, an optimizer-aware and practically efficient algorithm to effectively\nestimate data influences and perform Low-rank gradiEnt Similarity Search for\ninstruction data selection. Crucially, LESS adapts existing influence\nformulations to work with the Adam optimizer and variable-length instruction\ndata. LESS first constructs a highly reusable and transferable gradient\ndatastore with low-dimensional gradient features and then selects examples\nbased on their similarity to few-shot examples embodying a specific capability.\nExperiments show that training on a LESS-selected 5% of the data can often\noutperform training on the full dataset across diverse downstream tasks.\nFurthermore, the selected data is highly transferable: smaller models can be\nleveraged to select useful data for larger models and models from different\nfamilies. Our qualitative analysis shows that our method goes beyond surface\nform cues to identify data that exemplifies the necessary reasoning skills for\nthe intended downstream application.",
      "tldr_zh": "该论文提出 LESS 算法，用于从指令数据集选择最具影响力的数据，以实现针对性指令微调（instruction tuning），从而提升大型语言模型（LLMs）在特定技能（如推理）上的表现。LESS 基于优化器感知的低秩梯度相似性搜索（Low-rank gradiEnt Similarity Search），通过构建可重用梯度数据存储并与少数样本比较，适应 Adam 优化器和变长指令数据。实验结果显示，使用 LESS 选择的 5% 数据训练，往往在多种下游任务上优于使用全数据集，且该数据选择具有高转移性，可应用于不同模型家族。定性分析进一步证明，该方法能识别真正体现必要推理技能的数据，而非仅依赖表面特征。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024; Code and data are available at\n  https://github.com/princeton-nlp/LESS",
      "pdf_url": "http://arxiv.org/pdf/2402.04333v3",
      "published_date": "2024-02-06 19:18:04 UTC",
      "updated_date": "2024-06-13 03:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:44:20.524147"
    },
    {
      "arxiv_id": "2402.05138v1",
      "title": "SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark",
      "title_zh": "SceMQA：科学大学入学水平多模",
      "authors": [
        "Zhenwen Liang",
        "Kehan Guo",
        "Gang Liu",
        "Taicheng Guo",
        "Yujun Zhou",
        "Tianyu Yang",
        "Jiajun Jiao",
        "Renjie Pi",
        "Jipeng Zhang",
        "Xiangliang Zhang"
      ],
      "abstract": "The paper introduces SceMQA, a novel benchmark for scientific multimodal\nquestion answering at the college entrance level. It addresses a critical\neducational phase often overlooked in existing benchmarks, spanning high school\nto pre-college levels. SceMQA focuses on core science subjects including\nMathematics, Physics, Chemistry, and Biology. It features a blend of\nmultiple-choice and free-response formats, ensuring a comprehensive evaluation\nof AI models' abilities. Additionally, our benchmark provides specific\nknowledge points for each problem and detailed explanations for each answer.\nSceMQA also uniquely presents problems with identical contexts but varied\nquestions to facilitate a more thorough and accurate assessment of reasoning\ncapabilities. In the experiment, we evaluate both open-source and close-source\nstate-of-the-art Multimodal Large Language Models (MLLMs), across various\nexperimental settings. The results show that further research and development\nare needed in developing more capable MLLM, as highlighted by only 50% to 60%\naccuracy achieved by the strongest models. Our benchmark and analysis will be\navailable at https://scemqa.github.io/",
      "tldr_zh": "该论文引入了SceMQA，一个针对大学入学水平的科学多模态问答基准测试，以填补现有基准忽略的高中到大学入学阶段的空白。SceMQA涵盖数学、物理、化学和生物等核心科目，采用多项选择和自由回答格式，并为每个问题提供特定知识点、详细解释以及相同上下文下的不同问题设计，以全面评估AI模型的推理能力。在实验中，评估了开源和闭源的先进Multimodal Large Language Models (MLLMs)，结果显示最强模型的准确率仅为50%到60%，突显了进一步提升MLLMs能力的必要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2402.05138v1",
      "published_date": "2024-02-06 19:16:55 UTC",
      "updated_date": "2024-02-06 19:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:44:32.176814"
    },
    {
      "arxiv_id": "2402.04325v1",
      "title": "Enhance DNN Adversarial Robustness and Efficiency via Injecting Noise to Non-Essential Neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Liu",
        "Garrett Gagnon",
        "Swagath Venkataramani",
        "Liu Liu"
      ],
      "abstract": "Deep Neural Networks (DNNs) have revolutionized a wide range of industries,\nfrom healthcare and finance to automotive, by offering unparalleled\ncapabilities in data analysis and decision-making. Despite their transforming\nimpact, DNNs face two critical challenges: the vulnerability to adversarial\nattacks and the increasing computational costs associated with more complex and\nlarger models. In this paper, we introduce an effective method designed to\nsimultaneously enhance adversarial robustness and execution efficiency. Unlike\nprior studies that enhance robustness via uniformly injecting noise, we\nintroduce a non-uniform noise injection algorithm, strategically applied at\neach DNN layer to disrupt adversarial perturbations introduced in attacks. By\nemploying approximation techniques, our approach identifies and protects\nessential neurons while strategically introducing noise into non-essential\nneurons. Our experimental results demonstrate that our method successfully\nenhances both robustness and efficiency across several attack scenarios, model\narchitectures, and datasets.",
      "tldr_zh": "本研究针对深度神经网络(DNNs)易受对抗攻击和计算成本高的挑战，提出了一种非均匀噪声注入算法，以同时提升DNN的对抗鲁棒性和执行效率。该方法通过近似技术识别并保护必要神经元，同时向非必要神经元注入噪声，从而在每个DNN层有效地破坏对抗扰动。实验结果显示，该方法在多种攻击场景、模型架构和数据集上成功提升了鲁棒性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04325v1",
      "published_date": "2024-02-06 19:09:32 UTC",
      "updated_date": "2024-02-06 19:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:44:41.585820"
    },
    {
      "arxiv_id": "2402.04249v2",
      "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
      "title_zh": "翻译失败",
      "authors": [
        "Mantas Mazeika",
        "Long Phan",
        "Xuwang Yin",
        "Andy Zou",
        "Zifan Wang",
        "Norman Mu",
        "Elham Sakhaee",
        "Nathaniel Li",
        "Steven Basart",
        "Bo Li",
        "David Forsyth",
        "Dan Hendrycks"
      ],
      "abstract": "Automated red teaming holds substantial promise for uncovering and mitigating\nthe risks associated with the malicious use of large language models (LLMs),\nyet the field lacks a standardized evaluation framework to rigorously assess\nnew methods. To address this issue, we introduce HarmBench, a standardized\nevaluation framework for automated red teaming. We identify several desirable\nproperties previously unaccounted for in red teaming evaluations and\nsystematically design HarmBench to meet these criteria. Using HarmBench, we\nconduct a large-scale comparison of 18 red teaming methods and 33 target LLMs\nand defenses, yielding novel insights. We also introduce a highly efficient\nadversarial training method that greatly enhances LLM robustness across a wide\nrange of attacks, demonstrating how HarmBench enables codevelopment of attacks\nand defenses. We open source HarmBench at\nhttps://github.com/centerforaisafety/HarmBench.",
      "tldr_zh": "该研究引入了 HarmBench，这是一个标准化的评估框架，用于评估 Automated Red Teaming 方法，以发现并缓解大型语言模型（LLMs）的恶意使用风险。HarmBench 考虑了之前未涵盖的属性，如全面性和系统性，通过比较 18 种红队方法和 33 种目标 LLMs 及防御，提供了新的见解，并证明了其在代码开发中的实用性。研究还提出了一种高效的 Adversarial Training 方法，大大提升了 LLMs 的鲁棒性，并开源了 HarmBench（https://github.com/centerforaisafety/HarmBench）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Website: https://www.harmbench.org",
      "pdf_url": "http://arxiv.org/pdf/2402.04249v2",
      "published_date": "2024-02-06 18:59:08 UTC",
      "updated_date": "2024-02-27 04:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:44:55.370857"
    },
    {
      "arxiv_id": "2402.04247v4",
      "title": "Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangru Tang",
        "Qiao Jin",
        "Kunlun Zhu",
        "Tongxin Yuan",
        "Yichi Zhang",
        "Wangchunshu Zhou",
        "Meng Qu",
        "Yilun Zhao",
        "Jian Tang",
        "Zhuosheng Zhang",
        "Arman Cohan",
        "Zhiyong Lu",
        "Mark Gerstein"
      ],
      "abstract": "Intelligent agents powered by large language models (LLMs) have demonstrated\nsubstantial promise in autonomously conducting experiments and facilitating\nscientific discoveries across various disciplines. While their capabilities are\npromising, these agents, called scientific LLM agents, also introduce novel\nvulnerabilities that demand careful consideration for safety. However, there\nexists a notable gap in the literature, as there has been no comprehensive\nexploration of these vulnerabilities. This perspective paper fills this gap by\nconducting a thorough examination of vulnerabilities in LLM-based agents within\nscientific domains, shedding light on potential risks associated with their\nmisuse and emphasizing the need for safety measures. We begin by providing a\ncomprehensive overview of the potential risks inherent to scientific LLM\nagents, taking into account user intent, the specific scientific domain, and\ntheir potential impact on the external environment. Then, we delve into the\norigins of these vulnerabilities and provide a scoping review of the limited\nexisting works. Based on our analysis, we propose a triadic framework involving\nhuman regulation, agent alignment, and an understanding of environmental\nfeedback (agent regulation) to mitigate these identified risks. Furthermore, we\nhighlight the limitations and challenges associated with safeguarding\nscientific agents and advocate for the development of improved models, robust\nbenchmarks, and comprehensive regulations to address these issues effectively.",
      "tldr_zh": "这篇论文强调了基于大型语言模型 (LLMs) 的智能代理在科学领域的潜在风险，优先考虑安全而非自治，填补了现有文献中对这些漏洞的全面探讨缺口。作者通过系统审查代理的漏洞来源，分析了用户意图、科学领域和外部环境的影响，并总结了有限的现有研究。论文提出一个三元框架，包括人类监管、代理对齐和环境反馈 (agent regulation)，以缓解这些风险。最后，他们指出保护科学代理的挑战，并呼吁开发更先进的模型、稳健基准和全面法规来提升安全性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04247v4",
      "published_date": "2024-02-06 18:54:07 UTC",
      "updated_date": "2024-06-05 06:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:45:07.043680"
    },
    {
      "arxiv_id": "2402.04232v2",
      "title": "Can Generative Agents Predict Emotion?",
      "title_zh": "生成式代理能预测情绪吗？",
      "authors": [
        "Ciaran Regan",
        "Nanami Iwahashi",
        "Shogo Tanaka",
        "Mizuki Oka"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated a number of human-like\nabilities, however the empathic understanding and emotional state of LLMs is\nyet to be aligned to that of humans. In this work, we investigate how the\nemotional state of generative LLM agents evolves as they perceive new events,\nintroducing a novel architecture in which new experiences are compared to past\nmemories. Through this comparison, the agent gains the ability to understand\nnew experiences in context, which according to the appraisal theory of emotion\nis vital in emotion creation. First, the agent perceives new experiences as\ntime series text data. After perceiving each new input, the agent generates a\nsummary of past relevant memories, referred to as the norm, and compares the\nnew experience to this norm. Through this comparison we can analyse how the\nagent reacts to the new experience in context. The PANAS, a test of affect, is\nadministered to the agent, capturing the emotional state of the agent after the\nperception of the new event. Finally, the new experience is then added to the\nagents memory to be used in the creation of future norms. By creating multiple\nexperiences in natural language from emotionally charged situations, we test\nthe proposed architecture on a wide range of scenarios. The mixed results\nsuggests that introducing context can occasionally improve the emotional\nalignment of the agent, but further study and comparison with human evaluators\nis necessary. We hope that this paper is another step towards the alignment of\ngenerative agents.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能预测情感，特别关注代理的情感状态演化。研究提出一个新架构，让代理通过比较新事件与过去记忆的总结（norm）来理解上下文，从而根据评价理论 (appraisal theory of emotion) 生成情感响应。代理将新体验视为时间序列文本数据，使用 PANAS 测试评估情感状态，并将新事件添加到记忆库中以影响未来决策。在多种情感情境测试中，结果显示引入上下文偶尔能改善代理的情感对齐，但整体效果混合，需要进一步与人类评估者比较。研究旨在推动生成代理的情感对齐。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.04232v2",
      "published_date": "2024-02-06 18:39:43 UTC",
      "updated_date": "2024-02-07 17:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:45:18.178649"
    },
    {
      "arxiv_id": "2402.04228v1",
      "title": "Intelligent Collective Escape of Swarm Robots Based on a Novel Fish-inspired Self-adaptive Approach with Neurodynamic Models",
      "title_zh": "基于新型鱼类启发自适应方法和神经动力学模型的群机器人智能集体逃逸",
      "authors": [
        "Junfei Li",
        "Simon X. Yang"
      ],
      "abstract": "Fish schools present high-efficiency group behaviors through simple\nindividual interactions to collective migration and dynamic escape from the\npredator. The school behavior of fish is usually a good inspiration to design\ncontrol architecture for swarm robots. In this paper, a novel fish-inspired\nself-adaptive approach is proposed for collective escape for the swarm robots.\nIn addition, a bio-inspired neural network (BINN) is introduced to generate\ncollision-free escape robot trajectories through the combination of attractive\nand repulsive forces. Furthermore, to cope with dynamic environments, a\nneurodynamics-based self-adaptive mechanism is proposed to improve the\nself-adaptive performance of the swarm robots in the changing environment.\nSimilar to fish escape maneuvers, simulation and experimental results show that\nthe swarm robots are capable of collectively leaving away from the threats.\nSeveral comparison studies demonstrated that the proposed approach can\nsignificantly improve the effectiveness and efficiency of system performance,\nand the flexibility and robustness in complex environments.",
      "tldr_zh": "本论文提出了一种新型鱼启发自适应方法（fish-inspired self-adaptive approach），结合神经动力学模型（neurodynamic models），用于实现群机器人的智能集体逃逸。该方法引入生物启发神经网络（BINN）来生成无碰撞逃逸轨迹，通过吸引力和排斥力相结合，帮助机器人应对动态环境。实验和模拟结果表明，该方法显著提高了系统的有效性、效率、灵活性和鲁棒性，使群机器人能够像鱼群一样高效逃离威胁。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This article is accepted for publication in a future issue of IEEE\n  Transactions on Industrial Electronics",
      "pdf_url": "http://arxiv.org/pdf/2402.04228v1",
      "published_date": "2024-02-06 18:36:44 UTC",
      "updated_date": "2024-02-06 18:36:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:45:31.354963"
    },
    {
      "arxiv_id": "2402.04210v2",
      "title": "Task Success is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Guan",
        "Yifan Zhou",
        "Denis Liu",
        "Yantian Zha",
        "Heni Ben Amor",
        "Subbarao Kambhampati"
      ],
      "abstract": "Large-scale generative models are shown to be useful for sampling meaningful\ncandidate solutions, yet they often overlook task constraints and user\npreferences. Their full power is better harnessed when the models are coupled\nwith external verifiers and the final solutions are derived iteratively or\nprogressively according to the verification feedback. In the context of\nembodied AI, verification often solely involves assessing whether goal\nconditions specified in the instructions have been met. Nonetheless, for these\nagents to be seamlessly integrated into daily life, it is crucial to account\nfor a broader range of constraints and preferences beyond bare task success\n(e.g., a robot should grasp bread with care to avoid significant deformations).\nHowever, given the unbounded scope of robot tasks, it is infeasible to\nconstruct scripted verifiers akin to those used for explicit-knowledge tasks\nlike the game of Go and theorem proving. This begs the question: when no sound\nverifier is available, can we use large vision and language models (VLMs),\nwhich are approximately omniscient, as scalable Behavior Critics to catch\nundesirable robot behaviors in videos? To answer this, we first construct a\nbenchmark that contains diverse cases of goal-reaching yet undesirable robot\npolicies. Then, we comprehensively evaluate VLM critics to gain a deeper\nunderstanding of their strengths and failure modes. Based on the evaluation, we\nprovide guidelines on how to effectively utilize VLM critiques and showcase a\npractical way to integrate the feedback into an iterative process of policy\nrefinement. The dataset and codebase are released at:\nhttps://guansuns.github.io/pages/vlm-critic.",
      "tldr_zh": "这项研究探讨了机器人代理在完成任务后可能出现不良行为的问题，强调仅靠任务成功（如目标达成）不足以满足实际需求（如避免物体变形）。作者构建了一个包含多样化目标达成却行为不当的机器人策略的基准数据集，并评估了Video-Language Models (VLMs)作为Behavior Critics的效果，以检测视频中的 undesirable behaviors。结果显示，VLMs在捕捉这些问题方面表现出优势，但也存在失败模式；基于此，他们提供了有效利用VLMs批评的指南，并展示了将其反馈整合到策略迭代改进过程中的实用方法。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04210v2",
      "published_date": "2024-02-06 18:07:43 UTC",
      "updated_date": "2024-08-11 07:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:45:43.914906"
    },
    {
      "arxiv_id": "2402.04209v1",
      "title": "Acute kidney injury prediction for non-critical care patients: a retrospective external and internal validation study",
      "title_zh": "翻译失败",
      "authors": [
        "Esra Adiyeke",
        "Yuanfang Ren",
        "Benjamin Shickel",
        "Matthew M. Ruppert",
        "Ziyuan Guan",
        "Sandra L. Kane-Gill",
        "Raghavan Murugan",
        "Nabihah Amatullah",
        "Britney A. Stottlemyer",
        "Tiffany L. Tran",
        "Dan Ricketts",
        "Christopher M Horvat",
        "Parisa Rashidi",
        "Azra Bihorac",
        "Tezcan Ozrazgat-Baslanti"
      ],
      "abstract": "Background: Acute kidney injury (AKI), the decline of kidney excretory\nfunction, occurs in up to 18% of hospitalized admissions. Progression of AKI\nmay lead to irreversible kidney damage. Methods: This retrospective cohort\nstudy includes adult patients admitted to a non-intensive care unit at the\nUniversity of Pittsburgh Medical Center (UPMC) (n = 46,815) and University of\nFlorida Health (UFH) (n = 127,202). We developed and compared deep learning and\nconventional machine learning models to predict progression to Stage 2 or\nhigher AKI within the next 48 hours. We trained local models for each site (UFH\nModel trained on UFH, UPMC Model trained on UPMC) and a separate model with a\ndevelopment cohort of patients from both sites (UFH-UPMC Model). We internally\nand externally validated the models on each site and performed subgroup\nanalyses across sex and race. Results: Stage 2 or higher AKI occurred in 3%\n(n=3,257) and 8% (n=2,296) of UFH and UPMC patients, respectively. Area under\nthe receiver operating curve values (AUROC) for the UFH test cohort ranged\nbetween 0.77 (UPMC Model) and 0.81 (UFH Model), while AUROC values ranged\nbetween 0.79 (UFH Model) and 0.83 (UPMC Model) for the UPMC test cohort.\nUFH-UPMC Model achieved an AUROC of 0.81 (95% confidence interval [CI] [0.80,\n0.83]) for UFH and 0.82 (95% CI [0.81,0.84]) for UPMC test cohorts; an area\nunder the precision recall curve values (AUPRC) of 0.6 (95% CI, [0.05, 0.06])\nfor UFH and 0.13 (95% CI, [0.11,0.15]) for UPMC test cohorts. Kinetic estimated\nglomerular filtration rate, nephrotoxic drug burden and blood urea nitrogen\nremained the top three features with the highest influence across the models\nand health centers. Conclusion: Locally developed models displayed marginally\nreduced discrimination when tested on another institution, while the top set of\ninfluencing features remained the same across the models and sites.",
      "tldr_zh": "这篇论文针对非重症监护患者的急性肾损伤 (AKI) 预测，进行了一项回顾性队列研究，涉及匹兹堡大学医疗中心 (UPMC) 和佛罗里达大学健康 (UFH) 的46,815和127,202名患者，开发并比较了深度学习和传统机器学习模型，以预测未来48小时内进展到AKI 2级或更高的风险。模型包括本地训练模型（UFH模型和UPMC模型）和联合模型（UFH-UPMC模型），并进行了内部、外部验证以及按性别和种族的亚组分析，结果显示模型的AUROC值在0.77至0.83之间。研究发现，kinetic estimated glomerular filtration rate、nephrotoxic drug burden和blood urea nitrogen是关键影响特征，本地模型在外部测试时区分能力略有降低，但整体特征影响在不同站点保持一致，为AKI预测提供了可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04209v1",
      "published_date": "2024-02-06 18:05:30 UTC",
      "updated_date": "2024-02-06 18:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:45:59.370263"
    },
    {
      "arxiv_id": "2402.04203v1",
      "title": "Human-Like Geometric Abstraction in Large Pre-trained Neural Networks",
      "title_zh": "大型预训练神经网络中的人类般的几何抽象",
      "authors": [
        "Declan Campbell",
        "Sreejan Kumar",
        "Tyler Giallanza",
        "Thomas L. Griffiths",
        "Jonathan D. Cohen"
      ],
      "abstract": "Humans possess a remarkable capacity to recognize and manipulate abstract\nstructure, which is especially apparent in the domain of geometry. Recent\nresearch in cognitive science suggests neural networks do not share this\ncapacity, concluding that human geometric abilities come from discrete symbolic\nstructure in human mental representations. However, progress in artificial\nintelligence (AI) suggests that neural networks begin to demonstrate more\nhuman-like reasoning after scaling up standard architectures in both model size\nand amount of training data. In this study, we revisit empirical results in\ncognitive science on geometric visual processing and identify three key biases\nin geometric visual processing: a sensitivity towards complexity, regularity,\nand the perception of parts and relations. We test tasks from the literature\nthat probe these biases in humans and find that large pre-trained neural\nnetwork models used in AI demonstrate more human-like abstract geometric\nprocessing.",
      "tldr_zh": "这项研究探讨了大型预训练神经网络是否具备人类般的几何抽象能力，挑战了认知科学中认为神经网络缺乏离散符号结构的观点。研究者识别了人类几何视觉处理中的三个关键偏差：对复杂性(sensitivity towards complexity)、规律性(regularity)和部分与关系(perception of parts and relations)的敏感性，并通过测试相关任务来评估这些偏差。结果表明，随着模型规模和训练数据的增加，神经网络在抽象几何处理上显示出更接近人类的行为，为AI在认知领域的进展提供了新见解。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04203v1",
      "published_date": "2024-02-06 17:59:46 UTC",
      "updated_date": "2024-02-06 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:46:09.696865"
    },
    {
      "arxiv_id": "2402.04173v1",
      "title": "COPS: A Compact On-device Pipeline for real-time Smishing detection",
      "title_zh": "翻译失败",
      "authors": [
        "Harichandana B S S",
        "Sumit Kumar",
        "Manjunath Bhimappa Ujjinakoppa",
        "Barath Raj Kandur Raja"
      ],
      "abstract": "Smartphones have become indispensable in our daily lives and can do almost\neverything, from communication to online shopping. However, with the increased\nusage, cybercrime aimed at mobile devices is rocketing. Smishing attacks, in\nparticular, have observed a significant upsurge in recent years. This problem\nis further exacerbated by the perpetrator creating new deceptive websites\ndaily, with an average life cycle of under 15 hours. This renders the standard\npractice of keeping a database of malicious URLs ineffective. To this end, we\npropose a novel on-device pipeline: COPS that intelligently identifies features\nof fraudulent messages and URLs to alert the user in real-time. COPS is a\nlightweight pipeline with a detection module based on the Disentangled\nVariational Autoencoder of size 3.46MB for smishing and URL phishing detection,\nand we benchmark it on open datasets. We achieve an accuracy of 98.15% and\n99.5%, respectively, for both tasks, with a false negative and false positive\nrate of a mere 0.037 and 0.015, outperforming previous works with the added\nadvantage of ensuring real-time alerts on resource-constrained devices.",
      "tldr_zh": "本论文提出COPS，一种紧凑的设备端管道，用于实时检测Smishing（短信钓鱼）攻击，以应对智能手机网络犯罪的激增问题。COPS通过智能识别欺诈消息和URL特征，采用基于Disentangled Variational Autoencoder的检测模块（大小仅3.46MB），确保在资源受限设备上实现高效实时警报。该方法在公开数据集上实现了Smishing检测准确率98.15%和URL钓鱼检测准确率99.5%，假阴性和假阳性率分别仅为0.037和0.015，优于现有工作，并解决了传统恶意URL数据库的无效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Published at IEEE Consumer Communications & Networking Conference\n  (CCNC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04173v1",
      "published_date": "2024-02-06 17:27:12 UTC",
      "updated_date": "2024-02-06 17:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:46:20.253063"
    },
    {
      "arxiv_id": "2403.05547v1",
      "title": "AI for non-programmers: Applied AI in the lectures for students without programming skills",
      "title_zh": "翻译失败",
      "authors": [
        "Julius Schöning",
        "Tim Wawer",
        "Kai-Michael Griese"
      ],
      "abstract": "Applications such as ChatGPT and WOMBO Dream make it easy to inspire students\nwithout programming knowledge to use artificial intelligence (AI). Therefore,\ngiven the increasing importance of AI in all disciplines, innovative strategies\nare needed to educate students in AI without programming knowledge so that AI\ncan be integrated into their study modules as a future skill. This work\npresents a didactic planning script for applied AI. The didactic planning\nscript is based on the AI application pipeline and links AI concepts with\nstudy-relevant topics. These linkages open up a new solution space and promote\nstudents' interest in and understanding of the potentials and risks of AI. An\nexample lecture series for master students in energy management shows how AI\ncan be seamlessly integrated into discipline-specific lectures. To this end,\nthe planning script for applied AI is adapted to fit the study programs' topic.\nThis specific teaching scenario enables students to solve a discipline-specific\ntask step by step using the AI application pipeline. Thus, the application of\nthe didactic planning script for applied AI shows the practical implementation\nof the theoretical concepts of AI. In addition, a checklist is presented that\ncan be used to assess whether AI can be used in the discipline-specific\nlecture. AI as a future skill must be learned by students based on use cases\nthat are relevant to the course of studies. For this reason, AI education\nshould fit seamlessly into various curricula, even if the students do not have\na programming background due to their field of study.",
      "tldr_zh": "这篇论文针对没有编程技能的学生，探讨了如何将AI融入教学中，以培养AI作为未来技能。论文提出一个基于AI application pipeline的教学脚本（didactic planning script），将AI概念与学科相关主题（如能源管理）相结合，激发学生对AI潜力和风险的兴趣和理解。通过一个能源管理硕士课程的示例，该脚本指导学生逐步使用AI工具（如ChatGPT）解决专业任务，实现理论与实践的整合。此外，论文提供了一个检查列表，帮助评估AI在特定学科讲课中的适用性，从而使AI教育无缝融入各种课程。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "K.3.2; I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 6 figures, Translated from the German of \"KI f\\\"ur\n  Nicht-Programmierer*innen: Angewandte KI im H\\\"orsaal f\\\"ur Studierende ohne\n  Programmierkenntnisse\". Translated from the German of\n  https://nbn-resolving.org/urn:nbn:de:bsz:959-opus-52866",
      "pdf_url": "http://arxiv.org/pdf/2403.05547v1",
      "published_date": "2024-02-06 17:26:24 UTC",
      "updated_date": "2024-02-06 17:26:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:46:32.355814"
    },
    {
      "arxiv_id": "2402.06665v2",
      "title": "The Essential Role of Causality in Foundation World Models for Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Tarun Gupta",
        "Wenbo Gong",
        "Chao Ma",
        "Nick Pawlowski",
        "Agrin Hilmkil",
        "Meyer Scetbon",
        "Marc Rigter",
        "Ade Famoti",
        "Ashley Juan Llorens",
        "Jianfeng Gao",
        "Stefan Bauer",
        "Danica Kragic",
        "Bernhard Schölkopf",
        "Cheng Zhang"
      ],
      "abstract": "Recent advances in foundation models, especially in large multi-modal models\nand conversational agents, have ignited interest in the potential of generally\ncapable embodied agents. Such agents will require the ability to perform new\ntasks in many different real-world environments. However, current foundation\nmodels fail to accurately model physical interactions and are therefore\ninsufficient for Embodied AI. The study of causality lends itself to the\nconstruction of veridical world models, which are crucial for accurately\npredicting the outcomes of possible interactions. This paper focuses on the\nprospects of building foundation world models for the upcoming generation of\nembodied agents and presents a novel viewpoint on the significance of causality\nwithin these. We posit that integrating causal considerations is vital to\nfacilitating meaningful physical interactions with the world. Finally, we\ndemystify misconceptions about causality in this context and present our\noutlook for future research.",
      "tldr_zh": "该论文强调了因果性（causality）在构建 foundation world models 用于 Embodied AI 中的核心作用，因为当前 foundation models 无法准确建模物理互动，从而限制了代理在真实环境中的任务执行。作者提出一个新视角，认为整合因果考虑是实现有意义物理互动的关键，从而帮助创建 veridical world models。论文还澄清了关于因果性的常见误解，并展望了未来研究方向，以推动更可靠的 Embodied AI 代理发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06665v2",
      "published_date": "2024-02-06 17:15:33 UTC",
      "updated_date": "2024-04-29 23:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:46:45.913021"
    },
    {
      "arxiv_id": "2402.04154v7",
      "title": "Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction",
      "title_zh": "翻译失败",
      "authors": [
        "Yonggang Jin",
        "Ge Zhang",
        "Hao Zhao",
        "Tianyu Zheng",
        "Jarvi Guo",
        "Liuyu Xiang",
        "Shawn Yue",
        "Stephen W. Huang",
        "Zhaofeng He",
        "Jie Fu"
      ],
      "abstract": "Developing a generalist agent is a longstanding objective in artificial\nintelligence. Previous efforts utilizing extensive offline datasets from\nvarious tasks demonstrate remarkable performance in multitasking scenarios\nwithin Reinforcement Learning. However, these works encounter challenges in\nextending their capabilities to new tasks. Recent approaches integrate textual\nguidance or visual trajectory into decision networks to provide task-specific\ncontextual cues, representing a promising direction. However, it is observed\nthat relying solely on textual guidance or visual trajectory is insufficient\nfor accurately conveying the contextual information of tasks. This paper\nexplores enhanced forms of task guidance for agents, enabling them to\ncomprehend gameplay instructions, thereby facilitating a \"read-to-play\"\ncapability. Drawing inspiration from the success of multimodal instruction\ntuning in visual tasks, we treat the visual-based RL task as a long-horizon\nvision task and construct a set of multimodal game instructions to incorporate\ninstruction tuning into a decision transformer. Experimental results\ndemonstrate that incorporating multimodal game instructions significantly\nenhances the decision transformer's multitasking and generalization\ncapabilities.",
      "tldr_zh": "本研究旨在开发通用智能体（generalist agent），解决现有强化学习（Reinforcement Learning）方法在多任务场景中难以扩展到新任务的挑战。作者提出 R2-Play 框架，将多模态游戏指令（Multimodal Game Instruction）整合到 Decision Transformer 中，将视觉-based RL 任务视为长 horizons 视觉任务，并通过指令微调增强代理对游戏指令的理解。实验结果表明，这种方法显著提高了 Decision Transformer 的多任务和泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04154v7",
      "published_date": "2024-02-06 17:09:25 UTC",
      "updated_date": "2024-11-18 15:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:46:56.349656"
    },
    {
      "arxiv_id": "2402.04141v1",
      "title": "Multi-line AI-assisted Code Authoring",
      "title_zh": "翻译失败",
      "authors": [
        "Omer Dunay",
        "Daniel Cheng",
        "Adam Tait",
        "Parth Thakkar",
        "Peter C Rigby",
        "Andy Chiu",
        "Imad Ahmad",
        "Arun Ganesan",
        "Chandra Maddila",
        "Vijayaraghavan Murali",
        "Ali Tayyebi",
        "Nachiappan Nagappan"
      ],
      "abstract": "CodeCompose is an AI-assisted code authoring tool powered by large language\nmodels (LLMs) that provides inline suggestions to 10's of thousands of\ndevelopers at Meta. In this paper, we present how we scaled the product from\ndisplaying single-line suggestions to multi-line suggestions. This evolution\nrequired us to overcome several unique challenges in improving the usability of\nthese suggestions for developers.\n  First, we discuss how multi-line suggestions can have a 'jarring' effect, as\nthe LLM's suggestions constantly move around the developer's existing code,\nwhich would otherwise result in decreased productivity and satisfaction.\n  Second, multi-line suggestions take significantly longer to generate; hence\nwe present several innovative investments we made to reduce the perceived\nlatency for users. These model-hosting optimizations sped up multi-line\nsuggestion latency by 2.5x.\n  Finally, we conduct experiments on 10's of thousands of engineers to\nunderstand how multi-line suggestions impact the user experience and contrast\nthis with single-line suggestions. Our experiments reveal that (i) multi-line\nsuggestions account for 42% of total characters accepted (despite only\naccounting for 16% for displayed suggestions) (ii) multi-line suggestions\nalmost doubled the percentage of keystrokes saved for users from 9% to 17%.\nMulti-line CodeCompose has been rolled out to all engineers at Meta, and less\nthan 1% of engineers have opted out of multi-line suggestions.",
      "tldr_zh": "本论文介绍了 CodeCompose，一款基于 LLMs 的代码辅助工具，已扩展到为 Meta 的数万开发者提供多行内联建议，以提升代码编写效率。研究团队克服了多行建议带来的“jarring”效果（代码移动导致的干扰）和生成延迟问题，通过模型托管优化将延迟减少 2.5 倍。实验结果显示，多行建议占接受字符的 42%，并将用户节省击键百分比从 9% 提高到 17%；最终，该功能已在 Meta 全员推广，只有不到 1% 工程师选择退出。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04141v1",
      "published_date": "2024-02-06 16:48:50 UTC",
      "updated_date": "2024-02-06 16:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:47:08.596992"
    },
    {
      "arxiv_id": "2402.04140v3",
      "title": "Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)",
      "title_zh": "翻译失败",
      "authors": [
        "Michael De'Shazer"
      ],
      "abstract": "This study consists of a novel approach toward the analysis of court\njudgments spanning five countries, including the United States, the United\nKingdom, Rwanda, Sweden and Hong Kong. This study also explores the\nintersection of the latest advancements in artificial intelligence (AI) and\nlegal analysis, emphasizing the role of AI (specifically generative AI) in\nidentifying human biases and facilitating automated, valid, and coherent\nmultisided argumentation of court judgments with the goal of ensuring\nconsistent application of laws in and across various jurisdictions. By\nincorporating Advanced Language Models (ALMs) and a newly introduced human-AI\ncollaborative framework, this paper seeks to analyze Grounded Theory-based\nresearch design with Advanced Language Models (ALMs) in the practice of law.\nSHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT\ntechnology), focusing on detecting logical inconsistencies and biases across\nvarious legal decisions. SHIRLEY analysis is aggregated and is accompanied by a\ncomparison-oriented AI-based application called SAM (also an ALM) to identify\nrelative deviations in SHIRLEY bias detections. Further, a CRITIC is generated\nwithin semi-autonomous arbitration process via the ALM, SARA. A novel approach\nis introduced in the utilization of an AI arbitrator to critically evaluate\nbiases and qualitative-in-nature nuances identified by the aforementioned AI\napplications (SAM in concert with SHIRLEY), based on the Hague Rules on\nBusiness and Human Rights Arbitration. This Semi-Automated Arbitration Process\n(SAAP) aims to uphold the integrity and fairness of legal judgments by ensuring\na nuanced debate-resultant \"understanding\" through a hybrid system of AI and\nhuman-based collaborative analysis.",
      "tldr_zh": "本研究提出了一种创新方法，整合人工智能（AI）来分析五个国家（包括美国、英国、卢旺达、瑞典和香港）的法院判决，旨在识别人类偏差并促进多方论证，以确保全球法律的一致应用。论文引入了Advanced Language Models (ALMs) 和一个新型的人-AI 协作框架，其中SHIRLEY（基于 OpenAI 的 GPT）用于检测逻辑不一致性和偏差，SAM 则进行比较分析，而SARA 生成CRITIC 来评估这些偏差。最终，通过Semi-Automated Arbitration Process (SAAPs)，该框架基于Grounded Theory 和Hague Rules，实现对法律判断的公正性和公平性的提升，为AI 在法律实践中的应用提供了可靠基础。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04140v3",
      "published_date": "2024-02-06 16:47:34 UTC",
      "updated_date": "2024-02-29 17:23:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:47:21.772001"
    },
    {
      "arxiv_id": "2402.04108v1",
      "title": "Hierarchical Delay Attribution Classification using Unstructured Text in Train Management Systems",
      "title_zh": "在列车管理系统中使用",
      "authors": [
        "Anton Borg",
        "Per Lingvall",
        "Martin Svensson"
      ],
      "abstract": "EU directives stipulate a systematic follow-up of train delays. In Sweden,\nthe Swedish Transport Administration registers and assigns an appropriate delay\nattribution code. However, this delay attribution code is assigned manually,\nwhich is a complex task. In this paper, a machine learning-based decision\nsupport for assigning delay attribution codes based on event descriptions is\ninvestigated. The text is transformed using TF-IDF, and two models, Random\nForest and Support Vector Machine, are evaluated against a random uniform\nclassifier and the classification performance of the Swedish Transport\nAdministration. Further, the problem is modeled as both a hierarchical and flat\napproach. The results indicate that a hierarchical approach performs better\nthan a flat approach. Both approaches perform better than the random uniform\nclassifier but perform worse than the manual classification.",
      "tldr_zh": "这篇论文探讨了使用机器学习对火车管理系统的非结构化文本（如事件描述）进行延误归因分类，以辅助 Swedish Transport Administration 手动分配延误代码的问题。方法包括采用 TF-IDF 转换文本，并评估 Random Forest 和 Support Vector Machine 在分层（hierarchical）方法和扁平（flat）方法中的性能。结果表明，分层方法优于扁平方法，且机器学习模型的表现超过了随机均匀分类器，但仍不如手动分类。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.04108v1",
      "published_date": "2024-02-06 16:02:17 UTC",
      "updated_date": "2024-02-06 16:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:47:32.243724"
    },
    {
      "arxiv_id": "2402.07933v2",
      "title": "Human-Centered AI Product Prototyping with No-Code AutoML: Conceptual Framework, Potentials and Limitations",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Truss",
        "Marc Schmitt"
      ],
      "abstract": "This paper addresses the complexities inherent in AI product prototyping,\nfocusing on the challenges posed by the probabilistic nature of AI behavior and\nthe limited accessibility of prototyping tools to non-experts. A Design Science\nResearch (DSR) approach is presented which culminates in a conceptual framework\naimed at improving the AI prototyping process. Through a comprehensive\nliterature review, key challenges were identified and no-code AutoML was\nanalyzed as a solution. The framework describes the seamless incorporation of\nnon-expert input and evaluation during prototyping, leveraging the potential of\nno-code AutoML to enhance accessibility and interpretability. A hybrid approach\nof combining naturalistic (case study) and artificial evaluation methods\n(criteria-based analysis) validated the utility of our approach, highlighting\nits efficacy in supporting AI non-experts and streamlining decision-making and\nits limitations. Implications for academia and industry, emphasizing the\nstrategic integration of no-code AutoML to enhance AI product development\nprocesses, mitigate risks, and foster innovation, are discussed.",
      "tldr_zh": "这篇论文探讨了AI产品原型设计的复杂性，特别是AI行为的概率性和工具对非专家的低可访问性问题，并提出一个概念框架来改善原型过程。框架通过Design Science Research (DSR)方法和文献综述，整合no-code AutoML技术，以增强非专家的输入、评估和可解释性，同时采用案例研究与标准分析的混合方法进行验证。结果显示，该框架能有效支持AI非专家的决策和创新，但也存在局限性，为学术和行业提供了战略性指导，以减少风险并优化AI产品开发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.SE",
        "I.2.0; H.5.0; D.2.2; H.1.2; I.2.5; K.6.1"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07933v2",
      "published_date": "2024-02-06 16:00:32 UTC",
      "updated_date": "2024-06-07 11:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:47:44.326293"
    },
    {
      "arxiv_id": "2402.04103v1",
      "title": "An Exploration of Clustering Algorithms for Customer Segmentation in the UK Retail Market",
      "title_zh": "聚类算法在英国零售市场的客户细分探索",
      "authors": [
        "Jeen Mary John",
        "Olamilekan Shobayo",
        "Bayode Ogunleye"
      ],
      "abstract": "Recently, peoples awareness of online purchases has significantly risen. This\nhas given rise to online retail platforms and the need for a better\nunderstanding of customer purchasing behaviour. Retail companies are pressed\nwith the need to deal with a high volume of customer purchases, which requires\nsophisticated approaches to perform more accurate and efficient customer\nsegmentation. Customer segmentation is a marketing analytical tool that aids\ncustomer-centric service and thus enhances profitability. In this paper, we aim\nto develop a customer segmentation model to improve decision-making processes\nin the retail market industry. To achieve this, we employed a UK-based online\nretail dataset obtained from the UCI machine learning repository. The retail\ndataset consists of 541,909 customer records and eight features. Our study\nadopted the RFM (recency, frequency, and monetary) framework to quantify\ncustomer values. Thereafter, we compared several state-of-the-art (SOTA)\nclustering algorithms, namely, K-means clustering, the Gaussian mixture model\n(GMM), density-based spatial clustering of applications with noise (DBSCAN),\nagglomerative clustering, and balanced iterative reducing and clustering using\nhierarchies (BIRCH). The results showed the GMM outperformed other approaches,\nwith a Silhouette Score of 0.80.",
      "tldr_zh": "本研究探讨了聚类算法在英国零售市场的客户细分应用，旨在应对在线购物兴起带来的客户行为分析需求，并通过 RFM (recency, frequency, and monetary) 框架量化客户价值。研究使用 UCI 机器学习仓库的英国在线零售数据集（541,909 条记录，8 个特征），比较了 K-means clustering、Gaussian mixture model (GMM)、DBSCAN、agglomerative clustering 和 BIRCH 等算法。结果显示，GMM 以 Silhouette Score 0.80 的表现最佳，为零售行业提升决策过程和盈利能力提供了有效的客户细分模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.CO",
        "H.3.3"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, Journal of Analytics",
      "pdf_url": "http://arxiv.org/pdf/2402.04103v1",
      "published_date": "2024-02-06 15:58:14 UTC",
      "updated_date": "2024-02-06 15:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:47:57.806871"
    },
    {
      "arxiv_id": "2402.04102v1",
      "title": "Use of Multi-CNNs for Section Analysis in Static Malware Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Quertier",
        "Grégoire Barrué"
      ],
      "abstract": "Existing research on malware detection focuses almost exclusively on the\ndetection rate. However, in some cases, it is also important to understand the\nresults of our algorithm, or to obtain more information, such as where to\ninvestigate in the file for an analyst. In this aim, we propose a new model to\nanalyze Portable Executable files. Our method consists in splitting the files\nin different sections, then transform each section into an image, in order to\ntrain convolutional neural networks to treat specifically each identified\nsection. Then we use all these scores returned by CNNs to compute a final\ndetection score, using models that enable us to improve our analysis of the\nimportance of each section in the final score.",
      "tldr_zh": "本论文关注静态恶意软件检测，不仅强调检测率，还旨在提升对算法结果的理解和文件分析。研究提出一种新模型，将 Portable Executable 文件分成不同部分，并将每个部分转换为图像，然后使用 Multi-CNNs 分别训练处理这些特定部分。最终，通过整合 CNNs 返回的分数计算出检测分数，从而改善对每个部分重要性的分析，为分析师提供更精确的调查指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: text overlap with arXiv:2312.12161",
      "pdf_url": "http://arxiv.org/pdf/2402.04102v1",
      "published_date": "2024-02-06 15:57:08 UTC",
      "updated_date": "2024-02-06 15:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:48:09.075260"
    },
    {
      "arxiv_id": "2402.04088v1",
      "title": "The Use of a Large Language Model for Cyberbullying Detection",
      "title_zh": "大语言模型在网络欺凌检测中的应用",
      "authors": [
        "Bayode Ogunleye",
        "Babitha Dharmaraj"
      ],
      "abstract": "The dominance of social media has added to the channels of bullying for\nperpetrators. Unfortunately, cyberbullying (CB) is the most prevalent\nphenomenon in todays cyber world, and is a severe threat to the mental and\nphysical health of citizens. This opens the need to develop a robust system to\nprevent bullying content from online forums, blogs, and social media platforms\nto manage the impact in our society. Several machine learning (ML) algorithms\nhave been proposed for this purpose. However, their performances are not\nconsistent due to high class imbalance and generalisation issues. In recent\nyears, large language models (LLMs) like BERT and RoBERTa have achieved\nstate-of-the-art (SOTA) results in several natural language processing (NLP)\ntasks. Unfortunately, the LLMs have not been applied extensively for CB\ndetection. In our paper, we explored the use of these models for cyberbullying\n(CB) detection. We have prepared a new dataset (D2) from existing studies\n(Formspring and Twitter). Our experimental results for dataset D1 and D2 showed\nthat RoBERTa outperformed other models.",
      "tldr_zh": "本研究探讨了使用大型语言模型（Large Language Models, LLMs）如 BERT 和 RoBERTa 来检测网络霸凌（cyberbullying），以解决传统机器学习（ML）算法在高类别不平衡和泛化问题上的不足。研究者准备了一个新数据集 D2（基于 Formspring 和 Twitter 的现有数据），并在 D1 和 D2 数据集上进行了实验。结果显示，RoBERTa 模型在检测性能上超过了其他模型，为构建更有效的网络霸凌预防系统提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.AP",
        "H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, Journal of Analytics",
      "pdf_url": "http://arxiv.org/pdf/2402.04088v1",
      "published_date": "2024-02-06 15:46:31 UTC",
      "updated_date": "2024-02-06 15:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:48:19.462854"
    },
    {
      "arxiv_id": "2402.04087v1",
      "title": "A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengbo Wang",
        "Jian Liang",
        "Lijun Sheng",
        "Ran He",
        "Zilei Wang",
        "Tieniu Tan"
      ],
      "abstract": "Contrastive Language-Image Pretraining (CLIP) has gained popularity for its\nremarkable zero-shot capacity. Recent research has focused on developing\nefficient fine-tuning methods, such as prompt learning and adapter, to enhance\nCLIP's performance in downstream tasks. However, these methods still require\nadditional training time and computational resources, which is undesirable for\ndevices with limited resources. In this paper, we revisit a classical\nalgorithm, Gaussian Discriminant Analysis (GDA), and apply it to the downstream\nclassification of CLIP. Typically, GDA assumes that features of each class\nfollow Gaussian distributions with identical covariance. By leveraging Bayes'\nformula, the classifier can be expressed in terms of the class means and\ncovariance, which can be estimated from the data without the need for training.\nTo integrate knowledge from both visual and textual modalities, we ensemble it\nwith the original zero-shot classifier within CLIP. Extensive results on 17\ndatasets validate that our method surpasses or achieves comparable results with\nstate-of-the-art methods on few-shot classification, imbalanced learning, and\nout-of-distribution generalization. In addition, we extend our method to\nbase-to-new generalization and unsupervised learning, once again demonstrating\nits superiority over competing approaches. Our code is publicly available at\n\\url{https://github.com/mrflogs/ICLR24}.",
      "tldr_zh": "本文提出了一种无需训练的基线方法，用于提升 CLIP 模型在下游任务中的适应性能，基于 Gaussian Discriminant Analysis (GDA) 算法。该方法假设每个类别的特征服从相同的协方差高斯分布，并通过贝叶斯公式与 CLIP 的零样本分类器集成，实现高效的视觉-文本模态融合。在 17 个数据集上的实验验证，该方法在少样本分类、不平衡学习和分布外泛化方面优于或相当于是最先进方法，并成功扩展到 base-to-new 泛化和无监督学习场景中，展示了其广泛适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04087v1",
      "published_date": "2024-02-06 15:45:27 UTC",
      "updated_date": "2024-02-06 15:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:48:33.093131"
    },
    {
      "arxiv_id": "2402.07932v1",
      "title": "A Human-Machine Collaboration Framework for the Development of Schemas",
      "title_zh": "翻译失败",
      "authors": [
        "Nicos Isaak"
      ],
      "abstract": "The Winograd Schema Challenge (WSC), a seemingly well-thought-out test for\nmachine intelligence, has been proposed to shed light on developing systems\nthat exhibit human behavior. Since its introduction, it aimed to pivot the\nfocus of the AI community from the technology to the science of AI. While\ncommon and trivial for humans, studies show that it is still challenging for\nmachines, especially when they have to deal with novel schemas, that is,\nwell-designed sentences that require the resolving of definite pronouns. As\nresearchers have become increasingly interested in the challenge itself, this\npresumably necessitates the availability of an extensive collection of Winograd\nschemas, which goes beyond what human experts can reasonably develop\nthemselves, especially after proposed ways of utilizing them as novel forms of\nCAPTCHAs.\n  To address this necessity, we propose a novel framework that explicitly\nfocuses on how humans and machines can collaborate as teammates to design novel\nschemas from scratch. This is being accomplished by combining two recent\nstudies from the literature: i) Winventor, a machine-driven approach for the\ndevelopment of large amounts of Winograd schemas, albeit not of high quality,\nand ii) WinoFlexi, an online crowdsourcing system that allows crowd workers to\ndevelop a limited number of schemas often of similar quality to that of\nexperts. Our proposal crafts a new road map toward developing a novel\ncollaborative platform that amplifies human and machine intelligence by\ncombining their complementary strengths.",
      "tldr_zh": "这篇论文针对 Winograd Schema Challenge (WSC)，提出一个人类-机器协作框架，以解决机器在处理新型 schemas 时面临的挑战。框架结合 Winventor 的机器驱动方法（能生成大量 schemas 但质量不高）和 WinoFlexi 的众包系统（允许人类专家开发高质量 schemas），让人类和机器作为团队从零设计新型 schemas。最终，该框架放大双方的互补优势，有望生成更多高质量的 schemas，用于提升 AI 智能测试和 CAPTCHA 应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "I.2.0; I.2.3; I.2.4; I.2.7; I.5.1; I.5.4"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.07932v1",
      "published_date": "2024-02-06 15:41:49 UTC",
      "updated_date": "2024-02-06 15:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:48:44.999224"
    },
    {
      "arxiv_id": "2402.04082v1",
      "title": "An Optimal House Price Prediction Algorithm: XGBoost",
      "title_zh": "最优的房屋价格预测算法：XGBoost",
      "authors": [
        "Hemlata Sharma",
        "Hitesh Harsora",
        "Bayode Ogunleye"
      ],
      "abstract": "An accurate prediction of house prices is a fundamental requirement for\nvarious sectors including real estate and mortgage lending. It is widely\nrecognized that a property value is not solely determined by its physical\nattributes but is significantly influenced by its surrounding neighbourhood.\nMeeting the diverse housing needs of individuals while balancing budget\nconstraints is a primary concern for real estate developers. To this end, we\naddressed the house price prediction problem as a regression task and thus\nemployed various machine learning techniques capable of expressing the\nsignificance of independent variables. We made use of the housing dataset of\nAmes City in Iowa, USA to compare support vector regressor, random forest\nregressor, XGBoost, multilayer perceptron and multiple linear regression\nalgorithms for house price prediction. Afterwards, we identified the key\nfactors that influence housing costs. Our results show that XGBoost is the best\nperforming model for house price prediction.",
      "tldr_zh": "这篇论文探讨了房价预测问题，强调房价不仅受房产物理属性影响，还与周边环境密切相关，并将其视为回归任务。作者使用埃姆斯市（Iowa, USA）住房数据集，比较了多种机器学习模型，包括 support vector regressor、random forest regressor、XGBoost、multilayer perceptron 和 multiple linear regression，以评估其预测性能。结果表明，XGBoost 是最佳模型，并帮助识别了影响房价的关键因素。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME",
        "H.3.3"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, Journal of Analytics",
      "pdf_url": "http://arxiv.org/pdf/2402.04082v1",
      "published_date": "2024-02-06 15:36:06 UTC",
      "updated_date": "2024-02-06 15:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:48:56.345872"
    },
    {
      "arxiv_id": "2402.04081v2",
      "title": "Improved Generalization of Weight Space Networks via Augmentations",
      "title_zh": "翻译失败",
      "authors": [
        "Aviv Shamsian",
        "Aviv Navon",
        "David W. Zhang",
        "Yan Zhang",
        "Ethan Fetaya",
        "Gal Chechik",
        "Haggai Maron"
      ],
      "abstract": "Learning in deep weight spaces (DWS), where neural networks process the\nweights of other neural networks, is an emerging research direction, with\napplications to 2D and 3D neural fields (INRs, NeRFs), as well as making\ninferences about other types of neural networks. Unfortunately, weight space\nmodels tend to suffer from substantial overfitting. We empirically analyze the\nreasons for this overfitting and find that a key reason is the lack of\ndiversity in DWS datasets. While a given object can be represented by many\ndifferent weight configurations, typical INR training sets fail to capture\nvariability across INRs that represent the same object. To address this, we\nexplore strategies for data augmentation in weight spaces and propose a MixUp\nmethod adapted for weight spaces. We demonstrate the effectiveness of these\nmethods in two setups. In classification, they improve performance similarly to\nhaving up to 10 times more data. In self-supervised contrastive learning, they\nyield substantial 5-10% gains in downstream classification.",
      "tldr_zh": "本研究针对深度权重空间 (DWS) 模型的过度拟合问题，分析发现其主要原因在于数据集缺乏多样性，例如同一物体的不同权重配置未被充分捕捉。作者提出了一种适应权重空间的数据增强策略，包括专为 DWS 设计的 MixUp 方法，以增加训练数据的变异性。实验结果显示，这些方法在分类任务中提升了性能，相当于增加了多达 10 倍的数据，并在自监督对比学习中实现了 5-10% 的下游分类准确率改进，从而提高了 DWS 模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2402.04081v2",
      "published_date": "2024-02-06 15:34:44 UTC",
      "updated_date": "2024-11-09 22:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:49:09.310849"
    },
    {
      "arxiv_id": "2402.04064v1",
      "title": "Multi-class Road Defect Detection and Segmentation using Spatial and Channel-wise Attention for Autonomous Road Repairing",
      "title_zh": "多类道路缺陷检测和分割，使用空间和通道级注意机制，用于自动道路修复",
      "authors": [
        "Jongmin Yu",
        "Chen Bene Chi",
        "Sebastiano Fichera",
        "Paolo Paoletti",
        "Devansh Mehta",
        "Shan Luo"
      ],
      "abstract": "Road pavement detection and segmentation are critical for developing\nautonomous road repair systems. However, developing an instance segmentation\nmethod that simultaneously performs multi-class defect detection and\nsegmentation is challenging due to the textural simplicity of road pavement\nimage, the diversity of defect geometries, and the morphological ambiguity\nbetween classes. We propose a novel end-to-end method for multi-class road\ndefect detection and segmentation. The proposed method comprises multiple\nspatial and channel-wise attention blocks available to learn global\nrepresentations across spatial and channel-wise dimensions. Through these\nattention blocks, more globally generalised representations of morphological\ninformation (spatial characteristics) of road defects and colour and depth\ninformation of images can be learned. To demonstrate the effectiveness of our\nframework, we conducted various ablation studies and comparisons with prior\nmethods on a newly collected dataset annotated with nine road defect classes.\nThe experiments show that our proposed method outperforms existing\nstate-of-the-art methods for multi-class road defect detection and segmentation\nmethods.",
      "tldr_zh": "这篇论文针对自主道路修复系统，提出了一种新颖的端到端方法，用于多类道路缺陷检测和分割，以应对道路路面图像纹理简单、缺陷几何多样性和类别形态模糊的挑战。该方法通过集成多个空间和通道注意力块（spatial and channel-wise attention blocks），学习缺陷的形态信息（spatial characteristics）以及图像的颜色和深度全局表示，从而提升检测精度。在一个标注了九个道路缺陷类别的全新数据集上进行的实验表明，该方法优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04064v1",
      "published_date": "2024-02-06 15:09:50 UTC",
      "updated_date": "2024-02-06 15:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:49:21.619306"
    },
    {
      "arxiv_id": "2402.04062v2",
      "title": "Link Prediction with Relational Hypergraphs",
      "title_zh": "关系超图的链接预测",
      "authors": [
        "Xingyue Huang",
        "Miguel Romero Orth",
        "Pablo Barceló",
        "Michael M. Bronstein",
        "İsmail İlkan Ceylan"
      ],
      "abstract": "Link prediction with knowledge graphs has been thoroughly studied in graph\nmachine learning, leading to a rich landscape of graph neural network\narchitectures with successful applications. Nonetheless, it remains challenging\nto transfer the success of these architectures to relational hypergraphs, where\nthe task of link prediction is over $k$-ary relations, which is substantially\nharder than link prediction with knowledge graphs. In this paper, we propose a\nframework for link prediction with relational hypergraphs, unlocking\napplications of graph neural networks to fully relational structures.\nTheoretically, we conduct a thorough analysis of the expressive power of the\nresulting model architectures via corresponding relational Weisfeiler-Leman\nalgorithms and also via logical expressiveness. Empirically, we validate the\npower of the proposed model architectures on various relational hypergraph\nbenchmarks. The resulting model architectures substantially outperform every\nbaseline for inductive link prediction, and lead to state-of-the-art results\nfor transductive link prediction.",
      "tldr_zh": "这篇论文提出一个框架，用于处理关系超图上的链接预测问题，该任务涉及 k-ary 关系，比知识图谱的链接预测更具挑战性。\n框架将图神经网络（graph neural networks）应用于完全关系结构，并通过理论分析其表达能力，包括关系 Weisfeiler-Leman 算法和逻辑表达性。\n实验结果显示，该模型在各种关系超图基准上大幅超过了基线模型，在归纳链接预测（inductive link prediction）中准确率最高，并在半监督链接预测（transductive link prediction）上达到了最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04062v2",
      "published_date": "2024-02-06 15:05:40 UTC",
      "updated_date": "2024-05-23 15:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:49:32.667366"
    },
    {
      "arxiv_id": "2402.04059v2",
      "title": "Deep Learning for Multivariate Time Series Imputation: A Survey",
      "title_zh": "深度学习用于多变量时间序列插值：一项综述",
      "authors": [
        "Jun Wang",
        "Wenjie Du",
        "Yiyuan Yang",
        "Linglong Qian",
        "Wei Cao",
        "Keli Zhang",
        "Wenjia Wang",
        "Yuxuan Liang",
        "Qingsong Wen"
      ],
      "abstract": "Missing values are ubiquitous in multivariate time series (MTS) data, posing\nsignificant challenges for accurate analysis and downstream applications. In\nrecent years, deep learning-based methods have successfully handled missing\ndata by leveraging complex temporal dependencies and learned data\ndistributions. In this survey, we provide a comprehensive summary of deep\nlearning approaches for multivariate time series imputation (MTSI) tasks. We\npropose a novel taxonomy that categorizes existing methods based on two key\nperspectives: imputation uncertainty and neural network architecture.\nFurthermore, we summarize existing MTSI toolkits with a particular emphasis on\nthe PyPOTS Ecosystem, which provides an integrated and standardized foundation\nfor MTSI research. Finally, we discuss key challenges and future research\ndirections, which give insight for further MTSI research. This survey aims to\nserve as a valuable resource for researchers and practitioners in the field of\ntime series analysis and missing data imputation tasks.",
      "tldr_zh": "这篇调查论文总结了深度学习在多变量时间序列插值（MTSI）中的应用，强调这些方法如何通过利用复杂的时间依赖性和数据分布来处理缺失值问题。作者提出一个新颖的分类体系，将现有方法分为基于插值不确定性和神经网络架构两大类别，并重点介绍了PyPOTS Ecosystem等工具包，以提供标准化研究基础。最后，论文讨论了MTSI领域的关键挑战和未来研究方向，为时间序列分析和缺失数据处理的研究者提供宝贵资源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2402.04059v2",
      "published_date": "2024-02-06 15:03:53 UTC",
      "updated_date": "2025-02-12 13:16:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:49:44.287828"
    },
    {
      "arxiv_id": "2402.04050v2",
      "title": "Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengbo Wang",
        "Jian Liang",
        "Ran He",
        "Zilei Wang",
        "Tieniu Tan"
      ],
      "abstract": "With the emergence of pretrained vision-language models (VLMs), considerable\nefforts have been devoted to fine-tuning them for downstream tasks. Despite the\nprogress made in designing efficient fine-tuning methods, such methods require\naccess to the model's parameters, which can be challenging as model owners\noften opt to provide their models as a black box to safeguard model ownership.\nThis paper proposes a \\textbf{C}ollabo\\textbf{ra}tive\n\\textbf{F}ine-\\textbf{T}uning (\\textbf{CraFT}) approach for fine-tuning\nblack-box VLMs to downstream tasks, where one only has access to the input\nprompts and the output predictions of the model. CraFT comprises two modules, a\nprompt generation module for learning text prompts and a prediction refinement\nmodule for enhancing output predictions in residual style. Additionally, we\nintroduce an auxiliary prediction-consistent loss to promote consistent\noptimization across these modules. These modules are optimized by a novel\ncollaborative training algorithm. Extensive experiments on few-shot\nclassification over 15 datasets demonstrate the superiority of CraFT. The\nresults show that CraFT achieves a decent gain of about 12\\% with 16-shot\ndatasets and only 8,000 queries. Moreover, CraFT trains faster and uses only\nabout 1/80 of the memory footprint for deployment, while sacrificing only\n1.62\\% compared to the white-box method. Our code is publicly available at\nhttps://github.com/mrflogs/CraFT .",
      "tldr_zh": "该论文提出了一种协作微调方法CraFT，用于黑盒Vision-Language Models (VLMs)，旨在解决无法访问模型参数的挑战。CraFT包括提示生成模块（用于学习文本提示）和预测精炼模块（以残差风格增强输出预测），并引入辅助预测一致性损失（auxiliary prediction-consistent loss）及新型协作训练算法（collaborative training algorithm）来优化这些模块。在15个数据集上的少样本分类实验中，CraFT在16-shot设置下提升约12%的性能，仅需8,000次查询，且训练更快、内存占用仅为白盒方法的1/80，同时性能损失仅1.62%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04050v2",
      "published_date": "2024-02-06 14:53:19 UTC",
      "updated_date": "2024-06-03 13:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:49:57.631733"
    },
    {
      "arxiv_id": "2402.04049v3",
      "title": "Systematic Biases in LLM Simulations of Debates",
      "title_zh": "LLM 辩论模拟中的系统性偏差",
      "authors": [
        "Amir Taubenfeld",
        "Yaniv Dover",
        "Roi Reichart",
        "Ariel Goldstein"
      ],
      "abstract": "The emergence of Large Language Models (LLMs), has opened exciting\npossibilities for constructing computational simulations designed to replicate\nhuman behavior accurately. Current research suggests that LLM-based agents\nbecome increasingly human-like in their performance, sparking interest in using\nthese AI agents as substitutes for human participants in behavioral studies.\nHowever, LLMs are complex statistical learners without straightforward\ndeductive rules, making them prone to unexpected behaviors. Hence, it is\ncrucial to study and pinpoint the key behavioral distinctions between humans\nand LLM-based agents. In this study, we highlight the limitations of LLMs in\nsimulating human interactions, particularly focusing on LLMs' ability to\nsimulate political debates on topics that are important aspects of people's\nday-to-day lives and decision-making processes. Our findings indicate a\ntendency for LLM agents to conform to the model's inherent social biases\ndespite being directed to debate from certain political perspectives. This\ntendency results in behavioral patterns that seem to deviate from\nwell-established social dynamics among humans. We reinforce these observations\nusing an automatic self-fine-tuning method, which enables us to manipulate the\nbiases within the LLM and demonstrate that agents subsequently align with the\naltered biases. These results underscore the need for further research to\ndevelop methods that help agents overcome these biases, a critical step toward\ncreating more realistic simulations.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在模拟人类辩论时的系统偏见问题，指出尽管 LLMs 能模仿人类行为，但它们作为统计学习器易受内在社会偏见影响，导致在政治辩论模拟中偏离真实人类动态。研究发现，LLM 代理即使被指令从特定政治视角辩论，也倾向于符合模型固有的偏见，从而产生不符合人类社会互动的行为模式。通过自动自微调方法，研究者成功操纵了 LLM 的偏见，并验证代理会随之调整。这些结果强调了开发克服偏见的方法的必要性，以实现更真实可靠的 LLM 模拟。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04049v3",
      "published_date": "2024-02-06 14:51:55 UTC",
      "updated_date": "2024-12-17 17:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:50:09.036806"
    },
    {
      "arxiv_id": "2402.04046v2",
      "title": "Reviving Life on the Edge: Joint Score-Based Graph Generation of Rich Edge Attributes",
      "title_zh": "翻译失败",
      "authors": [
        "Nimrod Berman",
        "Eitan Kosman",
        "Dotan Di Castro",
        "Omri Azencot"
      ],
      "abstract": "Graph generation is integral to various engineering and scientific\ndisciplines. Nevertheless, existing methodologies tend to overlook the\ngeneration of edge attributes. However, we identify critical applications where\nedge attributes are essential, making prior methods potentially unsuitable in\nsuch contexts. Moreover, while trivial adaptations are available, empirical\ninvestigations reveal their limited efficacy as they do not properly model the\ninterplay among graph components. To address this, we propose a joint\nscore-based model of nodes and edges for graph generation that considers all\ngraph components. Our approach offers three key novelties: \\textbf{(1)} node\nand edge attributes are combined in an attention module that generates samples\nbased on the two ingredients, \\textbf{(2)} node, edge and adjacency information\nare mutually dependent during the graph diffusion process, and \\textbf{(3)} the\nframework enables the generation of graphs with rich attributes along the\nedges, providing a more expressive formulation for generative tasks than\nexisting works. We evaluate our method on challenging benchmarks involving\nreal-world and synthetic datasets in which edge features are crucial.\nAdditionally, we introduce a new synthetic dataset that incorporates edge\nvalues. Furthermore, we propose a novel application that greatly benefits from\nthe method due to its nature: the generation of traffic scenes represented as\ngraphs. Our method outperforms other graph generation methods, demonstrating a\nsignificant advantage in edge-related measures.",
      "tldr_zh": "该研究指出，现有的图生成方法忽略了边属性的生成，导致在关键应用中表现不佳。为解决这一问题，作者提出一个联合 score-based 模型，联合生成节点和边，同时引入三个创新：使用 attention module 结合节点和边属性、使节点、边和邻接信息在图扩散过程中相互依赖，以及支持生成具有丰富边属性的图。实验在真实世界和合成数据集上验证了该方法的有效性，尤其在边相关指标上优于基线模型，并应用于交通场景生成的新任务中。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04046v2",
      "published_date": "2024-02-06 14:48:34 UTC",
      "updated_date": "2024-12-26 13:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:50:20.725485"
    },
    {
      "arxiv_id": "2402.06664v3",
      "title": "LLM Agents can Autonomously Hack Websites",
      "title_zh": "LLM 代理能够自主入侵网站",
      "authors": [
        "Richard Fang",
        "Rohan Bindu",
        "Akul Gupta",
        "Qiusi Zhan",
        "Daniel Kang"
      ],
      "abstract": "In recent years, large language models (LLMs) have become increasingly\ncapable and can now interact with tools (i.e., call functions), read documents,\nand recursively call themselves. As a result, these LLMs can now function\nautonomously as agents. With the rise in capabilities of these agents, recent\nwork has speculated on how LLM agents would affect cybersecurity. However, not\nmuch is known about the offensive capabilities of LLM agents.\n  In this work, we show that LLM agents can autonomously hack websites,\nperforming tasks as complex as blind database schema extraction and SQL\ninjections without human feedback. Importantly, the agent does not need to know\nthe vulnerability beforehand. This capability is uniquely enabled by frontier\nmodels that are highly capable of tool use and leveraging extended context.\nNamely, we show that GPT-4 is capable of such hacks, but existing open-source\nmodels are not. Finally, we show that GPT-4 is capable of autonomously finding\nvulnerabilities in websites in the wild. Our findings raise questions about the\nwidespread deployment of LLMs.",
      "tldr_zh": "这篇论文展示了大型语言模型（LLM）代理（如GPT-4）能够自主黑客网站，进行复杂任务，例如盲数据库模式提取和SQL injections，而无需事先知道漏洞或人类反馈。研究方法利用LLM的工具使用和扩展上下文能力，使代理递归调用自身来执行攻击。实验结果显示，GPT-4成功率显著高于现有开源模型，并在真实网站中自主发现漏洞，这引发了对LLM广泛部署的安全风险担忧。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06664v3",
      "published_date": "2024-02-06 14:46:08 UTC",
      "updated_date": "2024-02-16 04:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:50:32.722522"
    },
    {
      "arxiv_id": "2402.04032v5",
      "title": "ProactivePIM: Accelerating Weight-Sharing Embedding Layer with PIM for Scalable Recommendation System",
      "title_zh": "翻译失败",
      "authors": [
        "Youngsuk Kim",
        "Junghwan Lim",
        "Hyuk-Jae Lee",
        "Chae Eun Rhee"
      ],
      "abstract": "The model size growth of personalized recommendation systems poses new\nchallenges for inference. Weight-sharing algorithms have been proposed for size\nreduction, but they increase memory access. Recent advancements in\nprocessing-in-memory (PIM) enhanced the model throughput by exploiting memory\nparallelism, but such algorithms introduce massive CPU-PIM communication into\nprior PIM systems. We propose ProactivePIM, a PIM system for weight-sharing\nrecommendation system acceleration. ProactivePIM integrates a cache within the\nPIM with a prefetching scheme to leverage a unique locality of the algorithm\nand eliminate communication overhead through a subtable mapping strategy.\nProactivePIM achieves a 4.8x speedup compared to prior works.",
      "tldr_zh": "本研究针对个性化推荐系统的模型规模增长导致的推理挑战，提出ProactivePIM系统，以加速权重-sharing嵌入层。ProactivePIM在PIM（处理在内存）中集成缓存和预取方案，利用算法的独特局部性，并通过子表映射策略消除CPU-PIM通信开销。实验结果显示，ProactivePIM比现有工作提速4.8倍，为可扩展推荐系统提供了高效解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.04032v5",
      "published_date": "2024-02-06 14:26:22 UTC",
      "updated_date": "2024-11-21 05:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:50:45.283606"
    },
    {
      "arxiv_id": "2402.04028v1",
      "title": "AlbNews: A Corpus of Headlines for Topic Modeling in Albanian",
      "title_zh": "翻译失败",
      "authors": [
        "Erion Çano",
        "Dario Lamaj"
      ],
      "abstract": "The scarcity of available text corpora for low-resource languages like\nAlbanian is a serious hurdle for research in natural language processing tasks.\nThis paper introduces AlbNews, a collection of 600 topically labeled news\nheadlines and 2600 unlabeled ones in Albanian. The data can be freely used for\nconducting topic modeling research. We report the initial classification scores\nof some traditional machine learning classifiers trained with the AlbNews\nsamples. These results show that basic models outrun the ensemble learning ones\nand can serve as a baseline for future experiments.",
      "tldr_zh": "这篇论文介绍了 AlbNews，这是一个针对低资源语言阿尔巴尼亚语的新闻标题语料库，包含 600 个主题标记的标题和 2600 个未标记的标题，可免费用于 topic modeling 研究。研究者评估了传统 machine learning classifiers 在该语料库上的初始分类性能，结果显示基本模型的表现优于 ensemble learning 模型。AlbNews 作为未来实验的基线，有助于缓解阿尔巴尼亚语在自然语言处理任务中的数据稀缺问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04028v1",
      "published_date": "2024-02-06 14:24:28 UTC",
      "updated_date": "2024-02-06 14:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:50:57.129276"
    },
    {
      "arxiv_id": "2403.18831v1",
      "title": "DeepTraderX: Challenging Conventional Trading Strategies with Deep Learning in Multi-Threaded Market Simulations",
      "title_zh": "DeepTraderX：使用深度学习在多线程市场模拟中挑战传统",
      "authors": [
        "Armand Mihai Cismaru"
      ],
      "abstract": "In this paper, we introduce DeepTraderX (DTX), a simple Deep Learning-based\ntrader, and present results that demonstrate its performance in a\nmulti-threaded market simulation. In a total of about 500 simulated market\ndays, DTX has learned solely by watching the prices that other strategies\nproduce. By doing this, it has successfully created a mapping from market data\nto quotes, either bid or ask orders, to place for an asset. Trained on\nhistorical Level-2 market data, i.e., the Limit Order Book (LOB) for specific\ntradable assets, DTX processes the market state $S$ at each timestep $T$ to\ndetermine a price $P$ for market orders. The market data used in both training\nand testing was generated from unique market schedules based on real historic\nstock market data. DTX was tested extensively against the best strategies in\nthe literature, with its results validated by statistical analysis. Our\nfindings underscore DTX's capability to rival, and in many instances, surpass,\nthe performance of public-domain traders, including those that outclass human\ntraders, emphasising the efficiency of simple models, as this is required to\nsucceed in intricate multi-threaded simulations. This highlights the potential\nof leveraging \"black-box\" Deep Learning systems to create more efficient\nfinancial markets.",
      "tldr_zh": "本论文引入了DeepTraderX (DTX)，一个基于Deep Learning的简单交易模型，通过观察其他策略的价格来学习，并在多线程市场模拟中挑战传统交易策略。DTX使用历史Level-2市场数据（即Limit Order Book）进行训练，从市场状态$S$在每个时间步$T$映射到报价（如bid或ask订单），并基于真实股票数据生成的模拟环境进行测试。实验在约500个模拟市场日中显示，DTX不仅能与公共领域交易者竞争，甚至在许多情况下超越它们，包括那些优于人类交易者的策略。结果通过统计分析验证，强调了简单Deep Learning模型在复杂多线程模拟中的高效性，并展示了其潜力在构建更高效金融市场方面的应用。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "I.2.6; J.1"
      ],
      "primary_category": "q-fin.TR",
      "comment": "11 pages, 9 png figures, uses apalike.sty and SCITEPRESS.sty, to be\n  published in the proceedings of ICAART 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.18831v1",
      "published_date": "2024-02-06 14:20:51 UTC",
      "updated_date": "2024-02-06 14:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:51:10.787739"
    },
    {
      "arxiv_id": "2402.04009v1",
      "title": "Low-rank Attention Side-Tuning for Parameter-Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Ningyuan Tang",
        "Minghao Fu",
        "Ke Zhu",
        "Jianxin Wu"
      ],
      "abstract": "In finetuning a large pretrained model to downstream tasks,\nparameter-efficient fine-tuning (PEFT) methods can effectively finetune\npretrained models with few trainable parameters, but suffer from high GPU\nmemory consumption and slow training speed. Because learnable parameters from\nthese methods are entangled with the pretrained model, gradients related to the\nfrozen pretrained model's parameters have to be computed and stored during\nfinetuning. We propose Low-rank Attention Side-Tuning (LAST), which\ndisentangles the trainable module from the pretrained model by freezing not\nonly parameters but also outputs of the pretrained network. LAST trains a\nside-network composed of only low-rank self-attention modules. By viewing the\npretrained model as a frozen feature extractor, the side-network takes\nintermediate output from the pretrained model and focus on learning\ntask-specific knowledge. We also show that LAST can be highly parallel across\nmultiple optimization objectives, making it very efficient in downstream task\nadaptation, for example, in finding optimal hyperparameters. LAST outperforms\nprevious state-of-the-art methods on VTAB-1K and other visual adaptation tasks\nwith roughly only 30\\% of GPU memory footprint and 60\\% of training time\ncompared to existing PEFT methods, but achieves significantly higher accuracy.",
      "tldr_zh": "该研究针对参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）中的高GPU内存消耗和慢速训练问题，提出了一种名为Low-rank Attention Side-Tuning (LAST)的创新方法。LAST通过冻结预训练模型的参数和输出，训练一个独立的侧网络（side-network），该网络仅由低秩自注意力模块（low-rank self-attention modules）组成，并将预训练模型视为特征提取器来学习任务特定知识。这种设计允许LAST在多目标优化中实现高效并行。实验结果显示，LAST在VTAB-1K和其他视觉适应任务上比现有最先进方法准确性更高，同时仅需约30%的GPU内存和60%的训练时间。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04009v1",
      "published_date": "2024-02-06 14:03:15 UTC",
      "updated_date": "2024-02-06 14:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:51:21.805806"
    },
    {
      "arxiv_id": "2403.08808v1",
      "title": "A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance",
      "title_zh": "一种仿生数据驱动方法，用于长距离水下导航，具有异常抵抗能力",
      "authors": [
        "Songnan Yang",
        "Xiaohui Zhang",
        "Shiliang Zhang",
        "Xuehui Ma",
        "Wenqi Bai",
        "Yushuai Li",
        "Tingwen Huang"
      ],
      "abstract": "Various animals exhibit accurate navigation using environment cues. The\nEarth's magnetic field has been proved a reliable information source in\nlong-distance fauna migration. Inspired by animal navigation, this work\nproposes a bionic and data-driven approach for long-distance underwater\nnavigation. The proposed approach uses measured geomagnetic data for the\nnavigation, and requires no GPS systems or geographical maps. Particularly, we\nconstruct and train a Temporal Attention-based Long Short-Term Memory (TA-LSTM)\nnetwork to predict the heading angle during the navigation. To mitigate the\nimpact of geomagnetic anomalies, we develop the mechanism to detect and\nquantify the anomalies based on Maximum Likelihood Estimation. We integrate the\ndeveloped mechanism with the TA-LSTM, and calibrate the predicted heading\nangles to gain resistance against geomagnetic anomalies. Using the retrieved\ndata from the WMM model, we conduct numerical simulations with diversified\nnavigation conditions to test our approach. The simulation results demonstrate\na resilience navigation against geomagnetic anomalies by our approach, along\nwith precision and stability of the underwater navigation in single and\nmultiple destination missions.",
      "tldr_zh": "这篇论文受动物导航启发，提出了一种仿生数据驱动的方法，用于长距离水下导航，利用地磁数据而无需依赖 GPS 或地理地图。核心技术包括构建 Temporal Attention-based Long Short-Term Memory (TA-LSTM) 网络来预测航向角，以及基于 Maximum Likelihood Estimation 的机制来检测、量化并校准地磁异常，从而提升导航的抗异常能力。模拟实验使用 WMM 模型数据验证了该方法的鲁棒性，在单/多目的地任务中实现了精确且稳定的导航性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08808v1",
      "published_date": "2024-02-06 13:20:56 UTC",
      "updated_date": "2024-02-06 13:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:51:33.524934"
    },
    {
      "arxiv_id": "2402.16874v1",
      "title": "Enhancing Retrieval Processes for Language Generation with Augmented Queries",
      "title_zh": "通过增强查询提升语言生成的检索过程",
      "authors": [
        "Julien Pierre Edmond Ghali",
        "Kosuke Shima",
        "Koichi Moriyama",
        "Atsuko Mutoh",
        "Nobuhiro Inuzuka"
      ],
      "abstract": "In the rapidly changing world of smart technology, searching for documents\nhas become more challenging due to the rise of advanced language models. These\nmodels sometimes face difficulties, like providing inaccurate information,\ncommonly known as \"hallucination.\" This research focuses on addressing this\nissue through Retrieval-Augmented Generation (RAG), a technique that guides\nmodels to give accurate responses based on real facts. To overcome scalability\nissues, the study explores connecting user queries with sophisticated language\nmodels such as BERT and Orca2, using an innovative query optimization process.\nThe study unfolds in three scenarios: first, without RAG, second, without\nadditional assistance, and finally, with extra help. Choosing the compact yet\nefficient Orca2 7B model demonstrates a smart use of computing resources. The\nempirical results indicate a significant improvement in the initial language\nmodel's performance under RAG, particularly when assisted with prompts\naugmenters. Consistency in document retrieval across different encodings\nhighlights the effectiveness of using language model-generated queries. The\nintroduction of UMAP for BERT further simplifies document retrieval while\nmaintaining strong results.",
      "tldr_zh": "本研究旨在通过增强查询优化来改进Retrieval-Augmented Generation (RAG) 技术，解决语言模型在文档检索中的幻觉问题和可扩展性挑战。研究者将用户查询与BERT和Orca2等高级语言模型整合，使用创新的查询优化过程，并在三种场景（无RAG、无额外辅助、带有额外辅助）下进行实验。结果显示，RAG显著提升了语言模型的性能，特别是结合prompt augmenters后，文档检索的一致性得到改善，且引入UMAP for BERT进一步简化了检索过程，同时保持高效的计算资源利用。总的来说，该方法为更准确的语言生成提供了可靠的框架。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "28 pages, 10 annexes, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.16874v1",
      "published_date": "2024-02-06 13:19:53 UTC",
      "updated_date": "2024-02-06 13:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:51:44.471694"
    },
    {
      "arxiv_id": "2402.03972v1",
      "title": "Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Toquebiau",
        "Nicolas Bredeche",
        "Faïz Benamar",
        "Jae-Yun Jun"
      ],
      "abstract": "Multi-agent deep reinforcement learning (MADRL) problems often encounter the\nchallenge of sparse rewards. This challenge becomes even more pronounced when\ncoordination among agents is necessary. As performance depends not only on one\nagent's behavior but rather on the joint behavior of multiple agents, finding\nan adequate solution becomes significantly harder. In this context, a group of\nagents can benefit from actively exploring different joint strategies in order\nto determine the most efficient one. In this paper, we propose an approach for\nrewarding strategies where agents collectively exhibit novel behaviors. We\npresent JIM (Joint Intrinsic Motivation), a multi-agent intrinsic motivation\nmethod that follows the centralized learning with decentralized execution\nparadigm. JIM rewards joint trajectories based on a centralized measure of\nnovelty designed to function in continuous environments. We demonstrate the\nstrengths of this approach both in a synthetic environment designed to reveal\nshortcomings of state-of-the-art MADRL methods, and in simulated robotic tasks.\nResults show that joint exploration is crucial for solving tasks where the\noptimal strategy requires a high level of coordination.",
      "tldr_zh": "本论文探讨了多智能体深度强化学习（MADRL）中稀疏奖励的挑战，特别是当代理需要协调时，联合行为变得至关重要。作者提出 JIM（Joint Intrinsic Motivation）方法，这是一种基于集中式学习与分散式执行范式的多智能体内部动机机制，通过集中式新颖性度量奖励代理的联合轨迹，以促进在连续环境中的探索。实验结果显示，JIM 在一个合成环境和模拟机器人任务中显著优于现有方法，尤其在需要高度协调的最优策略任务上，证明了联合探索的关键作用。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 13 figures. Published as an extended abstract at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03972v1",
      "published_date": "2024-02-06 13:02:00 UTC",
      "updated_date": "2024-02-06 13:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:51:56.804754"
    },
    {
      "arxiv_id": "2402.03970v2",
      "title": "Is Deep Learning finally better than Decision Trees on Tabular Data?",
      "title_zh": "深度学习终于在表格数据上",
      "authors": [
        "Guri Zabërgja",
        "Arlind Kadra",
        "Christian M. M. Frey",
        "Josif Grabocka"
      ],
      "abstract": "Tabular data is a ubiquitous data modality due to its versatility and ease of\nuse in many real-world applications. The predominant heuristics for handling\nclassification tasks on tabular data rely on classical machine learning\ntechniques, as the superiority of deep learning models has not yet been\ndemonstrated. This raises the question of whether new deep learning paradigms\ncan surpass classical approaches. Recent studies on tabular data offer a unique\nperspective on the limitations of neural networks in this domain and highlight\nthe superiority of gradient boosted decision trees (GBDTs) in terms of\nscalability and robustness across various datasets. However, novel foundation\nmodels have not been thoroughly assessed regarding quality or fairly compared\nto existing methods for tabular classification. Our study categorizes ten\nstate-of-the-art neural models based on their underlying learning paradigm,\ndemonstrating specifically that meta-learned foundation models outperform GBDTs\nin small data regimes. Although dataset-specific neural networks generally\noutperform LLM-based tabular classifiers, they are surpassed by an AutoML\nlibrary which exhibits the best performance but at the cost of higher\ncomputational demands.",
      "tldr_zh": "这篇论文探讨了深度学习是否在表格数据 (Tabular Data) 分类任务上优于决策树 (Decision Trees)，通过比较十种最先进的神经模型及其学习范式。研究发现，元学习 (Meta-learned) 基础模型在小数据场景下表现优于梯度提升决策树 (GBDTs)，而数据集特定的神经网络通常优于基于 LLM 的分类器。最终，AutoML 库在性能上领先，但这伴随着更高的计算需求，挑战了深度学习在该领域的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03970v2",
      "published_date": "2024-02-06 12:59:02 UTC",
      "updated_date": "2025-02-14 14:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:52:09.481075"
    },
    {
      "arxiv_id": "2402.03962v3",
      "title": "Position: Stop Making Unscientific AGI Performance Claims",
      "title_zh": "立场：停止对 AGI 性能做出不科学的主张",
      "authors": [
        "Patrick Altmeyer",
        "Andrew M. Demetriou",
        "Antony Bartlett",
        "Cynthia C. S. Liem"
      ],
      "abstract": "Developments in the field of Artificial Intelligence (AI), and particularly\nlarge language models (LLMs), have created a 'perfect storm' for observing\n'sparks' of Artificial General Intelligence (AGI) that are spurious. Like\nsimpler models, LLMs distill meaningful representations in their latent\nembeddings that have been shown to correlate with external variables.\nNonetheless, the correlation of such representations has often been linked to\nhuman-like intelligence in the latter but not the former. We probe models of\nvarying complexity including random projections, matrix decompositions, deep\nautoencoders and transformers: all of them successfully distill information\nthat can be used to predict latent or external variables and yet none of them\nhave previously been linked to AGI. We argue and empirically demonstrate that\nthe finding of meaningful patterns in latent spaces of models cannot be seen as\nevidence in favor of AGI. Additionally, we review literature from the social\nsciences that shows that humans are prone to seek such patterns and\nanthropomorphize. We conclude that both the methodological setup and common\npublic image of AI are ideal for the misinterpretation that correlations\nbetween model representations and some variables of interest are 'caused' by\nthe model's understanding of underlying 'ground truth' relationships. We,\ntherefore, call for the academic community to exercise extra caution, and to be\nkeenly aware of principles of academic integrity, in interpreting and\ncommunicating about AI research outcomes.",
      "tldr_zh": "这篇论文批评当前对人工智能通用智能(AGI)性能的非科学声明，指出大型语言模型(LLMs)中的潜在嵌入(latent embeddings)相关性常被误解为人类般的智能证据。作者通过实验测试了不同复杂度的模型，包括随机投影(random projections)、矩阵分解(matrix decompositions)、深度自编码器(deep autoencoders)和变换器(transformers)，证明这些模型都能提取信息用于预测变量，但这并不构成AGI的证据。论文进一步引用社会科学文献，强调人类易于寻找模式并拟人化(anthropomorphize)，并呼吁学术界在解释和传播AI研究结果时更加谨慎，以维护学术诚信。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 15 figures. Pre-print to be published at International\n  Conference on Machine Learning (ICML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03962v3",
      "published_date": "2024-02-06 12:42:21 UTC",
      "updated_date": "2024-05-31 15:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:52:21.486532"
    },
    {
      "arxiv_id": "2402.03951v1",
      "title": "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping",
      "title_zh": "翻译失败",
      "authors": [
        "Qinliang Lin",
        "Cheng Luo",
        "Zenghao Niu",
        "Xilin He",
        "Weicheng Xie",
        "Yuanbo Hou",
        "Linlin Shen",
        "Siyang Song"
      ],
      "abstract": "Adversarial examples generated by a surrogate model typically exhibit limited\ntransferability to unknown target systems. To address this problem, many\ntransferability enhancement approaches (e.g., input transformation and model\naugmentation) have been proposed. However, they show poor performances in\nattacking systems having different model genera from the surrogate model. In\nthis paper, we propose a novel and generic attacking strategy, called\nDeformation-Constrained Warping Attack (DeCoWA), that can be effectively\napplied to cross model genus attack. Specifically, DeCoWA firstly augments\ninput examples via an elastic deformation, namely Deformation-Constrained\nWarping (DeCoW), to obtain rich local details of the augmented input. To avoid\nsevere distortion of global semantics led by random deformation, DeCoW further\nconstrains the strength and direction of the warping transformation by a novel\nadaptive control strategy. Extensive experiments demonstrate that the\ntransferable examples crafted by our DeCoWA on CNN surrogates can significantly\nhinder the performance of Transformers (and vice versa) on various tasks,\nincluding image classification, video action recognition, and audio\nrecognition. Code is made available at https://github.com/LinQinLiang/DeCoWA.",
      "tldr_zh": "本论文针对对抗样本（Adversarial examples）从代理模型到目标模型的转移性问题，提出了一种通用攻击策略DeCoWA，以提升跨模型类型（Model Genus，例如CNN到Transformer）的攻击效果。DeCoWA通过弹性变形技术Deformation-Constrained Warping (DeCoW)增强输入样本，获得丰富的局部细节，同时采用自适应控制策略约束变形的强度和方向，避免全局语义的严重扭曲。实验结果表明，在图像分类、视频动作识别和音频识别等任务上，DeCoWA生成的对抗样本显著降低了目标模型的性能，提升了整体转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03951v1",
      "published_date": "2024-02-06 12:23:14 UTC",
      "updated_date": "2024-02-06 12:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:52:34.138906"
    },
    {
      "arxiv_id": "2402.03941v2",
      "title": "Discovery of the Hidden World with Large Language Models",
      "title_zh": "使用大型语言模型发现隐藏的世界",
      "authors": [
        "Chenxi Liu",
        "Yongqiang Chen",
        "Tongliang Liu",
        "Mingming Gong",
        "James Cheng",
        "Bo Han",
        "Kun Zhang"
      ],
      "abstract": "Revealing the underlying causal mechanisms in the real world is the key to\nthe development of science. Despite the progress in the past decades,\ntraditional causal discovery approaches (CDs) mainly rely on high-quality\nmeasured variables, usually given by human experts, to find causal relations.\nThe lack of well-defined high-level variables in many real-world applications\nhas already been a longstanding roadblock to a broader application of CDs. To\nthis end, this paper presents Causal representatiOn AssistanT (COAT) that\nintroduces large language models (LLMs) to bridge the gap. LLMs are trained on\nmassive observations of the world and have demonstrated great capability in\nextracting key information from unstructured data. Therefore, it is natural to\nemploy LLMs to assist with proposing useful high-level factors and crafting\ntheir measurements. Meanwhile, COAT also adopts CDs to find causal relations\namong the identified variables as well as to provide feedback to LLMs to\niteratively refine the proposed factors. We show that LLMs and CDs are mutually\nbeneficial and the constructed feedback provably also helps with the factor\nproposal. We construct and curate several synthetic and real-world benchmarks\nincluding analysis of human reviews and diagnosis of neuropathic and brain\ntumors, to comprehensively evaluate COAT. Extensive empirical results confirm\nthe effectiveness and reliability of COAT with significant improvements.",
      "tldr_zh": "本研究针对传统因果发现方法（Causal Discovery, CDs）依赖专家提供的高质量变量的问题，提出 Causal representatiOn AssistanT (COAT) 框架，利用 Large Language Models (LLMs) 从非结构化数据中提取并提出有用的高级因素及其测量方式。COAT 通过 LLMs 和 CDs 的相互协作，CDs 发现变量间的因果关系并反馈给 LLMs 以迭代优化因素，从而实现双向有益的改进。实验在多个合成和真实基准（如人类评论分析、神经病变和脑肿瘤诊断）上验证了 COAT 的有效性和可靠性，取得了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024; Chenxi and Yongqiang contributed equally; 59 pages, 72\n  figures; Project page: https://causalcoat.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2402.03941v2",
      "published_date": "2024-02-06 12:18:54 UTC",
      "updated_date": "2024-10-31 12:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:52:44.817912"
    },
    {
      "arxiv_id": "2403.00765v1",
      "title": "An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Haubold",
        "Petra Linke"
      ],
      "abstract": "As data science applications gain adoption across industries, the tooling\nlandscape matures to facilitate the life cycle of such applications and provide\nsolutions to the challenges involved to boost the productivity of the people\ninvolved. Reinforcement learning with agents in a 3D world could still face\nchallenges: the knowledge required to use a simulation software as well as the\nutilization of a standalone simulation software in unattended training\npipelines.\n  In this paper we review tools and approaches to train reinforcement learning\nagents for robots in 3D worlds with respect to the robot Robotino and argue\nthat the separation of the simulation environment for creators of virtual\nworlds and the model development environment for data scientists is not a well\ncovered topic. Often both are the same and data scientists require knowledge of\nthe simulation software to work directly with their APIs. Moreover, sometimes\ncreators of virtual worlds and data scientists even work on the same files. We\nwant to contribute to that topic by describing an approach where data\nscientists don't require knowledge about the simulation software. Our approach\nuses the standalone simulation software Webots, the Robot Operating System to\ncommunicate with simulated robots as well as the simulation software itself and\ncontainer technology to separate the simulation from the model development\nenvironment. We put emphasize on the APIs the data scientists work with and the\nuse of a standalone simulation software in unattended training pipelines. We\nshow the parts that are specific to the Robotino and the robot task to learn.",
      "tldr_zh": "这篇论文讨论了在3D世界中训练强化学习(Reinforcement Learning)代理的挑战，特别是数据科学家需要了解模拟软件知识的问题，并以Robotino机器人为例进行审视。作者提出了一种架构，使用Webots作为独立模拟软件、Robot Operating System(ROS)进行通信，以及容器技术来分离模拟环境和模型开发环境，从而让数据科学家只需通过特定API工作，而无需掌握模拟软件细节。這種方法支持无人值守训练管道，提高了生产力和效率，并展示了与Robotino机器人任务相关的具体实现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "D.2.11"
      ],
      "primary_category": "cs.RO",
      "comment": "Latex with llncs.cls, 17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.00765v1",
      "published_date": "2024-02-06 12:08:01 UTC",
      "updated_date": "2024-02-06 12:08:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:52:57.878676"
    },
    {
      "arxiv_id": "2402.03927v2",
      "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Balloccu",
        "Patrícia Schmidtová",
        "Mateusz Lango",
        "Ondřej Dušek"
      ],
      "abstract": "Natural Language Processing (NLP) research is increasingly focusing on the\nuse of Large Language Models (LLMs), with some of the most popular ones being\neither fully or partially closed-source. The lack of access to model details,\nespecially regarding training data, has repeatedly raised concerns about data\ncontamination among researchers. Several attempts have been made to address\nthis issue, but they are limited to anecdotal evidence and trial and error.\nAdditionally, they overlook the problem of \\emph{indirect} data leaking, where\nmodels are iteratively improved by using data coming from users. In this work,\nwe conduct the first systematic analysis of work using OpenAI's GPT-3.5 and\nGPT-4, the most prominently used LLMs today, in the context of data\ncontamination. By analysing 255 papers and considering OpenAI's data usage\npolicy, we extensively document the amount of data leaked to these models\nduring the first year after the model's release. We report that these models\nhave been globally exposed to $\\sim$4.7M samples from 263 benchmarks. At the\nsame time, we document a number of evaluation malpractices emerging in the\nreviewed papers, such as unfair or missing baseline comparisons and\nreproducibility issues. We release our results as a collaborative project on\nhttps://leak-llm.github.io/, where other researchers can contribute to our\nefforts.",
      "tldr_zh": "本研究首次对封闭源大型语言模型（LLMs）的数据污染问题进行了系统分析，焦点放在 OpenAI 的 GPT-3.5 和 GPT-4 上，通过分析 255 篇论文和 OpenAI 的数据使用政策，揭示这些模型在发布后第一年暴露于约 4.7M 样本来自 263 个基准。研究特别强调了间接数据泄露问题，即模型通过用户数据迭代改进。论文还记录了常见的评估不当行为，包括不公平的基线比较和再现性问题，并发布协作项目 https://leak-llm.github.io/ 以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EACL 2024 - main conference",
      "pdf_url": "http://arxiv.org/pdf/2402.03927v2",
      "published_date": "2024-02-06 11:54:23 UTC",
      "updated_date": "2024-02-22 12:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:53:10.162712"
    },
    {
      "arxiv_id": "2403.08807v1",
      "title": "Effective anytime algorithm for multiobjective combinatorial optimization problems",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Ángel Domínguez-Ríos",
        "Francisco Chicano",
        "Enrique Alba"
      ],
      "abstract": "In multiobjective optimization, the result of an optimization algorithm is a\nset of efficient solutions from which the decision maker selects one. It is\ncommon that not all the efficient solutions can be computed in a short time and\nthe search algorithm has to be stopped prematurely to analyze the solutions\nfound so far. A set of efficient solutions that are well-spread in the\nobjective space is preferred to provide the decision maker with a great variety\nof solutions. However, just a few exact algorithms in the literature exist with\nthe ability to provide such a well-spread set of solutions at any moment: we\ncall them anytime algorithms. We propose a new exact anytime algorithm for\nmultiobjective combinatorial optimization combining three novel ideas to\nenhance the anytime behavior. We compare the proposed algorithm with those in\nthe state-of-the-art for anytime multiobjective combinatorial optimization\nusing a set of 480 instances from different well-known benchmarks and four\ndifferent performance measures: the overall non-dominated vector generation\nratio, the hypervolume, the general spread and the additive epsilon indicator.\nA comprehensive experimental study reveals that our proposal outperforms the\nprevious algorithms in most of the instances.",
      "tldr_zh": "这篇论文针对多目标组合优化(multiobjective combinatorial optimization)问题，提出了一种新的精确anytime algorithm，能够在任何时刻提供在目标空间中分布良好的有效解决方案集。该算法结合三个创新想法，包括增强搜索过程和优化分布策略，以改善算法的实时性能。在使用480个基准实例和四个性能指标（overall non-dominated vector generation ratio、hypervolume、general spread以及additive epsilon indicator）的全面实验中，新算法在大多数实例上优于现有方法，为决策者提供更可靠的解决方案选择。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08807v1",
      "published_date": "2024-02-06 11:53:44 UTC",
      "updated_date": "2024-02-06 11:53:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:53:20.822977"
    },
    {
      "arxiv_id": "2402.03921v2",
      "title": "Large Language Models to Enhance Bayesian Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Tennison Liu",
        "Nicolás Astorga",
        "Nabeel Seedat",
        "Mihaela van der Schaar"
      ],
      "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing complex and\nexpensive-to-evaluate black-box functions. Its importance is underscored in\nmany applications, notably including hyperparameter tuning, but its efficacy\ndepends on efficiently balancing exploration and exploitation. While there has\nbeen substantial progress in BO methods, striking this balance remains a\ndelicate process. In this light, we present LLAMBO, a novel approach that\nintegrates the capabilities of Large Language Models (LLM) within BO. At a high\nlevel, we frame the BO problem in natural language, enabling LLMs to\niteratively propose and evaluate promising solutions conditioned on historical\nevaluations. More specifically, we explore how combining contextual\nunderstanding, few-shot learning proficiency, and domain knowledge of LLMs can\nimprove model-based BO. Our findings illustrate that LLAMBO is effective at\nzero-shot warmstarting, and enhances surrogate modeling and candidate sampling,\nespecially in the early stages of search when observations are sparse. Our\napproach is performed in context and does not require LLM finetuning.\nAdditionally, it is modular by design, allowing individual components to be\nintegrated into existing BO frameworks, or function cohesively as an end-to-end\nmethod. We empirically validate LLAMBO's efficacy on the problem of\nhyperparameter tuning, highlighting strong empirical performance across a range\nof diverse benchmarks, proprietary, and synthetic tasks.",
      "tldr_zh": "这篇论文提出了一种名为 LLAMBO 的方法，利用 Large Language Models (LLM) 来增强 Bayesian Optimization (BO)，通过自然语言框架让 LLM 基于历史评估迭代提出和评估解决方案，从而更好地平衡探索和利用。LLAMBO 利用 LLM 的上下文理解、少样本学习和领域知识能力，实现零样本预热、改进代理模型和候选采样，尤其在观察稀疏的早期阶段效果显著。该方法无需 LLM 微调，且设计模块化，便于整合现有 BO 框架，并在超参数调优的多种基准和任务上表现出色实证性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as Poster at ICLR2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03921v2",
      "published_date": "2024-02-06 11:44:06 UTC",
      "updated_date": "2024-03-08 12:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:53:33.995656"
    },
    {
      "arxiv_id": "2402.05135v1",
      "title": "CADReN: Contextual Anchor-Driven Relational Network for Controllable Cross-Graphs Node Importance Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Zhong",
        "Yunhui Zhang",
        "Ziyi Chang",
        "Zengchang Qin"
      ],
      "abstract": "Node Importance Estimation (NIE) is crucial for integrating external\ninformation into Large Language Models through Retriever-Augmented Generation.\nTraditional methods, focusing on static, single-graph characteristics, lack\nadaptability to new graphs and user-specific requirements. CADReN, our proposed\nmethod, addresses these limitations by introducing a Contextual Anchor (CA)\nmechanism. This approach enables the network to assess node importance relative\nto the CA, considering both structural and semantic features within Knowledge\nGraphs (KGs). Extensive experiments show that CADReN achieves better\nperformance in cross-graph NIE task, with zero-shot prediction ability. CADReN\nis also proven to match the performance of previous models on single-graph NIE\ntask. Additionally, we introduce and opensource two new datasets, RIC200 and\nWK1K, specifically designed for cross-graph NIE research, providing a valuable\nresource for future developments in this domain.",
      "tldr_zh": "本文提出 CADReN，一种基于 Contextual Anchor (CA) 机制的关系网络，用于可控的跨图 Node Importance Estimation (NIE)，以解决传统方法在适应新图和用户特定需求方面的局限性。CADReN 通过整合 Knowledge Graphs (KGs) 中的结构和语义特征，评估节点相对于 CA 的相对重要性，从而提升 Retriever-Augmented Generation 中外部信息整合的效率。实验结果表明，CADReN 在跨图 NIE 任务中表现出色，具有 zero-shot prediction 能力，并在单图任务中与现有模型性能相当。此外，论文开源了两个新数据集 RIC200 和 WK1K，旨在推动跨图 NIE 研究的进一步发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.05135v1",
      "published_date": "2024-02-06 11:29:44 UTC",
      "updated_date": "2024-02-06 11:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:53:46.749527"
    },
    {
      "arxiv_id": "2402.04870v3",
      "title": "Embedding Knowledge Graphs in Degenerate Clifford Algebras",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Mozart Kamdem Teyou",
        "Caglar Demir",
        "Axel-Cyrille Ngonga Ngomo"
      ],
      "abstract": "Clifford algebras are a natural generalization of the real numbers, the\ncomplex numbers, and the quaternions. So far, solely Clifford algebras of the\nform $Cl_{p,q}$ (i.e., algebras without nilpotent base vectors) have been\nstudied in the context of knowledge graph embeddings. We propose to consider\nnilpotent base vectors with a nilpotency index of two. In these spaces, denoted\n$Cl_{p,q,r}$, allows generalizing over approaches based on dual numbers (which\ncannot be modelled using $Cl_{p,q}$) and capturing patterns that emanate from\nthe absence of higher-order interactions between real and complex parts of\nentity embeddings. We design two new models for the discovery of the parameters\n$p$, $q$, and $r$. The first model uses a greedy search to optimize $p$, $q$,\nand $r$. The second predicts $(p, q,r)$ based on an embedding of the input\nknowledge graph computed using neural networks. The results of our evaluation\non seven benchmark datasets suggest that nilpotent vectors can help capture\nembeddings better. Our comparison against the state of the art suggests that\nour approach generalizes better than other approaches on all datasets w.r.t.\nthe MRR it achieves on validation data. We also show that a greedy search\nsuffices to discover values of $p$, $q$ and $r$ that are close to optimal.",
      "tldr_zh": "本文提出将知识图嵌入扩展到退化 Clifford algebras（Cl_{p,q,r}），通过引入 nilpotency index of two 的 nilpotent base vectors，泛化了现有方法并捕捉实体嵌入中实部和复部之间缺乏更高阶交互的模式。作者设计了两个新模型：第一个使用贪婪搜索优化参数 p, q 和 r；第二个基于神经网络对输入知识图进行嵌入以预测 (p, q, r)。在七个基准数据集上的实验表明，该方法在 MRR 上比现有技术实现了更好的泛化性，且贪婪搜索能有效发现接近最优的参数值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04870v3",
      "published_date": "2024-02-06 11:23:33 UTC",
      "updated_date": "2024-09-23 09:57:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:53:59.749731"
    },
    {
      "arxiv_id": "2402.03907v2",
      "title": "Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Efe Bozkir",
        "Süleyman Özdel",
        "Ka Hei Carrie Lau",
        "Mengdi Wang",
        "Hong Gao",
        "Enkelejda Kasneci"
      ],
      "abstract": "Advances in artificial intelligence and human-computer interaction will\nlikely lead to extended reality (XR) becoming pervasive. While XR can provide\nusers with interactive, engaging, and immersive experiences, non-player\ncharacters are often utilized in pre-scripted and conventional ways. This paper\nargues for using large language models (LLMs) in XR by embedding them in\navatars or as narratives to facilitate inclusion through prompt engineering and\nfine-tuning the LLMs. We argue that this inclusion will promote diversity for\nXR use. Furthermore, the versatile conversational capabilities of LLMs will\nlikely increase engagement in XR, helping XR become ubiquitous. Lastly, we\nspeculate that combining the information provided to LLM-powered spaces by\nusers and the biometric data obtained might lead to novel privacy invasions.\nWhile exploring potential privacy breaches, examining user privacy concerns and\npreferences is also essential. Therefore, despite challenges, LLM-powered XR is\na promising area with several opportunities.",
      "tldr_zh": "这篇论文探讨了将大型语言模型 (LLMs) 嵌入扩展现实 (XR) 的机会和挑战，旨在通过提示工程和微调来提升 XR 的包容性，促进用户多样性和交互体验。LLMs 的多功能对话能力有望增加 XR 中的参与度，推动其普及应用。另一方面，结合用户提供的信息和生物识别数据可能引发新型隐私入侵，因此需要深入研究用户隐私担忧和偏好。尽管存在这些挑战，LLM 驱动的 XR 仍是一个充满潜力的领域。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM Conversational User Interfaces 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03907v2",
      "published_date": "2024-02-06 11:19:40 UTC",
      "updated_date": "2024-06-20 10:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:54:12.287477"
    },
    {
      "arxiv_id": "2402.06663v2",
      "title": "Explainable Adversarial Learning Framework on Physical Layer Secret Keys Combating Malicious Reconfigurable Intelligent Surface",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuangkun Wei",
        "Wenxiu Hu",
        "Junqing Zhang",
        "Weisi Guo",
        "Julie McCann"
      ],
      "abstract": "Reconfigurable intelligent surfaces (RIS) can both help and hinder the\nphysical layer secret key generation (PL-SKG) of communications systems. Whilst\na legitimate RIS can yield beneficial impacts, including increased channel\nrandomness to enhance PL-SKG, a malicious RIS can poison legitimate channels\nand crack almost all existing PL-SKGs. In this work, we propose an adversarial\nlearning framework that addresses Man-in-the-middle RIS (MITM-RIS)\neavesdropping which can exist between legitimate parties, namely Alice and Bob.\nFirst, the theoretical mutual information gap between legitimate pairs and\nMITM-RIS is deduced. From this, Alice and Bob leverage adversarial learning to\nlearn a common feature space that assures no mutual information overlap with\nMITM-RIS. Next, to explain the trained legitimate common feature generator, we\naid signal processing interpretation of black-box neural networks using a\nsymbolic explainable AI (xAI) representation. These symbolic terms of dominant\nneurons aid the engineering of feature designs and the validation of the\nlearned common feature space. Simulation results show that our proposed\nadversarial learning- and symbolic-based PL-SKGs can achieve high key agreement\nrates between legitimate users, and is further resistant to an MITM-RIS Eve\nwith the full knowledge of legitimate feature generation (NNs or formulas).\nThis therefore paves the way to secure wireless communications with untrusted\nreflective devices in future 6G.",
      "tldr_zh": "这篇论文提出一个对抗学习框架，用于应对恶意 Reconfigurable Intelligent Surfaces (RIS) 对 Physical Layer Secret Key Generation (PL-SKG) 的攻击，旨在防止 Man-in-the-middle RIS (MITM-RIS) 窃听。框架首先推导合法双方与 MITM-RIS 之间的互信息差距，然后通过对抗学习让 Alice 和 Bob 学习一个共同特征空间，确保与恶意方无信息重叠，并利用符号化 Explainable AI (xAI) 解释黑箱神经网络以优化特征设计。模拟结果显示，该方法在合法用户间实现高密钥一致率，并能抵抗完全知晓特征生成机制的 MITM-RIS，从而为未来 6G 无线通信的安全性提供重要保障。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06663v2",
      "published_date": "2024-02-06 11:19:20 UTC",
      "updated_date": "2024-12-08 22:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:54:24.790984"
    },
    {
      "arxiv_id": "2402.03898v2",
      "title": "DistiLLM: Towards Streamlined Distillation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jongwoo Ko",
        "Sungnyun Kim",
        "Tianyi Chen",
        "Se-Young Yun"
      ],
      "abstract": "Knowledge distillation (KD) is widely used for compressing a teacher model to\na smaller student model, reducing its inference cost and memory footprint while\npreserving model capabilities. However, current KD methods for auto-regressive\nsequence models (e.g., large language models) suffer from missing a\nstandardized objective function. Moreover, the recent use of student-generated\noutputs to address training-inference mismatches has significantly escalated\ncomputational costs. To tackle these issues, we introduce DistiLLM, a more\neffective and efficient KD framework for auto-regressive language models.\nDistiLLM comprises two components: (1) a novel skew Kullback-Leibler divergence\nloss, where we unveil and leverage its theoretical properties, and (2) an\nadaptive off-policy approach designed to enhance the efficiency in utilizing\nstudent-generated outputs. Extensive experiments, including\ninstruction-following tasks, demonstrate the effectiveness of DistiLLM in\nbuilding high-performing student models while achieving up to 4.3$\\times$\nspeedup compared to recent KD methods.",
      "tldr_zh": "这篇论文提出了DistiLLM，一种更高效的知识蒸馏（KD）框架，针对大型语言模型（LLMs）的自回归序列模型问题，解决了现有方法缺乏标准化目标函数和高计算成本的问题。DistiLLM的核心包括一个新型skew Kullback-Leibler divergence损失，利用其理论属性优化训练，以及一个自适应off-policy方法，提高学生生成输出的利用效率。实验结果显示，该框架在指令跟随任务上构建了高性能学生模型，并比最近KD方法实现了高达4.3倍的速度提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2024; Code is available at https://github.com/jongwooko/distillm",
      "pdf_url": "http://arxiv.org/pdf/2402.03898v2",
      "published_date": "2024-02-06 11:10:35 UTC",
      "updated_date": "2024-07-03 04:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:54:35.756379"
    },
    {
      "arxiv_id": "2402.03885v3",
      "title": "MOMENT: A Family of Open Time-series Foundation Models",
      "title_zh": "MOMENT：开源时间序列基础模型家族",
      "authors": [
        "Mononito Goswami",
        "Konrad Szafer",
        "Arjun Choudhry",
        "Yifu Cai",
        "Shuo Li",
        "Artur Dubrawski"
      ],
      "abstract": "We introduce MOMENT, a family of open-source foundation models for\ngeneral-purpose time series analysis. Pre-training large models on time series\ndata is challenging due to (1) the absence of a large and cohesive public time\nseries repository, and (2) diverse time series characteristics which make\nmulti-dataset training onerous. Additionally, (3) experimental benchmarks to\nevaluate these models, especially in scenarios with limited resources, time,\nand supervision, are still in their nascent stages. To address these\nchallenges, we compile a large and diverse collection of public time series,\ncalled the Time series Pile, and systematically tackle time series-specific\nchallenges to unlock large-scale multi-dataset pre-training. Finally, we build\non recent work to design a benchmark to evaluate time series foundation models\non diverse tasks and datasets in limited supervision settings. Experiments on\nthis benchmark demonstrate the effectiveness of our pre-trained models with\nminimal data and task-specific fine-tuning. Finally, we present several\ninteresting empirical observations about large pre-trained time series models.\nPre-trained models (AutonLab/MOMENT-1-large) and Time Series Pile\n(AutonLab/Timeseries-PILE) are available on Huggingface.",
      "tldr_zh": "本研究引入了 MOMENT，一系列开源的时间序列 foundation models，用于通用时间序列分析，旨在解决预训练面临的挑战，如缺乏大型公共数据集和多样化数据特性。研究者编译了 Time series Pile，这是一个大型多样化公共时间序列集合，并系统处理时间序列特定问题以实现大规模多数据集预训练。同时，他们设计了一个基准，用于评估这些模型在有限资源和监督下的表现。实验结果显示，MOMENT 模型在最小数据和任务特定微调下表现出色，并提供了关于大型预训练模型的宝贵经验观察；相关模型和数据集已在 Huggingface 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML'24. This is a revision. See changelog in the\n  Appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.03885v3",
      "published_date": "2024-02-06 10:48:46 UTC",
      "updated_date": "2024-10-10 15:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:54:47.264282"
    },
    {
      "arxiv_id": "2402.03877v3",
      "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Spyridon Mouselinos",
        "Henryk Michalewski",
        "Mateusz Malinowski"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in\nmathematical and algorithmic tasks, yet their geometric reasoning skills are\nunderexplored. We investigate LLMs' abilities in constructive geometric\nproblem-solving one of the most fundamental steps in the development of human\nmathematical reasoning. Our work reveals notable challenges that the\nstate-of-the-art LLMs face in this domain despite many successes in similar\nareas. LLMs exhibit biases in target variable selection and struggle with 2D\nspatial relationships, often misrepresenting and hallucinating objects and\ntheir placements. To this end, we introduce a framework that formulates an\nLLMs-based multi-agents system that enhances their existing reasoning potential\nby conducting an internal dialogue. This work underscores LLMs' current\nlimitations in geometric reasoning and improves geometric reasoning\ncapabilities through self-correction, collaboration, and diverse role\nspecializations.",
      "tldr_zh": "这项研究揭示了大型语言模型 (LLMs) 在几何推理方面的显著缺陷，尽管它们在其他数学任务上表现出色。具体而言，LLMs 在构建性几何问题解决中存在目标变量选择偏差和处理 2D 空间关系困难的问题，常导致对象错误表示和幻觉。为解决这些问题，研究引入了一个基于 LLMs 的多智能体系统，通过内部对话、自我修正、协作以及多样化角色专业化来提升几何推理能力。该框架强调了 LLMs 当前的局限性，并展示了通过合作机制改善其推理潜力的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03877v3",
      "published_date": "2024-02-06 10:37:21 UTC",
      "updated_date": "2024-09-20 09:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:54:59.039021"
    },
    {
      "arxiv_id": "2402.04292v2",
      "title": "AdaFlow: Imitation Learning with Variance-Adaptive Flow-Based Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Xixi Hu",
        "Bo Liu",
        "Xingchao Liu",
        "Qiang Liu"
      ],
      "abstract": "Diffusion-based imitation learning improves Behavioral Cloning (BC) on\nmulti-modal decision-making, but comes at the cost of significantly slower\ninference due to the recursion in the diffusion process. It urges us to design\nefficient policy generators while keeping the ability to generate diverse\nactions. To address this challenge, we propose AdaFlow, an imitation learning\nframework based on flow-based generative modeling. AdaFlow represents the\npolicy with state-conditioned ordinary differential equations (ODEs), which are\nknown as probability flows. We reveal an intriguing connection between the\nconditional variance of their training loss and the discretization error of the\nODEs. With this insight, we propose a variance-adaptive ODE solver that can\nadjust its step size in the inference stage, making AdaFlow an adaptive\ndecision-maker, offering rapid inference without sacrificing diversity.\nInterestingly, it automatically reduces to a one-step generator when the action\ndistribution is uni-modal. Our comprehensive empirical evaluation shows that\nAdaFlow achieves high performance with fast inference speed.",
      "tldr_zh": "本研究提出 AdaFlow，一种基于 flow-based generative modeling 的 imitation learning 框架，旨在解决扩散-based 方法在多模态决策中推理速度慢的问题。AdaFlow 使用 state-conditioned ordinary differential equations (ODEs) 作为概率流表示策略，并揭示训练损失的条件方差与 ODEs 离散化误差之间的联系，从而开发出 variance-adaptive ODE solver，能在推理阶段动态调整步长，实现快速决策同时保持动作多样性。实验结果显示，当动作分布为单模态时，AdaFlow 自动简化为一步生成器，并在综合评估中表现出高性能和高效推理速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeuRIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.04292v2",
      "published_date": "2024-02-06 10:15:38 UTC",
      "updated_date": "2024-11-22 18:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:55:10.474985"
    },
    {
      "arxiv_id": "2402.03855v2",
      "title": "Challenges in Mechanistically Interpreting Model Representations",
      "title_zh": "机制解释模型表示的挑战",
      "authors": [
        "Satvik Golechha",
        "James Dao"
      ],
      "abstract": "Mechanistic interpretability (MI) aims to understand AI models by\nreverse-engineering the exact algorithms neural networks learn. Most works in\nMI so far have studied behaviors and capabilities that are trivial and\ntoken-aligned. However, most capabilities important for safety and trust are\nnot that trivial, which advocates for the study of hidden representations\ninside these networks as the unit of analysis. We formalize representations for\nfeatures and behaviors, highlight their importance and evaluation, and perform\nan exploratory study of dishonesty representations in\n`Mistral-7B-Instruct-v0.1'. We justify that studying representations is an\nimportant and under-studied field, and highlight several challenges that arise\nwhile attempting to do so through currently established methods in MI, showing\ntheir insufficiency and advocating work on new frameworks for the same.",
      "tldr_zh": "该研究探讨了 Mechanistic Interpretability (MI) 在解释模型表示时的挑战，MI 旨在通过逆向工程理解神经网络学到的确切算法，但现有工作主要聚焦于简单且标记对齐的行为，而忽略了安全和信任相关的复杂能力。论文形式化了特征和行为的表示，强调其重要性，并通过对 Mistral-7B-Instruct-v0.1 的不诚实表示进行探索性研究，揭示了当前 MI 方法的不足。作者呼吁开发新的框架，以更好地研究隐藏表示并应对这些挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, ICML 2024 Workshop on Mechanistic Interpretability",
      "pdf_url": "http://arxiv.org/pdf/2402.03855v2",
      "published_date": "2024-02-06 10:06:13 UTC",
      "updated_date": "2024-07-11 18:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:55:23.733877"
    },
    {
      "arxiv_id": "2402.03848v10",
      "title": "ANLS* -- A Universal Document Processing Metric for Generative Large Language Models",
      "title_zh": "ANLS*：用于生成式大型语言模型的通用文档处理指标",
      "authors": [
        "David Peer",
        "Philemon Schöpf",
        "Volckmar Nebendahl",
        "Alexander Rietzler",
        "Sebastian Stabinger"
      ],
      "abstract": "Traditionally, discriminative models have been the predominant choice for\ntasks like document classification and information extraction. These models\nmake predictions that fall into a limited number of predefined classes,\nfacilitating a binary true or false evaluation and enabling the direct\ncalculation of metrics such as the F1 score. However, recent advancements in\ngenerative large language models (GLLMs) have prompted a shift in the field due\nto their enhanced zero-shot capabilities, which eliminate the need for a\ndownstream dataset and computationally expensive fine-tuning. However,\nevaluating GLLMs presents a challenge as the binary true or false evaluation\nused for discriminative models is not applicable to the predictions made by\nGLLMs.\n  This paper introduces a new metric for generative models called ANLS* for\nevaluating a wide variety of tasks, including information extraction and\nclassification tasks. The ANLS* metric extends existing ANLS metrics as a\ndrop-in-replacement and is still compatible with previously reported ANLS\nscores. An evaluation of 7 different datasets, and more than 20 different GLLMs\ntogether with 3 different prompting methods using the ANLS* metric is also\nprovided, demonstrating the importance of the proposed metric.\n  We also benchmark a novel approach to generate prompts for documents, called\nSFT, against other prompting techniques such as LATIN. In almost all cases, SFT\noutperforms other techniques and improves the state-of-the-art, sometimes by as\nmuch as $10$ percentage points.\n  Sources are available at https://github.com/deepopinion/anls_star_metric",
      "tldr_zh": "这篇论文提出ANLS*，一个通用的指标，用于评估生成式大型语言模型(GLLMs)在文档处理任务（如信息提取和分类）中的表现，解决了传统二元真假评估无法适用于GLLMs的挑战。ANLS*是现有ANLS指标的扩展，可直接替换并兼容先前分数，并在7个数据集、20多个GLLMs和3种提示方法上进行了评估。实验结果显示，该指标突显了GLLMs的性能差异，同时作者引入的SFT提示生成方法在几乎所有情况下优于其他技术如LATIN，有时提升高达10个百分点。开源代码可在GitHub获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03848v10",
      "published_date": "2024-02-06 09:50:08 UTC",
      "updated_date": "2025-04-22 14:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:55:36.019531"
    },
    {
      "arxiv_id": "2402.03843v4",
      "title": "A new method for optical steel rope non-destructive damage detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yunqing Bao",
        "Bin Hu"
      ],
      "abstract": "This paper presents a novel algorithm for non-destructive damage detection\nfor steel ropes in high-altitude environments (aerial ropeway). The algorithm\ncomprises two key components: First, a segmentation model named RGBD-UNet is\ndesigned to accurately extract steel ropes from complex backgrounds. This model\nis equipped with the capability to process and combine color and depth\ninformation through the proposed CMA module. Second, a detection model named\nVovNetV3.5 is developed to differentiate between normal and abnormal steel\nropes. It integrates the VovNet architecture with a DBB module to enhance\nperformance. Besides, a novel background augmentation method is proposed to\nenhance the generalization ability of the segmentation model. Datasets\ncontaining images of steel ropes in different scenarios are created for the\ntraining and testing of both the segmentation and detection models. Experiments\ndemonstrate a significant improvement over baseline models. On the proposed\ndataset, the highest accuracy achieved by the detection model reached 0.975,\nand the maximum F-measure achieved by the segmentation model reached 0.948.",
      "tldr_zh": "本论文提出了一种新型光学钢绳无损损伤检测算法，针对高空环境（如空中缆车）中的钢绳损伤问题。该算法包括两个关键组件：RGBD-UNet 分割模型，通过 CMA module 处理和结合颜色与深度信息来精确提取钢绳；以及 VovNetV3.5 检测模型，整合 VovNet 架构和 DBB module 以区分正常和异常钢绳。此外，该方法引入了新型背景增强技术来提升分割模型的泛化能力，并在自建数据集上进行训练和测试。实验结果显示，该算法在检测模型上最高准确率达0.975，在分割模型上最大 F-measure 达0.948，显著优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03843v4",
      "published_date": "2024-02-06 09:39:05 UTC",
      "updated_date": "2024-09-22 12:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:55:48.097859"
    },
    {
      "arxiv_id": "2402.04291v2",
      "title": "BiLLM: Pushing the Limit of Post-Training Quantization for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Huang",
        "Yangdong Liu",
        "Haotong Qin",
        "Ying Li",
        "Shiming Zhang",
        "Xianglong Liu",
        "Michele Magno",
        "Xiaojuan Qi"
      ],
      "abstract": "Pretrained large language models (LLMs) exhibit exceptional general language\nprocessing capabilities but come with significant demands on memory and\ncomputational resources. As a powerful compression technology, binarization can\nextremely reduce model weights to a mere 1 bit, lowering the expensive\ncomputation and memory requirements. However, existing quantization techniques\nfall short of maintaining LLM performance under ultra-low bit-widths. In\nresponse to this challenge, we present BiLLM, a groundbreaking 1-bit\npost-training quantization scheme tailored for pretrained LLMs. Based on the\nweight distribution of LLMs, BiLLM first identifies and structurally selects\nsalient weights, and minimizes the compression loss through an effective binary\nresidual approximation strategy. Moreover, considering the bell-shaped\ndistribution of the non-salient weights, we propose an optimal splitting search\nto group and binarize them accurately. BiLLM achieving for the first time\nhigh-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bit\nweights across various LLMs families and evaluation metrics, outperforms SOTA\nquantization methods of LLM by significant margins. Moreover, BiLLM enables the\nbinarization process of the LLM with 7 billion weights within 0.5 hours on a\nsingle GPU, demonstrating satisfactory time efficiency. Our code is available\nat https://github.com/Aaronhuang-778/BiLLM.",
      "tldr_zh": "该论文提出BiLLM，一种创新的1-bit后训练量化方案，旨在解决大型语言模型(LLMs)的高资源需求问题，通过识别显著权重并采用二进制残差逼近策略来最小化压缩损失，同时针对非显著权重的钟形分布使用最优分割搜索进行精确分组和二值化。BiLLM在各种LLMs家族上实现了高精度推理，例如LLaMA2-70B的perplexity仅为8.41，且仅用1.08-bit权重就显著超越现有最先进量化方法。实验还证明，BiLLM能在单块GPU上在0.5小时内处理70亿参数的模型，展示了高效的时间性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.04291v2",
      "published_date": "2024-02-06 09:26:34 UTC",
      "updated_date": "2024-05-15 13:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:56:01.140009"
    },
    {
      "arxiv_id": "2402.03824v4",
      "title": "A call for embodied AI",
      "title_zh": "呼吁具身 AI",
      "authors": [
        "Giuseppe Paolo",
        "Jonas Gonzalez-Billandon",
        "Balázs Kégl"
      ],
      "abstract": "We propose Embodied AI as the next fundamental step in the pursuit of\nArtificial General Intelligence, juxtaposing it against current AI\nadvancements, particularly Large Language Models. We traverse the evolution of\nthe embodiment concept across diverse fields - philosophy, psychology,\nneuroscience, and robotics - to highlight how EAI distinguishes itself from the\nclassical paradigm of static learning. By broadening the scope of Embodied AI,\nwe introduce a theoretical framework based on cognitive architectures,\nemphasizing perception, action, memory, and learning as essential components of\nan embodied agent. This framework is aligned with Friston's active inference\nprinciple, offering a comprehensive approach to EAI development. Despite the\nprogress made in the field of AI, substantial challenges, such as the\nformulation of a novel AI learning theory and the innovation of advanced\nhardware, persist. Our discussion lays down a foundational guideline for future\nEmbodied AI research. Highlighting the importance of creating Embodied AI\nagents capable of seamless communication, collaboration, and coexistence with\nhumans and other intelligent entities within real-world environments, we aim to\nsteer the AI community towards addressing the multifaceted challenges and\nseizing the opportunities that lie ahead in the quest for AGI.",
      "tldr_zh": "本文呼吁将 Embodied AI 视为追求 Artificial General Intelligence (AGI) 的下一个关键步骤，与当前 Large Language Models 等静态学习范式形成对比，通过回顾哲学、心理学、神经科学和机器人领域的演变来阐述其独特价值。作者引入一个基于认知架构的理论框架，强调感知、行动、记忆和学习作为 Embodied AI 代理的核心组件，并与 Friston's active inference 原则对齐，以提供全面的开发方法。尽管存在制定新型 AI 学习理论和创新硬件等挑战，该框架为未来研究奠定基础，旨在推动创建能与人类无缝沟通、协作和共存的智能实体。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in ICML 2024 Position paper track",
      "pdf_url": "http://arxiv.org/pdf/2402.03824v4",
      "published_date": "2024-02-06 09:11:20 UTC",
      "updated_date": "2024-09-13 13:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:56:13.913806"
    },
    {
      "arxiv_id": "2402.03822v2",
      "title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
      "title_zh": "RevOrder：一种用于增强语言模型算术运算的新颖方法",
      "authors": [
        "Si Shen",
        "Peijun Shen",
        "Danhao Zhu"
      ],
      "abstract": "This paper presents RevOrder, a novel technique aimed at improving arithmetic\noperations in large language models (LLMs) by reversing the output digits in\naddition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks.\nOur method significantly reduces the Count of Sequential Intermediate Digits\n(CSID) to $\\mathcal{O}(1)$, a new metric we introduce to assess equation\ncomplexity. Through comprehensive testing, RevOrder not only achieves perfect\naccuracy in basic arithmetic operations but also substantially boosts LLM\nperformance in division tasks, particularly with large numbers where\ntraditional models struggle. Implementation of RevOrder is cost-effective for\nboth training and inference phases. Moreover, applying RevOrder to fine-tune\nthe LLaMA2-7B model on the GSM8K math task results in a considerable\nimprovement, reducing equation calculation errors by 46% and increasing overall\nscores from 41.6 to 44.4.",
      "tldr_zh": "本文提出了一种名为 RevOrder 的新方法，用于提升大型语言模型 (LLMs) 在加法、减法和 nD by 1D 乘法等算术运算中的性能，通过反转输出数字将我们引入的 CSID 指标减少到 O(1)，从而显著降低运算复杂度。实验结果显示，RevOrder 在基本算术任务中实现完美准确率，并在除法任务上，尤其是大数运算中，大幅提升模型表现。应用该方法微调 LLaMA2-7B 模型后，在 GSM8K 数学任务中，算式计算错误减少 46%，整体分数从 41.6 提高到 44.4，且在训练和推理阶段的实现成本较低。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03822v2",
      "published_date": "2024-02-06 09:10:35 UTC",
      "updated_date": "2024-02-24 01:11:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:56:27.754678"
    },
    {
      "arxiv_id": "2402.03807v2",
      "title": "SEABO: A Simple Search-Based Method for Offline Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiafei Lyu",
        "Xiaoteng Ma",
        "Le Wan",
        "Runze Liu",
        "Xiu Li",
        "Zongqing Lu"
      ],
      "abstract": "Offline reinforcement learning (RL) has attracted much attention due to its\nability in learning from static offline datasets and eliminating the need of\ninteracting with the environment. Nevertheless, the success of offline RL\nrelies heavily on the offline transitions annotated with reward labels. In\npractice, we often need to hand-craft the reward function, which is sometimes\ndifficult, labor-intensive, or inefficient. To tackle this challenge, we set\nour focus on the offline imitation learning (IL) setting, and aim at getting a\nreward function based on the expert data and unlabeled data. To that end, we\npropose a simple yet effective search-based offline IL method, tagged SEABO.\nSEABO allocates a larger reward to the transition that is close to its closest\nneighbor in the expert demonstration, and a smaller reward otherwise, all in an\nunsupervised learning manner. Experimental results on a variety of D4RL\ndatasets indicate that SEABO can achieve competitive performance to offline RL\nalgorithms with ground-truth rewards, given only a single expert trajectory,\nand can outperform prior reward learning and offline IL methods across many\ntasks. Moreover, we demonstrate that SEABO also works well if the expert\ndemonstrations contain only observations. Our code is publicly available at\nhttps://github.com/dmksjfl/SEABO.",
      "tldr_zh": "该研究针对离线强化学习（Offline RL）中手动设计奖励函数的难题，提出了一种简单有效的基于搜索的离线模仿学习（Offline Imitation Learning）方法，名为 SEABO。SEABO 通过无监督学习方式，将奖励分配给与专家演示最近邻居相似的过渡（transitions），否则分配较小奖励，从而自动生成奖励函数。在 D4RL 数据集上的实验显示，SEABO 仅需一个专家轨迹即可与使用真实奖励的离线 RL 算法媲美，并在多个任务中优于现有奖励学习和离线 IL 方法；此外，即使专家演示仅包含观察数据，该方法也能表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in ICLR2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03807v2",
      "published_date": "2024-02-06 08:48:01 UTC",
      "updated_date": "2024-02-21 05:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:56:36.509228"
    },
    {
      "arxiv_id": "2402.03804v1",
      "title": "ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyan Zhang",
        "Yixin Song",
        "Guanghui Yu",
        "Xu Han",
        "Yankai Lin",
        "Chaojun Xiao",
        "Chenyang Song",
        "Zhiyuan Liu",
        "Zeyu Mi",
        "Maosong Sun"
      ],
      "abstract": "Sparse computation offers a compelling solution for the inference of Large\nLanguage Models (LLMs) in low-resource scenarios by dynamically skipping the\ncomputation of inactive neurons. While traditional approaches focus on\nReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of\nsparse LLMs beyond zero activation values. We introduce a general method that\ndefines neuron activation through neuron output magnitudes and a tailored\nmagnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse\nactivation. To find the most efficient activation function for sparse\ncomputation, we propose a systematic framework to examine the sparsity of LLMs\nfrom three aspects: the trade-off between sparsity and performance, the\npredictivity of sparsity, and the hardware affinity. We conduct thorough\nexperiments on LLMs utilizing different activation functions, including ReLU,\nSwiGLU, ReGLU, and ReLU$^2$. The results indicate that models employing\nReLU$^2$ excel across all three evaluation aspects, highlighting its potential\nas an efficient activation function for sparse LLMs. We will release the code\nto facilitate future research.",
      "tldr_zh": "该论文探讨了稀疏计算在低资源场景下大语言模型（LLMs）的推理应用，引入一种通过神经元输出幅度和自定义幅度阈值定义激活的方法，以扩展稀疏LLMs的范围，证明非ReLU模型也能实现稀疏性。作者提出一个系统框架，从稀疏性与性能权衡、稀疏性的可预测性以及硬件亲和性三个方面评估不同激活函数，包括ReLU、SwiGLU、ReGLU和ReLU²。实验结果表明，采用ReLU²的模型在所有评估方面表现出色，证明其作为高效激活函数的潜力，并将发布代码以支持进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03804v1",
      "published_date": "2024-02-06 08:45:51 UTC",
      "updated_date": "2024-02-06 08:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:56:50.104697"
    },
    {
      "arxiv_id": "2402.04290v1",
      "title": "CasCast: Skillful High-resolution Precipitation Nowcasting via Cascaded Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Junchao Gong",
        "Lei Bai",
        "Peng Ye",
        "Wanghan Xu",
        "Na Liu",
        "Jianhua Dai",
        "Xiaokang Yang",
        "Wanli Ouyang"
      ],
      "abstract": "Precipitation nowcasting based on radar data plays a crucial role in extreme\nweather prediction and has broad implications for disaster management. Despite\nprogresses have been made based on deep learning, two key challenges of\nprecipitation nowcasting are not well-solved: (i) the modeling of complex\nprecipitation system evolutions with different scales, and (ii) accurate\nforecasts for extreme precipitation. In this work, we propose CasCast, a\ncascaded framework composed of a deterministic and a probabilistic part to\ndecouple the predictions for mesoscale precipitation distributions and\nsmall-scale patterns. Then, we explore training the cascaded framework at the\nhigh resolution and conducting the probabilistic modeling in a low dimensional\nlatent space with a frame-wise-guided diffusion transformer for enhancing the\noptimization of extreme events while reducing computational costs. Extensive\nexperiments on three benchmark radar precipitation datasets show that CasCast\nachieves competitive performance. Especially, CasCast significantly surpasses\nthe baseline (up to +91.8%) for regional extreme-precipitation nowcasting.",
      "tldr_zh": "该论文提出CasCast框架，用于高分辨率降水预报（precipitation nowcasting），旨在解决复杂降水系统演化建模和极端降水准确预测的两个关键挑战。CasCast采用级联框架（cascaded framework），包括确定性和概率性部分，以分离中尺度降水分布和小尺度模式的预测，并在低维潜在空间中使用frame-wise-guided diffusion transformer进行概率建模，从而提升极端事件优化并降低计算成本。在三个基准雷达降水数据集上的实验显示，CasCast在区域极端降水预报上比基线模型提升高达91.8%，展现出显著的性能优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04290v1",
      "published_date": "2024-02-06 08:30:47 UTC",
      "updated_date": "2024-02-06 08:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:57:00.344104"
    },
    {
      "arxiv_id": "2402.03796v1",
      "title": "Face Detection: Present State and Research Directions",
      "title_zh": "人脸检测：现状和研究方向",
      "authors": [
        "Purnendu Prabhat",
        "Himanshu Gupta",
        "Ajeet Kumar Vishwakarma"
      ],
      "abstract": "The majority of computer vision applications that handle images featuring\nhumans use face detection as a core component. Face detection still has issues,\ndespite much research on the topic. Face detection's accuracy and speed might\nyet be increased. This review paper shows the progress made in this area as\nwell as the substantial issues that still need to be tackled. The paper\nprovides research directions that can be taken up as research projects in the\nfield of face detection.",
      "tldr_zh": "这篇论文回顾了人脸检测（Face Detection）作为计算机视觉中处理人类图像的核心组件的现状和进展。尽管已有大量研究，但人脸检测在准确性和速度方面仍存在显著问题，需要进一步优化。论文总结了这些关键挑战，并提出了潜在的研究方向，以指导未来项目。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03796v1",
      "published_date": "2024-02-06 08:29:39 UTC",
      "updated_date": "2024-02-06 08:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:57:11.539564"
    },
    {
      "arxiv_id": "2402.03792v1",
      "title": "No-Regret Reinforcement Learning in Smooth MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Maran",
        "Alberto Maria Metelli",
        "Matteo Papini",
        "Marcello Restell"
      ],
      "abstract": "Obtaining no-regret guarantees for reinforcement learning (RL) in the case of\nproblems with continuous state and/or action spaces is still one of the major\nopen challenges in the field. Recently, a variety of solutions have been\nproposed, but besides very specific settings, the general problem remains\nunsolved. In this paper, we introduce a novel structural assumption on the\nMarkov decision processes (MDPs), namely $\\nu-$smoothness, that generalizes\nmost of the settings proposed so far (e.g., linear MDPs and Lipschitz MDPs). To\nface this challenging scenario, we propose two algorithms for regret\nminimization in $\\nu-$smooth MDPs. Both algorithms build upon the idea of\nconstructing an MDP representation through an orthogonal feature map based on\nLegendre polynomials. The first algorithm, \\textsc{Legendre-Eleanor}, archives\nthe no-regret property under weaker assumptions but is computationally\ninefficient, whereas the second one, \\textsc{Legendre-LSVI}, runs in polynomial\ntime, although for a smaller class of problems. After analyzing their regret\nproperties, we compare our results with state-of-the-art ones from RL theory,\nshowing that our algorithms achieve the best guarantees.",
      "tldr_zh": "本研究解决了强化学习(Reinforcement Learning, RL)中连续状态和/或动作空间的无后悔(No-Regret)保证难题，引入了新的结构假设ν-smoothness，以泛化现有的线性MDPs和Lipschitz MDPs设置。研究者提出两个算法：Legendre-Eleanor，利用基于Legendre多项式的正交特征映射构建MDP表示，实现无后悔属性但计算效率较低；以及Legendre-LSVI，该算法运行时间多项式，但适用于更小的问题子集。实验分析显示，这两个算法在后悔最小化方面提供了最先进的保证，超越了现有RL理论中的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03792v1",
      "published_date": "2024-02-06 08:18:14 UTC",
      "updated_date": "2024-02-06 08:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:57:25.743249"
    },
    {
      "arxiv_id": "2402.03784v2",
      "title": "AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction",
      "title_zh": "AirPhyNet：利用物理指导神经网络进行空气质量预测",
      "authors": [
        "Kethmi Hirushini Hettige",
        "Jiahao Ji",
        "Shili Xiang",
        "Cheng Long",
        "Gao Cong",
        "Jingyuan Wang"
      ],
      "abstract": "Air quality prediction and modelling plays a pivotal role in public health\nand environment management, for individuals and authorities to make informed\ndecisions. Although traditional data-driven models have shown promise in this\ndomain, their long-term prediction accuracy can be limited, especially in\nscenarios with sparse or incomplete data and they often rely on black-box deep\nlearning structures that lack solid physical foundation leading to reduced\ntransparency and interpretability in predictions. To address these limitations,\nthis paper presents a novel approach named Physics guided Neural Network for\nAir Quality Prediction (AirPhyNet). Specifically, we leverage two\nwell-established physics principles of air particle movement (diffusion and\nadvection) by representing them as differential equation networks. Then, we\nutilize a graph structure to integrate physics knowledge into a neural network\narchitecture and exploit latent representations to capture spatio-temporal\nrelationships within the air quality data. Experiments on two real-world\nbenchmark datasets demonstrate that AirPhyNet outperforms state-of-the-art\nmodels for different testing scenarios including different lead time (24h, 48h,\n72h), sparse data and sudden change prediction, achieving reduction in\nprediction errors up to 10%. Moreover, a case study further validates that our\nmodel captures underlying physical processes of particle movement and generates\naccurate predictions with real physical meaning.",
      "tldr_zh": "本研究针对空气质量预测中的问题，提出了一种名为 AirPhyNet 的物理指导神经网络框架，以解决传统数据驱动模型在数据稀疏、长期预测准确性不足以及缺乏物理基础的可解释性问题。具体而言，AirPhyNet 利用空气颗粒运动的物理原理（diffusion 和 advection）表示为 differential equation networks，并通过 graph structure 整合物理知识和潜在表示来捕获时空关系(spatio-temporal relationships)。实验在两个真实世界基准数据集上显示，AirPhyNet 在不同预测时长（24h、48h、72h）、稀疏数据和突发变化场景中，相比现有模型将预测错误降低高达10%。此外，案例研究证实该模型能捕捉颗粒运动的底层物理过程，并生成具有真实物理意义的预测结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 12th International Conference on Learning\n  Representations (ICLR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.03784v2",
      "published_date": "2024-02-06 07:55:54 UTC",
      "updated_date": "2024-02-07 02:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:57:37.968396"
    },
    {
      "arxiv_id": "2402.03782v1",
      "title": "Soft Prompt Tuning for Cross-Lingual Transfer: When Less is More",
      "title_zh": "翻译失败",
      "authors": [
        "Fred Philippy",
        "Siwen Guo",
        "Shohreh Haddadan",
        "Cedric Lothritz",
        "Jacques Klein",
        "Tegawendé F. Bissyandé"
      ],
      "abstract": "Soft Prompt Tuning (SPT) is a parameter-efficient method for adapting\npre-trained language models (PLMs) to specific tasks by inserting learnable\nembeddings, or soft prompts, at the input layer of the PLM, without modifying\nits parameters. This paper investigates the potential of SPT for cross-lingual\ntransfer. Unlike previous studies on SPT for cross-lingual transfer that often\nfine-tune both the soft prompt and the model parameters, we adhere to the\noriginal intent of SPT by keeping the model parameters frozen and only training\nthe soft prompt. This does not only reduce the computational cost and storage\noverhead of full-model fine-tuning, but we also demonstrate that this very\nparameter efficiency intrinsic to SPT can enhance cross-lingual transfer\nperformance to linguistically distant languages. Moreover, we explore how\ndifferent factors related to the prompt, such as the length or its\nreparameterization, affect cross-lingual transfer performance.",
      "tldr_zh": "本文研究了Soft Prompt Tuning (SPT)，这是一种参数高效的方法，用于适应预训练语言模型 (PLMs) 以实现跨语言转移，仅通过训练输入层的可学习嵌入（soft prompts），而保持模型参数冻结。相比于传统方法，这种策略显著降低了计算成本和存储开销，同时证明了SPT能提升对语言距离较远语言的转移性能。作者还探讨了prompt的长度和重新参数化等因素对跨语言转移效果的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 1st Workshop on Modular and Open Multilingual NLP\n  (co-located with EACL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.03782v1",
      "published_date": "2024-02-06 07:52:30 UTC",
      "updated_date": "2024-02-06 07:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:57:49.450891"
    },
    {
      "arxiv_id": "2402.03781v6",
      "title": "MolTC: Towards Molecular Relational Modeling In Language Models",
      "title_zh": "MolTC：面向语言模型中的分子关系建模",
      "authors": [
        "Junfeng Fang",
        "Shuai Zhang",
        "Chang Wu",
        "Zhengyi Yang",
        "Zhiyuan Liu",
        "Sihang Li",
        "Kun Wang",
        "Wenjie Du",
        "Xiang Wang"
      ],
      "abstract": "Molecular Relational Learning (MRL), aiming to understand interactions\nbetween molecular pairs, plays a pivotal role in advancing biochemical\nresearch. Recently, the adoption of large language models (LLMs), known for\ntheir vast knowledge repositories and advanced logical inference capabilities,\nhas emerged as a promising way for efficient and effective MRL. Despite their\npotential, these methods predominantly rely on the textual data, thus not fully\nharnessing the wealth of structural information inherent in molecular graphs.\nMoreover, the absence of a unified framework exacerbates the issue of\ninformation underutilization, as it hinders the sharing of interaction\nmechanism learned across diverse datasets. To address these challenges, this\nwork proposes a novel LLM-based multi-modal framework for Molecular inTeraction\nprediction following Chain-of-Thought (CoT) theory, termed MolTC, which\neffectively integrate graphical information of two molecules in pair. To train\nMolTC efficiently, we introduce a Multi-hierarchical CoT concept to refine its\ntraining paradigm, and conduct a comprehensive Molecular Interactive\nInstructions dataset for the development of biochemical LLMs involving MRL. Our\nexperiments, conducted across various datasets involving over 4,000,000\nmolecular pairs, exhibit the superiority of our method over current GNN and\nLLM-based baselines. Code is available at https://github.com/MangoKiller/MolTC.",
      "tldr_zh": "本研究针对 Molecular Relational Learning (MRL) 的挑战，提出了一种基于大型语言模型 (LLMs) 的多模态框架 MolTC，利用 Chain-of-Thought (CoT) 理论来整合分子对的图形信息，从而更好地理解分子互动。\nMolTC 引入 Multi-hierarchical CoT 概念来优化训练过程，并构建了 Molecular Interactive Instructions 数据集，以解决信息利用不足和框架不统一的问题。\n实验在超过 4,000,000 个分子对的数据集上证明，MolTC 优于现有的 GNN 和 LLM-based 基线方法，为生化研究中的分子关系建模提供了高效解决方案。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03781v6",
      "published_date": "2024-02-06 07:51:56 UTC",
      "updated_date": "2024-06-10 08:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:58:03.239143"
    },
    {
      "arxiv_id": "2402.03780v3",
      "title": "Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification",
      "title_zh": "翻译失败",
      "authors": [
        "Géraud Faye",
        "Benjamin Icard",
        "Morgane Casanova",
        "Julien Chanson",
        "François Maine",
        "François Bancilhon",
        "Guillaume Gadek",
        "Guillaume Gravier",
        "Paul Égré"
      ],
      "abstract": "This paper investigates the language of propaganda and its stylistic\nfeatures. It presents the PPN dataset, standing for Propagandist Pseudo-News, a\nmultisource, multilingual, multimodal dataset composed of news articles\nextracted from websites identified as propaganda sources by expert agencies. A\nlimited sample from this set was randomly mixed with papers from the regular\nFrench press, and their URL masked, to conduct an annotation-experiment by\nhumans, using 11 distinct labels. The results show that human annotators were\nable to reliably discriminate between the two types of press across each of the\nlabels. We propose different NLP techniques to identify the cues used by the\nannotators, and to compare them with machine classification. They include the\nanalyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to\nserve as a baseline, and four different classifiers: two RoBERTa-based models,\nCATS using syntax, and one XGBoost combining syntactic and semantic features.",
      "tldr_zh": "这篇论文分析了宣传语言的风格特征，引入了 PPN dataset（Propagandist Pseudo-News），这是一个多源、多语言、多模态数据集，包含从宣传网站提取的新闻文章，并通过混合实验进行人类标注。实验使用 11 个标签，让人类标注者区分宣传新闻和常规法国新闻，结果显示标注者能可靠地区分两种类型。论文比较了人类标注与机器分类，采用多种 NLP 技术如 VAGO 分析器（测量话语模糊性和主观性）、TF-IDF 基线、RoBERTa 模型、CATS（基于语法）和 XGBoost（结合语法与语义特征），以识别风格线索。整体结果为宣传检测提供了宝贵的洞见和基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper to appear in the EACL 2024 Proceedings of the Third Workshop on\n  Understanding Implicit and Underspecified Language (UnImplicit 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.03780v3",
      "published_date": "2024-02-06 07:51:54 UTC",
      "updated_date": "2024-02-26 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:58:15.099304"
    },
    {
      "arxiv_id": "2402.03776v4",
      "title": "Large Language Models As MOOCs Graders",
      "title_zh": "大型语言模型作为 MOOCs 评分者",
      "authors": [
        "Shahriar Golchin",
        "Nikhil Garuda",
        "Christopher Impey",
        "Matthew Wenger"
      ],
      "abstract": "Massive open online courses (MOOCs) unlock the doors to free education for\nanyone around the globe with access to a computer and the internet. Despite\nthis democratization of learning, the massive enrollment in these courses means\nit is almost impossible for one instructor to assess every student's writing\nassignment. As a result, peer grading, often guided by a straightforward\nrubric, is the method of choice. While convenient, peer grading often falls\nshort in terms of reliability and validity. In this study, using 18 distinct\nsettings, we explore the feasibility of leveraging large language models (LLMs)\nto replace peer grading in MOOCs. Specifically, we focus on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses:\nIntroductory Astronomy, Astrobiology, and the History and Philosophy of\nAstronomy. To instruct LLMs, we use three different prompts based on a variant\nof the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique:\nZero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoT\nin conjunction with both instructor-formulated answers and rubrics; and\nZero-shot-CoT with instructor-offered correct answers and LLM-generated\nrubrics. Our results show that Zero-shot-CoT, when integrated with\ninstructor-provided answers and rubrics, produces grades that are more aligned\nwith those assigned by instructors compared to peer grading. However, the\nHistory and Philosophy of Astronomy course proves to be more challenging in\nterms of grading as opposed to other courses. Finally, our study reveals a\npromising direction for automating grading systems for MOOCs, especially in\nsubjects with well-defined rubrics.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs），如 GPT-4 和 GPT-3.5，来替代 MOOCs 中的同行评阅问题，以提高作业评估的可靠性和有效性。研究者通过三种基于 Zero-shot Chain-of-Thought (Zero-shot-CoT) 提示方法，在三个课程（Introductory Astronomy、Astrobiology 和 History and Philosophy of Astronomy）中测试了 LLMs 的表现，包括结合教师提供的正确答案、评分标准或 LLM 生成的评分标准。结果显示，Zero-shot-CoT 与教师答案和评分标准结合时，评分结果更接近教师评估，比同行评阅更准确，但哲学相关课程的评分难度较高。该方法为 MOOCs 的自动化评分系统提供了可行路径，尤其适用于有明确评分标准的科目。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "v1.3 preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.03776v4",
      "published_date": "2024-02-06 07:43:07 UTC",
      "updated_date": "2024-03-01 04:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:58:27.686100"
    },
    {
      "arxiv_id": "2402.03774v2",
      "title": "Learning a Decision Tree Algorithm with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yufan Zhuang",
        "Liyuan Liu",
        "Chandan Singh",
        "Jingbo Shang",
        "Jianfeng Gao"
      ],
      "abstract": "Decision trees are renowned for their ability to achieve high predictive\nperformance while remaining interpretable, especially on tabular data.\nTraditionally, they are constructed through recursive algorithms, where they\npartition the data at every node in a tree. However, identifying a good\npartition is challenging, as decision trees optimized for local segments may\nnot yield global generalization. To address this, we introduce MetaTree, a\ntransformer-based model trained via meta-learning to directly produce strong\ndecision trees. Specifically, we fit both greedy decision trees and globally\noptimized decision trees on a large number of datasets, and train MetaTree to\nproduce only the trees that achieve strong generalization performance. This\ntraining enables MetaTree to emulate these algorithms and intelligently adapt\nits strategy according to the context, thereby achieving superior\ngeneralization performance.",
      "tldr_zh": "决策树（decision trees）在处理表格数据时以高预测性能和可解释性著称，但传统递归算法可能因局部优化而影响全局泛化。论文引入 MetaTree，一种基于 Transformers 的模型，通过 meta-learning 训练，直接生成性能强的决策树。具体而言，MetaTree 在大量数据集上拟合贪婪决策树和全局优化决策树，并学习仅输出那些泛化性能优秀的树，从而智能适应上下文并实现优越的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03774v2",
      "published_date": "2024-02-06 07:40:53 UTC",
      "updated_date": "2024-08-23 19:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:58:37.267201"
    },
    {
      "arxiv_id": "2402.03766v1",
      "title": "MobileVLM V2: Faster and Stronger Baseline for Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxiang Chu",
        "Limeng Qiao",
        "Xinyu Zhang",
        "Shuang Xu",
        "Fei Wei",
        "Yang Yang",
        "Xiaofei Sun",
        "Yiming Hu",
        "Xinyang Lin",
        "Bo Zhang",
        "Chunhua Shen"
      ],
      "abstract": "We introduce MobileVLM V2, a family of significantly improved vision language\nmodels upon MobileVLM, which proves that a delicate orchestration of novel\narchitectural design, an improved training scheme tailored for mobile VLMs, and\nrich high-quality dataset curation can substantially benefit VLMs' performance.\nSpecifically, MobileVLM V2 1.7B achieves better or on-par performance on\nstandard VLM benchmarks compared with much larger VLMs at the 3B scale.\nNotably, our 3B model outperforms a large variety of VLMs at the 7B+ scale. Our\nmodels will be released at https://github.com/Meituan-AutoML/MobileVLM .",
      "tldr_zh": "我们介绍了 MobileVLM V2，这是一个改进的视觉语言模型系列，通过新型架构设计、针对移动 VLM 的优化训练方案以及丰富的高质量数据集，显著提升了模型性能。具体而言，MobileVLM V2 1.7B 在标准 VLM 基准上表现优于或相当于是 3B 规模的模型，而其 3B 模型甚至超过了 7B+ 规模的各种 VLM。模型已在 GitHub 上开源发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03766v1",
      "published_date": "2024-02-06 07:16:36 UTC",
      "updated_date": "2024-02-06 07:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:58:49.573749"
    },
    {
      "arxiv_id": "2402.03755v1",
      "title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model",
      "title_zh": "QuantAgent：通过自提升大型语言模型寻求交易中的圣杯",
      "authors": [
        "Saizhuo Wang",
        "Hang Yuan",
        "Lionel M. Ni",
        "Jian Guo"
      ],
      "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and\ntackle real-world challenges have gained prominence.However, tailoring these\nagents for specialized domains like quantitative investment remains a\nformidable task. The core challenge involves efficiently building and\nintegrating a domain-specific knowledge base for the agent's learning process.\nThis paper introduces a principled framework to address this challenge,\ncomprising a two-layer loop.In the inner loop, the agent refines its responses\nby drawing from its knowledge base, while in the outer loop, these responses\nare tested in real-world scenarios to automatically enhance the knowledge base\nwith new insights.We demonstrate that our approach enables the agent to\nprogressively approximate optimal behavior with provable\nefficiency.Furthermore, we instantiate this framework through an autonomous\nagent for mining trading signals named QuantAgent. Empirical results showcase\nQuantAgent's capability in uncovering viable financial signals and enhancing\nthe accuracy of financial forecasts.",
      "tldr_zh": "本论文提出一个原则性框架，用于构建基于Large Language Models (LLMs)的自主代理，以应对量化投资领域的挑战，该框架强调高效构建和整合领域特定知识库。框架采用两层循环结构：在内层循环中，代理从知识库中提取信息来优化响应；在外层循环中，通过真实场景测试自动增强知识库，从而使代理逐步逼近最优行为，并证明其效率。论文通过实例QuantAgent展示了其在挖掘交易信号方面的能力，实证结果表明QuantAgent能发现可行的金融信号并显著提高金融预测的准确性。",
      "categories": [
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03755v1",
      "published_date": "2024-02-06 06:47:14 UTC",
      "updated_date": "2024-02-06 06:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:59:02.018836"
    },
    {
      "arxiv_id": "2402.03750v1",
      "title": "Digital Twin Mobility Profiling: A Spatio-Temporal Graph Learning Approach",
      "title_zh": "数字孪生移动性剖析：一种时空图学习方法",
      "authors": [
        "Xin Chen",
        "Mingliang Hou",
        "Tao Tang",
        "Achhardeep Kaur",
        "Feng Xia"
      ],
      "abstract": "With the arrival of the big data era, mobility profiling has become a viable\nmethod of utilizing enormous amounts of mobility data to create an intelligent\ntransportation system. Mobility profiling can extract potential patterns in\nurban traffic from mobility data and is critical for a variety of\ntraffic-related applications. However, due to the high level of complexity and\nthe huge amount of data, mobility profiling faces huge challenges. Digital Twin\n(DT) technology paves the way for cost-effective and performance-optimised\nmanagement by digitally creating a virtual representation of the network to\nsimulate its behaviour. In order to capture the complex spatio-temporal\nfeatures in traffic scenario, we construct alignment diagrams to assist in\ncompleting the spatio-temporal correlation representation and design dilated\nalignment convolution network (DACN) to learn the fine-grained correlations,\ni.e., spatio-temporal interactions. We propose a digital twin mobility\nprofiling (DTMP) framework to learn node profiles on a mobility network DT\nmodel. Extensive experiments have been conducted upon three real-world\ndatasets. Experimental results demonstrate the effectiveness of DTMP.",
      "tldr_zh": "本研究探讨了利用大数据进行流动性建模（mobility profiling），以提取城市交通模式并支持智能交通系统，但面临数据复杂性和海量挑战。作者提出digital twin mobility profiling (DTMP)框架，通过构建alignment diagrams辅助时空相关性表示，并设计dilated alignment convolution network (DACN)来学习细粒度的时空交互特征。实验在三个真实数据集上验证了DTMP的有效性，为优化交通管理提供了高效方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "68T09, 68T30, 68U35",
        "I.2.6; I.2.4; H.1.2"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03750v1",
      "published_date": "2024-02-06 06:37:43 UTC",
      "updated_date": "2024-02-06 06:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:59:13.500912"
    },
    {
      "arxiv_id": "2402.05970v1",
      "title": "Modeling Spatio-temporal Dynamical Systems with Neural Discrete Learning and Levels-of-Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Wang",
        "Hao Wu",
        "Guibin Zhang",
        "Junfeng Fang",
        "Yuxuan Liang",
        "Yuankai Wu",
        "Roger Zimmermann",
        "Yang Wang"
      ],
      "abstract": "In this paper, we address the issue of modeling and estimating changes in the\nstate of the spatio-temporal dynamical systems based on a sequence of\nobservations like video frames. Traditional numerical simulation systems depend\nlargely on the initial settings and correctness of the constructed partial\ndifferential equations (PDEs). Despite recent efforts yielding significant\nsuccess in discovering data-driven PDEs with neural networks, the limitations\nposed by singular scenarios and the absence of local insights prevent them from\nperforming effectively in a broader real-world context. To this end, this paper\npropose the universal expert module -- that is, optical flow estimation\ncomponent, to capture the evolution laws of general physical processes in a\ndata-driven fashion. To enhance local insight, we painstakingly design a\nfiner-grained physical pipeline, since local characteristics may be influenced\nby various internal contextual information, which may contradict the\nmacroscopic properties of the whole system. Further, we harness currently\npopular neural discrete learning to unveil the underlying important features in\nits latent space, this process better injects interpretability, which can help\nus obtain a powerful prior over these discrete random variables. We conduct\nextensive experiments and ablations to demonstrate that the proposed framework\nachieves large performance margins, compared with the existing SOTA baselines.",
      "tldr_zh": "本论文针对基于观测序列（如视频帧）的时空动态系统建模问题，提出了一种新框架，以克服传统PDEs依赖和现有数据驱动方法的局限，如单一场景处理和缺乏局部洞察。框架引入光学流估计作为通用专家模块，结合细粒度的物理管道来捕获物理过程的演化规律，并通过neural discrete learning揭示潜在空间的重要特征，从而提升模型的可解释性和对离散随机变量的先验知识。实验结果显示，该框架在多个场景中比现有SOTA基线取得了显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05970v1",
      "published_date": "2024-02-06 06:27:07 UTC",
      "updated_date": "2024-02-06 06:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:59:28.145209"
    },
    {
      "arxiv_id": "2402.03741v3",
      "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
      "title_zh": "SUB-PLAY：针对部分观察的多智能体强化学习系统的对抗策略",
      "authors": [
        "Oubo Ma",
        "Yuwen Pu",
        "Linkang Du",
        "Yang Dai",
        "Ruo Wang",
        "Xiaolei Liu",
        "Yingcai Wu",
        "Shouling Ji"
      ],
      "abstract": "Recent advancements in multi-agent reinforcement learning (MARL) have opened\nup vast application prospects, such as swarm control of drones, collaborative\nmanipulation by robotic arms, and multi-target encirclement. However, potential\nsecurity threats during the MARL deployment need more attention and thorough\ninvestigation. Recent research reveals that attackers can rapidly exploit the\nvictim's vulnerabilities, generating adversarial policies that result in the\nfailure of specific tasks. For instance, reducing the winning rate of a\nsuperhuman-level Go AI to around 20%. Existing studies predominantly focus on\ntwo-player competitive environments, assuming attackers possess complete global\nstate observation.\n  In this study, we unveil, for the first time, the capability of attackers to\ngenerate adversarial policies even when restricted to partial observations of\nthe victims in multi-agent competitive environments. Specifically, we propose a\nnovel black-box attack (SUB-PLAY) that incorporates the concept of constructing\nmultiple subgames to mitigate the impact of partial observability and suggests\nsharing transitions among subpolicies to improve attackers' exploitative\nability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under\nthree typical partial observability limitations. Visualization results indicate\nthat adversarial policies induce significantly different activations of the\nvictims' policy networks. Furthermore, we evaluate three potential defenses\naimed at exploring ways to mitigate security threats posed by adversarial\npolicies, providing constructive recommendations for deploying MARL in\ncompetitive environments.",
      "tldr_zh": "本研究探讨了多智能体强化学习(MARL)系统在部分观察条件下的安全威胁，首次揭示攻击者即使无法获得完整全局状态也能生成有效的对抗策略。研究提出了一种新型黑-box attack 框架SUB-PLAY，通过构建多个子游戏减轻部分可观察性的影响，并共享子策略的转移来提升攻击能力。在三种典型的部分可观察性限制下，实验证明SUB-PLAY 有效，导致受害者策略网络激活显著改变，并降低了任务成功率。该框架还评估了三种潜在防御措施，并为MARL在竞争环境中的部署提供了实用建议。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in the ACM Conference on Computer and Communications\n  Security (CCS'24), October 14-18, 2024, Salt Lake City, UT, USA",
      "pdf_url": "http://arxiv.org/pdf/2402.03741v3",
      "published_date": "2024-02-06 06:18:16 UTC",
      "updated_date": "2024-06-26 12:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:59:37.550015"
    },
    {
      "arxiv_id": "2402.03732v1",
      "title": "Deep Outdated Fact Detection in Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Huiling Tu",
        "Shuo Yu",
        "Vidya Saikrishna",
        "Feng Xia",
        "Karin Verspoor"
      ],
      "abstract": "Knowledge graphs (KGs) have garnered significant attention for their vast\npotential across diverse domains. However, the issue of outdated facts poses a\nchallenge to KGs, affecting their overall quality as real-world information\nevolves. Existing solutions for outdated fact detection often rely on manual\nrecognition. In response, this paper presents DEAN (Deep outdatEd fAct\ndetectioN), a novel deep learning-based framework designed to identify outdated\nfacts within KGs. DEAN distinguishes itself by capturing implicit structural\ninformation among facts through comprehensive modeling of both entities and\nrelations. To effectively uncover latent out-of-date information, DEAN employs\na contrastive approach based on a pre-defined Relations-to-Nodes (R2N) graph,\nweighted by the number of entities. Experimental results demonstrate the\neffectiveness and superiority of DEAN over state-of-the-art baseline methods.",
      "tldr_zh": "知识图谱（Knowledge Graphs）中过时事实的问题会影响其质量，现有的检测方法主要依赖手动识别。  \n本文提出 DEAN（Deep outdatEd fAct detectioN），一个基于深度学习的框架，通过全面建模实体和关系来捕获事实间的隐式结构信息，并采用基于预定义的 Relations-to-Nodes (R2N) 图的对比方法（加权由实体数量决定）来识别潜在过时信息。  \n实验结果显示，DEAN 比现有最先进基线方法更有效，证明了其在过时事实检测中的优越性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.LG",
        "68T09, 68T30, 68P20",
        "I.2.6; I.2.4; H.3.7; H.3.3"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03732v1",
      "published_date": "2024-02-06 05:58:15 UTC",
      "updated_date": "2024-02-06 05:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:59:50.126811"
    },
    {
      "arxiv_id": "2402.03728v1",
      "title": "Consistent Joint Decision-Making with Heterogeneous Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Rajaby Faghihi",
        "Parisa Kordjamshidi"
      ],
      "abstract": "This paper introduces a novel decision-making framework that promotes\nconsistency among decisions made by diverse models while utilizing external\nknowledge. Leveraging the Integer Linear Programming (ILP) framework, we map\npredictions from various models into globally normalized and comparable values\nby incorporating information about decisions' prior probability, confidence\n(uncertainty), and the models' expected accuracy. Our empirical study\ndemonstrates the superiority of our approach over conventional baselines on\nmultiple datasets.",
      "tldr_zh": "这篇论文提出了一种新的决策框架，用于在利用外部知识的同时，确保不同异构学习模型（Heterogeneous Learning Models）的决策一致性。该框架利用整数线性规划（Integer Linear Programming, ILP）将各模型的预测映射到全局归一化和可比较的值中，考虑了决策的先验概率、置信度（uncertainty）以及模型的预期准确性。通过实证研究，该方法在多个数据集上表现出色，优于传统基线模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "EACL 2024 Findings - Short Paper",
      "pdf_url": "http://arxiv.org/pdf/2402.03728v1",
      "published_date": "2024-02-06 05:50:04 UTC",
      "updated_date": "2024-02-06 05:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:00:01.280034"
    },
    {
      "arxiv_id": "2402.03720v1",
      "title": "Similarity-based Neighbor Selection for Graph LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Li",
        "Jiwei Li",
        "Jiawei Han",
        "Guoyin Wang"
      ],
      "abstract": "Text-attributed graphs (TAGs) present unique challenges for direct processing\nby Language Learning Models (LLMs), yet their extensive commonsense knowledge\nand robust reasoning capabilities offer great promise for node classification\nin TAGs. Prior research in this field has grappled with issues such as\nover-squashing, heterophily, and ineffective graph information integration,\nfurther compounded by inconsistencies in dataset partitioning and\nunderutilization of advanced LLMs. To address these challenges, we introduce\nSimilarity-based Neighbor Selection (SNS). Using SimCSE and advanced neighbor\nselection techniques, SNS effectively improves the quality of selected\nneighbors, thereby improving graph representation and alleviating issues like\nover-squashing and heterophily. Besides, as an inductive and training-free\napproach, SNS demonstrates superior generalization and scalability over\ntraditional GNN methods. Our comprehensive experiments, adhering to standard\ndataset partitioning practices, demonstrate that SNS, through simple prompt\ninteractions with LLMs, consistently outperforms vanilla GNNs and achieves\nstate-of-the-art results on datasets like PubMed in node classification,\nshowcasing LLMs' potential in graph structure understanding. Our research\nfurther underscores the significance of graph structure integration in LLM\napplications and identifies key factors for their success in node\nclassification. Code is available at https://github.com/ruili33/SNS.",
      "tldr_zh": "本文提出 Similarity-based Neighbor Selection (SNS) 方法，用于提升 Language Learning Models (LLMs) 在 Text-attributed graphs (TAGs) 中的节点分类性能，通过利用 SimCSE 和高级邻居选择技术改善邻居质量，从而缓解 over-squashing 和 heterophily 问题，并作为 inductive 和 training-free 方式增强泛化和可扩展性。相比传统 GNNs，SNS 通过简单的提示交互在标准数据集分区上表现出色，并在 PubMed 等数据集上实现 state-of-the-art 结果。研究强调了图结构集成在 LLM 应用中的关键作用，并为未来优化提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03720v1",
      "published_date": "2024-02-06 05:29:05 UTC",
      "updated_date": "2024-02-06 05:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:00:15.482877"
    },
    {
      "arxiv_id": "2402.03719v1",
      "title": "Empowering Language Models with Active Inquiry for Deeper Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jing-Cheng Pang",
        "Heng-Bo Fan",
        "Pengyuan Wang",
        "Jia-Hao Xiao",
        "Nan Tang",
        "Si-Hang Yang",
        "Chengxing Jia",
        "Sheng-Jun Huang",
        "Yang Yu"
      ],
      "abstract": "The rise of large language models (LLMs) has revolutionized the way that we\ninteract with artificial intelligence systems through natural language.\nHowever, LLMs often misinterpret user queries because of their uncertain\nintention, leading to less helpful responses. In natural human interactions,\nclarification is sought through targeted questioning to uncover obscure\ninformation. Thus, in this paper, we introduce LaMAI (Language Model with\nActive Inquiry), designed to endow LLMs with this same level of interactive\nengagement. LaMAI leverages active learning techniques to raise the most\ninformative questions, fostering a dynamic bidirectional dialogue. This\napproach not only narrows the contextual gap but also refines the output of the\nLLMs, aligning it more closely with user expectations. Our empirical studies,\nacross a variety of complex datasets where LLMs have limited conversational\ncontext, demonstrate the effectiveness of LaMAI. The method improves answer\naccuracy from 31.9% to 50.9%, outperforming other leading question-answering\nframeworks. Moreover, in scenarios involving human participants, LaMAI\nconsistently generates responses that are superior or comparable to baseline\nmethods in more than 82% of the cases. The applicability of LaMAI is further\nevidenced by its successful integration with various LLMs, highlighting its\npotential for the future of interactive language models.",
      "tldr_zh": "这篇论文提出 LaMAI（Language Model with Active Inquiry）框架，以提升大型语言模型（LLMs）的互动能力，通过主动提问来澄清用户意图并加深理解。LaMAI 采用 active learning 技术生成最具信息量的查询，促进动态双向对话，从而缩小上下文差距并优化模型输出。实验结果显示，在复杂数据集上，该方法将答案准确率从 31.9% 提高到 50.9%，并在人类参与场景中超过 82% 的情况下优于其他问答框架，证明其在各种 LLMs 中的广泛适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03719v1",
      "published_date": "2024-02-06 05:24:16 UTC",
      "updated_date": "2024-02-06 05:24:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:00:27.749466"
    },
    {
      "arxiv_id": "2402.03715v3",
      "title": "Clarify: Improving Model Robustness With Natural Language Corrections",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonho Lee",
        "Michelle S. Lam",
        "Helena Vasconcelos",
        "Michael S. Bernstein",
        "Chelsea Finn"
      ],
      "abstract": "The standard way to teach models is by feeding them lots of data. However,\nthis approach often teaches models incorrect ideas because they pick up on\nmisleading signals in the data. To prevent such misconceptions, we must\nnecessarily provide additional information beyond the training data. Prior\nmethods incorporate additional instance-level supervision, such as labels for\nmisleading features or additional labels for debiased data. However, such\nstrategies require a large amount of labeler effort. We hypothesize that people\nare good at providing textual feedback at the concept level, a capability that\nexisting teaching frameworks do not leverage. We propose Clarify, a novel\ninterface and method for interactively correcting model misconceptions. Through\nClarify, users need only provide a short text description of a model's\nconsistent failure patterns. Then, in an entirely automated way, we use such\ndescriptions to improve the training process. Clarify is the first end-to-end\nsystem for user model correction. Our user studies show that non-expert users\ncan successfully describe model misconceptions via Clarify, leading to\nincreased worst-case performance in two datasets. We additionally conduct a\ncase study on a large-scale image dataset, ImageNet, using Clarify to find and\nrectify 31 novel hard subpopulations.",
      "tldr_zh": "这篇论文提出 Clarify，一种创新方法，通过自然语言纠正来提升模型的鲁棒性，解决传统训练中模型从数据中学习误导信号的问题。Clarify 允许用户仅需提供模型一致失败模式的简短文本描述，即可实现端到端自动化训练改进，而无需大量标签努力。用户研究表明，非专家用户能有效描述误导模式，从而提高两个数据集的 worst-case performance，并在 ImageNet 案例研究中成功识别并修复 31 个硬子群（hard subpopulations）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "UIST 2024. Interface code available at\n  https://github.com/yoonholee/Clarify",
      "pdf_url": "http://arxiv.org/pdf/2402.03715v3",
      "published_date": "2024-02-06 05:11:38 UTC",
      "updated_date": "2024-08-22 01:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:00:38.752057"
    },
    {
      "arxiv_id": "2402.03706v1",
      "title": "MMAUD: A Comprehensive Multi-Modal Anti-UAV Dataset for Modern Miniature Drone Threats",
      "title_zh": "MMAUD：全面的多模态反无人机数据集，用于现代微型无人机威胁",
      "authors": [
        "Shenghai Yuan",
        "Yizhuo Yang",
        "Thien Hoang Nguyen",
        "Thien-Minh Nguyen",
        "Jianfei Yang",
        "Fen Liu",
        "Jianping Li",
        "Han Wang",
        "Lihua Xie"
      ],
      "abstract": "In response to the evolving challenges posed by small unmanned aerial\nvehicles (UAVs), which possess the potential to transport harmful payloads or\nindependently cause damage, we introduce MMAUD: a comprehensive Multi-Modal\nAnti-UAV Dataset. MMAUD addresses a critical gap in contemporary threat\ndetection methodologies by focusing on drone detection, UAV-type\nclassification, and trajectory estimation. MMAUD stands out by combining\ndiverse sensory inputs, including stereo vision, various Lidars, Radars, and\naudio arrays. It offers a unique overhead aerial detection vital for addressing\nreal-world scenarios with higher fidelity than datasets captured on specific\nvantage points using thermal and RGB. Additionally, MMAUD provides accurate\nLeica-generated ground truth data, enhancing credibility and enabling confident\nrefinement of algorithms and models, which has never been seen in other\ndatasets. Most existing works do not disclose their datasets, making MMAUD an\ninvaluable resource for developing accurate and efficient solutions. Our\nproposed modalities are cost-effective and highly adaptable, allowing users to\nexperiment and implement new UAV threat detection tools. Our dataset closely\nsimulates real-world scenarios by incorporating ambient heavy machinery sounds.\nThis approach enhances the dataset's applicability, capturing the exact\nchallenges faced during proximate vehicular operations. It is expected that\nMMAUD can play a pivotal role in advancing UAV threat detection,\nclassification, trajectory estimation capabilities, and beyond. Our dataset,\ncodes, and designs will be available in https://github.com/ntu-aris/MMAUD.",
      "tldr_zh": "该研究引入了MMAUD，一种全面的多模态反UAV数据集，针对现代小型无人机威胁，专注于无人机检测、UAV类型分类和轨迹估计。MMAUD整合了多种传感器输入，包括立体视觉、各种Lidars、Radars和音频阵列，并采用overhead aerial detection方式，提供精确的Leica生成地面真实数据，以模拟真实世界场景并提升算法可靠性。与现有数据集不同，MMAUD是公开可用的资源，支持开发成本有效且适配性的UAV威胁检测工具。预计此数据集将显著推进UAV威胁检测、分类和轨迹估计等领域的进展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03706v1",
      "published_date": "2024-02-06 04:57:07 UTC",
      "updated_date": "2024-02-06 04:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:00:49.947113"
    },
    {
      "arxiv_id": "2402.03700v1",
      "title": "GenLens: A Systematic Evaluation of Visual GenAI Model Outputs",
      "title_zh": "翻译失败",
      "authors": [
        "Tica Lin",
        "Hanspeter Pfister",
        "Jui-Hsien Wang"
      ],
      "abstract": "The rapid development of generative AI (GenAI) models in computer vision\nnecessitates effective evaluation methods to ensure their quality and fairness.\nExisting tools primarily focus on dataset quality assurance and model\nexplainability, leaving a significant gap in GenAI output evaluation during\nmodel development. Current practices often depend on developers' subjective\nvisual assessments, which may lack scalability and generalizability. This paper\nbridges this gap by conducting a formative study with GenAI model developers in\nan industrial setting. Our findings led to the development of GenLens, a visual\nanalytic interface designed for the systematic evaluation of GenAI model\noutputs during the early stages of model development. GenLens offers a\nquantifiable approach for overviewing and annotating failure cases, customizing\nissue tags and classifications, and aggregating annotations from multiple users\nto enhance collaboration. A user study with model developers reveals that\nGenLens effectively enhances their workflow, evidenced by high satisfaction\nrates and a strong intent to integrate it into their practices. This research\nunderscores the importance of robust early-stage evaluation tools in GenAI\ndevelopment, contributing to the advancement of fair and high-quality GenAI\nmodels.",
      "tldr_zh": "本论文探讨了视觉生成AI (GenAI) 模型的快速发展及其输出评估的空白问题，现有工具主要关注数据集质量和模型可解释性，而依赖开发者的主观评估缺乏可扩展性。作者通过工业环境中的形成性研究，开发了GenLens，这是一个视觉分析界面，用于模型开发早期阶段的系统评估，包括量化失败案例、自定义问题标签、分类和多用户协作。用户研究表明，GenLens显著提升了开发者的工作流程，获得高满意度和整合意愿，最终推动了公平和高质GenAI模型的发展。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To Appear in IEEE PacificVis 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03700v1",
      "published_date": "2024-02-06 04:41:06 UTC",
      "updated_date": "2024-02-06 04:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:01:02.888610"
    },
    {
      "arxiv_id": "2402.03694v2",
      "title": "ServeFlow: A Fast-Slow Model Architecture for Network Traffic Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Shinan Liu",
        "Ted Shaowang",
        "Gerry Wan",
        "Jeewon Chae",
        "Jonatas Marques",
        "Sanjay Krishnan",
        "Nick Feamster"
      ],
      "abstract": "Network traffic analysis increasingly uses complex machine learning models as\nthe internet consolidates and traffic gets more encrypted. However, over\nhigh-bandwidth networks, flows can easily arrive faster than model inference\nrates. The temporal nature of network flows limits simple scale-out approaches\nleveraged in other high-traffic machine learning applications. Accordingly,\nthis paper presents ServeFlow, a solution for machine-learning model serving\naimed at network traffic analysis tasks, which carefully selects the number of\npackets to collect and the models to apply for individual flows to achieve a\nbalance between minimal latency, high service rate, and high accuracy. We\nidentify that on the same task, inference time across models can differ by 1.8x\n- 141.3x, while the inter-packet waiting time is up to 6-8 orders of magnitude\nhigher than the inference time! Based on these insights, we tailor a novel\nfast-slow model architecture for networking ML pipelines. Flows are assigned to\na slower model only when the inferences from the fast model are deemed high\nuncertainty. ServeFlow is able to make inferences on 76.3% of flows in under\n16ms, which is a speed-up of 40.5x on the median end-to-end serving latency\nwhile increasing the service rate and maintaining similar accuracy. Even with\nthousands of features per flow, it achieves a service rate of over 48.5k new\nflows per second on a 16-core CPU commodity server, which matches the order of\nmagnitude of flow rates observed on city-level network backbones.",
      "tldr_zh": "这篇论文针对网络流量分析中机器学习模型的延迟挑战，提出ServeFlow框架，该框架采用快慢模型架构：先使用快速模型进行初步推理，仅在不确定性较高时切换到慢速模型，以平衡最小延迟、高服务率和高准确率。论文的关键洞见是模型推理时间差异巨大（1.8x-141.3x），而包间等待时间远高于推理时间（6-8数量级），因此优化了包收集策略和模型分配。实验结果显示，ServeFlow能在76.3%的流量上在16ms内完成推理，比中位端到端服务延迟快40.5x，同时提高服务率至48.5k新流量每秒，并保持类似准确率。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03694v2",
      "published_date": "2024-02-06 04:28:33 UTC",
      "updated_date": "2024-10-24 14:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:01:15.744090"
    },
    {
      "arxiv_id": "2402.03688v1",
      "title": "A Survey of Privacy Threats and Defense in Vertical Federated Learning: From Model Life Cycle Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Yu",
        "Meng Han",
        "Yiming Li",
        "Changting Lin",
        "Yao Zhang",
        "Mingyang Zhang",
        "Yan Liu",
        "Haiqin Weng",
        "Yuseok Jeon",
        "Ka-Ho Chow",
        "Stacy Patterson"
      ],
      "abstract": "Vertical Federated Learning (VFL) is a federated learning paradigm where\nmultiple participants, who share the same set of samples but hold different\nfeatures, jointly train machine learning models. Although VFL enables\ncollaborative machine learning without sharing raw data, it is still\nsusceptible to various privacy threats. In this paper, we conduct the first\ncomprehensive survey of the state-of-the-art in privacy attacks and defenses in\nVFL. We provide taxonomies for both attacks and defenses, based on their\ncharacterizations, and discuss open challenges and future research directions.\nSpecifically, our discussion is structured around the model's life cycle, by\ndelving into the privacy threats encountered during different stages of machine\nlearning and their corresponding countermeasures. This survey not only serves\nas a resource for the research community but also offers clear guidance and\nactionable insights for practitioners to safeguard data privacy throughout the\nmodel's life cycle.",
      "tldr_zh": "这篇论文调查了垂直联邦学习 (Vertical Federated Learning, VFL) 中隐私威胁和防御问题，VFL 允许多个参与者共享相同样本但不同特征来联合训练模型，而无需交换原始数据，但仍面临各种隐私风险。论文从模型生命周期角度出发，提供隐私攻击和防御的分类体系，详细探讨了机器学习不同阶段（如训练和部署）的隐私威胁及其对应对策。最终，该调查总结了开放挑战和未来研究方向，为研究者和从业者提供资源和实用指导，以增强数据隐私保护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03688v1",
      "published_date": "2024-02-06 04:22:44 UTC",
      "updated_date": "2024-02-06 04:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:01:25.665940"
    },
    {
      "arxiv_id": "2402.05133v3",
      "title": "Personalized Language Modeling from Personalized Human Feedback",
      "title_zh": "基于个性化人类反馈的个性化语言建模",
      "authors": [
        "Xinyu Li",
        "Ruiyang Zhou",
        "Zachary C. Lipton",
        "Liu Leqi"
      ],
      "abstract": "Personalized large language models (LLMs) are designed to tailor responses to\nindividual user preferences. While Reinforcement Learning from Human Feedback\n(RLHF) is a commonly used framework for aligning LLMs with human preferences,\nvanilla RLHF assumes that all human preferences share the same distribution,\npreventing fine-tuned LLMs from generating personalized content when user\npreferences are diverse. In this work, we propose Personalized-RLHF (P-RLHF),\nan efficient framework that utilizes a lightweight user model to capture\nindividual user preferences and jointly learns the user model and the\npersonalized LLM from human feedback. P-RLHF exhibits the following three\ncharacteristics: (1) It enables an LLM to generate personalized content and\nscale efficiently with growing number of users. (2) It handles both explicit\nuser preferences described as textual input and implicit user preferences\nencoded in the feedback data. (3) It eliminates the need for users to fully\narticulate their preferences, which are normally needed for prompting LLMs to\ngenerate personalized content yet are often impractical to obtain in real-world\nscenarios. Our experimental results show that personalized LLMs trained using\nP-RLHF generate responses that are more closely aligned with individual user\npreferences, outperforming vanilla, non-personalized RLHF and prompting-based\npersonalization approaches across different tasks. We opensource our code at\nhttps://github.com/HumainLab/Personalized_RLHF.",
      "tldr_zh": "这篇论文提出了 Personalized-RLHF (P-RLHF)，一个高效框架，用于从个性化人类反馈训练大型语言模型 (LLMs)，以解决传统 RLHF 在处理用户偏好多样性时存在的局限性。P-RLHF 通过一个轻量级用户模型联合学习个体偏好，包括显式文本输入和隐式反馈数据，从而使 LLMs 生成更个性化的内容，并能高效扩展到更多用户，而无需用户完全表达偏好。实验结果表明，该方法在各种任务中优于传统 RLHF 和基于提示的个性化方法，能更好地对齐个体用户偏好。作者在 GitHub 上开源了代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05133v3",
      "published_date": "2024-02-06 04:18:58 UTC",
      "updated_date": "2024-12-09 04:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:01:39.468794"
    },
    {
      "arxiv_id": "2402.03686v3",
      "title": "Are Machines Better at Complex Reasoning? Unveiling Human-Machine Inference Gaps in Entailment Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Soumya Sanyal",
        "Tianyi Xiao",
        "Jiacheng Liu",
        "Wenya Wang",
        "Xiang Ren"
      ],
      "abstract": "Making inferences in text comprehension to understand the meaning is\nessential in language processing. This work studies the entailment verification\n(EV) problem of multi-sentence premises that requires a system to make multiple\ninferences implicitly. Studying EV for such complex premises is important\nbecause modern NLP problems, such as detecting inconsistent model-generated\nrationales, require complex multi-hop reasoning. However, current textual\ninference datasets mostly contain short premises that only partially focus on\nthese challenges. To address this, we compile an EV benchmark that includes\ndatasets from three NLP domains (NLI, contextual QA, and rationales) containing\nmulti-sentence premises. On benchmarking humans and LLMs, we find that LLMs are\nbetter than humans in multi-hop reasoning across extended contexts, while\nhumans perform better in simple deductive reasoning tasks. We also finetune a\nFlan-T5 model for EV using two training objectives to obtain a strong\nopen-source model that outperforms GPT-3.5 and rivals GPT-4. Finally, we use\nthis model to filter out inconsistent model-generated rationales in\nself-consistency decoding, resulting in a 6% accuracy improvement on average\nacross three MCQ datasets.",
      "tldr_zh": "这篇论文探讨了机器与人类在蕴涵验证（EV）任务中的推理差距，焦点在于多句前提下需要隐式多跳推理的复杂场景。研究者编译了一个新的EV基准数据集，涵盖NLI、上下文QA和理由等领域，以评估人类和大型语言模型（LLMs）的性能，发现LLMs在多跳推理上优于人类，而人类在简单演绎推理中更占优势。他们微调了Flan-T5模型，使用两种训练目标，获得了一个开源模型，该模型超过了GPT-3.5并与GPT-4相当，并在自一致性解码中过滤不一致的模型生成理由，平均提高了6%的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03686v3",
      "published_date": "2024-02-06 04:14:09 UTC",
      "updated_date": "2024-05-27 18:44:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:01:52.731969"
    },
    {
      "arxiv_id": "2402.03681v4",
      "title": "RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback",
      "title_zh": "RL-VLM-F：基于视觉语言",
      "authors": [
        "Yufei Wang",
        "Zhanyi Sun",
        "Jesse Zhang",
        "Zhou Xian",
        "Erdem Biyik",
        "David Held",
        "Zackory Erickson"
      ],
      "abstract": "Reward engineering has long been a challenge in Reinforcement Learning (RL)\nresearch, as it often requires extensive human effort and iterative processes\nof trial-and-error to design effective reward functions. In this paper, we\npropose RL-VLM-F, a method that automatically generates reward functions for\nagents to learn new tasks, using only a text description of the task goal and\nthe agent's visual observations, by leveraging feedbacks from vision language\nfoundation models (VLMs). The key to our approach is to query these models to\ngive preferences over pairs of the agent's image observations based on the text\ndescription of the task goal, and then learn a reward function from the\npreference labels, rather than directly prompting these models to output a raw\nreward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F\nsuccessfully produces effective rewards and policies across various domains -\nincluding classic control, as well as manipulation of rigid, articulated, and\ndeformable objects - without the need for human supervision, outperforming\nprior methods that use large pretrained models for reward generation under the\nsame assumptions. Videos can be found on our project website:\nhttps://rlvlmf2024.github.io/",
      "tldr_zh": "本文提出RL-VLM-F方法，利用视觉语言基础模型(VLMs)的反馈，从任务目标的文本描述和代理的视觉观察中自动生成强化学习(RL)中的奖励函数，从而解决传统奖励工程的试错难题。该方法的关键在于查询VLMs对图像观察对的偏好，并从这些偏好标签中学习奖励函数，以避免直接输出奖励分数可能带来的噪声和不一致。实验结果显示，RL-VLM-F在经典控制以及刚性、关节和可变形物体的操作领域成功生成有效奖励和策略，无需人工监督，并优于现有基于预训练模型的奖励生成方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03681v4",
      "published_date": "2024-02-06 04:06:06 UTC",
      "updated_date": "2024-06-14 21:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:02:05.590558"
    },
    {
      "arxiv_id": "2402.03678v3",
      "title": "Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents",
      "title_zh": "逻辑规范引导的动态任务采样用于强化学习代理",
      "authors": [
        "Yash Shukla",
        "Tanushree Burman",
        "Abhishek Kulkarni",
        "Robert Wright",
        "Alvaro Velasquez",
        "Jivko Sinapov"
      ],
      "abstract": "Reinforcement Learning (RL) has made significant strides in enabling\nartificial agents to learn diverse behaviors. However, learning an effective\npolicy often requires a large number of environment interactions. To mitigate\nsample complexity issues, recent approaches have used high-level task\nspecifications, such as Linear Temporal Logic (LTL$_f$) formulas or Reward\nMachines (RM), to guide the learning progress of the agent. In this work, we\npropose a novel approach, called Logical Specifications-guided Dynamic Task\nSampling (LSTS), that learns a set of RL policies to guide an agent from an\ninitial state to a goal state based on a high-level task specification, while\nminimizing the number of environmental interactions. Unlike previous work, LSTS\ndoes not assume information about the environment dynamics or the Reward\nMachine, and dynamically samples promising tasks that lead to successful goal\npolicies. We evaluate LSTS on a gridworld and show that it achieves improved\ntime-to-threshold performance on complex sequential decision-making problems\ncompared to state-of-the-art RM and Automaton-guided RL baselines, such as\nQ-Learning for Reward Machines and Compositional RL from logical Specifications\n(DIRL). Moreover, we demonstrate that our method outperforms RM and\nAutomaton-guided RL baselines in terms of sample-efficiency, both in a\npartially observable robotic task and in a continuous control robotic\nmanipulation task.",
      "tldr_zh": "这篇论文提出了一种名为 Logical Specifications-guided Dynamic Task Sampling (LSTS) 的新方法，用于指导 Reinforcement Learning (RL) 代理在高水平任务规范（如 Linear Temporal Logic (LTL$_f$) 公式或 Reward Machines (RM)）下学习从初始状态到目标状态的策略，同时最小化环境交互数量。LSTS 与现有方法不同，不依赖环境动态或 RM 信息，而是动态采样有前景的任务，以提升学习效率。在 gridworld 环境以及部分可观察的机器人任务和连续控制机器人操作任务中，LSTS 比基线如 Q-Learning for Reward Machines 和 DIRL 在样本效率和时间到阈值性能上表现出显著改善。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03678v3",
      "published_date": "2024-02-06 04:00:21 UTC",
      "updated_date": "2024-04-03 00:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:02:17.612755"
    },
    {
      "arxiv_id": "2402.03675v1",
      "title": "Effective Protein-Protein Interaction Exploration with PPIretrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Chenqing Hua",
        "Connor Coley",
        "Guy Wolf",
        "Doina Precup",
        "Shuangjia Zheng"
      ],
      "abstract": "Protein-protein interactions (PPIs) are crucial in regulating numerous\ncellular functions, including signal transduction, transportation, and immune\ndefense. As the accuracy of multi-chain protein complex structure prediction\nimproves, the challenge has shifted towards effectively navigating the vast\ncomplex universe to identify potential PPIs. Herein, we propose PPIretrieval,\nthe first deep learning-based model for protein-protein interaction\nexploration, which leverages existing PPI data to effectively search for\npotential PPIs in an embedding space, capturing rich geometric and chemical\ninformation of protein surfaces. When provided with an unseen query protein\nwith its associated binding site, PPIretrieval effectively identifies a\npotential binding partner along with its corresponding binding site in an\nembedding space, facilitating the formation of protein-protein complexes.",
      "tldr_zh": "蛋白质-蛋白质相互作用（PPIs）在调控细胞功能如信号转导和免疫防御中至关重要，但随着多链蛋白复合物结构预测准确性的提升，如何有效探索潜在PPIs成为新挑战。  \n本研究提出PPIretrieval，这是首个基于深度学习的模型，利用现有PPI数据在嵌入空间中搜索潜在相互作用，并捕捉蛋白质表面的几何和化学信息。  \n当提供一个未知查询蛋白及其结合位点时，PPIretrieval能有效识别潜在结合伙伴及其对应结合位点，从而促进蛋白-蛋白复合物的形成。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03675v1",
      "published_date": "2024-02-06 03:57:06 UTC",
      "updated_date": "2024-02-06 03:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:02:29.490873"
    },
    {
      "arxiv_id": "2402.03667v2",
      "title": "Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yanfang Zhang",
        "Yiliu Sun",
        "Yibing Zhan",
        "Dapeng Tao",
        "Dacheng Tao",
        "Chen Gong"
      ],
      "abstract": "Recently, increasing attention has been focused on improving the ability of\nLarge Language Models (LLMs) to perform complex reasoning. Advanced methods,\nsuch as Chain-of-Thought (CoT) and its variants, are found to enhance their\nreasoning skills by designing suitable prompts or breaking down complex\nproblems into more manageable sub-problems. However, little concentration has\nbeen put on exploring the reasoning process, \\textit{i.e.}, we discovered that\nmost methods resort to Direct Reasoning (DR) and disregard Indirect Reasoning\n(IR). This can make LLMs difficult to solve IR tasks, which are often\nencountered in the real world. To address this issue, we propose a\nDirect-Indirect Reasoning (DIR) method, which considers DR and IR as multiple\nparallel reasoning paths that are merged to derive the final answer. We\nstimulate LLMs to implement IR by crafting prompt templates incorporating the\nprinciples of contrapositive and contradiction. These templates trigger LLMs to\nassume the negation of the conclusion as true, combine it with the premises to\ndeduce a conclusion, and utilize the logical equivalence of the contrapositive\nto enhance their comprehension of the rules used in the reasoning process. Our\nDIR method is simple yet effective and can be straightforwardly integrated with\nexisting variants of CoT methods. Experimental results on four datasets related\nto logical reasoning and mathematic proof demonstrate that our DIR method, when\ncombined with various baseline methods, significantly outperforms all the\noriginal methods.",
      "tldr_zh": "该研究发现，现有的 Large Language Models (LLMs) 推理方法，如 Chain-of-Thought (CoT) 和其变体，主要依赖 Direct Reasoning (DR)，而忽略了 Indirect Reasoning (IR)，导致模型难以处理真实世界的 IR 任务。\n\n为此，作者提出 Direct-Indirect Reasoning (DIR) 方法，将 DR 和 IR 作为并行路径合并，通过设计包含 contrapositive 和 contradiction 原则的提示模板，刺激 LLMs 假设结论的否定并进行逻辑推导，从而提升对推理规则的理解。\n\n实验结果显示，DIR 方法与各种 CoT 基线方法结合后，在四个逻辑推理和数学证明数据集上显著优于原方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2402.03667v2",
      "published_date": "2024-02-06 03:41:12 UTC",
      "updated_date": "2025-01-27 09:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:02:41.050410"
    },
    {
      "arxiv_id": "2402.03663v1",
      "title": "Symbol Correctness in Deep Neural Networks Containing Symbolic Layers",
      "title_zh": "包含符号层的深度神经网络",
      "authors": [
        "Aaron Bembenek",
        "Toby Murray"
      ],
      "abstract": "To handle AI tasks that combine perception and logical reasoning, recent work\nintroduces Neurosymbolic Deep Neural Networks (NS-DNNs), which contain -- in\naddition to traditional neural layers -- symbolic layers: symbolic expressions\n(e.g., SAT formulas, logic programs) that are evaluated by symbolic solvers\nduring inference. We identify and formalize an intuitive, high-level principle\nthat can guide the design and analysis of NS-DNNs: symbol correctness, the\ncorrectness of the intermediate symbols predicted by the neural layers with\nrespect to a (generally unknown) ground-truth symbolic representation of the\ninput data. We demonstrate that symbol correctness is a necessary property for\nNS-DNN explainability and transfer learning (despite being in general\nimpossible to train for). Moreover, we show that the framework of symbol\ncorrectness provides a precise way to reason and communicate about model\nbehavior at neural-symbolic boundaries, and gives insight into the fundamental\ntradeoffs faced by NS-DNN training algorithms. In doing so, we both identify\nsignificant points of ambiguity in prior work, and provide a framework to\nsupport further NS-DNN developments.",
      "tldr_zh": "本研究探讨了包含符号层的神经符号深度神经网络 (NS-DNNs)，这些网络结合了传统神经层和符号表达式（如 SAT formulas 或 logic programs），以处理感知与逻辑推理的任务。论文形式化了“symbol correctness”原则，即神经层预测的中间符号相对于输入数据的真实符号表示的正确性，并证明这一原则对 NS-DNNs 的可解释性和迁移学习至关重要，尽管训练时难以实现。该框架有助于精确分析模型在神经-符号边界的行为、揭示训练算法的根本权衡，并为未来 NS-DNNs 开发提供支持，同时指出了先前工作的模糊点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03663v1",
      "published_date": "2024-02-06 03:33:50 UTC",
      "updated_date": "2024-02-06 03:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:02:52.501160"
    },
    {
      "arxiv_id": "2402.03661v1",
      "title": "Transductive Reward Inference on Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Bohao Qu",
        "Xiaofeng Cao",
        "Qing Guo",
        "Yi Chang",
        "Ivor W. Tsang",
        "Chengqi Zhang"
      ],
      "abstract": "In this study, we present a transductive inference approach on that reward\ninformation propagation graph, which enables the effective estimation of\nrewards for unlabelled data in offline reinforcement learning. Reward inference\nis the key to learning effective policies in practical scenarios, while direct\nenvironmental interactions are either too costly or unethical and the reward\nfunctions are rarely accessible, such as in healthcare and robotics. Our\nresearch focuses on developing a reward inference method based on the\ncontextual properties of information propagation on graphs that capitalizes on\na constrained number of human reward annotations to infer rewards for\nunlabelled data. We leverage both the available data and limited reward\nannotations to construct a reward propagation graph, wherein the edge weights\nincorporate various influential factors pertaining to the rewards.\nSubsequently, we employ the constructed graph for transductive reward\ninference, thereby estimating rewards for unlabelled data. Furthermore, we\nestablish the existence of a fixed point during several iterations of the\ntransductive inference process and demonstrate its at least convergence to a\nlocal optimum. Empirical evaluations on locomotion and robotic manipulation\ntasks validate the effectiveness of our approach. The application of our\ninferred rewards improves the performance in offline reinforcement learning\ntasks.",
      "tldr_zh": "本文提出了一种基于图的transductive reward inference方法，用于offline reinforcement learning中有效估计未标记数据的奖励，尤其适用于直接互动成本高或不道德的场景，如医疗和机器人领域。该方法利用有限的人类奖励标注构建reward propagation graph，并通过边权重整合各种影响因素进行奖励传播和推断，同时证明了推断过程存在固定点并至少收敛到局部最优。实验在运动学和机器人操作任务上验证了该方法的有效性，使用推断的奖励显著提升了强化学习任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03661v1",
      "published_date": "2024-02-06 03:31:28 UTC",
      "updated_date": "2024-02-06 03:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:03:04.973104"
    },
    {
      "arxiv_id": "2402.03660v2",
      "title": "On the Emergence of Cross-Task Linearity in the Pretraining-Finetuning Paradigm",
      "title_zh": "论预训练-微调范式中跨任务线性性的出现",
      "authors": [
        "Zhanpeng Zhou",
        "Zijun Chen",
        "Yilan Chen",
        "Bo Zhang",
        "Junchi Yan"
      ],
      "abstract": "The pretraining-finetuning paradigm has become the prevailing trend in modern\ndeep learning. In this work, we discover an intriguing linear phenomenon in\nmodels that are initialized from a common pretrained checkpoint and finetuned\non different tasks, termed as Cross-Task Linearity (CTL). Specifically, we show\nthat if we linearly interpolate the weights of two finetuned models, the\nfeatures in the weight-interpolated model are often approximately equal to the\nlinear interpolation of features in two finetuned models at each layer. We\nprovide comprehensive empirical evidence supporting that CTL consistently\noccurs for finetuned models that start from the same pretrained checkpoint. We\nconjecture that in the pretraining-finetuning paradigm, neural networks\napproximately function as linear maps, mapping from the parameter space to the\nfeature space. Based on this viewpoint, our study unveils novel insights into\nexplaining model merging/editing, particularly by translating operations from\nthe parameter space to the feature space. Furthermore, we delve deeper into the\nroot cause for the emergence of CTL, highlighting the role of pretraining.",
      "tldr_zh": "本文研究了预训练-微调(pretraining-finetuning)范式中一种 intriguing 现象，即Cross-Task Linearity (CTL)，即从同一预训练检查点微调的模型，当线性插值其权重时，特征空间也会近似线性插值。作者通过全面实证证据证实了CTL在不同任务微调模型中的一致性，并假设神经网络在该范式中充当参数空间到特征空间的线性映射，从而为模型合并/编辑提供了新见解。最终，该研究强调预训练在CTL现象出现中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03660v2",
      "published_date": "2024-02-06 03:28:36 UTC",
      "updated_date": "2024-05-28 08:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:03:17.901786"
    },
    {
      "arxiv_id": "2402.06049v2",
      "title": "Limits of Large Language Models in Debating Humans",
      "title_zh": "翻译失败",
      "authors": [
        "James Flamino",
        "Mohammed Shahid Modi",
        "Boleslaw K. Szymanski",
        "Brendan Cross",
        "Colton Mikolajczyk"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable promise in communicating\nwith humans. Their potential use as artificial partners with humans in\nsociological experiments involving conversation is an exciting prospect. But\nhow viable is it? Here, we rigorously test the limits of agents that debate\nusing LLMs in a preregistered study that runs multiple debate-based opinion\nconsensus games. Each game starts with six humans, six agents, or three humans\nand three agents. We found that agents can blend in and concentrate on a\ndebate's topic better than humans, improving the productivity of all players.\nYet, humans perceive agents as less convincing and confident than other humans,\nand several behavioral metrics of humans and agents we collected deviate\nmeasurably from each other. We observed that agents are already decent\ndebaters, but their behavior generates a pattern distinctly different from the\nhuman-generated data.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在与人类辩论中的局限性，通过预注册研究运行多场辩论游戏来测试其表现。实验设计包括不同组合的参与者（如全人类、全 AI 或混合），结果显示 AI 能更好地融入辩论主题并提升所有玩家的生产力。然而，人类认为 AI 的说服力和自信度不如人类，且 AI 的行为模式与人类有显著差异。尽管 AI 已具备体面的辩论能力，该研究揭示了其在模拟人类互动方面的潜在限制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 4 figures, 3 tables, 42 pages of supplemental materials, 9\n  supplemental figures, 24 supplemental tables",
      "pdf_url": "http://arxiv.org/pdf/2402.06049v2",
      "published_date": "2024-02-06 03:24:27 UTC",
      "updated_date": "2025-02-01 23:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:03:28.529811"
    },
    {
      "arxiv_id": "2402.03647v1",
      "title": "CAMBranch: Contrastive Learning with Augmented MILPs for Branching",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Lin",
        "Meng Xu",
        "Zhihua Xiong",
        "Huangang Wang"
      ],
      "abstract": "Recent advancements have introduced machine learning frameworks to enhance\nthe Branch and Bound (B\\&B) branching policies for solving Mixed Integer Linear\nProgramming (MILP). These methods, primarily relying on imitation learning of\nStrong Branching, have shown superior performance. However, collecting expert\nsamples for imitation learning, particularly for Strong Branching, is a\ntime-consuming endeavor. To address this challenge, we propose\n\\textbf{C}ontrastive Learning with \\textbf{A}ugmented \\textbf{M}ILPs for\n\\textbf{Branch}ing (CAMBranch), a framework that generates Augmented MILPs\n(AMILPs) by applying variable shifting to limited expert data from their\noriginal MILPs. This approach enables the acquisition of a considerable number\nof labeled expert samples. CAMBranch leverages both MILPs and AMILPs for\nimitation learning and employs contrastive learning to enhance the model's\nability to capture MILP features, thereby improving the quality of branching\ndecisions. Experimental results demonstrate that CAMBranch, trained with only\n10\\% of the complete dataset, exhibits superior performance. Ablation studies\nfurther validate the effectiveness of our method.",
      "tldr_zh": "该论文提出 CAMBranch 框架，利用 contrastive learning 和 augmented MILPs (AMILPs) 来提升 Branch and Bound (B&B) 分支策略在 Mixed Integer Linear Programming (MILP) 求解中的性能，解决传统模仿学习 Strong Branching 时收集专家样本耗时的难题。方法通过对有限专家数据应用 variable shifting 生成 AMILPs，从而扩展样本规模，并结合 MILPs 进行模仿学习，以增强模型捕捉 MILP 特征的能力。实验结果表明，CAMBranch 只需 10% 的完整数据集即可实现优越性能，消融研究进一步验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03647v1",
      "published_date": "2024-02-06 02:47:16 UTC",
      "updated_date": "2024-02-06 02:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:03:41.647724"
    },
    {
      "arxiv_id": "2402.03640v1",
      "title": "torchmSAT: A GPU-Accelerated Approximation To The Maximum Satisfiability Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrahman Hosny",
        "Sherief Reda"
      ],
      "abstract": "The remarkable achievements of machine learning techniques in analyzing\ndiscrete structures have drawn significant attention towards their integration\ninto combinatorial optimization algorithms. Typically, these methodologies\nimprove existing solvers by injecting learned models within the solving loop to\nenhance the efficiency of the search process. In this work, we derive a single\ndifferentiable function capable of approximating solutions for the Maximum\nSatisfiability Problem (MaxSAT). Then, we present a novel neural network\narchitecture to model our differentiable function, and progressively solve\nMaxSAT using backpropagation. This approach eliminates the need for labeled\ndata or a neural network training phase, as the training process functions as\nthe solving algorithm. Additionally, we leverage the computational power of\nGPUs to accelerate these computations. Experimental results on challenging\nMaxSAT instances show that our proposed methodology outperforms two existing\nMaxSAT solvers, and is on par with another in terms of solution cost, without\nnecessitating any training or access to an underlying SAT solver. Given that\nnumerous NP-hard problems can be reduced to MaxSAT, our novel technique paves\nthe way for a new generation of solvers poised to benefit from neural network\nGPU acceleration.",
      "tldr_zh": "这篇论文提出了一种名为 torchmSAT 的方法，通过构建一个可微分函数和新型神经网络架构，来近似求解 Maximum Satisfiability Problem (MaxSAT)，并利用反向传播作为求解过程，而无需标记数据或预训练阶段。该方法充分利用 GPU 加速，提高了计算效率，在 challenging MaxSAT 实例上的实验结果显示，其性能优于两个现有求解器，并与另一个相当。鉴于许多 NP-hard 问题可归约到 MaxSAT，此技术为基于神经网络和 GPU 的新一代优化求解器铺平了道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03640v1",
      "published_date": "2024-02-06 02:33:00 UTC",
      "updated_date": "2024-02-06 02:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:03:53.778721"
    },
    {
      "arxiv_id": "2402.04286v1",
      "title": "Progress and Opportunities of Foundation Models in Bioinformatics",
      "title_zh": "基础模型在生物信息学的进展和机会",
      "authors": [
        "Qing Li",
        "Zhihang Hu",
        "Yixuan Wang",
        "Lei Li",
        "Yimin Fan",
        "Irwin King",
        "Le Song",
        "Yu Li"
      ],
      "abstract": "Bioinformatics has witnessed a paradigm shift with the increasing integration\nof artificial intelligence (AI), particularly through the adoption of\nfoundation models (FMs). These AI techniques have rapidly advanced, addressing\nhistorical challenges in bioinformatics such as the scarcity of annotated data\nand the presence of data noise. FMs are particularly adept at handling\nlarge-scale, unlabeled data, a common scenario in biological contexts due to\nthe time-consuming and costly nature of experimentally determining labeled\ndata. This characteristic has allowed FMs to excel and achieve notable results\nin various downstream validation tasks, demonstrating their ability to\nrepresent diverse biological entities effectively. Undoubtedly, FMs have\nushered in a new era in computational biology, especially in the realm of deep\nlearning. The primary goal of this survey is to conduct a systematic\ninvestigation and summary of FMs in bioinformatics, tracing their evolution,\ncurrent research status, and the methodologies employed. Central to our focus\nis the application of FMs to specific biological problems, aiming to guide the\nresearch community in choosing appropriate FMs for their research needs. We\ndelve into the specifics of the problem at hand including sequence analysis,\nstructure prediction, function annotation, and multimodal integration,\ncomparing the structures and advancements against traditional methods.\nFurthermore, the review analyses challenges and limitations faced by FMs in\nbiology, such as data noise, model explainability, and potential biases.\nFinally, we outline potential development paths and strategies for FMs in\nfuture biological research, setting the stage for continued innovation and\napplication in this rapidly evolving field. This comprehensive review serves\nnot only as an academic resource but also as a roadmap for future explorations\nand applications of FMs in biology.",
      "tldr_zh": "这篇论文系统调查了 Foundation Models (FMs) 在 Bioinformatics 中的进展和机会，强调 FMs 通过处理大规模未标注数据，成功解决了标注数据稀缺和数据噪声等传统挑战，并在序列分析、结构预测、功能注释以及多模态整合等任务中表现出色。作者比较了 FMs 与传统方法的结构和优势，并分析了其面临的限制，如数据噪声、模型可解释性和潜在偏差。最终，论文为 FMs 在生物信息学未来的发展路径提供了指导策略，作为学术资源和创新路线图。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "cs.CL, 92-02",
        "I.2.1"
      ],
      "primary_category": "q-bio.QM",
      "comment": "27 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.04286v1",
      "published_date": "2024-02-06 02:29:17 UTC",
      "updated_date": "2024-02-06 02:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:04:07.161049"
    },
    {
      "arxiv_id": "2402.03630v2",
      "title": "Enhancing LLM-Based Coding Tools through Native Integration of IDE-Derived Static Context",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Li",
        "Yun Peng",
        "Yintong Huo",
        "Michael R. Lyu"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success in code\ncompletion, as evidenced by their essential roles in developing code assistant\nservices such as Copilot. Being trained on in-file contexts, current LLMs are\nquite effective in completing code for single source files. However, it is\nchallenging for them to conduct repository-level code completion for large\nsoftware projects that require cross-file information. Existing research on\nLLM-based repository-level code completion identifies and integrates cross-file\ncontexts, but it suffers from low accuracy and limited context length of LLMs.\nIn this paper, we argue that Integrated Development Environments (IDEs) can\nprovide direct, accurate and real-time cross-file information for\nrepository-level code completion. We propose IDECoder, a practical framework\nthat leverages IDE native static contexts for cross-context construction and\ndiagnosis results for self-refinement. IDECoder utilizes the rich cross-context\ninformation available in IDEs to enhance the capabilities of LLMs of\nrepository-level code completion. We conducted preliminary experiments to\nvalidate the performance of IDECoder and observed that this synergy represents\na promising trend for future exploration.",
      "tldr_zh": "本文研究发现，现有的 Large Language Models (LLMs) 在代码补全方面表现优秀，但面临仓库级别任务的挑战，因为它们难以处理跨文件信息，导致准确性低下和上下文长度限制。作者提出 IDECoder 框架，通过整合 Integrated Development Environments (IDEs) 的本地静态上下文，进行跨上下文构建和自优化诊断，以增强 LLMs 的仓库级别代码补全能力。该框架利用 IDE 提供的直接、准确的实时信息，显著提升了代码补全的性能；初步实验验证了其有效性，并指出这种协同方法为未来 LLM-based 编码工具的发展提供了有前景的探索方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03630v2",
      "published_date": "2024-02-06 01:59:41 UTC",
      "updated_date": "2024-02-19 06:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:04:18.244702"
    },
    {
      "arxiv_id": "2402.03627v2",
      "title": "Partially Recentralization Softmax Loss for Vision-Language Models Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Jinzhe Jiang",
        "Xin Zhang",
        "Chen Li"
      ],
      "abstract": "As Large Language Models make a breakthrough in natural language processing\ntasks (NLP), multimodal technique becomes extremely popular. However, it has\nbeen shown that multimodal NLP are vulnerable to adversarial attacks, where the\noutputs of a model can be dramatically changed by a perturbation to the input.\nWhile several defense techniques have been proposed both in computer vision and\nNLP models, the multimodal robustness of models have not been fully explored.\nIn this paper, we study the adversarial robustness provided by modifying loss\nfunction of pre-trained multimodal models, by restricting top K softmax\noutputs. Based on the evaluation and scoring, our experiments show that after a\nfine-tuning, adversarial robustness of pre-trained models can be significantly\nimproved, against popular attacks. Further research should be studying, such as\noutput diversity, generalization and the robustness-performance trade-off of\nthis kind of loss functions. Our code will be available after this paper is\naccepted",
      "tldr_zh": "本研究针对视觉语言模型(Vision-Language Models)的对抗鲁棒性问题，提出了一种Partially Recentralization Softmax Loss方法，通过限制softmax输出的前K值来修改预训练模型的损失函数，从而提升模型对对抗攻击的抵抗力。实验结果显示，这种微调策略显著提高了预训练模型的鲁棒性，在常见攻击下表现出色。未来工作包括探索输出多样性、模型泛化和鲁棒性与性能之间的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03627v2",
      "published_date": "2024-02-06 01:44:38 UTC",
      "updated_date": "2024-10-08 08:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:04:29.699730"
    },
    {
      "arxiv_id": "2402.03621v1",
      "title": "Neural Network Approximators for Marginal MAP in Probabilistic Circuits",
      "title_zh": "神经网络逼近器用于概率电路中的边缘MAP",
      "authors": [
        "Shivvrat Arya",
        "Tahrima Rahman",
        "Vibhav Gogate"
      ],
      "abstract": "Probabilistic circuits (PCs) such as sum-product networks efficiently\nrepresent large multi-variate probability distributions. They are preferred in\npractice over other probabilistic representations such as Bayesian and Markov\nnetworks because PCs can solve marginal inference (MAR) tasks in time that\nscales linearly in the size of the network. Unfortunately, the\nmaximum-a-posteriori (MAP) and marginal MAP (MMAP) tasks remain NP-hard in\nthese models. Inspired by the recent work on using neural networks for\ngenerating near-optimal solutions to optimization problems such as integer\nlinear programming, we propose an approach that uses neural networks to\napproximate (M)MAP inference in PCs. The key idea in our approach is to\napproximate the cost of an assignment to the query variables using a continuous\nmultilinear function, and then use the latter as a loss function. The two main\nbenefits of our new method are that it is self-supervised and after the neural\nnetwork is learned, it requires only linear time to output a solution. We\nevaluate our new approach on several benchmark datasets and show that it\noutperforms three competing linear time approximations, max-product inference,\nmax-marginal inference and sequential estimation, which are used in practice to\nsolve MMAP tasks in PCs.",
      "tldr_zh": "该研究针对Probabilistic Circuits (PCs)中边缘最大后验(Marginal MAP, MMAP)推理的NP-hard问题，提出了一种使用神经网络的近似方法。关键创新是将查询变量的分配成本近似为一个连续的多线性函数，并将其用作损失函数，从而实现自监督学习。实验结果显示，该方法在多个基准数据集上优于现有线性时间近似技术，如max-product推理、max-marginal推理和sequential estimation，仅需线性时间即可输出高质量解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Will appear in AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03621v1",
      "published_date": "2024-02-06 01:15:06 UTC",
      "updated_date": "2024-02-06 01:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:04:41.854115"
    },
    {
      "arxiv_id": "2402.03620v1",
      "title": "Self-Discover: Large Language Models Self-Compose Reasoning Structures",
      "title_zh": "Self-Discover：大型语言模型自我组合推理结构",
      "authors": [
        "Pei Zhou",
        "Jay Pujara",
        "Xiang Ren",
        "Xinyun Chen",
        "Heng-Tze Cheng",
        "Quoc V. Le",
        "Ed H. Chi",
        "Denny Zhou",
        "Swaroop Mishra",
        "Huaixiu Steven Zheng"
      ],
      "abstract": "We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the\ntask-intrinsic reasoning structures to tackle complex reasoning problems that\nare challenging for typical prompting methods. Core to the framework is a\nself-discovery process where LLMs select multiple atomic reasoning modules such\nas critical thinking and step-by-step thinking, and compose them into an\nexplicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER\nsubstantially improves GPT-4 and PaLM 2's performance on challenging reasoning\nbenchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as\nmuch as 32% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER\noutperforms inference-intensive methods such as CoT-Self-Consistency by more\nthan 20%, while requiring 10-40x fewer inference compute. Finally, we show that\nthe self-discovered reasoning structures are universally applicable across\nmodel families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share\ncommonalities with human reasoning patterns.",
      "tldr_zh": "本文提出 SELF-DISCOVER 框架，让大型语言模型 (LLMs) 通过自发现过程自行选择和组合原子推理模块（如批判性思考和逐步思考），以构建显式推理结构，解决复杂推理问题。相比传统 Chain of Thought (CoT) 方法，该框架显著提升了 GPT-4 和 PaLM 2 在 BigBench-Hard、grounded agent reasoning 和 MATH 等基准上的性能，高达 32% 的改进，同时比 CoT-Self-Consistency 提高超过 20%，并仅需 10-40 倍更少的推理计算。SELF-DISCOVER 的推理结构在不同模型家族（如 PaLM 2-L 到 GPT-4 和 Llama2）中通用，并显示出与人类推理模式的共同点。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 11 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.03620v1",
      "published_date": "2024-02-06 01:13:53 UTC",
      "updated_date": "2024-02-06 01:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:04:56.722017"
    },
    {
      "arxiv_id": "2402.03618v1",
      "title": "Comparing Abstraction in Humans and Large Language Models Using Multimodal Serial Reproduction",
      "title_zh": "翻译失败",
      "authors": [
        "Sreejan Kumar",
        "Raja Marjieh",
        "Byron Zhang",
        "Declan Campbell",
        "Michael Y. Hu",
        "Umang Bhatt",
        "Brenden Lake",
        "Thomas L. Griffiths"
      ],
      "abstract": "Humans extract useful abstractions of the world from noisy sensory data.\nSerial reproduction allows us to study how people construe the world through a\nparadigm similar to the game of telephone, where one person observes a stimulus\nand reproduces it for the next to form a chain of reproductions. Past serial\nreproduction experiments typically employ a single sensory modality, but humans\noften communicate abstractions of the world to each other through language. To\ninvestigate the effect language on the formation of abstractions, we implement\na novel multimodal serial reproduction framework by asking people who receive a\nvisual stimulus to reproduce it in a linguistic format, and vice versa. We ran\nunimodal and multimodal chains with both humans and GPT-4 and find that adding\nlanguage as a modality has a larger effect on human reproductions than GPT-4's.\nThis suggests human visual and linguistic representations are more dissociable\nthan those of GPT-4.",
      "tldr_zh": "本研究使用多模态串行再现（multimodal serial reproduction）框架，比较了人类和大型语言模型（如 GPT-4）从嘈杂感官数据中提取抽象的过程。研究者设计了实验，让参与者将视觉刺激用语言再现，反之亦然，并在单模态和多模态链中进行测试。结果发现，添加语言作为模态对人类再现的影响远大于对 GPT-4 的，这表明人类的视觉和语言表示（visual and linguistic representations）更易分离。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03618v1",
      "published_date": "2024-02-06 01:07:56 UTC",
      "updated_date": "2024-02-06 01:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:05:06.736729"
    },
    {
      "arxiv_id": "2402.03616v1",
      "title": "Leveraging Large Language Models for Hybrid Workplace Decision Support",
      "title_zh": "翻译失败",
      "authors": [
        "Yujin Kim",
        "Chin-Chia Hsu"
      ],
      "abstract": "Large Language Models (LLMs) hold the potential to perform a variety of text\nprocessing tasks and provide textual explanations for proposed actions or\ndecisions. In the era of hybrid work, LLMs can provide intelligent decision\nsupport for workers who are designing their hybrid work plans. In particular,\nthey can offer suggestions and explanations to workers balancing numerous\ndecision factors, thereby enhancing their work experience. In this paper, we\npresent a decision support model for workspaces in hybrid work environments,\nleveraging the reasoning skill of LLMs. We first examine LLM's capability of\nmaking suitable workspace suggestions. We find that its reasoning extends\nbeyond the guidelines in the prompt and the LLM can manage the trade-off among\nthe available resources in the workspaces. We conduct an extensive user study\nto understand workers' decision process for workspace choices and evaluate the\neffectiveness of the system. We observe that a worker's decision could be\ninfluenced by the LLM's suggestions and explanations. The participants in our\nstudy find the system to be convenient, regardless of whether reasons are\nprovided or not. Our results show that employees can benefit from the\nLLM-empowered system for their workspace selection in hybrid workplace.",
      "tldr_zh": "本研究探讨了利用 Large Language Models (LLMs) 为混合工作环境提供决策支持，提出一个基于 LLMs 推理能力的模型，帮助员工设计工作计划并平衡决策因素。研究首先评估了 LLMs 在建议工作空间方面的能力，发现其能超越提示指导并处理资源权衡。接着，通过广泛的用户研究，观察到 LLMs 的建议和解释能影响员工决策，用户普遍认为系统方便且有益，最终证明了 LLMs 在混合工作场所选择中的实际价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03616v1",
      "published_date": "2024-02-06 01:05:14 UTC",
      "updated_date": "2024-02-06 01:05:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:05:17.494209"
    },
    {
      "arxiv_id": "2402.03610v1",
      "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tomoyuki Kagaya",
        "Thong Jing Yuan",
        "Yuxuan Lou",
        "Jayashree Karlekar",
        "Sugiri Pranata",
        "Akira Kinose",
        "Koki Oguri",
        "Felix Wick",
        "Yang You"
      ],
      "abstract": "Owing to recent advancements, Large Language Models (LLMs) can now be\ndeployed as agents for increasingly complex decision-making applications in\nareas including robotics, gaming, and API integration. However, reflecting past\nexperiences in current decision-making processes, an innate human behavior,\ncontinues to pose significant challenges. Addressing this, we propose\nRetrieval-Augmented Planning (RAP) framework, designed to dynamically leverage\npast experiences corresponding to the current situation and context, thereby\nenhancing agents' planning capabilities. RAP distinguishes itself by being\nversatile: it excels in both text-only and multimodal environments, making it\nsuitable for a wide range of tasks. Empirical evaluations demonstrate RAP's\neffectiveness, where it achieves SOTA performance in textual scenarios and\nnotably enhances multimodal LLM agents' performance for embodied tasks. These\nresults highlight RAP's potential in advancing the functionality and\napplicability of LLM agents in complex, real-world applications.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)作为代理在复杂决策应用（如机器人、游戏和API集成）中的挑战，提出了Retrieval-Augmented Planning (RAP)框架。该框架通过Contextual Memory动态检索和利用过去的经验，增强代理的规划能力，并适用于文本和多模态环境。实验结果显示，RAP在文本场景中达到SOTA性能，并在多模态任务中显著提升LLM代理的表现，展示了其在真实世界复杂应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03610v1",
      "published_date": "2024-02-06 00:53:27 UTC",
      "updated_date": "2024-02-06 00:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:05:29.045168"
    },
    {
      "arxiv_id": "2402.03607v2",
      "title": "Enhancing Cross-Modal Contextual Congruence for Crowdfunding Success using Knowledge-infused Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Trilok Padhi",
        "Ugur Kursuncu",
        "Yaman Kumar",
        "Valerie L. Shalin",
        "Lane Peterson Fronczek"
      ],
      "abstract": "The digital landscape continually evolves with multimodality, enriching the\nonline experience for users. Creators and marketers aim to weave subtle\ncontextual cues from various modalities into congruent content to engage users\nwith a harmonious message. This interplay of multimodal cues is often a crucial\nfactor in attracting users' attention. However, this richness of multimodality\npresents a challenge to computational modeling, as the semantic contextual cues\nspanning across modalities need to be unified to capture the true holistic\nmeaning of the multimodal content. This contextual meaning is critical in\nattracting user engagement as it conveys the intended message of the brand or\nthe organization. In this work, we incorporate external commonsense knowledge\nfrom knowledge graphs to enhance the representation of multimodal data using\ncompact Visual Language Models (VLMs) and predict the success of multi-modal\ncrowdfunding campaigns. Our results show that external knowledge commonsense\nbridges the semantic gap between text and image modalities, and the enhanced\nknowledge-infused representations improve the predictive performance of models\nfor campaign success upon the baselines without knowledge. Our findings\nhighlight the significance of contextual congruence in online multimodal\ncontent for engaging and successful crowdfunding campaigns.",
      "tldr_zh": "本研究旨在通过知识注入学习（Knowledge-infused Learning）增强跨模态上下文一致性（Cross-Modal Contextual Congruence），以提高多模态众筹活动的成功率。研究方法涉及整合外部常识知识从知识图谱（Knowledge Graphs）到紧凑的Visual Language Models (VLMs)，从而桥接文本和图像模态之间的语义差距，并统一多模态内容的整体含义。实验结果表明，知识注入后的表示显著提升了模型的预测性能，相比基线模型表现出色，并突出了上下文一致性在吸引用户参与和提升众筹成功中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.HC",
        "I.2.7; I.2.10; I.2.4; I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE International Conference on Big Data 2024 (IEEE\n  BigData 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.03607v2",
      "published_date": "2024-02-06 00:51:27 UTC",
      "updated_date": "2024-11-17 21:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T04:05:42.023738"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T04:06:00.601606"
}