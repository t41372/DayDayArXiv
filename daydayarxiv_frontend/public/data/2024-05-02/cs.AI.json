{
  "date": "2024-05-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-02 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化、生成式学习、强化学习和多模态应用等领域，强调高效训练、鲁棒性和实际部署；令人印象深刻的包括大型语言模型（LLMs）在个性化生成和多任务处理中的创新，以及一些高效的强化学习框架，而知名学者如 Yoshua Bengio 的相关工作在药物发现领域脱颖而出。\n\n### 重点论文讨论\n我们挑选了最具话题度和影响力的论文进行详细分析，将相关主题归类讨论，先从 LLMs 和 AI 治理入手，再聊强化学习和机器人应用，最后快速概述其他领域。以下是核心内容提取，每个条目包括论文标题（中文 + 英文）和主要贡献。\n\n#### LLMs 和 AI 治理：这些论文探讨了 LLMs 在生成、治理和多任务中的潜力，相关工作如 Anthropic 的 Claude 分析和上下文引导，展示了 LLMs 的实际应用和挑战。\n- **AI 治理和问责制：对 Anthropic 的 Claude 进行分析** (AI Governance and Accountability: An Analysis of Anthropic's Claude)  \n  这篇论文分析了 AI 模型 Anthropic's Claude，通过 NIST AI Risk Management Framework 和 EU AI Act 框架，识别潜在威胁并提出缓解策略。主要贡献是强调透明性、基准测试和数据处理在 AI 部署中的重要性，发现 AI 治理能显著提升社会影响和伦理考虑。\n  \n- **上下文引导：可控的推理时个性化** (Context Steering: Controllable Personalization at Inference Time)  \n  作者包括 Anca Dragan，这篇令人印象深刻的作品引入了 Context Steering (CoS) 方法，用于 LLMs 的推理阶段。主要发现是通过比较有/无上下文的输出概率，实现灵活的个性化响应，并在推荐任务中表现出色，同时扩展为贝叶斯生成模型。\n\n- **LLMs 在 UAV 中的应用** (Large Language Models for UAVs: Current State and Pathways to the Future)  \n  这篇论文探讨了 LLMs 与无人机的整合，评估了 LLMs 架构在 UAV 决策中的适用性。主要贡献是提出 LLMs 用于改进数据分析和光谱感知，扩展 UAV 在紧急响应中的应用，如灾难管理和网络恢复。\n\n- **LLMs 在用户表示学习中的作用** (SoMeR: Multi-View User Representation Learning for Social Media)  \n  论文提出 SoMeR 框架，用于社交媒体的多视图用户表示学习。主要发现是通过整合时间活动、文本和网络交互，SoMeR 能识别信息操作账户、测量在线极化，并预测用户行为，展示了 LLMs 在社会政治领域的潜力。\n\n- **LLMs 的不一致性和偏见** (Large Language Models are Inconsistent and Biased Evaluators)  \n  这篇快速引发讨论的作品揭示了 LLMs 在评估中的偏见，如熟悉偏好和锚定效应。主要贡献是提出改进方法，实验显示 LLMs 在文本评估中不稳定，但通过特定配置可缓解。\n\n其他 LLMs 相关论文，如 \"FLAME: Factuality-Aware Alignment for Large Language Models\" 和 \"Interpretable Data-driven Anomaly Detection\"，则展示了事实性对齐和可解释性的进展，但细节较常规，快速掠过。\n\n#### 强化学习和机器人应用：这些论文强调了 RL 在复杂环境中的鲁棒性，特别是在机器人导航和决策中，相关工作如安全优化和多任务学习。\n- **强化学习引导的半监督学习** (Reinforcement Learning-Guided Semi-Supervised Learning)  \n  论文提出 RLGSSL 方法，将半监督学习表述为单臂赌博问题，并设计加权奖励函数。主要发现是 RLGSSL 在基准数据集上超越了现有方法，提高了泛化性能。\n\n- **智能切换用于无重置 RL** (Intelligent Switching for Reset-Free RL)  \n  这篇论文引入 RISC 算法，用于无重置强化学习环境。主要贡献是通过置信度引导代理切换，实现状态-of-the-art 在挑战性环境中，显著提高了鲁棒性。\n\n- **LLM 引导的 RL 用于机器人任务** (Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks)  \n  论文提出 PSL 框架，将 LLMs 用于高层次规划和 RL 结合。主要发现是 PSL 在视觉输入的机器人任务中实现了高效规划，实验显示在多种基准上成功率超过 85%，远超传统方法。\n\n其他 RL 论文，如 \"Balance Reward and Safety Optimization\"，则专注于安全 RL，但影响较小，简要提及其在梯度操作中的优化。\n\n#### 图像处理和医疗 AI：这些论文关注高效生成和医疗应用，突出了生成模型在实际场景中的潜力。\n- **无分割的头颈癌预测** (Segmentation-Free Outcome Prediction from Head and Neck Cancer PET/CT Images)  \n  这篇论文提出基于深度特征提取的分割-free 方法，用于 PET/CT 图像分析。主要贡献是通过多角度投影融合，提高了癌症预后分析的准确性和可重复性，实验在 489 例患者中超越基准。\n\n- **量子迁移学习用于糖尿病视网膜病变检测** (Diabetic Retinopathy Detection Using Quantum Transfer Learning)  \n  论文使用量子迁移学习结合 ResNet 等网络检测视网膜病变。主要发现是模型在 Kaggle 数据集上达到 97% 准确率，展示了量子计算在医疗图像中的潜力。\n\n其他图像论文，如 \"Towards Inclusive Face Recognition\" 和 \"Efficient Compression of Multitask Multilingual Speech Models\"，则优化了生成和压缩，但不那么核心，快速掠过其在多样性和效率上的改进。\n\n### 其他快速概述\n剩余论文涉及生成模型、量子计算和杂项主题，如 \"Generative Active Learning for the Search of Small-molecule Protein Binders\"（Yoshua Bengio 参与，贡献了药物发现的生成 RL 方法）和 \"Quantum Transfer Learning\" 等，但这些较专业或冗长，仅提及其在小分子搜索和量子领域的创新。总体上，今天的论文展示了 AI 模型在高效、鲁棒和实际应用中的进展，但许多仍需关注泛化性和伦理问题。\n\n今天的快报到此结束，感谢阅读！如果您对特定主题感兴趣，建议查看这些论文的摘要。",
  "papers": [
    {
      "arxiv_id": "2407.01557v1",
      "title": "AI Governance and Accountability: An Analysis of Anthropic's Claude",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Priyanshu",
        "Yash Maurya",
        "Zuofei Hong"
      ],
      "abstract": "As AI systems become increasingly prevalent and impactful, the need for\neffective AI governance and accountability measures is paramount. This paper\nexamines the AI governance landscape, focusing on Anthropic's Claude, a\nfoundational AI model. We analyze Claude through the lens of the NIST AI Risk\nManagement Framework and the EU AI Act, identifying potential threats and\nproposing mitigation strategies. The paper highlights the importance of\ntransparency, rigorous benchmarking, and comprehensive data handling processes\nin ensuring the responsible development and deployment of AI systems. We\nconclude by discussing the social impact of AI governance and the ethical\nconsiderations surrounding AI accountability.",
      "tldr_zh": "这篇论文分析了 AI 治理和责任框架，焦点在于 Anthropic's Claude 模型，通过 NIST AI Risk Management Framework 和 EU AI Act 的视角识别潜在威胁并提出缓解策略。研究强调透明性、严格基准测试以及全面数据处理在确保 AI 系统负责开发和部署中的关键作用。主要结论讨论了 AI 治理的社会影响和相关伦理考虑，为构建可信赖的 AI 生态提供见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01557v1",
      "published_date": "2024-05-02 23:37:06 UTC",
      "updated_date": "2024-05-02 23:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:15:36.271042"
    },
    {
      "arxiv_id": "2405.01776v1",
      "title": "An Approach to Systematic Data Acquisition and Data-Driven Simulation for the Safety Testing of Automated Driving Functions",
      "title_zh": "一种针对自动驾驶功能的系统化数据采集和数据驱动模拟方法，用于安全测试",
      "authors": [
        "Leon Eisemann",
        "Mirjam Fehling-Kaschek",
        "Henrik Gommel",
        "David Hermann",
        "Marvin Klemp",
        "Martin Lauer",
        "Benjamin Lickert",
        "Florian Luettner",
        "Robin Moss",
        "Nicole Neis",
        "Maria Pohle",
        "Simon Romanski",
        "Daniel Stadler",
        "Alexander Stolz",
        "Jens Ziehn",
        "Jingxing Zhou"
      ],
      "abstract": "With growing complexity and criticality of automated driving functions in\nroad traffic and their operational design domains (ODD), there is increasing\ndemand for covering significant proportions of development, validation, and\nverification in virtual environments and through simulation models.\n  If, however, simulations are meant not only to augment real-world\nexperiments, but to replace them, quantitative approaches are required that\nmeasure to what degree and under which preconditions simulation models\nadequately represent reality, and thus, using their results accordingly.\nEspecially in R&D areas related to the safety impact of the \"open world\", there\nis a significant shortage of real-world data to parameterize and/or validate\nsimulations - especially with respect to the behavior of human traffic\nparticipants, whom automated driving functions will meet in mixed traffic.\n  We present an approach to systematically acquire data in public traffic by\nheterogeneous means, transform it into a unified representation, and use it to\nautomatically parameterize traffic behavior models for use in data-driven\nvirtual validation of automated driving functions.",
      "tldr_zh": "该论文针对自动驾驶功能的开发、验证和安全测试，强调了虚拟模拟的需求以及真实世界数据短缺的问题，特别是人类交通参与者的行为数据。研究提出了一种系统方法，通过异构手段在公共交通中获取数据，将其转化为统一的表示形式，并自动参数化交通行为模型。最终，该方法支持数据驱动的模拟，用于虚拟验证自动驾驶功能，从而在 Operational Design Domains (ODD) 中提升模拟的准确性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01776v1",
      "published_date": "2024-05-02 23:24:27 UTC",
      "updated_date": "2024-05-02 23:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:15:50.470988"
    },
    {
      "arxiv_id": "2405.01768v3",
      "title": "Context Steering: Controllable Personalization at Inference Time",
      "title_zh": "Context Steering：在推理时的可控个性化",
      "authors": [
        "Jerry Zhi-Yang He",
        "Sashrika Pandey",
        "Mariah L. Schrum",
        "Anca Dragan"
      ],
      "abstract": "To deliver high-quality, personalized responses, large language models (LLMs)\nmust effectively incorporate context -- personal, demographic, and cultural\ninformation specific to an end-user. For example, asking the model to explain\nNewton's second law with the context \"I am a toddler\" should produce a response\ndifferent from when the context is \"I am a physics professor\". However,\nleveraging the context in practice is a nuanced and challenging task, and is\noften dependent on the specific situation or user base. The model must strike a\nbalance between providing specific, personalized responses and maintaining\ngeneral applicability. Current solutions, such as prompt-engineering and\nfine-tuning, require collection of contextually appropriate responses as\nexamples, making them time-consuming and less flexible to use across different\ncontexts. In this work, we introduce Context Steering (CoS) -- a simple,\ntraining-free decoding approach that amplifies the influence of the context in\nnext token predictions. CoS computes contextual influence by comparing the\noutput probabilities from two LLM forward passes: one that includes the context\nand one that does not. By linearly scaling the contextual influence, CoS allows\npractitioners to flexibly control the degree of personalization for different\nuse cases. We show that CoS can be applied to autoregressive LLMs, and\ndemonstrates strong performance in personalized recommendations. Additionally,\nwe show that CoS can function as a Bayesian Generative model to infer and\nquantify correlations between open-ended texts, broadening its potential\napplications.",
      "tldr_zh": "这篇论文介绍了Context Steering (CoS)，一种无需训练的解码方法，用于在推理阶段实现可控的个性化响应，使大型语言模型 (LLMs) 更好地整合用户上下文（如个人、人口统计或文化信息）。CoS 通过比较带上下文和不带上下文的LLM输出概率来计算并放大上下文影响，并通过线性缩放允许用户灵活调整个性化程度，从而平衡通用性和特定性。实验结果显示，CoS在个性化推荐任务中表现出色，并能作为Bayesian Generative模型来推断和量化开放文本之间的相关性，为高效的上下文应用提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01768v3",
      "published_date": "2024-05-02 22:37:38 UTC",
      "updated_date": "2025-02-06 03:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:16:01.811040"
    },
    {
      "arxiv_id": "2405.05275v2",
      "title": "SoMeR: Multi-View User Representation Learning for Social Media",
      "title_zh": "SoMeR：社交媒体的多视图用户表示",
      "authors": [
        "Siyi Guo",
        "Keith Burghardt",
        "Valeria Pantè",
        "Kristina Lerman"
      ],
      "abstract": "Social media user representation learning aims to capture user preferences,\ninterests, and behaviors in low-dimensional vector representations. These\nrepresentations are critical to a range of social problems, including\npredicting user behaviors and detecting inauthentic accounts. However, existing\nmethods are either designed for commercial applications, or rely on specific\nfeatures like text contents, activity patterns, or platform metadata, failing\nto holistically model user behavior across different modalities. To address\nthese limitations, we propose SoMeR, a Social Media user Representation\nlearning framework that incorporates temporal activities, text contents,\nprofile information, and network interactions to learn comprehensive user\nportraits. SoMeR encodes user post streams as sequences of time-stamped textual\nfeatures, uses transformers to embed this along with profile data, and jointly\ntrains with link prediction and contrastive learning objectives to capture user\nsimilarity. We demonstrate SoMeR's versatility through three applications: 1)\nIdentifying information operation driver accounts, 2) Measuring online\npolarization after major events, and 3) Predicting future user participation in\nReddit hate communities. SoMeR provides new solutions to better understand user\nbehavior in the socio-political domains, enabling more informed decisions and\ninterventions.",
      "tldr_zh": "该研究提出 SoMeR，一种多视图用户表示学习框架，用于社交媒体，旨在通过整合时间活动、文本内容、个人资料信息和网络互动，全面捕捉用户的偏好、兴趣和行为。SoMeR 将用户帖子流编码为时间戳文本特征序列，使用 Transformers 进行嵌入，并结合链接预测和对比学习目标来训练用户相似性模型。实验结果显示，SoMeR 在三个应用中表现出色，包括识别信息操作驱动账户、测量重大事件后的在线极化和预测用户未来参与 Reddit 仇恨社区，从而为社交政治领域的用户行为理解提供新解决方案。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05275v2",
      "published_date": "2024-05-02 22:26:55 UTC",
      "updated_date": "2025-03-20 23:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:16:15.134869"
    },
    {
      "arxiv_id": "2405.01760v1",
      "title": "Reinforcement Learning-Guided Semi-Supervised Learning",
      "title_zh": "强化学习引导的半监督学习",
      "authors": [
        "Marzi Heidari",
        "Hanping Zhang",
        "Yuhong Guo"
      ],
      "abstract": "In recent years, semi-supervised learning (SSL) has gained significant\nattention due to its ability to leverage both labeled and unlabeled data to\nimprove model performance, especially when labeled data is scarce. However,\nmost current SSL methods rely on heuristics or predefined rules for generating\npseudo-labels and leveraging unlabeled data. They are limited to exploiting\nloss functions and regularization methods within the standard norm. In this\npaper, we propose a novel Reinforcement Learning (RL) Guided SSL method,\nRLGSSL, that formulates SSL as a one-armed bandit problem and deploys an\ninnovative RL loss based on weighted reward to adaptively guide the learning\nprocess of the prediction model. RLGSSL incorporates a carefully designed\nreward function that balances the use of labeled and unlabeled data to enhance\ngeneralization performance. A semi-supervised teacher-student framework is\nfurther deployed to increase the learning stability. We demonstrate the\neffectiveness of RLGSSL through extensive experiments on several benchmark\ndatasets and show that our approach achieves consistent superior performance\ncompared to state-of-the-art SSL methods.",
      "tldr_zh": "该论文提出了一种新型方法 RLGSSL，将强化学习 (RL) 应用于半监督学习 (SSL)，通过将 SSL 形式化为单臂赌博机问题 (one-armed bandit problem) 并使用基于加权奖励的 RL 损失，来自适应地指导预测模型的学习过程。方法设计了一个奖励函数来平衡标记和未标记数据的利用，并引入半监督的教师-学生框架以提高学习稳定性。与传统 SSL 方法相比，RLGSSL 在多个基准数据集上的实验中表现出色，实现了比现有最先进方法更优的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01760v1",
      "published_date": "2024-05-02 21:52:24 UTC",
      "updated_date": "2024-05-02 21:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:16:26.361803"
    },
    {
      "arxiv_id": "2405.01756v3",
      "title": "Segmentation-Free Outcome Prediction from Head and Neck Cancer PET/CT Images: Deep Learning-Based Feature Extraction from Multi-Angle Maximum Intensity Projections (MA-MIPs)",
      "title_zh": "翻译失败",
      "authors": [
        "Amirhosein Toosi",
        "Isaac Shiri",
        "Habib Zaidi",
        "Arman Rahmim"
      ],
      "abstract": "We introduce an innovative, simple, effective segmentation-free approach for\noutcome prediction in head \\& neck cancer (HNC) patients. By harnessing deep\nlearning-based feature extraction techniques and multi-angle maximum intensity\nprojections (MA-MIPs) applied to Fluorodeoxyglucose Positron Emission\nTomography (FDG-PET) volumes, our proposed method eliminates the need for\nmanual segmentations of regions-of-interest (ROIs) such as primary tumors and\ninvolved lymph nodes. Instead, a state-of-the-art object detection model is\ntrained to perform automatic cropping of the head and neck region on the PET\nvolumes. A pre-trained deep convolutional neural network backbone is then\nutilized to extract deep features from MA-MIPs obtained from 72 multi-angel\naxial rotations of the cropped PET volumes. These deep features extracted from\nmultiple projection views of the PET volumes are then aggregated and fused, and\nemployed to perform recurrence-free survival analysis on a cohort of 489 HNC\npatients. The proposed approach outperforms the best performing method on the\ntarget dataset for the task of recurrence-free survival analysis. By\ncircumventing the manual delineation of the malignancies on the FDG PET-CT\nimages, our approach eliminates the dependency on subjective interpretations\nand highly enhances the reproducibility of the proposed survival analysis\nmethod.",
      "tldr_zh": "本研究提出了一种无需分割的创新方法，用于预测头颈癌（HNC）患者的预后，通过深度学习（deep learning）提取特征并应用多角度最大强度投影（MA-MIPs）到FDG-PET图像上。该方法先利用先进的物体检测模型自动裁剪头颈区域，然后从72个多角度轴向旋转的PET体积中提取深度特征，并将这些特征聚合融合，用于对489名HNC患者的无复发生存分析（recurrence-free survival analysis）。结果显示，该方法在目标数据集上超过了最佳基准模型的性能，同时避免了手动分割肿瘤的依赖性，大大提高了分析的可再现性和客观性。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "62Nxx",
        "I.2.m"
      ],
      "primary_category": "physics.med-ph",
      "comment": "15 pages, 4 tables, 4 figures. Published in Cancers 2024, Volume 16,\n  Issue 14, page 2538",
      "pdf_url": "http://arxiv.org/pdf/2405.01756v3",
      "published_date": "2024-05-02 21:46:13 UTC",
      "updated_date": "2024-12-04 12:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:16:38.325000"
    },
    {
      "arxiv_id": "2405.01745v1",
      "title": "Large Language Models for UAVs: Current State and Pathways to the Future",
      "title_zh": "翻译失败",
      "authors": [
        "Shumaila Javaid",
        "Nasir Saeed",
        "Bin He"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as a transformative technology\nacross diverse sectors, offering adaptable solutions to complex challenges in\nboth military and civilian domains. Their expanding capabilities present a\nplatform for further advancement by integrating cutting-edge computational\ntools like Artificial Intelligence (AI) and Machine Learning (ML) algorithms.\nThese advancements have significantly impacted various facets of human life,\nfostering an era of unparalleled efficiency and convenience. Large Language\nModels (LLMs), a key component of AI, exhibit remarkable learning and\nadaptation capabilities within deployed environments, demonstrating an evolving\nform of intelligence with the potential to approach human-level proficiency.\nThis work explores the significant potential of integrating UAVs and LLMs to\npropel the development of autonomous systems. We comprehensively review LLM\narchitectures, evaluating their suitability for UAV integration. Additionally,\nwe summarize the state-of-the-art LLM-based UAV architectures and identify\nnovel opportunities for LLM embedding within UAV frameworks. Notably, we focus\non leveraging LLMs to refine data analysis and decision-making processes,\nspecifically for enhanced spectral sensing and sharing in UAV applications.\nFurthermore, we investigate how LLM integration expands the scope of existing\nUAV applications, enabling autonomous data processing, improved\ndecision-making, and faster response times in emergency scenarios like disaster\nresponse and network restoration. Finally, we highlight crucial areas for\nfuture research that are critical for facilitating the effective integration of\nLLMs and UAVs.",
      "tldr_zh": "这篇论文探讨了将大型语言模型（LLMs）整合到无人驾驶航空器（UAVs）中的潜力，以推进自主系统的开发。作者全面回顾了LLMs的架构，评估其适用于UAVs的适用性，并总结了现有LLM-based UAV架构，同时识别了新的机会，如提升数据分析和决策过程，特别是针对光谱感知和共享。研究发现，这种整合可扩展UAVs的应用，实现自主数据处理、改进决策和更快响应，例如在灾害响应和网络恢复等紧急场景中。最后，论文强调了未来研究的关键领域，以推动LLMs和UAVs的有效融合。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01745v1",
      "published_date": "2024-05-02 21:30:10 UTC",
      "updated_date": "2024-05-02 21:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:16:50.363996"
    },
    {
      "arxiv_id": "2405.01744v2",
      "title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
      "title_zh": "ALCM：自主 LLM 增强型因果发现框架",
      "authors": [
        "Elahe Khatibi",
        "Mahyar Abbasian",
        "Zhongqi Yang",
        "Iman Azimi",
        "Amir M. Rahmani"
      ],
      "abstract": "To perform effective causal inference in high-dimensional datasets,\ninitiating the process with causal discovery is imperative, wherein a causal\ngraph is generated based on observational data. However, obtaining a complete\nand accurate causal graph poses a formidable challenge, recognized as an NP-\nhard problem. Recently, the advent of Large Language Models (LLMs) has ushered\nin a new era, indicating their emergent capabilities and widespread\napplicability in facilitating causal reasoning across diverse domains, such as\nmedicine, finance, and science. The expansive knowledge base of LLMs holds the\npotential to elevate the field of causal reasoning by offering\ninterpretability, making inferences, generalizability, and uncovering novel\ncausal structures. In this paper, we introduce a new framework, named\nAutonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize\ndata-driven causal discovery algorithms and LLMs, automating the generation of\na more resilient, accurate, and explicable causal graph. The ALCM consists of\nthree integral components: causal structure learning, causal wrapper, and\nLLM-driven causal refiner. These components autonomously collaborate within a\ndynamic environment to address causal discovery questions and deliver plausible\ncausal graphs. We evaluate the ALCM framework by implementing two\ndemonstrations on seven well-known datasets. Experimental results demonstrate\nthat ALCM outperforms existing LLM methods and conventional data-driven causal\nreasoning mechanisms. This study not only shows the effectiveness of the ALCM\nbut also underscores new research directions in leveraging the causal reasoning\ncapabilities of LLMs.",
      "tldr_zh": "该论文提出ALCM框架，一种自主的LLM-Augmented因果发现框架，用于解决高维数据集中的因果推理挑战，通过结合数据驱动的因果结构学习和LLMs的知识优势。框架包括三个关键组件：causal structure learning、causal wrapper和LLM-driven causal refiner，这些组件在动态环境中自主协作，以生成更准确、可解释的因果图。实验在七个知名数据集上评估，结果显示ALCM优于现有LLM方法和传统数据驱动机制，并为LLMs在因果推理领域的应用开辟新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01744v2",
      "published_date": "2024-05-02 21:27:45 UTC",
      "updated_date": "2025-04-16 19:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:17:01.967680"
    },
    {
      "arxiv_id": "2405.01741v3",
      "title": "PVF (Parameter Vulnerability Factor): A Scalable Metric for Understanding AI Vulnerability Against SDCs in Model Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Xun Jiao",
        "Fred Lin",
        "Harish D. Dixit",
        "Joel Coburn",
        "Abhinav Pandey",
        "Han Wang",
        "Venkat Ramesh",
        "Jianyu Huang",
        "Wang Xu",
        "Daniel Moore",
        "Sriram Sankar"
      ],
      "abstract": "Reliability of AI systems is a fundamental concern for the successful\ndeployment and widespread adoption of AI technologies. Unfortunately, the\nescalating complexity and heterogeneity of AI hardware systems make them\nincreasingly susceptible to hardware faults, e.g., silent data corruptions\n(SDC), that can potentially corrupt model parameters. When this occurs during\nAI inference/servicing, it can potentially lead to incorrect or degraded model\noutput for users, ultimately affecting the quality and reliability of AI\nservices. In light of the escalating threat, it is crucial to address key\nquestions: How vulnerable are AI models to parameter corruptions, and how do\ndifferent components (such as modules, layers) of the models exhibit varying\nvulnerabilities to parameter corruptions? To systematically address this\nquestion, we propose a novel quantitative metric, Parameter Vulnerability\nFactor (PVF), inspired by architectural vulnerability factor (AVF) in computer\narchitecture community, aiming to standardize the quantification of AI model\nvulnerability against parameter corruptions. We define a model parameter's PVF\nas the probability that a corruption in that particular model parameter will\nresult in an incorrect output. In this paper, we present several use cases on\napplying PVF to three types of tasks/models during inference -- recommendation\n(DLRM), vision classification (CNN), and text classification (BERT), while\npresenting an in-depth vulnerability analysis on DLRM. PVF can provide pivotal\ninsights to AI hardware designers in balancing the tradeoff between fault\nprotection and performance/efficiency such as mapping vulnerable AI parameter\ncomponents to well-protected hardware modules. PVF metric is applicable to any\nAI model and has a potential to help unify and standardize AI\nvulnerability/resilience evaluation practice.",
      "tldr_zh": "本文提出了一种可扩展指标 Parameter Vulnerability Factor (PVF)，用于量化 AI 模型对 Silent Data Corruptions (SDCs) 导致的参数损坏的脆弱性，定义为特定参数损坏导致输出错误的概率。研究者将 PVF 应用于推荐任务 (DLRM)、视觉分类 (CNN) 和文本分类 (BERT) 等模型，并对 DLRM 进行深入分析，揭示不同模型组件的脆弱性差异。PVF 提供关键洞见，帮助 AI 硬件设计师在故障保护与性能效率之间权衡，例如将易受损参数映射到更可靠的硬件模块，并有望统一 AI 脆弱性评估标准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01741v3",
      "published_date": "2024-05-02 21:23:34 UTC",
      "updated_date": "2024-06-11 22:37:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:17:14.799058"
    },
    {
      "arxiv_id": "2405.01734v1",
      "title": "Diabetic Retinopathy Detection Using Quantum Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ankush Jain",
        "Rinav Gupta",
        "Jai Singhal"
      ],
      "abstract": "Diabetic Retinopathy (DR), a prevalent complication in diabetes patients, can\nlead to vision impairment due to lesions formed on the retina. Detecting DR at\nan advanced stage often results in irreversible blindness. The traditional\nprocess of diagnosing DR through retina fundus images by ophthalmologists is\nnot only time-intensive but also expensive. While classical transfer learning\nmodels have been widely adopted for computer-aided detection of DR, their high\nmaintenance costs can hinder their detection efficiency. In contrast, Quantum\nTransfer Learning offers a more effective solution to this challenge. This\napproach is notably advantageous because it operates on heuristic principles,\nmaking it highly optimized for the task. Our proposed methodology leverages\nthis hybrid quantum transfer learning technique to detect DR. To construct our\nmodel, we utilize the APTOS 2019 Blindness Detection dataset, available on\nKaggle. We employ the ResNet-18, ResNet34, ResNet50, ResNet101, ResNet152 and\nInception V3, pre-trained classical neural networks, for the initial feature\nextraction. For the classification stage, we use a Variational Quantum\nClassifier. Our hybrid quantum model has shown remarkable results, achieving an\naccuracy of 97% for ResNet-18. This demonstrates that quantum computing, when\nintegrated with quantum machine learning, can perform tasks with a level of\npower and efficiency unattainable by classical computers alone. By harnessing\nthese advanced technologies, we can significantly improve the detection and\ndiagnosis of Diabetic Retinopathy, potentially saving many from the risk of\nblindness.\n  Keywords: Diabetic Retinopathy, Quantum Transfer Learning, Deep Learning",
      "tldr_zh": "该研究针对糖尿病视网膜病变（Diabetic Retinopathy）检测问题，提出了一种基于Quantum Transfer Learning的混合方法，以解决传统诊断耗时且成本高的挑战。该方法首先利用预训练的经典神经网络（如ResNet-18、ResNet-50和Inception V3）进行特征提取，然后采用Variational Quantum Classifier进行分类，使用APTOS 2019数据集进行训练。实验结果显示，该模型在ResNet-18上达到了97%的准确率，显著提高了检测效率。总体而言，这展示了Quantum Transfer Learning在医疗图像处理中的潜力，有望通过更高效的诊断减少失明风险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 12 figures and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.01734v1",
      "published_date": "2024-05-02 21:09:39 UTC",
      "updated_date": "2024-05-02 21:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:17:24.860957"
    },
    {
      "arxiv_id": "2405.02351v2",
      "title": "Towards General Neural Surrogate Solvers with Specialized Neural Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Chenkai Mao",
        "Robert Lupoiu",
        "Tianxiang Dai",
        "Mingkun Chen",
        "Jonathan A. Fan"
      ],
      "abstract": "Surrogate neural network-based partial differential equation (PDE) solvers\nhave the potential to solve PDEs in an accelerated manner, but they are largely\nlimited to systems featuring fixed domain sizes, geometric layouts, and\nboundary conditions. We propose Specialized Neural Accelerator-Powered Domain\nDecomposition Methods (SNAP-DDM), a DDM-based approach to PDE solving in which\nsubdomain problems containing arbitrary boundary conditions and geometric\nparameters are accurately solved using an ensemble of specialized neural\noperators. We tailor SNAP-DDM to 2D electromagnetics and fluidic flow problems\nand show how innovations in network architecture and loss function engineering\ncan produce specialized surrogate subdomain solvers with near unity accuracy.\nWe utilize these solvers with standard DDM algorithms to accurately solve\nfreeform electromagnetics and fluids problems featuring a wide range of domain\nsizes.",
      "tldr_zh": "该研究针对现有神经代理偏微分方程(PDE)求解器受限于固定域大小、几何布局和边界条件的局限性，提出了一种基于域分解方法(Domain Decomposition Methods)的框架，即SNAP-DDM。SNAP-DDM使用一组专门的神经算子(specialized neural operators)来精确解决子域问题，通过创新的网络架构和损失函数设计，实现近乎完美的准确性。实验结果显示，该方法能有效应用于2D电磁学和流体流动问题，并准确处理各种域大小的自由形式问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "physics.optics"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 7 Figures, to be published in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02351v2",
      "published_date": "2024-05-02 21:08:49 UTC",
      "updated_date": "2024-06-14 23:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:17:37.276206"
    },
    {
      "arxiv_id": "2405.01724v1",
      "title": "Large Language Models are Inconsistent and Biased Evaluators",
      "title_zh": "大语言模型是不一致且有偏见的评估者",
      "authors": [
        "Rickard Stureborg",
        "Dimitris Alikaniotis",
        "Yoshi Suhara"
      ],
      "abstract": "The zero-shot capability of Large Language Models (LLMs) has enabled highly\nflexible, reference-free metrics for various tasks, making LLM evaluators\ncommon tools in NLP. However, the robustness of these LLM evaluators remains\nrelatively understudied; existing work mainly pursued optimal performance in\nterms of correlating LLM scores with human expert scores. In this paper, we\nconduct a series of analyses using the SummEval dataset and confirm that LLMs\nare biased evaluators as they: (1) exhibit familiarity bias-a preference for\ntext with lower perplexity, (2) show skewed and biased distributions of\nratings, and (3) experience anchoring effects for multi-attribute judgments. We\nalso found that LLMs are inconsistent evaluators, showing low \"inter-sample\"\nagreement and sensitivity to prompt differences that are insignificant to human\nunderstanding of text quality. Furthermore, we share recipes for configuring\nLLM evaluators to mitigate these limitations. Experimental results on the RoSE\ndataset demonstrate improvements over the state-of-the-art LLM evaluators.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 作为评估器的局限性，包括偏差和不一致性问题。作者使用 SummEval 数据集进行分析，确认 LLMs 存在熟悉性偏差 (familiarity bias)——偏好低 perplexity 的文本、评分分布偏差以及锚定效应 (anchoring effects) 在多属性判断中的影响，同时显示 LLMs 在不同样本间的协议较低，且对提示变化高度敏感。实验结果表明，这些问题导致 LLMs 评估不稳定，但在 RoSE 数据集上，通过共享的配置配方（如优化提示和调整模型参数），可以显著改善评估性能，超越现有最先进方法。整体而言，该工作强调了在使用 LLMs 作为评估工具时需注意其固有偏见，并提供了实用缓解策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Primary) 68T01, 68T37, 91F20 (Secondary)",
        "I.2; I.2.7; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01724v1",
      "published_date": "2024-05-02 20:42:28 UTC",
      "updated_date": "2024-05-02 20:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:17:49.544569"
    },
    {
      "arxiv_id": "2405.01723v1",
      "title": "Zero-Shot Monocular Motion Segmentation in the Wild by Combining Deep Learning with Geometric Motion Model Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Huang",
        "Yuhao Chen",
        "John Zelek"
      ],
      "abstract": "Detecting and segmenting moving objects from a moving monocular camera is\nchallenging in the presence of unknown camera motion, diverse object motions\nand complex scene structures. Most existing methods rely on a single motion cue\nto perform motion segmentation, which is usually insufficient when facing\ndifferent complex environments. While a few recent deep learning based methods\nare able to combine multiple motion cues to achieve improved accuracy, they\ndepend heavily on vast datasets and extensive annotations, making them less\nadaptable to new scenarios. To address these limitations, we propose a novel\nmonocular dense segmentation method that achieves state-of-the-art motion\nsegmentation results in a zero-shot manner. The proposed method synergestically\ncombines the strengths of deep learning and geometric model fusion methods by\nperforming geometric model fusion on object proposals. Experiments show that\nour method achieves competitive results on several motion segmentation datasets\nand even surpasses some state-of-the-art supervised methods on certain\nbenchmarks, while not being trained on any data. We also present an ablation\nstudy to show the effectiveness of combining different geometric models\ntogether for motion segmentation, highlighting the value of our geometric model\nfusion strategy.",
      "tldr_zh": "该论文提出了一种零-shot 单目运动分割方法，用于从移动相机中检测和分割运动物体，解决了现有方法依赖单一运动线索或大量标注数据的局限性。该方法巧妙结合深度学习与几何运动模型融合（geometric motion model fusion），在物体提案上进行融合，以处理未知相机运动、多样物体运动和复杂场景。实验结果显示，该方法在多个运动分割数据集上取得了竞争性表现，甚至在某些基准上超越了有监督的先进方法；此外，消融研究证明了结合不同几何模型的策略在提升分割准确性方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 2024 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshops (CVPRW)",
      "pdf_url": "http://arxiv.org/pdf/2405.01723v1",
      "published_date": "2024-05-02 20:42:17 UTC",
      "updated_date": "2024-05-02 20:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:18:00.666654"
    },
    {
      "arxiv_id": "2405.01714v3",
      "title": "Interpretable Vital Sign Forecasting with Model Agnostic Attention Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Liu",
        "Chen Dan",
        "Anubhav Bhatti",
        "Bingjie Shen",
        "Divij Gupta",
        "Suraj Parmar",
        "San Lee"
      ],
      "abstract": "Sepsis is a leading cause of mortality in intensive care units (ICUs),\nrepresenting a substantial medical challenge. The complexity of analyzing\ndiverse vital signs to predict sepsis further aggravates this issue. While deep\nlearning techniques have been advanced for early sepsis prediction, their\n'black-box' nature obscures the internal logic, impairing interpretability in\ncritical settings like ICUs. This paper introduces a framework that combines a\ndeep learning model with an attention mechanism that highlights the critical\ntime steps in the forecasting process, thus improving model interpretability\nand supporting clinical decision-making. We show that the attention mechanism\ncould be adapted to various black box time series forecasting models such as\nN-HiTS and N-BEATS. Our method preserves the accuracy of conventional deep\nlearning models while enhancing interpretability through\nattention-weight-generated heatmaps. We evaluated our model on the eICU-CRD\ndataset, focusing on forecasting vital signs for sepsis patients. We assessed\nits performance using mean squared error (MSE) and dynamic time warping (DTW)\nmetrics. We explored the attention maps of N-HiTS and N-BEATS, examining the\ndifferences in their performance and identifying crucial factors influencing\nvital sign forecasting.",
      "tldr_zh": "这篇论文针对ICU中脓毒症的预测挑战，提出了一种结合深度学习模型与模型无关注意力机制（Model Agnostic Attention Maps）的框架，以提升生命体征预测的可解释性。该框架通过突出关键时间步骤生成的热图，支持临床决策，同时兼容各种黑盒时间序列模型，如N-HiTS和N-BEATS。在eICU-CRD数据集上评估结果显示，该方法保持了传统模型的准确性（使用MSE和DTW指标），并通过分析注意力图揭示了影响预测的因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01714v3",
      "published_date": "2024-05-02 20:19:07 UTC",
      "updated_date": "2024-05-21 21:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:18:14.910066"
    },
    {
      "arxiv_id": "2405.01711v2",
      "title": "Individual Fairness Through Reweighting and Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoul Jalil Djiberou Mahamadou",
        "Lea Goetz",
        "Russ Altman"
      ],
      "abstract": "Inherent bias within society can be amplified and perpetuated by artificial\nintelligence (AI) systems. To address this issue, a wide range of solutions\nhave been proposed to identify and mitigate bias and enforce fairness for\nindividuals and groups. Recently, Graph Laplacian Regularizer (GLR), a\nregularization technique from the semi-supervised learning literature has been\nused as a substitute for the common Lipschitz condition to enhance individual\nfairness. Notable prior work has shown that enforcing individual fairness\nthrough a GLR can improve the transfer learning accuracy of AI models under\ncovariate shifts. However, the prior work defines a GLR on the source and\ntarget data combined, implicitly assuming that the target data are available at\ntrain time, which might not hold in practice. In this work, we investigated\nwhether defining a GLR independently on the train and target data could\nmaintain similar accuracy. Furthermore, we introduced the Normalized Fairness\nGain score (NFG) to measure individual fairness by measuring the amount of\ngained fairness when a GLR is used versus not. We evaluated the new and\noriginal methods under NFG, the Prediction Consistency (PC), and traditional\nclassification metrics on the German Credit Approval dataset. The results\nshowed that the two models achieved similar statistical mean performances over\nfive-fold cross-validation. Furthermore, the proposed metric showed that PC\nscores can be misleading as the scores can be high and statistically similar to\nfairness-enhanced models while NFG scores are small. This work therefore\nprovides new insights into when a GLR effectively enhances individual fairness\nand the pitfalls of PC.",
      "tldr_zh": "本文探讨了人工智能（AI）系统中固有偏见的问题，提出通过重新加权和调整来增强个体公平性，使用 Graph Laplacian Regularizer (GLR) 作为正则化技术，而非传统 Lipschitz 条件。不同于以往方法，本文在训练数据和目标数据上独立定义 GLR，并引入 Normalized Fairness Gain score (NFG) 指标来量化 GLR 带来的公平性收益，同时评估其在 German Credit Approval 数据集上的性能。实验结果显示，新方法与原方法在统计上类似，但 Prediction Consistency (PC) 分数可能误导，因为即使 PC 高，NFG 分数低时仍表示公平性提升有限；这为 GLR 有效增强个体公平性的条件提供了新见解，并揭示了 PC 的潜在缺陷。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 1 figure, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.01711v2",
      "published_date": "2024-05-02 20:15:25 UTC",
      "updated_date": "2024-05-07 19:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:18:27.211808"
    },
    {
      "arxiv_id": "2405.02350v1",
      "title": "What makes Models Compositional? A Theoretical View: With Supplement",
      "title_zh": "翻译失败",
      "authors": [
        "Parikshit Ram",
        "Tim Klinger",
        "Alexander G. Gray"
      ],
      "abstract": "Compositionality is thought to be a key component of language, and various\ncompositional benchmarks have been developed to empirically probe the\ncompositional generalization of existing sequence processing models. These\nbenchmarks often highlight failures of existing models, but it is not clear why\nthese models fail in this way. In this paper, we seek to theoretically\nunderstand the role the compositional structure of the models plays in these\nfailures and how this structure relates to their expressivity and sample\ncomplexity. We propose a general neuro-symbolic definition of compositional\nfunctions and their compositional complexity. We then show how various existing\ngeneral and special purpose sequence processing models (such as recurrent,\nconvolution and attention-based ones) fit this definition and use it to analyze\ntheir compositional complexity. Finally, we provide theoretical guarantees for\nthe expressivity and systematic generalization of compositional models that\nexplicitly depend on our proposed definition and highlighting factors which\ndrive poor empirical performance.",
      "tldr_zh": "本论文探讨了模型组合性(compositionality)的理论基础，分析了现有序列处理模型在组合性基准上的失败原因，并考察这些失败如何与模型的结构、表达性(expressivity)和样本复杂度(sample complexity)相关。作者提出一个通用的神经符号(neuro-symbolic)定义来描述组合函数及其组合复杂度，并应用此定义分析了如循环、卷积和注意力模型等现有模型的特性。最终，论文提供了理论保证，阐明组合模型的表达性和系统化泛化(systematic generalization)的条件，并突出影响模型性能的关键因素。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of the original IJCAI 2024 paper with detailed\n  supplementary materials (27 pages, 7 figures)",
      "pdf_url": "http://arxiv.org/pdf/2405.02350v1",
      "published_date": "2024-05-02 20:10:27 UTC",
      "updated_date": "2024-05-02 20:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:18:35.872599"
    },
    {
      "arxiv_id": "2405.01705v1",
      "title": "Long Tail Image Generation Through Feature Space Augmentation and Iterated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Elberg",
        "Denis Parra",
        "Mircea Petrache"
      ],
      "abstract": "Image and multimodal machine learning tasks are very challenging to solve in\nthe case of poorly distributed data. In particular, data availability and\nprivacy restrictions exacerbate these hurdles in the medical domain. The state\nof the art in image generation quality is held by Latent Diffusion models,\nmaking them prime candidates for tackling this problem. However, a few key\nissues still need to be solved, such as the difficulty in generating data from\nunder-represented classes and a slow inference process. To mitigate these\nissues, we propose a new method for image augmentation in long-tailed data\nbased on leveraging the rich latent space of pre-trained Stable Diffusion\nModels. We create a modified separable latent space to mix head and tail class\nexamples. We build this space via Iterated Learning of underlying sparsified\nembeddings, which we apply to task-specific saliency maps via a K-NN approach.\nCode is available at\nhttps://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning",
      "tldr_zh": "这篇论文针对长尾数据分布问题（如医疗领域的数据可用性和隐私限制），提出了一种新的图像生成方法，通过Feature Space Augmentation和Iterated Learning来增强欠表示类别的生成。方法利用预训练的Stable Diffusion模型的丰富潜在空间，创建修改后的可分离潜在空间，以混合头类和尾类示例，并通过Iterated Learning学习底层稀疏化嵌入，并结合K-NN应用于任务特定的显著性映射。实验表明，该方法能缓解生成欠表示类别的困难和推断过程缓慢的问题，从而改善图像和多模态机器学习任务的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4; I.2"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01705v1",
      "published_date": "2024-05-02 20:03:19 UTC",
      "updated_date": "2024-05-02 20:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:18:51.051093"
    },
    {
      "arxiv_id": "2405.01699v2",
      "title": "SOAR: Advancements in Small Body Object Detection for Aerial Imagery Using State Space Models and Programmable Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Tushar Verma",
        "Jyotsna Singh",
        "Yash Bhartari",
        "Rishi Jarwal",
        "Suraj Singh",
        "Shubhkarman Singh"
      ],
      "abstract": "Small object detection in aerial imagery presents significant challenges in\ncomputer vision due to the minimal data inherent in small-sized objects and\ntheir propensity to be obscured by larger objects and background noise.\nTraditional methods using transformer-based models often face limitations\nstemming from the lack of specialized databases, which adversely affect their\nperformance with objects of varying orientations and scales. This underscores\nthe need for more adaptable, lightweight models. In response, this paper\nintroduces two innovative approaches that significantly enhance detection and\nsegmentation capabilities for small aerial objects. Firstly, we explore the use\nof the SAHI framework on the newly introduced lightweight YOLO v9 architecture,\nwhich utilizes Programmable Gradient Information (PGI) to reduce the\nsubstantial information loss typically encountered in sequential feature\nextraction processes. The paper employs the Vision Mamba model, which\nincorporates position embeddings to facilitate precise location-aware visual\nunderstanding, combined with a novel bidirectional State Space Model (SSM) for\neffective visual context modeling. This State Space Model adeptly harnesses the\nlinear complexity of CNNs and the global receptive field of Transformers,\nmaking it particularly effective in remote sensing image classification. Our\nexperimental results demonstrate substantial improvements in detection accuracy\nand processing efficiency, validating the applicability of these approaches for\nreal-time small object detection across diverse aerial scenarios. This paper\nalso discusses how these methodologies could serve as foundational models for\nfuture advancements in aerial object recognition technologies. The source code\nwill be made accessible here.",
      "tldr_zh": "本研究针对航空图像中小物体检测的挑战（如物体微小、遮挡和背景噪声），提出SOAR框架，使用State Space Models (SSM) 和Programmable Gradients (PGI) 等创新方法来提升检测和分割性能。具体而言，该框架结合SAHI与轻量级YOLO v9架构，利用PGI减少特征提取过程中的信息损失，并采用Vision Mamba模型及双向SSM融合CNN的线性复杂度和Transformer的全局感受野，实现精确的位置感知和视觉上下文建模。实验结果显示，SOAR在实时小物体检测中显著提高了准确性和效率，为未来航空物体识别技术的发展奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01699v2",
      "published_date": "2024-05-02 19:47:08 UTC",
      "updated_date": "2024-05-06 01:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:19:02.464227"
    },
    {
      "arxiv_id": "2405.01686v2",
      "title": "Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hye Sun Yun",
        "David Pogrebitskiy",
        "Iain J. Marshall",
        "Byron C. Wallace"
      ],
      "abstract": "Meta-analyses statistically aggregate the findings of different randomized\ncontrolled trials (RCTs) to assess treatment effectiveness. Because this yields\nrobust estimates of treatment effectiveness, results from meta-analyses are\nconsidered the strongest form of evidence. However, rigorous evidence syntheses\nare time-consuming and labor-intensive, requiring manual extraction of data\nfrom individual trials to be synthesized. Ideally, language technologies would\npermit fully automatic meta-analysis, on demand. This requires accurately\nextracting numerical results from individual trials, which has been beyond the\ncapabilities of natural language processing (NLP) models to date. In this work,\nwe evaluate whether modern large language models (LLMs) can reliably perform\nthis task. We annotate (and release) a modest but granular evaluation dataset\nof clinical trial reports with numerical findings attached to interventions,\ncomparators, and outcomes. Using this dataset, we evaluate the performance of\nseven LLMs applied zero-shot for the task of conditionally extracting numerical\nfindings from trial reports. We find that massive LLMs that can accommodate\nlengthy inputs are tantalizingly close to realizing fully automatic\nmeta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).\nHowever, LLMs -- including ones trained on biomedical texts -- perform poorly\nwhen the outcome measures are complex and tallying the results requires\ninference. This work charts a path toward fully automatic meta-analysis of RCTs\nvia LLMs, while also highlighting the limitations of existing models for this\naim.",
      "tldr_zh": "本文探讨使用大型语言模型 (LLMs) 从随机对照试验 (RCTs) 中自动提取数值结果，以简化元分析 (meta-analyses) 的过程，从而提供更高效的治疗效果评估。研究团队标注并发布了包含干预、比较器和结果的评估数据集，并评估了七个 LLMs 在零样本 (zero-shot) 条件下提取性能。结果表明，LLMs 在处理二元结果（如死亡率）时表现接近实现完全自动元分析，但对复杂结果和需要推理的任务效果较差。该工作为自动元分析铺平道路，同时突出了现有模型的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 7 figures, 6 tables, MLHC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01686v2",
      "published_date": "2024-05-02 19:20:11 UTC",
      "updated_date": "2024-07-25 03:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:19:14.171932"
    },
    {
      "arxiv_id": "2405.01684v1",
      "title": "Intelligent Switching for Reset-Free RL",
      "title_zh": "翻译失败",
      "authors": [
        "Darshan Patil",
        "Janarthanan Rajendran",
        "Glen Berseth",
        "Sarath Chandar"
      ],
      "abstract": "In the real world, the strong episode resetting mechanisms that are needed to\ntrain agents in simulation are unavailable. The \\textit{resetting} assumption\nlimits the potential of reinforcement learning in the real world, as providing\nresets to an agent usually requires the creation of additional handcrafted\nmechanisms or human interventions. Recent work aims to train agents\n(\\textit{forward}) with learned resets by constructing a second\n(\\textit{backward}) agent that returns the forward agent to the initial state.\nWe find that the termination and timing of the transitions between these two\nagents are crucial for algorithm success. With this in mind, we create a new\nalgorithm, Reset Free RL with Intelligently Switching Controller (RISC) which\nintelligently switches between the two agents based on the agent's confidence\nin achieving its current goal. Our new method achieves state-of-the-art\nperformance on several challenging environments for reset-free RL.",
      "tldr_zh": "这篇论文解决了强化学习（RL）在现实世界中缺少重置机制的问题，强调传统方法依赖手动或人类干预来提供重置。作者提出了一种新算法Reset Free RL with Intelligently Switching Controller (RISC)，通过基于代理对当前目标信心水平的智能切换，在forward代理（执行任务）和backward代理（返回初始状态）之间动态转换。实验结果显示，RISC 在多个挑战性无重置RL环境中达到了state-of-the-art性能，证明了切换时机和终止对算法成功的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01684v1",
      "published_date": "2024-05-02 19:15:00 UTC",
      "updated_date": "2024-05-02 19:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:19:24.821868"
    },
    {
      "arxiv_id": "2405.01682v2",
      "title": "Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Hazan",
        "Gili Focht",
        "Naama Gavrielov",
        "Roi Reichart",
        "Talar Hagopian",
        "Mary-Louise C. Greer",
        "Ruth Cytter Kuint",
        "Dan Turner",
        "Moti Freiman"
      ],
      "abstract": "Automatic conversion of free-text radiology reports into structured data\nusing Natural Language Processing (NLP) techniques is crucial for analyzing\ndiseases on a large scale. While effective for tasks in widely spoken languages\nlike English, generative large language models (LLMs) typically underperform\nwith less common languages and can pose potential risks to patient privacy.\nFine-tuning local NLP models is hindered by the skewed nature of real-world\nmedical datasets, where rare findings represent a significant data imbalance.\nWe introduce SMP-BERT, a novel prompt learning method that leverages the\nstructured nature of reports to overcome these challenges. In our studies\ninvolving a substantial collection of Crohn's disease radiology reports in\nHebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed\ntraditional fine-tuning methods in performance, notably in detecting infrequent\nconditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more\naccurate AI diagnostics available for low-resource languages.",
      "tldr_zh": "本研究针对低资源语言（如希伯来语）中的放射学报告提取结构化信息，提出了一种名为SMP-BERT的提示学习(prompt-learning)方法，以克服自然语言处理(NLP)模型在数据不平衡和隐私风险方面的挑战。该方法利用报告的结构化性质，显著提升了从克罗恩病放射学报告中提取信息的准确性，在涉及超过8000患者和10000报告的实验中，SMP-BERT在检测罕见条件时表现出色（AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34），远超传统微调方法。通过这一创新，研究为低资源语言的AI诊断提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01682v2",
      "published_date": "2024-05-02 19:11:54 UTC",
      "updated_date": "2024-05-22 09:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:19:38.522401"
    },
    {
      "arxiv_id": "2405.01677v3",
      "title": "Balance Reward and Safety Optimization for Safe Reinforcement Learning: A Perspective of Gradient Manipulation",
      "title_zh": "安全强化学习的奖励与安全优化平衡：梯度操作的视角",
      "authors": [
        "Shangding Gu",
        "Bilgehan Sel",
        "Yuhao Ding",
        "Lu Wang",
        "Qingwei Lin",
        "Ming Jin",
        "Alois Knoll"
      ],
      "abstract": "Ensuring the safety of Reinforcement Learning (RL) is crucial for its\ndeployment in real-world applications. Nevertheless, managing the trade-off\nbetween reward and safety during exploration presents a significant challenge.\nImproving reward performance through policy adjustments may adversely affect\nsafety performance. In this study, we aim to address this conflicting relation\nby leveraging the theory of gradient manipulation. Initially, we analyze the\nconflict between reward and safety gradients. Subsequently, we tackle the\nbalance between reward and safety optimization by proposing a soft switching\npolicy optimization method, for which we provide convergence analysis. Based on\nour theoretical examination, we provide a safe RL framework to overcome the\naforementioned challenge, and we develop a Safety-MuJoCo Benchmark to assess\nthe performance of safe RL algorithms. Finally, we evaluate the effectiveness\nof our method on the Safety-MuJoCo Benchmark and a popular safe RL benchmark,\nOmnisafe. Experimental results demonstrate that our algorithms outperform\nseveral state-of-the-art baselines in terms of balancing reward and safety\noptimization.",
      "tldr_zh": "这篇论文探讨了安全强化学习(Safe RL)中奖励和安全性平衡的挑战，通过梯度操作理论分析奖励和安全梯度之间的冲突。作者提出了一种软切换策略优化方法，并为其提供收敛分析，以有效管理这一权衡。实验结果显示，该方法在 Safety-MuJoCo Benchmark 和 Omnisafe 基准上优于现有基线算法，在提升奖励性能的同时显著提高了安全性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01677v3",
      "published_date": "2024-05-02 19:07:14 UTC",
      "updated_date": "2025-03-01 18:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:19:48.941915"
    },
    {
      "arxiv_id": "2405.01663v1",
      "title": "ATNPA: A Unified View of Oversmoothing Alleviation in Graph Neural Networks",
      "title_zh": "ATNPA：图神经网络中过平滑缓解的统一视角",
      "authors": [
        "Yufei Jin",
        "Xingquan Zhu"
      ],
      "abstract": "Oversmoothing is a commonly observed challenge in graph neural network (GNN)\nlearning, where, as layers increase, embedding features learned from GNNs\nquickly become similar/indistinguishable, making them incapable of\ndifferentiating network proximity. A GNN with shallow layer architectures can\nonly learn short-term relation or localized structure information, limiting its\npower of learning long-term connection, evidenced by their inferior learning\nperformance on heterophilous graphs. Tackling oversmoothing is crucial to\nharness deep-layer architectures for GNNs. To date, many methods have been\nproposed to alleviate oversmoothing. The vast difference behind their design\nprinciples, combined with graph complications, make it difficult to understand\nand even compare their difference in tackling the oversmoothing. In this paper,\nwe propose ATNPA, a unified view with five key steps: Augmentation,\nTransformation, Normalization, Propagation, and Aggregation, to summarize GNN\noversmoothing alleviation approaches. We first outline three themes to tackle\noversmoothing, and then separate all methods into six categories, followed by\ndetailed reviews of representative methods, including their relation to the\nATNPA, and discussion about their niche, strength, and weakness. The review not\nonly draws in-depth understanding of existing methods in the field, but also\nshows a clear road map for future study.",
      "tldr_zh": "该论文针对图神经网络（GNNs）中的Oversmoothing问题提出一个统一的视角，即ATNPA框架，该问题会导致层数增加时节点特征变得相似，从而无法有效区分网络邻近性。ATNPA框架通过五个关键步骤——Augmentation、Transformation、Normalization、Propagation和Aggregation——将现有缓解方法归纳为三主题和六类别，并对代表性方法进行详细回顾，包括它们的优缺点及相互关系。最终，该研究不仅加深了对Oversmoothing缓解方法的理解，还为未来GNN研究提供了清晰的路线图。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.01663v1",
      "published_date": "2024-05-02 18:33:41 UTC",
      "updated_date": "2024-05-02 18:33:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:20:01.184551"
    },
    {
      "arxiv_id": "2405.01660v1",
      "title": "Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Tolga Buz",
        "Benjamin Frost",
        "Nikola Genchev",
        "Moritz Schneider",
        "Lucie-Aimée Kaffee",
        "Gerard de Melo"
      ],
      "abstract": "Recent Large Language Models (LLMs) have shown the ability to generate\ncontent that is difficult or impossible to distinguish from human writing. We\ninvestigate the ability of differently-sized LLMs to replicate human writing\nstyle in short, creative texts in the domain of Showerthoughts, thoughts that\nmay occur during mundane activities. We compare GPT-2 and GPT-Neo fine-tuned on\nReddit data as well as GPT-3.5 invoked in a zero-shot manner, against\nhuman-authored texts. We measure human preference on the texts across the\nspecific dimensions that account for the quality of creative, witty texts.\nAdditionally, we compare the ability of humans versus fine-tuned RoBERTa\nclassifiers to detect AI-generated texts. We conclude that human evaluators\nrate the generated texts slightly worse on average regarding their creative\nquality, but they are unable to reliably distinguish between human-written and\nAI-generated texts. We further provide a dataset for creative, witty text\ngeneration based on Reddit Showerthoughts posts.",
      "tldr_zh": "本研究调查了不同规模的Large Language Models (LLMs)，包括fine-tuned GPT-2和GPT-Neo，以及zero-shot GPT-3.5，在模仿Reddit Showerthoughts风格（短小创意文本）方面的机智、创意和可检测性。研究者将AI生成的文本与人类撰写文本进行比较，通过人类评估器在创意质量维度上评估偏好，并使用fine-tuned RoBERTa分类器检测AI文本。结果显示，人类评估者认为AI文本在创意和机智上略逊一筹，但无法可靠地区分AI与人类文本，而RoBERTa在检测方面表现出色。该研究还提供了一个基于Reddit Showerthoughts的创意文本生成数据集，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to *SEM 2024 (StarSEM) conference",
      "pdf_url": "http://arxiv.org/pdf/2405.01660v1",
      "published_date": "2024-05-02 18:29:58 UTC",
      "updated_date": "2024-05-02 18:29:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:20:13.332249"
    },
    {
      "arxiv_id": "2405.02347v2",
      "title": "COPAL: Continual Pruning in Large Language Generative Models",
      "title_zh": "COPAL: 大语言生成模型中的持续剪枝",
      "authors": [
        "Srikanth Malla",
        "Joon Hee Choi",
        "Chiho Choi"
      ],
      "abstract": "Adapting pre-trained large language models to different domains in natural\nlanguage processing requires two key considerations: high computational demands\nand model's inability to continual adaptation. To simultaneously address both\nissues, this paper presents COPAL (COntinual Pruning in Adaptive Language\nsettings), an algorithm developed for pruning large language generative models\nunder a continual model adaptation setting. While avoiding resource-heavy\nfinetuning or retraining, our pruning process is guided by the proposed\nsensitivity analysis. The sensitivity effectively measures model's ability to\nwithstand perturbations introduced by the new dataset and finds model's weights\nthat are relevant for all encountered datasets. As a result, COPAL allows\nseamless model adaptation to new domains while enhancing the resource\nefficiency. Our empirical evaluation on a various size of LLMs show that COPAL\noutperforms baseline models, demonstrating its efficacy in efficiency and\nadaptability.",
      "tldr_zh": "这篇论文提出了 COPAL 算法，用于在持续适应环境中修剪大型语言生成模型（LLMs），以同时解决高计算需求和模型适应性不足的问题。COPAL 通过敏感性分析指导修剪过程，该分析评估模型对新数据集引入的扰动抵抗能力，并识别与所有遇到数据集相关的权重，从而避免资源密集的微调或重训练。实验结果显示，COPAL 在各种规模的 LLMs 上优于基线模型，在资源效率和适应性方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02347v2",
      "published_date": "2024-05-02 18:24:41 UTC",
      "updated_date": "2024-06-14 18:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:20:25.412879"
    },
    {
      "arxiv_id": "2405.01534v1",
      "title": "Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks",
      "title_zh": "Plan-Seq-Learn：语言模型引导的强化学习用于解决长时域机器人任务",
      "authors": [
        "Murtaza Dalal",
        "Tarun Chiruvolu",
        "Devendra Chaplot",
        "Ruslan Salakhutdinov"
      ],
      "abstract": "Large Language Models (LLMs) have been shown to be capable of performing\nhigh-level planning for long-horizon robotics tasks, yet existing methods\nrequire access to a pre-defined skill library (e.g. picking, placing, pulling,\npushing, navigating). However, LLM planning does not address how to design or\nlearn those behaviors, which remains challenging particularly in long-horizon\nsettings. Furthermore, for many tasks of interest, the robot needs to be able\nto adjust its behavior in a fine-grained manner, requiring the agent to be\ncapable of modifying low-level control actions. Can we instead use the\ninternet-scale knowledge from LLMs for high-level policies, guiding\nreinforcement learning (RL) policies to efficiently solve robotic control tasks\nonline without requiring a pre-determined set of skills? In this paper, we\npropose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to\nbridge the gap between abstract language and learned low-level control for\nsolving long-horizon robotics tasks from scratch. We demonstrate that PSL\nachieves state-of-the-art results on over 25 challenging robotics tasks with up\nto 10 stages. PSL solves long-horizon tasks from raw visual input spanning four\nbenchmarks at success rates of over 85%, out-performing language-based,\nclassical, and end-to-end approaches. Video results and code at\nhttps://mihdalal.github.io/planseqlearn/",
      "tldr_zh": "这篇论文提出 Plan-Seq-Learn (PSL)，一种利用大型语言模型 (LLMs) 指导强化学习 (RL) 的模块化方法，用于从零开始解决长时域机器人任务，而无需预定义技能库。PSL 通过运动规划桥接抽象语言指令与低水平控制，实现对原始视觉输入的任务规划和学习。在超过 25 个挑战性任务中，PSL 取得了超过 85% 的成功率，优于语言-based、经典和端到端方法，为高效机器人控制提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2024. Website at\n  https://mihdalal.github.io/planseqlearn/ 9 pages, 3 figures, 3 tables; 14\n  pages appendix (7 additional figures)",
      "pdf_url": "http://arxiv.org/pdf/2405.01534v1",
      "published_date": "2024-05-02 17:59:31 UTC",
      "updated_date": "2024-05-02 17:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:20:37.693824"
    },
    {
      "arxiv_id": "2405.01531v2",
      "title": "Improving Intervention Efficacy via Concept Realignment in Concept Bottleneck Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nishad Singhi",
        "Jae Myung Kim",
        "Karsten Roth",
        "Zeynep Akata"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) ground image classification on\nhuman-understandable concepts to allow for interpretable model decisions.\nCrucially, the CBM design inherently allows for human interventions, in which\nexpert users are given the ability to modify potentially misaligned concept\nchoices to influence the decision behavior of the model in an interpretable\nfashion. However, existing approaches often require numerous human\ninterventions per image to achieve strong performances, posing practical\nchallenges in scenarios where obtaining human feedback is expensive. In this\npaper, we find that this is noticeably driven by an independent treatment of\nconcepts during intervention, wherein a change of one concept does not\ninfluence the use of other ones in the model's final decision. To address this\nissue, we introduce a trainable concept intervention realignment module, which\nleverages concept relations to realign concept assignments post-intervention.\nAcross standard, real-world benchmarks, we find that concept realignment can\nsignificantly improve intervention efficacy; significantly reducing the number\nof interventions needed to reach a target classification performance or concept\nprediction accuracy. In addition, it easily integrates into existing\nconcept-based architectures without requiring changes to the models themselves.\nThis reduced cost of human-model collaboration is crucial to enhancing the\nfeasibility of CBMs in resource-constrained environments. Our code is available\nat: https://github.com/ExplainableML/concept_realignment.",
      "tldr_zh": "本文针对 Concept Bottleneck Models (CBMs) 在图像分类中人类干预效率低的问题，发现现有方法因独立处理概念而需大量干预。研究提出了一种可训练的概念干预重对齐模块，利用概念关系来重对齐干预后的概念分配，从而显著减少达到目标分类性能或概念预测准确率所需的干预次数。在标准基准测试中，该模块易于整合到现有架构中，降低了人类-模型协作的成本，使 CBMs 在资源受限环境中更具可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01531v2",
      "published_date": "2024-05-02 17:59:01 UTC",
      "updated_date": "2024-08-05 18:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:20:50.141560"
    },
    {
      "arxiv_id": "2405.01525v1",
      "title": "FLAME: Factuality-Aware Alignment for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng-Chieh Lin",
        "Luyu Gao",
        "Barlas Oguz",
        "Wenhan Xiong",
        "Jimmy Lin",
        "Wen-tau Yih",
        "Xilun Chen"
      ],
      "abstract": "Alignment is a standard procedure to fine-tune pre-trained large language\nmodels (LLMs) to follow natural language instructions and serve as helpful AI\nassistants. We have observed, however, that the conventional alignment process\nfails to enhance the factual accuracy of LLMs, and often leads to the\ngeneration of more false facts (i.e. hallucination). In this paper, we study\nhow to make the LLM alignment process more factual, by first identifying\nfactors that lead to hallucination in both alignment steps:\\ supervised\nfine-tuning (SFT) and reinforcement learning (RL). In particular, we find that\ntraining the LLM on new knowledge or unfamiliar texts can encourage\nhallucination. This makes SFT less factual as it trains on human labeled data\nthat may be novel to the LLM. Furthermore, reward functions used in standard RL\ncan also encourage hallucination, because it guides the LLM to provide more\nhelpful responses on a diverse set of instructions, often preferring longer and\nmore detailed responses. Based on these observations, we propose\nfactuality-aware alignment, comprised of factuality-aware SFT and\nfactuality-aware RL through direct preference optimization. Experiments show\nthat our proposed factuality-aware alignment guides LLMs to output more factual\nresponses while maintaining instruction-following capability.",
      "tldr_zh": "本研究发现，传统的大语言模型（LLMs）对齐（alignment）过程未能提升事实准确性，反而增加了幻觉（hallucination）的发生，特别是在监督微调（SFT）和强化学习（RL）阶段。研究识别出关键因素，包括SFT中训练新知识或不熟悉文本导致幻觉，以及RL中奖励函数偏好更长详细响应。针对这些问题，提出factuality-aware alignment方法，包括factuality-aware SFT和factuality-aware RL，通过直接偏好优化（direct preference optimization）来强化事实性。实验结果显示，该方法使LLMs生成更多事实性的响应，同时保持指令遵循能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01525v1",
      "published_date": "2024-05-02 17:54:54 UTC",
      "updated_date": "2024-05-02 17:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:21:01.407182"
    },
    {
      "arxiv_id": "2405.01524v3",
      "title": "A separability-based approach to quantifying generalization: which layer is best?",
      "title_zh": "翻译失败",
      "authors": [
        "Luciano Dyballa",
        "Evan Gerritz",
        "Steven W. Zucker"
      ],
      "abstract": "Generalization to unseen data remains poorly understood for deep learning\nclassification and foundation models, especially in the open set scenario. How\ncan one assess the ability of networks to adapt to new or extended versions of\ntheir input space in the spirit of few-shot learning, out-of-distribution\ngeneralization, domain adaptation, and category discovery? Which layers of a\nnetwork are likely to generalize best? We provide a new method for evaluating\nthe capacity of networks to represent a sampled domain, regardless of whether\nthe network has been trained on all classes in that domain. Our approach is the\nfollowing: after fine-tuning state-of-the-art pre-trained models for visual\nclassification on a particular domain, we assess their performance on data from\nrelated but distinct variations in that domain. Generalization power is\nquantified as a function of the latent embeddings of unseen data from\nintermediate layers for both unsupervised and supervised settings. Working\nthroughout all stages of the network, we find that (i) high classification\naccuracy does not imply high generalizability; and (ii) deeper layers in a\nmodel do not always generalize the best, which has implications for pruning.\nSince the trends observed across datasets are largely consistent, we conclude\nthat our approach reveals (a function of) the intrinsic capacity of the\ndifferent layers of a model to generalize. Our code is available at\nhttps://github.com/dyballa/generalization",
      "tldr_zh": "这篇论文提出了一种基于可分性(separability-based)的评估方法，来量化深度学习模型在开放集场景下的泛化能力，重点探讨网络在few-shot learning、out-of-distribution generalization、domain adaptation和category discovery等任务中的表现。作者通过微调预训练模型并分析中间层的latent embeddings，在无监督和监督设置下评估模型对相关但不同变体数据的性能。研究发现，高分类准确率并不等同于高generalization能力，且模型的深层并不总是泛化最好，这对模型修剪(pruning)具有重要启示。总的来说，该方法揭示了模型不同层固有的泛化潜力，并提供了开源代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "I.5.1; I.2.6; I.4.10"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01524v3",
      "published_date": "2024-05-02 17:54:35 UTC",
      "updated_date": "2024-11-02 12:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:21:14.164908"
    },
    {
      "arxiv_id": "2405.01502v1",
      "title": "Analyzing the Role of Semantic Representations in the Era of Large Language Models",
      "title_zh": "分析语义表示在大语言模型时代的作用",
      "authors": [
        "Zhijing Jin",
        "Yuen Chen",
        "Fernando Gonzalez",
        "Jiarui Liu",
        "Jiayi Zhang",
        "Julian Michael",
        "Bernhard Schölkopf",
        "Mona Diab"
      ],
      "abstract": "Traditionally, natural language processing (NLP) models often use a rich set\nof features created by linguistic expertise, such as semantic representations.\nHowever, in the era of large language models (LLMs), more and more tasks are\nturned into generic, end-to-end sequence generation problems. In this paper, we\ninvestigate the question: what is the role of semantic representations in the\nera of LLMs? Specifically, we investigate the effect of Abstract Meaning\nRepresentation (AMR) across five diverse NLP tasks. We propose an AMR-driven\nchain-of-thought prompting method, which we call AMRCoT, and find that it\ngenerally hurts performance more than it helps. To investigate what AMR may\nhave to offer on these tasks, we conduct a series of analysis experiments. We\nfind that it is difficult to predict which input examples AMR may help or hurt\non, but errors tend to arise with multi-word expressions, named entities, and\nin the final inference step where the LLM must connect its reasoning over the\nAMR to its prediction. We recommend focusing on these areas for future work in\nsemantic representations for LLMs. Our code:\nhttps://github.com/causalNLP/amr_llm.",
      "tldr_zh": "本论文探讨了语义表示（如Abstract Meaning Representation, AMR）在大语言模型（Large Language Models, LLMs）时代的作用，调查其在五个多样化NLP任务中的效果。研究者提出了一种AMR驱动的链式思维提示方法（AMRCoT），但发现该方法通常会降低性能，而不是提升。分析实验显示，AMR在处理多词表达、命名实体以及将推理与最终预测连接的步骤中容易出错，因此推荐未来工作聚焦这些领域以优化语义表示在LLMs中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01502v1",
      "published_date": "2024-05-02 17:32:59 UTC",
      "updated_date": "2024-05-02 17:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:21:24.735910"
    },
    {
      "arxiv_id": "2405.01490v1",
      "title": "Controllable Text Generation in the Instruction-Tuning Era",
      "title_zh": "翻译失败",
      "authors": [
        "Dhananjay Ashok",
        "Barnabas Poczos"
      ],
      "abstract": "While most research on controllable text generation has focused on steering\nbase Language Models, the emerging instruction-tuning and prompting paradigm\noffers an alternate approach to controllability. We compile and release\nConGenBench, a testbed of 17 different controllable generation tasks, using a\nsubset of it to benchmark the performance of 9 different baselines and methods\non Instruction-tuned Language Models. To our surprise, we find that\nprompting-based approaches outperform controllable text generation methods on\nmost datasets and tasks, highlighting a need for research on controllable text\ngeneration with Instruction-tuned Language Models in specific. Prompt-based\napproaches match human performance on most stylistic tasks while lagging on\nstructural tasks, foregrounding a need to study more varied constraints and\nmore challenging stylistic tasks. To facilitate such research, we provide an\nalgorithm that uses only a task dataset and a Large Language Model with\nin-context capabilities to automatically generate a constraint dataset. This\nmethod eliminates the fields dependence on pre-curated constraint datasets,\nhence vastly expanding the range of constraints that can be studied in the\nfuture.",
      "tldr_zh": "该研究探讨了在指令微调时代如何实现可控文本生成，编译并发布了ConGenBench测试平台，该平台包含17个不同任务，用于评估9种基线方法在Instruction-tuned Language Models上的性能。结果显示，prompting-based approaches在大多数数据集和任务上优于传统可控文本生成方法，并在风格任务上接近人类水平，但结构任务表现较差。这突出了针对Instruction-tuned Language Models进行更多研究的必要性，并提供了一个算法，使用任务数据集和具有in-context capabilities的大型语言模型自动生成约束数据集，从而扩展未来研究的范围。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01490v1",
      "published_date": "2024-05-02 17:24:30 UTC",
      "updated_date": "2024-05-02 17:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:21:37.807014"
    },
    {
      "arxiv_id": "2405.01483v3",
      "title": "MANTIS: Interleaved Multi-Image Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongfu Jiang",
        "Xuan He",
        "Huaye Zeng",
        "Cong Wei",
        "Max Ku",
        "Qian Liu",
        "Wenhu Chen"
      ],
      "abstract": "Large multimodal models (LMMs) have shown great results in single-image\nvision language tasks. However, their abilities to solve multi-image visual\nlanguage tasks is yet to be improved. The existing LMMs like OpenFlamingo,\nEmu2, and Idefics gain their multi-image ability through pre-training on\nhundreds of millions of noisy interleaved image-text data from the web, which\nis neither efficient nor effective. In this paper, we aim to build strong\nmulti-image LMMs via instruction tuning with academic-level resources.\nTherefore, we meticulously construct Mantis-Instruct containing 721K\nmulti-image instruction data to train a family of Mantis models. The\ninstruction tuning empowers Mantis with different multi-image skills like\nco-reference, comparison, reasoning, and temporal understanding. We evaluate\nMantis on 8 multi-image benchmarks and 6 single-image benchmarks.\nMantis-Idefics2 can achieve SoTA results on all the multi-image benchmarks and\nbeat the strongest multi-image baseline, Idefics2-8B by an average of 13\nabsolute points. Notably, Idefics2-8B was pre-trained on 140M interleaved\nmulti-image data, which is 200x larger than Mantis-Instruct. We observe that\nMantis performs equivalently well on the held-in and held-out benchmarks, which\nshows its generalization ability. We further evaluate Mantis on single-image\nbenchmarks and demonstrate that Mantis also maintains a strong single-image\nperformance on par with CogVLM and Emu2. Our results show that multi-image\nabilities are not necessarily gained through massive pre-training, instead,\nthey can be gained by low-cost instruction tuning. The training and evaluation\nof Mantis has paved the road for future work to improve LMMs' multi-image\nabilities.",
      "tldr_zh": "该研究提出 MANTIS 框架，通过交错多图像指令微调（Interleaved Multi-Image Instruction Tuning）提升大型多模态模型（LMMs）的多图像处理能力，避免依赖海量预训练数据。研究者构建了包含 721K 多图像指令数据的 Mantis-Instruct 数据集，训练了一系列 Mantis 模型，提升技能如 co-reference、comparison、reasoning 和 temporal understanding。实验结果显示，Mantis-Idefics2 在 8 个多图像基准上达到 SOTA（State-of-the-Art）水平，比预训练数据多 200 倍的 Idefics2-8B 高出平均 13 分，并在 6 个单图像基准上表现与 CogVLM 和 Emu2 相当，证明多图像能力可通过低成本指令微调高效获得。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 3 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.01483v3",
      "published_date": "2024-05-02 17:14:57 UTC",
      "updated_date": "2024-11-15 06:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:21:50.877634"
    },
    {
      "arxiv_id": "2405.01481v2",
      "title": "NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Gerald Shen",
        "Zhilin Wang",
        "Olivier Delalleau",
        "Jiaqi Zeng",
        "Yi Dong",
        "Daniel Egert",
        "Shengyang Sun",
        "Jimmy Zhang",
        "Sahil Jain",
        "Ali Taghibakhshi",
        "Markel Sanz Ausin",
        "Ashwath Aithal",
        "Oleksii Kuchaiev"
      ],
      "abstract": "Aligning Large Language Models (LLMs) with human values and preferences is\nessential for making them helpful and safe. However, building efficient tools\nto perform alignment can be challenging, especially for the largest and most\ncompetent LLMs which often contain tens or hundreds of billions of parameters.\nWe create NeMo-Aligner, a toolkit for model alignment that can efficiently\nscale to a thousand GPUs for training the largest open-source LLMs such as\nNemotron 4 340B and Llama 3.1 405B. NeMo-Aligner comes with highly optimized\nand scalable implementations for major paradigms of model alignment such as:\nReinforcement Learning from Human Feedback (RLHF), Direct Preference\nOptimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally,\nour toolkit supports running most of the alignment techniques in a Parameter\nEfficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for\nextensibility, allowing support for other alignment techniques with minimal\neffort. It is open-sourced with Apache 2.0 License and we invite community\ncontributions at https://github.com/NVIDIA/NeMo-Aligner",
      "tldr_zh": "该论文介绍了NeMo-Aligner，一种高效可扩展的工具包，用于对Large Language Models (LLMs)进行模型对齐，以确保它们符合人类价值观和偏好。该工具包支持在数千GPU上训练大型开源LLMs，如Nemotron 4 340B和Llama 3.1 405B，并优化了多种对齐范式，包括Reinforcement Learning from Human Feedback (RLHF)、Direct Preference Optimization (DPO)、SteerLM和Self-Play Fine-Tuning (SPIN)。此外，NeMo-Aligner还支持Parameter Efficient Fine-Tuning (PEFT)设置，并设计为易于扩展，允许用户轻松添加其他对齐技术。该工具包以Apache 2.0许可证开源，并通过GitHub邀请社区贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 4 figures, Accepted to COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01481v2",
      "published_date": "2024-05-02 17:13:40 UTC",
      "updated_date": "2024-09-03 05:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:22:01.403734"
    },
    {
      "arxiv_id": "2405.01474v3",
      "title": "Understanding Figurative Meaning through Explainable Visual Entailment",
      "title_zh": "通过可",
      "authors": [
        "Arkadiy Saakyan",
        "Shreyas Kulkarni",
        "Tuhin Chakrabarty",
        "Smaranda Muresan"
      ],
      "abstract": "Large Vision-Language Models (VLMs) have demonstrated strong capabilities in\ntasks requiring a fine-grained understanding of literal meaning in images and\ntext, such as visual question-answering or visual entailment. However, there\nhas been little exploration of the capabilities of these models when presented\nwith images and captions containing figurative meaning, such as metaphors or\nhumor. To close this gap, we propose a new task framing the figurative meaning\nunderstanding problem as an explainable visual entailment task, where the model\nhas to predict whether the image (premise) entails a caption (hypothesis) and\njustify the predicted label with a textual explanation. The figurative\nphenomena can be present in the image, in the caption, or both. Using a\nhuman-AI collaboration approach, we build the accompanying expert-verified\ndataset V-FLUTE, containing 6,027 {image, caption, label, explanation}\ninstances spanning five diverse figurative phenomena: metaphors, similes,\nidioms, sarcasm, and humor. Through automatic evaluation, we find that VLMs\nstruggle to generalize from literal to figurative meaning, particularly when it\nis present in images. Further, we identify common types of errors in VLM\nreasoning (hallucination and incomplete or unsound reasoning) across classes of\nmodels via human evaluation.",
      "tldr_zh": "该研究探讨了大型视觉语言模型 (VLMs) 在处理比喻性含义（如 metaphors、similes、idioms、sarcasm 和 humor）时的局限性，提出一个新的可解释视觉蕴含 (explainable visual entailment) 任务，要求模型预测图像 (premise) 是否蕴含标题 (hypothesis)，并提供文本解释。研究者通过人类-AI 协作构建了数据集 V-FLUTE，包含 6,027 个经专家验证的 {image, caption, label, explanation} 实例，覆盖五种比喻现象。实验结果显示，VLMs 难以从字面意思泛化到比喻性含义，尤其是当后者出现在图像中，并常见错误包括 hallucination 和推理不完整或不严谨。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.01474v3",
      "published_date": "2024-05-02 17:07:25 UTC",
      "updated_date": "2025-02-17 17:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:22:13.947513"
    },
    {
      "arxiv_id": "2405.01472v1",
      "title": "IntervenGen: Interventional Data Generation for Robust and Data-Efficient Robot Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Hoque",
        "Ajay Mandlekar",
        "Caelan Garrett",
        "Ken Goldberg",
        "Dieter Fox"
      ],
      "abstract": "Imitation learning is a promising paradigm for training robot control\npolicies, but these policies can suffer from distribution shift, where the\nconditions at evaluation time differ from those in the training data. A popular\napproach for increasing policy robustness to distribution shift is interactive\nimitation learning (i.e., DAgger and variants), where a human operator provides\ncorrective interventions during policy rollouts. However, collecting a\nsufficient amount of interventions to cover the distribution of policy mistakes\ncan be burdensome for human operators. We propose IntervenGen (I-Gen), a novel\ndata generation system that can autonomously produce a large set of corrective\ninterventions with rich coverage of the state space from a small number of\nhuman interventions. We apply I-Gen to 4 simulated environments and 1 physical\nenvironment with object pose estimation error and show that it can increase\npolicy robustness by up to 39x with only 10 human interventions. Videos and\nmore results are available at https://sites.google.com/view/intervengen2024.",
      "tldr_zh": "本文提出IntervenGen (I-Gen)，一种创新的数据生成系统，旨在通过从少量人类干预中自主生成大量纠正干预数据，来提升机器人imitation learning的鲁棒性和数据效率，解决distribution shift问题。该系统通过丰富覆盖状态空间的干预数据，帮助策略适应评估条件与训练数据的差异。在4个模拟环境和1个物理环境（涉及object pose estimation error）中，I-Gen仅需10个人类干预即可将策略鲁棒性提高多达39倍，显著减轻了人类操作负担。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01472v1",
      "published_date": "2024-05-02 17:06:19 UTC",
      "updated_date": "2024-05-02 17:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:22:26.647802"
    },
    {
      "arxiv_id": "2405.01469v1",
      "title": "Advancing human-centric AI for robust X-ray analysis through holistic self-supervised learning",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Moutakanni",
        "Piotr Bojanowski",
        "Guillaume Chassagnon",
        "Céline Hudelot",
        "Armand Joulin",
        "Yann LeCun",
        "Matthew Muckley",
        "Maxime Oquab",
        "Marie-Pierre Revel",
        "Maria Vakalopoulou"
      ],
      "abstract": "AI Foundation models are gaining traction in various applications, including\nmedical fields like radiology. However, medical foundation models are often\ntested on limited tasks, leaving their generalisability and biases unexplored.\nWe present RayDINO, a large visual encoder trained by self-supervision on 873k\nchest X-rays. We compare RayDINO to previous state-of-the-art models across\nnine radiology tasks, from classification and dense segmentation to text\ngeneration, and provide an in depth analysis of population, age and sex biases\nof our model. Our findings suggest that self-supervision allows patient-centric\nAI proving useful in clinical workflows and interpreting X-rays holistically.\nWith RayDINO and small task-specific adapters, we reach state-of-the-art\nresults and improve generalization to unseen populations while mitigating bias,\nillustrating the true promise of foundation models: versatility and robustness.",
      "tldr_zh": "本研究提出了 RayDINO，一种通过 holistic self-supervised learning 在 873k 张胸部 X-rays 上训练的大型视觉编码器，旨在推进以人为中心的 AI 用于稳健的 X 光分析。RayDINO 与现有最先进模型在九个放射学任务（如 classification、dense segmentation 和 text generation）上进行了比较，并深入分析了人口、年龄和性别偏置。结果表明，自监督学习使 AI 更注重患者中心，提高了临床工作流中的整体 X 光解读能力；通过结合小任务特定适配器，RayDINO 达到了 state-of-the-art 性能，增强了对未见人群的泛化并缓解了偏置，展示了基础模型的通用性和稳健性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01469v1",
      "published_date": "2024-05-02 16:59:10 UTC",
      "updated_date": "2024-05-02 16:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:22:40.305244"
    },
    {
      "arxiv_id": "2405.01468v1",
      "title": "Understanding Retrieval-Augmented Task Adaptation for Vision-Language Models",
      "title_zh": "理解视觉语言模型的检索增强任务适应",
      "authors": [
        "Yifei Ming",
        "Yixuan Li"
      ],
      "abstract": "Pre-trained contrastive vision-language models have demonstrated remarkable\nperformance across a wide range of tasks. However, they often struggle on\nfine-trained datasets with categories not adequately represented during\npre-training, which makes adaptation necessary. Recent works have shown\npromising results by utilizing samples from web-scale databases for\nretrieval-augmented adaptation, especially in low-data regimes. Despite the\nempirical success, understanding how retrieval impacts the adaptation of\nvision-language models remains an open research question. In this work, we\nadopt a reflective perspective by presenting a systematic study to understand\nthe roles of key components in retrieval-augmented adaptation. We unveil new\ninsights on uni-modal and cross-modal retrieval and highlight the critical role\nof logit ensemble for effective adaptation. We further present theoretical\nunderpinnings that directly support our empirical observations.",
      "tldr_zh": "本研究探讨了检索增强任务适应（retrieval-augmented task adaptation）对视觉语言模型（vision-language models）的提升作用，针对这些模型在预训练中未充分覆盖类别时的表现不足问题。作者通过系统分析 uni-modal 和 cross-modal retrieval 的关键组件，揭示了 logit ensemble 在有效适应中的核心作用，并提供了理论基础来支持这些经验观察。这些发现为在低数据场景下优化模型适应提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper is accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01468v1",
      "published_date": "2024-05-02 16:59:05 UTC",
      "updated_date": "2024-05-02 16:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:22:49.603768"
    },
    {
      "arxiv_id": "2405.01460v2",
      "title": "Purify Unlearnable Examples via Rate-Constrained Variational Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Yu",
        "Yufei Wang",
        "Song Xia",
        "Wenhan Yang",
        "Shijian Lu",
        "Yap-Peng Tan",
        "Alex C. Kot"
      ],
      "abstract": "Unlearnable examples (UEs) seek to maximize testing error by making subtle\nmodifications to training examples that are correctly labeled. Defenses against\nthese poisoning attacks can be categorized based on whether specific\ninterventions are adopted during training. The first approach is training-time\ndefense, such as adversarial training, which can mitigate poisoning effects but\nis computationally intensive. The other approach is pre-training purification,\ne.g., image short squeezing, which consists of several simple compressions but\noften encounters challenges in dealing with various UEs. Our work provides a\nnovel disentanglement mechanism to build an efficient pre-training purification\nmethod. Firstly, we uncover rate-constrained variational autoencoders (VAEs),\ndemonstrating a clear tendency to suppress the perturbations in UEs. We\nsubsequently conduct a theoretical analysis for this phenomenon. Building upon\nthese insights, we introduce a disentangle variational autoencoder (D-VAE),\ncapable of disentangling the perturbations with learnable class-wise\nembeddings. Based on this network, a two-stage purification approach is\nnaturally developed. The first stage focuses on roughly eliminating\nperturbations, while the second stage produces refined, poison-free results,\nensuring effectiveness and robustness across various scenarios. Extensive\nexperiments demonstrate the remarkable performance of our method across\nCIFAR-10, CIFAR-100, and a 100-class ImageNet-subset. Code is available at\nhttps://github.com/yuyi-sd/D-VAE.",
      "tldr_zh": "本研究针对 Unlearnable Examples (UEs) 这种通过微小修改训练样本来最大化测试错误的毒化攻击，提出了一种高效的预训练净化方法。论文首先发现 Rate-Constrained Variational Autoencoders (VAEs) 能抑制 UEs 中的扰动，并通过理论分析解释了这一现象；随后引入 Disentangle Variational Autoencoder (D-VAE)，利用可学习的类-wise 嵌入来解耦扰动。基于 D-VAE，他们开发了一个两阶段净化方法：第一阶段粗略消除扰动，第二阶段生成精炼的无毒结果。实验在 CIFAR-10、CIFAR-100 和 ImageNet 子集上证明了该方法的卓越性能，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01460v2",
      "published_date": "2024-05-02 16:49:25 UTC",
      "updated_date": "2024-05-06 06:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:23:02.743186"
    },
    {
      "arxiv_id": "2405.01458v2",
      "title": "UQA: Corpus for Urdu Question Answering",
      "title_zh": "UQA：乌尔都语问答语料库",
      "authors": [
        "Samee Arif",
        "Sualeha Farid",
        "Awais Athar",
        "Agha Ali Raza"
      ],
      "abstract": "This paper introduces UQA, a novel dataset for question answering and text\ncomprehension in Urdu, a low-resource language with over 70 million native\nspeakers. UQA is generated by translating the Stanford Question Answering\nDataset (SQuAD2.0), a large-scale English QA dataset, using a technique called\nEATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in\nthe translated context paragraphs. The paper describes the process of selecting\nand evaluating the best translation model among two candidates: Google\nTranslator and Seamless M4T. The paper also benchmarks several state-of-the-art\nmultilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and\nreports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and\n74.56 EM. UQA is a valuable resource for developing and testing multilingual\nNLP systems for Urdu and for enhancing the cross-lingual transferability of\nexisting models. Further, the paper demonstrates the effectiveness of EATS for\ncreating high-quality datasets for other languages and domains. The UQA dataset\nand the code are publicly available at www.github.com/sameearif/UQA.",
      "tldr_zh": "本研究引入了 UQA 数据集，这是一个针对乌尔都语（一种低资源语言）的问答和文本理解语料库，通过翻译 SQuAD2.0 数据集并使用 EATS（Enclose to Anchor, Translate, Seek）技术来保留答案跨度，从而确保翻译质量。研究者比较了 Google Translator 和 Seamless M4T 两种模型，并选择了最佳选项来生成数据集。随后，在 UQA 上基准测试了多语言 QA 模型，如 mBERT、XLM-RoBERTa 和 mT5，其中 XLM-RoBERTa-XL 取得了 F1 score 85.99 和 EM 74.56 的出色结果。UQA 作为公开资源（可在 GitHub 获取），有助于开发乌尔都语的多语言 NLP 系统，并证明 EATS 技术在创建其他语言数据集方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01458v2",
      "published_date": "2024-05-02 16:44:31 UTC",
      "updated_date": "2024-07-22 18:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:23:14.965845"
    },
    {
      "arxiv_id": "2405.01616v1",
      "title": "Generative Active Learning for the Search of Small-molecule Protein Binders",
      "title_zh": "翻译失败",
      "authors": [
        "Maksym Korablyov",
        "Cheng-Hao Liu",
        "Moksh Jain",
        "Almer M. van der Sloot",
        "Eric Jolicoeur",
        "Edward Ruediger",
        "Andrei Cristian Nica",
        "Emmanuel Bengio",
        "Kostiantyn Lapchevskyi",
        "Daniel St-Cyr",
        "Doris Alexandra Schuetz",
        "Victor Ion Butoi",
        "Jarrid Rector-Brooks",
        "Simon Blackburn",
        "Leo Feng",
        "Hadi Nekoei",
        "SaiKrishna Gottipati",
        "Priyesh Vijayan",
        "Prateek Gupta",
        "Ladislav Rampášek",
        "Sasikanth Avancha",
        "Pierre-Luc Bacon",
        "William L. Hamilton",
        "Brooks Paige",
        "Sanchit Misra",
        "Stanislaw Kamil Jastrzebski",
        "Bharat Kaul",
        "Doina Precup",
        "José Miguel Hernández-Lobato",
        "Marwin Segler",
        "Michael Bronstein",
        "Anne Marinier",
        "Mike Tyers",
        "Yoshua Bengio"
      ],
      "abstract": "Despite substantial progress in machine learning for scientific discovery in\nrecent years, truly de novo design of small molecules which exhibit a property\nof interest remains a significant challenge. We introduce LambdaZero, a\ngenerative active learning approach to search for synthesizable molecules.\nPowered by deep reinforcement learning, LambdaZero learns to search over the\nvast space of molecules to discover candidates with a desired property. We\napply LambdaZero with molecular docking to design novel small molecules that\ninhibit the enzyme soluble Epoxide Hydrolase 2 (sEH), while enforcing\nconstraints on synthesizability and drug-likeliness. LambdaZero provides an\nexponential speedup in terms of the number of calls to the expensive molecular\ndocking oracle, and LambdaZero de novo designed molecules reach docking scores\nthat would otherwise require the virtual screening of a hundred billion\nmolecules. Importantly, LambdaZero discovers novel scaffolds of synthesizable,\ndrug-like inhibitors for sEH. In in vitro experimental validation, a series of\nligands from a generated quinazoline-based scaffold were synthesized, and the\nlead inhibitor N-(4,6-di(pyrrolidin-1-yl)quinazolin-2-yl)-N-methylbenzamide\n(UM0152893) displayed sub-micromolar enzyme inhibition of sEH.",
      "tldr_zh": "该研究引入了LambdaZero，一种基于生成式主动学习的方法，利用深度强化学习在庞大分子空间中搜索具有特定属性的合成小分子。LambdaZero 通过结合分子对接技术，设计出新型抑制剂针对可溶性环氧水解酶 2 (sEH)，并强制执行合成性和药物相似性约束，从而显著加速了搜索过程，比传统虚拟筛选节省百亿级分子评估。实验结果显示，LambdaZero 发现的创新分子支架中，合成的喹唑啉基配体如 UM0152893 在体外验证中表现出亚微摩尔水平的 sEH 酶抑制效果。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01616v1",
      "published_date": "2024-05-02 16:39:21 UTC",
      "updated_date": "2024-05-02 16:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:23:24.295237"
    },
    {
      "arxiv_id": "2405.01453v3",
      "title": "Creative Problem Solving in Large Language and Vision Models -- What Would it Take?",
      "title_zh": "大型语言和",
      "authors": [
        "Lakshmi Nair",
        "Evana Gizzi",
        "Jivko Sinapov"
      ],
      "abstract": "We advocate for a strong integration of Computational Creativity (CC) with\nresearch in large language and vision models (LLVMs) to address a key\nlimitation of these models, i.e., creative problem solving. We present\npreliminary experiments showing how CC principles can be applied to address\nthis limitation. Our goal is to foster discussions on creative problem solving\nin LLVMs and CC at prestigious ML venues. Our code is available at:\nhttps://github.com/lnairGT/creative-problem-solving-LLMs",
      "tldr_zh": "该论文主张将计算创造力（Computational Creativity, CC）与大型语言和视觉模型（LLVMs）的研究紧密整合，以解决 LLVMs 在创造性问题解决方面的关键局限性。研究者通过初步实验展示了如何应用 CC 原则来提升模型的创新能力，例如通过实验设计来激发更灵活的响应。论文旨在在知名机器学习会议上推动关于 LLVMs 和 CC 中创造性问题解决的讨论，并提供了开源代码（https://github.com/lnairGT/creative-problem-solving-LLMs）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.01453v3",
      "published_date": "2024-05-02 16:36:26 UTC",
      "updated_date": "2024-10-01 13:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:23:36.771800"
    },
    {
      "arxiv_id": "2405.01614v3",
      "title": "RULSurv: A probabilistic survival-based method for early censoring-aware prediction of remaining useful life in ball bearings",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Marius Lillelund",
        "Fernando Pannullo",
        "Morten Opprud Jakobsen",
        "Manuel Morante",
        "Christian Fischer Pedersen"
      ],
      "abstract": "Predicting the remaining useful life (RUL) of ball bearings is an active area\nof research, where novel machine learning techniques are continuously being\napplied to predict degradation trends and anticipate failures before they\noccur. However, few studies have explicitly addressed the challenge of handling\ncensored data, where information about a specific event (\\eg mechanical\nfailure) is incomplete or only partially observed. To address this issue, we\nintroduce a novel and flexible method for early fault detection using\nKullback-Leibler (KL) divergence and RUL estimation using survival analysis\nthat naturally supports censored data. We demonstrate our approach in the\nXJTU-SY dataset using a 5-fold cross-validation strategy across three different\noperating conditions. When predicting the time to failure for bearings under\nthe highest load (C1, 12.0 kN and 2100 RPM) with 25% random censoring, our\napproach achieves a mean absolute error (MAE) of 14.7 minutes (95% CI =\n13.6-15.8) using a linear CoxPH model, and an MAE of 12.6 minutes (95% CI =\n11.8-13.4) using a nonlinear Random Survival Forests model, compared to an MAE\nof 18.5 minutes (95% CI = 17.4-19.6) using a linear LASSO model that does not\nsupport censoring. Moreover, our approach achieves a mean cumulative relative\naccuracy (CRA) of 0.7586 over 5 bearings under the highest load, which improves\nover several state-of-the-art baselines. Our work highlights the importance of\nconsidering censored data as part of the model design when building predictive\nmodels for early fault detection and RUL estimation.",
      "tldr_zh": "本论文提出RULSurv，一种基于概率生存分析的方法，用于预测球轴承的剩余使用寿命(RUL)，特别针对censored data（不完整数据）问题，通过Kullback-Leibler (KL) divergence进行早期故障检测，并结合生存分析模型进行RUL估计。方法在XJTU-SY数据集上采用5-fold跨验证策略，在三种操作条件下测试，结果显示在最高负载（C1, 12.0 kN and 2100 RPM）下，线性CoxPH模型和非线性Random Survival Forests模型分别实现MAE为14.7分钟和12.6分钟，优于不支持censored data的LASSO模型（MAE 18.5分钟）。此外，该方法平均累积相对准确率(CRA)达0.7586，超越现有基线，强调在构建早期故障检测和RUL预测模型时，必须考虑censored data的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01614v3",
      "published_date": "2024-05-02 16:17:29 UTC",
      "updated_date": "2025-04-14 11:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:23:53.688758"
    },
    {
      "arxiv_id": "2405.01419v3",
      "title": "Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Paola Vitolo",
        "George Psaltakis",
        "Michael Tomlinson",
        "Gian Domenico Licciardo",
        "Andreas G. Andreou"
      ],
      "abstract": "This paper investigates the use of Large Language Models (LLMs) and natural\nlanguage prompts to generate hardware description code, namely Verilog.\nBuilding on our prior work, we employ OpenAI's ChatGPT4 and natural language\nprompts to synthesize an RTL Verilog module of a programmable recurrent spiking\nneural network, while also generating test benches to assess the system's\ncorrectness. The resultant design was validated in three simple machine\nlearning tasks, the exclusive OR, the IRIS flower classification and the MNIST\nhand-written digit classification. Furthermore, the design was validated on a\nField-Programmable Gate Array (FPGA) and subsequently synthesized in the\nSkyWater 130 nm technology by using an open-source electronic design automation\nflow. The design was submitted to Efabless Tiny Tapeout 6.",
      "tldr_zh": "本论文探讨了使用大型语言模型(LLMs) 和自然语言提示生成硬件描述语言 Verilog 的方法，具体通过 OpenAI 的 ChatGPT4 合成一个可编程的 recurrent spiking neural network 的 RTL Verilog 模块，并同时创建测试台以验证系统正确性。该设计在 XOR、IRIS 花分类和 MNIST 手写数字分类等三个简单机器学习任务上进行了验证，并在 Field-Programmable Gate Array (FPGA) 上运行成功。最终，该设计使用开源电子设计自动化流程在 SkyWater 130 nm 技术中合成，并提交到 Efabless Tiny Tapeout 6，展示了 LLMs 在硬件设计中的潜力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "This paper was presented at the IEEE/ACM International Conference on\n  Neuromorphic Systems (ICONS), July 30-Aug 2, 2024, Arlington, VA, USA",
      "pdf_url": "http://arxiv.org/pdf/2405.01419v3",
      "published_date": "2024-05-02 16:08:08 UTC",
      "updated_date": "2024-10-22 18:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:24:01.949810"
    },
    {
      "arxiv_id": "2405.03701v2",
      "title": "QxEAI: Quantum-like evolutionary algorithm for automated probabilistic forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Xin",
        "Lizhi Xin"
      ],
      "abstract": "Forecasting, to estimate future events, is crucial for business and\ndecision-making. This paper proposes QxEAI, a methodology that produces a\nprobabilistic forecast that utilizes a quantum-like evolutionary algorithm\nbased on training a quantum-like logic decision tree and a classical value tree\non a small number of related time series. We demonstrate how the application of\nour quantum-like evolutionary algorithm to forecasting can overcome the\nchallenges faced by classical and other machine learning approaches. By using\nthree real-world datasets (Dow Jones Index, retail sales, gas consumption), we\nshow how our methodology produces accurate forecasts while requiring little to\nnone manual work.",
      "tldr_zh": "这篇论文提出了 QxEAI，一种基于 quantum-like evolutionary algorithm 的方法，用于自动化 probabilistic forecasting，帮助商业决策。QxEAI 通过训练 quantum-like logic decision tree 和 classical value tree，利用少量相关的时间序列数据，克服了传统机器学习方法的挑战。实验结果显示，在 Dow Jones Index、零售销售和天然气消费等真实数据集上，该方法实现了高准确性，同时几乎不需要手动干预。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03701v2",
      "published_date": "2024-05-02 16:05:02 UTC",
      "updated_date": "2024-06-21 02:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:24:13.930756"
    },
    {
      "arxiv_id": "2405.01413v1",
      "title": "MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors",
      "title_zh": "MiniGPT-3D：使用 2D 先验高效对齐 3D 点云与大型语言模型",
      "authors": [
        "Yuan Tang",
        "Xu Han",
        "Xianzhi Li",
        "Qiao Yu",
        "Yixue Hao",
        "Long Hu",
        "Min Chen"
      ],
      "abstract": "Large 2D vision-language models (2D-LLMs) have gained significant attention\nby bridging Large Language Models (LLMs) with images using a simple projector.\nInspired by their success, large 3D point cloud-language models (3D-LLMs) also\nintegrate point clouds into LLMs. However, directly aligning point clouds with\nLLM requires expensive training costs, typically in hundreds of GPU-hours on\nA100, which hinders the development of 3D-LLMs. In this paper, we introduce\nMiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA\nresults while training for only 27 hours on one RTX 3090. Specifically, we\npropose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which\ncan leverage the similarity between 2D and 3D visual information. We introduce\na novel four-stage training strategy for modality alignment in a cascaded way,\nand a mixture of query experts module to adaptively aggregate features with\nhigh efficiency. Moreover, we utilize parameter-efficient fine-tuning methods\nLoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which\nis up to 260x fewer than existing methods. Extensive experiments show that\nMiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with\nsignificantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12\nincrease on GPT-4 evaluation score for the challenging object captioning task\ncompared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800.\nWe are the first to explore the efficient 3D-LLM, offering new insights to the\ncommunity. Code and weights are available at\nhttps://github.com/TangYuan96/MiniGPT-3D.",
      "tldr_zh": "本研究提出 MiniGPT-3D，一种高效的 3D-LLM（3D point cloud-language models），通过利用 2D priors 来自 2D-LLMs 来对齐 3D 点云，从而显著降低训练成本，仅需 27 小时在一个 RTX 3090 上完成。方法包括一个四阶段训练策略（four-stage training strategy）用于级联式模态对齐、混合查询专家模块（mixture of query experts module）来高效聚合特征，以及参数高效微调技术 LoRA 和 Norm fine-tuning，仅涉及 47.8M 可学习参数，比现有方法减少 260 倍。实验结果显示，MiniGPT-3D 在 3D 对象分类和描述任务上达到 SOTA（State-of-the-Art），并在对象描述任务上使 GPT-4 评估分数较 ShapeLLM-13B 提高 8.12，同时提供新见解并开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01413v1",
      "published_date": "2024-05-02 16:04:30 UTC",
      "updated_date": "2024-05-02 16:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:24:26.946853"
    },
    {
      "arxiv_id": "2405.01409v3",
      "title": "Goal-conditioned reinforcement learning for ultrasound navigation guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoul Aziz Amadou",
        "Vivek Singh",
        "Florin C. Ghesu",
        "Young-Ho Kim",
        "Laura Stanciulescu",
        "Harshitha P. Sai",
        "Puneet Sharma",
        "Alistair Young",
        "Ronak Rajani",
        "Kawal Rhode"
      ],
      "abstract": "Transesophageal echocardiography (TEE) plays a pivotal role in cardiology for\ndiagnostic and interventional procedures. However, using it effectively\nrequires extensive training due to the intricate nature of image acquisition\nand interpretation. To enhance the efficiency of novice sonographers and reduce\nvariability in scan acquisitions, we propose a novel ultrasound (US) navigation\nassistance method based on contrastive learning as goal-conditioned\nreinforcement learning (GCRL). We augment the previous framework using a novel\ncontrastive patient batching method (CPB) and a data-augmented contrastive\nloss, both of which we demonstrate are essential to ensure generalization to\nanatomical variations across patients. The proposed framework enables\nnavigation to both standard diagnostic as well as intricate interventional\nviews with a single model. Our method was developed with a large dataset of 789\npatients and obtained an average error of 6.56 mm in position and 9.36 degrees\nin angle on a testing dataset of 140 patients, which is competitive or superior\nto models trained on individual views. Furthermore, we quantitatively validate\nour method's ability to navigate to interventional views such as the Left\nAtrial Appendage (LAA) view used in LAA closure. Our approach holds promise in\nproviding valuable guidance during transesophageal ultrasound examinations,\ncontributing to the advancement of skill acquisition for cardiac ultrasound\npractitioners.",
      "tldr_zh": "本研究针对经食道超声心动图 (TEE) 的复杂操作提出了一种基于对比学习的目标条件强化学习 (GCRL) 方法，用于辅助超声导航，提高新手声学家的效率并减少扫描变异。创新点包括引入对比患者批量方法 (CPB) 和数据增强对比损失，以提升模型对患者间解剖变异的泛化能力，使单一模型能导航到标准诊断视图和复杂介入视图，如 Left Atrial Appendage (LAA) 视图。实验结果显示，在789个患者数据集上训练的模型，在140个测试患者上实现了位置误差6.56 mm和角度误差9.36度的表现，优于针对单个视图训练的模型，并为心脏超声技能获取提供宝贵指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.5.0"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in MICCAI 2024; 11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01409v3",
      "published_date": "2024-05-02 16:01:58 UTC",
      "updated_date": "2024-08-01 08:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:24:38.087591"
    },
    {
      "arxiv_id": "2405.01403v1",
      "title": "Unsupervised Flow Discovery from Task-oriented Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Patrícia Ferreira",
        "Daniel Martins",
        "Ana Alves",
        "Catarina Silva",
        "Hugo Gonçalo Oliveira"
      ],
      "abstract": "The design of dialogue flows is a critical but time-consuming task when\ndeveloping task-oriented dialogue (TOD) systems. We propose an approach for the\nunsupervised discovery of flows from dialogue history, thus making the process\napplicable to any domain for which such an history is available. Briefly,\nutterances are represented in a vector space and clustered according to their\nsemantic similarity. Clusters, which can be seen as dialogue states, are then\nused as the vertices of a transition graph for representing the flows visually.\nWe present concrete examples of flows, discovered from MultiWOZ, a public TOD\ndataset. We further elaborate on their significance and relevance for the\nunderlying conversations and introduce an automatic validation metric for their\nassessment. Experimental results demonstrate the potential of the proposed\napproach for extracting meaningful flows from task-oriented conversations.",
      "tldr_zh": "本论文提出了一种无监督方法，用于从任务导向对话（Task-oriented Dialogues, TOD）历史中自动发现对话流程（Flow Discovery），以简化 TOD 系统设计过程。具体而言，该方法将话语表示为向量空间，根据语义相似性进行聚类，将聚类结果视为对话状态（dialogue states），并构建过渡图（transition graph）来可视化流程。实验在 MultiWOZ 数据集上进行，展示了提取的有意义流程，并引入了自动验证指标，结果证明了该方法的有效性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01403v1",
      "published_date": "2024-05-02 15:54:36 UTC",
      "updated_date": "2024-05-02 15:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:24:49.309199"
    },
    {
      "arxiv_id": "2405.01402v2",
      "title": "Learning Force Control for Legged Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Tifanny Portela",
        "Gabriel B. Margolis",
        "Yandong Ji",
        "Pulkit Agrawal"
      ],
      "abstract": "Controlling contact forces during interactions is critical for locomotion and\nmanipulation tasks. While sim-to-real reinforcement learning (RL) has succeeded\nin many contact-rich problems, current RL methods achieve forceful interactions\nimplicitly without explicitly regulating forces. We propose a method for\ntraining RL policies for direct force control without requiring access to force\nsensing. We showcase our method on a whole-body control platform of a quadruped\nrobot with an arm. Such force control enables us to perform gravity\ncompensation and impedance control, unlocking compliant whole-body\nmanipulation. The learned whole-body controller with variable compliance makes\nit intuitive for humans to teleoperate the robot by only commanding the\nmanipulator, and the robot's body adjusts automatically to achieve the desired\nposition and force. Consequently, a human teleoperator can easily demonstrate a\nwide variety of loco-manipulation tasks. To the best of our knowledge, we\nprovide the first deployment of learned whole-body force control in legged\nmanipulators, paving the way for more versatile and adaptable legged robots.",
      "tldr_zh": "本文提出了一种基于强化学习 (RL) 的方法，用于训练直接力控制策略，而无需访问力传感器，旨在解决腿部操作任务中接触力的精确调节问题。该方法在四足机器人带有机械臂的全身控制平台上进行验证，实现重力补偿和阻抗控制，从而支持顺从的操作和可变顺从性的整机控制。结果表明，该控制器使人类遥操作者只需命令机械臂即可轻松演示多种 loco-manipulation 任务，为开发更通用适应的腿部机器人铺平道路。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been accepted to ICRA24, as well as the\n  Loco-manipulation workshop at ICRA24",
      "pdf_url": "http://arxiv.org/pdf/2405.01402v2",
      "published_date": "2024-05-02 15:53:43 UTC",
      "updated_date": "2024-05-20 12:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:25:02.243853"
    },
    {
      "arxiv_id": "2405.02345v1",
      "title": "Exploring the Capabilities of Large Language Models for Generating Diverse Design Solutions",
      "title_zh": "探索大语言模型生成多样设计解决方案的能力",
      "authors": [
        "Kevin Ma",
        "Daniele Grandi",
        "Christopher McComb",
        "Kosa Goucher-Lambert"
      ],
      "abstract": "Access to large amounts of diverse design solutions can support designers\nduring the early stage of the design process. In this paper, we explore the\nefficacy of large language models (LLM) in producing diverse design solutions,\ninvestigating the level of impact that parameter tuning and various prompt\nengineering techniques can have on the diversity of LLM-generated design\nsolutions. Specifically, LLMs are used to generate a total of 4,000 design\nsolutions across five distinct design topics, eight combinations of parameters,\nand eight different types of prompt engineering techniques, comparing each\ncombination of parameter and prompt engineering method across four different\ndiversity metrics. LLM-generated solutions are compared against 100\nhuman-crowdsourced solutions in each design topic using the same set of\ndiversity metrics. Results indicate that human-generated solutions consistently\nhave greater diversity scores across all design topics. Using a post hoc\nlogistic regression analysis we investigate whether these differences primarily\nexist at the semantic level. Results show that there is a divide in some design\ntopics between humans and LLM-generated solutions, while others have no clear\ndivide. Taken together, these results contribute to the understanding of LLMs'\ncapabilities in generating a large volume of diverse design solutions and offer\ninsights for future research that leverages LLMs to generate diverse design\nsolutions for a broad range of design tasks (e.g., inspirational stimuli).",
      "tldr_zh": "本文探讨大型语言模型(LLM)在生成多样设计解决方案方面的能力，特别考察参数调整和提示工程技术对多样性的影响。研究通过LLM生成4000个解决方案，涵盖五个设计主题、八种参数组合和八种提示工程方法，并使用四种多样性指标与人类众包的100个解决方案进行比较。结果显示，人类生成的解决方案在所有主题上多样性得分更高，且后续逻辑回归分析揭示某些主题在语义层面存在显著差异，而其他主题则无明显分化。该研究增强了对LLM生成设计解决方案潜力的理解，并为未来应用提供宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "preprint of journal paper",
      "pdf_url": "http://arxiv.org/pdf/2405.02345v1",
      "published_date": "2024-05-02 14:20:04 UTC",
      "updated_date": "2024-05-02 14:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:25:14.647886"
    },
    {
      "arxiv_id": "2405.01305v3",
      "title": "Distributed Representations Enable Robust Multi-Timescale Symbolic Computation in Neuromorphic Hardware",
      "title_zh": "分布表示使神经",
      "authors": [
        "Madison Cotteret",
        "Hugh Greatorex",
        "Alpha Renner",
        "Junren Chen",
        "Emre Neftci",
        "Huaqiang Wu",
        "Giacomo Indiveri",
        "Martin Ziegler",
        "Elisabetta Chicca"
      ],
      "abstract": "Programming recurrent spiking neural networks (RSNNs) to robustly perform\nmulti-timescale computation remains a difficult challenge. To address this, we\ndescribe a single-shot weight learning scheme to embed robust multi-timescale\ndynamics into attractor-based RSNNs, by exploiting the properties of\nhigh-dimensional distributed representations. We embed finite state machines\ninto the RSNN dynamics by superimposing a symmetric autoassociative weight\nmatrix and asymmetric transition terms, which are each formed by the vector\nbinding of an input and heteroassociative outer-products between states. Our\napproach is validated through simulations with highly nonideal weights; an\nexperimental closed-loop memristive hardware setup; and on Loihi 2, where it\nscales seamlessly to large state machines. This work introduces a scalable\napproach to embed robust symbolic computation through recurrent dynamics into\nneuromorphic hardware, without requiring parameter fine-tuning or significant\nplatform-specific optimisation. Moreover, it demonstrates that distributed\nsymbolic representations serve as a highly capable representation-invariant\nlanguage for cognitive algorithms in neuromorphic hardware.",
      "tldr_zh": "本研究提出了一种单次权重学习方案，用于在基于吸引子的循环脉冲神经网络（RSNNs）中嵌入鲁棒的多时间尺度动态，通过利用高维分布式 representations 的特性。方法涉及将有限状态机嵌入 RSNN 动态中，采用对称自联想权重矩阵与非对称转移项的叠加，这些转移项由输入和状态之间的向量绑定及异联想外积形成。该方案在高度非理想权重模拟、实验闭环忆阻硬件设置以及 Loihi 2 硬件上得到验证，能够无缝扩展到大型状态机，并无需参数微调或特定平台优化。最后，该工作证明分布式符号 representations 是一种高效的表示不变语言，促进神经形态硬件中的认知算法发展。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "19 pages, 7 figures. Supplementary material: 13 pages, 8 figures.\n  Accepted for publication in Neuromorphic Computing and Engineering",
      "pdf_url": "http://arxiv.org/pdf/2405.01305v3",
      "published_date": "2024-05-02 14:11:50 UTC",
      "updated_date": "2025-01-13 14:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:25:26.614878"
    },
    {
      "arxiv_id": "2405.01299v1",
      "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Maja Pavlovic",
        "Massimo Poesio"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful support tools across\nvarious natural language tasks and a range of application domains. Recent\nstudies focus on exploring their capabilities for data annotation. This paper\nprovides a comparative overview of twelve studies investigating the potential\nof LLMs in labelling data. While the models demonstrate promising cost and\ntime-saving benefits, there exist considerable limitations, such as\nrepresentativeness, bias, sensitivity to prompt variations and English language\npreference. Leveraging insights from these studies, our empirical analysis\nfurther examines the alignment between human and GPT-generated opinion\ndistributions across four subjective datasets. In contrast to the studies\nexamining representation, our methodology directly obtains the opinion\ndistribution from GPT. Our analysis thereby supports the minority of studies\nthat are considering diverse perspectives when evaluating data annotation tasks\nand highlights the need for further research in this direction.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）作为数据标注工具的有效性，通过对12个相关研究的比较概述，探讨了LLMs在节省成本和时间方面的优势，同时指出了其局限性，如代表性问题、偏差、对提示变化的敏感性和偏好英语。作者进行了实证分析，直接从GPT获取意见分布，并与人类意见在四个主观数据集上进行比对，结果显示LLMs在捕捉多样视角方面仍有不足，支持了少数研究的观点。总体而言，该研究强调了在数据标注任务中使用LLMs时需要进一步关注多样性和准确性，以改进其应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING NLPerspectives workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.01299v1",
      "published_date": "2024-05-02 14:00:22 UTC",
      "updated_date": "2024-05-02 14:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:25:38.158744"
    },
    {
      "arxiv_id": "2405.01293v1",
      "title": "Low-resource speech recognition and dialect identification of Irish in a multi-task framework",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Lonergan",
        "Mengjie Qian",
        "Neasa Ní Chiaráin",
        "Christer Gobl",
        "Ailbhe Ní Chasaide"
      ],
      "abstract": "This paper explores the use of Hybrid CTC/Attention encoder-decoder models\ntrained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech\nrecognition (ASR) and dialect identification (DID). Results are compared to the\ncurrent best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN).\nAn optimal InterCTC setting is initially established using a Conformer encoder.\nThis setting is then used to train a model with an E-branchformer encoder and\nthe performance of both architectures are compared. A multi-task fine-tuning\napproach is adopted for language model (LM) shallow fusion. The experiments\nyielded an improvement in DID accuracy of 10.8% relative to a baseline\nECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task\napproach emerges as a promising strategy for Irish low-resource ASR and DID.",
      "tldr_zh": "这篇论文探讨了在多任务框架中使用 Hybrid CTC/Attention 编码器-解码器模型结合 Intermediate CTC (InterCTC) 来处理爱尔兰语的低资源语音识别 (ASR) 和方言识别 (DID)。研究者首先使用 Conformer 编码器优化 InterCTC 设置，然后应用到 E-branchformer 编码器上，并与基线模型（如 TDNN-HMM 用于 ASR 和 ECAPA-TDNN 用于 DID）进行比较，同时采用语言模型 (LM) shallow fusion 的多任务微调方法。实验结果显示，DID 准确率相对于基线 ECAPA-TDNN 相对提高了 10.8%，而 ASR 的 WER 性能接近 TDNN-HMM 模型。这种多任务方法为爱尔兰语低资源场景的 ASR 和 DID 提供了有前景的策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages. Accepted to Odyssey 2024 - The Speaker and Language\n  Recognition Workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.01293v1",
      "published_date": "2024-05-02 13:54:39 UTC",
      "updated_date": "2024-05-02 13:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:25:52.059129"
    },
    {
      "arxiv_id": "2405.02344v1",
      "title": "Backdoor-based Explainable AI Benchmark for High Fidelity Evaluation of Attribution Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyu Yang",
        "Naveed Akhtar",
        "Jiantong Jiang",
        "Ajmal Mian"
      ],
      "abstract": "Attribution methods compute importance scores for input features to explain\nthe output predictions of deep models. However, accurate assessment of\nattribution methods is challenged by the lack of benchmark fidelity for\nattributing model predictions. Moreover, other confounding factors in\nattribution estimation, including the setup choices of post-processing\ntechniques and explained model predictions, further compromise the reliability\nof the evaluation. In this work, we first identify a set of fidelity criteria\nthat reliable benchmarks for attribution methods are expected to fulfill,\nthereby facilitating a systematic assessment of attribution benchmarks. Next,\nwe introduce a Backdoor-based eXplainable AI benchmark (BackX) that adheres to\nthe desired fidelity criteria. We theoretically establish the superiority of\nour approach over the existing benchmarks for well-founded attribution\nevaluation. With extensive analysis, we also identify a setup for a consistent\nand fair benchmarking of attribution methods across different underlying\nmethodologies. This setup is ultimately employed for a comprehensive comparison\nof existing methods using our BackX benchmark. Finally, our analysis also\nprovides guidance for defending against backdoor attacks with the help of\nattribution methods.",
      "tldr_zh": "这篇论文针对归因方法(attribution methods)的评估挑战，提出了一种基于后门攻击(Backdoor-based)的可解释 AI 基准(BackX)，以实现高保真度(fidelity)评价。该基准满足一组预定义的保真度标准，并通过理论分析证明其优于现有基准。论文还通过广泛实验确定了一个一致的基准设置，用于比较不同归因方法，并提供指导，帮助利用这些方法防御后门攻击(backdoor attacks)。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02344v1",
      "published_date": "2024-05-02 13:48:37 UTC",
      "updated_date": "2024-05-02 13:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:26:03.274770"
    },
    {
      "arxiv_id": "2405.01286v1",
      "title": "Data Feminism for AI",
      "title_zh": "翻译失败",
      "authors": [
        "Lauren Klein",
        "Catherine D'Ignazio"
      ],
      "abstract": "This paper presents a set of intersectional feminist principles for\nconducting equitable, ethical, and sustainable AI research. In Data Feminism\n(2020), we offered seven principles for examining and challenging unequal power\nin data science. Here, we present a rationale for why feminism remains deeply\nrelevant for AI research, rearticulate the original principles of data feminism\nwith respect to AI, and introduce two potential new principles related to\nenvironmental impact and consent. Together, these principles help to 1) account\nfor the unequal, undemocratic, extractive, and exclusionary forces at work in\nAI research, development, and deployment; 2) identify and mitigate predictable\nharms in advance of unsafe, discriminatory, or otherwise oppressive systems\nbeing released into the world; and 3) inspire creative, joyful, and collective\nways to work towards a more equitable, sustainable world in which all of us can\nthrive.",
      "tldr_zh": "这篇论文提出了一套交叉女权主义原则，用于推动公平、道德和可持续的 AI 研究，旨在应对 AI 领域的权力不平等。作者基于《Data Feminism (2020)》的七个原则，重新表述这些原则以适应 AI 情境，并引入两个新原则，涉及环境影响和同意。这些原则有助于识别并缓解 AI 研究中的提取性与排他性力量、提前防范有害系统的发布，并激发集体创新以实现更公平、可持续的世界。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; K.4.0"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages, to be published in the 2024 ACM Conference on Fairness,\n  Accountability, and Transparency (FAccT '24)",
      "pdf_url": "http://arxiv.org/pdf/2405.01286v1",
      "published_date": "2024-05-02 13:46:29 UTC",
      "updated_date": "2024-05-02 13:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:26:14.853059"
    },
    {
      "arxiv_id": "2405.01273v2",
      "title": "Towards Inclusive Face Recognition Through Synthetic Ethnicity Alteration",
      "title_zh": "翻译失败",
      "authors": [
        "Praveen Kumar Chandaliya",
        "Kiran Raja",
        "Raghavendra Ramachandra",
        "Zahid Akhtar",
        "Christoph Busch"
      ],
      "abstract": "Numerous studies have shown that existing Face Recognition Systems (FRS),\nincluding commercial ones, often exhibit biases toward certain ethnicities due\nto under-represented data. In this work, we explore ethnicity alteration and\nskin tone modification using synthetic face image generation methods to\nincrease the diversity of datasets. We conduct a detailed analysis by first\nconstructing a balanced face image dataset representing three ethnicities:\nAsian, Black, and Indian. We then make use of existing Generative Adversarial\nNetwork-based (GAN) image-to-image translation and manifold learning models to\nalter the ethnicity from one to another. A systematic analysis is further\nconducted to assess the suitability of such datasets for FRS by studying the\nrealistic skin-tone representation using Individual Typology Angle (ITA).\nFurther, we also analyze the quality characteristics using existing Face image\nquality assessment (FIQA) approaches. We then provide a holistic FRS\nperformance analysis using four different systems. Our findings pave the way\nfor future research works in (i) developing both specific ethnicity and general\n(any to any) ethnicity alteration models, (ii) expanding such approaches to\ncreate databases with diverse skin tones, (iii) creating datasets representing\nvarious ethnicities which further can help in mitigating bias while addressing\nprivacy concerns.",
      "tldr_zh": "本研究针对现有面部识别系统 (FRS) 的种族偏见问题，提出通过合成图像生成方法（如基于 Generative Adversarial Network (GAN) 的图像转换和流形学习）来改变种族和皮肤色调，从而增强数据集的多样性。研究者构建了一个平衡数据集，涵盖 Asian、Black 和 Indian 等三个种族，并通过 Individual Typology Angle (ITA) 和 Face image quality assessment (FIQA) 评估皮肤色调真实性和图像质量，同时对四种 FRS 进行整体性能分析。结果显示，此方法能有效缓解偏见，并为未来开发特定或通用种族改变模型、扩展多样化数据集以及解决隐私问题提供新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 Pages",
      "pdf_url": "http://arxiv.org/pdf/2405.01273v2",
      "published_date": "2024-05-02 13:31:09 UTC",
      "updated_date": "2024-05-07 03:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:26:28.082967"
    },
    {
      "arxiv_id": "2405.01611v1",
      "title": "Unifying and extending Precision Recall metrics for assessing generative models",
      "title_zh": "统一与扩展精确率-召回率指标用于",
      "authors": [
        "Benjamin Sykes",
        "Loic Simon",
        "Julien Rabin"
      ],
      "abstract": "With the recent success of generative models in image and text, the\nevaluation of generative models has gained a lot of attention. Whereas most\ngenerative models are compared in terms of scalar values such as Frechet\nInception Distance (FID) or Inception Score (IS), in the last years (Sajjadi et\nal., 2018) proposed a definition of precision-recall curve to characterize the\ncloseness of two distributions. Since then, various approaches to precision and\nrecall have seen the light (Kynkaanniemi et al., 2019; Naeem et al., 2020; Park\n& Kim, 2023). They center their attention on the extreme values of precision\nand recall, but apart from this fact, their ties are elusive. In this paper, we\nunify most of these approaches under the same umbrella, relying on the work of\n(Simon et al., 2019). Doing so, we were able not only to recover entire curves,\nbut also to expose the sources of the accounted pitfalls of the concerned\nmetrics. We also provide consistency results that go well beyond the ones\npresented in the corresponding literature. Last, we study the different\nbehaviors of the curves obtained experimentally.",
      "tldr_zh": "该论文统一并扩展了评估生成模型的 Precision-Recall 指标，旨在解决现有方法在比较分布相似度时存在的模糊联系问题。作者基于 Simon et al., 2019 的工作，整合了多种 Precision 和 Recall 变体（如 Kynkaanniemi et al., 2019；Naeem et al., 2020），不仅恢复了完整的 Precision-Recall 曲线，还揭示了这些指标的潜在缺陷。论文提供了超越现有文献的一致性结果，并通过实验验证了这些曲线的不同行为，从而提升了生成模型（如图像和文本模型）的评估可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01611v1",
      "published_date": "2024-05-02 13:19:21 UTC",
      "updated_date": "2024-05-02 13:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:26:38.928453"
    },
    {
      "arxiv_id": "2405.01266v1",
      "title": "MFTraj: Map-Free, Behavior-Driven Trajectory Prediction for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Haicheng Liao",
        "Zhenning Li",
        "Chengyue Wang",
        "Huanming Shen",
        "Bonan Wang",
        "Dongping Liao",
        "Guofa Li",
        "Chengzhong Xu"
      ],
      "abstract": "This paper introduces a trajectory prediction model tailored for autonomous\ndriving, focusing on capturing complex interactions in dynamic traffic\nscenarios without reliance on high-definition maps. The model, termed MFTraj,\nharnesses historical trajectory data combined with a novel dynamic geometric\ngraph-based behavior-aware module. At its core, an adaptive structure-aware\ninteractive graph convolutional network captures both positional and behavioral\nfeatures of road users, preserving spatial-temporal intricacies. Enhanced by a\nlinear attention mechanism, the model achieves computational efficiency and\nreduced parameter overhead. Evaluations on the Argoverse, NGSIM, HighD, and\nMoCAD datasets underscore MFTraj's robustness and adaptability, outperforming\nnumerous benchmarks even in data-challenged scenarios without the need for\nadditional information such as HD maps or vectorized maps. Importantly, it\nmaintains competitive performance even in scenarios with substantial missing\ndata, on par with most existing state-of-the-art models. The results and\nmethodology suggest a significant advancement in autonomous driving trajectory\nprediction, paving the way for safer and more efficient autonomous systems.",
      "tldr_zh": "本研究提出MFTraj，一种不依赖高清地图的轨迹预测模型，用于自动驾驶系统，专注于捕捉动态交通场景中的复杂互动。模型结合历史轨迹数据和动态几何图-based behavior-aware 模块，通过自适应结构感知交互图卷积网络和线性注意力机制来捕捉道路使用者的位置和行为特征，同时提升计算效率并减少参数开销。在Argoverse、NGSIM、HighD和MoCAD数据集上的评估显示，MFTraj超越多项基准模型，即使在数据缺失或无额外信息（如HD地图）的情况下，仍保持出色性能，为更安全、高效的自动驾驶系统提供了重要进展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01266v1",
      "published_date": "2024-05-02 13:13:52 UTC",
      "updated_date": "2024-05-02 13:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:26:51.967618"
    },
    {
      "arxiv_id": "2405.01259v1",
      "title": "Identification of Entailment and Contradiction Relations between Natural Language Sentences: A Neurosymbolic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xuyao Feng",
        "Anthony Hunter"
      ],
      "abstract": "Natural language inference (NLI), also known as Recognizing Textual\nEntailment (RTE), is an important aspect of natural language understanding.\nMost research now uses machine learning and deep learning to perform this task\non specific datasets, meaning their solution is not explainable nor explicit.\nTo address the need for an explainable approach to RTE, we propose a novel\npipeline that is based on translating text into an Abstract Meaning\nRepresentation (AMR) graph. For this we use a pre-trained AMR parser. We then\ntranslate the AMR graph into propositional logic and use a SAT solver for\nautomated reasoning. In text, often commonsense suggests that an entailment (or\ncontradiction) relationship holds between a premise and a claim, but because\ndifferent wordings are used, this is not identified from their logical\nrepresentations. To address this, we introduce relaxation methods to allow\nreplacement or forgetting of some propositions. Our experimental results show\nthis pipeline performs well on four RTE datasets.",
      "tldr_zh": "这篇论文提出了一种神经符号方法，用于识别自然语言句子之间的蕴涵（entailment）和矛盾（contradiction）关系（Recognizing Textual Entailment, RTE），以解决传统机器学习和深度学习方法缺乏解释性的问题。方法包括使用预训练的 Abstract Meaning Representation (AMR) 解析器将文本转换为AMR图，然后将其翻译成命题逻辑，并通过SAT solver进行自动推理。为了处理词汇差异和常识暗示，该管道引入了松弛方法，如替换或忽略某些命题。实验结果表明，该方法在四个RTE数据集上表现出色，提供了一个可解释的NLI解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01259v1",
      "published_date": "2024-05-02 13:06:24 UTC",
      "updated_date": "2024-05-02 13:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:27:03.815256"
    },
    {
      "arxiv_id": "2405.01242v3",
      "title": "TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Yueyuan Sui",
        "Minghui Zhao",
        "Junxi Xia",
        "Xiaofan Jiang",
        "Stephen Xia"
      ],
      "abstract": "We propose TRAMBA, a hybrid transformer and Mamba architecture for acoustic\nand bone conduction speech enhancement, suitable for mobile and wearable\nplatforms. Bone conduction speech enhancement has been impractical to adopt in\nmobile and wearable platforms for several reasons: (i) data collection is\nlabor-intensive, resulting in scarcity; (ii) there exists a performance gap\nbetween state of-art models with memory footprints of hundreds of MBs and\nmethods better suited for resource-constrained systems. To adapt TRAMBA to\nvibration-based sensing modalities, we pre-train TRAMBA with audio speech\ndatasets that are widely available. Then, users fine-tune with a small amount\nof bone conduction data. TRAMBA outperforms state-of-art GANs by up to 7.3% in\nPESQ and 1.8% in STOI, with an order of magnitude smaller memory footprint and\nan inference speed up of up to 465 times. We integrate TRAMBA into real systems\nand show that TRAMBA (i) improves battery life of wearables by up to 160% by\nrequiring less data sampling and transmission; (ii) generates higher quality\nvoice in noisy environments than over-the-air speech; (iii) requires a memory\nfootprint of less than 20.0 MB.",
      "tldr_zh": "本研究提出 TRAMBA，一种混合 Transformer 和 Mamba 架构，用于音频和骨导语音的超分辨率和增强，特别适用于移动和可穿戴平台，以解决数据稀缺和资源限制问题。方法包括先用广泛可用的音频语音数据集预训练模型，然后通过少量骨导数据微调，实现高效适应。实验结果显示，TRAMBA 比最先进的 GAN 模型在 PESQ 上提升 7.3%、在 STOI 上提升 1.8%，并具有小一个数量级的内存占用和高达 465 倍的推理速度加速。在实际系统中，TRAMBA 可将可穿戴设备电池寿命延长 160%、在嘈杂环境中生成更高质量语音，且内存占用不到 20.0 MB。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01242v3",
      "published_date": "2024-05-02 12:45:48 UTC",
      "updated_date": "2024-05-29 15:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:27:15.460990"
    },
    {
      "arxiv_id": "2405.01229v2",
      "title": "Boosting Jailbreak Attack with Momentum",
      "title_zh": "利用动量提升越狱攻击",
      "authors": [
        "Yihao Zhang",
        "Zeming Wei"
      ],
      "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的 jailbreak 攻击漏洞，指出现有 Greedy Coordinate Gradient (GCG) 攻击虽有效但效率低下。论文提出 Momentum Accelerated GCG (MAC) 攻击，通过在梯度启发式中整合动量项来稳定优化过程并提升随机搜索效率。实验结果显示，MAC 攻击在攻击成功率和优化效率上显著优于基线模型，且适用于转移攻击和防御机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.01229v2",
      "published_date": "2024-05-02 12:18:14 UTC",
      "updated_date": "2025-03-02 12:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:27:26.822685"
    },
    {
      "arxiv_id": "2405.01216v1",
      "title": "DMON: A Simple yet Effective Approach for Argument Structure Learning",
      "title_zh": "DMON：一种简单却有效的论点结构学习方法",
      "authors": [
        "Wei Sun",
        "Mingxiao Li",
        "Jingyuan Sun",
        "Jesse Davis",
        "Marie-Francine Moens"
      ],
      "abstract": "Argument structure learning~(ASL) entails predicting relations between\narguments. Because it can structure a document to facilitate its understanding,\nit has been widely applied in many fields~(medical, commercial, and scientific\ndomains). Despite its broad utilization, ASL remains a challenging task because\nit involves examining the complex relationships between the sentences in a\npotentially unstructured discourse. To resolve this problem, we have developed\na simple yet effective approach called Dual-tower Multi-scale cOnvolution\nneural Network~(DMON) for the ASL task. Specifically, we organize arguments\ninto a relationship matrix that together with the argument embeddings forms a\nrelationship tensor and design a mechanism to capture relations with contextual\narguments. Experimental results on three different-domain argument mining\ndatasets demonstrate that our framework outperforms state-of-the-art models.\nThe code is available at https://github.com/VRCMF/DMON.git .",
      "tldr_zh": "本论文针对Argument Structure Learning (ASL)任务，提出了一种简单有效的框架Dual-tower Multi-scale cOnvolution neural Network (DMON)，旨在预测论点之间的复杂关系，以结构化文档并提升其理解。该方法将论点组织成关系矩阵，与论点嵌入形成关系张量，并设计机制捕获上下文论点间的关联。实验在三个不同领域的论点挖掘数据集上表明，DMON 超过了现有最先进模型，证明了其在医疗、商业和科学领域中的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01216v1",
      "published_date": "2024-05-02 11:56:16 UTC",
      "updated_date": "2024-05-02 11:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:27:38.840689"
    },
    {
      "arxiv_id": "2405.01204v1",
      "title": "Towards Cross-Scale Attention and Surface Supervision for Fractured Bone Segmentation in CT",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Zhou",
        "Xiahao Zou",
        "Yi Wang"
      ],
      "abstract": "Bone segmentation is an essential step for the preoperative planning of\nfracture trauma surgery. The automated segmentation of fractured bone from\ncomputed tomography (CT) scans remains challenging, due to the large\ndifferences of fractures in position and morphology, and also the inherent\nanatomical characteristics of different bone structures. To alleviate these\nissues, we propose a cross-scale attention mechanism as well as a surface\nsupervision strategy for fractured bone segmentation in CT. Specifically, a\ncross-scale attention mechanism is introduced to effectively aggregate the\nfeatures among different scales to provide more powerful fracture\nrepresentation. Moreover, a surface supervision strategy is employed, which\nexplicitly constrains the network to pay more attention to the bone boundary.\nThe efficacy of the proposed method is evaluated on a public dataset containing\nCT scans with hip fractures. The evaluation metrics are Dice similarity\ncoefficient (DSC), average symmetric surface distance (ASSD), and Hausdorff\ndistance (95HD). The proposed method achieves an average DSC of 93.36%, ASSD of\n0.85mm, 95HD of 7.51mm. Our method offers an effective fracture segmentation\napproach for the pelvic CT examinations, and has the potential to be used for\nimproving the segmentation performance of other types of fractures.",
      "tldr_zh": "这篇论文针对CT扫描中骨折骨骼的自动分割挑战，提出了一种跨尺度注意力机制和表面监督策略，以应对骨折位置、形态差异以及骨骼结构特性。跨尺度注意力机制用于聚合不同尺度的特征，提供更强的骨折表示，而表面监督策略则通过约束网络关注骨边界来提升分割精度。在包含髋部骨折的公共数据集上，该方法实现了93.36%的DSC、0.85mm的ASSD和7.51mm的95HD，显著提高了性能。该方法为骨盆CT检查提供有效的骨折分割方案，并有望扩展到其他类型骨折的处理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01204v1",
      "published_date": "2024-05-02 11:46:12 UTC",
      "updated_date": "2024-05-02 11:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:27:52.074862"
    },
    {
      "arxiv_id": "2405.01198v1",
      "title": "Towards Interpretable Reinforcement Learning with Constrained Normalizing Flow Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Finn Rietz",
        "Erik Schaffernicht",
        "Stefan Heinrich",
        "Johannes A. Stork"
      ],
      "abstract": "Reinforcement learning policies are typically represented by black-box neural\nnetworks, which are non-interpretable and not well-suited for safety-critical\ndomains. To address both of these issues, we propose constrained normalizing\nflow policies as interpretable and safe-by-construction policy models. We\nachieve safety for reinforcement learning problems with instantaneous safety\nconstraints, for which we can exploit domain knowledge by analytically\nconstructing a normalizing flow that ensures constraint satisfaction. The\nnormalizing flow corresponds to an interpretable sequence of transformations on\naction samples, each ensuring alignment with respect to a particular\nconstraint. Our experiments reveal benefits beyond interpretability in an\neasier learning objective and maintained constraint satisfaction throughout the\nentire learning process. Our approach leverages constraints over reward\nengineering while offering enhanced interpretability, safety, and direct means\nof providing domain knowledge to the agent without relying on complex reward\nfunctions.",
      "tldr_zh": "本论文针对强化学习(Reinforcement Learning)策略的黑盒神经网络问题，提出了一种受限的 Normalizing Flow 策略，以实现可解释性和安全内置的设计。该方法通过分析构建 Normalizing Flow，对动作样本进行可解释的序列变换，确保即时安全约束的满足，并在整个学习过程中维持约束对齐。实验结果显示，这种策略简化了学习目标，提供比奖励工程更直接的领域知识注入方式，同时提升了整体安全性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01198v1",
      "published_date": "2024-05-02 11:40:15 UTC",
      "updated_date": "2024-05-02 11:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:28:03.810701"
    },
    {
      "arxiv_id": "2405.01189v1",
      "title": "Gradient-Congruity Guided Federated Sparse Training",
      "title_zh": "梯度一致性引导的联邦稀疏训练",
      "authors": [
        "Chris Xing Tian",
        "Yibing Liu",
        "Haoliang Li",
        "Ray C. C. Cheung",
        "Shiqi Wang"
      ],
      "abstract": "Edge computing allows artificial intelligence and machine learning models to\nbe deployed on edge devices, where they can learn from local data and\ncollaborate to form a global model. Federated learning (FL) is a distributed\nmachine learning technique that facilitates this process while preserving data\nprivacy. However, FL also faces challenges such as high computational and\ncommunication costs regarding resource-constrained devices, and poor\ngeneralization performance due to the heterogeneity of data across edge clients\nand the presence of out-of-distribution data. In this paper, we propose the\nGradient-Congruity Guided Federated Sparse Training (FedSGC), a novel method\nthat integrates dynamic sparse training and gradient congruity inspection into\nfederated learning framework to address these issues. Our method leverages the\nidea that the neurons, in which the associated gradients with conflicting\ndirections with respect to the global model contain irrelevant or less\ngeneralized information for other clients, and could be pruned during the\nsparse training process. Conversely, the neurons where the associated gradients\nwith consistent directions could be grown in a higher priority. In this way,\nFedSGC can greatly reduce the local computation and communication overheads\nwhile, at the same time, enhancing the generalization abilities of FL. We\nevaluate our method on challenging non-i.i.d settings and show that it achieves\ncompetitive accuracy with state-of-the-art FL methods across various scenarios\nwhile minimizing computation and communication costs.",
      "tldr_zh": "本研究提出了一种名为Gradient-Congruity Guided Federated Sparse Training (FedSGC)的创新方法，旨在解决Federated Learning (FL)中高计算通信成本以及数据异质性和分布外数据导致的泛化性能问题。FedSGC将动态稀疏训练与梯度一致性检查相结合，通过修剪梯度方向与全局模型冲突的神经元（这些神经元可能包含不相关或泛化差的信息），并优先增长梯度方向一致的神经元，从而显著降低本地计算和通信开销，同时提升模型的泛化能力。在非i.i.d设置下的实验中，FedSGC与最先进FL方法相比，实现了竞争性的准确率，同时最小化了资源消耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01189v1",
      "published_date": "2024-05-02 11:29:48 UTC",
      "updated_date": "2024-05-02 11:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:28:15.396815"
    },
    {
      "arxiv_id": "2405.01186v1",
      "title": "Potential Energy based Mixture Model for Noisy Label Learning",
      "title_zh": "基于势能的混合模型用于噪声标签学习",
      "authors": [
        "Zijia Wang",
        "Wenbin Yang",
        "Zhisong Liu",
        "Zhen Jia"
      ],
      "abstract": "Training deep neural networks (DNNs) from noisy labels is an important and\nchallenging task. However, most existing approaches focus on the corrupted\nlabels and ignore the importance of inherent data structure. To bridge the gap\nbetween noisy labels and data, inspired by the concept of potential energy in\nphysics, we propose a novel Potential Energy based Mixture Model (PEMM) for\nnoise-labels learning. We innovate a distance-based classifier with the\npotential energy regularization on its class centers. Embedding our proposed\nclassifier with existing deep learning backbones, we can have robust networks\nwith better feature representations. They can preserve intrinsic structures\nfrom the data, resulting in a superior noisy tolerance. We conducted extensive\nexperiments to analyze the efficiency of our proposed model on several\nreal-world datasets. Quantitative results show that it can achieve\nstate-of-the-art performance.",
      "tldr_zh": "这篇论文针对深度神经网络(DNNs)训练中噪声标签的问题，提出了一种新型的Potential Energy based Mixture Model (PEMM)，它通过引入基于距离的分类器并添加潜在能量正则化来优化类中心，从而更好地保留数据固有结构。PEMM 与现有深度学习骨干网络结合，能提升特征表示并提高对噪声标签的耐受性。实验在多个真实数据集上验证了该模型的有效性，实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "36th Conference on Neural Information Processing Systems (NeurIPS\n  2022)",
      "pdf_url": "http://arxiv.org/pdf/2405.01186v1",
      "published_date": "2024-05-02 11:19:57 UTC",
      "updated_date": "2024-05-02 11:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:28:27.308923"
    },
    {
      "arxiv_id": "2405.01175v1",
      "title": "Uncertainty-aware self-training with expectation maximization basis transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Zijia Wang",
        "Wenbin Yang",
        "Zhisong Liu",
        "Zhen Jia"
      ],
      "abstract": "Self-training is a powerful approach to deep learning. The key process is to\nfind a pseudo-label for modeling. However, previous self-training algorithms\nsuffer from the over-confidence issue brought by the hard labels, even some\nconfidence-related regularizers cannot comprehensively catch the uncertainty.\nTherefore, we propose a new self-training framework to combine uncertainty\ninformation of both model and dataset. Specifically, we propose to use\nExpectation-Maximization (EM) to smooth the labels and comprehensively estimate\nthe uncertainty information. We further design a basis extraction network to\nestimate the initial basis from the dataset. The obtained basis with\nuncertainty can be filtered based on uncertainty information. It can then be\ntransformed into the real hard label to iteratively update the model and basis\nin the retraining process. Experiments on image classification and semantic\nsegmentation show the advantages of our methods among confidence-aware\nself-training algorithms with 1-3 percentage improvement on different datasets.",
      "tldr_zh": "本论文提出了一种考虑不确定性的自训练框架，以解决传统自训练算法因使用硬标签而导致的过自信问题。框架通过 Expectation-Maximization (EM) 算法平滑标签并全面估计模型和数据集的不确定性，同时设计了一个 basis extraction network 来从数据集提取初始基础，并基于不确定性信息进行过滤和转换为硬标签，从而迭代更新模型。实验结果显示，该方法在图像分类和语义分割任务上，比其他置信度aware的自训练算法提高了1-3%的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01175v1",
      "published_date": "2024-05-02 11:01:31 UTC",
      "updated_date": "2024-05-02 11:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:28:39.715097"
    },
    {
      "arxiv_id": "2405.01158v1",
      "title": "Interpretable Data-driven Anomaly Detection in Industrial Processes with ExIFFI",
      "title_zh": "基于 ExIFFI 的工业过程数据驱动可解释异常检测",
      "authors": [
        "Davide Frizzo",
        "Francesco Borsatti",
        "Alessio Arcudi",
        "Antonio De Moliner",
        "Roberto Oboe",
        "Gian Antonio Susto"
      ],
      "abstract": "Anomaly detection (AD) is a crucial process often required in industrial\nsettings. Anomalies can signal underlying issues within a system, prompting\nfurther investigation. Industrial processes aim to streamline operations as\nmuch as possible, encompassing the production of the final product, making AD\nan essential mean to reach this goal.Conventional anomaly detection\nmethodologies typically classify observations as either normal or anomalous\nwithout providing insight into the reasons behind these\nclassifications.Consequently, in light of the emergence of Industry 5.0, a more\ndesirable approach involves providing interpretable outcomes, enabling users to\nunderstand the rationale behind the results.This paper presents the first\nindustrial application of ExIFFI, a recently developed approach focused on the\nproduction of fast and efficient explanations for the Extended Isolation Forest\n(EIF) Anomaly detection method. ExIFFI is tested on two publicly available\nindustrial datasets demonstrating superior effectiveness in explanations and\ncomputational efficiency with the respect to other state-of-the-art explainable\nAD models.",
      "tldr_zh": "工业过程中的异常检测（Anomaly Detection）至关重要，因为它能识别潜在问题并优化生产，但传统方法仅分类正常或异常，而缺乏解释原因。在Industry 5.0背景下，本文首次将ExIFFI应用于工业场景，该方法为Extended Isolation Forest (EIF)异常检测提供快速且高效的解释。实验结果显示，ExIFFI在两个公开工业数据集上，比其他最先进的可解释AD模型表现出更高的解释有效性和计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, submitted to IEEE RTSI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01158v1",
      "published_date": "2024-05-02 10:23:17 UTC",
      "updated_date": "2024-05-02 10:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:28:50.658892"
    },
    {
      "arxiv_id": "2405.01156v1",
      "title": "Self-Supervised Learning for Interventional Image Analytics: Towards Robust Device Trackers",
      "title_zh": "自监督学习在介入性图像分析中的应用：朝向鲁棒设备追踪器",
      "authors": [
        "Saahil Islam",
        "Venkatesh N. Murthy",
        "Dominik Neumann",
        "Badhan Kumar Das",
        "Puneet Sharma",
        "Andreas Maier",
        "Dorin Comaniciu",
        "Florin C. Ghesu"
      ],
      "abstract": "An accurate detection and tracking of devices such as guiding catheters in\nlive X-ray image acquisitions is an essential prerequisite for endovascular\ncardiac interventions. This information is leveraged for procedural guidance,\ne.g., directing stent placements. To ensure procedural safety and efficacy,\nthere is a need for high robustness no failures during tracking. To achieve\nthat, one needs to efficiently tackle challenges, such as: device obscuration\nby contrast agent or other external devices or wires, changes in field-of-view\nor acquisition angle, as well as the continuous movement due to cardiac and\nrespiratory motion. To overcome the aforementioned challenges, we propose a\nnovel approach to learn spatio-temporal features from a very large data cohort\nof over 16 million interventional X-ray frames using self-supervision for image\nsequence data. Our approach is based on a masked image modeling technique that\nleverages frame interpolation based reconstruction to learn fine inter-frame\ntemporal correspondences. The features encoded in the resulting model are\nfine-tuned downstream. Our approach achieves state-of-the-art performance and\nin particular robustness compared to ultra optimized reference solutions (that\nuse multi-stage feature fusion, multi-task and flow regularization). The\nexperiments show that our method achieves 66.31% reduction in maximum tracking\nerror against reference solutions (23.20% when flow regularization is used);\nachieving a success score of 97.95% at a 3x faster inference speed of 42\nframes-per-second (on GPU). The results encourage the use of our approach in\nvarious other tasks within interventional image analytics that require\neffective understanding of spatio-temporal semantics.",
      "tldr_zh": "该论文针对心血管内介入手术中的设备（如引导导管）在X-ray图像中的检测和跟踪问题，提出了一种基于自监督学习(Self-Supervised Learning)的创新方法，以提升鲁棒性。该方法利用超过1600万帧介入X-ray数据，通过masked image modeling技术和帧插值重建，学习精细的时空特征，并将其微调用于下游任务。实验结果显示，与基准解决方案相比，该方法将最大跟踪错误减少66.31%（使用流正则化时减少23.20%），成功率达97.95%，并以42帧/秒的速度实现3倍加速。该框架展示了在介入图像分析中理解时空语义的有效性，有望扩展到其他相关任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01156v1",
      "published_date": "2024-05-02 10:18:22 UTC",
      "updated_date": "2024-05-02 10:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:29:04.090704"
    },
    {
      "arxiv_id": "2405.01148v1",
      "title": "Qualia and the Formal Structure of Meaning",
      "title_zh": "Qualia 与意义的正式结构",
      "authors": [
        "Xerxes D. Arsiwalla"
      ],
      "abstract": "This work explores the hypothesis that subjectively attributed meaning\nconstitutes the phenomenal content of conscious experience. That is, phenomenal\ncontent is semantic. This form of subjective meaning manifests as an intrinsic\nand non-representational character of qualia. Empirically, subjective meaning\nis ubiquitous in conscious experiences. We point to phenomenological studies\nthat lend evidence to support this. Furthermore, this notion of meaning closely\nrelates to what Frege refers to as \"sense\", in metaphysics and philosophy of\nlanguage. It also aligns with Peirce's \"interpretant\", in semiotics. We discuss\nhow Frege's sense can also be extended to the raw feels of consciousness. Sense\nand reference both play a role in phenomenal experience. Moreover, within the\ncontext of the mind-matter relation, we provide a formalization of subjective\nmeaning associated to one's mental representations. Identifying the precise\nmaps between the physical and mental domains, we argue that syntactic and\nsemantic structures transcend language, and are realized within each of these\ndomains. Formally, meaning is a relational attribute, realized via a map that\ninterprets syntactic structures of a formal system within an appropriate\nsemantic space. The image of this map within the mental domain is what is\nrelevant for experience, and thus comprises the phenomenal content of qualia.\nWe conclude with possible implications this may have for experience-based\ntheories of consciousness.",
      "tldr_zh": "本文探讨了主观意义（subjective meaning）构成了意识经验的现象内容（phenomenal content），即现象内容是语义的（semantic），并表现为qualia的内在、非表征性特征。作者引用现象学研究，并将这一概念与Frege的“sense”和Peirce的“interpretant”关联起来，扩展sense到意识的原始感受中。论文通过形式化主观意义，论证了句法和语义结构超越语言，在物理和心理领域实现，并提出这可能为基于经验的意识理论（experience-based theories of consciousness）带来重要启示。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "math.CT",
        "physics.hist-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.01148v1",
      "published_date": "2024-05-02 10:05:36 UTC",
      "updated_date": "2024-05-02 10:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:29:17.115076"
    },
    {
      "arxiv_id": "2405.01134v1",
      "title": "Leveraging Procedural Generation for Learning Autonomous Peg-in-Hole Assembly in Space",
      "title_zh": "利用过程生成学习太空中的自治插销孔装配",
      "authors": [
        "Andrej Orsula",
        "Matthieu Geist",
        "Miguel Olivares-Mendez",
        "Carol Martinez"
      ],
      "abstract": "The ability to autonomously assemble structures is crucial for the\ndevelopment of future space infrastructure. However, the unpredictable\nconditions of space pose significant challenges for robotic systems,\nnecessitating the development of advanced learning techniques to enable\nautonomous assembly. In this study, we present a novel approach for learning\nautonomous peg-in-hole assembly in the context of space robotics. Our focus is\non enhancing the generalization and adaptability of autonomous systems through\ndeep reinforcement learning. By integrating procedural generation and domain\nrandomization, we train agents in a highly parallelized simulation environment\nacross a spectrum of diverse scenarios with the aim of acquiring a robust\npolicy. The proposed approach is evaluated using three distinct reinforcement\nlearning algorithms to investigate the trade-offs among various paradigms. We\ndemonstrate the adaptability of our agents to novel scenarios and assembly\nsequences while emphasizing the potential of leveraging advanced simulation\ntechniques for robot learning in space. Our findings set the stage for future\nadvancements in intelligent robotic systems capable of supporting ambitious\nspace missions and infrastructure development beyond Earth.",
      "tldr_zh": "这篇论文提出了一种利用程序生成（procedural generation）和领域随机化（domain randomization）的深度强化学习（deep reinforcement learning）方法，以提升太空机器人自主插销装配（peg-in-hole assembly）的泛化和适应性。研究者通过高度并行化的模拟环境训练代理，涵盖多样场景，并使用三种强化学习算法评估其性能，揭示了不同范式的权衡。结果显示，训练后的代理能够适应新场景和装配序列，为太空任务的智能机器人系统和基础设施发展奠定基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication at the 2024 International Conference on\n  Space Robotics (iSpaRo) | The source code is available at\n  https://github.com/AndrejOrsula/drl_omni_peg",
      "pdf_url": "http://arxiv.org/pdf/2405.01134v1",
      "published_date": "2024-05-02 09:50:01 UTC",
      "updated_date": "2024-05-02 09:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:29:27.562391"
    },
    {
      "arxiv_id": "2405.01121v3",
      "title": "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts",
      "title_zh": "翻译失败",
      "authors": [
        "Lotem Golany",
        "Filippo Galgani",
        "Maya Mamo",
        "Nimrod Parasol",
        "Omer Vandsburger",
        "Nadav Bar",
        "Ido Dagan"
      ],
      "abstract": "Automating data generation with Large Language Models (LLMs) has become\nincreasingly popular. In this work, we investigate the feasibility and\neffectiveness of LLM-based data generation in the challenging setting of\nsource-grounded information-seeking dialogs, with response attribution, over\nlong documents. Our source texts consist of long and noisy meeting transcripts,\nadding to the task complexity. Since automating attribution remains difficult,\nwe propose a semi-automatic approach: dialog queries and responses are\ngenerated with LLMs, followed by human verification and identification of\nattribution spans. Using this approach, we created MISeD -- Meeting Information\nSeeking Dialogs dataset -- a dataset of information-seeking dialogs focused on\nmeeting transcripts. Models finetuned with MISeD demonstrate superior\nperformance compared to off-the-shelf models, even those of larger size.\nFinetuning on MISeD gives comparable response generation quality to finetuning\non fully manual data, while improving attribution quality and reducing time and\neffort.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 高效生成源地化信息寻求对话数据，特别针对长而嘈杂的会议记录作为用例。\n他们提出了一种半自动方法：LLMs 负责生成对话查询和响应，随后由人类验证并标识归属范围，从而创建了 MISeD 数据集——一个专注于会议记录的信息寻求对话数据集。\n实验结果显示，在 MISeD 上微调的模型比现成模型（甚至更大规模的模型）性能更优，并在响应生成质量与完全手动数据相当的情况下，显著改善了归属质量并减少了时间和努力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01121v3",
      "published_date": "2024-05-02 09:35:06 UTC",
      "updated_date": "2024-10-15 08:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:29:40.350776"
    },
    {
      "arxiv_id": "2405.01113v1",
      "title": "Domain-Transferred Synthetic Data Generation for Improving Monocular Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Seungyeop Lee",
        "Knut Peterson",
        "Solmaz Arezoomandan",
        "Bill Cai",
        "Peihan Li",
        "Lifeng Zhou",
        "David Han"
      ],
      "abstract": "A major obstacle to the development of effective monocular depth estimation\nalgorithms is the difficulty in obtaining high-quality depth data that\ncorresponds to collected RGB images. Collecting this data is time-consuming and\ncostly, and even data collected by modern sensors has limited range or\nresolution, and is subject to inconsistencies and noise. To combat this, we\npropose a method of data generation in simulation using 3D synthetic\nenvironments and CycleGAN domain transfer. We compare this method of data\ngeneration to the popular NYUDepth V2 dataset by training a depth estimation\nmodel based on the DenseDepth structure using different training sets of real\nand simulated data. We evaluate the performance of the models on newly\ncollected images and LiDAR depth data from a Husky robot to verify the\ngeneralizability of the approach and show that GAN-transformed data can serve\nas an effective alternative to real-world data, particularly in depth\nestimation.",
      "tldr_zh": "本文提出了一种基于 3D 合成环境和 CycleGAN 域转移的模拟数据生成方法，以解决单目深度估计中获取高质量深度数据的挑战，该方法能有效减少数据收集的成本和噪声问题。研究者将此方法与 NYUDepth V2 数据集比较，通过训练基于 DenseDepth 结构的深度估计模型，并使用 Husky 机器人的新图像和 LiDAR 深度数据进行评估。结果显示，使用 GAN 转换的模拟数据显著提高了模型的泛化性能和准确性，作为真实数据的有效替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01113v1",
      "published_date": "2024-05-02 09:21:10 UTC",
      "updated_date": "2024-05-02 09:21:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:29:53.156362"
    },
    {
      "arxiv_id": "2405.01108v1",
      "title": "Federated Learning with Heterogeneous Data Handling for Robust Vehicular Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Khalil",
        "Tizian Dege",
        "Pegah Golchin",
        "Rostyslav Olshevskyi",
        "Antonio Fernandez Anta",
        "Tobias Meuser"
      ],
      "abstract": "In the pursuit of refining precise perception models for fully autonomous\ndriving, continual online model training becomes essential. Federated Learning\n(FL) within vehicular networks offers an efficient mechanism for model training\nwhile preserving raw sensory data integrity. Yet, FL struggles with\nnon-identically distributed data (e.g., quantity skew), leading to suboptimal\nconvergence rates during model training. In previous work, we introduced FedLA,\nan innovative Label-Aware aggregation method addressing data heterogeneity in\nFL for generic scenarios.\n  In this paper, we introduce FedProx+LA, a novel FL method building upon the\nstate-of-the-art FedProx and FedLA to tackle data heterogeneity, which is\nspecifically tailored for vehicular networks. We evaluate the efficacy of\nFedProx+LA in continuous online object detection model training. Through a\ncomparative analysis against conventional and state-of-the-art methods, our\nfindings reveal the superior convergence rate of FedProx+LA. Notably, if the\nlabel distribution is very heterogeneous, our FedProx+LA approach shows\nsubstantial improvements in detection performance compared to baseline methods,\nalso outperforming our previous FedLA approach. Moreover, both FedLA and\nFedProx+LA increase convergence speed by 30% compared to baseline methods.",
      "tldr_zh": "本论文提出 FedProx+LA，一种新型联邦学习（FL）方法，基于 FedProx 和 FedLA，专门针对车辆网络中数据异质性（如数量偏差）问题，以提升物体检测模型的鲁棒性和在线训练效率。该方法通过标签感知聚合机制优化模型收敛，适用于自动驾驶场景的连续在线训练。实验结果显示，FedProx+LA 在高度异质标签分布下显著改善检测性能，比基线方法提高30%的收敛速度，并优于之前的 FedLA 方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01108v1",
      "published_date": "2024-05-02 09:14:59 UTC",
      "updated_date": "2024-05-02 09:14:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:30:05.496578"
    },
    {
      "arxiv_id": "2405.01102v2",
      "title": "Less is More: on the Over-Globalizing Problem in Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Xing",
        "Xiao Wang",
        "Yibo Li",
        "Hai Huang",
        "Chuan Shi"
      ],
      "abstract": "Graph Transformer, due to its global attention mechanism, has emerged as a\nnew tool in dealing with graph-structured data. It is well recognized that the\nglobal attention mechanism considers a wider receptive field in a fully\nconnected graph, leading many to believe that useful information can be\nextracted from all the nodes. In this paper, we challenge this belief: does the\nglobalizing property always benefit Graph Transformers? We reveal the\nover-globalizing problem in Graph Transformer by presenting both empirical\nevidence and theoretical analysis, i.e., the current attention mechanism overly\nfocuses on those distant nodes, while the near nodes, which actually contain\nmost of the useful information, are relatively weakened. Then we propose a\nnovel Bi-Level Global Graph Transformer with Collaborative Training\n(CoBFormer), including the inter-cluster and intra-cluster Transformers, to\nprevent the over-globalizing problem while keeping the ability to extract\nvaluable information from distant nodes. Moreover, the collaborative training\nis proposed to improve the model's generalization ability with a theoretical\nguarantee. Extensive experiments on various graphs well validate the\neffectiveness of our proposed CoBFormer.",
      "tldr_zh": "本研究质疑了 Graph Transformer 的全局注意力机制是否总是有益，揭示了“over-globalizing problem”：模型过度关注远距离节点而忽略近距离节点，后者往往包含大部分有用信息，并通过实证和理论分析支持这一观点。为解决此问题，作者提出了一种新型 Bi-Level Global Graph Transformer with Collaborative Training（CoBFormer），包括 inter-cluster 和 intra-cluster Transformers，以平衡局部和全局信息提取，同时引入 collaborative training 来提升模型的泛化能力并提供理论保证。在各种图数据集上的广泛实验验证了 CoBFormer 的有效性，展示了其在处理图结构数据时的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024 (Camera-Ready)",
      "pdf_url": "http://arxiv.org/pdf/2405.01102v2",
      "published_date": "2024-05-02 09:12:22 UTC",
      "updated_date": "2024-05-24 08:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:30:16.132888"
    },
    {
      "arxiv_id": "2405.01073v1",
      "title": "Poisoning Attacks on Federated Learning for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Sonakshi Garg",
        "Hugo Jönsson",
        "Gustav Kalander",
        "Axel Nilsson",
        "Bhhaanu Pirange",
        "Viktor Valadi",
        "Johan Östman"
      ],
      "abstract": "Federated Learning (FL) is a decentralized learning paradigm, enabling\nparties to collaboratively train models while keeping their data confidential.\nWithin autonomous driving, it brings the potential of reducing data storage\ncosts, reducing bandwidth requirements, and to accelerate the learning. FL is,\nhowever, susceptible to poisoning attacks. In this paper, we introduce two\nnovel poisoning attacks on FL tailored to regression tasks within autonomous\ndriving: FLStealth and Off-Track Attack (OTA). FLStealth, an untargeted attack,\naims at providing model updates that deteriorate the global model performance\nwhile appearing benign. OTA, on the other hand, is a targeted attack with the\nobjective to change the global model's behavior when exposed to a certain\ntrigger. We demonstrate the effectiveness of our attacks by conducting\ncomprehensive experiments pertaining to the task of vehicle trajectory\nprediction. In particular, we show that, among five different untargeted\nattacks, FLStealth is the most successful at bypassing the considered defenses\nemployed by the server. For OTA, we demonstrate the inability of common defense\nstrategies to mitigate the attack, highlighting the critical need for new\ndefensive mechanisms against targeted attacks within FL for autonomous driving.",
      "tldr_zh": "该研究探讨了Federated Learning (FL) 在自动驾驶领域的应用及其对 poisoning attacks 的易受性，FL 允许各方在保持数据保密的情况下协作训练模型，从而减少存储和带宽需求。论文引入两种新型攻击：FLStealth（一种无针对性攻击，旨在恶化全局模型性能却显得无害）和 Off-Track Attack (OTA)（一种针对性攻击，改变模型在特定触发器下的行为）。通过车辆轨迹预测实验，研究者证明 FLStealth 成功绕过现有防御，而 OTA 暴露了常见策略的无效性，强调了开发针对自动驾驶 FL 的新防御机制的迫切需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to SCAI2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01073v1",
      "published_date": "2024-05-02 08:06:10 UTC",
      "updated_date": "2024-05-02 08:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:30:28.289255"
    },
    {
      "arxiv_id": "2405.02342v1",
      "title": "The Birkhoff completion of finite lattices",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Abdulla",
        "Johannes Hirth",
        "Gerd Stumme"
      ],
      "abstract": "We introduce the Birkhoff completion as the smallest distributive lattice in\nwhich a given finite lattice can be embedded as semi-lattice. We discuss its\nrelationship to implicational theories, in particular to R. Wille's\nsimply-implicational theories. By an example, we show how the Birkhoff\ncompletion can be used as a tool for ordinal data science.",
      "tldr_zh": "本论文引入了Birkhoff completion 概念，即将给定有限格（finite lattices）嵌入为半格（semi-lattice）的最小分配格（distributive lattice）。作者探讨了其与蕴涵理论（implicational theories）的关系，特别是R. Wille的简单蕴涵理论（simply-implicational theories）。通过一个例子，展示了Birkhoff completion 在序数数据科学（ordinal data science）中的潜在工具作用。",
      "categories": [
        "cs.DM",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.DM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02342v1",
      "published_date": "2024-05-02 08:01:43 UTC",
      "updated_date": "2024-05-02 08:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:30:39.018254"
    },
    {
      "arxiv_id": "2405.01067v2",
      "title": "AB-Training: A Communication-Efficient Approach for Distributed Low-Rank Learning",
      "title_zh": "AB-Training：一种通信高效的方法，用于分布式低秩学习",
      "authors": [
        "Daniel Coquelin",
        "Katherina Flügel",
        "Marie Weiel",
        "Nicholas Kiefer",
        "Muhammed Öz",
        "Charlotte Debus",
        "Achim Streit",
        "Markus Götz"
      ],
      "abstract": "Communication bottlenecks severely hinder the scalability of distributed\nneural network training, particularly in high-performance computing (HPC)\nenvironments. We introduce AB-training, a novel data-parallel method that\nleverages low-rank representations and independent training groups to\nsignificantly reduce communication overhead. Our experiments demonstrate an\naverage reduction in network traffic of approximately 70.31\\% across various\nscaling scenarios, increasing the training potential of\ncommunication-constrained systems and accelerating convergence at scale.\nAB-training also exhibits a pronounced regularization effect at smaller scales,\nleading to improved generalization while maintaining or even reducing training\ntime. We achieve a remarkable 44.14 : 1 compression ratio on VGG16 trained on\nCIFAR-10 with minimal accuracy loss, and outperform traditional data parallel\ntraining by 1.55\\% on ResNet-50 trained on ImageNet-2012. While AB-training is\npromising, our findings also reveal that large batch effects persist even in\nlow-rank regimes, underscoring the need for further research into optimized\nupdate mechanisms for massively distributed training.",
      "tldr_zh": "本论文提出AB-Training，一种通信高效的分布式低秩学习方法，通过利用low-rank representations和独立训练组，显著减少分布式神经网络训练中的通信开销。实验结果显示，该方法在各种规模场景下平均减少网络流量约70.31%，并加速收敛，同时在较小规模下表现出正则化效果，提高了泛化能力；在VGG16上CIFAR-10数据集实现44.14:1的压缩比，几乎无准确率损失，并在ResNet-50上ImageNet-2012数据集比传统data-parallel训练提高1.55%。尽管AB-Training前景广阔，但论文指出大型批次效果在低秩环境中依然存在，需要进一步优化更新机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01067v2",
      "published_date": "2024-05-02 07:49:28 UTC",
      "updated_date": "2024-06-30 08:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:30:53.271184"
    },
    {
      "arxiv_id": "2405.01066v3",
      "title": "HandS3C: 3D Hand Mesh Reconstruction with State Space Spatial Channel Attention from RGB images",
      "title_zh": "翻译失败",
      "authors": [
        "Zixun Jiao",
        "Xihan Wang",
        "Zhaoqiang Xia",
        "Lianhe Shao",
        "Quanli Gao"
      ],
      "abstract": "Reconstructing the hand mesh from one single RGB image is a challenging task\nbecause hands are often occluded by other objects. Most previous works attempt\nto explore more additional information and adopt attention mechanisms for\nimproving 3D reconstruction performance, while it would increase computational\ncomplexity simultaneously. To achieve a performance-reserving architecture with\nhigh computational efficiency, in this work, we propose a simple but effective\n3D hand mesh reconstruction network (i.e., HandS3C), which is the first time to\nincorporate state space model into the task of hand mesh reconstruction. In the\nnetwork, we design a novel state-space spatial-channel attention module that\nextends the effective receptive field, extracts hand features in the spatial\ndimension, and enhances regional features of hands in the channel dimension.\nThis helps to reconstruct a complete and detailed hand mesh. Extensive\nexperiments conducted on well-known datasets facing heavy occlusions (such as\nFREIHAND, DEXYCB, and HO3D) demonstrate that our proposed HandS3C achieves\nstate-of-the-art performance while maintaining a minimal parameters.",
      "tldr_zh": "本文提出 HandS3C，一种高效的 3D Hand Mesh Reconstruction 网络，从单一 RGB images 中重建手部网格，以应对手部遮挡带来的挑战。该网络首次将 State Space Model 融入任务中，并设计了新型 State-space Spatial-channel Attention Module，用于扩展有效感受野、在空间维度提取手部特征，并在通道维度增强区域特征，从而实现更完整详细的网格重建。在 FREIHAND、DEXYCB 和 HO3D 等重遮挡数据集上的实验显示，HandS3C 达到了 State-of-the-art 性能，同时保持最小参数，显著提高了计算效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.01066v3",
      "published_date": "2024-05-02 07:47:49 UTC",
      "updated_date": "2024-05-14 11:47:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:31:04.304166"
    },
    {
      "arxiv_id": "2407.03110v1",
      "title": "A Toolchain for Comprehensive Audio/Video Analysis Using Deep Learning Based Multimodal Approach (A use case of riot or violent context detection)",
      "title_zh": "基于深度学习的多模态",
      "authors": [
        "Lam Pham",
        "Phat Lam",
        "Tin Nguyen",
        "Hieu Tang",
        "Alexander Schindler"
      ],
      "abstract": "In this paper, we present a toolchain for a comprehensive audio/video\nanalysis by leveraging deep learning based multimodal approach. To this end,\ndifferent specific tasks of Speech to Text (S2T), Acoustic Scene Classification\n(ASC), Acoustic Event Detection (AED), Visual Object Detection (VOD), Image\nCaptioning (IC), and Video Captioning (VC) are conducted and integrated into\nthe toolchain. By combining individual tasks and analyzing both audio \\& visual\ndata extracted from input video, the toolchain offers various audio/video-based\napplications: Two general applications of audio/video clustering, comprehensive\naudio/video summary and a specific application of riot or violent context\ndetection. Furthermore, the toolchain presents a flexible and adaptable\narchitecture that is effective to integrate new models for further\naudio/video-based applications.",
      "tldr_zh": "本论文提出了一种基于深度学习的的多模态工具链，用于全面音频/视频分析，整合了 S2T（Speech to Text）、ASC（Acoustic Scene Classification）、AED（Acoustic Event Detection）、VOD（Visual Object Detection）、IC（Image Captioning）和 VC（Video Captioning）等任务。工具链通过结合音频和视觉数据，实现音频/视频聚类、综合摘要等通用应用，以及针对暴乱或暴力上下文的特定检测应用。实验结果显示，该架构灵活且可扩展，便于集成新模型以支持更多音频/视频应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03110v1",
      "published_date": "2024-05-02 07:34:31 UTC",
      "updated_date": "2024-05-02 07:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:31:16.078991"
    },
    {
      "arxiv_id": "2405.01060v1",
      "title": "A text-based, generative deep learning model for soil reflectance spectrum simulation in the VIS-NIR (400-2499 nm) bands",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Lei",
        "Brian N. Bailey"
      ],
      "abstract": "Simulating soil reflectance spectra is invaluable for soil-plant radiative\nmodeling and training machine learning models, yet it is difficult as the\nintricate relationships between soil structure and its constituents. To address\nthis, a fully data-driven soil optics generative model (SOGM) for simulation of\nsoil reflectance spectra based on soil property inputs was developed. The model\nis trained on an extensive dataset comprising nearly 180,000 soil\nspectra-property pairs from 17 datasets. It generates soil reflectance spectra\nfrom text-based inputs describing soil properties and their values rather than\nonly numerical values and labels in binary vector format. The generative model\ncan simulate output spectra based on an incomplete set of input properties.\nSOGM is based on the denoising diffusion probabilistic model (DDPM). Two\nadditional sub-models were also built to complement the SOGM: a spectral\npadding model that can fill in the gaps for spectra shorter than the full\nvisible-near-infrared range (VIS-NIR; 400 to 2499 nm), and a wet soil spectra\nmodel that can estimate the effects of water content on soil reflectance\nspectra given the dry spectrum predicted by the SOGM. The SOGM was up-scaled by\ncoupling with the Helios 3D plant modeling software, which allowed for\ngeneration of synthetic aerial images of simulated soil and plant scenes. It\ncan also be easily integrated with soil-plant radiation model used for remote\nsensin research like PROSAIL. The testing results of the SOGM on new datasets\nthat not included in model training proved that the model can generate\nreasonable soil reflectance spectra based on available property inputs. The\npresented models are openly accessible on:\nhttps://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation.",
      "tldr_zh": "本论文提出了一种基于文本输入的生成式深度学习模型 SOGM，用于模拟 VIS-NIR (400-2499 nm) 波段的土壤反射光谱，以解决土壤结构与成分复杂关系的模拟挑战。模型基于去噪扩散概率模型 (DDPM)，训练于近 18 万土壤光谱-属性对的数据集，能够从文本描述的土壤属性生成光谱，甚至处理不完整输入，并辅以子模型来填充光谱缺口和估计水分含量的影响。SOGM 可与 Helios 3D 植物建模软件整合，生成合成航空图像，并兼容 PROSAIL 等土壤-植物辐射模型。测试结果显示，该模型在新数据集上能产生合理的土壤反射光谱，并已开源于 https://github.com/GEMINI-Breeding/SOGM_soil_spectra_simulation。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been submitted to Remote sensing of Environment and\n  revised",
      "pdf_url": "http://arxiv.org/pdf/2405.01060v1",
      "published_date": "2024-05-02 07:34:12 UTC",
      "updated_date": "2024-05-02 07:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:31:29.583914"
    },
    {
      "arxiv_id": "2405.01055v2",
      "title": "Leverage Multi-source Traffic Demand Data Fusion with Transformer Model for Urban Parking Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Huang",
        "Yongqi Dong",
        "Youhua Tang",
        "Li Li"
      ],
      "abstract": "The escalation in urban private car ownership has worsened the urban parking\npredicament, necessitating effective parking availability prediction for urban\nplanning and management. However, the existing prediction methods suffer from\nlow prediction accuracy with the lack of spatial-temporal correlation features\nrelated to parking volume, and neglect of flow patterns and correlations\nbetween similar parking lots within certain areas. To address these challenges,\nthis study proposes a parking availability prediction framework integrating\nspatial-temporal deep learning with multi-source data fusion, encompassing\ntraffic demand data from multiple sources (e.g., metro, bus, taxi services),\nand parking lot data. The framework is based on the Transformer as the\nspatial-temporal deep learning model and leverages K-means clustering to\nestablish parking cluster zones, extracting and integrating traffic demand\ncharacteristics from various transportation modes (i.e., metro, bus, online\nride-hailing, and taxi) connected to parking lots. Real-world empirical data\nwas used to verify the effectiveness of the proposed method compared with\ndifferent machine learning, deep learning, and traditional statistical models\nfor predicting parking availability. Experimental results reveal that, with the\nproposed pipeline, the developed Transformer model outperforms other models in\nterms of various metrics, e.g., Mean Squared Error (MSE), Mean Absolute Error\n(MAE), and Mean Absolute Percentage Error (MAPE). By fusing multi-source\ndemanding data with spatial-temporal deep learning techniques, this approach\noffers the potential to develop parking availability prediction systems that\nfurnish more accurate and timely information to both drivers and urban\nplanners, thereby fostering more efficient and sustainable urban mobility.",
      "tldr_zh": "这篇论文针对城市停车预测的准确性问题，提出了一种整合多源交通需求数据融合的框架，使用Transformer模型作为空间-时间深度学习模型，并通过K-means聚类建立停车集群区，以提取和整合地铁、公交、在线叫车和出租车等交通模式的特征。相比传统机器学习、深度学习和统计模型，该框架在真实数据实验中表现出色，在Mean Squared Error (MSE)、Mean Absolute Error (MAE)和Mean Absolute Percentage Error (MAPE)指标上均有显著改善。最终，该方法为提供更准确及时的停车可用性信息，支持城市规划和可持续交通管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures, accepted by the 28th International Conference of\n  Hong Kong Society for Transportation Studies (HKSTS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.01055v2",
      "published_date": "2024-05-02 07:28:27 UTC",
      "updated_date": "2024-11-03 19:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:31:41.932828"
    },
    {
      "arxiv_id": "2405.01053v4",
      "title": "On the Universality of Self-Supervised Representation Learning",
      "title_zh": "论自监督表示学习的普遍性",
      "authors": [
        "Wenwen Qiang",
        "Jingyao Wang",
        "Lingyu Si",
        "Chuxiong Sun",
        "Fuchun Sun",
        "Hui Xiong"
      ],
      "abstract": "In this paper, we investigate the characteristics that define a good\nrepresentation or model. We propose that such a representation or model should\npossess universality, characterized by: (i) discriminability: performing well\non training samples; (ii) generalization: performing well on unseen datasets;\nand (iii) transferability: performing well on unseen tasks with distribution\nshifts. Despite its importance, current self-supervised learning (SSL) methods\nlack explicit modeling of universality, and theoretical analysis remains\nunderexplored. To address these issues, we aim to explore and incorporate\nuniversality into SSL. Specifically, we first revisit SSL from a task\nperspective and find that each mini-batch can be viewed as a multi-class\nclassification task. We then propose that a universal SSL model should achieve:\n(i) learning universality by minimizing loss across all training samples, and\n(ii) evaluation universality by learning causally invariant representations\nthat generalize well to unseen tasks. To quantify this, we introduce a\n$\\sigma$-measurement that assesses the gap between the performance of SSL model\nand optimal task-specific models. Furthermore, to model universality, we\npropose the GeSSL framework. It first learns task-specific models by minimizing\nSSL loss, then incorporates future updates to enhance discriminability, and\nfinally integrates these models to learn from multiple tasks. Theoretical and\nempirical evidence supports the effectiveness of GeSSL.",
      "tldr_zh": "这篇论文探讨了自监督学习 (SSL) 中表示的普遍性 (universality)，定义为三个关键特性：discriminability（在训练样本上表现良好）、generalization（在未见数据集上表现良好）和transferability（在分布偏移的未见任务上表现良好）。作者发现当前SSL方法缺乏对这些特性的明确建模和理论分析，因此从任务视角重新审视SSL，将每个mini-batch视为多类分类任务，并提出GeSSL框架，通过学习任务特定模型、增强discriminability并整合多任务来实现普遍性建模。论文引入σ-measurement来量化SSL模型与最优任务特定模型的性能差距，并通过理论和实证证据证明GeSSL的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01053v4",
      "published_date": "2024-05-02 07:15:23 UTC",
      "updated_date": "2025-02-17 12:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:31:54.385903"
    },
    {
      "arxiv_id": "2405.01035v1",
      "title": "LOQA: Learning with Opponent Q-Learning Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Aghajohari",
        "Juan Agustin Duque",
        "Tim Cooijmans",
        "Aaron Courville"
      ],
      "abstract": "In various real-world scenarios, interactions among agents often resemble the\ndynamics of general-sum games, where each agent strives to optimize its own\nutility. Despite the ubiquitous relevance of such settings, decentralized\nmachine learning algorithms have struggled to find equilibria that maximize\nindividual utility while preserving social welfare. In this paper we introduce\nLearning with Opponent Q-Learning Awareness (LOQA), a novel, decentralized\nreinforcement learning algorithm tailored to optimizing an agent's individual\nutility while fostering cooperation among adversaries in partially competitive\nenvironments. LOQA assumes the opponent samples actions proportionally to their\naction-value function Q. Experimental results demonstrate the effectiveness of\nLOQA at achieving state-of-the-art performance in benchmark scenarios such as\nthe Iterated Prisoner's Dilemma and the Coin Game. LOQA achieves these outcomes\nwith a significantly reduced computational footprint, making it a promising\napproach for practical multi-agent applications.",
      "tldr_zh": "论文介绍了 LOQA（Learning with Opponent Q-Learning Awareness），一种新型去中心化强化学习算法，旨在在一般和之和游戏环境中优化代理的个体效用，同时促进对手间的合作。LOQA 通过假设对手根据其行动价值函数 Q 采样动作，来预测和适应竞争性行为，从而解决现有算法在均衡和社交福利方面的不足。实验结果表明，LOQA 在 Iterated Prisoner's Dilemma 和 Coin Game 等基准场景中实现了最先进性能，同时显著降低了计算开销，使其适用于实际多智能体应用。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "accepted to ICLR but still not in proceedings\n  https://openreview.net/forum?id=FDQF6A1s6M",
      "pdf_url": "http://arxiv.org/pdf/2405.01035v1",
      "published_date": "2024-05-02 06:33:01 UTC",
      "updated_date": "2024-05-02 06:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:32:05.441806"
    },
    {
      "arxiv_id": "2405.01029v2",
      "title": "MVMoE: Multi-Task Vehicle Routing Solver with Mixture-of-Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Jianan Zhou",
        "Zhiguang Cao",
        "Yaoxin Wu",
        "Wen Song",
        "Yining Ma",
        "Jie Zhang",
        "Chi Xu"
      ],
      "abstract": "Learning to solve vehicle routing problems (VRPs) has garnered much\nattention. However, most neural solvers are only structured and trained\nindependently on a specific problem, making them less generic and practical. In\nthis paper, we aim to develop a unified neural solver that can cope with a\nrange of VRP variants simultaneously. Specifically, we propose a multi-task\nvehicle routing solver with mixture-of-experts (MVMoE), which greatly enhances\nthe model capacity without a proportional increase in computation. We further\ndevelop a hierarchical gating mechanism for the MVMoE, delivering a good\ntrade-off between empirical performance and computational complexity.\nExperimentally, our method significantly promotes zero-shot generalization\nperformance on 10 unseen VRP variants, and showcases decent results on the\nfew-shot setting and real-world benchmark instances. We further conduct\nextensive studies on the effect of MoE configurations in solving VRPs, and\nobserve the superiority of hierarchical gating when facing out-of-distribution\ndata. The source code is available at:\nhttps://github.com/RoyalSkye/Routing-MVMoE.",
      "tldr_zh": "本文提出 MVMoE，一种基于 Mixture-of-Experts (MoE) 的多任务车辆路径问题 (VRPs) 求解器，旨在同时处理多种 VRP 变体，提升模型的通用性和实用性。MVMoE 通过引入分层门控机制，显著增强模型容量，同时平衡计算复杂度和性能。实验结果显示，该方法在 10 个未见 VRP 变体上大幅提升零样本泛化性能，并在少样本设置和真实世界基准实例中表现出色。作者还对 MoE 配置进行了广泛研究，证明分层门控机制在面对分布外数据时具有明显优势。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01029v2",
      "published_date": "2024-05-02 06:02:07 UTC",
      "updated_date": "2024-05-06 11:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:32:19.460837"
    },
    {
      "arxiv_id": "2405.01022v3",
      "title": "UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "Yeonghwa Kim",
        "Seunguk Yu",
        "JungMin Yun",
        "YoungBin Kim"
      ],
      "abstract": "Although pre-trained language models have exhibited great flexibility and\nversatility with prompt-based few-shot learning, they suffer from the extensive\nparameter size and limited applicability for inference. Recent studies have\nsuggested that PLMs be used as dataset generators and a tiny task-specific\nmodel be trained to achieve efficient inference. However, their applicability\nto various domains is limited because they tend to generate domain-specific\ndatasets. In this work, we propose a novel approach to universal domain\ngeneralization that generates a dataset regardless of the target domain. This\nallows for generalization of the tiny task model to any domain that shares the\nlabel space, thus enhancing the real-world applicability of the dataset\ngeneration paradigm. Our experiments indicate that the proposed method\naccomplishes generalizability across various domains while using a parameter\nset that is orders of magnitude smaller than PLMs.",
      "tldr_zh": "该研究提出UniGen框架，通过zero-shot数据集生成实现情感分类的universal domain generalization，以解决预训练语言模型(PLMs)参数庞大和推理适用性有限的问题。UniGen使用PLMs作为数据集生成器，生成与目标领域无关的数据集，从而使小型任务特定模型能够在共享标签空间的任何领域泛化。实验结果表明，该方法在各种领域实现了良好的泛化性能，同时参数集比PLMs小几个数量级，提升了数据集生成范式的实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024: Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2405.01022v3",
      "published_date": "2024-05-02 05:46:13 UTC",
      "updated_date": "2024-09-22 08:58:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:32:29.810857"
    },
    {
      "arxiv_id": "2405.01016v4",
      "title": "Addressing Diverging Training Costs using BEVRestore for High-resolution Bird's Eye View Map Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Kim",
        "Giseop Kim",
        "Sunwook Choi"
      ],
      "abstract": "Recent advancements in Bird's Eye View (BEV) fusion for map construction have\ndemonstrated remarkable mapping of urban environments. However, their deep and\nbulky architecture incurs substantial amounts of backpropagation memory and\ncomputing latency. Consequently, the problem poses an unavoidable bottleneck in\nconstructing high-resolution (HR) BEV maps, as their large-sized features cause\nsignificant increases in costs including GPU memory consumption and computing\nlatency, named diverging training costs issue. Affected by the problem, most\nexisting methods adopt low-resolution (LR) BEV and struggle to estimate the\nprecise locations of urban scene components like road lanes, and sidewalks. As\nthe imprecision leads to risky motion planning like collision avoidance, the\ndiverging training costs issue has to be resolved. In this paper, we address\nthe issue with our novel BEVRestore mechanism. Specifically, our proposed model\nencodes the features of each sensor to LR BEV space and restores them to HR\nspace to establish a memory-efficient map constructor. To this end, we\nintroduce the BEV restoration strategy, which restores aliasing, and blocky\nartifacts of the up-scaled BEV features, and narrows down the width of the\nlabels. Our extensive experiments show that the proposed mechanism provides a\nplug-and-play, memory-efficient pipeline, enabling an HR map construction with\na broad BEV scope.",
      "tldr_zh": "本文研究了高分辨率 (HR) Bird's Eye View (BEV) 地图构建中存在的“diverging training costs”问题，即训练过程中 GPU 内存和计算延迟急剧增加，导致现有方法多采用低分辨率 (LR) BEV 并难以精确定位城市元素如道路车道和人行道。论文提出 BEVRestore 机制，将传感器特征先编码到 LR BEV 空间，然后通过恢复策略修复别名和块状伪影，并缩小标签宽度，从而实现内存高效的 HR 地图构建。该机制经广泛实验验证，提供了一个即插即用的管道，支持更广阔的 BEV 范围，并显著提升了城市场景映射的精度和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01016v4",
      "published_date": "2024-05-02 05:35:10 UTC",
      "updated_date": "2024-08-22 06:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:32:43.545306"
    },
    {
      "arxiv_id": "2405.01013v2",
      "title": "Non-clairvoyant Scheduling with Partial Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyad Benomar",
        "Vianney Perchet"
      ],
      "abstract": "The non-clairvoyant scheduling problem has gained new interest within\nlearning-augmented algorithms, where the decision-maker is equipped with\npredictions without any quality guarantees. In practical settings, access to\npredictions may be reduced to specific instances, due to cost or data\nlimitations. Our investigation focuses on scenarios where predictions for only\n$B$ job sizes out of $n$ are available to the algorithm. We first establish\nnear-optimal lower bounds and algorithms in the case of perfect predictions.\nSubsequently, we present a learning-augmented algorithm satisfying the\nrobustness, consistency, and smoothness criteria, and revealing a novel\ntradeoff between consistency and smoothness inherent in the scenario with a\nrestricted number of predictions.",
      "tldr_zh": "本文探讨了非先知调度(non-clairvoyant scheduling)问题，在学习增强算法的学习增强算法的背景下，仅对n个任务中的B个任务提供预测。研究首先建立了针对完美预测场景的近优下界和算法。接着，提出了一种满足鲁棒性(robustness)、一致性(consistency)和平滑性(smoothness)标准的学习增强算法，并揭示了在预测数量受限时，一致性和平滑性之间的新型权衡关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a conference paper at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.01013v2",
      "published_date": "2024-05-02 05:29:22 UTC",
      "updated_date": "2024-08-04 18:09:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:32:53.416388"
    },
    {
      "arxiv_id": "2405.01004v1",
      "title": "Deep Learning Models in Speech Recognition: Measuring GPU Energy Consumption, Impact of Noise and Model Quantization for Edge Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Chakravarty"
      ],
      "abstract": "Recent transformer-based ASR models have achieved word-error rates (WER)\nbelow 4%, surpassing human annotator accuracy, yet they demand extensive server\nresources, contributing to significant carbon footprints. The traditional\nserver-based architecture of ASR also presents privacy concerns, alongside\nreliability and latency issues due to network dependencies. In contrast,\non-device (edge) ASR enhances privacy, boosts performance, and promotes\nsustainability by effectively balancing energy use and accuracy for specific\napplications. This study examines the effects of quantization, memory demands,\nand energy consumption on the performance of various ASR model inference on the\nNVIDIA Jetson Orin Nano. By analyzing WER and transcription speed across models\nusing FP32, FP16, and INT8 quantization on clean and noisy datasets, we\nhighlight the crucial trade-offs between accuracy, speeds, quantization, energy\nefficiency, and memory needs. We found that changing precision from fp32 to\nfp16 halves the energy consumption for audio transcription across different\nmodels, with minimal performance degradation. A larger model size and number of\nparameters neither guarantees better resilience to noise, nor predicts the\nenergy consumption for a given transcription load. These, along with several\nother findings offer novel insights for optimizing ASR systems within energy-\nand memory-limited environments, crucial for the development of efficient\non-device ASR solutions. The code and input data needed to reproduce the\nresults in this article are open sourced are available on\n[https://github.com/zzadiues3338/ASR-energy-jetson].",
      "tldr_zh": "本研究探讨了基于 Transformer 的语音识别（ASR）模型在边缘部署中的能耗、噪声影响和模型量化问题，旨在解决传统服务器架构带来的碳足迹、隐私和延迟问题。研究在 NVIDIA Jetson Orin Nano 设备上测试了多种 ASR 模型，使用 FP32、FP16 和 INT8 量化水平评估 WER 和转录速度在干净及噪声数据集中的表现。结果显示，将精度从 FP32 切换到 FP16 可将音频转录能耗减半，同时性能损失最小；此外，模型大小和参数数量并不直接决定对噪声的鲁棒性或能耗预测。总体而言，此研究为优化能量和内存受限环境下的 ASR 系统提供了关键见解，并开源了相关代码以促进进一步开发。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.01004v1",
      "published_date": "2024-05-02 05:09:07 UTC",
      "updated_date": "2024-05-02 05:09:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:33:06.864920"
    },
    {
      "arxiv_id": "2405.00985v1",
      "title": "Progressive Feedforward Collapse of ResNet Training",
      "title_zh": "ResNet 训练中的渐进前向坍缩",
      "authors": [
        "Sicong Wang",
        "Kuo Gai",
        "Shihua Zhang"
      ],
      "abstract": "Neural collapse (NC) is a simple and symmetric phenomenon for deep neural\nnetworks (DNNs) at the terminal phase of training, where the last-layer\nfeatures collapse to their class means and form a simplex equiangular tight\nframe aligning with the classifier vectors. However, the relationship of the\nlast-layer features to the data and intermediate layers during training remains\nunexplored. To this end, we characterize the geometry of intermediate layers of\nResNet and propose a novel conjecture, progressive feedforward collapse (PFC),\nclaiming the degree of collapse increases during the forward propagation of\nDNNs. We derive a transparent model for the well-trained ResNet according to\nthat ResNet with weight decay approximates the geodesic curve in Wasserstein\nspace at the terminal phase. The metrics of PFC indeed monotonically decrease\nacross depth on various datasets. We propose a new surrogate model, multilayer\nunconstrained feature model (MUFM), connecting intermediate layers by an\noptimal transport regularizer. The optimal solution of MUFM is inconsistent\nwith NC but is more concentrated relative to the input data. Overall, this\nstudy extends NC to PFC to model the collapse phenomenon of intermediate layers\nand its dependence on the input data, shedding light on the theoretical\nunderstanding of ResNet in classification problems.",
      "tldr_zh": "这篇论文扩展了Neural Collapse (NC)概念，提出Progressive Feedforward Collapse (PFC)假设，描述了ResNet训练中特征塌缩现象如何在前向传播过程中逐层加深，并与输入数据相关联。研究者推导了一个透明模型，将ResNet与权重衰减下的Wasserstein空间测地线近似，并通过实验在多种数据集上验证PFC指标随深度单调递减。论文还引入Multilayer Unconstrained Feature Model (MUFM)，通过最优传输正则化连接中间层，其解比NC更集中于输入数据，从而深化了对ResNet在分类问题中的理论理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST",
        "stat.TH",
        "68T07",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.00985v1",
      "published_date": "2024-05-02 03:48:08 UTC",
      "updated_date": "2024-05-02 03:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:33:19.185908"
    },
    {
      "arxiv_id": "2405.00981v2",
      "title": "Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation",
      "title_zh": "翻译失败",
      "authors": [
        "David Eric Austin",
        "Anton Korikov",
        "Armin Toroghi",
        "Scott Sanner"
      ],
      "abstract": "Designing preference elicitation (PE) methodologies that can quickly\nascertain a user's top item preferences in a cold-start setting is a key\nchallenge for building effective and personalized conversational recommendation\n(ConvRec) systems. While large language models (LLMs) enable fully natural\nlanguage (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches\nlack the multi-turn, decision-theoretic reasoning required to effectively\nbalance the exploration and exploitation of user preferences towards an\narbitrary item set. In contrast, traditional Bayesian optimization PE methods\ndefine theoretically optimal PE strategies, but cannot generate arbitrary NL\nqueries or reason over content in NL item descriptions -- requiring users to\nexpress preferences via ratings or comparisons of unfamiliar items. To overcome\nthe limitations of both approaches, we formulate NL-PE in a Bayesian\nOptimization (BO) framework that seeks to actively elicit NL feedback to\nidentify the best recommendation. Key challenges in generalizing BO to deal\nwith natural language feedback include determining: (a) how to leverage LLMs to\nmodel the likelihood of NL preference feedback as a function of item utilities,\nand (b) how to design an acquisition function for NL BO that can elicit\npreferences in the infinite space of language. We demonstrate our framework in\na novel NL-PE algorithm, PEBOL, which uses: 1) Natural Language Inference (NLI)\nbetween user preference utterances and NL item descriptions to maintain\nBayesian preference beliefs, and 2) BO strategies such as Thompson Sampling\n(TS) and Upper Confidence Bound (UCB) to steer LLM query generation. We\nnumerically evaluate our methods in controlled simulations, finding that after\n10 turns of dialogue, PEBOL can achieve an MRR@10 of up to 0.27 compared to the\nbest monolithic LLM baseline's MRR@10 of 0.17, despite relying on earlier and\nsmaller LLMs.",
      "tldr_zh": "该论文提出了一种将Bayesian Optimization (BO) 与大型语言模型 (LLM) 相结合的框架，用于自然语言偏好elicitation (NL-PE)，旨在解决对话推荐系统在冷启动场景下快速识别用户首选项目的挑战。核心方法是PEBOL算法，它利用Natural Language Inference (NLI) 建模用户NL反馈的似然，并通过BO策略如Thompson Sampling (TS) 和Upper Confidence Bound (UCB) 来指导LLM生成查询，从而平衡偏好探索与利用。在模拟实验中，PEBOL在10轮对话后实现MRR@10高达0.27，显著优于单一LLM基线的0.17，展示了其在个性化推荐中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00981v2",
      "published_date": "2024-05-02 03:35:21 UTC",
      "updated_date": "2024-08-20 03:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:33:31.814758"
    },
    {
      "arxiv_id": "2405.00972v1",
      "title": "CACTUS: Chemistry Agent Connecting Tool-Usage to Science",
      "title_zh": "CACTUS：连接工具使用与科学的化学智能体",
      "authors": [
        "Andrew D. McNaughton",
        "Gautham Ramalaxmi",
        "Agustin Kruel",
        "Carter R. Knutson",
        "Rohith A. Varikoti",
        "Neeraj Kumar"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable potential in various\ndomains, but they often lack the ability to access and reason over\ndomain-specific knowledge and tools. In this paper, we introduced CACTUS\n(Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that\nintegrates cheminformatics tools to enable advanced reasoning and\nproblem-solving in chemistry and molecular discovery. We evaluate the\nperformance of CACTUS using a diverse set of open-source LLMs, including\nGemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of\nthousands of chemistry questions. Our results demonstrate that CACTUS\nsignificantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b\nmodels achieving the highest accuracy regardless of the prompting strategy\nused. Moreover, we explore the impact of domain-specific prompting and hardware\nconfigurations on model performance, highlighting the importance of prompt\nengineering and the potential for deploying smaller models on consumer-grade\nhardware without significant loss in accuracy. By combining the cognitive\ncapabilities of open-source LLMs with domain-specific tools, CACTUS can assist\nresearchers in tasks such as molecular property prediction, similarity\nsearching, and drug-likeness assessment. Furthermore, CACTUS represents a\nsignificant milestone in the field of cheminformatics, offering an adaptable\ntool for researchers engaged in chemistry and molecular discovery. By\nintegrating the strengths of open-source LLMs with domain-specific tools,\nCACTUS has the potential to accelerate scientific advancement and unlock new\nfrontiers in the exploration of novel, effective, and safe therapeutic\ncandidates, catalysts, and materials. Moreover, CACTUS's ability to integrate\nwith automated experimentation platforms and make data-driven decisions in real\ntime opens up new possibilities for autonomous discovery.",
      "tldr_zh": "本研究引入了 CACTUS（Chemistry Agent Connecting Tool-Usage to Science），这是一个基于大型语言模型（LLMs）的代理系统，将化学信息学工具整合进来，以提升化学和分子发现领域的推理与问题解决能力。研究评估了多种开源 LLMs（如 Gemma-7b、Falcon-7b 和 Mistral-7b）在数千个化学问题基准上的表现，结果显示 CACTUS 显著优于基线模型，其中 Gemma-7b 和 Mistral-7b 实现了最高准确率，且提示策略和硬件配置对性能影响重大。通过结合 LLMs 的认知能力与领域特定工具，CACTUS 可辅助分子属性预测、相似性搜索和药物特性评估，并有望加速科学进步和自主发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "physics.chem-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00972v1",
      "published_date": "2024-05-02 03:20:08 UTC",
      "updated_date": "2024-05-02 03:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:33:44.804231"
    },
    {
      "arxiv_id": "2405.00970v1",
      "title": "How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Jionghao Lin",
        "Zifei Han",
        "Danielle R. Thomas",
        "Ashish Gurung",
        "Shivang Gupta",
        "Vincent Aleven",
        "Kenneth R. Koedinger"
      ],
      "abstract": "One-on-one tutoring is widely acknowledged as an effective instructional\nmethod, conditioned on qualified tutors. However, the high demand for qualified\ntutors remains a challenge, often necessitating the training of novice tutors\n(i.e., trainees) to ensure effective tutoring. Research suggests that providing\ntimely explanatory feedback can facilitate the training process for trainees.\nHowever, it presents challenges due to the time-consuming nature of assessing\ntrainee performance by human experts. Inspired by the recent advancements of\nlarge language models (LLMs), our study employed the GPT-4 model to build an\nexplanatory feedback system. This system identifies trainees' responses in\nbinary form (i.e., correct/incorrect) and automatically provides template-based\nfeedback with responses appropriately rephrased by the GPT-4 model. We\nconducted our study on 410 responses from trainees across three training\nlessons: Giving Effective Praise, Reacting to Errors, and Determining What\nStudents Know. Our findings indicate that: 1) using a few-shot approach, the\nGPT-4 model effectively identifies correct/incorrect trainees' responses from\nthree training lessons with an average F1 score of 0.84 and an AUC score of\n0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases\nincorrect trainees' responses into desired responses, achieving performance\ncomparable to that of human experts.",
      "tldr_zh": "这篇论文探讨了使用 GPT-4 构建一个自动反馈系统，以帮助培训新手导师（trainees），通过识别响应正确性并重新表述不正确的内容。系统采用 few-shot 方法，对 410 个学员响应进行二元分类（correct/incorrect），在三个训练课程（Giving Effective Praise, Reacting to Errors, and Determining What Students Know）上实现了平均 F1 score 0.84 和 AUC score 0.85 的性能。结果显示，GPT-4 重新表述不正确响应的效果与人类专家相当，从而为高效的导师培训提供了一种可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "International Journal of Artificial Intelligence in Education",
      "pdf_url": "http://arxiv.org/pdf/2405.00970v1",
      "published_date": "2024-05-02 03:18:03 UTC",
      "updated_date": "2024-05-02 03:18:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:33:56.915967"
    },
    {
      "arxiv_id": "2405.00966v1",
      "title": "Efficient Compression of Multitask Multilingual Speech Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Palmeira Ferraz"
      ],
      "abstract": "Whisper is a multitask and multilingual speech model covering 99 languages.\nIt yields commendable automatic speech recognition (ASR) results in a subset of\nits covered languages, but the model still underperforms on a non-negligible\nnumber of under-represented languages, a problem exacerbated in smaller model\nversions. In this work, we examine its limitations, demonstrating the presence\nof speaker-related (gender, age) and model-related (resourcefulness and model\nsize) bias. Despite that, we show that only model-related bias are amplified by\nquantization, impacting more low-resource languages and smaller models.\nSearching for a better compression approach, we propose DistilWhisper, an\napproach that is able to bridge the performance gap in ASR for these languages\nwhile retaining the advantages of multitask and multilingual capabilities. Our\napproach involves two key strategies: lightweight modular ASR fine-tuning of\nwhisper-small using language-specific experts, and knowledge distillation from\nwhisper-large-v2. This dual approach allows us to effectively boost ASR\nperformance while keeping the robustness inherited from the multitask and\nmultilingual pre-training. Results demonstrate that our approach is more\neffective than standard fine-tuning or LoRA adapters, boosting performance in\nthe targeted languages for both in- and out-of-domain test sets, while\nintroducing only a negligible parameter overhead at inference.",
      "tldr_zh": "该研究分析了Whisper多任务多语言语音模型在99种语言中的局限性，特别是低资源语言的ASR性能较差，并揭示了说话者相关（如性别、年龄）和模型相关（如资源和大小）的偏差，其中量化会放大模型相关偏差。  \n为了解决这些问题，作者提出DistilWhisper方法，结合语言特定专家的轻量级ASR微调和从whisper-large-v2的知识蒸馏，显著提升了低资源语言的ASR性能，同时保留了多任务和多语言优势。  \n实验结果表明，DistilWhisper比标准微调或LoRA适配器更有效，在内部和外部测试集上提升了目标语言的性能，只引入微不足道的参数开销。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Master Thesis",
      "pdf_url": "http://arxiv.org/pdf/2405.00966v1",
      "published_date": "2024-05-02 03:11:59 UTC",
      "updated_date": "2024-05-02 03:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:34:09.173816"
    },
    {
      "arxiv_id": "2405.00960v2",
      "title": "Foundations for Digital Twins",
      "title_zh": "数字孪生的基础",
      "authors": [
        "Finn Wilson",
        "Regina Hurley",
        "Dan Maxwell",
        "Jon McLellan",
        "John Beverley"
      ],
      "abstract": "The growing reliance on digital twins across various industries and domains\nbrings with it semantic interoperability challenges. Ontologies are a\nwell-known strategy for addressing such challenges, though given the complexity\nof the phenomenon, there are risks of reintroducing the interoperability\nchallenges at the level of ontology representations. In the interest of\navoiding such pitfalls, we introduce and defend characterizations of digital\ntwins within the context of the Common Core Ontologies, an extension of the\nwidely-used Basic Formal Ontology. We provide a set of definitions and design\npatterns relevant to the domain of digital twins, highlighted by illustrative\nuse cases of digital twins and their physical counterparts. In doing so, we\nprovide a foundation on which to build more sophisticated ontological content\nrelated and connected to digital twins.",
      "tldr_zh": "该论文探讨了数字孪生（digital twins）在各行业应用中面临的语义互操作性（semantic interoperability）挑战，并提出使用本体论（Ontologies）作为解决方案，以避免在本体表示层面重新引入问题。作者基于 Common Core Ontologies（一种 Basic Formal Ontology 的扩展），提供了数字孪生的定义、设计模式，并通过示例用例说明其与物理对应物的关系。最终，该工作为构建更复杂的数字孪生相关本体内容奠定了基础，促进了跨领域的互操作性。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "14",
      "pdf_url": "http://arxiv.org/pdf/2405.00960v2",
      "published_date": "2024-05-02 02:52:11 UTC",
      "updated_date": "2024-08-16 03:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:34:19.288357"
    },
    {
      "arxiv_id": "2405.00958v2",
      "title": "Generative manufacturing systems using diffusion models and ChatGPT",
      "title_zh": "基于扩散模型和 ChatGPT 的生成式制造系统",
      "authors": [
        "Xingyu Li",
        "Fei Tao",
        "Wei Ye",
        "Aydin Nassehi",
        "John W. Sutherland"
      ],
      "abstract": "In this study, we introduce Generative Manufacturing Systems (GMS) as a novel\napproach to effectively manage and coordinate autonomous manufacturing assets,\nthereby enhancing their responsiveness and flexibility to address a wide array\nof production objectives and human preferences. Deviating from traditional\nexplicit modeling, GMS employs generative AI, including diffusion models and\nChatGPT, for implicit learning from envisioned futures, marking a shift from a\nmodel-optimum to a training-sampling decision-making. Through the integration\nof generative AI, GMS enables complex decision-making through interactive\ndialogue with humans, allowing manufacturing assets to generate multiple\nhigh-quality global decisions that can be iteratively refined based on human\nfeedback. Empirical findings showcase GMS's substantial improvement in system\nresilience and responsiveness to uncertainties, with decision times reduced\nfrom seconds to milliseconds. The study underscores the inherent creativity and\ndiversity in the generated solutions, facilitating human-centric\ndecision-making through seamless and continuous human-machine interactions.",
      "tldr_zh": "本文提出 Generative Manufacturing Systems (GMS)，一种创新框架，利用 diffusion models 和 ChatGPT 等生成式 AI 来管理自治制造资产，提升其响应性和灵活性。GMS 通过隐式学习从预想未来中生成决策，并支持人与机器的交互对话，实现多个高质量决策的迭代优化。与传统方法相比，实验结果显示 GMS 显著提高了系统韧性，将决策时间从秒级缩短至毫秒级，并促进了创造性解决方案和以人为中心的决策过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "We are withdrawing this preprint to incorporate significant new\n  results and expand the scope of the paper. We plan to resubmit a\n  substantially revised version in the near future",
      "pdf_url": "http://arxiv.org/pdf/2405.00958v2",
      "published_date": "2024-05-02 02:50:58 UTC",
      "updated_date": "2025-01-08 23:16:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:34:32.168006"
    },
    {
      "arxiv_id": "2405.00957v2",
      "title": "IntraMix: Intra-Class Mixup Generation for Accurate Labels and Neighbors",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghe Zheng",
        "Hongzhi Wang",
        "Xianglong Liu"
      ],
      "abstract": "Graph Neural Networks (GNNs) have shown great performance in various tasks,\nwith the core idea of learning from data labels and aggregating messages within\nthe neighborhood of nodes. However, the common challenges in graphs are\ntwofold: insufficient accurate (high-quality) labels and limited neighbors for\nnodes, resulting in weak GNNs. Existing graph augmentation methods typically\naddress only one of these challenges, often adding training costs or relying on\noversimplified or knowledge-intensive strategies, limiting their\ngeneralization. To simultaneously address both challenges faced by graphs in a\ngeneralized way, we propose an elegant method called IntraMix. Considering the\nincompatibility of vanilla Mixup with the complex topology of graphs, IntraMix\ninnovatively employs Mixup among inaccurate labeled data of the same class,\ngenerating high-quality labeled data at minimal cost. Additionally, it finds\ndata with high confidence of being clustered into the same group as the\ngenerated data to serve as their neighbors, thereby enriching the neighborhoods\nof graphs. IntraMix efficiently tackles both issues faced by graphs and\nchallenges the prior notion of the limited effectiveness of Mixup in node\nclassification. IntraMix is a theoretically grounded plug-in-play method that\ncan be readily applied to all GNNs. Extensive experiments demonstrate the\neffectiveness of IntraMix across various GNNs and datasets. Our code is\navailable at: https://github.com/Zhengsh123/IntraMix.",
      "tldr_zh": "论文提出 IntraMix，一种创新方法，用于同时解决图神经网络 (GNNs) 中标签不准确和高质标签不足以及节点邻居有限的问题。IntraMix 通过在同一类别的标签不准确数据之间进行 Mixup 生成高质量标签，同时为这些数据寻找高置信度同组数据作为邻居，从而丰富图的拓扑结构。该方法作为理论基础坚实的即插即用插件，在多种 GNNs 和数据集上的实验中显著提升了性能，并提供开源代码以便应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00957v2",
      "published_date": "2024-05-02 02:38:32 UTC",
      "updated_date": "2024-11-01 03:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:34:44.461071"
    },
    {
      "arxiv_id": "2405.00950v1",
      "title": "Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown Transitions and Bandit Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Guojun Xiong",
        "Jian Li"
      ],
      "abstract": "Restless multi-armed bandits (RMAB) play a central role in modeling\nsequential decision making problems under an instantaneous activation\nconstraint that at most B arms can be activated at any decision epoch. Each\nrestless arm is endowed with a state that evolves independently according to a\nMarkov decision process regardless of being activated or not. In this paper, we\nconsider the task of learning in episodic RMAB with unknown transition\nfunctions and adversarial rewards, which can change arbitrarily across\nepisodes. Further, we consider a challenging but natural bandit feedback\nsetting that only adversarial rewards of activated arms are revealed to the\ndecision maker (DM). The goal of the DM is to maximize its total adversarial\nrewards during the learning process while the instantaneous activation\nconstraint must be satisfied in each decision epoch. We develop a novel\nreinforcement learning algorithm with two key contributors: a novel biased\nadversarial reward estimator to deal with bandit feedback and unknown\ntransitions, and a low-complexity index policy to satisfy the instantaneous\nactivation constraint. We show $\\tilde{\\mathcal{O}}(H\\sqrt{T})$ regret bound\nfor our algorithm, where $T$ is the number of episodes and $H$ is the episode\nlength. To our best knowledge, this is the first algorithm to ensure\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret for adversarial RMAB in our considered\nchallenging settings.",
      "tldr_zh": "这篇论文研究了在未知转移函数和对抗性奖励下的 Restless Multi-Armed Bandits (RMAB) 问题，其中每个臂的状态根据 Markov Decision Process 独立演化，且仅激活臂的奖励被揭示给决策者，同时必须满足最多 B 个臂的即时激活约束。作者开发了一种新型强化学习算法，包括一个偏置对抗性奖励估计器（biased adversarial reward estimator）来处理 bandit feedback，以及一个低复杂度索引策略（low-complexity index policy）来确保约束满足。该算法实现了 \\(\\tilde{\\mathcal{O}}(H\\sqrt{T})\\) 的遗憾界，这是首次在这些挑战性设置下确保 \\(\\tilde{\\mathcal{O}}(\\sqrt{T})\\) 遗憾的算法，为对抗性 RMAB 的高效学习提供了理论保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.00950v1",
      "published_date": "2024-05-02 02:20:19 UTC",
      "updated_date": "2024-05-02 02:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:34:58.415016"
    },
    {
      "arxiv_id": "2405.17436v1",
      "title": "Intelligent Hybrid Resource Allocation in MEC-assisted RAN Slicing Network",
      "title_zh": "翻译失败",
      "authors": [
        "Chong Zheng",
        "Yongming Huang",
        "Cheng Zhang",
        "Tony Q. S. Quek"
      ],
      "abstract": "In this paper, we aim to maximize the SSR for heterogeneous service demands\nin the cooperative MEC-assisted RAN slicing system by jointly considering the\nmulti-node computing resources cooperation and allocation, the transmission\nresource blocks (RBs) allocation, and the time-varying dynamicity of the\nsystem. To this end, we abstract the system into a weighted undirected topology\ngraph and, then propose a recurrent graph reinforcement learning (RGRL)\nalgorithm to intelligently learn the optimal hybrid RA policy. Therein, the\ngraph neural network (GCN) and the deep deterministic policy gradient (DDPG) is\ncombined to effectively extract spatial features from the equivalent topology\ngraph. Furthermore, a novel time recurrent reinforcement learning framework is\ndesigned in the proposed RGRL algorithm by incorporating the action output of\nthe policy network at the previous moment into the state input of the policy\nnetwork at the subsequent moment, so as to cope with the time-varying and\ncontextual network environment. In addition, we explore two use case scenarios\nto discuss the universal superiority of the proposed RGRL algorithm. Simulation\nresults demonstrate the superiority of the proposed algorithm in terms of the\naverage SSR, the performance stability, and the network complexity.",
      "tldr_zh": "本研究针对合作 MEC-assisted RAN Slicing 系统，旨在通过联合考虑多节点计算资源合作、传输资源块 (RBs) 分配以及系统的时间变动态，最大化异构服务需求的 SSR (Service Satisfaction Rate)。为此，作者将系统抽象为加权无向拓扑图，并提出一种循环图强化学习 (RGRL) 算法，结合图神经网络 (GCN) 和深度确定性策略梯度 (DDPG) 来提取空间特征，并设计时间循环框架以应对动态网络环境。RGRL 算法将前一时刻的策略网络输出融入后续状态输入，提升了对上下文的适应性。模拟结果显示，该算法在平均 SSR、性能稳定性和网络复杂度方面均优于基线方法，证明了其通用优势。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17436v1",
      "published_date": "2024-05-02 01:36:13 UTC",
      "updated_date": "2024-05-02 01:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:35:08.711858"
    },
    {
      "arxiv_id": "2405.00915v2",
      "title": "EchoScene: Indoor Scene Generation via Information Echo over Scene Graph Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyao Zhai",
        "Evin Pınar Örnek",
        "Dave Zhenyu Chen",
        "Ruotong Liao",
        "Yan Di",
        "Nassir Navab",
        "Federico Tombari",
        "Benjamin Busam"
      ],
      "abstract": "We present EchoScene, an interactive and controllable generative model that\ngenerates 3D indoor scenes on scene graphs. EchoScene leverages a dual-branch\ndiffusion model that dynamically adapts to scene graphs. Existing methods\nstruggle to handle scene graphs due to varying numbers of nodes, multiple edge\ncombinations, and manipulator-induced node-edge operations. EchoScene overcomes\nthis by associating each node with a denoising process and enables\ncollaborative information exchange, enhancing controllable and consistent\ngeneration aware of global constraints. This is achieved through an information\necho scheme in both shape and layout branches. At every denoising step, all\nprocesses share their denoising data with an information exchange unit that\ncombines these updates using graph convolution. The scheme ensures that the\ndenoising processes are influenced by a holistic understanding of the scene\ngraph, facilitating the generation of globally coherent scenes. The resulting\nscenes can be manipulated during inference by editing the input scene graph and\nsampling the noise in the diffusion model. Extensive experiments validate our\napproach, which maintains scene controllability and surpasses previous methods\nin generation fidelity. Moreover, the generated scenes are of high quality and\nthus directly compatible with off-the-shelf texture generation. Code and\ntrained models are open-sourced.",
      "tldr_zh": "我们提出了EchoScene，一种基于场景图的交互式3D室内场景生成模型，使用双分支扩散模型动态适应场景图的节点和边操作问题。\n该模型引入information echo方案，通过节点去噪过程和图卷积信息交换，确保生成场景的全局连贯性和可控性，支持用户通过编辑输入场景图和采样噪声进行操作。\n实验验证显示，EchoScene在生成保真度上超越现有方法，生成的场景高质量且直接兼容纹理生成，且代码和模型已开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Nectar Track at 3DV 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.00915v2",
      "published_date": "2024-05-02 00:04:02 UTC",
      "updated_date": "2025-02-27 12:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T05:35:20.734774"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T05:35:44.907472"
}